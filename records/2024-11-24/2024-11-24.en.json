[
  {
    "id": 42225481,
    "title": "Frosted Glass from Games to the Web: HTML glass UI inspired by AAA game dev",
    "originLink": "https://www.tyleo.com/html-glass.html",
    "originBody": "tyleo.com Frosted Glass from Games to the Web Crafting beautiful HTML glass UI inspired by AAA game development. During my time as a UI developer for Forza Horizon 3 and Forza Motorsport 7, I had the opportunity to work with stunning frosted acrylic design elements. Here's an example from Horizon 3: Inspired by this design, I've always wanted to create a similar effect using HTML. On this page, I share my attempt at achieving a beautiful glass effect, along with sample code and assets for anyone who wants to explore this technique themselves. Here's a look at the final product: Toggle Fill Space Drag Me Final Recipe Lookahead Before diving into the core of this tutorial, some readers may prefer to skip straight to the final recipe so they can paste it right into their own page. Those readers can find it conveniently tucked away in this toggle. Toggle final recipe Light Reflection Asset JavaScript Version This works on all platforms. HTML 1 2 3 4 Drag Me CSS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025), /* Long subsurface effect */ inset 0px 0px 40px 5px rgba(255, 255, 255, 0.025); /* Round the corners */ border-radius: 5px; /* Hide the corners of the header */ overflow: hidden;} .light { /* Apply the background image */ background-image: url(path/to/light.png); background-repeat: repeat; background-size: 750px; /* Adjust the intensity */ opacity: 0.075; /* Fill the background space */ position: absolute; bottom: 0; left: 0; right: 0; top: 0; /* Render behind other children */ z-index: -1;} .drag-me { /* Center the content */ display: flex; align-items: center; justify-content: center; /* Size the content */ height: 30px; /* Add a transparent background */ background-color: rgba(12, 13, 14, 0.75);} JS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * Iterates through all `HTMLElement`s with * `data-js-background-attachment-fixed` and updates the `background-position` * to simulate `background-attachment: fixed`. */const updateDataJSBackgroundAttachmentFixedElements = () => { // Find all elements with the `data-js-background-attachment-fixed` attribute const elements = document.querySelectorAll( \"[data-js-background-attachment-fixed]\", ); for (const element of elements) { // Only consider `HTMLElement`s if (!(element instanceof HTMLElement)) continue; // Find the position of the element const clientRect = element.getBoundingClientRect(); // Move the background position opposite the position in the viewport const backgroundPositionX = `${(-clientRect.x).toString()}px`; const backgroundPositionY = `${(-clientRect.y).toString()}px`; element.style.backgroundPositionX = backgroundPositionX; element.style.backgroundPositionY = backgroundPositionY; }}; /** * Begins a loop which simulates `background-attachment: fixed` for * `HTMLElement`s with `data-js-background-attachment-fixed`. * * This loop executes each animation frame. */const initDataJSBackgroundAttachmentFixed = () => { requestAnimationFrame(() => { updateDataJSBackgroundAttachmentFixedElements(); initDataJSBackgroundAttachmentFixed(); });}; initDataJSBackgroundAttachmentFixed(); Non-JavaScript Version This won't work on every platform. HTML 1 2 3Drag Me CSS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025), /* Long subsurface effect */ inset 0px 0px 40px 5px rgba(255, 255, 255, 0.025); /* Round the corners */ border-radius: 5px; /* Hide the corners of the header */ overflow: hidden;} .glass::before { /* Make the element render */ content: \"\"; /* Apply the background image */ background-image: url(path/to/light.png); background-repeat: repeat; background-size: 750px; /* Adjust the intensity */ opacity: 0.075; /* Fill the background space */ position: absolute; bottom: 0; left: 0; right: 0; top: 0; /* Render behind other children */ z-index: -1; /* Fix the reflection to the screen */ background-attachment: fixed;} .drag-me { /* Center the content */ display: flex; align-items: center; justify-content: center; /* Size the content */ height: 30px; /* Add a transparent background */ background-color: rgba(12, 13, 14, 0.75);} Now, on with the show! backdrop-filter Does Heavy Lifting The key to a good frosted glass effect is using a Gaussian blur to obscure the background, mimicing the look of a translucent screen. Most browsers and game engines efficiently approximate Gaussian blurs by using box blurs. In CSS, Gaussian blurs can be applied by using backdrop-filter with the blur function. On iOS -webpkit-backdrop-filter is required unless you go deep into the settings where no man has ventured before (Settings -> Safari -> Advanced -> Feature Flags -> 'CSS Unprefixed Backdrop Filter'). Box blur is only recently supported by browsers. So Internet Explorer users can't experience these demos. Putting this all together, our glass is a simple div: 1We style the div with a glass class: 1 2 3 4 5 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px);} This is the result. Drag it to see how the blur interacts with the background. Toggle Fill Space Adding Depth We've crafted a respectable piece of glass using backdrop-filter: blur(10px). Many guides stop here, but there's room for improvement! Right now, our glass looks flat and boring. Real glass has an interesting visual character around its edges that we're missing. Let's bring that to life. Edges First we'll add edges to our glass. Others, like css.glass, do this using border: 1px solid. Borders affect the element's size and how it interacts with children. I prefer using box-shadow: inset. By using box-shadow: inset the children seamlessly fill the content area of the glass without negative margins or other magic. This allows them to behave like decals applied to the glass surface. box-shadow requires at least two size values and supports up to four. The first two define the shadow's x and y offsets. To mimic the edges of glass, we use two translucent white box-shadows. The first shadow represents the edge of the glass as seen from outside. In our example this appears along the bottom and left edges. The second shadow represents the edge as seen through the glass. In our example this appears along the top and right edges. Since light diminishes when viewing the edge through the glass, the top and left edges are softer and more translucent compared to the bottom and right edges. This subtle difference creates the illusion that the glass is slightly elevated at the bottom-right corner. 1 2 3 4 5 6 7 8 9 10 11 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025);} Toggle Fill Space Real Shadow Our glass now has some nice depth, but something still feels off—it has that uncanny appearance of a 3D object trapped in 2D space. To fix this, let's make it look physically raised from the background. Thankfully, there's a simple CSS trick for this: a traditional, dark box-shadow. Let's add a box-shadow proportional to the size of our edges to create the desired lift effect: 1 2 3 4 5 6 7 8 9 10 11 12 13 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25);} Toggle Fill Space Blending in Light Our glass has a nice depth and we're at a great stopping point. In comparison to other glass designs we are already ahead of the curve—but there's more to do! Lets shift our focus to the interaction between glass and light. Simple Subsurface Scattering We'll start playing with light by introducing a subsurface scattering approximation. Subsurface scattering refers to the way light disperses within a translucent surface. For glass, this is most noticable around the edges. We will use box-shadow: inset to simulate this effect. This will add a subtle layer of light that penetrates slightly into the glass from the edges. To fully appreciate the effect, try dragging the glass over a darker area of the image. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025);} Toggle Fill Space More Subsurface Scattering As you can see, the subsurface scattering is subtle. Lets add another, deeper layer to enhance it further. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025), /* Long subsurface effect */ inset 0px 0px 40px 5px rgba(255, 255, 255, 0.025);} Toggle Fill Space More Interesting Light We've done a good job refracting light from the background through our glass element. But another key characteristic of glass is its ability to reflect light off its surface. This reflective quality is the secret sauce to give our glass a distinctive look from other HTML glass examples. Rays of Light We'll blend in a image of light rays to create this effect. If you're interested in creating a similar image yourself, there are plenty of tutorials online. Here's one from YouTube, and here's a detailed textual walkthrough if you prefer that approach. Alternatively, you can use download and use these light rays I created: We'll explore a few ways to blend this image into the background. The first is to set it as the background-image of our glass element. Doing this directly on the element causes the box-filter to blur the background-image—we don't want that. Instead, we can apply the background-image to a pseudo child element using ::before. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 .glass::before { /* Make the element render */ content: \"\"; /* Apply the background image */ background-image: url(path/to/light.png); background-repeat: repeat; background-size: 750px; /* Adjust the intensity */ opacity: 0.075; /* Fill the background space */ position: absolute; bottom: 0; left: 0; right: 0; top: 0; /* Render behind other children */ z-index: -1;} Use the \"Toggle Fill Space\" option to most easily observe this effect. Toggle Fill Space Dynamic Light Our light rays are blending nicely, but they appear static on the glass. In reality, moving glass through light creates dynamic reflections as the light shifts across the glass surface. Unfortunately, replicating this effect across all browsers is challenging. To address this, we'll explore two solutions: a pure CSS approach that works on most platforms except mobile, and a CSS + JavaScript solution which works everywhere. The CSS solution is satisfyingly simple. We just add background-attachement: fixed to our ::before element. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 .glass::before { /* Make the element render */ content: \"\"; /* Apply the background image */ background-image: url(path/to/light.png); background-repeat: repeat; background-size: 750px; /* Adjust the intensity */ opacity: 0.075; /* Fill the background space */ position: absolute; bottom: 0; left: 0; right: 0; top: 0; /* Render behind other children */ z-index: -1; /* Fix the reflection to the screen */ background-attachment: fixed;} Use the \"Toggle Fill Space\" option and scroll or move the glass to observe the effect. Keep in mind that mobile support may be limited; we'll address this in the next example. Toggle Fill Space Cross-Platform Dynamic Light We'll use JavaScript to simulate background-attachment: fixed on all platforms :(. To achieve the effect, we'll dynamically adjust the background-position as the image moves within the viewport. Since accessing ::before elements directly from JavaScript is inefficient, we'll use a div instead. Our JavaScript will target elements with a specific data-* attribute. We'll use the attribute data-js-background-attachment-fixed. Putting this all together, we now have two divs: 1 2 3 We style the new child div with a light class: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 .light { /* Apply the background image */ background-image: url(path/to/light.png); background-repeat: repeat; background-size: 750px; /* Adjust the intensity */ opacity: 0.075; /* Fill the background space */ position: absolute; bottom: 0; left: 0; right: 0; top: 0; /* Render behind other children */ z-index: -1;} This JavaScript updates our background: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * Iterates through all `HTMLElement`s with * `data-js-background-attachment-fixed` and updates the `background-position` * to simulate `background-attachment: fixed`. */const updateDataJSBackgroundAttachmentFixedElements = () => { // Find all elements with the `data-js-background-attachment-fixed` attribute const elements = document.querySelectorAll( \"[data-js-background-attachment-fixed]\", ); for (const element of elements) { // Only consider `HTMLElement`s if (!(element instanceof HTMLElement)) continue; // Find the position of the element const clientRect = element.getBoundingClientRect(); // Move the background position opposite the position in the viewport const backgroundPositionX = `${(-clientRect.x).toString()}px`; const backgroundPositionY = `${(-clientRect.y).toString()}px`; element.style.backgroundPositionX = backgroundPositionX; element.style.backgroundPositionY = backgroundPositionY; }}; /** * Begins a loop which simulates `background-attachment: fixed` for * `HTMLElement`s with `data-js-background-attachment-fixed`. * * This loop executes each animation frame. */const initDataJSBackgroundAttachmentFixed = () => { requestAnimationFrame(() => { updateDataJSBackgroundAttachmentFixedElements(); initDataJSBackgroundAttachmentFixed(); });}; initDataJSBackgroundAttachmentFixed(); Use the \"Toggle Fill Space\" option and scroll or move the glass to observe the effect. Toggle Fill Space Bits n' Bobs Now that our glass effect is complete, let's finalize it by adding the remaining CSS properties and HTML to fully replicate our initial example. That means beautiful rounded corners and extra elements to enhance the glass with color and text. Rounded Corners Rounding the corners of our glass is straightforward—simply use the border-radius property. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025), /* Long subsurface effect */ inset 0px 0px 40px 5px rgba(255, 255, 255, 0.025); /* Round the corners */ border-radius: 5px;} Toggle Fill Space Colored Glass To color our glass, we'll add one final element on top, using a background-color with an alpha value for translucency. Since our glass has rounded corners, the child element will extend beyond the glass surface. To prevent this, we'll use overflow: hidden to clip it. Here is our final HTML: 1 2 3 4 Drag Me And our final CSS for the glass and drag-me classes: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 .glass { /* Blur effect */ backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); box-shadow: /* Bottom and right depth effect */ inset -0.75px -0.5px rgba(255, 255, 255, 0.1), /* Top and left depth effect */ inset +0.75px +0.5px rgba(255, 255, 255, 0.025), /* Shadow effect */ 3px 2px 10px rgba(0, 0, 0, 0.25), /* Short subsurface effect */ inset 0px 0px 10px 5px rgba(255, 255, 255, 0.025), /* Long subsurface effect */ inset 0px 0px 40px 5px rgba(255, 255, 255, 0.025); /* Round the corners */ border-radius: 5px; /* Hide the corners of the header */ overflow: hidden;} .drag-me { /* Center the content */ display: flex; align-items: center; justify-content: center; /* Size the content */ height: 30px; /* Add a transparent background */ background-color: rgba(12, 13, 14, 0.75);} Rendering it out we see our old friend: Toggle Fill Space Drag Me Thanks for Staying! Thanks for following along as we created an amazing glass effect! I hope you enjoyed the journey. For a quick way to copy all the assets and code, don't forget to check out the Final Recipe Lookahead section near the beginning. Discuss on Hacker News",
    "commentLink": "https://news.ycombinator.com/item?id=42225481",
    "commentBody": "Frosted Glass from Games to the Web: HTML glass UI inspired by AAA game dev (tyleo.com)612 points by tyleo 16 hours agohidepastfavorite141 comments schobi 9 hours agoI really like the aestectics, even if physically wrong at the edges. Thanks for sharing the details. As a embedded developer, I feel this is kind of wasteful. Every client computes an \"expensive\" blur filter, over an over again? Just for blending to a blurred version of the background image? I know - this is using the GPU, this is optimized. In the end, this should not be much. (is it really?)I feel the general trend with current web development is too much bloat. Simple sites take 5 seconds to load? Heavy lifting on the client? ... but not the authors fault reply pavlov 7 hours agoparentI guess everybody has their own preconceptions of what's wasteful. I grew up in the era of 14.4k modems, so I'm used to thinking that network bandwidth is many, many orders of magnitude more scarce and valuable than CPU time. To me, it's wasteful to download an entire image over the Internet if you can easily compute it on the client. Think about all the systems you're activating along the way to download that image: routers, servers, even a disk somewhere far away (if it's not cached on the server)... All that just to avoid one pass of processing on data you already had in RAM on the client. reply ttfkam 3 hours agorootparentI have the same perspective regarding bandwidth, but I also consider any client to be running on a computer at least ten years old and at least three OS revisions behind. I like to consider myself a guest on a client CPU, GPU, and RAM. I should not eat all their food, leave an unflushed turd in their toilet, and hog the remote control. Be a thoughtful guest that encourages feelings of inviting me back in the future. Load fast, even when cell coverage is marginal. Low memory so a system doesn't grind to a halt from swapping. Animate judiciously because it's polite. Good algorithms, because everyone notices when their cursor becomes jerky. reply gary_0 6 hours agorootparentprev\"Mips – processing cycles, computer power – had always been cheaper than bandwidth. The computers got cheaper by the week and the phone bills stayed high by the month.\" - The Star Fraction, 1995 reply gfody 3 hours agorootparenteach visitor brings their own cpu to do this work whereas the server bandwidth is finite reply cj 2 hours agorootparentI'm confused though. If the goal is to optimize for server bandwidth, wouldn't you still want to send the already-blurred photo? Surely that will be a smaller image size than the pre-blurred full res photo (while also reducing client-side CPU/OS requirements). reply pitched 42 minutes agorootparentWe don’t know the aspect ratio of the client window before-hand and on web, there are a lot of possibilities! So if any pre-blurred image is meant to peek out around the edges, those edge widths are dynamic. Otherwise, a low-res blurred image plus high-res non-blurred edges might be less bandwidth if overhead is low enough. reply pdimitar 3 hours agorootparentprevOkay but how do you compute an image? How would your browser -- or any other client software -- know what's the hero image of a blog that you never visited before, for example? I feel like I am missing something important in your comment. reply highwind 3 hours agorootparentThe article describes computational method of rendering frosted glass effect. You can achieve the same thing by rendering the effect once (then upload to a sever) and have client download the rendered image. Or you can compute the frosted glass effect. What's better? That's the argument. reply pdimitar 3 hours agorootparentAh, sorry, I didn't make it as far in the article. IMO it really depends on the numbers. I'd be OK if my client downloads 50KB extra data for the already-rendered image but I'll also agree that from 100KB and above it is kind of wasteful and should be computed. With the modern computing devices we all have -- including 3rd world countries, where a cheap Android phone can still do a lot -- I'd say we should default to computation. reply smusamashah 38 minutes agoparentprevI recently had a shower thought that the bigger you go, more energy you need to do computation. As in you could make a computer out of moving planets. On the other hand you could go small and make a computer out of a tiny particle. Both scales achieve the same result but at very different costs. reply mock-possum 26 minutes agorootparentThere is a sci-fi series that I am absolutely blanking on that features that concept - I remember a few characters each having access to a somewhat godlike ability to manipulate physics, and using it to restructure the universe to create computers to augment their own capabilities - definitely some planetary stuff and some quantum / atomic level stuff.. hmmmm maybe gpt can help reply vasco 7 hours agoparentprevMost of those websites that are technically \"wasteful\" in some ways, are way more \"wasteful\" when you realize what we use them for. Mostly it's for pure entertainment. So either entertainment is wasteful, or if it's not, spending more compute to make the entertainment better is OK. reply klabb3 6 hours agorootparentI would say most websites are wasteful wrt the customer, which is usually advertisers. There are websites where the user is the customer, but they’re rare these days. reply ktpsns 8 hours agoparentprevIsn't sending both the blurred and non-blurred picture over the network the way we did it since two decades in web dev? With (many!) high resolution pictures this is definetly less performant then a local computation, given that real networks have finite bandwiths, in particular mobile clients on spots with bad wireless coverage. It is astonishing what can be done with CSS/WebGL only these days. We needed a lot of hacks and workarounds in the past for that. reply pdimitar 3 hours agorootparentI don't have much data myself but when I was doing scraping some time ago I had thousands of examples where f.ex. the full-res image was something like 1.7MB and the blurred image was in the range of 70KB - 200KB, so more or less 7% - 11% of the original. And I might be lying here (it's been a while) but I believe at least 80% of the blurred images were 80KB or less. Technically yes you could make some savings but since images were transferred over an HTTP-1.1 Keep-Alive connection, I don't feel it was such a waste. Would love to get more data if you have it, it's just that from the limited work I did in the area it did not feel very worth of only downloading the high-res image and do the blur yourself... especially in scenarios when you just need the blurred image + dimensions first, in order to prevent the constant annoying visual reflow as images are downloaded -- something _many_ websites suffer from even today. reply djmips 8 hours agorootparentprevA blurred image shouldn't be very much extra over the high resolution image considering it's information content is much smaller. reply RicoElectrico 8 hours agoparentprevAs per the central limit theorem one can approximate Gaussian with a repeated convolution with any function, box blur being most obvious candidate here. And box blur can be computed quickly with a summed area table. reply jcelerier 3 hours agorootparent> a repeated convolution I really wonder what's the field of reference of \"quickly\" there. To me convolution is one of the last resort techniques in signal processing given how expensive it is (O(size of input data * size of convolution kernel)). It's of course still much faster than gaussian blur which is still non-trivial to manage at a barely decent 120fps even on huge Nvidia GPUs but still. reply pitched 30 minutes agorootparentHow are we supposed to think about SIMD in Big-O? Because this is still linear time if the kernel width is less than the max SIMD width (which is 16 I think on x64?) reply krsdcbl 4 hours agoparentprevI would argue that while it _feels_ wasteful to us humans, as we perceive it as a \"big recomputation of the rendered graphics\", technically it's not. the redrawing of anything that changes in your ui requires gpu computation anyway, and some simple blur is quite efficient to add. Likely less expensive than any kind of animations of dom objects thar aren't optimized as gpu layers. additionally, seeing how nowadays the most simple sites tend to load 1+ mb of JS and trackers galore, all eating at your cpu ressources, Id put that bit of blur for aesthetics very far down on the \"wasteful\" list reply promiseofbeans 8 hours agoparentprevI guess eventually it's a trade-off between doing heavy lifting yourself and paying a little more compute and bandwidth, or offloading it to clients and wasting more energy but at lower cost to the developer. I think there are environmental arguments in both directions (more energy spent computing stuff on the client vs more energy sending pre-computed assets over the networks). I'm not sure which is better ultimately - I suppose it varies case-by-case. reply dcuthbertson 7 hours agorootparentFirst, I really like the effect the author has achieved. It's very pretty. Now for a bit of whimsy. It's been said that a picture is worth a thousand words. However, a thousand words uses far less bandwidth. What if we go full-tilt down the energy saving path, replace some images with prose to describe them? What would articles and blog posts look like then? I know it's not practical, and sending actual images saves a lot of time and effort over trying to describe them, but I like the idea of imagining what that kind of web might look like. reply K0balt 6 hours agorootparentWith a standardized diffusion model on the receiving end, and a starting point image (maybe 16x16 pixels) with a fixed seed, we could send images with tiny amounts of data, with the client deciding the resolution (deciding how much compute to dedicate) as well as whatever local flavor they wanted (display all images in the style of Monet…) bandwidth could be minimized and the user experience deeply customized. We’d just be sending prompts lol. Styling , css, etc all could receive similar treatment, using a standardized code generating model and the prompt/seed that generates the desired code. Just need to figure out how to feed code into a model and have it spit out the prompt and seed that would generate that code in its forward generation counterpart. reply pitched 24 minutes agorootparentTo consistently generate the same image, we’d all have to agree on a standard model, which I can’t see happening any time soon. They feel more like fonts than code libraries. reply pavlov 5 hours agorootparentprevI’m pretty sure the radio on a mobile device consumes more energy than the GPU doing a 2D operation on a single image. If you want to save energy, send less data. reply fidotron 6 hours agoparentprevTbh I think people radically underestimate how fast, and efficiently so, GPUs are. The Apple Watch has physically based rendering in the UI. It would be curious to compare the actual cost of that versus using a microcontroller to update a framebuffer pushed to a display via SPI. I did some webgl nonsense like https://luduxia.com/showdown/ and https://luduxia.com/whichwayround/ . This is a experimental custom renderer with DoF, subsurface scattering and lots of other oddities. You are not killed by calculation but memory access, but how to reduce this in blur operations is well understood. What there is not is semi transparent objects occluding each other, because this becomes a sorting nightmare and you would end up having to resolve a whole lot of dependencies on this dynamically. (Unless you do things with restricting blending modes). Implementing that in the context of widgets that move on a 2D plane with z-index sorting is enormously easier than in a 3D scene though. reply grishka 14 hours agoprevI extracted a similar \"light rays\" texture from Windows 7 when I was trying to replicate its aero glass effect on Android to see what can be done with the new shader APIs. I ended up with something very close to this article, except I didn't do the inner shadows but I did increase the saturation of the blurred background a bit. https://mastodon.social/@grishka/110524476584503201 reply tyleo 14 hours agoparentVery cool. The light rays texture can actually do a lot of heavy lifting in the effect. TBH the one I made for the tutorial isn’t even that great. I like the harder lines on that Windows 7 one. I thought about playing with saturation and I saw some other examples do that. I decided against it. For my article anyways it wouldn’t have mattered as much given that the moon image I used doesn’t have much color. I’d encourage folks making their own glass to play with that though. reply tln 3 hours agoprevThis has like 10 stacked effects, thats about 7 too many except for the most demanding aesthetics. Just use the background color + blur + box shadow or border reply tyleo 2 hours agoparentFor folks who wanted a less intensive glass effect, they could pick and choose from the tutorial. You get a pretty respectable piece of glass at step three with just blur and shadow. I'd personally recommend doing that and mixing in a static light ray image. IDT most applications would need the full JavaScript effect. It's fun but it can be distracting. With blur, shadow, and light rays alone you can already get _really close_ to that Forza image at the top. reply tln 2 hours agorootparentThanks for the article! reply hirvi74 39 minutes agoparentprevWhat is the reason for the limit of stacked effects being nWhy not embedding a browser directly though? How do you feel about the Flutter based UI Widgets? Mostly to avoid overheads on both disk space and runtime performance. QuickJS is only ~20MB to embed. And I have no experience with Flutter, unfortunately. =/ reply tyleo 14 hours agoparentprevI was part of an investigation which considered Coherent products for one of the Forza titles. We didn't go with it at the time, and I haven't had the opportunity to use it on a title at other companies, but it looks rad. Forza used a custom UI system based on XAML and the acrylic elements at the top of the article were largely implemented in a custom shader. For a custom system it was pretty solid. We also built a lot of tech into it related to 3D placement of elements to support diagetic UI. reply msarchet 14 hours agorootparentWas this the in-house c++ WPF implementation? reply tyleo 14 hours agorootparentYes it was! I actually loved that thing. reply OptionOfT 14 hours agoparentprevLots of games used to use [Scaleform](https://en.m.wikipedia.org/wiki/Scaleform_GFx) for their UI. reply tyleo 14 hours agorootparentLots of games still use it but its been discontinued by Autodesk and is on its way out. Not to mention Flash also being discontinued. reply djmips 8 hours agoparentprevIncluding Minecraft (Bedrock / consoles) :) https://www.youtube.com/watch?v=BnTUmksfRJU reply lyu07282 5 hours agoparentprevThe ones that don't are also interesting, like baldurs gate 3 uses this: https://www.noesisengine.com/ reply genezeta 9 hours agoprevJust so you know... I'm not seeing the \"background-attachment fixed\" working at all. Not the CSS and neither the JavaScript solution. The rays stay static, detached from the moving div just as they were before applying that code. In both Firefox and Vivaldi, on Windows. reply lovegrenoble 15 hours agoprevNice effect, nice article too reply jp1016 12 hours agoprevi have created a library for generating frosted glass effect, this looks so good on icons. https://github.com/JP1016/react-icon-blur reply michelreij 9 hours agoprevBeautiful. And excellent writing! reply butterNaN 4 hours agoprevI have this almost everywhere on my KDE Plasma desktop, with the help of Kvantum* (their debian dependencies seem to be broken - I had to build it from source in a container). Maybe it won't last for long, but I absolutely love the aesthetics. * https://github.com/tsujan/Kvantum reply Animats 12 hours agoprev [–] Aw. Kind of like Windows 7 Aero theme. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The guide explores creating a frosted glass effect in HTML, inspired by AAA games like Forza Horizon 3 and Forza Motorsport 7, providing sample code and assets.",
      "Key techniques include using CSS's `backdrop-filter` for blur effects, `box-shadow` for depth, and JavaScript for dynamic light reflections, with both JavaScript and non-JavaScript versions for cross-platform compatibility.",
      "The tutorial includes a \"Final Recipe\" section for a quick start, allowing users to craft their own stunning glass UI."
    ],
    "commentSummary": [
      "The discussion focuses on the use of frosted glass UI effects in web development, inspired by high-end game design, highlighting both aesthetic appeal and computational cost concerns.",
      "There is a debate on the trade-offs between server bandwidth and client-side processing, with varying opinions based on personal experiences and technological perspectives.",
      "The conversation also considers the efficiency of modern GPUs and the environmental impact of different computational methods."
    ],
    "points": 612,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1732414785
  },
  {
    "id": 42224670,
    "title": "Bocker: Docker implemented in around 100 lines of Bash (2015)",
    "originLink": "https://github.com/p8952/bocker",
    "originBody": "Bocker Docker implemented in around 100 lines of bash. Prerequisites Example Usage Functionality: Currently Implemented Functionality: Not Yet Implemented License Prerequisites The following packages are needed to run bocker. btrfs-progs curl iproute2 iptables libcgroup-tools util-linux >= 2.25.2 coreutils >= 7.5 Because most distributions do not ship a new enough version of util-linux you will probably need to grab the sources from here and compile it yourself. Additionally your system will need to be configured with the following: A btrfs filesystem mounted under /var/bocker A network bridge called bridge0 and an IP of 10.0.0.1/24 IP forwarding enabled in /proc/sys/net/ipv4/ip_forward A firewall routing traffic from bridge0 to a physical interface. For ease of use a Vagrantfile is included which will build the needed environment. Even if you meet the above prerequisites you probably still want to run bocker in a virtual machine. Bocker runs as root and among other things needs to make changes to your network interfaces, routing table, and firewall rules. I can make no guarantees that it won't trash your system. Example Usage $ bocker pull centos 7 ######################################################################## 100.0% ######################################################################## 100.0% ######################################################################## 100.0% Created: img_42150 $ bocker images IMAGE_ID SOURCE img_42150 centos:7 $ bocker run img_42150 cat /etc/centos-release CentOS Linux release 7.1.1503 (Core) $ bocker ps CONTAINER_ID COMMAND ps_42045 cat /etc/centos-release $ bocker logs ps_42045 CentOS Linux release 7.1.1503 (Core) $ bocker rm ps_42045 Removed: ps_42045 $ bocker run img_42150 which wget which: no wget in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin) $ bocker run img_42150 yum install -y wget Installing : wget-1.14-10.el7_0.1.x86_641/1 Verifying : wget-1.14-10.el7_0.1.x86_641/1 Installed : wget.x86_64 0:1.14-10.el7_0.1 Complete! $ bocker ps CONTAINER_ID COMMAND ps_42018 yum install -y wget ps_42182 which wget $ bocker commit ps_42018 img_42150 Removed: img_42150 Created: img_42150 $ bocker run img_42150 which wget /usr/bin/wget $ bocker run img_42150 cat /proc/1/cgroup ... 4:memory:/ps_42152 3:cpuacct,cpu:/ps_42152 $ cat /sys/fs/cgroup/cpu/ps_42152/cpu.shares 512 $ cat /sys/fs/cgroup/memory/ps_42152/memory.limit_in_bytes 512000000 $ BOCKER_CPU_SHARE=1024 \\BOCKER_MEM_LIMIT=1024 \\bocker run img_42150 cat /proc/1/cgroup ... 4:memory:/ps_42188 3:cpuacct,cpu:/ps_42188 $ cat /sys/fs/cgroup/cpu/ps_42188/cpu.shares 1024 $ cat /sys/fs/cgroup/memory/ps_42188/memory.limit_in_bytes 1024000000 Functionality: Currently Implemented docker build † docker pull docker images docker ps docker run docker exec docker logs docker commit docker rm / docker rmi Networking Quota Support / CGroups † bocker init provides a very limited implementation of docker build Functionality: Not Yet Implemented Data Volume Containers Data Volumes Port Forwarding License Copyright (C) 2015 Peter Wilmott This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.",
    "commentLink": "https://news.ycombinator.com/item?id=42224670",
    "commentBody": "Bocker: Docker implemented in around 100 lines of Bash (2015) (github.com/p8952)336 points by emersonrsantos 19 hours agohidepastfavorite94 comments hks0 12 hours agoI did something (slightly) similar via proot, called Bag [1], which I must have not described as a docker alternative: It has nothing to do with cgroups, and the cli deviates from that of docker's. The backstory: To bypass internet censorship and deep packet inspection, I had written a proxy chain solution masquerading itself as plain html traffic. I needed it constantly running everywhere I went, but I didn't want to port it to a native android app. I wanted to run it through termux and at the time termux had no jdk/jre. Proot could spawn a archlinux env and there indeed was a jdk available. The arch env within termux turned out to be generally more suitable for all tasks. Creating and destroying ephemeral envs with different setups and prooting into them to just run a single command is easily automated with a script; I named it bag.sh, a drastically smaller form of a shipping container. Funny bag.sh also has a roadmap/todo in there untouched for 5 years! It's written on mobile screen hence mostly formatted to 40 columns lines to fit on the display without scrolling. [1]: https://github.com/hkoosha/bag reply noufalibrahim 2 hours agoparentI guess a lot of us had stories like this. I needed to package a bunch of things into a single environment where a VM was unsuitable. I cooked up something using chroot, deb-bootstrap and make an installer using makeself. It created a mini debian inside /opt which held the software and all the dependencies I needed (mysql etc.). Worked pretty well and the company I made this for used it till they got acquired in 2016 or so. More generally though, implementing a crude version of a larger application is one of the best ways of learning how things work inside it. I'm a big fan of the approach. reply dataflow 11 hours agoparentprevFYI, I think you forgot some important quotes in your script. Try shellcheck? > mkdir -p $(dirname \"$2\") reply jlokier 7 hours agorootparentThat'll handle whitespace in paths, but if you want it to handle all path characters, dirname and mkdir need \"--\" here too. reply p0w3n3d 2 hours agoparentprevWow reply random3 17 hours agoprevI love these. Been a fan of minimal bash stuff. Here's a proof of concept for a intra-cluster load balancer in 40 lines of bash done during a hackathon I organized to promote distributed infra with Docker, Mesos, etc. about a decade ago https://github.com/cell-os/metal-cell/blob/master/discovery/... I likely lost it, but I had a redundand and distributed reverse SSH tunnel based colo-to-cloud transfer tool. Shell Fu and others have good collections of these https://www.shell-fu.org/ reply Neywiny 14 hours agoprevI like when repos say \"not implemented yet\" or \"to-do\" or \"working on\" and the last commit was years ago. Makes me feel better about not going back to my to-dos I drop through my code. (Not meaning to throw shade on this author, just finding it comforting) reply SoftTalker 51 minutes agoparentWhen you start a project it's worth spending some time thinking about \"non-goals\" i.e. features that come to mind but that you intentionally are not going to implement. It's absolultely fine and often very helpful to have clear scope boundaries so you don't end up chasing rabbits and having projects that never feel \"finished.\" reply Brian_K_White 5 hours agoparentprevI think it's good. I guess it's possible for something to be simply done, and you don't always have to have a bunch of next ideas, but I generally always have next ideas. If there is always some next ideas then by definition you must always have todos that never get done. It should actually be the normal state of every single project. reply ramon156 11 hours agoparentprevI feel like most — if not all — projects are never done. Knowing when to stop is important reply Neywiny 6 hours agorootparentYeah it's weird, I feel like a repo is untrustworthy if it wasn't committed to in the past year but sometimes a project is just done. Now I'm actuality there would likely be work on my end to update it for integration with modern tools/devices, but there's a repo from 12 years ago I've been considering using. Maybe it'll just work, maybe it'll be trash. reply byearthithatius 13 hours agoparentprevGreat point! It is not shade at all, you are trying to normalize this which I like. For unpaid, volunteer, or hobby code feeling a _need_ because its public can make coding less fun or prevent people from sharing code publicly they otherwise would. reply thanatos519 4 hours agoparentprevTotall ok! As soon as the program does what I want, and my task is complete, I stop developing. Software is not my hobby. reply MathMonkeyMan 1 hour agoprev> Because most distributions do not ship a new enough version of util-linux you will probably need to grab the sources from here and compile it yourself. Careful. The default installation prefix is /usr/bin, and the install will happily clobber your mount command with one that requires a library that doesn't exist. Then next time you boot, the kernel will mount the file system read-only. reply yazzku 1 hour agoparentShould also be be /usr/local/bin. reply darkwater 7 hours agoprevI wonder why Bocker makes the frontpage so often. Is Docker still that controversial even in 2024? Why people don't recognize that it actually brought something useful (mainly, software distribution and easy of \"run everywhere\") to the table? reply UK-Al05 7 hours agoparentIt's just a learning tool to see how docker works. Docker is just a combination of kernel tech that already exists. Namespaces, cgroups, and union file systems and probably few others. reply ajross 2 hours agorootparentExactly. \"Docker\" is boring, everyone uses it, everyone knows it, no one really wants to rewrite it (on Linux) except for parochial infighting or religious license reasons. But Linux containers[1] are actually fascinating stuff, really powerful, and (even for the Docker experts) poorly understood. The point of Bocker isn't \"see how easy it is to rewrite Docker\" it's \"See how simple and powerful the container ecosystem is!\". [1] Also btrfs snapshots, which are used very cleverly in Bocker. reply oncallthrow 6 hours agoparentprevIt hits the frontpage often because people assume that Docker is this super complex thing, but (at its most fundamental), it's actually quite elegant and understandable, which is interesting - a perfect HN story, in fact. reply juped 2 hours agorootparentIt is kinda complex, but all the complexity is in Linux, ~none is in 'Docker'. reply delusional 7 hours agoparentprevIt's possible it's not climbing the front page to slight docker, but rather that people are seeing that docker is something useful and want to know how it works. Bocker can be an entrypoint into the technologies. reply outofpaper 7 hours agorootparentYes it's a wonderful little read. Besides without volumes and port forwarding few would ever deploy this to production. The reason people use docker over Podman and rolling their own is because of the ecosystem and ubiquity of docker. reply gosub100 5 hours agoparentprevI'm bringing overlayfs to people at my company to save time on a lenghty CI process, and they are in awe at the speedup. But after demo-ing it to a few people I realized they could just use / (I could have brought them) docker. reply Asaf51 3 hours agorootparentHow overlayfs speeds up CI processes? reply mythz 15 hours agoprevSurprised no one's mentioned lazydocker as a great alternative for Docker Desktop (on Linux/macOS/Windows) [1]. It's a fairly full-featured Terminal UI that has the benefit of running over ssh: [1] https://github.com/jesseduffield/lazydocker reply orphea 13 hours agoparentLiterally a few days ago: https://news.ycombinator.com/item?id=42214873 reply acka 8 hours agoparentprevLazydocker sure looks interesting, but self-promotional ads - for products in an entirely different space - in an OSS project's README.md? Seriously? At least for me it is the first time I have come across anything like this. I'm wondering if advertising like this is even allowed under GitHub's TOS and AUP. reply ffk 2 hours agoprevFun fact: docker started as bash, then moved to python before settling on golang. Also, in a 2013 docker meetup, someone wrote a docker clone in bash. People want to learn! Hopefully things like this help them. reply sellmesoap 10 hours agoprevA brother from another mother: https://bastillebsd.org/ Bastille manages jails using shell with many of the same constructs you'd find in docker. I like it over other jail management software in BSD because it has so few dependencies. reply sunshine-o 2 hours agoparentAbsolutely, it adds a lot of value for a shell script that is about 100 LoC. By the way it took me a while to get why it was named Bastille. As La Bastille was a castle built to defend Paris from English attacks during the Hundred Years' War, and then turned into a prison. reply mschuster91 18 hours agoprevThe fact how simple it is to re-implement a large part of Docker because all it fundamentally is a bit of glue code to the kernel is the biggest problem Docker-the-company faced and still faces. Where Docker adds real value is not (just) Docker Hub but Docker for Windows and Mac. The integrations offer a vastly superior experience than messing around with VirtualBox and Vagrant by hand (been there, done that) to achieve running Docker on one's development machine. reply seabrookmx 18 hours agoparentRancher desktop is also a viable option and free. Many including my work moved to it after Docker's new licensing kicked in. IMO the real magic of Docker was the Docker/OCI image format. It's a brilliant way to perform caching and distribute container images, and it's really what still differentiates the workflow from \"full\" VM's. reply jml78 17 hours agorootparentMy main dev machine is Linux so I use Rancher Desktop but I also have a MacBook Pro m1 machine. Orbstack is so much better than rancher and docker desktop. I know they are a small company but hell if their product isn’t significantly more efficient and better. reply throwaway817472 17 hours agorootparentCompletely agree. I moved from docker desktop to rancher after an update blew away my kubernetes cluster, and then from Rancher to Orbstack due to a number of bugs that were crashing the underlying VM. Orbstack has been rock solid (aside from one annoying networking issue), and it uses significantly less battery. They’ve done a fantastic job. reply jml78 17 hours agorootparentOnly complaint is that my home network assigns IPv6 addresses and that fucks up external dns lookups for pods in Orbstack. reply fl0id 9 hours agorootparentprevPodman-Desktop is also great b/c it now has gpu support on macOS (for the Linux container) reply moogly 3 minutes agorootparentI could not get LocalStack to run on Podman (w/ Docker emulation), on Fedora, so had to go back to Docker. reply kdrag0n 9 hours agorootparentprevLove to hear that :) sent you an email about the k8s IPv6 issue — should be able to get it fixed in OrbStack reply tryauuum 10 hours agorootparentprevRelated to image format, has anyone tried to use alternative image formats? There was a differnt format / filesystem for containers to leverage deduplication between different images (so the node won't need to fetch yet another copy of cuda / pytorch) reply fire_lake 9 hours agorootparentThis is common in the Bazel community. reply magic_hamster 17 hours agoparentprevDocker Desktop on Mac is a handicapped, underprivileged mess. Docker cli for Mac with Colima is still underprivileged, but at least you can skip the bs license and Docker's gui. On Windows you can at least use Docker on WSL which works great. Why use Docker Desktop is beyond me. reply skissane 17 hours agorootparent> Why use Docker Desktop is beyond me. I lived through a failed attempt to migrate from Docker Desktop for Mac to an open source alternative (minikube+portainer, IIRC). A lot of test scripts developers relied on – to run parts of the integration test suite on their laptops for debugging – broke, because Docker Desktop for Mac went to a lot of effort to make macOS look like you were running Docker on Linux, whereas the open source replacement wasn't as seamless. Some of these test scripts contained Java code directly talking to the Docker daemon over its Unix domain socket, so need the same API implemented. Many other scripts made heavy use of the Docker CLI. After spending a lot of time on it, it was decided to just go back to Docker Desktop for Mac. The failed migration had resulted in highly paid engineers spending time pulling their hair out trying to get test scripts to work instead of actually fixing bugs and delivering new features. Now, that was 2+ years ago now, and maybe the open source alternatives have caught up since, or maybe we picked the wrong one or made some other mistake. But I'm not rushing to try it again. reply jml78 17 hours agorootparentI would look at Orbstack. Yes it costs money but it is pretty great. Your situation sounds very similar to the company I work for. Orbstack has been a drop in replacement except one issue. Any dev using IPv6 assignment on their home network has issues where pods try to hit external dns because it tries to use IPv6 and I don’t think the Orbstack k8s instance is dual stack. There are hacks to get around it but if I could get Orbstack to address this issue, I couldn’t find one other issue. Orbstack is crazy fast and way better than docker desktop overall reply karmajunkie 13 hours agorootparenti used it for a year or so then subscribed finally the other day. it really is well worth the money. reply pmarreck 2 hours agorootparentprevI've heard from someone who would know that you should be using Orbstack. reply phinnaeus 15 hours agorootparentprevI have a feeling we work at the same company. Well, maybe not, but we went through a strikingly similar experience around the same timeframe. reply skydhash 17 hours agorootparentprevI've just use a Debian arm virtual machine and be done with it (M1). If I'm going to run a VM regardless, may as well go with a full fledged one. reply tyingq 6 hours agorootparentprevA fair amount of the Docker Desktop use, on both mac and Windows, is driven by it's internal workarounds for brain-dead corporate VPNs. reply bhhaskin 16 hours agorootparentprevDocker for Mac does run on Linux. Just a striped down lightweight vm. It's why file Io is complete shit. It's a network share. reply mschuster91 16 hours agorootparentUse either the cached or delegated options for the volume [1] then even NodeJS becomes decently performant. [1] https://tkacz.pro/docker-volumes-cached-vs-delegated/ reply notpushkin 13 hours agorootparentprevColima is the way to work with Docker on mac nowadays. I appreciate Docker Inc folks trying to get some money, but Docker Desktop is just not worth it. reply syndicatedjelly 13 hours agorootparentprevI've been using Docker CLI for Mac happily for years. What am I missing? reply acedTrex 17 hours agoparentprevI just use colima on macos, its a far better experience. Much lighter weight reply djmips 8 hours agoparentprevA lot of popular wealthy systems are 'easy' to re-implement. I thought the value was in Docker images? Or is that not how Docker is used? The only way I've used it is to be able to import someone's virtual build setup so I could build something from years ago. reply dilyevsky 17 hours agoparentprevNah, they should have prioritized building some sort of PaaS solution like CloudRun, Render or Fly so they can sell that to enterprises for $$$. Instead they did half-baked docker swarm which never really worked reliably and then lost ground to k8s rapidly reply smt88 15 hours agorootparentDocker was a spinoff of an internal tool used to build exactly the type of PaaS you're describing. It was like a better Heroku and I loved it, but they shut it down when they focused on commercializing Docker itself. reply rudasn 12 hours agorootparentdot cloud yes? I was surprised when they shut that down too. reply mardifoufs 14 hours agorootparentprevThat's what people usually say but they have tried to do just that a few years ago and it didn't really work. Docker inc has been doing great since they have shifted towards even more standardization in their container runtime, and focused on dev tooling. They became profitable when they focused on Docker desktop and docker hub instead of trying to build a clunky alternative to kubernetes or yet another cloud orchestration tool/platform. reply jen20 16 hours agorootparentprevDidn’t they buy at least one of these? It was garbage, and no one cared. reply exceptione 11 hours agoparentprevI think Docker is really lucky that devs still think container=Docker. Podman is in many aspects superior, while still being able to function as a drop in. reply maxloh 18 hours agoparentprevBut Rancher Desktop does the same too (and is also open source). reply airstrike 17 hours agoparentprevDocker for Mac is just unusable. They're not really adding any value there. reply SadTrombone 17 hours agorootparentHave you tried out Orbstack? reply Bnjoroge 16 hours agorootparent+1 on orbstack. near-perfect drop in reply aryonoco 17 hours agoparentprevDocker for Windows and Mac are both bloated pieces of software, outperformed by Rancher Desktop and Orbstack. Docker's only real innovation was the OCI format, which it had to give away for it to become an industry standard, and now doesn't own. reply hu3 14 hours agorootparentDocker on Windows can use WSL2 engine for near native performance. reply xyst 3 hours agoprevThis was written in 2015, I think we can get this down to 69 lines or less in brainfuck reply oneeyedpigeon 9 hours agoprevIf the author happens to see this: the link to your homepage on GitHub is broken - drop the \"www.\" reply noctane 9 hours agoprevPracticality aside, there seems to be a lot we can learn from the implementation. reply kondro 15 hours agoprevIsn’t this how Docker started? reply amelius 17 hours agoprevDoes it require root access to the machine I have a user account on? reply schmichael 13 hours agoparentYes, from the README: > Bocker runs as root and among other things needs to make changes to your network interfaces, routing table, and firewall rules. I can make no guarantees that it won't trash your system. Linux makes it quite hard to run \"containers\" as an unprivileged user. Not impossible! https://github.com/rootless-containers/rootlesskit is one approach and demonstrates much of the difficulty involved. Networking is perhaps the most problematic. Your choices are either setuid binaries (so basically less-root as opposed to root-less) or usermode networking. slirp4netns is the state of the art here as far as I know, but not without security and performance tradeoffs. reply yeldarb 16 hours agoprevIs there any Docker alternative on Mac that can utilize the MPS device in a container? ML stuff is many times slower in a container on my Mac than running outside reply habitue 16 hours agoparentThe issue you're running into is that to run docker on mac, you have to run it in a vm. Docker is fundamentally a linux technology, so first emulate x86_64 linux, then run the container. That's going to be slow. There are native macos containers, but they arent very popular reply AbuAssar 15 hours agorootparentDocker can run ARM64 linux kernel, no need to emulate x86 reply majormajor 15 hours agorootparentYou still pay the VM penalty, though it's a lot less bad than it used to be. And the Arm MacBooks are fast enough that IME they generally compare well against Intel Linux laptops even then now. But it sounds like first-class GPU access (not too surprisingly) isn't there yet. reply fl0id 9 hours agoparentprevPodman-Desktop can do it reply WanderPanda 14 hours agoprevMakes me wonder why docker still didn't make it to the ubuntu/debian repositories. Would be such an easy net benefit reply notpushkin 13 hours agoparentWhat do you mean? It's been there for years: https://packages.debian.org/docker.io It’s an old version, and I think it isn’t supported by Docker Inc (for the reasons mentioned in the sibling comment), but it’s there. reply WanderPanda 4 hours agorootparentDamn good to know! Have been gaslit by the ever-changing docker install instructions. Of course it would be a lagging version, but I think the docker feature-set has converged years ago, why would I care any more about the docker version than e.g. about the version of grep? reply djbusby 1 hour agorootparentThe buildx/build and docker-compose vs 'docker compose' are recent updates. reply ddtaylor 14 hours agoparentprev(a) Docker wants to bundle vendor libraries instead of using other packages and (b) Canonical uses LXD and MicroK8s instead. reply aussieguy1234 13 hours agoprevWhile not good for daily driving, this gives you an idea on what docker is and how it works. On Linux, docker is basically fancy chroot. reply musicale 12 hours agoparentOn macOS/Windows/etc., docker is basically fancy chroot in a linux VM. reply dcreater 17 hours agoprevVery interesting. With how standard containerization has become, we sorely need an FOSS solution reply tsujamin 17 hours agoparentDon’t we have them? I only casually use containers, but what about podman, runc, systemd-nspawn, LXC etc? reply wmf 17 hours agoparentprevIf Docker isn't open enough for you, check out Podman (now with extra CNCF). reply hackernewds 16 hours agorootparenthow is docker open in any way? https://i.imgur.com/2F0JmUw.png reply diggan 16 hours agorootparentIn this way: https://imgur.com/a/PIkm7Eb reply mardifoufs 14 hours agorootparentprevHow exactly is docker (buildkit, compose, the runtime, the daemon, etc) not open source? Docker desktop isn't, but that's almost entirely unrelated to the containerization technology that it uses or that people refer to when they talk about docker. reply ndsipa_pomu 7 hours agorootparentprevThat service agreement is for using the Docker Desktop GUI tool which isn't open source (though free to use for small businesses etc) whereas the basic docker CLI commands are all open source. reply MrDrMcCoy 17 hours agoparentprevWhy not podman? reply osigurdson 15 hours agorootparentAgree. Not sure about mac but on Windows, Podman + WSL works well. No need for podman desktop either, the cli vwrsion is fine. reply yalogin 15 hours agoprev [–] Is the original docker just a script? Have they not added anything to the container story themselves? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bocker Docker is a minimal Docker implementation written in approximately 100 lines of bash, designed for lightweight container management.",
      "It requires specific system packages and configurations, including a btrfs filesystem and network settings, and is best run in a virtual machine due to its need for root access.",
      "Bocker supports basic Docker functionalities like building, pulling, running containers, and managing resources, but lacks features such as data volume containers and port forwarding."
    ],
    "commentSummary": [
      "Bocker is a simplified Docker implementation written in Bash, demonstrating how Docker's core functionalities can be minimized.",
      "The discussion includes comparisons with other lightweight environment tools like proot and chroot, and alternatives such as Podman.",
      "Key topics include Docker's evolution, its ecosystem's value, and the challenges of running containers on non-Linux systems."
    ],
    "points": 336,
    "commentCount": 94,
    "retryCount": 0,
    "time": 1732403931
  },
  {
    "id": 42223099,
    "title": "How to give a senior leader feedback without getting fired",
    "originLink": "https://newsletter.weskao.com/p/how-to-give-a-senior-leader-feedback-without-getting-fired",
    "originBody": "Share this post Wes Kao's Newsletter How to give a senior leader feedback (without getting fired) Copy link Facebook Email Notes More Discover more from Wes Kao's Newsletter A weekly newsletter on managing up, executive communication, and standing out as a high-performer. Written by an a16z-backed founder. Over 56,000 subscribers Subscribe Continue reading Sign in How to give a senior leader feedback (without getting fired) There’s a right and wrong way to proceed. Here’s how to increase the chances your leader listens and takes action--while reducing the chances they feel threatened. Wes Kao Nov 20, 2024 98 Share this post Wes Kao's Newsletter How to give a senior leader feedback (without getting fired) Copy link Facebook Email Notes More 8 4 Share 👋 Hey, it’s Wes. Welcome to my weekly newsletter on managing up, executive communication, and standing out as a higher performer. For more, check out my new intensive course on Executive Communication & Influence. Read time: 7 minutes Today’s newsletter is sponsored by Uptempo. Planning season hits hard—with months of meetings, data dives, and presentations. Yet results often fail to tie back to corporate strategy and revenue. That's why Uptempo created the Marketing Planning Blueprint to help you streamline the process and drive impact. Get the guide today. I got this question from a student in my October course cohort: I’d love to hear any advice on helping people more senior than me recognize patterns of behavior that are stopping them from getting the results they want. A few examples: Not giving clear guidance during a process--then being disappointed with the results Not setting priorities--then being disappointed their team isn’t working on the right things Not training new hires--then being disappointed when they take longer to ramp up Ah, this is a dilemma. How can you help a senior leader see they’re making life harder for themselves and their team? If you don’t speak up, you’re robbing your organization of your good insights. If you do speak up, you might put your employment and well-being at risk. This puts you in a tough spot. Today I want to share some ways you can share feedback with senior leaders, or anyone more powerful than you—while being respectful, helpful, and protecting yourself from their wrath. Giving feedback to someone more powerful than you is a pattern break Traditionally, the more powerful person gives feedback to the less powerful person. So if you want to give feedback to a more senior person, it’s an inversion of norms. This causes a moment of potential chaos, which is why you want to control the energy and channel it in a positive direction. Feeling nervous about giving your senior leader feedback is a good thing. It means you have survival instincts that help with self-preservation. Giving a senior leader feedback shouldn’t be your first option: Your first option is to ask yourself, “What can I do that’s within my control to improve this situation?” Your second option is, “Can I live with this? How much does this bother me? Is it worth giving them feedback and what are my chances of success doing it?” Your third, fourth, and fifth option: Thinking more about the above Your final option: “I think I want to give this senior leader some feedback.” In other words, make sure YOU aren’t the problem. Make sure you are managing up, asking clarifying questions, acting like an owner, etc to get what you need. It’s easy to blame a leader, but before you do that, try reflecting on how you could behave differently to improve outcomes for both of you. It’s low-agency to assume other people should change. If you do want to give your senior leader feedback, proceed with the appropriate level of caution. You may want to adjust the tactics below based on your specific leader, their idiosyncrasies, worldview, your relationship, the level of trust they have in you, etc. For example, you might realize your relationship or credibility isn’t strong enough for you to give them feedback—that’s an equally appropriate conclusion. The only path I’d advise against: Going in with guns blazing, assuming you have moral high ground simply because you are right. If you are self-aware and could realistically see your senior leader taking the feedback well, read on. Here’s what I do that might be useful for you too. 1. “Even more” technique I’ve taught this framework to my clients, and they love it. I’m going to share it with you. The framing of “even more” works so well because you’re speaking from a place of generosity and giving the benefit of the doubt. You’re assuming they’re doing X—and that they should do it even more. You are assuming they are great--and you want to make them even stronger. 🚫 You: “We might need to give guidance to new hires.” Senior leader: “You think I don’t know that I need to give new hires guidance? I obviously gave them guidance. GTFO.” ✅ You: “We may need to give even more guidance to new hires.” Senior leader: “Hmm yeah. I gave them some guidance, but that probably wasn’t enough.” Why this works: The “before” scenario is binary—the senior leader either did or didn’t give guidance. And if they didn’t, well, they messed up. They feel threatened that you noticed. The “after” is a spectrum: You are generous in assuming that they did give guidance. You’re suggesting they may want to amp this up even more. This is much easier for them to accept. This isn’t simply an issue of semantics or phrasing. This is about positioning to increase the chances they change their behavior. Getting anyone to listen and change their behavior, especially someone more senior? That’s a huge win. [The “even more” technique works with giving feedback to direct reports too. It’s super versatile.] 2. Use yourself as an example Talk about yourself so it doesn’t seem like you’re pointing fingers. I do this whenever I want to say something the person might find insulting. 🚫 “You should try X.” ✅ “I used to struggle with this, and when I tried X, it really helped.” By the way, saying “you should try X” is fine--there’s nothing inherently wrong about it. The reason I would avoid it is because of the power dynamic and CONTENT of what I’m saying. If there’s a power dynamic and/or the content of what I’m saying might be sensitive for the person, that’s when I share about my own experience. I’m not saying YOU are struggling with X, I’m saying I used to and what I did. And if that lesson applies to what you’re dealing with, that’s cool, but no pressure. Subscribe 3. Adopt diplomatic, curiosity-forward language Most people are extreme in one of two ways: They think “respecting the person’s power” means being 100% supplicant. They do everything the powerful person says, and never push back even when they have reason to. → These people are spineless. They share their POV in the most blunt, low-finesse way without any regard for their recipient’s person’s ego. They think, “Well, I’m right, so I should just say the thing with zero framing.” → These people are insubordinate. Both are bad. Both lack judgment. What you want to do is: Share your POV in a way that doesn’t threaten the senior person, and gets them to listen. One simple way you can achieve this is by using diplomatic, curiosity-forward language. These phrases help you ease into the suggestion in a way that feels non-threatening: \"We might want to try…” “I wonder if...” \"Perhaps we could...” “What are your thoughts on...” “One approach might be...” You adopt the vibe of a helpful team member who has your leader’s best interest in mind and wants to serve your organization. You are forward-looking. Instead of focusing on what went wrong (which risks making your leader feel defensive), you’re focused on what to potentially do going forward. 4. Bring data and examples to support your point If you've been reading this newsletter for a minute, you know I bang on the drum of sharing your logic. I believe most people do not share their rationale enough. Don’t just make a high-level, hand-waving statement. Instead, share examples of what worked well in the past because it helps your feedback land. Supporting your claims makes you more persuasive and objective--and increases the chances your senior leader will take your recommendation. Example 1: Guidance during projects 🚫 “We need to give more feedback during projects.” ✅ “I noticed when we reviewed the design mockups weekly with the client, they loved the final result. For this project, early check-ins could help us make sure we’re aligned before going too far down a certain direction and could prevent rework.” Example 2: Setting priorities 🚫 “The team needs clearer priorities.” ✅ “The team made amazing progress when we all focused on the website update last month. It might help to have one or two clear priorities for the team this month that everyone can rally behind.” Example 3: Training new hires 🚫 “We should spend more time training new people.” ✅ “When we were able to dedicate that first week to training Steve, he got up to speed pretty quickly. The bit of upfront time seemed to have paid off, and taking a similar training approach for our next hire could help them ramp up just as fast. What do you think?” Why this works: Ends with a clear, actionable suggestion Shows the upside of updating their approach Keeps it simple, logical, and positive Personally, I think phrasing a recommendation as a statement reduces cognitive load. You can follow up with an open-ended question, like “what do you think?” Notice how the examples above are concrete AND concise. Avoid long diatribes and over-explaining—use your judgment to share just enough context. And for goodness sake, do not have a “well actually…” vibe when you share logic and data. This is obnoxious and will probably backfire. Notice how in the examples above, I’m sharing rationale, and doing it in a collaborative way. If you’re enjoying this, subscribe to receive a new post next week: Subscribe To recap, here are the points: Deploy the “even more” technique Use yourself as an example Adopt a diplomatic, curiosity-forward language Bring data and examples to support your point Which principle above do you want to try? Which do you think will work best with the senior leader you have in mind and why? Hit reply because I’d love to hear from you. Thanks for being here, and I’ll see you next Wednesday at 8am ET. Wes Executive Communication & Influence course The February 2025 cohort of my course is now open. I’m thrilled to see the testimonials from alumni continue to roll in too. Here’s what students are saying: “I decided to join Wes’ course because I've been a huge fan of her newsletter for a long time. It's always easy to get stuck in your own head or to be verbose in your writing when people are constantly asking for something from you and there's no time to think about your audience. I found the frameworks and perspective Wes shared really valuable, especially in a world where concise and clear written communication is critical. I would recommend this class for anyone who needs to align a large group of stakeholders or bring a valuable recommendation to executives.” - Angela Santurbano, Principal Product Manager, Square “Highly, highly recommended. This is the rare communication course I’ve taken that focuses on how I actually get things done at work: Slacks, emails, last minute cross-functional meetings, and constantly managing up. It’s also the rare virtual course where the activities are challenging, actually mirror real life scenarios, and provide a valuable opportunity to practice skills. On top of all that, Wes is giving real-time constructive feedback to her students. Sign up!” - Fred Geyer, Manager, Employee Onboarding Experience, HelloFresh “This course was filled with clear, actionable insights to improve communication habits and practices in my everyday work. I'm excited to implement the strategies Wes covered.” - Jess Mordo, Senior Manager, Senior Manager (Acquisition Marketing), Grammarly “This course provides a practical set of tools and tactics to apply immediately to your writing. It sparked valuable discussions within my team, who also attended, and I highly recommend it to anyone frequently operating in a ‘debate and commit’ environment. Wes’s approach to clear, kind, and persuasive writing is especially relevant if you rely on channels like Slack or Teams.” - Morgan King, Director of Client Support, Stitch Fix “This was an excellent course. I appreciated the real-world examples, appropriate level and complexity of coursework, and the ask-me-anything Q&A sessions. Very well done!” - Eric Livingston, Senior Director of Product Management, Salesforce In the past week, operators from Adobe, Meta, Shopify, Autodesk, Grammarly, Klayvio, Chick-fil-A, eBay, Square, Equifax, Roblox, etc have signed up. Check out the course page to learn more and see if it’s a fit for you. Connect with Wes Are you new to the newsletter? Subscribe for free Follow me on LinkedIn for more insights Check my availability to do a keynote for your team Work with me for 1:1 executive coaching Check out my 2-day intensive course. Join us: → Executive Communication & Influence for Senior ICs and Managers Subscribe to Wes Kao's Newsletter Launched a year ago A weekly newsletter on managing up, executive communication, and standing out as a high-performer. Written by an a16z-backed founder. Subscribe Error 98 Share this post Wes Kao's Newsletter How to give a senior leader feedback (without getting fired) Copy link Facebook Email Notes More 8 4 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=42223099",
    "commentBody": "How to give a senior leader feedback without getting fired (weskao.com)335 points by RobinHirst11 23 hours agohidepastfavorite287 comments lijok 21 hours agoAstonishing. Completely backwards. This article describes how to give feedback to your subordinates, not to your superiors. If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and will sink whatever function they have oversight of. If you find yourself working under such people, don't bother giving feedback, start polishing your resume. The reason you fluff up feedback to your subordinates is because lower down the chain they tend to be insecure and don't yet have the experience to distinguish between actionable impartial feedback, and threats to their job security. The reason you don't fluff feedback, or any information for that matter to your superiors, is described in basically every handbook on highly effective communication in organizations. reply NAHWheatCracker 21 hours agoparentI agree with you that's how it should be, but experience tells me that everyone is insecure and it's hardly correlated with position and job security. People lower down the chain are insecure because they could legitimately be let go at any time for any reason. People higher up the chain are insecure because any loss of face is debilitating. Especially having failings pointed out by someone \"below\" them. reply Kamq 19 hours agorootparent> People higher up the chain are insecure because any loss of face is debilitating. You don't do it in public. There's no face to lose in private (you're a subordinate, face is only lost among peers and superiors). It is, however, not really a good idea to be 100% blunt out of the gate. There's a dance to it. But in public, I'm there to make my manager look good, and in private I'll tell them exactly what I think. Once they're confident I'm there to be at their back, it's never gone wrong, even in highly disfunctional orgs (I'm a consultant and get brought in to play \"doctor\" with hopeless projects a lot). reply ChrisMarshallNY 5 hours agorootparentOne of my favorite pieces of consultant advice, is Beans and Noses: https://archive.uie.com/brainsparks/2011/07/08/beans-and-nos... reply The_Colonel 9 hours agorootparentprev> you're a subordinate, face is only lost among peers and superiors I disagree. Losing the respect of your subordinates is IMHO worse than of your superior. reply ChrisMarshallNY 5 hours agorootparentTo a point. I have found that subordinates always have to feel that they have a \"little secret edge\" over their managers. In my experience, this is both harmless and necessary. If I, as a manager, can't handle that, then I'm kinda screwed. But it is also highly dependent on the types of people we manage. Source: Manager for over 25 years, of a bunch of folks much smarter and more experienced than me. reply vampiresdoexist 2 hours agorootparentprevIf your superior is managing up well, then it truly doesn’t matter if subordinates lose respect. Probably laying groundwork for new ones well in advance of that becoming a real issue for their status. reply Kamq 2 hours agorootparentprevYou can lose the respect of your subordinates, but that's different than losing face. Although one may lead to the other, they are different things. reply lazide 11 hours agorootparentprevMost people can, some people can’t - and the ones who can’t can be incredibly dangerous. reply jajko 9 hours agorootparentYeah good luck with getting anything, ever, out of folks that feel butt-hurt due to their fragile emotions, in my experience women often go the extra mile to hold grudges, while sporting big smiles publicly.. That gate is closed for good, and you really have no idea what to expect - be it silent treatment or even subversion and backstabbing. To summarize - each of us is pretty unique, and without going though it you can't know how words can affect other people, even those above you that should know better. But they didn't get to that elevated position via honed skill of listening calmly to their subordinates feedback, did they. reply lazide 8 hours agorootparentThe challenge we all have is, that just leaves everyone angry with each other and unable to actually make progress or solve any problems together. reply thaumasiotes 18 hours agorootparentprevnext [14 more] [flagged] alsetmusic 18 hours agorootparent> You don't do it in public. The comment you're replying to specifically nullified your example. reply thaumasiotes 10 hours agorootparentYou might want to read the comments before you decide what they mean. It doesn't say \"face can only be lost in public\". It says \"face can only be lost among peers and superiors\". reply jack_pp 8 hours agorootparentIf you want to understand \"face\" here's a 56 min video : https://library.biblicalarchaeology.org/video/honor-and-sham... reply sleazebreeze 18 hours agorootparentprevThe Biden case seems like an example of when the senior leader was not given any honest feedback in private and then was humiliated in public. If anything that’s a reason to give feedback to the leader privately without sugar coating. reply thaumasiotes 10 hours agorootparentAccording to the comment I responded to, the senior leader can't be humiliated in public, because there is no such concept as the senior leader losing face. reply zenogantner 18 hours agorootparentprev\"The people\" are the president's superior. reply thaumasiotes 18 hours agorootparentOnly in the same sense that bottom-level employees are the CEO's superior. Which is to say, they aren't. Formal structure can stabilize a system and make it resilient to shocks. But there's a limit to how much stability can be provided, and if you provide enough shock, the structure will change. reply Kamq 2 hours agorootparent> Only in the same sense that bottom-level employees are the CEO's superior. Which is to say, they aren't. There's an important difference. Bottom-level employees don't get to choose the CEO at most companies. reply refulgentis 15 hours agorootparentprev> Only in the same sense that bottom-level employees are the CEO's superior. Which is to say, they aren't. Fascinating: What companies do you know of that have democratic elections of CEOs? reply Lvl999Noob 9 hours agorootparentDoesn't nearly every company have a democratic process for choosing CEOs? Just that the voters are only the board members. reply dataflow 9 hours agorootparentYour \"just\" is the point. reply aredox 5 hours agorootparentprevSo the Soviet system was democratic? reply Kamq 18 hours agorootparentprevThe president is not above the people. In fact, given the context we're talking about (having to go debate to try to get their votes), he's below them in the hierarchy in this particular social context. The president may be more powerful than any individual person, but when facing the public _collectively_, they're quite literally his boss, as they get to decide if he keeps his job. reply hashtag-til 21 hours agorootparentprevFrom my experience, you build that non-fluff boundaries in the first one or two meetings with a senior leader. I’d advise against going in the first one throwing punches. Go with actionable feedback and be honest about what it is and what is not something you can solve. From there, if you genuinely care about whatever you’re complaning, you are more likely to be taken seriously. reply stavros 18 hours agorootparent> I’d advise against going in the first one throwing punches. I’d advise against going in any one throwing punches. Instead, give actionable, honest, factual feedback with the intent to legitimately help the other person. reply jms703 11 hours agorootparentThis is the correct approach. reply rpmisms 15 hours agorootparentprevSimply be blunt about other topics to set the tone for interactions. reply inopinatus 19 hours agorootparentprevI don't know what godawful chain you are hitched to but I hope you can find a way off it. High-performance managers realise they are there to enable the talent. You're Brian Epstein, not John Lennon. The job is to create the conditions for folks at the pointy end to be wildly successful. One of the most defining characteristics of this attitude is the maxim \"hire people smarter than yourself\", a very fine sentiment with the only problem being that by induction it makes the CEO the dumbest person in the company. But I digress. If I'm fucking up, then I hope to god my trusted lieutenants will tell me without any pussyfooting around. It's practically what I hired them for. reply lifeisstillgood 19 hours agorootparentCan I suggest there is a difference between feedback and therapy We are all human, we have biases and blindspots. Your trusted lieutenants can come to you and tell you you forgot to do X and because doing X is something either within your personality comfort zone or just outside it, you can if reasonably adjusted take that on. But there will be things you are not reasonably adjusted for, things that require you to make significant adjustments to your world view and personality - things that you need to make serious compromises on Some people are so maladjusted they cannot compromise on stuff most of the world agrees on - generally we call them criminals. But this is a spectrum - bad managers usually have very poor matching between their personal problems and the needs of the role. But even good managers reach a point that their instincts and their rational mind cannot take them past. In short “everyone is promoted to their level of incompetence” is not a skills problem, but a character problem. reply NAHWheatCracker 19 hours agorootparentprevI don't know you, but based on what you're saying, I guess you're in a much different environment than I've ever been in. You're probably also more of a \"type A\" person than I am. I've always worked in places that are essentially established businesses. People are mostly bureaucrats and lazy. I believe that's a large majority employers. If you honestly can't understand that that's how a lot of people work, then I think you live in a bubble. reply inopinatus 19 hours agorootparentI cannot disagree with your assertion that the majority of employment environments have a toxic pathology of hierarchical insecurities, and I've certainly worked within them. Albeit, yes, with a flagrant disregard for authority (I hesitate to label myself \"type A\", it's such a reductive term) that worked best when in the second and third decades of my career I was generally engaged on a consulting basis as a fixer/troubleshooter. So I would admit guilt to an accusation that I have placed myself inside my current bubble intentionally. It's a matter of psychological safety and self-respect. I wasn't kidding when I said I hope you can find a way off that chain, it's an outcome I'd wish on all my peers. reply YZF 19 hours agorootparentprevI agree with you in principle that's the correct attitude. However I don't think the comparison to the music industry is necessarily correct. A lot of managers in tech got there because they are technically strong. We can argue about whether that's correct or not but I think that's typically the case. People who perform well as engineers are the ones who are given leadership opportunities. People who do not are not. So first challenge is given you were maybe one of the smarter hires, of some smart people that tried to hire people smarter than themselves (let's assume), how do you hire people smarter than yourself? at scale? Where we end up typically in successful tech companies is with some degree of a mix of trying to make \"folks at the pointy end successful\" and some degree of \"telling the folks at the pointy end what to do\". Usually managers and directors are very strong technically and quite sharp, though more distant from the actual work because they don't do it any more. The precise mix depends on culture and circumstances but it's almost never this ideal environment of servant leaders surrounded by immense talent and just facilitating that talent doing great things. I've been in places that are very close to the \"good\" end of this spectrum and there's still going to be some pause in giving feedback to leadership that they've done something wrong. Maybe you have a great relationship with your lieutenants where they can be openly critical of you and you reinforce that. I think that's highly unusual in a social environment. It's a lot more likely there are certain things they won't share with you because they estimate the damage to the relationship is larger than the utility of being open. EDIT: I misread your statement about hiring people smarter than yourself, so I think we agree there. The problem is still that if you're the smartest person there's a bit of tension between that and creating conditions for the people under you to be successful. Btw, I still think you should try and hire people smarter than yourself ;) it's just hard to impossible to scale that - as you point out. reply dahart 2 hours agorootparent> it’s just hard to impossible to scale that The phrase “hire people smarter than yourself” is a platitude that is intended to foster an attitude, just a useful way of framing & thinking about people, mainly aimed at the manager, but has the byproduct of making ICs feel good about themselves. It’s not really a literal measurable specific requirement or goal. One way to see that nobody is taking it literally is that nobody is reporting IQ on their resume, and nobody is giving standardized IQ tests during job interviews. (And of course I mean statistically nobody, I’m not claiming that it’s never happened.) Often in hiring ‘smart’ doesn’t really mean smart anyway, it means wisdom, experience, attitude, skill, communication, knowledge, motivation, creativity, adaptability, friendliness, culture-fit, etc., there are many different ways someone can be ‘smarter’ than you on at least 1 axis of whatever ‘smart’ means, and it’s generally not hard to find them if we’re realistic about how smart we are on all axes. reply inopinatus 18 hours agorootparentprevI don't want to rebut anything you say, but I will add one observation. > I think that's highly unusual in a social environment Agreed, but in my experience of startups particularly, this becomes more commonplace with older founders. It can also form the basis of an high-performance enclave within otherwise ossified large companies/institutions; these tend to get dragged down by the mediocrity police after a few years, but in the meantime you can get some good stuff done. Whether the music industry analogy is valid may be debatable, but I've had the privilege of seeing it first-hand, music was/is the family business, I grew up knocking around recording studios. So this mindset is engraved on my expectations of all talent-based professions, and I try to remember it whenever I fail to be humble. reply namdnay 6 hours agorootparentprevin my experience, people higher up the chain are much more at risk of being let go at any time reply joz1-k 5 hours agorootparentI agree. And the insecurity that these managers feel makes them very poor leaders. They tend to be overly subservient to higher-ups and just pass all management decisions down the chain without too much thought. And they like to punish any disagreement (no matter how reasonable) from their subordinates. Insecurity is the opposite of a culture of trust. And where there is no trust, there is no real leadership. reply fny 21 hours agoparentprevI think you’re ignoring the “without getting fired” part. The implication is that you’re in a situation where management is stubborn or even hostile to feedback. Most organizations don’t practice “highly effective communication”. It’s often a nightmare riddled with politics and ego. reply Rygian 21 hours agorootparent> I think you’re ignoring the “without getting fired” part. The \"start polishing your resume\" bit was quite explicit. reply harimau777 19 hours agorootparentUnless you are the .1% of developer (and probably with a heaping helping of luck) you aren't going to end up working someplace that isn't terminally dysfunctional no matter how much you polish your resume. reply rqmedes 12 hours agorootparentBeing in the top 0.001% of developers won’t help if you don’t have a large network or good brand reply Aeolun 18 hours agorootparentprevBesides, who wants to work with someone that’s only worked in these terminally dysfunctional workplaces. There must be something wrong with them. reply fny 21 hours agorootparentprevI'd argue 99% percent of companies operate like this. No one likes blunt feedback--even in friendships and marriage. Good luck if you throw money and ego into the mix. reply Muromec 19 hours agorootparentprevI would say ego problem comes with a title. reply roenxi 8 hours agoparentprevThere is some important piece of context there though - if leaders aren't capable of the emotional intelligence to process blunt feedback, they are bad leaders and there is no hope of change. Learning to recognise them and just leave them alone is one of those valuable life skills that most employees learn sooner or later. Some people are just not going to take feedback and if they end up in management that is that; there is nothing to do but enjoy the show as best you can. In that situation fluffing the feedback will do nothing. It might take years of effort to get marginal improvements and it is more productive to focus on something that is ... well ... more productive. reply joz1-k 5 hours agorootparentThere is a lot of truth in this, but especially when developers are semi-randomly promoted into leadership roles, they should be given enough time (and mentorship) to learn from their own mistakes. Some will learn very quickly (those with enough emotional intelligence), and some will learn nothing no matter how much time you give them. Being a good manager with formidable leadership skills is something you can only get through experience. reply throwawaymaths 2 hours agorootparentprev> there is no hope of change. There is an off chance that management (I'm not using the word leadership here deliberately) is taking leadership coaching, that the coaching is good, and that the coach will actually intervene and bring about change. Small likelihood of course, but not zero. reply danjl 21 hours agoparentprevIt would be wonderful if the world could accept blunt feedback. It is certainly easier to give and more in-line with what most technical people would prefer. However, we work with humans, and we have learned an awful lot about how humans respond to language, especially criticism. The advice here applies to giving feedback to any human, not just superiors. As you spend time working with humans, you learn, perhaps slowly that what you might consider \"fluff\" is really about helping make your point. Being direct doesn't always, or even usually, work as well. reply nithril 20 hours agorootparentDefinitively agree. Being blunt, too direct is just the opposite of a good and effective communication. reply lucgray 20 hours agorootparentBeing too blunt raises defenses and completely wipes out the effectiveness of your feedback. Folks that are invested in outcomes make choices for good reason, and they've probably got a track record to back it up. You have to meet them where they are, and considering their communication styles and how they make decisions will improve the chances you're actually heard. It's a fact of life that people shut down when approached with evidence that refutes their world view or choices. It doesn't matter if it's your boss or grandparents. reply nvarsj 18 hours agorootparent> It's a fact of life that people shut down when approached with evidence that refutes their world view or choices. I don't really agree with you. This is a basic quality of skilled leadership. You want people refuting your worldview with evidence! It lets you correct course and make things better. Only insecure people shut down like this in my experience. reply 0xDEAFBEAD 3 hours agoparentprev>The reason you don't fluff feedback, or any information for that matter to your superiors, is described in basically every handbook on highly effective communication in organizations. This is the key assertion underlying your comment, yet you just wave it off by referring to unnamed \"[handbooks] on highly effective communication in organizations\". My no-fluff feedback for you: Your comment would've been far stronger if you simply specified these unnamed handbooks, and summarized their argument, as opposed to fulminating + offering a handwavey argument-from-authority. (Curious to see how you'll take this no-fluff feedback. Let's see if you're management material by your own standards.) EDIT -- here is a LinkedIn post by a lady who wrote a book on workplace communication called Radical Candor. Her post recommends plenty of fluff for the boss, and to be frank, I think she makes some pretty good points: https://www.linkedin.com/posts/kimm4_how-can-you-practice-sa... reply hn_throwaway_99 3 hours agorootparentI'm always curious when comment responders glom on to the least important part of a comment and dissect it to no end. I took \"is described in basically every handbook on highly effective communication in organizations.\" as essentially \"the standard for communication in effective organizations is to be direct and to the point.\" It did not warrant a \"SOURCES??!!\" response IMO because it wasn't saying anything that was uniquely attributable. reply 0xDEAFBEAD 3 hours agorootparentThe claim didn't ring true to me, based on what I've read about the topic in the past, or based on my personal thoughts and experiences. So I wanted a source. It should be easy to provide a source, if sources are as plentiful as lijok says. >the standard for communication in effective organizations is to be direct and to the point. Sounds very nice, but empirically humans often struggle with frank feedback. I think that goes for both subordinates and superiors, for different reasons. I would argue it can be worthwhile to spend an additional 25% time to make it clear that it's nothing personal, to avoid risking a deterioration of your relationship. Obviously, it's good to have friendly relations with your coworkers, including your boss. If you have a high-trust relationship with your boss where there's no risk of deterioration, and you know your boss likes it when you speak your mind -- more power to you. Be direct and to the point. reply joyeuse6701 3 hours agorootparentI agree, I think there was a Buddhist analysis of conversation, right speech, which I find useful as a guide to giving and receiving information: Is it well intentioned? Is it kind? Is it timely? Is it beneficial? Is it true? I suppose that if you can craft feedback with this criteria in mind it’ll have a high chance of going over well. reply navane 3 hours agorootparentprevAre you replying to your superior? He didn't say always no fluff, just that as a superior you should be able to handle it. That actually is the key assertion, the power imbalance direction. reply 0xDEAFBEAD 3 hours agorootparentprevI was curious, so I used Perplexity.AI as a quick sanity check for lijok's comment. Here's the result: https://www.perplexity.ai/search/what-are-some-handbooks-on-... None of the books identified by Perplexity.AI appear to endorse lijok's claim. Of course, it could be a confabulation -- this is just a quick sanity check, to see if the claim is as manifestly true as lijok seems to think. (Putting this in a separate comment so people can downvote separately if they want. If people don't like this sort of AI sanity check on HN, that's fine. Thought it was worth trying as an experiment, though.) reply svnt 3 hours agorootparentDid you read the result you linked? > Several handbooks on highly effective communication in organizations are: 1. “Winning” by Jack Welch and Suzy Welch, which emphasizes clear communication, open dialogue, and transparency in organizational success. 2. “Fierce Conversations” by Susan Scott, focusing on transforming everyday conversations at work to achieve success. 3. “Radical Candor” by Kim Scott, which promotes empathetic yet direct communication in professional settings. In your reading of those titles and summaries, do they seem likely to recommend communicating layers of fluff to executives? reply 0xDEAFBEAD 3 hours agorootparentScroll down to the 2nd question: \"What advice do these books offer to a subordinate who wants to give feedback to their manager? What's their reasoning for the advice?\" reply dingnuts 3 hours agorootparentprevmore like an insanity check. Did you ask the AI multiple times? usually if I ask a yes or no question and simply repeat the prompt a few times the model will tell me yes, no, and maybe, for any question. reply 0xDEAFBEAD 3 hours agorootparentHere's a link the AI cited, a LinkedIn post by the author of the book Radical Candor https://www.linkedin.com/posts/kimm4_how-can-you-practice-sa... >How can you practice safe Radical Candor with your boss? >... >Start by asking for feedback before you give it. You want to make sure you understand the you're boss's perspective before you start dishing out praise or criticism. >... >Tell your boss what you appreciate about them. This is not \"kissing up.\" It's praise, which is an even more important part of Radical Candor than criticism. >... >Say something like, “Would it be helpful if I told you what I thought of X?” >... >If your boss says yes, start with something pretty small and benign and gauge how they react... reply haliskerbas 16 hours agoparentprev25% of my manager and above in big tech have acted in the ideal way you describe, and the rest have been back stabbing, childish, two faced, toxic, and many other negative traits, making any open honest or direct communication impossible reply disgruntledphd2 8 hours agorootparentHonestly, if you've had decent management 25% of the time, you're doing much better than the rest of us. Management is hard, because it makes significant emotional demands on us, and a lot of people deal with the combination of power and emotions badly. reply seanp2k2 20 hours agoparentprevAt [company that purportedly highly values candor], I’ve seen multiple people get canned by VPs or directors they’ve criticized internally. Granted, these situations were cases where this was communicated either in a larger feedback meeting that was supposed to be a “safe” space for such feedback, or via other communications that were visible to more than just the person being criticized. These criticisms were definitely high up in the PG pyramid and critical of the direction / vision / execution, not of the person themselves. The people who were fired from this were high performers who weren’t otherwise on PIPs or anything like that. Leadership did the typical leadership dance of shifting blame, re-org, and carry on. It was sad and further eroded both trust and morale of others familiar with these situations. reply Simon_ORourke 9 hours agorootparentI've seen this a lot, especially with junior folks getting on their high horse publicly about some direction or decision. Whenever it happens I make a point of putting a reminder in my calendar to check their corp Slack handle after three weeks to see if they're still employed. 9 out of 10 are deactivated when I check back. Hold your tongue, there's no such thing as a safe space in any all hands or group-level meeting. reply MortyWaves 3 hours agorootparentSorry you work in such a toxic job reply rqmedes 12 hours agorootparentprevSeen this dance many times reply zeroonetwothree 20 hours agorootparentprevI suppose it depends on what type of “criticism” it is. Generally feedback is most valuable when it’s constructive not critical. If you just say “X is bad” that isn’t very useful no matter how you phrase it. I would be surprised if respectful constructive criticism was met with firing but I suppose it does happen. Probably not the best to be working for those people in any case. reply wjnc 21 hours agoparentprevThis. I had to get a little used to not fluffing around my feedback. One of our managers just asked me to give it to him straight, directly and 1-on-1 and we’d get along fine. So we did. I still am having trouble with how little, what I see as fact based, feedback is needed before the average person has had enough. Example: I like to point out shitty work processes (one needs a hobby). Anything with a few loops and some rework goes for me to start my first time right story. People take offense. No stop, you are not the process. You didn’t design it, you merely took part because we asked you to. Now stop and consider whether you think it is shitty and if so, what can we do? Can you do it? Do you need help? When? Organizationally, it’s a good riff. For me, it’s strange to do and see it help. It feels like delivering snake oil. (I rationalize this as delivering Lean in thirty minutes.) My communication plan is facts >> options >> opinions >> advice. This way I help people mentally separate “what is” from whatever opinion I’m holding. This works for both verbal and written communication. It’s a coping strategy for being outlier direct. reply throwaway346434 10 hours agorootparentI would give up a huge amount of my paycheck for a manager who heard me bitch and whinge about every little flaw; told me I'd made them too angry to continue the conversation but we should pick it up in ~48 hours with a mutually agreeable plan coming back with stats and analysis for where my opinion was simply wrong; vs where it was right. reply cle 21 hours agoparentprev> If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and will sink whatever function they have oversight of. You're assuming that the subordinate's feedback is sufficiently important to the business. It might not be. It might also not be important to the business if subordinates leave b/c their feedback is disregarded. I can imagine plenty of scenarios where a leader could still succeed while not giving a crap about subordinate feedback. It depends on the goals and the dynamics of the business, the leader's experience, market conditions, labor environments, etc. > The reason you don't fluff feedback, or any information for that matter to your superiors, is described in basically every handbook on highly effective communication in organizations. You can argue in your exit interview that you were just following handbooks. reply zeroonetwothree 20 hours agorootparentIt’s even more important to give it bluntly if the feedback is irrelevant. That way you’ve wasted less time. Me: “we aren’t giving enough guidance to new hires” Leader: “it’s not a priority for us since we are freezing hiring” Perfectly good interaction, where you didn’t waste time sneakily phrasing things you think you know better than the leader. And you learned some valuable info about the org priorities as a result. reply cle 19 hours agorootparentIf the feedback is irrelevant, you'll waste the least amount of time by not giving it at all. (I think that's slightly different from your scenario though, where you don't actually know if it's irrelevant.) reply lazide 7 hours agorootparentAnd how would you know if it is irrelevant? See prior comment. reply cle 4 hours agorootparentDepends on the org and how information travels. Knowing tricks like this are the superpowers of people who move up quickly in large orgs and make things happen. You can sometimes do fine without knowing this, and going through the \"official\" route of the direct feedback loop. If you can figure it out elsewhere though, it'll usually build more trust with your superiors. reply fellowniusmonk 39 minutes agoparentprevYes, many \"superiors\" would be better replaced by AI because they would be better able to process accurate feedback dispationately. Where have you worked my dude that you have this perspective? After a long and storied career I can safely say you must have a narrow experience and there is nearly endless literature about the need to manage up. Or maybe you're a bully boss yourself and it's just an empathy disconnect. Or maybe you've only worked in relatively large corporations? Idk, the thick skinned executive isn't a trope and it isn't a trope for a reason. reply tyrust 21 hours agoparentprevThe advice isn't backwards, but some senior leaders are in the sense that they don't take feedback well. In this case, this advice is sound. Sure, in an ideal world you wouldn't have to fluff it, but I'm guessing many of us aren't in that world. reply cgio 18 hours agoparentprevAs a senior leader myself, that was my initial reaction. Then, I thought about myself and cohort and I would say, unfortunately, the advice in the article is required. There are challenges in feedback in both directions. E.g.the people who are best at receiving it are the ones who usually don't, either because they are strong in many other things than the feedback domain, or because they seem so self confident that people are intimidated. On the other hand, people who are not good at receiving feedback are also the ones who would be vindictive and their reactions may poison feedback as a practice. And also people may switch from one category to the other transiently, because of other pressures etc. In summary, in my own practice, while I am opinionated, I have never given negative feedback either to managers or subordinates. Not that they were all perfect, but I found it is usually up to me to work with the people and their strengths and weaknesses and by focusing on strengths I have not corrected any weakness, but have often made them irrelevant to me. Some may say this is a weakness for a leader, and I would agree but still focus on my other strengths. Edit: an additional consideration as I am digesting my response. People are more open to discussing how to improve a process or a system rather than a person or even more so themselves. Feedback is sometimes personal, that's why things like post mortems, process reviews etc. can work miracles when we manage to keep them about the process or framework rather than the people who are assigned to them. An additional slightly cynical point on feedback received as a subordinate (no matter how high up you most probably report to someone unless you are at the top). If someone gives you feedback about what you should do to get promoted/a raise etc , you are 90% not going to get those even if you heed to the feedback. These things happen for things you do, and the broader perception of yourself not on the basis of a checklist, and if they use a checklist against you, they don't really care about You. If someone mentors you, you will get it. Learn to read the difference between the two. reply zabzonk 18 hours agorootparentWell, \"senior leader\", if this is the kind of incomprehensible stuff you routinely come up with, I'm amazed your teams produce anything. reply ctxc 11 hours agorootparentFormatting/phrasing could be improved, but incomprehensible? I don't think so. reply cgio 5 hours agorootparentprevWell, I must be good in other things right? Not known for being very comprehensible indeed. We all have to play to our strengths. reply rdtsc 19 hours agoparentprev> If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and will sink whatever function they have oversight of. If you find yourself working under such people, don't bother giving feedback, start polishing your resume. Sounds good on paper. Maybe true, oh 5 years ago. In this job market, polishing the resume is nice but you might have to deal with irrational superiors for a little longer. That's what the article is about. > The reason you fluff up feedback to your subordinates is because lower down the chain they tend to be insecure and don't yet have the experience to distinguish between actionable impartial feedback, and threats to their job security. It would all be nice and good if \"subordinates\" and \"superiors\" were some completely different, disjoint sets. Yesterday's insecure peers and your subordinates will tomorrow become your superiors. People who can - do, those who can't - manage. Their personalities and other qualities likely wouldn't change in the meantime. In a perfect world, everyone who is promoted to be anyone's superior will go through a strong leadership vetting process and they will take un-fluffed honest feedback from subordinates, without retribution. But I have yet to work for such an organization. Maybe you're luckier... reply awanderingmind 10 hours agoparentprevI agree strongly - if I worked at an organisation where the linked article was the 'necessary' way of communicating I would look for a job at a less dysfunctional company. The context of the article seems to be a workplace with a sense of hierarchy that is inimical to honesty if it threatens insecure managers' egos or social standing. reply alistairSH 3 hours agoparentprevThere a lot more subtlety to this than you seem to indicate. I’d never give negative feedback to an exec (+2 levels above me) in a large meeting. I’d wait for a more private setting. With my immediate boss (director) I’d provide feedback in a small “managers only” group if I thought there was something to debate as a group, but not an open team meeting. But your comments about subordinates is true. Generally try to keep feedback positive/constructive. And time it so they don’t feel attacked. reply throwawaymaths 2 hours agorootparentFor (most) management. Absolutely do NOT do this: \"I’d wait for a more private setting.\" Only do this IF you think management is well adjusted human being that is not ego driven. I leave it to reader to decide exactly how much of management falls into that bin. If management is not, they will know that you are a threat to them and work to undermine you and get you removed. If you provide feedback publically they can less afford the reputational hit (if you're correct in your publically aired assessments). In either case you must play nice with your coworkers and subordinates. reply alistairSH 2 hours agorootparentFair point. “More private” not 1-on-1. I’d probably have my manager in that conversation (and quite possibly run my thoughts by them before offering them to the exec). reply chipdart 2 hours agoparentprev> If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and will sink whatever function they have oversight of. You're arguing based on how you think the world should be instead of how the world actually is. reply herval 20 hours agoparentprevThat’s nice in theory. In practice, the likelihood of you working for someone who’s unable to process the truth and will shoot the messenger is very high reply zeroonetwothree 20 hours agorootparentI don’t know if it’s “very high”. It can happen but on average I think successful people tend to be more reasonable and intelligent than average (not always obviously). reply lazide 5 hours agorootparentWhen times are good? You have a chance. When times are bad? Oh boy. reply atoav 6 hours agoparentprevYou must be very lucky. The majority of places where I worked was headed by people with fragile egos that you had to slowly guide to the right conclusion without the presence of an audience. If you told them something that could be interpreted as a criticism of a decision in front of others they would in principle not accept it and play to the audience. If you just told them a fact thst they disliked they would argue against it, I had a superior argue against fundamental laws of physics bscause he disliked the conclusion that followed from that lae being true. Luckily I am a very diplomatic person and have no issues with that — but apparently things within organizations aren't as they should be. reply runeblaze 16 hours agoparentprevMy limited corporate experience is that you fluff feedback to the less effective leaders so that you can still influence them. The more effective leaders you talk to them directly and team up with them to accomplish great things together. It is a matter of different strategies. reply kijin 7 hours agorootparentLess effective leaders are like GPT. You need to be both careful and creative with your prompt in order to get them to produce the result you want. :) reply swisniewski 18 hours agoparentprevI think you may be making assumption: that the feedback you are trying to give is clear, articulate, and constructive. When speaking to someone significantly more senior than you it’s entire possible that your feedback may not be. And that is really the point of the post. Here is advice on how to make sure your point is clear, articulate, and constructive. As someone becomes more senior 2 things happen: 1. They acquire more authority 2. They have more demands on their time. In these situations, you need to work to make sure you are communicating what you intended to communicate. That requires effort. I wouldn’t view this advice as “how to deal with fragile egos”, but instead would view it as “how to make sure you are not misunderstood when having critical conversations with high stakes”. In that regard it is good advice. reply Aeolun 18 hours agoparentprevI think not raising anyones hackles with your feedback applies pretty universally. It’s too much to expect senior leaders to not be human. reply Arech 5 hours agoparentprevExactly this. Somewhat an issue here though, that this is essentially a matter of a person's culture. What you've said is most likely true for WEIRD (acronym) people, but for other cultures where retailiation is quite possible, one either have to dance that silly dances, or indeed polish their CV. reply szundi 21 hours agoparentprevHard not to be cynical about your response but do you believe most of the superiors out there are on this level that you specify? Would be a joke. reply lr4444lr 7 hours agoparentprevYou are not entirely wrong, but I think you're underestimating the value of respecting human emotion. If people are leaving the team or it is missing deadlines, angering customers, making more work for other teams etc., your manager doesn't need your blunt feedback about performance and sustainability. reply majormajor 15 hours agoparentprevI'm not a fan of a lot of the examples here for feedback up or down. > “We may need to give even more guidance to new hires.” Up or down, \"we may\" and \"even more\" are weasel words that weaken what you're saying. It's trivial for someone to interpret that as \"they think maybe we could do more, but they seem to also see that we do a good amount already.\" > “I used to struggle with this, and when I tried X, it really helped.” This one I think is good for managing down; bad for managing up. It's less weasel-y but it risks coming off very aggressive - \"I already figured this out, what is wrong with you?\" > “The team made amazing progress when we all focused on the website update last month. It might help to have one or two clear priorities for the team this month that everyone can rally behind.” You have a great example, \"it might help\" is again weakening your POV compared to something more like a direct \"what are the top priorities this month that we can all rally around?\" > “When we were able to dedicate that first week to training Steve, he got up to speed pretty quickly. The bit of upfront time seemed to have paid off, and taking a similar training approach for our next hire could help them ramp up just as fast. What do you think?” Here we've taken a lot of words to state the obvious, which IMO both runs the risk of losing the urgency in the verbosity and coming off as pandering and over-explaining the obvious. I think \"what are your thoughts on\" and \"one approach might be\" are better in both up-and-down directions as long as associated with a clear specific \"here is something I noticed that I think is sub-optimal\" situation. reply mewpmewp2 9 hours agoparentprev> start polishing your resume What if you have reached the optimal level of income, and the work itself you like? Anywhere else would be a cut in either one of those 2. reply spoiler 8 hours agorootparentI guess distance yourself emotionally from your job, but continue looking and be picky about your next role. I'm in a similar boat, but my engineering manager wants to get rid of them, so I'm being dragged into office politics now. Other than a few rotten apples, the company is great. So, I'm also somewhat reluctantly looking for a new role. reply neilv 19 hours agoparentprevI had much the same reaction. To put it diplomatically, the article's advice is all about diplomacy. Much of their examples are a kind of diplomacy that you might use with a somewhat hostile, stupid, and/or petty person. Not in an environment of trust and respect. Or with an enterprise customer, where \"business politeness\" is expected, trying to gain advantage is expected, and no one expects you to be very honest. (Exception: In some cultures, it might be outright rude and mutually awkward to ever say anything critical-sounding upwards, or to offend someone by not going through the politeness motions, which would just be disrespectful. The article seems to be coming from some kind of environment or social expectations like that. I'm not talking about that here. I'm talking about, say, a US tech business environment that at least thinks it values speaking up with honest assessments.) Ideally, management welcomes straight talk, and will do the right thing with it. For example, if you've not been given reason to think the person above you is dishonest or unreasonable, and they haven't been given reason to think that about you, but you don't yet know them well, here's an example: \"The team is having some serious difficulty. Is now a good time to talk very candidly and constructively about that? ... Two things. First, I think that people are feeling that they don't have a good understanding of what the goals are, and how they're supposed to be prioritizing, on a daily basis. The other thing that seems to be bothering people is that onboarding is rough, and people immediately feel like they're not doing well, and then they aren't getting out of that feeling.\" Note that this might sound a bit like some of the diplomatic framing of the article, in that it's not accusatory, but that's not what I'm doing. Some examples in the article attribute problems to the manager, and then use diplomacy, for cultural politeness, and/or to circumvent some pettiness they expect. By contrast, in this example, I'm instead respecting the manager as someone who will take the information constructively. I'm also not presuming to attribute blame for the problems, since I don't have all the information about the situation, including not knowing everything the manager has been doing and why. reply interludead 3 hours agoparentprevIf you find yourself needing to tiptoe around a leader's ego too often, it might signal deeper systemic issues reply Simon_ORourke 9 hours agoparentprev> If you find yourself working under such people, don't bother giving feedback, start polishing your resume. Never a truer word said than this. It's incredibly naive to think that any unfiltered feedback upwards to senior management will be welcomed. In reality, no matter how accurate the feedback may be it will be regarded at best as useless, and at worst as a direct threat to leadership requiring a response. This response may come in the form of a re-org, team move or headcount reduction. While totally disingenuous, your best strategy is to simply tow the corporate line while looking for a new job. reply whateveracct 4 hours agoparentprev> If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and yet here we are... reply est 4 hours agoparentprevGood lord the comments section surely blew up. Can we just give this \"fluff-up feedback\" job to LLM already? reply IshKebab 21 hours agoparentprev> If your superiors are unable to process no-fluff information, regardless of whether it's feedback or updates, they have no business lording over anyone and will sink whatever function they have oversight of. Maybe, but the title is \"without getting fired\" not \"without being wrong damnit!\". Unless you have a significant number of shares in the company you should care about your own employment and success over the success of the whatever function this person has oversight of. > The reason you don't fluff feedback, or any information for that matter to your superiors, is described in basically every handbook on highly effective communication in organizations. And that reason is...? reply jellicle 20 hours agoparentprevIf you've honestly never seen the types of leaders envisioned in this article you are very lucky indeed. For a large majority of supervisors, if you give them carefully-worded, polite, respectful, private, accurate, truthful, ego-preserving feedback about something they're doing wrong, their response will range between \"immediate firing\" and \"hold a grudge against you, fire you as soon as they can find a replacement\". There is nothing that makes people as angry as accurately pointing out their flaws. The way around this is in essence to get the leader to think it was their idea to make a change, which is possible in some cases but not in others. reply zeroonetwothree 20 hours agorootparentIt’s surprising to me that such dysfunctional orgs exist where a single person can just fire someone immediately over some feedback. How have they even grown to be a business with that attitude? But sure, you do need to adapt your strategy for the environment you exist in. That’s just common sense. reply hibikir 18 hours agorootparentThe org has to be small for the firing to be immediate, but I have seen a \"top of stack rank to unpassable PIP\" be caused by a single conversation... and that's even in companies most of this forum would consider top performing. I would argue that trying to figure out the fragility of your management chain's ego is a key part of a successful career, even if what we are going to do with the news is to choose to change jobs. reply scotty79 6 hours agoparentprevThis article gives a good advice how to give feedback to anyone without souring relationship. Everyone can be insecure and if your superior happens to feel insecure about you that day the damage can be severe. reply The_Colonel 9 hours agoparentprev> If you find yourself working under such people, don't bother giving feedback, start polishing your resume. Yeah, I'm not going to change a job just because one of my superiors is insecure (and the other things are good). This all-or-nothing mentality is just thought-stopping. reply dheera 20 hours agoparentprev> The reason you fluff up feedback to your subordinates is because lower down the chain they tend to be insecure and don't yet have the experience to distinguish between actionable impartial feedback, and threats to their job security. Rather than fluff it up, just make it explicit whichever you are doing. If you actually like their work and are making an actionable suggestion, just say that, and don't forget to praise them for the work that you like. Far too often I see managers only give the suggestion and then it ends up looking like a threat. > The reason you don't fluff feedback, or any information for that matter to your superiors, is described in basically every handbook on highly effective communication in organizations. The reason you do fluff feedback to your superiors is that you're on an H1B visa, are at risk of getting deported from the country and having to find a new home for your partner and new school for your kids (possibly in an unfamiliar language and environment for them), just for upsetting one superior. The reality is most people in large companies do not care about \"highly effective communication\". They are just trying to survive and not get deported. Once we can get rid of this stupid 60 day rule and insane housing and child-raising costs maybe people will start caring about their work. The most basic of Maslow's needs are not being met, hence the fluffing up to the authorities (bosses) who are in control of your livelihood. reply zeroonetwothree 20 hours agorootparentWell yes, it’s a higher variance approach. If you can’t afford to look for a new job then by all means keep your head down and avoid all controversy. I would do the same in that situation. That doesn’t apply to everyone however, so for those people it would make sense to try to make things better and potentially advance their careers. reply lupire 19 hours agorootparentprevIf most people in your company are on s, your management is probably breaking the laws and is not the sort of person who appreciates honest communication. reply drewcoo 21 hours agoparentprevPeople get promoted by \"managing up,\" which you call \"fluffing.\" reply codr7 21 hours agoparentprevThank God I didn't have to write all of that myself :) Well said! reply palata 21 hours agoprevIn my 13 years of experience, I would say it's never worth giving feedback to your manager. Either they are good and it's useless, or they are not and they won't learn from you. I have come to a simple rule: if the manager is good, there is no problem. If the manager sucks (often that's because they lack experience, but it's all the same), just lie to them in order to preserve yourself. No need to have empathy for them: there is no karma out there. Bad managers usually have no problem climbing the ladder, even if it means making your life miserable. Work for you, not them. reply steveBK123 20 hours agoparentLargely agree, 19 years here. Good managers and bad managers alike have weaknesses that are largely in-built personality traits. Telling them won't change how they've spent decades behaving. The two worst managers I had clearly had anger management issues and some sort of inferiority complex, theres no feedback to fix that. Try to stick with good managers as long as you can, especially if their weaknesses that don't bother you too much, understand where it's coming from, and try not to take it personally. The 3 examples at the top of the article - unclear guidance, unable to set priorities, and not training new hires .. these are good benign issues that I've seen repeatedly from good managers. You can remind them in a friendly tone why things are happening -(as they raise yet another low importance high urgency task) \"if we keep switching to these urgent but less important tasks, the long-term important things (give examples) you are unhappy with the pace of will continue to be slow\". The best outcome tends to be a 20% reduction in the undesired behavior, over many months. It doesn't go away or get unlearned. reply kstenerud 3 hours agoparentprevClosing in on 30 years now. The trick is to get into a company where the mission is sound, the direction makes sense, and your manager is good (i.e. protects you from above, and makes sure shit gets done in a timely and orderly fashion). Then, help your manager out. Everyone has their flaws, bad situations etc. Be a true team member and help your manager out on those rare occasions where they really need it. reply stavros 18 hours agoparentprevI disagree. Superiors are people too, and they make mistakes. I've had subordinates give me feedback (which I followed), and I've given feedback to superiors (which they've followed). Both ways were extremely positive experiences and everyone involved was happier for it. reply palata 4 hours agorootparentWhat kind of feedback was it? My guess is that those were pretty minor things that slightly improved your life. But the fact that it worked hints towards the fact that the managers were already competent, so the reports were already in a pretty good situation. No need for the advice of the featured article for that, right? reply stavros 1 hour agorootparentThe most recent instance, a few days ago, my feedback to the CTO was that, while the org restructuring he proposed was a good idea in principle, the way he did it was terrible, and that he ignored and disrespected his highest performers. I said he hogs all the growth for himself and doesn't let any of his reports grow into more responsibilities, and he's showing that he doesn't respect the people who are integral in the company's functioning. I also told him that there are people who do a ton of work to correct others' mistakes and don't get any credit or recognition for it, and he failed to recognize those. It kind of made him sad, which wasn't great because he's a nice guy and a competent CTO, but his latest move was catastrophic and he needed to hear it. > No need for the advice of the featured article for that, right? I mostly agree with the other commenters here, giving feedback upwards is easier and you don't need to sugarcoat it as much, because you can't fire the person above so they aren't going to be insecure about your feedback. Then again, they are people, and giving constructive feedback gently is better than giving it harshly, so I can't say the article is entirely unnecessary. Maybe partly. reply jayd16 19 hours agoparentprevSo bleak. It's fine to protect yourself but your managers are people too. You _can_ build a report with them and be frank with them. When I manage folks, I much prefer honesty over someone who just bullshits you. reply Blackthorn 15 hours agorootparentManagers aren't just people, they're people who have your employment in their hands. Reports will act appropriately for that fact. reply palata 4 hours agorootparentprevI feel like you took only half of my point. If the manager is good, then there is no reason to bullshit them. But believing that a bad manager will suddenly become good because you as a report taught them with a few carefully-crafted politically-correct statements sounds extremely naive to me. Let me give an example: to a good manager, you could say \"I'm under a lot of pressure because I have two many urgent things on my plate\" and they should try to improve your life by maybe de-prioritizing some of them. In a way you gave feedback \"it's not going well for me\", but you did not try to guide your manager in their role. So that's not the kind of feedback the featured article talks about. Now a bad manager will maybe be nice and say \"I understand, I really appreciate the late nights and weekends you spend getting closer and closer to a burnout, you are a really valuable employee to me\", but that's completely useless. Trying to tell them \"you know, in a previous job I had a manager who in these situations would try to de-prioritize stuff so that I could live normally\" is completely useless. If they aren't doing it yet, it means that they should not be your manager in the first place. Best case they say \"thank you for the feedback, I appreciate that you feel comfortable speaking up\" and don't change anything, worst case they get pissed because you \"overstepped\" (they are the manager, they know they know better, remember?). There is no world where they say \"you're right, I sucked until today, but from tomorrow on I will magically know how to be a good manager\". reply Wurdan 1 hour agorootparentCrazily oversimplified view of people. Just one thing you’ve missed: in addition to the axis of good/bad there’s an axis of experienced/inexperienced. Managers can be both good and inexperienced, in which case feedback is absolutely necessary to improve their lives and yours. reply devjab 19 hours agorootparentprevThere is a difference between treating someone as a human and bullshitting your manager though. I’m painfully blunt to the point where the management staff had to spend 3 hours in a crisis meeting discussing whether to fire me an another developer over our opinions given on a department meeting. Which to be fair was the wrong place to throw a couple of managers under the bus for something we’d been telling them for months, but hey. Anyway we didn’t get fired and nothing changed either. I stopped stressing about it after I had spoken my piece though so it worked rather well for me. Less so for the company, but it’s not like the two of us were the only ones management wouldn’t listen to. So I like it when I can be frank with managers. I think I’m also notoriously hard to manage because one of my character flaws is that I don’t respect authorities. I’m not stupid though. I’ll absolutely bullshit managers in situations where there isn’t really a “win” to be achieved. Obviously this will mainly happen with bad managers, but there will always be great managers who won’t like, understand or have a good connection with you. reply jayd16 18 hours agorootparentI think this is an example of a different issue. It sounds like your managers listened to your feedback often and even let high profile disruptions slide. In general I think honesty is a good policy and management should be receptive to hearing out problems and possible solutions but that's not the same thing as implementing all feedback. Maybe you're right or maybe your pet peeve just isn't a priority or can't be done for countless reasons. I'm not saying you did this but something I've seen often is employees confusing being heard with taking the advice. As professionals I think it's our job to give advice and respect management's decision to take it or not. That's it I also think it's management's job to explain the reasoning. reply devjab 10 hours agorootparentI mean, this is one example which fits the discussion. Also one that I cherrypicked because I was actually right. I’ve had plenty of managers who were good at listening, however, I think most have been great. I have also worked management a few years myself and taken education in that direction before figuring out it wasn’t for me, so I certainly understand the financial and political parts of management and that you as an employee never have the full picture. That being said, I have also had managers that I’ve played board games with on our free time who I haven’t actually given my opinion on certain issues with because they weren’t very good at taking that advice. Sometimes I’ve also not done it because I knew managers of my manager wouldn’t take it well if it made I up the chain. I view this more as an issue between me and the organisation I work for. If I’m not invested I’m not going to help it beyond what they pay me to do because it rarely comes back to me in a positive way. There are many aspect to it. I’ve also had a manager who was a total waste of space as a manager, only caring about the “good story” whether it was true or not to push their own career. Who was also rather cold in regards to management employee duties since they really didn’t like the negative sides of it. Who was then the warmest nicest person in their personal life. So it’s a very complex situation as you pointed out, but it’s also one where it’s perfectly reasonable to not try to lead upwards if you don’t want the hassle. At least in my opinion. reply lupire 19 hours agorootparentprevPeople who are busy thriving at work aren't hanging out in this self-pity party thread. reply palata 4 hours agorootparentNot sure what you are trying to say here. I personally have good managers right now, so I don't bullshit them. I have had mostly bad managers in my career though, and my advice in this situation is: bad managers are adversaries, behave accordingly. reply specialist 2 hours agoparentprevYes and: Churn moots the entire notion. That whole storming -> forming -> norming -> performing team maturity model stuff. Have a bad boss? No worries; wait 3 months and you'll have a new boss. Thereby resetting the team(s) and relationship(s) back to storming. Lather, rinse, repeat. Best feedback I've ever gotten was from peers (other bosses). And that was only after years of working together. Sadly, that was a long time ago. I'd kick a puppy to work on a stable, durable team again. reply jeremycarter 8 hours agoparentprevThis is very accurate reply flog 21 hours agoprevThis was one of the most exhausting aspects of working for a US company, especially as an H1B. Simply: just don't say anything, it wasn't worth it. I'm from cultures where we bluntly call a spade a spade and pride ourselves on disdain for hierarchy. There's far less fear in raising concerns generally to anyone, but it's quite possibly because of the far better employment laws. reply Hilift 2 hours agoparentI call it the \"smile and wave boys\" response. reply interludead 3 hours agoparentprevThis is why sometimes, \"just don’t say anything\" becomes the survival tactic - especially when the risk of speaking up feels like it outweighs any potential benefit reply ninalanyon 9 hours agoparentprevSounds like you are Norwegian. reply INTPenis 7 hours agorootparentOr Swedish, Danish, German, Finnish, Dutch, and many other European countries where the laws protect workers. reply bradlys 21 hours agoparentprevIt's not just due to an employee being H1B. It's that 80% of your peers are Chinese and Indian H1Bs who bring that culture of deference to authority into the US. I don't even feel like I'm working in the US when I'm working for any tech company these days. If I'm at ads for FB, I may as well be in Beijing. Some others, I may as well be in Mumbai. It would be nice to work with Americans/westerners for once and actually be able to speak up about something without getting fired. reply 01100011 21 hours agorootparentI don't agree with OP. I'm American and have mostly worked for American companies and have rarely had issues with giving honest, often difficult, feedback to superiors. But > 80% of your peers are Chinese and Indian H1Bs who bring that culture of deference to authority into the US. is sadly spot on. Even when the org is very receptive to feedback, one manager in the chain who possesses a cultural belief in absolute authority is enough to break the feedback chain and lead to an organizational abscess of festering dysfunction. It becomes even worse when your org's management has been taken over by a single cultural group and there is no one to turn to and your only option is to wait for the org to implode and be restructured from above. reply oreally 5 hours agorootparentThis happens with any sort of foreign investments into any other country that has different sets of values. Even now the locals in my country are complaining about neo-colonialism and india/china-only perspectives in the companies they work for. Protectionist reactions are real and shape politics. reply fcarraldo 21 hours agorootparentprevIn my experience, Americans are much more likely to see criticism as a threat or an insult than in most European business cultures, where blunt feedback is common. I’ve seen many teams in different companies led by Americans where simply pointing out that a plan will fail in a public forum is tantamount to spitting in their face. It’s absurd, and it destroys teams. reply csa 21 hours agorootparent> I’ve seen many teams in different companies led by Americans where simply pointing out that a plan will fail in a public forum is tantamount to spitting in their face. I’ve been put into the “practitioner of the dark arts” bucket twice when I predicted with detail and accuracy why certain large projects would fail. The folks in charge were offended when I presented my analysis, and they were just afraid of me after my predictions came true. reply steveBK123 20 hours agorootparentI've found these situations to be no-win. When I had reasonable certainty of my next gig being lined up, I even put the question to leaders. \"If I tell you why this project is destined to failure now in Q1 vs being quiet and playing along til end of year, will I be rewarded or punished any differently then?\". The response was 100% nervous laughter. It turned out both layers of management above me were also well aware the marching order they were passing along were going to end badly, and had already lined up their internal transfers, which happened within days of my departure as well. reply lcnPylGDnU4H9OF 3 hours agorootparent> The response was 100% nervous laughter. It turned out both layers of management above me were also well aware the marching order they were passing along were going to end badly, and had already lined up their internal transfers, which happened within days of my departure as well. If one has not read The Gervais Principle, it’s highly recommended. https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-... reply steveBK123 3 hours agorootparentYes it’s quite explanatory reply bradlys 19 hours agorootparentprevThe gap is much bigger between Americans and Chinese/Indian than it is between American and European. I’m not just talking about public forums. Saying anything to your superior (perceived superior or otherwise) would result in disciplinary action nearly 100% of the time. It is not even about blunt vs tactful feedback. It’s about any feedback. You do exactly what you’re told and you shut the fuck up. reply Tabular-Iceberg 8 hours agorootparentI found that out the hard way first time I worked in a company with European managers and majority Indian ICs. Acting European got me PIPed and then fired so damned fast for failure to shut up and do the needful. I don’t think H1Bism is even primarily about depressing IC wages in the west, it’s about middle managers being so burdened with pointless make-work from above that they just don’t have time to lead. They need people who don’t need to be led even if it costs in terms of quality and efficiency. reply tkiolp4 20 hours agorootparentprevInteresting. I used to work mainly with european developers (dutch, french, germans, russians, spaniards, polish, etc.) and I always could speak my mind, and others would do so. No BS, no avoiding direct confrontation. But more recently I have been working with ex-faang american developers and I don’t like it. It’s not that they are like indians and the like, but definitely not as direct and straightforward as europeans. reply nvarsj 18 hours agorootparentI feel like Americans are all over the place. The top echelons of business in the US are very blunt and direct. The lower levels tend to be very indirect with lots of toxic positivity. I think this works out for capitalism and exactly fits the Gervais Principle. Brits are even worse than Americans at all levels (hence, the largely incompetent government and the fact most businesses are poorly run - it's literally The Thick of It at all levels). Indian/Asians are the absolute worst in terms of directness, these are all very strict hierarchies of business that only succeed if the top person is a genius, since they will never be challenged by anyone. Europeans definitely are most direct of all, so they don't put up with wage slavery, so business leaders can't maximize their extraction of value from labour, but they tend to have better quality of life all around :). reply kaashif 16 hours agorootparentAs a Brit, I agree with your comments. I've had to overcome a lot of my own culture to be an effective leader, and even then I don't always do a good job. reply nvarsj 18 hours agorootparentprevI've had a pretty similar experience in big tech. Some cultures do really seem to struggle with feedback (both giving and receiving). It can be a very painful work environment as a result - given I'm an incredibly direct person. The best work culture I had was in a dutch firm. People just straight up called bullshit out all the time, and it got fixed fast. So refreshing. I've never been able to find another workplace like that. reply enugu 9 hours agorootparentReasonable observations on office behaviour are being processed into glib stereotypes on culture. Employees routinely show discontent in India, (just one instance https://www.reuters.com/world/india/workers-apple-supplier-f...). So much so, that labour disputes are considered a major obstacle to corporate investment. Like Europe, India has labour laws which make people hard to fire. There are other factors involved - if a H1B employee, whose job security is tied to the employer risks taking a 10x salary cut or more by going back home, then a fear for job security leading to such behaviour is a given. reply Aeolun 18 hours agorootparentprev> It would be nice to work with Americans/westerners for once and actually be able to speak up about something without getting fired. In my experience Americans layer the “we’re all friends here” on too thickly to ever be described as blunt. reply tiznow 5 hours agorootparentprevIt's not just H1-Bs from those cultures, either. I'll give everybody a fair shot but if your cultural mores are extreme deference to authority I'd like to be far away from you when doing anything serious. I'd argue that a certain level of distrust of authority is not only good but inherently American. And no, I'm not saying \"Americans take criticism well.\" reply wnolens 15 hours agorootparentprevToo much my experience as well. Inside AWS felt like hundreds (thousands?) of Indians who have terrible jobs but don't do anything about it. Now that I'm out I can't believe what I put up with. reply hackernewds 14 hours agorootparentPerhaps you could present yourself as worthy through your work, rather than bemoaning that others as worthy were more conducive to being treasured employees? reply hackernewds 14 hours agorootparentprevWhat a ridiculous complaint and wild gymnastics to blame a cultural gripe on to the hardworking deferent immigrants reply lupire 19 hours agorootparentprevI don't like all the stereotypes people throw around, but among those stereotypes is that California tech bros are pathological delusional wannabe-hippie optimists who blow smoke and sunshine at everyone. reply 5cott0 21 hours agoprevCaptain Miller: \"I don't gripe to you, Reiben. I'm a captain. There's a chain of command. Gripes go up, not down. Always up. You gripe to me, I gripe to my superior officer, so on, so on, and so on. I don't gripe to you. I don't gripe in front of you. You should know that as a Ranger.\" Private Reiben: \"I'm sorry, sir, but uh... let's say you weren't a captain, or maybe I was a major. What would you say then?\" Captain Miller: Well, in that case... I'd say, \"This is an excellent mission, sir, with an extremely valuable objective, sir, worthy of my best efforts, sir. Moreover... I feel heartfelt sorrow for the mother of Private James Ryan and am willing to lay down my life and the lives of my men - especially you, Reiben - to ease her suffering.\" https://www.youtube.com/watch?v=DhbObZEF0Mc Saving Private Ryan reply thanksgiving 20 hours agoparentI don’t get it. He said gripe to his superior but he is basically kissing ass? reply inopinatus 20 hours agorootparentNo, that is exactly how you inform a superior officer that you believe the mission is a waste of time, effort, equipment, and manpower, and will probably get everyone killed for next-to-no benefit. reply unethical_ban 6 hours agorootparentprevIt's best understood in the context of the story. I highly recommend the movie. He's being sarcastic about his approval of the mission they're on, but is making the point of not overtly complaining to his unit. reply rendall 10 hours agorootparentprevI interpreted it to mean that he was still Captain and part of his job was to keep up morale and model positive attitude. Even hypothetically, he was not going to gripe to his troops, and as far as they are concerned, he believes it is a worthy mission. He was jokingly modeling the proper, positive attitude. All this was understood by his men. reply bambax 21 hours agoprevIn aviation this is what Crew Resource Management is about, and in particular, how to make sure the monitoring pilot, who may be the least experienced one, can effectively supervise and review the actions of the other. Many crashes were the result of copilots' fear of speaking up. Business life could learn from this. The person in charge is not a king, they're simply the person tasked with making decisions. There is nothing scandalous in having another person evaluate those decisions against a set of principles or common sense, and speaking up when something doesn't feel right. Better that than crashing into a mountain. reply vacuity 3 hours agoparentEven kings (nominally) have advisors and some level of contact with the people they rule over; they aren't expected to just make decisions from an empty room with exactly no room for being swayed. In theory, a good king is like that. A bad king, and similarly a bad business leader, shouldn't be used as exemplars though. reply Mawr 14 hours agoparentprev> Better that than crashing into a mountain. Quite literally: https://youtu.be/kamyxB-yKrc?t=1479 Or rolling off a cliff: https://youtu.be/0ga8UFy1M04?t=742 reply MrMcCall 17 hours agoparentprevThat story in Gladwell about the (IIRC) Korean Air having to switch cockpit languages to English in order to escape the intrinsic layers of deference built into the language was hardcore. They were going to get delisted in Canada if they didn't do it. Yeah, better than crashing into a mountain. That cockpit voice recording was really chilling. Gladwell gets a lot of flack, but he's told some interesting stories. And your further point about businesses needing it too should be expanded to organizations of all kinds. This is a human problem, which means it's an ego problem, on both sides. reply ptx 8 hours agorootparent> Gladwell gets a lot of flack, but he's told some interesting stories. Isn't the flack he's getting due to exactly that, that his stories would be interesting if true but often aren't? reply MrMcCall 8 hours agorootparentI haven't followed stories about him, but I doubt that all or even most of his stories were made up. I mean, the Korean Air (IIRC) one can't have been fudged, right? reply specialist 1 hour agorootparentprevHe recently did a mea culpa about the tipping point stuff. Glad he did. I really, really disliked Gladwell. And yet Pushkin (his podcast network) carries some of the best stuff ever (Jill Lepore). And I found I was agreeing with a lot of Gladwell's (and Michael Lewis') overall \"punching up\" worldview. So I was having trouble reconciliing my two views of him. As we've seen with Lewis' recent hagiography for that crypto freak: people are just people, they make mistakes, everyone's got blind spots, we don't have to agree on everything to learn from each other. reply Tabular-Iceberg 7 hours agoparentprevIt’s fascinating how resistant pretty much every industry is to taking lessons from aviation, considering how much empirical evidence there is compared to almost every other management paradigm, which basically amounts to “just trust me bro”. It particularly shocked me working in shipping where the lessons can be implemented pretty much without modification since it’s all the same work except they move in 2 rather than 3 dimensions. reply loup-vaillant 4 hours agorootparentThe difference is how measurable the consequences are. In aviation when there's a screw up people die right then and there. People dying is a very hard to game metric, and it provides a very strong incentive. The consequences of bad management in a software project on the other hand are much more nebulous. And nobody died as a direct consequence of some manager being a jerk… oh wait, I'm sure some did (committed suicide or gone postal), but it's easy to just blame the worker instead of the working place. reply Tabular-Iceberg 1 hour agorootparentIt’s not that. MV Sewol killed 304, many of them schoolchildren. The captain was put away for life, and rightfully so, but it’s not an incentive to do much else. For some reason only air crashes seem to make any lasting impressions. reply zug_zug 5 hours agoprevThe interesting thing in my mind is how dysfunctional I've found reporting chains' behavior (to the company). I've found the same thing others here have found -- certain cultural backgrounds or a large preponderance of H1Bs create a culture where upward feedback is silenced. And in the end usually the company loses out - directors forge ahead with ill-informed projects (rewrite entire system X), don't measure/cherry-pick/game-metrics, and create a major threat to anybody on the team who surfaces any contraindicating metrics (e.g. \"Our pipeline still takes Y hours and nobody is happy about it, including us\"). reply plank 9 hours agoprevDutch person here (have been told we are some of the most direct people): my experience is that it is not the words but the intention. E.g. the 'give more training' example: 'I do not understand why we do not give more training. It seemed to help with Steve, why are we not doing more so'. And being genuinely interested in the answer. Do not assume you are always right in assuming more training helps, but ask yourself why it may not be. Having an open mind can really help. And perhaps you were right to be astonished in 95% of situations, in 5% (or more) you might learn something. Other things are certainly true: it may be better to ask that question in private, as opposed to while the leader addresses the whole staff. reply kybernetikos 21 hours agoprevMost of those examples (not giving enough direction, not training new hires enough, not being clear enough on priorities) are probably not going to be surprises for the person, and if you give feedback that shows you want someone to behave differently without having given some thought about why they aren't already then your feedback talks more about your own lack of experience and empathy than anything else. To give good feedback to anyone you need to understand something about the pressures and challenges that they are facing. And remember that everything is a trade off. For example, perhaps they're incredibly busy, and would like to spend more time with new hires, but are struggling to find time because they aren't getting enough blocks of concentration time to work out clear priorities and they have been told they need to give their trusted colleague more opportunities to grow so they delegated it to someone. Most likely, if you think something is a problem then they do too. They don't need to be told that or criticised for it, they need help solving the problem that causes the problem. Imagine the difference between \"I want to give you feedback that you aren't spending enough time with new hires\" vs \"I know you've been wanting to spend more time with the new hires, why don't you take them for lunch and send me to your status meeting over Tuesday lunch time this week.\" As I started doing more leadership, I became aware that a lot of the things I might previously have cited as predictable examples of leadership incompetence causing problems were not surprises to leadership. They knew that this course of action would cause problems. The reason that they went ahead anyway was because they believed that the problems caused by the other courses of action available to them would be worse. Of course, there are situations this advice does not apply, maybe the leader genuinely is clueless or evil or mistaken about the severity of a problem, but a good leader when presented with a problem elsewhere needs to start from a position of respect and learning and if you want to give advice to a leader you should start by trying to model good leadership yourself. reply cdavid 20 hours agoparent> Imagine the difference between \"I want to give you feedback that you aren't spending enough time with new hires\" vs \"I know you've been wanting to spend more time with the new hires, why don't you take them for lunch and send me to your status meeting over Tuesday lunch time this week.\" This is the proper answer. Ultimately, feedback should be about changing something. My experience is that most people are neither good at giving or receiving feedback, and that includes myself. There are more effective ways to change things. OP's is useful when you have to give feedback, which is expected in most large companies in some form or other (evals, etc.). reply danparsonson 10 hours agorootparentDelegation is the managers job - it's not up to the subordinate to delegate on their managers behalf IMO. reply cdavid 5 hours agorootparentOne of the surest way to get your manager's back is to help them make their goals and put some stuff off their plates. Like other people said, most semi competent managers are aware of issues happening in their team. If you come up w/ some proposal to solve those issues, it will improve the team much more effectively than some feedback. It also depends on your goals, but fixing some issues encountered by your manager is one of the most reliable way to promotion in up to mid size companies, unless your manager is a a*hole. reply Zeebrommer 9 hours agoparentprevI agree that most leaders will now they are fallible, and also have some idea of which things are problematic. As an inexperienced leader, I still valued getting \"known feedback\". It gave me a better idea of which problems were growing too large, and which ones remained minor annoyances. In addition, acknowledging the points that were brought up and explaining why I hadn't gotten to addressing them (besides being human) usually gave the person giving the feedback a more positive outlook. reply zeroonetwothree 20 hours agoparentprevI think the best feedback is pointing out problems (and then trusting the other party to act or at least explain why things are that way). You never have the full context so just telling someone they need to behave differently may not even be ideal given the information they have. reply lupire 19 hours agoparentprevI don't think a manager will be impressed by a report saying \"I know you can't do your whole job, so let me handle face time with the execs so I can take your job from you.\" reply Wurdan 1 hour agorootparentI would be impressed by one of my reports saying “We’ve worked together to get me ready for the next step in my career, and I think more face time with our execs will help me take that step. Can you help me find opportunities to get it?” This is assuming we’re on the same page about how ready they are to take that step. But if we’re not on the same page, then I’ve already failed in performance reviews and feedback. reply kybernetikos 18 hours agorootparentprevI can only speak for myself, but if someone I trust wants to solve some of my problems for me, enabling me to be better at my job, I love that and will push for their recognition and promotion. If I don't trust them to represent me and the team, then obviously that suggestion wouldn't work, but I'm trying to express the difference between someone pointing out a problem as if the problem is just yours or offering to help take responsibility for the problem as part of a team with you. I've worked with people who made it a point of pride to always bring a concrete, workable suggestion whenever they brought me a problem. We didn't always go with their suggestion, but they were fantastic to work with. Thankfully, I've never had to worry about keeping good people on my team down out of fear they'd take my job. reply creer 11 hours agorootparentprev> I don't think a manager will be impressed by a report saying It's funny because it could go exactly the two opposite ways. If you \"report the problem\", you might be - totally as punishment - volunteered into the position to work on it, in addition to your normal workload. If you \"report the problem and volunteer to do something about it\", you might be shot down. Hilarious, right? That's back to the fundamental problem: you need to work on building an understanding of your manager. You have the workload assigned to you, then you have everything you need to do to further your own career. reply pmarreck 2 hours agoprevThis is not the first conversation on HN about management and feedback I've seen where the wide range of opinion and disagreement may reflect only 4 possible things: 1) There is some ideal way to interact that exists, but is not yet known, so we're all essentially still just fumbling in the dark and occasionally encountering light from an as-yet-unknown source 2) There is some ideal way to interact that is more or less understood by some but not all because it is simply not being communicated well (the rate of incoming employees is greater than the rate of knowledge spread- incidentally, this is the same problem I suspect exists with functional languages being perennially less-popular) 3) There is some ideal way to interact that is understood and known but is incompatible with existing and persistent (stable dysfunctional equilibrium) dysfunctionalities in orgs 4) There is in fact no ideal way to interact in a hierarchy because it is largely dependent on the individual personalities of the participants as well as the setup of the org reply cyanydeez 2 hours agoparentMmm. There's also the 4th option is probably better expanded to, individual perception of communication are encoded and decided using fundamentally incompatible protocols because of entirely differing status, background, wealth and social structure. I don't think personality real encapsulates it. I don't believe Elon musks personality has changed, but his fundamental GIGO has. reply ilitirit 11 hours agoprevThis title of my article doesn't make much sense to me. Why would you get fired for giving feedback? Is this just a US thing? I give feedback to my superiors all the time, and expect my subordinates to do the same. In fact, as far as my team goes, you're more likely to get into trouble (not fired) if you rarely give feedback. reply rawgabbit 11 hours agoparentAmerican workplaces are very toxic. Waves of managers ride on the coattails of the latest dude in charge. That they are completely clueless doesn’t prevent them from getting the job. If you point out their failures, you will immediately be labeled as part of the opposition. In other words, this is pure Machiavellian politics. The truth doesn’t matter. If you don’t kiss the donkey’s ass, the best advice IMO is to shut the hell up, collect your paycheck, and go home and kiss your wife. Your family is the only people who matter. The farce will go on for years. Like all Ponzi schemes, it will eventually collapse. But it may take years. reply switch007 11 hours agorootparentThat's an incredible summary, totally matching my experience reply lazystar 11 hours agoparentprevwhen your boss is a one-upper who doesnt understand your teams product, they will do everything possible to sabatoge your efforts and spin metrics to make you look bad. attempting to give feedback to such a person will get you this response: \"you need to earn trust and learn to disagree and commit\". idk if this is a US thing; its mainly a thing where a manager is tasked with supporting a product that they dont understand. managers in these situations attempt to treat their managerial role as if the product itself does not matter - the team has metrics to hit, and to them thats more important than the product. reply ilitirit 11 hours agorootparent> give feedback to such a person will get you this response: \"you need to earn trust and learn to disagree and commit\" Sure, but you won't get fired, right? Even so, this is just about dealing in general with people who have ego (for the sake of brevity) issues. I don't understand why this should be advice for dealing with senior leadership in general. reply lazystar 11 hours agorootparent> Sure, but you won't get fired, right? in my experience, they will start an email paper trail as a precursor to a PIP. reply StefanBatory 9 hours agorootparentprevIt's not only US thing, eastern european too. We're on average rather alright developers but culturally there's no skill of good management - we have been destroyed in this aspect by Soviet occupation and communism. reply loup-vaillant 4 hours agoparentprev> Why would you get fired for giving feedback? Is this just a US thing? Possibly: in many places there they have \"at will\" employment, where they can basically fire you with little to no severance at any time for any reason. There are limits, but compared to most of Europe that's the gist of it. So yeah, you can be fired just because someone doesn't like you. And giving feedback is a good way to not be liked. reply bdangubic 4 hours agorootparentevery employment should be at will!! is there a constitutional or birthright to employment at XYZ company? these discussion always look at one side, like “employer can’t fire employee X without paying severance and other junk” but if I started a company and said “if you leave the company you have to pay severance back to the company for leaving” everyone would be up in arms about it… reply loup-vaillant 2 hours agorootparent> every employment should be at will!! I would agree in an ideal world where salaries are tied to a qualification (a notion a tad more nuanced than just diploma), instead of their job. While there is no (nor should be any) constitutional right to work at any given company, I think people should have an inalienable right to live. Which in practice means food, shelter, and health care at a minimum, regardless of their ability (perhaps even willingness) to work anywhere. The compromise most EU countries have settled on is that once you're employed and past some probation period (in my line of work that can last up to 8 months), then they can't fire you without a damn good reason or a hefty severance (the better the reason the lower the severance, basically). But it cuts both ways: I personally can't leave immediately, I have to tell my employer 3 months in advance. It is in a way a kind of severance. reply bdangubic 2 hours agorootparentI think this arrangement would be fair if you had to pay back to the company the same amount they have to pay you. to get a notice for some period of time makes sense (both ways) but I can’t see a reason why this is all not equal on both sides. reply loup-vaillant 1 hour agorootparent> I can’t see a reason why this is all not equal on both sides. I can. Think of what employment is for a second: shareholders (or company owners) own the capital, and the employee gets to follow orders. Structurally, the company pay workers less than their actual value: shareholders gotta hold, and they squeeze the margin out of the employee. The margin may be thin, but it's never meant to be zero (except for non-profits, but they're the exception). Such a relationship is fundamentally asymmetrical, such an exchange fundamentally unequal. If you want any hope of restoring fairness from this system, termination conditions have to be asymmetrical as well. reply Wurdan 1 hour agorootparentprevAnd I can’t see a reason why it should be equal. Even if you strip the relationship down to its most basic principle, there is asymmetry. One party provides work with the expectation of pay, the other party providess pay with the expectation of work. But the asymmetries don’t end there. Terminating employment is a far greater threat to the employee than the employer. This creates a power imbalance which could easily be exploited by malicious or incompetent employers. That power imbalance is fundamental to this relationship and is reason enough (in the opinion of many countries) to bolster worker rights. reply fhfjfk 1 hour agorootparentprevI live in a US state that has at-will employment. I once had an owner of a small business threaten to sue me for quitting because it would cause financial harm to the business. And that was with giving 4 weeks notice. At-will employment laws protect employees that want to quit, not just employers that want to fire. reply virtualritz 5 hours agoprevSounds culturally biased. From working in northern Europe and especially with people from Scandinavian countries, I'd say that for each of those examples the 'wrong' choice would be the more likely to be exchanged and taken at face value. Whereas when I work with people from the US a lot of fluff is always needed or offense may be taken. Just as the article purports. And there is also body language. Here is one of my favorite exchanges I once witnessed, between two senior leaders, one Spanish, one Finnish, after a few beers at a company party. I leave it to the inclined reader to guess who is from which country. Sergio (gesticulating, grinning): Lauri, why don't you use your hands more when you're talking? Lauri (hands flat on the table, straight face): Because it's not efficient. reply lisper 22 hours agoprevAnother tactic I like to use is a riff on the authors suggestion #3: “Is there a reason you did (or did not do) X?” This works because it’s framed as accepting the decision and being genuinely curious about the rationale. Often the answer is: no, I never really gave it any thought. Other times there turns out to be a good reason that didn’t occur to me and it turns into a learning experience for me. Another tactic that works for me is “Can I offer a suggestion?” The answer is almost always yes but it’s a sign of respect to ask. reply BiteCode_dev 21 hours agoparentDepends on the profile, when somebody talks to me like that I immediately cringe in my head and lose all respect for the person. Probably a matter of culture too. reply thethirdone 20 hours agorootparentThis seems like a very shallow way of thinking. \"Losing all respect for the person\" implies that you think this is NEVER an appropriate way to address someone. Phrasing a disagreement of opinion as a question of reasoning is often the best course of action. In particular if a choice has been made and going back to reverse it has significant costs, it is important to not say anything like \"We should not be doing this\" or \"You made a mistake.\" Unless there is a good of action to reverse course that is simply being rude for no reason. Even in the case where there is a good way to reverse a decision, I would rather ask for the reasoning that led to the decision than strongly state the decision is wrong. If I am working with someone I respect at all, I must entertain the thought that I am wrong and they made the right decision with good reasoning. What would you say to a superior who made a decision that you disagree with, but don't think is worth reversing? My best guess is either nothing or something that more strongly asserts your belief, but I can't think of any better option than phrasing it as a question. reply BiteCode_dev 20 hours agorootparent> What would you say to a superior who made a decision that you disagree with, but don't think is worth reversing? \"I don't understand ... it seems it has the consequence of ... My professional opinion in that case would be... and I would advise to... because of... Is there something I'm not seeing here?\" Benefits: - I'm not faking it. - I already provide a lot of information up front to limit back-and-forth. This avoids assumptions and also works better for when you WFH. - The person knows exactly where I stand and where I want to go. It's not chit-chat, it's not politics, it's purely technical and I want to move on the issue. - If I'm wrong, I can get told right away. If I'm right, it's factual, and we can move on to solving the problem. And if the person's ego/social status is on the line, they can just BS their way out of it, and I'll just add nothing and move on. - The template drives the conversation enough that they only need a short answer to let us decide if it's worth reversing. And we can conclude on the price / consequence of that and move on if needed. I'll c",
    "originSummary": [
      "Wes Kao's Newsletter provides strategies for giving feedback to senior leaders safely, such as the \"even more\" technique and using diplomatic language.",
      "The newsletter emphasizes supporting feedback with data and sharing personal experiences to enhance communication effectiveness.",
      "It also promotes Wes's Executive Communication & Influence course, aimed at improving workplace communication skills."
    ],
    "commentSummary": [],
    "points": 335,
    "commentCount": 287,
    "retryCount": 0,
    "time": 1732389354
  },
  {
    "id": 42224330,
    "title": "Evidence of oldest known alphabetic writing unearthed in ancient Syrian city",
    "originLink": "https://hub.jhu.edu/2024/11/21/ancient-alphabet-discovered-syria/",
    "originBody": "Skip to main content Menu HubOpen Hub About the Hub Announcements For Media Faculty Experts Guide Subscribe to the newsletter Explore by Topic Arts+Culture Athletics Health Politics+Society Science+Technology Student Life University News Voices+Opinion Events At WorkOpen At Work About Hub at Work Gazette Archive Explore by Topic News+Info Benefits+Perks Health+Well-Being Tools+Tech Happenings Johns Hopkins MagazineOpen Johns Hopkins Magazine Current Issue About the Magazine Past Issues Contact Support Johns Hopkins Magazine Subscribe to the Magazine jhu.edu Search Archaeology Evidence of oldest known alphabetic writing unearthed in ancient Syrian city Archaeological findings suggest alphabetic writing may be some 500 years older than other discoveries By Hannah Robbins / Published Nov 21 Media Inquiries Name Hannah Robbins Email hlrobbins@jhu.edu Cell phone 667-232-9047 What appears to be evidence of some of the oldest alphabetic writing in human history is etched onto finger-length, clay cylinders excavated from a tomb in Syria by a team of Johns Hopkins University researchers. The writing, which is dated to around 2400 BCE, precedes other known alphabetic scripts by roughly 500 years, upending what archaeologists know about where alphabets came from, how they are shared across societies, and what that could mean for early urban civilizations, according to the researchers. \"Alphabets revolutionized writing by making it accessible to people beyond royalty and the socially elite. Alphabetic writing changed the way people lived, how they thought, how they communicated,\" said Glenn Schwartz, a professor of archaeology at Johns Hopkins University who discovered the clay cylinders. \"And this new discovery shows that people were experimenting with new communication technologies much earlier and in a different location than we had imagined before now.\" Schwartz will share details of his discovery on Thursday, Nov. 21, at the American Society of Overseas Research's Annual Meeting. A Near Eastern archaeologist, Schwartz studies how early urban areas developed throughout Syria and how smaller cities emerged in the region. With colleagues from the University of Amsterdam, he co-directed a 16-year-long archaeological dig at Tell Umm-el Marra, one of the first medium-size urban centers that popped up in western Syria. At Umm-el Marra, the archaeologists uncovered tombs dating back to the Early Bronze Age. One of the best-preserved tombs contained six skeletons, gold and silver jewelry, cookware, a spearhead, and intact pottery vessels. Next to the pottery, the researchers found four lightly baked clay cylinders with what seems to be alphabetic writing on them. \"The cylinders were perforated, so I'm imagining a string tethering them to another object to act as a label. Maybe they detail the contents of a vessel, or maybe where the vessel came from, or who it belonged to,\" Schwartz said. \"Without a means to translate the writing, we can only speculate.\" Using carbon-14 dating techniques, researchers confirmed the ages of the tombs, the artifacts, and the writing. \"Previously, scholars thought the alphabet was invented in or around Egypt sometime after 1900 BCE,\" Schwartz said. \"But our artifacts are older and from a different area on the map, suggesting the alphabet may have an entirely different origin story than we thought.\" Posted in Science+Technology Tagged archaeology, syria, writing Share on X Share on Facebook Pin it on Pinterest Email More social media options Share on LinkedIn Share on Reddit Share on Tumblr Share on X Share on Facebook Pin it on Pinterest Email More social media options Share on LinkedIn Share on Reddit Share on Tumblr Related Content Archaeology Dead letters Published Jul 13, 2021 Alphabetic writing may have begun 500 years earlier than believed You might also like Trending News Network The Hub At Work Johns Hopkins Magazine Search Explore by Topic Health Science+Technology Arts+Culture Politics+Society University News Student Life Athletics Voices+Opinion Resources About the Hub Get Email Updates Events Submit an Announcement Submit an Event For Media Faculty Experts Guide Privacy Statement Accessibility Contact Us Discover JHU jhu.edu About the University Schools & Divisions Academic Programs Admissions Plan a Visit Employment my.JohnsHopkins.edu © 2024 Johns Hopkins University. All rights reserved. University Communications 3910 Keswick Rd., Suite N2600, Baltimore, MD X Facebook LinkedIn YouTube Instagram",
    "commentLink": "https://news.ycombinator.com/item?id=42224330",
    "commentBody": "Evidence of oldest known alphabetic writing unearthed in ancient Syrian city (jhu.edu)314 points by Someone 20 hours agohidepastfavorite227 comments lisp2240 17 hours agoWooden structures 476,000 BCE Sailing 100,000 BCE Drawing 73,000 BCE Counting 60,000 BCE Medicine 40,000 BCE … Writing 3,200 BCE Alphabet 2,400 BCE I find it hard to believe humans were building houses, painting pictures, making rope, and sailing for tens of thousands of years without inventing writing. I think we just haven’t found any of it that survived. reply reissbaker 15 hours agoparentAgriculture started around 12k years ago. Prior to that, all of humanity lived in hunter-gatherer tribal bands. Why would you need writing, when you could just talk to the person who knew the thing you wanted to learn? Not to mention that prior to the invention of the printing press, writing was very laborious to produce at scale. Even as recently as the 1800s, nearly 90% of the world was illiterate [1]. We live in a hyper-literate society, so it's almost unimaginable, but it's really how the world worked! 1: https://www.weforum.org/stories/2022/09/reading-writing-glob... reply Glyptodon 12 hours agorootparentI think you have to assume that there's kind of an ambiguous continuum between art and writing. Obviously hunter-gatherer bands likely had reasons to communicate with band members, whether by sounds or visual signals. And obviously they made art, and humans being humans, presumably a lot of the art hat some kind of meaning. I think there are uses for using symbols to communicate well before you need ledgers or anything similar. But I don't know exactly where art turns into writing: Even when the world was mostly illiterate, it seems clear than lots of humans had some level of symbol literacy. And in some places that symbol literacy gets so dense you have Chinese or Egyptian hieroglyphs. And maybe in others you maybe have something similar but less preserved. reply phire 6 hours agorootparentThere is reasonably strong evidence that writing actually evolved out of accounting. These early agricultural city-states needed to track the seasonal collection of harvests from the farmers, and continual distribution of food back to everyone. What started as a ad-hoc system of tellies, eventually evolved into a fully-fledged writing system. And once the accountants had a functioning writing system, it would have been obviously useful, and moved into other parts of society. Tax records, laws, contracts, long-distance messages, recording history. Art was probably one of the last places in society actually take advantage of this new writing technology. Hunter-gatherer societies didn't develop writing because they didn't need accountants. reply arcbyte 4 hours agorootparentOr... we've found the most evidence of writing connected to an activity that would have naturally made the most effort to ensure it's preservation. reply mmooss 11 hours agorootparentprev> Even when the world was mostly illiterate, it seems clear than lots of humans had some level of symbol literacy. Interesting - where is that from? reply thejohnconway 10 hours agorootparentPractically all painting or drawing includes some sort of symbolism. Sometimes it’s so obvious that we don’t recognise it as symbolism (picture of cow = cow), but other things aren’t (spiral = ?). The Wikipedia article on Rock Art contains a lot of discussion on the meaning of ancient drawings, for example: https://en.m.wikipedia.org/wiki/Rock_art More recently, medieval painting has a lot of symbolism modern audiences can no longer “read”. reply tsimionescu 7 hours agorootparentprevI think it's a trivial observation. For example, it's clear illiterate people in Europe still knew what a cross meant when on a building, there is no doubt about that. There are many more religious symbols that were also well known. Flags and official seals similarly had well known meanings in their own areas, as did various military symbols. reply mmooss 11 hours agorootparentprev> prior to the invention of the printing press, writing was very laborious to produce at scale. Imagine having to engrave anything you write in clay, stone, wood, etc. One reason runic alphabets are shaped that way is because it's easier to carve in straight lines (iirc). How many comments would there be on a HN page if that was required? reply dghughes 4 hours agorootparentI agree runes like Norse, Anglo-Saxon, Irish were straight lines for the most part since they were easy to make. Irish Ogrham runes were just basic lines literally just lines. Norse Futhark was more complex but still all angles. Ancient Sumerians in modern Iraq area used cuneiform. The cut tip of a reed was used to make marks in in wet clay which was quite a rapid way to write. There are even old practice tablets with scribblings of children in school learning to write. The reason they still exist is fire. A wood building burned at some point and the fire caused the clay tablets to harden like in a kiln preserving them. In modern Inda/Pakistan region Harappan culture also used clay Indus script but it was more elaborate and not as \"wordy\". It seems mainly clay tags to attach to goods to identify them. reply PittleyDunkin 1 hour agorootparentprevCultivation began around 20kya. reply thordenmark 2 hours agorootparentprev\"nearly 90% of the world was illiterate\" I've never believed statistics like this. Humans have a remarkable ability to grasp symbols. reply tsimionescu 2 hours agorootparentTry to learn a script you don't know without any kind of instruction whatsoever. Maybe you'd have some chance with the Latin alphabet, but most writing systems are more complex than it, some far more complex. I would bet no one could learn Chinese writing for example without instruction, even if they knew spoken Mandarin to perfection. reply monero-xmr 12 hours agorootparentprevI don’t believe that agriculture only started then. It’s just the earliest evidence we have. Everything always gets pushed earlier reply tim333 5 hours agorootparentYeah, you can do a lot of agriculture just by planting some plants and comming back later which would have looked basically the same as hunter gathering to archeologists. Similar stuff is done to this day for cannabis https://www.vice.com/en/article/meet-the-gangster-free-weed-... reply AlotOfReading 3 hours agorootparentIt doesn't actually look the same to archaeologists. One of the things we'll do is look for subtle changes in seed morphology as a sign of domestication. There are also methods of seeing what types of plants are growing in a region, which changes when humans begin selectively cultivating certain plants. We can also get a rough estimate of how many people were in an area and in what seasons. reply tastyfreeze 13 hours agorootparentprevEnter the hypothetical ice age civilization that was destroyed 13k years ago in a global cataclysm. reply mmooss 11 hours agoparentprevMany cultures never invent writing. From well-known 1969 research on 186 pre-industrial societies: [0] * 39.2%: No writing * 37.1%: Pictures only * 23.7%: Writing Also of interest (but also a bit dated): \"... the making and reading of two dimensional maps is almost universal among mankind whereas the reading and writing of linear scripts is a special accomplishment associated with a high level of social and technical sophistication.\" [1] > I think we just haven’t found any of it that survived. It's an interesting question, but do I think that? That's the thing about science - we need evidence. Otherwise, what we think turns out to be especially unreliable. [0] George P. Murdock, D.R. White. Standard Cross-Cultural Sample (SCCS). Ethnology (1969) [1] Edmund Leach. Culture and Communication. Cambridge U. Press (1976) reply cogman10 5 hours agorootparentIn fact, there are used languages today that are not written! I have family that just returned from a 2 year religious mission in pohnpei. The native language there is just barely starting to be written. One of the challenges to learning it is because of it's mostly unwritten nature, the language evolves rapidly. That fast evolution is part of what makes turning the language into a written language difficult. reply simmerup 5 hours agorootparentThis reminded me of how cyrillic was invented. The Byzantines created the cyrillic alphabet in the 9th century so that they could write a bible for Slavic countries. Blew my mind that they didn’t have an alphabet before that. reply unscaled 5 hours agorootparentHow is that different from the thousands of different languages that did not have alphabet until recently but then got one created by linguists or missionaries (or often someone who is a little bit of both[1])? Cyril and Methodius (who created the Glagolithic Alphabet, not the Cyrillic alphabet) weren't even the first Chritian missionaries who created a new alphabet for a language that didn't have on in order to spread Christianity. I believe the first one was Armenian (in the early 5th century). [1] https://en.wikipedia.org/wiki/SIL_International reply simmerup 2 hours agorootparentDoes it have to be different? reply ACS_Solver 4 hours agorootparentprevIt similarly blows my mind how far back many languages go with written accounts. My own native language wasn't written down until the 16th century, so its earlier forms are basically unattested. And the 16th writing is just a few sentences in official records and translations of certain Christian prayers. It took until the late 17th century to have a translated Bible, and for the first non-religious texts to appear. Meanwhile some other languages spoken next door had centuries old literature by then. reply cogman10 3 hours agorootparentThat's what's mind-blowing to me about pohnpei. It's an island with an airport and internet. English is the official language but according to my relative the native language is what everyone uses day to day. It has about 40k residents. Literacy is 98%. Yet with all that, the spoken language remains unwritten. That's just wild to me. reply asveikau 3 hours agorootparentAccording to Wikipedia, the two most spoken indigenous languages on Pohnpei are written with the Latin alphabet. https://en.m.wikipedia.org/wiki/Pohnpeian_language https://en.m.wikipedia.org/wiki/Chuukese_language See the \"phonology\" and \"orthography\" sections of the respective articles. It seems like both have a standard orthography. reply cogman10 2 hours agorootparentVery interesting. Perhaps my family member confused the fact that the religion had no training materials for the language with there being no written version of the language. (I'm admittedly ignorant about this, I just had a conversation with them on Saturday) I wonder if the language isn't as commonly written as it is spoken? reply mistercheph 11 hours agorootparentprevnext [3 more] [flagged] mmooss 10 hours agorootparentThere's an old quote among lawyers: If you have the facts on your side, hammer on the facts. If you have the law, hammer on the law. If you have neither, hammer on the table. If I understand you correctly: You have no claim of your own or argument for it, so you are using what you do know, insults. reply mistercheph 2 hours agorootparentThe claims you are making (unsupported by evidence) are the only thing that's insulting, And with fitting aphorisms exchanged, we can part ways Mr. 40%-of-human-societies-don't-write-according-to-an-unreproduced-survey-performed-in-1969-that-is-not-a-survey-of-human-societies-but-our-own-knowledge-of-human-societies-and-is-confused-about-cultural-boundaries-and-how-to-count-one-society-or-many. reply lkrubner 13 hours agoparentprevI agree that there must have been earlier writing, likely written on wood. Early systems could have evolved from markings on trees, like we still use on the Appalachian Trail, and other trails. Warnings for bears or tigers, symbols for different tribes on different paths. If you've hiked much then you're aware that even experienced woodsmen can get lost as the season changes and a valley changes, or after a hard storm washes away evidence of a trail. Children, in particular, would have been at risk, but would have almost certainly needed to do work over distances, in particular fetching water, which is something that even today children as young as 5 are asked to do. Notches on trees would have been a likely starting point for a system of symbols to communicate. When I was much younger I used to work as a hike leader for a summer camp in Virginia. We would take a small group of teenagers out for 7 day hikes, during which we could cover something between 70 to 90 miles (112 to 145 kilometers). At one time I knew that stretch of trail so well I thought I could walk it blindfolded. And yet, I only knew it in the summer. One year I went in the fall and I was astonished how different it was. I was helped by the markings on the trees. (This was before cell phones and GPS.) reply dachris 12 hours agorootparentExactly - there's probably a fluent transition between symbols and painting and writing and then alphabetic writing. Territorial animals that we are, I'd add \"here starts the territory of the Saber-Toothed Tiger Clan\" signs to path markings as likely candidates for earliest symbolic communication. Nice to see that the earliest examples of writing are still somewhat recognizable (as opposed to modern alphabets) - see https://en.wikipedia.org/wiki/History_of_writing - a hand, a foot, a goat or sheep. Fun thing is, with modern technology we have regressed (advanced?) to a massive use of pictograms - a modern smartphone wielding human, in addition to the alphabet, knows at least a few hundreds or even thousands of pictograms ¯\\_(ツ)_/¯ reply truculent 6 hours agorootparent> there's probably a fluent transition between symbols and painting and writing and then alphabetic writing I'm with you until we get to alphabetic writing, which has (to our knowledge) only been invented once. To get from other writing systems to an alphabet requires a few conceptual leaps which are much more challenging and, I would suggest, not fluent. If it were a smooth path, we ought to have seen alphabetic scripts arise independently multiple times (as we have other forms of writing). reply mcswell 1 hour agorootparentNot sure, but I think Hangul counts as a second invention of alphabetic writing. If you count syllabic writing systems (which are not technically alphabetic, but are more so than Chinese, or Mayan or Egyptian hieroglyphics), there are more: Japanese hiragana and katakana, Cherokee syllabics, Pahawh Hmong, Vai (West Africa), and Linear B (and presumably Linear A). There's also Thaana, the script used for Maldivian, which uses some Arabic script symbols, as well as Indic digits. So while it's semi-alphabetic (partly abugida), and it's derived from existing writing systems, it uses the borrowed symbols in unique ways. There are other syllabic writing systems as well, like Inuktitut and Cree, but those were created by missionaries familiar with other writing systems. reply Tainnor 2 hours agorootparentprevAlphabets may only have been invented once, but writing systems that have a (roughly, it's never perfect) 1:1 correspondence with the sounds of the language have been invented several times independently, e.g. in syllabaries (Japanese Kana are derived from Kanji) and abugidas. I would suggest that that conceptual leap is a much bigger one than the one of treating consonants and vowels as independent. reply DonHopkins 12 hours agorootparentprevI'm so old that we didn't even have Emojis, not even letters yet, and we had to communicate with punctuation alone! ;) reply choeger 9 hours agorootparentYou had punctuation? We had to to with empty spaces and silence! I once read an entire poem just using silence! reply AlotOfReading 16 hours agoparentprevThis is more an artifact of how we typically define writing than anything meaningful about the act of communication itself. Graphical symbolic communication is tens of thousands of years older than what the article discusses. Writing as typically defined is a complete system for encoding verbal language using specific, formalized symbols. That's much more sophisticated and largely unnecessary for \"most\" human activities prior to the invention of large, hierarchical societies. reply mmooss 11 hours agorootparent> Graphical symbolic communication is tens of thousands of years older than what the article discusses. This article says that the earliest proto-writing is 10,000 years old - 3-d clay counters used for accounting. What was earlier? https://sites.utexas.edu/dsb/tokens/the-evolution-of-writing... reply AlotOfReading 10 hours agorootparentProto-writing is still quite far along on the spectrum I'm talking about of contextually defined symbols. Lascaux and chauvet have plenty of examples generally agreed to be partially symbolic, just off the top of my head. reply consf 3 hours agorootparentprevAnd that distinction is crucial reply AlotOfReading 1 hour agorootparentCan't say I agree, and I suspect you probably don't agree with the implications of that definition either. As a hypothetical example, do you think any of the following aren't writing: * a script which can represent taxes, histories, and religious texts but not the full range of verbal expression * programming languages * emojis The first of these is an actual scholarly debate about whether Aztec script can be considered \"full\" writing or merely proto-writing. reply canjobear 1 hour agoparentprevConsider the many cultures that Europeans discovered in the Americas. Of them, only one had a real writing system (the Maya). The Aztecs wrote down history in a sort of comic book form, and the Inca did accounting with qhipu, but only the Maya had a conventional system of written forms that correspond systematically with verbal language. You can communicate and remember a lot orally. The Polynesian navigators encoded information about how to navigate from island to island in oral poems passed down generation to generation. A lot of these traditions seem to vanish once a culture gets writing, leaving it unclear how they used to pass on so much information before. reply sapphicsnail 15 hours agoparentprevHumans are able to pass on an incredible amount of knowledge without the use of writing. There are oral, epic traditions 100s of years old that we only know about because they were eventually written down. People were able to do things like recite the Iliad from memory. I don't know about other ancient languages but the oldest Greek texts of significant length are all metrical poetry. We know and have scientific works that were written in meter. There are probably all sorts of things that were passed don't orally that we can't even imagine. reply philipswood 12 hours agorootparentA book that gives a nice view of these some of these memory technologies is The Memory Code by Lynne Kelly I can't get myself to link to the marketing blurb inspired summaries, but I love the book. This wikipedia heading gives a less breathless overview: https://en.wikipedia.org/wiki/Lynne_Kelly_(science_writer)#R... reply stevenwoo 11 hours agorootparentprevI think this was on here in prior story but Australian Aboriginal stories about changes in ocean level were shown to reflect conditions about 10000 years ago. https://www.scientificamerican.com/article/ancient-sea-rise-... reply PittleyDunkin 1 hour agoparentprev> I find it hard to believe humans were building houses, painting pictures, making rope, and sailing for tens of thousands of years without inventing writing. Why? reply danielheath 16 hours agoparentprevWe find lots of non-alphabetic writing from earlier periods that does survive, though. Surely if they had alphabetic writing, we'd find that when we find writing? reply StanislavPetrov 13 hours agorootparentVirtually all of the writing we find from earlier periods has been carved in stone. Without finding the rare monument or well-preserved grave stone, a traveler that arrived here 10,000 years in the future would find just as little evidence that we knew how to write. reply bjt 12 hours agorootparentI've heard this argument before, and generally don't buy it. It really comes down to how hard they're looking. We have found many dinosaur bones that are hundreds of millions of years old. We have an Australopithecus skeleton (Lucy) from 3.2 million years ago. We have many examples of writing that would be similarly durable. Even if most things wither or decay or erode or get scavenged or build over, so 99% of it is gone in 10,000 years, there's still plenty that'd get buried and preserved. You give the example of monuments. They're not all that rare though. Every town has a few, usually right at the center, right where excavation would be most likely. I'm thinking of the world war memorials that every little English town seems to have, with the names of all their fallen soldiers. They're not ALL just going to turn to dust, right? There are temples in Egypt where you can still see not just what they carved in the stone thousands of years ago, but even the paint that they put on it. So if we're all gone in 10,000 years and that traveller just buzzes by and doesn't scratch the surface or even look very hard, sure. But if they're excavating at the level that humans are today, it will be hard to miss that we had writing. reply gregschlom 16 hours agoparentprevCounter example: until relatively recently you had large segments of the population who didn't know how to read and write, but were very skilled at whatever their trade was. reply bentley 15 hours agoparentprevEven within the last millennium powerful and accomplished civilizations like the Inca survived and excelled without writing. I think a better lesson to take from this is that though humans are inherently communicative and inventive, these characteristics don’t depend upon written communication, and that writing is not an obvious invention even if we can see elements of it in similar inventions like quipu. reply philipswood 12 hours agorootparentThe Inca had Quipu. reply mcswell 58 minutes agorootparentThe Quipu were definitely not an alphabetic system, and probably not a system for transcribing words. reply bentley 9 hours agorootparentprevYes, I mentioned that. reply mmooss 11 hours agorootparentprevQuipo are amazing, but mostly accounting records? reply lou1306 4 hours agoparentprevClearly, almost every time we find an ancient artifact, it is fair to assume that the technology it displays was common and established by the time the artifact was created. However, (and adding to the other replies here which also have a point) in Plato's Phaidros Socrates places the invention of writing in Egypt [1], not in some mind-blowingly past aeon, and the undertone of the tale is that civilization can (and reach) pretty interesting levels of sophistication before writing becomes a necessity. [1] https://www.historyofinformation.com/detail.php?id=3439 reply heresie-dabord 4 hours agoparentprevLanguage is a powerful human talent. It's reasonable to assume that there have been many variants of writing systems throughout human evolution. However, such systems would need to be widely adopted and durably preserved to survive millennia and eventually be rediscovered. Which is how we happen to know the precious little that we do know about past writing systems. reply consf 3 hours agorootparentEven widely adopted systems face challenges reply Hilift 9 hours agoparentprevGreek society switched alphabets between 750 and 950 BC, and adopted a number system. There were writing collapses. There is still a lot of history to uncover from the end of the Bronze Age. https://en.wikipedia.org/wiki/Late_Bronze_Age_collapse reply riffraff 11 hours agoparentprevWhy not? People lived ok without being able to read and write until a couple generations ago. Passing knowledge orally and by example is easy. reply mcswell 58 minutes agorootparentPeople still survive that way. reply tivert 14 hours agoparentprev> I find it hard to believe humans were building houses, painting pictures, making rope, and sailing for tens of thousands of years without inventing writing. I think we just haven’t found any of it that survived. What's so hard to believe? Everything you can write you can say, and you can show quite a lot that's difficult to describe in writing. reply DonHopkins 10 hours agorootparent>Everything you can write you can say That's easy to say if you've never written C++ or Perl. One of the unique golden rules of FORTH is that every word definition must have a well defined pronunciation in the documentation, so you can discuss FORTH code over the telephone without confusion. That's because FORTH words have no syntax except space as a delimiter, so can mix arbitrary punctuation with letters in any way, so you have many weird words like @ (fetch) ! (store) +! (plus store) ' (tick) ['] (bracket tick) >R (to r) R> (r from) etc. So you could define an emoticon in FORTH like: : ;-) WINK NOSE SMILE ; // Pronounced \"winkie\". reply ehecatl42 7 hours agorootparentWriting Perl is easy; reading it a few weeks later is the hard part. CPP I don't know much about… I was a sysadmin, not a programmerI find it hard to believe humans were building houses, painting pictures, making rope, and sailing for tens of thousands of years without inventing writing. Egyptian Pyramids - 3,800 BCE They were writing just not with an alphabet reply otherme123 11 hours agorootparentExactly. It seems that alphabet development is closely related to the regions more focused on international trading (the region we know as Phoenicia) rather than war and conquest of the neighbours. Maybe a system that represent sounds was useful to write words from sounds in multiple languages that were never heard before, unlike pictograms, hieroglyphs or cuneiform, that had to be adapted to each language. reply tim333 5 hours agoparentprevIt makes you think how rapidly things are changing with the petabytes we are leaving these days. reply nunez 13 hours agoparentprevIt's easy to believe when you learn that there are still parts of the world that struggle with literacy. reply tastyfreeze 13 hours agoparentprevWritten on what? There are very few materials that will last 10s of millennia. Aztec, Greeks, Romans, Egyptians and their contemporaries all used some type of paper. Sumerians seem to be alone in their use of clay for writing. reply AlotOfReading 13 hours agorootparentPaper was only one written medium. All of the cultures you've listed constructed stone stelae with writing, like the Rosetta stone. South Asian cultures used palm leaves instead of paper. Maya used fig bark. Europeans and Nahuatl often used animal hides instead of paper. There's a long list. reply tastyfreeze 13 hours agorootparentOk. Maybe I should have been more generic. Organic thin sheet material... velum, parchment, papyrus. The bulk of writing is done on material that is gone in a few thousand years at most. reply AlotOfReading 13 hours agorootparentWhich still leaves stelae as already mentioned. There's also petroglyphs, ceramics, and paints. The point I'm trying to convey is that writing has never been limited solely to paper or even organic materials. reply globular-toast 10 hours agoparentprevI take it you've never interacted with people who build houses, make rope or administer medicine then? They don't read, even today. They learn their trade by watching others. We are quite exceptional in that reading is usually the most efficient way to learn stuff, but it's not like that in other areas. If you needed to change a spark plug or plumb in a washing machine would you be reaching for the books or YouTube? reply raincole 15 hours agoparentprevHow do we know humans did \"counting\" when there weren't no written text? Just a few marks on the stone? Does it not count as writing? reply gus_massa 7 hours agorootparentQuipu https://en.m.wikipedia.org/wiki/Quipu I remember an article about credit in stores in tiny towns in Spain. It was just a rod of wood with some simbol as a signature of the store. Each time you buy something ¿big? they add a mark, and when you get all the ¿10? marks you have to pay with real money. IIRC, the oldest number recorded was some kind of lunar calendar in a bone, wit marks like IIIIIII IIIIIII IIIIIIII IIIIIII IIIIIII IIIIIII IIIIIII IIIIIII Coincidence? (I don't remember the details, but the article was convincing.) reply griffzhowl 5 hours agorootparentYou're probably referring to the Ishango bone https://en.wikipedia.org/wiki/Ishango_bone reply mmooss 11 hours agorootparentprevThere is a matter of definition. IIRC, if you lookup some cave paintings from ~30,000 years ago, there is/was a debate whether marks near animals were intended to represent quantities. reply watwut 6 hours agoparentprevWhy would it be so hard to believe that people \"would build houses, painting pictures, making rope\" without writing? Illiteracy was high 2-3 hundred years ago, in Russia even longer. And all those illiterate villages and areas would build houses, draw, craft ropes and clothing. You need writing for organizing large groups of people and such. You dont need it for survival necessities. reply consf 3 hours agoparentprevThe timeline of human innovation isn't linear; it’s likely there were many steps we just haven’t uncovered reply v8xi 13 hours agoparentprevWas going to say about the same - this is ~2500 years after construction of the pyramids. How do you coordinate something that massive without any form of writing? reply dragonwriter 13 hours agorootparent> Was going to say about the same - this is ~2500 years after construction of the pyramids. The first Egyptian pyramid known was built ~2780 BCE, the alphabetic writing in this article was from ~2500 BCE. That’s a gap of ~250 years, not ~2,500. > How do you coordinate something that massive without any form of writing? The Egyptians at the time of the Pyramids had writing, but it was logographic (symbols directly represent a word/concept), not alphabetic (a small inventory of symbols are combined in different ways to represent words/concepts.) An alphabetic – and also phonetic – script is a big advance not because of what you communicate with it, but because if you know a fairly small set of symbols and their phonetic interpretation, you can encode a spoken language in it in a reasonably intelligible way to anyone who knows the same script (and you can even encode different spoken languages in the same script intelligibly, if they have a similar-enough phonetic inventory.) reply timschmidt 12 hours agorootparentI'm no expert, but my understanding is that Coptic made use of hieroglyphs as an alphabet, and co-existed with their use for Egyptian: https://en.wikipedia.org/wiki/Coptic_language reply jaco6 13 hours agorootparentprevThe article is about alphabets. There was writing prior to alphabets, but it was done in hieroglyphics, cuneiform, and characters. Alphabets are easier to learn and therefore more widely used. reply asdff 11 hours agoparentprevLiteracy is a modern phenomenon. reply momoschili 12 hours agoparentprevthe distinction between writing and drawing seems to be a bit gray to be honest reply dyauspitr 15 hours agoparentprevWhy? The alphabet seems like a huge abstraction I don’t think I could come up with on my own. I could see myself coming up with structures, drawing, counting etc. on my own given enough free time. reply mmooss 11 hours agorootparent> The alphabet seems like a huge abstraction I don’t think I could come up with on my own. Given how many humans did come up with it, over all those millennia, I think we all can safely say that! reply philipswood 11 hours agorootparentprevA is for apple, B is for bear, ... And then you use the picture of an apple, bear, etc. It's one of those simple solutions that anyone could have, but not often do. reply WalterBright 15 hours agoparentprevIt's clumsy and inconvenient to have writing without paper and pen. There wasn't a whole lot of writing before the printing press. I've sometimes idly wondered if I was transported back in time to the stone age, could I help the tribe by teaching them to read and write? Sadly, nope. If I was transported to Roman times, I'd try to invent paper and a printing press. I bet it would catch on fast. reply gostsamo 11 hours agorootparentThey had paper though not as durable as the modern one. Papyrus had the same function, but it decays over few decades and things written on it should be rewritten. If you have a few centuries of war and low literacy like in the western parts of the Roman empire, there is noone to renew the pagan texts and they get lost. The eastern empire bothered only with the texts compatible with christianity while the arabs kept those compatible with islam. The printing press might've been useful though. reply mmooss 11 hours agorootparentprev> I'd try to invent ... a printing press I sometimes wonder if the development of the printing press relied on technology that hadn't been available previously - like many/most innovations. But what? Paper? There were ink-retaining sheets long before the printing press. A durable mechanism for the roller? They made wagon axles, I assume, that supported much more weight. Durable letters? Even sans metal, I'd guess that carving wood letters would still be worth the effort. reply WalterBright 1 hour agorootparentGutenberg's press was a modified wine press that was based on a screw. The Romans had screw wine presses. The precursors were available to the Romans. He used lead letters. Lead was readily available in Roman times - after all, the water pipes were made of lead (and poisoned the people who used them). The lead letters would quickly wear out, but it was easy to melt and recast them as needed. I've seen a demonstration of it. I think the Chinese did wood block printing, but it didn't get very far. reply DonHopkins 9 hours agorootparentprevIt would be dangerous to transport you back to Roman times, because you might teach them to write C++ and compile it into cellular automata, and then program Empire with a 30 million soldier human computer, like the \"human abacus\" scene in \"Three Body Problem\"! https://www.youtube.com/watch?v=DFgRNY6fpOc reply WalterBright 6 minutes agorootparentOf course you're right! After much thinking about it, providing a printing press would be the most effective invention to bootstrap a modern society. And, well, that's exactly what happened after Gutenberg invented it. The greatest inventions in history are: 1. writing 2. phonetic alphabet 3. paper 4. printing 5. networks And the pattern is obvious! reply nurettin 10 hours agoparentprevI find it totally believable. There weren't that many humans living in comfort to create institutions and innovate. reply webdoodle 15 hours agoparentprevBook burning has been a major issue many times by people trying to control history. The library of Alexandria, one of the oldest known book burnings, may have had some of the evidence your expecting. Then there are the cretins like folks trying to unroll the Dead Sea Scrolls. The modern day equivalent are the internet censors deleting our comments and posts on social media. reply joshdavham 17 hours agoprevAlphabetic writing really is incredible. Despite the fact that I personally prefer syllabaries. I can't discount the fact that alphabets have done an incredible job of being adopted by other languages that didn't previously have any sort of writing system. Alphabets are really flexible like that. The latin alphabet alone is used in all sorts of languages from English to Tukish, Indonesian and Swahili. Having this many diverse languages follow a single writing system is only really possible with alphabets. You couldn't do this with Chinese characters or Korean hangul, for example. reply twelvechairs 15 hours agoparentHangul is a 'syllabic alphabet'- it is a combination of alphabetic and syllabic and as such probably the clearest/simplest writing system invented. reply dhosek 15 hours agorootparentAlthough it has some weirdnesses of its own, such as having jamo that change their sound based on context (e.g., ᄋ is silent if it’s an initial consonant but has the sound ng at the end of a syllable). Nearly every consonant has a different sound between initial and final position, although many of these are inaudible to English ears. On the other hand, having been a consciously designed writing system, it does have a rationality that most traditional writing systems lack, such as the fact that all vowels are based on either ㅡ or ㅣ with additional strokes added as appropriate to modify the base vowel (the fact that a double stroke, e.g., ㅑ or ㅛ represents the single stroke vowel with a y- sound prefixed seems just brilliant to me). reply unscaled 10 hours agorootparentConsonants changing their sound based on position is not such an abnormality — that's just basic phonology. This phenomenon (allophony [1]) is found in virtually every language, but it remains a bit obscure to laymen, since it is mostly undetectable to the language's own speaker. For instance, the phoneme /t/ is always rendered by the English letter /t/, but that phoneme can be rendered in so many different ways. In an initial position it would be rendered as an aspirated voiceless alveolar plosive [tʰ], equivalent to the Korean Jamo ㅌ in initial or intervocalic positions. An English /t/ in other positions is generally not aspirated, but besides that the rendition is highly dependent on the speaker's accent. MRP (\"BBC English\") speakers render a \"final\" /t/ (i.e. after a vowel or consonant, but not before another vowel) as as [ʔt] ([t] sound preceded by a glottal stopped) or even just as a pure glottal stop [ʔ]. In intervocalic position RP speakers would keep /t/ as a simple [t] sound, but most Americans would change this sound into a voiced alveolar flap [ɾ]. Cockney speakers famously change an intervocalic /t/ into a glottal stop (so you'd get something that sounds like \"woh-ah\" for \"water\") and I didn't even get into how /t/ behaves when it follows other consonants such as the elided /t/ in \"listen\" or the way some American speakers pronounce \"winter\". In all honesty, this is probably just as messy as what happens in Korean, it's just that the Korean allophones are more foreign to us. Besides ᄋ, all the variations are regular allophones. As far as I understand ᄋ was indeed just reused for two different purposes (there is no /ŋ/ phoneme that transforms to an empty sound in initial position). I'd say that one thing that still makes Hangul hard, is that a lot of consonant clusters sounds sound the same when they come in final position. It makes pronunciation regular, but it's a bit hard to know how to transcribe many words. The vowels ㅐ and ㅔ are also pronounced the same in most (perhaps all?) modern Korean dialects, but that's a small irregularity compared to the redundancies of many other alphabetic writing systems. In short, Hangul is much more regular than most alphabets. I wouldn't say it is the most regular though — it's hard to beat new writing systems designed by professional linguists for small language that didn't have an alphabet before. Hangul is still an relatively older system that had to go through writing reforms, but still retrains some spelling complexities. And if you compare Korean to Polynesian languages like Hawaiian, with their extremely simple phonology and phonotactics (they have very few vowels and consonants and generally don't allow consonant clusters and final consonants at all) - then the writing system of these languages is much simpler — and almost all of them use the Latin alphabet with a highly regular orthography. I think there is a more impressive trait of Hangul, that is highly underappreciated. It's an alphabetic writing system that blends very well with traditional Chinese characters. Chinese characters are all monosyllabic (i.e. they represent a single syllable) and while that property is not maintained in Japanese (due to its vastly different phonology), it has been maintained in Korean and Vietnamese. Hangul lets you write each syllable with a single graphic block (even if that block contains multiple \"Jamo\" letters). All other alphabet systems that have been developed in languages that used Chinese characters (Such as Pinyin, Zhuyin or the Vietnamese alphabet) do not share this property. This means that when you try to add some alphabet letters into a document written Chinese characters, the result is extremely unpleasant typographically. It is not only harder to typeset nicely, but it's also quite painful to read. Although Modern Korean doesn't blend Hangul and Hanja (Chinese characters) very often, I think this property made Hangul quite a lot more palatable as a replacement for Chinese characters in Korea compared to Pinyin or Zhuyin. Koreans didn't have to throw your entire typographic and calligraphic tradition in order to adopt Hangul: A block is fixed-size (not proportional), the writing is easier to read both vertically and horizontally and you can keep writing it with brush strokes using traditional Chinese calligraphic methods and practices. It can even be mixed nicely with Chinese characters like Japanese Kana (and it would be more compact than Japanese Kana). Eventually Korean language reformers have chosen to mostly drop Hanja altogether, but when you still do need to mix Hanja in a Korean text, you can do it seamlessly. reply teleforce 16 hours agoparentprevAlphabet writing is probably the most important invention perhaps even more so than the invention of wheel. It's truly the original \"bicycle of the mind\". Syllable based writing are not intuitive for human, Korean found it the hard way by relatively recently by inventing Hangul alphabets despite had been using the Chinese characters for several thousands of years previously with majority of the people remained illiterate. reply aragonite 1 hour agorootparentThe low literacy rates in pre-Hangul Korea had less to do with phonological vs. logographic writing systems and more to do with the fact that in Korea at the time Chinese played the role Latin played in medieval Europe: it was the language of scholars and officials, but most ordinary people couldn't read it because, well, they didn't speak Latin. The same thing happened with Hanja in Korea. When you're trying to get people literate in a writing system designed for a language they don't use in daily life, you're fighting an uphill battle from the start. What is true that unlike the Latin alphabet, which European languages could adopt/adapt for their own use (or think the way Cyrillic was adapted for Mongolian), Chinese characters, being logographic, couldn't simply be repurposed to represent sounds of the Korean tongue — that's why Hangul had to be invented from scratch. That's one important difference between phonological and logographic writing systems, but it has little do with the question which system is better at spreading literacy. reply talideon 6 hours agorootparentprevWhen some form of phonetic writing is developed, it's almost invariably syllabic. If anything, the very intuitiveness of syllabaries is why all alphabets, abjads, and abugida originate from a single source while there are many syllabaries that have developed independently. Further, Hangul is not \"syllabic\". It's an alphabet. It happens to organise its letters into syllable blocks, but that's it. reply teleforce 5 hours agorootparentThat's what I'm saying, after several thousands years of using Chinese characters Korean found that it's not intuitive for literacy hence they invented their very own alphabet, and voila the literacy increased considerably. Actually as a foreigner, you can learn to read Hangul in one single day, and then you can read the Korean for names, sign boards, etc but to understand them is another story. However, if your mother tongue is Korean, you can understand them intuitively. That's the reason I considered alphabet is more important than invention of the wheels and it's truly the original \"bicycle of the mind\". reply cenamus 7 hours agorootparentprevNot intuitive? Why would that be? From https://en.m.wikipedia.org/wiki/Cherokee_syllabary \"Around 1809, impressed by the \"talking leaves\" of European written languages, Sequoyah began work to create a writing system for the Cherokee language. After attempting to create a character for each word, Sequoyah realized this would be too difficult and eventually created characters to represent syllables. He worked on the syllabary for twelve years before completion and dropped or modified most of the characters he originally created.\" \"After the syllabary was completed in the early 1820s, it achieved almost instantaneous popularity and spread rapidly throughout Cherokee society. By 1825, the majority of Cherokees could read and write in their newly developed orthography.\" They literally achieved higher literacy than the european settlers reply koolala 14 hours agorootparentprevLogographic seems fine for the mind? Thinking in speech is the default and most people talk before they read. reply mcswell 48 minutes agorootparentSpeech is far more like alphabetic writing than it is like logographic writing. Spoken words are not single units, rather they're made up of phonemes. reply teleforce 14 hours agorootparentprevI am talking about literacy. For reading Chinese newspaper headlines you probably need around 50,000 basic character recognition. reply throwthrowee 11 hours agorootparentMy understanding is that the average Chinese dictionary has 20,000 characters. The full set is somewhere around 50,000. The average educated adult knows about 8000. The number of characters to read a Chinese newspaper is about 2500 to 3500. This is based on multiple sources online. Here is one example source (BBC): https://www.bbc.co.uk/languages/chinese/real_chinese/mini_gu... reply teleforce 5 hours agorootparentRegardless the number of characters required for understanding the headlines, I think my points are still valid. After several thousands years of using Chinese characters Korean found that it's not intuitive for literacy hence they invented their very own alphabet namely Hangul, and voila the literacy increased considerably. Fun facts, as a foreigner, you can learn to read Hangul in one single day, and then you can read the Korean written words for names, sign boards, etc but to understand them you need to learn the Korean language. However, if your mother tongue is Korean, you can understand them intuitively. That's the reason I considered alphabet is more important than invention of the wheels and it's truly the original \"bicycle of the mind\". reply rrr_oh_man 11 hours agorootparentprevYou’re off by a factor of 20+. reply sneak 17 hours agoparentprevHangeul is an 24 character alphabet, with 14 consonants and 10 vowels. Each little square is a syllable made up of consonants and vowel combinations. reply WalterBright 15 hours agoparentprevSadly, we are unwinding thousands of years of progress by reverting to picture writing. reply openrisk 9 hours agorootparentThat seems only partly true. We did already have punctuation marks (like !?) that are a form of picture writing to modulate the underlying alphabetic meaning. The smiley was invented because a pure alphabetic script does not do a good job expressing emotions, especially in short isolated sentences. Emojis are overused in some current contexts (smartphone/messaging addiction) but some sort of standardization along with \"emoji\" literacy is, in principle, an evolution of the alphabet towards more sophistication and nuance. reply WalterBright 1 hour agorootparentEmojis are not quite the same thing as picture writing (icons). I used emojis for a while, then got kinda sick of them. > a pure alphabetic script does not do a good job expressing emotions Instead of a smiley emoji, I'll write \"haha\". Instead of a barf emoji, I write \"barf\". English has a million words in it. I'm sure you can find a variety of words that express emotions just fine. ?! being a form of picture writing? I don't see it. reply mcswell 47 minutes agorootparentprevI blame Microsoft for that--in particular, the Ribbon (and before that, toolbars). reply WalterBright 15 hours agorootparentprevCase in point: Susan Kare's trash can icon is slowly being replaced by [delete] as people discover that words for actions are better than pictures. reply astrobe_ 8 hours agorootparentNot convincing to me. The world of UI design is too agitated with copycat and fads to be a solid reference. reply riffraff 11 hours agorootparentprevMany years ago I had a designer friend do some interface for me and I pointed out we should be using a couple icons for actions like \"post\", \"delete\", etc. He replied something like \"I don't believe in the thaumaturgical power of icons\" and that has stayed with me forever since. Words may he worth 1/1000th of a picture but at least you understand them. reply fragmede 8 hours agorootparentyou hover your mouse over the icon and a tooltip appears with words. Also the menu item shows the icon next to the word. reply WalterBright 1 hour agorootparent> the menu item shows the icon next to the word Proof that icons don't work. reply rrr_oh_man 5 hours agorootparentprevNeeding to hover over an icon is already a failure in UI design reply TacticalCoder 15 hours agorootparentprev:( reply jmyeet 16 hours agoparentprevCurious: why do you prefer syllabaries? I think about Chinese writing systems, which additionally don't have clear word boundaries. Now you can argue that this is an independent issue (which is true) but why does this complication seemingly show up in such writing systems? Anyway, alphabets have been profoundly successful. You bring up Turkish. It's a good example. I'm sure most here know that prior to 1929 or so Turkish used the Arabic writing system. This is also an alphabet but a more complicated one (eg vowels aren't typically written) and didn't necessarily fit the Turkish language. So they designed a Latin writing system that is entirely phonetic it was was profoundly successful at increasing literacy rates. A completely illiterate person could be taught to read and write Turksih in a matter of months. I compare this to Taiwan that has high school competitions to see who can find a word the fastest in a dictionary because knowledge is required of the roots and symbols. There are thousands of characters to learn in Chinese languages. As a foreigner, this will often take a decade or more. I've seen accounts of people who have spent a decade learning Chinese that still struggle to read books intended for 12 year olds. Literacy is so transformative to one's life that I'm so on board with anything that makes that easier. reply talideon 5 hours agorootparentThe Arabic writing system is an abjad, not an alphabet. The two kinds of system are closely related (the Phoenician script was the origin of both the Greek alphabet and the various Semitic abjads and was itself an abjad) but are not the same thing. Abjads are well-suited to Semitic languages where the vowels are less important for morphological reasons, but in Indo-European languages (like Greek) and Turkic languages (like Turkish) vowels are important in writing for comprehension. It's no surprise that switching to an alphabet aided literacy in Turkey. Abjads are no more or less complicated than alphabets though. They're just a bad fit for Turkish. reply consf 3 hours agoparentprevThey're simple enough to learn and reproduce, yet powerful enough to capture the nuances of different languages reply dyauspitr 15 hours agoparentprevHangul is a very new alphabet. The Koreans didn’t have their own script until something like a century ago. Swahili has its own alphabet too. reply dhosek 15 hours agorootparentA bit less recent than that. More like the 15th century for Hangul. Swahili uses either modified Latin or modified Arabic for writing. Are you perhaps thinking of one of the invented scripts for indigenous American languages, e.g., Cree syllabics or Inuktitut? reply dyauspitr 14 hours agorootparentI was thinking of the Ge’ez script but that’s for Amharic not Swahili. reply drcode 20 hours agoprevTo clarify, this is specific to \"alphabetic\" writing, cuneiform/hieroglyphs are older. reply Archelaos 19 hours agoparentIt should also be noted that a difference is often made between alphabets in the strict sense, where consonants and also vowels are represented by distinct symbols, and alphabets in the wider sense, where this is not the case (vowels are not represented at all or occasionally by certain consonant symbols typically when clarification is necessary). A writing system where symbols denote larger units of speech is not called an alphabet, but a syllabary. If it does not represent phonetic, but semantic units, it is called a logographic script. There are of course all kinds of mixed forms (\"I ♥ NY\"). reply ejplatzer 19 hours agorootparentTechnically, a syllabary only refers to writing systems where the symbol represents the specific consonant and vowel pair, such as Japanese's Hiragana. For example, in a syllabary, the syllables \"ka\" and \"ki\" are two different symbols. If the vowels are optional or not present, e.g. there's one \"k\" symbol regardless of the vowel, it's an Abjad. The archetypal Abjad is the Hebrew writing system. If the vowels are written by adding them to the consonant symbol (similar to diacritics), it's called an Abugida. One example of this is the Ge'ez script in Ethiopia. reply Archelaos 18 hours agorootparentI did not want to make it too technical, so \"Abjad\" falls under \"alphabets in the wider sense\" and \"Abugida\" under \"mixed forms\". My comment was based on the assumption that the article in question does not necessarily refer to an alphabet in the strict sense. To make this clear, I did not think it was necessary to go into too much detail. reply thaumasiotes 18 hours agorootparentprevThere are many specialized terms for different types of writing system, but those distinctions are generally of very little interest unless you're compiling a table of different writing systems. Generally you look at what concepts are embodied in the script, and at the form of the glyphs. So: You might have a script that assigns glyphs to phonemes. (\"Language is made of sounds.\") You might have a script that assigns glyphs to consonants and doesn't bother to represent vowels. (\"Language is made of sounds, and some of them are more important than others.\") You might have a script that assigns glyphs to syllables. (\"Language is made of things you can say.\") You might have a script in which the glyphs assigned to syllables are composed of recognizable and conceptually distinct parts, but those parts have no independent representation. (Compare the glyphs ሀ ለ ሐ with the related glyphs ሄ ሌ ሔ.) (\"Language is made of things you can say, but there are patterns.\") You might have a script that assigns glyphs to words, though in almost all cases you don't. The label \"logographic script\", applied to a script the labeler doesn't know well, is infinitely more popular than the concept \"logographic script\". I don't think any script has ever existed meeting the criterion of \"it does not represent phonetic, but semantic units\". But there are some, and used to be more, that leaned more or less strongly in that direction. reply tdeck 18 hours agoparentprevJust a fun fact: some later forms of cuneiform were alphabets. Like Old Persian Cuneiform: https://www.omniglot.com/writing/opcuneiform.htm If you wanted to tell people you \"learned cuneiform\" you could memorize this in an afternoon! reply abtinf 19 hours agoparentprev> To clarify, this is specific to \"alphabetic\" writing, cuneiform/hieroglyphs are older. That’s literally in the title of both the post and the article. What are you “clarifying”? reply sapphicsnail 19 hours agorootparentIt's common to think of alphabetic writing as all writing. I assume that the author is asserting that the characters represent individual phonemes as opposed to pictograms or syllables because those have been around much earlier. There's not much information though and I have no idea how they can make such a radical claim with 4 finger-sized cylinders. reply alok-g 17 hours agorootparentprevYes, however, I was still left wondering about the writing that existing from earlier; and was hoping the article would explain it. I am still not fully clear actually -- Alphabet being a finite set of symbols, how did pre-alphabetic writing work? reply Electricniko 16 hours agorootparentAlphabets have symbols that represent sounds which are strung together to make words. Other types of writing might include symbols that represent words or phrases, with an example being like Egyptian hieroglyphs or Chinese characters. reply mmooss 11 hours agorootparentAlso, in some, symbols represent syllables. It's significant because there are many more syllables than individual sounds. reply Mistletoe 18 hours agorootparentprevWell it helped me, I didn’t put two and two together. reply PittleyDunkin 20 hours agoprevI'm curious how they arrived at the conclusion it's an alphabet without deciphering it. reply teleforce 17 hours agoparentNormally researcher will make a statistical distribution and compared it with the existing deciphered alphabets for example the most popular is the yet to be deciphered Indus script against the popular Egyption script or Egyptian hieroglyphs. The Indus script research findings on it being a script was so controversial that the researcher had a death threat upon him based on the discovery. I think the OP article author is wrong by claiming it's the oldest while it should be the Indus script but perhaps they considered the latter as symbols like Chinese characters not strictly alphabets [1]. [1] Indus script: https://en.wikipedia.org/wiki/Indus_script reply reissbaker 15 hours agorootparentPersonally I'm not convinced that it's alphabetic writing: it's four cylinders with some markings on them, supposedly in an unknown language (convenient!), that appears to have had zero influence on and zero influence from its surrounding region. For the two claimants to the oldest alphabets — the Indus script [1], and the Proto-Sinaitic script [2] — there is ample evidence of broad usage and influence from existing cultures: the Proto-Sinaitic script developed as simplified hieroglyphics used to communicate with Canaanite slaves [3] in Egypt and was the origin of (probably) all modern alphabetic systems, and the Indus script developed from earlier potter's marks over hundreds of years and has nearly a thousand years of archeological evidence, although there is some debate as whether it qualifies as an alphabet. This appears unrelated to any existing writing system in the region, and — if it was an alphabet — appears to have had no subsequent influence on any other writing system ever made. If archeologists are suspicious of even the Indus script, how on earth do these qualify? We have plenty of examples of pottery with markings on it that aren't alphabets. Cuneiform obviously, but also simply tradesman marks like the predecessors to the Indus script. What makes this \"seem like alphabetic writing\" as opposed to any of the other kinds of clay markings we've seen at the time? There are only four objects bearing the markings, with nothing else to compare against, in a supposedly \"unknown\" language! If this really is an alphabet: what did it develop from? Where are the cultures who used it? And why did no one in the region ever use anything like it again? 1: https://en.wikipedia.org/wiki/Indus_script 2: https://en.wikipedia.org/wiki/Proto-Sinaitic_script 3: https://en.wikipedia.org/wiki/History_of_the_alphabet reply casenmgreen 9 hours agorootparent> If this really is an alphabet: what did it develop from? Where are the cultures who used it? And why did no one in the region ever use anything like it again? All good points, and my sense of it also is that it's pre-writing, but it might be that additional material just hasn't yet been discovered. Linear A and PS are known from a very, very few inscriptions. reply teleforce 13 hours agorootparentprevThe skeptics also provided similar arguments as yours against the idea of Egyption hieroglyphics as syllabic/alphabets until they found the venerable Rosetta Stone, and the rest is history. We just need another Rosetta Stone but for Indus script. reply unscaled 9 hours agorootparentThis does not make GP incorrect though. It just means we really cannot know for sure how the writing system works until we have enough information to decipher the inscriptions. I don't take beef with the possibility of an earlier alphabet that predates the Proto-Canaanite alphabet — that is entirely plausible. But I think the article is overselling the story. The evidence is not very strong at this point, and I although I can be wrong, I suspect it can never be with if we remain with just four very short inscriptions without external context. It is important to clarify the vast difference between this and the decipherment of Egyptian Hieroglyphs. I think the myth and magic of the Rosetta stone is overemphasized in popular culture, so just a few points of difference between the Egyptian Hieroglyphs and scripts like the Indus Valley Script or Linear A. - Of course, to start with we did have the Rosetta Stone, and we have no equivalent for these scripts. But the Rosetta Stone was rediscovered in 1799, while Champollion provided the first phonetic interpretation of Egyptian hieroglyphs only two and half decades later, in 1822. But even after Champollion's famous achievement, we weren't able to read most hieroglyphic texts yet! Champollion didn't realize that many phonetic hieroglyphs represent not just a single consonant, but often two or three different consonants! It took a couple of more decades until we Egyptian was fully deciphered. - We knew exactly which culture and language the Egyptian Hieroglyphs belonged to. More importantly, we had a vast wealth of external historical sources about this culture that we could read: mostly in Greek, Hebrew, Roman and Aramaic. From these sources we knew the names of Egyptian kings that we could expect to find in Egyptian hieroglyphs, and we knew enough about Egyptian culture, religion and history to often guess what the texts would be talking about. This is not anywhere nearly as true for the Indus Valley Script! Since we don't know who their kings were, we cannot use the names of kings as a highly verifiable way to test the phonetic writing hypothesis. - We had a vast quantity of Hieroglyphs inscriptions. There are fewer attested Indus Valley Script inscriptions, but the number should be enough if we just had other external clues. - Egyptian still had a (barely-)living descendant (Coptic) at the time Champollion and other scholars were working on its decipherment. Coptic priests and AFAIK even native speakers have provided a lot of help them in understanding how the Egyptian language they were trying to decipher might sound and work. reply mmooss 11 hours agorootparentprev> Personally I'm not convinced that it's alphabetic writing What is their evidence and argument for it? reply Steko 16 hours agoparentprevThe tldr is that they don't know it's alphabetic for sure (see below quote). The main scholar (Glenn Schwartz) who co-oversaw the '9410 excavation isn't an expert in writing. He put it out there around 2010 and said \"maybe it's alphabetic, idk\" and there was not much followup from the community. So he consulted with some writing experts who helped him with the 2021 paper where he goes over the evidence for different possibilities and suggests that the strongest argument is for alphabetic. The dating seems to be on firmer ground but the error bands on this and Wadi el-Hol can probably knock a century or two off the \"500 years\". A decent summary is the blog post below from another researcher who briefly was part of the same dig and a former student of Schwartz (so not entirely independent): http://www.rollstonepigraphy.com/?p=921 It is worth noting that in the past Schwartz has been reluctant to affirm that the four inscribed clay cylinders from Tomb 4 of Umm el-Marra are alphabetic (Schwartz 2010). Thus, he certainly did not rush to this conclusion. Moreover, his most recent article about these is also very cautious (Schwartz 2021), as he moves through various possibilities (as discussed above). But it is clear that he is now willing to state that this is the most reasonable position (i.e., it is Early Alphabetic). And I concur. That is, the most reasonable conclusion is that the Umm el-Marra clay cylinders are inscribed with signs that are most readily understood as Early Alphabetic letters (graphemes). Moreover, since the Early Alphabetic alphabet was used to write Semitic, it is logical to conclude that this is the language of the Umm el-Marra inscriptions (the fact that they were found in Syria would also augment this conclusion, of course). The full blog post is worth reading and summarizes the case for various non-alphabetic possibilities. reply unscaled 9 hours agorootparentI admit I didn't have time to read this blog post deeply, but it doesn't sound very convincing. It doesn't bring any EVIDENCE that this is an alphabet it just cites other cases of possible alphabets in Mesopotamia and the near East [1]. Besides that, this blog post mentions some morphological characteristics of the inscriptions that make the author believe the writing is alphabetic, but it fails to mention these characteristics. I don't doubt Rollston has good reasons for this statement, but the claims behind them need to be published and reviewed. I'm not sure if this is the case (and I do not have access to the 2021 article). [1] This includes the Lachish Dagger I tried to look up, but its dating seems disputed, but even the earliest proposed date (the 17th century) is more recent than the Wadi el-Hol inscriptions, so I'm not entirely sure what it is supposed to prove, except perhaps an earlier spread of the Alphabet from Egypt and the Sinai peninsula to Canaan proper? reply Steko 6 hours agorootparent> it doesn't sound very convincing That's because it's not a strong conclusion. It's a \"better than the alternatives\" hypothesis. Repeating my tldr above \"they don't know it's alphabetic\". > doesn't bring any EVIDENCE .. some morphological characteristics of the inscriptions I'd say the \"morphological characteristics of the inscriptions\" count as evidence and I'll just recap everything linked that I think counts as evidence: the graphemes include several repetitions even with only 12 signs in total; they don't resemble cuneiform at all; they have a weak resemblances to some Egyptian glyphs but weak and Egypt didn't have these clay cigars; they have a weak resemblance to some Indus glyphs and (later) Byblos glyphs but again weak; they don't appear to be numbers, potmarks, etc.; but what they do strikingly resemble is later alphabetic signs, to the point where the author, one of the foremost experts on Semitic epigraphy, really wanted the dating to be wrong. Now the blog post doesn't go into much detail on these items but Schwartz's 20+ page 2021 paper (I had no trouble getting a free, legal copy) does (not always a lot more detail but also covers more possible alternatives). But, like the blog post says, the case Schwartz 2021 makes is still extremely cautious and he basically concludes that we just have to hope we can find more examples to confirm what kind of system they are from, and to increase the chance of deciphering them. reply mcswell 43 minutes agorootparent> Egypt didn't have these clay cigars Sometimes a cigar is just a cigar. I'll escort myself out now... reply unscaled 4 hours agorootparentprevHow is it better than the alternative \"we have a set of symbol and we don't know what it means\"? I really think there is a merit in saying \"with this sample size, every theory we put out has low confidence level\". With 12 signals in total, it's very hard to show patterns that are in line with an alphabet. I don't think that with this sample size you can make a very strong claim that the chance that this is an alphabet is higher than the chance is that these symbol serve any other kind of purpose (including being a non-language). The main claim seems to be that repetition (what kind? I'm a quite disappointed the blog post has no transcritions, considering it's just 12 symbols we're talking about!) makes the chance that this is an alphabet higher. The rest of the claims (it doesn't resemble cuneiform, doesn't seem to be derived from hieroglyphs and doesn't seem related to any other script) are meaningless. The resemblence for later Canaanite alphabetic signs is interesting, and could probably be more convincing if we had a larger sample size. So in the end, if we are convinced by these claims, we're basically saying something like \"We have at most 1% confidence for every other theory, but we've got 2% confidence that this is an independent development of the alphabet that may have inspired the Canaanite alphabet we've seen 500 later\". Higher confidence that is still far below the threshold doesn't cut it. Now, I'm pretty sure the original article did not put the theory in these terms, but the headline is somewhat sensationalist, and the way it was picked up in newspapers is even worse, for instance: Scientific American: World's Oldest Alphabet Found on an Ancient Clay Gift Tag Stopping the press from misreporting science is a bit like trying to stop space rockets in midair with your bare hands, but even \"Evidence of oldest known alphabetic writing unearthed in ancient Syrian city\". The popular understanding of the word evidence is assumed to be \"hard\" evidence by default, not a weak evidence that bumps up the probability of a certain theory a little bit more. I'll actually be quite excited if this turns out to be truly an alphabet encoding a Semitic language (it opens a lot of interesting questions and possibilities), but I'm not holding my breath for it. reply w10-1 19 hours agoparentprevRight. 4 clay cylinders inch-long, perforated, with geometric symbols on the outside, are not jewelry (otherwise found in the same tomb) but ... labels with a new form of writing because... they were found next to the pottery? The article is brilliantly written to lead with the significance of such a find before providing evidence. reply thaumasiotes 19 hours agorootparentThe article is well cited. They handily beat out newspapers by providing links to earlier blog posts on the research. You might want this one: http://www.rollstonepigraphy.com/?p=921 > I will convey my own perspective regarding these four inscribed clay cylinders: namely, the script is Early Alphabetic (based on the clear morphology of the letters), the language is arguably Semitic, and the date is early (based on the secure archaeological context and carbon 14 dates). > My initial thought (because of the graphemic shapes of the signs on the cylinders and the clear similarity to Early Alphabetic letters) was that these cylinders might be intrusive So, the major argument that they're writing is that they look very similar to other writing that we can read. Imagine that you can read Latin, but not Greek, and you're confronted with some inscriptions in Greek. Should you call them writing? reply sterlind 18 hours agorootparent\"乇乂ㄒ尺卂\" looks like \"EXTRA\", but it's (meaninglessly-arranged) Chinese characters with a purely coincidental relationship to the Latin. Did they find a bunch of these artifacts, with a variety of inscriptions? If so then sure, I buy it. If it's just the \"CHON\" fragment - that could well be coincidence. reply blahedo 15 hours agorootparentDepends; your example (乇乂ㄒ尺卂) would be a truly stupendous coincidence if it were the only extant example of something and the Chinese characters just happened to be arranged in that way, but would be much weaker evidence if you had gone mining through thousands of characters and cherry-picked one five-character string that happened to match something. It would be an even bigger coincidence if those five characters, in sequence, were found, by themselves, on a document created in an English-speaking or Latin-alphabet-writing region. So if all of the handful of fragments have marks that look like actual alphabetic symbols that were actually used in that area (later), that's substantially stronger evidence than you're giving credit for. reply mmooss 11 hours agorootparentprevIs it worth inquiring whether people who acquired PhDs and have spent lifetimes studying this subject, and (I think) years studying these particular objects, would overlook and be fooled by the most obvious issue? reply timeon 18 hours agorootparentprev> Imagine that you can read Latin, but not Greek, and you're confronted with some inscriptions in Greek. Should you call them writing? Not sure if this is good example since we know that Greek alphabet really is writing. reply thaumasiotes 19 hours agoparentprevahmedfromtunis's comment was killed, presumably because he attributed it to Gemini, but it was correct on the facts. Here's the response I wrote to him: ----- Count of symbol types is what you'd look at. You have a bunch of unknown symbols, so there's nothing else you can look at. For comparison: Japanese hiragana: ~71 symbols [*] Cherokee syllabary: ~86 symbols Greek alphabet: ~24 symbols Latin alphabet: ~21 symbols ( https://ancientgraffiti.org/Graffiti/graffito/AGP-EDR187776 ) [*] Many Japanese syllables are spelled with digraphs (\"sh\", if the \"h\" appeared in a special combining form) or diacritics (\"è\", if è and e were completely distinct sounds, as they are in French), which lowers the memory burden. I've counted diacritics as creating new symbols and digraphs as not doing so. reply glandium 16 hours agorootparentHow do you get 71 hiraganas? By counting the dakuten versions and smaller versions separately? reply NelsonMinar 17 hours agoprevSome informed speculation about this on languagehat, in the comments: https://languagehat.com/oldest-alphabet/ reply mcswell 39 minutes agoparentAnd some comments at Language Log here: https://languagelog.ldc.upenn.edu/nll/?p=67023 reply mihaic 20 hours agoprevWow, this is impressive if actually true. I wonder how accurate their dating methodology is, since they have to do carbon dating on something in that layer, and not on the clay tablet itself. It does seem strange that the alphabet would have remained isolated for so many hundreds years, and not spread out somewhere else. reply singularity2001 8 hours agoprevGiven that most signs on the cylinders are unique it's much more likely that they represent just another syllabary of it's time, no? reply novateg 17 hours agoprevThe article is not complete. I could not find any comparison of the new alphabet to the known ones. Is this close to Phoenician or Aramaic? reply olalonde 12 hours agoprevCarbon-14 dating can't be used directly on clay right? I assume the dating is inferred from some organic material found nearby? reply tivert 14 hours agoprev> Schwartz said. \"Without a means to translate the writing, we can only speculate.\" If you can't translate it, how do they know it's alphabetic? reply philipov 14 hours agoparentStatistical analysis, more or less. Alphabets have a couple dozen characters, syllabaries have a couple hundred, and logographic scripts have thousands to tens of thousands. reply openrisk 9 hours agoprev> Alphabets revolutionized writing by making it accessible to people beyond royalty and the socially elite. Alphabetic writing changed the way people lived, how they thought, how they communicated Thousands of years later (with few cultural diffusion barriers) billions of people do not use alphabets. So there is probably something missing from this picture. E.g., the large Chinese society is notoriously competitive and you would think that if the use of alphabet is an obvious enabler it would have been adopted by some segment? Maybe there is a tradeof in a phonetic system: if the spoken language cannot be properly captured it negates the combinatorial benefits of an alphabet. reply Ericson2314 20 hours agoprevCHON? reply mometsi 17 hours agoparentIt's the brand name. When you need authentic pottery built to last, look for CHON on the cylinder. Customer: *checks cylinder*, hey, this isn't CHON, it's C𓅓ON! reply ggambetta 19 hours agoparentprevI guess they also knew organic chemistry back then! reply consf 3 hours agoprevHow practical and functional early writing systems were, far before they became the monumental tools of record-keeping we often associate with ancient civilizations reply photochemsyn 19 hours agoprevHow do they know when the writing is pictographic (an idea expressed as an image, like a big predator showing teeth), or syllabic (an image of a bestial grunt, basically, like 'ugh' or 'caw' or what not) or alphabetic (the breakdown of syllabic utterances into, at first, the hard consantants and the vowels)? reply ahmedfromtunis 19 hours agoparentBasically, the number of symbols and the repeating patterns. But it seems that in this particular case, they also relied on the shapes of the \"letters\" to conclude the alphabetic nature of the script. reply Sam6late 10 hours agoprevSome claim that standard Arabic has been intentionally made more complicated because writers were paid well by rulers back in old days, and there were more incentives to make grammar hard for the ordinary folks, so that you need \"craftsmen\" to write according to an Arabic linguist.Until the 80s in many Arab countries you needed clerks to produce documents from governments. (Comedy sketch on it https://www.youtube.com/watch?v=wtloJgMgFho) Arabic linguist https://www.youtube.com/watch?v=UoqDR0Hd9f0 'Category V – It usually takes 88 weeks or 2200 hours to reach S-3/R-3 proficiency in these languages. This small group of “super-hard languages” includes Chinese (Mandarin), Cantonese, Japanese, Korean and Arabic.' (Arabic linguist)https://www.youtube.com/watch?v=UoqDR0Hd9f0&t=3645s reply mcswell 36 minutes agoparentI don't think anyone has seriously claimed that Modern Standard Arabic has been intentionally made complicated. It's clearly related to a lot of other Semitic languages (including the regional varieties of spoken Arabic). And the Category V thing is only about learning Arabic (any variety, not just MSA) as a second language, an in particular a second language for native speakers of English. reply newsclues 8 hours agoparentprevSounds like our laws and lawyers. reply mrkeen 7 hours agorootparentLikewise with keeping science and Catholicism in Latin. reply aprilthird2021 20 hours agoprevnext [43 more] [flagged] aithrowawaycomm 18 hours agoparentMany countries are bombing Syria, including Syria itself, Jordan, Russia, and the US, largely because of the ongoing civil war and related ISIS attacks, though Jordan is mostly targeting drug smugglers aligned with the Syrian government. Focusing on Israel is just incredibly ignorant. reply mandmandam 7 hours agorootparent\"Focusing on Israel\" is pretty fair in this instance. Israel has been bombing many important archaeological sites recently (along with hospitals, refugee camps, humanitarian corridors, press offices, schools, etc). reply aprilthird2021 12 hours agorootparentprevHave any of these countries (except the US) bombed Syria within the past few months that this discovery could be from? Also the discovery is actually from 2004, so the point of my question was valid, it's not safe to do such research there now due to geopolitics reply ahmedfromtunis 19 hours agoparentprevI had the same question, especially that the researchers are from a western \"enemy\" country. It's impressive the length researchers go to, well, research. reply card_zero 19 hours agorootparentOften these things have been sitting in a drawer somewhere for years before the research is released. > Archaeologists first found the cylinders in 2004 https://archive.ph/YOsqx (Also: \"It’s an alphabet. It’s easy-peasy. I’m used to much tougher things,\" said Silvia Ferrara, who was not involved.) reply ahmedfromtunis 18 hours agorootparentThanks for the clarification. And, yes, that quote is so badass! reply emmelaich 18 hours agorootparentprevMost Westerners have their ancestry in Syria, the Levant, Mesopotamia if you go back far enough. Not that that is the only criterion! reply Tagbert 20 hours agoparentprevYou may be thinking of Lebanon. reply bojan 20 hours agorootparentIsreal is regularly bombing targets in Syria as well. But the targets seem to be mostly military installations, so the civilian life is not nearly as much disrupted as it is in Lebanon. reply kamikazeturtles 19 hours agorootparentAccording to Israel's Dahiya doctrine, civilian targets are legitimate targets in order to put pressure on opposing governments. reply klipt 19 hours agorootparentSyria has been bombed way more by Assad, the dictator of Syria, than by Israel. Assad has killed about half a million Syrians already in the civil war. reply dotancohen 18 hours agorootparent> Assad has killed about half a million Syrians already in the civil war. How can that be true? Western academics protest when so many people are killed. The Gaza health ministry itself claims less that 1/10 of that number, and look at how many protests and riots are in the US right now. If Syria really had half a million dead you'd see the academics rioting about that. reply tdeck 18 hours agorootparentPeople typically protest their own government to effect policy changes. In the case of Gaza, the US is sending billions of dollars to Israel on a regular basis. The Syrian government, meanwhile, has been sanctioned for more than a decade by these western countries. https://en.m.wikipedia.org/wiki/International_sanctions_agai... reply bojan 18 hours agorootparentprevKeep in mind that Gaza's Health Ministry isn't really functional any more, and they are in no state to keep numbers. reply emmelaich 18 hours agorootparentprev¯\\_(ツ)_/¯ reply throw310822 19 hours agorootparentprevIsn't this pretty much the definition of terrorism? reply o11c 18 hours agorootparentThe definition of terrorism generally excludes acts performed by a legitimate state. Whenever this causes problems, you have to declare the relevant state illegitimate (which, depending on the state, may be trivial or highly contested). reply lolinder 18 hours agorootparentprevIt's also been standard practice in war since pretty much forever. Not that that's a good thing—war is and always has been terrible—but Israel didn't invent the idea of targeting civilians, nor are there any countries in recent history who have suddenly become above that kind of warfare. There are some that like to talk the talk, but they either have managed to just avoid war (to be fair, good on them) or do the same thing. reply ptidhomme 20 hours agorootparentprevIsrael does regularly bomb Syria. https://www.aljazeera.com/news/2024/10/12/how-can-israel-att... reply mupuff1234 20 hours agorootparentSyria also regularly bombs Syria. It's worth mentioning the ongoing civil war in Syria that so far result in around 700k dead. reply dotancohen 19 hours agorootparent> It's worth mentioning the ongoing civil war in Syria that so far result in around 700k dead. There's no way there are 700,000 people dead in Syria. US and European colleges are up in arms over Gaza, and Gaza has less than 50,000 dead. If 700,000 people really were dead in the Syrian civil war there would be riots in the West just like there are for Palestine. reply benreesman 19 hours agorootparent700k fatalities is a little high as consensus estimates go, but it’s not ridiculous, even low estimates are in the hundreds of thousands. It’s been going on for more than 13 years and has way more factions than anything happening in Gaza right now, many/most great powers both regionally and globally have a hand in somehow, and the Western press doesn’t report on it nearly as much as on more recent conflicts. If college campus protests were driven directly or substantially by human suffering you’d be hearing about Sudan every day. https://en.m.wikipedia.org/wiki/Syrian_civil_war reply throw310822 19 hours agorootparentprevRiots for what? Assad was blamed and bombed by the West already, what should have people rioted for? Besides, the entire Syrian civil war was started and fueled with American money and weapons- which ended up in the hands of each and every rebel/ terror group, including ISIS. Then the West blamed Assad for fighting back instead of leaving the country in the hand of those terror groups. Had he done that, now Syria would be a wasteland roamed by warlords, Mad Max style. reply klipt 19 hours agorootparentprevBut Syria is (incorrectly) stereotyped as \"brown people killing brown people\" which college students shrug at. While Israel is (incorrectly) stereotyped as \"white people killing brown people\" which is a big no no. Incorrectly because if you look at pictures of Syrian dictator Assad, he would be considered white in the US. Certainly whiter than many Israelis of Yemenite ancestry. reply kamikazeturtles 19 hours agorootparentprevAccording to the Lancet medical journal, the Gaza deaths are closer to 200k but other sources say it might even be higher. No one knows because most of the hospitals are not operational, the dead from collapsed buildings can't be retrieved. For Syria, I've heard ranges of anywhere between 300k and 700k. The difference between Syria and Gaza is most of the dead in Gaza are woman and children and the Syrian civil war death toll is over a decade reply dotancohen 18 hours agorootparentI had to look that up. Apparently the Lancet just multiplied by five the numbers from the Gazan health ministry, on the basis \"of four indirect deaths per one direct death\". That inflation technique is not used in any conflict anywhere else in the world, and particularly not in the Syrian conflict we're discussing and comparing to. If you would like to use that number, then apply that inflation technique also to the Syrian conflict as well. https://www.france24.com/en/middle-east/20240711-more-than-1... reply grumple 18 hours agorootparentprevLancet's numbers are not based in facts. Here's the exact excerpt from them: > Armed conflicts have indirect health implications beyond the direct harm from violence. Even if the conflict ends immediately, there will continue to be many indirect deaths in the coming months and years from causes such as reproductive, communicable, and non-communicable diseases. The total death toll is expected to be large given the intensity of this conflict; destroyed health-care infrastructure; severe shortages of food, water, and shelter; the population's inability to flee to safe places; and the loss of funding to UNRWA, one of the very few humanitarian organisations still active in the Gaza Strip. > In recent conflicts, such indirect deaths range from three to 15 times the number of direct deaths. Applying a conservative estimate of four indirect deaths per one direct death9 to the 37 396 deaths reported, it is not implausible to estimate that up to 186 000 or even more deaths could be attributable to the current conflict in Gaza. Again, from their own words, these numbers are not based in any reality on the ground, they are just taking the current number of reported deaths and multiplying it by 5. It also includes theoretical deaths in the future. Edit: corrected multiple reply dotancohen 18 hours agorootparent> they are just taking the current number of reported deaths and multiplying it by 4. Actually, multiplying by five. reply grumple 18 hours agorootparentHaha, apologies, you are correct. reply grumple 19 hours agorootparentprevJust wait until you find out that our NATO ally Turkey is occupying an area larger than the west bank and gaza combined in Syria. reply akira2501 19 hours agorootparentprevThe USA sponsors ISIS terrorism inside Syria. I wonder if that's why they are in the position to \"bomb themselves.\" It's worth mentioning that this is an externally state sponsored \"civil war\" on both sides. The most appropriate description is \"proxy war.\" reply dotancohen 18 hours agorootparentWell Iran sponsors Hamas terrorism in Israel (rockets have been regularly shot across the border for years before the current war started). Iran also sponsors Hezbollah terror in both Israel and in Lebanon. Does that justify Israeli bombing against Hamas or Hezbollah? So how is \"Syria bombing Syria\" suddenly justified if someone is sponsoring terrorists? reply akira2501 18 hours agorootparent> Well Iran sponsors Hamas terrorism in Israel So two wrongs make a right? > how is \"Syria bombing Syria\" suddenly justified It's not. Nowhere in my statement did I attempt to justify it. I explained the context so that people wouldn't walk away confused as to what that short sentence actually means. Apparently that context being added irritates you. That is interesting in it's own right. reply kamikazeturtles 19 hours agorootparentprevIt was closer to a \"regime change\" proxy war with thousands of imported fighters, rather than a \"civil war\". reply grumple 18 hours agoparentprevSyria has been bombed far more by the US and Turkey than Israel, and a significant area is currently being occupied by Turkey. Israel is barely a player in this conflict and is just striking the occasional tactical or strategic target (like random factions attacking Israel, IRGC or Hezbollah leadership). But the answer is that there's really not much bombing at this point. A bigger problem for Syria is the multi-faction conflict on the ground, of which Hezbollah was one of the biggest factions: https://en.wikipedia.org/wiki/Syrian_civil_war#Belligerents reply nabakin 20 hours agoparentprevYou might be confusing it with Lebanon, but Syria has been bombed by Israel and is pretty unstable in general so it's impressive they were able to do this research regardless. People shouldn't be downvoting you for asking a question. reply jajko 19 hours agorootparentNah Israel is heavily assaulting Syria too, these days, at this moment, continuously. Special ops raids for targeted killing, blowing up some stuff or the other, bombing places. They don't even try to hide it, videos from chopper pilots, drones and helmet cams from soldiers are all over internet. It may have some good reasons behind given war they wage on Lebanon, or just settling decades old political grudges, don't know. reply dotancohen 18 hours agorootparent> It may have some good reasons behind given war they wage on Lebanon The day after Hamas attacked Israel in October 2023, Lebanon (well, Hezbollah) stepped up their rocket attacks on Israel. Israel had to evacuate the entire north of the country, so that combined with the evacuated people from the Gaza area means something like 200,000 internally displaced Israelis right now. Hezbollah has killed dozens of citizen across the border, most prominently 12 children playing soccer a few months ago. They bombed two kindergartens in Israel this past week. reply nabakin 19 hours agorootparentprevHonestly, I don't understand why the threshold for war seems to be ground invasion. If you're shooting missiles at another country, that's war too. Israel is at war with Syria, Iran, and Lebanon imo. Not to mention Hamas. reply kamikazeturtles 19 hours agorootparentWhen we bomb, it's called a preemptive strike. It's only considered war when the enemy responds. Welcome to the \"rules based international order\" reply tokinonagare 19 hours agorootparentAlso giving billions worth of weapon is seemingly totally fine but selling shells and sending troops to an allied country is \"an escalation\" when the opponent camp does it. The double standards and double speak is so tiring. reply aprilthird2021 12 hours agorootparentprevAlso, Israel claims it must preemptively strike and do all sorts of things due to what its enemies may do to them, but given how much slaughter and actual genocide Israel sanctioned its allies to do in Lebanon in its history, they would be equally justified in reverse reply bargainbot3k 18 hours agoprevGraham Hancock. reply Eumenes 3 hours agoparentA classic: https://www.theguardian.com/tv-and-radio/2022/nov/23/ancient... reply af3d 17 hours agoprev [–] They could also be descriptions of musical scales, or maybe weaving patterns, base-encoded numbers perhaps....who knows, really? Also Egyptian writing goes back perhaps 5000 years. That is a Semitic language so it stands to reason that it too would likely fall in the same category. Anyway I do love these kinds of archeological finds nonetheless. Interesting to see if Gobekli Tepe yields even older instances of written script? (If they ever get around to a proper excavation, that is! IIRC the site is currently not open to researchers.) reply kleton 13 hours agoparentEgyptian is afro-asiatic but not semitic, like Berber, somali and others reply alpinisme 17 hours agoparentprev [–] Egyptian writing is old but it is not (primarily) alphabetic. reply af3d 16 hours agorootparent [–] Yes kind of a hybrid, isn't it? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers from Johns Hopkins University have uncovered what could be the oldest known alphabetic writing, dating to approximately 2400 BCE, in a Syrian tomb.",
      "This discovery suggests that alphabetic writing is 500 years older than previously believed, potentially altering the understanding of its origins.",
      "The writing, found on clay cylinders at Tell Umm-el Marra in Syria, predates known scripts from Egypt and will be presented at the American Society of Overseas Research's Annual Meeting."
    ],
    "commentSummary": [
      "Researchers have discovered the oldest known alphabetic writing in an ancient Syrian city, dating back to approximately 2400 BCE, indicating that alphabetic writing may have originated earlier than previously believed.- The writing was found on four clay cylinders, but without a translation method, the content remains speculative, prompting questions about the evolution and dissemination of alphabetic writing systems.- This finding is significant as it challenges existing theories about the timeline and influence of alphabetic writing in ancient societies."
    ],
    "points": 314,
    "commentCount": 227,
    "retryCount": 0,
    "time": 1732399882
  },
  {
    "id": 42223690,
    "title": "Antenna Diodes in the Pentium Processor",
    "originLink": "http://www.righto.com/2024/11/antenna-diodes-in-pentium-processor.html",
    "originBody": "Ken Shirriff's blog Computer history, restoring vintage computers, IC reverse engineering, and whatever Antenna diodes in the Pentium processor I was studying the silicon die of the Pentium processor and noticed some puzzling structures where signal lines were connected to the silicon substrate for no apparent reason. Two examples are in the photo below, where the metal wiring (orange) connects to small square regions of doped silicon (gray), isolated from the rest of the circuitry. I did some investigation and learned that these structures are \"antenna diodes,\" special diodes that protect the circuitry from damage during manufacturing. In this blog post, I discuss the construction of the Pentium and explain how these antenna diodes work. Closeup of the Pentium die showing the silicon and bottom metal layer. The arrows indicate connections to two antenna diodes. I removed the top two layers of metal for this photo. Intel released the Pentium processor in 1993, starting a long-running brand of high-performance processors: the Pentium Pro, Pentium II, and so on. In this post, I'm studying the original Pentium, which has 3.1 million transistors.1 The die photo below shows the Pentium's fingernail-sized silicon die under a microscope. The chip has three layers of metal wiring on top of the silicon so the underlying silicon is almost entirely obscured. The Pentium die with the main functional blocks labeled. Click this photo (or any other) for a larger version. Modern processors are built from CMOS circuitry, which uses two types of transistors: NMOS and PMOS. The diagram below shows how an NMOS transistor is constructed. A transistor can be considered a switch between the source and drain, controlled by the gate. The source and drain regions (green) consist of silicon doped with impurities to change its semiconductor properties, forming N+ silicon. The gate consists of a layer of polysilicon (red), separated from the silicon by an absurdly thin insulating oxide layer. Since the oxide layer is just a few hundred atoms thick,2 it is very fragile and easily damaged by excess voltage. (This is why CMOS chips are sensitive to static electricity.) As we will see, the oxide layer can also be damaged by voltage during manufacturing. Diagram showing the structure of an NMOS transistor. The Pentium processor is constructed from multiple layers. Starting at the bottom, the Pentium has millions of transistors similar to the diagram above. Polysilicon wiring on top of the silicon not only forms the transistor gates but also provides short-range wiring. Above that, three layers of metal wiring connect the parts of the chip. Roughly speaking, the bottom layer of metal connects to the silicon and polysilicon to construct logic gates from the transistors, while the upper layers of wiring travel longer distances, with one layer for signals traveling horizontally and the other layer for signals traveling vertically. Tiny tungsten plugs called vias provide connections between the different layers of wiring. A key challenge of chip design is routing, directing signals through the multiple layers of wiring while packing the circuitry as densely as possible. The photo below shows a small region of the Pentium die with the three metal layers visible. The golden vertical lines are the top metal layer, formed from aluminum and copper. Underneath, you can see the horizontal wiring of the middle metal layer. The more complex wiring of the bottom metal layer can be seen, along with the silicon and polysilicon that form transistors. The small black dots are the tungsten vias that connect metal layers, while the larger dark circles are contacts with the underlying silicon or polysilicon. Near the bottom of the photo, the vertical gray bands are polysilicon lines, forming transistor gates. Although the chip appears flat, it has a three-dimensional structure with multiple layers of metal separated by insulating layers of silicon dioxide. This three-dimensional structure will be important in the discussion below. (The metal wiring is much denser over most of the chip; this region is one of the rare spots where all the layers are visible.) Closeup of the Pentium die showing the metal layers. The L-shaped hook towards the lower left is a connection to an antenna diode. This photo shows a tiny part of the floating point unit. To show all the layers in focus, I combined multiple images with focus stacking. The manufacturing process for an integrated circuit is extraordinarily complicated but I'll skip over most of the details and focus on how each metal layer is constructed, layer by layer. First, a uniform metal layer is constructed over the silicon wafer. Next, the desired pattern is produced on the surface using a process called photolithography: a light-sensitive chemical called \"resist\" is applied to the wafer and exposed to light through a patterned mask. The light hardens the resist, creating a protective coating with the pattern of the desired wiring. Finally, the unprotected metal is etched away, leaving the wiring. In the early days of integrated circuits, the metal was removed with liquid acids, a process called wet etching. Inconveniently, wet etching tended to eat away metal underneath the edges of the mask, which became a problem as integrated circuits became denser and the wires needed to be thinner. The solution was dry etch, using a plasma to remove the metal. By applying a large voltage to plates above and below the chip, a gas such as HCl is ionized into a highly reactive plasma. This plasma attacks the surface (unless it is protected by the resist), removing the unwanted metal. The advantage of dry etching is that it can act vertically (anisotropically), providing more control over the line width. Although plasma etching improved the etching process, it caused another problem: plasma-induced oxide damage, also called (metaphorically) the \"antenna effect.\"3 The problem is that long metal wires on the chip could pick up an electrical charge from the plasma, producing a large voltage. As described earlier, the thin oxide layer under a transistor's gate is sensitive to voltage damage. The voltage induced by the plasma can destroy the transistor by blowing a hole through the gate oxide or it can degrade the transistor's performance by embedding charges inside the oxide layer.4 Several factors affect the risk of damage from the antenna effect. First, only the transistor's gate is sensitive to the induced voltage, due to the oxide layer. If the wire is also connected to a transistor's source or drain, the wire is \"safe\" since the source and drain provide connections to the chip's substrate, allowing the charge to dissipate harmlessly. Note that when the chip is completed, every transistor gate is connected to another transistor's source or drain (which provides the signal to the gate), so there is no risk of damage. Thus, the problem can only occur during manufacturing, with a metal line that is connected to a gate on one end but isn't connected on the other end. Moreover, the highest layer of metal is \"safe\" since everything is connected at that point. Another factor is that the induced voltage is proportional to the length of the metal wire, so short wires don't pose a risk. Finally, only the metal layer currently being etched poses a risk; since the lower layers are insulated by the thick oxide between layers, they won't pick up charge. These factors motivate several ways to prevent antenna problems.5 First, a long wire can be broken into shorter segments, connected by jumpers on a higher layer. Second, moving long wires to the top metal layer eliminates problems.6 Third, diodes can be added to drain the charge from the wire; these are called \"antenna diodes\". When the chip is in use, the antenna diodes are reverse-biased so they have no electrical effect. But during manufacturing, the antenna diodes let charge flow to the substrate before it causes problems. The third solution, the antenna diodes, explains the mysterious connections that I saw in the Pentium. In the diagram below, these diodes are visible on the die as square regions of doped silicon. The larger regions of doped silicon form PMOS transistors (upper) and NMOS transistors (lower). The polysilicon lines are faintly visible; they form transistor gates where they cross the doped silicon. (For this photo, I removed all the metal wiring.) Closeup of the Pentium die showing transistors. The metal and polysilicon layers have been removed to show the silicon. Confusingly, the antenna diodes look almost identical to \"well taps\", connections from the substrate to the chip's positive voltage supply, but have a completely different purpose. In the Pentium, the PMOS transistors are constructed in \"wells\" of N-type silicon. These wells must be raised to the chip's positive voltage, so there are numerous well tap connections from the positive supply to the wells. The well taps consist of squares of N+ doped silicon in the the N-type silicon well, providing an electrical connection. On the other hand, the antenna diodes also consist of N+ doped silicon, but embedded in P-type silicon. This forms a P-N junction that creates the diode. In the Pentium, antenna diodes are used for only a small fraction of the wiring. The diodes require extra area on the die, so they are used only when necessary. Most of the antenna problems on the Pentium were apparently resolved through routing. Although the antenna diodes are relatively rare, they are still frequent enough that they caught my attention. Antenna effects are still an issue in modern integrated circuits. Integrated circuit fabricators provide rules on the maximum allowable size of antenna wires for a particular manufacturing process.7 Software checks the design to ensure that the antenna rules are not violated, modifying the routing and inserting diodes as necessary. Violating the antenna rules can result in damaged chips and a very low yield, so it's more than just a theoretical issue. Thanks to /r/chipdesign and Discord for discussion. If you're interested in the Pentium, I've written about standard cells in the Pentium, and the Pentium as a Navajo rug. Follow me on Mastodon (@kenshirriff@oldbytes.space) or Bluesky (@righto.com) or RSS for updates. Notes and references In this post, I'm looking at the Pentium model 80501 (codenamed P5). This model was soon replaced with a faster, lower-power version called the 80502 (P54C). Both are considered original Pentiums. ↩ IC manufacturing drives CPU performance states that gate oxide thickness was 100 to 300 angstroms in 1993. ↩ The wires are acting metaphorically as antennas, not literally, as they collect charge, not picking up radio waves. Plasma-induced oxide damage gave rise to research and conferences in the 1990s to address this problem. The International Symposium on Plasma- and Process-Induced Damage started in 1996 and continued until 2003. Numerous researchers from semiconductor companies and academia studied the causes and effects of plasma damage. ↩ The damage is caused by \"Fowler-Nordheim tunneling\", where electrons tunnel through the oxide and cause damage. Flash memory uses this tunneling to erase the memory; the cumulative damage is why flash memory can only be written a limited number of times. ↩ Some relevant papers: Magnetron etching of polysilicon: Electrical damage (1991), Thin-oxide damage from gate charging during plasma processing (1992), Antenna protection strategy for ultra-thin gate MOSFETs (1998), Fixing antenna problem by dynamic diode dropping and jumper insertion (2000). The Pentium uses the \"dynamic diode dropping\" approach, adding antenna diodes only as needed, rather than putting them in every circuit. I noticed that the Pentium uses extension wires to put the diode in a more distant site if there is no room for the diode under the existing wiring. As an aside, the third paper uses the curious length unit of kµm; by calling 1000 µm a kµm, you can think in micrometers, even though this unit is normally called a mm. ↩ Sources say that routing signals on the top metal prevents antenna violations. However, I see several antenna diodes in the Pentium that are connected directly from the bottom metal (M1) through M2 to long lines on M3. These diodes seem redundant since the source/drain connections are in place by that time. So there are still a few mysteries... ↩ Foundries have antenna rules provided as part of the Process Design Kit (PDK). Here are the rules for MOSIS and SkyWater. I've focused on antenna effects from the metal wiring, but polysilicon and vias can also cause antenna damage. Thus, there are rules for these layers too. Polysilicon wiring is less likely to cause antenna problems, though, as it is usually restricted to short distances due to its higher resistance. ↩ Email ThisBlogThis!Share to XShare to FacebookShare to Pinterest Labels: electronics, Pentium, reverse-engineering No comments: Post a Comment Older Post Home Get new posts by email: Subscribe About the site Contact info and site index Popular Posts Antenna diodes in the Pentium processor Inside a vintage aerospace navigation computer of uncertain purpose Apple iPhone charger teardown: quality in a tiny expensive package A Multi-Protocol Infrared Remote Library for the Arduino Mining Bitcoin with pencil and paper: 0.67 hashes per day The Pentium as a Navajo weaving Teardown and exploration of Apple's Magsafe connector Inside the Globus INK: a mechanical navigation computer for Soviet spaceflight Search This Blog Labels 386 6502 8008 8085 8086 8087 8088 aerospace alto analog Apollo apple arc arduino arm beaglebone bitcoin c# cadc calculator chips css datapoint dx7 electronics f# fairchild fpga fractals genome globus haskell HP html5 ibm ibm1401 ibm360 intel ipv6 ir java javascript math microcode oscilloscope Pentium photo power supply random reverse-engineering sheevaplug snark space spanish synth teardown theory unicode Z-80 Blog Archive ▼ 2024 (20) ▼ November (1) Antenna diodes in the Pentium processor ► October (1) ► September (3) ► August (2) ► July (2) ► June (1) ► May (1) ► April (1) ► March (2) ► February (3) ► January (3) ► 2023 (35) ► December (4) ► November (2) ► October (3) ► September (1) ► August (2) ► July (3) ► May (1) ► April (2) ► March (4) ► February (5) ► January (8) ► 2022 (18) ► November (3) ► August (1) ► July (1) ► June (1) ► May (1) ► April (4) ► March (2) ► February (3) ► January (2) ► 2021 (26) ► December (4) ► November (2) ► September (1) ► August (1) ► July (2) ► June (2) ► May (1) ► April (2) ► March (4) ► February (4) ► January (3) ► 2020 (33) ► December (2) ► November (3) ► October (2) ► September (4) ► August (5) ► July (2) ► June (3) ► May (4) ► April (2) ► March (5) ► January (1) ► 2019 (18) ► November (3) ► October (2) ► September (3) ► August (1) ► July (4) ► April (2) ► February (1) ► January (2) ► 2018 (17) ► December (1) ► September (4) ► August (1) ► June (1) ► May (1) ► April (1) ► March (3) ► February (1) ► January (4) ► 2017 (21) ► December (5) ► November (2) ► October (3) ► August (1) ► July (2) ► June (2) ► April (2) ► March (2) ► February (1) ► January (1) ► 2016 (34) ► December (2) ► October (5) ► September (8) ► August (2) ► July (3) ► June (4) ► May (1) ► April (1) ► March (1) ► February (4) ► January (3) ► 2015 (12) ► December (2) ► November (1) ► October (3) ► August (1) ► May (2) ► March (2) ► February (1) ► 2014 (13) ► December (1) ► October (1) ► September (3) ► May (2) ► March (1) ► February (5) ► 2013 (24) ► November (2) ► September (4) ► August (4) ► July (4) ► June (2) ► April (1) ► March (2) ► February (2) ► January (3) ► 2012 (10) ► December (1) ► November (5) ► October (1) ► May (1) ► March (1) ► February (1) ► 2011 (11) ► December (2) ► July (2) ► May (2) ► April (1) ► March (1) ► February (3) ► 2010 (22) ► December (2) ► November (4) ► October (3) ► August (1) ► June (1) ► May (2) ► April (3) ► March (4) ► January (2) ► 2009 (22) ► December (2) ► November (5) ► September (1) ► August (3) ► July (1) ► June (3) ► April (1) ► March (3) ► February (2) ► January (1) ► 2008 (27) ► July (3) ► June (1) ► May (3) ► April (4) ► March (10) ► February (6)",
    "commentLink": "https://news.ycombinator.com/item?id=42223690",
    "commentBody": "Antenna Diodes in the Pentium Processor (righto.com)235 points by chmaynard 22 hours agohidepastfavorite38 comments lizknope 20 hours agoI was following this discussion on the /r/chipdesign subreddit when Ken posted there a few days ago. Nice to see that he gave credit and linked to that thread. I'm a physical design engineer that uses software from Cadence and Synopsys to do chip layout of blocks with billions of standard cells. Our flow automatically puts antenna diodes in for all block input pins. Then the tools are usually good enough to breakup internal nets with layer jumping to avoid antennas. Some of the charge also comes from the CMP process. Modern chips have about 20 layers of metal but there are lots of other via layers in between those and then all the base layers with the actual transistors. You want the wafer to be flat before building the next layer. https://en.wikipedia.org/wiki/Chemical-mechanical_polishing reply kens 21 hours agoprevAuthor here: I know this is a very obscure topic, but hopefully it will be interesting to some. Let me know if there are any questions... reply araes 16 hours agoparentReading through, appears this is mostly a manufacturing concern that goes away once the chip is actually active. Correct? The charge buildup goes away, and then there's no further need for the diode antenna. However, second question, does any chip actually use these for anything afterward? Or are these ever built so they actually do something other than simple provide manufacturing protection? Example, they build up charge. So then the charge build up itself is effectively used as some form of remote communication method or channel between various portions of the chip. The diode discharges and in discharging effectively acts as some form of communication transfer. Others, or it serves multiple purposes. One during manufacturing, one after manufacturing? Safety mechanism during manufacturing, and then the charge buildup location is oscillated, purposely charged, or used as a charge outlet for some other reason? Others, Light Emitting Diode is, kind of by the name, a diode. Any of these that basically do blinking communication or something similar? Emits light when the charge breaks down, then that is picked up and used as data transfer? Others, not going into extensively. Tune radio and TV receivers (varactor diodes). Generate radio-frequency oscillations (like actual antennas) (tunnel diodes, Gunn diodes, IMPATT diodes). Basically, anything other than a safety mechanism for manufacturing? reply kayson 14 hours agorootparentYou're correct that these are for manufacturing only. I've never heard of them being used for actual design purposes and that's probably because if you wanted an actual diode, you'd just use a \"real\" one. reply accrual 17 hours agoparentprevHi Ken! Your work is extremely interesting to me and I admire the effort your pour into these articles. It's been very cool to see your die analyses ramp up to more and more complex chips over the years. The Pentium is an especially neat target since it represents a major shift in the x86 architecture towards the modern chips we have today. Never a dull moment when I see a righto link! reply iakov 20 hours agoparentprevYour pictures give insight into such a small world, individual freaking transistors on a CPU chip! Reading textbooks and wiki is one thing, but seeing silicon spliced up and photographed up close is another. Very interesting read, and very well presented too, thank you. reply beenBoutIT 19 hours agorootparentIt'd be interesting to see how big a CPU chip scaled up to be big enough for a human to fit in (were it hollowed out) would end up being. reply namibj 18 hours agorootparentThey're usually 150μm thick. Humans fit in about 300mm thick spaces, so you need 2000x linear scale. reply accrual 17 hours agorootparentprevReminds me of the Monster 6502. Not quite what you're suggesting, but still a large discrete monster of a board. https://monster6502.com/ Instead of a hedge maze maybe we can have VR \"walking through a 8086 or 8088\" chip style maze in the future. reply emmelaich 18 hours agorootparentprevNot to answer your question exactly but ... Chips seem to be around 25mm sq, and the smallest features around 10nm. If you scaled up so the smallest feature is one mm then the chip would be around 2.5km square. (over 1.5 miles on each side) If the smallest feature was about the width of human hair then divide the above by 100. reply dtgriscom 5 hours agoparentprevLate to the show, but this only works because the deposited charge always has the same sign, correct? For instance, if the ions used are positive icons (electrons stripped), the surface elements get positively charged, and the diodes drain that charge to the substrate. But, in operation, the surface elements are negatively charged, so the diodes block. (Right? Or is it the other way around?) reply kens 1 hour agorootparentThe diodes break down nondestructively under the voltage, getting rid of the charge regardless of polarity. During operation of the chip, the diodes are reverse biased, so they have no effect. reply bonzini 6 hours agoparentprevHow are vias manufactured, and why tungsten (I suppose it has something to do with high fusion point?). reply kens 58 minutes agorootparentThey etch holes in the oxide for the vias and then use CVD (chemical vapor deposition) to put a tungsten film over the surface, filling the holes. Then they polish off the excess tungsten with CMP (chemical mechanical planarization). I think there's also an adhesion layer of titanium. I think tungsten vias replaced aluminum vias because tungsten with CVD filled vias better than sputtered aluminum. But then copper vias were used because it has better conductivity and better electromigration characteristics. reply amelius 3 hours agoparentprevAre these structures automatically added by most EDA tools? (If not, why not?) reply jiggawatts 21 hours agoparentprevAbsolutely fascinating! It’s precisely these orthogonal, secondary concerns that make every industry more difficult than people on the outside might think. Articles like yours shed light on these challenges. I’m reminded of a recent project working on a (small!) data warehouse where for the first time in my career I had to not only be concerned with theoretical performance of queries, such as the presence or absences of indexes, but orthogonal concerns such as the time taken to rewrite terabytes of data on disk during night ETL jobs… combining with the “change rate” of the source data. Your article is a similar concern that only specialists in the in the industry are even aware of: it’s not enough to logically route connections — a challenging optimisation all by itself — but there are these competing physical optimisation issues as well that need to be simultaneously optimised! reply rayiner 5 hours agoparentprevThis is amazing! How did you get the pictures? reply kens 1 hour agorootparentI spent a long time with various chemical processes to remove the layers of the chip before discovering that 1500-grit sandpaper works shockingly well. Then I took the pictures with my metallurgical microscope and stitched the images together with a program called Hugin. I wrote a blog post about the process: https://www.righto.com/2015/12/creating-high-resolution-inte... reply raverbashing 12 hours agoparentprevGreat article! > Note that when the chip is completed, every transistor gate is connected to another transistor's source or drain (which provides the signal to the gate) That's a very curious assertion, which made me think a bit more (it feels incorrect at first but on a second thought it looks correct) I would think of \"pure input pins\" but I suppose those have pull-up or pull-down \"resistors\" which in silicon are actually diodes? gateless fets? reply kens 1 hour agorootparentYes, input pins are kind of an exception; the source or drain providing the voltage is external. reply pclmulqdq 20 hours agoprevFun fact about \"antennas\" in chip manufacturing: They have nothing to do with actual antennas. Charge can build up on long wires during manufacturing because the chemicals involved are not neutral and have some interactions with exposed wires. That charge needs to go somewhere to protect the rest of the circuits. There's nothing RF about this. Later technologies (28 nm and below) have extensive design rules around prevention of \"antenna\" effects. reply anonymous_user9 20 hours agoparentI think that’s incorrect. The article and the Wikipedia page on the antenna effect say antenna effects are caused by plasma etching, which uses RF to create the plasma. reply kens 20 hours agorootparentIt's a bit confusing. The plasma is created by RF, but the RF doesn't cause the antenna effect (nor do \"chemicals\"). The charged ions and electrons in the plasma are what cause the charge buildup. The wire acts as an antenna in a metaphorical sense, not a literal sense, as I mentioned in Footnote 3. reply danecek099 18 hours agoprevI'm fascinated by the fact that we study this 31 year old technology and are amazed by the complexity reply emmelaich 18 hours agoparentIndeed! A thought experiment I have some times is to imagine that every machine on the earth was destroyed overnight. We still have mines, people, books. How long would it take to get back to the level of industrialisation and science that would allow us to make (in this case) a 3 million transistor chip? The vast majority of people have little idea of how much intellectual effort has gone into the current state of technology. reply II2II 15 hours agorootparentPerhaps decades. Perhaps thousands of years. It probably depends upon why those machines were destroyed. Look at World War II. European nations and Japan rebuilt relatively rapidly then rapidly built upon progress made during the war. On the other hand, we have the decline of the Roman Empire. While we may now acknowledge that the dark ages weren't as dark as our 19th century peers thought, the western world lost the will or the imagination to rebuild at large scales (which the semiconductor industry certainly is). reply aphantastic 15 hours agorootparentprevIndeed. A lady at a bar in Portland once inquired what I thought humanity’s most advanced technological achievement was, after a slight pause I said the modern microprocessor. She laughed in my face at the suggestion. But when I pressed her for an answer of her own, she refueled to say, instead would only insist that my answer was ridiculous. Odd lady. reply ribcage 6 hours agoparentprevI am pretty sure ordinary people will be amazed by this technology even after a thousand years. reply nine_k 16 hours agoprevWhile the discussion of IC architecture is doubtlessly interesting, I want to praise this page, and other pages on that site, for the photos of the circuits. Not only they are enlightening, they also have really great, soothing color palettes. reply rietta 21 hours agoprevAre the antenna diodes only there to reduce damage during manufacture or is there also impact runtime in an electromagnetic noisy environment? reply kens 21 hours agoparentThe antenna diodes are only relevant during manufacturing, when a metal line is connected on one end but not the other. ESD diodes on the other hand protect inputs against electrostatic discharge when the chip is in use. reply Germont 20 hours agoparentprevThere is a tiny amount of extra capacitance on the net because of the reverse-biased junction of the antenna diode, but that's it. These diodes do get taken into account in when determining timing though. reply neuroelectron 21 hours agoparentprevI thought they were there to allow Van Eck phreaking of the processor state reply accrual 18 hours agoprevVery cool that this would be on the front page after I picked up a Pentium-75 from my local recycler today, it's an SX969. I can hold this chip in my hand and look up to see Ken's die shots. So cool! The ceramic package these Pentiums came in are pretty unique as well - it kind of sounds like setting a piece of glass down when I set the CPU on my desk. reply kens 16 hours agoparentThat Pentium is the 80502, so it's almost the same as the one in my article except that it is built with 600 nm technology instead of 800 nm and it has 200,000 more transistors. It's easy to knock the lid off the package with a chisel if you want to see the die inside. reply Germont 20 hours agoprevNow go look at the need for antenna diodes in SOI technology:) with the substrate no longer the safe haven, a lot more oxides can be exposed to large differential voltages during manufacturing. reply guerrilla 9 hours agoprev [–] Do we have the technology to automate reading of decapped chips so that we can reconstruct the logic, something like \"OCR\"? It seems like such a thing would be hard if it has to deal with all these weird details. reply brennanpeterson 1 hour agoparent [–] It exists, though I don't know of any free or open versions reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ken Shirriff's blog delves into computer history, with a focus on vintage computers and integrated circuit (IC) reverse engineering, providing insights into the complexities of chip design and manufacturing.",
      "In a post about the Pentium processor, he explains \"antenna diodes,\" which protect circuitry from plasma-induced charges during the etching process, a critical aspect of manufacturing.",
      "Despite being released in 1993 with 3.1 million transistors, the Pentium's use of antenna diodes is limited due to space constraints, highlighting ongoing challenges in modern IC design to mitigate antenna effects."
    ],
    "commentSummary": [
      "Antenna diodes in Pentium processors are utilized during manufacturing to prevent charge buildup on long wires, protecting circuits from damage.",
      "These diodes are not functional in the chip's active design, emphasizing their role solely in the manufacturing phase.",
      "The discussion sheds light on the intricate processes of chip manufacturing, including the use of multiple layers and materials such as tungsten for vias, appealing to those interested in chip design and manufacturing."
    ],
    "points": 235,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1732394126
  },
  {
    "id": 42228538,
    "title": "A Career Ending Mistake",
    "originLink": "https://bitfieldconsulting.com/posts/career",
    "originBody": "Jan 14 Jan 14 A career ending mistake John Arundel From Code For Your Life You came for the schadenfreude, but you’ll stay for the thought-provoking advice This isn’t about the time I inadvertently shut down one of Britain’s nuclear power stations, an entirely true story for which the world is nevertheless not yet prepared. Nor is it about the poor junior developer who accidentally destroyed the production database on their first day (they’ll be fine, bless them). Instead, I want to talk about another kind of career ending mistake, one that affects more than just the unlucky few. Indeed, it’s a mistake we’re probably all making right now. And that’s not planning the end of our careers. The end By “the end”, I don’t necessarily mean picking your retirement date. This is really about the aim or goal of your career. Where will you be when you realise that this is where you’ve always wanted to be? If you love what you’re doing now and don’t ever want to change jobs, great: you’ve reached the end of your career, even if it plays out over many decades. If you don’t love it, though, and that’s much more likely, then it’s worth asking what job you would love, and how you’re going to get it. So, where do you want to end up? And is that where you’re currently heading? If not, what should you do about it? Out of control The word “career” means, among other things, “to rush about wildly”, or, of a vehicle, “to move fast and in a way that is out of control”. Isn’t that apt? And doesn’t it describe the career experience of most of us pretty well? The indispensable first step to getting what you want is this: decide what you want. —Saying Most of us, in fact, don’t really know what we want to do with our working lives until we’re more or less doing it. By the time we’ve made our minds up where we want to go, we may already be a long way down the wrong track. It’s not surprising, then, that many of us find ourselves in less than fully satisfying jobs, with doubtful or non-existent prospects for advancement. In all honesty, if we are happy in our jobs, it’s probably more often a matter of luck than of design. Maybe rather than rushing around wildly, we should give a little thought to what we want to achieve in our careers. Rather than just sit back and hope we get the career we want, maybe we should actively plan and take steps to bring it about. As software engineers, we’re constantly making detailed, elaborate plans for computers to execute; that’s what software is, after all. Isn’t it kind of weird that we rarely give a moment’s thought to the program we want to write for ourselves? Choose your destination The best time to start a pension is always twenty years ago, and career planning is a bit like that, too. By the time you realise you need it, you usually wish you’d started a lot earlier. On the other hand, it would be foolish to let that prevent you from starting at all. Even a late, sketchy, and uncertain plan is way better than no plan. So what would a career plan look like? And when should we start making it? The first phase of your career is probably too early to make serious plans, and any decisions you make at this stage are rarely critical: there’s plenty of room to experiment and make mistakes. In the final phase, by contrast, you have fewer options, and there’s not much time to pull off a significant change of direction. The autopilot tends to lock in and steer you further down the glide path you’re already on. You should be planning, in other words, to enter the final phase of your career in the right position, at the right level, and at the right time to land where you want to. So where is that, exactly? Three kinds of careers Your career is likely to encompass lots of different things. Over the years, you’ll do all sorts of different jobs at different companies, and the perfect career destination for you may end up being something you can’t even imagine right now. To help us think about it, though, let’s divide the possibilities, very broadly, into three groups: Seniority Management Independence In the rest of this article, we’ll take a closer look at each of these destination airports, check out the local weather conditions, and ask what kind of flight plan would get us there. So, what kind of career do you want to have? Seniority The first kind of career destination we’ll consider is senior individual contributor (IC), which usually means something like “high-level engineer”. A senior IC doesn’t run their own firm, or work independently. They’re at the top of their game technically, and may be a technical leader for others, but they spend the majority of their time doing the work, not managing other people who do. What does a senior IC do? The exact ranks and job titles for senior engineers vary from one company to the next, and there may be many levels for you to achieve within a given company. But in terms of your eventual career goal, let’s say we’re talking about the top level you can reach while still being primarily an engineer. In a small company, that might simply be something like “senior developer”, or even team leader. In larger companies, the pinnacle of engineering pay and responsibilities might be called something like “principal engineer” or even “distinguished engineer” (sounds good, doesn’t it?). This isn’t an executive position: you won’t have your own washroom, or a seat on the board. On the other hand, you’ll have plenty of money, status, and authority, and unlike your colleagues in management, you won’t spend all day in meetings. You’ll be at the highest level of your profession, and getting well paid to excel at the work you love. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. —Steve Jobs, Stanford commencement address What they don’t do There are a few limitations, though. You probably won’t get to choose what to work on, and you may not agree with all the decisions of the powers that be. In fact, it’s practically certain you won’t. After all, you know more about the subject matter than they do. If, in the end, you can’t live with those decisions, you can go work for another company, but of course you’ll find the same dynamic there. A senior IC role appeals to those who want to stay technical and keep their hands on the keyboard, or at least the mouse. You don’t have the time-consuming, cross-disciplinary responsibilities of a business owner, or the political challenges of a manager. You get to do all the fun stuff: the building and making. And you can do it until you choose to retire—hopefully in financial comfort. How to get there Find out what the situation is where you work. If senior ICs are a thing in your company, talk to them. Ask them for advice. How did they get where they are? What were the steps along the way? And is it what they thought it would be? Talk to your boss. Do they know this is what you want? What are they prepared to do to help you get it? And what will they expect from you in return? Establishing this dialogue is important, but it’s not enough: you need to keep it open throughout your employment. Check in with them often on how you’re doing, and what more you can do to help them help you. Don’t wait for annual reviews. A year is too long to wait to find out that you’ve made no progress towards your career goal. Some people blithely assume that if they keep doing what they’re doing for long enough and don’t screw up, they’ll eventually make senior IC. Well, maybe. But a more reliable strategy is to take personal control of your skills development, and start taking it seriously. Seniority means mastery The most senior engineers in any company are the most accomplished, the most experienced, and those who have the most to teach others. If you want to reach this level, you’ll need to become a master of your chosen craft. Don’t wait for the company to train you. They prefer to promote people who don’t need training. Instead, once you’ve found the craft you love, you’ll need to dedicate yourself to mastering it. Start seeing your current work not as a simple exchange of your time for their money, but rather as an opportunity to find out what you’re good at, and to get better at it. A professional coach can help you figure this out, support your learning, and keep your eye on the ball. Manhood is patience. Mastery is nine times patience. —Ursula K. Le Guin, “A Wizard of Earthsea” Management While very senior engineers can be well-compensated, their roles are usually not the most senior in the company. If you want to rise even higher in pay and responsibility while staying within the firm, you may need to think about leaving your technical work behind and switching to management. Management is perhaps the default destination for many tech careers. Provided you can stay in a company long enough, the natural path to further advancement may be for you to become a manager. If you don’t change direction, in other words, you may end up where you’re heading. But is that where you want to go? What does a manager do? Engineering managers need a solid foundation of technical competence, to be sure, but the work itself is primarily about leading, supervising, hiring, and developing the skills of other technical people. It turns out those are all skills, too, and relatively rare ones. Managing people is hard; much harder than programming. Computers just do what you tell them, whether that’s right or wrong (usually wrong). Anyone can get good at programming, if they’re willing to put in enough time and effort. I’m not sure anyone can get good at managing, and most don’t. Most managers are terrible. That’s quite a sweeping statement, I know. (Prove me wrong, managers, prove me wrong.) But, really, would a car mechanic last long in the job if they couldn’t fit a tyre, or change a spark plug? Would a doctor succeed if they regularly amputated the wrong leg? We would hope not. But many managers are just as incompetent, in their own field, and yet they seem to get away with it. Being a great manager Good managers, then, like good teachers, are rare, but all the more precious for it. If you’ve ever had a really good boss, you’ll remember them all your life, and, if you’re lucky, emulate them. (You’ll remember the really bad ones, too.) And just because managers don’t cut code or solder chips, it doesn’t mean they don’t have a big influence on the success of projects and companies. Indeed, managers can have an outsize influence on events. I’m sure we can all cite examples of promising projects that sank without trace because of a disastrous manager. I’m less sure that there are many examples of inspirational managers rescuing doomed projects from the brink, though it does happen. If you want to become a great manager, which I think is the only kind worth being, start practising now. Learn people skills, communication, collaboration, psychology. Work on understanding the things that make different kinds of people tick. Manage yourself excellently. If you can’t organise yourself, how do you expect to be responsible for a team? Getting started Study your own manager. If they do the job well, figure out why (and talk to them about it). If they’re a shambles, figure out what they’re doing wrong, and decide how you’d do better. A great manager understands what’s happening with each person in their team, and can be there to eliminate problems and roadblocks almost before they happen. Why shouldn’t you start doing this kind of thing right now, rather than waiting to be told? Sometimes the de facto leader of a team is simply the person that everyone turns to when they have a problem they can’t solve on their own. If that’s you, you may already be on the road to becoming a memorable manager—for the right reasons. Independence Being independent means working for yourself, most likely in your own company, and maybe with others working for you, but also maybe not. Just being a one-person company doesn’t necessarily make you truly independent, though. For example, are you a consultant or a contractor? While the client tells a contractor what to do, a consultant tells the client what to do. The difference matters. A consultant is independent; a contractor is not. The pros and cons of independent working Running your own business, or otherwise being an independent worker, is great for those who like it. I do, and I was never really happy working for someone else. I couldn’t wait to strike out on my own. I was probably a pretty mediocre employee for that reason, among others. And there was the little nuclear incident, of course. On the other hand, not everyone wants the hassle of figuring out how to market their business and pitch clients, or the headache of handling accounts and taxes. And not everyone can manage on an irregular, unpredictable income, especially if they have a family to support. You don’t get vacations, insurance, or sick pay. On the plus side, you own a business. When it’s time to leave If you do want to swap your stable job and decent salary for the joys of career independence, the transition needs a little careful planning. It would be unwise, for example, to just quit one day in a fit of pique, then start wondering how you’re going to make rent the first few months. Timing is important. DENPOK: Lao Tzu teaches: the best fighter is never angry. More important than the blow is knowing when to strike. Like, perhaps, after we experience the executive whitewater rafting trip in Coeur d’Alene. —“Silicon Valley” And to make money on your own, you’ll need to be excellent at what you do. There’s no one else to pick up the slack. In a big company, you can learn on the job. When you run your own company, you’d better already know your trade. Testing the waters If you can make the time, it’s a good idea to dip your toe into independent working by doing a few small, one-off side gigs. You’ll gain experience and some satisfied clients, making it easier to go fully independent when you want to. And if it turns out that you don’t enjoy the experience of working for yourself, it’s better to find that out before you rage-quit your job, isn’t it? Of course, we don’t always leave our jobs through choice. Layoffs are a fact of life in a volatile industry. You may not see the rocks coming; companies tend to fail gradually, then suddenly. But an unexpected transition to “funemployment” needn’t be a disaster. If you’ve always dreamed of being independent but somehow never quite worked up the courage to jump ship voluntarily, then being made to walk the plank could be just the spur you need. Making the choice I hope I’ve encouraged you to think about where your career is going, where you want to go, and what you can do to get there. Of course, you may not yet know how you want to spend the bulk of your career. That’s okay, and completely normal. But you can think about it, even if it’s too early to come to any firm decisions. And you’re not limited to just one of these potential destinations: many successful careers combine seniority, management, and independence in some way. For example, you could be a full-time or part-time manager, and also run your own business on the side. Or you could achieve independence by being a roving consultant within a large organisation, while still technically being a senior engineer. Or you could combine all three by being the chief executive and the director of engineering in your own firm. There are many possibilities. Figuring out who you are You can inquire of yourself what things you value, and how your working life could contribute to them. As your experience and knowledge of the world grows, ideas may start to slot into place for you about what you want to do and be. Tell me, what is it you plan to do With your one wild and precious life? —Mary Oliver, “The Summer Day” Your future may not, in fact, lie in the tech industry. That’s all right, too. I have more than one friend who, despite achieving considerable success as an engineer, has decided that this isn’t really what they want to do in the long term. If you want to quit and be a doctor instead, or a schoolteacher, a spaaaaaace engineer, a woodworker, or simply wander the world like a badass righting wrongs, go to it. Don’t waste any more of your one wild and precious life careering down a blind alley. Making small course corrections Once you do have a sense of where you want to go, it can help guide your choices. Even if you don’t know exactly what your perfect job looks like, you may start to feel that you won’t be truly happy until you’re independent, or a senior IC, or a manager. You can steer away from things that would limit your options in those areas, and instead seek out companies, fields, or sectors where you’ll have the best chance of achieving the career you want. That’s not to say you should have a detailed map of every step that you plan to take (“make junior VP by Q4 2035”). As engineers, we already know that a too-rigid plan rarely survives contact with reality. Instead, assume life will throw all kinds of crazy and unexpected things at you. Plan to be flexible, and to change your plans. It’s about the planning, not the plan You can’t stop the waves, as the saying goes, but you can learn to surf. Chance favours the prepared mind. Never underestimate the role of serendipity. The perfect opportunity may show up just when you least expect it, but if you’ve never thought about what you want, how will you recognise it? The time to start planning for the end of your career is now. It’s never too early, and it’s also never too late, provided, of course, that you don’t have your own little incident. Let’s be careful out there. John Arundel career, code for your life Twitter LinkedIn0 Reddit John Arundel John Arundel Cras mattis consectetur purus sit amet fermentum. Integer posuere erat a ante venenatis dapibus posuere velit aliquet. Aenean eu leo quam. Pellentesque ornare sem lacinia quam venenatis vestibulum.",
    "commentLink": "https://news.ycombinator.com/item?id=42228538",
    "commentBody": "A Career Ending Mistake (bitfieldconsulting.com)188 points by gus_leonel 3 hours agohidepastfavorite107 comments equestria 1 hour agoHere's the thing about the average career in big tech: five years after you leave, almost no one will remember you were there. Most of your old team mates will leave for other other jobs. Your code will get refactored or rewritten. Docs will be superseded, then lost in some CMS migration. Before long, it will be as if you have never worked there. I know it sounds preposterous, but ask anyone over the age of 55 or 60: except for folks who built their own companies or made truly exceptional contributions to their field, most will say that hobbies, friends, and family mattered a lot more. So, there is this fundamental contradiction in this article: you can engineer a very neat career, but for most techies, the most useful goal is to make money fast in a way that doesn't drain your life energy. And most of the time, this means responding to opportunities, not sticking to your guns. For example, a lifetime IC job may be ultimately worth less than a management job that gets you to VP level in a decade. You don't need to dream about being a manager; you just need to be reasonably good at it. reply geophile 27 minutes agoparentI am 67, and equestria is mostly correct. I still get great satisfaction from my tech career, but sure, friends and family matter more. This story involves some work I did that did not bring me satisfaction. I worked at my first consumer-oriented tech company, right after the dotcom crash. It was a really unexciting interlude in my career. I was given the job of writing the database and Java representation of credit/debit cards, and the related business logic. As often happens, the code grew over time, as requirements and card types were added. And it was finally time for a rewrite, and this code became a poster child for technical debt. Startup activity resumed, and I left for a far more interesting startup. Then, maybe 15 years later, I was retired, and doing consulting, and ran into a friend from the company, who told me that a new company doing something very similar, and was looking for help. I go in and talk to them, and discover that they actually licensed the software from my former company. Including my long-in-the-tooth credit/debit/xyz-card software. The code was still completely recognizable, disturbingly so. It lived on far past the point that it should have. I decided to not take the consulting job. I really did not relish the idea of going back to this very forgettable and uninteresting code. But most importantly, I had just retired, and wanted to spend my summer on a lake, not keeping this code alive a bit longer. reply frmersdog 54 minutes agoparentprevI think that this speaks to an issue that's common across the economy, not simply isolated to tech: the career lifecycle. Specifically, the notion that there's an optimal amount of time and an optimal point in one's life (both for business and employee) for a worker to be in a given position, and that it's again optimal for him or her to not get there too early and to not stay too long. E.g., tech suffers from the former, politics from the latter, and for both fields, the effect is a warping of the good that they could be doing for society. Society should be set up to encourage \"correct\" entries and exits and to discourage \"incorrect\" ones (with allowances, during the transition, to avoid having a \"lost generation\" that never gets to contribute). Letting people hang on, with their outmoded ideas, into their 70s and 80s? Forcing breadwinners to take on maximum workplace responsibility at the same time that they are most able to contribute to raising their family or building and maintaining their community? There's something perverse about this set-up. To say nothing of the people forced to spin their wheels while the 10xers load their own plates with all the opportunities. reply ghaff 45 minutes agorootparentThe first time I transitioned to a different type of job in tech was really tough but I had been pretty unhappy for a while. I wasn't pushed out--the opposite in fact--which made leaving tougher but subsequent events showed it was absolutely the right decision. The next time, my hand was pretty much forced by any clear-headed view of company financials which made it a lot easier to get on a very interesting (and better compensated) track through someone I had done some work for. At the end I wasn't especially happy but it was around the time I was planning to at least semi-retire anyway so the decision was straightforward again. reply toast0 1 hour agoparentprev> but for most techies, the most useful goal is to make money fast in a way that doesn't drain your life energy. And most of the time, this means responding to opportunities, not sticking to your guns. For example, a lifetime IC job may be ultimately worth less than a management job that gets you to VP level in a decade. If you can switch to management without draining your life energy, go for it? I hope you're a good manager. Personally, all of my experiences managing people have been very draining. reply paxys 1 hour agorootparentExactly. If making good money without taking on too much stress was the goal, my advice to everyone would be to become a senior/staff IC at a decent company and stay in that role till retirement. reply skeeter2020 59 minutes agorootparentprevDraining but also rewarding? I think work is supposed to be hard and tiring - seems like most things of value are - but if it sucks your life force permanently that's not a good thing. I've found management is a bit of a muscle that can be worked and you increase your energy reserve with time & practice. Similar to being an IC I've found it's fear that drains the most, and building a perspective of \"I don't know exactly how to do this (nobody really does) but we'll figure it out.\" has been immensly valuable. reply toast0 1 minute agorootparentI can see how it could be rewarding, but it wasn't for me. Since I don't need to do and don't enjoy it, and other people are better at it, I can leave it for someone else and be thankful my circumstances allow for that. reply njtransit 33 minutes agoparentprevThis argument assumes that code is an ends not a mean, which is false. The value you deliver is not your code, it’s the enablement of business functions. Let’s say you launch a new product that gains traction. Sure, in 5 years your code may be refactored out of existence. But the people doing the refactoring only have jobs because of the value you delivered when launching the initial product. That is your lasting contribution, not the lines of code you wrote. reply Attummm 49 minutes agoparentprevI have to disagree with your premise. The goal of many software engineers is to build software / systems they can be proud of. They love software and the machines it runs on. Many people here have Arduino projects, 3D printers, home servers, and similar hobbies. A few weeks ago, I was looking for compression algorithms for a particular use case and came across Brotli[0]. I was surprised to learn it was developed by Google. That realization hit me hard. Google used to be a hub for this kind of innovation. Projects like Brotli aren't built to maximize personal profit; they're driven by passion and a genuine love for software engineering. It's clear that the industry is shifting from being geeky and nerdy to being more business and management focused. [0] https://github.com/google/brotli reply tokioyoyo 24 minutes agorootparent> The goal of many software engineers is to build software / systems they can be proud of. Maybe for peopleIt's clear that the industry is shifting from being geeky and nerdy to being more business and management focused. I've heard this same complaint for the last 30 years, probably starting with this - Bret Hart helps you debug a null pointer dereference: https://www.youtube.com/watch?v=HSmKiws-4NU reply K0HAX 19 minutes agorootparentJust because you've heard it for 30 years doesn't mean it's not still true. Some things move at a glacial pace, and I see it too. reply billy99k 10 minutes agoparentprevVery true. I saw comments in the code base where I work from someone that had worked there 3 years prior. Most of the people I asked could barely remember the person. reply tdeck 1 hour agoparentprevTo me this seems to make a strong case for focusing more on relationships at work with people and less on work products. I still remember people I worked with 10+ years ago though I have no idea if the code they wrote then is still in production. reply arp242 20 minutes agoparentprevFor my previous job some stuff is public, and I can see it's still being used as it gets commits. I left about five and a half years ago. For the non-public stuff I wrote a lot of the foundational code, and I'd be surprised if all of that that been replaced. reply donatj 49 minutes agoparentprevEven in small tech. I worked for an agency in the aughts and we would put up websites at roughly the pace of 1 a week. In my time there I'd guess I'd personally built a little over 100 websites and developed our internal framework for us to make doing so easier. Every couple years since, I've gotten a bug in my butt and investigated how many sites still had pieces I'd clearly worked on. On this most recent occasion, I could no longer find anything. They've changed over to some open source CMS and I was unable to find anything I had built. It's been 12 years in there since I left, but as far as I can see on the front side everything I'd written is gone. It's a strange feeling, like 5 years of my life just evaporated. reply mathattack 40 minutes agorootparentThe code may be gone but not the impact. A gas station sells gas that is gone within weeks. But someone fills their car, and drives to Mountain View and gets a job that changes your life. Helping a business grow by 10% more each year because they were an early adopter to websites is something you impacted, even if your code isn’t there to remind people why. “All we are is dust in the wind.” (Kansas and Ecclesiastes) reply Retric 4 minutes agorootparentThat feels true, but a single gas station disappears and people fill up somewhere else. The world isn’t a static place. The impact is often closer to saving X thousands of people a few seconds than anything more meaningful. Perhaps the indirect result is someone finds the love of their life but it could just as easily be a life changing STD or getting run over and impacting many people means many such indirect changes both positive and negative. reply mgkimsal 42 minutes agorootparentprevI left a project in 2003. I can still hit their web login page, and I still see something specific in the URL I put there. I've no doubt they've upgraded some stuff behind the scenes, but they've likely not done huge overhaul, otherwise they'd have simply redone the auth process to whatever an upgraded system uses. They did change some graphics on the login page, and added a google tag thing, and converted some styles to css. Very odd to look at it and know that I'm probably one of 2 or 3 people who know why that specific code is there, and also to know that the base of this is still running. reply codingdave 1 hour agoparentprevI don't find that to be true. I remember many of my co-workers... some fondly, some not, but they are remembered. They added as much flavor to my life as my family and friends, if not more, because we spent more hours together. Their work influenced mine and I learned from them. And their insights helped direct which directions we took the projects. Now, did our presence impact the company? Did our code survive? Or documentation? Do people who work there today have any idea we ever existed? No, perhaps not. But really... who cares? The relationships we have with people in our lives matter, as do the impacts we have on each other, regardless of what our impact was on some rando corporation I earned a check from some number of years ago. reply skeeter2020 58 minutes agorootparentOne of the constants in this field is the people; I've continued to work with the same individuals in various environments and configurations for decades - often intentionally. reply groestl 1 hour agoparentprev> almost no one will remember And that is true for all memory, I suppose. There is none. It's constant communication, down to the quantum level, a constant vortex of information, and if the vortex stops, all memory is gone. reply boredtofears 1 hour agoparentprevThere's no guarantee your code will be rewritten or refactored. I have code written over 15 years ago that I know is still in production because it is stable and core to the application. I suppose one day it probably will be replaced but I'm pretty satisfied with that piece of work and found it to be, if anything, more life affirming than draining. You can have your cake and eat it, too: if your work is satisfying and seeing people use the things you built gives you joy, you can make good money doing something you life without optimizing your entire life solely around ladder climbing or bigger paychecks. reply mjr00 1 hour agorootparentyeah, if anything it's dangerous to assume that your code will get thrown away soon-ish. as an extreme example I'm aware of, the core AWS infrastructure is still heavily dependent on Perl scripts mashed together 15+ years ago. reply derefr 56 minutes agorootparent> core AWS infrastructure is still heavily dependent on Perl scripts mashed together 15+ years ago What part of the infrastructure? The control-plane logic that triggers when the dashboard/CLI/CloudFormation request modifications to resources? reply mjr00 33 minutes agorootparentI never worked with it directly so this may not be totally accurate, but IIRC a lot of the fundamental networking code for managing data centers -- DNS, traffic routing, etc -- was legacy Perl scripts. While I was there, at least one major us-east-1 outage was directly linked to a problem with one of these scripts. reply paganel 1 hour agoparentprevThe problem with that is that it drains away your life energy in your late 20s and throughout your 30s, and in fact it's not only about draining one's energy, let's say that would be fine up to a point, but it drains away your purpose in life, and, in the end, your will to live. I refuse to believe that there are people whose purpose in life is to be a manager/VP, and, if they are, they might as well be walking corpses for all I know. reply mjr00 1 hour agorootparent> I refuse to believe that there are people whose purpose in life is to be be a manager/VP, and, if they are, they might as well be walking corpses for all I know. You could say the same thing about ICs though -- \"I refuse to believe there are people whose purpose in life is to spend 5 days a week for 3 years building an enterprise line-of-business app to automate an obscure legacy business process that will be used by 10 people in total, and all 10 of those people will complain about the new app and wish they could go back to doing things the old way\" reply ponector 1 hour agorootparentAnd as VP you can make a ton of money and spend it wisely, make a difference to your extended family or even a community you live. That is a real meaning and sense of purpose for your earned money! reply paganel 1 hour agorootparentprevThe very fact of calling \"computer programmers\" as \"ICs\" is part of this syndrome, I'm not sure exactly when it started showing up, I'd say it was popularised by FAANGs, so maybe 2015-2016-ish? reply mjr00 40 minutes agorootparentICs aren't just computer programmers, they're designers, sales, marketing, customer support, etc. It's just an easier term for people who aren't managers than \"not a manager\". reply Ancalagon 56 minutes agorootparentprevIs IC offensive? I’ve never considered it to be. “Resources”, on the other hand, feels very offensive. reply frmersdog 51 minutes agorootparentWell, taken at face value, it is a bit of an oxymoron. To contribute is to be part of a group; by definition, a contributor can't be wholly independent, because they're adding to a corpus, not producing it by themselves. reply sokoloff 1 hour agorootparentprevI've heard the term (or \"individual contributor\") since at least the first dotcom boom in the late 90s. reply analog31 1 hour agorootparentprevI've noticed that the successful ones have exceptional self discipline, part of which is not letting it affect your life as a person. Also, from their body language as observed through office windows and meeting rooms, they're spending a lot of their time socializing. reply CooCooCaCha 1 hour agorootparentprevThe only way I know how to deal with this is FIRE. Investing as much as possible and working towards early retirement or semi-retirement so that you can at least live a good chunk of your life. The world we live in still sucks away the best years of your life but at least you don't have to wait until your 60s to live the life you want. You can also work on side projects in your spare time that will hopefully accelerate this process. This should be doable on a tech salary. reply stego-tech 25 minutes agoparentprevYour argument, while valid, also kind of misses the point of the original post: to know where your career ends, you also have to know what the general trajectory looks like. Basically, you cannot \"coast\" ever upward \"naturally\" anymore, because we've learned that's a bad concept (hence the term \"failing up\"). We pressure people into management roles who have no reason being there other than \"that's where more money is\" or \"that's how you create change\". If someone's \"end state\" is a highly competent and flexible IC, then why isn't there more money for them to continue succeeding at that role as compared to an ineffective manager? For all the talk that tech is a meritocracy, it obviously isn't, otherwise we'd be rewarding the best talent without forcing them into bad roles or hollow titles. Motivations aren't restricted to money alone, either, as we've seen post-pandemic with the WFH-RTO conflicts. A plurality of workers have realized their time is more valuable than their work, and are refusing to take chump change for multi-hour commutes from affordable suburbs just because their employer is arbitrarily demanding butts-in-seats in a pricey city. Others want their employers to be more involved in politics, or at least acknowledge that choosing to be a for-profit business is in fact a political statement in and of itself; hiding behind faux-neutrality in times of crisis isn't sufficient response anymore. The times are a changing, and the workforce is increasingly making its frustrations known. Which brings me to your last paragraph: > ...for most techies, the most useful goal is to make money fast in a way that doesn't drain your life energy. I would like to proudly stand up as one of those not in that \"most techies\" crowd. I do this work because it comes easy to me, is incredibly interesting, and allows me to work in infrastructure in a way that isn't building roads or laying pipe. I identified my career ending way back in High School: acting as the jack-of-all-trades IT guy for the school or district, grey hair and hoarse voice, gradually nerd-sniping the kids who, like I was, are bored out of their skulls and looking for a challenge. The money certainly helps (even if it's not nearly enough to buy a home close to the office), but my career begins and ends in ultimately the same place. And that's the point of the post: identifying where your career ends, and the arc it takes to get there. It's why I'm doing the leadership courses and trying to beat a new path upward in the corporate world, one where highly-competent ICs who are also good leaders are recognized as such and put into long-term positions within an organization, to weather the storm of cyclic leaders and fickle shareholders, and ultimately build a stronger, successful, and sustainable entity as a result. I need those years/decades of leadership and money to reach that position where I have a paid-off home, decent retirement savings, and can finally dedicate my remaining time and talent toward building a better future for the next-generation of people. reply derefr 59 minutes agoparentprev> Your code will get refactored or rewritten. Docs will be superseded, then lost in some CMS migration. Before long, it will be as if you have never worked there. The exception is if you build a fundamental component of the system, and that component is so unique in what it does that nobody who comes after you will even consider the idea of ground-up reimplementing it, but instead just has to immerse themselves into your mindset, trust your docs, etc, whenever they're maintaining that component, forever. --- The bad/painful version of this, is when the component relies on unique hardware (e.g. a mainframe's native IO-acceleration capabilities), and was designed by someone who was immersed in that ecosystem and understood how to write code to take advantage of it. So the code is incredibly non-portable, written in terms of the low-level abstractions of the hardware, that nobody else in the company will ever understand to the same level the original programmer did. This is e.g. flight booking. You should hope to never encounter these, since they make the rest of your service that has to interact with this thing into a tar pit of low momentum, from your lack of ability to effect change on this component. -- There is a good version of this, too, though: when the component relies on unique concepts and math (say, doing static analysis by generating constraint statements and solving/simplifying them using a prover) that are portable, and could in theory be reimplemented in a new codebase if desired... but which were literally invented by the programmer in the process of implementing the code, at the climax of months of lateral thinking about how to solve the problem. This is an engineering True Dweomer. There's usually nothing wrong with codebases containing True Dweomer code; they're not any less maintainable than usual. And they solve a problem that isn't solvable with simpler solutions — that's why such a weird solution was arrived at in the first place. So they usually tend to stick around. But everyone who arrives at the company will nevertheless be slightly afraid of touching the True Dweomer code. They don't understand it, even though they know they could understand it given enough time (and prerequisite textbook reading.) Unlike mainframe code, people might look fondly on the code, looking for opportunities to be assigned to a project that requires that they come to grips with it... but the project usually ticks along by itself, not requiring much maintenance. (What you'll actually hope for, is that whoever writes the True Dweomer code requests to lift it out, out of whatever project it's a part of, out of the company itself, into an open-source project. Because that way, that person who does understand it, can keep maintaining it, even after they leave.) reply paxys 1 hour agoprev\"What do you want to be?\" is a question we have all constantly been asked since middle school by parents, teachers, career counsellors, professors, recruiters, mentors, managers, HR and lots of other well meaning souls. My answer is the same at 40 as it was at 14 – I don't know. And you know what? I've been fine. I have worked at some great companies, and some not so great ones. A couple FAANGs as well as a 20-person startup and everything in between. I have been part of some fantastic product teams and a fair number of disasters. I have been a code monkey, an architect, a tech lead, a staff engineer, a manager, a director...and now know that none of these fancy titles really mean anything. And throughout all this I have managed to put a decent chunk of money in the bank. Most would consider my career to be pretty successful. I like to say that I don't really have a career but simply jump from one project to the next and one opportunity to the next depending on how the wind is blowing. Never once have I had any semblance of a \"plan\" or a \"goal\". And despite what all the authority figures in your life will tell you, that is a perfectly fine way to live and be happy. reply piecerough 6 minutes agoparentHave you had a common theme for these projects you navigated? reply rakejake 44 minutes agoparentprevI'm happy to hear this. Cheers. reply analog31 1 hour agoparentprevA friend of mine, who is quite successful in his occupation, told me that his motto is: \"Always do the next thing.\" Our culture possesses this weird belief, that people always need to be transformed. This cuts across all ideologies, ranging from religion to Marxism and corporate culture. I think simply declaring \"bullshit\" to that belief can lead to a much happier life. reply tossandthrow 2 hours agoprevThis approach to careers fails to take into account that we inherently change as people. In periods of ones life other things matters - maybe it is taking an education, starting a family, etc. Other periods work matter. It should be entirely fine to switch it on and off and change tracks throughout life - and in my view it seems like it is! To reach a peak it takes roughly 10 years, but these 10 years can be started at 40 when your kids does not wear diapers anymore. reply rakejake 54 minutes agoparentI don't think the OP is talking about whether to focus on running the race or not, but rather which race to run. As you grow older, the number of open tracks diminishes and that is the point the OP is trying to make. While one can change tracks at any time, success is far from guaranteed. Being a distinguished engineer at 40, one cannot suddenly decide to enter the track for CFO or CEO. The track for that accepted entries 10 years back and is already over-subscribed. Only the CTO track is open at that point and only in certain companies. reply tossandthrow 13 minutes agorootparentI don't think the number of open tracks diminishes. But I do think we generally focus. When one is 55 it is probably not too interest to attempt to go into the race to become and investment banker. Not because it is inherently impossible, but because there are more interesting opportunities. Or at least: I think this narrative is the most productive, and the one I will stick to. reply mettamage 59 minutes agoparentprevWell said: I think in this sense, flexibility is key. reply mckn1ght 0 minutes agorootparentAs well as knowledge of, and honesty with, oneself! reply la64710 1 hour agoparentprevAnd also I want to acknowledge everything that ends our career is not in our control .. like the dual forces of global offshoring / outsourcing and relentless automation (including AI driven) will continue to put downward pressure in the career curves of tech workers for next few years/decades. reply tonyedgecombe 1 hour agorootparentIt's interesting that the common sentiment on HN a couple of years ago was the polar opposite of that. I lost count of the number of comments that affirmed the boom was going to go on forever. Software was eating the world, etc. reply mettamage 1 hour agorootparentSoftware is steal eating the world, just not for employees. But we will integrate with tech more, as a society. I wonder where brick and mortar stores will be in 20 years. reply coldcode 1 hour agoprevI never intended to have a career as a programmer. I planned to work for two years, save a bit of money, and get a PhD in Chemistry. Forty years later I retired as a programmer. Every step was something new, I had 15 different employers (plus myself for 9 years starting two little companies). There was never a plan beyond finding a better/different/less irritating job, and constantly improving what I could do. I never gave any thought to what I wanted to end my career on. It actually ended entirely as my decision, I still was at the top of my ability, and my employer was happy to pay me, but I was tired of working. While planning might work for some people, having a more short term view can work for others. The only thing I could ever control was what I was able to do, and when I was ready to move on. There are many optimizations available to succeed in life; not all are obvious. reply yodsanklai 53 minutes agoparent> While planning might work for some people, having a more short term view can work for others One thing I noticed is that what I valued in my 20s wasn't what I valued in my 30s and 40s. It's difficult to anticipate who you will be in a few years from now. It may change drastically. Keep that in mind when planning! reply mettamage 58 minutes agoparentprevCould you describe how each job hop was less annoying than the less? I know it’s a big ask. I am just insanely curious to know. reply fallinditch 1 hour agoprev> Most managers are terrible. A sweeping statement indeed, but it does reflect my experience too. Perhaps it's my ingrained deference to authority - when I start a new position I tend to believe that my manager has my best interests at heart. This is a mistake and I now believe it's better to maintain a kind of defensive attitude and to always be assertive in establishing, and if necessary negotiating, the responsibilities and expectations of your role and your relationship with the manager. This may not necessarily be a personal failing on their part, this may just be a consequence of the operational management system you both work within. reply ptero 57 minutes agoparentJust as a personal data point, most managers I had in my now 25-year career in tech were good. They set clear goals and expectations, provided honest feedback, both positive and negative, and quickly jumped to help re-plan when things did not work out. They were also asking what I am optimizing for (for me at different times it was more money; promotion; interesting problems to work on; time to explore other long-term products) and as far as I could tell worked with their managers to move me in that direction, sometimes successfully, sometimes not. I did not assume any of my managers had my best interest in heart, but one of my first managers gave me some lessons on \"how to manage your managers, myself included\". It took a few iterations, but he convinced me that by far the #1 thing most managers want is for me to deliver things on time; not cut a few days off the project timeline. And if I learn to do that, they will advocate for my interests, shield me from corporate BS, etc. Some specific advice from that manager was (in his words) \"never promise something in 2 weeks unless you could demonstrate it today\" and \"do not sit quietly when you are given unrealistic timelines; counter with specific subtasks you see and how long you expect each will take\". That general advice worked very well for me and helped build symbiosis with direct managers. I did dislike a few managers, but those were generally good ICs stuck into a management role they did not like (or at least did not know how to do) and kept both sticking their fingers into what their team was doing and start timeline discussions with \"it would take me one day to do this, I will give you two; go-build-this-now\". Again, just a personal data point; not claiming that most of the world works this way. I may have been just lucky. reply yodsanklai 44 minutes agorootparent> Some specific advice from that manager was (in his words) \"never promise something in 2 weeks unless you could demonstrate it today\" and \"do not sit quietly when you are given unrealistic timelines; counter with specific subtasks you see and how long you expect each will take\". Thanks these are good advice. > most managers I had in my now 25-year career in tech were good. I didn't have tons of managers, but my experience as well. Of course, they have their own interest in mind, rather than mine, but in my case at least, our interests were more or less aligned (completing projects, not burning out or leaving the team, working on things that matter to the company, avoid conflicts...). reply mjr00 1 hour agoparentprev> A sweeping statement indeed, but it does reflect my experience too. IMO - managers are terrible at the same rate as ICs. But the damage a terrible IC can do is limited in most companies because there's guardrails like automated testing, pull requests, no access to the production database, etc. At worst they end up being a big timesuck for other team members until they get let go. A terrible manager will sink a project or team single-handedly, though. reply noirbot 1 hour agorootparentThere is no code-review process for management decisions. Management is essentially like writing code on the production server all the time. The stakes are maybe a little lower, it's a good bit harder to make disastrous mistakes, but there's no real roll-back or testing for if you're about to ruin your team. reply lifeisstillgood 38 minutes agorootparentBut why isn’t there a code review process for management decisions? What if code was how decisions were recorded ? What if companies were programmable ? reply AnimalMuppet 23 minutes agorootparentWhat if there were no hypothetical questions? That is, you can ask hypothetical what ifs all you like, but unless you have a concrete plan for getting there, you're just writing fantasies. And, management decisions get reviewed before implementation all the time. It's just not a code review, precisely because management decisions are not code. Why aren't they code? Because people aren't computers. If you're going to treat them like they are computers, then I don't want to work in your company. reply kstrauser 1 hour agoparentprevI think that’s largely due to the weird notion that engineers will eventually “upgrade” to management, as though one is the advanced version of the other. There are whole degree programs dedicated to managing and organizing people, but we’re like, “nah, Joe’s a good programmer so we should talk him into stopping that so he can supervise people instead”. Fact is, there’s little relation between the two. A person may happen to be good at both, but expertise in one does not imply adequacy in the other. reply cocoto 1 hour agorootparentNot every programmer can be a good manager, but no non-programmer can be a good manager on a programming project. reply kstrauser 56 minutes agorootparentThis is objectively and demonstrably untrue. I’ve had very good non-technical managers. Part of the requirement is them knowing they’re non-technical so they can stay out of the way and concentrate on the PM bits, rather than micro-managing. reply BurningFrog 1 hour agoparentprevOTOH, this can be a case of the \"if everyone around you is a jerk, the jerk is really you\" rule. If you can't work well with any manager the common denominator is you. It's also the only thing you can change. reply dbish 22 minutes agorootparentThis. I’ve known many an engineer who thinks their manager is bad because they don’t do what this IC (who has never been a manager or knows that is happening at the company above them) would do. The kind of people who think Elon is a bad CEO. Results are what matters first and foremost in tech reply noirbot 1 hour agorootparentprevThe difficulty is the small sample size. Most people won't have a ton of different managers in their career and you'll change over time and your role will change over time and want/need different things from your manager. There's also a lot of selection bias. What many people point out in these threads is that the sort of people who desire to be in management, and the sort of skills selected for in managers often don't align to what more ICs would actually want out of their managers. Managers are often hired by other managers and not by the managed, so the skills that get you the job often aren't aligned to what would make them good to work for. reply SoftTalker 30 minutes agoparentprevPeople rise to their level of incompetence[1]. This simple principle explains most managers completely. [1] https://en.wikipedia.org/wiki/Peter_principle reply tonyedgecombe 1 hour agoparentprevMy first manager was really good so it came as quite a shock when the next one turned out to be a lying, conniving bastard. Given enough experience you get hardened to it. Of course it would be better if you didn't need to. reply andrewaylett 1 hour agoparentprevWe train people in their technical role, but we (generally) don't train people to manage -- and years of poor experience don't count. I'm not a manager, and I don't want to be. But I'm quite happy with the manager training that my employer puts people through before giving them direct reports. One should always be negotiating expectations, though, even when one considers management to have our best interests in mind. And also remember that your manager is learning how to manage from you. You get to shape their experience of being a manager, and you get (to an extent) to guide them in how they grow as a manager. reply hobs 1 hour agoparentprevAs a person whose done it all, independent stuff, senior ic stuff, management stuff, the main thing that makes management terrible is simply that most companies have no support for middle managers. You are a good IC? Sure let's promote you to management, but in 95% of cases, we're not even going to pair you with anyone or have a senior manager help you understand, build and grow - we're going to throw you in the deep end and have you sink or swim. This often ends up with stressed out people used to doing well now approaching an entirely new problem with slow feedback loops and entirely different protocols than before, and the amount of burned out shitty middle managers I see is off the charts. reply hn72774 59 minutes agoprevThe end of my career is uncertain. My entire career has been uncertain. Not completely unplanned, but rather has progressed in ways I could never have predicted. I had luck and opportunity to ride the cloud computing wave and it carried me into software development and distributed analytics systems, from a B.A degree in business. 20 years of lateral moves up to Sr. Level, but never outside of IC, yet. I daydream about turning my DIY skills into some type of construction trades business while I am physically able. Or testing the waters with software consulting. Manager role is not appealing working for someone else's company although just like construction trades, being an apprentice in that role is probably going to be the best way to learn it. I dread the meetings and politics and employee reviews. But if I really want to run my own business, at some my point I may need to be a manager on someone else's payroll. Even if just for a year. reply negus 11 minutes agoprev> Lao Tzu teaches: the best fighter is never angry. More important than the blow is knowing when to strike Seems like a fake citation https://www.taoistic.com/fake-laotzu-quotes/fake-laotzu-quot... reply tschellenbach 2 hours agoprevIt's not true that in all companies you have to chose between tech and management. It's true in some companies. But at many companies lead and director roles are very hands on. At Stream a lead is 80% technical, a director roughly 50% sometimes more. And even VPs and up are still somewhat technical. I think the idea of management without technical excellence track is just misguided. Small teams, technical excellence, and leaders who can do the work is the right way. reply stoneman24 1 hour agoparentI agree that Managers/Directors should have a deep technical experience but having them contribute code to the day to day development is not a good situation for anyone (especially the companay). There are some different aspects to this; The director will have many other responsibilities and may not be able to provide to provide the research/expertise required to produce a good code solution to the issue at hand and integrated with the rest of the system. The rest of the project team may be delayed with waiting for the directors code and may well find it difficult to co-ordinate with the directors level of knowledge (which is perhaps out of date). In general, criticising the director for delay or bad code is not likely to be a career-enhancing path. In small company/start-ups, this a common condition that does need to be remedied. Directors/managers have significant responsibilities that needs to come first rather than feed their own ego/desires. Hire good people and direct them to scale the business, your job is different now and you need all your skill/time/resources to do it well. In short, personally been there a number of times and it wasn't good for anyone. But we struggled on. reply f1shy 2 hours agoparentprev> It's not true that in all companies you have to chose between tech and management. It's true in some companies. But at many companies lead and director roles are very hands on. I‘ve seen bad companies where it is true, but in good companies typically not true. Look for example Peter Norvig, 100% hands on technical type, but in a high management position. reply leeoniya 2 hours agoparentprevthere is a difference between \"technical\" and \"writing code every day\". c-levels, VPs, and directors can be very technical, but rarely write code. team leads definitely do, though it may be only 3 days a week, and rest is org/planning/pr reviews. only at small companies does the CTO write code. our cto has written plenty of deep code back in the day that enabled the business to scale to its current size. reply creer 1 hour agoparentprev> management without technical excellence track is just misguided It's different technical excellence. What's not given proper weight is that it's different technical excellence. Roles seen as \"more management\" demand system-level understanding and technical knowledge. And a technical knowledge that includes what many see as not technical such as awareness of people or finance dynamics. They can, should be seen as technical aspects. A more senior, \"more management\" role has different levers to use to make projects come through. And these are different higher level projects. A more senior role is also free to juggle reports who specialize in this or that. If you hate or you are bad at task scheduling, have someone do that for you. If you are not great at writing speeches, etc, etc. Among the ways you can prepare for that: (1) find at least one mentor (someone at least two steps more senior who can guide you on what to think about and on how things work. If the people two steps up in your company are bros... your mentors don't have to be in your same company.) (2) Consider what's missing to your skillset - and that's not planning software but maybe it is. reply madeofpalk 1 hour agoparentprevThere is also a difference between being a capital-L Leader, and leadership. Healthy companies have space for technical leadership that is different from being on the management track to being CEO. reply Sytten 1 hour agoprevMaybe I am a pessimist but I really don't believe you can plan for 20y in the future especially in the tech sector. People fail to realize that we live in a world that changes not in a linear fashion but rather exponential. For all we know in 10y we will only need 1/5 of the coders we have and IC won't be viable, who knows. reply snozolli 1 hour agoparentIMO, there's no such thing as a career in tech, outside of maybe FAANGs (or whatever they're called now). It's just a series of jobs until accumulated wealth, ageism, or disability ends it. reply mupuff1234 1 hour agorootparentThe public sector is probably a decent place for a well defined career. reply mahmoodz98 2 hours agoprevAs someone who has fallen into this trap myself, I feel like many people tend to just go with the flow and then end up in a place they don't like doing work they don't enjoy, with no idea how to get out. This has inspired me to approach my manager about possibly stepping down from my role into a more IC role, or possibly swapping jobs, as I realized a Senior IC is where I want to be reply hcrean 2 hours agoprevThis article assumes a lot more self-determinism than is available in practice to most people. Beyond that many of us have been running on fumes for years, I can't lose ten extra hours every week away from seeing my family, so I can up-skill for a new variation on the same career with ultimately the same bull. reply __turbobrew__ 5 minutes agoparentIf your goal is to get a cushy high paying job you will need to make sacrifices, otherwise that job would no longer be cushy and high paying. Some sacrifice their 20s and grind an education, career, and have no kids or spouse. Others put a large burden on their spouse to retrain, you have to weigh the short term toil versus the amortized improvements over your career. And it is important to remember that luck plays a part as well. Some get lucky on their first go around and others never get luck in life. The only thing you can do is maximize the number chances you have for good luck. It is important to live well within your means. Having an extra margin makes job and life changes much easier and lower risk. Many people’s expenses grow to their income and they paint themself into a financial corner. Unfortunately once you are in that spot it becomes much more difficult to get out, and larger sacrifices need to be made. There are always options, and we have more opportunities and “stuff” than any other generation which has lived. Our stuff and jobs should serve us and not the other way around. reply foogazi 1 hour agoparentprevWhat if it’s an article for self-determined people ? Or meant to plant a seed of thought in someone’s mind ? > I can’t lose ten extra hours every week away from seeing my family I hope you find the time to make it work for you. And , I don’t want to assume but so have found “I can’t” attitudes don’t work for effecting change in life. Maybe work on that aspect of your personality. reply mathgeek 1 hour agorootparent> And , I don’t want to assume but so have found “I can’t” attitudes don’t work for effecting change in life. I personally subscribe to framing “I can’t” as “I will not”. Then you can view such things as the conscious choices they are. You can also avoid feeling forced to do things just because they are expected of you. E.g. “I can’t give up time with my kids” vs “I will not give up time with my kids”. reply snozolli 1 hour agorootparentprev\"Here, drink this Flavor Aid. If you don't like it, it's a personality defect in you.\" reply syndicatedjelly 1 hour agoparentprevWhat kind of advice would have been better? reply loup-vaillant 34 minutes agoprev> You probably won’t get to choose what to work on, and you may not agree with all the decisions of the powers that be. In fact, it’s practically certain you won’t. After all, you know more about the subject matter than they do. Wait a minute if the people most suited to make a decision are overridden by people less competent than them (they have to be most of the time, given the different focus of their career), that's kind of a problem, isn't it? Is there any way to avoid such structural failures? reply rakejake 9 minutes agoparentLess competent in what? The people with decision-making power are supposed to be good at some combination of product innovation, product management, sales, marketing and accounting. ICs are only suited to making some decisions in the first two, and have next to zero expertise in the others. reply rakejake 1 hour agoprevYes, I do find that a lot of people get caught in whatever race they started running in the beginning of their careers and don't care to stop for a bit and try retrospecting/introspecting. I recently took a break from work with the intention of working on some side projects and also thinking about what it is I like to do (somewhat along the lines mentioned in the article - do I want to stay on my current trajectory and try to hit senior IC, management etc). I am only about 6 years into my career, perhaps a bit early for a sabbatical but I felt this was the right time for it. I had a pretty good reputation in my job and I could have done the thinking while on the job, yet I felt I couldn't. I am helped by not having any financial concerns or other responsibilities. I am not sure what I expect to gain from this though most people assume that either I must be starting my own business or chilling at home although neither is true. I took care to put some structure into it so I don't while away the time scrolling HN. I don't think I will get a sudden epiphany but feel if I put in some hours without any external constraints, something might happen. The worst that could happen is that I have to write off this time and go back to running the race in my IC track. reply giantg2 1 hour agoprevJoke's on them. I have a job, not a career. reply mettamage 1 hour agoprevI feel the discussion needs to be opened up to other ends of careers. My favorite career end that I'm naturally working towards to is the ability to jop hob to different roles without having prior experience. One way to do that is to be able to show in an interview that you have transferable skills and learn crazy fast. Another facet of that is that you need to identify companies that are open to this sort of thing. Another career end is to become rich and not work. It's not achievable for everyone of course. But it is a type of career end. Other career ends that one becomes disabled and live on disability checks or welfare. To me, it seems that this is a career end that people want to avoid. I feel digital nomads aren't really represented in this career end. You could put it under independence, but the characterization of independence in this blog post was quite narrow which is why I feel the need to state it explicitly. Some people are in their career end when they can just work remote 4 days and have a decent salary. There are many more career ends, what could you come up with? reply ChrisMarshallNY 2 hours agoprevI have found that I can't actually plan with much certainty, and, quite often, the very worst thing that can happen, is that Everything Goes As Planned. I have found utility in \"overengineering\" my life. Not just the tech I do, but in most things, and creating small, robust, high-Quality, and adaptable structures. Things that can be rearranged, and repurposed, when (not \"if\") the context/paradigm changes. I started maxing out my retirement in 1990, and that's a good thing, because, in 2017, when I finally started looking for work, I was surprised (and disgusted) to find that no one wants to hire us olds. I wasn't planning to retire, but I wasn't consulted by Reality. In my work, I have found utility in writing in modular fashion, and making every module as high-Quality as possible. I've had to toss quite a few, and had to do substantial refactoring on some, but, for the most part, they have served me very well, and continue to do so, to this day. reply inglor_cz 2 hours agoparentIn a similar fashion, I try to address all sorts of corner cases in my code, to the point of being called obsessive by some colleagues - but it definitely helped a few times with really stubborn and obscure bugs. An extra log line here or there, or an e-mail sent to the admin in weird situations, goes a long way - provided that you don't generate many false positives, because no one pays attention to a program that cries \"binary wolf\" too often. reply tonyedgecombe 1 hour agorootparentIt's always surprised me how many people are happy with somewhat sloppy work, doing just enough to solve a particular issue. Most of the time it doesn't even come from management pressure, it's just the way people work. Perhaps there is something wrong with me but I always want to dot all the i's and cross all the t's. reply yawnxyz 1 hour agoprevPlans are worthless, but planning is everything. It's not entirely clear that much of this field will look the same in five years, but still, I think doing the thinking and the planning for the sake of mapping out the route is important. If only to inform you that no, you don't want any of those routes. (I did this planning and ended up in academia/microbiology, as a product designer, for better or worse but it's been fun) reply AnimalMuppet 1 hour agoparentMy wife asks me from time to time: \"What do you need to learn now for the next five years of your career?\" It's a great question. It is also, I think, the right time frame, though one could argue for three years instead of five. Given the terrain I see now, I can plan for the next five years, and have those plans be mostly reasonable most of the time. Past that is harder. reply OutOfHere 2 hours agoprevOn the contrary, it's those who can't write code that become managers. They're not even good enough to ascend to the truly parasitic executive class. reply itronitron 40 minutes agoparentAnd those who can't manage people become managers of managers. reply dfedbeef 24 minutes agoprevThe mistake I see people make it _not_ ending their career out of narcissism, pride, ego, etc. I am not a religious person but it is good to remember you will die. You should have some better stuff to put on your tombstone than your job title. People aren't going to care who you were in 100 years and people aren't going to remember you in 1000 years. Your tombstone will crumble in the dirt. Spend time with people you love, spend time with your family and friends. Find meaning without economic strings attached. reply dfedbeef 22 minutes agoparentOh and by the way: you might die sooner than you think. It happens all the time. Are you spending time the way you want? reply mlhpdx 2 hours agoprevI prefer the journey. I don’t want to “be” independent, I want to “become” independent. The former is winning the lottery, the latter is a long and difficult path. reply applied_heat 1 hour agoprevI am curious about how he accidentally shut down a nuclear reactor. reply moffkalast 45 minutes agoprev> career ending mistake > the time I inadvertently shut down one of Britain’s nuclear power stations There is a scram joke in there somewhere ;) reply readthenotes1 1 hour agoprev [–] I have advised multiple people in their 50s that they are no longer seeking a position, they are looking for a decent paying job. Career progression should be dominated by FIRE... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article emphasizes the importance of planning the end of your career, focusing on achieving career goals beyond just retirement.",
      "It outlines three potential career paths: Seniority (becoming a senior individual contributor), Management (transitioning to a managerial role), and Independence (working for yourself).",
      "The text stresses the need for self-reflection, skill development, and flexibility, encouraging readers to actively plan their career paths and remain open to change and unexpected opportunities."
    ],
    "commentSummary": [
      "In the tech industry, contributions can quickly become obsolete after departure, as code is rewritten and documentation is lost.",
      "The post suggests prioritizing financial gain and personal well-being over a rigid career path, highlighting management roles as potentially offering more long-term value than individual contributor positions.",
      "Emphasizes the importance of adaptability in career paths and suggests that relationships and personal satisfaction often outweigh career achievements."
    ],
    "points": 188,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1732463794
  },
  {
    "id": 42228759,
    "title": "Howstuffworks.com creator, Marshall Brain, has died",
    "originLink": "https://www.wral.com/news/local/nc-state-marshall-brain-dies-november-2024/",
    "originBody": "NC State faculty member, website creator Marshall Brain dies A North Carolina State University faculty member and creator of the popular website \"How Stuff Works\" has died. Updated This is a modal window. No compatible source was found for this media. NC State faculty member found dead in office WRAL staff A North Carolina State University faculty member and creator of the popular website \"How Stuff Works\" has died. Marshall Brain died inside his office Wednesday on N.C. State’s centennial campus. While the university would not confirm any details related to his death, sources close to Brain said he died by suicide. The N.C. State Police Department said it is no longer investigating, and foul play is not suspected. Brain contributed several articles to WRAL.com over the years, including an editorial piece. He’s also author of \"The Doomsday Book: The Science Behind Humanity’s Greatest Threats.\" Get Help: County-by-county guide to mental health and crisis resources in NC If you're having suicidal thoughts or a mental health crisis, call or text 988 or call the National Suicide Prevention Lifeline at 800-273-8255. Veterans can press “1” after dialing 988 to connect directly to the Veterans Crisis Lifeline. For texts, veterans should continue to text the Veterans Crisis Lifeline short code: 838255. © 2024 Copyright Capitol Broadcasting Company",
    "commentLink": "https://news.ycombinator.com/item?id=42228759",
    "commentBody": "Howstuffworks.com creator, Marshall Brain, has died (wral.com)146 points by bsagdiyev 2 hours agohidepastfavorite32 comments monocasa 1 hour agoI'm going to use this time to drop the Marshall Brain work that had the biggest impact on me, and is some of the most prescient speculative fiction I've read. Manna: Two Views of Humanity’s Future He contracts two societies. One is a dystopia where AI very, very similar to today's ML models is integrated into society as a replacement for the middle class, removing social mobility as well as acting as a panopticon lower management, and centralized social credit system. The other society uses the similar technology not as a social class moat, but as a tool to form a synthesis with all members of their culture and and unlock new levels of individual freedom. https://marshallbrain.com/manna1 reply simpaticoder 1 hour agoparentVery cool story, quite impactful on my thinking, although I will caution that the dystopia is better conceived than the utopia, mainly because the later requires inventing fantasy technology while the former does not. Indeed it's not clear at all what forces might destabalize the dystopia, since the power structures are immortal and self-replicating, and physics and biology (at least) prevents the utopia from existing. Maybe an asteroid or a caldera explosion? In fact I would love to read a sequel where the dystopia wins and AI-empowered oligarchs and human wage slaves create generation ships to nearby stars and eventually setup fast food restaurants in every corner of the galaxy. reply marcosdumay 1 minute agorootparentThe only clear distinction between the utopia and the dystopia is on wealth distribution. All the rest of it is a narrative about consequences. Anyway, the AI there isn't like our LLMs either. It's an AGI capable of long term societal prediction. reply monocasa 31 minutes agorootparentprevWhich physics and biology prevent the utopia from existing? reply bhhaskin 9 minutes agorootparentWell for starters having the technology for prefect recycling. reply nazgulnarsil 29 minutes agorootparentprevAccelerando reply yrral 54 minutes agoprevWow, when I was a kid back in the early 2000s, howstuffworks was my favorite website. I bet I read every article on how various things work (there were many hundreds). I found that the knowledge from that website helped me understand how everything in the world worked and satisfied my curious mind. I attribute my knack for understanding new things and fixing things to this website. Back then, the site was clean and had very good clean and expertly written explanations of how various mechanical, everyday and scientific equipment worked. Nowadays that website is not the same, seems riddled with SEO spam and fluff articles like a content mill. Rest in Peace Marshall Brain, thank you for all your contributions to my (and likely others) life reply idealism 13 minutes agoparentSame here! In my teenage years HowStuffWorks.com was one of my favorite websites. It was a treasure trove of fascinating information. I remember at one point feeling like I had read pretty much the whole site and would check back every couple of weeks or months to see what new had been published. The site surely helped develop my young mind to be curious about many disparate subjects, a very useful and important life-skill. RIP Mr. Brain reply gothink 1 hour agoprevWow, this is very tragic. I was actually just reflecting on the influence Howstuffworks.com had on my life and interests. Quick story: My first introduction to programming was building a Geocities website in HTML (using notepad, of course) at a science camp in 1999. They also showed us the \"How HTML Works\" web page as a resource, which became my first technical resource. I remembering struggling with something on my website and eventually emailing my question to Howstuffworks, not expecting much back. Not only did a very patient and informative woman respond to me, she continued to answer my questions and offer helpful guidance to this very eager kid for the rest of the summer. Without that positive experience, who knows if I would have stuck with it. It's been on mind a lot since I just realized that was 25 years ago. I hope Marshall knew how much people valued the things he created and the impact they had. reply schiffern 1 hour agoparentMarshall Brain also wrote many programming books in the 90s era. https://en.wikipedia.org/wiki/Marshall_Brain#Publications reply bn-l 52 minutes agoparentprevThis makes me nostalgic for the small internet. reply FlynnCruse 1 hour agoprevMarshall was one of my closest Mentors through college. Truly heartbreaking to hear of his passing. I wish his family; wife and kids, the best through this tragic period. He inspired me daily with his dedication to his students, incredible work-ethic and love for entrepreneurial engineering. My life is forever changed for having met and been mentored by Marshall, I cannot express enough gratitude for the time I got to spend with him. Rest in Peace Marshall Brain, a real-life legend. reply panoply220 23 minutes agoparentSame! I owe so much to him. Heartbreaking and forever grateful for the time we got to spend together. reply lwhalen 2 hours agoprevHe was also the author of https://marshallbrain.com/manna, a sci-fi story that has stuck with me for years. reply ryoshu 1 hour agoparentVery relevant in the age of smart glasses for workers. reply chgs 35 minutes agorootparentI was think about the software some companies use to “monitor productivity” reply BadHumans 1 hour agoprevGiven the amount of dystopian content he was posting on his website and subreddit lately, he seemed to be despairing quite a bit regarding the direction of society. reply schiffern 1 hour agoparentI noticed that. He made several subreddits, here's a (likely incomplete) list. https://news.ycombinator.com/item?id=42224139 His commentary near the end of this interview is also telling. https://www.youtube.com/watch?v=BA5v2cfJp1o An optimist in (increasingly) a cynic's world. Be at peace, Marshall Brain. reply StephenSmith 15 minutes agoprevI just wanted to highlight that he was also an entrepreneurship professor at NC State and shaped many students' views of what they could do with their lives. I was one of those students. I now own my own company as a result of his teachings. He was very influential and a wonderful human being. This news is tragic. RIP Marshall. You were loved. reply goodmunky 46 minutes agoprevHe was 63 and wrote this a few years ago, “You’ve Had Your Turn –The Case for Euthanizing Everyone at Age 65” https://marshallbrain.com/youve-had-your-turn-the-case-for-e... reply panoply220 31 minutes agoprevI shared this on the other HN thread, but I spent some time revisiting the HowStuffWorks c 2001, and highly recommend as a catharsis and reminder of the web as it once was: https://web.archive.org/web/20010202064900/http://howstuffwo... reply nisten 1 hour agoprevSpent hours in highschool printing stuff out of howstuffworks.com because dialup at home was too slow until we got dsl :( May he rest in peace. reply Horffupolde 34 minutes agoprevWhat happens with domains, content, etc now? Is there a systematic way of preparing and securing online services for death? reply raphman 2 hours agoprevDuplicate (different submitted link, however): https://news.ycombinator.com/item?id=42222387 reply bckr 1 hour agoprevOh, this is very sad. I was really inspired by his essays and stories when I was 17. I wonder what was happening with him. reply Mistletoe 1 hour agoparent> Marshall Brain died inside his office Wednesday on N.C. State’s centennial campus. >While the university would not confirm any details related to his death, sources close to Brain said he died by suicide. :( Marshall was a frequent poster in subreddits such as /r/collapse. https://www.reddit.com/user/MarshallBrain/ I don’t think it’s hard to see what things concerned him. I think it’s important for all of us to realize that no matter how we think the world is going there is still brightness in the world and Marshall contributed to that brightness through his contributions to society. reply bckr 57 minutes agorootparentI wondered. How dark. reply joemazerino 12 minutes agoprevSad to hear a brilliant man decided to take his own life. He seemed increasingly dark on his later takes, and it's a testament to the evils of unrestrained high-IQ and no guard rails. reply willio58 1 hour agoprevVery sad, just a reminder that success doesn’t translate to happiness. The podcasts that came out of HSW.com have heavily influenced my life. Especially Stuff You Should Know (still a top 20 podcast but no longer owned by How stuff works. I remember 16 years ago going through the whole rigmarole of downloading the podcast on my white MacBook, syncing to my iPod, repeating each week so I could keep up with the episodes of SYSK coming out. Fast-forward to today I still listen to each episode religiously and have learned so much from Josh and Chuck. reply readthenotes1 50 minutes agoparent\"success doesn’t translate to happiness.\" I suspect that the pursuit of happiness, without the capture, leads to success. Or perhaps a strong avoidance of the fear of failure (iirc, that was a common motivation for Olympic athletes) reply yarg 1 hour agoprevAs someone who has pulled himself back from suicidality, I absolutely abhor the expression \"died by suicide\". If I had gone through with it, I would have killed myself - and any euphemisms being thrown around would serve no-one at all (especially not those still living in that hole). I would much rather have it framed as me having done something unforgivably stupid and completely preventable - but as a society we'd much rather reject that reality and instead refuse to acknowledge that more often than not the signs were all there; that not only was the death an irreversible act of idiocy, but it was also something that we could've and should've stopped yet did nothing to prevent. reply blackeyeblitzar 2 hours agoprev [–] Sad to hear. This is an amazing resource that many curious people have grown up with. It alleges here that he committed suicide. It makes me extra sad that someone who gifted others with so much found themselves in that place. Dang - deserves a black bar? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Marshall Brain, the creator of Howstuffworks.com and author of the speculative fiction \"Manna,\" has passed away, leaving a significant impact on many through his work.",
      "He was a professor at NC State University, where he influenced and shaped the futures of numerous students.",
      "His passing, reportedly by suicide, underscores the critical importance of mental health awareness, while his legacy continues to inspire curiosity and understanding."
    ],
    "points": 147,
    "commentCount": 32,
    "retryCount": 0,
    "time": 1732466347
  }
]
