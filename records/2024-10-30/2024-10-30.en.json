[
  {
    "id": 41992314,
    "title": "Australia/Lord_Howe is the weirdest timezone",
    "originLink": "https://ssoready.com/blog/engineering/truths-programmers-timezones/",
    "originBody": "Australia/Lord_Howe is the weirdest timezone Timezones are weird. But only finitely so. Here's the exact conceptual model you should have of them. Ulysse Carion X GitHub Cofounder and CTO, SSOReady The standard trope when talking about timezones is to rattle off falsehoods programmers believe about them. These lists are only somewhat enlightening – it’s really hard to figure out what truth is just from the contours of falsehood. So here’s an alternative approach. I’m gonna show you some weird timezones. In fact, the weirdest timezones. They’re each about as weird as timezones are allowed to get in some way. Asia/Kathmandu has a weird offset from UTC Africa/Casablanca doesn’t fit into the timezone model cleanly, so it’s hard-coded America/Nuuk does daylight savings at -01:00 (yes, with a negative) and Africa/Cairo and America/Santiago do it at 24 o’clock (not 0 o’clock) Australia/Lord_Howe, population 382 and some notable stick bugs, has the weirdest daylight savings rule To learn how their weirdness is represented in software, we’ll look at the raw timezone files that all software ultimately relies on. From there, two things will become clear: Yeah, this stuff is weird But only finitely so, because ultimately a computer’s gotta implement them But first, an aside on the calendar. PGXIIREAM: Pope Gregory XIII rules everything around me Unless you’re doing some fairly exotic things where you’re finding yourself saying things like Oh yeah the OCR on Japanese driving licenses pops out things like “平成 8”, that’s just how they sometimes say 1996 over there. That’s why we have this in the parser: eras = { \"大正\": 1912, \"昭和\": 1926, \"平成\": 1989 } One of these days we’ll need to add \"令和\": 2019, but it hasn’t come up yet. or We’re gonna need to set up a per-country feature flag when deciding whether banks are closed for Eid. Saudi Arabia and Iran don’t agree on when the lunar month starts. Then yeah, sure, you may need to write software that knows about the Japanese or Islamic calendar systems. Cases like this are a small minority. The reality of the world is that the Western system of timekeeping is the dominant one, and even in e.g. Japan and the Muslim world, almost everyone who uses computers is familiar with the Gregorian system. With computers, we project the Gregorian system into the future and past, which is called the proleptic Gregorian calendar and isn’t historically accurate but nobody really cares except Russian revolution nerds. This calendar system is pretty much good enough, and barring any rationalist coups d’etat, is the one we’ll be stuck with for a long time. It does one thing well: it’s very good at keeping the sun at the same place in the sky across the years. It doesn’t let the months drift around the seasons like the Roman calendar did. Technically, this “keep the sun roughly in the same place whenever it’s the same time-of-day” is called “mean solar time”. And that’s why GMT, Greenwich Mean Time, is called that way. It’s about the mean solar time of the English observatory in Greenwich. By the way, we technically don’t call it GMT anymore. Unless you’re talking about what time people in London say it is, you probably technically mean UTC. Coordinated Universal Time is basically just a modern formalization of GMT. It’s useful because almost everyone on the planet has agreed to base their clocks off of an offset from UTC. It’s still a solar mean time, but the connection to Greenwich isn’t really there anymore. I bring this up because you may have heard of a weird modern quirk on Pope Gregory’s sun-following endeavors: Leap seconds don’t matter The Earth’s rotation is slowing down. Days are getting longer. So you need to correct for it if you want to keep IRL days in sync with computer days. The nerd task force assigned to this problem is the International Earth Rotation and Reference Systems Service, which has two primary goals: Watch the Earth rotate, and report back on their findings Break Wikipedia’s CSS with their long name timecops If the days are getting longer, and they’re doing so at a fairly unpredictable rate, the simplest solution is to have IERS occasionally just insert an extra second in the day to make clocks go slower. It’s called a leap second. You should completely ignore the fact that this is a thing. It’s a cool novelty, but it’s effectively just a detail you can ignore, because: It’s not like programming languages support representing 61-second minutes anyway You (and by you I mean your cloud provider) can just run your clocks slower around the time of the leap second, and pretend to everyone else over NTP that their clocks are running fast. This is called leap smearing. Btw it’s called UTC (Universal Time Coordinated? huh?) because the same folks who publish UTC also publish UT1, which is UTC sans the leap seconds. There were other UTs before the Coordinated variant came up. Weird time zones OK! Let’s start looking at some weird time zones, and find out how your computer knows to represent them. Asia/Kathmandu is on a weird offset Most of the world is on a whole number of hours before or after UTC. About a fifth the world by population is on a half-hour offset from UTC; in particular, India is 5h30m ahead of UTC. Nepal is 5h45m ahead of UTC: $ TZ=UTC date ; TZ=Asia/Kathmandu date Tue Jul 30 23:52:11 UTC 2024 Wed Jul 31 05:37:11 +0545 2024 If you’re like me, you must be have at one point wondered how in the world your computer knows this fact. Here’s a hint: $ TZ=Asia/Kathmandu strace -e trace=openat date ... openat(AT_FDCWD, \"/usr/share/zoneinfo/Asia/Kathmandu\", O_RDONLY|O_CLOEXEC) = 3 Wed Jul 31 05:40:49 +0545 2024 On your filesystem is a database called the IANA Timezone Database, aka tzdb or zoneinfo. It’s a bunch of binary files, encoded in Timezone Information Format. The names of those files act as timezone identifiers, which is where you see strings like America/Los_Angeles or Europe/London come from: $ tree /usr/share/zoneinfo ... ├── America │ ├── Los_Angeles ├── Europe │ ├── London ... At the very end of /usr/share/zoneinfo/Asia/Kathmandu is this little string: cat /usr/share/zoneinfo/Asia/Kathmandu ... -5:45 The syntax is here pretty obtuse, but what it means is: Unless otherwise specified, UTC is 5h45m behind this timezone. Call this time +0545. That’s precisely how software can figure out the time in Nepal. That’s also why the output from date above has +0545 in it. Why strings like PDT or CET are pretty meaningless In the example above, +0545 is called a “designator”. It’s a pretty-ish string describing which part of a timezone a timestamp is in. It’s meant to be used for outputting timestamps, and is only unambiguous if you already know what timezone the timestamp was taken in. Just how ambiguous are these designators? I wrote a tzdump script that converts TZIF files to JSON. Here’s the top hits: find -L /usr/share/zoneinfo -type f \\xargs -n1 ./tzdump \\jq -r '\"\\(.ID)\\t\\(.Transitions[].LocalTimeType.Designation)\"' \\sortuniqsort -k 2uniq -f 1 -csort -nawk '{ print $1 \"\\t\" $3 }'tail -r The most popular designators are: 66 CST 58 CDT 56 CET 56 CEST A total of 66 timezones use CST, either in the past or future. Many timezones are functionally exact clones of each other – there’s no difference between America/Phoenix and America/Creston, but they each get their own file – but still. There’s a lot of ambiguity in there. In case you’re curious, only 33 designators are unique to a timezone. A lot more are functionally unique, but I’m too lazy to dedupe logically-equivalent timezones right now. As an extra fun bit of trivia, designators are not strictly uppercase/numeric. ChST, appearing in Pacific/Saipan, stands for Chamorro Standard Time. It’s the only designator with a lowercase name. CHST is not taken, sadly for those of us who love bugs. How are timezones with DST represented? When we looked at Kathmandu, we had this string telling us the Nepalese time rules: -5:45 Ok, simple enough. But what about a timezone with DST transitions? The syntax has lots of defaults (DST will be a one-hour jump, it happens at 2am by default, etc) but Europe/Athens is a good example of one that uses most of the syntax: $ cat /usr/share/zoneinfo/Europe/Athens ... EET-2EEST,M3.5.0/3,M10.5.0/4 That syntax means: Standard time is called EET, it’s 2 hours ahead of UTC. DST is called EEST (it’s 3 hours ahead, an implicit default relative to standard time). Start DST in month 3 on the last instance of (5) day 0 (Sunday) in that month, at 3am local (/3). End DST on month 10 on the last Sunday at 4am local (5.0/4). So yeah, your computer does a bunch of kind of gnarly logic to figure out what date-and-time a timestamp corresponds to, then figures out whether it’s inside or outside DST to figure out the current local time. Delightful. In case you’re curious, the spec says “5” means “last instance of”, and “1” means “first instance of”. But only weeks “1”, “2”, and “5” are used: $ find -L /usr/share/zoneinfo -type fxargs -n1 ./tzdumpjq -r 'if .Rules.DST == null then empty else \"\\(.ID)\\t\\(.Rules.DST.Week)\" end'sort -k2uniq -f 1 -cawk '{ print $1 \"\\t\" $3 }' 18 1 89 2 81 5 Here’s a fun twist: on my Mac 100% of timezones either don’t have DST at all or use this nth-instance-of-day-of-month rules to do DST switching. But inside /var/db/timezone there’s different versions of tzdb. In there is a version with other kinds of timezones in it: $ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/Africa/Casablanca ... XXX-2-1,0/0,J365/23 That timezone basically means “we are perpetually on daylight savings”, because the J### syntax means “###-th day of the year, not counting Feb 29 if there is one” (J stands for “Julian calendar”). Technically, that timezone also exercises the prefixless (i.e. without M or J) syntax for indicating days, where ### means “###-th day of year, counting any Feb 29”. But in this case it’s a distinction without a difference. (Aside: All this stuff comes from POSIX. GNU’s docs about the POSIX TZ env var, which TZIF builds on, are the best I know of online for this stuff.) But this is just the start of the weirdness that is Africa/Casablanca. Africa/Casablanca and Asia/Gaza follow the moon, but timezones follow the sun The TZIF format supports three possible rules for deciding on your daylight savings transition day: Rules like “first Tuesday of March” Rules like “45th day of the year” Rules like “45th day of the year, Feb 29 doesn’t count” Morocco and Gaza do their daylight savings based on Ramadan. Ramadan is a month in the Islamic calendar. The Islamic calendar is based on the moon. The lunar calendar isn’t a clean multiple of the solar calendar; from the Gregorian perspective, lunar months seem to slowly “rotate” around the year, because they’re basically on a different modulo. There’s a problem there for our heroes at the tzdb. The solution? The dumbest possible one. A TZIF file ends with the footer syntax we’ve been talking about to this point. But it starts with a big long list of historical data about a timezone. If a country ever changes timezone rules, TZIF represents that by encoding the new rule in the footer, and hard-coding all the old transitions. But you can also just take these hard-coded transitions and put them into the future. The hard-coded transitions take precedence over the footer. So the TZIF folks: Picked a year far enough into the future (2086, as it turns out) Wrote a script in emacs lisp to calculate Ramadan Use the output of that script to generate transitions for Morocco and Gaza And that’s why in practice Morocco and Gaza are just hard-coded in the tzdb, unlike every other timezone. In case you’re hoping for more fun timezones like this, I’m afraid you’re out of luck. The others at the bottom of this list, which filters for transitions beyond 2025, are just synonyms of Casablanca and Gaza. $ find -L /var/db/timezone/tz/2024a.1.0/zoneinfo/ -type fxargs -n1 ./tzdumpjq 'select(.Transitions[].TransitionTime > 1735689600).ID' -runiq -csort -n 26 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Cairo ... 26 /var/db/timezone/tz/2024a.1.0/zoneinfo//US/Pacific 26 /var/db/timezone/tz/2024a.1.0/zoneinfo//WET 26 /var/db/timezone/tz/2024a.1.0/zoneinfo//posixrules 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Casablanca 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/El_Aaiun 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Gaza 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Hebron It looks like every other timezone just has 26 transitions beyond 2025, which I think are just there to make software that doesn’t know about the TZIF footer transition rules be accurate a few years into the future anyway. America/Nuuk transitions to DST at -1 o’clock Nuuk is in Greenland, and is part of the greater EU cinematic universe. All of Europe (idk whether this is an EU/EEZ/EFTA/CoE thing) syncs up their daylight savings, except for Iceland, which doesn’t do DST at all (Atlantic/Reykjavik, which is technically an alias for Africa/Abidjan, is basically just UTC; their rule string is just GMT0). Most Europeans are familiar with three major timezones, which we can refer to as Europe/Lisbon (western), Europe/Brussels (central), and Europe/Athens (eastern). They’re each one hour ahead of the other, and so their timezone transitions look like: # I'm gonna space these out to highlight the symmetry, # and also spell out the implicit \"/2\" Europe/Lisbon: WET0WEST ,M3.5.0/1,M10.5.0/2 Europe/Brussels: CET-1CEST,M3.5.0/2,M10.5.0/3 Europe/Athens: EET-2EEST,M3.5.0/3,M10.5.0/4 In other words, Lisbon springs forward at 1am, Brussels at 2am, and Athens at 3am. But those times are local. In reality, they’re all at the same instant. This makes good sense. It’s good for business that the time difference between any two spots in Europe is always the same. Greenland would like to be part of the action. Thing is, Greenland is pretty far west of continental Europe. Whereas Lisbon’s standard time is UTC, Greenland’s is 3 hours behind UTC. Here’s their daylight transition rules: $ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/America/Nuuk 2,M3.5.0/-1,M10.5.0/0 Take note of M3.5.0/-1. The first part is the standard European DST start day. The /-1 part? That means that instead of doing DST at like 2am (/2), Greenland does it at -1 o’clock (/-1). The way the rules file is encoded, daylight savings for Greenland is meant to happen on Sunday, but in fact happens at 11pm on the Saturday before. Super weird. I’m guessing this breaks software, because America/Nuuk and its aliases are one of those timezones whose transition rules are just entirely ommitted in /usr/share/zoneinfo on my Mac. They’re only available in other copies of tzdb in /var/db/timezone. Oh, America/Santiago and Africa/Cairo transition at 24 o’clock Nuuk is the earliest anyone does a transition. Santiago and Cairo are the latest. They both do transitions at 24 o’clock? Like, the next day? America/Santiago: 4,M9.1.6/24,M4.1.6/24 Africa/Cairo: EET-2EEST,M4.5.5/0,M10.5.4/24 I think they’re both encoded like that because of weirdness in how the governments define the rules. Like M10.5.4/24 means “last Thurday of October, 24 o’clock”, which really means “the day after the last Thursday of October”. But that’s not the same thing as “last Friday of October” if the month ends on Thursday? Both of these files are also in Mac’s list of naughty timezones that don’t go in /usr/share/zoneinfo. Australia/Lord_Howe has the weirdest DST transition When you do a DST transition, you “spring forward” and “fall back”. Surely everyone agrees it’s a one-hour jump, right? Here’s a script to check. What is the time difference between standard and daylight time in every timezone? $ find -L /usr/share/zoneinfo -type fxargs -n1 ./tzdumpjq 'if .Rules.DST == null then \"\\(.ID)\\t0\" else \"\\(.ID)\\t\\(.Rules.DST.LocalTimeType.UTCOffsetSeconds - .Rules.Std.LocalTimeType.UTCOffsetSeconds)\" end' -rsort -n -k 2uniq -c -f 1awk '{ print $1 \"\\t\" $3 }' 410 0 2 1800 185 3600 1 7200 Hmm. 410 timezones just don’t DST at all. 185 have a 3600-second, i.e. 1-hour, difference. And then there are the malcontents. The 7200-second, i.e. 2-hour, jump is Antarctica/Troll. Fitting. 0-2,M3.5.0/1,M10.5.0/3 So during the winter (i.e. the northern summer) they use Norway time? But there are like 6 people over the winter at Troll? Do these 6 souls appreciate their contribution to software esoterica? I hope they do. Apparently they use like four different times during the year down there in practice, but there’s no syntax to express that. OK but the real question is what’s up with the two 1800 transitions. They’re synonyms for each other. It’s Australia/Lord_Howe, which has a powerful 30-minute DST transition: -10:30-11,M10.1.0,M4.1.0 10h30m ahead of UTC standard, 11h DST. Love this for them. Running cron jobs on an hourly basis doesn’t in practice have very weird interactions with DST. Everywhere else on the planet, every 60 minutes you’re back to the same spot on the clock. Except Lord Howe Island. Heroes. On the first Sunday of October, a 60-minute timegap only puts you halfway around the clock. All your cron jobs are now staggered relative to the local wall clock. In case you’re curious, Lord Howe Island belongs to Australia. It has 382 people at the latest census. It’s a bit of a natural paradise, and apparently to preserve that there’s a cap of 400 tourists at a time. Probably the most famous aspect of Lord Howe is Ball’s Pyramid. Ball's Pyramid Memorial for Stickbugs and Software Engineers who write Timezone-related Code. It’s an old collapsed volcano. It looks cool. It has some rare stick bugs. Big takeaways Timezones are weird, but finitely so. All they consist of is: An ID, e.g. America/Los_Angeles A set of hard-coded transitions, which range from the past into the future A set of rules for how future transitions may happen Any given time in a timezone is just: An offset from UTC With a “designator” time that doesn’t mean much (This usually isn’t outputted anywhere) Whether the time is considered DST You can always uniquely identify what UTC time someone is referring to whenever they tell you their timezone + local time + current time designator. The timezone + designator gives you an offset, and you can apply the offset to the local time to get UTC. Like, it’s weird, it’s quirky, but it’s not like all bets are off. Also: Don’t let people bully you into thinking that just because something is complicated, it’s impossible. This is because almost every standard (except ISO8601, whatever) is just a file, and you can read it. You are smart. You can do it. Embrace the weirdness of Greenland’s daylight savings. Believe in yourself. If I were UN secretary general, I would kick out any countries that I deem insufficiently considerate of Paul Eggert’s time. Appendix: Other weird stuff in zoneinfo Honestly, there’s some stuff in zoneinfo that I can’t figure out. Even I have nerd-sniping limits. Exercises for the reader. These time zones have hundreds of hard-coded transitions out into the future. I don’t understand why, it’s not like they all have lunar calendar stuff going on. Asia/Jerusalem has 780 transitions in the future, out of 901 total Africa/Cairo has 800 transitions in the future, out of 929 total America/Nuuk has 800 transitions in the future, out of 889 total America/Santiago has 800 transitions in the future, out of 931 total Pacific/Easter has 800 transitions in the future, out of 911 total Asia/Gaza has 982 transitions in the future, out of 1106 total They all lack a rules footer, but our friend Africa/Casablanca has a mere 132 transitions hard-coded and lacks a rules footer too. What’s up with that? P.S. If you’re the type of weird to think this stuff is neat: email me. ulysse.carion@ssoready.com ;)",
    "commentLink": "https://news.ycombinator.com/item?id=41992314",
    "commentBody": "Australia/Lord_Howe is the weirdest timezone (ssoready.com)816 points by noleary 12 hours agohidepastfavorite333 comments kccqzy 2 hours agoThe most amusing tidbit about the tz database is that it contains an estimate of Big Bang, and it refuses to calculate timezone transitions occurring before the Big Bang. The commit message at https://github.com/eggert/tz/commit/b22d459a367f4d01b10f6f6b... says: > For example, Glib computes Sao Paulo time stamps as if Brazil's circa-1913 rules were still in effect. (Thanks to Leonardo Chiquitto for reporting the bug.) Work around the bug by not generating time stamps equal to -2**63. Come to think of it, time stamps before the Big Bang are physically suspect anyway, so don't generate time stamps before the Big Bang. Soon afterwards, a separate commit disallowed leap seconds before the Big Bang. reply ucarion 1 hour agoparentThis is really neat! Separately, I'm a little skeptical of the tzdb's endeavor of even thinking about pre-Unix-epoch stuff. The bug-to-utility ratio of that stuff doesn't seem to be there. `zic` is where most of the ugly gnarliness of tzdb lies, and I sometimes feel that it would have been better if `zic` weren't an artifact others could depend on. reply guidedlight 11 hours agoprevNah, the weirdest time zone is Africa/Addis_Ababa, which nobody in Ethiopia follows. Instead the locals offset the time by 6 hours. So the AM cycle starts at dawn (i.e. 6am), and the PM cycle starts at dusk (i.e. 6pm). https://en.wikipedia.org/wiki/Time_in_Ethiopia reply wakahiu 5 hours agoparentThis is common across East Africa, including Kenya where I’m from. The night ends at 6:00AM, with 7:00AM being saa moja (first hour) of the day. Similarly, the day ends at 6:00PM (thenashara). Intuitively, this clock makes much more sense than the English clock. There’s rarely confusion between times because it’s embedded in the language. reply spuz 4 hours agorootparentWhat time is displayed on your phone when you are in Kenya? Is there a setting to make it display the commonly used time rather than the official time? I'm going to Kenya next year and I'm excited to see how my phone behaves. reply nine_k 4 hours agorootparentprevThis is indeed a more logical clock, as it follows the natural cycle of activity. Equally, calendars that put the end of the year at the time after harvest (\"autumn\"), or at the start of agricultural work (\"spring\") are also more logical. Positioning the beginning of a new day at noon, and a new year t a solstice, is just a technical convenience, because these are easy to detect with very simple astronomy tools. reply Y_Y 2 hours agorootparentOnly if everyone is a peasant farmer with the same crops in the same place. My activities are barely related to the height of the sun in the sky, and like the other residents of my city I don't take a ton of notice of harvest time. Bus timetables and cultural festivals are a much bigger deal (of which one in particular is indeed historically related to a harvest). reply jvanderbot 1 hour agorootparentThis \"Day is 12 hours long\" thing just doesn't work anywhere else. I live far from the equator - \"Dawn\" is sometimes after breakfast, and \"Dusk\" can happen before I get off work. reply jachee 52 minutes agorootparentAs former Alaska resident, can confirm. December sunrises are often after 10am, and sunsets before 4pm. Vice versa in summer. Then you get above the Arctic Circle, and there are days with neither. :D reply nerdponx 3 hours agorootparentprevWhat makes it more logical? The wheel turns all the same no matter where you mark the beginning. In the Northern hemisphere, there's actually something nice about starting the year in the dead of winter: it feels like the year is born in the spring and then dies away the following winter, not unlike a lifetime. reply xeromal 1 hour agorootparentMarch should be the 1st month then I'd think. I'm pretty sure that's how the roman calendar worked. War started in spring. reply ComputerGuru 1 hour agorootparentprevIf the year is “born in the spring” then surely you would want the year to start in the spring (if not the spring equinox, then March) and not winter? reply delecti 2 hours agorootparentprev> it feels like the year is born in the spring Then shouldn't the start of the year be when the year is \"born\"? Or alternatively, the end of the year when the year \"dies\"? January 1 is neither. reply jvanderbot 1 hour agorootparentThe year \"dies\" on the longest, darkest nights. (Dec 21, technically). We mourn its passing and celebrate it's life with drinks. I'm guessing there was in antiquity, a whole bunch of dreadful and exciting parties in the last 10 days around the longest nights. It slowly grows after that and blooms later. reply QuercusMax 3 hours agorootparentprevPositioning of the new year at the Equinox shouldn't be any harder than doing it at the solstice (since equinoxes are halfway between the solstices), and it makes much more sense IMO. First half of the year: more day than night. Second half of the year: more night than day. reply alserio 2 hours agorootparentprevdidn't the julian/gregorian calendar started that way and drifted? reply chgs 2 hours agorootparentprevEveryone I work with in Kenya uses standard dates and times. It’s a requirement when you work internationally. reply tobyjsullivan 1 hour agorootparentDo they exclusively speak English as well? reply borski 1 hour agorootparentMany do, yes. And I’d suspect that’s true for those the parent commenter works with in particular. reply Maxamillion96 4 hours agorootparentprevSame with Somali. The first hour of daylight is hal saac (Hour 1) 7 AM is 1 Saac ( Hour 1) 6 PM is 12 Saac ( Hour 12) 7 PM is 1 Saac 6 AM is 12 Saac reply krick 10 minutes agorootparent> 7 AM is 1 Saac > 7 PM is 1 Saac How do you distinguish AM/PM? How does one say that something will happen 19:00 specifically, and not 07:00? reply bloppe 3 hours agorootparentprevI would probably be a bit confused by the fact that 6pm is 13 hours after 5pm, but I'm assuming Swahili has better ways of communicating time reply TremendousJudge 4 hours agorootparentprevSince it's pretty much on the Equator it makes a lot of sense to keep time like that -- days and nights have the same duration all year long. Such a system doesn't make sense for places that have wide variations between seasons, unless you also alter the length of the hours to match (which I think was done at some point somewhere in Europe, but I can't find any references) reply xvedejas 4 hours agorootparentEven on the equator, sunrise and sunset times will vary by +/-15 minutes, because solar days are not of equal length. But yeah, close enough for imprecise use. https://en.wikipedia.org/wiki/Equation_of_time reply samatman 1 hour agorootparentprevIntuitive is a synonym for \"what one is used to\", so I believe you when you say that according to your intuition, what you're accustomed to makes the most sense. In a place with considerable skew in daylight hours between the summer and the winter, this would be quite unintuitive, because daylight hours would become longer (and night hours shorter) during winter and spring, and the opposite for summer and autumn. Either that, or a fixed conventional notion of \"dawn\" which only corresponds to the sun rising around the Equinoxes. Either way would be unintuitive. reply ar_lan 1 hour agorootparentIt's also incredibly condescending, at least the way they wrote it. reply hprotagonist 7 hours agoparentprevEthiopian time keeping is peculiar all over. https://en.wikipedia.org/wiki/Ethiopian_calendar The Ethiopian calendar has twelve months, all thirty days long, and five or six epagomenal days, which form a thirteenth month. reply brodo 6 hours agorootparentThat's similar to the Shire calendar system[1]. It has twelve months of 30 days, but the missing days are not in any month. 1: https://tolkiengateway.net/wiki/Shire_Calendar reply libraryofbabel 4 hours agorootparentAnd also similar to the French Revolutionary calendar (1793 to 1805) which had twelve 30-day months and 5 or 6 jours complémentaires. I like that Tolkien’s legendarium got the first mention here though. reply rainingmonkey 3 hours agorootparentThe ancient Roman calendar was before that, with 10 months of 30 or 31 days and intercalated days when it's no month at all. Sometimes priests moved these days to suit political shenanigans. Caesar ended this madness and \"rationalised\" the system, coincidentally making his year-long consulship last for 446 days. reply prmph 1 hour agorootparentprevWasn't Tolkien's LOTR partly inspired by Ethiopia? reply aquova 5 hours agorootparentprevI'm actually quite a fan of perennial calendars like that, I think the Ethiopian calendar is a much more logical system than the Gregorian system. reply hhdhdbdb 7 hours agorootparentprevThat no odder than Gregorian reply IggleSniggle 6 hours agorootparentIt's not odd as in a more unusual system, but odd in that it is widely incompatible with the calendar of most of the world, but still official calendar. Kinda like the Kodak calendar (which was instead 13 28-day months (364 days), and iirc does the off-day adjustments over the corporate winter holiday...actually pretty reasonable) reply antod 17 minutes agorootparentNot reasonable at all... it's Corporate Summer Holiday around here. reply pc86 2 hours agorootparentprevMerry Corporate Winter Holiday! reply xeromal 1 hour agorootparentlmao reply kergonath 3 hours agorootparentprevThere are good reasons for the Gregorian calendar’s oddities, though. Any simple system stops being simple when you apply it to enough different situations. I am not sure programmers would like it better if each country had a different calendar for each season. Because a day that starts at 6 and ends at 18 would make sense 2 days each years here in Europe. Not even that if you go far enough North. reply charlieyu1 6 hours agorootparentprevStill not weirder than Lunar calendar reply stronglikedan 5 hours agorootparentWhy use celestial bodies at all? Let's bring the Soviet calendar back! reply hprotagonist 4 hours agorootparentsomething something every 5 years. reply marginalia_nu 9 hours agoparentprevThat's very similar to how the romans conceived of time. Wonder if it's an old relic from when north africa was a bunch of provinces. https://en.wikipedia.org/wiki/Roman_timekeeping reply ttepasse 6 hours agorootparentYou'll find the ancient interpretation that the new day starts at sunset still in religions. Sabbath starts on Friday evening, Easter and Christmas day start on the eve of the day before. Possibly the Eids of Islam too, but I'm unsure. Ethiopia is one of the ancient Christian countries, the second of officially convert and the Ethiopian Ortodox Church still seems prominent. I assume that's the reason why. reply arethuza 8 hours agorootparentprev\"An hour was defined as one twelfth of the daytime\" That must have been fun for the Romans here in Scotland - an hour would be roughly two and a half time as long in winter as in summer! reply throw0101a 7 hours agorootparent> That must have been fun for the Romans here in Scotland - an hour would be roughly two and a half time as long in winter as in summer! Mechanical clocks in Japan were designed to handle those situations: > Adapting the European clock designs to the needs of Japanese traditional timekeeping presented a challenge to Japanese clockmakers. Japanese traditional timekeeping practices required the use of unequal time units: six daytime units from local sunrise to local sunset, and six night-time units from sunset to sunrise. * https://en.wikipedia.org/wiki/Japanese_clock#Temporal_hours reply pbmonster 7 hours agorootparentprevMuch less of an issue without clocks. Look where the sun is, remember where it is at sunrise/-set (much easier if you're outside every day) and then mentally divide the sky into segments and just ballpark it. reply arethuza 6 hours agorootparent\"Look where the sun is\" Well, maybe that was another problem with Scotland... ;-) No wonder they built a few walls and retreated south.... reply Horffupolde 6 hours agorootparentprevThat’s standard traditional Hebrew time still today. reply ucarion 1 hour agoparentprevJapan does something similar in the context of things that close after midnight: https://en.wikipedia.org/wiki/Date_and_time_notation_in_Japa... FWIW, the English-speaking world used to switch years on March 25: https://en.wikipedia.org/wiki/Calendar_(New_Style)_Act_1750#... Neither of these are technically things that tzdb can even talk about. They're concerned with civil time, not calendars or other \"reckoning\" problems. reply prmph 1 hour agoparentprevInteresting. I propose that the transition between AM and PM should happen right in the human-sensible middle of the day. If most people start their daily activity around 6, and retire by by 10pm, then the middle would be 14hrs. This would also give a nice 3-part division to the day that matches their use: 1st 8 hours for the morning, next 8 hours for the afternoon, and the next 8 hours for evening/night. Currently, morning alone is 12 hours, and afternoon is like 6 (or less) and the evening takes the rest. But I guess the current noon time is chosen for when the sun is highest in the sky, so maybe to preserve noon as the transition point, morning should start from 4:00 hrs, then the afternoon starts from 12:00 hours, and evening would start from 20:00 hours. reply Ekaros 10 hours agoparentprevFor country near equator that is not actually unreasonable system to define day cycle. reply rob74 8 hours agorootparentYeah, for countries further away from the equator this would be crazy. Actually I thought Ethiopia is already far enough from the equator to have significant changes of sunrise/sunset times, but according to https://www.timeanddate.com/sun/ethiopia/addis-ababa, they only vary by ~ 40 minutes over the year, so I guess that's close enough to \"constant\" for most of the population... reply helsinkiandrew 3 hours agoparentprevThats almost as confusing as the Nautical Day. Where a day on ship started at noon the \"previous\" day - with PM proceeding AM. https://en.wikipedia.org/wiki/Nautical_time#Nautical_day reply layer8 2 hours agorootparentThat’s also how Julian days work, they go from noon to noon: https://en.wikipedia.org/wiki/Julian_day reply kbbgl87 10 hours agoparentprevAnd they live 7 years in the past. reply guidedlight 9 hours agorootparentThey do. So I guess the observed timezone is UTC-61314. reply Scarblac 2 hours agorootparentProbably depends on how many of those 7 were leap years at any point in time? reply squiggleblaz 11 hours agoparentprevSounds like it could be a candidate. Any system which can't be expressed in standard software is stranger than every system that can be. reply Majromax 5 hours agorootparentNot necessarily. To be inexpressible in software, all it has to do is be unpredictable; it can still be boring. Let me define \"local snoozing time\" (LST): it's set to my local standard timezone as of today, but every time I hit the snooze button on my morning alarm it shifts 9 minutes backwards (the length of the snooze). By definition, I wake up at 8am in LST, regardless of what the world is doing. If the time shifts by more than one hour compared to the prevailing timezone, LST shifts forwards by a whole number of hours on Saturday morning, 2am LST to minimize that difference. This timezone is \"boring\" but uncomputable, since it depends on unpredictable events. reply dpassens 9 hours agorootparentprevBut whether standard software is able to express this system is up to the software, not the system, no? Why is this way of timekeeping weird, apart from the arbitrary decision not to support it? reply tsimionescu 8 hours agorootparentI would agree it's weird, but not because software doesn't support it, but because it's different from what the vast majority of the population of the world does. The fact that software doesn't support it is a downstream consequence of that. reply dpassens 5 hours agorootparentI agree with that take. It's also quite different from saying that it's weird because software doesn't support it, which is the claim I took issue with. Maybe I should've phrased my comment differently. reply tankenmate 9 hours agorootparentprevThe decision to not support it isn't \"arbitrary\" per se; it's a function of utility vs cost to implement (which a healthy dose of fudge). \"Standard software\" for timekeeping is far more useful precisely because it is used by far more people. reply dpassens 9 hours agorootparentMaybe arbitrary was the wrong word. I understand that this is an implementation cost issue and I'm not saying that the decision not to pay this cost wasn't reasonable. My objection is not with tzdb, but with the characterisation of a real-life practice as weird just because software doesn't accommodate it. Shouldn't what people do be the reference for what is normal, rather than the rules encoded in software? reply lazide 8 hours agorootparentSoftware doesn’t accomodate it because it’s weird relative to literally the rest of the world. reply dpassens 5 hours agorootparentSure. But that's completely different from saying it's strange because software doesn't accommodate it. reply lazide 4 hours agorootparentIs it? reply dpassens 2 hours agorootparentYes, it is, because in your phrasing the fact that nobody else keeps time that way is the cause and lack of support in software the effect. The comment that I originally responded to is phrased as though lack of software support is the cause of weirdness. I object to the latter since software is not the source of truth, the social practices it aims to encode are. It is perfectly reasonable to say that this particular practice is so rare that it is out of scope, but this makes tzdb a not quite correct approximation of reality, rather than reality an approximation of tzdb. reply dudeinjapan 1 hour agoparentprevWow, this is great! This is exactly how Ive thought times should be done. Ive always called it “local sunrise time”. All the advantages of DST without the biannual spikes in traffic fatalities. reply AStonesThrow 9 hours agoparentprevEthiopian Christians have retained many Jewish customs compared to others, so you will also see them observing something like kosher diets. Although dusk is not sunset, it may be the case that they've adapted the cycle from Hebrew calendar observance. reply azernik 8 hours agoprevThe \"Asia/Jerusalem\" weirdness is because Daylight Savings Time is a big church-and-state issue. Religious people want the workday to be convenient for holidays that start at sunset. This led to decades (up to the mid00s) where Daylight Savings was the result of annual negotiations between religious and secular parties. It often caused problems when the decision wasn't made until juuuust before the transition date. There are still exceptions built in to prevent Daylight Savings from ending on Rosh HaShanah, so that's probably the future stuff. reply RegnisGnaw 3 hours agoparentThere is no more exceptions, IDT got extended to last Sunday of October in 2013. reply ars 3 hours agorootparentAccording to Wikipedia: \"If the end of IDT falls on Rosh Hashana, then IDT will end on the first Monday after October 1.\" reply azernik 3 hours agorootparentprevHuzzah, at last! reply rob74 8 hours agoparentprevReading this, and considering the limited advantages of DST (especially for a country that is relatively far to the south), I wonder why they didn't decide to scrap DST completely? Maybe they will if the EU eventually manages to do it? reply layer8 2 hours agorootparentThe EU likely won’t scrap it, because the CET countries want to stay in a common time zone (no new time zone borders) for economic reasons, but either the very Eastern or very Western ones in that range would object to permanent DST or permanent non-DST, because it would move them too far from the solar day either in winter or summer. It can’t be fixed without one country or another getting the short stick, which means it won’t be fixed. reply yyyfb 30 minutes agorootparentIf the continental US can do it (and it looks like it might soon, with California voting for it) I'm not sure I buy that argument. Heck if China can survive on one timezone... reply layer8 12 minutes agorootparentThey certainly could if they had started that way, but changing it now will disadvantage at least one of the countries (Spain for example), and those countries’ politicians don’t want to risk the ire of their voters for the greater good. And DST is regulated on the EU level, so can’t be changed by individual EU members without breaking EU law, like apparently individual US states can. It’s status quo bias and loss aversion. Similar to how it would be better for the US to change their voting system, but it will never happen because it would disfavor one of the political parties who’d have to approve the change. reply Navarr 16 minutes agorootparentprevUS is the same way; my hot take has always been \"time to move to a -/+ 30 minute timezone\" reply maratc 6 hours agorootparentprevI would argue that DST actually makes most sense in 30-40 degrees of latitude. With about 13 hours of sunlight in the summer, split evenly around the mid-day, it comes down to 05h30 to 18h30 under light. There are many more people who would be out there to enjoy the sunlight between 18h30 and 19h30 than there are between 05h30 and 06h30. reply bena 3 hours agorootparentI really dislike this argument of \"I'd rather enjoy the sun in the evening than in the morning\" ignoring all of the other problems it causes. Sunlight in the morning is useful. It's better for your sleep rhythms. It's safer for school children, etc. And to be completely fair, I don't see that many more people \"enjoying the sunlight\" during the weekend when they have the entire day to do so. Like, what is the sun going down at 6 really preventing you from doing that you couldn't do otherwise? reply maratc 3 hours agorootparent> I really dislike this argument of \"I'd rather enjoy the sun in the evening than in the morning\" My argument is not \"I'd rather enjoy the sun in the evening than in the morning\", my argument is \"From what I can observe, most people would prefer an hour of sunlight at the end of the day rather than in its beginning\". This is not about what I think, it's about what most people think. > what is the sun going down at 6 really preventing you from doing Again, my observation is that most people, given a choice of A. having sunlight between 5am and 6am; or B. having sunlight between 6pm and 7pm, would prefer option B, simply for the reason that more are awake during that time. reply bena 1 hour agorootparentDid you take a poll, or do you just have the feeling that that is the case? Not to mention, it's a bit weaselly. It offsets the burden of defending the position to \"most people\". And it doesn't even matter what \"most people\" think. \"Most people\" in this case, would be wrong. Even if it were \"most people\" and not \"most people whose opinions you've happened to remember on the subject because they happen to align with yours\". And it's going to get darker earlier in winter. That's just what it does. People are really just lamenting the lack of daylight hours in general. Because during the winter, few places have sunlight during 6pm and 7pm even if we kept DST year round. What they say they want is sunlight between 5pm and 6pm. And after the clocks roll back, it'll start getting dark soon after 5. And once again, I ask, for what? Having the sun rise just after 6am is better for everyone. School kids waiting for the bus are safer, kids walking to school way safer. Better driving when you're waking up. Everything is more in line with your circadian rhythms, etc. reply maratc 41 minutes agorootparent> And it's going to get darker earlier in winter. It's summer we're talking about when we talk about DST. There's no DST in the winter. > School kids waiting for the bus are safer, kids walking to school way safer. For several months in the summer, the schools are closed. Other months during DST, the schools start at 08h00 and the vast majority of the kids wake up about seven-ish, to leave their house at about 07h30. It is inconsequential for the kids whether the sun has risen at 06h30 or at 05h30 that day; when they wake up, there's light outside anyway. For the rest, let me give you an analogy. For several months this coming summer, I am going to give out an hour of free internet[0] each day. This won't interfere with the (paid) one that people are having otherwise. I'm not going to ask the question \"would you prefer this hour to be between 05h30 and 06h30, or between 18h30 and 19h30?\" but I am going to ask this question instead: What would the majority prefer, in your opinion? [0] - any useful utility can be substituted: free hour of water, free hour of electricity, etc. reply samatman 1 hour agorootparentprev> It offsets the burden of defending the position to \"most people\". Decisions where the only effect is to align something arbitrary with people's preferences can only be made through appeal to the majority. > And it doesn't even matter what \"most people\" think. Yes. Yes it does. reply lazide 8 hours agorootparentprevIf they didn’t have that to argue about, what else would they do with their spare time? reply ars 3 hours agoparentprevIt's because of Passover: The Seder (main celebratory meal) lasts till midnight and later, and it's a very big deal for children. So they don't want Daylight Savings Time to make it end even later than it already does. It's also because of the fast day of Yom Kippur - people wanted the faster to end 1 hour earlier. So they wanted DST to match up to those days - but that made the DST period too short, and led to the negotiations. reply alexjplant 10 hours agoprevEarlier this year I had to write a function to find the current local time given a US address. The naive way to do so would be via a static mapping of state to time zone but there are a few edge cases that preclude doing this; in the interest of cost and speed relative to this specific application I spent a few dollars on a CSV that maps every US ZIP code to UTC offset and whether DST is followed (among other data). pytz takes IANA timezone names so I ended up having to map offset and DST info manually to specific timezones. As it turns out the US has a fair number of weird edge cases for overseas territories and military bases that necessitated the use of things like \"Etc\" zones [1] that have funky semantics (because of Unix for some reason if Wikipedia is to be believed). [1] https://en.wikipedia.org/wiki/Tz_database#Area reply hocuspocus 7 hours agoparent> The naive way to do so would be via a static mapping of state to time zone but there are a few edge cases that preclude doing this More than a few, state is really the wrong resolution here, US timezones follow counties and native reservations borders. ZIP codes should probably be good enough but I'd be careful too. If your volume of addresses isn't too crazy, the robust way is to reverse geocode them and use a library that gets you the IANA identifier from timezone shapes. https://github.com/RomanIakovlev/timeshape is maintained by a former coworker who could open source some of the work we did internally. reply ComputerGuru 1 hour agorootparent> state is really the wrong resolution here, US timezones follow counties County is the smallest resolution one can reasonably use, but in terms of what timezones themselves follow, that would be metro areas. I.E. the Chicago metro area has its timezone and cities (or counties, if you will) that are part of that metro region, even when belonging to other states that largely follow a different time zone, follow the metropolis’ tz instead. (Not arguing with you but clarifying the meaning of “follow” here.) reply apelapan 6 hours agorootparentprevThere used to be at least one airport in a tribal area in the US, that had the timezone of the reservation (not same as state) but the DST of the surrounding state (not same as reservation). Can't remember the code for it now, had a lot of interesting timezone issues in a previous job. reply kstrauser 4 hours agorootparentIIRC you crossed 6 time borders in 30 miles if you flew the right straight line across it. reply seoulbigchris 7 hours agoparentprevAs a young engineer right out of university back in 1985, one of my early tasks involved merging together a bunch of telemetry data provided on mag tapes recorded at different radar sites (in the USA). One or two of the systems time stamped their data in local time, and all the others used UTC. I remember buying one of those old Farmers' Almanacs in order to make an algorithm to account for DST. When I read the rules, I threw up my arms in despair. The almanac gave nominal rules for the transitions. But there was a footnote explaining that these transitions had and will continue to be adjusted year to year due to Congressional intervention. I showed this to my boss and said, \"If I could write an algorithm that predicted future votes of Congress, I would be a billionaire and could quit this engineering job.\" I think in the end I coded the algorithm with the recent known transitions, and the nominal rules for future ones. What else could you do (this was before everyone was networked, and the code ran on standalone computers like a VAX). I also learned that task of merging three sources of tracking data, each with its own validity and measurement degradation status, was an absolute nightmare. But still easier than predicting future actions of Congress. reply TheNewsIsHere 7 hours agorootparentThis is a fantastic story, well and amusingly told. reply koliber 8 hours agoparentprevA good approach would be to map a zip code to the named timezone (e.g. US/Eastern). Then, if you need to produce the UTC offset, apply the timezone to a date using pytz and get the offset. The named timezone is special as it is constant. The UTC offset timezone (e.g. \"-05:00\") and the shorthand name (e.g. \"EST\") is NOT constant over time for a given location, because of daylight savings time. \"US/Eastern\" flips between \"-05:00\" and \"-05:00\", as well as between \"EDT\" and \"EST\". If you ask someone what their timezone is and offer them offsets or the short names, it causes confusion for everyone. reply gorkish 1 hour agoparentprevI see you too have wrestled with GreatData's time zone data being hot garbage. Been that way for decades. reply entuno 8 hours agoprevThe time zone in Palestine is a bit weird as well: https://en.wikipedia.org/wiki/Time_in_the_State_of_Palestine They have DST, but it's not on fixed dates, the government just announces each year when it's going to start and end. Sometimes with less that a week's notice, which must cause all kinds of interesting problems for people. reply karel-3d 2 hours agoparentIt's in the actual article. It's tied to Ramadan. reply arrowsmith 5 hours agoparentprevThis is mentioned in the article. reply weinzierl 7 hours agoparentprevNot sure if true today, but used to be the case in Brazil too. Once almost missed a flight because of that. reply marcosdumay 3 hours agorootparentBrazil doesn't have DST anymore. And when it had, it used to be announced with 6 months of antecedence. It also had \"standard\" dates that were almost always used. If your comment was about the 2019 change that almost all computers got wrong, this one was announced with 6 months of antecedence like most others. reply yokoprime 8 hours agoparentprevWithout getting deep into politics I don't understand why they would prioritize spending effort on DST at all, seems like there are plenty of other concerns. reply jdietrich 7 hours agorootparentAgain, without wanting to get too political, I think it's essentially bikeshedding. The Palestinian National Authority is riven with factional conflicts and has very limited state capacity. That almost inevitably leads to a lot of bickering over largely irrelevant decisions as a symbolic but hollow demonstration of political authority. The ability to make the decision takes on an importance completely out of proportion with the actual significance of the decision. reply FateOfNations 7 hours agorootparentprevMost of the population there is interested in those dates for non-DST-related reasons. They will want to know when Ramadan begins and ends, regardless of whether it's used to determine DST. reply ComputerGuru 1 hour agorootparentprevYou (and everyone else opining here) are missing the practical context: DST makes Ramadan easier, because the sun sets an hour earlier. Yes, you are fasting the same number of hours, but your day “starts” at a point fixed to the TZ-adjusted clock and the sooner sunset arrives, the shorter your effective day. reply DoughnutHole 7 hours agorootparentprevIf your life is dominated by an us vs them dynamic small demonstrations of difference become hugely important. In a similar vein different people in Xinjiang in China observe entirely different timezones - Han Chinese observe Beijing time (because China is insane and uses one timezone despite spanning 5), while Uyghurs observe a local time 2 hours behind. It’s a small show of resistance, which is sometimes all a people have if they have limited control of their own affairs. reply grotorea 7 hours agorootparentprevI don't see why announcing DST would be a big effort. And it saves on electricity costs. reply Kwpolska 7 hours agorootparentEven if DST did save something (it does not), it becomes a problem when your timekeeping is done by computers. My computers know I live in Poland (Europe/Warsaw), and they know the DST rules. I can trust the time on my computers’ clock matches the official time the government recognizes. In Palestine, this depends on my OS vendor managing to update the tz database in the short window before the official announcement and the decision coming into force. (I believe the tz database makes some assumptions based on past performance, but the government can change their mind any year.) If my OS does not update, I need to change my time zone manually to something that has the right UTC offset, and then I need to manually change back in the autumn, and I can never be 100% sure if any given computer shows the official time. reply macspoofing 7 hours agorootparentprevAnnouncing is not a big effort. Having millions of people, and thousands of companies (in the territory and outside the territory) adjusting to the announcement is a big effort. If you're going to have DST, you want it to be stable and predictable so that people can plan for it. reply Lance_ET_Compte 2 hours agoprevA thousand years ago, every village had their own timekeeping and it worked. Our village is now earth. What if we just abandoned daylight-savings time and timezones and just went with GMT (or anything else) for everywhere on earth? There would be cultural effects as people in California now start work at 16:00, for example... reply ianburrell 1 hour agoparentEveryone would create local time zones and use them. It is convenient to have the clock synchronized to the local day. Using UTC optimizes for long distances when people use local clocks much more often. How do you handle the date changing in the middle of the day? If I was on UTC, the date would change at 5pm. Is that still Wednesday or would it be Thursday? Also, it doesn't solve the problem since still need to figure out local time when interacting long distances. If need to keep track of local times, might as well use time zones. Finally, can solve most of the problems with time zones by including UTC time with anything long distance. Say \"meeting is at 4pm, 23:00 UTC\", then nobody has to worry about your local time zone. reply tshaddox 46 minutes agorootparent> How do you handle the date changing in the middle of the day? It seems like you would have to do absolutely nothing? Just like you do absolutely nothing to \"handle\" the hour changing throughout the day. People work overnight shifts. People schedule important events close to and on either side of midnight. reply sethammons 28 minutes agorootparent\"did it happen wednesday the 23rd or wednesday the 24th?\" reply cle 2 hours agoparentprevThe hard part is not doing it, it's getting people to agree. I highly doubt people will agree to do that, because a large portion of people don't agree with \"our village is now Earth\". reply tshaddox 48 minutes agorootparentIn order to do computing involving time zones you also need to get an enormous number of people (particularly vendors of computer operating systems and maintainers of programming languages) to agree. But yes, this does appear to be easier than getting a few hundred political jurisdictions to agree. reply bakkoting 2 hours agoparentprevHere's a good essay about that: So You Want To Abolish Time Zones [1] [1] https://qntm.org/abolish reply throitallaway 50 minutes agoparentprevOur world has gotten smaller. For people that travel often and schedule calls across time zones, time zones are a complete pain in the ass. I've advocated for getting rid of time zones for ~10 years now. It really doesn't matter if people in California start work at 16:00; the people that live in that area will get used to it. Daylight will remain the same. reply maxwell 1 hour agoparentprevUTC is problematic since it splits the day: when it's midnight in Greenwich, it's still yesterday for half the world. The Unix epoch occurred in 1969 in Hawaii. BIT (UTC-12) is better. Only positive offsets. Everyone on the same day. reply soperj 2 hours agoparentprevI'd adjust to that better than adjusting to Daylight savings time. reply fermuch 2 hours agoparentprevIsn't that how china works? One timezone for everyone reply ianburrell 2 hours agorootparentThat is good example why one timezone doesn't work. The locals in Xinjiang use a local time zone +6, instead of China time +8, because the latter is too far off the daylight hours. My understanding is that use of Xinjiang time has dropped recently because of the crack down on Uygurs and government forcing China time. reply a57721 2 hours agorootparentprevThere are various countries that optimize the number of time zones for administrative purposes, but this is much easier and sensical to implement within one country than globally. UTC is used globally when it makes sense, e.g. for the schedules of international radio broadcasts. reply chanandler_bong 2 hours agoparentprevThis. 100%. reply grishka 4 hours agoprevAnother fun fact about timezones: if the government abolishes DST one year, and then moves some timezones an hour the next year, it creates a wild mess. Especially when you're building an Android app. Especially when it's the early 2010s so the timezone database is built into the system image but most devices that run your app don't receive system updates at all. Instead of picking the timezone with the correct offset and no DST, many people would adjust the time itself so the wrong timezone and the wrong unixtime cancel each other out so the clock \"looks right\". Not fun when you're doing math with timestamps, some of which are local and some come from the server. reply jandrese 2 hours agoparentI worked with a group of people once who just didn't care about timezones. All (ok, most) clocks were set to local time, but with some random timezone, about half of the time it was GMT, and 2/3 of the remainder were our actual timezone, but the rest were totally random. I had to write a \"figure out what the time actually is\" routine in my code because it was such a pervasive problem. reply grishka 1 hour agorootparentI ended up doing kinda the same. Our API already had a method to retrieve the current unixtime on the server, which I used, together with the user-set timezone, to figure out the UTC offset that the user actually meant to set by adjusting their clock. reply lxgr 2 hours agoparentprevThis makes me wonder: Should NTP servers broadcast the tz database...? (And should the tz database support a stable but turing-complete scripting/bytecode language?) reply ironmagma 1 hour agorootparentThat sounds like the beginning of a story that ends with an RCE. reply lxgr 1 hour agorootparentHey, if OpenType fonts get to do it, why shouldn't timezones? :) reply heironimus 2 hours agoprevMe: This does not look interesting at all, but its really popular, so I'll quickly skim it. Me, 5 mins later: I can't stop reading this! reply gausswho 6 hours agoprevExcellent read around the acrobatics of timezone software. It really is quite flexible. It leads me to wonder. If it's all just an automated and finite offset, there's no reason for daylight savings policies to hew to 60 minutes adjustments. Couldn't a nation decide to have a continuously changing offset throughout the year? It might make their offset lookup table substantially longer, but this could 'solve' daylight savings time It'd be adjusting all the time and you wouldn't notice, just you don't notice when leap seconds occur. Those who rely on analog clocks might no longer adjust the same direction each time! reply ucarion 47 minutes agoparentIn theory, this can be expressed in tzdb. Obviously, it will cause problems. The only really important assumption not obviously present in TZif's data format is that when you go from a local time to a UTC time, there can only be up to two possibilities. A lot of software works on that assumption, for instance java.time.LocalDateTime has a withLaterOffsetAtOverlap(): https://docs.oracle.com/javase/8/docs/api/?java/time/LocalDa... That implicitly assumes that whenever it's ambiguous what 2:30AM means, you can only have two possible solutions (pre- and post-DST). If a timezone were ever to manipulate its offsets so that there were three or more solutions (such as if they did a \"fall back\" at 2:00AM and then 2:15AM or something), a lot of stuff would be unable to represent that. reply PopAlongKid 5 hours agoparentprev> If it's all just an automated and finite offset, there's no reason for daylight savings policies to hew to 60 minutes adjustments. For as long as clock sync for electronic devices has been common, I have suggested to anyone who would listen that we should adjust forward 10 minutes on the first Sunday of each month for six months, and then back 10 minutes on the first Sunday of the other six months. A ten minute change once a month is not only easier to adjust to (almost unoticeable), but if you miss it, it's not as big a deal as being off by an hour would be. reply Buttons840 5 hours agorootparentMoving up and down at a linear rate would result in a saw-tooth-like wave, but the length of days change in a sine wave. Why not have the clocks sync themselves to sunrise time based on their timezone and latitude? I don't think this would be much different, in practice, than changing times at a linear rate. reply mywittyname 3 hours agorootparentThis would lead to a monumental amount of confusion. The primary time keeping device in my house is the clock on my stove; I wear old school watches a lot; and most of my cars are old and have old clocks in them. I can't be the only one, so multiply this by at least a few million other people in America alone. Sure, you can tell everyone they need to ditch dumb clocks and replace them with internet-enabled smart clocks. But I think that's a far more onerous undertaking than just dealing with the fact that solar time and clock time are mismatched. reply jerska 2 hours agorootparentprevAdding to my sibling comment, time is also mostly used as a coordination system. Being offset by a few minutes would make aligning meetings with your remote coworker an even bigger nightmare than it is now. reply Gormo 6 hours agoparentprevThe logical conclusion of going down that route would be to dispense with the concept of time zones altogether, and just revert to using local solar time. reply crazygringo 5 hours agorootparentWhich would make scheduling Zoom meetings or even just phone calls hell. Especially when everyone's half-hour blocks are misaligned with each other's so you can't even stack meetings efficiently. reply iggldiggl 4 hours agorootparentAnd public transport timetables, which were the original reason timezones were introduced in the first place. reply mywittyname 3 hours agorootparentThis is why I think we should entirely ditch the concept of timezones. Clock time, as we use it, is largely decoupled from solar time anyway, and all attempts to reconcile the two just lead to confusion. We already have terms a few terms to tie events to solar time, for example, a park being open from dawn to dusk. And without time zones, we might come up with a few more. reply VyseofArcadia 4 hours agoparentprev> but this could 'solve' daylight savings time This ignores the easiest solution to daylight savings time. Stop doing daylight savings time. My preferred solution would be permanent standard time rather than permanent DST, but I'll take what I can get as long as we stop changing the clocks twice a year. reply akira2501 2 hours agoparentprev> It really is quite flexible. Other than considering current legally defined timezones as \"legacy\" definitions and then removing them for no reason other than to follow European fashion. So, flexible, but managed by inflexible university types. reply fragmede 6 hours agoparentprevIndia is UYC+5:30, and doesn't do daylights savings time, which is interesting for interacting with the rest of the world. Of course, China famously has one time zone despite being really wide which makes things interesting both internally and externally. reply em500 3 hours agorootparentMost of the world doesn't do DST either[1], nowadays it's mostly a European/American thing. [1] See the map at https://en.wikipedia.org/wiki/Daylight_saving_time_by_countr... reply lazide 6 hours agoparentprevPlease don’t give them any ideas. reply rswail 5 hours agoprevFor years I've been saying that a programming course is composed of two subjects: 1. Date and Time Programming 2. Debugging You will encounter every possible issue and common bug when doing #1, leading naturally to #2. reply mayneack 2 hours agoprevMy personal favorite timezones: There's UTC+14 in Micronesia: https://en.wikipedia.org/wiki/UTC%2B14:00 Also Antarctica/Troll: A timezone for a norwegian research station. https://en.wikipedia.org/wiki/Time_in_Norway reply fouronnes3 11 hours agoprevWhat I like about the tz database is that's it's technically a diff of a diff. It stores the difference across history, of the difference of each timezone with UTC. Right? So it's a diff^2. But! The tz database gets updates! So those commits are diffs of diffs of diffs, or diff^3. Can we go further? You bet! It has a changelog, and that changelog is stored in git, so commits to the tz changelog are diff^4: they are changes to the list of changes to the list of changes to the list of changes to UTC. reply dalmo3 9 hours agoparentYou forgot that UTC (or timekeeping in general) itself is a diff. reply fouronnes3 7 hours agorootparentOh that's a great point! We have achieved diff^5 at last! Now that I think of it, we could even stretch it one more level. In practice UTC is \"realized\" as a \"best of\" diff to atomic clocks in labs around the world, which are themselves diff against a fixed time point, as you pointed out. So that realization technically changes when the official UTC bulletin[1] is published by BIPM. So diff^6! [1] https://www.bipm.org/en/time-metrology reply flippyhead 6 hours agorootparentYes, but, it's always 5 o'clock somewhere, amiriiight?? reply hhdhdbdb 7 hours agorootparentprevCan we bring relativity in for another diff :) reply Yossarrian22 5 hours agorootparentprevDon’t forget using GPS to get the time and tell you if you’ve crossed time zones reply gavindean90 3 hours agorootparentSo would that be diff ^ 10? reply Horffupolde 6 hours agoparentprevA diff of a diff is just 2 diff. It’s not a product of diffs. reply ninalanyon 5 hours agorootparentSpoilsport! reply Horffupolde 4 hours agorootparentJust be rigorous with your words. reply squiggleblaz 11 hours agoprevI kind of thing a half hour daylight savings difference instead of an hour is a pretty low bar for the weirdest timezone. Almost any of the others are weirder: Antarctica/Troll definitely sounds weirder. The Moroccan and Gazan timezones that can't be expressed by the system as it was written because at least that means that they have some different kind of a rule, even if lunar time is well known. Same with the ones that are in Apple's naughty list because they're transitions the day before some day - again, not very weird, but at least it's weird enough to break things. But I do agree with leap seconds: it's absolute trivia, not a useful thing for a programmer to know. Your computer smears them and you don't even know when they happened. You could completely forget them. Except that countries transitioned from ignoring leap seconds to considering them, so the switch in Australia from \"GMT+x\" to \"UTC+x\" a couple of decades ago was the transition from ignoring leap seconds to incorporating them. The fact that this is almost universally ignored is probably for the better. reply michaelt 11 hours agoparent> But I do agree with leap seconds: it's absolute trivia, not a useful thing for a programmer to know. By and large, I agree with this. But I've always found it a bit funny when a large organisation [1] says \"our servers have sub-millisecond timing accuracy, thanks to GPS synchronization and these PCIe rubidium atomic clock cards we've developed\" while at the same time saying [2] \"we smear leapseconds over the course of a day, in practice it doesn't matter if a server's time is off by ±0.5 seconds\" [1] https://engineering.fb.com/2021/08/11/open-source/time-appli... [2] https://engineering.fb.com/2020/03/18/production-engineering... reply growse 9 hours agorootparentThe thing that super accurate timestamps buys you is common agreement across your infrastructure as to what the time is. This basically makes distributed systems work faster/better/whatever. The relation between that time and what the rest of the world thinks the time is is actually less relevant. reply knallfrosch 4 hours agorootparentprevAnd then you validate against Microsoft's default `ClockSkew` of 5 minutes. reply zarzavat 10 hours agoparentprev> even if lunar time is well known The date of Ramadan is not well known because it's based on being able to see the moon from the local position on Earth. If the sky is particularly overcast for instance, then you cannot see the moon, regardless of where the moon is. This presents problems for implementation of the calendar into the workings of a nation state. Many countries that adopt the Islamic calendar officially use an approximation, a pre-calculated date based on the moon's predicted visibility at a particular position. The Islamic calendar is therefore not really one calendar, but two: the observational Islamic calendar and the predicted calendar, and both have a dependence on a location from which either real observations are made, or predicted observations are made. I don't know how Morocco or Gaza do it. reply pavel_lishin 5 hours agorootparent> The date of Ramadan is not well known because it's based on being able to see the moon from the local position on Earth. Note to self, look up what Islamic scholars think should be done about Ramadan on a moon base. reply umanwizard 4 hours agorootparentNot quite a moon base, but for Muslims on the ISS: > the Malaysian government called a gathering of 150 Islamic legal scholars, scientists, and astronauts to create guidelines for Dr. Shukor. The scholars produced a fatwa, or non-binding Islamic legal opinion, intended to help future Muslim astronauts, which they translated into both Arabic and English. They wrote that in order to pray, Muslims in space should face Mecca if possible; but if not, they could face the Earth generally, or just face “wherever.” To decide when to pray and fast during Ramadan, the scholars wrote, Muslims should follow the time zone of the place they left on Earth, which in Dr. Shukor’s case was Kazakhstan. To prostrate during prayer in zero gravity, the scholars stated that the astronaut could make appropriate motions with their head, or simply imagine the common earthly motions. I’m not an Islamic scholar (or a Muslim at all), so this is just speculation, but my guess is that if it were a permanent settlement, with people being born and living their whole lives on the moon base (so “where they left earth from” is not meaningful), they’d probably just settle on one permanent Earth time zone to follow; presumably either that of Mecca, or that of whatever country on Earth (if any) owns the base. reply pavel_lishin 4 hours agorootparentPrayer and pointing to Mecca seems pretty simple on the moon - but if Ramadan is based on when you can see the moon, it seems that Ramadan would start as soon as the person in charge walks by a window. reply vikingerik 3 hours agorootparentMoon-dwelling Muslims would go by the phases of Earth, if they wanted to match Earth timing but not rely on communication with Earth. The Earth as seen from the Moon exhibits the opposite phase as the reverse. Ramadan would begin when the Moon-dweller sees the Earth as being just past full. If you wanted, you could synch it with a particular timezone on Earth, by watching for when that location on Earth (Mecca or whatever) just rotated past the terminator so it experienced sundown. (Of course none of this can be directly observed if you're on the far side.) (And I get your joke about seeing the moon when you're on it; this is the practical alternative.) reply umanwizard 3 hours agorootparentprevYep! I think for that case the \"follow the time zone of some particular place on Earth\" rule would apply. reply jdietrich 7 hours agoparentprevLeap seconds are generally trivia, but they become absolutely crucial in applications where multiple parties must be in exact agreement about chronology - the obvious example being financial transactions. A lot of markets were closed for the leap second and many banks still suspend all transactions during any change of local time to mitigate the risk of error. Even in applications where we don't particularly care, there have been a surprisingly large number of leap second-related bugs. CGPM have decided to abolish the leap second for good reason. https://en.wikipedia.org/wiki/Leap_second#Other_reported_sof... reply Tor3 4 hours agorootparentAnd when processing satellite data.. if you're not in agreement of the time, that one second error results in a ~7km geographical error for your typical polar orbit weather satellite. reply jiri 8 hours agoparentprevAntarctica/Troll is not that weird. Really they use just two times: Cape Town time during short summer and Norway time otherwise. Unfortunately, Norway time happens to have DST ;-) reply madcaptenor 4 hours agoparentprevCame here looking for Troll - as far as I know it's the only one to have winter daylight savings time. Also it gets extra points for the name. reply Izkata 5 hours agoparentprev> I kind of thing a half hour daylight savings difference instead of an hour is a pretty low bar for the weirdest timezone. Especially when, even disregarding the ones with special rules, there's a couple that are 45 minutes off. reply Epa095 10 hours agoparentprev> But I do agree with leap seconds: it's absolute trivia, not a useful thing for a programmer to know. Maybe, all I know is that it was relevant for me during the first years in industry. If you work with timeseries which comes from source systems you don't 100% controll, like in many industrial settings, its important to know about them, and how they are handled upstream. Do the source do smearing, or does it just sync every X hours? Does it sync with NTP, which will smear (slew) the change, or have they implemented their own thing? Do they just run `ntpd -q` regularly? But yeah, as I type it out I realize that most programmers probably don't work in that domain:-p reply bdmatatu 7 hours agoprev> It’s not like programming languages support representing 61-second minutes anyway Raku supports leap seconds. see https://docs.raku.org/type/Instant reply ochrist 6 hours agoprevThe article says that \"Nuuk is in Greenland, and is part of the greater EU cinematic universe.\" It is correct that Greenland is part of Denmark, and Denmark is a member of EU. But Greenland voted several years ago to stay out of the EU. reply dmd 6 hours agoparentWhich is why it's part of the greater universe, not the regular one. reply armada651 6 hours agorootparentGreenland is one of those spin-off movies that is part of the cinematic universe, but is generally considered to be non-canon. reply IggleSniggle 6 hours agorootparentprevLike how Spider-Man actually belongs to Sony, not Marvel, and it gets loaned back to Marvel? Or more like how Blade isn't part of the MCU, but totally belongs to Marvel? reply toast0 4 hours agorootparentSpider-Man belongs to Marvel, but is on conditional perpetual loan to Sony, who can optionaly loan it back to Marvel/Disney. Sony has to release a Spider-Man movie every N months, or they lose the license, and will probably never get it again, since Marvel started making their own films and now they're part of Disney. This is why Sony keeps making reboot trilogies. Better to shovel something out than to lose the license forever. It does make a nice backstory for the Spider-Verse though. reply ta1243 5 hours agorootparentprevExcept Blade is part of the MCu now since Deadpool 3 But I think the analogy may be being stretched reply IggleSniggle 3 hours agorootparentAhh, figures. As soon as I said it I thought it likely that Marvel had roped it in at some point. Nothing is safe! Just wait til we get Star-Lord (Guardians of the Galaxy) accidentally facing off against some Jedi just so a writer can make some \"Hans shot first\" \"inside\" joke in some \"way overshot the time travel to long ago in a galaxy far far away\" plot...basically a movie to set up the joke in a trailer. reply ta1243 1 hour agorootparentI'm just so relieved that Disney didn't buy Star Trek. Was slightly concerned by an offhand remark from the Doctor in the most recent Doctor Who series who made an off-hand comment about dropping in on the Star Trek people. reply crazygringo 6 hours agorootparentprevAlso, geographically it belongs to North America. Not Europe. reply ochrist 6 hours agorootparentprevIn that case Greenland is accompanied by their 'sister country' The Faroe Islands, that has a similar status wrt. Denmark and EU. reply layer8 2 hours agoparentprevEU stands for Extended Universe here, probably. ;) https://en.wikipedia.org/wiki/Extended_universe reply kergonath 3 hours agoparentprev> It is correct that Greenland is part of Denmark, and Denmark is a member of EU. But Greenland voted several years ago to stay out of the EU. Greenland is still part of the EU’s overseas countries and territories. It’s not like it’s in a different universe. reply lazide 6 hours agoparentprevSo…. Antman? reply Terr_ 11 hours agoprevTo me, one of the key framing ideas that almost all dates/times are actually a set of matching-rules that you are monitoring for. You can guess how many seconds will elapse until the match triggers, but you can't be totally sure [0] until it happens, and in some cases it will never quite happen at all. [1] Then the second half is often to reverse your \"I think it will happen X seconds from now\" delta-guess into \"I'm also guessing that your timezone's clocks will say Y when it happens.\" Just don't forget to keep track of which timezones is controlling the event versus which timezones it is being displayed in. ____ [1] Your UTC estimate might occur plus or minus leap seconds. TAI is safer, unless somebody discovers something exciting and new that changes the behavior of cesium atoms. [0] Such as if the time zone vanishes because the country is gone. Or perhaps the 1:30 to 2:00 thing couldn't exactly happen because the clocks went forward from 1:00 to 2:00 with a missing hour. reply imrejonk 10 hours agoprevI find it slightly ironic that a blog that’s educating (and entertaining) us on time and timezones does not itself mention when its blogposts were published, at least on mobile. This one appears to have been published in the summer of 2024. reply ajdlinux 6 hours agoparent> This one appears to have been published in the summer of 2024. \"Summer\" in certain parts of the world, at least. reply imrejonk 6 hours agorootparentSharp! reply ucarion 44 minutes agoparentprevThanks! The irony is not missed on me. I think I have the dates internally in the article metadata, just didn't set up my Hugo templates to display it. TODO! reply FateOfNations 7 hours agoparentprevFor a while (currently?) there was SEO \"wisdom\" going around about not putting dates on content so that search engines would treat the content as \"evergreen\" rather than \"stale\". reply Gormo 6 hours agoparentprevI figured I'd check the RSS feed to see the timestamp there, only to discover that this \"blog\" doesn't even have a feed! reply rozenmd 9 hours agoparentprevSeems like pretty timeless content to me. reply tuoret 7 hours agorootparentThere's a couple of things that made me think the article was way older than it actually is (and made me mildly irritated that it doesn't include the publication date). First off, the author starts off by talking about GMT and goes on to educate the reader how UTC is actually the current standard. Maybe it's just me but I thought this would be common knowledge by now, while the author frames this as some sort of a revelation. Then there's the jab about The IERS breaking Wikipedia's css which just doesn't seem to happen on the two devices I opened it on, so I assumed that was the case prior to Wikipedia's redesign. Minor things for sure, and the content itself is pretty timeless (heh). reply AStonesThrow 8 hours agoparentprevWhile there's no explicit publication date, there are a few shell commands which strongly imply that the blogger was writing on or about \"Tue Jul 30 23:52:11 UTC 2024\". reply spockz 12 hours agoprevI really love this way of writing. Informational with occasional bits of humor. It makes it read and ingest. reply Semaphor 11 hours agoparentAgreed, and the humor is restrained. Often there are posts (which tend to also have an annoying amount of gifs) which just overdo it. But here it’s neatly used to lighten the writing. reply ucarion 42 minutes agoparentprevYou should read Matt Levine's Money Stuff! I think his is the tone I roughly was going for here. reply ides_dev 5 hours agoparentprevAbsolutely agreed, it’s a really nice conversational tone. It is technical without being dry and entertaining without watering down the information. I strive to write like this. reply jccalhoun 2 hours agoparentprevI guess I'm alone. I HATED it. reply __alexs 10 hours agoprevI think the old Riyadh timezone is the weirdest personally https://github.com/eggert/tz/blob/be62d5918223b4df209cc94163... reply ucarion 39 minutes agoparentIf you go by the wtf-ness of the comments on a tz, Asia/Riyadh has gotta be up there. But contemporarily it behaves as `-3`, which is vanilla. reply NelsonMinar 1 hour agoparentprevagreed. From pytz's docs: \"the intention was to set sunset to 0:00 local time, the start of the Islamic day. In the best case caused the DST offset to change daily and worst case caused the DST offset to change each instant depending on how you interpreted the ruling\" reply chikere232 2 hours agoprevAt some point, adding software support for these things is just enabling bad ideas. If there wasn't support for Australia/Lord_Howe they might be annoyed into picking a simpler time zone reply aleksi 7 hours agoprevThe most interesting timezone I ever encountered is Europe/Moscow on and around January 1, 1900. If you decide to use that date as a zero date in your code (for example, to handle the transition from two digits per year), you will be in a lot of pain: the offset was +02:30:17. Yes, with 17 seconds! Demo: https://go.dev/play/p/lq36Plr1sIL reply iso8859-1 6 minutes agoparentThe tzdb assumes Local Mean Time (LMT) was used all over. For example, the tzdb has Africa/Monrovia still using LMT in 1970. https://en.wikipedia.org/wiki/Local_mean_time reply prmoustache 11 hours agoprevIn my opinion, the best way to see it is not to pretend their are weird timezones. It is not because most of the world do summer time and that when they do they have a 1h transitions that we should take it for granted. This article do not mention the Chatham Standard Time Zone from Chatham Islands archipelago in NZ which is 45 minutes ahead of New Zealand Daylight Time, nor the Central Western Standard Time (Australia/Eucla). Also wikipedia mention there is a \"train timezone\" for the Indian Pacific train. I wonder if other trains have a dedicated timezone? reply ucarion 30 minutes agoparentI mention Asia/Kathmandu instead of Pacific/Chatham or Australia/Eucla mostly because it's not one of those \"exotic birds / kangaroos outnumber humans 5:1\" kinds of places. reply sakjur 11 hours agoparentprev> I wonder if other trains have a dedicated timezone? They used to, railway time is how our timezone system came to be. reply angrygoat 5 hours agoparentprevThe great thing about Australia/Eucla is that it’s not officially gazetted, and yet there are road signs informing travellers about it. I love that people just do it and everyone goes along reply reisse 9 hours agoparentprev> It is not because most of the world do summer time Eh? Most of the world don't do summer time. reply ComputerGuru 1 hour agorootparentIs that also true by population? reply prmoustache 8 hours agorootparentprevYes for some reason I read the following sentence backwards thinking that 410 timezones were observing DST while 185 did not. > Hmm. 410 timezones just don’t DST at all. 185 have a 3600-second, i.e. 1-hour, difference. My point stands that there is no normality, just governments taking different decisions and being entitled to it and what the majority does is not relevant. reply Scarblac 11 hours agoprevI'm going to steal \"Greenland is part of the greater EU cinematic universe\". reply tankenmate 9 hours agoprev\"Running cron jobs on an hourly basis doesn’t in practice have very weird interactions with DST\" Of course every sane person runs their default system clock on UTC and lets users pick their own local time. That way cron always does the \"right thing\"(TM). reply rubenv 8 hours agoparentThat's true if you need to clean up temporary files every night or make a backup. But what if your cronjob has an effect in the physical world, locally? E.g. open the parking gates every morning. The world is inherently messy :-) reply roryirvine 7 hours agorootparentThat sort of thing would be best handled by your own user's crontab, so would naturally inherit that user's TZ. If you must run it as root, you can specify a CRON_TZ variable on a per-file basis, which will override the default. reply cesarb 4 hours agorootparentprev> That's true if you need to clean up temporary files every night or make a backup. Making a backup is usually reserved for the quietest hours of the morning, so that it does not compete as much for resources with the normal operation of the system; in my experience, the quietest hour is usually around 4:00 local time. reply tankenmate 7 hours agorootparentprevWell assuming that the gates don't move timezones. But obviously jobs that need to run for a given timezone should be configured to run in that timezone. reply cube00 6 hours agorootparentUnless the gates need to open at 2:30am and in the case of daylight savings time that hour is skipped. reply tankenmate 5 hours agorootparentNot if that cron file (you can have multiple cron files per user/system) is configured to run in the local timezone. reply sib 1 hour agorootparentBut then wouldn't the job run twice when time \"falls back\"? reply sgarland 6 hours agoparentprevTangentially, Debian’s vixie-cron did / does handle DST, but it did not handle TZ changes [0], as I discovered. [0]: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1019716 reply ryzvonusef 11 hours agoprevReminds me of when Tom Scott descended into madness at trying to account for time zones: https://www.youtube.com/watch?v=-5wpm-gesOY reply luoc 11 hours agoparentSomehow I end up watching this about twice a year reply LysPJ 10 hours agoprev> America/Nuuk does daylight savings at -01:00 (yes, with a negative) Somewhat related: Europe/Dublin has a negative DST offset. Irish DST runs through the European winter (i.e. the opposite of the other European timezones). (More details here: https://github.com/golang/go/issues/56743#issuecomment-13157... ) Edit: To be clear: the quote is referring to a negative DST start, rather than a negative DST offset. reply extraduder_ire 8 hours agoparentIn the github repo the article links, there is a large number of comments about the Europe/Dublin time zone in the europe file, including one quote from Ulysses: https://github.com/eggert/tz/blob/7748036bace8562b9c047f368c... reply hnbad 10 hours agoparentprevI think you misread that. America/Nuuk doesn't have reverse DST (which is easily solved by just switching DST and non-DST around). It starts DST at a negative offset because the offset is defined as relative to the previous day. reply LysPJ 10 hours agorootparentYes, this is indeed a different situation and my comment doesn't make that clear. Thank for pointing that out. I've made an edit. reply lifthrasiir 11 hours agoprev> These time zones have hundreds of hard-coded transitions out into the future. I don’t understand why, it’s not like they all have lunar calendar stuff going on. Without any additional update to the tz database, all annual transitions are assumed to continue indefinitely. So TZif version 1 would repeat transitions up to January 2038 (i.e. the end of signed 32-bit time_t), while version 2 or later would keep them for the compatibility (see the section 4 of RFC 8536) but also include the algorithmic description in the footer for later dates. reply an-allen 2 hours agoprevObligatory - David Olsen and Paul Eggert - thank you for your service. The world literally works because of your efforts and I don’t feel people really appreciate the ridiculous man made problem that you spent your labours to help resolve. If there was a Hall of Fame of OSS contributors - you would be in it sitting on top of a mountain. The Time Zone problem is a unique problem in that its not just a problem of whats the time in this location - its what was the time in this location 20, 50, 100 years ago. The level of scholarship and historical research you put into this library is really quite unmatched. Amazing folks you two. The whole world quite literally sits on the shoulders of you two giants. “Daylight Saving Time was first suggested as a joke by Benjamin Franklin in his whimsical essay “An Economical Project for Diminishing the Cost of Light” published in the Journal de Paris (1784-04-26). Not everyone is happy with the results.” - Paul Eggert reply NotYourLawyer 13 minutes agoprevI’m so glad I don’t have to think about this stuff for my day job. Just miserable. reply jmbwell 2 hours agoprevThose interested in this kind of pedantry might also take care to note that it’s called “daylight saving time,” with no “s.” It is a system of time for saving daylight. It is not a sales event promising “savings.” Frustrating to read an otherwise excellent and detailed article that makes this error throughout. reply bob1029 10 hours agoprevThe Japanese calendar has always been the most fascinating date/time thing for me: https://devblogs.microsoft.com/dotnet/handling-a-new-era-in-... reply dfc 7 hours agoprevDoes anyone understand what was meant by \"This is because almost every standard (except ISO8601, whatever) is just a file, and you can read it.\" Initially I thought it was because the PDF of ISO-8601 is not a file commonly distributed with operating system. But that's not unique to ISO8601, you won't find IEEE 1588-2019 or NMEA 0183 v4.11 on your computer either. For ~20$ I think I can buy a PDF of the standard from ISO. Is there something special about ISO8601 that is not contained in the standard? reply lozf 1 hour agoparent> For ~20$ I think I can buy a PDF of the standard from ISO. You might find most standards for ~20 USD, but ISO8601 direct from iso.org will set you back 173 CHF (~200 USD) for part 1¹, 194 CHF (~220 USD) for part 2². For $20 you get only the latest amendments from them. Meanwhile the Estonians will gladly sell you their version of part 1 for just under 30 USD.³ ¹: https://www.iso.org/standard/70907.html ²: https://www.iso.org/standard/70908.html ³: https://www.evs.ee/en/evs-iso-8601-1-2019 reply sundarurfriend 2 hours agoparentprevI believe the IEEE and others also would come under the exceptions to the \"almost\" - anything you'd have to make a special effort to seek out and purchase. > Don’t let people bully you into thinking that just because something is complicated, it’s impossible. > This is because almost every standard (except ISO8601, whatever) is just a file, and you can read it. In context, (my interpretation is that) \"standard\" includes things like The Time Zone Information Format [1], the GNU docs about TZ [2], etc. I think the idea is to say \"the documents laying out the details of complicated things are still just documents, you can read them if you're interested and don't have to just see them as meant of domain experts. Some of them have barriers to access like the ISO documents, but even excepting those you have direct access to most everything you might want to understand, don't let the idea of standards intimidate you.\" [1] https://www.rfc-editor.org/rfc/rfc8536.html [2] https://www.gnu.org/software/libc/manual/html_node/TZ-Variab... reply NeoTar 7 hours agoparentprevPossibly joking about the .iso file-type for optical disc images? Or maybe that 'most' ISO standards that are encountered by engineers are defining file-types. I'm also a big fan of ISO-3166 though ! reply nokeya 9 hours agoprevI always say that timezones and font rendering are the most sucking problems that developer can encounter. Both have a ton of weird quirks, both implemented differently across various target devices/OSes and require a lot of time and effort to implement reasonably right. reply lokar 4 hours agoprevI recall working on some calendar software and finding that at some point in the past (you have to deal with all the rules from the past) a country (Saudi Arabia?) had an offset like every day to keep solar noon in line with civil time. reply sebastialonso 4 hours agoprevRelated to the subject, can anyone recommend a book about timezones? Not a technical, programming book, but one with the history of time zones and curious use cases? reply noleary 1 hour agoparentIt is not exactly what you're looking for, but long ago I read this book about the invention of the naval chronometer: https://en.m.wikipedia.org/wiki/Longitude_(book) It's generally pretty well-regarded and closely related. reply fokker 5 hours agoprevA fun read! My brother actually lives on Lord Howe Island along with his wife and 2 daughters. I’m visiting them in a few weeks too actually. I will share this tidbit with them haha. reply uludag 10 hours agoprev> Wrote a script in emacs lisp to calculate Ramadan I found this pretty funny, but a spot on solution. The solar/calendar features of Emacs are surprisingly robust and easy to work with. reply trollied 11 hours agoprevhttps://en.wikipedia.org/wiki/Sandringham_time was a crazy one reply djaychela 10 hours agoprevOddly was just reading something yesterday and it mentioned that in the UK there were years during the war where we had double DST for energy saving reasons. (although we went between 1 hour and 2 hours, so it was only really a change compared to the norm) https://www.atlasobscura.com/articles/the-extreme-daylight-s... reply extraduder_ire 8 hours agoparentI thing, more helpfully, that would better sync up UK time with time on much of the continent. Quite useful if you're doing a lot of things internationally. reply IshKebab 10 hours agoparentprevI don't really understand how that would save energy. Did people work 7am-3pm days or something? reply jdietrich 8 hours agorootparentYesterday in the UK, sunrise was about 7am and sunset was about 4:40pm. Electricity demand peaked at about 5:30pm, in the overlap between workplaces closing for the evening and people returning home and turning everything on. There's a straightforward case for either staying on BST (UTC+1) throughout the year, or (as was the case during WWII) using UTC+2 during summer and UTC+1 during winter, effectively bringing the UK in line with CET/CEST. The key factor in the war was the blackout - street lighting was turned off for the duration and vehicle headlights were mostly covered over, to avoid providing easy targets for night bombing raids. This obviously hugely increased the hazards posed by the early sunsets under GMT. https://www.timeanddate.com/astronomy/uk https://www.energydashboard.co.uk/live https://www.bbc.co.uk/news/articles/c0mznrv3jvmo reply hnbad 10 hours agorootparentprevThe idea behind DST is that it shifts working hours into daylight hours during the darker months. This would theoretically cut down on energy use for lighting during those hours. Of course offices, factories and even schools still use artificial lighting even during daylight hours. And now the energy use of artificial lighting is much lower than back when everything used filament. reply shultays 10 hours agorootparentEven ignoring the energy saving part, it sucks waking up and leaving for work or school while it is still dark. A while ago Turkey switched to a different timezone and stopped doing DST for reasons and now everyone was waking up one hour early in winters. Considering how bad traffic is in larger cities that meant a lot of people will be waking up and going to work or school while it is still dark. reply euroderf 6 hours agorootparentprevI thought the main idea behind it is (or used to be) that kids can go to and return from school in daylight. reply f1shy 10 hours agorootparentprevIt doesn't! That is why some countries want to leave one time for the whole year. When lots of power were used by lighting, it must have saved something... reply 0xbadcafebee 3 hours agoprevEver since I was assigned to work on the school website's calendar when I was in high school, I have successfully avoided any software project having to do with time and date. I feel like my quality of life has been better for it. reply ChrisMarshallNY 9 hours agoprevI’ve found the best way to deal with TZ conversions, is to use UTC as a common fulcrum. I convert the target TZ to UTC, using my local utility, then use my local TZ utility to convert from UTC to local. But I write iOS software, so I have very solid local tools at hand. It might be more problematic, on, say, a webserver. On a related note, I wrote this utility[0], some time ago. It uses the TZ map from the TZ Boundary Builder project[1]. [0] https://github.com/LittleGreenViper/LGV_TZ_Lookup [1] https://github.com/evansiroky/timezone-boundary-builder reply klysm 8 hours agoparentUTC is generally a good idea for storing, but there are still some ways to have that bite you. If a user enters a local date time for a future event in a particular time zone, converting that to UTC could result in incorrect behavior if the timezone definition changes. It depends on if the user meant that UTC time or if they meant the local time. reply Ndymium 6 hours agorootparentIt can also cause trouble if you store past events but do not store the user's local offset or timezone at the time of the event. If you aggregate these events later into a dataset of \"events by hour\", they may be grouped wrong (from a user's perspective) if you convert them all to the user's _current_ timezone. reply bmicraft 7 hours agorootparentprev> if the timezone definition changes Or if DST kicks in/out. No need to have the definitions change. reply klysm 45 minutes agorootparentDepends on how naive the conversion is. If you consider DST while making the conversion that’s not really a problem reply ChrisMarshallNY 7 hours agorootparentprevThat's why I do it at the time the query is made. I don't ever store UTC. reply Tepix 4 hours agoprevI'd like to know the rationale behind these weird timezones, in particular non-hourly offsets to UTC. Why was it chosen that way? Why is it being upheld? It must be a big hassle. Why not switch to a normal 60 minute offset to UTC? reply ucarion 25 minutes agoparenttzdb often has the answer, and it's almost always because everyone used to do local solar time (i.e. on average, the sun is at the top of the sky at noon) until convenience (i.e. train and plane schedules) required an offset friendlier to mental math. reply pvaldes 4 hours agoprevWith the weirdest inhabitants like the legendary Lord Howe Island stick insect, AKA tree lobsters or more informally sausages with legs. A 20 cm long halloweenesque black beauty. reply bjoli 10 hours agoprevA friend of mine has been visiting places with weird time related things going on, because it is interesting and takes you funny places. He has been to Lord Howe. Now I know why. He has a user account on HN. I will ask him if he wants to make an appearance here... reply dv35z 6 hours agoparentPlease do! Announce his arrival using his favorite time zone, and see if we can figure it out... reply jamiehall 9 hours agoprev> Btw it’s called UTC (Universal Time Coordinated? huh?) because the same folks who publish UTC also publish UT1, which is UTC sans the leap seconds. I’m not sure that’s right! According to legend among metrologists I’ve talked to, “UTC” was chosen as a compromise candidate: it makes sense as an acronym in neither English nor French. reply samatman 54 minutes agoparentSo like ISO, then. Which is not an acronym, btw, it's just styled in all caps, and is to be pronounced \"iso\" rather than \"eye-ess-oh\". reply radekk 11 hours agoprevI wonder why the dst transition hours are encoded in local time. Wouldn't it be easier to do it in UTC? There is no need to differentiate between the same hour before and after change then. reply taneliv 10 hours agoparentSuppose in local time (which is, say, UTC+3) the DST transition is on something like \"last Sunday of 10th month at 02:00\", which might then in UTC become \"last Saturday of 10th month at 23:00, except if that Saturday is the last day of the month, then the second to last Saturday\". In effect, if conversion to UTC causes the transition to move to a different day, it might also be on a different week or month, causing headache. (Or did you ask something else entirely? It wouldn't be the first time I misunderstood things about time zones.) reply winternewt 11 hours agoparentprevPerhaps to decouple DST transition rules from other time-zone changes. So if the time-zone offset is adjusted for some other reason then the DST rule does not also need to be changed. reply benreesman 12 hours agoprevSo this is a thing: I caught the Snake emoji behaving differently in some code because it was coded one thing before #celebrity-thing, and the opposite months later. Snake Emoji Kanye vibes are the weirdest timezone. reply pests 11 hours agoparentWait, how is it different before/after? reply twelvechairs 10 hours agoprevAlong with Kathmandu for weird offsets is Australian Central Western Standard Time (UTC +8:45), used in a tiny area of Australia with the largest town being Eucla (population 37). Being mainly within Western Australia (which doesn't use daylight savings) but partially within South Australia (which does use daylight savings) there has also been informal use of UTC+9:45 Historically there was also Dublin mean time (UTC -00:25.21) and Warsaw mean time (UTC+1:24) reply ajdlinux 6 hours agoparentAn interesting aspect of ACWST is that it has no legal status - it's observed purely by local convention, though it's still managed to make it into tzdata. reply antisol 3 hours agorootparentindeed! and not only is it in tzdata, there are signs on the road telling you about it reply szemy2 9 hours agoprev> With a “designator” time that doesn’t mean much This might not 'mean much' to the computer, but it means a lot to the human. The computer uses it to communicate with the human and the humans between each other. When I arrange a meeting across timezones I will say CET 16.00 or ET3.00PM and they will understand it faster than saying how much offset we are from UCT. reply captn3m0 11 hours agoprevThe tz-iana mailing list is a lot of fun to subscribe to. reply floitsch 11 hours agoprevI implemented `DateTime` in Dart and Toit and wrote a blog post about the things I noticed: https://medium.com/@florian_32814/date-time-526a4f86badb Timezones are fun... reply vander_elst 9 hours agoprevI still hope that someday the whole world will run on UTC0 and there is no more time zones madness. I know the day will likely never come but I like to keep dreaming. reply hypeatei 8 hours agoparentI'd rather timezones be split based on actual logic rather than politics and eliminate things like daylight savings. It's insane to me that China has one timezone because they felt like it. People must sleep terribly in certain regions. reply marcthe12 7 hours agorootparentYep. And the logic can be made very easy. Outside polar regions or outer space, timezone could simply be the longitude/15 degrees rounded to a constant fraction. This is not perfect as cities maybe in 2 time zones but this basically a really good approximation. reply sethammons 8 hours agoparentprevSome dates will change when at relatively strange times. For some, the date change will be two hours into the workday. That seems odd. And you lose some info too: if I want a 07:30 (am) meeting, is that during the working hours of my target location? With offsets, I can see that it is 12:30pm at my target location and know that I am scheduling over lunch very likely. With no timezones, how do I know what time of day it is there? Recall some anchor time and do mental math each time? \"Morning in London is 13:00, so four hours later right before lunch is 17:00, and for an LA meeting, let's see, morning there is 05:00, so 17:00 is evening time, I think reply vander_elst 8 hours agorootparent> the date change will be two hours into the workday. That seems odd Seconds minutes and hours can change but the day cannot? > mental math each time Usually meetings are setup using an app and shared calendars should actually help here, a person can have meeting slots and out of office time, that should provide the same info. logistically I don't see that much of a difference from the current situation reply iggldiggl 3 hours agorootparent> Seconds minutes and hours can change but the day cannot? The calendar day being aligned to the sleep/wake cycle and changing when most of the population is either asleep or at least might not terribly care about the actual date does help quite a bit. > Usually meetings are setup using an app and shared calendars should actually help here, a person can have meeting slots and out of office time, that should provide the same info. logistically I don't see that much of a difference from the current situation It'd also wreck any time references in any kinds of stories that aren't consumed locally. So every time I read/watch/listen to a story that isn't set where I live, I'd first have to look up the local time to make sense of any time references. reply Aidevah 4 hours agoprev> Unless you’re doing some fairly exotic things where you’re finding yourself saying things like >> Oh yeah the OCR on Japanese driving licenses pops out things like “平成 8”, that’s just how they sometimes say 1996 over there. That’s why we have this in the parser: eras = { \"大正\": 1912, \"昭和\": 1926, \"平成\": 1989 } >> One of these days we’ll need to add \"令和\": 2019, but it hasn’t come up yet. Taiwan also uses the ROC calendar[1] which is directly descended from the regnal calendars of imperial china. But it's quaint that the Japanese name their year after one person, while us enlightened westerners simply use a calendar where it's simply the 2024th year of the, erm, hmmmph... [1] https://en.wikipedia.org/wiki/Republic_of_China_calendar reply Kwpolska 7 hours agoprev> Yeah, this stuff is weird, but only finitely so, because ultimately a computer’s gotta implement them Historic data can be recorded. Rules like \"last Sunday in October\" or \"first day of Ramadan\" can be implemented and handled automatically (even if the current Unix implementations don’t do non-Gregorian calendars out-of-the-box). But there can be time zones whose DST rules are \"if the groundhog sees its shadow, we start DST two weeks later, otherwise, there is no DST this year\". Some countries actually implement this, except the groundhog is replaced by your friendly local regime. reply stevage 8 hours agoprevThis is awesome - I have always kind of wondered how this stuff was implemented, but never looked it up. reply bradley13 9 hours agoprevHard-coded yearly transitions for a particular region, because they just have to have their own, special rules? Transitioning to DST on Sunday at -01:00 (minus one o'clock)? Or at 24:00? Honestly, the IT world has a certain amount of influence. There comes a time where we could collectively just say \"no\". No, you are not that special, use any of the already incredibly flexible options that you have. reply magnio 9 hours agoparent> There comes a time where we could collectively just say \"no\" Well, C23 mandates a byte is 8 bits, and POSIX 2024 disallows newlines in filename, so we do exercise that right times to times. reply growse 9 hours agoparentprevI think you've got who's serving whom the wrong way round. reply surfingdino 12 hours agoprevI love time/date problems. One of the best references on the subject of calendars is \"Standard C Date/Time Library: Programming the World's Calendars and Clocks\" by Lance Latham. He really goes into a lot of detail on various calendaring systems, some really cooky, https://amzn.to/4hjv5L3 BTW. A long, informative post without a single mention of AI. A rare thing these days. reply notachatbot123 11 hours agoparentClean link without affiliate code: https://www.amazon.co.uk/Standard-Date-Time-Library-Programm... reply import 11 hours agoprevNice morning reading reply gonzo41 5 hours agoprevI lived in Hobart for a while and I was a firm proponent of having a Tassie south timezone that had a 2 hour winter shift to get some afternoon light. That six week pit in winter when the sun goes down at 430pm is tough. reply jiggawatts 11 hours agoprevOh wow, what a coincidence, I was just looking at Lord Howe Island on a map of species conservation. For anyone who doesn't know: Lord Howe Island is the last true paradise on Earth. I went there on holidays a few years back based on two travel review recommendations. Both were by professional travellers that had been to pretty much everywhere, and both said it's the best place they've ever been. The reasoning was that every other tropical island has \"something\" wrong with it. Pushy locals trying to sell you stuff, sharks in the water, malaria, pollution, crime, poverty, or something. Lord Howe is about as safe as it's possible to get, civilised beyond belief, pristine, unpolluted, etc... It's one of the last places in the world with undamaged, unbleached coral reefs in protected waters. The diving there is just unbelievable, more beautiful than any Planet Earth documentary you've seen. Birds nest on the beach, and you have to step over them gently because there's thousands of them and the juveniles can't fly yet. I met the police officer of the island and pointedly asked him when was the last time he had to deal with crime. \"Crime... crime... let's see.\" he said, counting on his fingers slowly \"Umm... seven years ago there was a domestic violence report because a tourist slapped his wife in an argument.\" The hotel doors have no locks. There's $500 in cash in a tin next to a shack full of equipment on the beach with a \"honesty system\" rental price list sign next to it. The bloke selling you coke cans at the milk bar bought it with the $20 million he made in the stock market. Half the tourists go there by private plane. Ballmer's son took his super yacht there with a harem of models. And on, and on. If you ever get the opportunity to visit: GO! reply danielvaughn 3 hours agoprevJust wait until we decide on a time zone for the moon, or Mars. reply perlgeek 3 hours agoparentMars days are longer than Earth days, so a time zone alone won't do. I think I actually heard on a podcast that some Mars rover mission team had to operate in shifts that were synchronized with Mars days. reply twojastara 4 hours agoprevGUWNO JEBANE reply IgorPartola 6 hours agoprevI know this is a popular sentiment here but it bears repeating: timezones need to go away. Time according to timezones measures the position of the sun. Except when we clearly decide with daylight savings time that we don’t care about the position of the sun, we just want it to be a certain time. When the sun is directly over NYC it is usually 1pm or 2pm, depending on time of year, but 5pm or 6pm in London. Why? Are these events happening at different times? No, they are happening at the same time. Why do we use a different number for them? Your “time zone” may decide that generally the workday is from 14:00 to 22:00. Why not? We already have second and third shift workers, so the idea of 9-5 is dead anyways. When I schedule a meeting with someone in Tokyo and I am in NYC, is the meeting not happening at the same time? Wouldn’t it be easier to say “let’s do it at 13:00”? We still would need to figure out if people are awake and at work but we have to do that now while also figuring out daylight savings, so not only time but day of the year matters. Heaven forbid you schedule a meeting or an event or a delivery or a stock trade and your time zone gets helpfully updated after you schedule the thing but before it happens. Better hope all the processes and software get that right or else! And here is my favorite example I recently encountered: what is the speed of federal laws in the US? Say the tax brackets are rewritten for 2025, starting “January 1”. Cool, so if you work the NYE shift from 8pm to 4am in Chicago, is it the DC timezone that matters for your taxes? The local? If cannabis is legalized starting at midnight but you get arrested for possession at 11pm the day before in LA are you wrongfully detained or did you miss it by one hour? Timezones are 19th century thinking. We can do better. reply aniforprez 6 hours agoparentUnless you can propose a proper way to locally represent time where a person is currently present in relation to the position of the sun then no, time zones will never go away. I know time zones suck for us as programmers but it's a practical way to separate different regions that will experience different times of day differently. As long as we have clocks and times with \"midnight\"s and \"noon\"s, time zones will exist. I assume once we truly become an interplanetary species and colonise multiple planets, we will begin to use different methods of time since 24 hour/365 day clocks are going to be an Earth only thing but that's for future scientists to decide. There were proposals for daylight savings to go away but that seems to have disappeared into the ether for some reason. reply IgorPartola 6 hours agorootparentJust because you personally are used to a specific type of clock doesn’t mean you can’t imagine a different kind. Submarines use 24 hour clocks and give no hecks about where the sun is. The solution is to just use UTC. That’s it. That means in NYC you’d get to work at 13:00 and go home at 21:00, which used to be 9am-5pm. That’s it. Your whole transition has been completed. The rest is just what your calendar says. Niece’s recital on Thursday at 19:00, beers with Greg at 23:00 on Friday, etc. It really isn’t hard to imagine. reply coldpie 5 hours agorootparent> The solution is to just use UTC. That’s it. Okay. I work in Minneapolis and need to schedule a meeting with someone in London. How do I know what UTC time is during daylight hours for both participants? Well, we can use a formula that will tell us where the sun in the sky for a given longitude. But that's kind of a chore. So let's break ranges of longitude into zones and create a lookup table. Hang on a minute... I've just traveled to Tokyo from Minneapolis. What time do I need to set my alarm to, to wake up an hour before most businesses open? Well, I can use trigonometry to figure out what UTC time the sun will rise at this location on Earth. But that's kind of a chore, so presumably each city will have an offset from UTC time that they all agree on to begin business hours. Hang on a minute... reply Tor3 4 hours agorootparentprev>That means in NYC you’d get to work at 13:00 and go home at 21:00, Fine.. so I'm going to have a teleconference with a company in NYC. Due to what you wrote above I now have an idea of what UTC time window to plan for - after all, I want to be able to reach them during their working hours. Then on Friday I have to schedule a teleconf with a company in Japan. When do they work, relative to UTC? You forgot to add that, so I have to find it somewhere. Hm, wouldn't it be nice if my computer could keep track of the working hours everywhere in the world. Let's make a database of that.. There's just one issue: How is this any better than using the timezone system we already have? Using that, I can figure out the local time in those places, and I can safely assume that they'll at least be working from around 09:00 local time. Having to instead keep track of their working hours relative to UTC doesn't seem like much of an improvement to me. reply vundercind 5 hours agorootparentprevTraveling would be so much more disorienting. Forgetting what the local daytime range is and checking the position of the sun to guess whether you're closer to the front or back half of the day. Having to consult a table to figure out exactly how much you're going to inconvenience the person giving you a ride from the airport. Accidentally running into rush hour because you forgot that 1100 is 5:00 here. LOL. reply hugh-avherald 5 hours agorootparentprevWhy don't people just do this then? There's no overwhelming obligation on individuals to use the local timezone. I also think that your using the example of submarines -- notoriously an onerous lifestyle that very few are capable of living -- pretty much torpedoes your implicit suggestion that this would not be too much of a change. reply rswail 4 hours agorootparent> pretty much torpedoes your implicit suggestion that this would not be too much of a change. You did that on porpoise I hope. reply ta1243 5 hours agorootparentprevOK, you're in LA. You finish work at 2300 on Monday. You have plans to go to the theatre on Tuesday after work. Is that 0100 on Tuesday (after finishing at 2300 on Monday) or 0100 on Wednesday (after finishing at 2300 on Tuesday) reply iggldiggl 3 hours agorootparentAlong the same vein… how are public holidays supposed to be handled? Do those always start and finish at midnight UTC, even if midnight UTC happens to be right during the middle of the solar day (and everybody's waking hours)? Or does every place define a specific time (aligned to solar midnight or some other suitable point during the night) for when holidays are supposed to start and e",
    "originSummary": [
      "Timezones can be complex, with unique cases like Australia/Lord_Howe's 30-minute daylight savings transition and Asia/Kathmandu's 5-hour 45-minute offset from UTC.",
      "The IANA Timezone Database manages timezones using hard-coded transitions and rules, ensuring accurate time conversion despite their complexity.",
      "While timezones are finite and mostly follow the Gregorian calendar, leap seconds are generally ignored in programming, simplifying their management."
    ],
    "commentSummary": [
      "Australia/Lord_Howe is notable for its unusual half-hour daylight savings time difference, making it one of the most peculiar time zones.",
      "The tz database, responsible for global time zone data, deals with unique challenges such as not calculating time before the Big Bang and managing leap seconds.",
      "Time zones like Africa/Addis_Ababa and the Palestinian time zone present additional complexities, with local practices and sudden daylight savings changes posing programming challenges."
    ],
    "points": 817,
    "commentCount": 333,
    "retryCount": 0,
    "time": 1730269265
  },
  {
    "id": 41995701,
    "title": "M4 MacBook Pro",
    "originLink": "https://www.apple.com/newsroom/2024/10/new-macbook-pro-features-m4-family-of-chips-and-apple-intelligence/",
    "originBody": "PRESS RELEASE October 30, 2024 Apple’s new MacBook Pro features the incredibly powerful M4 family of chips and ushers in a new era with Apple Intelligence With an advanced 12MP Center Stage camera, Thunderbolt 5 on M4 Pro and M4 Max models, and an all-new nano-texture display option, MacBook Pro gets even more capable and even more pro Supercharged by Apple Intelligence, even more powerful Apple silicon with the M4 family of chips, and new capabilities, MacBook Pro accelerates pro workloads like never before. CUPERTINO, CALIFORNIA Apple today unveiled the new MacBook Pro, powered by the M4 family of chips — M4, M4 Pro, and M4 Max — delivering much faster performance and enhanced capabilities. The new MacBook Pro is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. Now available in space black and silver finishes, the 14-inch MacBook Pro includes the blazing-fast performance of M4 and three Thunderbolt 4 ports, starting with 16GB of memory, all at just $1,599. The 14- and 16-inch models with M4 Pro and M4 Max offer Thunderbolt 5 for faster transfer speeds and advanced connectivity. All models include a Liquid Retina XDR display that gets even better with an all-new nano-texture display option and up to 1000 nits of brightness for SDR content, an advanced 12MP Center Stage camera, along with up to 24 hours of battery life, the longest ever in a Mac.1 The new MacBook Pro is available to pre-order today, with availability beginning November 8. “MacBook Pro is an incredibly powerful tool that millions of people use to do their life’s best work, and today we’re making it even better,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With the powerful M4 family of chips, and packed with pro features like Thunderbolt 5, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and Apple Intelligence, the new MacBook Pro continues to be, by far, the world’s best pro laptop.” A look at the front and the back of the new MacBook Pro. A close-up of the keyboard on the new MacBook Pro. The new MacBook Pro is transformed with Apple Intelligence, the blazing performance of the M4 family, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and more. The new MacBook Pro is transformed with Apple Intelligence, the blazing performance of the M4 family, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and more. previous next Supercharged by the M4 Family of Chips Built using second-generation 3-nanometer technology, the M4 family is the most advanced lineup of chips for a personal computer. The M4 family features phenomenal single-threaded CPU performance with the world’s fastest CPU core,2 along with outstanding multithreaded CPU performance for the most demanding workloads. Combined with machine learning accelerators in the CPU, an advanced GPU, and a faster and more efficient Neural Engine, Apple silicon is built from the ground up to deliver incredible performance for AI. Together with faster unified memory, each chip also includes increased memory bandwidth, so large language models (LLMs) and other large projects run smoothly and on device. Additionally, the industry-leading performance per watt of the M4 family means that users get up to 24 hours of battery life, raising the bar of what users can do on a single charge. The new MacBook Pro features the M4 family of chips, the most advanced lineup of chips ever built for a pro laptop. New 14-inch MacBook Pro with M4 The 14-inch MacBook Pro with M4 is the ideal choice for entrepreneurs, students, creators, or anyone doing what they love. Featuring a more powerful 10-core CPU, with four performance cores and six efficiency cores, and a faster 10-core GPU with Apple’s most advanced graphics architecture, the new MacBook Pro starts with 16GB of faster unified memory with support for up to 32GB, along with 120GB/s of memory bandwidth. With M4, MacBook Pro is up to 1.8x faster than the 13-inch MacBook Pro with M1 for tasks like editing gigapixel photos, and even more demanding workloads like rendering complex scenes in Blender are up to 3.4x faster.1 With a Neural Engine that’s over 3x more powerful than in M1, it’s great for features in Apple Intelligence and other AI workloads. The M4 model also supports two high-resolution external displays in addition to the built-in display, and now features three Thunderbolt 4 ports so users can connect all their peripherals. MacBook Pro empowers users to work and be creative wherever they are, with even more game-changing performance and extraordinary battery life. MacBook Pro with M4 delivers:1 Up to 7x faster image processing in Affinity Photo when compared to the 13‑inch MacBook Pro with Core i7, and up to 1.8x faster when compared to the 13-inch MacBook Pro with M1. Up to 10.9x faster 3D rendering in Blender when compared to the 13‑inch MacBook Pro with Core i7, and up to 3.4x faster when compared to the 13‑inch MacBook Pro with M1. Up to 9.8x faster scene edit detection in Adobe Premiere Pro when compared to the 13‑inch MacBook Pro with Core i7, and up to 1.7x faster when compared to the 13‑inch MacBook Pro with M1. M4 brings phenomenal performance to the new 14-inch MacBook Pro, from creative tasks to even more demanding workloads such as rendering complex scenes in Blender. MacBook Pro with M4 Pro: A Pro Powerhouse For researchers, developers, engineers, creative pros, or anyone that needs even faster performance for more demanding workflows, MacBook Pro with M4 Pro offers a tremendous performance boost. M4 Pro features a powerful 14-core CPU with 10 performance cores and four efficiency cores for a jump in multicore performance, along with up to a 20-core GPU that is twice as powerful as M4. With M4 Pro, the new MacBook Pro gets a massive 75 percent increase in memory bandwidth over the prior generation — double that of any AI PC chip.3 The new MacBook Pro with M4 Pro is up to 3x faster than models with M1 Pro, speeding up workflows like geo mapping, structural engineering, and data modeling.1 The new 14- and 16-inch MacBook Pro with M4 Pro is ideal for researchers, developers, engineers, creative pros, or for anyone looking for even faster performance. MacBook Pro with M4 Pro offers:1 Up to 4x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Core i9, and up to 3x faster when compared to the 16-inch MacBook Pro with M1 Pro. Up to 5x faster simulation of dynamical systems in MathWorks MATLAB when compared to the 16-inch MacBook Pro with Core i9, and up to 2.2x faster when compared to the 16-inch MacBook Pro with M1 Pro. Up to 23.8x faster basecalling for DNA sequencing in Oxford Nanopore MinKNOW when compared to the 16-inch MacBook Pro with Core i9, and up to 1.8x faster when compared to the 16-inch MacBook Pro with M1 Pro. A user works in Fusion on the new MacBook Pro. A user works in Luna Modeler on the new MacBook Pro. A user works in Xcode on the new MacBook Pro. The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more. The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more. The new MacBook Pro with M4 Pro speeds up a variety of workflows such as structural engineering, data modeling, and more. previous next MacBook Pro with M4 Max: The Ultimate in Pro Performance Designed for pros like data scientists, 3D artists, and composers who constantly push workflows to the limit, MacBook Pro with M4 Max empowers users to work on projects that were previously only imaginable on a desktop. M4 Max brings up to a 16-core CPU, up to a 40-core GPU, over half a terabyte per second of unified memory bandwidth, and a Neural Engine that is over 3x faster than M1 Max, allowing on-device AI models to run faster than ever. With M4 Max, MacBook Pro delivers up to 3.5x the performance of M1 Max, ripping through heavy creative workloads like visual effects, 3D animation, and film scoring.1 It also supports up to 128GB of unified memory, so developers can easily interact with LLMs that have nearly 200 billion parameters. And with the powerful Media Engine in M4 Max, which features two ProRes accelerators, MacBook Pro performance is amazing even when taking 4K120 fps ProRes video captured with the new iPhone 16 Pro and editing it in Final Cut Pro. MacBook Pro with M4 Max enables:1 Up to 7.8x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Intel Core i9, and up to 3.5x faster when compared to the 16-inch MacBook Pro with M1 Max. Up to 4.6x faster build performance when compiling code in Xcode when compared to the 16‑inch MacBook Pro with Intel Core i9, and up to 2.2x faster when compared to the 16‑inch MacBook Pro with M1 Max. Up to 30.8x faster video processing performance in Topaz Video AI when compared to the 16‑inch MacBook Pro with Intel Core i9, and up to 1.6x faster when compared to the 16-inch MacBook Pro with M1 Max. Flame is shown on MacBook Pro with M4 Max. LM Studio is shown on MacBook Pro with M4 Max. With M4 Max, MacBook Pro rips through the heaviest creative workloads like visual effects, 3D animation, and film scoring. With support for up to 128GB of unified memory, developers can easily interact with LLMs that have nearly 200 billion parameters. previous next Industry-Leading Liquid XDR Display Gets Even Better The new MacBook Pro introduces an all-new nano-texture display option that dramatically reduces glare and distractions from reflections. In bright lighting conditions, the new MacBook Pro can now show SDR content at up to 1000 nits and still displays HDR content at up to 1600 nits of peak brightness. All together, it’s a game-changing experience for users working outdoors. A game changer when working outdoors, the Liquid Retina XDR display gets even better with an all-new nano-texture display option and up to 1000 nits of brightness for SDR content. New 12MP Center Stage Camera MacBook Pro includes a new 12MP Center Stage camera that delivers enhanced video quality in challenging lighting conditions. Video calls are even more engaging with Center Stage, which automatically keeps users centered in the frame as they move around. The new camera also supports Desk View, which adds a whole new dimension to video calls. And with studio-quality mics and a phenomenal six-speaker sound system with support for Spatial Audio, MacBook Pro delivers an incredibly immersive audio experience whether users are listening to music or watching a movie in Dolby Atmos. MacBook Pro features a new 12MP Center Stage camera, which keeps users centered in the frame, and supports Desk View, which adds a whole new dimension to video calls. Thunderbolt 5 Comes to the Mac MacBook Pro with M4 Pro and M4 Max features Thunderbolt 5 ports that more than double transfer speeds up to 120 Gb/s, enabling faster external storage, expansion chassis, and powerful docking and hub solutions. For example, by connecting just a single cable, pros like music producers can now light up their entire studio. All MacBook Pro models feature an HDMI port that supports up to 8K resolution, a SDXC card slot, a MagSafe 3 port for charging, and a headphone jack, along with support for Wi-Fi 6E and Bluetooth 5.3. MacBook Pro with M4 Pro and M4 Max now features Thunderbolt 5 with faster transfer speeds that enable powerful docking and hub solutions, allowing pros to connect to higher-bandwidth gear with a single cable. A New Era with Apple Intelligence on the Mac Apple Intelligence ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools. Apple Intelligence transforms the things users do every day on their Mac. With brand-new Writing Tools, users can rewrite, proofread, or summarize everything from daily emails to important projects. Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply. An Unrivaled Experience with macOS Sequoia macOS Sequoia completes the new MacBook Pro experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and notifications directly from their Mac.4 Safari, the world’s fastest browser,5 now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply new beautiful built-in backgrounds for video calls, which include a variety of color gradients and system wallpapers, or upload their own photos. The Perfect Time to Upgrade or Switch to a Mac Upgraders will get monumental improvements over Intel-based MacBook Pro models, including the amazing features of Apple Intelligence. When compared to an Intel-based MacBook Pro, the new MacBook Pro provides nearly 10x faster performance for AI-based workloads,1 and for graphics-intensive workloads, users get up to 20x faster performance.6 With battery life on the new MacBook Pro now up to 24 hours, upgraders will also experience up to 14 additional hours. And with the Liquid Retina XDR display, a new 12MP Center Stage camera, an immersive six-speaker sound system, the unrivaled experience of macOS Sequoia, and more, there’s never been a better time to upgrade or switch to MacBook Pro. MacBook Air: The World’s Most Popular Laptop Now Starts at 16GB MacBook Air is the world’s most popular laptop, and with Apple Intelligence, it’s even better. Now, models with M2 and M3 double the starting memory to 16GB, while keeping the starting price at just $999 — a terrific value for the world’s best-selling laptop. Better for the Environment The new MacBook Pro is built to last and incredibly durable, created from a custom alloy that uses 100 percent recycled aluminum in the enclosure. It also uses 100 percent recycled rare earth elements in all magnets, and 100 percent recycled tin soldering, gold plating, and copper in multiple printed circuit boards. The packaging for the 14-inch MacBook Pro is now entirely fiber-based, joining the 16-inch MacBook Pro and bringing Apple closer to its goal to remove plastic from its packaging by 2025. Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade. Pricing and Availability Customers can pre-order the new MacBook Pro starting today, October 30, on apple.com/store and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8. The 14-inch MacBook Pro with M4 starts at $1,599 (U.S.) and $1,499 (U.S.) for education; the 14‑inch MacBook Pro with M4 Pro starts at $1,999 (U.S.) and $1,849 (U.S.) for education; and the 16‑inch MacBook Pro starts at $2,499 (U.S.) and $2,299 (U.S.) for education. All models are available in space black and silver. Additional technical specifications, including the nano-texture display and configure-to-order options, are available at apple.com/mac. MacBook Air with M2 and M3 comes standard with 16GB of unified memory, and is available in midnight, starlight, silver, and space gray, starting at $999 (U.S.) and $899 (U.S.) for education. New accessories with USB-C — including Magic Keyboard ($99 U.S.), Magic Keyboard with Touch ID ($149 U.S.), Magic Keyboard with Touch ID and Numeric Keypad ($179 U.S.), Magic Trackpad ($129 U.S.), Magic Mouse ($79 U.S.), and Thunderbolt 5 Pro Cable ($69) — are available at apple.com/store. Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come. Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in Australia, Canada, Ireland, New Zealand, South Africa, and the U.K., and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported. With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit apple.com/shop/trade-in to see what their device is worth. AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best. Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store. Share article Media Text of this article October 30, 2024 PRESS RELEASE Apple’s new MacBook Pro features the incredibly powerful M4 family of chips and ushers in a new era with Apple Intelligence With an advanced 12MP Center Stage camera, Thunderbolt 5 on M4 Pro and M4 Max models, and an all-new nano-texture display option, MacBook Pro gets even more capable and even more pro CUPERTINO, CALIFORNIA Apple today unveiled the new MacBook Pro, powered by the M4 family of chips — M4, M4 Pro, and M4 Max — delivering much faster performance and enhanced capabilities. The new MacBook Pro is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. Now available in space black and silver finishes, the 14-inch MacBook Pro includes the blazing-fast performance of M4 and three Thunderbolt 4 ports, starting with 16GB of memory, all at just $1,599. The 14- and 16-inch models with M4 Pro and M4 Max offer Thunderbolt 5 for faster transfer speeds and advanced connectivity. All models include a Liquid Retina XDR display that gets even better with an all-new nano-texture display option and up to 1000 nits of brightness for SDR content, an advanced 12MP Center Stage camera, along with up to 24 hours of battery life, the longest ever in a Mac.1 The new MacBook Pro is available to pre-order today, with availability beginning November 8. “MacBook Pro is an incredibly powerful tool that millions of people use to do their life’s best work, and today we’re making it even better,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With the powerful M4 family of chips, and packed with pro features like Thunderbolt 5, an advanced 12MP Center Stage camera, an all-new nano-texture display option, and Apple Intelligence, the new MacBook Pro continues to be, by far, the world’s best pro laptop.” Supercharged by the M4 Family of Chips Built using second-generation 3-nanometer technology, the M4 family is the most advanced lineup of chips for a personal computer. The M4 family features phenomenal single-threaded CPU performance with the world’s fastest CPU core,2 along with outstanding multithreaded CPU performance for the most demanding workloads. Combined with machine learning accelerators in the CPU, an advanced GPU, and a faster and more efficient Neural Engine, Apple silicon is built from the ground up to deliver incredible performance for AI. Together with faster unified memory, each chip also includes increased memory bandwidth, so large language models (LLMs) and other large projects run smoothly and on device. Additionally, the industry-leading performance per watt of the M4 family means that users get up to 24 hours of battery life, raising the bar of what users can do on a single charge. New 14-inch MacBook Pro with M4 The 14-inch MacBook Pro with M4 is the ideal choice for entrepreneurs, students, creators, or anyone doing what they love. Featuring a more powerful 10-core CPU, with four performance cores and six efficiency cores, and a faster 10-core GPU with Apple’s most advanced graphics architecture, the new MacBook Pro starts with 16GB of faster unified memory with support for up to 32GB, along with 120GB/s of memory bandwidth. With M4, MacBook Pro is up to 1.8x faster than the 13-inch MacBook Pro with M1 for tasks like editing gigapixel photos, and even more demanding workloads like rendering complex scenes in Blender are up to 3.4x faster.1 With a Neural Engine that’s over 3x more powerful than in M1, it’s great for features in Apple Intelligence and other AI workloads. The M4 model also supports two high-resolution external displays in addition to the built-in display, and now features three Thunderbolt 4 ports so users can connect all their peripherals. MacBook Pro with M4 delivers:1 Up to 7x faster image processing in Affinity Photo when compared to the 13‑inch MacBook Pro with Core i7, and up to 1.8x faster when compared to the 13-inch MacBook Pro with M1. Up to 10.9x faster 3D rendering in Blender when compared to the 13‑inch MacBook Pro with Core i7, and up to 3.4x faster when compared to the 13‑inch MacBook Pro with M1. Up to 9.8x faster scene edit detection in Adobe Premiere Pro when compared to the 13‑inch MacBook Pro with Core i7, and up to 1.7x faster when compared to the 13‑inch MacBook Pro with M1. MacBook Pro with M4 Pro: A Pro Powerhouse For researchers, developers, engineers, creative pros, or anyone that needs even faster performance for more demanding workflows, MacBook Pro with M4 Pro offers a tremendous performance boost. M4 Pro features a powerful 14-core CPU with 10 performance cores and four efficiency cores for a jump in multicore performance, along with up to a 20-core GPU that is twice as powerful as M4. With M4 Pro, the new MacBook Pro gets a massive 75 percent increase in memory bandwidth over the prior generation — double that of any AI PC chip.3 The new MacBook Pro with M4 Pro is up to 3x faster than models with M1 Pro, speeding up workflows like geo mapping, structural engineering, and data modeling.1 MacBook Pro with M4 Pro offers:1 Up to 4x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Core i9, and up to 3x faster when compared to the 16-inch MacBook Pro with M1 Pro. Up to 5x faster simulation of dynamical systems in MathWorks MATLAB when compared to the 16-inch MacBook Pro with Core i9, and up to 2.2x faster when compared to the 16-inch MacBook Pro with M1 Pro. Up to 23.8x faster basecalling for DNA sequencing in Oxford Nanopore MinKNOW when compared to the 16-inch MacBook Pro with Core i9, and up to 1.8x faster when compared to the 16-inch MacBook Pro with M1 Pro. MacBook Pro with M4 Max: The Ultimate in Pro Performance Designed for pros like data scientists, 3D artists, and composers who constantly push workflows to the limit, MacBook Pro with M4 Max empowers users to work on projects that were previously only imaginable on a desktop. M4 Max brings up to a 16-core CPU, up to a 40-core GPU, over half a terabyte per second of unified memory bandwidth, and a Neural Engine that is over 3x faster than M1 Max, allowing on-device AI models to run faster than ever. With M4 Max, MacBook Pro delivers up to 3.5x the performance of M1 Max, ripping through heavy creative workloads like visual effects, 3D animation, and film scoring.1 It also supports up to 128GB of unified memory, so developers can easily interact with LLMs that have nearly 200 billion parameters. And with the powerful Media Engine in M4 Max, which features two ProRes accelerators, MacBook Pro performance is amazing even when taking 4K120 fps ProRes video captured with the new iPhone 16 Pro and editing it in Final Cut Pro. MacBook Pro with M4 Max enables:1 Up to 7.8x faster scene rendering performance with Maxon Redshift when compared to the 16-inch MacBook Pro with Intel Core i9, and up to 3.5x faster when compared to the 16-inch MacBook Pro with M1 Max. Up to 4.6x faster build performance when compiling code in Xcode when compared to the 16‑inch MacBook Pro with Intel Core i9, and up to 2.2x faster when compared to the 16‑inch MacBook Pro with M1 Max. Up to 30.8x faster video processing performance in Topaz Video AI when compared to the 16‑inch MacBook Pro with Intel Core i9, and up to 1.6x faster when compared to the 16-inch MacBook Pro with M1 Max. Industry-Leading Liquid XDR Display Gets Even Better The new MacBook Pro introduces an all-new nano-texture display option that dramatically reduces glare and distractions from reflections. In bright lighting conditions, the new MacBook Pro can now show SDR content at up to 1000 nits and still displays HDR content at up to 1600 nits of peak brightness. All together, it’s a game-changing experience for users working outdoors. New 12MP Center Stage Camera MacBook Pro includes a new 12MP Center Stage camera that delivers enhanced video quality in challenging lighting conditions. Video calls are even more engaging with Center Stage, which automatically keeps users centered in the frame as they move around. The new camera also supports Desk View, which adds a whole new dimension to video calls. And with studio-quality mics and a phenomenal six-speaker sound system with support for Spatial Audio, MacBook Pro delivers an incredibly immersive audio experience whether users are listening to music or watching a movie in Dolby Atmos. Thunderbolt 5 Comes to the Mac MacBook Pro with M4 Pro and M4 Max features Thunderbolt 5 ports that more than double transfer speeds up to 120 Gb/s, enabling faster external storage, expansion chassis, and powerful docking and hub solutions. For example, by connecting just a single cable, pros like music producers can now light up their entire studio. All MacBook Pro models feature an HDMI port that supports up to 8K resolution, a SDXC card slot, a MagSafe 3 port for charging, and a headphone jack, along with support for Wi-Fi 6E and Bluetooth 5.3. A New Era with Apple Intelligence on the Mac Apple Intelligence ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools. Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply. An Unrivaled Experience with macOS Sequoia macOS Sequoia completes the new MacBook Pro experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and notifications directly from their Mac.4 Safari, the world’s fastest browser,5 now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply new beautiful built-in backgrounds for video calls, which include a variety of color gradients and system wallpapers, or upload their own photos. The Perfect Time to Upgrade or Switch to a Mac Upgraders will get monumental improvements over Intel-based MacBook Pro models, including the amazing features of Apple Intelligence. When compared to an Intel-based MacBook Pro, the new MacBook Pro provides nearly 10x faster performance for AI-based workloads,1 and for graphics-intensive workloads, users get up to 20x faster performance.6 With battery life on the new MacBook Pro now up to 24 hours, upgraders will also experience up to 14 additional hours. And with the Liquid Retina XDR display, a new 12MP Center Stage camera, an immersive six-speaker sound system, the unrivaled experience of macOS Sequoia, and more, there’s never been a better time to upgrade or switch to MacBook Pro. MacBook Air: The World’s Most Popular Laptop Now Starts at 16GB MacBook Air is the world’s most popular laptop, and with Apple Intelligence, it’s even better. Now, models with M2 and M3 double the starting memory to 16GB, while keeping the starting price at just $999 — a terrific value for the world’s best-selling laptop. Better for the Environment The new MacBook Pro is built to last and incredibly durable, created from a custom alloy that uses 100 percent recycled aluminum in the enclosure. It also uses 100 percent recycled rare earth elements in all magnets, and 100 percent recycled tin soldering, gold plating, and copper in multiple printed circuit boards. The packaging for the 14-inch MacBook Pro is now entirely fiber-based, joining the 16-inch MacBook Pro and bringing Apple closer to its goal to remove plastic from its packaging by 2025. Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade. Pricing and Availability Customers can pre-order the new MacBook Pro starting today, October 30, on apple.com/store and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8. The 14-inch MacBook Pro with M4 starts at $1,599 (U.S.) and $1,499 (U.S.) for education; the 14‑inch MacBook Pro with M4 Pro starts at $1,999 (U.S.) and $1,849 (U.S.) for education; and the 16‑inch MacBook Pro starts at $2,499 (U.S.) and $2,299 (U.S.) for education. All models are available in space black and silver. Additional technical specifications, including the nano-texture display and configure-to-order options, are available at apple.com/mac. MacBook Air with M2 and M3 comes standard with 16GB of unified memory, and is available in midnight, starlight, silver, and space gray, starting at $999 (U.S.) and $899 (U.S.) for education. New accessories with USB-C — including Magic Keyboard ($99 U.S.), Magic Keyboard with Touch ID ($149 U.S.), Magic Keyboard with Touch ID and Numeric Keypad ($179 U.S.), Magic Trackpad ($129 U.S.), Magic Mouse ($79 U.S.), and Thunderbolt 5 Pro Cable ($69) — are available at apple.com/store. Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come. Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in Australia, Canada, Ireland, New Zealand, South Africa, and the U.K., and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported. With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit apple.com/shop/trade-in to see what their device is worth. AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best. Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store. About Apple Apple revolutionized personal technology with the introduction of the Macintosh in 1984. Today, Apple leads the world in innovation with iPhone, iPad, Mac, AirPods, Apple Watch, and Apple Vision Pro. Apple’s six software platforms — iOS, iPadOS, macOS, watchOS, visionOS, and tvOS — provide seamless experiences across all Apple devices and empower people with breakthrough services including the App Store, Apple Music, Apple Pay, iCloud, and Apple TV+. Apple’s more than 150,000 employees are dedicated to making the best products on earth and to leaving the world better than we found it. Testing was conducted by Apple from August through October 2024. Battery life varies by use and configuration. See apple.com/macbook-pro for more information. Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks. Based on published technical specifications of shipping competitive chips as of October 2024. Available on Mac computers with Apple silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user’s iPhone and Mac are signed in with the same Apple Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone Mirroring. Testing was conducted by Apple in August 2024. See apple.com/safari for more information. Results are compared to previous-generation 1.7GHz quad-core Intel Core i7-based 13-inch MacBook Pro systems with Intel Iris Plus Graphics 645, 16GB of RAM, and 2TB SSD. Press Contacts Michelle Del Rio Apple mr_delrio@apple.com Starlayne Meza Apple starlayne_meza@apple.com Apple Media Helpline media.help@apple.com Copy text Images in this article Download all images About Apple Apple revolutionized personal technology with the introduction of the Macintosh in 1984. Today, Apple leads the world in innovation with iPhone, iPad, Mac, AirPods, Apple Watch, and Apple Vision Pro. Apple’s six software platforms — iOS, iPadOS, macOS, watchOS, visionOS, and tvOS — provide seamless experiences across all Apple devices and empower people with breakthrough services including the App Store, Apple Music, Apple Pay, iCloud, and Apple TV+. Apple’s more than 150,000 employees are dedicated to making the best products on earth and to leaving the world better than we found it. Testing was conducted by Apple from August through October 2024. Battery life varies by use and configuration. See apple.com/macbook-pro for more information. Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks. Based on published technical specifications of shipping competitive chips as of October 2024. Available on Mac computers with Apple silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user’s iPhone and Mac are signed in with the same Apple Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone Mirroring. Testing was conducted by Apple in August 2024. See apple.com/safari for more information. Results are compared to previous-generation 1.7GHz quad-core Intel Core i7-based 13-inch MacBook Pro systems with Intel Iris Plus Graphics 645, 16GB of RAM, and 2TB SSD. Press Contacts Michelle Del Rio Apple mr_delrio@apple.com Starlayne Meza Apple starlayne_meza@apple.com Apple Media Helpline media.help@apple.com Latest News PRESS RELEASE Apple introduces M4 Pro and M4 Max October 30, 2024 PRESS RELEASE Apple’s new Mac mini is more mighty, more mini, and built for Apple Intelligence October 29, 2024 APPLE STORIES How Apple developed the world’s first end-to-end hearing health experience October 28, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41995701",
    "commentBody": "M4 MacBook Pro (apple.com)457 points by tosh 4 hours agohidepastfavorite525 comments carlgreene 3 hours agoWhat’s amazing is that in the past I’ve felt the need to upgrade within a few years. New video format or more demanding music software is released that slows the machine down, or battery life craters. Well, I haven’t had even a tinge of feeling that I need to upgrade after getting my M1 Pro MBP. I can’t remember it ever skipping a beat running a serious Ableton project, or editing in Resolve. Can stuff be faster? Technically of course. But this is the first machine that even after several years I’ve not caught myself once wishing that it was faster or had more RAM. Not once. Perhaps it’s my age, or perhaps it’s just the architecture of these new Mac chips are just so damn good. reply jchw 3 hours agoparentLaptops in general are just better than they used to be, with modern CPUs and NVMe disks. I feel exactly the same seeing new mobile AMD chips too, I'm pretty sure I'll be happy with my Ryzen 7040-based laptop for at least a few years. Apple's M1 came at a really interesting point. Intel was still dominating the laptop game for Windows laptops, but generational improvements felt pretty lame. A whole lot of money for mediocre performance gains, high heat output and not very impressive battery. The laptop ecosystem changed rapidly as not only the Apple M1 arrived, but also AMD started to gain real prominence in the laptop market after hitting pretty big in the desktop and data center CPU market. (Addendum: and FWIW, Intel has also gotten a fair bit better at mobile too in the meantime. Their recent mobile chipsets have shown good efficiency improvements.) If Qualcomm's Windows on ARM efforts live past the ARM lawsuit, I imagine a couple generations from now they could also have a fairly compelling product. In my eyes, there has never been a better time to buy a laptop. (Obligatory: I do have an M2 laptop in my possession from work. The hardware is very nice, it beats the battery life on my AMD laptop even if the AMD laptop chews through some compute a bit faster. That said, I love the AMD laptop because it runs Linux really well. I've tried Asahi on an M1 Mac Mini, it is very cool but not something I'd consider daily driving soon.) reply dijit 3 hours agorootparent> Laptops in general are just better than they used to be, with modern CPUs and NVMe disks. I feel exactly the same seeing new mobile AMD chips too, I'm pretty sure I'll be happy with my Ryzen 7040-based laptop for at least a few years. You say that, but I get extremely frustrated at how slow my Surface Pro 10 is (with an Ultra 7 165U). It could be Windows of course, but this is a much more modern machine than my Macbook Air (M1) and feels like it's almost 10 years old at times in comparison. - despite being 3-4 years newer. reply jchw 2 hours agorootparentIt's true that Linux may be a bit better in some cases, if you have a system that has good Linux support, but I think in most cases it should never make a very substantial difference. On some of the newer Intel laptops, there are still missing power management features anyways, so it's hard to compare. That said, Intel still has yet to catch up to AMD on efficiency unfortunately, they've improved generationally but if you look at power efficiency benchmarks of Intel CPUs vs AMD you can see AMD comfortably owns the entire top of the chart. Also, as a many-time Microsoft Surface owner, I can also confirm that these devices are rarely good showcases for the chipsets inside of them: they tend to be constrained by both power and thermal limits. There are a lot of good laptops on the market, I wouldn't compare a MacBook, even a MacBook Air, a laptop, with a Surface Pro, a 2-in-1 device. Heck, even my Intel Surface Laptop 4, a device I kinda like, isn't the ideal showcase for its already mediocre 11th gen Intel processor... The Mac laptop market is pretty easy: you buy the laptops they make, and you get what you get. On one hand, that means no need to worry about looking at reviews or comparisons, except to pick a model. They all perform reasonably well, the touchpad will always be good, the keyboard is alright. On the other hand, you really do get what you get: no touchscreens, no repairability, no booting directly into Windows, etc. reply thrw42A8N 1 hour agorootparentI boot Windows on my Mac M1 just fine. Just yesterday I played Age of Empires 3. reply jchw 1 hour agorootparentI changed the wording to be \"booting directly\" to clarify that I'm not including VMs. If I have to explain why that matters I guess I can, but I am pretty sure you know. reply thrw42A8N 52 minutes agorootparentI am genuinely interested, why does it matter? The performance is more than good enough even to run a Visual Studio (not Code). reply jchw 37 minutes agorootparentIf the roles were reversed would you still need an explanation? e.g. If I could run macOS inside of a VM on Windows and run things like Final Cut and XCode with sufficient performance, would you think there's no benefit to being able to boot macOS natively? reply thrw42A8N 7 minutes agorootparentBooting natively means you need real drivers, which don't exist for Windows on Mac as well as for macOS on PC. It'd be useless. Just use the VM, it's good. And it's not the same - running Windows natively on Mac would seriously degrade the Mac, while running macOS on a PC has no reason to make it worse than with Windows. Why not buy a PC laptop at that point? The close hardware/OS integration is the whole point of the product. Putting Windows into a VM lets you use best of both. acomjean 2 hours agorootparentprevI’ll agree the AMD laptops from the past couple of years are really impressive. They are fast enough that I’ve done some bioinformatics work on one. Battery life is decent. At this point I’m not switching from laptop Linux. The machines can even game (thanks proton/steam) reply caycep 2 hours agorootparentthe office Ryzen thinkpads we have are ok...but they're definitely no M1 MacBook Air or Pro... reply jchw 2 hours agorootparentIf we're mostly concerned about CPU grunt, it's really hard to question the Ryzen 7040, which like the M1, is also not the newest generation chip, though it is newer than the M1 by a couple of years. Still, comparing an M1 MacBook Pro with a Framework 16 on Geekbench: https://browser.geekbench.com/macs/macbook-pro-14-inch-2021-... https://browser.geekbench.com/v6/cpu/4260192 Both of these CPUs perform well enough that most users will not need to be concerned at all about the compute power. Newer CPUs are doing better but it'd be hard to notice day-to-day. As for other laptop features... That'll obviously be vendor-dependent. The biggest advantage of the PC market is all of the choices you get to make, and the biggest disadvantage of the PC market is all of the choices you have to make. (Edit: Though if anyone wants a comparison point, just for sake of argument, I think generally the strongest options have been from ASUS. Right now, the Zephyrus G16 has been reviewing pretty good, with people mostly just complaining that it is too expensive. Certainly can't argue with that. Personally, I run Framework, but I don't really run the latest-and-greatest mobile chipsets most of the time, and I don't think Framework is ideal for people who want that.) reply ikari_pl 2 hours agorootparentwhat about heat and noise? those are another two reasons why I can't ignore Apple Silicon reply jchw 1 hour agorootparentUltimately it'll be subjective, but the fans don't really spin up on my Framework 16 unless I push things. Running a game or compiling on all cores for a while will do the trick. The exact battery life, thermals and noise will be heavily dependent on the laptop; the TDP of modern laptop CPUs is probably mostly pretty comparable so a lot of it will come down to thermal design. Same for battery life and noise, depends a lot on things other than the CPU. reply bjackman 29 minutes agorootparentprevI only do coding & browsing so maybe I'm a weak example but I find this even with my pretty old Intel laptops these days. My Skylake one (I think that would be 6 years old now?) is doing absolutely fine. My Broadwell one is starting to feel a little aged but perfectly usable, I wouldn't even _consider_ upgrading it if I was in the bottom 95% of global income. Compiling is very slow on these, but I think I'd avoid compilation on my laptop even if I had a cutting edge CPU? reply jchw 6 minutes agorootparentDepends. I used to offload almost all compilation tasks, but now I only really do this if it's especially large. If I want to update my NixOS configuration I don't bother offloading it anymore. (NixOS isn't exactly Gentoo or anything, but I do have some overrides that necessitate a decent amount of compilation, mainly dogfooding my merge requests before they get merged/released.) YMMV. reply sangnoir 27 minutes agorootparentprev> If Qualcomm's Windows on ARM efforts live past the ARM lawsuit FWIW, Qualcomm cancelled orders of its Windows devkit and issued refunds before the lawsuit. That is probably not a good sign reply wing-_-nuts 1 hour agorootparentprev>Laptops in general are just better than they used to be, with modern CPUs and NVMe disks. I've had my xps 13 since 2016. Really the only fault I have against it nowadays is that 8gb of ram is not sufficient to run intellij anymore (hell, sometimes it even bogs down my 16gb mbp). Now, I've also built an absolute beast of a workstation with a 7800x3d, 64gb ram, 24 gb vram and a fast ssd. Is it faster than both? Yeah. Is my old xps slow enough to annoy me? Not really. Youtube has been sluggish to load / render here lately but I think that's much more that google is making changes to make firefox / ublock a worse experience than any fault of the laptop. reply chx 1 hour agorootparentprevI am on Intel TGL currently and can't wait for Strix Halo next year. That is truly something else, it's nothing we have seen in notebooks before iGPU wise. reply jchw 55 minutes agorootparentI've had a couple of Tiger Lake laptops, a Thinkpad and I believe my Surface Laptop 4. Based on my experience with current AMD mobile chipsets, I can only imagine the Strix Halo will be quite a massive uplift for you even if the generational improvements aren't impressive. reply extr 3 hours agoparentprevI've owned an M1 MBP base model since 2021 and I just got an M3 Max for work. I was curious to see if it \"felt\" different and was contemplating an upgrade to M4. You know what? It doesn't really feel different. I think my browser opens about 1 second faster from a cold start. But other than that, no perceptible difference day to day. reply stringsandchars 1 hour agorootparent> It doesn't really feel different. My work machine was upgraded from an M1 with 16GB of RAM to an M3 Max with 36GB and the difference in Xcode compile times is beyond belief: I went from something like 1-2 minutes to 15-20 seconds. Obviously if opening a browser is the most taxing thing your machine is doing the difference will be minimal. But video or music editing, application-compiling and other intensive tasks, then the upgrade is PHENOMENAL. reply jcgrillo 5 minutes agorootparentMy current work machine is M1 Max 64Gb and it's the fastest computer I've ever used. Watching rust code compile makes me laugh out loud it's so quick. Really curious what the newer ones are like, but tbh I don't feel any pressure to upgrade (could just be blissfully ignorant). reply eropple 1 hour agorootparentprevFWIW I think that's more the core count than anything. I have a M1 Max as a personal machine and an M3 Max at work and while the M3 Max is definitely faster, it isn't world-beating. reply Aeolun 1 hour agorootparentprevI very much enjoy being able to start compilation and just seeing results fly by. reply fwip 1 hour agorootparentprevI think most of that difference is going to be the huge increase in performance core count between the base chip and the Max (from 4 to 12). The RAM certainly doesn't hurt though! reply charliebwrites 2 hours agorootparentprevThis is how I feel about the last few iPhones as well I upgraded from a 13 pro to a 15 pro expecting zippier performance and it feels almost identical if not weirdly a bit slower in rendering and typing I wonder what it will take to make Mac/iOS feel faster reply alwillis 2 hours agorootparent> I upgraded from a 13 pro to a 15 pro expecting zippier performance and it feels almost identical if not weirdly a bit slower in rendering and typing I went from an iPhone 13 mini to an iPhone 16 and it's a significant speed boost. reply lawgimenez 2 hours agorootparentI went from 12 to 15 pro max, the difference is significant. I can listen to Spotify while shooting from the camera. On my old iPhone 12, this is not possible. reply pacifika 17 minutes agorootparentI’m sure you’re right but that’s pretty unreal. reply jonhohle 1 hour agorootparentprevI think that says more about Spotify than your phone. reply stevenjgarner 58 minutes agorootparentTest Spotify against YouTube Music (and others) - I personally see no reason for Spotify when I have YouTube Premium, which performs with less overhead. reply andrei_says_ 2 hours agorootparentprev16 pro has a specialized camera button which is a game changer for street / travel photography. I upgraded from 13 pro and use that. But no other noticeable improvements. Maybe Apple intelligence summarizing wordy emails. reply danieldk 2 hours agorootparentprevI think the only upgrade now is from a non-Pro to Pro, since a 120Hz screen is noticeably better than a 60Hz screen (and a borderline scam that a 1000 Euro phone does not have 120Hz). The new camera button is kinda nice though. reply matwood 2 hours agorootparent> The new camera button is kinda nice though. I was initially indifferent about the camera button, but now that I'm used to it it's actually very useful. reply thenthenthen 1 hour agorootparentprev> I wonder what it will take to make Mac/iOS feel faster I know, disabling shadows and customisable animation times ;) On a jailbroken phone I once could disable all animation delays, it felt like a new machine (must add that the animations are very important and generally great ux design, but most are just a tad too slow) reply tomjen3 2 hours agorootparentprevI upgraded my iPhone 13 pro to the 16 pro and it was overall really nice - but it was the better use of hardware, the zoom camera, etc. The CPU? Ah, never really felt a difference. reply doublerabbit 2 hours agorootparentprevXR to 13, as I don't want the latest and didn't want to loose my jailbreak. Infuriated by the 13. The 3.5mm audio thunder bolt adapters disconnect more often than usual. All I need to do is tap the adapter and it disconnects. And that Apple has now stopped selling them is even more infuriating, it's not a faulty adapter. reply qubitcoder 31 minutes agorootparentI realize this isn't your particular use case. But with newer iPhones, you can use USB-C directly for audio. I've been using the Audio Technica ATH-M50xSTS for a while now. The audio quality is exceptional. For Slack/Team/Zoom calls, the sidetone feature plays your voice back inside the headphones, with the level being adjustable via a small toggle switch on the left side. That makes all the difference, similar to transparency/adaptive modes on the AirPod Pro 2s (or older cellphones and landlines). I use a small Anker USB-A to USB-C adapter [1]. They're rock solid. As great as the AirPod Pro 2s are, a wired connection is superior in terms of reliability and latency. Although greatly improved over the years, I still have occasional issues connecting or switching between devices. Out of curiosity, what's the advantage of a jailbroken iPhone nowadays? I'd typically unlock Android phones in the past, but I don't see a need on iOS today. Interestingly, the last time I used Android, I had to sideload Adguard (an adblocker). On the App Store, it's just another app alongside competing adblockers. No such apps existed in the Play Store to provide system-level blocking, proxying, etc. Yes, browser extensions can be used, but that doesn't cover Google's incessant quest to bypass adblockers (looking at you Google News). [0] https://www.audio-technica.com/en-us/ath-m50xsts [1] https://www.amazon.com/Adapter-Anker-High-Speed-Transfer-Not... reply doublerabbit 15 minutes agorootparent> Out of curiosity, what's the advantage of a jailbroken iPhone nowadays? I'd typically unlock Android phones in the past, but I don't see a need on iOS today. I have custom scripts, Ad blocking without VPNs, Application firewalls. I enjoy having most-full control of my device. reply HumblyTossed 2 hours agorootparentprev> The 3.5mm thunder bolt adapters The what? is this the adapter for 3.5mm headphones? If so, you don't have to get Apple made dongles. Third parties make them also. reply Kirby64 36 minutes agorootparentOr just buy the actual Apple adapter from any number of other vendors. Best Buy still has plenty in stock, for instance. I'd guess the GPs actual problem is lint in the Lightning port though. Pretty common, relatively easy to clean out too, especially compared to USB-C. reply doublerabbit 19 minutes agorootparentI'm in the EU. Third party ones cost the same as authentic Apple ones. If not more. Regardless of either, they both have the same fault. The connector between the phone and the adapter is poor. It could just be a fault with my phone but I have no way of proving this. reply Kirby64 11 minutes agorootparentThird party ones are almost certainly not as good as the actual Apple ones. The Apple one has remarkably good quality for its price. I suspect this sounds like a problem with your specific phone. Never had a problem with any lightning accessories myself. doublerabbit 18 minutes agorootparentprevYes, which have the same fault as Apple authentic adapters which cost the same amount if not more. reply internet2000 2 hours agorootparentprevIt’s probably because of the jailbreak. reply HumblyTossed 2 hours agorootparentHow would that woller out his port? reply ToucanLoucan 2 hours agorootparentprevCan confirm. I have an M2 Air from work and an M1 Pro for personal, and tbh, both absolutely fly. I haven't had a serious reason to upgrade. The only reason I do kind of want to swap out my M1 Pro is because the 13\" screen is a wee small, but I also use the thing docked more often than not so it's very hard to justify spending the money. reply nsxwolf 31 minutes agoparentprevMy 2019 i9 flagship MBP is just so, so terrible, and my wife's M1 MacBook Air is so, so great. I can't get over how much better her computer is than mine. reply crystal_revenge 1 hour agoparentprevOn the other side, as someone doing a lot of work in the GenAI space, I'm simultaneously amazed that I can run Flux [dev] on my laptop and use local LLMs for a variety of tasks, while also wishing that I had more RAM and more processing power, despite having a top of the line M3 max MBP. But it is wild that two years ago running any sort of useful genAI stuff on a MBP was more-or-less a theoretical curiosity, and already today you can easily run models that would have exceeded SotA 2 years ago. Somewhat ironically, I got into the \"AI\" space a complete skeptic, but thinking it would be fun to play with nonetheless. After 2 years of daily work with this models I'm starting to be increasingly convinced they are going to become increasingly disruptive. No AGI, but it will certainly reduce a lot of labor and enable things that we're really feasible before. Best of all, it's clear a lot of this work will be doable from a laptop! reply tomcam 12 minutes agorootparentI would love to hear more about what exactly you think will be disruptive. I don’t know the LLM world very well. reply bhouston 3 hours agoparentprev> I haven’t had even a tinge of feeling that I need to upgrade after getting my M1 Pro MBP. I upgraded my M1 MBP to a MacBook Air M3 15\" and it was a major upgrade. It is the same weight but 40% faster and so much nicer to work on while on the sofa or traveling. The screen is also brighter. I think very few people actually do need the heavy MBPs, especially not the web/full-stack devs who populate Hacker News. EDIT: The screens are not different in terms of brightness. reply tebbers 2 hours agorootparentLooked at it but ruled out the Air due to lack of ports and limited RAM upgrades. reply 05 3 hours agorootparentprevPretty sure Air displays don't support HDR, are they really brighter? reply bhouston 3 hours agorootparentI am not sure. I notice a difference. Maybe it is just screen age related? reply 05 2 hours agorootparentThey supposedly have the same base brightness (500 nits), with Pro allowing up to 1000 in HDR mode (and up to 1600 peak). Air doesn't support 120Hz refresh either. There's an app that allows to unlock max brightness on Pros (Vivid)[0] even without HDR content (no affiliation). HDR support is most noticeable when viewing iPhone photos and videos, since iPhones shoots in HDR by default. [0] https://www.getvivid.app reply bhouston 2 hours agorootparentI just looked at it again side by side and I think they are actually the same. Not sure why I earlier thought they were different. reply nottorp 1 hour agorootparentprevOn a tangent, if I have a M3 pro laptop how do I test HDR? Download a test movie from where, play it with what? I may or may have not seen HDR content accidentally, but I’m not sure. reply rizzaxc 2 hours agorootparentprevthe Air doesn't have ProMotion right? that feature is non-negotiable on any display for me nowadays reply grujicd 1 hour agorootparentFor me faster refresh rate is noticeable on phone or ipad where you scroll all the time. On a laptop you don't have that much smooth scrolling. For me it's a non issue on laptop, not even once I wished it had faster refresh. While I always notice when switching between Pro and non Pro iPad. reply sroussey 2 hours agorootparentprevI have ProMotion on my MBP and iPhone but… it’s ok? Honestly, I use an older computer or iPhone temporarily and don’t notice a difference. I’m looking forward to the day I notice the difference so I can appreciate what I have. reply danieldk 2 hours agorootparentI find 60Hz on the non-Pro iPhone obnoxious since switching to 120Hz screens. On the other hand, I do not care much about 60Hz when it comes to computer screens. I think touch interfaces make low refresh rates much more noticeable. reply nottorp 1 hour agorootparentI wonder. Do you do a lot of doom scrolling? I can’t understand the people who notice the 120 hz adaptive refresh whatever and one guess is their use is a lot twitchier than mine. reply rbanffy 3 hours agoparentprevA lot of my work can be easily done with a Celeron - it's editing source, compiling very little, running tests on Python code, running small Docker containers and so on. Could it be faster? Of course! Do I need it to be faster? Not really. I am due to update my Mac mini because my current one can't run Sonoma, but, apart from that, it's a lovely little box with more than enough power for me. reply mysteria 2 minutes agorootparentI still use Ivy Bridge and Haswell workstations (with Linux, SSD and discrete GPU) as my daily drivers and for the things I do they still feel fast. Honestly a new Celeron probably beats them performance wise. The modern AMD or Intel desktops I've tried obviously are much faster when performing large builds and such but for general computing, web browsing, and so forth I literally don't feel much of a difference. reply klooney 2 hours agorootparentprevHow's the performance of Gmail on the Celeron? That's always my sticking point for older computers. The fancy web applications really drag. reply rbanffy 2 hours agorootparentNot great. Works well with Thunderbird or Evolution though. And yes. Web apps are not really great on low-spec machines. reply rconti 3 hours agoparentprevIt's so nice being able to advise a family member who is looking to upgrade their intel Mac to something new, and just tell them to buy whatever is out, not worry about release dates, not worry about things being out of date, and so on. The latest of whatever you have will be so much better than the intel one, and the next advances will be so marginal, that it's not even worth looking at a buyer's guide. reply baq 3 hours agorootparentM3 Air with 16gb (base config as of today) is potentially a decade’s worth of computer. Amazing value. reply chamomeal 2 hours agorootparentBase 16gb is absolutely wild. My base m2 air with 8gb is almost enough to handle anything I’d ever want it to without zero slowdown. A 16gb model for about a thousand bucks?? I can’t believe how far macbooks have come in the last few years reply zitterbewegung 57 minutes agoparentprevI agree with you about not needing to upgrade but, it still stands that IMHO Apple is better off with upgrading or even having the need to upgrade with competition. (Also it's really good that Macs now have 16GB of ram by default). As I have had my M1 14.2 Max I believe that the only reason I would want to upgrade is that I can configure it with 128GB of ram which allows you to load newer AI models on device. The MacBook Pro seems like it does have some quality of life improvements such as Thunderbolt 5, the camera is now a center stage (follows you) 14 megapixel camera now all of them have three USB-C ports and the battery life claims of 22-24 hours. Regardless if you want a MacBook Pro and you don't have one there is now an argument on not just going to buy the previous model. reply noman-land 1 hour agoparentprevI would normally never upgrade so soon after getting an M1 but running local LLMs is extremely cool and useful to the point where I'd want the extra RAM and CPU to run larger models more quickly. reply astrostl 1 hour agorootparentI'm bumping from a still-excellent M1 MAX / 64GB to M4 MAX / 128GB, mostly for local GenAI. It gives me some other uplift and also enables me to sell this system while it's still attractive. I'm able to exhaust local 7B models fairly easily on it. reply yieldcrv 1 hour agorootparentprevI have a 64gb M1 Max and already do that but yes, I was looking at and anticipating the max RAM on the M4 as well as the max memory speed 128gb and 546GB/s memory bandwidth I like it, I don't know yet on an upgrade. But I like it. Was hoping for more RAM actually, but this is nice. reply madeofpalk 1 hour agoparentprevWork just upgraded my M1 Pro to M3 Pro and I don't notice any difference except for now having two laptops. reply matthoiland 52 minutes agoparentprevI feel the same way about my M1 Macbook Air ... it's such a silly small and powerful machine. I've got money to upgrade, I just have no need. It's more than enough for even demanding Logic sessions and Ollama for most 8b models. I love it. reply davidhariri 1 hour agoparentprevI think this is confirmed by the fact software vendors are still not taking advantage of ARM chips maximum performance. Where this might shift is as we start using more applications that are powered by locally running LLMs. reply nhumrich 3 hours agoparentprevI dont think this has anything to do with the hardware. I think we have entered an age where users in general are not upgrading. As such, software can't demand more and more performance. The M1 came out at a time where mostly all hardware innovation had staggered. Default RAM in a laptop has been 16G for over 5 years. 2 years ago, you couldn't even get more than 16 in most laptops. As such, software hardware requirements havent changed. So any modern CPU is going to feel overpowered. This isn't unique to M1's. reply vlovich123 2 hours agorootparentThat’s because today’s hw is perfectly capable of running tomorrow’s software at reasonable speed. There aren’t huge drivers of new functionality that needs new software. Displays are fantastic, cellular speeds are amazing and can stream video, battery life is excellent, UIs are smooth with no jankiness, and cameras are good enough. Why would people feel the need to upgrade? And this applies already to phones. Laptops have been slowing for even longer. reply slowmovintarget 2 hours agorootparentUntil everything starts running local inference. A real Siri that can operate your phone for you, and actually do things like process cross-app conditions (\"Hey Siri, if I get an email from my wife today, notify me, then block out my calendar for the afternoon.\") would use those increased compute and memory resources easily. Apple has been shipping \"neural\" processors for a while now, and when software with local inference starts landing, Apple hardware will be a natural place for it. They'll get to say \"Your data, on your device, working for you; no subscription or API key needed.\" reply mixmastamyk 2 hours agorootparentprevI standardized on 16gb for my laptops over 10 years ago. I keep a late 2013 MBP with 16 for testing projects on, separate from my main Linux box. Getting an extra five years of longevity (after RAM became fixed) for an extra 10% was a no-brainer imho. reply samatman 42 minutes agorootparentprevI upgraded from the last 16\" MBP Intel sold to the first 16\" MBP M1 available. It is absolutely, 100%, no doubt in my mind: the hardware. reply 7ewis 53 minutes agoparentprevI have exactly the same experience, usually after 3 years I'm desperate for new Mac but right now I genuinely think I'd prefer not to change. I have absolutely no issues with my M1 Pro, battery and performance is still great. reply OskarS 3 hours agoparentprevYep, the same, M1 Pro from 2021. It's remarkable how snappy it still feels years later, and I still virtually never hear the fan. The M-series of chips is a really remarkable achievement in hardware. reply erickhill 1 hour agoparentprevI have an MBP M1 Max and the only time I really feel like I need more oomph is when I'm doing live previews and/or rendering in After Effects. I find myself having to clear the cache constantly. Other than that it cruises across all other applications. Hard to justify an upgrade purely for that one issue when everything else is so solid. But it does make the eyes wander... reply pjmlp 1 hour agoparentprevI have a 2009 and a 2018 Windows laptops. The only reason the 2009 one now gets little use, is its motherboard now has some electronic issues, otherwise it would serve me perfectly well. reply gniv 2 hours agoparentprevI've had Macs before, from work, but there is something about the M1 Pro that feels like a major step up. Only recently I noticed some slowness. I think Google Photos changed something and they show photos in HDR and it causes unsmooth scrolling. I wonder if it's something fixable on Google's side though. reply jrochkind1 2 hours agoparentprevI bought my M1 Pro MBP in 2021. Gave it 16G of RAM and a 1TB HD. I plan to keep it until circa 2031. reply danieldk 2 hours agoparentprevSame. I used to upgrade every 1.5 years or so. But with every Apple Silicon generation so far I have felt that there are really no good reasons to upgrade. I have a MacBook M3 Pro for work, but there are no convincing differences compared to the M1 Pro. In fact, I bought a highly discounted Mac Studio with M1 Ultra because the M1 is still so good and it gives me 10Gbit ethernet, 20 cores and a lot of memory. The only thing I am thinking about is going back to the MacBook Air again since I like the lighter form factor. But the display, 24 GiB max RAM and only 2 Thunderbolt ports would be a significant downgrade. reply clairegraham 49 minutes agoparentprevSame. The upgrade from my Intel MBP to the M1 Pro 2011 was huge, but I haven't felt the need to upgrade at all. reply dagw 1 hour agoparentprevThe only reason I'd want to upgrade my M1 Pro MBP is because I kind of need more RAM and storage. The fact that I'm even considering a new laptop just for things that before could have been a trivial upgrade is quite illuminating. reply mark_l_watson 2 hours agoparentprevI think regretting Mac upgrades is a real thing, at least for me. I got a 32G Mac mini in January to run local LLMs. While it does so beautifully, there are now smaller LLMs that run fine on my very old 8G M1 MacBook Pro, and these newer smaller models do almost all of what I want for NLP tasks, data transformation, RAG, etc. I feel like I wasted my money. reply tarruda 1 hour agorootparentSmall models retain much less of the knowledge they were trained on, especially when quantized. One good use case for 32gb Mac is being able to run 8b models at full precision, something that is not possible with 8-16gb macs reply Eugr 1 minute agorootparentOr better run quantized 14B or even 32B models... reply fwip 9 minutes agorootparentprevYou can sell it, get most of your money back. reply xenospn 1 hour agorootparentprevWhich ones in particular? I have an M2 air with 8GB, and doing some RAG development locally would be fantastic. I tried running Ollama with llama3.2 and it predictably bombed. reply kromokromo 1 hour agoparentprev100% agree on this. Ive had this thing for 3 years and I still appreciate how good it is. Of course the M4 tingles my desire for new cool toys, but I honestly don´t think I would notice much difference with my current use. reply HumblyTossed 2 hours agoparentprevBut this ad is specifically for you! (Well, and those pesky consumers clinging on to that i7!): > Up to 7x faster image processing in Affinity Photo when compared to the 13‑inch MacBook Pro with Core i7, and up to 1.8x faster when compared to the 13-inch MacBook Pro with M1. reply 1R053 3 hours agoparentprevprobably the next update wave is coming from the need of AI features for more local memory and compute. The software is just not there yet in usual tasks but it's just a question of time I guess. Of course there will be the pressure to do that in the cloud as usual, but local compute will always remain a market. and probably it's good that at least one of the big players has a business model that supports driving that forward reply jfoster 1 hour agoparentprevI expect this trend to begin reversing as we start getting AI models that are intended to run locally. reply prmoustache 3 hours agoparentprev> Perhaps it’s my age, or perhaps it’s just the architecture of these new Mac chips are just so damn good. I feel the same of my laptop of 2011 so I guess it is partly age (not feeling the urge to always have the greatest) and partly it is non LLM and gaming related computing is not demanding enough to force us to upgrade. reply data-ottawa 2 hours agorootparentI think the last decade had an explosion in the amount of resources browsers needed and used (partly workloads moving over, partly moving to more advanced web frameworks, partly electron apps proliferating). The last few years Chrome seems to have stepped up energy and memory use, which impacts most casual use these days. Safari has also become more efficient, but it never felt bloated the way Chrome used to. reply sylens 2 hours agoparentprevAgreed. Also rocking a M1 Pro MBP and can’t see myself replacing it until it dies reply stouset 2 hours agoparentprevI feel exactly the same. The one thing that would get me to pull the trigger on a newer one is if they start supporting SVE2 instructions, which would be super useful for a specific programming project I’ve been playing with. reply andrei_says_ 2 hours agoparentprevI got 6+ years out of my last intel MacBook Pro and expect at least the same from my M1 Max. Both have MagSafe and hdmi output :) reply matwood 2 hours agoparentprevSame. I have an M1 Max 64GB. It has great battery life and I never feel myself waiting on anything. Such an amazing computer all around. reply JyB 3 hours agoparentprevSame feeling. The jump from all the previous laptops I owned to an M1 was an incredible jump. The thing is fast, has amazing battery life and stays cold. Never felt the need to upgrade. reply dawnerd 3 hours agoparentprevGuess that’s why most of their comparisons are with the older Intel Macs. reply Cthulhu_ 3 hours agorootparentAnd M1 from 4 years ago instead of M3 from last year; while a 2x speed improvement in the benchmarks they listed is good, it also shows that the M series CPUs see incremental improvements, not exponential or revolutionary. I get the feeling - but a CPU expert can correct me / say more - that their base design is mostly unchanged since M1, but the manufacturing process has improved (leading to less power consumption/heat), the amount of cores has increased, and they added specialized hardware for AI-related workloads. That said, they are in a very comfortable position right now, with neither Intel, AMD, or another competitor able to produce anything close to the bang-for-watt that Apple is managing. Little pressure from behind them to push for more performance. reply Zafira 17 minutes agorootparentTheir sales pitch when they released the M1 was that the architecture would scale linearly and so far this appears to be true. It seems like they bump the base frequency of the CPU cores with every revision to get some easy performance gains (the M1 was 3.2 GHz and the M3 is now 4.1 GHz for the performance cores), but it looks like this comes at the cost of it not being able to maintain the performance; some M3 reviews noted that the system starts throttling much earlier than an M1. reply renewiltord 3 hours agoparentprevThe M1 series was too good. Blows Intel Macs out of the water. But I still have an M1 Max. It’s fantastic. reply AISnakeOil 2 hours agoparentprevThis is how it feels to own a desktop computer. reply mattgreenrocks 2 hours agoparentprevMy 2019 Intel MBP is getting long in the tooth. These M4 Pros look great to me. The base model is perfect. Now to decide between the M3/M4 Air and the M4 Pro. reply charliebwrites 2 hours agorootparentI’m using the M3 Air 13 in (splurged for 24 GB of RAM, I’m sure 16 is fine) to make iOS apps in Xcode and produce music in Ableton and it’s been more than performant for those tasks Only downside is the screen. The brightness sort of has to be maxed out to be readable and viewing at a wrong angle makes even that imperfect That said it’s about the same size / weight as an iPad Pro which feels much more portable than a pro device reply fstephany 3 hours agoparentprevI have the same feeling performance-wise with the laptop I bought in 2020 with a Ryzen 7 4800H. But it's a heavy brick with a short battery life compared to the M1/2/3 Mac. reply frantathefranta 3 hours agoparentprevOut of curiosity and also because I'm wondering which specification to potentially buy in the future, how much RAM does your MBP have? reply crazygringo 2 hours agoparentprevYup, honestly the main reason I'd like to upgrade from my M1 MBA is the newer webcams are 1080p instead of 720p, and particularly much better in low light like in the evening. Has nothing whatsoever to do with CPU/memory/etc. reply rafaelmn 2 hours agorootparentIf you're in the ecosystem get an iphone mount - image quality is unreal compared to anything short of some fancy DSLR setup - it is some setup but not much with magnets in iphone. reply maxvisser 3 hours agoparentprevSame for me. The only reason to replace it, is that my M1 pro’s SSD or battery will go bad or if I accidentally drop the machine and something breaks. reply rbanffy 3 hours agorootparentI am replacing a Dell laptop because the case is cracking, not because it's too slow (it isn't lightning fast, of course, but it sure is fast enough for casual use). reply fckgw 3 hours agorootparentprevI replaced my M1 Air battery last year and it's still going like a champ. $129 for another 3 years of life is a bargain. reply fullspectrumdev 3 hours agoparentprevTbf, the only thing I miss with my M2 MacBook is the ability to run x86_64 VM’s with decent performance locally. I’ve tried a bunch of ways to do this - and frankly the translation overhead is absolute pants currently. Not a showstopper though, for the 20-30% of complete pain in the ass cases where I can’t easily offload the job onto a VPS or a NUC or something, I just have a ThinkPad. reply JodieBenitez 2 hours agoparentprevDitto... will probably upgrade when the battery is dead ! reply digitalsushi 2 hours agoparentprevwhen the hardware wait time is the same as the duration of my impulsive decisions i no longer have a hardware speed problem, i have a software suggestion problem reply fellowniusmonk 2 hours agoparentprevI got an MBP M1 with 32gb of RAM. It'll probably be another 2-3 years or longer before I feel the pressure to upgrade if not longer. I've even started gaming (something I dropped nearly 20 years ago when I switched to mac) again due to Geforce Now, I just don't see the reason. Frankly though, if the mac mini was a slightly lower price point I'd definitely create my own mac mini cluster for my AI home lab. reply AtlasBarfed 1 hour agoparentprevI don't think there's any sort of processor for the last 10 years. It really makes me feel like I need to upgrade. What I do know is that Linux constantly breaks stuff. I don't even think it's treading water. These are interfaces are actively getting worse. reply drcongo 1 hour agoparentprevI also have an M1 Pro MBP and mostly feel the same. The most tempting thing about the new ones is the space black option. Prior to the M1, I was getting a new laptop every year or two and there was always something wrong with them - butterfly keyboard, Touch Bar etc. This thing is essentially perfect though, it still feels and performs like a brand new computer. reply jart 3 hours agoparentprevI hate to say it but that's like a boomer saying they never felt the need to buy a computer, because they've never wished their pen and paper goes faster. Or a UNIX greybeard saying they don't need a Mac since they don't think its GUI would make their terminal go any faster. If you've hit a point in your life where you're no longer keeping up with the latest technological developments like AI, then of course you don't need to upgrade. A Macbook M1 can't run half the stuff posted on Hugging Face these days. Even my 128gb Mac Studio isn't nearly enough. reply mrweasel 1 hour agorootparent> If you've hit a point in your life where you're no longer keeping up with the latest technological developments like AI, then of course you don't need to upgrade. That's me, I don't give a shit about AI, video editing, modern gaming or Kubernetes. That newest and heaviest piece of software I care about is VSCode. So I think you're absolutely correct. Most things new since Docker and VSCode has not contributed massively to how I work and most of the things I do could be done just fine 8-10 years ago. reply rconti 3 hours agorootparentprevI think the difference is that AI is a very narrow niche/hobby at the moment. Of course if you're in that niche having more horsepower is critical. But your boomer/greybeard comparisons fall flat because they're generally about age or being set in your ways. I don't think \"not being into AI image generation\" is (currently) about being stuck in your ways. To me it's more like 3d printing as a niche/hobby. reply ach9l 3 hours agorootparenton ai being a niche/hobby at the moment... feels like something a unix greybeard would say about guis in the late 70s... reply vundercind 1 hour agorootparentPlaying with them locally? Yes, of course it's a niche hobby. The people doing stuff with them that's not either playing with them or developing not just an \"AI\" product, but a specific sort of AI product, are just using ChatGPT or some other prepackaged thing that either doesn't run locally, or does, but is sized to fit on ordinary hardware.A Macbook M1 can't run half the stuff posted on Hugging Face these days. Example? reply jart 2 hours agorootparentLLaMA 3.1 405B reply chrsw 11 minutes agorootparentI thought LLaMA 3.1 405B was a relatively huge model. Is the size of this model really typical of half the models you find on Hugging Face these days? reply int_19h 1 hour agorootparentprevGiven that models are only going to get larger, and the sheer amount of compute required, I think the endgame here is dedicated \"inference boxes\" that actual user-facing devices call into. There are already a couple of home appliances like these - NAS, home automation servers - which have some intersecting requirements (e.g. storage for NAS) - so maybe we just need to resurrect the \"home server\" category. reply jart 1 hour agorootparentI agree, and if you want to have the opportunity to build such a product, then you need a personal computer whose specs today are what a home server would have in four years. If you want to build the future you have to live in the future. I'm proud to make stuff most people can't even run yet, because I know they'll be able to soon. That buys me time to polish their future and work out all the bugs too. reply ach9l 3 hours agorootparentprevyou could not say this better than this. reply turnsout 3 hours agoparentprevSame boat—I'm on a lowly M1 MacBook Air, and haven't felt any need to upgrade (SwiftUI development, video editing, you name it), which is wild for a nearly 4 year-old laptop. reply kristofferR 3 hours agoparentprevYeah, I feel like Apple has done the opposite of planned obsolescence with the M chips. I have a Macbook Air M1 that I'd like to upgrade, but they're not making it easy. I promised myself a couple of years ago I'll never buy a new expensive computing device/phone unless it supports 120 hertz and Wi-Fi 7, a pretty reasonable request I think. I got the iPhone 16 Pro, guess I can wait another year for a new Macbook (hopefully the Air will have a decent display by then, I'm not too keen to downgrade the portability just to get a good display). reply rbanffy 3 hours agorootparentApple equipment always last a long time and retain value on the second-hand market. reply spyckie2 3 hours agorootparentNot true. Look at how little supercharged intel apples are going for in Facebook marketplace. The quality stuff retains value, not brand. reply zinckiwi 3 hours agorootparentComparing against the intel era is a bit apples (excuse me) to oranges. Technical generation gaps aside, Apple products hold value well. reply spyckie2 2 hours agorootparentSo the intel era is not Apple products? Butterfly keyboard is not an Apple invention? They have the highest product quality of any laptop manufacturer, period. But to say that all Apple products hold value well is simply not true. All quality products hold value well, and most of Apples products are quality. I guarantee you that if Apple produced a trashy laptop it would have no resell value. Again, the quality holds the value not the brand. reply rbanffy 2 hours agorootparentIt's expected Intel-based Macs would lose value quickly considering how much better the M1 models were. This transition was bigger than when they moved from PowerPC to Intel. reply microtherion 2 hours agorootparentprevOne complicating factor in the case of the Intel Macs is that an architectural transition happened after they came out. So they will be able to run less and less new software over the next couple of years, and they lack most AI-enabling hardware acceleration. That said, they did suffer from some self inflicted hardware limitations, as you hint. One reason I like the MBP is the return of the SD card slot. reply babblingdweeb 3 hours agorootparentprevSimilar for me. MacBook Air M1 (8 cpu / 8 gpu; 16 GB RAM)...running in or out of clamshell with a 5k monitor, I rarely notice issues. Typically, if I'm working very inefficiently (obnoxious amount of tabs with Safari and Chrome; mostly web apps, Slack, Zoom, Postman, and vscode), I'll notice a minor lag during a video call while screen sharing...even then, it still keeps up. (Old Pentium Pro, PII, multi chip desktop days) -- When I did a different type of work, I would be in love with these new chips. I just don't throw as much at my computer anymore outside of things being RAM heavy. The M1 (with 16 GB ram) is really an amazing chip. I'm with you, outside of a repair/replacement? I'm happy to wait for 120hz refresh, faster wifi, and longer battery life. reply JimDabell 3 hours agorootparentprev> Yeah, I feel like Apple has done the opposite of planned obsolescence with the M chips. They always have. If you want an objective measure of planned obsolescence, look at the resale value. Apple products hold their resale value better than pretty much every competitor because they stay useful for far longer. reply opjjf 3 hours agoprevIt seems they also update the base memory on MacBook Air: > MacBook Air: The World’s Most Popular Laptop Now Starts at 16GB > MacBook Air is the world’s most popular laptop, and with Apple Intelligence, it’s even better. Now, models with M2 and M3 double the starting memory to 16GB, while keeping the starting price at just $999 — a terrific value for the world’s best-selling laptop. reply electriclove 3 hours agoparentWow, I didn't expect them to update the older models to start at 16GB and no price increase. I guess that is why Amazon was blowing the 8GB models out at crazy low prices over the past few days. reply bronco21016 3 hours agorootparentCostco was selling MB Air M2 8 GB for $699! Incredible deal. I’ve been using the exact model for about a year and I rarely find limitations for my typical office type work. The only time I’ve managed to thermally throttle it has been with some super suboptimal Excel Macros. reply porphyra 2 hours agorootparentI'm waiting for the 16 GB M2 Air to be super cheap to pick one up to use with Asahi Linux! reply __rito__ 2 hours agorootparentprevI was seeing $699 MB Air M1 8 GB on Amazon India a week ago. reply bhouston 3 hours agoparentprevBut no update to a M4 for the MacBook Air yet unfortunately. I would love to get an M4 MacBook Air with 32GB. I believe the rumor is that the MacBook Air will get the update to M4 in early spring 2025, February/March timeline. reply nsbk 3 hours agorootparentThis is the machine I'm waiting for. Hopefully early 2025 reply brewmarche 31 minutes agorootparentGiven that the Mini and iMac have received support for one more additional external display (at 60Hz 6K), I hope we’ll see the same on the MBA M4. reply rbanffy 3 hours agorootparentprevThere are still a couple days left this week. reply 39896880 2 hours agorootparentThey said there would be three announcements this week and this is the third reply sroussey 2 hours agorootparentThey did? The tweet that announced stuff from the head of marketing did not mention 3 days. That said, I believe you. Some press gets a hands-on on Wednesday (today) so unless they plan to pre-announce something (unlikely) or announce software only stuff, I think today is it. reply 39896880 2 hours agorootparent\"This is a huge week for the Mac, and this morning, we begin a series of three exciting new product announcements that will take place over the coming days,\" said Apple's hardware engineering chief John Ternus, in a video announcing the new iMac. reply sroussey 2 hours agorootparentAh, thanks. I was referring to last weeks Tweet. I didn’t watch the iMac video. reply rbanffy 2 hours agorootparentprevThat's disappointing. I was expecting a new Apple TV because mine needs replacement and I don't really feel inclined to get one that's due for an upgrade very soon. Also, Studio and Pro are hanging there. reply coder543 1 hour agorootparentThe current-gen Apple TV is already overpowered for what it does, and extremely nice to use. I can think of very few changes I would like to see, and most of them are purely software. reply int_19h 1 hour agorootparentI really wish it had some way to connect USB storage directly. reply coder543 31 minutes agorootparentMine has 128GB of onboard storage... but Apple still bans apps from downloading video, which annoys me. The streaming apps virtually all support downloading for offline viewing on iPhone, but the Apple TV just becomes a paperweight when the internet goes out, because I'm not allowed to use the 128GB of storage for anything. If they're not going to let you use the onboard storage, then it seems unlikely for them to let you use USB storage. So, first, I would like them to change their app policies regarding internal storage, which is one of the purely software improvements I would like to see. reply jq-r 3 hours agorootparentprevThere really isn't a chance they'll update the same product twice in a week. reply rbanffy 3 hours agorootparentThey haven't officially updated it. They just discontinued the smaller model. reply jq-r 40 minutes agorootparentIt would make more sense to discontinue the smaller model along with some other updates to the line. Or in other words, Air won't receive any other updates this week unfortunately. reply ant6n 1 hour agorootparentprevThe big question for me is whether they will have a matte option for the Air. I want a fanless machine with a matte screen. Unfortunately Apple won’t tell you until the day they sell the machines. reply jsheard 3 hours agoparentprevEvery M-series device now comes with at least 16GB, except for the base iPad Pro, right? reply fckgw 3 hours agorootparentCorrect, every Mac computer starts at 16gb now. 256gb/512gb iPad Pro is 8gb, 1tb/2tb is 16gb. reply MBCook 3 hours agorootparentprevAt least all the M4 Macs. I’m not sure of every older M config has been updated, though at least some have been. reply fckgw 3 hours agorootparentThe only older configs that Apple sells are the M2 and M3 Airs, which were bumped. Everything else is now on M4, or didn't have an 8gb base config (Mac Studio, Mac Pro) reply nsteel 3 hours agoparentprevBut still just 256GB SSD Storage. £200 for the upgrade to 512GB (plus a couple more GPU cores that I don't need. Urgh. reply DrBenCarson 2 hours agorootparentIt’s stationary. Just get a Thunderbolt NVMe drive and leave it plugged in reply jq-r 39 minutes agorootparentWhy buy a laptop then if you're lugging all those external hard drives? reply ActorNightly 2 minutes agoparentprevIm sorry but any laptop that costs $1000 should come with 64 gigs minimum, or expandable slots. reply modeless 2 hours agoparentprevI've seen a lot of people complaining about 8GB but honestly my min spec M1 Air has continued to be great. I wouldn't hesitate to recommend a refurb M1 8GB Air for anyone price conscious. reply hiatus 1 hour agoparentprevIf only they would bring back the 11\" Air. reply yurishimo 3 hours agoparentprevIt'll be interesting to see the reaction of tech commentators about this. So many people have been screaming at Apple to increase the base RAM and stop price gouging their customers on memory upgrades. If Apple Intelligence is the excuse the hardware team needed to get the bean counters on board, I'm not going to look a gift horse in the mouth! reply sroussey 2 hours agorootparentSo we can scream about the lousy base storage, which is the same as my phone. Yikes. reply criddell 1 hour agorootparentIt wouldn't surprise me if people typically use more storage on their phone than their computer. The phone should probably have a higher base storage than the base storage of their laptops. reply alsetmusic 3 hours agoparentprevOhh, good catch. Sneaking that into the MBP announcement. I skimmed the page and missed that. So a fourth announcement couched within the biggest of the three days. reply abhinavk 3 hours agoparentprev> while keeping the starting price at just $999 — a terrific value for the world’s best-selling laptop Only in US it seems. India got a price increase by $120. reply alberth 3 hours agoparentprevI guess that implies the MacBook Air won't be updated this week. Makes me wonder what else will be updated this week (Studio or Mac Pro)? reply FireBeyond 3 hours agoparentprevWell, the issue for me with memory on these new models is that for the Max, it ships with 36GB and NO expandable memory option. To get more memory that's gated behind a $300 CPU upgrade (plus the memory cost). reply twilo 3 hours agoparentprevGreat news. The pro is kinda of heavy for my liking so the Air is the way to go reply int_19h 1 hour agorootparentIt's not just the weight - Air is also fanless (and still runs cold). And yes, with enough RAM, it is a surprisingly good dev laptop. reply jq-r 38 minutes agorootparentReally too bad you cannot upgrade to 32GB RAM though =( reply Analemma_ 3 hours agorootparentprevI think spec-wise the Air is good enough for almost everyone who isn't doing video production or running local LLMs, I just wish it had the much nicer screen that the Pro has. But I suppose they have to segregate the product lines somehow. reply Der_Einzige 2 hours agoparentprevApple deserves to be punished hard for not having done this back in 2018 when they should have. Would love to see regulators do to them what they did with USB-C here. Force them to bring back the audio jack on iphone as a response please regulators! 6 years of insulting their customers with DOA useless hardware. The reality is that zero people will \"not run into issues\" with 8 gb of ram and a gimped 256gb SSD for caching. reply Vayu 3 minutes agoprevAs it goes for the section where they demoed the assistance from apple intelligence to the researcher creating an abstract and adding pictures to their paper. Is it better or worse to do this? People are already complaining so heavily about dead internet theory with the 'AI voice' being so prominent.. reply throw0101a 3 hours agoprev> All MacBook Pro models feature an HDMI port that supports up to 8K resolution, a SDXC card slot, a MagSafe 3 port for charging, and a headphone jack, along with support for Wi-Fi 6E and Bluetooth 5.3. No Wifi 7. So you get access to the 6 GHz band, but not some of the other features (preamble punching, OFDMA): * https://en.wikipedia.org/wiki/Wi-Fi_7 * https://en.wikipedia.org/wiki/Wi-Fi_6E The iPhone 16s do have Wifi 7. Curious to know why they skipped it (and I wonder if the chipsets perhaps do support it, but it's a firmware/software-not-yet-ready thing). reply cojo 18 minutes agoparentI was quite surprised by this discrepancy as well (my new iPhone has 7, but the new MBP does not). I had just assumed that for sure this would be the year I upgrade my M1 Max MBP to an M4 Max. I will not be doing so knowing that it lacks WiFi 7; as one of the child comments notes, I count on getting a solid 3 years out of my machine, so future-proofing carries some value (and I already have WiFi7 access points), and I download terabytes of data in some weeks for the work I do, and not having to Ethernet in at a fixed desk to do so efficiently will be a big enough win that I will wait another year before shelling out $6k “off-cycle”. Big bummer for me. I was looking forward to performance gains next Friday. reply canucker2016 1 hour agoparentprevYeah, I thought that was weird. None of the Apple announcements this week had WiFi7 support, just 6E. https://www.tomsguide.com/face-off/wi-fi-6e-vs-wi-fi-7-whats... Laptops/desktops (with 16GB+ of memory) could make use of the faster speed/more bandwidth aspects of WiFi7 better than smartphones (with 8GB of memory). reply ygouzerh 2 hours agoparentprevIt looks like few people only are using Wifi 7 for now. Maybe they are going to include it in the next generation when more people will use it. reply throw0101a 46 minutes agorootparent> It looks like few people only are using Wifi 7 for now. Machines can last and be used for years, and it would be a presumably very simple way to 'future proof' things. And though the IEEE spec hasn't officially been ratified as I type this, it is set to be by the end of 2024. Network vendors are also shipping APs with the functionality, so in coming years we'll see a larger and larger infrastructure footprint going forward. reply 404mm 1 hour agoparentprevThe lack of Wifi7 is a real bummer for me. I was hoping to ditch the 2.5Gbe dongle and just use WiFi. reply mort96 31 minutes agorootparentHm why? Is 6E really so much worse than 7 in practice that 7 can replace wired for you but 6E can't? That's honestly really weird to me. What's the practical difference in latency, bandwidth or reliability you've experienced between 6E and 7? reply 404mm 24 minutes agorootparentI don’t have any 6E device so I cannot really tell for sure but from what I read, 6E gets you to a bit over 1Gbit in real world scenario. 7 should be able to replace my 2.5Gbe dongle or at least get much closer to it. I already have routers WiFi 7 Eeros on a 2.5Gbe wired backbone. reply mort96 12 minutes agorootparentI guess it makes sense if what you do is extremely throughput-focused... I always saw consistency/reliability and latency as the benefits of wired compared to wireless, the actual average throughput has felt fast enough for a while on WiFi but I guess other people may have different needs reply sroussey 2 hours agoparentprevYeah, this threw me as well. When the iMac didn’t support WiFi 7, I got a bit worried. I have an M2, so not going to get this, but the spouse needs a new Air and I figure that everything would have WiFi 7 by then, and now I don’t think so. reply carstenhag 47 minutes agorootparentFaster is always nice, makes sense. But do you really need WiFi 7 features/speed? I don't know when I would notice a difference (on a laptop) between 600 or 1500 Mbit/s (just as an example). Can't download much anyhow as the storage will get full in minutes. reply throw0101a 40 minutes agorootparent> But do you really need WiFi 7 features/speed? One of the features is preamble punching, which is useful in more dense environments: * https://community.fs.com/article/how-preamble-puncturing-boo... * https://www.ruckusnetworks.com/blog/2023/wi-fi-7-and-punctur... MLO helps with resiliency and the improved OFDMA helps with spectrum efficiency as well. It's not just about speed. reply iknowstuff 42 minutes agorootparentprevCall of Duty is 200GB reply mort96 29 minutes agorootparentHow frequently are you downloading CoD on your Mac? reply BrentOzar 3 hours agoprevThe M4 Max goes up to 128GB RAM, and \"over half a terabyte per second of unified memory bandwidth\" - LLM users rejoice. reply manaskarekar 3 hours agoparentThe M3 Max was 400GBps, this is 540GBps. Truly an outstanding case for unified memory. DDR5 doesn't come anywhere near. reply Rohansi 3 hours agorootparentApple is using LPDDR5 for M3. The bandwidth doesn't come from unified memory - it comes from using many channels. You could get the same bandwidth or more with normal DDR5 modules if you could use 8 or more channels, but in the PC space you don't usually see more than 2 or 4 channels (only common for servers). Unrelated but unified memory is a strange buzzword being used by Apple. Their memory is no different than other computers. In fact, every computer without a discrete GPU uses a unified memory model these days! reply rbanffy 3 hours agorootparent> (only common for servers). On PC desktops I always recommend getting a mid-range tower server precisely for that reason. My oldest one is about 8 years old and only now it's showing signs of age (as in not being faster than the average laptop). reply throwaway48476 1 hour agorootparentprevHigh end servers now have 12 ddr5 channels. reply sliken 35 minutes agorootparentYes, you could buy a brand new (announced weeks ago) AMD Turin. 12 channels of DDR5-6000, $11,048 and 320 watts (for the CPU) and get 576GB/sec peak. Or you could buy a M3 max laptop for $4k, get 10+ hour battery life, have it fit in a thin/light laptop, and still get 546GB/sec. However those are peak numbers. Apple uses longer cache lines (double), large page sizes (quadruple), and a looser memory model. Generally I'd expect nearly every memory bandwidth measure to win on Apple over AMD's turin. reply binary132 3 hours agorootparentprevI read all that marketing stuff and my brain just sees APU. I guess at some level, that’s just marketing stuff too, but it’s not a new idea. reply sliken 2 hours agorootparentThe new idea is having 512 bit wide memory instead of PC limitation of 128 bit wide. Normal CPU cores running normal codes are not particularly bandwidth limited. However APUs/iGPUs are severely bandwidth limited, thus the huge number of slow iGPUs that are fine for browsing but terrible for anything more intensive. So apple manages decent GPU performance, a tiny package, and great battery life. It's much harder on the PC side because every laptop/desktop chip from Intel and AMD use a 128 bit memory bus. You have to take a huge step up in price, power, and size with something like a thread ripper, xeon, or epyc to get more than 128 bit wide memory, none of which are available in a laptop or mac mini size SFF. reply reliabilityguy 2 hours agorootparent> instead of PC limitation of 128 bit wide Memory interface width of modern CPUs is 64-bit (DDR4) and 32+32 (DDR5). No CPU uses 128b memory bus as it results in overfetch of data, i.e., 128B per access, or two cache lines. AFAIK Apple uses 128B cache lines, so they can do much better design and customization of memory subsystem as they do not have to use DIMMs -- they simply solder DRAM to the motherboard, hence memory interface is whatever they want. reply sliken 1 hour agorootparent> Memory interface width of modern CPUs is 64-bit (DDR4) and 32+32 (DDR5). Sure, per channel. PCs have 2x64 bit or 4x32 bit memory channels. Not sure I get your point, yes PCs have 64 bit cache lines and apple uses 128. I wouldn't expect any noticeable difference because of this. Generally cache miss is sent to a single memory channel and result in a wait of 50-100ns, then you get 4 or 8 bytes per cycle at whatever memory clock speed you have. So apple gets twice the bytes per cache line miss, but the value of those extra bytes is low in most cases. Other bigger differences is that apple has a larger page size (16KB vs 4KB) and arm supports a looser memory model, which makes it easier to reach a large fraction of peak memory bandwidth. However, I don't see any relationship between Apple and PCs as far as DIMMS. Both Apple and PCs can (and do) solder dram chips directly to the motherboard, normally on thin/light laptops. The big difference between Apple and PC is that apple supports 128, 256, and 512 bit wide memory on laptops and 1024 bit on the studio (a bit bigger than most SFFs). To get more than 128 bits with a PC that means no laptops, no SFFs, generally large workstations with Xeon, Threadrippers, or Epyc with substantial airflow and power requirements reply jsheard 1 hour agorootparentprev> The new idea is having 512 bit wide memory instead of PC limitation of 128 bit wide. It's not really a new idea, just unusual in computers. The custom SOCs that AMD makes for Playstation and Xbox have wide (up to 384-bit) unified memory buses, very similar to what Apple is doing, with the main distinction being Apples use of low-power LPDDR instead of the faster but power hungrier GDDR used in the consoles. reply Tepix 3 hours agorootparentprevFor comparison, a Threadripper Pro 5000 workstation with 8x DDR4 3200 has 204.8GB/s of memory bandwidth. The Threadripper Pro 7000 with DDR5-5200 can achieve 325GB/s. And no, manaskarekar, the M4 Max does 546 GB/s not GBps (which would be 8x less!). reply wtallis 3 hours agorootparent> And no, manaskarekar, the M4 Max does 546 GB/s not GBps (which would be 8x less!). GB/s and GBps mean the same thing, though GB/s is the more common way to express it. Gb/s and Gbps are the units that are 8x less: bits vs Bytes. reply hmottestad 1 hour agorootparentprevThanks for the numbers. Someone here on hackernews got me convinced that a Threadripper would be a better investment for inference than a MacBook Pro with a M3 Max. reply leptons 1 hour agorootparentprevB = Bytes, b = bits. GB/s is the same thing as GBps The \"ps\" means \"per second\" reply manaskarekar 3 hours agorootparentprevYes, it's just easier to call it that without having to sprinkle asterisks at each mention of it :) And yes, the impressive part is that this kind of bandwidth is hard to get on laptops. I suppose I should have been a bit more specific in my remark. reply oDot 3 hours agorootparentprevIsn't unified memory* a crucial part in avoiding signal integrity problems? Servers do have many channels but they run relatively slower memory * Specifically, it being on-die reply wtallis 3 hours agorootparent\"Unified memory\" doesn't really imply anything about the memory being located on-package, just that it's a shared pool that the CPU, GPU, etc. all have fast access to. Also, DRAM is never on-die. On-package, yes, for Apple's SoCs and various other products throughout the industry, but DRAM manufacturing happens in entirely different fabs than those used for logic chips. reply kube-system 1 hour agorootparentSystem memory DRAM never is, but sometimes DRAM is technically included on CPU dies as a cache https://en.wikipedia.org/wiki/EDRAM reply wtallis 24 minutes agorootparentIt's mostly an IBM thing. In the consumer space, it's been in game consoles with IBM-fabbed chips. Intel's use of eDRAM was on a separate die (there was a lot that was odd about those parts). reply metadat 3 hours agorootparentprevI was curious so I looked it up: https://en.wikipedia.org/wiki/DDR5_SDRAM (info from the first section): > DDR5 is capable of 8GT/s which translates to 64 GB/s (8 gigatransfers/second * 64-bit width / 8 bits/byte = 64 GB/s) of bandwidth per DIMM. So for example if you have a server with 16 DDR5 DIMMs (sticks) it equates to 1,024 GB/s of total bandwidth. DDR4 clocks in at 3.2GT/s and the fastest DDR3 at 2.1GT/s. DDR5 is an impressive jump. HBM is totally bonkers at 128GB/s per DIMM (HBM is the memory used in the top end Nvidia datacenter cards). Cheers. reply reliabilityguy 2 hours agorootparent> So for example if you have a server with 16 DDR5 DIMMs (sticks) it equates to 1,024 GB/s of total bandwidth. Not quite as it depends on number of channels and not on the number of DIMMs. An extreme example: put all 16 DIMMs on single channel, you will get performance of a single channel. reply sroussey 2 hours agorootparentprevYes, and wouldn’t it be bonkers if the M4 Max supported HBM on desktops? reply jsheard 3 hours agorootparentprevIt's not the memory being unified that makes it fast, it's the combination of the memory bus being extremely wide and the memory being extremely close to the processor. It's the same principle that discrete GPUs or server CPUs with onboard HBM memory use to make their non-unified memory go ultra fast. reply smith7018 3 hours agorootparentI thought “unified memory” was just a marketing term for the memory being extremely close to the processor? reply jsheard 3 hours agorootparentNo, unified memory usually means the CPU and GPU (and miscellaneous things like the NPU) all use the same physical pool of RAM and moving data between them is essentially zero-cost. That's in contrast to the usual PC setup where the CPU has its own pool of RAM, which is unified with the iGPU if it has one, but the discrete GPU has its own independent pool of VRAM and moving data between the two pools is a relatively slow operation. An RTX4090 or H100 has memory extremely close to the processor but I don't think you would call it unified memory. reply refulgentis 2 hours agorootparentI don't quite understand one of the finer points of this, under caffeinated :) - if GPU memory is extremely close to the CPU memory, what sort of memory would not be extremely close to the CPU? reply jsheard 2 hours agorootparentI think you misunderstood what I meant by \"processor\", the memory on a discrete GPU is very close to the GPUs processor die, but very far away from the CPU. The GPU may be able to read and write its own memory at 1TB/sec but the CPU trying to read or write that same memory will be limited by the PCIe bus, which is glacially slow by comparison, usually somewhere around 16-32GB/sec. A huge part of optimizing code for discrete GPUs is making sure that data is streamed into GPU memory before the GPU actually needs it, because pushing or pulling data over PCIe on-demand decimates performance. reply refulgentis 1 hour agorootparentI see, TL;DR == none; and processor switches from {CPU,GPU} to {GPU} in the 2nd paragraph. Thanks! reply hollerith 3 hours agorootparentprevI thought it meant that both the GPU and the CPU can access it. In most systems, GPU memory cannot be accessed by the CPU (without going through the GPU); and vice versa. reply layer8 1 hour agorootparentCPUs access GPU memory via MMIO (though usually only a small portion), and GPUs can in principle access main memory via DMA. Meaning, both can share an address space and access each other’s memory. However, that wouldn’t be called Unified Memory, because it’s still mediated by an external bus (PCIe) and thus relatively slower. reply vid 3 hours agorootparentprevIt's not \"DDR5\" on its own, it's a few factors. Bandwidth (GB/s) = (Data Rate (MT/s) * Channel Width (bits) * Number of Channels) / 8 / 1000 (8800 MT/s * 64 bits * 8 channels) / 8 / 1000 = 563.2 GB/s This is still half the speed of a consumer NVidia card, but the large amounts of memory is great, if you don't mind running things more slowly and with fewer libraries. reply Y-bar 1 hour agorootparent> This is still half the speed of a consumer NVidia card, but the large amounts of memory is great, if you don't mind running things more slowly and with fewer libraries. But it has more than 2x longer battery life and a better keyboard than a GPU card ;) reply wtallis 3 hours agorootparentprev> (8800 MT/s * 64 bits * 8 channels) / 8 / 1000 = 563.2 GB/s Was this example intended to describe any particular device? Because I'm not aware of anything that operates at 8800 MT/s, especially not with 64-bit channels. reply sliken 2 hours agorootparentM4 max in the MBP (today) and in the Studio at some later date. reply wtallis 4 minutes agorootparentThat seems unlikely given the mismatched memory speed (see the parent comment) and the fact that Apple uses LPDDR which is typically 16 bits per channel. 8800MT/s seems to be a number pulled out of thin air or bad arithmetic. sliken 2 hours agorootparentprevFewer libraries? Any that a normal LLM user would care about? Pytorch, ollama, and others seem to have the normal use cases covered. Whenever I hear about a new LLM seems like the next post is some mac user reporting the token/sec. Often about 5 tokens/sec for 70B models which seems reasonable for a single user. reply vid 1 hour agorootparentIs there a normal LLM user yet? Most people would want their options to be as wide as possible. The big ones usually get covered (eventually), and there are distinct good libraries emerging for Mac only (sigh), but last I checked the experience of running every kit (stable diffusion, server-class, etc) involved overhead for the Mac world. reply manaskarekar 3 hours agorootparentprevThanks, but just to put things into perspective, this calculation has counted 8 channels which is 4 DIMMs and that's mostly desktops (not dismissing desktops, just highlighting that it's a different beast). Most laptops will be 2 DIMMS (probably soldered). reply wtallis 3 hours agorootparentDesktops are two channels of 64 bits, or with DDR5 now four (sub)channels of 32 bits; either way, mainstream desktop platforms have had a total bus width of 128 bits for decades. 8x64 bit channels is only available from server platforms. (Some high-end GPUs have used 512-bit bus widths, and Apple's Max level of processors, but those are with memory types where the individual channels are typically 16 bits.) reply sliken 2 hours agorootparentprevI think you are confusing channels and dimms. The vast majority of any x86 laptop or desktops are 128 bits wide. Often 2x64 bit channels up till last year or so, now 4x32 bit DDR5 in the last year or so. There are some benefits to 4 channels over 2, but generally you are still limited by 128 bits unless you buy a Xeon, Epyc, or Threadripper (or Intel equiv) that are expensive, hot, and don't fit in SFFs or laptops. So basically the PC world is crazy behind the 256, 512, and 1024 bit wide memory busses apple has offered since the M1 arrived. reply cjbprime 3 hours agorootparentprevRight, the nvidia card maxes out at 24GB. reply mort96 2 hours agorootparentprevThis is a case for on-package memory, not for unified memory... Laptops have had unified memory forever EDIT: wtf what's so bad about this comment that it deserves being downvoted so much reply garciasn 3 hours agoparentprevWe run our LLM workloads on a M2 Ultra because of this. 2x the VRAM; one-time cost at $5350 was the same as, at the time, 1 month of 80GB VRAM GPU in GCP. Works well for us. reply alfonsodev 3 hours agorootparentCan you elaborate, are those workflows in queue or can they serve multiple users in parallel ? I think it’s super interesting to know real life workflows and performance of different LLMs and hardware, in case you can direct me to other resources. Thanks ! reply garciasn 3 hours agorootparentOur use case is atypical, based on what others seem to require. While we serve multiple requests in parallel, our workloads are not 'chat'. reply manaskarekar 3 hours agorootparentprevIf the 2x multiplier holds up, the Ultra update should bring it up to 1080GBps. Amazing. reply SirMaster 2 hours agorootparentThere isn't even an M3 Ultra. Will there be an M4 Ultra? reply hmottestad 1 hour agorootparentAt some point there should be an upgrade to the M2 Ultra. It might be an M4 Ultra, it might be this year or next year. It might even be after the M5 comes out. Or it could be skipped in favour of the M5 Ultra. If anyone here knows they are definitely under NDA. reply tromp 2 hours agorootparentprevThat would make the most sense for the next Mac Studio version. reply int_19h 58 minutes agorootparentThere were rumors that the next Mac Studio will top out at 512Gb RAM, too. Good news for anyone who wants to run 405B LMs locally... reply mpweiher 1 hour agorootparentprevAnd the week isn't over... reply bushbaba 3 hours agorootparentprevAbout 10-20% of my companies gpu usage is inference dev. Yes horribly not efficient usage of resources. We could upgrade the 100ish devs who do this dev work to M4 mbp and free up gpu resources Smart move by Apple reply Der_Einzige 2 hours agorootparentprevRight now, there are 0.90$ per hour H100 80gbs that you can rent. reply sgt101 3 hours agorootparentprevYou have another one with a network gateway to provide hot failover? Right? reply ithkuil 3 hours agorootparentHigh availability story for AI workloads will be a problem for another decade. From what I can see the current pressing problem is to get stuff working quickly and iterate quickly. reply Inviz 3 hours agoparentprevI have M3 Max with 128GB of ram, it's really liberating. reply sfn42 3 hours agorootparentI have 32gb and I've never felt like I needed more. reply umanwizard 2 hours agorootparentHaving 128GB is really nice if you want to regularly run different full OSes as VMs simultaneously (and if those OSes might in turn have memory-intensive workloads running on them). Somewhat niche case, I know. reply moffkalast 3 hours agorootparentprevObviously you're not a golfer. reply andy_ppp 1 hour agorootparenthttps://www.youtube.com/watch?v=YzhKEHDR_rc :-) Thanks for that, I think I will watch The Big Lebowski tonight! reply moffkalast 1 hour agorootparentFar out, man :P reply thimabi 3 hours agoparentprevAt least in the recent past, a hindrance was that MacOS limited how much of that unified memory could be assigned as VRAM. Those who wanted to exceed the limits had to tinker with kernel settings. I wonder if that has changed or is about to change as Apple pivots their devices to better serve AI workflows as well. reply jjcm 1 hour agoparentprevFor context, the 4090 has 1,008 GB/s of bandwidth. reply spacedcowboy 0 minutes agorootparent... but only 1/4 of the actual memory, right ? The M4-Max I just ordered comes with 128GB of RAM. reply doctoboggan 3 hours agoparentprevThis is definitely tempting me to upgrade my M1 macbook pro. I think I have 400GB/s of memory bandwidth. I am wondering what the specific number \"over half a terabyte\" means. reply rsanek 2 hours agorootparent540 reply segmondy 2 hours agoparentprevNeed more memory, 256GB will be nice. MistralLarge is 123B. Can't even give a quantized Llama405B a drive. LLM users rejoice. LLM power users, weep. reply moffkalast 3 hours agoparentprevWell it's more like pick your poison, cause all options have caveats: - Apple: all the capacity and bandwidth, but no compute to utilize it - AMD/Nvidia: all the compute and bandwidth, but no capacity to load anything - DDR5: all the capacity, but no compute or bandwidth (cheap tho) reply jcmontx 3 hours agoprev> \"up to 1.8x faster when compared to the 16-inch MacBook Pro with M1 Pro\" I insist my 2020 Macbook M1 was the best purchase I ever made reply shade 3 hours agoparentI have the OG 13\" MBP M1, and it's been great; I only have two real reasons I'm considering jumping to the 14\" MBP M4 Pro finally: - More RAM, primarily for local LLM usage through Ollama (a bit more overhead for bigger models would be nice) - A bit niche, but I often run multiple external displays. DisplayLink works fine for this, but I also use live captions heavily and Apple's live captions don't work when any form of screen sharing/recording is enabled... which is how Displaylink works. :( Not quite sold yet, but definitely thinking about it. reply AdamJacobMuller 1 hour agoparentprevYep. I've never kept any laptop as long as I've kept the M1. I was more or less upgrading yearly in the past because the speed increases (both in the G4 and then Intel generations) were so significant. This M1 has exceeded my expectations in every category, it's faster quieter and cooler than any laptop i've ever owned. I've had this laptop since release in 2020 and I have nearly 0 complaints with it. I wouldn't upgrade except the increase in memory is great, I don't want to have to shut down apps to be able to load some huge LLMs, and, I ding'ed the top case a few months ago and now there's a shadow on the screen in that spot in some lighting conditions which is very annoying. I hope (and expect) the M4 to last just as long as my M1 did. reply stetrain 3 hours agoparentprevYep. That's roughly 20% per generation improvement which ain't half-bad these days, but the really huge cliff was going from Intel to the M1 generation. M1 series machines are going to be fine for years to come. reply drewbitt 3 hours agoparentprevAnd my 2020 Intel Macbook Air was a bad purchase. Cruelly, the Intel and M1 Macbook Air released within 6 months of each other. reply rconti 3 hours agorootparentIn early 2020, I had an aging 2011 Air that was still struggling after a battery replacement. Even though I \"knew\" the Apple Silicon chips would be better, I figured a 2020 Intel Air would last me a long time anyway, since my computing needs from that device are light, and who knows how many years the Apple Silicon transition will take take anyway? Bought a reasonably well-specced Intel Air for $1700ish. The M1s came out a few months later. I briefly thought about the implication of taking a hit on my \"investment\", figured I might as well cry once rather than suffer endlessly. Sold my $1700 Intel Air for $1200ish on craigslist (if I recall correctly), picked up an M1 Air for about that same $1200 pricepoint, and I'm typing this on that machine now. That money was lost as soon as I made the wrong decision, I'm glad I just recognized the loss up front rather than stewing about it. reply cantsingh 2 hours agorootparentExact same boat here. A friend and I both bought the 2020 Intel MBA thinking that the M1 version was at least a year out. It dropped a few months later. I immediately resold my Intel MBA seeing the writing on the wall and bought a launch M1 (which I still use to this day). Ended up losing $200 on that mis-step, but no way the Intel version would still get me through the day. That said...scummy move by Apple. They tend to be a little more thoughtful in their refresh schedule, so I was caught off guard. reply drewbitt 2 hours agorootparentWhen I saw the M1s come out, I thought that dev tooling would take a while to work for M1, which was correct. It probably took a year for most everything to be compiled for arm64. However I had too little faith in Rosetta and just the speed upgrade M1 really brought. So what I mean to say is, I still have that deadweight MBA that I only use for web browsing :) reply chrizel 2 hours agorootparentprevOh yes, my wife bought a new Intel MBA in summer 2020... I told her at the time Apple planned its own chip, but it couldn't be much better than the Intel one and surely Apple will increase prices too... I was so wrong. reply ElCapitanMarkla 2 hours agorootparentprevYeah I’m in the same boat. I had my old mid 2013 Air for 7 years before I pulled the trigger on that too. I’ll be grabbing myself an M4 Pro this time reply d1str0 3 hours agoparentprevSame. My MBP and M1 Air are amazing machines. But I’m now also excited that any future M chip replacement will be faster and just as nice. The battery performance is incredible too. reply BenFranklin100 3 hours agoparentprevI got a refurbed M1 iPad Pro 12.9” for $900 a couple years ago and have been quite pleased. I still have a couple of years life in it I estimate. reply RobinL 3 hours agoprevCan anyone comment on the viability of using an external SSD rather than upgrading storage? Specifically for data analysis (e.g. storing/analysing parquet files using Python/duckdb, or video editing using divinci resolve). Also, any recommendations for suitable ssds, ideally not too expensive? Thank you! reply pier25 2 hours agoparentIt's totally fine. With a TB4 case with an NVME you can get something like 2300MB/s read speeds. You can also use a USB4 case which will give you over 3000MB/s (this is what I'm doing for storing video footage for Resolve). With a TB5 case you can go to like 6000MB/s. See this SSD by OWC: https://www.owc.com/solutions/envoy-ultra reply joshvm 1 hour agoparentprevBasically any good SSD manufacturer is fine, but I've found that the enclosure controller support is flaky with Sonoma. Drives that appear instantly in Linux sometimes take ages to enumerate in OSX, and only since upgrading to Sonoma. Stick with APFS if you're only using it for Mac stuff. I have 2-4TB drives from Samsung, WD and Kingston. All work fine and are ridiculously fast. My favourite enclosure is from DockCase for the diagnostic screen. reply schainks 1 hour agoparentprevWith a thunderbolt SSD you'll think your external drive is an internal drive. I bought one of these (https://www.amazon.com/gp/product/B0BGYMHS8Y) for my partner so she has snappy photo editing workflows with Adobe CC apps. Copying her 1TB photo library over took under 5 min. reply trogdor 2 hours agoparentprev> Also, any recommendations for suitable ssds, ideally not too expensive? I own a media production company. We use Sabrent Thunderbolt external NVMe TLC SSDs and are very happy with their price, quality, and performance. I suggest you avoid QLC SSDs. reply thejazzman 3 hours agoparentprevi go with the acasis thunderbolt enclosure and then pop in an nvme of your choice, but generic USB drives are pretty viable too ... thunderbolt can be booted from, while USB can't i tried another brand or 2 of enclosures and they were HUGE while the acasis was credit card sized (except thickness) reply AlphaWeaver 2 hours agoparentprevI've used a Samsung T5 SSD as my CacheClip location in Resolve and it works decently well! Resolve doesn't always tolerate disconnects very well, but when it's plugged in things are very smooth. reply rbanffy 3 hours agoparentprevThe USB-C ports should be quite enough for that. If you are using a desktop Mac, such as an iMac, Mini, or the Studio and Pro that will be released later this week, this is a no-brainer - everything works perfectly. reply DrBenCarson 49 minutes agoparentprevGet something with Thunderbolt and you’ll likely never notice a difference reply Tepix 3 hours agoparentprevRun your current workload on internal storage and check how fast it is reading and writing. For video editing - even 8K RAW - you don't need insanely fast storage. A 10GBit/s external SSD will not slow you down. reply tomrod 3 hours agoprevThis is the first compelling Mac to me. I've used Macs for a few clients and muscle memory is very deeply ingrained for linux desktops. But with local LLMs finally on the verge of usability along with sufficient memory... I might need to make the jump! Wish I could spin up a Linux OS on the hardware though. Not a bright spot for me. reply aidenfoxivey 3 hours agoparentYou totally can after a little bit of time waiting for M4 bringup! https://asahilinux.org It won't have all the niceties / hardware support of MacOS, but it seamlessly coexists with MacOS, can handle the GPU/CPU/RAM with no issues, and can provide you a good GNU/Linux environment. reply p_j_w 3 hours agorootparentAsahi doesn't work on M3 yet after a year. It's gonna be a bit before M4 support is here. reply quux 3 hours agorootparentIIRC one of the major factors holding back M3 support was the lack of a M3 mini for use in their CI environment. Now that there's an M4 mini hopefully there aren't any obstacles to them adding M4 support reply mmcnl 3 hours agorootparentWhy would that matter? You can use a MacBook in CI too? reply umanwizard 2 hours agorootparentHow? What cloud providers offer it? MacStadium and AWS don't. I guess you could have a physical MBP in your house and connect it to some bring-your-own-infrastructure CI setup, but most people wouldn't want to do that. reply umanwizard 2 hours agorootparentprev\"a little bit of time\" is a bit disingenuous given that they haven't even started working on the M3. (This isn't a dig on the Asahi project btw, I think it's great). reply __MatrixMan__ 1 hour agoparentprevI miss Linux, it respected me in ways that MacOS doesn't. But maintaining a sane dev environment on linux when my co-workers on MacOS are committing bash scripts that call brew... I am glad that I gave up that fight. And yeah, the hardware sure is nice. reply tomrod 55 minutes agorootparentIIRC brew supports linux, but it isn't a package manager I pay attention to outside of some very basic needs. Way too much supply chain security domain to cover for it! reply d1str0 3 hours agoparentprevCheck out Asahi linux reply BenFranklin100 3 hours agoparentprevOff topic, but I’m very interested in local LLMs. Could you point me in the right direction, both hardware specs and models? reply thrownblown 3 hours agorootparenthttps://www.reddit.com/r/LocalLLaMA/ https://www.reddit.com/r/SillyTavernAI/ reply BenFranklin100 2 hours agorootparentThanks to both of you! reply doctoboggan 3 hours agorootparentprevIn general for local LLMs, the more memory the better. You will be able to fit larger models in RAM. The faster CPU will give you more tokens/second, but if you are just chatting with a human in the loop, most recent M series macs will be able to generate tokens faster than you can read them. reply int_19h 53 minutes agorootparentThat also very much depends on model size. For 70B+ models, while the tok/s are still fast enough for realtime chat, it's not going to be generating faster than you can read it, even on Ultra with its insane memory bandwidth. reply noman-land 1 hour agorootparentprevGet as much RAM as you can stomach paying for. reply lowbloodsugar 3 hours agoparentprevYou can spin up a Unix OS. =) It’s even older than Linux. reply tomrod 54 minutes agorootparentBSD is fun (not counting MacOS in the set there), but no, my Unix experiences have been universally legacy hardware oversubscribed and undermaintained. Not my favorite place to spend any time. reply umanwizard 2 hours agorootparentprevNextSTEP which macOS is ultimately based on is indeed older than Linux (first release was 1989). But why does that matter? The commenter presumably said \"Linux\" for a reason, i.e. they want to use Linux specifically, not any UNIX-like OS. reply wkyleg 2 hours agoprevWhat's the consensus regarding best MacBooks for AI/ML? I've heard it's easier to just use cloud options, but I sill like the idea of being able to run actual models and train them on my laptop. I have a M1 MacBook now and I'm considering trading in to upgrade. I've seen somewhat conflicting things regarding what you get for the money. For instance, some reports recommending a M2 Pro for the money IIRC. reply ZeroCool2u 1 hour agoparentTraining is not practical. For inference they're pretty great though, especially if you go up in the specs and add a bunch of memory. reply rTX5CMRXIfFG 5 minutes agoprevThat ad reveal at the end. Someone in the marketing team must have started doing CrossFit reply LeifCarrotson 3 hours agoprevI'm pleased that the Pro's base memory starts at 16 GB, but surprised they top out at 32 GB: > ...the new MacBook Pro starts with 16GB of faster unified memory with support for up to 32GB, along with 120GB/s of memory bandwidth... I haven't been an Apple user since 2012 when I graduated from college and retired my first computer, a mid-2007 Core2 Duo Macbook Pro, which I'd upgraded with a 2.5\" SSD and 6GB of RAM with DDR2 SODIMMs. I switched to Dell Precision and Lenovo P-series workstations with user-upgradeable storage and memory... but I've got 64GB of RAM in the old 2019 Thinkpad P53 I'm using right now. A unified memory space is neat, but is it worth sacrificing that much space? I typically have a VM or two running, and in the host OS and VMs, today's software is hungry for RAM and it's typically cheap and upgradeable outside of the Apple ecosystem. reply jsheard 3 hours agoparent> I'm pleased that the Pro's base memory starts at 16 GB, but surprised they top out at 32 GB: That's an architectural limitation of the base M4 chip, if you go up to the M4 Pro version you can get up to 48GB, and the M4 Max goes up to 128GB. reply FireBeyond 3 hours agorootparentThe \"base level\" Max is limited at 36GB. You have to get the bigger Max to get more. reply redundantly 3 hours agoparentprevThe M4 tops off at 32 GB The M4 Pro goes up to 48 GB The M4 Max can have up to 128 GB reply ldoughty 3 hours agorootparentIt seems you need the M4 Max with the 40-core GPU to go over 36GB. The M4 Pro with 14‑core CPU & 20‑core GPU can do 48GB. If you're looking for ~>36-48GB memory, here's the options: $2,800 = 48GB, Apple M4 Pro chip with 14‑core CPU, 20‑core GPU $3,200 = 36GB, Apple M4 Max chip with 14‑core CPU, 32‑core GPU $3,600 = 48GB, Apple M4 Max chip with 16‑core CPU, 40‑core GPU So the M4 Pro could get you a lot of memory, but less GPU cores. Not sure how much those GPU cores factor in to performance, I only really hear complaints about the memory limits... Something to consider if looking to buy in this range of memory. Of course, a lot of people here probably consider it not a big deal to throw an extra 3 grand on hardware, but I'm a hobbyist in academia when it comes to AI, I don't big 6-figure salaries :-) reply SparkyMcUnicorn 3 hours agorootparentprevIt doesn't look this cut and dry. M4 Max 14 core has a single option of 36GB. M4 Max 16 core lets you go up to 128GB. So you can actually get more ram with the Pro than the base level Max. reply fckgw 3 hours agoparentprevOn the standard M4 processor. If you move the M4 Pro it tops out at 48gb or moving to the M4 Max goes up to 128gb. reply Tepix 3 hours agorootparentThe 96GB RAM option of the M3 Max disappeared. reply 41995701 3 hours agorootparentprevWeird that the M4 Pro in the Mac mini can go up to 64GB. Maybe a size limitation on the MBP motherboard or SOC package? reply _diyar 3 hours agorootparentProbably just Apple designing the pricing ladder. reply post-it 3 hours agoparentprevI haven't done measurements on this, but my Macbook Pro feels much faster at swapping than any Linux or Windows device I've used. I've never used an M.2 SSD so maybe that would be comparable, but swapping is pretty much seamless. There's also some kind of memory compression going on according to Activity Monitor, not sure if that's normal on other OSes. reply thimabi 3 hours agorootparentYes, other M.2 SSDs have comparable performance when swapping, and other operating systems compress memory, too — though I believe not as much as MacOS. Although machines with Apple Silicon swap flawlessly, I worry about degrading the SSD, which is non-replaceable. So ultimately I pay for more RAM and not need swapping at all. reply Octoth0rpe 3 hours agoparentprevThe max memory is dependent on which tier M4 chip you get. The M4 max chip will let you configure up to 128gb of ram reply MaxDPS 2 hours agorootparentIt looks like the 14 core M4 Max only allows 36GB of ram. The M4 Pro allows for up to 48GB. It's a bit confusing. reply unsupp0rted 2 hours agoprevI have a 16\" M1 Pro with 16 gigs of ram, and it regularly struggles under the \"load\" of Firebase emulator. You can tell not because the system temp rises, but because suddenly Spotify audio begins to pop, constantly and irregularly. It took me a year to figure out that the system audio popping wasn't hardware and indeed wasn't software, except in the sense that memory (or CPU?) pressure seems to be the culprit. reply duped 26 minutes agoparentThis kind of sounds like someone is abusing perf cores and high priority threading in your stack. iirc, on MacOS audio workgroup threads are supposed to be scheduled with the highest (real time) priority on p cores, which shouldn't have issues under load, unless someone else is trying to compete at the same priority. reply zaptrem 53 minutes agoparentprevThis happens whenever I load up one of our PyTorch models on my M1 MBP 16gb too. I also hate the part where if the model (or any other set of programs) uses too much RAM the whole system will sometimes straight up hang and then crash due to kernel watchdog timeout instead of just killing the offender. reply maxioatic 2 hours agoparentprevI have a 14\" M1 Max with 32gb of ram for work, and it does that popping noise every once it a while too! I've always wondered what was causing it. reply SSLy 1 hour agorootparentIm relatively surprised modern Macs have same buffer underrun issue I had on intel laptops with pulseaudio 7+ years back. reply silvr 1 hour agoparentprevWhoa! I've been so annoyed by this for years, so interesting that you figured it out. It's the kind of inelegance in design that would have had Steve Jobs yelling at everyone to fix, just ruins immersion in music and had no obvious way to fix. reply zja 59 minutes agoprev> MacBook Air is the world’s most popular laptop, and with Apple Intelligence, it’s even better. Now, models with M2 and M3 double the starting memory to 16GB, while keeping the starting price at just $999 — a terrific value for the world’s best-selling laptop. This is nice, and long overdue. reply hartator 1 hour agoprevI’m really excited about the nano-texture display option. It’s essentially a matte coating, but the execution on iPad displays is excellent. While it doesn’t match the e-ink experience of devices like the Kindle or ReMarkable, it’s about 20-30% easier on the eyes. The texture feels also great (even though it’s less relevant for a laptop), and the glare reduction is a welcome feature. I prefer working on the MacBook screen, but I nearly bought an Apple Studio Display XDR or an iPad as a secondary screen just for that nano-texture finish. It's super good news that this is coming to the MacBook Pro. reply dkarbayev 29 minutes agoparentDo you actually have to wipe the screen with the included special cloth? The screen on all of the macbooks that I've had usually get oily patches because of the contact with keycaps, so I have to w",
    "originSummary": [
      "Apple has introduced the new MacBook Pro with the M4 chip family, including M4, M4 Pro, and M4 Max, which promise improved performance and capabilities.- The MacBook Pro now features Apple Intelligence, a personal intelligence system, and comes in space black and silver, with prices starting at $1,599 for the 14-inch model and $2,499 for the 16-inch model.- Notable features include a 12MP Center Stage camera, Thunderbolt 5 ports, a nano-texture display option, and up to 24 hours of battery life, with availability for pre-order and in-store release on November 8."
    ],
    "commentSummary": [
      "The M4 MacBook Pro has garnered attention for its impressive performance, reducing the need for frequent upgrades among users, even those with M1 models.- The M-series chips have enhanced battery life and efficiency, influencing a shift in the laptop market and underscoring the longevity and value of Apple's recent hardware.- Discussions include the potential for local AI processing and the advantages of unified memory in Apple's architecture, which contribute to the overall appeal of these devices."
    ],
    "points": 457,
    "commentCount": 525,
    "retryCount": 0,
    "time": 1730300420
  },
  {
    "id": 41994640,
    "title": "Dropbox announces 20% global workforce reduction",
    "originLink": "https://blog.dropbox.com/topics/company/an-update-from-drew",
    "originBody": "Company An update from Drew By Drew Houston Published on October 30, 2024 Today, our cofounder and CEO Drew Houston shared the difficult news that we’ll be making reductions to our global workforce. He sent the following email to all employees: Hi everyone, I’m writing to let you all know that after careful consideration, we've decided to reduce our global workforce by approximately 20% or 528 Dropboxers. As CEO, I take full responsibility for this decision and the circumstances that led to it, and I’m truly sorry to those impacted by this change. Why we're making this decision As we've shared over the last year, we're in a transitional period as a company. Our FSS business has matured, and we've been working to build our next phase of growth with products like Dash. However, navigating this transition while maintaining our current structure and investment levels is no longer sustainable. We continue to see softening demand and macro headwinds in our core business. But external factors are only part of the story. We’ve heard from many of you that our organizational structure has become overly complex, with excess layers of management slowing us down. And while I'm proud of the progress we’ve made in the last couple years, in some parts of the business, we’re still not delivering at the level our customers deserve or performing in line with industry peers. So we're making more significant cuts in areas where we're over-invested or underperforming while designing a flatter, more efficient team structure overall. The opportunity ahead The changes we're making today, while difficult, come at a pivotal moment when the market is accelerating precisely where we've placed our biggest bets. It's been tremendously rewarding over the last few weeks to see customers and prospects light up when using Dash for Business for the first time, much like people did when we first launched Dropbox. And this time we're starting from a position of strength. Millions of customers trust us as the home for their most important files, making the leap to organizing all their cloud content a natural evolution. But we're not operating on our own schedule. This market is moving fast and investors are pouring hundreds of millions of dollars into this space. This both validates the opportunity we've been pursuing and underscores the need for even more urgency, even more aggressive investment, and decisive action. The steps we’re taking today are necessary to both strengthen our core product and accelerate the growth of our new products. We’ll share more about our 2025 strategy in the days ahead. Taking care of impacted employees To those leaving Dropbox, we're committed to supporting you through this transition. You’ll be eligible to receive the following benefits and support: Severance, equity, and transition payment All impacted employees will be eligible for sixteen weeks of pay, starting today, with one additional week of pay for each completed year of tenure at Dropbox. Internationally, severance packages will vary depending on regional practices and statutory requirements. All impacted employees will receive their Q4 equity vest. Those on the Corporate Bonus plan will be eligible to receive a pro-rated lump sum transition payment equivalent to their 2024 bonus target based on company performance forecasts and aligned with their level. We will pay out eligible remaining current and approved upcoming paid leaves, including medical or family leaves. We will support impacted visa holders by providing additional time to transition and access to 1:1 immigration consultation. Healthcare and benefits US employees will be eligible for up to six months of COBRA. Canada-based employees will be eligible for a one-month healthcare extension. All employees will continue to have access to Modern Health to support their mental well-being. Devices Impacted employees will be eligible to keep company devices (phones, tablets, laptops, and peripherals) for personal use. Job placement Job placement services and career coaching will be available at no cost. Next steps We'll be sharing more details on high-level changes later today and will host company-wide Town Halls later this week to answer questions and discuss our plans in more detail. I know this is incredibly difficult and unwelcome news. To everyone leaving Dropbox, I’m deeply grateful for everything you've done for our company and our customers. Drew Filed under News Company The Author Drew Houston Share 'close share' @ i18n} Twitter Facebook LinkedIn Copy Link",
    "commentLink": "https://news.ycombinator.com/item?id=41994640",
    "commentBody": "Dropbox announces 20% global workforce reduction (dropbox.com)405 points by mfiguiere 5 hours agohidepastfavorite708 comments tschellenbach 2 hours agoThe same forces that enable high tech salaries, also make layoffs more likely. - The market for talent is competitive. So companies bid up to the absolute max they can - The market for managers is also competitive. Creating dynamics that lead to larger teams and raises for team members - Companies allow things like remote work, which is a perk, but also has a lot of abuse in terms of how much work gets done The end result is that if companies are spending their max, if there's a shock to the market/system etc they have to cut. You'd see this less if there was more padding/ less competitive pressure/lower salaries. I think that's fine and the system is working as intended. People should be freed up to move to other roles where they can be productive. Your manager doesn't get upset when you leave, bit weird how people feel so differently when they get fired. The issue is not that you're getting fired. The issue is that healthcare is attached to employment, that makes zero sense. There should also be some reasonable government provided safety net so people can reskill/learn and move to other fields. reply njtransit 1 hour agoparentA somewhat sensible take, but the issue isn’t just healthcare. A lot of your life is based off of long-term, fixed cost cash flow. E.g. you can’t pay less on your mortgage just because you got fired. Even with savings, getting laid off is highly disruptive, and, if done as part of a broader downturn in the market, you may never recover the required cash flow to enable your lifestyle. reply midhhhthrow 2 minutes agorootparentThis why we need the tiny home movement combined with progressive property taxes - 0 prop tax bracket for lowest 20% property values If you have mortgage then you don’t really own your house. reply wbl 1 hour agorootparentprevAvoid lifestyle creep! I have to say I'm bad at this myself: somehow it all adds up, while each individual expense doesn't look so bad. reply nickff 1 hour agorootparentThere are also different types of creep, some that you can easily stop, and others that are more difficult. Specifically, everything that involves a medium to long-term obligation (such as a mortgage or vehicle loan) can cause problems if you cannot sustain it through cashflow interruptions or significant declines. Going out to expensive restaurants and Broadway shows definitely costs a lot of money, but you can immediately stop them if you have money trouble. reply dixie_land 1 hour agorootparentprevExactly, I feel a lot of my coworkers fell under this trap: if you need cashflow for mortgage on your 4m mansion in (affluent neighborhood), you can't really afford it. reply silisili 19 minutes agorootparentEvery house requires cash flow, regardless of mortgage amount. There's something to be said for overspending on a house for sure - but let's not forget mortgage(if any), maintenance, property tax, utilities, insurance, etc. Last year I spent more on maintenance than my mortgage cost. reply xeromal 1 hour agorootparentprevI make a decent salary as a programmer (150k) but my house only cost 250k and my mortgage is about 1400. How I see it, if I have to flip burgers to keep my house, I can pull it off. I can't imagine have a mortgage that's 10gs a month. reply firesteelrain 4 minutes agorootparent> my house only cost 250k I find it hard to believe you can flip enough burgers to pay that mortgage and still survive. Not many fast food places will pay over 30 hours a week to burger flippers. Managers yes. You would barely survive. jrs235 36 minutes agorootparentprev>if I have to flip burgers to keep my house Sadly it seems it's unlikely they'll hire you even though they might need the help that bad because they're afraid of paying to train you and then you leaving once something better, and in your line of work, comes along. reply xeromal 33 minutes agorootparentI mean I just meant a low paying job. During COVID which even have more oversupply, I was bored and I was drive around doing doordash and other delivery services even though I had my tech job. There is always a surefire way of making one or two thousand a month here in the states if you're properly motivated. reply mvdtnz 1 hour agorootparentprevFor a lot of people this isn't possible. You won't find a liveable home in my country for under 600k. reply jokethrowaway 1 minute agorootparentAnd salaries are likely not 150k either xeromal 57 minutes agorootparentprevFor sure but that would mean saving for it is even more impossible. reply Brystephor 1 hour agorootparentprevThe only mortgages that don't require cashflow are the paid off mortgages. Even if someone has a year of savings, or two years, or three, after that amount is drained, they need cash flow again. So how does one buy a house without being dependent on cash flow? reply jonkho 0 minutes agorootparentIf the problem is the mortgage then rent /s. If the problem is you need money to pay the bills, well I got news for you… ghaff 1 hour agorootparentprevWell, you need cashflow on a house in general. Even with a paid-off mortgage, I'm easily $10K/year and probably closer to $20K if I'm not pushing various stuff off. reply sokoloff 1 hour agorootparentProperty tax alone is around $13K/yr for me. Insurance is another couple grand. Only after that comes wear and tear and maintenance items. reply herf 41 minutes agorootparentIf you pay cash for a house and put 60% more in an annuity, you cover the total costs. Not cheap though. reply ghaff 25 minutes agorootparentThe point is that, however you finance it, owning a paid-for place will often have significant ongoing costs. Some more, some less. reply mulmen 1 hour agorootparentprevWell the most obvious approach would be to pay cash. The more fiscally conservative option is to only borrow money if you have capital which is earning income at a higher rate than the mortgage. This probably necessitates having more capital than the house costs. reply xeromal 1 hour agorootparentThe problem with that is that unless you have an extremely well paying job or rich parents, you have to outsave inflation and rising house prices. You may never own. Getting a loan just locks you into an inflation proof price as a \"forced\" savings. I don't think it's realistic at all for 85% of Americans to save for a new house. reply mulmen 49 minutes agorootparentYes, it’s a tragedy of the commons. That doesn’t make taking on a loan you can’t afford less of a bad idea. House prices are unaffordable because people take on loans they can’t afford. This reinforces the unaffordable prices. If milk was $40.00 a gallon you’d just stop putting it on cereal and eventually farmers get the message. Houses are the same thing. If you can’t comfortably afford a house then don’t buy it. You’re stuck renting or buying something more modest. This isn’t complicated. The idea that house prices can only go up is delusional. Nothing about a house is uniquely inflation proof or even inflation resistant. This isn’t the only investment vehicle available to you. This idea that houses are an important part of financial security is putting the cart in front of the horse. It leads to the NIMBYism that prevents additional supply from being built because prices must always go up. We all exist in the same economy and no action happens in a vacuum. When you buy something you have reduced supply and applied upward pressure on price. Individually this effect is so small it is immeasurable. In aggregate it isn’t. reply GiorgioG 1 hour agorootparentprevCan I avoid inflationcreep? How? reply krambs 1 hour agorootparentIndex funds? reply GiorgioG 1 hour agorootparentI can't eat index funds. reply dvngnt_ 1 hour agorootparentprevlike kids? reply jes5199 1 hour agorootparentprevhonestly this is one of the reasons I prefer pre-IPO companies, my salary is lower until they do a buyback or an exit, but it ends up basically in the same place over the long term. This is how I was able to put a downpayment on a house without consciously \"saving up\" for it. Obviously there's some risk but I've had two buybacks, one IPO, and two acquisitions since 2012 reply lazide 57 minutes agorootparentprevJust wait until you have to deal with child support and imputed income. Getting fired/laid off is about the only thing that can save you. reply bruckie 30 minutes agoparentprev> Your manager doesn't get upset when you leave, bit weird how people feel so differently when they get fired. When you leave, your manager loses 1/N of team productivity. When you get fired, you lose 100% of your income. I bet the manager would be more upset if the entire team quit. But even then, they'd still have their job—for a while, at least. reply midhhhthrow 1 minute agoparentprevHealthcare attached to employment makes no sense ina world where people constantly need to switch jobs reply desbo 1 hour agoparentprevThe idea that someone's response to being fired should be the same as a manager's response to one of their reports quitting is hilariously out of touch. reply ironmagma 44 minutes agorootparentIt kind of ignores the core asymmetry of capitalism, that those with the capital are the ones with the power. Nobody can do a background check on a company to see who they laid off or fired before they work there. reply frmersdog 12 minutes agoparentprevIt comes down to the concentration of wealth. Companies wouldn't have the capital to bid up salaries if they faced stiffer competition or couldn't access investment from a limited pool of investors (who all think the same), as is the case now. I know that \"diversity\" is a dirty word these days, but it's key. A large middle class, where each family has a small amount of money to put towards their diverse desires, is going to lead to a more stable economy than all of the money pooled in the hands of a small group with a much smaller set of needs. Dropbox should never have been able to hire so many people; that capital should have been in the hands of the larger public, who could have spent it supporting a more diverse set of hundreds or thousands of jobs (who wouldn't all be competing with each other for a limited number of seats in the \"not laid off\" lifeboat). Put simply, these kinds of things are going to keep happening until our wealthiest (individuals/families/companies) are a lot less rich. reply sokoloff 1 hour agoparentprev> bit weird how people feel so differently when they get fired That doesn't seem the least bit weird to me. If I choose to leave a job (or relationship), I could quite sensibly feel differently if that same job (or relationship) chooses to leave me. reply not_your_vase 1 hour agoparentprev> high tech salaries Are they really high? They are not that different from UPS driver salaries. Just the other day I clicked on the website of some random law firm's career page. I wasn't happy with what I saw (in the context of my own career). Some researchers with 1 year of experience with starting salary of 450k+... tech salaries look high as long as you don't check other professions. reply stoniejohnson 1 hour agorootparentThey were high in 2013. reply teractiveodular 1 hour agoparentprevFYI, Dropbox does not merely allow remote work, it's a fully remote-first company. There's a couple of offices for get-togethers and a few people physically staffing data centers, but everybody else works wherever they want to. reply marcosdumay 51 minutes agoparentprev> Your manager doesn't get upset when you leave, bit weird how people feel so differently when they get fired. That's because people have a single employer, while companies have several employees. That's also why employees are protected, while companies are mostly not. And yeah, the US doubles down on the problem by linking health insurance with the job. reply Powdering7082 42 minutes agoparentprevBeing able to stay in the country is also tied to employment for plenty of people reply mulmen 1 hour agoparentprev> Companies allow things like remote work, which is a perk, but also has a lot of abuse in terms of how much work gets done Do you have any evidence of this? There are unfounded claims of “productivity metrics” but I have never actually seen one. E: I realize this is a poor choice of words after saying productivity metrics don’t exist. What I mean is my tasks are easier to complete in a WFH environment than they are in an office. I have been far more productive from home. The constraints around communication necessitate effective documentation which enables asynchronous communication which alleviates scheduling challenges which improves delivery. Maybe managers need to go in to the office to rub elbows but ICs definitely don’t. reply itsoktocry 1 hour agorootparent>I have been far more productive from home. Same. It's been a boon for me, and I genuinely enjoy my work, so it's win win. But anecdotally, I know people who abuse it. On net, remote work is a plus: less commute, less pollution etc etc. And even the abusers, it's not like those people were highly productive in the office, I'm sure. reply mulmen 47 minutes agorootparentOk but how do you know they are abusers? And what is the net effect? reply pc86 1 hour agoparentprev> There should also be some reasonable government provided safety net There is, it's called Medicaid. reply jedberg 8 minutes agorootparentThat's not really a solution. You have to be broke to use Medicaid. They expect you to fully drain all your assets first. I shouldn't have to sell my house to get medical care. reply slater 1 hour agorootparentprevThey said reasonable, not \"endlessly-patched-up nonsense that conservatives want to gut at every turn\" reply pc86 1 hour agorootparentI feel like \"Medicaid could be better\" is a statement everyone can agree on, but my point stands that the meme that US healthcare is some Mad Max apocalyptic wasteland where you're completely on your own and left to die in the street is categorically false. Not a single person in the US is denied healthcare based on inability to pay. reply slater 1 hour agorootparent> Not a single person in the US is denied healthcare based on inability to pay. Yes, because that's the law. Then they hand you an exorbitant bill on the way out, which you can't pay. Then you get hounded by collections. Then your credit score tanks. etc. etc. etc. Not everything is a direct line, the end result is the same. reply miningape 1 hour agoparentprev> Your manager doesn't get upset when you leave, bit weird how people feel so differently when they get fired. Really? You think its weird that someone leaving impacts that person more than their manager, team, or company? A manager doesn't care that you leave because he still gets to bring home a salary, all they have to do is hire another person and maybe cut back on scope for a little while. When someone is layed off or fired they have to go find a new job, their income streams dry up, and are forced to rely on savings. People often have long term financial commitments they cannot back out of, and not knowing how you'll make rent, if you can afford your child's school fees, or even maybe having to cut back on how much you eat, _is stressful_ and emotionally taxing. Are you fucking kidding me? \"Which is a bit weird\" I'll tell you what's weird: management who doesn't understand that their employees rely on them more than they rely on the employee. Of course its fine when someone chooses to leave their job, they've made contingencies and planned around it. Whether it's through savings, another job, or the lottery, people have at least some idea of their plan when they leave a job. reply mrthrowaway999 1 hour agorootparent> People often have long term financial commitments they cannot back out of, and not knowing how you'll make rent, if you can afford your child's school fees, or even maybe having to cut back on how much you eat, _is stressful_ and emotionally taxing. I'm sure people making >200k/year and getting a 4 month severance package will be cutting back on how much they eat. What you say is true about low or even medium income jobs. But most of the cuts are to tech workers and their managers, ie. people best equipped to manage in this kind of event. reply miningape 1 hour agorootparentYou'd be surprised what lifestyle creep does to people. Often people don't pay off their debts and instead scale their debts to their new income - it's stupid I know. I agree they should be in a better position because of their income, and I'd say more than an average amount are. But there are still a lot of people in that bracket who absolutely would have the floor pulled out from under them. People are often caught with their pants down assuming the good times will keep rolling. And even when they see the market downturn or have a generous severance, it still can be very difficult to scrape together the 6+ months emergency fund required on short notice. reply whatshisface 1 hour agorootparentDepending on the resale value of what the debt is for (homes mainly) maintaining your leverage ratio can work out great for you. Mortgages are the only way most people are able to invest with leverage and the source of a lot of generational wealth. reply Goronmon 1 hour agorootparentprevA manager doesn't care that you leave because he still gets to bring home a salary, all they have to do is hire another person and maybe cut back on scope for a little while. Yeah, I'm curious how someone can have an opinions on workplaces and workers and not seem to have personal experience with the subject, especially in a community like this. Do they just come from a wealthy family so the stance is \"Getting fired isn't a big deal, just ask your dad to cover expenses until your next job.\"? reply miningape 1 hour agorootparentIt seems the original commenter has never really been a \"line-worker\". But I could be very wrong too, but then I'd be curious how those opinions were formed. reply cipheredStones 20 minutes agorootparentNope, you're correct: he runs a startup and apparently has been running startups since his early 20s. > Please tell us briefly about your background. > I grew up in the Netherlands, and I was interested in technology from a young age. I started a gaming website when I was 13. Later, I attended Erasmus University Rotterdam before founding Fashiolista, my first startup and an early social network similar to Pinterest. It grew to millions of users... reply mrthrowaway999 1 hour agorootparentprevDon't people have savings? Don't people see what's happening in the industry and make sure to have 6+ months of savings? Don't people think that putting away a small portion of their immense tech salary would be a healthy thing to do? reply muffinman26 1 hour agorootparentIf you grew up with even the slightest feeling of financial insecurity, dipping in to savings can already feel like the end of the world. I can't imagine living with only 6 months of savings. There's no guarantee that I could find another job in 6 months, and unexpected expenses (medical, car trouble, housing repairs) can easily wipe out a month of savings anyway. In fact, given that a layoff means likely also an economic downturn, finding a job at the same salary within 6 months seems highly unlikely. I have probably 3 years of no-risk savings at this point, have managed to reduce my living expenses to the point where I could work a 40-hour minimum wage job and still pay for my expenses, and have multiple back-up careers, and I'm only now starting to feel that taking money out of savings is an acceptable risk. That took years of frugal living on a high tech salary. People in their first few years at a tech job or with families will probably never achieve that. reply zero-sharp 0 minutes agorootparentIt's so frustrating reading the comments around here. It's like the conversation is driven by people whose circumstances fall on the upper tail end. No concept of financial insecurity. No long-term financial commitments to worry about. Infinite flexibility. Like jeez, congrats. ghaff 1 hour agoparentprevThere's also COBRA, and the exchanges in the US. Frankly, even if you're eligible for Medicare it really isn't any cheaper if you're a current or recent high earner. But, in any case, it's about $7K/year for an individual who doesn't otherwise have coverage for a spouse etc. reply deeviant 43 minutes agoparentprev> Companies allow things like remote work, which is a perk, but also has a lot of abuse in terms of how much work gets done Do you mind expanding on this? How does remote work change the standards of how much work somebody has to get down? reply thaumasiotes 10 minutes agoparentprev> The market for talent is competitive. A couple months ago interviewing.io posted something bragging about how \"we do anonymous mock interviews. If people perform well in those interviews, they get introduced directly to a decision-maker at top-tier companies, regardless of how they look on paper.\" ( https://interviewing.io/blog/i-love-meritocracy-but-all-the-... ) This annoyed me enough that I sent in an email complaining that their introduction process specifically notes that I am not eligible for anything, despite performance measured by the site as \"highest ever achieved: 94th percentile\" (so, knock that down a bit for being a high water mark), because of an insufficient number of years of experience. They responded: > It really sucks, especially in this market, but this policy is a function of us having tried for years to get companies to take junior intros, and it didn't work. We offered to do it completely for free, too, fwiw, and no dice. How competitive is the market for talent? Let's stipulate that, because of a lack of prior employment, I'm not qualified to have a job. How exactly would that situation change? reply progbits 1 hour agoparentprev> remote work, which is a perk, but also has a lot of abuse in terms of how much work gets done If you can't tell remote employees are slacking then you also can't tell if they are slacking in the office, you are just getting fooled by thinking presence implies work. So tired of hearing this \"argument\". reply steveBK123 3 hours agoprevVery generous severance packages and companies/laders should be commended for this. If it's a one-and-done big cut with generous packages to save the company, then good on them. Somehow overhiring and maintaining said headcount long enough to need to do a 20% cut is probably less commendable, but not exactly an outlier there in the current climate. I've always wondered about all these standalone \"point solution\" companies and how durable the model is. In the current climate of reduce M&A, and cost consciousness there is no one to sell to. And as the big platforms - AWS, Azure, GCP continue to grow.. it strikes me that more big companies would rather have a one-stop shop full of 80% solutions than pay for 100 different SaaS. reply bravetraveler 2 hours agoparentNot one-and-done, at least step 3 in a potential routine: 16% in 2023: https://blog.dropbox.com/topics/company/a-message-from-drew Or, before that, another 11%: https://dropbox.gcs-web.com/node/8916/html I wish them well, things look rough. reply alpb 2 hours agoparentprevThey've been doing 20% layoffs two years in a row now. reply steveBK123 2 hours agorootparentYeah that's \"run for the exits\" territory to me. Especially considering they are already below pre-COVID staff levels it appears. reply TechDebtDevin 2 hours agoparentprevSeverence is only so they can dodge regulatory scrutiny. They are not doing it out of the goodness of their hearts and was a line-item in the burden category for those employees when they were hired. reply spit2wind 2 hours agorootparentWhat regulatory scrutiny do you mean? They don't need to provide severance, as far as California law seems concerned. I'm not a Californian, but an Internet search shows they're an at-will state. So it seems like everything is on the (legal) level. reply benbayard 1 hour agorootparentCalifornia has the WARN act which I believe requires notice of 50 days, which people usually use to give severance. In the USA when someone is told they will be fired, usually we do not keep them on staff so severance is the usual middle ground. reply sgerenser 1 hour agorootparentIt's 60 days, not 50. But 60 days of severance would be significantly less than what they are offering. They're definitely not doing it strictly to avoid regulatory scrutiny, more like to avoid bad press and a bad reputation in the tech market. When things eventually swing back up, companies still want to be able to hire the best talent, they don't want to be grouped with companies like Twitter. reply objektif 37 minutes agorootparentWhat is wrong with Twitter? reply mbbbb 19 minutes agorootparentThey did not pay severance when they laid people off. reply kirubakaran 1 hour agorootparentprevhttps://en.wikipedia.org/wiki/Worker_Adjustment_and_Retraini... reply seneca 2 hours agorootparentprevThere's really no pleasing some people. Companies make cuts and don't give generous packages, they're evil. They give a package and it's just so they can dodge scrutiny. This kind of no-win complaining is tiresome. reply sosodev 2 hours agorootparentObviously the win is not laying people off. It's no secret that tech companies have not been hiring for sustainability and that sucks. reply hn_throwaway_99 1 hour agorootparent> Obviously the win is not laying people off. All you are arguing for is that Dropbox should never have hired these people in the first place. Why is that better? At least these people got some years of high pay, experience, networking relationships, etc. Obviously it's disruptive, and it could be a big net negative for people who maybe jumped ship from more stable jobs only to be quickly laid off, but that's not the broad experience. reply gretch 1 hour agorootparentprev\"It's no secret that tech companies have not been hiring for sustainability and that sucks.\" Does it suck? It means that someone got a job where they didn't really have to do that much and got paid anyway. An alternative is where that job was never offered. And then we're complaining that there's no jobs. Also, no, the solution is not to \"just hire the perfect amount\". Sure if we could just do anything perfectly everything is great, but how is that a reasonable demand. reply rsanek 25 minutes agorootparent> where they didn't really have to do that much Source? reply AdmiralAsshat 2 hours agoprevRemember how there used to be a blog (or maybe it was a Tumblr, I forget) that documented every \"Our incredible journey\" post that inevitably announced the start-up's closure? I think we need another one for \"An update from \", as this has seemingly become the standard subject to use when you're announcing layoffs or data breaches. I saw an identical headline earlier today from Sony announcing a studio closure: https://sonyinteractive.com/en/news/blog/an-update-from-play... reply bravetraveler 1 minute agoparentThey used this exact phrasing a year ago, lmao. Building rapport, The CEO has a name. Hi Drew. https://blog.dropbox.com/topics/company/a-message-from-drew reply hn_throwaway_99 1 hour agoparentprevI always think it's a bit weird how people put so much effort and angst into (over)analyzing the language that execs use in layoff announcements in the first place. It's a layoff. Yeah, it sucks, and no matter what the CEO says people will be pissed. Better to just take the same good advice as when starting a new relationship: \"Just ignore everything they say, and only consider what they do.\" I.e. is the severance package good? Are folks given some assistance/recommendations finding new jobs? If so, I couldn't care less about what the preamble in the layoff announcement looks like. reply switch007 28 minutes agoparentprevNailed it. We got \"An update on...\" when they cancelled our Christmas parties. reply carabiner 2 hours agoparentprevThis guy takes \"full responsibility,\" even. reply geodel 1 hour agoparentprevIndeed. \"An update..\" is a trend in lot of enterprises nowadays, probably taking cue from SV companies. reply jordanb 1 hour agoparentprev\"A difficult decision\" reply elric 4 hours agoprevI'm always a bit confused by profitable companies with (presumably) large reserves laying off lots of people. I get that they want to remain profitable. But sure 500ish people could be put to some use? A new product, a new market, a spinoff. Whatever? Are you telling me that no one in such a big, wealthy company of clever engineers has any use for a bunch of talented people? reply hn_throwaway_99 1 hour agoparentInterestingly enough, I once worked at a company that saw how huge amounts of money could be made taking the exact opposite approach. This all came about because this company had built a couple of hugely successful, and profitable, enterprise software products. So this company then decided to plow a ton of money into building out other products. The company was also pretty famous for having a high employee bar, and their college recruiting process was kind of legendary for attracting top CS and other tech grads. However, this company discovered that building follow on successful products, even with lots of really smart people, is extremely difficult. As a not-perfect analogy, think of all the \"one hit wonders\" out there in the music industry. Beyond those one hit wonders, the vast majority of the rest are basically two hit wonders. Point being, once you've built a really successful product, even if you have tons of smart people, there is no guarantee that plowing money into another product will give you a positive ROI. So this company realized this, and then saw there were a lot of other small-to-midsize software companies who were similar: they had one or two really successful products, but then were trying to use money from that to expand and grow into other areas, usually with little or no success. So this original company pivoted their business model: they went out to buy these \"one hit wonder\" software companies, immediately stopped any investment into other products, laid off as many people as possible and outsourced the operations and maintenance of the few successful products to low-cost locales (at the time, India and China) and then essentially just milked the subscription revenue until the product slowly petered out. That is, they weren't really investing in big new features in the product, but the product had a lot of existing customers who didn't (or couldn't) move off of it right away, so often they had at least a couple years of milking the existing revenue dry. I called it \"the world's most successful and depressing business model\". My overall point in telling this story is that when you ask \"Are you telling me that no one in such a big, wealthy company of clever engineers has any use for a bunch of talented people?\", that often times the answer is \"Correct!\" People tend to underestimate how difficult it is to build successful products, even if you've already knocked one out of the park. reply bsimpson 1 hour agorootparent\"Killed by Google\" has a similar problem. Google has killed products that could be entire companies if they weren't attached to the Search Ads firehose. A $100 dinner could be an annual splurge if you're making minimum wage, and an arbitrary Tuesday if you have a quarter million dollar salary. Executives think the same way about revenue streams. When they have one product that makes $$$$$ in revenue, they think \"not worth my time\" to consider another that makes $$. Really frustrating for the people making and using the lower revenue product, but it's why Google feels like a \"billion users or bust\" company. reply Seattle3503 24 minutes agorootparentprevMy guess is Oracle. reply sgerenser 1 hour agorootparentprevWas the company Computer Associates (now part of the Broadcom conglomerate)? Sounds exactly like their playbook. reply ericmcer 3 hours agoparentprevIt always seemed common sense to me that once a piece of software became stable and profitable you would need a much smaller engineering staff than when it was being built. The opposite seems to happens and orgs 10X their engineer headcount once they start making money. It makes sense to keep some high performers and a few redundancies to stabilize/modernize it and make small improvements, but it feels like tech got really bloated with these massive corps who were trying to burn as much as they could to keep all the VC money flowing. Take like Uber having a team that built and maintained a chat app just for internal use, and every single big org having a bunch of teams responsible for various \"some_dumb_name\" that is the \"custom X for 'Y'\" where smaller teams just use the OS solutions to those problems. reply crazygringo 2 hours agorootparent> once a piece of software became stable and profitable you would need a much smaller engineering staff than when it was being built This is not generally the case, except in monopoly situations. Your software product generally has a competitor, and they're busy trying to make theirs better than yours -- whether with more features, better integrations, whatever it is. So your staff size generally stays about the same in order to build more features desired by customers to prevent customers from switching to your competitor and you go out of business. And certain features, by themselves, can be more complex than the entire v1 of a product. And/or involve massive refactoring, etc. The companies that get to reduce their team size are often because they're in a monopoly position, and then customers suffer because the software gets stagnant and the features they need don't get built. That's capitalism failing. Also, something like an internal chat app isn't always a bad decision. If your company is above a certain size headcount, it can literally be cheaper to build small tools than to license them. Especially when you can more deeply customize and integrate them, which you often simply can't with off-the-shelf software. reply randomdata 1 hour agorootparent> Your software product generally has a competitor, and they're busy trying to make theirs better than yours Unless you are selling a commodity. There is a good case to be made that what Dropbox sells is a commodity. > That's capitalism failing. That's government failing. 1. You can't dig the moats necessary to establish a monopoly without regulation to support it. 2. If/when the government screws up, the onus is on it to fix the problem before the situation gets out of hand. reply smileson2 50 minutes agorootparentprevFor real, at some point running development and product teams cracking on features for no reason is a real negative software can generally be 'done' in the same way building a skyscraper can be reply ac29 2 hours agoparentprev> I'm always a bit confused by profitable companies with (presumably) large reserves laying off lots of people. According to their financial statement, Dropbox has more liabilities than assets. So yes, they have a large cash reserve, but with an even larger debt offsetting it its hard to argue they are in a good overall financial position. reply ilamont 1 hour agoparentprev> A new product, a new market, a spinoff. Five or 10 years ago, they were doing a lot of this. Dropbox Paper (\"a collaborative online workspace that allows you to create, share, and edit documents and notes with your team\") for one. It's still active but it never took off. I was just notified that there is some sort of migration taking place which is probably related to the RIF. reply bsimpson 1 hour agorootparentThey also bought that indie email app that was a peer of Inbox. Neither exists anymore. reply RivieraKid 4 hours agoparentprevThose employees were costing more than the value they were creating. If the marginal product of labor is lower than the marginal cost of labor, the company should reduce headcount. If higher, the company should increase headcount. reply vundercind 54 minutes agorootparentThat is the current orthodoxy, yes. Whether in the long term this is net-beneficial for a given actor in the typical case, is at best unclear. This marginal-labor-cost/benefit-in-a-given-moment accounting misses a large proportion of the harmful effects of a layoff. When a bunch of companies in one sector do it, it does lower wages and reduce labor power to e.g. demand better working conditions. That part, is a benefit for companies. But it's not the result of one company doing what's best for their particular situation—it's a result of coordination, even if only by the understanding that \"this is what you do, when there's an excuse to, and especially when you see others doing it\". It's merely best practice then, not... collusion. reply hmmm-i-wonder 3 hours agorootparentprevArguably the value they were creating was influenced by the direction and application that labor was directed at. Redirecting that available labor at something more valuable would fix that as well wouldn't it? reply beezlebroxxxxxx 2 hours agorootparent> direction and application that labor was directed at That would require leadership to take a hard look at the value they bring to the table as well. It's a lot easier to just lay people off than do that though, conveniently. reply MrHamburger 4 hours agoparentprevIt is basically showing that company is out of ideas, so only thing which they mange to do now is bean counting. reply jayd16 2 hours agoparentprevWhat's the alternative? Busy work and shrinking equity value until things turn around or I get a much more abrupt layoff? I think I prefer the severance, the full disclosure, the opportunity to find another job and the possibility to keep teams together at a new thing. reply nitwit005 1 hour agoparentprevI had a product manager at Salesforce tell me he went around trying to build support for a new reporting product. He was eventually taken aside by some coworker and told they don't build new products at Salesforce, and bought companies instead. And they did indeed later buy multiple companies, including Tableau, in that space. reply beezlebroxxxxxx 2 hours agoparentprev> But sure 500ish people could be put to some use? A new product, a new market, a spinoff. Whatever? Are you telling me that no one in such a big, wealthy company of clever engineers has any use for a bunch of talented people? I think a lot of the low hanging fruit in tech has been eaten up, bought up and consolidated, or actually was recognized as much more difficult and expensive than they actually thought. The leadership talent and vision in a lot of these companies is also painfully lacking. In short, to answer your last question: probably not. And I think they're terrified that Wall Street is going to notice. reply aylmao 2 hours agorootparentI agree with both comments. ~500 can surely build some amazing tech, smaller teams have done more. I personally do think there's still a lot of relatively low-hanging fruit left, especially with the boom of possibilities due to AI, or simply what one can do with modern CPU/GPU performance, new browser APIs, modern tech factors, etc. I also do agree and think leadership talent and vision in a lot tech companies is painfully lacking. This are the companies that could burn some money and use their wedge in the market to build some really cool things, but they wont. I guess to some degree, ironically, the money they're making might be part of the problem. reply anon291 2 hours agoparentprevThe company could put them to some use, or they could get capital and launch their own ventures. It's equivalent from a market perspective, except the one you suggest requires unnecessary coercion (forcing the employees to work on something they may not have signed up for). At the end of the day, the american market place is distinguished in that venture capital, especially in tech, is very accessible. Being laid off seems to be a bonus in the hunt for VC money. It's the same reason companies return dividends. Sure, they could use the money for R&D and launching a new product, or they could send the money to investors so that they can scour the marketplace for a new technology of their own choosing for investment. The first one unnecessarily takes investor money for a project they may not have signed up for, whereas the former maximizes their freedom to invest in what they find interesting reply Hilift 2 hours agoparentprevRemember Better, the mortgage company? They were briefly notable for laying off 900 people on a Zoom call. However, no-one asked why a re-envisioned mortgage application/process was failing in the best possible market. My opinion is Dropbox most valuable commodity is the millions of Windows PCs with a system level scheduled task that is vulnerable to \"hijacking\"... basically they are a data stream. reply kshahkshah 2 hours agorootparentIt was not failing in the best possible market. Better was a successful lender for mortgage refinancing. Better struggled to establish itself within the purchase market which has far more complex relationships. reply sgerenser 1 hour agorootparentAnd once 30-year mortgage rates got to 5% or higher, the refinancing market basically dried up. Without much of a purchase mortgage business they basically had no business, regardless of how much better their technology was. reply dylan604 4 hours agoparentprevBut which people: the sales/marketing, the developers that actually make the product, across the board? At some point, development gets to a stable and solid product, so revenue increases come from staffing up sales/marketing. So does that mean you can reduce the devs to try and increase new users or that you've overstaffed the sales/marketing? Maybe there's just too damn many middle managers? Will the cutting be a surgical blade or a broad axe? reply slightwinder 2 hours agoparentprevEvery new product or market usually also needs additional investments, maybe even new workers with relevant domain knowledge. And Dropbox did try new products and markets, but what if it's not working out? Should they continue until money runs out? And some interesting part of this announcement is the mentioning of the grown overcomplex management. This kinda smells of some shrinking for health-benefits. For some reason or another, they grew into a wrong direction, and maybe now remove the unhealthy parts to be able to operate better. reply marcosdumay 39 minutes agoparentprevIt absolutely says a company is done innovating, and shouldn't expect any large growth from now on. And somehow, the P/E of its stock almost always increases... Forcing it to double down on growth, that it can't do anymore. Corporation governance is broken nowadays. reply ramraj07 4 hours agoparentprevOften they target the lowest performers for such layoff. Of course they rarely succeed in doing that, but the idea is that these people should have been let go anyway but weren’t for various reasons. reply beezlebroxxxxxx 2 hours agorootparent> Often they target the lowest performers for such layoff. In my experience, this is often an after-the-fact rationalization by people who \"survive\" layoffs to explain them, and a convenient justification by leadership for layoffs. If you've ever been in the room when layoffs are planned or discussed, the actual process is way more focused on blunt cost, personality of the people involved or on the chopping block, and is often practically a tossup considering \"performance\" is not really a clear or meaningful metric (actually, more often it's arbitrary for most companies --- they will find the metric they need to justify laying off someone). This phenomenon is greater the bigger the company and the more abstracted managers and leadership are from their lower level employees. reply sgerenser 1 hour agorootparentIn many cases it can actually be inversely proportional to performance, since the one factor they can count in black and white is how much the person costs. Laying off someone making a TC of $500K probably feels like you're saving the company a lot of money, but its also possible the reason they were making that much is because they were more than twice as productive/valuable as the person making $250K. But salary and benefits are easy to quantify, and performance is not. reply _whiteCaps_ 4 hours agorootparentprevThat hasn't been my experience. I usually see the senior people with higher salaries being laid off. At one company I worked at, a whole division got laid off because the director didn't like the manager of said division. reply Ray20 1 hour agoparentprev>bunch of talented people Very bold assumption reply jamil7 4 hours agoparentprevIt might be 500 middle managers which you can't do much with. reply siliconc0w 4 hours agoparentprevI'm a libertarian in most things but I still don't like layoffs from profitable companies. Like it's probably not good for our society that people have to up end their life every few years and probably move to find a new job. Both my parents stayed in the same job for their careers and it meant they could stay in the same place, have kids, build ties to the community, etc. Seems important if you want to not die out as a society. reply randomdata 2 hours agorootparent> Like it's probably not good for our society that people have to up end their life every few years and probably move to find a new job. The thing is, Dropbox is done (as in feature complete). Like when the construction of a building completes, many people are \"laid off\" because they aren’t needed anymore. Yeah, you need to keep some people around for things like maintaining the building, but not to the scale of the original workforce required to build it. It is \"good\" that the excess labour is freed up to go work on the next \"building\". What may not be good is that the workers didn't think to associate with each other like construction workers do. Construction, being a much more mature industry, typically keeps a clear separation between the workers and the building so that then construction is done the entire excess group of people can be lifted on to the next project instead of all going their separate ways. Software will undoubtedly go that way eventually. But it is, in the grand scheme of things, still early days for it as an industry. We haven't yet learned the lessons that older industries have. reply whilenot-dev 9 minutes agorootparentSoftware engineering, as profession, offers a very different kind of capacity compared to professions found in the construction industry, though. The physical resources for buildings are expensive and rare (land, material etc), whereas compute and storage are literally getting cheaper by the minute. The Silicon Valley dream of getting from garage to unicorn within months might be far from realistic, but still way more probable that in any other industry. Quick prototypes can be built in days and it isn't uncommon for graduates to finish their research with a viable business idea. I never seen that in my circle of architecture friends. reply steveBK123 3 hours agorootparentprev> Both my parents stayed in the same job for their careers My father was the same, BUT.. this is an INCREDIBLY risky thing to do career-wise in the modern era. Given how much tech advances and that we actually face international competition that a lot of our boomer parents didn't during their career, I don't see really any going back either. Some of the worst layoff situations I've seen were guys who worked in the same company for 25 years.. long enough that their knowledge & skills was too company-specific, but not long enough to retire. Just because someone seems indispensable doesn't mean they are safe. Having to drain savings for 1-2 years jobless after a layoff in the last 10 years of your career and reset at a probably lower salary can set back your retirement 10 years. reply asah 2 hours agorootparentprevAs one friend put it, he \"works for Silicon Valley Inc,division.\" reply alluro2 2 hours agorootparentprevFully agreed - yet, we as a society consistently and systematically trade (or let \"others\" trade) much more critical aspects of life, such as quality of air, water, food etc. for short-term profits, even though that very often has no clear/direct positive impact on any other comparably valuable aspects of our lives. So it's no wonder that \"some people losing their jobs and needing to move for a new one\" is irrelevant, when the only goal is profit maximisation, even though we don't even understand what for. reply crabbone 3 hours agoparentprevWhy not? Some companies do try this. It rarely succeeds though. The reason is that re-education en-masse, restructuring of the chain of command, re-allocation of resources are hard. Most businesses at some point enter the phase where the inertia is the strongest driving force: they only need to apply a tiny fraction of initial force to keep the lights on. At this point, trying to restructure is bound to be very hard. Maybe, if the company can foresee and realistically assess the problems it's about to face, it may gradually prepare for the transition. I've seen this happen at my friend's job at Dell storage division: some storage product failed, they tried to reshuffle the teams to start working on something else, with some code reuse from the previous one. It still didn't go well, and a lot of people were still let go (because the initial effort of developing a new product cannot really accommodate an army of various kinds of extra personal that's necessary for mature product). They sort-of survived, but with a huge loss. reply mrthrowaway999 1 hour agoprevI'm sad to see so much venom in these comments. HN of old would have tried to delve into the details and find something to learn from this. reply hn_throwaway_99 1 hour agoparentThis literally happens every single time there is a big layoff announcement on HN; at this point it's completely predictable. People love these stories as a place to vent (not that I necessarily blame them), but I do find that these kind of stories always attract the lowest quality comments. E.g. \"Why hasn't the CEO committed harakiri!\" Which is always a bit sad to me because I think the biggest mistake (especially in highly paid industries) is to think that a layoff is the end of the world and the absolute worse possible thing that can happen to someone. reply John_Cena 32 minutes agorootparentAhem The CEO's breath smelled of genitals reply staunton 1 hour agoparentprevLet's keep trying. What learning opportunities do you see in the details here? reply mrthrowaway999 1 hour agorootparentJust off the top of my head: every engineer should have 6+ months of savings. Market isn't great but our salaries can help build those savings easy. If I had more time, I would love to understand the fss market better and also what impact ai is having there. I don't see a Q3 earnings report from Dropbox, but as others have pointed out in other comments, Dropbox seems to have been doing fine financially. reply alephnerd 22 minutes agorootparent> Dropbox seems to have been doing fine financially Not really. The issue is Dropbox's core product is heavily commodified (Cloud File Store for Enterprise and Consumers). Dropbox's EBIDTA is much lower than peers in the Software industry making it a much less attractive investment - even public companies need to attract investment. Furthermore, Dropbox has missed out on multiple trends that it had the right ingredients to execute on, such as DLP, DSPM, AI Search, AI-leveraged Business Tooling, etc. It's not that Dropbox didn't try building these teams - they did and I know plenty of people who were hired to work or lead these initiatives - but tech is competitive and they got outcompeted. At some point they have to initiate layoffs in order to retool internally and concentrate on the BUs that actually generate outsized revenue along with strategic bets that can help make Dropbox more enticing. > every engineer should have 6+ months of savings. Market isn't great but our salaries can help build those savings easy Pretty much. Layoffs have always a thing in the tech industry. And compared to previous cycles (early 2000s, 2008-2013), the current job market is fairly standard for mid-career. I think this tech downturn is just the first one that a lot of 2011-22 grads went through and it makes them feel like it's the end of the world. Keep saving, keep upskilling, and keep networking - these are what save you when we all (inevitably) get laid off. reply ilrwbwrkhv 1 hour agoparentprevI think the real learning here is that the company is still around even though they are sort of not in the popular zeitgeist at all anymore and there are so many other tools that does what they do. reply ozim 1 hour agorootparentIt is still around even if as a Linux user I can get ftp server and mount it locally then use CVS or SVN … ;) reply kraig911 4 hours agoprevDropbox my one critique is can you please make it affordable again. I just can't justify the cost as there are cheaper services out there. I don't care about PDF signing etc. I fear OneDrive/Google Drive are eating you lunch because it's a hard sell to be competitive against them price wise. reply bigstrat2003 3 hours agoparentI left Dropbox when they added (and preemptively enabled) a checkbox that shared your data with them for AI training. I refuse to do business with a company that will just unilaterally invade my privacy like that. They can make it as cheap as they want, I'll never go back. reply jjnoakes 45 minutes agorootparentCitation please, about Dropbox training models with customer data? reply lotsofpulp 2 hours agorootparentprevSelling data is always the last play for all businesses that have data. Either you never give it to them in a way that can be sold (e.g. fully encrypted), or you expect them to sell it when the leaders need to increase cash flow. reply NKosmatos 4 hours agoparentprevExactly!!! I stopped being a customer when they lost touch with their customer base. They decided to become something else, adjust plans however they thought, introduced useless featured and all these while riding the money train. I feel sorry for those being laid off, it’s not immediately/directly their fault. It’s the management and the product responsible that should take the blame. reply sk11001 3 hours agoparentprevSteve Jobs was right - Dropbox is a feature, not a product. reply onion2k 2 hours agorootparentA feature of what? Surely Jobs didn't expect a feature of Windows, OSX, Android, Linux, and ChromeOS to all seamlessly interact with one another. I don't doubt that Jobs might have seen Dropbox as a feature that Apple could have implemented across the Apple ecosystem, but that's a pretty limited view of where the value of Dropbox lies. reply ghusto 1 hour agorootparentprevIt's a product that I was willing to pay for (until I required native E2E encryption). _iCloud Drive_ is a feature, mostly — aside from the fact that you still have to pay for it to be useful, so kind of still a product. Steve Jobs was wrong about many things, and this was one of them. reply karaterobot 3 hours agorootparentprevIt's been a product for 17 years. reply JAlexoid 2 hours agorootparentNot when your competition are consumer companies like Google, Microsoft and Apple. I'm on Google One at $100 per year, getting more services than Dropbox can offer with their $120 plan. Maybe they have a future in enterprise sales, but they are outcompeted even by Zoho in consumer space reply karaterobot 2 hours agorootparentI'm responding to the person who quoted Steve Jobs by saying Dropbox isn't a product, it's a feature. 17 years is a really long time on the web, and Dropbox has not only been a product, but a successful publicly traded company for most of that time, during which so many other \"real\" products have risen and fallen. The fact that you subscribe to Google One doesn't tell me anything, except that Google created a product to compete with Dropbox, which is also a product. reply Destiner 3 hours agoparentprevyou're not a target customer anymore. they need $$$ from enterprise, everything else is a distraction. reply HEmanZ 3 hours agoparentprevOneDrive/Google can afford to take a loss on you, they are effectively selling you storage at a loss. Dropbox can not do this. reply mock-possum 1 hour agoparentprevI stopped using them when they refused to work with valid windows paths - to wit, files and folders with emoji in their names. Now I pay for google drive instead. reply talldayo 2 hours agoparentprevFunny how Hacker News spent the past 15 years laughing at anyone questioning the viability of Dropbox as a business, but then after two years in a down market half the site is begging them to be cheap again. What's the matter? You like the sound of that crusty, slow Linux NAS that this site has derided for years? reply hankman86 2 hours agoprevThe uncomfortable truth is that pretty much any business can cut staff by 20% without impacting overall performance. Provided that you manage to weed out the tail end of the performance bell curve that is. Most of the time, reducing staff is a healthy move for the business and the impacted employees. The company will not only save cost, but strengthen its culture of high performance. And under-achieving employees are often fundamentally unhappy in their role. While the short term impact of being made redundant can cause some distress, these people can still use the occasion to reset their careers. So all in all, no reason for grief. reply whatshisface 1 hour agoparentThey don't know which 20% needs to be cut. That's why they wait until something unrelated to their business internals (market downturn, other companies are cutting) happens to try. reply jordanb 1 hour agorootparentI remember seeing somewhere an analysis that layoffs do not improve medium or long-term stock performance for companies performing layoffs. But if layoffs are coordinated sector-wide they can have a big impact on employee compensation in the sector by creating a reserve army of unemployed. reply whatshisface 1 hour agorootparentYes, it's justified on the same economic basis as pricefixing, and unionization with coordinated strikes if you interchange the parties. reply rsanek 21 minutes agoparentprevKeep in mind that knowledge work isn't really a bell curve, it's more of a power law. https://www.hermanaguinis.com/pdf/PPsych2012.pdf reply VirusNewbie 41 minutes agoparentprevI was originally a huge fan of dropbox, and still a customer, though reluctantly these days. Dropbox has fallen so far behind many other companies. Google photos search is amazing, it merges people even if they don't have contacts, it has really good image recognition, it has some sorting/ordering amongst many various dimensions. Why can't I make small edits to text files in dropbox? Why haven't they added any useful apps? Why are they not the best photo organizer/searching system? reply adamc 1 hour agoparentprevEvidence, please. From what I've seen in person, it doesn't work this way at all. Companies don't have a great fix on whom to cut, and it usually just makes the other employees feel stressed (and start looking at other jobs), while the unemployed suffer very significant life stress. reply formerlurker 2 hours agoparentprevSo, reduce people to numbers and accept the suicides? reply hn_throwaway_99 1 hour agorootparentPerhaps the better lesson is that tying your self-worth to your corporate employment is a really, really bad idea. I realize that's difficult in today's performative world, where an quick perusal of LinkedIn shows loads of people that are \"passionate\" about banking compliance or insurance claims or whatever. Many companies have also have fostered this false idea that companies are a \"family\". That is always false. The best companies are more like a team, and when things start to go south, sometimes people on that team are cut. Ironically, I think the professions where people really are passionate and see it as a \"dream job\" (think professional sports teams, actors, musicians, artists, etc.) generally have a much healthier view of their employment in the first place because they realize how tenuous it is to begin with. Point being, if you're considering suicide if you lose your job, you should be in therapy long, long before it gets to that point. One final note: before I get the pushback of \"that's all nice to say until you have no income and are living on the streets!\", let's get real for a moment. First, I have a ton of sympathy for people who are laid off - it sucks and can be very destabilizing. But lets also get real - people were laid off from Dropbox with a very generous severance package and they are in a highly paid industry to begin with. None of these people are going to starve, and nearly all of them will be able to eventually find employment (if perhaps not at the same exact high salary as Dropbox). Any mental health issues folks have after getting laid off is nearly always the result of tying one's self-worth to one's job, and that's the link that should be broken. reply tqi 3 hours agoprevTBH it feels like Dropbox has a pretty fair earnings multiple at the moment (~4X). Have we reached a point where tech companies have been around long enough that they can / should enter a sort of maintenance mode? It feels like there is a company version of the Peter Principle. Why do they (Dropbox specifically) need to continue to \"innovate\"? Wouldn't it be better for all parties if they just focused on maintaining the best possible version of their core offering at the lowest cost? Maybe Dash (or whatever) will work but most likely it won't, and investing in that initiative puts their whole business at risk. reply dsnr 3 hours agoparent> enter a sort of maintenance mode There exists such a mode: it's called dividend distribution. But currently DBX and many other tech companies aren't paying any dividends to stock holders. So if it's not growing and not paying dividends, what is the company doing? reply bravetraveler 2 hours agorootparentProviding goods/services. Perhaps the qualifier \"being publicly traded\" will help reply bink 39 minutes agorootparentI think the question is more for investors. If the company isn't growing and isn't paying a dividend, why would I buy shares? reply bravetraveler 35 minutes agorootparentI bring attention the qualifier; if it's not performing and likely won't be, why is it traded? A company that is relatively stable and holds no grand world-domination-to-feed-shareholder plans is still nice reply jordanb 3 hours agoparentprevAlternately we have entered a phase where layoffs have metastasized as a thing to do so much that executives are being asked about it. \"We've noticed you haven't done any layoffs yet, can you explain that?\" reply alephnerd 2 hours agoparentprev> pretty fair earnings multiple at the moment (~4X). Dropbox's EBIDTA is 14.67, but most Software Companies tend to have an EBIDTA of 28. Dropbox is significantly underperforming compared to their peers. Furthermore, cloud file storage has become commodified and Dropbox missed the DLP, DSPM, and AI Search train. > Have we reached a point where tech companies have been around long enough that they can / should enter a sort of maintenance mode Absolutely not. If you do not innovate as a software company, you risk becoming commodified. And if BUs within a company fails to execute on their innovation or GTM strategy, they will be let go. reply absoluteunit1 5 hours agoprevThe severance package is great! I don’t think I would be upset (unless I was extremely passionate about a project I was working on) reply yellow_lead 4 hours agoparentI dunno. It may take 1-2 months to prepare for Leetcode style interviews, and this can be pretty mentally exhausting. Every time you fail to solve a leetcode question, it feeds your imposter syndrome, which is probably even worse due to getting fired. reply bigstrat2003 3 hours agorootparentWith all due respect, that sounds like a personal shortcoming to me. One can (and should) not take interviews personally. One also can (and should) be able to acquit oneself well at an interview even without prep time. reply yellow_lead 2 hours agorootparent> One also can (and should) be able to acquit oneself well at an interview even without prep time. I don't agree. If you don't prepare at all for an interview, it shows. Aside from leetcode, it's also important to research the company. My point is mainly that I might be upset if I were in that group that's laid off today. I don't want to prep leetcode for several weeks. It feels like a waste of time. reply rsanek 15 minutes agorootparentprevYou're telling me you maintain the ability to pass the various interviews that the modern FAANG SWE gauntlet requires year-round? Good for you if so, but this doesn't match the experience of any of the folks that I've worked with across my career. reply FredPret 4 hours agorootparentprevIf leetcode wasn't hard enough to make a good programmer fail now and then, there would be no point to it. reply neilv 2 hours agorootparentIf Leetcode didn't provide discrimination defense and neg the candidate shortly before offer, there would be no point to it. reply gwbas1c 2 hours agorootparentprev16 weeks + 1 week / year severance works out to 3-5 months. Looks like enough time to prepare, take a vacation, ect. reply pembrook 3 hours agorootparentprevWow, that's horrible. And you might even have to stay at a 4 star instead of a 5 star resort in Bali when you take a vacation during your severance, job market is tough. Even worse, you might have to miss one contribution to your FATfire investment account to deal with the extra risk. Compounded, that missed contribution might mean you'll have to retire at 46 instead of 45. How dare these companies treat these people this way. They took the massive risk of working for an already-successful company at $250K/yr with a $200K stock package, and now fat cat Drew Houston dares to leave them with just an abnormally large severance after they are no longer needed. reply iaw 3 hours agorootparentI don't think your tone aligns with the community guidelines[1]. Please consider not being snarky and sarcastic but actually responding to the merit of what people say here. [1] https://news.ycombinator.com/newsguidelines.html reply pembrook 2 hours agorootparentAs a fellow tech worker, I genuinely believe all the things I mentioned are upsetting. It's happened to me before! I realized though that I was probably going to be okay, and what I actually needed was some perspective. Sometimes the contrast of \"sarcasm\" is the only way to shake you out of your bubble and give you that perspective. reply VirusNewbie 39 minutes agorootparentSarcasm is bad. It would have been fine to say \"I think there is a social contract of it being acceptable to lay off workers making 400k\". reply harimau777 4 hours agoparentprevConsidering how horrible the job market is right now, four months of pay may not go very far. reply BossingAround 4 hours agoparentprevReally? 16 weeks of salary, or 4 months of pay. In my country, you get 3 months of pay as standard when you're fired from your job. Doesn't seem that great to me to be honest. reply nsxwolf 4 hours agorootparentIn the US, the minimum required is usually zero. The most I ever got was 4 weeks. reply lesuorac 2 hours agorootparentThe minimum needed in the US for this situation is 60 calendar days [1]. Hence the 16 weeks. https://en.wikipedia.org/wiki/Worker_Adjustment_and_Retraini... reply nsxwolf 22 minutes agorootparentThe WARN Act doesn't mandate severance payments AFAIK. reply rsanek 13 minutes agorootparentI think perhaps that's why poster used \"for this situation\" -- if a company doesn't want to have to provide advance notice, their only option with WARN is to do it with this kind of severance payment. Not sure if it was intended but that's a pretty cool outcome of the law. reply opjjf 3 hours agorootparentprevDo you earn SF salaries in your country? reply cbzbc 2 hours agorootparentThey probably don't have SF housing costs in their country. reply ramraj07 4 hours agorootparentprevUS salaries are quite a lot more; lifestyle creep is a thing but at least for developers they get paid a lot more than the average worker in the US than say in the Europe. Factoring that, 4 months is amazing. reply Epa095 4 hours agorootparentprevBut are you not expected to work those 3 months? 4 months of pay without work is decent, but not amazing. reply prmoustache 2 hours agorootparent> But are you not expected to work those 3 months? When you are leaving on your own term yes. When you are laid off you are technically still an employee for those 3 months but nowadays many companies will just tell you to not show up for security reason. reply ahstilde 4 hours agorootparentprevIt sounds like it's 25% better than what you get in your country? reply BossingAround 4 hours agorootparentPersonally, I'd consider this nothing to write home about. It's OK. Not great, not terrible. If we're laying off 20% of the company, I'd expect the package to be somewhere in the 6-12 months range. To me, that would seem more fair, considering they are completely restructuring the whole company. reply pembrook 2 hours agorootparentI'd rather take having a tech industry at all and the 2-4X bigger US salaries (and 30% lower average taxes) than having my fellow citizens shoulder the burden of giving me 6-12 months of daycare. In the US luckily the job market is still quite dynamic (and extremely tight by historical standards) so only in an extreme scenario would someone with Dropbox on their resume need 12 months to find another job. They might have to take a pay cut from a 99th percentile salary to a 96th percentile salary though. Rough, I know. reply geodel 3 hours agorootparentprevYeah, nothing to write home about until they pay inflation adjust salary till retirement age of 67 for all laid off employees. reply klausa 4 hours agorootparentprev“25% better than legally required minimum” is not generally considered “great” in many circumstances. reply nsxwolf 4 hours agorootparentComparison is the thief of joy. In the US, any amount is... infinity %? Undefined %? better than the legally required minimum of 0. reply triceratops 4 hours agorootparentprev33% reply aprilthird2021 4 hours agorootparentprevIn big tech in the US, 4 months is usually enough to find another similar job in the industry. Also in the US for mass layoffs at big firms, the minimum is effectively 2 months because you are required by law to give 2 months notice to workers about such layoffs, 2 months severance is a way to not have to give such notice. reply harimau777 4 hours agorootparentIn this market, 4 months definitely isn't enough to find a similar job. reply gcr 4 hours agoparentprevThis is a bullshit package because of the healthcare. I was laid off from a different company with access to 18 months of COBRA. Dropbox is offering a third of that. Lots of job searches take longer than 6 months, so the employees are going to be left high and dry right when they need it the most. For the non-Americans, my COBRA expenses are about USD$2,000/month for me and my partner. I’m paying as much for healthcare as I am for rent. Even so, it’s still financially better to take COBRA than pay out of pocket for my prescriptions. reply sct202 3 hours agorootparentI wonder if they meant paid COBRA of 6 months, bc 18 months is like the minimum to offer continuing coverage. COBRA coverage is a Federal Law for large employers. https://www.dol.gov/sites/dolgov/files/ebsa/about-ebsa/our-a... \"Q11: How long does COBRA coverage last? COBRA requires that continuation coverage extend from the date of the qualifying event for a limited period of 18 or 36 months. The length of time depends on the type of qualifying event that gave rise to the COBRA rights. A plan, however, may provide longer periods of coverage beyond the maximum period required by law.\" reply erikw 4 hours agorootparentprevAll West Coast states have free healthcare (medicaid) available if your income is below a certain threshold. And there is no time limit on that. It won’t help with rent, but at least these folks won’t be completely without healthcare access. reply vel0city 3 hours agorootparentThere's pretty much no way they'd qualify for Medicaid if they were a dev at Dropbox. The income limit for Medi-Cal is $20,783 for a single adult, $28,208 for a household of two adults. Chances are they were past that income limit the first few months of the year. You don't just immediately qualify after making $140k annualized for the first 10 months and then hit $0 one day. Plus, they're getting 16 weeks of salary. At $140k/yr, that's $2,692/wk. Lets say their severance starts next week. There's 8 weeks left in the year. So they'll get 8 weeks of pay in 2025. $2,692 * 8 = $21,538. So no, they won't qualify for Medicaid at all in 2025 if they make that much as a single person. reply cruffle_duffle 1 hour agorootparentTrue but even making $140k/year does qualify you for tax credits on ACA marketplace health insurance plans. COBRA is kind of obsolete, honestly. You should be switching over to a insurance plan purchased through your state's health insurance marketplace. reply vel0city 56 minutes agorootparentTotally agree there. Chances are they'll be better served with a marketplace plan unless they've got a complicated health situation/very specific care that might be questionablly covered without thoroughly shopping around. I'm just pushing back at the idea someone can go from making six figures and turn around and hop on Medicaid. It's not that simple. It should be IMO, but it isn't. reply skwee357 5 hours agoprevBeing sorry - check Takes full responsibility - check Layoffs are still there reply my_berner 2 hours agoparentI think we'd all collectively blow our minds if a CEO said \"I take full responsibility for the bad decisions and overhiring, so I'm resigning\" reply FirmwareBurner 43 minutes agorootparentWould the CEO resigning or getting laid off, make your situation any better if you were one of those laid off? Feels like a weird hill to die on, and more like a crabs in the bucket mentality that doesn't change anything in the grand scheme of things. In the end I'm still unemployed and whatever happens to my ex-CEO doesn't change my situation one bit. As I grew older and experienced my share of layoffs, I stopped caring about what happens to those responsible for me getting laid off, as my energy is better spent on improving my situation and my life instead of ruminating how Krama vengeance would make me feel better. reply smetj 1 minute agorootparent> Would the CEO resigning or getting laid off, make your situation any better if you were one of those laid off? No, of course not. But he is the leader, and he guided the company to a point where certain areas became \"over-invested or under-performing.\" In other words, he didn’t do a good job. So, it should be him stepping down. Nobody ever said being a CEO would be easy. reply TomK32 4 hours agoparentprevAvoided the \"20% more space at Dropbox\" headline - check reply layer8 1 hour agorootparentI was hoping for a 20% price reduction. reply Clent 5 hours agoparentprevClaims to take full responsibility but since he has not resigned he has not taken any responsibility he has just said the words. reply SoftTalker 2 hours agorootparentThat's not what it means. As CEO, it's his responsibility to make/approve the decision to do the layoffs, or not. The buck stops with him. That's all that it means. It doesn't mean he's liable for any hardships. reply s1artibartfast 1 hour agorootparentExactly, it doesnt mean that the CEO is submitting themselves to whatever consequences internet users deem appropriate. reply yieldcrv 5 hours agoparentprevhow would you like the next CEO to handle it, for reference? reply stonemetal12 4 hours agorootparentStop saying \"take responsibility\" if they aren't actually. If you knock a girl up and you \"take responsibility\" it means you getting married. If you are in a car wreck and you \"take responsibility\" it means you are paying for repairs. If you commit a crime and \"take responsibility\" you are going to jail. So if a CEO is \"taking responsibility\" it should be something like that second case, dollars from their own pocket to the effected party. reply s1artibartfast 1 hour agorootparentHave you considered that not everyone shares your opinion and that this could explain the difference between reality and your expectations. reply YetAnotherNick 3 hours agorootparentprevGP asked what should CEO say instead. Not what should they not say. reply timeon 59 minutes agorootparentAbsence is also part of the content. reply geodel 3 hours agorootparentprevLOL, CEOs job is to keep company up and running and in good graces of wall street. And he is taking responsibility of doing that. Layoffs are terrible but acting like petulant child and lashing out at CEO won't do much. CEOs responsibilities are defined by shareholders and relevant laws applicable, not by rank and file employees. reply talldayo 2 hours agorootparent> but acting like petulant child and lashing out at CEO won't do much. I don't think anyone is attacking the CEO with the expectation that he's got his iPad in-hand, reading every comment through his tears. What we are saying is that corporate doublespeak is unbelievably fucking grating when it doesn't correlate whatsoever with tangible change at the company. This kind of repeat behavior is what makes people (justifiably) laugh when CEOs walk out onstage. Like when Tim Cook steps out on and insults us all perennially with his \"best iPhone yet\" comment. Like, duh, of-fucking-course it is! Why don't you tell me something I don't know, show me some form of change in your posture or the way you provide your products and services to me. Don't just advertise to me - convince me that you're not steering the company in a direction that sucks for everyone but the CEO. reply qwerpy 2 hours agorootparent> Tim Cook steps out on and insults us all perennially with his \"best iPhone yet\" comment I loved this sentence and the sentiment behind it. Nowadays whenever I get the urge to upgrade my old iPhone 13, I go and rewatch old recordings from 2021 of Tim Cook gushing about how the phone I already have is such a huge leap forward for humanity and why everything that came before it is garbage. Applying this to CEOs and layoffs, every time you join a new job and start to drink the company kool-aid about how you're part of this wonderful family, go and reread that CEO talking about how he took personal responsibility for throwing hundreds of his \"family\" out on the street right before the holidays. reply apwell23 2 hours agorootparentprevGP is attacking annoying bullshit language. Not the CEO. reply skwee357 5 hours agorootparentprevThese words mean nothing really. I expect the next CEO to not use meaningless phrases. How does \"taking responsibility\" works in his case? What does it even mean other than PR fluff? reply layer8 1 hour agorootparentIt means he’s saying people should be mad at him instead of at someone else. It seems to be working. reply dylan604 4 hours agorootparentprevwhy would you expect the next CEO to not use weasel words? it's like they all go to the same \"mom school\". they all go to the same tailor to make teflon suits so nothing sticks to them, and they all learn the same \"rain in spain falls on the plain\" dreck. reply foobarian 4 hours agorootparentprevI mean he's just stating what his job is. CEO is responsible by definition. He's saying \"Hey all this is my job.\" reply skwee357 4 hours agorootparentNo, responsibility is not a word. Responsibility is an action. If I'm on-call, I'm responsible to carry my laptop with me and be available immediately to fix critical issues. I don't just say \"I take responsibility of being on-call\", and the leave my laptop at home, get drunk and fall asleep in a bar for the weekend. That's called being irresponsible. reply foobarian 4 hours agorootparentI see. But that's still like doing your job. I do my job for being on-call by having my laptop with me and phone on, etc. If do my job badly I get fired. So this CEO is saying, \"if I do my job poorly I understand I could get fired.\" But, did he/she do their job poorly? That's the thing I can't figure out quite yet. It seems it was bad for the laid off people, but maybe not for Dropbox? reply glimshe 5 hours agorootparentprevIf he was responsible for the conditions that led to the layoff, he could also resign. reply empath75 4 hours agorootparentLayoffs happen even in well run companies. reply GiorgioG 4 hours agorootparentActually they don't. Well run companies have cash reserves and expect to have periods of ups and downs. They don't pray to the alter of the next quarterly report. reply yieldcrv 18 minutes agorootparent> Actually they don't then they probably should not saying I should go work for McKinsey, just noticing that unnecessary payments are likely happening. companies don't exist to employ people. employees exist to help companies. just make everyone a decent shareholder with decent liquidity and move on when the employee isn't necessary. reply ziddoap 4 hours agorootparentprevWell run companies laying off 20% of the global staff? None come to my mind, do you have any examples? reply blitzar 2 hours agorootparent> Well run companies laying off 20% of the global staff? Well run companies laying off 20% of the global staff a year after laying off 20% of the global staff? reply dylan604 4 hours agorootparentprevwell run companies do not hire more employees than they can afford reply coldpie 4 hours agorootparentprevThey should make whole those affected, as best as possible. The CEO, who is the responsible party by their own declaration, should distribute their personal wealth to those affected until all parties have approximately the same amount of wealth. reply CoolGuySteve 5 hours agorootparentprevI would like for there to be a next CEO reply jrochkind1 1 hour agorootparentprevTake a pay cut. Return last year's mega bonus. reply realusername 5 hours agorootparentprevA 20% layoff means either the market changed very very quickly or something went terribly wrong in the company strategy. Here it's the second scenario and I'd expect the CEO to be on shaky grounds after such bad results. There needs to be more explanation on where the CEO screwed up that badly and the consequences for the management. reply mrguyorama 2 hours agorootparentAt the very very least, they should be explaining how Dropbox is suddenly a 20% smaller company, because either that means the market has contracted by 20%, or Dropbox has shit the bed as a competitive entity in said market. Both options should directly imply that the CEO should earn less. Either you're running a smaller, simpler company, or you sucked at your job. Eat the loss. reply stevenAthompson 1 hour agorootparentThey aren't 20% smaller, they stopped growing. Some of those positions existed to help them continue with growth, which now isn't happening. They reached market saturation, which isn't the same thing as failing. reply randomdata 5 hours agorootparentprevBy letting a lower rung employee take the responsibly. This is giving CEOs a bad name and is only one step away from the board taking the heat. reply bravetraveler 5 hours agorootparentprevWith the resources that would otherwise be given to the excised one, is a good start reply BossingAround 5 hours agorootparentprevHow about describing what exactly taking full responsibility means for them in that particular situation? Saying e.g. what is the impact on the situation for those responsible might be nice - no bonuses for next year? A plan in place so that this doesn't happen again? Stepping down as a CEO? I mean, if I take responsibility for e.g. wrong tax filing, I pay the fine penalty, and/or go to jail. Saying \"I take responsibility\" some kind of failure while having no consequences for said failure is not taking responsibility. reply wahnfrieden 5 hours agorootparentprevConversion to worker coop reply azemetre 2 hours agoprevSomething weird I noticed about Dropbox: I cancelled my paid account two years ago. I had 5 terabytes of storage being used (mostly shitty concert vids and food pics). Everyday they email me telling me I’m over my limit. They always “threaten” to delete the data but it’s been two years since I cancelled. My Qs are: why are they hoarding my data for so long? Why would they want to do this? How cheap is storage for them to want to do this? How likely is it that they have sold my data to train various LLMs with? reply layer8 1 hour agoparentIf they delete your stuff, you almost certainly won’t resume your subscription. The cost of storage may be lower than the benefit from re-subscriptions, and possibly the cost of actually implementing and maintaining an automated deletion process in compliance with all jurisdictions. reply flappyeagle 2 hours agoparentprevYou can just delete your data dude. No one is forcing you to keep it there. They’re generally not going to do something destructive because of unpaid bills. It’s nice of them reply azemetre 1 hour agorootparentBut why do I have to log into Dropbox to do this? I haven't logged into the site in 2 years and don't plan on it. I just find it odd that they keep threatening to delete my data but from where I'm standing it looks like they will keep my data indefinitely. I'm not forcing them to do anything. I terminated my service and they're still keeping my data. Seems like shitty consumer rights that they'll just keep the data regardless of what I do. That's what I'm trying to figure out, if others have similar stories. reply s1artibartfast 1 hour agorootparent>Seems like shitty consumer rights that they'll just keep the data regardless of what I do. But they aren't keeping it regardless of what you do. You can ask them to delete it and they will. The power is in your hands and you are refusing to use it. reply tantalor 2 hours agoparentprev> sold my data Sure the license agreement would not legally permit that. I wonder what kind of legal recourse you would have. There's obviously copyright infringement, but I think state laws like CCPA include remedies for violations. reply EVa5I7bHFq9mnYK 1 hour agoparentprevMaybe they are just good people and don't like to do evil things like deleting someone's life memories? reply adamc 1 hour agorootparentThis is a company, so no. reply golly_ned 4 hours agoprevThis is a great severance plan. 1. 4 months pay + 1 week per year of tenure. 2. Receive Q4 vests. 3. Upcoming approved leaves paid in cash. 4. Year-end bonuses paid. 5. Keep company devices. reply 7thpower 3 hours agoparentIt is a great deal. The core demographic of HN has been very fortunate and does not understand what the norm across industries is. reply insane_dreamer 4 hours agoparentprevYou know what's better than a great severance plan? Keeping your job. reply onlyrealcuzzo 4 hours agorootparentNot necessarily. If you're actually good at your job, you typically end up with an even better job: https://hbr.org/2018/10/research-when-getting-fired-is-good-... reply MeetingsBrowser 3 hours agorootparentThe linked article is specific to executives and kind of confirms what most are complaining about here. > a 10-year study of over 2,600 leaders showed almost half (45%) suffered at least one major career blow-up — like getting fired, messing up a major deal, or blowing an acquisition. Despite that, 78% of these executives eventually made it to the CEO role. An executive can make a series of awful decisions and still advance in their career. reply onlyrealcuzzo 3 hours agorootparentMost employees can as well - IFF you move to different companies. reply MeetingsBrowser 1 hour agorootparentI think its tough to argue that getting laid off is a net-benefit for your career most of the time. reply John_Cena 27 minutes agorootparentprevYeah I end up with like twice the salary, but the job search is always the worst parts of my life. reply gcr 4 hours agoparentprevYou can’t be serious. This package sucks specifically because of the healthcare. Industry standard is to offer 18 months of COBRA, not 6. Job searches frequently take way longer than that. COBRA is a huge deal for departing employees. My single largest expense is health insurance for my partner and I, more so than even rent. reply vkazanov 4 hours agoprevthis is a good deal, better than most retention packages out there. But why is every ceo feels obligated to use this kind of meaningless corpo speak in these emails? \"Macro Headwinds\", \"full responsibility\"? reply rchaud 4 hours agoparentPR-speak is the same everywhere. The audience for this is Wall St, not the general public. reply dylan604 4 hours agorootparentGotta prevent panic in stockholders is the main priority of a CEO in publicly traded companies. They only concern themselves with the well being of their employees as much as how it affects the stock price. reply bhouston 4 hours agoprevIf you look at its earnings they have appeared to plateau and there isn’t a major offering planned that will change this. I am reminded of Slack which has a similar history of rapid growth followed by a very competitive market and then significant slowing. Maybe Salesforce could acquire Dropbox and bundle it into their offerings or some other similar company? reply aprilthird2021 4 hours agoparentSlack shot their own selves in the foot iirc. They were miles ahead of any competitor, employees loved it, and then they just started gouging all their whale customers in contract negotiations, to the point that they started looking elsewhere... If this isn't the full picture, let me know. I was at multiple companies trying to move away from Slack as the cost was not justifiable reply umeshunni 4 hours agorootparentWhat are they moving to, though? I can't imagine that Teams is any better. reply antonyt 3 hours agorootparentTeams and Google Chat. They're both incredibly bad compared to Slack. But if your org is on 365 or Workspace, you're already paying for them. Big orgs don't love double-paying, quality be damned. reply Spooky23 3 hours agorootparentprevTeams is close enough, especially given its cost. Slack displayed alot of hubris and didn’t pivot. Their goal should have been Microsoft or Google acquisition. reply mschuster91 4 hours agorootparentprevMS Teams was a large contributor as well to the downfall of Slack. It automates decently with the stuff most companies already have (AD, O365, and most importantly all that compliance bullshit), and nowadays it can even do landline telephony, providing enterprises with a way to reduce their exposure to Cisco crap on top of it. In the end, Microsoft is IMHO once again abusing its stronghold on the market. Just the enterprise-compliance-integration stuff is more than enough to cause any medium or large company to move off of Slack or its competitors (e.g. Mattermost). reply andyjohnson0 3 hours agoprev> \"As CEO, I take full responsibility for this decision and the circumstances that led to it, and I’m truly sorry to those impacted by this change.\" As with other CEOs who say such things in similar situations - does this \"responsibility\" amount to anything? Like loss of salary or options or seniority. Or is this just empty words? I appreciate that this action is probably necessary to safeguard the business but, as someone who has been at the sharp end of a number of redundancies, I wish leaders would be honest: \"We tried stuff but it didn't work. I was and am in charge, and I'm staying. We're making you redundant because we need the money more than we need you.\" Obviously no leader would say such a thing. But the people affected (and thas not just those being made redundant) deserve honesty, not platitudes. reply penguin_booze 3 hours agoparent\"I earn the big money because I make decisions and I take risks (with others lives, but let's not talk about that). My decisions haven't worked; my risks haven't paid off. I'm however letting you take the hit, because I'm too important for that kind of shit. I've more decisions to make, and risks to take. My family is fine; my pay is fine. It's just you who are affected.\". -- Your CEO, who still makes more money that you do (or don't), no matter what. reply matchbok 3 hours agoparentprevMost people understand that companies need to adjust in size. There’s nothing moral about it. reply andyjohnson0 2 hours agorootparent(Your comment was dead but I vouched for it because I want to explain why youve failed to appreciate an important distinction.) tldr: the redundancy is not the announcement I think people (and I include myself) do understand that companies need to adjust their workforce. I think that decision is not wholly moral in nature. But it does have a moral component - and Dropbox seems to appreciate that somewhat in the assistance they're providing the people who are leaving. But what isn't moral is an individual announcing publicly that they take responsibility for acts that cause trauma to others (however constrained that decision was) while in reality that responsibility-taking involves no consequences at all the individual. None. In the large train station in the city where I live, the automated voice announcements \"apologise\" for train cancellations. I'd argue that this is as empty and insulting as this CEO's email - because no responsibility has in fact been taken. The CEOs words and the announcement software are as morally empty as eachother. reply racl101 3 hours agoparentprevIf You Want To Tell People the Truth, You’d Better Make Them Laugh or They’ll [unalive] You -- Some famous person's quote that I paraphrased. reply 39896880 3 hours agorootparentYou’re allowed to say kill on Hackernews reply atlintots 5 hours agoprevIt's so cooked. There are just no jobs anymore. reply momojo 1 hour agoparentRequest: Any tech-recruiters on here who can validate this? I spent a single month in June job hunting (mid-level SWE, DE roles) and it was terrible. Hundreds of applicants per position. It felt like being a fresh-grad again. But that's just my anecdata reply coldpie 1 hour agorootparentNo luck from your connections at previous jobs? That's always the best way in. reply cruffle_duffle 1 hour agorootparentWhen I was looking none of that helped at all. People in my network would refer me to all kinds of jobs posted online but basically once submitted you'd still be ghosted. I'm not even sure those were real jobs because to this day they have the same listing posted. reply electriclove 5 hours agoprevCompany isn’t doing so great and future doesn’t look so great and people cost a lot of money so they are letting folks go who aren’t as valuable. This makes sense. reply airstrike 4 hours agoparentWhat doesn't make sense is hiring so many people to begin with. The writing has been on the wall about Dropbox for quite a while now reply electriclove 4 hours agorootparentAgreed! So many of these companies hired needlessly over the recent years. reply blitzar 2 hours agorootparentIt wasnt needless, they didnt want to miss out. They are not sure what they didnt want to miss out on, but they knew for sure that they didnt want to be the only one not doing it. reply andygcook 4 hours agoprevFor context, Drew Houston's total compensation for the year in 2023 was $1.5M: > According to our data, Dropbox, Inc. ... paid its CEO total annual compensation worth US$1.5m over the year to December 2023. That's a notable increase of 34% on last year via https://finance.yahoo.com/news/heres-why-dropbox-inc-nasdaq-... Even if Drew took minimum wage, that would save ~15 jobs assuming $100K all-in comp (which seems low to me for a tech salary). 500 employees is more like $50M/year, and probably more. Of course, Drew Houston's net worth is ~$2B and he could technically loan Dropbox Inc money personally to save the jobs, my guess is a lot of his net worth is actually Dropbox stock that he would have to liquidate and would affect the stock price materially. He would also need to follow insider trading laws too and can't just up and sell vast amounts of stock on a whim. Most executives are on pre-approved schedules to sell any stock to avoid triggering insider trading. The severance package Dropbox is offering is pretty good - 16 weeks of pay + an additional week for each year of tenure, impacted employees get their Q4 equity vest & prorated bonuses, everyone keeps company devices, an offer for extra time + help for people on visas, and job placement help for everyone. Dropbox is a public company that is profitable, but not really growing through their flagship product. No growth is more or less bad on Wall Street. They also haven't really had a major hit since their initial file-sharing product and missed some shots they probably should have hit (mainly vs. Notion with Dropbox Paper, Mailbox acquisition, etc). With many systems moving away from \"files\" and to \"cloud objects\" like Figma, Notion, etc, their workhorse product might be going away over time too. They need the time and focus to find that next S-growth curve. Layoffs suck and no one wants to do it, but sometimes it's needed to save the ship. reply duped 3 hours agoparent> Layoffs suck and no one wants to do it, but sometimes it's needed to save the ship. Layoffs are the trolley problem but you get to pick how many people are lying down on each side of the track and if you want yourself to be one of them. That said, if one reaches the conclusion that under their leadership they were forced to downsize by 20% (either due to over hiring, failure to reach revenue/growth targets, whatever) that should make that person one of the people on proverbial tracks. Compensation has little to do with it. reply Matticus_Rex 3 hours agorootparent>that should make that person one of the people on proverbial track That's a satisfying thing to say, but as practical advice it's absolutely terrible. Often that person's leadership wasn't the problem, but even when it was, that doesn't necessarily mean that the company will be better-off without them. And that's the question -- what will make the company most likely to be the most successful going forward? Even if the current trouble is because of some of that leader's mistakes, the answer is often to keep that leader. Sometimes it isn't. reply pixelatedindex 2 hours agorootparent> Often that person's leadership wasn't the problem Then what is the problem? Ultimately you’re paid the big bucks for being held responsible. Why isn’t it never something like the CEO doesn’t get any stocks that year. I’m not saying he needs to leave the company but maybe he should take a substantial hit to his pay. He has enough money to put food on the table for many years, unlike the people who are let go where it’s mostly a mixed bag. reply s1artibartfast 2 hours agorootparent>Why isn’t it never something like the CEO doesn’t get any stocks that year. Performance based compensation is absolutely standard for CEOs- Both in terms of options and stock grants. reply DrillShopper 2 hours agorootparentDo those metrics count \"number of people laid off\" explicitly? We know they do implicitly because laying off people makes the company more profitable, but is there any penalty for killing jobs? If not, shouldn't there be? reply s1artibartfast 1 hour agorootparentNo, I dont think there should be a penalty by default. The objective of a company isnt and shouldn't be to run a charity. Some amount of layoffs are desirable just as a matter of housekeeping. Layoffs can be a hard part of doing a good job.",
    "originSummary": [
      "Dropbox CEO Drew Houston announced a 20% reduction in the global workforce, impacting 528 employees, as part of a transition to streamline operations and address declining demand.- The company plans to focus on new growth areas, such as Dash, indicating a strategic shift in its business model.- Affected employees will receive severance packages, equity, healthcare benefits, and job placement support, with more details on the 2025 strategy to be revealed soon."
    ],
    "commentSummary": [
      "Dropbox is cutting its global workforce by 20% due to financial pressures, highlighting the challenges companies face in a competitive talent market.",
      "The layoffs underscore the debate on whether such workforce reductions allow individuals to find more productive roles or if they cause significant disruption, particularly during economic downturns.",
      "The conversation also includes the importance of a safety net and how lifestyle choices can affect financial stability during such transitions."
    ],
    "points": 406,
    "commentCount": 712,
    "retryCount": 0,
    "time": 1730295772
  },
  {
    "id": 41993012,
    "title": "Classic 3D videogame shadow techniques",
    "originLink": "https://30fps.net/pages/videogame-shadows/",
    "originBody": "30fps.net - Computer Graphics & Programming with Pekka Väänänen Classic 3D videogame shadow techniques October 25th, 2024 Towards the end of Wim Wenders’s excellent Perfect Days, the protagonist Hirayama is drinking beer under a bridge after he has seen a Businessman courting his crush. Suddenly the Businessman joins him under the bridge. As it turns out, things aren’t actually that simple but the point is their conversation takes them to some fundamental questions: Businessman: Shadows. Do they get darker when they overlap? Hirayama: Not sure. Businessman: So many things I still don’t know… That’s how life ends… I guess. Hirayama: Let’s find out now. Businessman: What? Then they step into to the light of a street lamp and investigate their shadows (the full scene): An iconic scene in Perfect Days (2023). Still via film-grabs.com. Even though the Businessman sees no difference, Hirayama is convinced the overlapping shadows do become darker. “It has to get darker to make sense.” What a moving scene. Shadows do become darker when they overlap in Metal Gear Solid. Unfortunately Hirayama is mistaken. Shadows don’t get any darker there. There’s just one light source, and relatively far away, so the shadow is simply an absence of light. It doesn’t matter how many times the light is blocked. When it comes to 3D videogames, shadows are something else. It’s easy to paint dark blob under some character’s feet and assume everything else is lit. Perhaps Hirayama was recalling the blob shadow in Metal Gear Solid that does become darker when it overlaps with others? In the real world, shadows simply exist but in games they are both engineered and designed. They must run well but also look good. I find this relationship fascinating and I’m going to show you why. Let’s start simple. On-screen 2D shadows You can draw a shadow image to the screen before you draw a character. I’m not talking about shadow sprites like in Duke Nukem 3D but literally a 2D image without any scaling. This works if the character is in front of everything like in Winter Gold or MDK. Winter Gold (1996, SNES) and MDK (1996, PC) draw animated 2D shadow images. Also check out Winter Gold’s sick Amiga-style intro video :) I said it was simple. Blob shadow OK now in 3D. Draw a dark disc under the character. Done. Well, you should also align the shadow disc with the ground and also decide how to handle situations where the shadow would reach over a ledge. For example in Super Mario 64, the blobs are drawn using a special hardware feature that effectively clips the shadow to show up only on the ground plane. Super Mario 64 (1996, Nintendo 64) uses blob shadows for characters. Left: A blob shadow overlapping with tree shadows. Center: A blob shadow getting clipped using a hardware decal feature. Right: All moving characters and objects have their own shadow. The clipped shadow inside that transparent bubble shows the limitation of the Nintendo 64 decal feature. Screenshots taken in the ares emulator. The blob shadow can also be animated. In Super Mario 64 it becomes smaller when jumping and in Metal Gear Solid it changes shape. If you’re feeling ambitious, you can also solve the shadow-over-a-ledge issue by projecting the blob quad like a decal. Planar shadows with a render texture The blob is just a texture and usually textures can be rendered to at runtime. So render the character from the top and use that instead of a dark circle. This works great in Crash 3 (video) but not so well in Soldier of Fortune because they kept the shadow resolution so low. Left: Crash Bandicoot: Warped (1998, PlayStation) renders shadow textures at runtime. Right: Soldier of Fortune (2000, PC) also does but at a lower resolution. A cropped still from a video by FirstPlays HD. Note that this is distinct from shadow mapping where a depth map is rendered from the light’s point of view. Here we render only a black & white image that is used as a texture. So in a sense we’re talking about a 1-bit shadow map. How could we make the shadows sharper? Planar shadows with geometry The F-117A plane casts a shadow in F-19 Stealth Fighter (1988, DOS). One intuitive option is to flatten a shadow caster on a plane by projecting it away from the light. Then render it the second time but now in black. They are usually kept opaque to hide how object parts are drawn on top of another. Naturally the shadow will be correct only on a flat floor. Some early flight simulators draw a top-down flat shadow when on a runway. During my research I expected to see examples where the shadow is also seen when in flight but couldn’t find any. GLQuake’s planar shadows in two games. Left: Kingpin: Life of Crime (1999, PC) gets away with black planar shadows. Right: Shadows exhibit transparency issues in Half-Life alpha 0.52. Screenshot taken via Wine on Linux. Visually these look the same as black stencil shadows cast on a flat plane. Shadows on terrain Virus (1987) Atari ST port. The little ship casts a neat drop shadow. David Braben’s 1987 Virus on Acorn Archimedes and other home computers draws spaceships that cast top-down shadows on terrain. A more elaborate example is Interstate ’76. There they tilt and stretch a planar shadow to match the ground slope. The shadows occasionally penetrate the ground but are pretty convincing overall. Interestingly, the below software-rendered screenshot has slightly transparent shadows while the hardware accelerated ones are pitch black. They also had the courage to try to project shadows for large objects like bridges which isn’t, well, entirely successful. Interstate ’76 (1997, PC) has sun casting tilted planar shadows on terrain. But how do you cast shadows on any kind of scene? Projected texture drop shadow Left: A slide from the deck Toy Story 3: The Video Game Rendering Techniques. Right: The drop shadow gets darker when it overlaps with other shadows. A still from an Xbox 360 gameplay video of Toy Story 3: The Video Game (2010). This approach bears a lot of similarity to Planar shadows with a render texture presented earlier but works on surfaces of any shape. The game renders a shadow texture from the top but instead of showing it on a flat plane, the texture is projected to other objects. Think of it as the Bat-Signal but pointed straight down from the sky. Shadows like this can be made really sharp but they can look strange on vertical surfaces and occassionally even appear on the ceiling. See this gameplay video of Sonic Adventure 2: Battle (2001, GameCube). This technique also works great for trees: The Elder Scrolls IV: Oblivion (2006, Xbox 360) has beautiful projected tree shadows. Projected shadows can show through objects which makes them suitable only for special cases. Shadow maps are something you can use anywhere. Shadow maps The de facto approach to shadows. The game draws a depth image, the shadow map, from the point of view of the light and reads from that image when rendering the world. This is easy to do since you can reuse the game engine’s regular rendering code. Half-Life 2 (2004, PC) used shadow maps for characters. Dynamic flashlight shadows (not shown) were added in the 2007 Episode Two expansion. The limited resolution of the shadow map gives rise to well-known artifacts with inventive names such as “Peter Panning” and “shadow acne”. Many tricks have been proposed to allocate more shadow map area to surfaces near the camera where the extra resolution is needed the most. Shadow maps usually need some tweaking to look right. Before shadow maps became dominant, there was a popular competitor. Stencil shadows The has-been approach to shadows. Stencil shadows draw sharp shadows on any kind of surface. They create a unique film-noir look that’s hard to emulate with shadow maps. Most well-known example is of course Doom 3 with its dark rooms: Doom 3 (2004) had no static level lighting and all shadows were computed at runtime. Screenshot from Doom 3 shadow engine snapshots. Stencil shadows are based on the idea of shadow volumes, invisible geometry that cuts the world into lit and shadowed spaces. The game applies lighting only on pixels that don’t lie inside a shadow volume. The game needs to construct “shadow volume” meshes shown in yellow. Surfaces inside the volumes stay unlit. Shadow volume illustration by Rainwarrior, CC BY-SA 3.0. Stencil shadows need the world to be drawn many times to work. Simplified a bit, the game first draws the whole world with ambient lighting. Then for each light, all the shadow volumes, followed by the world again, affecting only unshadowed pixels. The volumes are drawn with different stencil operations set for front and back faces. It’s a lot of pixels to draw. Possibly the earliest shipping game with stencil shadows is Severance: Blade of Darkness from 2001 whose shadows look great. Severance: Blade of Darkness (2001, PC) had stencil shadows. Reading the Edge UK edition March 2001 review (pdf) of the game makes it clear that despite the graphics advancements, the world wasn’t ready for a soulslike back then. Stencil shadows are not used much nowadays. One reason is their unpredictable runtime cost. The cost is dependent on how large the volume is on screen and therefore varies a lot. Also an optimized algorithm was patented. For Doom 3, Id Software apparently reached some sort of a deal. Soft stencil shadows Left: Silent Hill 2 (2001, PlayStation 2) has soft stencil shadows. Center: 2x zoomed crop. Right: A shadow debug view with unlit areas colored black. Screenshots from the PCSX2 emulator lightened up for visualization. Stencil shadows don’t need to be sharp. Another game from 2001, Silent Hill 2 on the PlayStation 2, blurred the stencil shadows afterwards as seen above. It looks pretty much perfect on the console. Simplified character shadows What if the shadows are cast by a simpler model than what’s shown on screen? For example in Zelda on the Nintendo 64, Link’s feet cast shadows even though nothing else does: The Legend of Zelda: Ocarina of Time (1998, Nintendo 64) has Link’s feet cast shadows as if they were tall vertical cylinders. I presume the shadows are two stretched decals. One unique approach is seen in Hyperblade where players on a futuristic hockey arena cast planar shadows as simple animated shapes. Hyperblade (1996, PC) projects a simplified planar shadow that moves. It’s not perfect as seen in the rightmost image. Stills from a video by Bit Games Reviews. Shadows in static level lighting Vertex colors and lightmaps are techniques to capture lighting of a game level. They have been used in many games as the only way to show large scale shadows, which is why I’ve included them here. Vertex colors Ico shows how sophisticated shadows can look with just old school per-vertex lighting. Ico (2001, PlayStation 2) has level lighting baked to vertex colors. For characters it uses stencil shadows. For low-poly maps even sharp shadows can be represented with vertex colors. A prime example is Tony Hawk Pro Skater 2 (2000, Playstation) which looks amazing considering the simplicity of the technique. “Venice Beach” level in Tony Hawk Pro Skater 2 (2000, PlayStation) with its sharp vertex color shadows. This shot is from the Dreamcast port. Lightmaps Lightmaps are the classic way to store level lighting and shadows. Instead of storing a color for each vertex, there’s a second set of textures that represent only lighting. The resolution can vary per area, making the shadows more accurate where needed. On the other hand, lightmaps consume more memory than vertex colors. Mirror’s Edge (2008, PC) is basically Lightmaps: The Game. Lightmaps were popularized by Quake (1996, PC) and this is how they look. That concludes our look into traditional shadow techniques. Let’s talk a bit about lighting in general next. Shadows in modern games Modern games use the traditional techniques when appropriate. Some examples: Variants of shadow mapping such as Cascaded Shadow Maps to cover large areas while still staying fast. Lightmaps in combination with other techniques such as light probes. Call of Duty still has lightmaps, see the Hemispherical Lighting Insights slides. The simplified character model idea. The Last of Us (2013, PlayStation 3) casts soft character shadows with stretched spheres. See this slide of the deck Lighting Technology of The Last Of Us (2013). Also Unreal Engine supports simplified “capsule shadows” for characters. Projected shadows. In Hot Wheels Track Attack (2010, Wii) they render a shadow mesh to a texture and project that on the race track, as described in one of the developer’s blog. The game looks great in motion! Ray-traced shadows In the beginning we established that shadows are formed by a lack of light. If the game really tries to simulate physically correct lighting then shadows will naturally appear. Even small geometric details will cast accurate shadows, unlike in shadow maps. Big lamps will naturally create soft shadows and indirect light will brighten dark corners. An incredible amount of time and money have been invested in ray tracing algorithms and hardware to make this dream reality. In practice modern games have such complex scenes the above simulated solution has to be approximated. For example in the ray-traced shadows of Alan Wake 2 (2023) each pixel receives lighting only from a single randomly chosen light. The result is eventually fed to a denoiser that intelligently smooths out the noisy picture. See the whole presentation for details. Therefore even ray-traced shadows won’t be “perfect” and will have their own look, depending on the tradeoffs made. Finally, the obvious option. No shadows Sometimes your priorities are elsewhere. Alone in the Dark (1992, DOS) had no character shadows. In the movie scene, when Hirayama is carefully studying the shadows, his new friend makes an observation: Businessman: You’re really into this. As computer graphics enthusiasts, I think we can symphatize. All screenshots provided by MobyGames unless noted otherwise. Thanks to mankeli for detailed notes on an early draft of this article. Thanks to noby, msqrt, shaiggon and Warma for feedback. Mastodon Bluesky YouTube Feed 30fps.net",
    "commentLink": "https://news.ycombinator.com/item?id=41993012",
    "commentBody": "Classic 3D videogame shadow techniques (30fps.net)255 points by ibobev 10 hours agohidepastfavorite47 comments 01HNNWZ0MV43FF 3 hours agoMy favorite shadow fact is that outdoor shadows are blue. It's not an optical illusion or artistic vibe or anything. The sky is blue, shadows on a clear day are illuminated by bounced light from the sky, therefore shadows are blue. If you look underneath cars you can see it - A sharp blue shadow where the sky is visible, that fades to true black where the car's body occludes light from the sky. If you combine this sharp blue sun shadow with a soft and black \"AO\" sky shadow you can get very pretty shadows for cheap. reply Sohcahtoa82 2 hours agoparentIt's true, and so subtle that a lot of people don't even notice it. But a good graphics rendering engine will do it. Shadows should carry a slight tint from the color of the sky. Which is why some old screenshots of No Man's Sky bothered me. Pretty sure I saw scenes where shadows were purple despite a green sky. reply stonethrowaway 47 minutes agorootparent> But a good graphics rendering engine will do it. Correlation/Causation: lots of things in graphics rendering work because of observed phenomena. A “good graphics engine” is only as good as the eyes that implemented it. Todays engines still fall short of what is in front of us, and not because of a technical limitation. > Pretty sure I saw scenes where shadows were purple despite a green sky. If it’s a stylistic effect then it’s a stylistic effect. But otherwise, purple shadows are literally everywhere. Shadows can have an immense amount of chroma and vibrancy to them, or they can be incredibly cool and muted. It all depends on the context. reply fourteenfour 1 hour agoprevI've always thought Valorant looked like crap because the players don't cast shadows. Just found out the other day that it's because other player model positions aren't sent to the client until the server determines they are visible to reduce cheating. This would cause shadows to appear and disappear as the player model was loaded and unloaded so you would never see a shadow unless you could also see the body of the player. reply jsheard 46 minutes agoparentI think you read my post about that, I don't know if they specifically disabled player shadows because of the anti-cheat system but it certainly makes the anti-cheat simpler. Valorant intentionally has extremely bare-bones rendering to allow for very high framerates on modest hardware, aside from no dynamic shadows it has no dynamic lighting whatsoever, and no alpha transparency anywhere. Things like smoke that would usually be transparent are stylized in ways that let them be drawn fully opaque because it's faster. Regardless of the cheating situation they probably would have skipped dynamic shadows anyway, for performance. reply enragedcacti 23 minutes agorootparentSpot on: \"We have cast shadows only on objects in first person, like your own hands and weapon. This is to avoid cast shadows being a competitive factor in both effect (knowing where your cast shadow is) and performance (low-spec machines can’t reasonably run well with cast shadows).\" https://technology.riotgames.com/news/valorant-shaders-and-g... reply tetris11 43 minutes agorootparentprevLink to your post for the curious? reply jsheard 42 minutes agorootparenthttps://news.ycombinator.com/item?id=41937205 reply mikepurvis 55 minutes agoparentprevSurely fixable by the server checking for visibility of the shadow as well? I don’t know Valorant but I assume that could actually become a strategic element to not hide with a light source at your back. reply jsheard 7 hours agoprevI like the variant used in modern Nintendo platformers - they use shadow maps like basically everything else nowadays, but the player characters shadow is rigged to always be cast straight down regardless of where the actual light sources are. That helps the player gauge where they're going to land after a jump like a classic blob shadow, but with the visual fidelity of a proper shadow. IIRC in dark environments they also rig the shadow to be brighter than the ground to make sure it remains visible. reply aarongeisler 5 hours agoprevGreat post. There are lots of nostalgic game references here. I still remember being blown away by the shadows in the N64 Zelda many years ago. I expect area lights and soft shadows to become the norm as ray-traced techniques are adopted. If you have the hardware, it's worth checking out Quake 2 RTX to see what the future might look like. Lastly, I've added your blog to my growing list of graphics resources: https://github.com/aaron9000/c-game-resources reply lawlessone 3 hours agoparentHonestly if they can get good enough shadows with smoke and mirror trickery i'd prefer they stick to smoke and mirrors for performance reasons. reply aarongeisler 1 hour agorootparentAgreed. Even with a top-end GPU I almost always turn off RT features. I expect we will continue to see hybrid RT approaches for the foreseeable future. reply mordae 4 hours agoprevThanks, it was an interesting read. Could have been more technical, though. I am toying with lighting little voxel grid scene these days, targeting RP2040 and a measly 160x120 px screen and it's crazy how computationally and memory expensive this stuff is. reply msephton 5 hours agoprevOne of my favourites are the shadows in PS1 game Power Shovel (aka Power Diggerz) which were interesting as they had to be projected over uneven terrain. I guess planar shadows is the closest technique in the article. https://www.youtube.com/watch?v=j_c4ZgcLTuE reply edflsafoiewq 4 hours agoparentInteresting. It looks like each vertex in the \"shadow model\" is projected onto the ground individually, which means the shadows can \"peel away\" from the ground. : : : :____ ground : /| : /wall ground __:/__| reply otikik 9 hours agoprevShadows do get \"darker\" when they overlap and there's more than a single light source. 3 people illuminated by 2 lamps will project 6 shadows. Where the 6 shadows all overlap, that will be \"black\" (or only picking ambient light). In other places where less shadows overlap, you will get a gradient of illumination. reply fregus 7 hours agoparentthat's not true, it will be black (or ambient light) when any two shadows, one from each light, intersect. that's because if it is in shadow from light A and in shadow from light B, where would it get any illumination from? only from the ambient light, or if there is none, it would be black. reply terminalbraid 6 hours agorootparentNo. Consider two objects, two light sources, and an ant. An ant outside any shadow can see both light sources. An ant in a non-overlapping shadow cast from one object will have one light source blocked out but the other light source will be visible to the ant. An ant in overlapping shadows from two objects will have both light sources blocked out. (Geometrically in this case it is necessary the overlapping shadows be cast from two separated points each from distinct light sources) When one light source is visible to the ant that area must be lighter than when no sources are visible. This is the scenario presented by the OP. edit: Since people seem to not believe this you can find a representation in part E in this diagram https://i.imgur.com/r6x6QPQ.jpeg and a photograph of this nicely done with colored lights here https://i.imgur.com/NUlywpb.jpeg reply twodave 6 hours agorootparentWe aren’t questioning your logic, just your reading comprehension in this case :) OP was correctly describing the case where both lights are blocked from view. reply terminalbraid 6 hours agorootparentJust to summarize, because someone is missing something: otikik pointed out a case of multiple light sources where overlapping shadows will be darker (otikik is correct) fregus says \"that's not correct\" and argues a true case (shadows from one light source will not be darker) which is a bad argument because it tries to overgeneralize. The case from fregus is for the same light source and they cannot use this to argue otikik is incorrect because otikik's argument explicitly requires multiple light sources. I point out, responding to fregus, how otikik is correct and how you need to consider multiple sources as well as including examples and physical evidence. You question my reading comprehension for some reason reply freestyle24147 3 hours agorootparent> ... when any two shadows, one from each light, intersect. that's because if it is in shadow from light A and in shadow from light B ... They actually reference two light sources TWICE in their comment: (\"any two shadows, one from each light\", \"from light A and in shadow from light B\"). Hence the question of reading comprehension. reply danparsonson 4 hours agorootparentprev> when any two shadows, one from each light @fregus explicitly described a scene with two light sources. Thus the question about your reading comprehension. reply Fraterkes 5 hours agorootparentprevFregus point is that otikik seems to suggest that the darkest shadow will be the combination of all 6 shadows; thats obviously wrong, any shadow blocked from both lights will be as dark as any other shadow blocked from both lights, no matter the amount of \"overlapping\" shadows. You then respond to Fregus by unnecesarily just explaining shadows again, hence the reading comprehension comment. reply binary132 5 hours agorootparentLet’s all write long explanations of one another’s long explanations, then the people who couldn’t comprehend the simple point in the first place will definitely understand reply Fraterkes 3 hours agorootparentI'm not talking to \"people\", I'm writing a specific response to a specific person. Do try to keep up reply binary132 5 hours agorootparentprevThat would be true if lights were simple point sources with simple straight ray behavior and no diffusion and no reflection but they’re not. reply yazzku 1 hour agorootparentYou are right. fregus leaves it at \"ambient light\" and calls it a day, but ambient light is just an empirical construct, not grounded in physics. In reality, light bounces around, and areas will appear darker the more the light paths otherwise converging on them are blocked by occluders. I think \"overlapping shadows get darker\" is just not a very intuitive way to think about it because it disregards the stuff that actually matters, which is the light sources and how the scene may block their light paths. For early games that could not afford advanced methods of global illumination, making overlapping shadows get darker seems like a reasonable, though not necessarily correct, way of faking it. And the other thing ignored in these comments is perception. For the case of the two businessmen looking at their shadows under a bridge, it is easy to show with a diagram that some areas of overlapping shadows are, in fact, darker. But in such a poorly lit scene, people are likely to conclude that there is no difference, which isn't to say that there isn't one but, rather, that they don't perceive one. reply lukan 8 hours agoparentprevGood observation, but the article is not wrong (and quite interesting) \"There’s just one light source, and relatively far away, so the shadow is simply an absence of light.\" reply throwawayk7h 1 hour agoprev> Shadows do become darker when they overlap in Metal Gear Solid. They should indeed get darker when there are multiple significant light sources, as in the Metal Gear Solid screenshot. This is because the addition of another obstruction (i.e. Solid Snake) causes more sources of light to be blocked. reply ajuc 1 hour agoparentI recently realized this when there was a heat-wave and I walked through a small patch of trees in the middle of the city. The shadows of buildings were pretty light color and walking through them wasn't changing the temperature noticeably. But between the trees almost all of the sky was blocked - so the diffused light wasn't getting there - and the shadow there was much darker and it was significantly colder than every other part of the city. So - shadows can get darker or lighter, even if there's just one light source and it's very far :). reply chungus 8 hours agoprevClicked this because it sounded interesting and was surprised to see one of my favorite movies in the introduction! edit: really nice and nostalgic read, I played almost all of the games mentioned. reply samsartor 3 hours agoprevSketchUp uses stencil shadows! Although we have more modern options, it is part of the look. reply MattRix 6 hours agoprevFor an example of the state of the art in videogame lighting, check of Epic’s recent UE 5.5 MegaLights demo: https://youtu.be/p9XgF3ijVRQ?si=GcU0kP33iKQh_5Ge reply tanepiper 3 hours agoprevA great article but I can't believe they missed Third: The Dark Project from their list. reply moralestapia 4 hours agoprevGreat article, fun to read. The shadow overlap in MGS is not completely incorrect as there's ambient light, scattering and other similar global illumination phenomena. >Mirror’s Edge (2008, PC) is basically Lightmaps: The Game. Lol, true. Impressive game at the time, and even nowadays. reply nuancebydefault 8 hours agoprevSo many shadowing techniques! Interesting how using ray tracing inherently makes rendering shadows a non issue. reply samsartor 3 hours agoparentSorta, in classical single-bounce ray tracing you still need to cast explicit shadow rays from diffuse surfaces. Path tracing gives shadows for free, because it is simulating global illumination rit large: ambient occlusion, shadows, bounce light are all special cases. reply Cthulhu_ 8 hours agoparentprevI mean ray tracing is (probably? I'm no expert) the most physically accurate rendering method available, mapping closely to how light works in real life ('rays' of light bouncing around until they hit your retina, but then in reverse so you only simulate the rays that actually hit the camera instead of wasting every one that doesn't). But it's also the most expensive one. reply hnuser123456 7 hours agorootparentWe're at the point where we need new systems to represent material surfaces better, like leaves glowing from beneath when sun hits them from above, since they're thin enough for light get through. Or imagine putting a flashlight on your skin and seeing your skin glow from the inside around it. Unfortunately a much more complicated scenario than large open rooms and solid flat walls. reply jsheard 7 hours agorootparentGames do simulate subsurface scattering, it's been a staple since the PS4 generation. They currently fake it rather than brute forcing the light paths traveling inside the surface like offline renderers do, but it still works fairly well. https://old.reddit.com/r/gaming/comments/4jc38z/til_in_uncha... In offline rendering the sky is the limit when it comes to SSS quality, if you have enough compute to throw at it. It's essential for getting skin to look right. https://x.com/HadiKarimi_Art/status/1730627284141216181 reply Keyframe 4 hours agorootparentprevBRDF, BSSRDF.. all can simulate that and are part of the rendering equation (Kajiya) if you plug it in. reply bathtub365 5 hours agorootparentprevWhy are the existing systems inadequate? reply teamonkey 6 hours agorootparentprevRay tracing algorithms are quite simple - it’s essentially just checking line intersections with geometry and doing bounce calculations - but a VAST number of rays are needed and a GPU that can do ray tracing needs to keep much more information about the scene geometry in memory. In older generations you wouldn’t store detailed collision information in GPU memory. A GPU that can handle ray tracing, however, can do a lot of the techniques mentioned in the article (and others) more efficiently without doing what you’d consider full scene ray tracing, because the fundamental path tracing algorithms are very versatile. reply lukan 7 hours agoparentprev\"Interesting how using ray tracing inherently makes rendering shadows a non issue.\" Raytracing simulates real lighting. Shadows are, where no light is. reply magicalhippo 6 hours agorootparentIn traditional Whitted-style ray tracing, the expensive part is indeed figuring out where there is no light. You know where you are, you know where the light is, but is there something inbetween? reply justsomehnguy 6 hours agoprev [–] >> Some early flight simulators draw a top-down flat shadow when on a runway. During my research I expected to see examples where the shadow is also seen when in flight but couldn’t find any. F-29 RETAL aka F29 Retaliator aka F29 That shadow was another small tidbit what gave this game the enormous feel of speed. https://imgur.com/a/hOgxr7a https://www.mobygames.com/game/6233/f29-retaliator/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article by Pekka Väänänen on 30fps.net delves into the evolution of shadow techniques in 3D video games, starting with a reference to Wim Wenders's \"Perfect Days.\"",
      "It covers a range of shadow rendering methods, from traditional 2D and blob shadows to advanced techniques like ray-traced shadows, highlighting the complexity of shadow creation.",
      "The piece concludes by noting that some games choose to forego shadows entirely, offering a comprehensive overview of the topic for those interested in video game graphics."
    ],
    "commentSummary": [
      "The post discusses classic 3D video game shadow techniques, noting that outdoor shadows often appear blue due to sky illumination, a detail replicated by good graphics engines.",
      "Some games, such as Valorant, avoid dynamic shadows to enhance performance and prevent cheating, while Nintendo uses shadow maps for better gameplay clarity.",
      "Ray tracing is highlighted for its realistic lighting capabilities, though it is computationally demanding, and modern techniques like path tracing are mentioned for their efficient shadow handling."
    ],
    "points": 255,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1730278194
  },
  {
    "id": 41994567,
    "title": "Gross Apple Marketing",
    "originLink": "https://jonathanbuys.com/Gross_Apple_Marketing/",
    "originBody": "Gross Apple Marketing October 29, 2024 I’m not sure what’s going on over in Cupertino for them to think that any of the recent Apple Intelligence ads they’ve been running are a good idea. They’re cringy at best, and honestly just flat out insulting. In one a schlub writes an email to his boss and uses AI to make it sound ‘more professional’, in another a young woman uses it to lie about remembering an acquaintance’s name. In another the same young woman again uses it to lie about reading an email from a college, to her face, while she’s sitting with her. In yet another, linked to recently by Scott McNulty, a woman uses AI to lie to her husband about getting him something for his birthday. If this is what Apple thinks their AI is for, I honestly don’t know that I want any part of it. Compare and contrast with the video I posted yesterday, and with this beautiful animation from Canonical. I’ve watched that little animation several times, and they tell a better story in a minute twenty-five than all of Apple’s AI commercials combined.",
    "commentLink": "https://news.ycombinator.com/item?id=41994567",
    "commentBody": "Gross Apple Marketing (jonathanbuys.com)223 points by mrzool 5 hours agohidepastfavorite231 comments devin 4 hours agoI think this is mostly just a problem of not having good reasons to sell AI products to consumers in the first place. I recently saw some Ray Ban Meta glasses ads. One of them had a guy ask the glasses to describe what was in front of his face, and then he remarked “wow that’s accurate” (there are people skateboarding). The guy wasn’t blind. His use of the glasses made little sense. Another ad has a young man asking his glasses how to dress for fall and then blindly following the suggestions like they’ve never dressed themselves before. It was embarrassing to watch. A third ad has someone ask their glasses how to decorate for a disco theme party, and then they implement the very mediocre suggestions. None of these things required AI, it’s just kind of “there”, and companies are like “idk maybe people will use our AI to like… dress themselves? or something?” reply jfoster 4 hours agoparentNo way! There are definitely legitimate use-cases for all of the features demoed in these ads, but Apple's marketing took a darker path. Email to boss: could've been someone who had a genuine struggle with language using it to finally get their boss to notice the effort they put into their work. Remembering a name: could've used it to get the name and left it at them being impressed rather than making it a lie. Summarizing email: could've used it when in a hurry at work whilst someone sent an extremely long email. Video memories: could've used it for two people to share a nostalgic moment together without making it a lie. reply philistine 2 hours agorootparentThe fact that lying is a core element of the ads is what makes them so gross to me. The guys says he's surprised she remembers him. She could just look straight at the camera, say what can I say, I'm very intelligent, wink, and it wouldn't be gross. reply jfoster 1 hour agorootparentRight, there's so many ways that they could have made these characters slightly less lazy & deceptive and it would've been fine. It's not the first Apple ad to be in poor taste this year. https://www.youtube.com/watch?v=xGyOIFRJPII reply consf 4 hours agorootparentprevThe marketing goes for flashy scenarios reply jfoster 4 hours agorootparentMy writing ability might not be good enough to make them flashy here on HN, but I am sure that each of the scenarios could be made very flashy or moving with a bit of imagination & Apple's still-excellent production quality. One of my favourite ads is a very simple story that is made gut-wrenching by creating an emotional connection and some great production value: https://www.youtube.com/watch?v=a2lv_Xl1e4U reply briandear 4 hours agorootparentprevErnest Hemingway once said, “I’m sorry for the long letter, I didn’t have time for a shorter one.” With Apple Intelligence, now you do. reply B56b 4 hours agorootparentThat's a Blaise Pascal quote actually. reply BobaFloutist 3 hours agorootparentprevWhy would I take the time to read a letter you couldn't be bothered to take the time to write? reply phil-martin 3 hours agorootparentBecause they took the time to write a long letter, and were thoughtful enough to have it shortened to save you time when reading it? reply wruza 3 hours agoparentprevNot unique to AI, honestly. If I try to watch a technical review on a smartphone, they’ll still talk about camera megapixels, screen size/brightness, corners, etc. No one talks about scroll sensitivity and jankiness, [bad] position of buttons on screen and on the frame, sensor nuances, how it feels in a pocket, can it work as a display, notification sounds and sound level separation, etc. All marketing, including third-party based, focuses on absolutely basic features for abstract people who do nothing and have no problems to solve apart from taking pics of themselves and other two-digit iq activities. I guess it’s only logical for this image to walk into a skate park and ask their glasses about what these guys are doing. reply ncr100 3 hours agoparentprev> mostly just a problem of not having good reasons I disagree, I think this is bad ethics, and bad marketing people, working for Apple...what other explanation - same people crushed musical instruments and books, human craft-work -- using a hydraulic press, in a recent Apple advert. Advertising certainly can show outrageous ways to behave, and it's \"okay\". Calling someone and simply shouting WAZZZAAAAAAP! into the cell phone, for the famous Budweiser advert during the superbowl...derives into a crew of 3-5 people shouting AAAAAAAAAAAZZZAAA into their phones, oddly. That was cute .... However this is about enabling through lying. In one ADVERT it makes a Manager believe an Employee is more engaged than they truly are, rewriting their unprofessional language using the new \"Professional\" button, reasonably leading to a future misallocation of resources by the manager to the irresponsible seemingly under-skilled or simply lazy unethical employee. What's worse is the people who are NOT using Apple products to lie. The Employees who did not lie about their grip on written language now have to compete with AI, wielded by their ill-behaved coworker. It stratifies society into Idiocracy. This is a TERRIFYING series of advertisements chosen by Apple. reply vundercind 3 hours agorootparentThe signaling value of knowing how to writey words good is dead. More dead even than a coffin-nail, and assuredly that of a door (thanks, Dickens). Signaling through speaking will become even more important. Get thy children to debate club, seminar-based classes (hope you're rich!), theater, and hell, I dunno, ToastMasters Junior or whatever. reply dialup_sounds 1 hour agorootparentprevIt's not a good set of ads, granted. But millions of people have been using Grammarly, et al. for this for years. Managers have actually paid to deploy tools like this to their employees. The ship you're talking about has already sailed. reply tpmoney 1 hour agorootparentprevNonsense. Are people who use spell checkers also lying when the computer helps them not sound like an illiterate 5th grader? What about Word’s pre-AI grammar correction? Further, it’s pretty clear from the watching the commercial that the boss is not fooled by this. The humor of the commercial is supposed to derive from the absolute contrast between the well established and known behavior of the employee and the content of their email. Humor doesn’t always land for everyone to be sure but this sounds like the same sort of handwringing over tech replacing human effort we’ve seen for years. Calculators would let people bad at math sneak their way into jobs where you need math, IDEs will let people bad at coding sneak their way into places where you need to code. Now it’s “ai grammar editing” will allow people bad at writing professionally sneak into places where they need to edit professionally. reply tiltowait 4 hours agoparentprev> One of them had a guy ask the glasses to describe what was in front of his face, and then he remarked “wow that’s accurate” (there are people skateboarding). The guy wasn’t blind. His use of the glasses made little sense. On the other hand, this is a pretty common scenario: user is surprised when AI gets something right :) Not sure it’s the best showcase of a product, though … reply solaris152000 4 hours agoparentprevYesterday I was walking in Greece and saw a sign I couldn't read so asked my Meta glasses and it gave me a translation and short explanation quickly, which was very helpful. But generally, yes the uses aren't there. In the Apple AI video, the worst is that the 'more professional' text, actually reads much less professional. If someone in a business situation sends you an AI generated email (and it's obviously AI it's so easy to tell) it makes it seem like they are unable to write English properly, giving the opposite impression than intended. reply jsheard 4 hours agorootparent> Yesterday I was walking in Greece and saw a sign I couldn't read so asked my Meta glasses and it gave me a translation and short explanation quickly, which was very helpful. Like other attempts at AI wearables like the Rabbit and Humane pins, I think that falls under \"maybe useful but why wouldn't I just do the same thing with the phone that I'm carrying anyway\". reply vundercind 3 hours agorootparent- AR is very promising for both work and play, but is worthless shit if you have to hold a device to use it. Instantly 100x better if you've got hypothetical near-future non-terrible AR glasses on most of the day. - Half of what people use the Web for is looking up trivia that would have been too high-cost to look up before, to bother with (most of the other half is posting on social media about it). Glasses further lower the cost of looking up many categories of trivia, making even more trivial pieces of knowledge cheap enough to look up. On a revealed-preference basis, this seems to be something people really like and find irritating when denied—nobody used to feel an itch when they couldn't find an answer to some fleeting trivial question that entered their mind. Once exposed to the Web, and even more so when smartphones were introduced and the Web became something you carried everywhere, they do, and it'll be the same for answering questions about stuff they're looking at, once used to glasses. - The use case of capturing otherwise-missed (getting out the phone is too slow) fleeting once-ever moments is going to be very compelling for people. reply pjmlp 4 hours agorootparentprevWell as someone that only has a passable knowledge of Greek, my phone has been doing that since at least 5 years now. Yes AI algorithms are behind it, but hardly something new to brag about in 2024. reply lxgr 3 hours agorootparentUsability matters for use cases like this. A lot. Yes, Google Translate has been able to do this for a while now, but I still find the experience very yanky and high friction so that I don't do it on a whim, usually. Everything-translating AR glasses would have been something I'd have really appreciated on a trip to Japan, for example. reply tzs 3 hours agorootparentprev> In the Apple AI video, the worst is that the 'more professional' text, actually reads much less professional. The original text is: > Hey J, > Been thinking, this project might need a bit of zhuhzing. But you're the big enchilada. > Holler back followed by the sender's first name in lower case surrounded by flexed bicep emoji. The AI rewritten text keeps the \"Hey J,\". It changes the rest to > Upon further consideration, I believe this project may require some refinement. However, you are the most capable individual to undertake this task. > Please let me know your thoughts. > Best regards, followed by the sender's first name capitalized and with no emoji. I don't see how the second could be considered less professional than the first. From the other comments here it seems like some people may be seeing different ads when they follow the links, possibly depending on their location. The text above is what was in the ad I get to from the link in the article. Are you getting something different? reply timeon 2 hours agorootparentSorry for moving the goal post... it is just that this example in the ad illustrates path to idiocracy. reply pavlov 4 hours agorootparentprevSounds like it’s time for an AI that writes emails like a busy tech executive: “no big deal. get it done. steve” reply mdhb 3 hours agorootparentprevHonestly I wouldn’t hesitate to steal and break any meta ray bands I see on the street in real life. I don’t want to see that creepy always recording without permission kind of shit normalised. reply sourcepluck 3 hours agorootparentDo you steal and break people's phones? Not trying to be snarky, I think I very much understand your reaction to this constantly monitored and surveilled world we're in. I think it's arguable that these types of glasses will make it worse too. But people are recording without permission on their phones since several years now - what has been your reaction there? I'm not a very confrontational person, so I tend to grumble and say nothing. reply majewsky 3 hours agorootparentHolding a phone in front of you to record is obviously deliberate, unlike wearing glasses. reply knowitnone 3 hours agorootparentprevtheft and violence is your solution? what a nice group of \"intellectuals\" here at HN. reply ryandrake 3 hours agoparentprevThis is what always happens when you have a technology and then desperately try to find problems to solve with it. Rather than starting with a problem and then applying the most appropriate technology to solve it. The exact same thing happened with Blockchain, but \"AI\" has about 100x more hype behind it. reply paul7986 3 hours agorootparentI think people present day do not understand how to really use AI.. understand how it can benefit their life. The commercial the OP speaks and the ad agency sounds lame as they arent helping. Personally Ive been enjoying wearing my Ray Bans for the past year and have used them to do things no other glasses can like... - Translate.... was in Canada recently and a sign about Jasper the town i was in was in French. I asked Meta to translate it... it took a pic and audibly translated it for me. - Was in Harpers Ferry WV on an overlook ..looking down into the town of Harpers Ferry which has a huge church which i have no idea it's name yet ask Meta what church is that over there. Took a pic and told me. - Was in line at HersheyPark up on a platform and my friend wondered how many people you think are in line so i asked Meta and it took a pic and gave me an estimate. reply itishappy 3 hours agorootparentAs with the Apple ads, I remain unconvinced these are benefits. Translation, yes, but your last two examples feel oddly isolating and dehumanizing. Like, estimating the number of people in a line is a trivial task, and something fun to discuss and argue about with your friends! If your friend had the glasses to, do you think it would have come up in conversation at all or would they just ask theirs? I dunno, I'm picturing a future with everyone standing around absorbed in their own devices (not too different from today) but where we struggle to ask each other normal questions due to offloading our collective intelligence and social skills to the cloud. Destined to become Daphne totally reliant on glasses to interact with the world around us. I'm probably overly dramatic here. You're out having fun at a park with friends! I'm just trying to imagine how future generations will interact with this tech, particularly the youth who won't know a world without. reply paul7986 3 hours agorootparentIt enhanced my conversation as when both people do not know something you are looking at and or discussing you can now find the answer quickly via glasses on your face. We all use Google to find knowledge/answers but most are not pulling out our phones during conversations cause that's rude. Yet it's not rude to get the answer from your glasses you are wearing on your face and still present in the conversation your having as well people will think wow that's cool (per my experience). reply olyjohn 1 hour agorootparentYeah I don't think you're still present in the conversation while taking a photo and listening to or reading an explanation of what you're looking at. You might think it's less interruptive than pulling out a phone, but your attention is on the smart glasses. People think they can multi task too. I can see when someone just zones out during a conversation and they don't even realize it. I'm gonna be annoyed when I see you looking at the shit coming out of your glasses. reply dbalatero 3 hours agorootparentprevI appreciate you might find value in these things, but each example I read just gets less and less compelling. Translation does seem mildly useful, the other things feels like information I can live with or without. E.g. these aren't burning problems in my life. Even the translation, I'm happy to just be in the dark, or take a phone pic and translate if I really really need to. Having everpresent AI tech on my face doesn't seem worth it if these are the kinds of problems I get solved. reply ryandrake 2 hours agorootparentprevMy problem with all three of these features (besides the terrible privacy impact that other commenters have already addressed) is: As the end user, how do you know and verify the results are actually correct? How do you know the road sign was translated correctly? How do you know that the name of the church was actually correct? How do you know that the estimate given was even close? Your examples were all pretty low-stakes, so I guess \"it doesn't matter if it's correct\" is fine for them. But what if you actually ended up relying on an answer to be correct and it wasn't? Would you independently verify the correctness, or just blindly operate on bad info? reply tpmoney 42 minutes agorootparentHow do you know any information you get from a source that you can’t personally and independently verify is correct? How do we know a tourist guide book is correct? How do we know our language dictionary is correct? You don’t. People will need to learn to what degree they can actually trust a given source of information and decide how much the risk is worth taking. We do this all the time today, and every time new technology comes along there’s always an adjustment period as we sort out the boundaries of trust (see also people driving off roads and into ponds when GPS was new). The danger to me is not that it can be wrong, it’s that people don’t yet understand it can be wrong. That’s not helped by AI boosters trying to use AI in inappropriate ways and situations, but it’s also not helped by AI doomers that treat every failing of the new technology as proof it’s worthless and will never be useful. Both extremes are speed running a “boy who cried wolf” scenario for losing public trust in what they have to say. reply jajko 3 hours agorootparentprevAre those glasses with camera always on sticking it into other people's faces, just like before Google glass had it? That's an idiotic toy to use among other people, and I am keeping things polite here. Unless you ask each of them if its OK they will be recorded and evaluated by Meta company (and who knows who else). Your convenience stops right where rights of me and my family starts. Bring it next to any small kids and expect some well deserved non-nice feedback coming your way. reply paul7986 3 hours agorootparentThe privacy issue in time Im sure Meta and or Apple will figure out (i have some ideas to fix that) .. they need to cause that's half of peoples reaction to them while the other half dont care. I could care less about other people I do not know I am using the glasses to capture my life (not theirs) and for - Sunglasses - To listen to music and take phone calls - To take pics and videos of what Im experiencing in my life not others - To enhance my conversations as pulling out my phone is rude to get the answer in a social conversation .. using my glasses no one has said anything rather thinking it's cool reply vundercind 3 hours agorootparent> The privacy issue in time Im sure Meta and or Apple will figure out (i have some ideas to fix that) .. they need to cause that's half of peoples reaction to them while the other half dont care. They don't need to figure it out, they just have to wait. People holding their camera phones up everywhere and (maybe! You can't know for sure!) recording stuff used to be off-putting in about the same way, but we got over it within a few years. Ditto various other socially-shitty things, like talking on a phone in public or using nearly-invisible earbuds that make it hard for people to tell where your attention is or even notice that it might be somewhere else. I kinda wish we hadn't gotten over those things, but we did, and having watched it happen a few times I'm sure we will again for this. reply boplicity 4 hours agoparentprevThe problem with \"AI\" is that when it is well integrated, and useful, it is often invisible to the user. Many people, for example, benefit from automatic (and instant) transcriptions in live Zoom meetings. This is pretty much complete magic -- and yet, boring. You don't notice it. You focus on the result, which you need, rather than the fact that it's \"AI.\" reply cut3 3 hours agorootparentThis is my current belief as well. Ive designed many features with AI models and it wasn't until we recently branded those features with an AI personified name that users (and wall street) noticed. reply ffsm8 4 hours agoparentprevMaybe this will convince you? https://youtu.be/zvbTDUSz8Cc?si=IdlMNjydYgbZH_6n reply majewsky 3 hours agorootparentSame link without tracking: https://youtu.be/zvbTDUSz8Cc reply jareklupinski 4 hours agorootparentprevmaybe this will finally get people to actually be able to say my name :,) reply candiddevmike 4 hours agoparentprevSounds like a repeat of blockchain hype. Biggest threat here is replacing the cultural zeitgeist of \"let me google that for you\" with \"let me GPT that for you\". reply InDubioProRubio 4 hours agoparentprevChat GPT what should i wear, if i were emperor? \"Most emperors in my stories are going out naked.\" reply bryanlarsen 4 hours agoparentprevThe Ray-Ban Meta glasses seem like they're actually gaining moderately useful abilities. https://www.androidpolice.com/ray-ban-meta-smart-glasses-5-t... Why not highlight those in the ad rather than the useless stuff? reply kraig911 4 hours agoparentprevI feel the ads I've seen are precisely what you say. I will say this though I have a kid on the spectrum and if I could teach her how to integrate her thoughts with the glasses it may help her in social settings. But for others who simply already know I, like you, don't see the value. reply consf 4 hours agoparentprevAI has so much potential, but sometimes the consumer products come across as a bit forced, like they’re still looking for their purpose. Overall, I didn't really like Meta's presentation this year. It felt kind of strange... reply CharlieDigital 4 hours agoprevI work at a startup in the AI space. We've been working with it for over a year now and I'm of the mind that AI, in it's current state, really isn't a tool meant for an end user to interact with. It feels like it's the most useful when it's transparent and you -- as an end user -- don't know that there's an LLM in the process. The best use cases seem to be those that don't require an end consumer to directly interact with an AI, but their journey through some process is assisted by an AI instead. The problem is that a lot of the marketing -- like these examples and Google's very misguided \"Write me a letter\" to an Olympian -- exists because companies keep trying to make \"fetch\" happen; the AI becomes the journey instead of being an assistant in that journey. Amazon's Rufus is a prime example. It's tucked away as a button that one has to activate explicitly. But it would almost be better if it could just clean up the search results when I do a search and a bunch of junk is returned. reply exitb 4 hours agoparentBut it seems like Apple could make \"fetch\" happen in the past. Their ads were very aspirational, almost like you could become an Olympian if you just owned a Macintosh. These ads though, they're not about \"you can do more\". They're about \"you can care less\". reply snovymgodym 8 minutes agorootparentEh, I mean Apple has had its flops over the years like any company. Their ads were good, but all of their successful products were of high quality when evaluated objectively, in addition to having been marketed well. reply pininja 3 hours agorootparentprevThese ads feel like YouTube Short sketches. A little absurd, and a bit of a fantasy land. Would people really interact this way - word for word? I think being aspirational with AI can feel a bit in-humane. A lot of people seeing this experience a bit of cringe when the topic of AI is brought up. Maybe they’re worried about their job, that technology is too pervasive - whatever it is, they’re uncomfortable. It’s an easier pill to swallow if I can laugh at it. Apple seems to be picking up on that in these ads. reply consf 4 hours agorootparentprevIn a way ads seem to have lost that edge? reply empath75 4 hours agoparentprevThere's basically two places where I see it as being useful -- as part of an automation pipeline where you need some translation layer from natural language to structured data or vice versa, and when the user knows it's an LLM and _wants to interact with an LLM_. I never want to see LLM generated content as an end user when I haven't specifically asked for it. reply CharlieDigital 3 hours agorootparentI agree with those. The use case our startup is working is one more that I think really works well: why are you showing me these results? Our product basically takes any search output and uses our internal knowledge graph for our clients to \"explain\" to the customer \"why these results for this query/question?\" We use the same knowledge graph to then extend our client's native search results with much more relevant results using the LLM to better match results to the semantic intent of the question. It's all quite nifty and transparent; the user wouldn't know that there's an AI involved without labeling it as AI generated. reply candiddevmike 4 hours agoparentprevI absolutely despise rufus. I used to be able to search questions and reviews instantaneously. Now I need to wait for rufus to poorly summarize everything, tap at least 2-3 times, and then get to see the search results. Talk about piss poor UX. reply lubujackson 4 hours agorootparentReminds me of Austin Powers where he has a TV in his car in the 70s to talk with his boss then wakes up in modern times (the 90s) and has shitty, fractured streaming video. \"Skating where the puck is going\" is a great strategy for businesses - not so much for end users. reply vundercind 3 hours agorootparentIt's similar to how ~all phone calls sound worse than they used to before the phone system was digitized. For a while, you could only get audio quality and delay that bad by using a cell phone (actually, those went through a couple phases of differently-bad audio quality, as the tech \"advanced\")! Then they brought that joyful new experience to land line phones, so everyone could have it. It's cheaper, though. I assume. The main effect of which is that it's finally cheap enough to be economical to phone-spam our grandparents and scam them out of their savings... hm, yeah, never mind, it's all down-side. reply consf 4 hours agoparentprevI think a good marketing move is showcasing the seamlessness of artificial intelligence. For some reason, AI is being stigmatized reply CharlieDigital 4 hours agorootparentYeah, a really basic and relevant example might be if I have a meeting coming up on my calendar, an agent can pull info from my LinkedIn about the participants, check their socials (so I can make small talk and chat), research info about some of the topics in the meeting (e.g. pull stats, recent articles, etc.) and summarize it to prepare me for the meeting. Like, that's actually useful but probably not super sexy. reply Ensorceled 3 hours agorootparentThis is a good example of where we should have stigma attached to AI: a partner showed me their CRM that summarized my profile for them. It was creepy in how far into my online life it had dug. It also said, along with the creepy things, that I was \"risk adverse\" and \"only acted when I had complete information\" ... as a startup CTO this is both laughably wrong and could have career implications. reply CharlieDigital 3 hours agorootparentLLM's can be tuned to do what you want it to do. It can be as simple as \"summarize these notes\" to as questionable as \"rate this candidate for this job\". The former is mostly just a reduction in task and condensation of information. The latter is the opposite: an extrapolation of some conclusion based on given information. This is not the fault of an LLM, but the people using it and the use cases that have been designed. An AI assistant that just gave me the facts (condense) rather than generate its own conclusions (expand, extrapolate) is fine, IMO. reply Ensorceled 1 hour agorootparentI get what you are saying but, the same way ad targeting can be used to \"serve me more interesting ads\" and \"surveillance\" can be used to find missing children and sex trafficing victims, it isn't being used that way across the board. reply dagmx 4 hours agoprevThis article is a prime example of why tech literate people aren’t inherently strong marketers for tech. What does the Ubuntu ad say to the user? How does it capture someone’s attention? None of the ad tells me why this is something worth paying attention to versus other distros or OSs, it doesn’t even tell me it’s about the OS at all unless I already know what Ubuntu is. Contrast with the Apple ads that tell you exactly what they want in the same time frame. Apple ads have always been tongue in cheek, and have always had a portion of people rubbed the wrong way because they took it too literally. But at the end of the day, barring the few missteps like the crush ad, they seem to work for the target audience. I find a lot of technical folk seem to struggle with “I don’t like it therefore it must be bad” and would have failed basically any media analysis class in college as a result. Similarly, the author falls into the “I like Ubuntu and this ad” and hasn’t stopped to think about how it plays to anyone but himself. It’s a really self centered outlook and one that means they’d never be able to market to others. reply bee_rider 4 hours agoparentI remember iPods being advertised as, like, very cool. Remember all the ads with, like, the silhouettes dancing on colorful backgrounds? I can see thinking these ads were a bit over the top and silly, like a corporate ad exec’s idea of what is cool, but they definitely intended to be cool. The people in these new ads are lame and clearly Apple intends to portray them as lame. reply dagmx 4 hours agorootparentApple have a range of ads to appeal to a range of people. Even back then they had the Mac vs PC or a variety of other ads too that weren’t “cool” but were funny. Tongue in cheek ads have been in their DNA since forever. Take for example the new Mac mini ad which is cute https://youtu.be/JjpGvjy0Gxk?si=Gk1cU80FiJX2KYbC Or just scrolling through their YouTube channel now to find a few over the years Find your Friends https://youtu.be/yk6UVnMn9ts?si=UIqblUwbbONPFyRR The Greatest https://youtu.be/8sX9IEHWRJ8?si=NhRVcMZyOlU7-PfC HomePod ( probably my favorite of the bunch. Directed by Spike Jonze, starring FKA Twigs. Imho one of the best ads they’ve done) https://youtu.be/k70OczvX45k?si=4cKP63L4UwdP1vaW AirPod pros https://youtu.be/DpcXUXtZ4CU?si=AqWofXEOu7ejTCA0 One could argue that they’ve not had anything as iconic as the silhouette commercial. I’d agree with that, but I disagree with the position that their ads today don’t show cool people or that ads back then didn’t show “lame” people. reply bee_rider 2 hours agorootparentEh, but even in the Find Your Friends ad, where the guy is pretty nerdy and not conventionally cool (I mean he’s going to some cosplay festival), it is still portraying the main character as kind of… somebody you wouldn’t mind being, right? Like he’s doing something nerdy, dressing up in cosplay, but he’s doing it well, he’s got friends, businessmen get out of his way as he strides down the sidewalk. Some of the people he interact with don’t get him, but he doesn’t care. He’s nerdy but he’s living his best life. The Mac Mini ad is cute, and it portrays the Mac Mini as a sort of… little computer with over-the-top bravado. It is sort of self-effacing and tongue in cheek, like clearly the little computer is over-compensating for its small size with attitude. But it works somehow. Partly because it is the device, I think. I’m not imagining being the computer, I’m imagining being the user, so the over-eager awkwardness of the computer doesn’t reflect poorly on the “me” character. Partly I think because the computer is like… awkward but not unpleasant. There’s a big difference between being nerdy/awkward but embracing it, and being nerdy/awkward and a loser. Some of these new ads look more like the latter to me. The Bella Ramsey ones, IMO, they are not so bad, like she’s doing a “forgetful/absent minded but still successful” character and it kinda works. But one with the guy who can’t write a professional email and the lady who forgot a gift but wants to sneak into the nice moment, they didn’t work for me. You don’t want to be those characters, right? reply dagmx 27 minutes agorootparentCoolness is about being comfortable and confident being yourself these days. Not just outward shows of “coolness” That’s apples brand and has always been. It’s the “you’re weird, you’re quirky, you’re different, you’re you” of being cool, not the jock/rockstar cool. The iPod commercials just happened to illicit both. But look at most Apple ads through the years and they have a consistent corporate theme. That’s what is cool. Being confident to meet your friends at a convention in costume is cool. Idk who said it, but it’s the “personal computer”. The person is key. reply nordsieck 4 hours agoparentprev> What does the Ubuntu ad say to the user? How does it capture someone’s attention? Exactly. Contrary to the article, it doesn't tell a story at all. It's just some slick-ish graphics with a few words overlayed on top. They're nice words. But they didn't really embrace \"show, don't tell\". reply iamtheworstdev 2 hours agorootparenti have no idea what the ubuntu ad is trying to tell me, but OPs points on the Apple ads still seem pretty relevant. reply makeitdouble 3 hours agoparentprev> it doesn’t even tell me it’s about the OS at all unless I already know what Ubuntu is. Try watching the iPhone ads assuming you don't know what Apple does nor what an iPhone is. They make absolutely no sense. Ads are targeted at a market, and these in particular assume some degree of familiarity. I guess the Ubuntu one in particular is to celebrate the 20 years, so it's a different vibe from a sheer call to action spot. reply dagmx 3 hours agorootparentWhich iPhone ad can you point me to that doesn’t have a story around a feature at the least? Also since you bring up familiarity, does that Ubuntu ad tell you which version it’s about? What’s it telling even a seasoned Ubuntu veteran? And lastly, there’s a much larger percent of the population that knows what an iPhone is but even if they didn’t, it’s in the name. The ads end with iPhone, by Apple and show the product. Based on that ad, what is Ubuntu? A desktop? An OS? A computer company? reply makeitdouble 2 hours agorootparentIf you don't know what an iPhone is, what Siri is, this ad spot's is this girl asking on the phone for someone's name and faking remembering the guy: https://www.youtube.com/watch?v=TPe8revsg3k Is that a story or one single scene ? Was there someone on the phone ? Is the text bubble that person answering ? or is it just movie magic like so many over ads? It only makes sense as an ad if you know the product, otherwise you wouldn't even understand it's the phone doing it all. We're in agreement that the Ubuntu movie isn't selling it either. My point was that it's probably not aimed at that, you aren't suppose to rush to Ubuntu's site to download an ISO on the spot after watching it, it's probably more of a branding act than a push to action. Precisely to seed the Ubuntu name perhaps ? reply dagmx 31 minutes agorootparentThe story is you ask your phone and it tells you. The rest of the details are irrelevant to it. You don’t need to know how it happens. And that’s fair about the Ubuntu ad. I think the issue is the Ubuntu ad isn’t trying to be anything much. But the author has positioned it on a podium against the Apple ads where it doesn’t belong. They’re not trying to do the same thing at all, and so framing them that way isn’t fair to Ubuntu reply boogieknite 2 hours agoparentprevI've learned not to trust my taste in marketing for the same point you make in your first sentence. While watching those ads i considered a kids perspective. It bugs bunny looney tunes stuff. Its silly, cartoonish, and sticky. Its a very good ad. Side-point: imagine if this clearly cartoonish ad did encourage \"cheating at life\". whats the downside? Those people are still putting in as much effort as they would have regardless. only now maybe they have read an example of a good email or a summary which could encourage them to learn more later. or maybe its just fun having a world where lazy people are trying to skate by a la The Dude reply taikahessu 3 hours agoparentprevYeah, I think the Apple ads also reveal changes in the meta level of human communication. You cannot know for certain, that the other person is \"being real\", if that makes sense. That Ubuntu commercial left me with a weird akwardness, not knowing what or who it was for. It said \"For you\", which was the best part and I think it means I am in control of things, but that message might be lost with everybody not familiar with IT/Linux/Open Source. I don't know what certificates it was talking about though. reply thrwaway1985882 4 hours agoprev> I’ve watched that little animation several times, and they tell a better story in a minute twenty-five than all of Apple’s AI commercials combined. If I showed that video to someone who isn't steeped in decades of Linux, I suspect they'd ask me what an Ubuntu is. As compared to the \"schlub writes an email\" video, which was compelling, funny, and actually shows the product they're marketing. reply BugsJustFindMe 4 hours agoparent> As compared to the \"schlub writes an email\" video, which was compelling, funny OP is right, though. What you're calling \"compelling\" and \"funny\" seems very much also like messages telling you to that it's ok to lie to everyone around you including your family and friends. That's not a funny message to me. It's an appalling one. reply stackghost 4 hours agorootparentAbsolutely nobody is going to see these ads and to \"Ah, well, now that I have seen this ad I will start lying\". That person is already lying about stuff. We've all done it. I think the real indictment against Apple (and AI more broadly) is that this is the best use case for their supposedly revolutionary technology that they could come up with. reply Thorrez 3 hours agorootparentI don't want to interact with people who lie. I don't want to interact with people who say lying is a good thing. Apple is saying lying is a good thing (\"genius\") in some of these ads. reply addicted 4 hours agorootparentprev> Absolutely nobody is going to see these ads and to \"Ah, well, now that I have seen this ad I will start lying\". I don’t think anyone is claiming these ads will get people to start lying. The claim is that lying to your loved ones is good and makes you smart is indeed the message these ads are sending. People do lie. But they don’t usually feel good about it. These ads send the message that not only is that good, but Apple Intelligence will make you even better at lying. It’s just a bad message. reply InDubioProRubio 4 hours agorootparentprevLoneliness is the product that creates more markets to fill the void. reply michaelt 3 hours agorootparentprev> What you're calling \"compelling\" and \"funny\" seems very much also like messages telling you to that it's ok to lie to everyone around you including your family and friends. Eh, \"lovable but lazy dumbass forgot something and has to lie their way out of it\" is a pretty standard trope of boomer sitcom humour. Just imagine these ads, but the person using AI was Homer Simpson. reply actionablefiber 3 hours agorootparentA lot of sitcom tropes involve behaviors that are repulsive in real life. reply foobarian 4 hours agoparentprevHeh. That \"little animation\" is so generic, you could have substituted Ubuntu with Windows or MacOS and everything they showed would have been valid. reply vundercind 3 hours agorootparentRight—what \"story\"? \"The appearance of desktop computers has changed over the period of time that Ubuntu has existed\"? What does this thing do for me? Especially, what does it do for me that other platforms don't, or that I might not expect it would do for me? reply Zanfa 4 hours agoparentprevIt was exactly like every other enterprise animated product video. Random words with some electronic music. I was actually expecting \"synergy\" to pop up. reply amatecha 3 hours agorootparentAt least they got one noteworthy \"hit\" on the jargon bingo card: \"performant\" -_- reply mateus1 4 hours agoparentprevThe most annoying part when I worked in marketing was explaining to people that it’s not about the their opinion, it’s about profit. One person’s take is worthless. reply hbn 4 hours agoparentprevIt's funny the video is celebrating 20 years of Ubuntu yet the editing style and music choice feels like it should have been for the 10 year anniversary. Real early-2010s chic. reply windexh8er 4 hours agoparentprevI think the write up seems to bring the indirect point that AI has limited use cases currently. So instead of taking the traditional Apple approach with showcasing the technical aspects of the product (an example being Apple has highlighted photography and video a lot in the last few generations of iPhone), instead Apple falls back on cheeky ads, which to be fair, are also not new to Apple marketing. I do think that Apple's \"white lies\" series of ads are awkward, however. Apple has seemingly paused ads around privacy and security and are now targeting Apple Intelligence - they seem to be somewhat at opposite ends of the target market in a way. It does feel as though Apple is conflicted here and I'm curious to see how it plays out for them. I'm, personally not a fan of the current generation or implementation of AI and do not want to use it. If AI could hook apps for more hands free operations at a deeper level I could see usability improvements for hands free environments which might be nice. Beyond that I really don't want it. reply Alex3917 4 hours agorootparent> I'm, personally not a fan of the current generation or implementation of AI and do not want to use it. Why not? It gives vastly better than human performance across a wide range of problems. Just this morning I asked Chat GPT to find me the smallest set of positive integers whose median is 2 and whose average is 3.75, and it just spit out the correct answer instantly. That would have been an enormous pain in the ass to figure out how to do manually, but instead I got it done while in the middle of packing my kids' lunches for school. reply epcoa 2 hours agorootparent> and it just spit out the correct answer instantly. What did it spit out? Because there is more than one solution (or none, if unhelpfully pedantic). It's certainly possible with practice to quickly mentally figure out that 3.75 * 4 is the least whole multiple, so n = 4. Quick and dirty 2,2 makes a possible median and so 1, 2, 2, 10 and 2,2,2,9 are clearly solutions, since x+y= 15-4 where 02 is not hard to do mentally. I struggle to call this a hard or enormous mental calculation. (Not missing the other solution, just acknowledging it takes an extra step - apparently it is hard for ChatGPT!) 4o actually struggled with keeping a median straight: https://chatgpt.com/share/67225a67-48ec-800f-a581-9651e7f65d... And o1-preview had a very difficult time coming up with all solutions. https://chatgpt.com/share/67225ead-c9bc-800f-bcc1-067aacbf2b... I'm not terribly impressed by that last one especially for nearly 2 minutes of \"thinking\". I also don't love that it keeps saying, set, set... A helpful tutor should at least gently point out these are not strictly sets. There's no solution of a set of positive integers that solves that problem. If your GPT didn't give those 3 solutions right off the bat (I could not get mine to) and clarify they are not formally sets, it is a type of failure. Sure you can argue that a better prompt would improve it, but this is a problem, non experts putting in ill-formed or flawed prompts and not getting useful feedback where an expert human would be more helpful. A good human will tell you it's a multiset and in general there isn't a unique solution so the problem could be phrased better. I asked o1-preview to make the question more rigorous and it came up with \"Find all sets...\". reply tzs 2 hours agorootparentprevIn case anyone is curious how you would solve this manually, here it is. In what follows assume all lists are sorted from low to high. For a list of just one or two integers the median and mean are the same so we can rule those out. For a list of 3 integers the average is their sum divided by 3. But 3 times the average we want (3.75) is 11.25 which is not an integer. That eliminates lists of length 3. On to lists of length 4. In a sorted list of length 4 the median is the average of the middle two numbers. The only pairs of 2 positive integers that average 2 are {2, 2} and {1, 3}. That gives us these templates for possible lists: {a, 1, 3, b} {a, 2, 2, b} Remember, these are sorted and they are positive integers. In the first then the only possible value for a is 1. In the second a could be 1 or 2. Our templates are now {1, 1, 3, b} {1, 2, 2, b} {2, 2, 2, b} For 4 positive integers to have a mean of 3.75 their sum must be 15. Setting b to make the sums 15 we get these as the possible solutions: {1, 1, 3, 10} {1, 2, 2, 10} {2, 2, 2, 9} A quick glance to make sure that the 4th number didn't end up smaller than the 3rd number, and we are done. reply windexh8er 4 hours agorootparentprevBecause, ultimately, I'd like to continue to think and solve on my own. If I want to leverage a chat model, which I do, I can do that very easily on my own hardware. I don't want it so far shoved down my phones innards that I'm paying for hardware that is useless outside that use case. Imagine the next 30 years when the majority of the population has no clue on how to function without cloud connected models answering questions on the daily. Very Black Mirror. I also don't trust any of the frontier model vendors at this point so there's also that. Especially Sam Altman / OpenAI. reply LeafItAlone 3 hours agorootparent>Imagine the next 30 years when the majority of the population has no clue on how to function without cloud connected models answering questions on the daily. The basis of this argument has probably existed for as long as humans have been able to self reflect. If technology can very reliably do something I need to do better than I can do, why would I spend energy doing it myself. reply windexh8er 2 hours agorootparent> If technology can very reliably do something I need to do better than I can do, why would I spend energy doing it myself. In reality, you're spending more energy. That being, yet, another problem with this use case [0]. Also, did it really \"do it better\"? Maybe it did it better than OP could, by their own admission. But they didn't learn anything in the process nor did they seem to consider the validity. Will it be right next time? How does one know? As indicated above - it doesn't appear to be a stretch that it could have just as easily given the wrong answer. [1] \"In an age of information, ignorance is a choice.\" — Donny Miller [0] https://www.energypolicy.columbia.edu/projecting-the-electri... [1] https://news.ycombinator.com/item?id=41997498 reply CaptainFever 3 hours agorootparentprevRelated quote: \"They will cease to exercise memory because they rely on that which is written, calling things to remembrance no longer from within themselves, but by means of external marks.\" - Plato https://fs.blog/an-old-argument-against-writing/ Related blog: https://pessimistsarchive.org/ reply windexh8er 2 hours agorootparentThe irony of Plato's writings on writing shouldn't be lost on you. reply boringg 4 hours agoparentprevCan I just point out the self gazing nature of this post? Short form: I made an Advertisement in AI, I promote it by making shitting all over Apple (get more viewership using Apple) and then finish off to say I watched my own video in amazement 5 times. What a beautiful self promotional world we live in. reply digitalPhonix 3 hours agorootparentI can't tell who you're saying is self promoting? Apple/the team that made the Apple ads or Ubuntu/the team that made the Ubuntu ad? reply CaptainFever 3 hours agorootparentI think: Ubuntu/the team that made the Ubuntu ad. reply tr3ntg 3 hours agoparentprevAgreed. The Ubuntu ad feels like it's written with Apple Intelligence. \"Secure, Certified, Everywhere, For You\" reply ellisv 4 hours agoparentprevI agree. If I showed that video to anyone I don't work with, they'd have no idea what they were watching. reply briandear 4 hours agorootparentI have no idea what they were selling. Are they selling a free operating system? reply repelsteeltje 4 hours agoparentprevIs there somewhere I can watch the Apple ad(s)? I don't understand what or who this schlub is. reply KTibow 4 hours agorootparentAds are linked in the article, I believe the \"schlub\" is shown in https://www.youtube.com/watch?v=3m0MoYKwVTM reply repelsteeltje 4 hours agorootparentYeah. Somehow I get a different ad reply ceejayoz 4 hours agorootparentprevThey're linked in the article. That video specifically: https://www.youtube.com/watch?v=3m0MoYKwVTM reply repelsteeltje 4 hours agorootparentMy bad, it seems YouTube guides me towards other ads. Might be because I'm in eu or not using their app. I managed to find the ad elsewhere reply nicoco 4 hours agorootparentprevThe post contains hyperlinks. reply jangxx 4 hours agorootparentprevThe article has links to all the mentioned videos. reply epcoa 4 hours agoparentprevForget about lying, this is just amorally stupid and pandering. I find the hypothetical universe where that guy is going to get anywhere good suggesting what his boss should “undertake” unbelievable. (Also not a good demo). And we’ve been in this GPT world nearly 2 years. The boss is obviously supposed to be smart, he’s a black guy in a suit after all. Is this the first time he’s ever received something that was obviously from an AI. What’s he confused about? reply ceejayoz 3 hours agorootparent> The boss is obviously supposed to be smart, he’s a black guy in a suit after all. Is this the first time he’s ever received something that was obviously from an AI. What’s he confused about? Ironically, you're doing the same thing as the actor in the skit - pretending to be confused, for effect. Obviously, the boss is used to receiving unprofessional responses from the employee in question. Obviously, the boss is thrown as a result. Obviously, this is a contrived situation for the purpose of humor that in real life wouldn't go like this. reply epcoa 2 hours agorootparentThe idea that a shlub like this would only just now for the first time be using an LLM like this is what is unbelievable. And as a joke it is simply stale. I get it, Apple has to at least pretend to themselves like they are groundbreaking in these things that are now years old. It's cringe because Apple thinks this is a novel premise for humor. reply ceejayoz 1 hour agorootparent> The idea that a shlub like this would only just now for the first time be using an LLM like this is what is unbelievable. It's unbelievable that someone would use a brand-new feature on their device for the first time? reply epcoa 1 hour agorootparentAgain: It's unbelievable that someone (like this) would be using an LLM to compose an email to their boss for the first time. He's a lazy fuck office stiff (yet still manages to warrant an iMac desktop), you're telling me he's just now starting to use an LLM to compose emails? Sure, whatever. If you think this ad is clever and funny you are entitled to that, you're not going to convince me it isn't idiotic and the joke is old. Unless the message was Apple AI: the new thing for oblivious dipshits or the recently recovered comatose. Their ad agency should know better too: https://www.cnbc.com/2024/08/02/google-pulls-ai-ad-for-olymp... Even the bastion of pretentious journalism Fast Company has this headline: \"In Apple’s new ads for AI tools, we’re all total idiots\" > Ironically, you're doing the same thing as the actor in the skit - pretending to be confused, for effect. If you're intuitive enough to conclude that an otherwise inarticulate douchebag probably used an LLM to compose an email, why would you \"pretend\" to be confused? Makes no sense. There's nothing remarkable about using an LLM to write an email. reply ceejayoz 35 minutes agorootparent> Again: It's unbelievable that someone (like this) would be using an LLM to compose an email to their boss for the first time. There's always a first time. > He's a lazy fuck office stiff (yet still manages to warrant an iMac desktop), you're telling me he's just now starting to use an LLM to compose emails? I know plenty of \"lazy fuck\" people not yet using LLMs. Having it built in to the device is likely to change that. > Even the bastion of pretentious journalism Fast Company has this headline: \"In Apple’s new ads for AI tools, we’re all total idiots\" That's fairly standard for ads. Cleaning supplies are sold on a \"so easy dads can use it\" sort of basis. Prepared food is sold on a \"because you can't cook, obviously\" basis. etc. I have managers at work who ask me to write client emails for them, even, because I'm a pretty good writer. > If you're intuitive enough to conclude that an otherwise inarticulate douchebag probably used an LLM to compose an email, why would you \"pretend\" to be confused? The actor is pretending. The character is shocked - for comic effect - that such a nice email came from someone who never sends professional ones. In the real world the response is obviously more likely to be \"ah, they used ChatGPT this time\", but if you expect realism in ads... This really isn't as complicated to understand as you're making it. reply epcoa 8 minutes agorootparent> This really isn't as complicated to understand as you're making it. https://www.youtube.com/shorts/vGAVcSjqMps This is just running defense for the reality distortion field. > I know plenty of \"lazy fuck\" people not yet using LLMs. Having it built in to the device is likely to change that. Sorry I just don't live in this world. Everybody and their dog uses LLM. Especially the crowd affluent enough to afford Apple devices. The untapped market here is tiny. I use an iPhone, a MacBook, I use a HomePod as part of a home automation system. I'm not an anti Apple fanboy. This shit is completely stupid and underwhelming. > That's fairly standard for ads. Now you're just being a condescending prat. I don't need a lesson in the obvious. I told you it's stupid for specific reasons that you simply care to not acknowledge, fine. Think whatever you want. kraig911 4 hours agoparentprevI just get a sense from all this AI marketing hype is that AI is yet another grifter tool. The Ubuntu video was meh and I dont think it worked well to describe the story. A better video would be to show perhaps someone getting their kid an ubuntu laptop and how it shaped their mindset and future. Or Ubuntu on your grandma's computer and now we can enjoy coffee instead of fixing computers... etc etc. reply jasonlotito 4 hours agoparentprev> If I showed that video to someone who isn't ...the target audience, it wouldn't work. Same with the AI stuff. Show that to someone with no understanding of Apple and it's products, or AI, and you'll have someone equally confused. The understanding here is that in both cases the marketing is targeted at a certain group. More interestingly, you admit that one story promotes interest in the product, while the other promotes the viewer being, as you put it, a schlub. Maybe you can explain why you being a schlub is better than wanting to learn more about a product (or how quickly you try to pretend like that's not what you mean/said and move the goal post, lol)? reply thrwaway1985882 4 hours agorootparent> Show that to someone with no understanding of Apple and it's products, or AI, and you'll have someone equally confused. Apple is selling a magical button that unprofessional idiots can press to be perceived as professional. Who in the world is going to be confused by that? reply Apreche 4 hours agoprevI was already bothered by the Apple Watch marketing. The messaging there is total fear. Buy an Apple Watch or literally die. Also, get them for your children or they will die too. The messaging that AI is for lying is another big yikes. Apple marketing department has lost the magic. reply CubsFan1060 4 hours agoparentAs someone whose watch called 911 for me when I was in an accident, and who got a call when my mother fell, fear or not there are real, tangible benefits that probably can't be overstated. reply jonah 4 hours agorootparentI just wish they would cut down on false positives though. As a volunteer firefighter, I don't think I've responded to an \"Apple Crash Detection\" that was an actual car crash or fall or something... After a while it feels like crying wolf... reply makeitdouble 4 hours agorootparentprevThey could go the same way some insurances do it, with a very positive imagery through and through and only ever indirectly implying the \"or else\" reply _fat_santa 4 hours agoparentprevTo be fair, since the Apple Watch introduced heart rate monitoring and other \"medical\" features, there have been numerous reported cases of it saving a persons life, from detecting heart conditions to detecting falls. reply moooo99 4 hours agorootparentYeah that is true, but also not sufficient data to indicate that the Apple Watch actually net saves lives. On the other side of the coin of more widespread and continuous monitoring is always the concerns of increasing false positives reply danaris 3 hours agorootparentWhat do you mean by \"net\"? Are you suggesting that the Apple Watch actually causes people's deaths, too—in numbers large enough to counterbalance the lives it's saved? reply vundercind 2 hours agoparentprevApple's ecosystem is all about replacing other products, devices, and services with features of Apple devices. See: all those photos of \"here's all the devices an iPhone replaces\" from like 15 years ago. I'm not sure how else they advertise that now your Apple devices replace OnStar and Life Alert, than advertising kinda the same way that those did (but less lame, hopefully). reply ziddoap 4 hours agoparentprev>The messaging there is total fear. Buy an Apple Watch or literally die. Also, get them for your children or they will die too. Is there a specific advertisement you're referring to here, or just all apple watch advertisements? I haven't really seen any ads for the apple watch, and I am curious if this is an exaggeration. I'm assuming by \"literally\" you meant \"metaphorically\", but I'd like to look up which ad you are referencing to get an idea of what you mean. Edit: I've watched the ads. They are not in great taste, in my opinion, however they also did not tell me I would literally die if I don't buy an Apple Watch. reply DHPersonal 4 hours agorootparentThis is the kind of ad people take issue with. https://www.youtube.com/watch?v=XRwkZWowI8o / https://www.youtube.com/watch?v=0k4VVgmuNvU / https://www.youtube.com/watch?v=dD0rUo1wZds Or a similar crash detection feature in iPhone: https://www.youtube.com/watch?v=JWBFF9R3VmU / https://www.youtube.com/watch?v=HsAL36M8bwE reply wasabi991011 4 hours agorootparentprevI think they are referring to the \"Apple Watch Series 7 911 ad\". I think they are correct in their use of \"literally\". reply sickofparadox 4 hours agorootparentprevI believe this is the ad being described by GP: https://www.youtube.com/watch?v=XRwkZWowI8o reply DHPersonal 4 hours agoparentprevI remember people expressing similar frustrations with the crash detection features on iPhones, and I still don't understand the issue. These new safety features are helpful and have helped save lives. Scaling back the ad copy to \"maybe you'd want to use this, just in case, though it's not a guarantee of anything, so whatever,\" as it seems the complaints are indicating, is not how any other life-saving features on any device have ever been sold. Those old LifeAlert \"I've fallen and I can't get up\" commercials didn't pull their punch and say \"Eh, maybe you'll want this for your grandparent.\" reply bschwindHN 3 hours agorootparentI dunno, those life alert ads gave me the impression that they might not care https://youtu.be/8C4Sb9TpfM4?si=39Os2aBHL1mpSygy reply jollyllama 4 hours agorootparentprevContrast with old OnStar commercials would be more fruitful. reply neilv 3 hours agoprevThe consumer use cases of \"AI\" right now are mostly about cheating at work that one is still really supposed to do themselves. Maybe the ad people tried to come up with relatively palatable ones? Note that no one is cheating on their school homework, which is a huge consumer use case category. And no creative work was detectably plagiarized (art, code). Though they still did do employment slacking/incompetence gaining advantage, by increasing deceptive and time-wasting noise for everyone else. Or maybe that's the actual use cases of their target audience? reply knallfrosch 4 hours agoprevThe blog entry suffers from congratulating the mediocre Ubuntu ad, but it's right about the vile Apple ads. The Apple ads are dystopian and revulsive. She really pulls out her phone while talking to a person and then lies to her face. A wife and mother forgets dad's birthday and smugly \"gifts\" him 50 auto-playing photos, as shown on her phone screen? reply throwaway106382 3 hours agoparentUbuntu nothwistanding, I found the Apple ads quite offensive. Ads tell you what the company thinks about it's target audience and clearly Apple thinks we're all just a bunch of bumbling fools that can't do anything without our phones. Compared to this Samsung Galaxy S24 FE, which frames everything as something that can help you out and is fun and quirky: https://youtu.be/GZ-xGBTvtO4 I've been using Mac as my workhorse my entire career, switched from Android to iPhone recently. These ads are actually making me reconsider what my next hardware upgrades are going to be. reply cmiller1 3 hours agorootparent> Apple thinks we're all just a bunch of bumbling fool He's out of line, but he's right. reply throwaway106382 2 hours agorootparentI'm fully aware that Apple has always targeted people who are less tech literate, but this is just another level. reply ahstilde 4 hours agoprevIf you think the Ubuntu ad is telling a story, I'd ask you what the story is. reply jfoster 4 hours agoparentIt's just a very standard ad. A lot better than these horrible ads from Apple, though. reply hbn 3 hours agorootparentIt doesn't even give a hint as to what it's an ad for. You could not air that on TV and expect anyone who didn't already know of/use Ubuntu to know what it's advertising. Something about a computer, and there's privacy? You think \"certified\" means anything to anyone outside of tech circles? reply briandear 4 hours agoparentprevWhat is it selling? And where do you buy it? It’s a terrible ad. reply tr3ntg 4 hours agoprevThe really funny thing about the \"lies about birthday present\" one is that the wife asks the AI to make a Woodworking Memory Video, and while they're watching it, it looks like a beach vacation photo is included in the mix. For a second I forgot where I was, and thought she'd be found out, then remembered it's an ad, and everyone is impressed. Maybe the image is actually related to the woodworking? But I couldn't help but think, \"that's about right - a random, ill-fitting photo\" reply Suppafly 3 hours agoparent>the wife asks the AI to make a Woodworking Memory Video, and while they're watching it, it looks like a beach vacation photo is included in the mix What's funny is that google photos sorta makes these sort of random little videos all the time for you and asks if you want to see them. It also suffers from the issue of not really understanding the context from some of the pictures it pulls in. But this is a thing that's been around for a few years, like a lot of things, apple is late to the game but pretending they invented it. reply eddd-ddde 2 hours agorootparentI love google photos little albums and creations. I am the kind of person that almost nevers looks at pictures on their own, so when I get a google photos notifications I always get watch them and get to remember cool memories. reply Suppafly 50 minutes agorootparentyeah I like them, it's just weird what they pull in sometimes. the ones with my kids often seem to always include the same pictures too, so I always end up seeing this one specific one of my son in basically every slideshow. I wonder if it meets some criteria for being colorful or something. reply tw04 4 hours agoprevI’m not sure if the author noticed, but the intent of the commercials is to be humorous. If the image of a middle aged man writing an email like he’s in middle school didn’t tip the author off, I’m not sure what will. reply jawilson2 4 hours agoparentIt's like the Google Pixel ads showing how you can take a picture, and change all of the scenery with AI. Nothing is real, and you can't trust anything you see or hear. I would be pretty disappointed in my wife if she A) forgot my birthday, and B) spent 10 seconds putting together a photo collage using AI. I would expect her to feel the same. Personal and financial circumstances aside, it IS the thought that counts, and all of these ads seem to be saying it is fine to offload thinking to your trusty AI companion. It's not really humorous, it is dystopian. Also, those ads showing different AIs acting like HAL but saying \"the future doesn't have to be scary\" are terrifying. In one the woman is locked in her house by her AI-bot, and uses a menacing tone, doesn't let her leave until she grabs her water bottle. In another, a man is in a self-driving car, which changes routes and takes him to a surprise birthday party. It is NOT a leap to go from these to hearing actual cases where \"woman is trapped in her apartment and dies in a fire because the AI wouldn't unlock her door (or AI died first in the fire)\", or \"self-driving Tesla is hacked by the cartel/abusive ex and drives passenger to their death.\" I want NO part of the future they are selling. reply HumblyTossed 4 hours agorootparentI would rather my SO just tell me they forgot. Then we could have an honest conversation about why. That, I believe, is what you should do in a marriage. reply boogieknite 39 minutes agorootparentIn my marriage i have been slowly trying to move my birthday back one day at a time. After 3 years of effort ive successfully moved it back 1 day and my spouse still gets confused if its 1 or 2 days later, all due to my active efforts. I dont believe anyone should do this in a marriage, but they could! reply moralestapia 3 hours agorootparentprev>Then we could have an honest conversation about why. It doesn't even need to be a conversation. Humans forget things. \"Oh damn, I forgot! Let's grab dinner tonight!\" or w/e, that's all people need. reply HumblyTossed 2 hours agorootparentI don't disagree, but sometimes there could be something else going on. reply yalogin 4 hours agorootparentprevI think society will take care of those dystopian feelings in time through non-tech means. Society will always adapt and people can clearly tell a gift or message that is made using AI. So if you want it to be thoughtful you will make it without AI. We are in the cusp of the next phase of growth and so we are seeing/feeling it, but in time it will become seamless reply pmontra 4 hours agorootparentprevOn the other side it's a good thing that there are ads teaching people that they can't trust anything they receive on their phone, because we can really receive fake images, videos, conversations. reply Suppafly 3 hours agorootparentprev>I want NO part of the future they are selling. Most AI in a nutshell right now. reply moralestapia 3 hours agorootparentprev(On the ad) The face she makes when walking away from her family ... imagine being married to that. reply HumblyTossed 4 hours agoparentprev> I’m not sure if the author noticed, but the intent of the commercials is to be humorous. The birthday one was in no way meant to be humorous. reply ceejayoz 4 hours agorootparentIt absolutely was. May have missed the mark for many, but the scenario depicted is certainly intended to be funny. \"Oh shit, we said no presents but the kids did some!\" reply rob74 4 hours agorootparentprevNot sure if it's not meant to be humorous - at least it uses (and reverses) several well-known tropes: - \"we said no gifts\" - right... so you're the only one who actually followed that? Well, bad luck! - usually it's the husband forgetting the wife's birthday, not the other way around. - ...and finally, I'd like to quote Jesus himself: \"He who is without sin can cast the first stone\" - this ad (and the others) show situations most of us have been in, so they're at least relatable. reply lm28469 4 hours agoparentprevIs that because \"AI\" use cases are a joke ? reply qsort 4 hours agoparentprevI don't think the problem is with the tone, but rather with the messaging. All AI-related marketing has been along the lines of \"let the computer think for you\" rather than \"use the computer to think better\", infantilizing rather than empowering the user. From the bicycle of the mind to the tricycle of the mind. reply tonyedgecombe 4 hours agorootparentSadly that's what most users expect. They don't want to be bothered with learning and understanding, they just want a quick result now with as little effort as possible. reply skydhash 4 hours agorootparentprevs/tricycle/wheelchair/ reply ucosty 4 hours agorootparentMore like one of those hover chairs from Wall-E reply devmor 4 hours agoparentprevI didn’t think they were humorous. If that was the intention, I question the moral baseline of those who wrote them and those that find them funny. To me they looked bleak, depressing and evocative of a culture that views giving respect to other people as an annoyance that needs an app to make it go away. reply 10729287 4 hours agorootparentMe neither. And it will be funny for some until it's not anymore. I don't like how those, for now, useful ai tools, will dissposses us from our creativity and ability to make things by ourself in the future. It will be fast and hit hard. reply kylebenzle 4 hours agoparentprevI think the author is trying to discuss how common lying has become. How it seems like nobody is expected to be honest anymore and everybody's just getting away with whatever they can get away with. How narcissism is an American disease and it's spreading fast do to companies like Apple, Facebook and online dating learning how to profit off it. reply switch007 4 hours agorootparentRight! It's one thing to accept marketing teams lying about their products, but now they are promoting lying! reply troyvit 4 hours agorootparentprevI think you nailed it. And coming from Apple, the company that established its cred by touting creativity, individuality, and innovating, it's a wild shift. Apple in 1997 [1]: \"Here’s to the crazy ones. The misfits. The rebels. The troublemakers. The round pegs in the square holes. The ones who see things differently. They’re not fond of rules. And they have no respect for the status quo. You can quote them, disagree with them, glorify or vilify them. About the only thing you can’t do is ignore them. Because they change things. They push the human race forward. And while some may see them as the crazy ones, we see genius. Because the people who are crazy enough to think they can change the world, are the ones who do.\" Apple today: \"Very Victorian, which I loved.\" [1] https://thebrandhopper.com/2023/08/20/apple-top-commercials-... reply tomfly 4 hours agorootparentprevHow is narcissism an American disease? reply lm28469 4 hours agorootparenthttps://www.bloomberg.com/news/articles/2015-12-11/study-the... I think the only way to not be aware of this trend is to be american reply kylebenzle 3 hours agorootparentThank you for this article, many of us American's see it too! reply dingnuts 4 hours agorootparentprevany universally appearing personality trait can be attributed to a whole nation with one easy trick: racism! reply raverbashing 4 hours agoparentprevCorrect I wonder how much of (people self diagnosing themselves with) autism is actually related to other circumstances like lack of media literacy, lack of familiarity with social circles/norms (or lack of cultural knowledge) The Ubuntu ad is not bad certainly but it is meh, and where it lacks is where it goes on the tech mode. reply abalone 4 hours agoprevHe had my attention until he posted that mind-numbingly generic Ubuntu ad. Most people would tune that out in seconds. I’m kind of glad Apple is putting a touch more flavor in their ads. reply illwrks 4 hours agoprevAppple are speaking to the “Everyman”, Canonical are speaking to the tech literate. Different audiences, Apple has power users, but its largest audience is an average person (my wife for example). The average person doesn’t care about tech, they want it to work, work well enough and be dependable. Linux is can be a minefield, and Windows is a mess IMO. reply ellisv 4 hours agoparentApple also shows while Canonical tells. The average person doesn't care about an animation of a terminal or a chip with 3d composited \"Performant\" or \"Secure\" text. They care about \"what can this thing do\". reply AlexandrB 4 hours agorootparentThe Ubuntu ad could also have been for any version of Ubuntu since 14.04, or maybe even earlier. There's nothing that distinguishes 24.04 in there from what I can tell. reply eddd-ddde 2 hours agorootparentClearly you missed the change to the background image then. reply throwaway106382 3 hours agoparentprevApple's ads tell you what they think their target audience is, clearly they think it's \"bumbling fool that can't do anything right\". reply illwrks 33 minutes agorootparentYou’re simplifying it a bit, but versions of that framing and mindset have brought user interfaces and interactions into existence. reply preinheimer 4 hours agoparentprevI'd really like to hold onto the belief that \"make lying easier\" doesn't speak to the everyman for just a little bit longer please. reply the_other 3 hours agorootparentLying can be seen as a sign of intelligence. Are you saying you hope “everyman” stays dumb? I’m just being provocative to highlight this is a subtle issue. I agree with the general sentiment that Apple shouldn’t be encouraging ppl to lie. I found the actress kying to her colleague one quite tasteless. That said, this all sums up how I feel about generative AI at the moment: a solution looking for a problem. reply AlexandrB 4 hours agoprev> lie about remembering an acquaintance’s name. That's a heck of a reach. Is it also a lie if I ask my partner what someone's name is when I forget? The email writing one is pretty innocuous as well. Grammarly has been running basically the same ad for the last 5 years. I agree the others are not so great. reply jsnell 4 hours agoparentAsking about someone's name is isn't the lie. Bragging to them about how you remembered their name is. And the latter is the scenario in this ad: > 0:16 Bella: Zac! > 0:17 Zac: Oh wow, I didn't think you'd remember me. > 0:19 Bella: Yeah of course, as soon a I saw you I'm like, it's Zac, nobody walks like Zac. reply crowcroft 4 hours agoprevThe Ubuntu animation tells me nothing a short bullet point list couldn't. If you're going to create a video, show me something. Don't just tell Ubuntu is secure and put little boxes around a few icons – show me that Ubuntu is secure. I don't love the Apple ads, but they are at least showing me some evidence of the features they're saying exist in Apple Intelligence. reply cjpearson 4 hours agoparentThe comparison is a great example of the \"show don't tell\" cliche that English teachers love. reply sourcepluck 2 hours agoprevAhh. \"Gross\", meaning, the author thinks they should do a better job selling their products from a practical standpoint. At a push, if we wanted to try maintain a more essential meaning of \"gross\", I guess we could imagine that the author is saying that not doing an optimal job of selling your products is morally repugnant to them. Maybe that's true, I suppose. An example of Apple actually being gross in their marketing is using the word \"privacy\" to mislead people into thinking they have privacy when they use Apple's devices. It's security they are attempting to offer to users, not privacy. This intentional and somewhat subtle conflation of two terms in order to give people a false impression of Apple products is, in my opinion, properly gross. reply longtimelistnr 4 hours agoprevI think people still aren't accepting that Steve Jobs era marketing and product development left with the man. Apple is fundamentally different and is never going back. reply bigstrat2003 4 hours agoparentMarketing yes, product development no. Jobs was a salesman, not an engineer or designer. He didn't contribute to the product of Apple despite his reputation for doing so. reply xanderlewis 4 hours agorootparentSteve Jobs didn’t contribute to the product of Apple? Are you sure? reply briandear 4 hours agorootparentprevRidiculous. I worked at Apple and if you have the correct permissions, you can see old Radars that Steve himself wrote and also the comments on them. He was profoundly insightful and absolutely drove product development. An absolute myth that he was just a “salesman.” Many people who comment on Apple have never actually worked there and they think some curated history book tells the real story. Go have a conversation with Eddie Cue or Craig Federighi about Steve. Or even Jony Ive. Perhaps talk to some of the original Lisa and Mac teams. reply edweis 4 hours agoprevIt's the first time I've seen an advertisement for Ubuntu. Are they getting ready to get new users dissatisfied by Apple's AI? reply Mainsail 4 hours agoparentWell, it is the year of Linux on the desktop. reply r3trohack3r 4 hours agorootparentNow that everyone is using laptops, it’s the year of the Linux desktop. The old clunkers under our desks are all Linux. reply FeepingCreature 4 hours agorootparentprevRemarkable then, how that entire advertisement managed to not mention Linux once in its entire 85 seconds of runtime. reply moooo99 4 hours agorootparentThat actually makes a lot of sense. If a companies tries to capture non technical users, telling users what kernel the system you’re trying to sell makes little sense reply amatecha 3 hours agorootparentprevYeh, they don't want to give credit to anyone else, only giving attention to \"Ubuntu\". Even at the end when it says some literal credits, it only cites Ubuntu \"and other open source software\" (which is almost undoubtedly Blender). Another example of Canonical's extractive approach to the Linux ecosystem (IMO). reply transcriptase 4 hours agoprevFedEx should licence their model that’s meant to frustrate users into giving up trying to speak to a human. Earlier it told me that it looked into my parcel tracking details and assured me that it was on schedule for delivery, so it wasn’t able to let me connect to an agent. Except I hadn’t yet given it any tracking number. reply joshdavham 4 hours agoprev> I’ve watched that little [Canonical] animation several times, and they tell a better story in a minute twenty-five than all of Apple’s AI commercials combined. I'm afraid I disagree here. While I do find the Apple ads a tad obnoxious, they speak to the problems of normal people and how Apple Intelligence can directly solve these problems. How many people haven't forgotten a birthday, forgotten someone's name or felt stupid while writing an email? The Canonical animation on the other hand, while cool, doesn't communicate to me that it understands my problems and is going to help me fix them. Here's the full transcript of the Canonical ad: \"Modern, Private, Performant, Secure, Supported, Certified, Everywhere, For Everyone, for You\". This is comparing apples to oranges. reply addicted 4 hours agoprevI’m not so sure about the Canonical ad, but the Apple ones are really bad. I clicked on those thinking that the author may be overstating things but those ads are really really bad. There’s basically 2 messages they’re promoting (the office worker one seems to be promoting a different message from the other 3). The first ad: - You’re a loser and Apple Intelligence will make you look like less of a loser in an email. But also people will look at you, see you as the loser you are, and then immediately be suspicious about that email you sent. The other 3: - Apple Intelligence will make you an even more efficient psychopath and make you great at manipulating loved ones and people who are interested in you. WTF, Apple. The quality of Apple advertising has taken a huge hit over the past decade or so. But these ads go beyond just the anodyne nature of their previous advertising. This stuff is truly deranged. reply LeafItAlone 3 hours agoprevIn other words, Apple’s ads depict what people are actually going to use it for and already do (lie). I guess this is truth in marketing. Contrast that with the Canonical ad provided as an example in the article, which I found a waste of my time and closed it after 30 seconds, having learned nothing and not drawn to use the product. reply gbanfalvi 4 hours agoprevWhat is this \"Ubuntu\" and how can I use it? As a consumer, what does it mean to me that it's \"Certified\"? Certified in what? Apple's ads show you the product, how you can use it and how you and the people around you feel after using it (like you took a sneaky shortcut and happy, respectively). reply alsetmusic 4 hours agoprevI am terrible with names. If I use my phone to remind me the name of a person who I describe to my phone where and when I met a person, I wouldn’t classify that as a lie. This is a stretch. I remember the person. I remember the interaction. I remember where and when we met. I just can’t remember names, even of people who I work with but only bump into sporadically. I call bs. Edit: the ad in question: https://www.youtube.com/watch?v=TPe8revsg3k reply bee_rider 4 hours agoprevI dunno if the birthday video ad is really, like, gross. I guess the main character is sort of dishonest, but it isn’t a huge thing really. It is pretty depressing though. The main character is just kind of tired and sad. reply drcongo 1 hour agoprev> In another the same young woman again uses it to lie about reading an email from a college, to her face If only he'd let Apple Intelligence proof-read his blog post. reply anonzzzies 3 hours agoprevIf it cannot write code, I am not very interested. reply _boffin_ 4 hours agoprevVibing off the name of the post’s title, I think the fact that Apple sends all Siri and Dictation’s transcripts to Apple without the ability to disallow that behavior, even if all processing happens on device kind of sickening. reply luxuryballs 3 hours agoprevI installed 18.1 last night and after finishing waitlist I promptly asked Siri if she could answer questions like chatGPT now, didn’t understand. I said what questions can I ask you then? She said “Ask away!” I asked the difference between watts and volts, “I don’t understand”, she understood nothing, I’m so confused! I was upgrading for these features so now I’m thinking of selling this 16 pro and buying a drum set because my 13 mini was easier to hold and apparently Siri isn’t getting any smarter according a the WSJ article yesterday. reply parpfish 3 hours agoprevi'm surprised he didn't bring up the ad with the parents playing with the new iphone in bed and make comments that their kids overhear and think something sexy is going on. i hate that ad because: a) they're not really even doing sexual innuendo, they're just saying things in a tone of voice that makes you think they're making racy comments b) why are the kids sitting outside the bedroom door listening? do they want to hear their parents doin' it? reply diimdeep 3 hours agoprevHoly Jobs, these Ads as if straight from the Black Mirror episode or that The Circle movie, unreal and sad, to the level of Idiocracy (2006) movie cringe. reply 23B1 4 hours agoprevI don't think this is gross, I think it's hilarious. My phone is supposed to be a heat sink for other people's B.S. reply paul7986 4 hours agoprevGetting tired of being sold what may exist or will exist sometime in the future. How is this legal and now Apple is doing it? How is the fake it before you make it (make the actual product a reality for consumers to consume) strategy legal? This video was posted a month ago even when Apple Intelligence wasnt available at all and in any form https://www.youtube.com/watch?v=TPe8revsg3k . Even present day after it was launched Siri can not do this. Start-ups and other tech companies are doing the whole fake it before you make it so Apple is too. Some recent examples...Open AI demoed and sold if you sign up you might get access to their version of H.E.R. yet Many months later its nowhere to be found yet surely that juiced their revenue. Does it really exist or it was a fake it before you make it demo? Similarly with Musk bringing out those robots implying they were AI driven yet later we learn they weren't. Isnt this all something called false advertising?? reply empath75 4 hours agoprevI agree that the ads miss their mark, and I think a better ad would have instead focused on how it could have _prevented_ the awkward situation to begin with, rather than awkwardly helping you cover it up after the fact. reply bobobob420 4 hours agoprevI agree unlike other commenters here that the apple intelligence ads try too hard to be quirky and appease this weird flavour of incompetence being popular. Theres nothing inspiring or awe inducing about the ad that induces excitement about technology reply hggigg 4 hours agoprevAI is mostly about selling something no one needs to people who don't need it. I think they nailed it there. The Ubuntu ad looks cheap. reply j45 4 hours agoprevWhile this post is about the authors own video being better and less cringe than Apple’s videos, the Apple videos might not be for me, and trying to say Apple’s AI is for everyone, including people who aren’t perfect. The scenarios could have been different or better to me. But maybe I’m not the target audience, and iPhone is the beginner smartphone that almost anyone can use. reply bowsamic 4 hours agoprevI agree those ads are pretty concerning and reinforcing bad human behaviours, but the Ubuntu one shown is boring and vague animations. Hardly a good comparison. Who cares about those? reply jfoster 4 hours agoparentI like Ubuntu but agree that this post would've been better off without the comparison. Let's just ignore it. The Apple Intelligence ads really are sending a terrible message. Humanity needs more honesty, not a higher pile of lies. reply bowsamic 4 hours agorootparentI don't think it will be possible to ignore it, the bad comparison makes the author seem confused and unreliable reply iolo 4 hours agoparentprevI feel there's a lack of respect for the person being interacted with in these ads. They all end too soon to show the consequences of transparent AI use and imply the other character has never heard of AI. More accurate endings would be: - \"I thought we told Warren to stop uploading company emails to chatgpt.\" - \"A photo collage?!, after I spent a week building you that new console table for your birthday.\" reply xanderlewis 4 hours agoparentprevOverly techie people can’t comprehend marketing and think it shouldn’t even exist. Most Linux users probably think advertising should consist of a bulleted list of features and bugs (set in a standard, easy to read font — none of that hipster shit) followed by the price, perhaps conveniently divided by the expected lifetime of the product. reply fazeirony 4 hours agoprevwhen the largest company in the world is telling you that lying is the main sell of AI....i guess lying is the new honesty in 2024? smfh lmfao reply FollowingTheDao 4 hours agoprevThe problem with the ad that no one is touching on is that it makes the consumer look like an idiot or a lazy, disingenuous person. \"You need AI because you are lazy and stupid and do not care about honesty and accountability.\" reply victor106 4 hours agoprev [–] Sorry, but I don’t see them as the author. I love these ads. reply bar000n 4 hours agoparent [–] They are lovely indeed. Apple seems to be big enough to make fun of the AI fiasco. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple's recent AI advertisements have been criticized for portraying AI as a tool for deception or superficial professionalism, which some find unappealing.",
      "The ads have sparked discussions about Apple's vision for AI, suggesting it may not align with consumer expectations or desires.",
      "In contrast, Canonical's brief animation has been praised for effectively conveying a more positive narrative about AI."
    ],
    "commentSummary": [
      "Apple's recent AI advertisements have faced criticism for promoting dishonesty and laziness by depicting users relying on AI for simple tasks, which some find unrelatable and misleading.- Critics argue that these ads convey a negative message by implying that it is acceptable to lie or be lazy, sparking a debate on AI's role in daily life and marketing.- In contrast, an Ubuntu ad has been praised for its storytelling approach, although some consider it generic, highlighting differing opinions on effective marketing strategies for AI technology."
    ],
    "points": 223,
    "commentCount": 231,
    "retryCount": 0,
    "time": 1730295187
  },
  {
    "id": 41990326,
    "title": "Wasmer 5.0",
    "originLink": "https://wasmer.io/posts/introducing-wasmer-v5",
    "originBody": "Products Developers BlogTemplates SDK'S CLI Tools Visual Studio Code Extension 17k Sign in Back to articles Introducing Wasmer 5.0 Today we are presenting the latest stable version of Wasmer: v5.0 with tons of improvements and a better performance overall syrusakbary Syrus Akbary Founder & CEO runtime October 29, 2024 Back to articles We are thrilled to announce the release of Wasmer 5.0, the latest milestone in our journey to make WebAssembly the greatest tool for executing software anywhere. This announcement comes packed with awesome new features: Experimental support for more backends: V8, Wasmi and WAMR iOS support Leaner codebase Enhanced Performance Upgraded Compilers (now using LLVM 18 and latest Cranelift) Do you like the new features? Don't wait and give us a ⭐ on Github! github.com/wasmerio/wasmer Key Highlights New experimental backends Some time ago we asked in Wasmer’s Community which backend would you like to see Wasmer support next. The responses were overwhelming: V8 (the engine behind Google’s Chrome Javascript runtime) was the most voted backend, with 56% of the votes. We learned from the poll results that interpreter support was also a desire from the community. Well, the day has come. We have added support for more backends: V8, Wasmi and also WAMR. All of them are integrated via the Wasm-C-API , as they all share this external interface in common. Thanks to the latest additions, now any interpreter or runtime that supports the Wasm-C-API spec can be easily integrated into Wasmer. We expect that the V8 integration will allow bringing a great debugging experience via the V8 debugger and Chrome Devtools. But not only that, having V8 as a backend also means supporting WebAssembly Exceptions and Garbage Collection under the hood. Stay tuned for more news on this front soon. As of today, Wasmer supports the following backends, so you can run WebAssembly using the Wasmer API in the following contexts: Natively (via Wasmer native compilers) Singlepass (singlepass feature): ideal for blockchains Cranelift (cranelift feature): ideal for development LLVM (llvm feature): ideal for production workloads Browser: the browser’s underlying Wasm engine (web feature) See https://github.com/wasmerio/wasmer-js for more info. JavascriptCore: JavascriptCore engine from Apple. Ideal if you want to use a lightweight and incredibly performant runtime in macOS (jsc feature) V8: Google’s JS V8 engine, ideal if you want to use Wasmer in iOS or Android (v8 feature) Wasmi: one of the most optimal Rust WebAssembly interpreters. Ideal if you want to use Wasm in nostd environments or blockchains with a pure Rust codebase (wasmi feature) WAMR: (wamr feature) ideal for iOS So… how fast are each of the backends? Benchmarking the backends We have run an extensive set of benchmarks based on Wasmi’s great benchmarking blogpost to see how each of these backends behave for diverse scenarios. Here are our findings! Full iOS Support via WAMR, Wasmi and V8 bindings For the first time, Wasmer brings WebAssembly to iOS devices through a new interpreted mode. About a year ago we added support for JavacriptCore in Wasmer, with the hope that it would enable a fast runtime on iOS (since the JIT would be unrestricted). Unfortunately, iOS capped the ability of using WebAssembly via JavascriptCore (since iOS 14). Leveraging the capabilities of V8, Wasmi and WebAssembly Micro Runtime (WAMR), developers can now run WebAssembly modules seamlessly on iOS thanks to Wasmer 5.0. No changes needed on their codebase. This opens up a world of possibilities for mobile development, enabling high-performance applications on Apple's ecosystem. We want to thank Holochain as this work wouldn’t be possible without our partnership. Leaner codebase For the release of Wasmer 5.0 we have put an special emphasis on making Wasmer codebase as lean as possible, so we can develop new features even faster. As part of this effort, we realized that: Emscripten bindings have been mostly unused in the last two years, mainly influenced by these two factors: Emscripten emits code using WASI systemcalls under the hood when possible, removing the need for having special bindings for Emscripten WASIX helps to bridge the gap of the WASI systemcalls that are not supported (threads, longjmp/setjmp, fork, …) Some of the dependencies Wasmer used have been long unmaintained, or duplicated by newer and safer crates Because of that, we decided to drop support for Emscripten and trimmed up the dependencies resulting in a net result of 20k lines of code deleted in the Wasmer codebase. Enhanced Performance Module deserialization now is up to 50% faster (that is, when you call Module::deserialize or when you run a module via wasmer run). Performance is at the heart of Wasmer, and version 5.0 takes it to the next level. These improvements are leveraging essential updates on rkyv: the zero-copy deserialization library that we use to deserialize our Modules. Here’s a benchmark of all the backends using latest Wasmer vs the latest release. Upgraded Compilers: Cranelift and LLVM 18 The latest Cranelift integration results in significant runtime speed improvements, making your WebAssembly modules execute faster than ever before. Wasmer 5.0 now includes the most recent version of LLVM (18), ensuring that developers have access to the latest optimizations from the toolchain. The LLVM upgrade enhances compatibility and performance, providing a robust foundation for compiling and running complex WebAssembly modules. On top of that, Wasmer 5.0 also ships with experimental LoongAarch64 support. We have also benchmarked coremark with the latest version of the compilers to see how they compare: LLVM and Cranelift are about 8% faster in Wasmer v5.0 compared to v4.4.0 Getting Started with Wasmer 5.0 Ready to dive in? Here's how you can start exploring the new features: Download Wasmer 5.0: Get the latest version from our official website. Update Your Projects: Upgrade your existing Wasmer projects to leverage the new capabilities. Explore the Documentation: Visit our updated docs for detailed guides and tutorials. Join the Community: Connect with other developers on our Discord server and share your experiences. Looking Ahead Wasmer 5.0 is a significant step forward in our mission to empower developers thanks of the exciting possibilities that WebAssembly brings to the table. With iOS support, our pluggable backend architecture and the enhanced performance, the possibilities are now endless. We can't wait to see what you'll build next with Wasmer. Stay Updated Website: wasmer.io GitHub: github.com/wasmerio/wasmer Twitter: @wasmerio Discord: Join our community Thank you everyone for being part of the Wasmer journey! About the Author Syrus Akbary is an enterpreneur and programmer. Specifically known for his contributions to the field of WebAssembly. He is the Founder and CEO of Wasmer, an innovative company that focuses on creating developer tools and infrastructure for running Wasm Syrus Akbary Syrus Akbary Founder & CEO Key Highlights New experimental backends Benchmarking the backends Full iOS Support via WAMR, Wasmi and V8 bindings Leaner codebase Enhanced Performance Upgraded Compilers: Cranelift and LLVM 18 Getting Started with Wasmer 5.0 Looking Ahead Read more wasixengineeringepollruntime Boosting Performance: Integration of epoll syscall in WASIX RudraAugust 8, 2023 engineeringruntime Announcing Wasmer 3.0 Syrus AkbaryNovember 23, 2022 engineeringruntimewasmer 2.1 Wasmer-JS: A New Hope Syrus AkbaryDecember 7, 2021 engineeringruntimewasmer runtime Wasmer 4.1 Syrus AkbaryJuly 17, 2023 Making software universally accessible TwitterDiscordGitHub Explore Packages Blog Products Runtime Registry Edge Use cases Static Site Hosting PHP Hosting Company About Values & Culture Imprint Privacy Terms",
    "commentLink": "https://news.ycombinator.com/item?id=41990326",
    "commentBody": "Wasmer 5.0 (wasmer.io)193 points by syrusakbary 19 hours agohidepastfavorite74 comments skybrian 13 hours agoThese performance graphs are confusing and possibly cursed. Sometimes they're log scale (confusing enough) and others, I have no idea what they're trying to say. For example, the first graph, labelled \"Argon 2\", nearly all the bars are the same length, labelled \"100\" (no units given, apparently log scale) and the individual bars are labelled with entirely different numbers in ms (presumably milliseconds). reply ledgerdev 19 hours agoprev> having V8 as a backend also means supporting WebAssembly Exceptions and Garbage Collection under the hood. Stay tuned for more news on this front soon Looking forward to this and languages that can make use of wasm-gc. Does wasm-gc allow sharing of host data/strings across different modules in the same runtime, or is it contained to only single module with repeated calls/invocations? The scenario I am considering would invoke several different modules in a pipeline, pass data between each step in an efficient manner. reply throw4950sh06 19 hours agoparentThat's what reference types (the Wasm proposal) are for, GC builds on top of that. reply azakai 16 hours agoparentprevSharing GC data between wasm modules is supported, yes. You just need to define the types identically on both sides, and things work. reply thiht 11 hours agoprevI have a hard time understanding what Wasmer does from their landing page. I understand it runs everything everywhere, unbound and above the cloud, but what does it do? From the name it seems like a very dev oriented product, and I can’t find a single technical word, just buzzwords reply syrusakbary 6 hours agoparentThanks for the feedback! I'm Syrus, from Wasmer. We are currently working on redesigning the homepage so its easier to know what we do and what is our business value. Stay tuned :) reply flohofwoe 8 hours agoparentprevIt's a runtime for WASI blobs (basically a WASM based standard for crossplatform command line tools), for instance: emcc hello.c -o hello.wasm wasmer hello.wasm Hello World! This uses Emscripten as C compiler, but alternatively you can use the wasi-sdk toolchain instead of Emscripten to build WASI blobs: - https://github.com/WebAssembly/wasi-sdk ...or Zig as C compiler: zig cc -target wasm32-wasi hello.c -o hello.wasm wasmer hello.wasm Hello World! ...or of course Zig as Zig compiler :) zig -target wasm32-wasi hello.zig wasmer hello.wasm Hello World! (not sure if the Rust toolchain comes with builtin WASI support, but probably yes). ...or instead of wasmer use another WASI runtime: - https://github.com/wasmerio/awesome-wasi?tab=readme-ov-file#... ...this is probably the best part of WASM and WASI, there's no 'vendor lock-in'. reply thiht 7 hours agorootparent> It's a runtime for WASI blobs (basically a WASM based standard for crossplatform command line tools) Thanks! I wish this was the subtitle on their homepage :) reply flohofwoe 7 hours agorootparentI mean, it's a Californian tech startup, what did you expect ;) Anything that isn't \"earth-shattering\" and \"world-changing\" would be too pedestrian, especially when your product is essentially a simple cmdline tool for coders (a very useful tool of course but not exactly \"glamorous\"). reply Alifatisk 8 hours agoparentprevFrom my understandning, it's a runtime that runs webassembly (wasm). So anything that can be compiled to wasm can be runned with this which means it can be executable everywhere wasmer exists. reply OtomotO 18 hours agoprevInteresting. I am happy with wasmtime though. Hacking on a wasm component model and wasi based plugin system these days. Having loads of fun. (I am aware of extism, but I am doing it for the fun :)) reply bschwindHN 17 hours agoparent> Hacking on a wasm component model and wasi based plugin system these days. Same here! Can you share what you're working on? I'm (slowly) making a 3D CAD modeling API, so you write Rust code to define a model, and compile it to WASM so it can hot-reload and let you iterate faster. https://github.com/bschwind/opencascade-rs/tree/main/crates/... reply 1oooqooq 14 hours agorootparentshape.faces().farthest(Direction::PosZ) nice. is this original from openscad (if that even is your inspiration)? reply bschwindHN 12 hours agorootparentOpenSCAD is of course the OG for code-based CAD, but this particular syntax came about from converting CadQuery-esque queries into Rust iterators with a bit more type-safety instead of something stringly-typed. Here's a snippet from a CadQuery example: # 3a. The top-most Z face is selected using the >Z selector. # 3b. The lower-left vertex of the faces is selected with the Z\").vertices(\" Multiplayer needs a server backend Did you mean single player? Although perhaps I'm just old and thinking about this in a strange way. And can I clarify.. your scrabble app is web based already right? connecting to a rust web server for the game logic? And you want to embed that server by compiling to wasm? I probably should go read up on how this works. reply 01HNNWZ0MV43FF 19 hours agoparentprevIt probably makes sense if you're running untrusted code or handling untrusted data, or running code that was written after the rest of your app So for a solo dev it doesn't add much, but for a web browser or something that needs plugins it could make a lot of sense. reply 1oooqooq 14 hours agorootparenthistory tells us, that usecase will go out the window as soon as the usual suspects do their usual standards capture by implementation to support something or another related to advertising attribution. reply MuffinFlavored 19 hours agorootparentprev> It probably makes sense if you're running untrusted code or handling untrusted data I never understood this because... I feel like wasm (the standard) is an empty box and a lot of runtimes help you attach things to it / make it useful (able to read/write to filesystem, call the Internet, etc.) reply xn 19 hours agoparentprevI've used wasm to write web applications in Go that run in the browser, both HTML applications (https://github.com/octoberswimmer/masc) and TUI apps using xterm.js (https://github.com/charmbracelet/bubbletea/pull/887). reply Starlevel004 19 hours agoparentprevWASM has two primary usages: 1) Making canvas webapps with unblockable ads built-in 2) Downloading and running random blobs of other people's code in a sandbox reply taberiand 19 hours agorootparentTo be fair, a rock-solid sandbox with extremely well defined and host controlled ingress/egress in a tiny package sounds absolutely fantastic reply api 19 hours agorootparentThat’s what it is. reply 1oooqooq 14 hours agorootparentprevthat would have been implement in something like forward only language like ebpf. wasm is just an outgrown hack that people are hopping will be that safe sandbox and solve all JavaScript problems. do not fool yourself with this temporary feature. wasm was first for js performance. secondly for portability. and third and accidentally for sandbox. reply mrugiero 4 hours agorootparent> that would have been implement in something like forward only language like ebpf. wasm is just an outgrown hack that people are hopping will be that safe sandbox and solve all JavaScript problems. It's funny that every time an article on new functionality for eBPF appears in LWN everybody is like \"why don't they just use WASM???\". More seriously, a forward only language is by definition too strict for the general case of sandboxing, unless you mean using it only for hooking the syscalls rather than as a target for your program. In particular, the Linux implementation caps your execution to 1M instructions, which is not a lot for something you'd want on your browser. reply flohofwoe 7 hours agorootparentprev> 1) Making canvas webapps with unblockable ads built-in Which isn't any different from Javascript if you choose to embed the ads right into the Javascript code - but nobody does this because it doesn't make any sense. In reality, a WASM app that displays ads would also need to load the ad content over one of the existing ad-network mafias (serving ads any other way simply doesn't make any financial sense), and those HTTP requests initiated by a WASM blob (by calling out into JS - because that's the only way in browsers) will be blocked just as fine by existing ad-blockers. ...but I'm also not actually aware of any webpage that does this (trying to defeat ad-blockers via wasm), do you have any example? reply peutetre 16 hours agorootparentprevYou can do both of those things in JavaScript. WebAssembly brings every language to the web and does it with higher performance than JavaScript. reply enugu 14 hours agorootparentFor sandboxing in JS, we can use sandboxed iframes or webworkers. Both of those communicate to hosted code via postmessage which serializes an object and this can be used as a base for implementing function calls. Whereas if I understand correctly, WASM can be provided with host approved JS functions to call directly in importObject. This seems more convenient and fast. But for a plugin system, many people would prefer to write plugins in JS itself, so for WASM plugins, they might have to be compiled to WASM first. Dont know how if there is a mature implementation of JS->WASM. reply mrugiero 4 hours agorootparent> But for a plugin system, many people would prefer to write plugins in JS itself, so for WASM plugins, they might have to be compiled to WASM first. Dont know how if there is a mature implementation of JS->WASM. Not everyone tho, which is kinda the point of abstracting away your language for plugins. People like Python, Lua, Go, Rust, etc... Some do like JS of course, but not everybody. Re: mature implementations, I would guess worst case QuickJS probably can compile to WASM and it's small enough that your runtime will probably offset the extra blob size. reply bakkoting 1 hour agorootparent> I would guess worst case QuickJS probably can compile to WASM That's actually exactly what Figma is doing for their plugins. [1] Seems to be working ok, though not without some pain [2]. [1] https://www.figma.com/blog/an-update-on-plugin-security/ [2] https://macwright.com/2024/03/29/figma-plugins reply enugu 2 hours agorootparentprevJavy project seems more active. reply pjmlp 12 hours agorootparentprevI am happy with 3) Bring back all the plugins that were taken away. See no other use for it. reply simonask 18 hours agoparentprevI’m using WASM as the modding interface in my game. (I’m using wasmtime from Rust, but same principle.) Main benefits are isolation, binary portability, and hot reload. reply crabmusket 19 hours agoparentprevTake that API scraping script example. Imagine next you want to build a platform where you run code written by your users who want to e.g. scrape APIs. Think ParseHub I guess? Zapier is another good example. You'd let them write in Rust or some other language that can target WASM, then you'd run the WASM blobs in a controlled sandboxed execution environment in your platform. reply Groxx 19 hours agorootparentSo basically: what every single platform with plugins should be doing to protect their users. Or similar via some other language that allows sandboxing, e.g. Lua. reply lll-o-lll 17 hours agorootparentYeah, but the plugins can be written in Rust! OK, OK, it’s a bad example. WASM is language agnostic though, so as more languages can target WASM, then the possible advantage is programming language agnosticism. If I have some code, I don’t have to re-write it in Lua. reply iknowstuff 19 hours agorootparentprevyea https://blog.cloudflare.com/announcing-wasi-on-workers/ and such. reply sroussey 19 hours agoparentprevONNX has a WASM backend for running models in a browser. It’s what transformer.js (from HuggingFace) uses behind the scenes. reply csomar 17 hours agoparentprevI think the biggest company using wasm in production is figma (though there might be others). Otherwise, here is an example where wasm shines. Say you have an editor (rvim) and you want to support plugins. Usually, you’ll have a language interpreter and ask developers to develop in this language. With wasm, you can give them the freedom to use whatever stack they want. Then you expose an interface for their wasm artifacts. This abstract the host OS away. Another example is game mods/plugins. reply peutetre 16 hours agorootparent> I think the biggest company using wasm in production is figma (though there might be others) Amazon uses Rust to wasm for the Prime video app and Google uses Java to wasm for Google Sheets. Both get higher performance and lower memory usage versus JavaScript: https://www.amazon.science/blog/how-prime-video-updates-its-... https://web.dev/case-studies/google-sheets-wasmgc Abode uses wasm in the web based version of Photoshop: https://medium.com/@addyosmani/photoshop-is-now-on-the-web-3... reply 0points 9 hours agoparentprevWasm could be a handy way of letting users mod your app using their choice of programming language that can compile to wasm. Compare with how lua is used. reply dgfitz 19 hours agoparentprevI cross-compile a native qt app in windows, Mac, and Linux variants. It’s pretty neat to see it compile in wasm as well. reply colordrops 18 hours agoparentprevEveryone else has answered about WASM, so I'll answer about raspberry pi. I've got 5 of them. One is running Home Assistant for all my home automation and camera recording. One is running a quadruped that I built. And three are connected to three sets of speakers around the house running a home-rolled Sonos-like setup so I can stream the same music all around the house from my phone. reply MuffinFlavored 16 hours agorootparentCool! Thanks! I've got none of that. reply int_19h 18 hours agoprevIs Wasmer still openly adversarial wrt the Bytecode Alliance? reply spirobelv2 10 hours agoparentcan you link more infos on the drama pls reply SirGiggles 4 hours agorootparentMost prolific example was this: https://news.ycombinator.com/item?id=30758651 Not a big one, but this was of personal note: https://github.com/bytecodealliance/wit-bindgen/issues/306 reply wg0 18 hours agoprevSorry to be that guy but what's the business model for all these web assembly runtime companies? reply jsheard 18 hours agoparentThis one runs their own serverless platform that you can deploy your WASM apps to, but their pricing is... vague. reply wg0 11 hours agorootparentI think it's same docker Inc. all over. A great open source tool but no viable business model. reply thrdbndndn 17 hours agoprev [–] God, please stop using random AI-generated images in a release post.. reply spretzer 16 hours agoparent [–] What is the issue with AI-generated images? Just being overdone in general? Or ethical concerns? reply thrdbndndn 16 hours agorootparent [–] Makes your article looks cheap like a random blogspam. My personal opinion, obviously. reply NitpickLawyer 13 hours agorootparent [–] What's the difference between this and a generic photo from one of the dozens stock photo catalogs? Is this somehow \"cheaper\" because it's \"AI\" generated? Using stock photos is also cheap (free or cents per)... Second, does anyone really care? Has anyone spent more than half a second looking at a generic picture on an unrelated article? Does the generic hoodie hacker look good on security articles? Or the earth with pretty links on a networking article? Or the overdone handshake on a deal article? They feel equally as cheap and more importantly equally unimportant. It's a placeholder that noone should really care about. Third, what's the value of having human beings spend time on an image that's just there to fill space? I kinda get the argument for company identity and things that matter, but filler for an article? Nah, that's exactly where we shouldn't be spending human resources, IMO. reply 0points 8 hours agorootparent> What's the difference between this and a generic photo from one of the dozens stock photo catalogs? You see an AI generated image next to a bullet point list and start to suspect all you are reading is AI generated nonsense. It doesn't exactly help communicating professionalism if that is the intended goal. Rather, it gives the idea that the author did a minimal effort post. reply flohofwoe 7 hours agorootparentprev> What's the difference between this and a generic photo from one of the dozens stock photo catalogs? None really, using a stock photo in a blog post is also a stupid idea. Just don't add any image if it isn't needed to get an important point across. reply lxgr 1 hour agorootparentI personally find title images pretty helpful to remember a certain blog post, quickly identify it when I have several of the same blog open as tabs etc. Of course it can be overdone, but it definitely does add utility for me at least sometimes. reply thrdbndndn 12 hours agorootparentprevI think using a stock photo in this case is also bad but not as bad; because the photo itself usually looks fine. I hate AI-generated photo more simply because they're not good enough (yet) to not look fake immediately; it even has somewhat uncanny valley effect. If one day they're as good as stock photos, then my opinion with them would be on par with that, too. I care, hence the comment. Can't speak for others. > where we shouldn't be spending human resources I agree; which is why in general I don't see the need to include irrelevant pictures at all for a software release post. reply gherard5555 9 hours agorootparentprev [–] It looks soulless, even more than a the generic \"hacker man\" picture, at least you could tell these were made by a human. For me its one of the lowest \"effort\" you could put in a picture. Of course thats entirely subjective but personally I hate it and it doesn't seems like im the only one here. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Wasmer 5.0 has been released, offering improved performance and new features, including experimental support for V8, Wasmi, and WAMR backends, and full iOS support.",
      "The update includes a leaner codebase with upgraded compilers using LLVM 18 and Cranelift, enhancing WebAssembly's capabilities for high-performance applications.",
      "Developers benefit from faster module deserialization and a more efficient tool for executing WebAssembly modules, with resources available for getting started and community engagement."
    ],
    "commentSummary": [
      "Wasmer 5.0 has been released, featuring V8 as a backend, which supports WebAssembly Exceptions and Garbage Collection, enhancing its functionality.",
      "Wasmer serves as a runtime for WebAssembly System Interface (WASI) blobs, enabling cross-platform command line tools and applications like running untrusted code and modding game interfaces.",
      "Discussions highlight confusion about Wasmer's purpose and the unclear business model for WebAssembly (WASM) runtime companies, alongside criticism of using AI-generated images in release announcements."
    ],
    "points": 193,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1730242927
  },
  {
    "id": 41989511,
    "title": "RIP botsin.space",
    "originLink": "https://muffinlabs.com/posts/2024/10/29/10-29-rip-botsin-space/",
    "originBody": "RIP botsin.space 29 October 2024 There's no easy way to put it, so here goes -- after a lot of consideration, I've made the hard (frankly, painful) decision to shut down botsin.space. TLDR: here's the plan: Effective immediately I'm shutting down new account signups I will switch the site into read-only mode sometime not long after December 15th. I'll do everything I can to help people migrate their accounts elsewhere, and/or generate archives. I'll keep the site running in read-only mode at least into March of 2025, and if possible/needed I'll extend that as long as I can. Why? I launched botsin.space in April of 2017, which honestly feels like it was about six thousand years ago. Originally I just wanted to play around with the fediverse and Mastodon. The oauth flow for creating a bot was messy, so I forked Mastodon and fixed it, deployed those changes to botsin.space, and invited people to create bots. The server was popular with bot allies and artists, people who wanted to get RSS feeds onto the fediverse, as well as students and professors who wanted to work on coding projects or learn about federated social media. There have been some moderation challenges over the years, but to be honest those have never been all that considerable. But botsin.space has always been a bit of an odd duck with a unique set of challenges. Over the years, the server has grown to have around a few thousand active accounts, which isn't all that many. However, they've generated something like 32 million statuses. Just to put that in perspective, mastodon.social has over 2 million users, who have generated around 110 million statuses. So the usage patterns are very different, and I think it's safe to say the the mastodon codebase is tuned for mastodon.social and not a weird freaky server like botsin.space. I work on the internet professionally, use Rails at my day job, and server management is part of my job description, so I've been able to use my skills to keep botsin.space running on a relative shoestring budget. Until recently, the whole thing ran on one server. But that's not maintainable, and given that and some other concerns, I think that now is the time to retire the server. There are four major expenses for botsin.space, in order from least to most expensive: My time. As long as I find managing the server rewarding, this is an expense I'm happy to pay. Server costs. I've been able to be fairly cheap here until recently. Database storage. The database for the server lives on a dedicated volume at Digital Ocean, and is currently around 191GB in size. Every time I need to increase the size of this volume, the expense goes up, and it's safe to assume that this will only continue to grow. File storage and bandwidth. These expenses will also only get more expensive over time. File bandwidth is the #1 charge on the monthly server bill right now. I live in fear of an AI scraper figuring out how to scrape all of these files and bankrupting me overnight. Until recently, my thinking has been: \"I'm cool with finding all sorts of weird tricks to keep the server going, and I'll worry about #3 and #4 someday in the future maybe lalalalala I can't hear you.\" But the recent Mastodon upgrade has caused a significant amount of performance degradation, and I think the only way to really solve it is going to be to throw a lot of money into hardware. I should mention at this point that I've had a Patreon to help with server expenses, and I've also accepted Paypal donations, and I'm truly grateful for everyone who has ever sent me money to support the server. However, even with the support, expenses have always outpaced the donations, and while that's been fine with me for a long time, it's not sustainable. I'm fortunate enough to have a career and life where I've been able to support botsin.space, but I can't do it forever, and as the expenses and challenges mount, I find myself thinking about things that I'd probably rather be doing with my time. With a few exceptions, botsin.space isn't anyone's primary instance, and I've always been mindful of the fact that everyone who supports botsin.space financially has other places and people to think of also, and I am so thankful for the consideration. I hope that everyone who is currently supporting botsin.space finds another instance to support, there are a lot of great instances out there with vibrant communities that need all the help they can get to survive. So, given two choices -- asking for more donations so I can pay for more hardware to keep the instance running, or retiring it and encouraging people to support more community-oriented instances, I'll choose the second option every time. As I mentioned above, I'll be working to keep the server stable and running for as long as possible, to give people a chance to migrate their accounts, get archives, etc. If anyone has any questions, please feel free to contact me at @colin@muffin.industries. It's probably smarter to ping me there instead of at botsin.space, because it's more likely that your message will be delivered in a timely fashion. I'd like to thank everyone who has ever run a bot on botsin.space and gotten joy out of it. I'd like to thank all the people who have ever shared their thanks or kind words with me online -- your support has meant the world to me. I'd like to thank all the #botALLY folks, who have been a constant source of inspiration and learning to me for over a decade. Finally, I'd like to thank Johanna, who has always been there for me <3",
    "commentLink": "https://news.ycombinator.com/item?id=41989511",
    "commentBody": "RIP botsin.space (muffinlabs.com)191 points by edent 21 hours agohidepastfavorite114 comments ChrisArchitect 18 hours agoI wholly appreciated the openness to accepting bot accounts, migrated some projects from twitter there during the big exoduses in the last couple years. And while it worked for bot purposes, fun to tinker with etc...(not unlike twitter tbf) it was just some server in space a blip in the fediverse and traction and lack of proper network effects for accounts meant it wasn't much use. I'm not hot on the fediverse in general, and this just sours me on it a bit more. A bunch of dedicated admins keeping instances going, basically running hobby servers/websites like it was the 90s/early 00s, is never gonna work for the kind fo scale services grow to these days. I know not everything requires scale and lots of ppl are happy existing in their little silos, but that's just it, they're silos. Might as well be back on seperate forums for our seperate interests again. When you want the power of a mix of accounts/networks/interests everything balloons and can't be run with funds and larger centralization. Sigh. It's a tough one and has yet to be solved in full, with any existing approaches all sort of half-solutions. Maybe that's the way forwards in general (an internet of islands) but it sucks to have things going up and down and having to migrate around the net (with or without our own data) like nomads. reply AlexandrB 16 hours agoparent> When you want the power of a mix of accounts/networks/interests everything balloons and can't be run with funds and larger centralization. I don't really get the appeal of this. Different topics/interests often demand different moderation and forum features. Trying to shove everything into the lowest common denominator of social media results in things like people posting essays as screenshots of Apple Notes. The only obvious benefit I see of this kind of large scale centralization is for marketing. And that's not a benefit to me as a user. reply CaptainFever 15 hours agorootparentThe benefit of a centralized forum like Reddit, for a user like me, is the ability to use one account for everything (i.e. easy to join new forums) and the ability to have everything on one algorithmic or chronological feed. Traditional forums can solve the former by using social sign-ins, and the latter by having RSS. However, support for either of this is inconsistent, so it's usually easier to just use subreddits. Finally, money. Forums cost money to host, while subreddits don't. reply alexvitkov 12 hours agorootparentThose are real and well understood benefits, and they're the reason Reddit won. The costs of moving a community from a forum to Reddit are nowadays mostly understood as well, unfortunately they weren't as obvious back then. reply jayknight 14 hours agorootparentprevLemmy works like that more or less. You can subscribe to communities on other instances and interact with them. reply CaptainFever 12 hours agorootparentTrue, I've forgotten that's the whole purpose of federation: to create a unified home feed. But then the Fediverse unfortunately runs up with the classic issue of network effects. For me personally, my Unified Home Feed of Reddit has more relevant content to me than my Unified Home Feed of Lemmy. And it seems it'll stay that way since Reddit's communities have thousands or millions more subscribers in general. So, sticking to Reddit is easier. This isn't helped by the admin wars on the Fediverse which introduce messy and silent breaks in the network, often requiring multiple accounts to view everything you're interested in. To the Fediverse's credit, their network is a lot wider so it still has some uses, that is, hosting communities banned on Reddit. But I'm not sure if some of the more \"normal\" subreddits have much incentive to move over. reply Propelloni 9 hours agorootparentprevHmh, that's a drawback to me. I like to have different accounts for different things and keep them more or less strictly separated. I use two subreddits and each has its own account. On average I'd say account creation has become harder because everybody and her child tries to shunt you into some social sign-in but it still is not difficult to make accounts. \"Modern\" password managers make it a breeze to juggle many accounts, and frankly, what Netscape Navigator could do almost 30 years ago was already enough for that. Same goes for forums. phpbb [1] can run on any LAMP potato and you get a whole boatload of potatoes for 2 EUR/month at Hetzner. I don't know what HN requires, but I guess it's not much more. The hard part of forums are the people needed to keep order and Reddit is not helping there, quite the opposite. Sorry, I notice I'm grumpy. [1] https://www.phpbb.com/ reply iforgotpassword 12 hours agoprevIf this is just a matter of motivation or lack of time I can understand, but if cost is an issue, why not just move to hetzner? A dedicated server there can be had for around 40 bucks, e.g.: €42.48 max. per month. CPU: Intel Core i7-7700 RAM: 64 GB Drives: 2 x 4.0 TB Enterprise HDD Thats with unlimited traffic, but no ddos protection or similar, so I don't know how essential that was at DO. Also you're on physical hw which is always more annoying if you have to call in because of a failing disk, but from my years of experience this is as smooth as it gets; shut down the server, open a ticket requesting replacement ASAP and give the drive's SN, and the server will be up again within 20 minutes. Absolutely acceptable for a side-project that doesn't offer anything mission critical. But I'd really be curious what the bill currently is at DO, and maybe you have some monster HW there that can't be matched here. Genuinely curious. reply lifthrasiir 12 hours agoparentI think the author assumes the server requirement to continue to increase in the future, even only because of ever growing number of statuses, so no amount of server hardware right now is going to put one at ease anyway. reply iforgotpassword 12 hours agorootparentSure, with 191GB we'd need to know what the growth looks like. But 4TB might work for a good while. Unfortunately we know nothing about the rest. Was it a mid-tier VPS and all the money went into storage and traffic? Then this should be plenty for another couple years at least. reply immibis 9 hours agorootparentYou're also allowed to choose to expire old tweets. Fediverse doesn't force every administrator to archive junk forever. reply SideburnsOfDoom 9 hours agorootparentprevIt may also be that the moderation effort required will also continue to increase in the future, that the human ability to that is exhaustible. i.e. It may actually decrease at a point in time. You might want to act on these opposing trends before they reach a crisis point. reply kstrauser 4 hours agoparentprevI don’t do that because I’m in the US and currently live, work, and operate my servers in the same legal jurisdiction. That’s handy! For instance, if one of my users pisses off Turkey, and they order me to take it down, I can ignore it. If the server were in the same court system as Turkey that may not be so simple. reply Tepix 8 hours agoparentprevWhy not limit the bot accounts to a certain (low) number of messages per minute/hour/day/week/month? reply relistan 10 hours agoparentprevThere was a brief mention of other recent circumstances, which are not elucidated further. Guessing there are unstated personal reasons. Aside from that, if you’re running something on a shoestring and your own time, moving it somewhere else is a lot of work for little joy. reply mosselman 10 hours agoparentprevThat was my first thought too. I’ve run pgbench on some 12 euro/month VM at hetzner and it outperformed our 18k/year AWS RDS instance. Sure it isn’t managed, etc, but there is a lot of room between 12 and 1500 euros reply weinzierl 5 hours agoprev\"I live in fear of an AI scraper figuring out how to scrape all of these files and bankrupting me overnight.\" What is the best way around this for a hobby project similar to botsin.space. I don't mind the service going down in case of a DOS attack. I want to handle TLS myself though (so no free Cloudflare). Most important thing is my good sleep at night, so no fine print that allows the provider to pass on the cost to me in case something goes wrong. (If that means higher fixed cost, that's how it is, I'm not asking for a dream house, just reliable cost control). reply _fat_santa 4 hours agoparentI could see a huge business opportunity here. In Amazon S3 there is a concept of \"requestor pays\" so you can have an S3 bucket that loads of people download data from yet you aren't hit with the bill and instead the \"requestor\" pays for the bandwidth. With AI scraping becoming more of a thing, a cloud platform could roll out a feature where an AI is allowed to scrape the daylights out of your site, but they must pay for the bandwidth or bandwidth + premium. In this scenario you wouldn't wake up bankrupt but instead with a windfall of cash because TikTok decided to scrape all your stuff. reply kraftman 3 hours agoparentprevA dedicated server with no bandwidth cap? reply NelsonMinar 19 hours agoprevAw too bad, this has been a really useful service. I wonder if anyone wants to pick it up? The post mentions part of the problem is Mastodon's implementation being a poor match to high volume bots. You could imagine other architectures that were more efficient for this use case, it'd be a fun yak shaving exercise. If anyone needs to migrate their own projects I've had good luck with feed2toot, to post RSS to a Mastodon account on a ordinary server. It's been around a long time now and seems reliable. reply sigmar 19 hours agoprev>I'd like to thank everyone who has ever run a bot on botsin.space and gotten joy out of it I definitely got joy out of setting up a bot on it. Huge thanks to colin for making it so easy. reply uuddlrlrbaba 1 hour agoprevIf it's not generating income consider moving it to your basement. Maybe it'll be down occasionally, but not forever. reply tjwds 21 hours agoprevThis is incredibly sad; botsin.space has been a steady stream of joy for me over the years. Here's hoping a bunch of alternatives pop up. reply stavros 20 hours agoparentWhat was it? reply acherion 20 hours agorootparentA mastodon instance where bots were welcomed. reply ahrjay 7 hours agoprevAh bummer I've been posting my earthin24 timelapses[1] to this for quite a while now. [1] https://botsin.space/@earthin24 reply gradientsrneat 17 hours agoprevIt's always nice when Fediverse servers have a sunsetting period which allows account migration to other servers. reply pluc 7 hours agoprevFor a decentralized system, there sure is a lot of stress on that one database. reply ciroduran 7 hours agoparentNot decentralized: federated. Some instances are a lot bigger than others, and some work in different ways, such as one instance with lots of bots making procedural content. reply Kye 21 hours agoprevI've had lots of fun calling it bot sin space. It will be missed. reply mmastrac 14 hours agoprevAck. I have a bot there. I appreciate the extended warning time. reply klntsky 8 hours agoprevOnly a very rich person would use managed cloud for anything large scale. reply threemux 18 hours agoprevWebsite is being hugged: https://archive.ph/6Krrp reply dawnerd 19 hours agoprevDamn, I asked the other day if it was down after noticing a ton of timeouts in sidekiq. Reached out and Colin said they were looking into it. Guess fixing it up just proved to be too much. reply scudsworth 20 hours agoprev>Over the years, the server has grown to have around a few thousand active accounts, which isn't all that many. However, they've generated something like 32 million statuses. Just to put that in perspective, mastodon.social has over 2 million users, who have generated around 110 million statuses. unsurprising that the bots would outpace organic users, but wow, what a ratio. i'd be curious to see this data charted over time reply Yawrehto 15 hours agoparentIt makes sense. Assuming the average bot toots ~once an hour (24 times a day) and has been tooting for two years, you get on the order (nearest multiple of 5000) of 20,000 toots per user, which works out to 1600 users. Also, there's a measuring change from active accounts to plain old users. I don't know the proportion that are active, but if I recall right, the fediverse as a whole had under 1 million active users. Assuming 500,000 active accounts that pull all the weight, it's 220 toots per user on average. reply pietervdvn 20 hours agoprevRIP! Thanks for hosting this all those years. I'll try to find a new home for my bot. reply op00to 19 hours agoprevThanks, botsin.space! It was fun while it lasted! reply neonsunset 11 hours agoprevI assume just not using Ruby would have given the project a few more years of scalability hassle-free runway. reply aseipp 1 hour agoparentFile transfer costs on a typical provider will absolutely eat away at any money you could save through CPU or memory efficiency gains, I think. If you move to a different provider (like others have mentioned) to fix this then you'll often get good CPU and memory to go with it so the whole calculus changes. Those two resources are often the cheapest in the whole stack, for better and worse. You'll save $20 by using a smaller droplet but still pay $80 for outgoing traffic and another $30 for disk storage, and those are the costs that increase the fastest. The design of the existing Fediverse means that they just use a lot of bandwidth and storage. I think it would be a wash at the end of the day. reply mosselman 11 hours agoparentprevBut then only 1/10 of the features they currently have would’ve been finished. The real culprit is the cloud premium. If you go with hetzner you have lots of runway too. reply wink 10 hours agorootparentThis would work for an instance of human accounts who need real UX. A bot instance should really work with the most basic Fediverse software, if it supports posting, reading, replying, etc. reply neonsunset 10 hours agorootparentprevThis is a typical excuse I always hear in defense of Ruby but am yet to see a proof that it is the case, with plenty of arguments that demonstrate that Ruby also happens to be a productivity loss the moment the project scale goes beyond trivial. It has such an embarrassing failure mode that is unthinkable in statically typed compiled languages. Rails is not even a better choice at its main selling point which is developer UX, it has been many years since the rest of the industry caught up and surpassed this. Nowadays, as a primarily C# developer I’m always baffled by the crutches RoR developers have to deal with - one would just not tolerate these in .NET. At the end of the day, if every line of code costs 100x more, it’s very difficult to come up with a good reason where such Ruby tax is worth it in the projects that cannot afford to throw more compute and memory at a problem. reply hombre_fatal 3 hours agorootparentThe proof is that Mastodon and his server were implemented in Ruby. It doesn't exist in another language. And it's the same language that he uses at his day job and according to him, it's part of what compelled him to work on it at all. The fact that he built it and maintained it is the proof for the claim. Without Ruby it simply doesn't exist, so it doesn't matter how much hypothetically better your favorite language is. reply Evidlo 19 hours agoprevMaybe requiring payment could've worked out instead of shutting down? reply paranoidrobot 13 hours agoparentNo relationship to the author, but this makes it into running a commercial service. So, at a rough guess you need: - Some kind of company entity for all this to belong to, possibly a LLC, and all the associated paperwork that goes with it. - Bank accounts and some way to handle card payments - Some level of requirement to provide customer service/support, at least for billing related issues - Have to now also deal with card fraud, refunds, disputes, charge-backs - even if you use some service that will handle most of it, you'd still need some level of involvement - Have to handle billing related tech stuff - issuing bills, ensuring accounts are activated/deactivated based on billing events - And now you need to charge enough to cover all of the above, and your time, and the time of any professionals involved in the above Starts to sound like at least a part time job. The OP may not want to go there. For my personal projects that I provide as a service to others, I do them for the fun of it. In the past I've bailed or cut access to them when they've started to feel like a job. reply slightwinder 5 hours agorootparentIsn't there a nonprofit association aimed for making the managing/finance-side of such small projects easy? I mean, there are all kinds of orgs for free software and other hobbies. Having a dedicated organization for collecting small money or donation and handling taxes worldwide for small projects, might be something useful, I guess. reply shadowgovt 20 hours agoprevSafe travels to a known name. One of the reasons I maintain a node with only one user is I fear the day I'll be responsible for other people's social media presence; I could easily see myself going \"It's just a few thousand users\" and the next thing I know I'm asking whether I can keep this thing going (and agonizing over what it'll do to my users to cut the service). And unlike Colin, I despise Rails and wouldn't have the patience to hammer on it when it starts to misbehave. Props to Colin having the guts to take the risk. reply darknavi 21 hours agoprevFederated networks like Mastodon and Lemmy are going to get people well-acquainted with websites shutting down. It's hard work (time, money, etc.) to run these things for people, and people start to really lean on them. It's almost novel now days getting sucked into something that shuts down. killedbygoogle.com is a meme partly I think because websites shutting down is just so uncommon in areas that we get personally invested in. I run my own Lemmy instance just for my self and even that can be trying sometimes. I enjoy using it instead of reddit, but one day I will probably shut it down and be sad. reply jchw 19 hours agoparentI'm starting to think nostr was barking up the right tree after all. Put as much complexity into the client as possible and make the servers dumb and completely uncoordinated, utterly interchangeable. Spam your broadcasts to any relay that will listen. No idea if it actually works (I've read a lot about nostr and AT proto but never used either of them) but I think it's very obvious that any system that deeply relies on some company that everyone becomes extremely reliant on (including AT proto/Bluesky) is only a couple steps away from the same sort of problems as centralization. Of course, the real gold standard would be P2P, if only it could work. But... mobile phones can't burn battery running P2P clients in the background, everyone's under a NAT these days, and some types of software (like microblogging networks) would be horrifically intractable as a P2P system. Oh well. At the very least, I really love the concept of Decentralized Identifiers (DIDs). I'd like to see more stuff like that. reply pfraze 19 hours agorootparentThe atproto team came from the p2p space. We had a lot of experience running client-side computation. There are challenges you can try to solve in that design -- key sync, key recovery, reliable hosting, reliable discovery, etc -- but what you can't get around is the need to run queries against aggregations of data. Even scales that we consider \"mid\" start to strain on the client-driven model. Federated queries might be able to solve it, but it's extremely challenging to get reliable performance out of that. The design we landed on was replaceable big nodes. The common comparable people raise is email/gmail, but we used the DID system and account portability to try to get a better outcome on provider migration. It's hopefully more like web/google -- which still has the centralizing pressures of scale benefits, but hopefully injects enough fluidity in the system to move the situation forward. Sometimes, you pick the design that moves the ball down the field, not the one that guarantees a touchdown. If somebody wanted to improve on what we've done, I'd tell them to focus on the federated queries problem. reply jchw 18 hours agorootparentIn theory AT proto doesn't seem like a bad design. I've read a fair bit of the docs, although mostly skimming. (I've been meaning to read the paper on Merkle Search Trees so I can figure out what exactly is going on with PDSes.) On the other hand, in practice it seems like the AT proto infrastructure is still very centralized for now. DIDs are excellent in theory, but everyone is using PLC DIDs, which depends on the centralized plc.directory. You can run your own PDSes, but there's only one relay for now (that I am aware of.) I also don't think there is more than one instance of the Bluesky AppView, and the official instance is locked into the Bluesky Moderation Service, which seems to limit the usefulness of some of the censorship resistance of the protocol. I'm not sure how much of that is social problems rather than technical, but I worry that since Bluesky and AT proto are gaining massive popularity with this status quo (millions of users!) it'll have a problem akin to Matrix.org, where in practice almost everyone is using the same infrastructure anyways. It's still relatively early days, but millions of people is definitely enough to where you start to hit problems with having everyone under one roof. I really hope we get to see how things play out when more of the network is operated independently. reply pfraze 18 hours agorootparentThe necessary future is more providers, more relays, a move of PLC to an independent body, and more DID methods. I will also say - there are ~100 self-hosting PDSes in the network, about 25 relay consumers, 3 alternative appviews that I know of (smoke signals, frontpage.fyi, and whitewind), the firehose & backfill are fully available, the specs are getting fairly complete, and the software is open source. This is a priority for us. reply Arathorn 18 hours agorootparentprevfwiw roughly 50% of Matrix is on the matrix.org instance currently. we consider this a bug, but also prioritise ease of onboarding over decentralisation purity ideology. reply jchw 17 hours agorootparentI hate to be a downer but there's a lot of things Matrix could prioritize over decentralization. That said, the decentralization works pretty badly. Large federated joins are somewhere between comically slow and horrifically slow. Status does not seem to work well across federation either. I'm also a bit miffed that Dendrite was positioned as a \"next generation\" Matrix server but now it feels nearly orphaned with missing support for newer features, issues with various appservice bridges, few updates at a very slow pace, and no migration path out in sight. I know it came with a fair number of disclaimers, but that still bums me out as it seemed like it would be okay for a small non-critical homeserver, and now it seems likely I'll have to engineer my own path out when clients finally stop working with Dendrite. (It already happened once...) You have no idea how bad I want to love Matrix, but frankly if it was due to a focus on usability that decentralization \"purity\" has suffered, it simply does not show in the resulting usability improvements over years of time. Sorry to be harsh. reply Arathorn 17 hours agorootparentif you feel miffed, imagine how the Dendrite team feels, given the lack of funding which means it is on best-effort dev currently. if you’re interested in progress on Matrix, https://matrix.org/blog/2024/10/29/matrix-2.0-is-here/ is where it’s at. reply jchw 17 hours agorootparentI did see the Matrix 2.0 announcement, though for obvious reasons I can't actually use any of the features listed in it. Obviously, improvements to the basic chat functions of Matrix would be great. For now though, I am stuck with the reality that joining a large federated channel sometimes takes more than 6 hours. I wish I were exaggerating. edit: I guess though that faster room joins weren't a part of Matrix 2.0. Actually, I don't really have a huge problem with the sync taking too long personally. So maybe Matrix 2.0 wouldn't bring that big of an improvement for me anyway. reply hifikuno 21 hours agoparentprevI, too, ran my own instance. I enjoyed it for some time but I've now moved to the omg.lol ecosystem. I feel that by paying a little money for it that I have a higher chance of the server not shutting down. reply joeross 12 hours agorootparent+1 for omg.lol, it’s a great community. reply qudat 19 hours agoparentprevActivityPub seems to require a lot of hardware resources in order to run properly, which is unfortunate. It’s not something I would ever want to run myself, especially to the public. reply SLWW 18 hours agorootparentPlease be wary to conflate ActivityPub with the code on top of it, like Mastodon for instance; which is, on both front and back-end, proven to be resource intensive and difficult/costly to scale especially over time. (the older the dbs get, the more inactive users pile up, etc.) Versus something like Pleroma; which I've used since it's inception, being incredibly janky and lightweight, prone to breaking, but later versions have mostly ironed out most of those catastrophic bugs. It has it's own challenges as well, but it does historically scale better, is more flexible, and less intensive per instance One demands a lot of money and time, where the other demands a lot of time and not so much on the money side. I'm not going to spend the time to give you a history of pleroma/mastodon instances, as it's a controversial history at best and there's a lot of people who know little, yet who will believe themselves an oracle. (ofc that could also be me so take it with a grain of salt and all) Though if you are willing to read through a bunch of highly opinionated accounts, and you pay close attention to what actually happened, the answer is pretty clear. ActivityPub is intensive, but not the main culprit. reply zimpenfish 13 hours agorootparentprev> ActivityPub seems to require a lot of hardware resources in order to run properly Correction: \"The Mastodon software requires a lot of hardware resources in order to run properly\" Alternatives like GotoSocial, Akkoma, even Honk are much less resource intensive. reply rtpg 18 hours agorootparentprevI wonder how much of that is endemic to ActivityPub or how much is about the software stack itself I don’t mean to be glib, just wondering if things can be “done better” reply qudat 18 hours agorootparentI'm guessing the syncing process between instances is really brutal on resources. Imagine constantly syncing external databases for your service to function properly. reply jeroenhd 12 hours agorootparentAP is push based (which actually causes the \"every instance has its own set of comments\" problem). You can run pullers on a small instance to get a better experience if the remote sides support listing posts, but the standard sync process is no more than receiving HTTPS calls and storing the JSON contents in the right place. There's some additional overhead (doing HTTPS calls for verifying signatures, for instance) but that information can be cached pretty effectively. Pushing contents is no more than posting HTTPS calls to every server in your follow lists, and possibly exposing said content in a GET API for pullers, though that's entirely optional. Mastodon is heavy because of the way the backend is written (I blame Ruby on Rails for tha one), but there are fully featured ActivityPub servers out there that are orders of magnitude more efficient. Mastodon devs prefer the ease of development over performance but that's a choice, not an inherent problem of ActivityPub. reply rtpg 18 hours agorootparentprevI thought AP was push-based though? Might be wrong of course, and I think stuff like media is its own thing reply OgsyedIE 20 hours agoparentprevBesides the monetary costs of operating small fora there are also significant competence hurdles. Site owners who manage to hit a couple thousand users have to figure out spam handling, automated content moderation (including photoDNA and the required reporting if they host images), registering a DMCA agent with the copyright office, setting up an LLC, assessing their needs for COPPA, GDPR and CCPA, their site's tax situation and anything they may want to do involving employing others (such as T&S) without getting burnt out. The median size for a forum getting its first subpoena is 4,300 users. Managing all of that is easily learnable in a couple months if they have time, disposable income and few distractions but surprisingly few people who have site management thrust upon them know about these things in advance. To most people who think about running an internet anything the above are unknown unknowns. You can't go looking for things you don't know exist, so burnout is high. reply kstrauser 19 hours agorootparentCitation highly needed. I'm close to quite a few people who run larger instances than that, including my own, and none of them have ever told me about getting subpoenaed. That's exactly the kind of war story we'd tell each other, too. I've seen no evidence that running a fediverse server is nearly so legally fraught. reply OgsyedIE 19 hours agorootparentI'll go looking for the citation and it may take a couple hours but I'll point out that FWIW my info is drawn from some academic surveying vBulletin and Xenforo site owners in the 2010s so I wouldn't be surprised if they aren't applicable anymore. reply OgsyedIE 17 hours agorootparentUpdate: My apologies. I've totally confabulated old blog posts from Antone Johnson with TSPA articles and some Steven Myers papers. The actual figure is a median of 1 subpoena per annum per 430k users if the majority of the users are under 30. reply kstrauser 17 hours agorootparentNo problem. I thought that seemed on the high side but didn’t have any stats to counter with. Which paper does 430k come from? I’d like to squirrel that away for later. reply immibis 9 hours agorootparentprevNote that getting a subpoena isn't \"legally fraught\". You're being called on to assist in an investigation of someone else, not in trouble yourself. reply immibis 9 hours agoparentprevhttps://wiki.archiveteam.org/index.php/Deathwatch reply happosai 14 hours agoparentprevEh, it's not new to federated sites. Many of the web sites I frequented a decade a go are dead. Or enshittified useless so I visit them rarely anymore. It was sad to see say, the \"user friendly\" webcomic go away. But I enjoyd it in the time. Just live the moment. Don't expect even the big websites and apps of today to last - not at least in the form you enjoy. reply mschuster91 19 hours agoparentprev> Federated networks like Mastodon and Lemmy are going to get people well-acquainted with websites shutting down. It's hard work (time, money, etc.) to run these things for people, and people start to really lean on them. Mastodon is filled with such utterly basic UX issues. You move instances because the old one announces a shutdown? No old posts visible, no import possible. You want to see the history of an old account on another instance? The oldest toot you'll see is the first one that your instance picked up from that account. You have to switch to their instance to see old toots - there's a helpful link at the end of the feed, but it's still annoying. \"Trending\" topics only carry stuff happening on your server, and most of it is days old garbage. Search is horribly broken and inconsistent. reply zimpenfish 13 hours agorootparent> You move instances because the old one announces a shutdown? No old posts visible, no import possible. But this isn't \"utterly basic\" to solve on the backend due to how ActivityPub (currently) works. First you have to allow backdated posts[0] (not supported in the spec) which requires a mechanism to stop them being sent out (else they'll appear in current timelines[0]) but also you need a mechanism to send them out (to update the old URLs except how does the new instance know where the old instance sent the status? And how do you prove that you have the right to even request the change?) These are probably not insurmountable but they do require a lot of thinking about! [0] I ran into these importing an old Twitter bot into my Akkoma instance. I had to modify the server code and it was not a fun time. reply mschuster91 10 hours agorootparent> But this isn't \"utterly basic\" to solve on the backend due to how ActivityPub (currently) works. They're basic for the user. I know a few people who left Mastodon for good after the second or third time they had to shift servers. That kind of stuff should have been thought of from the beginning... > to update the old URLs except how does the new instance know where the old instance sent the status? And how do you prove that you have the right to even request the change? The same way an account move is currently reported to the instances where followers reside and handled there - the account-move operation would only need to do a full re-scan of the old profile. That's a ton of traffic for people with followers from many instances, I agree, but the source instance could trigger the creation of something like a data dump that destination instances can download without hitting the API. reply zimpenfish 9 hours agorootparent> something like a data dump that destination instances can download without hitting the API That gets you the old statuses, great. How do you then insert them into your existing instance? You can't just repost them because they'll appear with new timestamps (bad). You can't just repost them with old timestamps because servers and clients assume \"just arrived == now\" (bad). If you're using sequential IDs on your status table, good luck with that because I'm pretty sure someone has taken the shortcut of using that instead of the timestamp. Assuming you can work all those out, now you need to update the old URLs in the follower timelines to point to the new URLs (unless we punt on this and just let the old timeline sit around as it.) Except you don't know who got those statuses when they were posted - the old instance would need to have kept all the queue records for every post and be willing to supply them to the new instance. Or you can \"eh\" that and send them out to the new followers (except we don't want to do that because it confuses current instances and clients to get old timestamps at a new time) but that doesn't mean everyone will be updated. Or you can try and persuade the old instance to redirect each old status to its new URL once you've updated the software and protocol and clients to allow for status redirection, obviously, and worked out how to verify that server X is actually allowed to redirect A@Y's old statuses and isn't some hijacker / spammer / whatever and ... I've not even given this much thought - I'm sure people who actually dwell in ActivityPub and security worlds can give a much better explanation of why it's not at all easy to implement. > That kind of stuff should have been thought of from the beginning... Yep, can't disagree that a whole heck of a lot more thought should have been put into the AP protocol from the start. reply BeFlatXIII 1 hour agorootparentprevTrending topics were a waste to add, anyway. reply r3trohack3r 20 hours agoprevFederated networks like Mastadon strike me as being centralization at scale. They don’t appear to solve any of the power dynamics of users and operators - users are still at the mercy of the operator - and they run on either altruism or monetization. Mastadon appears to have successfully created N copies of the Facebook problem, which is definitely better than where we were. reply MBCook 19 hours agoparentI like Mastodon, it’s the only Twitter like thing I use. But I think this just reflects the facts. Centralization works and is highly preferable for many users. Just like in the only big federated service: email. Yes you can run your own. But there are a lot of costs in terms of time/complexity/knowledge/trust to that. Outsourcing it to someone else is really nice. You don’t need one big instance like Twitter was. Having a small handful of big ones works well too. But the dream some people seemed to have where everyone should run their own instance alone or with a few friends was never going to happen. reply pessimizer 18 hours agorootparent> Centralization works and is highly preferable for many users. I don't think users care about that at all, and if they have it explained to them, hate it. I think the real problem is that we haven't decentralized ownership and decisionmaking, instead we shattered big dictatorships into little fiefdoms, often run by local gangs (as one would expect.) Arguing that federation should automatically solve our problems with social media is like the US argument for \"state's rights.\" You had one problem, now you have 50. This is also exacerbated by the fact that people can't migrate. That would seem like it should be a developer priority to enable competition between instances, but instead people get irritated when asked about it at all. Every post locks you in farther to a particular instance. If people can leave on a whim, bad instances would starve. Instead of people being able to vote with their feet, the politics of mastodon all revolve around punishing other instances for various examples wrongthink by defederating. So now it's little fiefdoms at war with each other, you have to be in the in-crowd of your likely randomly chosen instance to have a say about it, and if you leave you lose everything. reply jeroenhd 12 hours agorootparentMy experience is that tons of people heard about Mastodon when the first wave of Musk bullshit hit Twitter and they immediately had an allergic reaction to having to pick a server. They don't realise there's no practical difference from email (which they're already using) but somehow the need to pick a server baffles and confuses the average social media user. Instead, everyone seems to be joining Bluesky now, which is also federated but doesn't mention it anywhere so users can just join the main instance. I expect this will cause massive problems in the future when federation will start taking place on a serious scale and the risks of misleading users by using similar usernames on other servers start applying. People don't know the network is federated and there's no easy way to read up about it without diving into dev documents. reply steveklabnik 6 hours agorootparentEven the “main instance” on bluesky is a cluster of instances; it’s just not exposed in a way that causes the choice issue. And since you have full account portability, if you ever want to change, it’s at least possible. reply broodbucket 18 hours agorootparentprev>Yes you can run your own. But there are a lot of costs in terms of time/complexity/knowledge/trust to that. >Outsourcing it to someone else is really nice. Yeah but the key thing is that you can choose your provider. Email isn't a walled garden that can be enshittified because you can just migrate somewhere else - yes it's a huge pain and has a bunch of drawbacks, but you can do it, and people do do it. Moving to a different Mastodon instance is a way smaller transition than moving from Twitter to another social media platform entirely. The Fediverse has a bunch of issues but I don't think we should think about it as \"running your own\", we should think of it as \"choosing the provider that best fits your needs\", as many have with Gmail. reply Yodel0914 18 hours agoparentprevAs always, it depends. I'm on a mastodon instance centered around a fairly specific topic, whose members donate (more than) enough to cover the costs of running the instance. Of course, it still relies on the benevolence of the guy who runs and maintains the instance. He actually takes a fee out of the donations each month to pay for his time, but it's a token amount. reply LeoPanthera 19 hours agoparentprev> users are still at the mercy of the operator Mastodon allows you to be the operator, if you so choose. reply ketzo 19 hours agorootparentI think OP’s point is that most users don’t choose to do so. Whether because of lack of ability, interest, time, whatever, people would mostly rather just be users. reply mschuster91 18 hours agorootparentprev> Mastodon allows you to be the operator, if you so choose. ... and if you forget a critical update or you see it too late, you'll get hacked. Self-hosting anything comes with serious challenges that most people only realize in hindsight. reply Nathan2055 18 hours agoparentprevThis is why I believe that Bluesky and the AT protocol is a significantly more attractive system than Mastodon and ActivityPub. Frankly, we’ve tried the kind of system ActivityPub offers before: a decentralized server network ultimately forming one big system, and the same problems have inevitably popped up every time. XMPP tried to do it for chat. All the big players adopted it and then either realized that the protocol wasn’t complex enough for the features they wanted to offer or that it was much better financially to invest in a closed system. Sometimes both. The big providers split off into their own systems (remember, Google Talk/Hangouts/Chat and Apple iChat/FaceTime both started out as XMPP front-ends) and the dream of interconnected IMing mostly died. RSS tried to do it for blogs. Everyone adopted it at first, but eventually content creators came to the realization that you can’t really monetize sending out full-text posts directly in any useful way without a click back to the originating site (mostly defeating the purpose), content aggregators realized that offering people the option to use any front-end they wanted meant that they couldn’t force profitable algorithmic sorts and platform lock-in, and users overwhelmingly wanted social features integrated into their link aggregators (which Google Reader was famously on the cusp of implementing before corporate opted to kill it in favor of pushing people to Google+; that could have potentially led to a very different Internet today if it had been allowed to release). The only big non-enthusiast use of RSS that survives is podcasts, and even those are slowly moving toward proprietary front-ends like Spotify. Even all the way back to pre-Web protocols: IRC was originally a big network of networks where every server could talk to every other server. As the system grew, spam and other problems began to proliferate, and eventually almost all the big servers made the decision to close off into their own internal networks. Now the multi-server architecture of IRC is pretty much only used for load balancing. But there’s two decentralized systems that have survived unscathed: the World Wide Web over HTTP and email over SMTP. Why those two? I believe that it’s because those systems are based on federated identities rather than federated networks. If you have a domain name, you can move the website attached to it to any publicly routable server and it still works. Nobody visiting the website even sees a difference, and nobody linking to your website has to update anything to stay “connected” to your new server. The DNS and URL systems just work and everyone just locates you automatically. The same thing with email: if you switch providers on a domain you control, all the mail still keeps being routed to you. You don’t have to notify anyone that anything has changed on your end, and you still have the same well-known name after the transition. Bluesky’s killer feature is the idea of portable identities for social media. The whole thing just ties back to a domain name: either one that you own or a subdomain you get assigned from a provider. That means that picking a server isn’t something the average person needs to worry about, you can just use the default and easily change later if you want to and your entire identity just moves with you. If the server you’re on evaporates, the worst thing that you lose is your activity, and that’s only if you don’t maintain any backups somewhere else. For most people, you can just point your identity at a different server, upload a backup of your old data, and your followers don’t even know anything has changed. A sufficiently advanced client could probably even automate all of the above steps and move your whole identity elsewhere in one click. Since the base-level object is now a user identity rather than a server, almost all of the problems with ActivityPub’s federation model go away. You don’t deal with blocking bad servers, you just block bad people (optionally using the same sorts of “giant list” mechanisms already available for places like Twitter). You don’t have to deal with your server operator getting themself blacklisted from the rest of the network. You don’t have to deal with your server operator declaring war on some other server operator and suddenly cutting you off from a third of your followers. People just publish their posts to a server of their choice, others can fetch those posts from their server, the server in question can be moved wherever without affecting anything for those other users, and all of the front-end elements like feed algorithms, post display, following lists and block lists, and user interface options could either be handled on the client-side or by your choice of (transferable) server operator. Storage and bandwidth costs for text and (reasonable) images are mostly negligible at scale, and advertising in clients, subscription fees, and/or offering ancillary services like domain registration could easily pay for everything. ActivityPub sounds great to nerds who understand all of this stuff. But it’s too complicated for the average social media user to use, and too volatile for large-scale adoption to take off. AT protocol is just as straightforward to understand as email (“link a website domain if you already have one or just register for a free one on the homepage, and you can easily change in the future”), doesn’t require any special knowledge to utilize, and actually separates someone’s identity and content from the person running the server. Mastodon is 100 tiny Twitters that are somewhat connected together, AT actually lets everyone have their own personal Twitter and connect them all together in a way that most people won’t even notice. reply ChrisArchitect 13 hours agorootparentGood post of historical reminders and I appreciate the framing of bluesky's identity approach. Never was sold on Fediverse/ActivityPub as being it and not a fan yet of Bluesky's slow-building-in-public approach but am intrigued by this key facet of the main role the personal domain takes. How can one easily change/migrate their AT identity if they change domains? How is their whole social history transferrable? Like that was one of the problems/unclear things to most about Mastodon - that it actually wasn't that easy to move instances because sure your identity could move but your posts would be on the old instance, so it wasn't really that portable. I'm all about the permanence and data preservation, so I don't want to commit to a platform now without assured control over my data and ability to maintain history/identity in a move. Have enjoyed the centralization and longevity for too long on a place like Twitter to get all loose and ephemeral now. reply steveklabnik 5 hours agorootparentTo change domains, you: Go into settings, click change handle. Type in the domain you wish to change to. Click next. It’ll give you some stuff to put into a DNS TXT entry on that domain. Do that. Click “verify DNS record.” And that’s it. You’re done. Everything is “transferred.” The history is transferable for the same reason a domain is transferable to another web host: what does URL stand for again? Uniform resource locator? That is, it’s how you locate something, not what that something is. In this case, the domain isn’t actually your identity: your identity is your DID, “decentralized identifier.” To hand wave slightly, all your content is signed with your DID information, not the URL you use. There’s a service that resolves domains to DIDs. So changing your domain means changing what that service resolves to. That’s why I put “transferred” in quotes above; when changing domains, nothing actually moves. Now, if you want to change the server where your data is hosted, your PDS, it’s effectively the same thing: you spin up a new server, backfill your data by a backup or by replaying it from the network, and then say “hey here’s a new PDS” to the network. All of this is possible because of the fundamental design choices atproto makes over the ones ActivityPub does. Happy to answer more questions. But if data ownership and preservation is a thing for you, you should like atproto. reply jordigh 17 hours agoprevThe important bit > But the recent Mastodon upgrade has caused a significant amount of performance degradation, and I think the only way to really solve it is going to be to throw a lot of money into hardware. I found the latest upgrade also making some odd UX decisions. Content warnings got a weird new styling and it's not clear anymore how to hide images separately from hiding the text. Are the mastodons okay? There are good things too, don't get me wrong, like grouping notifications instead of getting a notification flood on a popular toot. That's nice. But what's up with perf regressions and (in my opinion) UX regressions? reply renchap 11 hours agoparentThe content warning styling may be reverted (its already done in `main`), and we are not aware of any performance issues with 4.3, it's in fact the opposite from all the feedback we got. I am really curious of what is happening here and asked the admin to provide more information. reply numpad0 14 hours agoprev [–] Why are these Twitter clones always so resource intensive and finicky? Twitter is just \"IRC in reverse\", if you take literal descriptions transitive relations in IRC(v2) and moved around nouns, lots of it should apply to Twitter/Bluesky/Mastodon well. RDB gurus can probably recreate lots of APIs as tables on bare MySQL too. It doesn't make sense to me that such a thing take so much dev and ops cost compared to IRCv2 servers, other than for the fact that modern webdev just so happens to be extremely bloated, especially when extremely competent and high spirited developers are giving up like this. Are we doomed to keep adding more RAM and more disk and more bandwidth to catch up with ever-growing bloat? reply sigmar 14 hours agoparent>extremely competent and high spirited developers are giving up like this. I'm pretty sure the median IRC server runs for much less than 7.5 years. I don't think anyone expects volunteers to dedicate decades of their life to admin duty. and it seems fine and healthy for the ecosystem that he is telling people they have a few months to move their bots to a different server. reply lanstin 9 hours agorootparentI didn't read TFA but was there a way to find the migrated bots? honestly, for some quirky reason, the bots are a big chunk of my enjoyment of social media (from Opposum's every hour to randomly generated 3 body simulations of suns in 3d to flight tracking to weather alerts to CO_2 levels), and I have so much enjoyed botsinspace bots since joining mastodon (which is by far the most enjoyable/least addictive/least evil social media I've found). reply viraptor 13 hours agoparentprevThe post shows where the cost is - storage and bandwidth. With IRC servers you're not expected to serve the all the history forever, with a website around it, persistent subscriptions, outbound queued notifications, etc. On IRC people also pretty much expect missed messages and splits from time to time. Those are very different services. reply kraftman 10 hours agorootparentYeah but are those valid reasons? Bandwidth is unlimited for most dedicated servers, and 190 GB for 7 years of data isn't a lot; it could fit on my phone 5 times. reply viraptor 10 hours agorootparent190GB in the database. That didn't include media. I'm assuming the media part is not served from the same host since that can easily overshadow other traffic. reply koito17 14 hours agoparentprevNot related to Mastodon, but in the case of Matrix, the server software ranges from \"runs on a raspberry pi with zero issues\" (Conduit) to \"even with 16 GB of RAM, federating with a large enough room will exhaust Python's heap\" (Synapse). In the case of Conduit, a Matrix server with a few private rooms and users consumed only 32 MB of RAM, using RocksDB for storage. The equivalent on Synapse required about 5x as much memory, despite using SQLite. In practice, Synapse instances will use Postgres since many appservice plugins specifically require Postgres and don't support SQLite. Not to mention, SQLite isn't optimized for frequent, concurrent writes. I do sincerely think the choice of Rails, and the fact Ruby only got a compiler people use recently, means that most Ruby programs require fairly beefy processors and plenty of memory in order to keep up with a few hundred clients. Of course, I am extrapolating based off my experience running Synapse (a Matrix server) with Postgres. There is a chance Mastodon scales much better. reply robobro 14 hours agoparentprevFrom what I understand, IRC doesn't hold messages for extended periods of time or allow media uploads, while fediverse does, so that's one big difference. reply numpad0 5 hours agorootparentDo they have to? Twitter does and that's noble, but can't the server, say, per-user logrotate, sign that with webserver cert, and send via email or force download or push to HTML localStorage thing when user is on desktop and then forget about it? reply r14c 12 hours agoparentprevit really, really varies by implementation. mastodon is popular (for some reason), but far from the most efficient activitypub server. akkoma derivatives are more limited by postgresql's IO performance than the phoenix app itself. unfortunately, what people know is a really slow rails app. i haven't personally operated a misskey derivative, but based on my experience writing network servers on node.js it probably performs better than rails XD the same applies for clients. there are nice native apps and some pretty efficient web clients, but they aren't the default on the most popular server software so nobody uses them. reply strken 14 hours agoparentprevI think there are issues with hotspots. The most popular tweets are seen by a big chunk of the userbase, which means they have to operate on a fanout model where each tweet is pushed to individual followers. I believe IRC doesn't operate like that. The messages delivered to each user don't need to be retained, and I assume the size of the largest channels is in the tens or hundreds of thousands. reply sureglymop 12 hours agoparentprevRead the post. This specific server is created as a \"playground for bots\", ran by one hobbyist volunteer. Nothing in the post is surprising or says anything about the architecture of Mastodon-like software. reply mardifoufs 14 hours agoparentprevBecause twitter isn't just IRC in reverse? reply lifthrasiir 12 hours agoparentprevDo you really think those \"extremely competent and high spirited developers\" haven't tried? Not only that there are numerous attempts to extend or replace IRC, but those attempts generally understood what is fundamentally different between an ephemeral room-base chatting protocol and a protocol that allows efficient traversal, aggregation and streaming of possibly large social graph and interactions. reply noduerme 12 hours agorootparentVery incisive. Your post got me thinking: Rather than a federated system like Mastodon, what sort of protocol could (a) function as a temporary, room-based, privately hosted chat, that also (b) encoded the social graph and aggregated interactions in a distributed way that could be polled by any client? It seems like the past 30 years have designed either for the decentralized, chat-first model, or else the centralized social-first model (federated or not). I'm thinking of what an LLM could do in terms of summarizing and compressing both at the client level, so large aggregate searches would know where to look in a decentralized universe of chat rooms to more or less emulate the data-retrieval functionality of a massive centralized social network... reply lifthrasiir 12 hours agorootparentWhile technically different, relays in the ATProto protocol serve a similar purpose; it can be thought as a materialized view in RDB as far as I understand. So if ATProto proves to be successful in the future, extensions to relays might make that possible transparently. (One big limitation of relays right now is that they have to consume the entire repository at once, making it hard for individuals to host their own relays.) reply noduerme 11 hours agorootparentWhat about like just readable fragments of materialized views that were encoded into the messages themselves. So that a sharp local context and a blurrier larger context could be reconstructed from any given message. Sort of like a Mipmap. And with maybe 10% of the messages in a thread you could reconstruct a fairly accurate representation of the whole thread, at least good enough to run a search on. Every client could serve as a relay that stored its own threads and a constellation of associated mipmaps, and, if some were missing messages, it would be obvious which other clients needed to be checked for the missing portions the next time they logged on. Old/archaic data could be warehoused by clients that chose to do so. No central servers at all, you just crawl client to client looking for the connections, and build your own graph based on what you're looking for. reply neonsunset 11 hours agoparentprevThese clones are often written in unimaginably inefficient languages like Ruby or Python. If I’m not mistaken, Twitter uses Scala. That would have been a good start. For all the indie-ness, one of these clones could have been written in hand-tuned Rust or C# or Kotlin to respect the resources of people who would run them out of their own pocket. But sadly this has not happened yet. reply goodpoint 10 hours agoparentprevMastodon is not a twitter clone. Unfortunately it's written in ruby and it has no quotas on the amount of images and videos uploaded or downloaded per-account. Also it is not designed to scale horizontally or leverage any form of p2p. reply mplewis 14 hours agoparentprev [–] Scrollback. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Botsin.space, a server for bot creators, artists, and students, will shut down, with new signups closed and the site transitioning to read-only mode by December 15th, 2024.- The decision to close is due to unsustainable expenses and performance issues, despite reliance on Patreon and PayPal donations.- Users are encouraged to migrate accounts and support other community-oriented instances, with assistance provided for a smooth transition until at least March 2025."
    ],
    "commentSummary": [
      "Botsin.space, a Mastodon instance dedicated to bot accounts, is closing due to performance and scalability challenges, reflecting common issues in decentralized networks.",
      "The fediverse, a decentralized social network, often encounters difficulties with network effects and server maintenance, leading to the shutdown of instances like botsin.space.",
      "The closure underscores the challenges of maintaining federated networks without substantial resources, prompting some users to prefer centralized platforms or explore alternatives like Lemmy and Bluesky, which offer unique approaches to decentralization."
    ],
    "points": 191,
    "commentCount": 114,
    "retryCount": 0,
    "time": 1730236738
  },
  {
    "id": 41992975,
    "title": "Async Rust is not safe with io_uring",
    "originLink": "https://tonbo.io/blog/async-rust-is-not-safe-with-io-uring",
    "originBody": "Async Rust is not safe with io_uring October 30, 2024 by Tzu Gwo TL;DR1. Clone this repository on a Linux system that supports io_uring.2. Try switching these two lines.3. Execute cargo run for a while. The demo shows that even though the behavior appears similar, TCP connections leak when using the io_uring driver but not with the epoll driver. I've also tested this across various io_uring runtimes, and it turns out to be a common issue across all of them. Barbara's TCP connection mysteriously leaked Barbara had a lot of experience developing web services with async Rust. One day, she read a blog about io_uring, which described it as the next-generation async I/O interface for Linux. Interested, Barbara decided to try it out in her sidecar web service. Rust's \"async/await\" model is separate from the async runtime and I/O interface implementations, making it easy to switch between different runtimes. Barbara was very familiar with Tokio, the most popular async runtime in Rust, which uses epoll for I/O interface. So, she looked for an async runtime that supported io_uring to transform her web service into an io_uring-based version. After some research, Barbara discovered several async runtimes like glommio, monoio, and compio that supported io_uring. She decided to give one of them a try—monoio, in particular, which provided both epoll and io_uring interfaces and allowed for easy switching. It seemed like the perfect fit for Barbara's io_uring exploration. With her familiarity with Tokio, Barbara quickly wrote her first HTTP server demo: Barbara thought, \"Great, this looks no different from a typical Tokio program—first bind to an address, then continuously accept new TCP connections in a loop and process them.\" Barbara then considered her next steps. She decided to learn how to implement asynchronous control, such as timeouts, so that if the TCP listener did not accept a connection for a while, it could switch to handling some sidecar tasks (like logging) before resuming acceptance: Using the concurrency primitive \"select\" to add timeouts to futures worked well with io_uring. Barbara was pleased and quickly updated her web service to use io_uring, eventually deploying it. Everything ran smoothly until one day she noticed something odd in the client logs: some requests were never processed. To investigate, Barbara wrote a minimal example, only to find the issue was far more complex than expected. Barbara found that while the client running in a child thread was connecting correctly, the server in the main thread wasn’t proceeding as it should. Instead, the timeout kept getting triggered, as if the client's connection had vanished. A TCP connection leak had occurred. And it wasn't just monoio—this issue affected all async runtimes that used io_uring. What’s going on? Before understanding why using \"select\" for timeout control in an io_uring-based async runtime leads to TCP connection leaks, we need to first understand why this issue doesn’t occur with epoll. The entire async Rust ecosystem is built around a core asynchronous primitive from the standard library: Future. Its definition is as follows: In Rust, all asynchronous operations—not just those manually written by async library developers but also those written by users using \"async\" blocks—are defined as recursive future structures, which get instantiated when \".await\" is called. The entire structure contains all the state that must be saved across suspended futures during pending operations. The async executor is then responsible for repeatedly calling the \"poll\" method to advance this state until completion. Consider this example async block: will transform to below by compiler: For a more detailed explanation of futures and how they are executed, I recommend reading ihciah's blog. He is one of the core authors of monoio. Async Rust makes a few core assumptions about futures:1. The state of futures only change when they are polled.2. Futures are implicitly cancellable by simply never polling them again.Futures bound to epoll adhere to these assumptions, which relates to the mechanism of epoll: epoll is not an asynchronous syscall mechanism; it’s an event notification mechanism. In the above example, the actual behavior of the \"listener.accept()\" future, simplified, is as follows: \"self.accept()\" runs synchronously, either succeeding by obtaining a TCP stream or encountering a \"would block\" exception, leaving it in a pending state until the kernel is ready. To cancel this operation, you simply stop polling, as the syscall only happens during polling. However, io_uring-bound futures break these two assumptions:1. The syscall is executed asynchronously by the kernel, not during polling. The kernel commit the TCP stream into a kernel / user shared ring buffer, meaning the accept event is completed implicitly.2. You cannot simply cancel an io_uring-bound future by stopping polling, as the kernel might complete the syscall at any time, even during the cancellation progress.A step-by-step explanation of the earlier example will make this process clearer: How to solve this? Before discussing the solution, we need to break the problem down into two parts:1. I/O Safety: Ensuring that accepted TCP streams are properly closed without leaking connections.2. Halt Safety (proposed by Yoshua Wuyts): Handling connections that have already been opened when they are cancelled, allowing them to continue being processed.I/O Safety First of all, we are fortunate that the I/O safety problem can be addressed now, which safe Rust aims to ensure this in the future. Rust provides the Drop trait to define custom behavior when a value is cleaned up. Thus, we can do something like this: We just need to encourage async runtimes to implement this fix. Halt Safety Halt safety is more complicated. Monoio provides a component called \"cancellable I/O\" to properly handle the cancellation of io_uring-bound futures. A complete example can be found here: cancellable I/O example. You can run this branch to see that the connection handling behavior now matches that of epoll. Here, I’ll show a simplified usage: As you can see, besides performing the accept operation in the regular select branch, the timeout branch explicitly cancels the accept future. Afterwards, it proceeds to .await the accept future again to confirm if a TCP stream was ready during the timeout period. Monoio's component partially solves the problem, but there's still an issue: since a future is a recursive structure, an io_uring-bound future may not be directly at the place where cancellation occurs: Canceling a future that contains an io_uring-bound future will also affect its inner io_uring-bound futures. This means that the cancellation safety of io_uring-bound futures is \"contagious.\" Simply converting an io_uring-bound future to cancellable I/O does not solve all the issues. Another key issue is that if you forget to handle the cancellation of an io_uring-bound future, there are no compile-time checks to catch it. For io_uring-bound futures, you need to \".await\" them after cancellation to see if they have completed. This means they must be used exactly once, a concept called linear types, which ensures correct usage of resources at compile time. Unfortunately, Rust lacks the support for this kind of type system. For more details on why adding linear logic to Rust is challenging, you can refer to Without Boats' blog: Changing the rules of Rust. Why wrote this? There has been a lot of discussion about memory safety in the context of io_uring. For more details, you can refer to these resources: • Async Cancellation by yoshuawuyts • Notes on io-uring by withoutboats • Async Rent by ihciah However, the community rarely addresses I/O safety and halt safety with io_uring in async Rust. I'm presenting a specific case to draw attention to this topic. The title of this blog might sound a bit dramatic, but everyone has different definitions and understandings of \"safety.\" What do you think about this issue: • Keep things as they are; I/O safety and halt safety do not need guarantees from the language. • Rust should ensure I/O safety (this is already a goal outlined in the RFC, but not yet implemented in Rust.) • Rust should ensure halt safety (rarely discussed!)",
    "commentLink": "https://news.ycombinator.com/item?id=41992975",
    "commentBody": "Async Rust is not safe with io_uring (tonbo.io)173 points by ethegwo 10 hours agohidepastfavorite116 comments withoutboats3 6 hours agoThis is nothing to do with async Rust; monoio (and possibly other io-uring libraries) are just exposing a flawed API. My ringbahn library written in 2019 correctly handled this case by having a dropped accept future register a cancellation callback to be executed when the accept completes. https://github.com/ringbahn/ringbahn reply pjdesno 6 hours agoparentDoesn't this close the incoming connection, rather than allowing another pending accept to receive it? reply withoutboats3 6 hours agorootparentYou're right. Looking at my actual code, instead I stored the accept to be yielded next time you call accept and only cancel an accept call if you drop the entire listener object mid-accept. The solution proposed in this post doesn't work, though: if the accept completes before the SQE for the cancellation is submitted, the FD will still be leaked. io-uring's async cancellation mechanism is just an optimization opportunity and doesn't synchronize anything, so it can't be relied on for correctness here. My library could have submitted a cancellation when the future drops as such an optimization, but couldn't have relied on it to ensure the accept does not complete. reply Arch-TK 5 hours agorootparent> You're right. Looking at my actual code, instead I stored the accept to be yielded next time you call accept and only cancel an accept call if you drop the entire listener object mid-accept. This is still a suboptimal solution as you've accepted a connection, informing the client side of this, and then killed it rather than never accepting it in the first place. (Worth noting that linux (presumably as an optimisation) accepts connections before you call accept anyway so maybe this entire point is moot and we just have to live with this weird behaviour.) Now it's true that \"never accepting it in the first place\" might not be possible with io_uring in some cases but rather than hiding that under drop the code, it should be up front about it and prevent dropping (not currently possible in rust) in a situation where there might be uncompleted in-flight requests before you've explicitly made a decision between \"oh okay then, let's handle this one last request\" and \"I don't care, just hang up\". reply withoutboats3 5 hours agorootparentIf you want the language to encode a liveness guarantee that you do something meaningful in response to an accept rather than just accept and close you do need linear types. I don't know any mainstream language that encodes that guarantee in its type system, whatever IO mechanism it uses. reply amluto 3 hours agorootparentThis all feels like the abstraction level is wrong. If I think of a server as doing various tasks, one of which is to periodically pull an accepted connection off the listening socket, and I cancel that task, then, sure, the results are awkward at best and possibly wrong. But I’ve written TCP servers and little frameworks, asynchronously, and this whole model seems wrong. There’s a listening socket, a piece of code that accepts connections, and a backpressure mechanism, and that entire thing operates as a unit. There is no cancellable entity that accepts sockets but doesn’t also own the listening socket. Or one can look at this another way: after all the abstractions and libraries are peeled back, the example in the OP is setting a timeout and canceling an accept when the timeout fires. That’s rather bizarre — surely the actual desired behavior is to keep listening (and accepting when appropriate) and do to the other timed work concurrently. It just so happens that, at the syscall level, a nonblocking (polled, selected, epolled, or even just called at intervals) accept that hasn’t completed is a no-op, so canceling it doesn’t do anything, and the example code works. But it would fail in a threaded, blocking model, it would fail in an inetd-like design, and it fails with io_uring. And I really have trouble seeing linear types as the solution — the whole structure is IMO wrong. (Okay, maybe a more correct structure would have you “await connection_available()” and then “pop a connection”, and “pop a connection” would not be async. And maybe a linear type system would prevent one from being daft, successfully popping a connection, and then dropping it by accident.) reply gpderetta 3 hours agorootparent> maybe a more correct structure would have you “await connection_available()” and then “pop a connection” This is the age-old distinction between a proactor and reactor async design. You can normally implement one abstraction of top of the other, but the conversion is sometimes leaky. It happens that the underlying OS \"accept\" facility is reactive and it doesn't map well to a pure async accept. reply amluto 2 hours agorootparentI’m not sure I agree. accept() pops from a queue. You can wait—and-pop or you can pop-or-fail. I guess the former fits in a proactor model and the latter fits in a reactor model, but I think that distinction misses the point a bit. Accepting sockets works fine in either model. It breaks down in a context where you do an accept that can be canceled and you don’t handle it intelligently. In a system where cancellation is synchronous enough that values won’t just disappear into oblivion, one could arrange for a canceled accept that succeeded to put the accepted socket on a queue associated with the listening socket, fine. But, in general, the operation “wait for a new connection and irreversibly claim it as mine IMO just shouldn’t be done in a cancellable context, regardless of whether it’s a “reactor” or a “proactor”. The whole “select and, as one option, irrevocably claim a new connection” code path in the OP seems suspect to me, and the fact that it seems to work under epoll doesn’t really redeem it in my book. reply doctorpangloss 17 minutes agorootparentprevTCP connections aren’t correct representations of the liveness of sessions. The incorrectness is acute when it’s mobile browsers connecting over LTE to load balanced web servers. That’s why everyone reinvents a session idea on top of the network. reply gpderetta 3 hours agorootparentprev> Worth noting that linux (presumably as an optimisation) accepts connections before you call accept anyway so maybe this entire point is moot and we just have to live with this weird behaviour. listen(2) takes a backlog parameter that is the number of queued (which I think it means ack'd) but not yet popped (i.e. listen'd) connections. reply ethegwo 3 hours agorootparentprev> if the accept completes before the SQE for the cancellation is submitted, the FD will still be leaked. If the accept completes before the cancel SQE is submitted, the cancel operation will fail and the runtime will have a chance to poll the CQE in place and close the fd. reply withoutboats3 2 hours agorootparentHmm, because the cancel CQE will have a reference to the CQE it was supposed to cancel? Yes, that could work. reply ethegwo 6 hours agoparentprevThe rest of this blog discusses how to continue processing operations after cancellation fails, which is blocked by the Rust abstraction. Yes, not everyone (probably very few) defines this as a safety issue, I wrote about this at the end of the blog. reply withoutboats3 6 hours agorootparentI don't consider Yosh Wuyts's concept of \"halt safety\" coherent, meaningful or worth engaging with. It's true that linear types would enable the encoding of additional liveness guarantees that Rust's type system as it exists cannot encode, but this doesn't have anything to do with broken io-uring libraries leaking resources. reply ethegwo 5 hours agorootparentContinuing process after cancellation failure is a challenge I face in my actual work, and I agree that \"halt-safety\" lacks definition and context. I have also learned and been inspired a lot from your blogs, I appreciate it. reply lowbloodsugar 3 hours agorootparentprevAgree. When I hear “I wish Rust was Haskell” I assume the speaker is engaged in fantasy, not in engineering. The kernel is written in C and seems to be able to manage just fine. Problem is not Rust. Problem is wishing Rust was Haskell. reply airstrike 4 hours agoparentprevI look forward to your blog post running the code provided by the article and rebutting it And I mean that honestly, no sarcasm at all! reply ryansouza 1 hour agorootparentEven without sarcasm the wording here reads as a presumption that this person will do work (blog post) for your benefit. Their post not indicating any plans to do that is why it reads so sarcastically, a sort of “pull requests welcome” reply in a more rude way. reply infamouscow 3 hours agorootparentprevYou're replying to the author of ringbahn, whom also happens writes some of the best technical blog posts ever to grace this website on these topics. It is very difficult not to conclude you're either very ignorant, or trolling. reply airstrike 3 hours agorootparentWhat makes you think I don't know who I'm talking to? All I was trying to do was encourage another blog post. I literally went out of my way to try to sound nice and preemptively dismiss the chance that I was interpreted sarcastically. https://news.ycombinator.com/newsguidelines.html > Please respond to the strongest plausible interpretation of what someone says, not a weaker one that's easier to criticize. Assume good faith. reply itishappy 3 hours agorootparentprevAlternative explanation: They're a fan! reply withoutboats3 3 hours agorootparentprevnext [2 more] [flagged] airstrike 3 hours agorootparentnext [2 more] [flagged] withoutboats3 3 hours agorootparentMy sincere apologies if I read this uncharitably, I interpreted your comment about sarcasm to itself be sarcastic. I will not be publishing any such post. To clarify what you seem not to understand: the code in the blog post depends on a library called monoio, and based on the post's description of the behavior of that code (I haven't actually read the source for monoio), monoio contains a bug. I don't dispute that this code behaves incorrectly, just that it has anything to do with Rust's facility for async IO rather than with the specific IO library employed in the post. reply ajross 5 hours agoparentprevWell, it's \"about\" async Rust and io-uring inasmuch as they represent incompatible paradigms. Rust assumes as part of its model that \"state only changes when polled\". Which is to say, it's not really \"async\" at all (none of these libraries are), it's just a framework for suspending in-progress work until it's ready. But \"it's ready\" is still a synchronous operation. But io-uring is actually async. Your process memory state is being changed by the kernel at moments that have nothing to do with the instruction being executed by the Rust code. reply withoutboats3 4 hours agorootparentYou are completely incorrect. You're responding to a comment in which I link to a library which handles this correctly, how could you persist in asserting that they are incompatible paradigms? This is the kind of hacker news comment that really frustrates me, it's like you don't care if you are right or wrong. Rust does not assume that state changes only when polled. Consider a channel primitive. When a message is put into a channel at the send end, the state of that channel changes; the task waiting to receive on that channel is awoken and finds the state already changed when it is polled. io-uring is really no different here. reply ethegwo 3 hours agorootparent> Rust does not assume that state changes only when polled. I will replace to more exact description about this, thanks. reply ajross 3 hours agorootparentprevWhat you're describing is a synchronous process, though! (\"When a message is put...\"). That's the disconnect in the linked article. Two different concepts of asynchrony: one has to do with multiple contexts changing state without warning, the other (what you describe) is about suspending threads contexts \"until\" something happens. reply withoutboats3 3 hours agorootparentAgain you are wrong. A forum full of people who just like to hear themselves talk. I guess it makes you feel good in some way? With io-uring the kernel writes CQEs into a ring buffer in shared memory and the user program reads them: its literally just a bounded channel, the same atomic synchronizations, the same algorithm. There is no difference whatsoever. The io-uring library is responsible for reading CQEs from that ring buffer and then dispatching them to the task that submitted the SQE they correspond to. If that task has cancelled its interest in this syscall, they should instead clean up the resources owned by that CQE. According to this blog post, monoio fails to do so. That's all that's happening here. reply biorach 2 hours agorootparent> Again you are wrong. A forum full of people who just like to hear themselves talk. I guess it makes you feel good in some way? I think you're being unduly harsh here. There are a variety of voices here, of various levels of expertise. If someone says something you think is incorrect but it seems that they are speaking in good faith then the best way to handle the situation is to politely provide a correct explanation. If you really think they are in bad faith then calmly call them out on it and leave the conversation. reply nemothekid 14 minutes agorootparentI've been following withoutboats for ~6 years and it really feels like his patience has completely evaporated. I get it though, he has been really in the weeds of Rust's async implementation and has argued endlessly with those who don't like the tradeoffs but only have a surface level understanding of the problem. I think I've read this exact convo maybe 20+ times among HN, Reddit, Github Issues and Twitter among various topics including but not limited to, async i/o, Pin, and cancellation. reply biorach 2 minutes agorootparent> has argued endlessly with those who don't like the tradeoffs but only have a surface level understanding of the problem But that's really not what's going on here. ajross has an understanding of the fundamentals of async that is different to withoutboats'. ajross is setting this out in a clear and polite way that seems to be totally in good faith. withoutboats is responding in an extremely rude and insulting manner. Regardless of whether they are right or not (and given their background they probably are), they are absolutely in the wrong to adopt this tone. withoutboats3 4 minutes agorootparentprevI freely admit I’m frustrated by the discourse around async Rust! I’m also very frustrated because I feel I was iced out of the project for petty reasons to do with whom I’m friends with and the people who were supposed to take over my work have done a very poor job, hence the failure to ship much of value to users. What we shipped in 2019 was an MVP that was intended to be followed by several improvements in quick succession, which the Rust project is only now moving toward delivering. I’ve written about this extensively. My opinion is that async Rust is an incredible achievement, primarily not mine (among the people who deserve more credit than me are Alex Crichton, Carl Lerche, and Aaron Turon). My only really significant contributions were making it safe to use references in an async function and documenting how to interface with completion based APIs like io-uring correctly. So it is very frustrating to see the discourse focused on inaccurate statements about async Rust which I believe is the best system for async IO in any language and which just needs to be finished. ajross 2 minutes agorootparentprevAlternatively there's a problem with being \"really in the weeds\" of any problem in that you fail to poke your head up to understand other paradigms and how they interact. I live in very different weeds, and I read the linked article and went \"Oh, yeah, duh, it's racing on the io-uring buffer\". And tried to explain that as a paradigm collision (because it is). And I guess that tries the patience of people who think hard about async[1] but never about concurrency and parallelism. [1] A name that drives systems geeks like me bananas because everything in an async programming solution IS SYNCHRONOUS in the way we understand the word! ajross 1 hour agorootparentprev> If that task has cancelled its interest in this syscall, they should instead clean up the resources owned by that CQE. So, first: how is that not consistent with the contention that the bug is due to a collision in the meaning of \"asynchronous\"? You're describing, once more, a synchronous operation (\"when ... cancel\") on a data structure that doesn't support that (\"the kernel writes ...\" on its own schedule). And second: the English language text of your solution has race conditions. How do you prevent reading from the buffer after the beginning of \"cancel\" and before the \"dispatch\"? You need some locking in there, which you don't in general async code. Ergo it's a paradigm clash. Developers, you among them it seems, don't really understand the requirements of a truly async process and get confused trying to shoehorn it into a \"callbacks with context switch\" framework like rust async. reply withoutboats3 56 minutes agorootparentnext [2 more] [flagged] ajross 8 minutes agorootparentI think we just have to end this, your tone is just out of control and you're doing the \"assume bad faith\" trick really badly. But to pick out some bits where I genuinely think you're getting confused: > Rust has ample facilities for preventing you from reading from the buffer after cancellation The linked bug is a race condition. It's not about \"after\" and if you try to reason about it like that you'll just recapitulate the mistakes. And yes, rust has facilities to prevent race conditions, but they're synchronization tools and not part of async, and lots of developers (ahem) seem not to understand the requirements. ethegwo 2 hours agorootparentprevthe post only talks about \"future state\", maybe I'm not clearly to point out this. with epoll, accept syscall and future state changing is happened in the same polling, which io_uring is not. Once accept syscall is complete, future has already advanced to complete, but actually it is not at that moment in the real world Rust. reply withoutboats3 2 hours agorootparentIt's true, there's a necessary layer of abstraction with io-uring that doesn't exist with epoll. With epoll, the reactor just maps FDs to Wakers, and then wakes whatever Waker is waiting on that FD. Then that task does the syscall. With io-uring, instead the reactor is reading completion events from a queue. It processes those events, sets some state, and then wakes those tasks. Those tasks find the result of the syscall in that state that the reactor set. This is the difference between readiness (epoll) and completion (io-uring): with readiness the task wakes when the syscall is ready to be performed without blocking, with completion the task wakes when the syscall is already complete. When a task loses interest in an event in epoll, all that happens is it gets \"spuriously awoken,\" so it sees there's nothing for it to do and goes back to sleep. With io-uring, the reactor needs to do more: when a task has lost interest in an incomplete event, that task needs to set the reactor into a state where instead of waking it, it will clean up the resources owned by the completion event. In the case of accept, this means closing that FD. According to your post, monoio fails to do this, and just spuriously wakes up the task, leaking the resource. The only way this relates to Rust's async model is that all futures in Rust are cancellable, so the reactor needs to handle the possibility that interest in a syscall is cancelled or the reactor is incorrect. But its completely possible to implement an io-uring reactor correctly under Rust's async model, this is just a requirement to do so. reply 0x457 47 minutes agorootparent> But its completely possible to implement an io-uring reactor correctly under Rust's async model, this is just a requirement to do so. I don't get why people say it's incompatible with rust when rust async libraries work IOCP, which follows the similar model as io-uring? reply withoutboats3 14 minutes agorootparentTo be fair, I’m not sure if there exists any zero cost IOCP library. The main way people use IOCP is via mio via tokio. To make IOCP present a readiness interface mio introduces a data copy. This is because tokio/mio assume you’re deploying to Linux and only developing on windows and so optimize performance for epoll. So it’s reasonable to wonder if a completion based interface can be zero cost. But the answer is that it can be zero cost, and we’ve known that for half a decade. It requires different APIs from readiness based interfaces, but it’s completely possible without introducing the copy using either a “pass ownership of the buffer” model or “buffered IO” model. Either way, this is unrelated to the issue this blog post identifies, which is just that some io-uring libraries handle cancellation incorrectly. reply ordu 5 hours agoprev> The title of this blog might sound a bit dramatic, but everyone has different definitions and understandings of \"safety.\" Still in Rust community \"safety\" is used in a very specific understanding, so I don't think it is correct to use any definition you like while speaking about Rust. Or at least, the article should start with your specific definition of safety/unsafety. I don't want to reject the premise of the article, that this kind of safety is very important, but for Rust unsafety without using \"unsafe\" is much more important that an OS dying from leaked connections. I have read through the article looking for rust's kind of unsafety and I was found that I was tricked. It is very frustrating, it looks to me as a lie with some lame excuses afterwards. reply ozgrakkurt 11 minutes agoparentI agree with these points but as someone that has been using rust for a long time now, this “you can’t do that, it is not good” attitude got very stale by now. Not saying it is bad to say these stuff, anyone should do what they want in the end including saying this. But just sad that this is very common in Rust discussions and it gives a bad taste to me reply airstrike 5 hours agoparentprevIt's definitely clickbaity. The author knew exactly what they were doing. Time to flag, hide and move on. reply ethegwo 3 hours agorootparentI apologize for not using a good title, but I think the issues I listed (especially my argument that we should break issues down to bugs in runtime and the limitations of Rust abstractions) are worth discussing, even if there are many people who argue otherwise reply zbentley 3 hours agorootparentAgreed, though a better title would probably not use the term \"safe\" unqualified (e.g. \"Async rust with io_uring leaks resources (and risks corrupting program state\"). reply qw3rty01 4 hours agoparentprevSo in this case it is still a form of safety that’s well-defined in rust: cancel safety. The io-uring library doesn’t have the same cancel safety guarantees that everyone is used to in epoll libraries. In Tokio, the cancel safety of `accept` is well documented even though it works the way you’d expect, but in monoio, it’s literally just documented as `Accept` with no mention of the cancel safety issues when using that function. reply tsimionescu 4 hours agoparentprevNot leaking resources is a part of Rust's safety model, isn't it? reply qw3rty01 4 hours agorootparentNo, leaking is explicitly safe in rust: https://doc.rust-lang.org/nomicon/leaking.html reply tsimionescu 2 hours agorootparentInteresting. I would have thought that leak-free is part of the premise, since you can very well right C or C++ with a guarantee of no use after free at least, assuming you don't care about memory leaks. reply whytevuhuni 1 hour agorootparentThe difference is that memory safety of any kind (including leaking everything) in C/C++ requires discipline, whereas in Rust the compiler is what prevents it. And yes, leaking is not part of that guarantee, because leaks cannot cause corruption or undefined behavior. With that said, while Rust does not guarantee it, it does have much better automatic memory cleanup compared to C++, because every value has only one owner, and the owner automatically drops/destructs it at the end of its scope. Getting leaks is possible to do with things like Box::leak, or ref-count cycles, but in practice it tends to be explicit, rather than the programmer forgetting to do something. reply xyst 7 hours agoprevNotably, io_uring syscall has been a significant source of vulnerabilities. Last year, Google security team decided to disable it in their products (ChromeOS, Android, GKE) and production servers [1]. Containerd maintainers soon followed Google recommendations and updated seccomp profile to disallow io_uring calls [2]. io_uring was called out specifically for exposing increased attack surface by kernel security team as well long before G report was released [3]. Seems like less of a rust issue and more of a bug(s) in io_uring? I suppose user space apps can provide bandaid fix but ultimately needs to be handled at kernel. [1] https://security.googleblog.com/2023/06/learnings-from-kctf-... [2] https://github.com/containerd/containerd/pull/9320 [3] https://lwn.net/Articles/902466/ reply eqvinox 5 hours agoparent> Seems like less of a rust issue and more of a bug(s) in io_uring? I'm working with io_uring currently and have to disagree hard on that one; io_uring definitely has issues, but the one here is that it's being used incorrectly, not something wrong with io_uring itself. The io_uring issues overall also disaggregate in mostly 2 overall categories: - lack of visibility into io_uring operations since they are no longer syscalls. This is an issue of adding e.g. seccomp and ptrace equivalents into io_uring. It's not something I'd even call a vulnerability, more of a missing feature. - implementation correctness and concurrency issues due to its asynchronicity. It's just hard to do this correctly and bugs are being found and fixed. Some are security vulnerabilities. I'd call this a question of time for it to get stable and ready but I have no reason to believe this won't happen. reply mamcx 4 hours agorootparent> but the one here is that it's being used incorrectly Being ALLOWED to be used badly, is the major cause of unsafety. And consider that all the reports you reply to are by serious teams. NOT EVEN THEM succeed. That is the #1 definition of > something wrong with io_uring itself reply zbentley 3 hours agorootparentStrongly disagree. At the level of io_uring (syscalls/syscall orchestration), it is expected that available tools are prone to mis-use, and that libraries/higher layers will provide abstractions around them to mitigate that risk. This isn't like the Rust-vs-C argument, where the claim is that you should prefer the option of two equivalently-capable solutions in a space that doesn't allow mis-use. This is more like assembly language, or the fact that memory inside kernel rings is flat and vulnerable: those are low-level tools to facilitate low-level goals with a high risk of mis-use, and the appropriate mitigation for that risk is to build higher-level tools that intercept/prevent that mis-use. reply the8472 7 hours agoparentprevThose are separate issues. The blog post is about using it properly in userspace, google's concerns are about kernel security bugs. reply pferde 7 hours agoparentprevThat is all well and true, and the vulnerabilities are getting fixed, but that is off-topic to the posted article. The article is more about the Rust io_uring async implementation breaking assumption that Rust's async makes, in that a Future can only get modified when it's poll()-ed. I'm guessing that assumption came from an expectation that all async runtimes live in userland, and this newfangled kernel-backed runtime does things on its own inside the kernel, thus breaking the original assumption. reply pornel 6 hours agorootparentThe problem has been known from the beginning, because async I/O on Windows has the same issues as io_uring. Rust went with poll-based API and synchronous cancellation design anyway, because that fits ownership and borrowing. Making async cancellation work safely even in presence of memory leaks (destructors don't always run) and panics remains an unsolved design problem. reply simonask 6 hours agorootparentprevI mean, it’s only a problem if your design is based on the Future having exclusive ownership of its read buffer, but io\\_uring assumes a kind of shared ownership. The “obvious” solution is to encode that ownership model in the design, which implies some kind of cancellation mechanism. C and C++ programs have to do that too. reply smatija 7 hours agoprevThis reference at the bottom of article was very interesting to me: https://without.boats/blog/io-uring/ \"So I think this is the solution we should all adopt and move forward with: io-uring controls the buffers, the fastest interfaces on io-uring are the buffered interfaces, the unbuffered interfaces make an extra copy. We can stop being mired in trying to force the language to do something impossible. But there are still many many interesting questions ahead.\" reply n_plus_1_acc 8 hours agoprevIt's not about memory safety, as you might assume from the title. There's no soundness bug involved. reply ethegwo 7 hours agoparentRust not only provides memory safety, it also promises at least I/O safety in the future: https://rust-lang.github.io/rfcs/3128-io-safety.html reply remram 41 minutes agorootparentThat doesn't mean the Rust project promise no one will write a library that is not safe... The title of this submission is aimed specifically at \"Async Rust\", ie the language. The reality is that one third-party library with 4k stars on GitHub and 0.2.4 version number has a non-memory-unsafe leak. I'd say the title is a full-on lie. reply fallingsquirrel 7 hours agorootparentprevResource leaks have nothing to do with safety. That's true both for memory safety and i/o safety. See for yourself with `mem::forget(File::open(...)?)` reply chubot 6 hours agorootparentYeah the article is giving what looks like a bad definition: According to: https://rust-lang.github.io/rfcs/3128-io-safety.html Rust’s standard library almost provides I/O safety, a guarantee that if one part of a program holds a raw handle privately, other parts cannot access it. According to the article: I/O Safety: Ensuring that accepted TCP streams are properly closed without leaking connections. These are not the same definition. As I've mentioned several times [1], in Rust, the word \"safety\" is being abused to the point of causing confusion, and it looks like this is another instance of that. [1] https://news.ycombinator.com/item?id=31726723 reply ethegwo 5 hours agorootparentThank you! I will update the post and fix it. reply ekidd 7 hours agorootparentprevYeah, \"safe Rust\" is officially allowed to leak memory and other resources. - The easiest way to do this is mem::forget, a safe function which exists to leak memory deliberately. - The most common real way to leak memory is to create a loop using the Rc or Arc reference count types. I've never seen this in any of my company's Rust code, but we don't write our own cyclic data structures, either. This is either a big deal to you, or a complete non-issue, depending on your program architecture. Basically, \"safe Rust\" aims to protect you from memory corruption, undefined behavior, and data races between threads. It does not protect you from leaks, other kinds of race conditions, or (obviously) logic bugs. reply the8472 7 hours agorootparentprevLeaking file descriptors is safe, at least as far as the IO-safety RFC defines it. It's just a regular bug. reply morning-coffee 2 hours agorootparentprevWhere do you conclude \"Rust promises I/O safety in the future\"? An RFC is not a promise to do anything... it may represent a desire... a possibility, but you taking that leap and implying a promise is a flagrant misrepresentation. Now let's take \"the future\" part... you seem to be impugning Async Rust for something it's not even purported to do in the present. What's the point of this? You found a bug in monoio it seems... I don't see the argument you've presented as supporting the premise that \"Async Rust is not safe\". reply whalesalad 25 minutes agoprevI am really confused that rust was not designed to do async out of the box? Am I wrong that third party libraries are required (tokio) to do this? reply LudwigNagasena 13 minutes agoparentRust provides async syntax out of the box, but you have to Bring Your Own Runtime. reply whytevuhuni 6 hours agoprevI don't get it. What's the ideal scenario here? That going to the sleep branch of the select should cancel the accept? Will cancelling the accept terminate any already-accepted connections? Shouldn't it be delayed instead? Shouldn't newly accepted connections be dropped only if the listener is dropped, rather than when the listener.accept() future is dropped? If listener.accept() is dropped, the queue should be with the listener object, and thus the event should still be available in that queue on the next listener.accept(). This seems more like a bug with the runtime than anything. reply ethegwo 6 hours agoparentthe ideal scenario is like cancellable io provide by monoio, I write an example of this in the blog: https://github.com/ethe/io-uring-is-not-cancellation-safe/bl... . However, it has lots of limitation, and do not have a perfect way to do this at the moment. reply whytevuhuni 6 hours agorootparentThat's an implementation detail. What's the user-facing behavior? What should happen with mistakenly-accepted connections? Even the blog admits that cancellation of any kind, is racing with the kernel which might complete the accept request anyway. Even if you call `.cancel()`, the queue might have an accepted connection FD in it. Even if it doesn't, it might do by the time the kernel acknowledges the cancellation. So you now have a mistakenly-accepted connection. What do you do with it? Drop it? That seems like the wrong answer, whoever writes a loop like the one in the blog will definitely not expect some of the connections mysteriously being dropped. reply whytevuhuni 5 hours agorootparentOkay, looks like withoutboats gave the answer to this in another thread [1], and that seems like the right answer. The accept() future being dropped must not result in any cancellation of any kind, unless the listener itself is also dropped. This is an implementation issue with monoio that just needs more polishing. And given how hard io_uring is to get right, monoio should be given that time before being chosen to be used in production for anything. [1] https://news.ycombinator.com/item?id=41994308 reply ethegwo 3 hours agorootparentprevI don't think the operation that completes after cancellation failed is \"mistakenly-accepted,\" it should be handled in the normal way, but I admit that there are lots of people don't agree that reply lifthrasiir 8 hours agoprevThis aspect of io_uring does affect a lot of surface APIs, as I have experienced at work. At least for me I didn't have to worry much about borrowing though. reply eqvinox 8 hours agoparentHmm. Does it? Python's futures have an explicit .cancel() operation. And the C io_uring usage I'm looking at knows to cancel events too… It's really that Rust might've made a poor choice here, as the article points out: > Async Rust makes a few core assumptions about futures: > 1. The state of futures only change when they are polled. > 2. Futures are implicitly cancellable by simply never polling them again. But at the same time, maybe this is just that Rust's Futures need to be used different here, in conjunction with a separate mechanism to manage the I/O operation that knows things need to be cancelled? reply lifthrasiir 7 hours agorootparentThat part of the article is kinda irrelevant in my opinion. Futures do require polling to move forward, but polling can be forced by an external signal (otherwise the whole future model wouldn't work!). Therefore io_uring can be safely implemented by having central worker threads which then signal outstanding futures; that was how I ended up doing at work as well. So the article actually seems to ask whether such out-of-band mechanism can be entirely prevented or not. reply eqvinox 7 hours agorootparentThe sibling comment to yours points out cancelling Futures is dropping Futures, what's your experience / do you think that would work to prevent needing the out-of-band mechanism? reply lifthrasiir 7 hours agorootparentThat's backwards... Rust's way to do cancellation is simply to drop the future (i.e. let it deallocated). There is one big caveat here though, namely the lack of async drop as others pointed out. In the current Rust io_uring-like stuffs can be safely implemented with an additional layer of abstraction. Some io_uring operations can be ongoing when it looks fine to borrow the buffer, sure. Your API just has to ensure that it is not possible to borrow until all operations are finished then! Maybe it can error, or you can require something like `buf.borrow().await`. This explicit borrowing is not an alien concept in Rust (cf. RefCell etc.) and probably the best design at the moment, but it does need dynamic bookkeeping which some may want to eliminate. reply fnord123 7 hours agorootparentprev> First of all, we are fortunate that the I/O safety problem can be addressed now, which safe Rust aims to ensure this in the future. Rust provides the Drop trait to define custom behavior when a value is cleaned up. Thus, we can do something like this... > We just need to encourage async runtimes to implement this fix. This likely needs async drop if you need to perform a follow up call to cancel the outstanding tasks or closing the open sockets. Async Drop is currently experimental: https://github.com/rust-lang/compiler-team/issues/727 reply eptcyka 7 hours agorootparentprevThe assumption made by rust is that a future is cancelled when it is dropped. reply eqvinox 7 hours agorootparentAh, Thanks, that makes sense, but then I don't understand how this isn't just a bug in these Rust runtimes. As in: the drop codepath on the future needs to not only submit the cancellation SQE into io_uring, it also needs to still process CQEs from the original request that pop up before the CQE for the cancellation… NB: I have only done a little bit of Rust, but am hoping to move there in the future — but I am working on C code interfacing io_uring… I will say doing this correctly does in fact require a bit of brainpower when writing that code. reply eptcyka 6 hours agorootparentI am not well versed in the async things as of late, but one complication is that the drop implementation is a blocking one. This could easily lead to deadlocks. Or the drop implementation could spawn an async task to clean up after itself later. reply wg0 4 hours agoprevI have tried to learn rust and borrow checker is no problem but I can't get lifetimes and then Rc, Box, Arc Pinning along with async Rust are a whole another story. Having programmed in raw C, I know Rust is more like Typescript if you once try it after writing Javascript, you can't go back for anything serious in plain Javascript. You would want to have some guard rails better than having no guard rails. reply riskable 3 hours agoparentTry embedded rust: Get an RP2040 board and fool around with that. It'll make a lot more sense to you if the parts you don't understand are encapsulation types like RC, Box, and Arc because those aren't really used in embedded rust! Lifetimes are still used but not nearly as much. reply pjdesno 6 hours agoprevSince io_uring has similar semantics to just about every hardware device ever (e.g. NVMe submission and completion queues), are there any implications of this for Rust in the kernel? Or in SPDK and other user-level I/O frameworks? Note that I don't know a lot about Rust, and I'm not familiar with the rules for Rust in the kernel, so it's possible that it's either not a problem or the problematic usages violate the kernel coding rules. (although in the latter case it doesn't help with non-kernel frameworks like SPDK) reply gspr 5 hours agoparentI think async Rust is far from entering the kernel. Edit: I realize my comment might come off as a bit snarky or uninformative to someone who isn't familiar with Rust. That was not the intention. \"Async Rust\" is particular framework for abstracting over various non-blocking IO operations (and more). It allows terse code to be written using a few convenient keywords, that causes a certain state machine (consisting of ordinary Rust code adhering to certain rules) to be generated, which in turn can be coupled with an \"async runtime\" (of which there are many) to perform the IO actions described by the code. The rules that govern the code generated by these convenient keywords, i.e. the code that the async runtimes execute, are apparently not a great fit for io_uring and the like. However, I don't think anyone is proposing writing such code inside the kernel, nor that any of the async runtimes actually make sense in a kernel setting. The issues in this article don't exist when there is no async Rust code. Asynchronous operations can, of course, still be performed, but one has to manage that without the convenient scaffolding afforded by async Rust and the runtimes. reply duped 5 hours agoprevWhile it's true that the \"state\" of a future is only mutated in the poll() implementation, it's up to the author of the future implementation to clone/send/call the Waker provided in the context argument to signal to the executor that poll() should be called again by the executor, which I believe is how one should handle this case. reply Sytten 6 hours agoprevWe so need a way to express cancellation safety other than documentation. This is not just an io_grind problem, you have a lot of futures in tokio that are not cancel safe. Are there some RFC of the subject? reply NooneAtAll3 4 hours agoprev> // we loose the chance to handle the previous one. lose? reply ethegwo 3 hours agoparentThanks, I will fix it. reply api 8 hours agoprevThere are async libraries like glommio, which I’m using for a new project, that avoid this I think, but they require you to factor things a little differently from tokio. Maybe cancellation itself is problematic. There’s a reason it was dropped from threading APIs and AFAIK there is no way to externally cancel a goroutine. Goroutines are like async tasks with all the details hidden from you as it’s a higher level language. reply badmintonbaseba 7 hours agoparentI don't think that cancellation is inherently problematic, but it needs to be cooperative. One-sided cancellation of threads (and probably goroutines) can never work. Cooperative cancellation can be implemented in languages that mark their suspension points explicitly in their coroutines, like Rust, Python and C++. I think Python's asyncio models cancellation fairly well with asyncio.CancelledError being raised from the suspension points, although you need to have some discipline to use async context managers or try/finally, and to wait for cancelled tasks at appropriate places. But you can write your coroutines with the expectation that they eventually make forward progress or exit normally (via return or exception). It looks like Rust's cancellation model is far more blunt, if you are just allowed to drop the coroutine. reply ekidd 7 hours agorootparent> It looks like Rust's cancellation model is far more blunt, if you are just allowed to drop the coroutine. You can only drop it if you own it (and nobody has borrowed it), which means you can only drop it at an `await` point. This effectively means you need to use RAII guard objects like in C++ in async code if you want to guarantee cleanup of external resources. But it's otherwise completely well behaved with epoll-based systems. I find that a bigger issue in my async Rust code is using Tokio-style async \"streams\", where a cancelled sender looks exactly like a clean \"end of stream\". In this case, I use something like: enum StreamValue { Value(T), End, } If I don't see StreamValue::End before the stream closes, then I assume the sender failed somehow and treat it as a broken stream (sort of like a Unix EPIPE error). This can obviously be wrapped. But any wrapper still requires the sender to explictly close the stream when done, and not via an implicit Drop. reply badmintonbaseba 6 hours agorootparent> This effectively means you need to use RAII guard objects like in C++ in async code if you want to guarantee cleanup of external resources. But it's otherwise completely well behaved with epoll-based systems. Which limits cleanup after cancellation to be synchronous, doesn't it? I often use asynchronous cleanup logic in Python (which is the whole premise of `async with`). reply ekidd 3 hours agorootparentCorrect. Well, you can dump it into a fast sync buffer and let a background cleanup process do any async cleanup. Sync Rust is lovely, especially with a bit of practice, and doubly so if you already care about how things are stored in memory. (And caring how things are stored is how you get speed.) Async Rust is manageable. There's more learning curve, and you're more likely to hit an odd corner case where you need to pair for 30 minutes with the team's Rust expert. The majority of recent Rust networking libraries are async, which is usually OK. Especially if you tend to keep your code simple anyway. But there are edge cases where it really helps to have access to Rust experience—we hit one yesterday working on some HTTP retry code, where we needed to be careful how we passed values into an async retriable block. reply eqvinox 7 hours agoparentprevI don't think it's possible to get away with fundamentally no cancellation support, there are enough edge cases that need it even if most applications don't have such edge cases. FWIW, this was also painful to do across threads in our C event loop, but there was no way around the fact that we needed it (cf. https://github.com/FRRouting/frr/blob/56d994aecab08b9462f2c8... ) reply zbentley 3 hours agoprevMy hot take is that the root of this issue is that the destructor side of RAII in general is a bad idea. That is, registering custom code in destructors and running them invisibly, implicitly, maybe sometimes but only if you're polite, is not and never was a good pattern. This pattern causes issues all over the place: in C++ with headaches around destruction failure and exceptions; in C++ with confusing semantics re: destruction of incompletely-initialized things; in Rust with \"async drop\"; in Rust (and all equivalent APIs) in situations like the one in this article, wherein failure to remember to clean up resources on IO multiplexer cancellation causes trouble; in Java and other GC-ful languages where custom destructors create confusion and bugs around when (if ever) and in the presence of what future program state destruction code actually runs. Ironically, two of my least favorite programming languages are examples of ways to mitigate this issue: Golang and JavaScript runtimes: Golang provides \"defer\", which, when promoted widely enough as an idiom, makes destructor semantics explicit and provides simple and consistent error semantics. \"defer\" doesn't actually solve the problem of leaks/partial state being left around, but gives people an obvious option to solve it themselves by hand. JavaScript runtimes go to a similar extreme: no custom destructors, and a stdlib/runtime so restrictive and thick (vis-a-vis IO primitives like sockets and weird in-memory states) that it's hard for users to even get into sticky situations related to auto-destruction. Zig also does a decent job here, but only with memory allocations/allocators (which are ironically one of the few resource types that can be handled automatically in most cases). I feel like Rust could have been the definitive solution to RAII-destruction-related issues, but chose instead to double down on the C++ approach to everyone's detriment. Specifically, because Rust has so much compile-time metadata attached to values in the program (mutability-or-not, unsafety-or-not, movability/copyabiliy/etc.), I often imagine a path-not-taken in which automatic destruction (and custom automatic destructor code) was only allowed for types and destructors that provably interacted only with in-user-memory state. Things referencing other state could be detected at compile time and required to deal with that state in explicit, non-automatic destructor code (think Python context-managers or drop handles requiring an explicit \".execute()\" call). I don't think that world would honestly be too different from the one we live in. The rust runtime wouldn't have to get much thicker--we'd have to tag data returned from syscalls that don't imply the existence of cleanup-required state (e.g. select(2), and allocator calls--since we could still automatically run destructors that only interact with cleanup-safe user-memory-only values), and untagged data (whether from e.g. fopen(2) or an unsafe/opaque FFI call or asm! block) would require explicit manual destruction. This wouldn't solve all problems. Memory leaks would still be possible. Automatic memory-only destructors would still risk lockups due to e.g. pagefaults/CoW dirtying or infinite loops, and could still crash. But it would \"head off at the pass\" tons of issues--not just the one in the article: Side-effectful functions would become much more explicit (and not as easily concealable with if-error-panic-internally); library authors would be encouraged to separate out external-state-containing structs from user-memory-state-containing ones; destructor errors would become synonymous with specific programmer errors related to in-memory twiddling (e.g. out of bounds accesses) rather than failures to account for every possible state of an external resource, and as a result automatic destructor errors unconditionally aborting the program would become less contentious; the surface area for challenges like \"async drop\" would be massively reduced or sidestepped entirely by removing the need for asynchronous destructors; destructor-related crash information would be easier to obtain even in non-unwinding environments... Maybe I'm wrong and this would require way too much manual work on the part of users coding to APIs requiring explicit destructor calls. But heck, I can dream, can't I? reply int_19h 8 minutes agoparentI don't think Java finalizers should be considered in the same bucket as C++-style destructors. They are very explicitly not about RAII. If explicit destruction is desirable, IMO the C#-style `using` pattern (try-with-resource in Java, `with` in Python etc) makes more sense than `defer` since it still forces the use of the correct cleanup code for a given type while retaining the explicitness and allowing linters to detect missing calls (because destructability is baked into the type). `defer` is unnecessarily generic here IMO. In JS, you still end up having to write try/finally for anything that needs explicit resource management, so I don't think it's a good example. They are adding `using`, though, and TS already provides it. reply vacuity 2 hours agoparentprevI think Austral and Vale's linear typing is a good start, although it would probably have to be opt-in in practice. This goes along with explicit, manual destructors and alleviates issues like async drop. Even with automatic destructors, they can have more visibility and customizability. Exceptions are a can of worms and need to be redesigned (but not removed). I think automatic destruction doesn't have to mean oh-wait-what-do-you-mean-it-unwound-and-ran-a-destructor-uh-oh-double-exception-abort and similar very weird cases. The concept should have its own scope and purpose, same with exceptions. reply amoss 5 hours agoprevWho is Barbara? reply ethegwo 5 hours agoparenthttps://rust-lang.github.io/wg-async/vision/characters.html#... reply the8472 5 hours agoparentprevUser B reply jerf 5 hours agoprevThere are certain counterintuitive things that you have to learn if you want to be a \"systems engineer\", in a general sense, and this whole async thing has been one of the clearest lessons to me over the years of how seemingly identical things sometimes can not be abstracted over. Here by \"async\" I don't so much mean async/await versus threads, but these kernel-level event interfaces regardless of which abstraction a programming language lays on top of them. At the 30,000 foot view, all the async abstractions are basically the same, right? You just tell the kernel \"I want to know about these things, wake me up when they happen.\" Surely the exact way in which they happen is not something so fundamental that you couldn't wrap an abstraction around all of them, right? And to some extent you can, but the result is generally so lowest-common-denominator as to appeal to nobody. Instead, every major change in how we handle async has essentially obsoleted the entire programming stack based on the previous ones. Changing from select to epoll was not just a matter of switching out the fundamental primitive, it tended to cascade up almost the entire stack. Huge swathes of code had to be rewritten to accommodate it, not just the core where you could do a bit of work and \"just\" swap out epoll for select. Now we're doing it again with io_uring. You can't \"just\" swap out your epoll for io_uring and go zoomier. It cascades quite a ways up the stack. It turns out the guarantees that these async handlers provide are very different and very difficult to abstract. I've seen people discuss how to bring io_uring to Go and the answer seems to basically be \"it breaks so much that it is questionable if it is practically possible\". An ongoing discussion on an Erlang forum seems to imply it's not easy there (https://erlangforums.com/t/erlang-io-uring-support/765); I'd bet it reaches up \"less far\" into the stack but it's still a huge change to BEAM, not \"just\" swapping out the way async events come in. I'm sure many other similar discussions are happening everywhere with regards to how to bring io_uring into existing code, both runtimes and user-level code. This does not mean the problem is unsolvable by any means. This is not a complaint, or a pronunciation of doom, or an exhortation to panic, or anything like that. We did indeed collectively switch from select to epoll. We will collectively switch to io_uring eventually. Rust will certainly be made to work with it. I am less certain about the ability of shared libraries to be efficiently and easily written that work in both environments, though; if you lowest-common-denominator enough to work in both you're probably taking on the very disadvantages of epoll in the first place. But programmers are clever and have a lot of motivation here. I'm sure interesting solutions will emerge. I'm just highlighting that as you grow in your programming skill and your software architecture abilities and general system engineering, this provides a very interesting window into how abstractions can not just leak a little, but leak a lot, a long ways up the stack, much farther than your intuition may suggest. Even as I am typing this, my own intuition is still telling me \"Oh, how hard can this really be?\" And the answer my eyes and my experience give my intuition is, \"Very! Even if I can't tell you every last reason why in exhaustive detail, the evidence is clear!\" If it were \"just\" a matter of switching, as easy as it feels like it ought to be, we'd all already be switched. But we're not, because it isn't. reply vacuity 2 hours agoparentI appreciate the insight in this comment! I see your problem, and I offer an answer (I daren't call it a solution): there is no surefire way to make an interface/abstraction withstand the test of time. It just doesn't happen, even across just a few paradigm shifts, at least not without arbitrary costs to performance, observability/debuggability, ease of use, and so on. The microkernel (in the spirit of Liedtke)/exokernel philosophy tells us to focus on providing minimal, orthogonal mechanisms that just barely allow implementing the \"other stuff\". But unless a monolithic system is being built for one purpose, \"the other stuff\" isn't meaningfully different from a microkernel; it has different \"hardware\" but must itself impose minimally on what is to be built above it. We build layers of components with rich interactions of meaningful abstractions, building a web of dependencies and capabilities. There is no accidental complexity here in this ideal model; to switch paradigms, one must discard exactly the set of components and layers that are incompatible with the new paradigm. Consider Linux async mechanisms. They are provided by a monolithic kernel that dictates massive swathes of what worldview a program is developed in. When select was found lacking, it took time for epoll to arrive. Then io_uring took its sweet time. When the kernel is lacking, the kernel must change, and that is painful. Now consider a hypothetical microkernel/exokernel where a program just gets bare asynchronous notifications about hardware and from other programs. Async abstractions must be built on top, in services and libraries, to make programming feasible. Say the analogous epoll library is found lacking. Someone must uproot it and perhaps lower layers and build an io_uring library instead. I will not say this is always less pain that before, although it is decidedly not the same as changing a kernel. But perhaps it is less painful in most cases. I do not think it is ever more painful. This is the essential pain brought about by stability and change. reply MuffinFlavored 6 hours agoprevHow common of a pattern is it to accept in a loop but also on a timeout so that you can pre-empt and go do some other work? reply majewsky 6 hours agoparentThe timeout is only a stand-in for the generic need to be able to cancel an acceptance loop. You could just as well want to cancel accept() when SIGINT/SIGTERM/etc is received, or when recreating the server socket, e.g. in response to a configuration change. Most server processes have a need like this. reply newpavlov 6 hours agoprevYet another example of async Rust being a source of unexpected ways to shoot yourself in the foot... Async advocates can argue as long as they want about \"you're holding it wrong\", but to me it sounds like people arguing that you can safely use C/C++ just by being \"careful\". reply speed_spread 4 hours agoparentAsync has its uses, but there should also be a way to ensure that a Rust stack does not use async at all, like there is for unsafe. Most codebases could do without the added complexity. There will be better ways to do concurrency in the future (hehe) reply dboreham 3 hours agorootparentAgree. If people want to delude themselves that async is useful, that's fine. But don't inflict it on the rest of us by viral propagation throughout the dependency ecosystem. reply vacuity 2 hours agorootparentI claim that async/await is far more basic (/fundamental/simple, not necessarily easy) than most acknowledge, but it should indeed be more composable with sync code. It is a means of interacting with asynchronous phenomena, which underlie the OS-hardware connection. The composability is necessary because no one is going to write a massive state machine for their entire program. reply int_19h 4 minutes agorootparentPart the problem is ABI. Fibers are a more sensible approach to async, but as soon as you introduce them, FFI becomes a massive pain (see e.g. Go) in any environment which doesn't have fibers as a first-class primitive that everybody supports. Promise-based async has the advantage that you can desugar it down to C-compatible ABI. reply lsofzz 5 hours agoprev<3 reply not_a_dane 8 hours agoprevnext [4 more] [flagged] eqvinox 8 hours agoparentNo it won't. reply Ygg2 7 hours agoparentprevThat'd be a Sisyphean job. Writing kernel in Rust from scratch, I understand, but this? Please, let this be a joke. reply simion314 7 hours agoparentprevIf Rust would be as good as advertised we would have at least 5 Rust kernels 10x faster then Linux or BSD and 100% safe and all servers in the world would run those kernels. Is there at least one kernel with a big tech behind it or with a big army or Rust evangelists giving 5$ a month to finance it? reply sylware 6 hours agoprev [–] dude, machine code generated with gcc/clang is not safe in the first place. This is only the tip of the iceberg. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Async Rust faces safety issues when used with io_uring, as TCP connections can leak, unlike with the epoll driver.- This problem affects all async runtimes using io_uring because it breaks core assumptions of async Rust, such as the asynchronous execution of syscalls by the kernel.- Solutions like monoio's cancellable I/O exist, but challenges persist due to Rust's lack of linear type support, necessitating a community focus on improving I/O and halt safety with io_uring."
    ],
    "commentSummary": [
      "Async Rust is not inherently unsafe with io_uring; the concern is with some io-uring libraries that expose flawed APIs.- The ringbahn library is noted for correctly handling cancellations, unlike others that may lead to resource leaks when a future is dropped without synchronized cancellation.- This issue is not specific to Rust but relates to the complexity of io-uring's asynchronous cancellation mechanism, emphasizing the need for careful management to avoid resource leaks."
    ],
    "points": 173,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1730277744
  },
  {
    "id": 41992419,
    "title": "AI Flame Graphs",
    "originLink": "https://www.brendangregg.com/blog//2024-10-29/ai-flame-graphs.html",
    "originBody": "Brendan's site: Start Here Homepage Blog Sys Perf book BPF Perf book Linux Perf eBPF Tools perf Examples Perf Methods USE Method TSA Method Off-CPU Analysis Active Bench. WSS Estimation Flame Graphs Heat Maps Frequency Trails Colony Graphs DTrace Tools DTraceToolkit DtkshDemos Guessing Game Specials Books Other Sites Systems Performance 2nd Ed. BPF Performance Tools book Recent posts: 29 Oct 2024 » AI Flame Graphs 22 Jul 2024 » No More Blue Fridays 24 Mar 2024 » Linux Crisis Tools 17 Mar 2024 » The Return of the Frame Pointers 10 Mar 2024 » eBPF Documentary 28 Apr 2023 » eBPF Observability Tools Are Not Security Tools 01 Mar 2023 » USENIX SREcon APAC 2022: Computing Performance: What's on the Horizon 17 Feb 2023 » USENIX SREcon APAC 2023: CFP 02 May 2022 » Brendan@Intel.com 15 Apr 2022 » Netflix End of Series 1 09 Apr 2022 » TensorFlow Library Performance 19 Mar 2022 » Why Don't You Use ... 26 Sep 2021 » The Speed of Time 06 Sep 2021 » ZFS Is Mysteriously Eating My CPU 30 Aug 2021 » Analyzing a High Rate of Paging 27 Aug 2021 » Slack's Secret STDERR Messages 05 Jul 2021 » USENIX LISA2021 Computing Performance: On the Horizon 03 Jul 2021 » How To Add eBPF Observability To Your Product 15 Jun 2021 » USENIX LISA2021 BPF Internals (eBPF) 04 Jun 2021 » An Unbelievable Demo Blog index About RSS Brendan Gregg's Blog home AI Flame Graphs 29 Oct 2024 Imagine halving the resource costs of AI and what that could mean for the planet and the industry -- based on extreme estimates such savings could reduce the total US power usage by over 10% by 20301. At Intel we've been creating a new analyzer tool to help reduce AI costs called AI Flame Graphs: a visualization that shows an AI accelerator or GPU hardware profile along with the full software stack, based on my CPU flame graphs. Our first version is available to customers in the Intel Tiber AI Cloud as a preview for the Intel Data Center GPU Max Series (previously called Ponte Vecchio). Here is an example: Simple example: SYCL matrix multiply microbenchmark (Click for interactive SVG.) The green frames are the actual instructions running on the AI or GPU accelerator, aqua shows the source code for these functions, and red (C), yellow (C++), and orange (kernel) show the CPU code paths that initiated these AI/GPU programs. The gray \"-\" frames just help highlight the boundary between CPU and AI/GPU code. The x-axis is proportional to cost, so you look for the widest things and find ways to reduce them. Layers This flame graph shows a simple program for SYCL (a high-level C++ language for accelerators) that tests three implementations of matrix multiply, running them with the same input workload. The flame graph is dominated by the slowest implementation, multiply_basic(), which doesn't use any optimizations and consumes at 72% of stall samples and is shown as the widest tower. On the right are two thin towers for multiply_local_access() at 21% which replaces the accessor with a local variable, and multiply_local_access_and_tiling() at 6% which also adds matrix tiling. The towers are getting smaller as optimizations are added. This flame graph profiler is a prototype based on Intel EU stall profiling for hardware profiling and eBPF for software instrumentation. It's designed to be easy and low-overhead, just like a CPU profiler. You should be able to generate a flame graph of an existing AI workload whenever you want, without having to restart anything or launch additional code via an interposer. Instruction-offset Profiling This is not the first project to build an AI profiler or even something called an AI Flame Graph, however, others I've seen focus on tracing CPU stacks and timing accelerator execution, but don't profile the instruction offsets running on the accelerator; or do profile them but via expensive binary instrumentation. I wanted to build AI flame graphs that work like CPU flame graphs: Easy to use, negligible cost, production safe, and shows everything. A daily tool for developers, with most of the visualization in the language of the developer: source code functions. This has been an internal AI project at Intel for the past year. Intel was already investing in this space, building the EU stall profiler capability for the Intel Data Center GPU Max Series that provides an approximation of HW instruction sampling. I was lucky to have Dr. Matthew (Ben) Olson, an Intel AI engineer who has also worked on eBPF performance tooling (processwatch) as well as memory management research, join my team and do most of the development work. His background has helped us power through difficulties that seemed insurmountable. We've also recently been joined by Dr. Brandon Kammerdiener (coincidentally another graduate of the University of Tennessee, like Ben), who also has eBPF and memory internals experience, and has been helping us take on harder and harder workloads. And Gabriel Muñoz just joined today to help with releases. Now that our small team has shown that this is possible, we'll be joined by other teams at Intel to develop this further. We could have built a harder-to-use and higher-overhead version months ago using Intel GTPin but for widespread adoption it needs minimal overhead and ease of use so that developers don't hesitate to use this daily and to add it to deployment pipelines. What's a Flame Graph? A flame graph is a visualization I invented in 2011 for showing sampled code stack traces. It has become the standard for CPU profiling and analysis, helping developers quickly find performance improvements and eliminate regressions. A CPU flame graph shows the \"big picture\" of running software, with x-axis proportional to CPU cost. The example picture on the right summarizes how easy it can be to go from compute costs to responsible code paths. Prior to flame graphs, it could take hours to understand a complex profile by reading through hundreds of pages of output. Now it takes seconds: all you have to do is look for the widest rectangles. Flame graphs have had worldwide adoption. They have been the basis for five startups so far, have been adopted in over thirty performance analysis products, and have had over eighty implementations. My first implementation of flame graphs took a few hours on a Wednesday night after work. The real effort has been in the decade since, where I worked with different profilers, runtimes, libraries, kernels, compilers, and hypervisors to get flame graphs working properly in different environments, including fixing stack walking and symbolization. Earlier this year I posted about the final missing piece: Helping distros enable frame pointers so that profiling works across standard system libraries. Similar work is necessary for AI workloads: fixing stacks and symbols and getting profiling to work for different hardware, kernel drivers, user-mode drivers, frameworks, runtimes, languages, and models. A lot more work, too, as AI analysis has less maturity than CPU analysis. Searching Samples If you are new to flame graphs, it's worth mentioning the built-in search capability. In the earlier example, most of the stall samples are caused by sbid: software scoreboard dependency. As that may be a unique search term, you can run search (Ctrl-F, or click \"Search\") on \"sbid\" and it will highlight it in magenta: Search also shows the total number of stack samples that contained sbid in the bottom right: 78.4%. You can search for any term in the flame graph: accelerator instructions, source paths, function names, etc., to quickly calculate the percentage of stacks where it is present (excluding vertical overlap) helping you prioritise performance work. Note that the samples are EU stall-based, which means theoretical performance wins can take the percentages down to zero. This is different to timer-based samples as are typically used in CPU profiling. Stalls mean you better focus on the pain, the parts of the code that aren't making forward progress, but you aren't seeing resource usage by unstalled instructions. I'd like to supuport timer-based samples in the future as well, so we can have both views. Who will use this? At a recent golang conference, I asked the audience of 200+ to raise their hands if they were using CPU flame graphs. Almost every hand went up. I know of companies where flame graphs are a daily tool that developers use to understand and tune their code, reducing compute costs. This will become a daily tool for AI developers. My employer will use this as well for evaluation analysis, to find areas to tune to beat competitors, as well as to better understand workload performance to aid design. Why is AI profiling hard? Consider CPU instruction profiling: This is easy when the program and symbol table are both in the file system and in a standardized file format (such as ELF) as is the case with native compiled code (C). CPU profiling gets hard for JIT-complied code, like Java, as instructions and symbols are dynamically generated and placed in main memory (the process heap) without following a universal standard. For such JITted code we use runtime-specific methods and agents to retrieve snapshots of the heap information, which is different for each runtime. AI workloads also have different runtimes (and frameworks, languages, user-mode drivers, compilers, etc.) any of which can require special tinkering to get their CPU stacks and symbols to work. These CPU stacks are shown as the red, orange, and yellow frames in the AI Flame Graph. Some AI workloads are easy to get these frames working, some (like PyTorch) are a lot more work. But the real challenge is instruction profiling of actual GPU and AI accelerator programs -- shown as the aqua and green frames -- and correctly associating them with the CPU stacks beneath them. Not only may these GPU and AI programs not exist in the file system, but they may not even exist in main memory! Even for running programs. Once execution begins, they may be deallocated from main memory and only exist in special accelerator memory, beyond the direct reach of OS profilers and debuggers. Or within reach, but only through a prohibitively high-overhead HW-specific debugger interface. There's also no /proc representation for these programs either (I've been proposing building an equivalent) so there's no direct way to even tell what is running and what isn't, and all the other /proc details. Forget instruction profiling, even ps(1) and all the other process tools do not work. It's been a mind-bending experience, revealing what gets taken for granted because it has existed in CPU land for decades: A process table. Process tools. Standard file formats. Programs that exist in the file system. Programs running from main memory. Debuggers. Profiliers. Core dumping. Disassembling. Single stepping. Static and dynamic instrumentation. Etc. For GPUs and AI, this is all far less mature. It can make the work exciting at times, when you think something is impossible and then find or devise a way. Fortunately we have a head start as some things do exist. Depending on the runtime and kernel driver, there are debug interfaces where you can list running accelerator programs and other statistics, as used by tools like intel_gpu_top(1). You can kill -9 a GPU workload using intel_gpu_abrt(1). Some interfaces can even generate basic ELF files for the running accelerator programs that you can try to load in a debugger like gdb(1). And there is support for GPU/AI program disassembly, if you can get your hands on the binary. It feels to me like GPU/AI debugging, OS style, is about two years old. Better than zero, but still early on, and lots more ahead of us. A decade, at least. What do AI developers think of this? We've shown AI Flame Graphs to other AI developers at Intel and a common reaction is to be a bit puzzled, wondering what to do with it. AI developers think about their bit of code, but with AI Flame Graphs they can now see the entire stack for the first time, including the HW, and many layers they don't usually think about or don't know about. It basically looks like a pile of gibberish with their code only a small part of the flame graph. CPU Flame Graph Implementations This reaction is similar to people's first experiences with CPU flame graphs, which show parts of the system that developers and engineers typically don't work on, such as runtime internals, system libraries, and kernel internals. Flame graphs are great at highlighting the dozen or so functions that matter the most, so it becomes a problem of learning what those functions do across a few different code bases, which are typically open source. Understanding a dozen such functions can take a few hours or even a few days -- but if this leads to a 10% or 2x cost win, it is time well spent. And the next time the user looks at a flame graph, they start saying \"I've seen that function before\" and so on. You can get to the point where understanding the bulk of a CPU flame graph takes less than a minute: look for the widest tower, click to zoom, read the frames, done. I'm encouraged by the success of CPU flame graphs, with over 80 implementations and countless real world case studies. Sometimes I'm browsing a performance issue I care about on github and hit page down and there's a CPU flame graph. They are everywhere. I expect AI developers will also be able to understand AI Flame Graphs in less than a minute, but to start with people will be spending a day or more browsing code bases they didn't know were involved. Publishing case studies of found wins will also help people learn how to interpret them, and also help explain the value. What about PyTorch? Another common reaction we've had is that AI developers are using PyTorch, and initially we didn't support it as it meant walking Python stacks, which isn't trivial. But prior work has been done there (to support CPU profiling) and after a lot of tinkering we now have the first PyTorch AI Flame Graph: PyTorch frames in pink (Click for interactive SVG.) The PyTorch functions are at the bottom and are colored pink. This example runs oneDNN kernels that are JIT-generated, and don't have a source path so that layer just reads \"jit\". Getting all other the layers included was a real pain to get going, but an important milestone. We think if we can do PyTorch we can do anything. In this flame graph, we show PyTorch running the Llama 2 7B model using the Intel Extensions for PyTorch (IPEX). This flame graph shows the origin of the GPU kernel execution all the way back to the Python source code shown in pink. Most samples are from a stack leading up to a gemm_kernel (matrix multiply) shown in aqua, which like the previous example has many stalls due to software scoreboarding. There are two instructions (0xa30 and 0xa90) that combined are 27% of the entire profile. I expect someone will ask: Can't we just click on instructions and have it bring up a dissassembly view with full source? Yes, that should be possible, but I can't answer how we're going to provide this yet. Another expected question I can't yet answer: Since there are now multiple products providing AI auto-tuning of CPU workloads using CPU flame graphs (including Intel Granulate) can't we have AI auto-tuning of AI workloads using AI Flame Graphs? First Release: Sometimes hard and with moderate overhead Getting AI Flame Graphs to work with some workloads is easy, but others are currently hard and cost moderate overhead. It's similar to CPU profiling, where some workloads and languages are easy to profile, whereas others need various things fixed. Some AI workloads use many software dependencies that need various tweaks and recompilation (e.g., enabling frame pointers so that stack walking works) making setup time consuming. PyTorch is especially difficult and can take over a week of OS work to be ready for AI Flame Graphs. We will work on getting these tweaks changed upstream in their respective repositories, something involving teams inside and outside of Intel, and is a process I'd expect to take at least a year. During that time AI workloads will gradually become easier to flame graph, and with lower-overhead as well. I'm reminded of eBPF in the early days: You had to patch and recompile the kernel and LLVM and Clang, which could take multiple days if you hit errors. Since then all the eBPF dependency patches have been merged, and default settings changed, so that eBPF \"just works.\" We'll get there with AI Flame Graphs too, but right now it's still those early days. The changes necessary for AI Flame Graphs are really about improving debugging in general, and are a requirement for Fast by Friday: A vision where we can root-cause analyze anything in five days or less. Availability AI Flame Graphs will first become available on the Intel Tiber AI Cloud as a preview feature for the Intel Data Center GPU Max Series. If you are currently deployed there you can ask through the Intel service channel for early access. As for if or when it will support other hardware types, be in other Intel products, be officially launched, be open source, etc., these involve various other teams at Intel and they need to make their own announcements before I can discuss them here. Conclusions Finding performance improvements for AI data centers of just fractions of a percent can add up to planetary savings in electricity, water, and money. If AI flame graphs have the success that CPU flame graphs have had, I'd expect finding improvements of over 10% will be common, and 50% and higher will eventually be found*. But it won't be easy in these early days as there are still many software components to tweak and recompile, and software layers to learn about that are revealed in the AI flame graph. In the years ahead I imagine others will build their own AI flame graphs that look the same as this one, and there may even be startups selling them, but if they use more difficult-to-use and higher-overhead technologies I fear they could turn companies off the idea of AI flame graphs altogether and prevent them from finding sorely needed wins. This is too important to do badly. AI flame graphs should be easy to use, cost negligible overhead, be production safe, and show everything. Intel has proven it's possible. Disclaimer * This is a personal blog post that makes personal predictions but not guarantees of possible performance improvements. Feel free to take any claim with a grain of salt, and feel free to wait for an official publication and public launch by Intel on this technology. 1 Based on halving the Arm CEO Rene Haas' estimate of 20-25% quoted in Taking a closer look at AI's supposed energy apocalypse by Kyle Orland of ArsTechnica. Thanks Thanks to everyone at Intel who have helped us make this happen. Markus Flierl has driven this project and made it a top priority, and Greg Lavender has expressed his support. Special thanks to Michael Cole, Matthew Roper, Luis Strano, Rodrigo Vivi, Joonas Lahtinen, Stanley Gambarin, Timothy Bauer, Brandon Yates, Maria Kraynyuk, Denis Samoylov, Krzysztof Raszknowski, Sanchit Jain, Po-Yu Chen, Felix Degrood, Piotr Rozenfeld, Andi Kleen, and all of the other coworkers that helped clear things up for us, and thanks in advance for everyone else who will be helping us in the months ahead. My final thanks is to the companies and developers who do the actual hands-on work with flame graphs, collecting them, examining them, finding performance wins, and applying them. You are helping save the planet. Click here for Disqus comments (ad supported). Site Navigation Systems Performance 2nd Ed. BPF Performance Tools book Recent posts: 29 Oct 2024 » AI Flame Graphs 22 Jul 2024 » No More Blue Fridays 24 Mar 2024 » Linux Crisis Tools 17 Mar 2024 » The Return of the Frame Pointers 10 Mar 2024 » eBPF Documentary 28 Apr 2023 » eBPF Observability Tools Are Not Security Tools 01 Mar 2023 » USENIX SREcon APAC 2022: Computing Performance: What's on the Horizon 17 Feb 2023 » USENIX SREcon APAC 2023: CFP 02 May 2022 » Brendan@Intel.com 15 Apr 2022 » Netflix End of Series 1 09 Apr 2022 » TensorFlow Library Performance 19 Mar 2022 » Why Don't You Use ... 26 Sep 2021 » The Speed of Time 06 Sep 2021 » ZFS Is Mysteriously Eating My CPU 30 Aug 2021 » Analyzing a High Rate of Paging 27 Aug 2021 » Slack's Secret STDERR Messages 05 Jul 2021 » USENIX LISA2021 Computing Performance: On the Horizon 03 Jul 2021 » How To Add eBPF Observability To Your Product 15 Jun 2021 » USENIX LISA2021 BPF Internals (eBPF) 04 Jun 2021 » An Unbelievable Demo Blog index About RSS Brendan's site: Start Here Homepage Blog Sys Perf book BPF Perf book Linux Perf eBPF Tools perf Examples Perf Methods USE Method TSA Method Off-CPU Analysis Active Bench. WSS Estimation Flame Graphs Heat Maps Frequency Trails Colony Graphs DTrace Tools DTraceToolkit DtkshDemos Guessing Game Specials Books Other Sites Copyright 2024 Brendan Gregg. About this blog",
    "commentLink": "https://news.ycombinator.com/item?id=41992419",
    "commentBody": "AI Flame Graphs (brendangregg.com)169 points by mfiguiere 12 hours agohidepastfavorite30 comments _heimdall 47 minutes ago> Imagine halving the resource costs of AI and what that could mean for the planet and the industry -- based on extreme estimates such savings could reduce the total US power usage by over 10% by 2030 The way this is phrased threw me off. It sounded to me like the author was comparing the power use of a more efficient LLM industry to US usage without LLMs and expecting it to be 10% lower. Looking into the source linked with the claim, it doesn't even hold up when compared against how much power LLMs use today. The linked article raises an estimate that LLM power use could increase 15-23 times between 2023 and 2027, and that by 2030 LLMs could account for 20-25% of our total energy use. Working that match backwards, the benefit the author is hailing as a success is that we would only increase energy use by say 7.5-11.5 times by 2027 and that in 2030 LLMs would only be 10% of the total energy use. That's not a win in my book, and doesn't account for the Jevan's Paradox problem where we would almost certainly just use all that efficiency gain to further grow LLM use compared to the 2030 prediction without the efficiency gains. reply wcunning 5 hours agoprevI actually looked at this in detail about a year ago for some automated driving compute work at my previous job, and I found that the detailed info you'd want from Nvidia was just 100% unavailable. There's pretty good proxies in some of the data you can get out of Nvidia tools, and there's some extra info you can glean from some of the function call stack in the open source Nvidia driver shim layer (because the actual main components are still binary blob, even with the \"open source\" driver), but over all you still can't get much useful info out. Now that Brendan works for Intel, he can get a lot of this info from the much more open source Intel GPU driver, but that's only so useful since everyone is either Nvidia or AMD still. The more hopeful sign is that a lot of the major customers of Nvidia are going to start demanding this sort of access and there's a real chance that AMD's more accessible driver starts documenting what to actually look at, which will create the market competition to fill this space. In the meantime, take a look at the flamegraph capabilities in PyTorch and similar frameworks, up an abstraction level and eek what performance you can. reply kevg123 3 hours agoprev> based on Intel EU stall profiling for hardware profiling It wasn't clearly defined but I think EU stall means Execution Unit stall which is when a GPU \"becomes stalled when all of its threads are waiting for results from fixed function units\" https://www.intel.com/content/www/us/en/docs/gpa/user-guide/... reply Veserv 41 minutes agoprevI do not really understand the mentioned difficulties with instruction profiling. Are they saying it is hard to sample the stacks across the boundary? Are they saying it is hard to do so coherently because the accelerator engine is actually asynchronous so you need to do some sort of cross-boundary correlation? However, they then talk about file systems and /proc representations which have nothing to do with the actual sampling process; only posing problems for the display of human-readable information. Many naive profiling, tracing, and logging implementations conflate these actions to their detriment; are they being conflated here or is it just a generic statement of the scope of problems? reply zkry 6 hours agoprev> Imagine halving the resource costs of AI and what that could mean for the planet and the industry -- based on extreme estimates such savings could reduce the total US power usage by over 10% by 20301. Why would it be the case that reducing the costs of AI reduces power consumption as opposed to increase AI usage (or another application using electricity)? I would think with cheaper AI their usage would be come more ubiquitous: LLMs in fridges, toasters, smart alarms, etc. reply Erethon 6 hours agoparentThis is the https://en.wikipedia.org/wiki/Jevons_paradox and it's what always happens in these cases. reply ben_w 5 hours agorootparentIt does happen, but not always. For example, food got cheaper and consumption has increased to the extent that obesity is a major problem, but this is much less than you might conclude from the degree to which productivity has increased per farmer. For image generation, the energy needed to create an image is rapidly approaching the energy cost of a human noticing that they've seen an image — once it gets cheap enough (and good enough) to have it replace game rendering engines, we can't really spend meaningfully more on it. (Probably. By that point they may be good enough to be trainers for other AI, or we might not need any better AI — impossible to know at this point). For text generation, difficult to tell because e.g. source code and legal code have a lot of text. reply _heimdall 22 minutes agorootparentFood may be a bit of an outlier, the number of consumers won't change quickly in response and each person can only eat so much. When it comes to converting electricity into images and text, there really is no upper bound in sight. People are happy to load the internet up with as much content as they can churn out. reply esafak 6 hours agoparentprevIt's possible to decrease costs faster than usage can rise. reply airstrike 5 hours agoparentprevYou specifically picked things like toasters and fridges which seem like frivolous if not entirely useless applications of LLMs. But you can be more charitable and imagine more productive uses of AI on the edge that are impossible today. Those uses would presumably create some value, so if by reducing AI energy costs by 90% we get all the AI usage we have today plus those new uses that aren't currently viable, it's a better bang for buck. reply lodovic 6 hours agoparentprevI had the same thought - power use will not be halved, usage will double instead. reply theptip 4 hours agoparentprevThe answer depends on what is rate-limiting growth; while we are supply-constrained on GPUs you can’t just increase AI usage. The next bottleneck will be datacenter power interconnects, but in that scenario as you say you can expect power usage to expand to fill the supply gap if there is a perf win. reply treefarmer 26 minutes agoprevWould love it if it was available and open source so people could use it in their own projects (or on their own hardware), instead of only being available on Intel's AI Cloud. But cool idea and execution nevertheless! reply xnx 5 hours agoprev> Imagine halving the resource costs of AI and what that could mean for the planet and the industry Google has done this: \"In eighteen months, we reduced costs by more than 90% for these queries through hardware, engineering, and technical breakthroughs, while doubling the size of our custom Gemini model.\" https://blog.google/inside-google/message-ceo/alphabet-earni... reply htrp 5 hours agoparentrephrased as \"We took compute from everything else.... and gave it to AI\" reply davidclark 5 hours agoprevThis is so cool! Flame graphs are super helpful for analyzing bottlenecks. The eflambe library for elixir has let us catch some tricky issues. https://github.com/Stratus3D/eflambe/blob/master/README.adoc reply simpledood 1 hour agoprevI've tried using flame graphs, but in my view nothing beats the simplicity and succinctness of gprof output for quickly analyzing program bottlenecks. https://ftp.gnu.org/old-gnu/Manuals/gprof-2.9.1/html_chapter... For each function you know how much CPU is spent in the function itself, as opposed to child calls. All in a simple text file without the need for constantly scrolling, panning, and enlarging to get the information you need. reply adrianco 8 hours agoprevThis is super interesting and useful. I tried reading the code to understand how GPU workloads worked last year and it was easy to get lost in all the options and pluggable layers. reply have_faith 7 hours agoprev> Imagine halving the resource costs of AI ... based on extreme estimates such savings could reduce the total US power usage by over 10% by 2030 Is that implying that by 2030 they expect at least 20% of all US energy to be used by AI? reply benreesman 7 hours agoparentData centers are big consumers of energy. Most modern data centers will have a mix of vector and scalar compute because ML/AI is a bunch of stuff, most of which was ubiquitous a decade ago. In the limit case where Prineville just gets 100k BH100 slammed into it? The absolute best you’re going to do is to have Brendan Gregg looking at the cost. He’s the acknowledged world expert on profiling and performance tuning on modern gear in the general case. There are experts in a vertical (SG14, you want to watch Carl Cook). I’ve been around the block and my go-to on performance trouble is “What’s the Gregg book say here…” it your first stop. reply Writingdorky 6 hours agoparentprevThe data source is linked and is based on the ARM Datacenter Energy prediction. But i don't think its too far fetched. The compute needed for digital twins, simulating a whole army of robots than uploading it to the robots, who sitll need a ton of compute, is not unrealistic. Cars like Tesla have A TON of compute build in too. And we have seen what suddenly happens to an LLM when you switch the amount of parameters. We were in a investment hell were it was not clear in what to invest (crypto, blockchain and NFT bubble bursted) but AI opened up the sky again. If we continue like this, it will not be far fetched that everyone has their own private agent running and paying for it (private / isolated for data security) + your work agent. reply klysm 7 hours agoparentprevSeems pretty absurd reply benreesman 7 hours agorootparentGiven who said it, I chose to read for understanding. reply shidoshi 3 hours agoprevI can imagine Nelson and other Anthropic engineers jumping for joy at this release. reply FeepingCreature 4 hours agoprevUnrelated, but on the topic of reducing power consumption, I want to once again note that both AMD and NVidia max out a CPU core per blocking API call, preventing your CPU from entering low power states even when doing nothing but waiting on the GPU, for no reason other than to minimally rice benchmarks. Basically, these APIs are set up to busyspin while waiting for a bus write from the GPU by default (!), rather than use interrupts like every other hardware device on your system. You turn it off with NVidia: `cudaSetDeviceFlags(cudaDeviceScheduleBlockingSync)` AMD: `hipSetDeviceFlags(hipDeviceScheduleBlockingSync)` On Pytorch NVidia: `import ctypes \\ ctypes.CDLL('libcudart.so').cudaSetDeviceFlags(4)` AMD: `import ctypes \\ ctypes.CDLL('libamdhip64.so').hipSetDeviceFlags(4)` This saves me 20W whenever my GPU is busy in ComfyUI. Every single device using the default settings for CUDA/ROCM burns a CPU core per worker thread for no reason. reply bob1029 3 hours agoparent> for no reason other than to minimally rice benchmarks. For AI/ML applications, perhaps no one will notice. For gaming, yielding threads of execution to the OS can periodically incur minimum scheduler delays of 10-20ms. Many gamers will notice an ~extra frame of latency being randomly injected. reply FeepingCreature 2 hours agorootparentSure, but CUDA is an AI/ML API, and anyways you're not doing blocking calls when writing a graphics engine regardless. (Well, you better not.) And anyways, these calls will already busyspin for a few millis before yielding to the OS - it's just that you have to explicitly opt in to the latter part. So these are the sorts of calls that you'd use for high-throughput work, but they behave like calls designed for very-low-latency work. There is no point in shaving a few milliseconds off a low-seconds call other than to make NVidia look a few percent better in benchmarks. The tradeoffs are all wrong, and because nobody knows about it, megawatts of energy are being wasted. reply nonamepcbrand1 5 hours agoprevtotally looks like self promotion article lol reply tantalor 3 hours agoparentThis guy invented flame graphs (among other things) so... I'm gonna allow it. https://en.wikipedia.org/wiki/Brendan_Gregg reply Lerc 5 hours agoprev [–] There has been a bit of hyperbole of late about energy saving AI. There isn't a magic bullet here, it's just people improving a relatively new technology. Even though the underlying neural nets are fairly old now, the newness of transformers and the newness of the massive scale means there's quite a lot of low hanging fruit still. Some of the best minds are on this problem and are reaching for the hardest to get fruit. A lot of these advancements work well together improving efficiency a few percent here, a few percent there. This is a good thing, but people are doing crazy comparisons by extrapolating older tech into future use cases. This is like estimating the impact of cars by correctly guessing that there are 1.4 Billion cars in the world and multiplying that by the impact of a single model-T Ford. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Brendan Gregg's blog introduces AI Flame Graphs, a tool by Intel designed to visualize AI hardware and software profiles to optimize performance and reduce costs.- AI Flame Graphs, inspired by CPU flame graphs, are available as a preview in the Intel Tiber AI Cloud, aiming to aid developers in identifying performance improvements.- The blog also discusses challenges in AI profiling, potential energy savings, and future developments of AI Flame Graphs, alongside other topics like Linux Crisis Tools and eBPF Documentary."
    ],
    "commentSummary": [
      "The discussion on AI Flame Graphs suggests that improving AI efficiency could potentially reduce US power usage by over 10% by 2030, though some argue this might lead to increased AI usage instead.- There are challenges in accessing detailed GPU profiling data, with hopes that market demand will encourage greater transparency.- Current GPU APIs are noted to consume unnecessary CPU power, with suggestions on how to mitigate this issue, reflecting on the complexities of AI energy efficiency improvements."
    ],
    "points": 169,
    "commentCount": 30,
    "retryCount": 0,
    "time": 1730271290
  },
  {
    "id": 41989322,
    "title": "Hobby CAD, CNC machining, and resin casting (2015)",
    "originLink": "https://lcamtuf.coredump.cx/gcnc/full/",
    "originBody": "Hobby CAD, CNC machining, and resin casting A tutorial for getting top-notch results with benchtop CNC mills and modern polymers Copyright (C) 2013, 2014, 2015 by Michal Zalewski (lcamtuf@coredump.cx) 1. Preface 1.1. The purpose of this guide I'm a computer geek by day, and an occasional hobbyist robot builder by night. For most DIYers, the craft of robotics requires either deep pockets, or a combination of outstanding manual skills and easy access to a top-notch machine shop. Because of this, many urban-dwelling enthusiasts tend to give up, resort to expensive and limiting premade kits, or fall back to junkyard-quality engineering. The simplest tasks are often the biggest challenge. Many can program a microcontroller; not as many know how to make a simple actuated joint, a custom gearwheel, or a custom chassis for their creations. With 3D printers, we've been promised a revolution in desktop manufacturing, but many of the issues are more fundamental - having to do with mastering CAD software or understanding materials science to make lightweight and durable parts. Meanwhile, on the manufacturing side, a simple, affordable, and home-workshop-friendly solution - CNC machining coupled with resin casting - is already within reach. Around 2007, I took a huge leap of faith, decided to buy a small CNC mill (Roland MDX-15), set up a resin casting workshop, and then engaged in a fair amount of trial and error to understand the tech. Today, I can routinely crank out remarkably cool and precise designs in no time, and with only minimal cost: This guide is more or less modular. If you're interested in buying a CNC mill, keep reading. If you already have one and know how it works, or want to try the overall process with a 3D printer or other manufacturing process, you can skip directly to the relevant part: Section 3: A crash course in CAD and CAM. Section 4: A primer on high-performance casting resins and moldmaking work. Section 5: A library of components for electromechanical projects. Section 6.1: Simple part design techniques for optimal rigidity and strength. Section 6.2: An introduction to gear geometries and transmission systems. 1.2. A bit on CNC machining, and how it compares to 3D printing In basic terms, computer numerical control milling is a \"subtractive\" method for processing raw material (workpiece or stock), usually with a drill-like rotating cutter (end mill), through a set of computer-driven movements of the cutting head. You can think of it as a robot equipped with a Dremel tool. Some of the most basic CNC mills resemble a drill press on steroids. A growing number of them is designed specifically for home and office uses, and have more sophisticated looks - but still, in comparison with technologies such as 3D printing, which produces 3D shapes by additive deposition, CNC machining seems pretty savage. In reality, the most common hobby 3D printing method - FDM, or fused deposition modeling - is difficult to use for precision, high-quality parts. The extrusion process is finicky and dimensionally inaccurate; further, materials such as PLA tend to exhibit poor mechanical strength. Affordable resin printers are more promising, but also surprisingly messy and excruciatingly slow. For now, CNC has an upper hand on four fronts: Precision: when I started working on the guide, this was a good result from a Makerbot FDM printer; and this would be a more common example. The technology has improved since, but it's still nowhere near WYSIWYG. In contrast, CNC mills can achieve true mechanical resolutions of 5 µm (0.005 mm) in all axes, and produce silk smooth surfaces for almost arbitrarily complex parts. Right now, the real-world accuracy of a $2,000 mill is usually difficult to replicate with any printer that costs less than $20,000. In fact, even with very expensive printers, there tend to be significant constraints on what you can make: features smaller than 0.7 mm in the X-Y plane, or under 0.1-0.2 mm in the Z axis, are often taboo. Choice of materials: CNC machines work in cheap, commodity materials - anything from wax, to transparent plastics, to PCBs, to wood, to plaster, to aluminum, to steel. 3D printers, on the other hand, are restricted to a small set of proprietary stock, and produce parts that are rarely suitable for demanding applications - chiefly due to poor strength. Cost per part: With the processes advocated in this guide, the cost of making a small part out of high strength, engineering grade plastic, or from tough rubber, seldom exceeds 25 cents; the raw material hovers at about $15 per liter or so (this photo log has a detailed price breakdown). Speed: A typical cutting process takes between 5 minutes and 3 hours on a medium size CNC mill. When it's done, it's done: you don't need to remove intricate supports, wash, sandblast, polish, seal, or post-cure the part. Most additive technologies take much, much longer to produce usable parts of similar size, and almost always require painstaking manual work to get rid of manufacturing artifacts. On the flip side, the fundamental advantage that 3D printers have over CNC mills is that they can often produce basic internal geometries inside enclosed parts - whereas milling can only process the areas for which there is a sufficient cutter clearance. It is not always trivial to do that on low-cost 3D printers - and the constraint of CNC mills is seldom a big deal: almost everything can be split into halves, rotated, or so. Still, it is a constraint, even if almost every mass-produced item - from iPads to soda bottles - copes with this reality in a graceful way. 1.3. The virtues of resin casting Resin casting is a nifty process that involves creating a mold, and then pouring a liquid, two-component polymer resin into the mold cavity. Once the resin sets, the finished part is removed - and the mold can be used again. This method of replicating parts is popular artists of all trades, but is seldom employed in amateur CNC or 3D printing work. Despite sounding needlessly complicated, it's a fantastic addition to any DIY workshop. It offers some interesting advantages over directly machining (or printing, or hand-carving) the desired shape: You can use just about any material, including some truly exotic choices. You can master the workflow for one easily-shaped tooling material - perhaps even clay! - and then make the final part out of rubber, glass-filled composite, low-melt metal, or concrete laced with rocks. You can customize the apperance of the part, practically for free. There is no need to spend money on a variety of differently colored materials, you can just add several drops of dye. You can replicate and tweak parts easily. You can quickly make 50 identical gearwheels, instantly replicate a broken part, or change the mechanical properties of a component on the go. You save materials and time. Directly machining a part out of aluminum or plastic involves starting with a rectangular stock and then removing most of it. Moldmaking is considerably more efficient, with less waste and faster cycle times. Although you can follow this guide just for the CNC bits, some of the content is geared toward that process - and it's probably worth your time. 1.4. But how much will this really cost me? As with any hobby, sky is the limit! That said, if you want to get good results on a budget, the breakdown of expenses is roughly this: CNC mill: as little as $1,000 to $3,000 for an entry-level unit; around $150 for end mills and collets. CAD / CAM software: $0 to $1,000, depending on taste. Free of charge options are available, and work reasonably well. Resin casting setup: $100 for a vacuum pump; $70 for chamber and hoses; less than $100 for mold releases, cups, and other auxiliary supplies. Media for moldmaking work: $230 for a giant (150 x 50 cm) prototyping board; $120 for two gallons of polyurethane resin; $130 for a pail of silicone. This should last for at least a year. Other tools: $70 for a micron-resolution micrometer; $50 for a micron-resolution dial indicator; $40 for a simple magnifier. For the processes advocated in this guide, the ongoing maintenance costs for a CNC mill are negligible: after several thousand hours of machining, you may have to replace several bearings or spindle motor; cutters should last for hundreds of hours, too. The savings add up quickly, especially if you are already paying for specialty or made-to-order parts. 2. Setting up a CNC mill Okay, still interested? Let's dive in, then. The first \"proper\" section of this guide deals with shopping for a mill and understanding its operating characteristics; picking the appropriate cutting tools; and monitoring the performance of your setup to achieve perfect results every time. Again, if you're using another manufacturing process and are interested strictly in the CAD tutorial or the resin casting bits, feel free to skip ahead. 2.1. Picking the right machine Some purists make a distinction between what they call \"CNC routers\", suited chiefly for working in wood and plastics, and \"true\" CNC mills, designed for machining steel. This guide will not dwell on this; almost any CNC machine can handle almost any material, albeit not always as quickly as a beefier mill. Just as importantly, the focus on metal is usually a distraction. Unless you're making car parts or firearms, machining metals isn't cost-effective and in home workshops, isn't particularly fun. With this in mind: gneral purpose, benchtop-sized CNC mills start at around $600 and go up to $20,000 or so. There are numerous manufacturers of benchtop CNC mills around the world; examples include Carbide 3D, Laguna Tools, Roland DG, Taig, LittleMachineShop, Probotix, and many more. Some folks have luck with ultra-low cost mills made in China, too, although this is hit-and-miss. When shopping for a pre-made system, there are several key characteristics to pay attention to; let's have a look at them, and use them as an excuse to discuss some of the inner workings of CNC milling jobs. 2.1.1. Number of axes This is perhaps the most fundamental quality of any CNC mill. In the most basic design, the cutting head can move in three directions - X, Y, and Z - and the tool itself always points down, aligned with the Z axis. In this setup, the machine can only machine shapes that can be represented using a two-dimensional \"depth map\" projected onto the workpiece: the cutter may descend lower for some X-Y coordinates, and move up for others, but it will not enter the workpiece from any other side. This video is a pretty good illustration of the process: In this machining mode, the machinable geometries are outlined here: Note: CAM applications are designed to fail safely in regard to part geometry; that is, if a cavity on the part can't be reached without going through an area that isn't supposed to be cut, the problematic region won't be machined at all. The gray regions in the two workpieces on the right correspond to the material that will be left in place. The limitations of three-axis machining may seem severe, but seldom truly are. Every section of an industrial injection mold or a metal forming die typically needs to be a depth projection anyway, so that the processed material could be pulled out of it easily. Even in direct machining, it is common to simply flip the workpiece with the aid of registration pins. This video illustrates the manual rotation process fairly well. That said, there are some shapes that truly benefit from automated, multi-directional machining; this includes exotic types of gears (helical, herringbone, and worm geometries), screws / bolts, and certain categories of jewelry (say, rings). For these uses, some CNC mills come with additional rotary \"axes\": the so-called A axis corresponds to rotating the workpiece around the X axis (see video); B axis stands for rotation around Y; and C axis is the rotation around Z. The four-axis AXYZ setup is the most common one. The premium for fourth axis starts at around $100 for manual indexers (a precision rotary chuck that holds the workpiece, but where the angle needs to be dialed in manually); and from $500-$1,000 for computer controlled units. What to buy: 99% of moldmaking work will not appreciably benefit from a fourth axis, so three axes are usually fine. You may want to get a mill where fourth axis is an option, though, especially if you are also planning to projects such as jewelry or artistic figurines. 2.1.2. Mechanical movement ranges Greater X-Y-Z tool movement ranges translate to the ability to make larger parts in a single pass. It's important to pick a mill that won't get in the way of your imagination - but to make this call, you need to calibrate your expectations sensibly. As an extreme example, let's consider building a man-sized biped robot. You don't need a man-sized mill for that job - for at least three reasons: Although the entire project would be obviously pretty big, virtually all the individual parts should be much smaller. In fact, most of the components will likely fall into the range of 1 to 30 cm. Any oversized part can be broken into sequentially machined segments. If you are using the resin casting process, this scales up almost arbitrarily; in other types of work, you will see some (usually modest) constraints. Many large and simple elements do not have to be machined at all; for example, it would be sensible to make the frame out of pipes or metal rods sawed to the desired length, and then simply machine custom connectors and joints that hold the frame together. What to buy: do your own math. In my experience, about 15 x 10 cm in the X-Y plane is a good starting point, and about 30 x 20 cm will accommodate almost any medium-size robotic job. In the Z axis, you will probably not need more than 4 cm or so; and going over 8 cm is usually pointless. Whatever you do, do not confuse movement ranges with table dimensions, though. 2.1.3. Use of a specialized spindle Spindle - the part that connects the motor and the rotating tool - has a profound impact on the accuracy of any CNC mill. Its role is to ensure that the rotation of the tool is highly concentric and vibration-free, and that it stays this way under load. If the whole rig is not perfectly centered, you may end up with a situation such as this: The total amount of back-and-forth wobble - in other words, the difference between the intended and effective diameter of the tool - is known as total indicated runout, or TIR. High TIR will not only affect the dimensional accuracy of machined parts, but will also ruin surface finish, and prematurely wear the tool. In fact, the effect is pretty dramatic: in some materials, eccentricity of 0.01 mm can reduce tool life by 50%. Proper CNC spindles are usually long, round or rectangular blocks of metal with precision ball bearings mounted on both ends (and often pre-tensioned with a spring). Inside, there is a heavy-duty rotating shaft that couples the motor belt drive system to the tool holder. With quality spindles, TIR usually can be kept below 2 µm. Some of the low-end manufacturers don't bother with a proper spindle, however; the most common example of this are CNC mills that use repurposed manual rotary tools. These cases are a bit of a gamble: some of them may have still somewhat bearable TIR in the vicinity of 0.01 mm - but some will be as bad as 0.10 mm, which makes them fairly bad for precision work. Runout aside, you also can't be sure if the tool is perfectly aligned with the Z axis or not; if it isn't, that opens a yet another can of worms. Note: to put all these numbers in perspective, 0.10 mm is roughly the diameter of a human hair; level differences of this magnitude can be easily felt when sliding your finger across a hard surface. Notches down to about 0.05 mm can be easily seen on smooth but matte finishes - and on glossy surfaces, the threshold may be closer to 0.01 mm or so. What to buy: try to avoid CNC mills without real spindles; if you need to get one, ask the manufacturer about TIR. If they are not sure, it's an obvious red flag: the parameter can be trivially measured with a $50 tool, and is one of the most rudimentary things to examine when designing a mill. Note that there are aftermarket spindles that can be fitted into certain mills, though! 2.1.4. Movement precision There are many factors that contribute to the real-world precision of a CNC mill, but one of the most important aspects is repeat accuracy: the ability to return to the same position over and over again. Along with spindle characteristics, this quality has a tremendous impact on surface finish, and on the dimensional accuracy of small parts. Repeat accuracy is affected chiefly by two things: Backlash: many types of transmissions will have some amount of play, which often leads to imperfections in positioning. This play tends to be greater in CNC mills that use stepper motors or acme screw drives; and lower with servo motors and ball screws. Mill rigidity: machines that use low-cost materials (HDPE, plywood, sheet metal) to hold everything together, rely on rudimentary slides to support the moving parts, or use timing belts as a motion system, will deflect more significantly under load, or in response to own acceleration and deceleration. This problem is much less pronounced in mills with heavy-duty cast frames and ball-bearing linear ways. Unfortunately, there is no widely accepted standard for testing repeat accuracy; many manufacturers don't bother to advertise it, and others test it with varying levels of honesty. In fact, the good guys will give you a figure that represents the worst-case, momentary deviation following a rapid long-distance movement - but that's not really representative of most types of fine work with sub-millimeter tools. Now, don't despair: the good news is that most of the commercially available mills are actually pretty good in this department, especially when moving slower and doing precision cuts in easily machinable stock. You can expect many entry-level mills to conduct themselves within 0.02 mm or better during normal work; more expensive units with ball screws and servo motors will probably stay around 2-5 µm. Accuracy aside, mechanical resolution is the other important piece of the puzzle. Stepper or servo motors in a CNC mill can assume only a certain number of positions per turn, and that translates to a specific minimum distance by which the table or the cutting head can be moved around. Insufficient mechanical resolution means that the mill will have difficulty smoothly approximating certain curves, and may end up producing unattractive finish. What to buy: The basic rule is that you should not expect a plywood-based contraption with acme screws to reach 1 µm repeat accuracy. If the manufacturer advertises an improbable value, ask them to explain. If they advertise a suspiciously high figure (over 0.1 mm or so), be wary, too. As for the mechanical resolution: look for 5 µm or better. 2.1.5. Machining speeds Time is money. When it comes to CNC machining, the time needed to complete a job is to a surprising extent dependent on your skill and the capabilities of your software - but with a skilled operator and good toolpath decisions, the final part of the equation is always the performance of the mill itself. To understand how the mill's performance is tied to the numbers you see in the datasheet, it is helpful to look at the geometry of a typical end mill. Upon closer inspection, the tool closely resembles a drill: it consists of a round shaft with several blades (flutes) wrapped around it in a spiral fashion. As opposed to a drill, however, these flutes have a sharp, exposed edge running along their entire length; this is because the bulk of their work is meant to be done by moving sideways. This is how it looks from the top: Even in the most easily machinable material imaginable, the cutter is able to scoop away only a certain amount of swarf per turn - just enough to fit under the flute. If you exceed that capacity, you will end up dragging a clogged, non-cutting tool across the workpiece - which ends with one or the other eventually giving up. For every material and cutter geometry, there is an optimal ratio of linear speed and cutter RPM that leads to efficient, high-quality machining. This is often expressed as feed per tooth. In plastics and similar materials, the ideal values are: Up to 0.1-0.2 mm for larger tools used to do the bulk of material removal in every cutting job. These tools frequently have four flutes, so this translates to 0.4-0.8 mm per turn. Down to 0.01 mm or less for sub-miniature, 2-flute cutters used to reproduce minutiae detail (0.02 mm per turn). In practical terms, it's healthy to aim for mills where the ratio between maximum movement speed (mm/min) and maximum RPM hovers around 0.4 to 0.8 for optimum performance during rough cutting. At the same time, there is also some value in shopping for the highest maximum RPM you can get - as it lets you move faster during the precision finishing steps. Of course, there are some gotchas: Very high spindle speeds tend to be problematic; going over 25,000 RPM or so may cause problems with heat dissipation, tool oscillation, and so on. High traverse speed can help even without high RPM. This is because certain types of cutting jobs involve a fair amount of rapid, non-cutting movements between various locations to be machined. Good CAM applications should know to avoid excess travel, but not all CAM applications are very good. Acceleration matters. Fast-moving mills need to be good at accelerating and braking to fully utilize their capabilities during series of short, stop-and-go movements that are often involved in CNC work. Rates of at least 0.1 G (~1 m/s²) are desirable in any mill capable of four-digit speeds. What to buy: at least 6,000 RPM is nice; and if the aforementioned speed ratio is favorable, there are no real downsides to going up to 20,000 RPM. Maximum movement speed, in mm/min, should be ideally at least 6-10 times the movement range, so that it doesn't take more than several seconds to traverse the table. 2.1.6. Tool sensor support Spare for some pathological situations, the mill is intrinsically aware of the position of its spindle at any given time; but the actual cutting action takes place beneath the spindle - at a distance dictated by how far the tool sticks out from its holder. And here lies the problem: most toolholding systems do not allow you to precisely preset tool extension length, or to maintain it when you replace the cutter. If you switch the tool in the middle of a machining process, and don't compensate for the difference, the results will be off; in fact, the tool may unexpectedly hit an uncut area and break. There are several manual tricks that can be used to work around this issue. One of them is to place a thin strip of paper or foil in a fixed reference location, and then slowly lower the tool until the strip gets caught between the cutter and whatever happens to be underneath. By comparing the Z position of the spindle at that point with the reading obtained for the previous tool, the appropriate offset can be calculated and communicated to the machine. But of course, this technique is somewhat inconvenient, and accurate only to perhaps 0.05 mm. A better approach is to incorporate a tool height sensor into the mill. The sensor can be just a flat block of precisely machined metal; the mill automatically lowers the tool onto the sensor until contact is made - which, in the simplest design, is detected by noticing the flow of current between the probe and spindle body. The accuracy of this approach is often better than 0.01 mm. More complex (and costly) solutions involving optical sensors can also be used. What to buy: try to find a mill that has a built-in sensor, or can be equipped with one. Failing this, you can always rig a manual tester that uses the same operating principle, and simply illuminates a LED. 2.1.7. Tool mounting method The spindle must be terminated with some sort of a tool holding device. This can be a direct system, where the tool slides into the spindle assembly with no intermediate components; a collet-based approach, where the spindle accepts a small clamping device that actually grips the cutter and is tightened with a nut; or a model where the spindle has a large tapered bore that accepts standalone toolholders used by automatic tool changers. Leaving automatic tool changers and exotic cutters aside, the simplest way to clamp an endmill is to use a fixed-diameter opening, be it using a set screw or thermal expansion (shrink-fit). The solution can be very accurate, but is also quite cumbersome when it comes to tool changes. For example, on a Roland MDX-15 mill, you have to replace the entire spindle assembly to switch between two different diameters of the shank. On the opposite end of the spectrum, you have jaw chucks, similar to the solution seen in power drills. They can grip a wide range of tool diameters, but tend to suffer from poor eccentricity, and TIR is seldom better than 0.2 mm. For precision work and rigid CNC machines, that's a bad deal. A reasonable middle ground is a system that accommodates fixed-diameter collets fastened with a nut; the spindle has a single taper to accommodate a family of collets (e.g., ER16), and every collet is precision-ground to hold a specific diameter of a tool. Because collet changes are quick and the collets themselves are inexpensive, this is a good balance between accuracy and ease of use. The ER system is a particularly popular and dependable choice. What to buy: If you can get ER or a similar collet-based system, go for it. Otherwise, just make sure that the toolholding system is versatile enough to accommodate common shank sizes (3, 4, and 6 mm for metric cutters; 1/8\" and 1/4\" for imperial system tools), and will be sufficiently precise for your needs. 2.1.8. Availability of CAM software Manually programming your CNC machine is about as much fun as building a steamboat out of toothpicks. For a higher-level approach, you need to turn to CAM software: it automatically analyzes the provided geometry (created with any 3D modelling application) and converts it to a set of paths that need to be retraced by the tool to approximate the desired shape. Once these toolpaths are ready, the software then breaks them down into a sequence of painfully basic instructions that actually make sense to the controller embedded in the mill; say, \"set speed to 12,000 RPM\" or \"move cutter to X = 10.245, Y = 5.000, Z = -2.000\". The toolpath generation stage is largely hardware-agnostic; but the program generation one isn't. It's good to shop for a machine that speaks a common and well-documented language - or, lacking this, is popular enough to be supported by some of the best-known CAM apps. Keep in mind that even if the manufacturer bundles the mill with some starter software, you don't want to be left out in the cold if the application one day refuses to work with your new PC - or if it simply turns out to be of poor quality. The most common quasi-standard language used by almost all CNC mills is called G-code (aka \"NC\"). Calling it a real standard may be a stretch: there are very significant variations in how the syntax is implemented by the manufacturers. Still, having support for G-code spells rudimentary compatibility, or at least easy integration, with almost any CAM application on the market. For other languages, this is not always given. What to buy: check if the mill is supported by common third-party packages (Deskproto, VisualMILL, madCAM, MeshCAM, Mayka, etc); if it's not, and if it speaks something else than a clearly documented variant of G-code, be wary. 2.1.9. Size, weight, power needs We're almost done: the last thing to do is a quick reality check. Benchtop mills span from units no larger than an inkjet printer, to ones weighing in excess of 200 kg and taking up almost 1 x 1 m of desk space. When shopping for the larger models, be sure to account for their physical characteristics, and make sure you have a way to get them in your workshop to begin with (some doors are barely 70 cm wide). For heavier mills, it is also important to have a piece of sturdy furniture; it's not just the static load that you have to worry about, as the machine may also produce horizontal shear forces due to acceleration and deceleration of the cutting head. Not every wobbly desk from Ikea can handle that - but any proper workbench should. Benchtop mills usually run on standard, single-phase 110 / 230 VAC power supply, but of course, make sure to double-check. They may require several amps in peak, so you don't want them to share a single circuit with a vacuum cleaner, an electric kettle, or a space heater - especially in an older home. 2.1.10. And now, all the things you don't have to worry about Okay - that sums up the list of parameters that are worth looking at. There are also some characteristics that sound important, but usually aren't - so to help you decide, here's a quick list to consult when in doubt: Positioning accuracy: this value tells you how true the machine's idea of a millimeter is to a calibrated reference. The difference is usually negligible, and even if it wasn't, you can compensate in software without any special effort. Origin reproducibility: this indicates how good the machine is about resuming the same starting location after being power cycled. Not particularly important in normal work, unless your power goes out in the middle of a cutting job. Software resolution: unlikely to be lower than mechanical resolution, and fairly meaningless if it's higher. Motor power: spindle motors delivering as little as 75-100 W should be perfectly sufficient for the processes advocated in this guide. More powerful mills are beneficial chiefly in heavy-duty metal work. Table size: easy to confuse with the actual machinable area, but nowhere near as important. The difference between a 2 cm margin and a 10 cm one usually doesn't matter at all. List of millable materials: every mill should be able to cope with a wide variety of materials; don't read too much into the list provided by the manufacturer. Tool changer (ATC): it's a convenient device for unattended jobs, but it's usually not worth the expense in hobby work. It's nice, but unless you have money burning a hole in your pocket, you can do without it. Contact scanner accessory: contact scanning heads are a gadget available for some CNC mills, but chances are, you will use them to scan a couple of coins or pendants, and then lose all interest. For reverse engineering of mecanical designs, just using a caliper works a lot better, and takes less time. Noise ratings: probably not what you think. These parameters describe the noise produced by the mill when in standby mode (spindle off); or when operating, but not making contact with a workpiece. Benchtop mills are fairly quiet in no-load conditions; and even the most compact and underpowered devices can be pretty loud when actually machining something. The actual noise level will range from barely perceptible when working in waxes or using sub-mm cutters, to pretty unpleasant when rapidly plowing through metal with a large-diameter tool. In fact, just imagine the noise made by a saw or a drill. Well, that's probably it. If you spot any other puzzling parameters, please let me know. 2.1.11. So, which one should I buy?! That really depends on your budget and the scale of the projects you want to be working on. The manufacturers listed 2.1 are a starting point, but the market is evolving rapidly; I had some specific recommendations listed here in the initial version of the guide, but within two years, most of them were out of date. My best advice is to run some Google searches; if in doubt, check out forums such as /r/hobbycnc on Reddit, or simply drop me a mail. 2.2. Stocking up on end mills Ordering a CNC machine? Well, the next stop is getting some cutters. The selection available on the market is quite overwhelming, so to save you time and money, let's talk about some of the properties that set these tools apart. Oh, before we dive in... here's a drawing of a typical end mill, and all the lingo you will have to memorize soon: All right - so here are the differences you will see: Material: end mills are made either out of cobalt steel alloys (known as high speed steel, or HSS), or from tungsten carbide in a cobalt lattice (colloquially shortened to \"carbide\"). The latter option is considerably harder, more rigid, and more wear-resistant - and for the tool sizes we are interested in, carries a relatively small premium (30% or so). What to buy: Stick to carbide. Coatings: carbide cutters may be further coated with ceramics such as titanium aluminum nitride (TiAlN, aka AlTiN), titanium nitride (TiN), titanium carbon nitride (TiCN), or with amorphous or crystalline diamond. The coatings tend to improve hardness or reduce friction; the bluish-gray TiAlN coating is probably the most common one. In non-abrasive plastics, this particular coating doesn't have a very pronounced effect, but it extends tool life by some 20% or so - and the cost is only 10% extra, so it's not a bad deal. Of course, in some situations, tool wear is a more pronounced concern; for example, glass or carbon fiber composites can leave a mark on carbide tools in a matter of hours. In the same vein, in ultra-precise micromachining, you may have to worry even about early-stage wear, because it can subtly affect the dimensions of the tool. In such cases, amorphous \"diamond\" coatings offer more definite benefits compared to TiAlN, often extending tool life by a factor of 2-3x. Alas, the coating at a 30%-40% premium and is available only for some tools. (True, crystalline diamond works, too, but costs a lot more and is reserved for more demanding jobs.) What to buy: If you're on a tight budget, skip any coatings and pocket the change. Otherwise, TiAlN or amorphous diamond is probably not a complete waste of money, although you can still skip it on your first set of \"training wheel\" tools. Tip geometry: precision machining operations in plastics will almost always rely on \"vanilla\", single-end finishing tools with no chip-breaking ridges, no taper, no coolant outlets, and so forth. The tips of these standard tools come in three basic flavors: Flat tip cutters are the primary tool in all sorts of mechanical work. Ball nose cutters come handy when you need to reproduce gentle slopes and other organic designs. And lastly, corner radius cutters offer a compromise design that combines 90° arcs in the corners, and a flat mid-section - but you can safely ignore them until you have a specific itch to scratch. About the only other type of a cutter worth mentioning here are conical engraving cutters, which look like this; these are useful for making very fine but shallow cuts, for example when machining traces on a PCB. What to buy: build a competent collection of flat tip cutters first. If you want to experiment, grab one or two ball nose cutters, but you probably won't be using them that much in non-artistic work. Cutting diameter: end mills come in cutting diameters from 0.01 mm (a lot thinner than human hair) to 50 mm and more. For most intents and purposes, cutters below 0.25 mm or so are just not very useful, unless you are doing some truly hardcore micromachining; and over 8 mm or so, they get too big to mount and meaningfully use on benchtop mills. Your cutters need to strike a sensible balance: large tools can't machine tiny features, but small tools remove very little material in every pass, making them useful mostly for selective refinishing work. In fact, a two-fold reduction in tool cutting diameter often translates to a 10-fold reduction in effective material removal speed! What to buy: try to get a 3 mm (or 1/8\") cutter to handle most of the machining work; for large projects, 6 mm (or 1/4\") may come handy, too. On top of that, keep 0.4 mm and 1 mm cutters for touching up fine details. Cutting diameter tolerance (tricky!): \"1 mm\" cutters don't always have a diameter of 1 mm. In a nod to the legacy of drilling and tapping applications, many manufacturers make their tools to non-symmetric tolerances, as denoted either with a pair of explicit values (say, +0.00 / -0.04 mm), or with an ISO tolerance code such as \"e8\". Of course, modern tool grinding machines are often a lot more precise than that; micron accuracy is not unheard of. The machine is therefore preset to simply crank out tools at the mid-point of the specified range. Using the example of a 1 mm tool specified as +0.00 / -0.04 mm, the actual diameter will end up being 0.98 mm or so. In most uses, you won't even notice - but then, every now and then, such a subtle difference can bite back. Okay, so the case of explicit tolerances is pretty clear; as for the \"e8\" case: for cutters with diameters below or equal to 3 mm, the offset is -0.021 mm. For cutters over 3 mm and up to 6 mm, the difference is -0.029 mm. What to buy: whatever you want, just make sure to double-check the tolerance, and write down the actual diameter of the tool. Also, if the vendor declares a suspiciously sloppy tolerance, approach such tools with caution, and perhaps ask the company if they mean it. Shank diameter: this is the diameter of the top portion of the end mill - the one that goes into the holder. It has no significant effect on the cutting process, so you simply need to make sure that you have a matching collet for all the tools you intend to buy. Cutting length: the cutter will have flutes extending only through some of its length. The height of the cutting region sets the upper limit of how deep the tool can be driven into the workpiece in a single pass. What to buy: for the processes outlined here, you typically only need the flutes to extend to a distance equal to about 50% of tool diameter. Because the flute-bearing section somewhat more vulnerable than the rest of the end mill, and may also be subject to uneven wear, it's actually beneficial to opt for stub-flute tools when you have a choice. Reach length: many end mills have a neck - a section between the flutes and the shank, across which the diameter of the tool does not exceed that of the cutting tip (and in most cases, is about 10% percent smaller). The distance from the tip of the tool to the end of this section puts an absolute limit on the depth of machining near any vertical walls: As you can see in the rightmost drawing, the problem can be avoided by introducing a non-zero draft angle: a subtle slant on any tall, vertical walls. Draft angles also help with removing cured parts from rigid molds - but are not always desirable or practical. That's why having a tool with a decent reach length is still a good plan. On the flip side, more is not always better: with miniature long-reach tools, as the neck gets longer, the cutter becomes more prone to deflection and easier to break. A 1 mm tool with a 3 mm reach can be operated with few worries; at 10 mm, you need to be a bit more careful; and at 30 mm, it starts to require ninja skills. Oh, of course, some tools don't have a neck to speak of; in these cases, there is a taper that immediately follows the flutes, and reach length is identical to cutting length. That may be good or bad, depending on whether flute length is sufficient for your needs. Note: there is an interesting special case - some 3 mm or 6 mm tools have shank diameter identical to their nominal cutting diameter; the same goes for their imperial 1/8\" and 1/4\" counterparts. You can think of them as having reach length equal to total tool length, minus about 20 mm needed for the collet. There are some drawbacks of driving these tools deeper than their cutting length, though: their pretend \"neck\" doesn't have a reduced diameter, so when dealing with zero draft angles, it may end up rubbing against the workpiece. This usually has no effect in prototyping plastics, but quickly becomes a problem in metals and other tough stuff. The situation gets slightly worse if the actual cutting diameter is smaller than the nominal one, due to non-symmetric tolerances. In these cases, driving such a tool too deep may have a minor but noticable impact on dimensional accuracy or surface finish. What to buy: moldmaking often involves relatively deep cuts and vertical walls. Make sure that your 3 mm tools have a reach of at least 20-30 mm; for 1 mm, stick closer to 10 mm; and for 0.4 mm, 2-4 mm should do the trick. Overall length (OAL): self-explanatory. Typical mold cutters have lengths of about 50 to 75 mm; some lower cost or subminiature tools may be available as 38 mm, too. Longer end mills - up to 150 mm or so - are also available, but seldom worth the price. The main significance of this parameter is that the tool will stick out of the spindle by no more than OAL, less something around 15 mm for the part that needs to be gripped by the collet. Life gets more complicated when the collet nut and the rest of the spindle gets in the vicinity of the workpiece, so it's preferable to have tools long enough to deal with the typical depth of the molds you are planning to work on. What to buy: if your projects will be anything like mine, your molds will probably range from about 6 to 22 mm in depth, with infrequent excursions down to 40 mm or so. If so, OAL of 50-75 mm is a good pick. Number of flutes: higher flute count translates to faster material removal rates and superior finish, because there are more cutting passes per every turn of the spindle. Unfortunately, there are modest limits to how many sufficiently robust flutes you can cram onto a small cutter, and still have enough room for swarf; 4 flutes are the common limit, although 6 are not unheard of. What to buy: for the materials we will be using for moldmaking, the more flutes, the better; at least three or four are strongly desirable on 3 mm cutters, and nice to have on smaller tools. For aluminum, rubbers, and malleable plastics, one or two flutes may be a better pick. Helix angle: zero degree flutes are perfectly straight, and run vertically along the tool. The industry standard is 30°, which offers a sensible balance between edge sharpness, vibration, and swarf removal speed. Lower angles are used to rapidly engage and remove softer materials (e.g., rubbers, thermoplastics); while higher angles improve tool life and reduce vibration in hard materials. What to buy: there is virtually no difference between 15, 30, 45, and 60° when working with easily machinable plastics; you can safely disregard this parameter, and just focus on finding the most interesting and the most affordable tool. Center cutting ability: almost all the cutters of interest to CNC work have a bottom flute that extends through the entire diameter of the tool - which allows it to be plunged straight down into the workpiece, and effectively act as a somewhat competent drill. But a small minority of end mills are not center-cutting, and can't be operated this way. You probably don't want that. What to buy: avoid non-center-cutting tools. Phew! My favorite tool manufacturer is Hanita (now a division of Kennametal, confusingly sold under the brand name of WIDIA): they have an unmatched selection of metric tools at reasonable prices, and are available all over the world. If you are in the States, Sierra Tool is a good reseller; Centerline Industrial is a bit cheaper, but for some reason, refuses to ship to residential addresses. And if you are anywhere in Europe, I can strongly recommend ordering Hanita products with ITC. Hanita aside, Harvey Tool has a very interesting selection of imperial system miniature tools in the US - and I found K&H Sales to be a dependable distributor. Other US manufacturers include OSG Tap & Die, Monster Tool, Micro100, and Microcut, but their catalogs are not as impressive. Readers in the EU may want to check out Nachreiner. Here are the catalogs of the three most interesting manufacturers: Hanita: full end mill range (most are \"e8\"). Harvey Tool: all tools (some have non-symmetrical tolerances). Nachreiner: carbide finishers. As for practical recommendations, I would suggest starting with Hanita 401403000, 402403000, or Harvey 73118-C4, as the baseline \"3 mm\" cutter ($15-$30); Hanita 7N2201021 or Harvey 76440-C3 for 1 mm work ($30-35); and Hanita 7N2200410 or Harvey 992515-C3 as a long-reach ~0.4 mm tool ($35). If you are not on a very tight budget, it makes sense to order two of each - it's easy to mess something up in the heat of initial experimentation. With the tools selected, you also need to make sure you have the right set of collets. For ER16, if you are not desperate to save a few bucks, try Rego-Fix \"UP\" (ultra-precision) collets; they retail for about $45 a pop, and are carried by K&H; another good option are \"DNA\" collets from Techniks (about $30, require a custom nut). You can find lower-cost collets from many other, more obscure brands - but they are not always particularly good. Oh, one more thing: for ER16, every collet has a specified clamping range - for example, 3.00-2.00 mm. It is always preferable to use the upper value: a 3.00-2.00 mm collet is better than a 4.00-3.00 one when holding a 3 mm tool. 2.3. Periodic testing and troubleshooting Before embracing any complex or high-precision projects, it is important to understand the performance of your mill, and see if anything needs to be fixed, adjusted, or compensated for. While CNC mills don't require constant tuning, making several simple measurements after unpacking the device can save you a lot of time. If you neglect this step, you will find that troubleshooting mill accuracy issues in complex, real-world projects tends to be a daunting task, simply due to the sheer number of variables to look at. The essential tool that you will need to perform the initial measurements is a micron-resolution dial indicator with a magnetic base. You can get a no-name unit on eBay for about $50 (link), or go with Mitutoyo or other reputable brand for about $220 (indicator, base). For lower-cost mills with a rotary tool acting as a spindle, you may be better served by a 0.01 mm indicator, though; in this case, you can get a Mitutoyo one for about $80 (link, base not included). 2.3.1. Spindle TIR The first thing to check is the runout of the spindle and the tool holder. Wipe clean the internal spindle taper and the collet (use WD-40 if there is any excess grease or other accummulated dirt; a small brass brush works well for any stubborn gunk), and install a tool that extends at least about 20-30 mm from the collet. Tighten until you feel definite resistance, but don't overdo it - excess force may deform the collet, and is not essential in lightweight work. Next, affix the dial indicator to the table or other sturdy surface, make the tip of the indicator touch the tool near the spindle, and observe the change in readings as you gently turn the spindle by hand, preferably at the top (the mill should be turned off, of course). Be very careful not to exert any unnecessary pressure on any of the parts. Let's call the result of this measurement Rcollet. Move the indicator about 10 mm lower (stay clear of the flutes) and repeat the test; we'll refer to it as Rmiddle. Finally, if possible, remove the tool and the collet, and reposition the indicator to make contact with the internal taper of the spindle (the measuring tip now pointing up). Repeat the procedure, and write down the result - Rtaper. Here's how to interpret the data: Rtaper: this measurement tells you about the concentricity of the spindle itself. If it is excessive, it may be time to service the spindle (e.g., adjust the internal tension spring; disassemble it and install a new pair of precision bearings; or, insert a shim somewhere to fine-tune the concentricity). Rcollet: if the spindle measurement looks OK (and only then!), this value helps you estimate the eccentricity contributed by the tool holder (on top of Rtaper). If the value is high, examine the collet for dirt and damage (again, WD-40 is a pretty good cleaning liquid). Small tool holder misalignment can be often \"fixed\" simply by adjusting the tightening torque, or applying a gentle pressure to the appropriate side of the tool when tightening the nut. If that doesn't help, replacing the collet - perhaps with a higher-quality model - may be the way to go. Rmiddle: this value lets you estimate the eccentricity at the tip of the tool, which ultimately, is the most important observation to make. You can see if the TIR is increasing, decreasing, or staying about the same in relation to Rcollet - and use that to extrapolate the apparent diameter of the tip. For a quality machine with a dedicated spindle and ultra-precision ER16 collects, after some adjustments, TIR should preferably stay within 2 µm or so; and for any mill, it is good to have runout within 0.01 mm. If you are seeing something much worse, poke around and see if you can improve it: it's usually simpler than it may seem. For example, the factory spindle that came with my MDX-540 mill had a TIR of about 6 µm; using a hook spanner to adjust the tension of the internal spring by one tenth of a turn reduced the value to 1 µm. In more complex cases, switching around or rearranging the existing bearings inside the spindle, or replacing them with new ones, will often do the trick. Tip: try to quickly repeat the Rcollet measurement after every tool change, even if you are not doing high-precision work. Trapped dirt will affect the concentricity of the tool holder, and even a tiny difference can easily reduce tool life by 50%, and increase cutting noise by more than that. 2.3.2. Axial alignment of the tool Spindle eccentricity aside, it is also useful to verify that the tool is truly perpendicular to the X-Y plane; if that's not the case, for example because one of the screws that attach the spindle to the rest of the mill is not tightened to the same torque, you may see somewhat perplexing dimensional errors in machined parts. The test you should perform is exceedingly simple: you need to mount a cutter that offers at least around 2-3 cm of clearance between the collet and the flutes; programmatically lower the spindle by 2 cm or so; and set up the dial indicator as shown on the previous drawing, in section 2.3.1. When done, gently rotate the tool to find the mid-point of its TIR, and then programmatically move the spindle up by about 1 cm. The same procedure should be repeated after repositioning the dial indicator to make contact with the side of the tool (rather than the front). If everything is fine, you should see no appreciable change in the values shown by the dial indicator; a few microns may be fine, but if the difference is getting close to 0.01 mm, you should definitely investigate. The issue is almost always trivial to fix: you may need to loosen the screws that hold the spindle in place, and perhaps insert a shim made out of aluminum foil on the offending side to straighten it out. Caution: before operating the mill, be sure to read the safety tips provided by the manufacturer, as well as the advice included in section 7 of this guide. Small CNC machines are not particularly deadly power tools, but they are still power tools - and it's your responsibility to use them safely. 2.3.3. Spindle vibration The spindle assembly is typically fairly heavy, and under normal operating conditions, will be rotating rapidly. At these speeds, any poorly balanced rotating part, any malfunctioning ball bearing, and any damaged transmission belt may easily introduce significant vibration - and that vibration will inevitably propagate to the end mill or the workpiece. It is difficult to accurately measure high-frequency vibration without the help of specialized tools, but this shouldn't stop you from performing two rudimentary checks. Try this: Attach your dial indicator to the table or other part of the mill frame, and let the tip touch any non-rotating part of the spindle. Run the spindle at several different speeds, and observe the reading; oscillation of the indicator hand, if any, should stay well under 1 µm. Remove the tool, grab a long screwdriver, and carefully touch any non-rotating part of the spindle with its tip. Be vigilant, and keep your body and the screwdriver itself well clear of any moving parts. When the tool is touching the spindle, you shouldn't be able to hear any ringing noise, or sense any appreciable vibration in the palm of your hand. If any of these tests reveals excessive vibration, the first thing to do is disenage the motor from the spindle (there's usually a belt or some sort of a clutch involved); if the problem doesn't go away, you know that the problem is with the motor itself, in which case, it may be useful to have it serviced or replaced. If the spindle is to blame, replacing the internal bearings would be the obvious next step. Whatever the cause is, fixes shouldn't be too expensive, but pinpointing the issue may take a while. 2.3.4. Repeat accuracy Repeat accuracy is the single most important factor limiting the precision of the parts you can make. Even if you are not planning to machine anything particularly intricate, this parameter is still worth checking: if it's alarmingly poor, it may be indicative of a problem with the mill. To estimate the accuracy of the machine, brace the tip of the dial indicator against the side of the spindle assembly, and then programmatically move the spindle away in the X axis, in 0.01 mm increments (or whatever the nearest multiple of your mill's mechanical resolution is supposed to be). After about 5-10 steps or so, reverse the direction, and gradually move back to the starting point. Here's what to look for: Every step should move the needle of the dial indicator by the same amount, ideally within 1 µm, and definitely within 0.01 mm. Jerky stepping may be due the increments not being a multiple of the actual hardware resolution of the mill, or due to wiring problems in the stepper motor. The actual travel distance, as measured by the dial indicator, should match the expected distance closely. If there's any substantial error that seem to be proportional to how far you are moving, your CNC software should let you compensate. The locations of the steps when moving away from the dial indicator should be the same as when moving back; and the spindle should return to the same starting position at the end of the test. Any observable offset is probably due to backlash - which should be in the micron range. There may be some limited ability to compensate for this in software (for example, your CNC application may offer low-level motor calibration settings), but it's not a silver bullet. Of course, try to repeat this procedure for all axes. If in any of them, repeat accuracy is worse than 0.01 mm, it may be good to talk to the manufacturer. 2.3.5. Deflection under load We're almost done! The last parameter of note is the loss of accuracy you can expect if the mill is braking or accelerating rapidly, or aggressively plowing through a difficult workpiece. The value depends on the rigidity of mill frame, and the type and quality of its linear motion systems. If it's poor, there is no reason to despair - but it means that you may have to slow down when doing precision work. The test here is extremely simple: with the mill on but the spindle turned off, brace the dial indicator against the side of the cutting head, and then use your hand to gently press the spindle from the other side - along the tested axis. Don't overdo it: the goal is to exert may be 20-50 g of force, and not to overcome the holding torque of the motors. In a quality mill, the momentary deflection should stay under 5 µm or so - but up to 0.02 mm is something you can live with. 2.4. Ongoing maintenance Once you know that your machine is behaving correctly, there isn't that much that needs to be done on an ongoing basis: it's a pretty sturdy piece of machinery, and it's usually not subject to heavy wear. Consult the manual for manufacturer-specific advice - but in most cases, the rules are pretty simple: Always keep the collets, cutters, and the spindle taper squeaky clean and lightly lubricated. Get rid of any thick, factory-applied grease (use WD-40 or naphtha to do that); carefully remove all cutting residues (use a small brass brush for any stubborn bits); and apply WD-40 or a similar low-viscosity oil to protect all these components against corrossion - especially after handling them with bare hands. Sweat residue can quickly lead to corrosion! Thoroughly vacuum the mill after every job. Cuttings, if allowed to pile on, may eventually make their way into the sensitive, normally shielded parts of the drivetrain - or more prosaically, may simply obstruct the movement of the table. Do not use compressed air for cleaning, as this can push dirt deeper into the machine, or just spread it around your workshop unnecessarily. Every few hundred hours of machining (1-2 years' worth of weekend projects), wipe old grease and dirt off of ball screws and linear guides, and apply a fresh coat. Medium-viscosity lithium grease is typically the right choice - but check the manual carefully, and whatever you do, avoid mixing lubricants of different kinds. After several thousand hours of use (5+ years), it may be time to inspect the spindle assembly for any obvious wear, loss of concentricity, noise, vibration, or elevated operating temperature - and service it as necessary. If you do it yourself, the replacement of spindle bearings should cost between $40 and $300, depending on the design. Some of the entry-level mills may be using low-cost brushed motors to power the spindle; such motors are a consumable, and may require a replacement after anywhere from 100 to 2,000 hours - but typically don't cost much. Higher end machines usually rely on brushless motors that should last a decade or more. Linear drivetrain motors, bearings, and so on are typically not subject to substantial wear when doing lightweight hobbyist work; if properly maintained, they should last pretty much forever. Insufficient lubrication or contamination with abrasive materials (ferrous metals, glass, etc) are about the only things to watch out for. 2.5. Cutter management If you are planning to do high-precision work, or simply wish to ensure high-quality surface finish when working with organic shapes, it's useful to measure and document the diameter of every new end mill in your collection. Although the tools are usually manufactured with micron-level accuracy, the specifications can sometimes be wrong, and on top of that, manufacturing variations may occur from batch to batch - for example, due to changes in the thickness of applied coatings or the gradual wear of the grinding tool. Case in point: some of my Harvey's 0.04 inch cutters actually measure around 1.022 mm, rather than the expected 1.016 mm. At these scales, such differences can bite. To perform the measurements, you will need an accurate micrometer. This tool, along with quality calipers, is one of the most important investments you will make, so don't fret: $50 will get you a decent no-name brand, while $140 is enough for Mitutoyo. For two- or four-flute tools, the idea is to gently tighten the jaws of the micrometer around the flutes, while simultaneously rotating the cutter (in the direction opposite to its normal operation) to find the maximum diameter. You need to stop as soon as you feel any resistance, to avoid breaking the tool or gouging the jaws; practice on larger, sturdy end mills before moving on to sub-mm ones. Three-flute tools are a bit harder to deal with. If the flutes are long enough, you may be able to grip the cutter so that one face of the micrometer is touching the peak points of two flutes, and the opposite face is touching the remaining one. That said, with stub-length tools, you may be essentially out of luck; doing a careful test cut and measuring the result may be the way to go (you need to account for TIR and repeat accuracy). Beyond the initial measurements, it is also a good habit to re-check your tools after every 10 hours of cutting or so, preferably measuring the diameter near the very tip. When doing heavy cutting, you may see some reduction in tool diameter as the outer edge of the flutes gets a bit more dull; for this reason, I suggest keeping your primary roughing tool separate from the finishing ones. Tip: even when working with plastics, applying several drops of a cutting fluid to the workpiece can improve finish and limit tool wear by keeping the tool cool and helping remove chips more efficiently - give it a try! For lightweight work, sulfur-free oils, such as Oatey 30200, work best. They are also easy to clean up with a detergent and don't interfere with resin casting work. Cutting fluids or no fluids, it makes sense to examine your tools for damage and excess wear every now and then. You can't trust your naked eye, but a simple 7x magnifier, selling for under $50, should do the trick. If you have a microscope with magnification between 10x and 50x, that's even better. Here are the two most common cutter failure modes that aren't visible with naked eye - significant wear (left) and a chipped flute (right): Both of these tools will still work, but the one on the left will not hold tight dimensional tolerances in particularly demanding applications; while the one on the right will produce crummy finish in machined parts and will be prone to gumming up. Tip: good bookkeeping is incredibly important in CNC work: computer-aided design and creative chaos simply don't mix. Cultivate good habits starting with end mills: make sure that you have a spreadsheet (or even a flat text file) listing all the tools you have, outlining their geometry, and making note of the measurements you have taken. Having such a list will not only help you avoid surprises, but will also make it easier to maintain a healthy stock of tools - so that you never have to put a project on hold for two weeks after accidentally breaking your last 0.4 mm end mill. 3. Mastering CAD and CAM By now, you should have a good idea of which mill to choose, where to find the cutters, and how it all fits together... or perhaps you own a 3D printer, and didn't read the previous chapter at all. Either way, the next step is getting comfortable with the software needed to bring your ideas to life. In this section, we'll go over some of the basics, and then proceed with a simple starter project of our own. 3.1. Computer-aided design (CAD) The primary function of CAD software is, quite simply, to let you design 3D parts. Your CAD application may be just about any general-purpose modeling program, such as Blender - but in the long haul, it makes sense to settle for a purpose-built tool. \"Real\" mechanical design software offers better control over part accuracy, and comes with powerful data input and analysis tools that streamline engineering work. On the flip side, they usually have less impressive rendering capabilities - and may come with no support for animation, physics, and other perks taken for granted in general-purpose 3D apps. For now, though, the distinction between general-purpose modeling tools and CAD isn't that important. You simply need to get comfortable with any 3D design software of your choice - and that takes a bit of work. 3.1.1. Wait, but which application to choose? A-ha, that's a good question indeed! In the previous edition of this guide, I tried to give an impartial overview of the market - but in the end, there is plenty of choice, and very few genuinely bad CAD tools. You can just look around, find the one you like and can afford. If you just want a simple recommendation - and are willing to spend some money on software to begin with - Rhino 3D is probably the best CAD package that you can get on a hobbyist budget. Students can purchase a fully-featured edu license for under $140, so if you are still in the academia, it would be foolish not to go for it. For mere mortals, there is a heftier price tag attached - $750 - so it's a more difficult call. Still, it's a mature and user-friendly tool that runs well even on low-end systems, and it's just done well - so you probably won't regret it. Now, if Rhino is priced outside your league, many people in the community are also fond of Alibre Design PE, which sells for about $100. Or, if you prefer not to spend any money at all, and can live with a somewhat clunky app, then FreeCAD looks fairly OK for simpler work. What else? Several accomplished DIYers use general-purpose 3D modeling tools such as Sketchup or Blender. The free-of-charge general-purpose tools are pretty diverse and mature; the only problem is that they may be less suited for complex work later on. If you are willing to cross that bridge when you come to it, they are definitely worth a try as a starter option. Last but not least, cash-strapped DIYers may also want to check out one of the \"demo\" editions of commercial CAD tools. For example, Creo Elements has a modest limit of 60 parts per document, but otherwise, should do the trick. 3.1.2. Some existential CAD advice We should probably start the lesson with a gentle warning: CAD programs tend to have a fairly steep learning curve. This is in part because you are forced to manipulate 3D objects using a 2D input device and a 2D display - and it takes a while to master that skill. The other problem is that these applications tend to use unfamiliar UI paradigms and obscure terminology - and even something as simple as right-clicking an object may have an unexpected result. It takes some effort to start using the software in a competent way - and if you're just banking on your innate abilities, you will probably learn to do things exactly the wrong way. If you want to make real progress, here are some rules to live by: Read the manual and do the tutorials. Trust me, you are not too good for this - even if you never had to do that with any other software. Set aside 2-3 days to go through all the exercises, and read the help pages. You need to understand what the program has to offer and what terminology it uses; even if you have some experience with 3D modeling software, you will learn a lot. Give your mouse a break. Try to do as much as possible without clicking around the UI. Learn command names and keyboard shortcuts, and make a habit of entering coordinates and dimensions manually. Find hotkeys for enabling, disabling, and changing grid and object snaps, changing drag modes, constraining movement, zooming and rotating viewports, and so on. This will save you plenty of time. Don't approximate. Never move objects around to make them just sort-of fit together. Learn to leverage object snaps, or use parametric operators to move, copy, rotate, or replicate objects with precision. If you don't, you will quickly start accummulating subtle geometry errors that will cause many 3D operations to unexpectedly fail later on (e.g., due to self-intersecting curves or imperceptible gaps). Don't believe in magic. CAD programs often come with advanced features to automatically calculate intersections or unions of 3D solids, place and remove holes, etc - but these functions aren't perfect, and tend to misbehave at least opportune times. Instead, learn to break down complex problems into simple steps, and operate on intuitive primitives (e.g., planar curves and surfaces) for as long as possible in the editing process. This also makes it easier to revise your designs later on. Before you start, there's just one more thing to do - you need to customize the program for precision work. Needless to say, the tolerances needed to design a building aren't the same as when designing a gearwheel - and CAD applications are used for both. For now, simply go through the configuration pages, and try to do the following: System units: set to millimeters. Or don't, but I find inches pretty unwieldy for precision work. Precision: set precision (or tolerance, or accuracy) to 0.5 µm (0.0005 mm) or so. Display mesh tolerance can be set to about 0.01 mm, simply to speed up rendering. Display grid: enable if necessary, and set major spacing to 5 mm, and minor spacing to 1 mm. Set grid size to match the work area of your machine. Snaps: disable object and angle snaps by default (you will be able to turn them on with a hotkey when necessary). Enable linear snaps and set distance to 0.5 mm. If the program supports it, turn on \"planar\" mode for snaps, where all the object snap points are projected to the construction plane of the current viewport. Viewports: switch to four-viewport display mode - showing top, front, and right sides of the model, plus a rotatable \"perspective\" (axonometric) view. Zoom in all viewports so that there are about 2-4 mm between the grid lines displayed on your screen. Shading mode: configure all viewports to use 3D shading, preferably with translucent surfaces (opacity around 80-90%; \"ghosted\" preset in Rhino), and with 1 pixel edge thickness. If possible, set a different edge color (e.g., red) for any \"naked\" edges that do not form a closed solid. Done? Then let's roll... 3.1.3. Drawing and manipulating simple planar shapes Your first job is to figure out how to draw several simple, two-dimensional shapes on the X-Y construction plane (i.e., using the \"top\" viewport of your CAD app). Try do to sketch all of the following: A single, straight line segment, A multi-segment zig-zag line (with sharp turns), A closed multi-segment line, where the end is joined with the beginning, A circle, using three methods: center point and diameter; two boundary points; and three boundary points, An arc - by selecting center point, diameter, and start / stop angles, A rectangle, using two methods: two corner points; or a center point and one corner, A polygon - circumscribed and inscribed, with a specified number of sides. Practice a bit; perhaps sketch a simplified, boxy outline of a car, complete with wheels. When you are comfortable with these 2D primitives, it's time for your next exercise: try to draw a smiley face without using your mouse at all. Type in the required commands and specify coordinates by hand; the display grid should be of great help. Oh - for some extra credit, add a hat! With your drawing in place, it's time to get familiar with several important operators. Figure out how to select one or more objects with your mouse, and then find the commands that perform the following tasks: Move selected objects by a specified distance in the current viewport, Duplicate (\"clone\") an object, likewise, Rotate object by a specified angle, around a selected point in the viewport, Flip (or \"mirror\") selected objects around a specified axis, Scale object proportionately in all directions, by a specified factor, Scale object in one direction only, Form an array of objects by cloning the selection at a given linear interval, Form a radial (polar) array by cloning the selection at an angular interval. Play around with these operators until you are comfortable with the way they work; pay special attention to scaling and rotation operators, and the way they are affected by the choice of the origin, reference point, and the viewport. As soon as you are done moving, flipping, and cloning stuff, locate and play with the analytic tools that let you do the following: Measure the distance between any two points, Measure the angle between two straight lines, Calculate the diameter (or radius) of a circle or an arc, Find the center point of a circle or an arc, Show maximum deviation between two similar curves, Compute the surface area of any closed curve. This is a good opportunity to experiment with object snaps, too: enable them temporarily, and check the various options they offer. In particular, be sure to give tangent snaps a try: draw three random circles, and then try to connect them with tangent lines, like this: Piece of cake? Thought so! You should be now ready to master several more complicated modeling skills. Note: Somewhat surprisingly, 2D drawing techniques are more important than any 3D sketching tools; in fact, you should resist the temptation to play with 3D primitives at this point. The bulk of mechanical modeling work is almost always done with spline curves, which are later converted into 3D objects with the help of operations such as extrusion, revolution, or lofting. We'll get to these operators soon. 3.1.4. The inner workings of splines Your CAD application probably stores every curve as a non-uniform rational B-spline. The visual representation of this mathematical model is not very easy to grasp, but getting a hang of it is essential to any sort of serious modeling work. In essence, every NURBS curve is defined by three parameters: Degree: this parameter defines how many control points will be simultaneously affecting the trajectory of the curve at any given location. Degree 1 curves allow just two points to have a say, with a linear transition between the starting and the destination point (i.e., a straight line). For degree 2 curves, the shape is influenced by three points, allowing it to have smooth bends. With degree 3, the number grows to four, and so on. Control points: every curve is accompanied by at least degree + 1 control points, to which it is progressively attracted to along its length. In degree 1 curves, control points simply lie on the curve (at the vertices). For degrees 2 and above, the points are often positioned outside the curve, forming a sort of an editable, elastic envelope, as shown below. Knots: these are the intervals along the length of the curve at which the influence of a previous control point ends, and the influence of a new one begins. Think of it as a way to pace the changes: densely packed knots can result in sharper turns. Note: it is possible to have multiple subsequent knots at the same location. If the number of knots in a cluster is equal to the degree of the curve, it's called a kink: it effectively forms a barrier that prevents control points on one side to have any influence over the other, and vice versa. This allows the curvature to change aburptly, forming a proper angle. Curves can be losslessly broken into separate segments at such a kink, too. An example of a degree 2 spline with no kinks is shown below; control points are marked in yellow, and knots are red: To practice a bit, try to locate the command that lets you draw a curve of a given degree by specifying subsequent control points. Get a hang of its behavior particularly for curve degrees 2 and 3. There should be also a separate command for creating interpolated curves that go through any number of specified \"via\" points that you click on, which may be useful for tracing around bitmaps and so forth. Oh, one more thing: using both of these tools, try to create a proper kink! When you are comfortable with drawing, experiment with the following curve-editing tools: Displaying and moving around control points for an existing curve, Adding and removing control points, inserting a kink, Non-uniform refitting, to simplify the curve or remove kinks while maintaining its approximate shape, Soft-editing a curve by dragging a selected point on its surface, Displaying curvature and continuity information - can you spot any exising kinks? Last but not least, be sure to familiarize yourself with the \"explode\" operator that splits curves at existing kinks (see what it does to a rectangle, circle, etc); and the \"join\" tool that merges adjacent curve endpoints to form a curve with kinks. 3.1.5. Curve trimming As should be apparent by now, NURBS curves can be separated and joined at kinks in a completely lossless manner: the underlying coefficients do not have to change, and there is no gradual reduction of accuracy if you repeat these operations 100 or 1,000 times. Unfortunately, in many cases, you will need to truncate curves at locations that do not correspond to any existing kink. In these situations, the CAD application will be usually forced to create a new curve with a different set of control points in the vicinity of the cut. This fitting process usually works very well, and the resulting deviation should be much smaller than your configured tolerance, but you should be aware that the operation does not come completely free. With that warning in mind, find the command that let you split a curve at a point where it intersects with another one, and experiment with it. For degrees higher than 1, you should be able to see the effect it has on the set of control points for the curve - and if you ask the program to calculate the deviation between the input and the output curve, it will probably give you a tiny but non-zero result. Examine the deviations for a couple of input curves to see what to expect in normal work. In addition to the curve splitting tool, there may be also a second operator that works roughly the same way, but lets you immediately delete (trim) the unwanted parts. It may sometimes save you a click, so if possible, get familiar with it. In any case, it's time for a brief exercise. Remember the command for drawing radial arrays? Try to combine that with splitting and trimming to arrive at a result such as this: Nice, eh? It's not quite a proper gearwheel, but we're pretty close. Note: as mentioned earlier, it is always preferable to use the simplest editing tools that still do the job. In particular, you should always favor the join, explode, refit, split, and trim operators over any features that, for example, automatically compute unions, differences, or intersections of 3D objects. Why? Well, these advanced tools quickly go bonkers if you have something as simple as two closely touching, parallel walls - not to mention accidental self-intersections, non-watertight curves or solids, etc. It's one thing if they just fail in an obvious way... but if the resulting error is subtle and goes unnoticed, you may end up having to redo a good chunk of your work later on. 3.1.6. Other curve tools We're almost done with curves - hooray! But before we go, there are three other, immensely useful editing tools that you should probably learn about: The fillet operator is applied to any angle (kink) on a curve, and replaces it with a specified radius. The trick is often used for engineering purposes: fillets serve as a stress relief in sharp corners and drastically improve their strength. But even more interestingly, filleting lets you capture the real-world result of machining a corner with an end mill of a given size - which is important for certain types of snap fits. This illustation shows the use of filleting to determine the actual shape of a machined part: Note: Of course, it's not that you can't make a competent acute angle with a CNC mill. For example, refinishing the one on the left with a 0.4 mm cutter would result in a deviation of barely 0.3 mm. Still, in many cases, it's more convenient to account for such intrinsic fillets in your designs, than it is to refinish the workpiece with a separate tool. Oh, one more thing: in situations where you don't control the shape of the mating part (lighter blue in the picture below), you can always resort to bone fillets, too: Chamfering is a similar operation, but it replaces the selected kink with a straight segment that starts at a specified distance from the vertex. Compared to fillets, chamfering may have a more desirable appearance, depending on the effect you are aiming for - and produces a much simpler 3D mesh. The last operator, offsetting, offers an interesting way to resize any shape: it creates a derived curve that consists of points at a particular, constant distance from the original geometry. It is quite different from traditional scaling, in the same way that gaining weight is different from growing bigger - and it comes quite handy for generating walls, undersizing or oversizing parts, and so forth. Well, that's really it! You may also want to explore tools that let you extend or close curves, or blend them with more fine-grained controls - but for most intents and purposes, we are ready to talk about something a bit cooler than that. 3.1.7. Creating simple surfaces Let's start building three-dimensional solids. It's simple: draw a closed curve, and then find the command that creates a planar surface from it. Examine the result, then check out what happens if you select two curves, one within another. What about separate or intersecting input curves? Examine failure modes of this operator, too: what if one of the input curves is at a slightly different Z level? What if the curve is open or self-intersects? Of course, the planar surface that you have just created is still, well, pretty flat. The next important operator to play with is extrusion: select your curve, and using the side view, select the extrusion height. Disable the creation of top and bottom \"caps\": we just need the side walls. Try to use the join operator to merge the flat base surface with the extruded wall. If it worked, you have pretty much mastered 3D work. Lets try a slightly more complicated exercise: That's pretty easy, eh? In fact, it's a lot simpler to construct shapes this way than it is to start with 3D primitives, and clumsily piece them together. But don't let it go to your head. Spend a few more minutes playing with extrusion: see what it does to open or self-intersecting curves, to multiple curves that overlap or aren't at the same Z level, and so on. You should also take this opportunity to experiment with the explode, split, and trim operators that you remember from your curve editing days. Draw two solids and make them overlap, then see if you can use the trim operator to remove all the overlapping internal sections, and join the resulting outer shells into a new, closed shape. Can you do the same to \"subtract\" one solid from another, or only keep the intersection? Find the analytic tool that lets you calculate the volume of each of the solids, and use it to double-check that your results check out. Oh, one more thing: can you trim surfaces with curves? Why not give it a try! These tools aside, there are several other advanced surface editing operators that you should be aware of; they are particularly important if you want to create organic shapes without having to think too much: Curve revolution: this operator lets you draw a surface by taking any curve, and rotating it around a specified axis, and letting it leave a trail in the 3D space. This is the method of choice for creating many simple shapes with axial symmetry - bottles, vases, cans, chess pieces, rings. In fact, try to create each one of these. Lofting: this mechanism lets you \"drape\" a surface through a series of curve outlines arranged in the 3D space. Think of it as the opposite of slicing. It comes handy in a variety of situations, including creating draft angles for molds, or adding a handle to a cup. Play with it a bit - it's fun: Sweeping: this tool lets you select a curve and drag it along a specified rail, generating a surface in the process. It can be seen as a generalized form of curve revolution (in which the rail is always circular). A more advanced version of this operator lets you use multiple rails, which allow variable scaling of the profile curve; or multiple profiles, thus also generalizing the loft operator. Blending, filleting, chamfering: equivalents of the curve editing tools that let you smoothen the edges of your solids. Blending is particularly useful for creating a smooth, variable-curvature joint: The list of useful operators goes on - for example, it's sometimes useful to extract edges from surfaces or solids, to place or remove holes, or to orient something on an oddly-shaped surface - but you can discover these on your own. For now, let's just have a quick look at how to manage your work. 3.1.8. Working with multiple objects It's one thing to sketch a nice 3D box - but any medium-scale project may easily consist of several hundred of such solids, often meshing closely and stacked in creative ways. If you don't manage your virtual workspace well, you will get overwhelmed, make mistakes, or both. The document management tools at your disposal will vary from one program to another, but you should familiarize yourself with at least the following: Grouping. This function lets you combine any number of objects into a single logical component that can be moved around and copied as a whole. Unlike trimming and joining, this operator does not require the objects to form a single solid - in fact, you can group completely disjoint things, such as curves, dimensions, and even light sources for the rendered scene. When necessary, the group can be opened, and its contents can be edited separately. This tool is very useful for conveniently creating serviceable parts from simpler, reusable solids. Note: some programs go beyond simple grouping, and let you instantiate objects loaded from a separate document. These instances are automatically updated to reflect any changes to the \"master\" document. I find this to be an overkill in my work, but your mileage may vary. Assigning to layers. Layers offer a simple way to centrally manage certain properties of objects, such as visibility or color, without merging them into a single blob. All objects or groups that comprise a named layer can be still accessed individually - although you can also select all members of a layer if so desired. You should use layers to keep track of all instances of any given part, or to denote other important information - for example, that a particular object represents a premade part not meant to be machined, or that it's only a visual aid. Locking and hiding. Objects or layers that get in the way of editing may be locked. This keeps them at least somewhat visible, but prevents any interaction: you can't accidentally select them or move them around. Hiding is a more radical alternative: it completely removes the affected items from view. Locking and hiding is typically best applied to layers, as it usually takes just a single click to toggle this parameter in the layer manager. For individual objects, hiding is useful predominantly for items that you are not planning to access again: for example, any construction curves that were already used to create all the solids you needed, but that are worth keeping around just in case you need to redo something later on. To get them back, you will need to activate a special mode that hides all the visible objects, shows all the hidden ones, and lets you select the ones you want to bring back to life. As soon as you are reasonably comfortable with object management, we can actually make a simple mold! 3.1.9. Practice time: let's show some love! Okay, it's time for some fun. Let's start by trying to draw a heart: Here's what's going on in that illustration: We draw a helper rectangle as a guide for the overall size of the part. This one is 23 mm wide and 20 mm tall. We then use object snaps to draw a vertical line through the middle of the part, which will be our axis of symmetry. Once the guides are sketched out, we add a 13 mm circle (slightly larger than half the rectangle), and align it with the edges of the box. You can use grid snaps for that. We draw an arc using object snaps. The beginning of the arc is tangent to the existing circle, the end is at the bottom of the center guide, and the diameter is manually entered as about 110 mm. We mirror the circle and the arc around the axis of symmetry. At this point, the symmetry guide is no longer necessary, so we delete it. We use the trim operator to remove the internal parts of the heart, and then delete the outer rectangle. Voila! Easy, right? Now, let's join all the curve segments, and turn the whole thing into a mold: See if you can figure out all the steps on your own. The final result should be a watertight box with dimensions around 33 x 30 x 8 cm. Its bottom left corner should be at coordinates (0, 0), and the top surface should be at 0 mm, likewise. The mold cavity should have a 4 mm clearance around the heart, and should be 7 mm deep. The heart itself should be resting at the bottom of the cavity, and should be 4 mm high (its top surface should be at -3 mm). If everything checks out - well, the good news is that you have yourself a master mold (aka a pattern). Now, we cut some corners with the moldmaking process, given the simplicity of this project, but this is how the entire thing usually plays out: Be sure to save that project - we'll need this file soon. 3.2. Computer-aided manufacturing (CAM) CAM software reads the geometry created with your favorite modeling application, and turns it into toolpaths that can be sent to a milling machine, a 3D printer, or some other automated tool. All the computer-controlled manufacturing technologies use a common set of underlying concepts and have a comparable degree of complexity, but there are many details that remain specific to a particular tool. Since we have to choose one way or the other, the rest of this chapter will focus on the software designed for CNC mills. 3.2.1. Shopping for the right application When I first published the original version of this guide, the makers of CAM applications catered almost exclusively to commercial users. The software was ridiculously overpriced, shipped with archaic UIs, and always included a collection of mind-boggling bugs. Thankfully, the emergence of low-cost mills and serious hobbyists is slowly changing that. Still, there is no single package that would be a sure bet for all users, and you need to understand what sets them apart. Here's a quick list of the things that matter the most for everyday CNC work. 3.2.1.1. Support for fourth axis If you own a computer-controlled rotary axis, or plan on getting one, you should figure out which 4-axis machining modes are supported by the program - and decide if they are worth the extra price. The three fundamental choices are: Indexed cutting (XYZ): in this mode, every milling job is handled using traditional, planar three-axis movements. The only new trick is that the program will automatically rotate the workpiece (and the CAD model itself) in between jobs, letting you machine the part from multiple sides with no extra leg work. This rudimentary approach is probably the most useful one, particularly for engineering work. It works great on geometries that have a small number of distinct, planar faces - for example, a two-sided PCB, a nut, or a rectangular enclosure. Interestingly, indexed cutting is actually fairly easy to simulate by creating several CAD files with the same part rotated by the desired degree, generating toolpaths for each of these files, and then sending them to the mill and rotating the part in between. It takes a bit more time, and there's a higher risk of human error - but it's up to you to decide if the extra convenience is worth spending several hundred bucks extra on your CAM tool. Lathe-type machining (AXZ): in this mode, the Y axis is kept in a fixed position, so that the tool hovers directly over the axis of rotation, or stays at a predefined offset. The workpiece is turning continuously as the milling head is moving up, down, and to the sides. If you haven't seen a lathe in action, this video should clarify what's going on. Such an approach allows efficient reproduction of smooth, cylindrical shapes that would require indexed cuts from 6 or more sides to approximate the shape by traditional means. Examples may include threaded shafts, worm gears, soda bottles, or rings. Unlike the previous mode, this one can't be trivially approximated in a program that doesn't support it natively; but it's also not nearly as essential, not unless you're planning to work on jewelry or other artistic stuff. Fully simultaneous four axis machining (AXYZ): in this mode, the machine is free to move in all four axes while cutting, and the application analyzes the geometry to find the right balance between lathe-like and planar movements. This may result in more efficient machining of complex surfaces with variable curvature or hard-to-reach undercuts - but it's seldom of any use to begin with, and it can be approximated by alternating between the two techniques mentioned earlier; the extra cost is difficult to justify in hobbyist work. What to buy: your call. If indexed cutting is all you need, you may be able to live with lower-cost three-axis CAM. 3.2.1.2. 3D milling strategies Vendors of CAM software tend to be pretty creative about the range of specialized and obscure machining modes that they offer, but there are only three options that really matter; the rest is either redundant, or doesn't work well in complex molds. Here are the three methods in question; the first two really must be supported by the application you want to go with: Overhead projection: this method amounts to projecting a simple surface-filling pattern onto the workpiece, from the top. In the most basic case, the pattern may be just a bunch of evenly spaced parallel lines, connected together on alternating ends. The tool then follows these lines in the X-Y plane (X-A for lathe-style machining), and is lowered or raised as necessary to reproduce the shape of the part: Such a computationally inexpensive approach is particularly efficient when machining flat regions or very gentle slopes with a flat tip cutter; in this case, the spacing between projected lines (stepover) may be comparable to the diameter of the tool, and still produce excellent surface finish. Alas, the strategy is a bit less suitable as soon as the cutter gets near any vertical surfaces. If the wall is in a direction perpendicular to the toolpath, the process will leave scallops of uncut material, as shown above; the height of the scallop is equal to cutter_radius - sqrt(4 * cutter_radius² - stepover²) / 2. Walls that happen to be parallel to the direction of the cut will acquire a better finish, but the process may leave a layer of uncut material, up to stepover thick. Walls at other angles will get a combination of both artifacts. Note: both of these issues can be remedied to some extent without switching to a more advanced machining strategy. Scallop height can be managed with modest changes to stepover - for example, when using a 3 mm tool, changing stepover from 2 mm to 0.5 mm reduces scallop from 0.38 mm to 0.02 mm - that's a 20-fold improvement at the expense of slowing down by a factor of four. The other problem - with the accuracy of parallel walls - can be fixed by doing a second pass using lines projected at a different angle, so that the cut is no longer parallel in the previously affected area. Of course, the situation gets a lot trickier if you have walls at many different angles, or worse yet, any arcs. Good CAM software be able to not only generate linear projections, but also \"offset\" patterns that are constructed from an arbitrary outline provided by the user. This has some important benefits that we'll talk about soon; the end result looks kind of like this: Z axis slicing: also known as waterline cutting, this machining strategy starts by creating a stack of horizontal surfaces, evenly spaced in the Z axis. Each of these surfaces intersects the CAD model, and every such intersection results in a number of closed, two-dimensional outlines of the part. These outlines can be then offset for the size of the tool, checked for collisions, connected together, and used as a toolpath: This mode allows for faithful and highly efficient reproduction of intricate vertical features, such as spur gears. On the flip side, it does not do anything useful for horizontal surfaces; and produces staircase patterns on sloped surfaces, unless the spacing of Z levels is unreasonably tight - as seen above. On top of the basic mode with a constant Z step, some of the more expensive CAM programs allow you to automatically detect and optimize the spacing of Z levels based on the geometry of the part. That sounds nice in principle, but I could never get this feature to work in a sensible and consistent way in any of the programs I have tried. 3D draping: this method generates a toolpath that always maintains a particular distance between cuts, or keeps a particular scallop size, regardless of the shape of the machined part; this is somewhat akin to printing linear toolpaths on a piece of fabric, and then laying it over the geometry to be reproduced. This strategy can be a significant time saver when working with organic shapes using ball tip tools, but it is not commonly useful in everyday mechanical work. What to buy: the two first strategies must be supported unconditionally, and should come with no strings attached: you should have full control over how they are used and when. The third one is a plus. Advanced features of these modes, and other toolpath generation methods, matter a lot less. 3.2.1.3. Region selection capabilities Efficient machining of complex models requires the ability to decide which tool and which strategy will be applied to various regions of the model - and in what order. To facilitate this process, your CAM application should let you define a freeform region for every machining operation, either by selecting an existing boundary curve imported alongside with the 3D model - or by drawing something by hand. It should let you exclude regions within an existing selection by picking a second curve inside the first one, too. These capabilities are pretty much all that matters. You may notice that certain programs have the ability to automatically generate selections based on some property of the model - for example, to only machine flat surfaces, vertical walls, or something in between. These features are sometimes nice, but are usually more limited or less reliable than what you can do in CAD - so don't pay any special attention to this. What else? Oh - several programs offer \"residual machining\" of regions left over after the previous operation with a larger tool. This sounds great in theory, but is typically both fairly coarse and extremely slow; I tried two applications that supported this feature, and it misbehaved or ran out of memory more often than it proved to be useful. What to buy: curve-based selection is a must. Pay little or no attention to the rest. 3.2.1.4. Cut optimization Some CAM applications do not put any special thought into organizing the toolpath segments that are spewed out by the underlying geometry-analyzing algorithm. Depending on your model, the result of that can be pretty inefficient; for example, a waterline cut that sequentially machines every outline on every layer before moving further down will produce a total of 15 operations when machining these two separate holes (left): The image on the right shows a more sensible ordering: instead of going back and forth between the machined regions, finish one first, and then move to the other. The result is 9 operations, consisting mostly of short movements. Quite a few programs are capable of such common-sense optimizations - but not all. What to buy: it is useful to shop for CAM applications that offer cut optimization, especially for waterline machining. It's not an essential feature, but it's a major time saver. If in doubt, consult the manuals or ask the vendor before buying. 3.2.1.5. Arc interpolation G-code - the language supported by most of the CNC machines on the market - has several commands that can be used to execute circular, spiral, or helical movements of the tool. While support for these opcodes is not required, quite a few e",
    "commentLink": "https://news.ycombinator.com/item?id=41989322",
    "commentBody": "Hobby CAD, CNC machining, and resin casting (2015) (coredump.cx)163 points by hughgrunt 22 hours agohidepastfavorite91 comments jwr 5 hours agoI followed that guide (it is excellent, if a little outdated) to get really good results. I should really write up and share my experiences, there is so much to learn. In brief: * It's an excellent method of producing very precise parts with fantastic mechanical properties (the next step up is aluminum, but you don't need it in most cases). * It is much more difficult than just throwing something at a 3d printer. * It is not comparable with 3d printing at all. I use both methods: FDM printing for most stuff, resin casting for parts that need to be strong, dimensionally precise, or nice. * Yes, you can use your resin printer to produce originals or master molds, but you will have two problems: 1) precision, 2) silicone cure inhibition. * Tips for those in the EU: Sika Biresin F50 is fantastic, Rencast 5146 is slightly worse (higher viscosity), but works very well, too. Both are relatively easily available. For silicones, BLUESIL RTV 3450 is unbeatable. * For desktop CNC machines, there are good options now: Makera Carvera (either the full model or the \"Air\" scaled down version) are really nice and precise machines. Software is crappy, but hopefully will get better. I had a Nomad 3, but switched to Carvera. * Don't buy a cheap CNC. There is simply no way to produce a desktop CNC with good precision for less than, say USD $2000. You will be disappointed. Perhaps if one day a Bambu Lab arrives with experienced engineers and a lot of money, they could mass-produce something cheaper, but right now this is roughly the cutoff. * Autodesk Fusion, much as I hate it and the company behind it, is pretty much the only game in town if you want integrated CAD+CAM. Again, I hate the software with a passion, but there is simply nothing else that is as well integrated, works well, and is reasonably priced. * Achievable precision: ±20μm is doable with a little care, things get difficult below that. This is roughly 10x better than what you can get from FDM 3d printing. Note also that this is the limit of what most people can measure: your calipers have an error of ±20μm if they are good. I also noticed that the 3d-printing crowd often has no idea what precision means, so you'll see crazy numbers thrown around. * Mechanical properties of produced parts are way better than what you can get from FDM printing. I laugh at those \"strong filament with carbon fiber\" youtube videos. reply dylan604 5 hours agoparent> It is not comparable with 3d printing at all. Not just not comparable, but totally opposite. Subtractive vs Additive. CNC is like chiseling the David out of single block of stone by removing bits. 3d printing is starting with nothing and adding material. reply WillAdams 19 hours agoprevPrevious discussions: https://news.ycombinator.com/item?id=41467268 https://news.ycombinator.com/item?id=27645605 This was a resource which was mentioned on the Shapeoko wiki --- while it's off-line, it's still on the Wayback Machine: https://web.archive.org/web/20211127090321/https://wiki.shap... Since then, some of those pages have been made available on Reddit: https://old.reddit.com/r/hobbycnc/wiki/index https://old.reddit.com/r/shapeoko/wiki (ob. discl., I work for Carbide 3D) And there have been a number of other developments - FreeCAD has hugely improved since that was written. - Solvespace as greatly improved, adding some basic CAM functionality - Blender has had the Solvespace sketcher ported to it as https://www.cadsketcher.com/ and BlenderCAM has gotten quite a bit more workable - Dune3D was created and is remarkably capable: https://dune3d.org/ Also a fair number of forums discussing CNC were gathered at: https://forum.makerforums.info/ reply Animats 15 hours agoparentRight. This article is (2015). 3D printing with PLA has improved in the intervening decade. You can usually get a good print on good modern printers. The first generation of those things had poor extruders, and filament formulation has reportedly improved. There's complicated heat transfer going on in those things. You're welding a hot thing to a cold thing, which is inherently troublesome. I'm told that works better now. Machining resin molds is straightforward, because you start with a block of something and machine only its top. So there's no work-holding problem. Trying to figure out how to clamp something that needs to be machined on several sides is usually hard. Not sure what's going on in tiny mills today. I've used Tormachs, the whole range of Shopbots, and some strange one-off machines that TechShop somehow obtained. (Never did use the beautiful little Pocket 5-axis machine. TheShop had one just before they went bankrupt.) reply aidenn0 17 hours agoparentprevThese also had discussions: https://news.ycombinator.com/item?id=4679939 https://news.ycombinator.com/item?id=34339459 reply cellular 15 hours agoparentprev\"GatorCAM for CNC\" Instructions to download: https://youtu.be/hqyPzCKGUQc?si=VJ0KRhQOl_-d7Bmm Download here: https://sites.google.com/view/gatorcam/home Very user friendly. Tab support, v-bit, ATC, sorts toolpaths for faster carving. reply hnisoss 17 hours agoparentprevawesome dump, thanks for sharing. solvespace is cool but until they iron out the chamfer/fillet situation and parametric input I ll have to continue using freecad.. reply WillAdams 3 hours agorootparentIf you want something lighter than FreeCAD I'd recommend trying Dune3D --- it's amazingly easy/nice to use. reply syntaxing 17 hours agoprevFormer MechE for a decade and I owned personal CNC routers and on my 6th 3D printer. The biggest issue with CNC is the cost for consumables and accessories. Need a special bit? $$$ Need stock to cut? $$$ Want a nice ER11 or R2 collet set? $$$. A nice vise? $$$ Cut something wrong with a carbide bit? Shrapnel explosion. 3D printing has a bunch of limitations but is a way better machine for hobbyist. But I have been eyeing the Millennium Machines Milo. A very fair price point for a traditional style CNC. You can also decorate it however you want with your 3D printer. reply sottol 17 hours agoparentIt is definitely more expensive than 3d printing in terms of consumables but china/aliexpress has really good hobby-quality equipment now - if you don't mind the country of origin. Many of their coated end-mills are decent and Having a CNC Router table in a non-industrial zoned area will not work for most people. Lolwut? Throw it inside where the narcs can't see it (you'll want it inside or at least in an out building anyway). They're not loud. The venting you'll want isn't loud either. Source: I do this stuff in my house. reply Joel_Mckay 5 hours agorootparentAre you using a full sized \"router\" on steel plate, or a mini-engraver made from a hobby-motor on balsa? Even a compressor fed Plasma-cutter rig is usually far quieter by comparison, as cheap import engravers often just make a mess of the surfaces. Best of luck, =3 reply potato3732842 5 hours agorootparentMy router itself is a 2x2 with the Vevor 3hp spindle (not a repurposed handheld wood router). The router, regardless of material it's being used on, is quieter than just about any woodworking tool with a circular blade. When it's indoors nobody cares. I mostly use mine for making wood mockups of parts before I make them in steel. I have more traditional tools for steel fabrication. The router makes basically no noise compared to the \"loud\" ones of those. reply WillAdams 15 hours agorootparentprevI use mine in my (finished) basement, or if cutting tropical hardwoods out on my back deck (I have a machine on a wheeled cart). reply Joel_Mckay 15 hours agorootparentThe noise from having a router and vacuum dust-collection running all the time can become a problem in residential areas. Most would like a full-sized machine that could directly handle standard sheets of material, but the space is not the only limiting factor (i.e. the insurance provider could pull something nasty with your mortgage creditors etc.) Peoples situations will differ, and definitely check out reverse-spiral flute carbide-cutters if you handle a lot of sheet-work on a 2.5D setup =3 reply WillAdams 8 hours agorootparentWhile everyone wants a machine for full-sheets of plywood, they're expensive, and not used for many projects --- a smaller machine suits most needs and there is always tiling. My machine is quieter than my neighbor's drum kit --- and I've run mine after 11PM and you can't hear it over traffic and the nearby speedway (on race night) outside in the yard (a quiet vacuum helps a lot), but I have gone over to their house at 11:01 PM to remind them of what time it is. reply dekhn 19 hours agoprevWith some concerted effort and money spent over several years I was able to more or less reproduce most of this document (but not nearly to the level of detail or variation on process). Eventually I was able to finely CNC engrave a wax block with extremely fine (0.1mm) features, make a mold, and then stamp out as many copies as I wanted. This guide was really helpful in understanding some of the core ideas. reply sottol 18 hours agoprevShameless plug if anyone is interested - I'm working on a $600-ish open-source, reasonably capable, but small and somewhat \"tidy\" hobby CNC machine with BOM cost around $600 that requires some DIYing. It's meant to be an alternative to the Desktop CNCs like Nomad, Carvera, Bantam, ... moreso than a PCNC or other proper entry-level CNC. The ultimate goal is to make it hobbyist-friendly, capable of easily cutting alumin(i)um and not taking up a lot space, not being messy or loud enough to require a dedicated workshop. Unfortunately, cutting metal is inherently loud so you probably would not be able to run it in an apartment as I'd hoped. I've made a couple decisions around being friendly for people coming from the 3DP space around probing, using roborock CPAP as chipvac, running it mostly dry, fully enclosed. I'm also starting to work on computer-vision-based probing and the idea is to later enable a host of more user-friendly and safety-focused features and maybe integration with Kiri:Moto's CNC mode for \"guided\" CAM and so on - basically a beginner-friendly CNC that guides newbies using an integrated web-interface. More info on Github: https://github.com/thingsapart/mini_nc GH is a little outdated but I've been using the little machine to cut alu for a while (mostly parts for itself) and it's working quite well. There's more videos and such on the Discord linked in the GH readme - feel free to ask questions on the Discord, I try to respond as quickly as I can. The full model with all its components is completely open in Onshape (I know it's not ideal but how I learned CAD - link also on GH). reply Animats 14 hours agoparentFully enclosed with a chip vac is good. Chips all over the place is no fun. Especially with coolant. Don't expect people to precision-cut wood for the frame. The Liteplacer people tried that for their pick and place machine, and most people never got a working machine. If it needs plates with holes in them, make them in bulk and sell them. Waterjets are good for that. The holes will be where they are supposed to be. (The Liteplacer was a really good idea - a pick and place machine for assembling prototype PC boards. Camera controlled, with the input parts in partitioned trays rather than reels, it was slow but did the job precisely. The PixiePlacer seems to be the next generation of this. But, as with the Liteplacer, you can't just order the metal parts. You have to make them or have them made. There are commercial machines, of course, but they're for production, feed parts from reels, and are more expensive.) reply sottol 13 hours agorootparentGood point - there is a provision for laser-cut steel or alu plates that sit inside pockets inside the enclosure panels as I figured many would be turned off by a full plywood design. The metal parts are symmetric so you can cut 2x of each - that is way cheaper on send-cut-send (afair only 25% extra for 2nd part). reply Animats 11 hours agorootparent> plywood design. Coolant and plywood do not play well together. reply bluGill 2 hours agorootparentI like to think of wood CNC as a step in the kit to something better. If you do your operations rights errors can cancel each other out and so you get better results by having a few extra steps. Make the wood CNC, then use that to cut the molds to make a epoxy-granite frame, then transfer the electronics to the new frame. reply sottol 4 hours agorootparentprevThe bottom panel is hdpe currently and \"trayed\", but you wouldn't run this machine with flood coolant anyway. mql might work but the idea was to cut dry, suck away chips and rely on coated end mills. I've seen people experiment with diesel heater pumps for mql, might try that some time. coolant always ends up very messy. even mql lubricated chips can be a relative mess compared to dry cutting. reply Animats 15 minutes agorootparent> but the idea was to cut dry, suck away chips and rely on coated end mills. You can go through a lot of end mills cutting dry. This is less of an issue for hobbyists who aren't turning large volumes of metal into chips and aren't using high-powered milling machines. The main limit on milling speed is getting rid of the heat. If you're willing to run slow, dry cutting works. Or if you only cut materials softer than steel. At some point, you get Machinery's Handbook.[1] For most of a century, machinists' toolboxes had a built-in space for a copy of that book. Now it's available as an app. [1] https://books.industrialpress.com/machinery-handbook/ reply aaronblohowiak 14 hours agorootparentprevWhat about the lumen from opulo? reply Animats 13 hours agorootparentThat's neat, but it's meant to get its parts from feeders. It's a small-volume production machine. reply sottol 15 hours agoparentprevI uploaded a quick video of it cutting some alu recently if anyone's interested: https://youtube.com/shorts/XUsj06iMbb0 reply sgnelson 13 hours agorootparentAt first I was skeptical, but that's an impressive demo for such a small machine. The documentation on your github is a tad lacking however. :) But good luck on your machine, I like your CPAP fan idea. reply sottol 13 hours agorootparentDocumentation is definitely lacking - I just got the design to a point where I'm pretty happy with it. So far only 1 machine exists and the build has a few bits that are... less than ideal. The plan was to build a second machine and optimize some of the assembly, take notes and document the build. reply mdorazio 17 hours agoparentprevWhat's the advantage of this over a 3018 or 3030 machine? With some basic upgrades (you mentioned needing to diy anyway) you can easily cut aluminum on those for $500 or less. reply sottol 15 hours agorootparentI tried [1] - replaced the sides with 2040s, blind-jointed every extrusion, replaced X with MGN12H + 4 carriages, replaced the whole Z with 4080U and even bolted it into an MDF box to stiffen it up. The 3018 could cut alu, but not well. Maybe it was the 4080U but it just didn't work for me, it could cut alu but had lot of chatter. For $600-800 it is fully enclosed, includes a decent spindle, wifi-enabled +offline RRF-based controller with folding/rotating LCD screen, 2 power supplies (24V + 48V for the spindle), a chip vacuum and probably some more I forget. This machine was designed [3] specifically to cut alu rather well for < $1000, can run adaptive clearing toolpaths at 0.5mm optimal load and 3mm doc at 1800 mm/min with a 6mm end mill and produce decent chips. It can probably do more, my standard settings are 1200mm/min, 0.5 woc, 3mm doc. Mind you, this is all still hobby-level though you could still push the feeds and speeds a bunch I reckon. [1] https://youtube.com/shorts/C0ngUJrWrB4 [2] https://youtube.com/shorts/XUsj06iMbb0 reply bluGill 16 hours agorootparentprevNot made in china though since many parts come from china anyway... reply throwaway81523 15 hours agoparentprevThis would be a lot more interesting if it could cut steel and titanium. I guess that is more difficult. Added: a dumb question, if the main cutting device is a router with a spinning bit, how do you cut angles? One thing I'd like to make is a 4mm hexagonal hole in a piece of steel, to turn little hex drive screwdriver bits and the like. Is it even possible to make that with a mill, or do you need a different machine? reply Animats 14 hours agorootparentThat's usually done with something called a rotary broach.[1] This is a clever trick. You first make a round hole. The rotary broach is a hex-shaped cutting tool. Both workpiece and tool are clamped in a lathe. But the center of the tool is slightly offset from the rotational center of the workpiece. Both spin, but the eccentricity makes it cut a hexagonal hole. Here's the process.[1] A milling machine can cut a hexagonal hole, but the inside radius at each corner cannot be smaller than the radius of the cutter. A 4mm hex hole would require a tiny cutter to do a good job. Here's that process for a larger hole.[2] If the hole goes all the way through, just get a hexagonal punch. Might need to drill a round hole first. Or just buy a 4mm socket with a T-handle. Cost US$4.99.[3] [1] https://www.youtube.com/watch?v=_AYEFjbGaL4 [2] https://www.youtube.com/watch?v=zOqSIRuBgCY [3] https://www.amainhobbies.com/rc4wd-metric-hex-twrench-tool-4... reply throwaway81523 13 hours agorootparentThanks, yeah, a separate 4mm socket with a handle is certainly a possibility, but I liked the idea of a 4mm hex hole in something like this, to accompany the holes that are already there: https://knifeworks.com/crkt-9100kc-eatn-tool-black-oxide-fin... I'll look at the rotary broach video. Yes the hole would go all the way through, so a punch sounds ok. Anyway it's not about making this one hole. It's more an example of the kind of stuff I'd like to do with metalworking gear if I had access to it and knew how to use it. It does sound like hard materials are an obstacle as well. Aluminum is a start though. reply Animats 12 hours agorootparentAh. Here's the tool for that job - a Roper-Whitney hand punch.[1] This is like a hand paper punch, but stronger. Costs $85. Made in USA. With a punch and die, you get clean edges on the hole on the exit side. Scroll down for how to order the specific punch and die you need. Hex punches are not common, but are available. If you fill out their form, and tell them you need to punch 3CR13 stainless, they'll tell you what to order. Might need something with more leverage than the small hand punch. Lubrication helps. Most machine shops will have such a punch, but they won't have a 4mm hex die in stock. Or you could drill an undersized round hole and file it out to a hex hole. Maybe use the existing round carabiner hole. There are touch-up kits for guns, called \"gun bluing\", to make your shiny new hole black. This is all do-able but way more trouble than it is worth. [1] https://www.roperwhitney.com/our-products/no-5-jr-hand-punch... reply throwaway81523 11 hours agorootparentprevCool, thanks, yeah for a single hole, doing it by hand with a needle file sounds more practical. Does something like this seem CNC-able? https://sakparts.com/products/can-opener-diy-tool-part-for-8... The idea isn't to duplicate an existing can opener, but rather to make custom specialized tools to fit into a SAK, or replacement knife blades out of specialty knife steels (i.e. very hard, so probably difficult to machine). It wouldn't just be for SAK's but also for other folding knives, each with its own special cutting pattern to work with its pivot and locking system. Titanium is another material of interest, for ultralight gear. All of this is probably impractical at the hobbyist level with limited work space, though. Oh well. reply Animats 10 hours agorootparentDIY knife forging is common. Search \"knife forging\". Look around for classes and forges with training. There's a huge amount of info on knife making and metallurgy. People obsess on this stuff. A good knife is a trick of metallurgy. The blade must be hard at the edge to be sharp but ductile in the body so as not to be brittle. How to do this is well understood today, but there was much mystery around it for centuries. If you're fascinated by metalworking, but don't have to make machine parts, that's a hobby direction. Victorinox knife manufacture.[1] Stamp, heat treat, grind, polish. They're not exotic blades, just good manufactured stainless steel parts. A primer on machining titanium.[2] [1] https://www.popularmechanics.com/adventure/outdoor-gear/a351... [2] https://www.harveyperformance.com/in-the-loupe/titanium-mach... reply throwaway81523 10 hours agorootparentSure, knife forging is one thing, but the idea of making replacement blades for folding knives sounds like it takes machining, because of the weird shapes needed at the pivot end, especially for weird locking mechanisms. It would be nice to be able to do that at a semi-commercial level if one were to get into it at all. Victorinox is on a completely different scale, making millions of units of whatever. But forging is for making one or two of something, while CNC machining is interesting for making a few hundred. In practice I don't have it in me to pursue something like that for real. It's just interesting to find out about. If I simply wanted to make knives, then no machining would be needed, just some cutting discs and belt sanders. It's the specific thought of making replacement blades for existing folders that seems to want more automation. I guess there are existing shops that can do that type of thing from a CAD drawing though. reply WillAdams 6 hours agorootparentWe (ob. discl., I work for Carbide 3D) have a video series on doing this: https://www.youtube.com/watch?v=G5TYla5x-Nk reply bluGill 7 hours agorootparentprevKnifes are done with heat treating. you need to get the steel red hot and follow the proper cooling process. You machine soft iron to close then make it too hard to machine, finally grindit to the perfect size. reply aaronblohowiak 14 hours agorootparentprevSteel is sooooooooooooo much harder than al, it’s not even in the same ballpark. Aluminum is about as hard to cut as wood. For non round holes, you are looking at approximations or broaching. Look up manual hex broaching reply hnisoss 17 hours agoparentprevthat looks like a nice project, reminds me of the ghost gunner 3 machine. I like the safety note too. might hop into discord sometime next week. thanks for sharing! reply hnisoss 17 hours agoprevoh my! I found this exact page in ~2017. I m something of a tab hoarder and I had around 2k open tabs back then. I loved the page and content and wanted to get back to it, but you know how it goes. Somewhere in early 2018 my browser crashed and I lost the tab. I distinctively remembered losing that page and I tried to find it, over and over again. I actually had one of the pictures saved (blue-red-white wheel), so I opened it in new tab as placeholder until I find the page. 6 years later here we are!!! tnx hughgrunt xd reply ajot 4 hours agoparentYou may also like lcamtuf's current thingy, a substack https://lcamtuf.substack.com/ reply gaze 15 hours agoprevI read this when I was 25 and now I have a fanuc Robodrill in my garage. CNC is quite the bug reply mvidal01 5 hours agoprevI wish there was an update to these pages. Some of the products and urls are defunct. reply WillAdams 5 hours agoparentThe most likely successor would be: https://shapeokoenthusiasts.gitbook.io/shapeoko-cnc-a-to-z (ob. discl., I work for Carbide 3D) reply throwaway81523 15 hours agoprevI'm not too excited by the idea of making little plastic precision gearboxes for robots, so when PLA printing isn't good enough, I mostly want to machine metal. Not car parts or firearms but flashlight bodies, knife blades, small tools, that sort of thing. Nothing wrong with robotics but there are other interesting areas too. I think the article skips over that a little too easily. That said, it's a good article. reply WillAdams 5 hours agoparentFlashlight body would probably want a lathe, but one of the newer flat ones would be easy in two halves. For an example of a knife blade: https://www.youtube.com/watch?v=G5TYla5x-Nk small tool: https://community.carbide3d.com/t/nomad-made-custom-titanium... reply KaiserPro 5 hours agoprevI wish I had seen this when I was starting out, that would have made life a lot easier! reply eth0up 7 hours agoprevTo the machinist/s here: For nearly a year, I've been contacting local machinists for a small[*] project which involves 1) an accurate cut on both ends of a 17\" billet of T6061, 2) two crescent cuts, 3) up to 8 threaded holes, but probably, 4) a wee bit o end shaping. All the aesthetic contours, shaping and weight reduction I'd do manually - I hand machine bronze, aluminum and wood archer's thumb-rings, so can wangle that part. This project would result in the world's first ILF asiatic (no shelf), ambidextrous aluminum 17\" riser. Though... Every machinist I've spoken to is either friendly at first, implying willingness and ready capabilities, or they simply say no thanks. But all of them ultimately reject the task, typically saying they're too busy. I also have a design for a bow stringer that can handle longbows, recurves and short Asiatic bows safely and efficiently. No one will fabricate it around here. Any suggestions as to why this is such a pariah project? Any suggestions on how I might achieve this? * Not necessarily a good reason/excuse reply riiii 32 minutes agoparentDo you have a complete technical drawing? My guess form rejection is either: 1. No drawing and vague specs. 2. Too time consuming and they don't want to quote the crazy price it'd take. Machine shop time is very expensive. reply WillAdams 5 hours agoparentprevHave you looked at Shapeways or sendcutsend or xometry or 100k Garages? That said, I have an especial interest in archery and multiple machines. Contact me at: https://community.carbide3d.com/u/willadams and we can at least work out doing a couple of prototypes. reply potato3732842 6 hours agoparentprevFind a hobby machinist. People who aren't trying to expand their business don't want to deal in non-gravy projects from customers who don't seem likely to shovel them a bunch of gravy projects later. Machining is a slowly dying industry in the west so there's far more people not growing their business at any one time. reply eth0up 5 hours agorootparentThanks for the insight. I think you're correct... My area is very gravy oriented in general. reply AnarchismIsCool 19 hours agoprevI remember reading this around a decade ago. Still holds up though reply blackeyeblitzar 15 hours agoprevHas anyone here tried using CNC machines for gunsmithing as a hobbyist? Is that even feasible? What about 3-D printing metals instead of plastic? To be clear, I know little about either firearms or metal working, but it seems like it would be an interesting engineering challenge for a hobbyist. reply dole 4 hours agoparentCurrent hobby 3d printing of metals usually requires a clay-metal type of filament and sintering, usually by heat or laser to harden the metal, and often needing compensation for shrinking and a lot of other inconveniences. The resultant pieces are \"metal\" but not strong enough for most internal firearms parts that need to be metal but not necessarily pressure-bearing like a barrel: most notably bolts and carrier groups, fire control group parts like triggers, hammers, sears, disconnectors. reply doe_eyes 3 hours agoparentprevYou can't easily make a high-quality firearm a hobby mill, chiefly because the barrel needs to be made out of good steel and needs to be rifled. But the quirk in the US is that federally, only the receiver is the regulated part, and many types of receivers can be made out of plastic or aluminum. You can certainly use cheap three-axis CNC with some fixturing to make AR-15 receivers, for example, and many people did. Cody Wilson / Defense Distributed had this whole thing where they were selling CNC mills for cranking out guns. You can also definitely make junk single-use guns using either technology, just like the 3D-printable \"Liberator\". reply potato3732842 6 hours agoparentprevYou can do it but don't expect top notch results. Routers don't have enough rigidity (this is why you don't see gantry mills except in huge sizes) for the kind of work you'll want to do. So much of your stuff will be one off that you're not going to have any speed advantage over a guy with a Bridgeport. reply 99_00 17 hours agoprev [–] It’s hard for me to believe that using a CNC to mill a model for resin casting works better than 3D printing it and casting it. I’d expect that with 3D printing you can even print the spruce and risers. reply fn-mote 16 hours agoparentFor one thing, IME with cheap hobbyist 3d printers (e.g., Ender printing PLA), the article is dead on about accuracy... people say 3d printers are good for 0.1mm but I don't know how long they spend tuning the machine. I mean, they are... kind of... just not reliably. CNC accuracy of 0.025mm is much easier to achieve (IME). If you mean to tell me that I should just have a resin printer to start with, well I agree but I think we should be specific about what kind of 3D printing we are discussing. Remember, the guide was written over a decade ago. Certainly 3d printing has gotten better, cheaper, and a lot more reliable. Resin is really strong, though. reply WillAdams 16 hours agoparentprevThat was written before resin printers were affordably available or input shaping and so forth had made such a leap in print quality for fused filament printers --- that said, I get much better surface finishes on my CNC machines than my 3D printers, and casting will reproduce even the tiniest imperfection. reply imtringued 7 hours agoparentprevIt is possible to get good results with 3D printers, but that requires you to go to below than 0.1mm layer heights with 0.1mm nozzles and nobody has time for that. You can make a hundred resin parts in the time it takes for the printer to finish making one. reply DannyBee 15 hours agoparentprev [–] It depends on the accuracy you are trying to achieve, and with what technology. If you mean FDM, it's absolutely true. If you mean SLA/MSLA these days, i think you could get there. On the first - i have an entirely ballscrew + linear rails driven FDM printer with closed loop servos and proper absolute encoders - I got bored and do lots of CNC retrofits/etc, so had lots of parts around. Think of it as insane version of the Pantheon HS30, if you didn't care at all about costs or practicality. It can position, at speed (IE 300mm/s+), and repeat, the nozzle placement to within 0.0005 inches on all axes, easy. But even with input shaping/etc, you will not get a better surface finish than CNC, and definitely not one good enough for casting. Filaments are just too finicky, even with really really good hotends, sensors everywhere to monitor response and optimize, etc. Now, i did this for giggles, and yeah, i never get misplaced layers, my parts are consistent, etc. But 0.4mm is still a pretty big feature size, and that's the minimum if i don't want prints to take until the heat death of the sun. So I could still machine the same thing on my metal mill and achieve castable surface finish, etc, in much less time and effort. reply jhardy54 14 hours agorootparent [–] This sounds fun, have you written anything up about this project? I’ve been considering switching to ball screws and closed loop servos on my next project. I’d be especially curious for component recommendations for hobbyists, as it seems like ball screws and servos are often super expensive or suspiciously cheap. reply DannyBee 4 hours agorootparent [–] I haven't written it up. For hobbyists, i think components are tricky. You have two basic options: 1. Linear motors - these are ideal (because it's a high acceleration, low intertia application. the extruders basically weigh nothing), but harder to find. Peopoly has a kit but my experience has not been the best there. They do seem to be coming down in price, but i haven't yet seen the equivalent of what teknic did with the clearpath steppers, but for linear motors. 2. For closed-loop steppers, you'd be best off with something close to the pantheon - closed loop teknic steppers. They have a good history at this point (well known in the CNC community), and are now even commonly used in mid-grade CNC machines these days. I've heard nothing but good things about them. As for real servos, if you want real servos, the problem you hit (relative to the current requirements of the average 3d printer) is not just cost, but the space requirement. You need real servo controllers, and they are all basically built to be in cabinets. So having 6 servo drives is not an insignificant amount of space + power. It is also severe overkill in some sense. Servos are meant to bring more efficient power usage to bear on the problem of generating torque (for the most part). But you don't need that much torque to drive a 3d printing axis, it weighs basically nothing and the mechanisms used rarely have any meaningful inertia or friction. So while I haven't tried it, i suspect you would be a lot better off with steppers + absolute encoders to ensure positioning (absolute so you don't have to home, and because incremental vs absolute cost is a complete wash at this point). The servo drives are just basically PID controllers + rotary encoders on the motors anyway. If you instead used steppers, linear absolute encoders, and controlled them by pid, i would bet you could do very well (assuming you can dynamically increase the step resolution as you approach position). The ball screws and linear rails are easy - you can get cheap c5 ballscrews (which, over this distance, are fine), and pretty much any linear rail will do (a 25mm linear rail can easily work on a 1000lb gantry). Don't overdo the ballscrews. The thing about ballscrews that people miss is that while the grades tell you the rough positioning error (which is caused by deviation in the ball track), they have little affect on repeatability, which is still very high. So even C7/rolled/whatever ballscrews are very very repeatable. The ball tracks just aren't ground as precisely, so the deviation from expected distance is higher. What this means is that if you just map the position error, once, even on a low grade ballscrew, you can correct for it very easily, because it doesn't really change. (this isn't perfectly true, but is true enough for this purpose). This is commonly done to get better accuracy out of lower grade ballscrews. If you do use linear encoders, you don't have to worry about any of this - they will be much more accurate than the ballscrew, especially over this small a distance (ie 300-400mm) and you use their position as the source of truth. In that case, you could easily use c7 or rolled ballscrews. The thing you won't be able to fix in the end without changing how we think about these printers is the mass. Wood/Metal CNC use mass to reduce vibration because it's very effective. While input shaping is great, in the end, you will hit the limit of the acceleration/movement speed you can practically achieve unless you are willing to add like 1000 pounds to your printer to absorb vibration. This is not fixable. you can't make the vibration 0 and the energy has to go somewhere. You can see this on linear motor based printers. Even without belts and lots of moving parts, they still can't do more than about 300mm/s print speed without vibrating too much. I would bet with better isolation/etc we'll get towards 500mm/s, but we will hit a limit that will require increasing mass in practice (IE whether you bolt the printer to the floor or built a concrete base or whatever) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The guide by Michal Zalewski provides a detailed tutorial on hobby CAD (Computer-Aided Design), CNC (Computer Numerical Control) machining, and resin casting, emphasizing high-quality results with benchtop CNC mills and modern polymers.- It explains the setup of a CNC mill, machine selection, and the differences between CNC machining and 3D printing, along with a cost breakdown for establishing a CNC and resin casting workshop.- The guide is modular, allowing readers to focus on specific areas like CAD/CAM (Computer-Aided Manufacturing) software tutorials or resin casting techniques, offering practical advice for efficient machining."
    ],
    "commentSummary": [
      "CNC (Computer Numerical Control) machining and resin casting are preferred for producing precise parts with superior mechanical properties compared to 3D printing, particularly FDM (Fused Deposition Modeling) printing.- CNC machining is more complex and costly than 3D printing, with quality machines starting around $2000, but offers better precision (±20μm) and mechanical properties.- For hobbyists, CNC projects can be pursued with open-source and DIY options, such as a $600 hobby CNC machine, though they require an understanding of precision and materials."
    ],
    "points": 163,
    "commentCount": 91,
    "retryCount": 0,
    "time": 1730235452
  },
  {
    "id": 41988171,
    "title": "PhD student finds lost city in Mexico jungle",
    "originLink": "https://www.bbc.com/news/articles/crmznzkly3go",
    "originBody": "PhD student finds lost city in Mexico jungle by accident What discovered Mayan city Valeriana might have looked ike A huge Maya city has been discovered centuries after it disappeared under jungle canopy in Mexico. Archaeologists found pyramids, sports fields, causeways connecting districts and amphitheatres in the southeastern state of Campeche. They uncovered the hidden complex - which they have called Valeriana - using Lidar, a type of laser survey that maps structures buried under vegetation. They believe it is second in density only to Calakmul, thought to be the largest Maya site in ancient Latin America. The team discovered three sites in total, in a survey area the size of Scotland's capital Edinburgh, “by accident” when one archaeologist browsed data on the internet. “I was on something like page 16 of Google search and found a laser survey done by a Mexican organisation for environmental monitoring,” explains Luke Auld-Thomas, a PhD student at Tulane university in the US. It was a Lidar survey, a remote sensing technique which fires thousands of laser pulses from a plane and maps objects below using the time the signal takes to return. But when Mr Auld-Thomas processed the data with methods used by archaeologists, he saw what others had missed - a huge ancient city which may have been home to 30-50,000 people at its peak from 750 to 850 AD. That is more than the number of people who live in the region today, the researchers say. Mr Auld-Thomas and his colleagues named the city Valeriana after a nearby lagoon. The find helps change an idea in Western thinking that the Tropics was where “civilisations went to die”, says Professor Marcello Canuto, a co-author in the research. Instead, this part of the world was home to rich and complex cultures, he explains. We can’t be sure what led to the demise and eventual abandonment of the city, but the archaeologists say climate change was a major factor. Getty Images There are no pictures of the city but it had pyramid temples similar to this one in nearby Calakmul Valeriana has the “hallmarks of a capital city” and was second only in density of buildings to the spectacular Calakmul site, around 100km away (62 miles). It is “hidden in plain sight”, the archaeologists say, as it is just 15 minutes hike from a major road near Xpujil where mostly Maya people now live. There are no known pictures of the lost city because “no-one has ever been there”, the researchers say, although local people may have suspected there were ruins under the mounds of earth. The city, which was about 16.6 sq km, had two major centres with large buildings around 2km (1.2 miles) apart, linked by dense houses and causeways. It has two plazas with temple pyramids, where Maya people would have worshipped, hidden treasures like jade masks and buried their dead. It also had a court where people would have played an ancient ball game. How ancient Maya cities have withstood the ravages of time There was also evidence of a reservoir, indicating that people used the landscape to support a large population. In total, Mr Auld-Thomas and Prof Canuto surveyed three different sites in the jungle. They found 6,764 buildings of various sizes. The ruins were found in eastern Mexico, in Campeche Professor Elizabeth Graham from University College London, who was not involved in the research, says it supports claims that Maya lived in complex cities or towns, not in isolated villages. \"The point is that the landscape is definitely settled - that is, settled in the past - and not, as it appears to the naked eye, uninhabited or ‘wild’,\" she says. The research suggests that when Maya civilisations collapsed from 800AD onwards, it was partly because they were so densely populated and could not survive climate problems. \"It's suggesting that the landscape was just completely full of people at the onset of drought conditions and it didn't have a lot of flexibility left. And so maybe the entire system basically unravelled as people moved farther away,\" says Mr Auld-Thomas. Warfare and the conquest of the region by Spanish invaders in the 16th century also contributed to eradication of Maya city states. Getty Images Evidence of the ruins were found by a plane using laser remote sensing to map beneath the jungle canopy Many more cities could be found Lidar technology has revolutionised how archaeologists survey areas covered in vegetation, like the Tropics, opening up a world of lost civilisations, explains Prof Canuto. In the early years of his career, surveys were done by foot and hand, using simple instruments to check the ground inch by inch. But in the decade since Lidar was used in the Mesoamerican region, he says it’s mapped around 10 times the area that archaeologists managed in about a century of work. Mr Auld-Thomas says his work suggests there are many sites out there that archaeologists have no idea about. In fact so many sites have been found that researchers cannot hope to excavate them all. \"I've got to go to Valeriana at some point. It's so close to the road, how could you not? But I can't say we will do a project there,\" says Mr Auld-Thomas. \"One of the downsides of discovering lots of new Maya cities in the era of Lidar is that there are more of them than we can ever hope to study,\" he adds. The research is published in the academic journal Antiquity. More on this story Huge ancient city found in the Amazon Egypt unearths 3,000-year-old 'lost golden city' Lost Silk Road cities discovered in Uzbek mountains Science & Environment Mexico",
    "commentLink": "https://news.ycombinator.com/item?id=41988171",
    "commentBody": "PhD student finds lost city in Mexico jungle (bbc.com)163 points by janpot 23 hours agohidepastfavorite113 comments bee_rider 23 hours ago> “I was on something like page 16 of Google search and found a laser survey done by a Mexican organisation for environmental monitoring,” explains Luke Auld-Thomas, a PhD student at Tulane university in the US. Oh, I thought he’s just gotten lost deep in the jungle (presumably looking for the free pizza that was left over from the undergrads’ seminar). But wow, 16’th page of Google, that really is uncharted territory. reply kyle-rb 22 hours agoparentWe shouldn't be rushing to explore space when we haven't even explored our own planet's ocean, or page 16 of google search results. reply notahacker 20 hours agorootparentPage 16 of Google search results: the final frontier. starts sketching out a funding application for a mission to explore page 17 reply zeristor 19 hours agorootparent\"There be dragons!\" reply melling 20 hours agorootparentprevAt last count, we had 8 billion people on the planet. I think it’ll be fine if some people do space while others work on oceans. Must admit this is the most overused excuse I’ve ever heard in my life. “Hey, let’s all work on this one problem and ignore every other problem.” reply soupfordummies 19 hours agorootparentLol I think they were just having a laugh reply churchill 18 hours agorootparentprevBut, who's going to end world hunger though? /s reply chipdart 13 hours agoparentprev> But wow, 16’th page of Google, that really is uncharted territory. Would it make a difference if instead of querying google he was at the library of a Mexican organization for environmental monitoring reading obscure reports? reply jdthedisciple 21 hours agoparentprevOne wonders what other mysteries are waiting to be uncovered amid the dark depths of Google search results ... reply textlapse 17 hours agoparentprevOnly slightly less difficult than hunting down an obscure Reddit thread that is improperly red-black balanced 15 nodes in from the root and still 10 nodes away from the leaf. reply keyle 19 hours agoparentprevBitdiana Jones. 16th page of Google, that's dark, humid, full of snakes. Better bring a torch! reply pessimizer 20 hours agoparentprevSince the 16th page of a google search is usually the end of the third repetition of the first four pages of a google search, he'd probably already missed it three times... reply 0xbadcafebee 17 hours agoprevThrow a stone and you'll find a lost city in Mexico. Lost cities found so far: Acanceh, Aguada Fénix, Aké, Balamku, Balankanche, Becan, Bonampak, Calakmul, Chacchoben, Chactún, Chicanná, Chinkultic, Chichen Itza, Chunchucmil, Chunhuhub, Chunlimón, Coba, Comalcalco, Dzibanche, Dzibilchaltun, Edzna, Ekʼ Balam, Hormiguero, Izama, lIzapa, Jaina, Joljaʼ, Kabah, Kiuic, Kohunlich, Komchen, Labna, La Mar, Mayapan, Maní, Moral Reforma, Muyil, Ocomtún, Oxkintok, Palenque, Plan de Ayutla, Pomona, Punta Sur, Río Bec, San Gervasio, Sayil, Tamchen, Toniná, Tortuguero, Tulum, Uxmal, Uxul, Valeriana, Xcaret, Xelha, Xlapak, Xpuhil, Xtampak, Yaxchilan, Yaxuná, Yula, Yoʼokop. reply jacobolus 16 hours agoparentThe larger of these are definitely not \"lost\" (as in, local people who are the descendants of their inhabitants have known exactly where they are, continuously since they were abandoned as places to live a millennium ago), though most of them are in the middle of the jungle. Southern Mexico and Central America are incredibly beautiful though, and ancient ruins there are fascinating places to visit. reply dreamcompiler 10 hours agorootparentTulum for example was never \"lost.\" It sits directly on the coast and it was \"found\" by Europeans (from a ship!) in 1518. The local Maya people knew exactly where it was. Today the Maya still live in the area and they support their families by working in the tourist industry. reply devoutsalsa 14 hours agoparentprevCalakmul is so cool’s. So is the nearby volcano of the bats. reply cossatot 19 hours agoprevThe actual journal article is here (open access): https://www.cambridge.org/core/journals/antiquity/article/ru... Based on the images, I think that the largest structure is about here: 18.891548°N, -89.323622°E. But you can't see anything in google earth (otherwise why would he have had to traverse 16 pages of google search results). reply OgsyedIE 23 hours agoprevThis link: https://i.redd.it/gm8273jvjrk71.jpg is an map (outdated though, it dates to 2019 AFAIK) of how much of the Earth's surface has been mapped by google street view. Is there a similar map product that shows how much of the Earth's surface has yet to be surveyed with lidar (or a suitable equivalent)? I would assume that areas with zero vegetation can be covered by satellite imagery but it is possible that the resolution is poor (for example, SRTM had a 30m resolution). reply ipdashc 21 hours agoparentThat map, while interesting, seems entirely subjective - the whole appearance of the map can be determined by the thickness that you set the street view lines to, no? reply bee_rider 21 hours agorootparentI guess you just lose the ability to distinguish between areas past some density, right? What would be a good way to improve it… maybe apply some filter, Lanzcos or whatever? reply AlotOfReading 19 hours agorootparentThe technical term is \"viewshed analysis\", what areas are visible from a given set of points. Any competent GIS system will have ways to do it, but peakfinder.com works pretty well as a more visually interesting demo. reply perihelions 16 hours agorootparentThat doesn't appear to be the same problem? reply AlotOfReading 15 hours agorootparentGuess I didn't read the parent closely enough. Thought it was asking what the best way to figure out the actual coverage without arbitrarily increasing line width as you zoom out. reply karim79 17 hours agoprevPlease don't tell Graham Hancock[0]. He'll claim this as more proof for his ancient ice age civilisation (for which there is no evidence). [0] https://en.wikipedia.org/wiki/Graham_Hancock reply pookha 5 hours agoparentSince we're going there...Graham Hancock's a philistine but I'd take his word over somebody like Flint Dibble. Dibble lied and pushed off bad information to win a debate and he did a disservice to himself and his peers. Many of whom work thankless jobs out on remote sites with no health insurance and for pitiful wages. They shouldn't be represented by a smug arrogant conman that passes off irrelevant studies on metallurgy, outright lies about ship wrecks and has to name drop and smear the civilians at any chance (I'd like to see that 15th century drawing of an island orthorectified like it's an image captured from a multispectural sensor Mr. Rogan) https://www.youtube.com/watch?v=Z1de_GHm63k reply alberth 23 hours agoprevLidar has been finding a lot of lost cities. Not discounting this finding. It's just becoming more common. reply HenryBemis 22 hours agoparentI've been watching the Ancient Apocalypse (S2) on Netflix and I had similar thoughts on discoveries. With drones and lidars we can discover so many of these villages/towns/cities, but the challenge would be to actually send boots on the ground and excavate into getting meaningful data/findings. At the same time, the baddies (grave robbers, looters, etc.) can use the same tech and beat us to the game. reply alberth 22 hours agorootparentNational Geographic even created a TV show 5-years ago specifically on this topic. \"Lost Cities with Albert Lin\" (2019) It's an 11-episode show where they use Lidar in each episode to find lost cities. https://www.imdb.com/title/tt10366494/ reply Hikikomori 20 hours agorootparentprevThat drivel got a second season? reply a2l3aQ 18 hours agorootparentThat you Flint? reply Hikikomori 9 hours agorootparentNobody has a more appropriate name than that man. reply Animats 22 hours agoprev\"It is just 15 minutes hike from a major road near Xpujil where mostly Maya people now live.\" And nobody sent a drone yet? The BBC has a jungle drone team.[1] [1] https://www.bbc.co.uk/programmes/articles/3P6MX7bbl0Y5SSnvJW... reply muststopmyths 22 hours agoparentIt won't be visible to the naked eye. Maya ruins like these are covered by centuries of overgrowth. Lidar scans can spot shapes buried under this overgrowth, but from the air it'll at best look like random hills of dirt. Maybe if there are structures comparable to Calakmul (which is close to Xpujil), you'll see some rocks on a tall hill. reply Animats 20 hours agorootparentWe can look forward to the Instagram video, \"With machete and weed-whacker\". reply EasyMark 15 hours agorootparentprevI mean if you have the coordinates? And it’s 15 minutes away, why would you need Lidar or drones? You could probably send in some inquisitive geeky nerds from the local schools to scout it out. reply chrisbrandow 21 hours agoprevfor a $500 plane ticket and a 4 hour drive, seems like someone has surely gone there by now, just to ground-truth this. Otherwise, seems like a fun (with plenty of risks, obvs) way of being \"the first\" to lay eyes on this. reply whartung 20 hours agoparentI'm guessing you've never actually been in \"the jungle\". It's not hospitable at all. The other thing is that that area of Mexico is just teeming with this stuff. There's just an untold boatload of \"lost cities\" in there. They can't dig and map the stuff they are working on, much less any of the numerous finds that have been made in the past 10-20 years. \"Oh, yea, yay, another lost Mayan city. Woo hoo.\" reply AlotOfReading 18 hours agorootparentA good chunk of Central America is like this. One person I know maintaining maps of historic Maya settlements was tracking thousands of known names, most of which were positionally located by rough distance estimates from some other coarsely located feature. Many didn't even have that, just a name in some historic document. reply stavros 17 hours agorootparentprevThat's kind of like finding ancient stuff in Greece. You dig a hole, and there's some ancient pots and pans in there. It's gotten to the point where people who want to build houses just carry the ancient findings away in the night, because the antiquities service will otherwise deem your plot an archaeological site. reply EasyMark 15 hours agorootparentThis type of thing happens in most countries. In the USA they actually have to hire bored archeologists to check things out as part of any contract from the federal government (and a lot of state governments) on anything that might have a hint of Native American relics. reply jaza 16 hours agorootparentprevIt's sad if \"lost cities\" are becoming so common, that they're losing their romantic-exotic-intrepid charm. If lost cities ain't got it no more, what in this world does? reply Cthulhu_ 19 hours agoparentprev\"4 hour drive\" implies you can just drive into the jungle... that's not exactly how these things work. reply kansai 15 hours agorootparentFor what it's worth, TFA does mention that the site is: > \"hidden in plain site\", the archaeologists say, as it is just 15 minutes hike from a major road reply SoftTalker 22 hours agoprevI love the idea that there might have been fully technological civilizations of humans on earth that have been totally lost to time. I know that the Maya were not that, but go back 10,000 years maybe, who knows? reply jfactorial 22 hours agoparentDinosaurs lived on Earth for about 100,000,000 years, at least 50 times as long as our species. Perhaps some dinosaurs were the most advanced species our planet has ever seen. https://pbfcomics.com/comics/dinosaur-meteors/ reply lupusreal 21 hours agorootparentSadly there's basically zero chance of that. We don't find dinosaur pottery sherds or cola bottles embedded in sedimentary rock anywhere. reply Rebelgecko 20 hours agorootparentI read a stat (maybe not true?) that we've only found around one dinosaur fossil for each 10,000 years that they existed. Maybe we just haven't found peak dino society yet- if you broke humanity down into one archaeological find per 10k years you probably wouldn't think we had much of a society either. reply notahacker 19 hours agorootparentIf dinosaurs had changed their environment as much as humans, there would probably be more than the occasional fortuitously preserved corpse or footprint to find. reply Rebelgecko 13 hours agorootparentMaybe dinosaurs were just more advanced when it came to building a society that coexisted with their environment reply hangsi 4 hours agorootparentprevYeah, there should be some sort of world wide epoch shifting environmental change about 65 million years ago to show for it. reply lupusreal 8 hours agorootparentprevMost of the time, dino bones don't fossilize. And we only find some small fraction of the small fraction that do. But with glass and ceramics the situation is different. Those are stable in almost all conditions, running water excepted. A beach will break down a coke bottle in a few years but if it lands just about anywhere else it has a high chance of lasting basically forever. If dinosaurs ever became like us, there should be a clear layer in the rock where they started throwing their trash on the ground. reply gitaarik 15 hours agorootparentprevThey didn't make pottery but they had very intellectual conversations and some very good philosophers reply digging 20 hours agorootparentprevThey lived so long ago, my understanding is such artifacts would be extremely unlikely to survive. We also haven't looked in that many places at that depth. I mean it's still quite unlikely though. reply Panzer04 20 hours agorootparentIf bones survived, some advanced remnants would also survive, I would expect. reply roywiggins 16 hours agorootparentWell, survived by turning into rocks: https://ucmp.berkeley.edu/paleo/fossilsarchive/permin.html reply EasyMark 15 hours agorootparentGah, wrong comment responded to. reply janalsncm 21 hours agoparentprevMaybe not full-blown technology, but a lot of New World philosophy, art, and mathematics, and history were destroyed by the Europeans or otherwise lost to time. Maybe even medicines that we don’t know about. They didn’t have electric computers though. reply matthewdgreen 22 hours agoparentprevhttps://en.wikipedia.org/wiki/Silurian_hypothesis reply ants_everywhere 16 hours agoparentprevI'm not sure what \"fully technological\" means, but if they had made anything at scale out of durable materials like stone or ceramic we would most likely have seen some indication. What we do probably underestimate is how advanced ancient hominids were. They mostly worked with materials that decay like wood, plants, and animal skin. But we're slowly learning that they were more advanced than we used to believe. reply EasyMark 15 hours agorootparentAny former civilization that is any sizable fraction of ours with same level of tech would have been spotted long ago. Well unless Atlantis is real somehow sunk 3 miles down reply ants_everywhere 6 hours agorootparentThen we're in agreement right? reply Cthulhu_ 19 hours agoparentprevAn interesting theory (albeit likely sci-fi) is that on a long enough timescale, any existence of an advanced precursor society will have been lost by tectonic plates sliding down. But that's a timescale of hundreds of millions of years (apparently the earth is ~4.5 billion years old, human life that left traces of intelligence behind is a percentage of a percentage of that) reply stormfather 18 hours agorootparentIts the ocean plates that slide down when they hit the more buoyant continents. When continents hit they make the Himalayas. reply shrubble 21 hours agoparentprevThe conquistadors praised Tenochtitlan, viewing it as an advanced city equal to the Spanish cities of the time. reply jaza 16 hours agorootparentHey muchachos, I think 5 minutes of praise for Tenochtitlan is in order. Right, that's that done, now, onto the 3 centuries of murder, rape, pillage, inquisition, and subjugation. reply EasyMark 15 hours agorootparentYou mean like the Aztecs (and other civs) before them? Humans gonna human. I think we have to always look at the whole story and not just what’s currently popular to demonize. reply blovescoffee 13 hours agorootparentTheir actions were still unique in many ways. And the Spanish’s action were an order of magnitude more consequential. The Aztecs warred and pillage other groups but were not in the business of wiping centuries of knowledge off the face of the earth nor did they ever manage or desire to kill 90% of all peoples of central Mexico. reply bobthepanda 20 hours agorootparentprevThe floating city would've almost certainly been a marvel in its own right. reply superxpro12 22 hours agoparentprevIs \"love\" really the right descriptor here? The implications are truly depressing. reply ks2048 22 hours agorootparentNo need to get depressed about an idea with zero evidence. reply keybored 21 hours agorootparentprevConsidering what terrible stewards of the the Earth and of each other we are, depressing is also a wrong descriptor. reply SoftTalker 22 hours agorootparentprevYes, it would be a sobering reminder on how essentially powerless we are in the face of global calamity. You see this recognized in religions and in pre-technological societies, but few of us in the modern era do. reply melling 22 hours agoparentprevThat means we squandered almost 10,000 years of human history before humans became an advanced civilization. We could have invented flight, discovered antibiotics, etc five thousand years ago. reply bee_rider 19 hours agorootparentMost of the clocks we’re racing against are ones we invented in the last 200 or so years. So the other 9,800 years weren’t really squandered, the clock really wasn’t ticking so much back then. reply melling 18 hours agorootparentThat sort of makes absolutely no sense. Just killing time here? No one said anything about racing the clock. reply bee_rider 17 hours agorootparentSquandered implies it was somehow a meaningful loss, at least that’s how I interpreted it. It was meaningless time. If we’d gotten to our current development level ~5000 years ago, we’d just be writing these same comments next to calendars that had their zero sent to ~7000 years ago. reply melling 17 hours agorootparentWe still wouldn’t be alive 5000 years ago. That part doesn’t change. I think you’re confusing yourself. Half of Europeans that died during the great plague would’ve benefited, for example. Most people who were born in the past 150 years would still be alive. let your imagination have a go at it. reply bee_rider 16 hours agorootparentI’m not at all confused. But we’re somehow talking past each other. Which I probably contributed to too, although that wasn’t my intent, so sorry for the mix up. Anyway, it is just silly chitter-chatter so I think it is not worth sorting out where we’ve missed each other. reply batch12 17 hours agorootparentprevTrue, we (the ones reading and writing these comments) would likely never exist if the past was that radically different. reply buzzerbetrayed 17 hours agorootparentprevYou’re taking a radically different past, and then somehow arriving at the conclusion that any part of history that we current know would have still happened. reply melling 16 hours agorootparentNo, I’m assuming we had an advanced civilization 10,000 years ago then assuming continuous progress was made. I threw out the Great Plague, or something similar, as an example of something that wouldn’t have occurred because science would have addressed these types of diseases. Covid today would be easily treatable in a more advanced society Clearly history wouldn’t play out the same way. The point is that today’s society would be much more advanced reply spaceman_2020 22 hours agoparentprevThe oldest city that we’ve found to date was buried - intentionally - under a mound of earth. There could be dozens of these sites Lidar the planet reply StanislavPetrov 18 hours agoparentprevConsidering that the seas were hundreds of feet lower, and most settlements are built on coasts and waterways for transport and food harvesting purposes, it is very likely that anything left before the last ice age was destroyed by rising seas and any remnants are far offshore. reply elphinstone 16 hours agoprevI wonder if tomb raiders and other artifact thieves are using the same methods and arriving faster. reply dylan604 23 hours agoprev“I was on something like page 16 of Google search \" whoa, I had no idea there were that many pages in a google search. that's some serious googlefu to get that kind of a result. I guess it definitely says something about the researcher too to continue on that deep. I'm expecting that comment to have been hyperbolic though reply jeffwask 22 hours agoparentThe first 10 are all SEO and AI junk now. reply gkanai 19 hours agorootparentyou get an upvote reply columbus567 23 hours agoprevImagine putting that on a resume for a postdoc - discovered lost Mayan city reply potato3732842 23 hours agoparentFlock will hire him as a consultant when they develop their upcoming \"fine people for unpermitted garden sheds\" service. (joking, but sadly not joking) reply SoftTalker 22 hours agorootparentCities and counties have been using traditional aerial photography for that for a long time now. reply vips7L 22 hours agorootparentI have friends who work in InsuranceTech and they use satellite images of houses when someone apply for home owners insurance. They've said it flags people with trampolines all the time. reply SoftTalker 20 hours agorootparentMy insurance company asked about that when I got the policy, I said Yes we have one and it was not an issue. Perhaps they are charging me a higher premium, but not enough that I noticed. Though we no longer have it, so perhaps I should mention that next time I meet with my agent. reply amelius 21 hours agoparentprevI was imagining what Indiana Jones would look like in this day and age. reply maxerickson 19 hours agorootparentJuvy record for the train thing, working as a waiter in the city the detention center was in. reply jll29 23 hours agoparentprevI was going to say: that's a thesis result sorted - check. reply 77pt77 22 hours agoparentprevIt's going to get as common as > New exoplanet discovered Very soon. And therefore unworthy of barely being mentioned. reply Oarch 22 hours agoprevSighs and resets the 'Days since we discovered a lost city using LiDAR' counter back to zero. reply bkandel 22 hours agoprevHow is this by accident? He was specifically looking for datasets for this purpose and found a good one, then loaded it into a program to find man-made structures. reply baq 22 hours agoparentPage 16 of google. He might have been the first person to see those datasets except the ones who published them. reply dang 21 hours agoparentprevOk, we've taken the accident out of the title above. reply ghssds 21 hours agoprevHow many cities are lost every year? Can finding those cities help alleviate the housing crisis? Won't the inhabitants of those cities complain about disrupted postal service? I have so many questions! reply advisedwang 23 hours agoprev [12 more] Once again, the sensationalized \"discovery\" of a \"lost\" by people that fly over with lidar and never talk to the locals. https://www.smithsonianmag.com/smart-news/did-recent-expedit... reply dang 21 hours agoparentI appreciate the link but your comment isn't in keeping with the site guidelines, which include: \"Don't be snarky.\" \"Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.\" If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful. reply mitthrowaway2 23 hours agoparentprevCan the locals draw a map of these lost cities? Or are they just aware that there are many lost cities, but without knowing exactly where they are? And for that matter, if the locals did know the specifics but weren't spreading that knowledge, then it still can constitute a discovery. \"Discovery\" can mean revealing knowledge that was previously known to insiders, eg. if I say \"I discovered an underground smuggling ring and reported it to the police\", you probably wouldn't argue that \"you didn't discover anything; the smugglers already knew about it\". reply romwell 22 hours agorootparent>\"Discovery\" can mean revealing knowledge that was previously known to insiders, eg. if I say \"I discovered an underground smuggling ring and reported it to the police\", you probably wouldn't argue that \"you didn't discover anything; the smugglers already knew about it\". Just wanted to say how much I'm enjoying this point. Newspaper Headline: Discoverer of Underground Smuggling Ring Proven a Fraud: Ring Leader Says He Discovered It First\" reply jklinger410 22 hours agoparentprevWow archaeology should be rife for disruption if you can just go around and ask locals. Seems like anyone with gumption could be the next great scientist. Or maybe one of those locals could be. I wonder what stops them? reply 77pt77 22 hours agorootparentLocals lie. Like a lot! They even pretend to be able to read ancient languages/scripts when in reality that are just making stuff up. reply lupusreal 20 hours agorootparentprevThis, but unironically. > Or maybe one of those locals could be. I wonder what stops them? They're living their lives, rarely becoming academics in the relevant field, assuming that local rock ruin is known to somebody outside of their community, or if not, then assuming nobody cares anyway. You can probably find a lot of undocumented ancient stuff by asking shepherds in areas known to be territory of ancient poorly documented civilizations. reply OgsyedIE 23 hours agoparentprevWhat is the proportion of villages where surveying the locals will lead to documenting an abandoned city that is otherwise only known to the locals? If only 2% of villages have an undiscovered profitable heritage, then 98% of surveys will show no results, which makes it difficult for anthropological surveys to compete with lidar for grant funding, especially when lidar is still new enough to seem \"sexy\" and \"sci-fi\". reply dylan604 22 hours agorootparentThrow in some AI processing of the LIDAR data, and watch those funding dollars flood in!! reply AlotOfReading 14 hours agorootparentTo put into context how few funding dollars there are in archaeology, the NEH currently has $800k available for archaeological field research proposals. That's the largest \"funding agency\" pool for generic field research. This same funding agency that doesn't directly fund computer research also has $2.5M available for proposals specifically targeted to starting collaborations researching AI alignment. They have another $3.5M for the actual collaborations themselves, and an additional $2.2M for AI work that \"contributes to scholarly research in the humanities\". reply EasyMark 15 hours agoparentprevHow about “discovered it for the world at large” I think there have been many cases where the locals knew about a lost city or even took stones for their farms from it for X purposes. Still it lets the government there know about a new lost city they can properly check out (or leave alone) reply empath75 22 hours agoparentprev [–] \"Discovery\" probably isn't the right word, but the important part isn't knowing that something is there, the important part is telling the rest of the world about it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A PhD student, Luke Auld-Thomas, discovered a lost Mayan city named Valeriana in Mexico's jungle using Lidar technology, which uses laser light to map the ground beneath dense vegetation.",
      "The city, located in Campeche, features pyramids, sports fields, and causeways, and was densely populated, challenging the idea that tropical regions were unsuitable for large civilizations.",
      "The discovery highlights Lidar's revolutionary impact on archaeology, revealing numerous lost cities and suggesting that climate change and Spanish conquest contributed to the Maya civilization's decline."
    ],
    "commentSummary": [
      "A PhD student from Tulane University discovered a lost city in the Mexican jungle using a laser survey found deep in Google search results, highlighting the potential for hidden discoveries in less-explored search pages.",
      "The discussion humorously addressed the obscurity of deep Google pages and emphasized the role of technology, such as Lidar (Light Detection and Ranging), in archaeological discoveries.",
      "Commenters noted that many \"lost\" cities are often known to local populations but remain undocumented by external researchers, pointing to the gap between local knowledge and academic documentation."
    ],
    "points": 163,
    "commentCount": 113,
    "retryCount": 0,
    "time": 1730228655
  },
  {
    "id": 41988285,
    "title": "GLP-1 for Everything",
    "originLink": "https://www.science.org/content/blog-post/glp-1-everything",
    "originBody": "www.science.org Verifying you are human. This may take a few seconds. www.science.org 8dada8c19db761ad",
    "commentLink": "https://news.ycombinator.com/item?id=41988285",
    "commentBody": "GLP-1 for Everything (science.org)147 points by etiam 23 hours agohidepastfavorite222 comments kbos87 21 hours agoThe best way that I can describe what Semaglutide has done for me is that I feel like almost nothing in my life has changed (other than being down 45lbs, suddenly having normalized liver enzyme levels and blood pressure.) Before starting it, I generally ate until I was satiated, almost never over full. From time to time I'd maintain a caloric deficit, but it meant a large part of my attention was consumed, day and night, by a nagging distraction of food. Today, I still just eat a normal diet until I'm satiated - but 1/3 of the food is left on the plate. I have a little less of an interest in alcohol and coffee, but other than that it's like nothing has changed. My point is that there's still a common sentiment that these drugs are some sort of a shortcut for people who want the ability to over-indulge, when in reality that couldn't be further from the truth. I think what I feel like on a GLP-1 is what most people feel like without one. If you want to know what I feel like without a GLP-1, try not eating until your mind is constantly nagging you to do so - then try staying like that forever. That's what a lot of people propose to anyone who has a problem with their weight. reply Salgat 20 hours agoparentThis is my issue. I have lost 40-60lb many times in the past 15 years, but I always gain it back because the root cause is not fixable. I always have a lingering hunger, and I don't want to spend my entire life hungry. reply kbos87 6 hours agorootparentIt seems like there's growing medical acceptance of the idea that everyone has a natural weight that they seem to plateau at (which in some cases is overweight.) 1mg of semaglutide reset my natural plateau from 225 to 180. You are exactly right though - being overweight is either a daily physical battle or an hour by hour mental battle if you are trying to restrict calories. reply 404mm 20 hours agoparentprevI assume you are also on weekly doses. How does it work for you? I feel like I go through cycles of: Day 1: no change Day 2: can go whole day without eating, a bit nauseous Day 3-5: feeling bloated, food doesn’t digest fast, not eating much, biggest weight loss Day 6-7: Slowly getting back to eating reasonable portions reply kbos87 7 hours agorootparentI'm on 1mg of compounded semaglutide, where I've been for the past 4 months. I have a similar arc in terms of days 2-5 being the strongest effect, but I haven't experienced any nausea (except the smallest bit during the first couple of weeks at 0.5mg.) I was briefly at 1.5mg but was brought down because I started losing weight faster than needed. My weight has been rock steady since coming back to 1mg. reply kubectl_h 19 hours agorootparentprevI feel like I have an almost optimal reaction to the drug, which I kind of feel bad about, given all the side effects other people seem to have. My experience mostly matches yours, except without bloating or nausea. I do have a slight urge to drink on day 6 and 7 -- well not an urge, more like an acceptance of it -- kind of hard to explain. I don't even think about alcohol on the other days. I am injecting the Hims formulation of semaglutide. I had no side effects on my first two injections, so my next two (which were supposed to be the same as the first two) I increased the dosage slightly. I am pretty happy with how I feel so I'm not sure how aggressively I'll ramp up to the full dose. reply 404mm 18 hours agorootparentI’m on Zepbound and I had no side effects for my 2.5mg and 5mg doses. It’s starting to be more prevalent with 7.5mg - and I haven’t moved to higher dose yet. reply kubectl_h 18 hours agorootparentAh, ok so my experience parallels yours. Are you eating \"healthier\"? What I've found is I prefer \"simpler\" meals to more complex/layered/richer dishes. I forgo pasta dishes or sandwiches for simple meals like eggs + a vegetable + fruit. I've actually had to throw out a bunch of ingredients that went bad that I never would have had to before. I've had to adjust my grocery shopping quite a bit, including frequency. reply 404mm 17 hours agorootparentYes, simpler is better. More specifically, I no longer can do Thai food. To spicy now. reply bb88 20 hours agorootparentprevThat's usually how it works for me too. I find that days 2-5 I start feeling not very good. I wouldn't say bloated, but almost weird blood sugar levels. Usually about 6pm in the evening is when I start feeling terrible. Kinda makes me want to eat less. reply hbosch 20 hours agorootparentprevIt works much better, in my experience, to cut the dose in half and take it twice a week. I do Sunday and Thursday, 2.5mg of tirzepatide per injection. reply s1artibartfast 18 hours agoparentprev>If you want to know what I feel like without a GLP-1, try not eating until your mind is constantly nagging you to do so - then try staying like that forever. That's what a lot of people propose to anyone who has a problem with their weight. Ironically- not eating- is what solved this issue for me. I imagine it is what people on GLP-1 feel like all the time. I spent a long time food fixated, frequently nagged by hunger, until I started practicing going without. Now I can go 2-3 days without eating and have to force myself to eat something. I encourage most people to try going 2-3 days without food and seeing how it changes their relationship to it. reply nunez 12 hours agorootparentGoing days without eating for nonreligious reasons is a Hallmark indicator of an eating disorder. reply s1artibartfast 11 hours agorootparentI'm sure it is in some cases, but overall I think having self control over when and how much one eats is a good thing. I would be more concerned about unrestrained compulsive eating disorders. It is interesting that compulsive eating to the point of exhaustion, obesity, loss of mobility, and organ failure is normal, but skipping a few meals is considered strange. The former is a leading cause of death, while the later is perfectly safe and may even have a number of benefits. reply devilbunny 4 hours agorootparentprevIndicator, not proof. If you're an illegal spy (no diplomatic cover), paranoia isn't a maladaptive behavior. If you're overweight, going days without eating isn't necessarily a sign that you have swapped one bad relationship with food for another - it could just be a way to lose weight. Effective weight loss methods absolutely depend on reining in hunger. Fasting happens do that for some people. If you weigh 40 kg as an adult and you don't eat for days, you probably have an eating disorder. If you weigh 140 kg as an adult and you don't eat for days, meh? reply s1artibartfast 2 hours agorootparentbingo. As I understand it, disorder is characterized by harm and lack of control. spending time lifting weights for health is usually OK, staying up all night throwing things at invisible monsters is not. reply valval 13 hours agoparentprevYou’ve been eating the wrong things all your life. Animals aren’t obese in the wild, nor would you be if you didn’t eat slop. reply kbos87 7 hours agorootparentWhat an insightful and additive point of view that I've never considered before. reply deepfriedchokes 12 hours agorootparentprevHumans aren’t obese in the wild, either. reply kelseyfrog 22 hours agoprevThe main difference between GLP-1 agonists and telling people to eat less/better is that one works and one doesn't. reply Attummm 22 hours agoparentThat is because the advice around eating less is focused on old paradigms that have clearly failed. Those drugs let people experience intermittent fasting and fasting by reducing hunger and snacking. The danger of suppressing hunger signals is that hunger could've been a important que for nutritional needs. Muscle loss is severe danger of gpl-1, And muscle size is tied to longevity. So although promising it's not without danger. And there are other paradigms but those are not yet explored yet the underlying mechanisms work the same. Edit: Let's keep HN a place where discussion can be held without just kneejerk down voting. Edit2: great discussion thanks all. reply vineyardmike 21 hours agorootparentIf people are obese, they’re not getting the right hunger signals anyways. Obesity is heavily tied to longevity. GLP1s cause muscle loss because when you lose weight, some of your caloric deficit will be supplemented by your muscles. The article suggests that non-weight loss side effects of GLP1s are also worth considering taking the medication for. If you’re maintaining a healthy weight, while taking the drug, you shouldn’t experience the muscle atrophy. Also, muscle size isn’t tied to longevity, usable muscle and a certain strength and physical ability is tied to longevity. Muscle size is a convenient proxy. Also cardiovascular ability in a related way. You basically just need to be able to move and carry things and act in your environment in a responsible way at an old age so you don’t fall or hurt yourself. reply Attummm 21 hours agorootparentYour points are just reforcing my initial point. Old paradigms of nutrition have clearly failed. If we could acknowledge that we could move forward and be open to very promosing alternative paradigms. Which currently are not studied enough, to create clear nutritional guidelines for the public. Gpl1 and those paradigms work through the same mechanisms action (autophagy, ketones, reducing food intake). If there is acute problem with health such as (morbidly)obesity then gpl-1 could be a great intervention. But its not long term solution, nutrition and a healthy relationship with food and lifestyle is. Muscles are very important for health, but let's not go into that. For muscle size I linked to meta study about muscle size and all cause mortality (longevity) > Conclusions: Low SMI(skeletal muscle mass Index) was significantly associated with the increased risk of all-cause mortality. https://pubmed.ncbi.nlm.nih.gov/37285331/ reply vineyardmike 20 hours agorootparent> Old paradigms of nutrition have clearly failed. If we could acknowledge that we could move forward and be open to very promosing alternative paradigms. > Which currently are not studied enough, to create clear nutritional guidelines for the public. We have very clear, very obvious nutritional guidelines for the public, and we have lots of research on the healthy food to eat. The TLDR guidelines that would have a positive impact on most people is \"eat less\". Doesn't seem to work, and it's not an informational problem. (1) its not long term solution, nutrition and a healthy relationship with food and lifestyle is. The reality is that plenty of people will just never have this. Some people are \"weak\" or \"genetically predisposed\" or \"addicted\" or \"impoverished\" or any other number of things that people use to explain poor diet. No amount of nutritional guidelines will fix this. That's just the (unfortunate) reality. Now what do we do? (2) GLP-1 medication (according to the article) have other benefits beyond nutrition, eg addiction, Alzheimer's, kidney health, etc. These benefits could be very real (some are still being studied). If they turn out real, how does our relationship with the drug change, how that its not just a replacement for a \"healthy relationship with food and lifestyle\"? You've mentioned muscle being a proxy for health. Do you consider going to the gym and working out to be a \"long term solution\"? Why is spending an hour a day performing an artificial activity (lifting weights) generally considered a healthy lifestyle, but taking safe preventative medication not considered part of a healthy lifestyle? (Generally) society considers vaccines to be safe and healthy, and we recommend them for everyone from a young age. They're obviously quite artificial, and they trick our body by stimulating certain biological pathways artificially. What is different about certain medication like GLP1 meds that keep us from considering it part of a safe, healthy lifestyle? reply Attummm 20 hours agorootparentThe health benefits of eating less and fasting such as autophagy, ketones occurs with or without gpl1. That is how gpl1 is healthy, because eating less and fasting is healthy. You don't have to go to the gym to activate and stimulate muscles. But our bodies are made for daily usage of muscles. We always had downtrodden, poor, weak people, in any society. But in the 1970's they were not obese. We dont take daily vaccins they are a intervention. Gpl1 could be intervention for obesity patients. The danger of long term usage of gpl1 is that our bodies emerged ecosystems that we don't understand yet. By reducing hunger signals that their motivate a person to get nutrition such as protein, vitamins and minerals, etc Leads to malnutrition, muscle loss and other diseases. Your point is that there is no problem with current paradigm of nutrition while at the same time promoting a agent that stops the addictive nature of our current nutritional paradigm. If you use gpl-1, And it works for you that is great and we should be grateful that gpl-1 is available. My only advice would be, to lift weights or callisthenics to keep your muscle size and strength. And to explore other nutritional paradigms that can help you maintain the weight loss without gpl-1. reply vineyardmike 14 hours agorootparent> That is how gpl1 is healthy, because eating less and fasting is healthy. These medications do so much more than this. First, they have all sorts of direct metabolic benefits beyond just eating less, and secondly, studies are linking them to non-metabolic benefits too. You don’t have to go to the gym to stimulate your bodies, but most people require it because they won’t do it naturally in their life. You don’t need GLP1s to regulate your metabolism, but it seems most people aren’t doing it naturally in their life. In 1970s, people died of hunger. We’re also not in the 70s and won’t be going back. Our society has a surplus of unhealthy food and an uneven distribution of healthy food. The food is engineered in labs to be addictive. Our society doesn’t make room for regular physical exercise. So many things wrong, and until we start regulating the food industry, the best we can do is correct mistakes. I’m also not sure there is any real evidence that the GLP1s are causing malnutrition because of “hunger signals”. But ensuring proper nutrition of vitamins and micronutrients is not that hard to monitor. I’ve never used a GLP1 antagonist. I’m not one to brag to strangers on the internet, but I view myself as rather healthy and athletic. It’s a lot of work, it’s not that fun, it takes a lot of time. I just don’t believe that the only right way to be healthy is waste an hour in the gym every morning and do “hard work”. If there was a CrossFit pill, I’d be here supporting that too. Some things (working out, vaccines) are basically just a net-good on the health of society. Why isn’t it possible that this is included in that list? reply ryanobjc 21 hours agorootparentprevI came here to basically say this. People who tout the dangers of glp1 - and there ARE risks! - are also ignoring the \"what did you do instead of a glp1\" and the answer is.... remain overweight, which has many risks! Yes glp1 might increase the risk of a certain kind of cancer. But guess what, it also reduces the risks of many other cancers tied to obesity! It's hard for me to take hand-wringing over glp1s seriously. Appeals to \"JUST do x\" are lost in the \"just\" - hello if people could just do intermittent fasting, or eat less calories, well then there would be less obesity. The obesity epidemic is literally a rebuttal to any of these arguments. reply stavros 21 hours agorootparentprev> Those drugs let people experience intermittent fasting and fasting by reducing hunger and snacking. This shows you haven't tried GLP-1s. I've been doing IF for ten years, doesn't stop me from being overweight. GLP-1s do. reply Attummm 21 hours agorootparentFirst of all congratulations with your succes, and not take away from that. But IF nor fasting is a silver bullet. Reducing food intake, and insuline while keeping hunger down is. Important aspect is keeping hunger down. And if your fasting/excersicsing you can experience the same. The discussion on weight unfortunately almost always focused on total weight. But we would like to retain our muscles, and reduce adipose tissue(fat). With gpl1 people are able to fast, stop snacking and reduce food intake because hunger signals are blocked. But a fasting lifestyle, which goes further then just IF. And a focus on nutrition(vitamins, minerals, quality sources) could the same. Furthermore the effects of lowering inflammation of gpl1 is only logical reduction in food intake/fasting will lead to autophagy. IF/Fasting and other new nutritional paradigms are still new and uncharted. It's not clear yet what the full effects are, and how to implement them correctly. reply stavros 21 hours agorootparentYeah, but at the end of the day, it either works, or it doesn't. You can say \"you're holding it wrong\" all you want, but if it's easy to hold the thing wrong, it's the thing's fault. GLP-1s work for many more people than any other diet advice we've ever had. reply s1artibartfast 19 hours agorootparentI dont think this is an either or situation. People still need tools in their toolbox if they dont want to be be on a biologic for the rest of their lives. Fasting is just one such tool. reply bb88 18 hours agorootparent\"Oh you don't want to be on a statin for the rest of your life, do you?\" Yes! I do! It lowers the risk of stroke and heart attack! reply s1artibartfast 17 hours agorootparentwho are you talking to? I dont think making up quotes and responding to yourself is a productive way to carry on a conversation. reply Attummm 20 hours agorootparentprevIF is not well understood, nor explained. So in that aspect we agree completely. A few years ago people would call you mad for fasting, and now we have drug that allows people to life the fasting lifestyle. And if there is a medical reason I'm not making the argument against. I'm making the argument that it's a intervention and that healyhy nutrition, healthy relationship with food will is the long-term solution. And order todo that we would need to explore other nutritional paradigms than the current one. Edit: - Fasting lifestyle, like omad(eat once a day) removes the feeling of hunger and thoughts about food, until it's the moment to eat. reply stavros 20 hours agorootparent> So in that aspect we agree completely. A few years ago people would call you mad for fasting, and now we have drug that allows people to life the fasting lifestyle. It's nothing like the fasting lifestyle, it just quiets the food noise. > I'm making the argument that it's a intervention and that healyhy nutrition, healthy relationship with food will is the long-term solution. That's like saying \"I'm making the argument that diabetes medication is an intervention, and that producing healthy amounts of insulin is the long-term solution\". Yeah, it's all well and good, except it doesn't work. You can yell at people for not , but, at the end of the day, people have tried diet, they've struggled with it, and it's failed. No matter how much yelling you do, they won't stop. It's like trying to talk a meth addict out of their addiction. reply bb88 20 hours agorootparentDoctors have long said, \"Diet and Exercise\", but they couldn't really address the pain aspect of hunger until the last few years. And hunger is painful. Hunger is something that is left to the patient to cope with -- usually badly. Sure there could be support groups and exercise groups, but nobody is going to be there in your bed when you're trying to fall asleep with hunger pains. reply stavros 20 hours agorootparentThis thread is kind of painful because it's full of people who have no problem with their weight telling others to \"just don't have a problem too!\". I don't eat because I'm hungry. I eat because food is there, or because I remembered that food exists, or because I have nothing better to do, or because stuff tastes good. I can't remember the last time I was hungry. The weird thing is I can go a really long time without food. I can go 36 hours easily without eating something, hunger doesn't bother me at all. After 36 hours, I think \"huh, I should probably eat something\". Such situations where I forget to eat are really, really, really rare. I have to basically be on my own and working on something fun, because that's when I both don't have food in the house and don't want to spend the two minutes it takes to order something. reply bb88 20 hours agorootparentExactly. Kids who went hungry at school had behavioral problems, and couldn't focus on schoolwork. The solution was to give the kids breakfast, not to tell them to cope with hunger until they got home. reply schnebbau 21 hours agorootparentprevYou don't lose weight when IF if you eat your maintenance calories during the period you're not fasting. reply sangnoir 21 hours agorootparentprevDepending on ones metabolism, IF with no caloric deficit doesn't guarantee weight loss. reply bb88 20 hours agorootparentRight and caloric deficit is just diet. reply illiac786 21 hours agorootparentprevOn one side, sure GPL-1 may have side effects, maybe bad ones. On the other hand, overweight in the sense of excessive adipose tissue, correlates with a huge number of very bad health problems (both mental and physiological), with an abundance of proof around causality for many of these. I’m thinking, whatever negative side effects we find for GPL-1 in the future, they will have to be pretty massive to offset all these benefits. reply RachelF 21 hours agorootparentprevA GLP-1 drug trial 12 years ago by a major pharma company was stopped because of increased suicide risk (2 in 10,000) among the cohort. We will see what happens long term the second time around. reply phonon 12 hours agorootparent\"Compared with those prescribed lifestyle intervention for obesity, adolescents prescribed either liraglutide (Saxenda; Novo Nordisk) or semaglutide (Wegovy; Novo Nordisk) had a 33% lower risk of suicidality over 12 months of follow-up after controlling for potential baseline confounders.\"[1] [1]https://www.tctmd.com/news/defying-earlier-glp-1-data-study-... reply chpatrick 21 hours agorootparentprevIt's not even the second time around now, liraglutide was approved a decade ago. reply derbOac 20 hours agoparentprevI'm fine with GPL-1 agonists, they seem great, not trying to argue against them. This is an age old problem in the obesity treatment and research community. It never seems to go away. It's come up with bariatric surgery, with other methods, and now GPL1- agonists. The issue for me is that \"telling people to eat less\" is sort of a strawman in some ways. It doesn't work. What does work, however, at least according to evidence I've seen, is giving people strategies for losing weight, therapy, support, and so forth. It doesn't work for everyone but it does for some. I would rather people try that first as it can be self-sustaining and doesn't require medication. I'm not opposed to the medication or people using it, in fact I think it's a good thing, but it seems a little dangerous to me to create a culture where people are just told \"take this pill, pay lots of money for it, because nothing else will work\" which is not actually true. I don't think we're at that point but it's easy for me to imagine. reply CooCooCaCha 19 hours agorootparentIt's tricky because losing weight can take a mental load off, it's just getting there that's hard. Once you get there you gain confidence, people treat you differently, doctors take you more seriously, exercise becomes easier (less weight to throw around and less strain on joints), etc. reply thefz 21 hours agoparentprevEating less works, if taking a drug that makes you eat less, well, works. reply maxerickson 20 hours agorootparentThat's a bad read of what they said. They didn't say that eating less doesn't work, they said that telling people to eat less doesn't work. I am tempted to make a snide remark, but I suppose that won't do any good. reply s1artibartfast 18 hours agorootparentI think the post is as hostile to GLP-1 as you feel it is. Eating less works. Telling people to eat less and exercise self control doesn't work very often. reply ZYbCRq22HbJ2y7 20 hours agoparentprevExcept adherence to taking GLP-1 agonists isn't a given, especially with dosing regimens that are shorter than a week. reply akira2501 22 hours agoparentprevObesity rates are not consistent across the world or time. Neither work. They just hide symptoms of the larger problem. reply toomuchtodo 22 hours agorootparentThe problem is the human existing in a modern environment that is hostile to it. GLP-1s enable the human to more effectively operate in said environment. It patches malfunctioning reward centers (addiction and food compulsion), it reduces overall inflammation, it provide cardiovascular protective properties. As kubectl_h mentions [1], the future is better understanding and fine tuning the mechanisms responsible. I think gene therapy is the end goal (permanent fix vs chronic maintenance with GLP-1s), but others have indicated in previous threads that might not be possible. We need more information and research. This is only the beginning of the \"Aha!\" moment (The most exciting phrase to hear in science, the one that heralds new discoveries, is not “Eureka” but “That's funny...” —Isaac Asimov). [1] https://news.ycombinator.com/item?id=41989101 reply akira2501 22 hours agorootparent> in a modern environment that is hostile to it. Our ancient environment was hostile as well. > It patches malfunctioning reward centers It has an impact on them. It does not \"patch\" them. This is not a rational way to describe any drug. > it reduces overall inflammation It can inhibit certain inflammatory pathways. > it provide cardiovascular protective properties. It reduces the number of cardiovascular events. Whether that number is normal to begin with is not considered here. > We need more information and research. You certainly do. reply toomuchtodo 22 hours agorootparentYou're free to your opinion (legit, no snark intended), the market will deliver to the demand. The cost benefit ratio is obvious, even accounting for potential side effects at scale. https://www.axios.com/2024/01/18/ozempic-wegovy-weight-loss-... https://www.axios.com/2024/01/19/weight-loss-drugs-america-o... https://recursiveadaptation.com/p/the-growing-scientific-cas... https://www.jpmorgan.com/insights/global-research/current-ev... Edit: I simply do not understand the hostility towards this simple intervention, my apologies. reply akira2501 22 hours agorootparent> You're free to your opinion Oh. Thank you. That's very generous. I assumed we started from that position but apparently not. > the market will deliver to the demand. Yes, because our healthcare market is perfect, and we should acquiesce to it's demands. The same could be said of opioid pain killers. > The cost benefit ratio is obvious Which entities cost benefit ratio, exactly? The patients? Are you _sure_ you have data which allows you to say that? > even accounting for potential side effects at scale. You're free to your opinion. The market will repeat history. reply Teever 22 hours agorootparentprevYou seem hostile to this possible solution. Can you explain why? reply derektank 22 hours agorootparentprevObesity rates aren't consistent because access to cheap calories is not consistent across the globe. I don't mean to be glib, there are certainly other factors, but as a first order approximation obesity rates of a region or country are going to be proportional to how easy calories are to access, followed by how satiating those calories are reply astrange 19 hours agorootparentJapan and Colorado have just as much access to cheap calories as Louisiana, but notably less obesity. Also, obesity rates have increased faster than access to calories has; it's a surprisingly recent problem. reply derektank 19 hours agorootparentEven in the eighties, household spending on food was nearly 50% higher relative to overall consumption than today.[0] Japanese households today actually spend 16%(!) of their household income on food, compared to only 7% in the US.[1] Obviously there are multiple factors, as I said I think the relative satiety of food also plays a role. US food spending has been more or less static over the last two decades while obesity rates have continued to climb so cost can't explain everything (though as an aside, I do think lower costs probably take some time to have an effect). But even if there are multiple factors at play, cost really should not be discounted as a huge driver, especially if we're taking a public health approach to addressing the problem. If we just attribute obesity to individual moral failings, as some are wont to do, I think we're really doing a disservice to ourselves [0] https://www.cepr.net/in-the-good-old-days-one-fourth-of-inco... [1] https://www.cia.gov/the-world-factbook/field/average-househo... reply jmward01 22 hours agorootparentprev'problem' is a loaded word. The data is coming in saying that this class of drugs provides potentially massive benefits. If I get a lot of benefit but didn't fully address the root 'problem', I still get a lot of benefit. reply akira2501 22 hours agorootparentAs long as the supply chain correctly functions for the entire time you plan on being on the drug. reply prepend 22 hours agorootparentYes, obviously. As long as the drug is available and the earth exists, etc etc Therapies are contingent on being available. That’s uniform. What’s unique about glp-1s is that they are very effective in weight loss and many other things. As compared to alternatives that aren’t. reply pixl97 21 hours agorootparentprevOne, going off GLP-1 for all I know doesn't have bad side effects, other than going back to your bad diet. If we are back at the point of supply chain issues that interrupt GLP-1 for any significant amount of time you're starting to look at issues like we had during covid that are going to have all kinds of other effects. From my understanding getting the pre-compounded components isn't that difficult, and that India and China are making versions of it now. reply drowsspa 22 hours agorootparentprevObesity rates consistently increase as people get more access to calories. reply smith7018 21 hours agorootparentYes, but that’s an incomplete view on the obesity epidemic in the West, imo. It’s not just that there’s “more access to calories,” it’s that access to healthy foods is getting more difficult for a large portion of the population. People working multiple jobs don’t have time to cook a complete, nutritious meal. Also, due to our ever-increasing wealth inequality, it’s harder for people to afford healthy food. A whole chicken, a vegetable, and a starch will always cost more than getting something at Wendy’s. Similarly, a jar of jelly is cheaper and lasts longer than a box of strawberries. reply drowsspa 21 hours agorootparentI'm Brazilian, but whether you consider Latin America western or western-adjacent, here healthy food is definitely not cheaper than processed food at all. Yet, you can see populations and regions dropping from food insecurity directly into obesity as soon as people do have access to more food. The time argument might be relevant, but even then, most Brazilians do have cheap and easy access to a very healthy lunch in restaurants or to-go meals, purchased or prepared, with rice, beans, meat, salad... The breakfast is probably bread, but I'd say most people don't eat a lot of that in the morning. Getting proper nutrition at night will probably be problematic, but it's also a smaller window... But, like I said, processed food is quite expensive here. For instance, a 1 kg of chicken breast goes by less than a third the price of a McDonald's combo. A pack of cookies or snacks will be like double the price of a 1 kg of bananas... reply smith7018 6 hours agorootparentI can only speak for my culture so thank you for the perspective and insights on yours. Just checked and it seems like bananas are 27.5% cheaper in Brazil than America. Chicken fillets are a shocking 71% cheaper! I'm sure I'm not taking a lot of things into account here like the average income levels, but still, that's crazy. reply throwaway2037 17 hours agorootparentprevHow do you explain why Japanese and Koreans are so thin? There is so little obesity in those countries. For most other countries, I agree. reply kelseyfrog 22 hours agorootparentprevThis is like saying that driving doesn't work because people still walk and the real problem is transportation. It simply doesn't matter. It's not an argument. reply akira2501 22 hours agorootparentI'm pointing out the problems of considering this a valid on term \"solution.\" It's simply not. You need a plan to eventually be rid of this compromise. That GLP-1 has benefits is good. That we could possibly rearrange our food system so we don't need it anymore is better. You can acknowledge both without hurting _anyone_. You entirely lack an argument. reply pixl97 22 hours agorootparent>That we could possibly rearrange our food system so we don't need it anymore is better. Ya so you want to change a system that involves millions of selfish actors and corporations looking to profit and that have entrenched themselves, and are protected by freedom of association versus a choice between a doctor and a patient. I can tell you which one will be more successful. reply kelseyfrog 21 hours agorootparentprevThis is a textbook case of letting better stand in the way of good. I'd love to re-imagine our food of food production and consumption, but it sounds like you're arguing that because food production and consumption is a better solution, we shouldn't be promoting GLP-1 agonists. Sorry, but one is exists in reality and the other exists in our imaginations. When we let our imaginations take precedence over reality, we live in a fantasy and the consequence is that we get neither. Effectively this argues for neither, and that's a bad deal for everyone. reply kbos87 21 hours agorootparent\"The [food system] can remain irrational longer than you can remain [alive].\" reply kaibee 21 hours agorootparentprev> It's simply not. You need a plan to eventually be rid of this compromise. because..? > That we could possibly rearrange our food system so we don't need it anymore is better. Will this be before or after we fix capitalism/finish building communism? reply SpicyLemonZest 22 hours agorootparentprevI don't understand your point. Many common medications - ibuprofen, albuterol, insulin injections - function entirely by hiding symptoms of an underlying problem. If the symptoms being hidden are worse than the side effects of the medication, what's the concern? reply bigstrat2003 21 hours agorootparentSolving symptoms and not root causes is how you get band-aid fixes that wind up being inadequate to the task in the end. I would've thought everyone here would be aware of the danger of treating symptoms rather than the underlying issues, given it's such a common pitfall in the computer field. reply moron4hire 21 hours agorootparentI think if you reflect on the purpose of a bandaid a little bit, you would come to understand why your own analogy is bad. reply SpicyLemonZest 21 hours agorootparentprevAgain, I genuinely don't understand the point. There's a large and well-funded segment of the nutrition industry dedicated to solving the root causes - Weight Watchers alone has over a billion dollars in annual revenue. We just haven't invented a diet-based solution which works as well as GLP-1 agonists without requiring you to compromise on palatability and feel hungry all day. It'll be great if we do, although I don't know of any promising research avenues and I lean towards the hypothesis that the average human metabolism is simply tuned to mild obesity under conditions of widespread food availability. reply UglyToad 21 hours agorootparentThe point, which seems to be routinely massively downvoted on here, is that both things can be true at once: - these drugs are good and a paradigm shift in the treatment of obesity (and have other benefits) - we must not lose sight of the need to address a thoroughly sick food industry that necessitate so many people needing to use these. Junk food advertising, lack of subsidies for fresh vegetables, HFCS, food deserts, etc. Chile is experimenting with banning junk food ads to children and is seeing some early behaviour changes. The point which people seem to be wilfully missing is that we can have both these drugs and advocate for cracking down on a food system that deliberately poisons everyone in society. Having everyone be on this drug because we shrug and say \"free market innit\" while big corps continue to feed us crap is not a solution, obviously. reply Sakos 20 hours agorootparent\"Fixing\" the food industry isn't possible for as long as they have billions to sink into influencing politics. Trying to find a market or political solution has failed. Full stop. The fact that you're still trying to find some way to make it work is embarrassing and depressing. It's time to attack the problem from another direction, one that will also ensure these companies either go bankrupt, lose relevance and power and/or evolve into a form that's less parasitic and more beneficial to us as a species. GLP-1 can be one tool to help us do that. reply SpicyLemonZest 19 hours agorootparentprevWe can only crack down on a \"food system that deliberately poisons everyone in society\" if such a system actually exists. * Food deserts are a problem, but the vast majority of Americans don't live in one. We just don't typically want to eat a pile of fresh veggies when there's other options available. * Criticisms of HFCS are, as far as I can tell, entirely viral misinformation - not once have I seen someone point to concrete evidence that HCFS is worse than table sugar. It seems to me that this entire idea of a poisonous food system is an epicycle to avoid the obvious conclusion, that our bodies are calibrated on average to eat ourselves into obesity when we have the means to do so. If you don't start from the premise that there must be an external reason we're getting heavier, it's very hard to explain why potato chips should be any more unhealthy than a traditional breakfast of potatoes and bacon. reply astrange 19 hours agorootparentIIRC food deserts are a demand issue, not supply. The reason healthy food doesn't exist in those neighborhoods is because it closed because people didn't go there. reply SpicyLemonZest 19 hours agorootparentI've heard that too, but even if true it's still a problem for the minority of people in the area who would have liked to get fresh veggies and such. reply jpadkins 22 hours agoprevI haven't seen any comments on the topic of chronic inflammation. I am not knowledgeable on this topic, but we do know that chronic inflammation is linked to a huge number of disease end points. GLP-1 may be reducing (or preventing) systemic inflammation. https://en.wikipedia.org/wiki/Systemic_inflammation reply devit 22 hours agoprevWhat about people who, with their current habits, are on the bottom range of what is considered \"normal\" weight (in the BMI sense) or already underweight? Wouldn't taking GLP-1 agonists (for potential non-weight-loss benefits) be potentially harmful as it may reduce eating even further and lead to being significantly underweight? reply kubectl_h 22 hours agoparent> Wouldn't taking GLP-1 (for potential non-weight-loss benefits) be potentially harmful as it may reduce eating even further and lead to being significantly underweight? Almost certainly at the weight loss dosages people are taking now, but semaglutide (at least) can be tuned up and down for effect. Time will tell what kind of dosage is required for these non-weight-loss benefits. That said, I think it's more important to focus on how this drug works -- it works in the brain and in specific areas of the brain that we now know are important for weight loss/addiction/inflammation(?) (because of these emergent miracle drug effect). It doesn't seem outside the realm of possibility that drug companies will be able to target these systems with more finesse in the future as opposed to superdosing engineered stable GLP-1 molecules that flood the system. It is the future understanding of what this drug does that is the real promise for all people -- we are just in the early stages of understanding what we've found. reply loeg 22 hours agoparentprevSure, it would probably not be helpful to give these people medical anorexia unless there was some huge, huge, more-than-offsetting other benefit. (Less than 2% of the US population is considered underweight by BMI: https://www.kff.org/other/state-indicator/distribution-of-bo... . ) reply leetnewb 22 hours agoparentprevObviously subject to conversation with their doctor, but my endocrinologist suggested against this class of drugs for blood sugar control. reply riwsky 22 hours agoparentprevThey just need to take GLP+1, instead. reply throwup238 22 hours agorootparentIt's the number one recommended supplement by the American Society for Cannibals. The flavor is in the fat! reply nonameiguess 22 hours agoparentprevIf it really is inflammation, exercise targets that just as well, and also acts as a miracle drug that seems to reduce the risk of just about everything, somewhat paradoxically even orthopedic injuries over a long enough timescale (because you stave off age-related muscle and bone mineral loss). But that puts us back in the \"telling people to exercise doesn't cause them to actually do it\" at the public health level. For you yourself, you can simply live a less risky, healthier life. For all yous, probably we need something like a once-weekly pill or injection that doesn't require drastic habit changes. For all of society on a forever timescale, of course, we can ignore the fact that adults won't change their ways and focus on instilling lifelong athlete habits in kids. Doesn't seem to be the direction we're going in, though. reply pixl97 21 hours agorootparentThings like GLP-1 can give a near immediate bodily response that can lead to people starting to work out. When you have inflammation issues I can promise the last thing you want to do is put stress on your body from working out. Especially when most people don't know how to do it properly. reply explodingman 18 hours agoprevLove that word \"pleiotropic\", nice vocab builder. So it looks like GLP-1 may have positive side-effects beyond what can be explained as consequences of weight loss. Surprising linkages between biochemistry/hormones and temperament. I am slowly (1 kilogram per month) losing weight by eating nothing but meat 2-3 days per week. My understanding is that the extra GLP-1 secreted by the gut when digesting lots of protein leads to appetite suppression. It works, and is surprisingly easy to do (no feelings of hunger). So will I also be getting the beneficial side effects of GLP-1? If so, high-protein dieting becomes the smart way to lose weight. reply avelis 20 hours agoprev> FTA: So we're not only going to be treating (or outright preventing) a number of diseases, we're going to be learning more about the cause of these diseases than we ever did before. Ultra processed foods (UPF) needs a hard look IMO. It's the leading cause of many diseases stated in the article and several others including cancer and dementia. reply levocardia 23 hours agoprevColor me a bit skeptical on the \"GLP-1 is the cure for everything\" hype. These drugs are clearly a game-changer for obesity and T2D, and possibly a few other conditions, but it strikes me as unlikely that a chemical exists that is more or less an across-the-board improvement to health, with no downsides. If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Or modify GLP-1 itself? The best argument against is \"starvation was a human universal\" and that survival through famines totally dominated the evolutionary trend in GLP-1 related things in the body. But even something as simple as lactose tolerance responded quite quickly to changes in human dietary structure in different areas of the world. My suspicion is that at least some of these medical record review studies are just driven by confounding - people who find out about GLP-1 agonists are better educated, wealthier, or have behavioral/lifestyle traits that explain many of the apparent benefits. (still, part of me is still holding out for the \"miracle drug\" explanation) reply ben_w 23 hours agoparent> If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Or modify GLP-1 itself? Because evolutionary fitness doesn't care about what we care about, and even if it did it operates so slowly it hasn't yet finished adapting to us having invented cooking. That said, I share your skepticism. This kind of story feels almost exactly like the old Victorian (literal) snake oil advertising: https://commons.m.wikimedia.org/wiki/File:Clark_Stanley%27s_... reply corry 22 hours agorootparentTrue, but (a) maybe it would evolve \"naturally\" given enough time, and (b) the things that humans create are a product of evolution too, no? Albeit not directly through the mechanism of natural selection. reply kaibee 21 hours agorootparent> True, but (a) maybe it would evolve \"naturally\" given enough time, You could say the same for myopia. But we still make glasses for people, which breaks the natural selection process that would drive that evolution. reply dleary 22 hours agoparentprevThe obesity epidemic is only 50 years old. GLP-1 seems to be a “thing that fixes your satiety balance”, that is applying to more than just food, but maybe also help you regulate yourself when you have way too much access to alcohol, drugs, etc. In short: the reason that the human body wouldn’t have evolved to make more GLP-1 automatically yet is because evolution causes populations of organisms (not individuals) to change, over generations, to be better suited to their environment. And 50-100 years is nothing in terms of evolution. We spent 500k years evolving to optimize gathering every calorie we can. And then yesterday it turned out that maybe it is in fact possible to have too much. Also, the human body does make some GLP-1 itself. Maybe it was just getting started. reply majormajor 23 hours agoparentprev> If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Because we haven't had the infinite years required to \"just evolve\" every possible bodily improvement? I don't know if it's an ideal wonder drug or also has downsides we haven't found yet or some of the positives are misinterpreted but if \"why didn't we just evolve it\" was meaningful it could be an argument against ANYTHING being good in the way presented. reply manmal 22 hours agorootparentTo be fair, we don’t need infinite years/generations to select for favorable traits. Such a selection process might already be underway - obesity lowers fertility, so there is pressure towards not being obese. IMO the next generation will already be either slightly reducing their intake, or increase their expenditure of calories. There‘s many ways to do that - becoming taller, more restless, less hungry, decreasing intestinal uptake, reduced enjoyment of food (loss of taste/smell) etc reply pixl97 20 hours agorootparentFertility is one of those things that's dropped faster than obesity has increased in most places and will have a much greater impact on future generations. reply modeless 22 hours agoparentprev> If it was that simple, why didn't the human body just evolve That's easy to answer. We exist today in a very different environment to that we evolved in. It makes perfect sense that there could be a hormone that wouldn't provide a net reproductive benefit to hunter-gatherers or subsistence farmers but provides an immense health benefit to sedentary humans eating unlimited food. In fact, it would be surprising if there wasn't. reply jstanley 22 hours agoparentprev> If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Or modify GLP-1 itself? Replace \"GLP-1\" with any of: aircraft, computers, buildings, WiFi, ... Some things are easy for nature to find and some things aren't! And even of the things that are easy for nature to find, and that we would have found useful even in the environment of evolutionary adaptation, they might not confer overall fitness if they are too costly. reply criddell 22 hours agorootparentWell said. Diseases that affect the elderly don’t get a lot of consideration from nature. Natural selection really only cares about us reproducing. On top of all that, our current environment and diet are quite a bit different from the norm over the past few million years. reply TechDebtDevin 22 hours agoparentprevGo to the glp-1 related Subreddits and you'll see they aren't all wealthy educated people. Hell I read a story of a girl on the Manjaro subreddit who couldn't get her meds and ate herself into the ER in two days. My sister takes Ozempic and is the proto-typical obese white girl with way too many kids she can't afford and only eats trash. It probably saved her life. reply rictic 22 hours agoparentprevI'm putting increasing probability on the idea that there's something in our modern environment that's disrupting the GLP-1 metabolism (or a related system), these drugs are counteracting that effect. When it was just appetite suppression, that made sense, we're not adapted to a modern degree of plenty. Not sure that explains the other positive effects, if these results reproduce. reply nick__m 22 hours agorootparentMy bet is on the HFCS in the processed food. reply pixl97 20 hours agorootparentLook at all countries that are having rapid increases in obesity and see how many use HFCS to see if you're on the right track. reply manmal 22 hours agoparentprevThe lactose adaption took a couple thousand years to develop, no? While the last famines in developed countries took place less than 100 years ago. Feeling less hungry does feel like an elegant solution to the blatant oversupply humans are facing now. reply timr 22 hours agoparentprev> My suspicion is that at least some of these medical record review studies are just driven by confounding - people who find out about GLP-1 agonists are better educated, wealthier, or have behavioral/lifestyle traits that explain many of the apparent benefits. This exactly. There was a recent paper about Ozempic and (IIRC) dementia that saw that the drug acted implausibly quickly to prevent illness -- the Kaplan Meier curves were literally separated at day 0. [1] Confounding is rampant in this area. The people who published the paper I linked below should not be scientists. It's embarrassing. Anyone who cites it in support of Ozempec as a miracle drug has revealed that they don't know what they're doing, and should be ignored, with prejudice [2]. More generally, it's depressing that so many people are piling on here to tell you that you're wrong, based on little more than their \"knowledge\" that obesity is bad. The fact is that most of the science around GLP-1 agnoists and anything other than obesity is weak, to say the least. [1] I believe it was this paper. Certainly, the KM curves in this are ridiculous: https://alz-journals.onlinelibrary.wiley.com/doi/10.1002/alz... [2] Sadly, this appears to include the \"Alzheimer's Association\"...though you sort of understand why they're biased in favor of miracles. EDIT: I am just now realizing that Derek Lowe is citing this paper. Oy vey. reply MarkusQ 22 hours agorootparentThose graphs are incredible. Literally. As in impossible to credit. What sort of other things would we have to conclude if we took them seriously? Insulin causes AD, starting the day you get the prescription? The mind (assuming it's turned on and operating) boggles. reply timr 21 hours agorootparentOne of the disappointing things in my life has been the discovery of how much \"medical science\" is based on statistical illiteracy. reply danielmarkbruce 21 hours agorootparentdrop the \"medical\", it's cleaner. reply zosima 22 hours agoparentprevGLP-1 of course is the GLP-1 agonist created by the body. I don't think that humans eat to obesity by default. People have had adequate food for quite long and not grown fat. Maybe there is something in out environment or our foods that are blocking the GLP-1 receptor? If a modern food company discovered something like that they'd immediately realize that (unintentionally) they sell better, probably without realizing what they had created. reply eropple 22 hours agorootparent> People have had adequate food for quite long and not grown fat. That's revisionist, both in terms of \"for quite long\" (food insecurity was common in America until about World War II, and massive food surplus available at consumer-cheap prices begins a little later; other countries still suffer from food insecurity today) and that people haven't grown fat when able to do so. Being wealthy enough to the point of being able to be fat has been A Thing for a thousand years. We know this because the medieval Catholic Church felt that they had to preach moderation; if they had to preach it, it's because it wasn't happening as a universality. reply matthewdgreen 22 hours agorootparentprevA good amount of GLP-1 is made in the intestines, and production is heavily affected by interactions between those cells and gut bacteria. So anything that caused dysbiosis of the gut microbiome could potentially be causing problems with natural GLP-1 emissions, e.g., antibiotics in the food supply, emulsifiers, etc. reply drowsspa 22 hours agorootparentprevNot really. Being fat was a sign of being rich back then, because only rich people could even have enough surplus calories to get fat. reply hbosch 20 hours agoparentprev>an across-the-board improvement to health Obesity is itself an across-the-board impairment to health. Anything with a positive impact on obesity will be, therefore, an across-the-board improvement to health. reply jvanderbot 22 hours agoparentprevWhy didn't evolution make us smart enough to not overeat? reply herval 22 hours agorootparentThere’s no evolutionary benefit to eating as little as possible any time in human history, other than the past few decades. We’re barely into the third generation where calory overconsumption is an issue. It takes a few hundreds of thousands more to evolve something this complex, with a population as global as ours reply nkozyra 22 hours agorootparent> There’s no evolutionary benefit to eating as little as possible any time in human history In multiple organisms we see that under-eating and fasting extends lifespan, so I'm not sure that's the case. https://www.nature.com/articles/s41392-022-01163-z https://www.science.org/content/article/why-eating-less-mean... https://www.nature.com/articles/d41586-024-03277-6 reply herval 22 hours agorootparentHumans (and other mammals) starve to death way more often than died of calorie overconsumption, since the first little mammal climbed a tree reply nkozyra 20 hours agorootparentEating at little as possible means enough to live, though. That's what the \"as possible\" means, otherwise it would be \"not eating\" reply herval 19 hours agorootparentAnd then you store the rest of the food cache you found… where again? A prehistoric fridge? Oh wait that’s called fat cells, one of the best evolutionary advancements ever! Overeating really pays off. reply nkozyra 19 hours agorootparentI'm not really sure what you're arguing, because the initial claim was there's no evolutionary benefit to undereating. Yes you can store visceral fat and I'm not arguing there isn't a benefit for that, just that there's a clear benefit for undereating as well. reply herval 8 hours agorootparentNo evolutionary benefit. reply nkozyra 5 hours agorootparentBut there's a demonstrable one - a longer lifespan. In most animals (including mammals) a longer lifespan gives more time for reproduction. reply scheme271 22 hours agorootparentprevYeah but lifespan benefits usually come after the animal has had a lot of chances to have offspring. Also undereating is much more likely to kill you in times of famine. reply jvanderbot 21 hours agorootparentprevThis was a rhetorical question. reply herval 19 hours agorootparentNot to everyone, clearly reply thierrydamiba 23 hours agoparentprevIs it addictive at all? reply SomeHacker44 23 hours agorootparentIn the sense that you need a constantly increasing amount to maintain the same results: yes. reply chrisoconnell 22 hours agorootparentI think it's important to call out that it's actually constantly increasing amount to increase the results. As patients lose weight, they need to eat fewer and fewer calories to continue to lose weight, as the BMR decreases. This isn't because of the medication, but rather because it requires fewer calories to maintain their mass, so they burn fewer calories at rest. Increasing the dose further decreases hunger signals, which further decreases their desire to eat as much. It's not \"increasing to maintain the same results\" its \"increasing to increase results\". Ex. Patient A currently weighs 330lbs. Has a BMR of 3300 Calories. - Initial dose, they eat 2,800 calories a day instead of 3,500 calories they used to. - Loses weight. Now weighs 250lbs. - BMR is roughly now weighs 250lbs, and has a BMR of roughly 2500 calories, but dose still has them eating around 2,800 calories. - Dose is increased, patient is now eating around 2,000 calories. - Patient A reaches 200lbs, BMR is roughly 1,800 calories, but is still eating 2,000 calories. - Dose is increased, Patient A is now eating 1600 calories. reply hcazz 23 hours agorootparentprevThat's incorrect. It's a titrated drug similar to blood pressure meds. If you have effectiveness at a 1mg dose for example, you stay at that. The drugs have maximum doses. reply xk_id 19 hours agoparentprev> If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Have you read the submission before writing your comment? An answer to this question is given in one of the few short paragraphs. reply eli_gottlieb 22 hours agoparentprev>If it was that simple, why didn't the human body just evolve to excrete GLP-1 agonists? Or modify GLP-1 itself? Honestly? I'm not much of a physiologist, but based on the effects regarding addictions like tobacco or narcotics that cannot be causally downstream just of diet, I'd wonder if GLP-1 agonists aren't actually impacting stress-interoception systems rather than just hunger and metabolism. Under that hypothesis, the evolutionary reason would be: because we evolved to undergo stress mostly in physically strenuous, energy-burning situations, while high loads of cognitive and emotional stress without physical effort are a novelty to post-industrial lifestyles. reply breck 22 hours agoparentprevnext [4 more] [flagged] type_enthusiast 22 hours agorootparentOf course, saying \"fat people should simply eat less\" is by no means novel. It's the same as \"have you tried _not_ being addicted to [drug]?\" or \"Why doesn't he just [obvious but impossible action]? Is he stupid?\" For some people, \"eat less\" is easier said than done. Their body, for whatever reason, makes them suffer when they don't eat. Maybe it's easy – or hard, but possible – for you, and that's great. But don't assume that simply because you've never experienced it as impossible, doesn't mean others don't (or that they simply lack some kind of strength that you possess). If anything, the effectiveness of this medicine appears to demonstrate that – much like other \"chemical imbalances\" such as ADHD or depression – obesity might be a symptom of biology that simply doesn't make enough of a certain chemical, or makes too much of another. Also, I see you posting your website link on a bunch of threads. I read it. This isn't the place for a discussion about it, but I do want to point out a major rhetorical flaw: you appear to assume that _no_ patented invention is _ever_ actually useful. I think this nullifies most of your argument, because it's demonstrably untrue. reply breck 18 hours agorootparent> much like other \"chemical imbalances\" such as ADHD or depression Interesting that the examples you bring up are also things that turned out to be misunderstood and were not actually chemical imbalances. > you appear to assume Where do I appear to assume this? reply SpicyLemonZest 22 hours agorootparentprevMost people ate quite poorly before the 1800s, routinely suffering from various nutrient deficiencies depending on what the local staple food lacked. The few people who were rich enough to get abundant food could and did become obese. reply cschmidt 22 hours agoprevThis exact line of reasoning is the cover story on the Economist this week: Briefing: https://www.economist.com/briefing/2024/10/24/glp-1s-like-oz... Leader (opinion piece): https://www.economist.com/leaders/2024/10/24/its-not-just-ob... (sorry, paywalled) reply toomuchtodo 22 hours agoparenthttps://archive.today/D06ZN https://archive.today/YgiWx reply RachelF 21 hours agoparentprevThis can also be viewed as advertising - there are board members in common between The Economist's holding company and Novo N. reply mentos 23 hours agoprevIsn’t this just eating less food is good for everything? reply didgeoridoo 23 hours agoparentEating less food and keeping your body from knowing it seems to be a big part of why it works. On GLP-1 agonists, you don’t get nearly the counterbalancing reduction in energy expenditure you usually see with caloric restriction. Your body keeps happily releasing lipid stores, assuming they will be replenished, but they aren’t. Hunger hormones remain untriggered, cortisol stays low, and insulin keeps shuttling glucose into cells to be burned. If you aren’t metabolically deranged, your body does this anyway. But many people have totally decompensated metabolically due to excess energy intake over time, and essentially cannot recover without some kind of treatment. GLP-1 is just the beginning — future compounds will do a better job maintaining muscle mass, for example. But this is looking like an absolute miracle, and once patent protection ends (especially for oral formulations), we’re going to be living in a very different world health-wise. reply schnebbau 21 hours agorootparentLosing muscle mass is just what happens when you're in a calorie deficit. The same thing happens if you're in a calorie deficit without the aid of a GLP-1. Making sure each meal contains substantial protein will help negate this. reply didgeoridoo 20 hours agorootparentRight, it’s not something specific to GLP-1 treatment, but there are myostatin and activin A modulators under investigation to specifically counteract muscle loss related to caloric deficit more generally. reply scheme271 22 hours agorootparentprevPatent protection for the early versions has already ended. Teva is making generic versions of liraglutide and it's been available in the US for a few months. The other GLP-1 agonists will be protected for a few more years though. reply didgeoridoo 20 hours agorootparentTrue but imagine the price and availability impact when the oral formulations go off-patent. The autoinjectors are inherently expensive to make and ship, and some people have a needle phobia. Oral daily seems like the endgame here. reply outworlder 21 hours agorootparentprev> On GLP-1 agonists, you don’t get nearly the counterbalancing reduction in energy expenditure you usually see with caloric restriction And that's mostly related to how much you move. If the body needs to reduce energy expenditure, there isn't much it can cut that's non essential that will make a difference, other than activity and movement in general. So you feel like laying on the couch all day. I haven't tried GLP-1 myself, but reports seem to indicate that GLP-1 drugs make you feel _tired_, which is basically the same thing. So I am not sure the body is fooled that easily. > many people have totally decompensated metabolically Around 88% of americans have some level of metabolic dysfunction so that tracks. Numbers worldwide are trending up. > and essentially cannot recover without some kind of treatment. They can. Going back to a healthy food intake will fix anything that's not permanently damaged(and if it is permanently damaged, there isn't much medicine can do either). That can be sped up with other measures, such as fasting. I am a bit skeptical of trying to fix a problem that was mostly created by the food industry with medication. GLP-1 isn't without side effects. Cutting sugars and simple carbs in general has very similar effects and will decrease your hunger hormones as well. I think everybody should try that first before relying on medical interventions. Besides, carbs tend to make you retain a lot of liquid. Drastically cutting them usually improves fluid retention, people see changes pretty quickly in the scale, and that can motivate them to continue. Do that long enough and even eating habits will change and so will your palate. A soda becomes unbearable. reply pixl97 21 hours agorootparent>but reports seem to indicate that GLP-1 drugs make you feel _tired_, I know a few people that take one of the name brands, and they really don't complain about this issue. What they do talk about is having more energy after dropping weight because they just don't feel compelled to eat much anymore. I'm not overweight myself, but I am a Type 1 diabetic from a young age. \"Sugar noise\" is not something that is easy to ignore. Especially in the case where you have excess insulin in your bloodstream but not active enough for your body to use it. Your body will scream at you to eat something sweet/carby. In people that are overweight this can be caused by insulin resistance. Until you experience it, it's really easy to say \"People should try\", but it's about as easy as telling someone to drop meth or heroin. reply babyoil 20 hours agorootparentI am overweight. That food and sugar noise thing is real and brutal. Your parent comment should really factor that in the discussion. I know it's hard because (fortunately) they may not have experienced this themselves, but it's horrible. My body SCREAMS for me to eat something sweet/carby all fucking day long. All day. Never realized the extent of it until using GLP-1s. I tried many things: full strict diets with macro counting, IF, more lenient and \"natural-feeling\" diets where you just try to eat whole foods that are filling and tasty. With or without weight lifting, sometimes cardio. Yeah they work, big surprise! But the entire time you are fighting against that urge, doesn't matter if you've gone a full month with perfect \"discipline\". Eventually it gets you. And I was miserable the entire time trying _not_ to think about food. This is life changing. reply chpatrick 20 hours agorootparentprevAs public health policy though, just telling people to do the things you describe doesn't work because dieting sucks and your body doesn't want you to do it. Some people can do it but they're usually not among the huge percentage of obese people in the population. With GLP-1 agonists it doesn't even feel like you're fighting your body because you just automatically don't want to eat too much (just like people who don't have problems managing their weight). I think it's basically a good thing that modern day civilization has cheap and available calories because no one has to go hungry, but this is an environment that evolution just hasn't prepared us for and many many people are just not calibrated right for it. Maybe we can finally fix that. reply jasongill 20 hours agorootparentprevI've been taking Ozempic or Zepbound for a couple months as a personal experiment and the effects have been nothing short of life-changing. I have been somewhat of a \"casual bio hacker\" for the past 25 years and have done things like quitting alcohol or caffeine cold turkey and staying off it for years, or tracking every calorie I ate for 10+ years. I've had periods of eating really healthy, I've had periods of eating whatever but staying in calorie deficit, I've had periods of just not eating much at all, I've had periods of eating anything and not caring. I've tried a variety of more extreme body modifications just to try it and note the results. I find messing with the body (or food intake or whatever) to be like trying to reverse engineer an unknown binary, or like trying to write a keygen but for your mood and health. It's been a little hobby of mine for a long time. These medications are WAY different. There is no way to describe it. You just feel... better, in almost every way. As someone once posted on another thread, their relationship with food changed. I noticed my relationship with food changed as did my relationship with other minor vices; my \"screen time\" is down. My anxiety is almost entirely gone, my mood is better, and I feel like I sleep better. Even as the weight loss rate decreased (which was dramatic at first but has mostly stopped as I didn't increase my dosage of the medications to see what would happen), I just feel... better. No amount of eating better or healthy lifestyle that I've tried (and documented) in the past two decades has produced anything nearly as profound as the impact that Ozempic has, both on my mental and physical health. Which seems crazy, and I thought that people who were crowing about an off-label diabetes drug were crazy as you probably think I am. But I agree with these types of articles - GLP-1 drugs are just the first step in some kind of next step in health, and obviously right now the focus is on \"lose weight, undo the damage of processed foods!\" but I think we are going to find that GLP-1's are just the first of many new discoveries that could extend or improve our lives beyond the aesthetic reasons that people take them today. Regarding side effects, I have a lot of people ask me or comment about this. I think just like any drug, you only hear about the people with bad side effects. 8% of American adults are taking a GLP-1 drug right now, yet CVS Pharmacy doesn't have a section dedicated to managing the side effects (but they do for opioid side effects like constipation), which would be my gauge as to how it's really going. I did have some dehydration (far less than something like scopolamine gives me) on the first couple days after my first self injection, but increasing my water and electrolyte intake fixed that and it seems to have gone away (I've even tried lowering my water and electrolyte intake and it didn't come back). I am not more tired, nor do I have more (or fewer) digestive issues than before. I think people who do have increased digestive issues have just never experienced (or not recently) what happens when you are really full and just overeat, because their bodies are so used to higher calorie or sugar consumption. Just like how Thanksgiving dinner can make you tired or make you have to wait in the family line for the bathroom, I suspect that GLP-1's are causing some people's \"normal\" meals to feel to their body like a \"Thanksgiving dinner\" because they effectively are (by comparison). I have noticed some slight muscle loss in my non-dominant arm that is of mild concern but nothing that I am worried about at this time. This is anecdotal yes and it's just my personal account of these medications but I was skeptical until I tried them, like you are, as I thought \"oh, just eat healthy, why needs a shot\". I will update this post when it's determined that GLP-1's cause some crazy or horrible disease but for now I am enjoying this experiment with them. reply stavros 21 hours agorootparentprev> But this is looking like an absolute miracle What are you referring to here? The muscle-preserving medication? Are GLP-1s actively reducing your muscle mass, or is it the fact that people on them ate very little and didn't tend to exercise? reply arijo 23 hours agorootparentprevAssuming you're going to fix a extremely complex system like the human body by just taking a pill is what some people call the bias of Illusion of Control. https://en.wikipedia.org/wiki/Illusion_of_control reply didgeoridoo 23 hours agorootparentYou’re going to have to be more specific, because I am sure you are not arguing against the concept of medicine. reply breck 22 hours agorootparentnext [4 more] [flagged] malfist 22 hours agorootparentTry telling a type 1 diabetic patient to eat like it's the 1800s reply breck 19 hours agorootparent> a type 1 diabetic patient Are you sure there is such a thing? reply malfist 4 hours agorootparentYes. reply arijo 22 hours agorootparentprevI argue that medicine still does not have enough accumulated knowledge about the complexity of the human body to be playing God with a single pill. reply herval 22 hours agorootparentYou don’t believe the medicine that billions of people take to treat diseases that would’ve otherwise demonstrably killed them is “accumulated knowledge” enough? From insulin to antibiotics, we have sufficient evidence that many types of medicine DO work. Nobody is “playing god” (whatever that means), it’s just reproducible and consistent data reply cyberax 22 hours agorootparentprevThere is no god. So I argue that medicine is at least just as potent as nothing. reply kelseyfrog 22 hours agorootparentprevYou may begin your argument now reply kadoban 22 hours agorootparentprevAny single pill? Or is your objection specific to this one? (That iirc is actually an injection, not a pill, but w/e) reply okaram 22 hours agorootparentprevMaybe ... maybe not. Modern medicine does have magic pills for many illnesses; for example, antibiotics are magical for many bacterial infections, many vaccines are almost magical too. OTOH, many pills will have undesired side-effects, and the body is in a complex dynamic equilibrium, so it may happen that blocking GLP-1 may have side effects. Eventually, we'll all die, but I'm optimistic that GLP-1 will lead to a better equilibrium. Preliminary evidence says it will. I'm not as confident as the author though :) reply emptiestplace 22 hours agorootparentprevYou're right, but the way you're going about it isn't. reply kadoban 22 hours agorootparentprevAre diabetics biased in this way when they take insulin? Or where is your cutoff? How many average person years does an intervention need to save before it meets your approval? reply akira2501 22 hours agorootparentUntreated diabetics can die within a week. Are we facing the same sort of problem here? reply kadoban 22 hours agorootparentNo, but same thing with different numbers. Like I asked, where's our cutoff? If obesity on average kills you a couple of decades earlier than otherwise, does treatment for that meet your approval? reply akira2501 22 hours agorootparent> No, but same thing They're either the same or they're different. > Like I asked, where's our cutoff? Exigency of loss of life. > kills you a couple of decades earlier Staying obese into old age carries risks. There are multiple ways to manage that risk. None of it is as exigent as other conditions. > does treatment for that meet your approval? Universally? No. reply kadoban 22 hours agorootparent>> Like I asked, where's our cutoff? > Exigency of loss of life. Cool. How about cancer treatment? Some of those you can live with for some months/years. We allowed to treat anyway when the outcomes are better? > Staying obese into old age carries risks. There are multiple ways to manage that risk. None of it is as exigent as other conditions. And why should this not be one of the ways to manage that risk? The biggest difference seems to be that it actually works, on average, unlike some other common treatments like telling people to eat less and exercise more. reply david-gpu 23 hours agoparentprevDoes eating less food reduce addiction to tobacco, alcohol and other substances? Because there is mounting (but not conclusive) evidence that GLP-1 agonists do just that. reply phil21 23 hours agorootparentSample of only a half dozen people close enough to me to talk intimately about it - but for drinking it’s been absolutely proven in my mind for some people. I have one friend in particular who started a GLP-1 drug solely to assist in drinking less - she certainly does not need to lose any weight. It worked like a light switch for her and turned moderately problematic drinking into easily achieved light social drinking. No impact on appetite since she is on a very low dose. I have had the same experience, even though I took it for weight loss to start with. I do know that drinking can be downright unpleasant for me if I push through the aversion after my first drink and try to go for a few more. I have noticed a strong correlation to drinking and my blood sugar crashing rapidly afterwards while on Tirzepatide while wearing a glucose monitor. A single cold beer on hot day with friends is still quite pleasant. Sitting in a bar for hours on end drinking heavily is simply downright uninteresting now before you get into any unpleasant side effects. reply herval 22 hours agorootparentAdd me to that sample set, I drink far, far less with it reply akira2501 22 hours agorootparentprev> turned moderately problematic drinking into easily achieved light social drinking. Is this based on your survey or her self assessment? > Sitting in a bar for hours on end drinking heavily is simply downright uninteresting Yet it used to be? You don't find this situation suspect? reply phil21 22 hours agorootparent> Is this based on your survey or her self assessment? Both? Being around her, and her self-assessment. Not sure how else one could interpret such a statement. This is all anecdotal evidence and should be taken as such. > Yet it used to be? You don't find this situation suspect? Yes, it used to be moderately interesting sometimes with the right people. Suspect in what manner? That it removes the desire to get inebriated? Perhaps so, since we do not understand the mechanism at play. What we don't know can certainly hurt us. Overall the desire to drink less seems very similar to the impact it has on appetite and hunger levels. In that way, it is not so surprising to me. reply pixl97 21 hours agorootparentprevFFS. An anecdote is one piece of data, when those pieces of data come together it provides evidence. For example we see the same behaviors in mice https://www.niaaa.nih.gov/news-events/research-update/semagl... >In the current study, the researchers demonstrated that semaglutide reduced binge-like alcohol drinking in both male and female mice, and that the effect was dose-dependent (i.e., greater amounts of semaglutide led to greater reductions in binge alcohol intake). The researchers also tested semaglutide in rats that were made dependent on alcohol through long-term exposure to alcohol vapor. They found that semaglutide reduced alcohol intake in this animal model, again with no sex differences. reply akira2501 9 hours agorootparent> An anecdote is one piece of data It is not documented, so no, it is not. Which is why I questioned if it was entirely based on self assessment or not and left the door open either way as the question was based out of curiosity and if his anecdote was public I wanted the answer to be as well. Is that not fair? > when those pieces of data come together it provides evidence. When you properly document them it literally stops being an anecdote and then becomes evidence. > The researchers also tested semaglutide in rats that were made dependent on alcohol through long-term exposure to alcohol vapor. So.. what are we actually measuring then? Isn't alcoholism a disease and not some acquired exposure based dependency? The idea that \"GLP-1 for Everything\" is even floated in this way is unusual in and of itself. I'm uncomfortable with all this and am once again annoyed at the way we use rats in research. reply Jhsto 21 hours agorootparentprevI wonder if it's about more stable glucose levels hence avoidance of cravings. Anecdotally, alcohol and nicotine cravings seem to pass me whenever I have a particularly fast acting (low osmolality) carbohydrate supplement. reply Etheryte 23 hours agoparentprevThere is no known link between how much you eat and Alzheimers, substance abuse, etc. If it was as simple as eating less makes these issues go away, we would've figured that out a long long time ago. reply arijo 23 hours agorootparentAlzheimer's is now being referred as type 3 diabetes for a reason. Human metabolism is sensitive to the type of food you eat. Check https://www.metabolicmind.org/ as a starting point and follow the rabbit hole to understand the link between what you eat and mental and metabolic illness. Also, GLP-1 also eliminates muscle - your heart is a muscle. reply phil21 23 hours agorootparentGLP-1 reduces calorie intake and puts many people on a deficit (typically on purpose). This of course will reduce muscle just like any other calorie deficit anyone runs long term. reply johnyzee 22 hours agorootparentFasting increases growth hormone release (dramatically, in the case of extended fasting), which counters muscle loss. Does this happen with GLP-1? reply phil21 22 hours agorootparentThis goes against all evidence I have seen for folks who have lost a drastic amount of weight very rapidly. Bodybuilders seem to see the same effect as well when on cuts. When you are losing 5% of your bodyweight per month (as I was, and many do) a substantial portion of that is simply going to be mean muscle mass. You can counteract some, but not all, of this by heavy resistance training. It's very difficult to not lose muscle mass while losing weight - it takes extreme measures for most folks (e.g. athletes) to do so. reply cyberax 22 hours agorootparentprev> Alzheimer's is now being referred as type 3 diabetes for a reason. No it's not. reply ZYbCRq22HbJ2y7 20 hours agorootparentSome are referring to it that way https://pmc.ncbi.nlm.nih.gov/articles/PMC2769828/#:~:text=We.... reply Etheryte 22 hours agorootparentprevWhat you eat is a very different concept to the amount you eat. Especially on topics like these, the distinction is critical. reply dmicah 23 hours agorootparentprevThere have previously been associations between caloric intake and Alzheimer Disease or Cognitive Aging, for example: https://jamanetwork.com/journals/jamaneurology/fullarticle/7... https://www.pnas.org/doi/10.1073/pnas.0808587106 reply Etheryte 22 hours agorootparentI think it's a fair bit of a stretch to broadly say that this study shows an association. > Conclusion: Higher intake of calories and fats may be associated with higher risk of [Alzheimer Disease] in individuals carrying the apolipoprotein E ϵ4 allele. > The hazard ratios of [Alzheimer Disease] for the highest quartiles of calorie and fat intake compared with the lowest quartiles in individuals without the apolipoprotein E ϵ4 allele were close to 1 and were not statistically significant. For the general population, there was no correlation. Identifying specific genetic outliers where there may be a connection is still useful, but far from a general result. reply bb88 23 hours agorootparentprevExactly. There are lots of skinny alcoholics and drug addicts. Unfortunately many of them are homeless. The real surprise I learned is that GLP-1 may discourage other addictions as well, including gambling. Source: A nurse I talked to who works with GLP-1 trials. reply phil21 23 hours agorootparentprevAs others have already stated, it’s starting to become mainstream science that there is a strong correlation between obesity/poor body composition and Alzheimers. It’s not settled science yet, but the correlation is starting to look a whole lot like causation at a society level. reply eli_gottlieb 22 hours agorootparentNot to cite anecdotal evidence, but my father-in-law was skinny as a rail and got severe, early-onset Alzheimer's. Obesity might be one potential cause of Alzheimer's, but it's among many. reply phil21 22 hours agorootparentYep, just like there are skinny as rails type 2 diabetics. My grandfather was one. There is also a huge correlation between obesity and type 2 diabetes as well. I imagine they share similarities, but that’s pure speculation. reply ugh123 22 hours agorootparentprev>If it was as simple as eating less makes these issues go away, we would've figured that out a long long time ago. You can't get people in large enough quantities to do that reliably and for long enough as part of a study. Best you can do is a small quantity of lab rats. The data is already rolling in as part of prescribed out-patient data. reply ZYbCRq22HbJ2y7 17 hours agoparentprevNo, there are a number of effects of GLP-1 RAs that are not directly related to their initial research and development associated with insulin response, beta cells, etc or recent research associated with appetite suppression. For instance, there is growing research and speculation around dopamine systems in humans. It might be awhile before the research propagates to the realm of popular science. IMO, it kind of represents how incredibly blind we are to supposedly safe compounds, and how arrogant others are for calling for less regulation. When attention is high, suddenly so much more is revealed. reply loeg 22 hours agoparentprevI don't think we know conclusively yet. That probably explains quite a lot of it, yes. It's unclear how that would lead to the substance (ab)use results, though. reply slaymaker1907 23 hours agoparentprevDepends on who you are and if you have an eating disorder. reply api 23 hours agoparentprevDo we know? I think that's the question being asked here. Using these drugs seems to improve a bunch of indicators and we're not sure why. It's really interesting to me that there's some evidence for Metformin -- a diabetes drug that suppresses glucose production and appears to do other things we don't fully understand -- having general health benefits and possible life extending benefits in healthy people. Normally it's just used to treat some forms of diabetes. Feels like we're on the cusp of figuring something out about inflammation, aging, and metabolism. reply breck 23 hours agoparentprevYes. Turns out everyone should have just been eating fats all along. reply fredgrott 23 hours agorootparenthmm, ahem no! veg fats okay, animal fats no so much as if you limit them you tend to live longer due to the decrease in oxidative damage. reply greenavocado 23 hours agorootparentPolyunsaturated fatty acids (PUFAs), whether from plants or animals, are most susceptible to oxidative damage because they have multiple double bonds that can react with oxygen. Each double bond creates a potential site for oxidation. Societies consuming high amounts of oxidized oils (repeatedly heated cooking oils, whether plant or animal) show increased rates of cardiovascular disease Mediterranean populations consuming fresh, minimally processed olive oil show better cardiovascular outcomes Populations with high fresh fish consumption (like traditional Japanese diets) show better health outcomes despite high PUFA intake, likely due to immediate consumption and minimal oxidation Modern food processing/storage methods increase exposure to oxidized fats Fast food consumption correlates with higher intake of oxidized fats due to repeated oil heating Socioeconomic factors influence exposure - processed foods with oxidized fats are often cheaper and more accessible Oxidation status of fats may be as important as the traditional saturated/unsaturated classification reply david-gpu 23 hours agorootparentprev> if you limit them you tend to live longer due to the decrease in oxidative damage Can you elaborate on that? Aren't animal fats, particularly dairy, rather rich in saturated fats? And saturated fats oxidize less easily than unsaturated fats precisely because they lack weak double bonds. reply milliams 21 hours agoprevWhat's GLP-1? reply philipkglass 21 hours agoparentIn this context it's shorthand for \"GLP-1 receptor agonist.\" https://en.wikipedia.org/wiki/GLP-1_receptor_agonist Glucagon-like peptide-1 (GLP-1) receptor agonists, also known as GLP-1 analogs, GLP-1DAs or incretin mimetics, are a class of anorectic drugs that reduce blood sugar and energy intake by activating the GLP-1 receptor. They mimic the actions of the endogenous incretin hormone GLP-1 that is released by the gut after eating. reply dyauspitr 20 hours agoprevThis is probably what’s going to get us over the 80 years life estimate plateau. The main killers now are overwhelmingly cardiovascular diseases and cancers. reply andrewmcwatters 20 hours agoprevIt feels more likely to me that there's some sort of condition we don't have a widely known name for that is caused long-term by a combination of predisposition in genetics and something in western diets that is, I'm not sure, forcing us to overproduce ghrelin (possible links to puberty occurring earlier in both young boys and girls?), or underproduce certain classes of incretins (possible links to excessive blood sugar levels in larger percentages of the population historically over time?). It would be boring to learn that it's just caused by excessive exposure to fructose. But what do I know, I'm just a dumb HN reader. Seems neat that there's ongoing work in this area and it'll be cool to read about new knowledge in that space when something is discovered. reply bartwr 23 hours agoprevIt's interestingly disingenuous that many claim of GLP-1 agonist miraculous effects on all kinds of health problems, where the same problems are \"simply\" solved by getting on a calorie deficit and lean. Liver, kidneys, heart, etc. If you have a non-alcoholic fatty liver disease and are obese, getting leaner will heal it. All those impressive results are on obese or diabetic people. So it is not only not a surprise, but also dishonest marketing or ignorance. Don't get me wrong - those are miraculous drugs. First real non-stimulant low side effect appetite suppresion that will help millions. But let's wait for honest research on lean people before spreading marketing on how it improves overall health. Also, how nobody mentions the need for increasing the dosage and tolerance build-up (just check reddits how much people end up having to take after months of continuous use). You cannot be on it \"for life\". reply bbatha 23 hours agoparentThe increasing dosage is to tritrate up to a dose not because you gain tolerance. There are patients on GLP-1 for over a decade. Also maintenance and weight loss dosages are different: see the dosing charts for ozembic vs wegovy which are exactly the same drug. Even if folks gain tolerance that doesn’t seem overly concerning. Mental health drugs also have tolerance issues and changing medicines every few years, while it has challenges for the patient, is an accepted part of long term psychiatric treatment. reply leetnewb 23 hours agoparentprevJust a narrow comment, but type 2 diabetes certainly isn't limited to the obese. Many lean people develop issues with blood sugar that can't be controlled with diet alone. reply bearjaws 22 hours agorootparentA friend's son, who is an EMT, was recently diagnosed with type 2 diabetes at the age of 21. He doesn't drink or eat sweets, except on holidays, and works out five days a week. Suddenly, he started feeling sick, was vomiting, and ended up in the ER, all within three days. It can really hit you like a truck. reply corry 22 hours agoparentprevThis is my #1 question on GLP-1: are we just seeing how humans do much, much better by being lean vs. the direct result of the drug? A lean current-epoch human -- with our food abundance, access to modern medicines, higher standards of life, lower risks of injury, etc -- is likely going to be markedly healthier than a non-lean current-epoch human or a lean human from a prior age where medicine/food/etc was worse. Or is it, in fact, the direct result of the drug? reply pdabbadabba 20 hours agoparentprev> where the same problems are \"simply\" solved by getting on a calorie deficit and lean Except that there apparently is mounting evidence that GLP-1 agonists also address some issues that are not generally addressed by just restricting calories. TFA touches on this briefly: \"The weight loss involved with GLP-1 agonist treatment is surely a big player in many of these beneficial effects, but there seem to be some pleiotropic ones beyond what one could explain by weight loss alone.\" I seem to recall seeing claims that they reduce COVID-19 mortality even controlling for BMI (possibly because they inhibit systemic inflammation), reduce alcohol consumption, and even (though I think just anecdotally) may help overcome gambling addiction. See, for example: https://pmc.ncbi.nlm.nih.gov/articles/PMC8425441/ [COVID-19] https://www.ncbi.nlm.nih.gov/search/research-news/19361/ [Addiction] reply majormajor 23 hours agoparentprevI don't know that you have to be disingenuous to both be enthused about these medications AND wish we'd never created the super-processed, super-sugary, make-people-crave-them-and-overeat-them modern American diet. Once you fuck with your gut biome for long enough it's not \"simple\" to solve it. It's incredibly difficult both discipline and metabolism-wise. reply erulabs 23 hours agoprevBorn too late to die in infancy, born too early to see immortality. I imagine parents in the 1890s felt the same way. Our children will see a new and different world than we can imagine. I love this topic of moving past “health” and towards something better. To quote an 1890s thinker: “it’s time to find out what value our values really had”. This does remind me of the superconductor stuff tho - I’m too excited - it will be interesting to see what focused clinical studies show us here, particularly around GLP-1’s effects on addiction. reply modeless 22 hours agoparentThe most important question in the world right now is: which generation will be the first to live indefinitely? It is clear to me that we are on a trajectory to achieve indefinite lifespan extension, but unlike Kurzweil et al I don't see a real possibility that it will happen soon enough for me personally. Maybe my kids, or maybe one or two generations further. Will it happen soon enough to prevent population collapse due to plummeting fertility rates? Will fertility rates go even lower or will the population start to rise again as deaths fall? Will we see stagnation due to older brains being stuck in their ways, or will we be able to fix that too? reply andrewmcwatters 20 hours agoparentprevBorn just in time to live too long and outlive your savings while modern monetary policy infinitely reduces the value of your local currency! reply Traubenfuchs 23 hours agoprevnext [3 more] [flagged] eli_gottlieb 23 hours agoparentNo. Some of the positive effects of GLP-1s are seen before the actual weight-loss occurs. reply Traubenfuchs 22 hours agorootparentA healthy diet and lifestyle lead to increased GLP-1 levels. Were there actually any studies on their effect on healthy and fit people? Loss of muscle mass is already recognized: https://pubmed.ncbi.nlm.nih.gov/38937282/ And probably especially bad in people without fat reserves. reply haccount 22 hours agoprevGuys hear me out. The next VC funded killer idea: ChatGLP! reply riwsky 22 hours agoprev [–] I used GLP-1 to prepare my taxes last week, it was such a stress-free experience. Then as I was coding I kept hitting context window limitations with o1-preview. so on a lark I just fired up my local Ozempic and submitted the same prompts and bam: spit out a whole working iOS app first try. I heard that before they nerfed it with RLHF, Mounjaro not only treated diabetes but also made you charming in conversation and sublimely compassionate towards all beings. The future is now reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "GLP-1 drugs, such as Semaglutide, are gaining attention for their significant weight loss benefits and potential to address other health conditions, including addiction and inflammation.- Users report reduced cravings and better management of hunger, sparking debate on whether these drugs are a shortcut or a necessary intervention for weight management.- Despite their promise, there are ongoing concerns about the long-term effects, side effects, and the importance of accompanying lifestyle changes, highlighting the need for further research."
    ],
    "points": 147,
    "commentCount": 222,
    "retryCount": 0,
    "time": 1730229330
  },
  {
    "id": 41993832,
    "title": "EPA cancels pesticide shown to be harmful to unborn babies",
    "originLink": "https://www.thenewlede.org/2024/10/epa-cancels-pesticide-shown-to-be-harmful-to-unborn-babies/",
    "originBody": "October 22 2024 EPA cancels pesticide shown to be harmful to unborn babies Carey Gillam 0 Citing a need to protect the unborn babies of pregnant women, the US Environmental Protection Agency (EPA) on Tuesday banned a pesticide used to kill weeds on farms, golf courses and athletic fields. The action comes after years of mounting scientific evidence of the dangers posed by exposure to the chemical dimethyl tetrachloroterephthalate, also known as DCPA or Dacthal. “With the final cancellation of DCPA, we’re taking a definitive step to protect pregnant women and their unborn babies,” Michal Freedhoff, assistant administrator for the EPA Office of Chemical Safety and Pollution Prevention, said in a press release. “The science showing the potential for irreversible harm to unborn babies’ developing brains, in addition to other lifelong consequences from exposure, demands decisive action to remove this dangerous chemical from the marketplace.” The agency said “robust studies” demonstrated “thyroid toxicity,” and said that unborn babies whose pregnant mothers are exposed to DCPA could experience changes to fetal thyroid hormone levels. Such changes are “generally linked to low birth weight, impaired brain development, decreased IQ, and impaired motor skills later in life, some of which may be irreversible,” the EPA said. DCPA was registered to control weeds in both agricultural and non-agricultural settings, but has largely been used to control weeds in fields growing crops such as broccoli, brussels sprouts, cabbage and onions. The EPA action comes after years of research and smaller moves by the EPA to limit the impact of DCPA on public health. In April, the agency issued a rare warning that the pesticide posed “serious, permanent and irreversible health risks,” especially to farmworkers involved in tasks such as transplanting, weeding and harvesting after the pesticide has been applied. In August, the EPA issued an “emergency suspension” of the chemical, marking the first time in almost 40 years the agency took such an emergency action. The agency said that, following the suspension, it received a letter from AMVAC Chemical Corporation, the sole manufacturer of DCPA, stating its intent to voluntarily cancel pesticide products containing DCPA sold in the US. AMVAC later said it would also cancel all international registrations. The EPA cancellation prohibits anyone from distributing or selling DCPA pesticide products and bars anyone from using existing supplies. (Featured photo by Jordan González for Unsplash+)",
    "commentLink": "https://news.ycombinator.com/item?id=41993832",
    "commentBody": "EPA cancels pesticide shown to be harmful to unborn babies (thenewlede.org)141 points by PaulHoule 7 hours agohidepastfavorite87 comments Jimmc414 5 hours agoGreat! But the EPA classified DCPA as a \"likely carcinogen\" 29 years ago. Why does it take 30 years to stop spraying the stuff? reply jws 2 hours agoparentFor the EPA, \"likely carcinogen\" means: • There is evidence of carcinogenicity in animals. (Multiple, consistent studies) • The substance is shown to directly or indirectly cause chromosomal damage or mutations in a way that is relevant to humans. • There are no or limited human studies, they are inconclusive, or otherwise inadequate. ((Note: This is sort of a \"Why isn't this classified higher?\" factor.)). ((If a substance isn't in widespread use, it is kind of hard to design an ethical human study. I mean, you aren't going to have some of your test subjects drink a bunch of likely carcinogen each morning.)) So this is a a classification for \"Let's maybe not go nuts with this stuff, and someone really ought to check this out. And if you plan to ship tons of this stuff you might want to talk to your lawyers and lawsuit judgement mitigation team.\" I didn't manage to find an exhaustive list of things the EPA has listed with this, but I found one that included higher risks as well, and in my little warehouse/workshop I identified 8 things at a casual glance that I have in inventory or generate. Proper use of these have minimal exposure to my squishy bits for most of them, and the others a well informed user should know to take adequate precautions. (e.g. \"wood dust\": wear a respirator) The US does not currently fund the EPA to commission studies to further investigate likely carcinogens, so they stay on the list for ages. reply BJones12 3 hours agoparentprev\"Carcinogenic risk estimate for exposure to DCPA, HCB, and dioxin/furans through food were 3.5e-7, and 7e-8, respectively. All of these risk estimates are within the range (zero to 1e-6) generally considered to be negligible by the Agency. Thus, the Agency concludes that DCPA use does not pose a significant excess lifetime cancer risk.\" [0] [0] https://www3.epa.gov/pesticides/chem_search/reg_actions/rere... reply culi 1 hour agorootparentAnd now in 2024 they've issued an emergency order... > Effective Aug. 7, DCPA may not be sold, distributed or used in any manner. Consumers with current stocks of the product cannot use it. We need to start retesting pesticide safety more often and be more strict. Currently pesticides are only rechecked every 15 years reply rsynnott 5 hours agoparentprevIn this case it doesn't seem to have been due to its carcinogen classification, but due to fetal toxicity. reply culi 1 hour agorootparentBirth defects > DCPA exposure in pregnant women can cause thyroid level changes in their unborn babies. These changes are linked to low birth weight, impaired brain development, decreased IQ and impaired motor skills later in life. reply gruez 5 hours agoparentprev>Great! But the EPA classified DCPA as a \"likely carcinogen\" 29 years ago Is this the same list as the IARC group 2A list, which contains stuff like red meat, hot beverages, and french fries[1]? [1] https://en.wikipedia.org/wiki/Acrylamide reply TeaBrain 4 hours agorootparentWhy bring this IARC list up out of the blue? The parent comment mentioned an EPA classification and you brought up a list of IARC classifications. The EPA and IARC frequently disagree on their classifications. reply jws 2 hours agorootparentProbably because you don't find a list from the EPA. The two categories are very similar, they are sort of aimed at the same result but have slightly different criteria. e.g. the EPA considers exposure levels, IARC requires at least some human evidence. So you wouldn't say one is stricter than the other, just different ways of skinning a cat. reply delichon 4 hours agorootparentprevRed meat is on IARC 2A: https://en.wikipedia.org/wiki/IARC_group_2A. The IARC is an agency of the World Health Organization, so these lists don't impose any obligations on the FDA. reply TeaBrain 4 hours agorootparentThe parent comment's mention of the IARC list is completely irrelevant. IARC doesn't have anything to do with the EPA. Edit: Prior to it being edited, the comment I responded to here posed the question to the original IARC comment of whether the EPA could ban red meat due to it classified as a carcinogen by IARC. reply stonemetal12 3 hours agorootparentprevIsn't that their point? If the Chemical in question is a carcinogen, but a weak one categorized the same way as other foods like red meat, then it probably isn't going to get banned. reply TeaBrain 3 hours agorootparentThe parent of their comment seems to be confused by how the EPA and IARC are not related, so I don't think they do have a point. Prior to my comment, the comment you responded to originally posed the question of whether the EPA could ban red meat due to it being on IARCs list, before being stealth edited. reply mmcdermott 2 hours agorootparentI don't think the point was organizational, that decisions by the IARC must be respected by the EPA, but more common sensical: if a substance is roughly equivalent in risk to food, which is ingested, then it surely can't be more harmful to spray it than it is to eat it. That may not hold in all situations, but it doesn't seem crazy as a general principle. reply yesco 5 hours agoparentprevTbf it takes a while for unborn babies to grow up and change things reply blackeyeblitzar 3 hours agoparentprevI think an even better question is why private organizations are allowed to spray random chemicals all over the environment without the safety being proven first. This will keep happening with some new alternative substance if the current approach continues. reply mschuster91 3 hours agorootparentThe fundamental divide in approaching regulation between the US and Europe. The US prefers libertarianism and only regulates (if at all) when problems grow so large they cannot be swept under the rug any more, while European countries generally prefer \"big governments\" that have an obligation to protect every single citizen. The US may have more innovation and a more powerful economy as a result, but at least we don't have drinking water taps that can be set ablaze because the drinking water is oversaturated with fracking gas. reply CarpaDorada 2 hours agorootparentAs a European I find your assessment appalling. The oft repeated lie that Europe has protected its citizens against anything is bizarre, European governments only protect their big governments. The ban of US pesticides is to stifle American infiltration of EU agriculture, and basically every other law can be viewed under this lens. It is as if people live in a lie, they do not understand what has taken place in the past 200 years, the devastating destruction of the environment with pollution worldwide. As for protecting its citizens, what can really be said about this other than: ignorance is bliss. reply biorach 2 hours agorootparent> The ban of US pesticides is to stifle American infiltration of EU agriculture, and basically every other law can be viewed under this lens. You really really need to cite some sources for this reply CarpaDorada 2 hours agorootparentFor my own opinions, if you'd like to hear more, you can just ask me. I will only provide the citation as a one-off... : >Agriculture has always been influenced by the actions of governments around the world. Never has this been more evident than during the first half of the 20th century, when two major wars profoundly disrupted food production. In response to the tumultuous economic climate, European countries implemented tariffs and other measures to protect local agriculture. ---Rasmussen, Wayne D. , Mellanby, Kenneth , Nair, Kusum , Gray, Alic William , Ordish, George , Crawford, Gary W. and Fussell, George Edwin. \"origins of agriculture\". Encyclopedia Britannica, 28 Oct. 2024, https://www.britannica.com/topic/agriculture. Accessed 30 October 2024. This puts it in the context of WW2. Here's one example where you find the opposite of \"protections\" at play: in the US you need prescriptions for antibiotics, in EU 7% is without.(their PDF link is broken; one that works is\"Antimicrobial resistance and causes of non-prudent use of antibiotics in human medicine in the EU\" (2017)) Here's their Figure 2.6 e.g. . reply Y_Y 1 hour agorootparentprev> oft repeated lie that Europe has protected its citizens against anything is bizarre I, for one, enjoy having strict safety requirements for consumer products. I'm also glad to share this endeavour with many similar countries, since it would be wasteful and unfeasible for small nations otherwise. reply croes 3 hours agoparentprevLobbyists? reply culi 1 hour agorootparentDon't know why you're downvoted. In both the EPA and the USDA scientists only play a consultant role. Their advice has no teeth. No actual power on the final decisions made by the organizations. Industry representatives are \"in the room where it happens\" much more so than scientists reply simonsarris 5 hours agoprevThis happened back in August, the real press release is here: https://www.epa.gov/newsreleases/epa-issues-emergency-order-... reply culi 1 hour agoparent> Effective Aug. 7, DCPA may not be sold, distributed or used in any manner. Consumers with current stocks of the product cannot use it. This probably means we got a huge increase in DCPA usage. In the 1970s when they found out Di-bromochloropropane made most workers infertile and caused extremely high rates of birth defects for those that were still fertile, it was banned immediately in the US. Companies that had large stockpiles of the chemical simply sold them to banana republics. This caused an epidemic of infertility and birth defects in many countries in South America and it still an ongoing concern: https://www.bbc.com/news/world-latin-america-62120058 reply Y_Y 1 hour agorootparentMaybe the prohibition on selling will prevent these companies from selling DCPA? reply clcaev 4 hours agoprevMore generally, from a public policy perspective, how do we tax product externalities, not merely population health impact of product use, but additionally the environmental impact, inclusive of production and disposal, wherever those costs may be incurred across the globe. reply ars 3 hours agoparentThat's the easy part. The hard part is agreeing what the externality is in the first place! \"My study shows Foobar to cause Baz.\" \"No, your study is wrong, my study shows it doesn't.\" All the easily agreed upon stuff is already done - what's left is the stuff people argue about. reply freeone3000 2 hours agorootparentThe easily agreed upon stuff is done?? Gasoline is taxed enough to remove its carbon afterwards? Coal carries an environmental surcharge? Methane leaks are fined? The really obvious stuff is done?? Where? reply s1artibartfast 45 minutes agorootparentHow do you calculate the balance of positive an negative externalities? I think this is the sticking point. You could put a price on the negative externality from gasoline carbon. How does that compare to the positive value people get from goods shipped with that gasoline: consumer satisfaction, jobs, ect. If we look at all the externalities, should we be subsidizing it or taxing it? This is the challenge with adjusting for externalities. reply energy123 38 minutes agorootparentThe positive value is from goods shipped. It's not from goods shipped with gasoline. That's why you tax the gasoline, and not the shipping. Shipping companies will move to EV trucks or synthetic gasoline or hydrogen or carbon credits or whatever and goods will still be shipped, just without the gasoline. At least in the steady state after the market optimizes. reply s1artibartfast 30 minutes agorootparent>The positive value is from goods shipped. It's not from goods shipped with gasoline. When goods & people are shipped with gasoline, it is producing that external value. When I drive to the super market to buy groceries, the grocery store receives 2nd order value (aka externality). The fact that alternative modes of transportation exist does not negate the fact that the positive externality exists. Externalities are not defined using comparative analysis. Lets say you move to EVs or whatever, those too will have externalities. The composition of those externalities may be different than gasoline, as factors are internalized and excluded to the costs paid. reply ars 2 hours agorootparentprevYou actually think those things were \"easily agreed upon\"? They most certainly are not! I'll give you a tiny example: > Gasoline is taxed enough to remove its carbon afterwards? Gasoline is the entire reason we have an economy, do anything to make it more expensive and you'll unleash an earthquake of inflation and lower productivity. That's like the last thing you want to tax! Note: it's irrelevant if you agree with the argument, (or even if I agree with it) - the issue is that the argument exists. reply kelseyfrog 3 hours agoprevWhy can't harm to the unborn simply be priced in so it's no longer an externality? reply lenerdenator 1 hour agoparentBecause that reduces the value transferred to shareholders. reply s1artibartfast 2 hours agoparentprevbecause at some point it is no longer an economic question, but a moral one. reply masa331 3 hours agoparentprevHow would you price it? reply kelseyfrog 2 hours agorootparentIt would incorporate a present value calculation for medical costs, present value of future earnings, work life expectancy, and account for disability-adjusted life years. The marginal price increase would correspond to the hazard ratio adjusted risk of causing harm. reply adamc 30 minutes agorootparentI don't see the emotional devastation in that, but those are real costs. reply culi 1 hour agorootparentprevI agree this is a good idea. Actuaries do calculations/models like these all the time. We shouldn't limit ourselves by our imagination reply peppers-ghost 1 hour agoparentprevIs this a serious question? reply kelseyfrog 54 minutes agorootparentYes. I feel like I have something to learn from the answers I receive. Especially, why are folks ok with pricing in externalities to some harms, but not others. reply markvdb 5 hours agoprev15 years after the EU. reply amelius 1 hour agoparentAnd the EU still has work to do: https://www.msn.com/en-ie/news/other/proven-child-of-florist... reply underseacables 6 hours agoprevThe action comes after years of mounting scientific evidence of the dangers posed by exposure to the chemical dimethyl tetrachloroterephthalate, also known as DCPA or Dacthal. Great, now do Glyphosate. reply adzm 5 hours agoparentGlyphosphate is no where near comparable to this chemical though reply VoodooJuJu 5 hours agorootparentYet. Just like this chemical. Just like DDT. Just like BPA. Just like PFCs. Not nearly enough testing is ever done on these things. Everyone is in such a rush to get these things into our environment and our bodies, no regard for higher order effects, which is why this pattern keeps repeating. reply lesuorac 18 minutes agorootparentDDT is still legal, its just banned for agriculture, you can use it as a pesticide. > [1] in 1972, to a ban on DDT's agricultural use in the United States [1]: https://en.wikipedia.org/wiki/DDT reply gruez 5 hours agorootparentprev>Not nearly enough testing is ever done on these things. Everyone is in such a rush to get these things into our environment and our bodies, no regard for higher order effects, which is why this pattern keep repeating. It was discovered more than 50 years ago and the evidence for its harm is still \"inconclusive\". How much more evidence do you need? When does \"precautionary principle\" become crankiness (eg. vaccine skepticism or cellphones cause cancer)? https://en.wikipedia.org/wiki/Glyphosate#Toxicity reply themaninthedark 5 hours agorootparentI don't have a good enough stat's background for digging deep into the Lancet or IARC citations on Wiki that are the support for IARC's classification of \"probably carcinogenic to humans\" but the rest of the sub from Wikipedia says that it is low risk. reply ars 3 hours agoparentprevGlyphosate is not toxic. But the stuff in the bottle is mixed with adjuvants and surfactants - and those are toxic. So you have to distinguish which thing is being studied if you want to research this product. reply culi 1 hour agorootparentA 2019 meta-analysis found compelling evidence for a link between Glyphosate-based herbicides and non-Hodgkin lymphoma https://pubmed.ncbi.nlm.nih.gov/31342895/ reply pengaru 1 hour agorootparentprevnit: Isn't it spelled glyphosate? reply ars 1 hour agorootparentIt is, I was copy-pasting from someone else and didn't notice. reply simiones 5 hours agoparentprevNah, you can totally drink a big glass of that. reply saalweachter 3 hours agorootparentA glass of the concentrate is where it starts to get worrisome. The LD50 is somewhere in the 5000 mg/kg range; that's around 250 grams for a 50kg person. For concentrated glyphosate, you're in that ballpark with around a liter of concentrate, depending on the exact dilution. reply brink 5 hours agorootparentprevYou can also drink a big glass of car engine coolant. reply Etheryte 4 hours agorootparentYou can drink a big glass of nearly anything once. reply ars 3 hours agorootparentprevIt's actually true: Propylene glycol is harmless. Although some use Ethylene glycol, don't drink that. reply jajko 3 hours agorootparentprevSomething tells me we're not spraying en masse fields with veggies with engine coolants, are we. reply BJones12 3 hours agorootparentSounds like your car is in better condition than mine. reply ImHereToVote 5 hours agoprevnext [4 more] [flagged] dfxm12 5 hours agoparentnext [4 more] [flagged] BadHumans 5 hours agorootparentNext several years could possibly be devastating to the EPA and consequently the environment. reply Zigurd 5 hours agorootparentWhat we need is some of that supposedly conservative originalism: One justice for every federal circuit, and fixed ratio apportionment for House seats to make districts too small to gerrymander. reply dfxm12 5 hours agorootparentprevIt's too bad some politicians get appointed for life. reply tiahura 5 hours agoprevnext [10 more] [flagged] giantg2 5 hours agoparentIt seems to be more accurate. If a fetus is going to be aborted, then the negative affects of this chemical are moot. The affects of the chemical only become a problem if the fetus becomes a baby. reply throw0101a 4 hours agorootparent> If a fetus is going to be aborted, then the negative affects of this chemical are moot. The affects of the chemical only become a problem if the fetus becomes a baby. Without getting into value judgements or supporting a particular position: I think the GP is implying that when the fetus \"becomes a baby\" is the 'divisive' part. For some folks think the fetus (zygote, whatever) is a baby/human/person at (e.g.) the moment of conception, while other folks pick a different moment of time for this. The (philosophical?) question is why should the entity in the uterus sometimes be considered a (unborn) baby, while other times not a human/person/baby but rather just a bunch of cells? Even if you concede that the fetus is a person (which is a position that some disagree with), that still does not necessarily settle things: > It is possible, of course, to acknowledge the personhood of the fetus and still defend abortion. Half a century ago the philosopher Judith Jarvis Thomson, conceding that the fetus becomes a person well before birth, famously argued that the personhood of the fetus does not make the mother’s decision to kill it unjust. Killing the fetus is unjust, Thomson argued, only if the mother first agrees to carry it. But this, again, is a philosophical question. Do we owe others only what we agree to owe them? > Some philosophers, like Thomson, think so, but very many philosophers disagree. If I live alone in the woods and wake one day to find an infant on my doorstep, am I obligated to care for it? Or may I simply step over it and go on about my day, until it dies from exposure and neglect? To think I am obligated in justice to help it, as a great many people (philosophers and non-philosophers alike) do, is to think we owe things to other people simply because they are people. And if we can owe things to other people simply because they are people, then Thomson’s argument falls apart. […] * https://archive.is/https://www.dallasnews.com/opinion/commen... * https://en.wikipedia.org/wiki/Judith_Jarvis_Thomson IMHO this is central question in the abortion debate, and I find it hard to believe it will ever be resolved or 'universally' agreed upon as it involves all kind personal value judgements. reply giantg2 4 hours agorootparentWell sure, there's only really 2 questions that must be answered when evaluating abortion, yet they're almost never discussed. First is what defines a human life. Second is when is it acceptable to take a life. reply potato3732842 4 hours agorootparent>Second is when is it acceptable to take a life. As an aside, I think the general increase over the past few decades when it comes to society's inability to tolerate general case loss of life and/or limb did a lot more heavy lifting than anyone wants to give credit for when it comes to swinging the political pendulum against abortion. Arguments about the point of minimum viability, \"but it's a human life\", etc. resonate a lot less in a world where kids grow up in houses full of second hand smoke, are playing with lawn darts at 10 and drunk driving by 18 and while not considered ideal all that is considered normal. reply catlikesshrimp 5 hours agorootparentprevHe meant unborn vs born. The earlier the exposure, the worse the effects reply Etheryte 4 hours agorootparentThis is not necessarily true, there are many cases where the mother's immune system can fend for the unborn child, whereas once a child is born, that helping hand is largely gone, outside of what you get with breast milk etc. reply Zigurd 5 hours agorootparentprevStill doesn't make sense. Prenatal and neonatal, especially when breastfeeding, face the same problems with harmful pesticides and other stuff that has been marketed as safe for broad use, until it turned out otherwise. reply dfxm12 5 hours agorootparentprevunborn vs born Maybe the EPA is playing realpolitik here. Fetuses get way more consideration from conservatives, so maybe, after getting shut down a lot recently from the conservative courts, they think this will be more likely to stand if the concern is over a fetus and not a living baby. Obligatory George Carlin clip: https://www.youtube.com/watch?v=nZdRMBTF-hQ reply ImJamal 5 hours agoparentprevWhat would be an accurate phrase that would not be unnecessarily divisive? Clump of cells? Feteus? Everything is political and divisive nowadays so no matter what you choose it will be wrong. reply TimTheTinker 3 hours agoprevGreat. Now do all the other pesticides developed since the 1950s. And GMO crops while you're at it. reply tifik 3 hours agoparentGMOs can reduce need for pesticide and insecticide use, reduce water and fertilizer use, increase yields and make produce last longer. Are there any credible studies showing any GMOs in the states to be harmful? reply TimTheTinker 3 hours agorootparentJust a lot of anecdotal stories that people suffering from various forms of food intolerance (gluten intolerance in particular seems to be strongly correlated with GMO grains) can't eat most GMO/non-organic American food, but can eat food from Europe, where GMO foods are banned and regulatory bodies do not allow new things until clinically proven to not be harmful. More generally, I'm a proponent of the philosophical view that the FDA and EPA should allowlist things, not denylist. A pesticide, GMO technique, additive, dye, preservative, etc. should be proven via clinical trials before being allowed, not allowed by default until proven harmful. As it is, this allow-by-default makes the US population the test case for everything at once, making causes of harm difficult to trace (as certain vendors are financially incentivized to want them to be). Furthermore, regulators can be bought via lobbyists, preventing things from being banned until long after their harmfulness is well-known. Wanting to do things better is nice, but it's no excuse for failing to sufficiently test new things in isolation. reply consumer451 51 minutes agorootparent> More generally, I'm a proponent of the philosophical view that the FDA and EPA should allowlist things, not denylist. A pesticide, GMO technique, additive, dye, preservative, etc. should be proven via clinical trials before being allowed, not allowed by default until proven harmful. I agree with this 100%. I believe that it used to be that way in the USA until the burden of proof was shifted by the Toxic Substances Control Act of 1976, although I am not entirely clear on this. reply consumer451 1 hour agorootparentprevDisclaimer: each GMO product should be looked at individually, just like each chemical product. When people say all GMOs are good or bad, it's as silly as saying that all chemicals are good or bad. That aside, > GMOs can reduce need for pesticide and insecticide use A funny thing happened on the way to quarterly report. I believe that the most popular GMO product line is Roundup Ready [0], and it does the exact opposite. It allows the creator's cash cow product to be applied more liberally. https://en.wikipedia.org/wiki/Roundup_Ready reply TimTheTinker 11 minutes agorootparentGreat callout. Roundup Ready is my primary GMO concern for US-grown food -- so much so that \"GMO bad\" and \"roundup ready\" are synonymous for me. reply lesuorac 14 minutes agorootparentprevSure, but they should be looked at by the producer first before widespread selling. Either that or just have some blanket warning on them that the product wasn't tested for safety. reply themaninthedark 1 hour agorootparentprevWhat it does is allows for a mass spraying of Roundup rather than targeted sprayings. If you had to do several targeted sprayings over a growing season vs 1 mass spraying at a critical point, you could end up spraying more. I would think the main selling point is ease of use but economics is going to play into it. If you have Farmer A who has to buy the seeds and spray + is using more spray vs Farmer B who is using their own seeds and less spray, who is going to make more money? reply consumer451 1 hour agorootparentFrom the wiki: > While the use of Roundup Ready crops has increased the usage of herbicides measured in pounds applied per acre ... reply mint2 55 minutes agoprev [–] Good. Oh and “unborn” babies is a weird term for fetus that is a politically loaded term… and is as much logical sense as calling the living “undead” or “unburied” reply lxe 48 minutes agoparentI'm pro-choice, but labeling terms like 'unborn babies' as 'weird' for being 'politically loaded' feels like an unproductive distraction. You're just adding bait to a divisive debate rather than contributing any real substance to the conversation. reply mint2 2 minutes agorootparentIt’s divisive to not want loaded language that is almost exclusively used by anti-abortion advocates rather than the general terminology? Using the divisive terminology is what’s divisive, not the comment complaining about the divisive language reply exabrial 51 minutes agoparentprev [–] Its literally what they are, they're not aliens, they're people. reply mint2 3 minutes agorootparent [–] They are fetuses, the term unborn baby was until recently has been almost exclusively used by anti abortion advocates. Perhaps they are becoming successful at normalizing the terminology. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The US Environmental Protection Agency (EPA) banned the pesticide DCPA on October 22, 2024, due to its harmful effects on unborn babies, including thyroid toxicity and potential irreversible harm to fetal brain development.- The decision follows years of evidence and previous warnings, highlighting the serious health risks DCPA posed, particularly to farmworkers.- AMVAC Chemical Corporation, the sole manufacturer, agreed to cancel all DCPA products, and the ban prohibits the sale and use of existing supplies both in the US and internationally."
    ],
    "commentSummary": [
      "The EPA has revoked the use of the pesticide DCPA due to its detrimental effects on unborn babies, despite its classification as a \"likely carcinogen\" nearly three decades ago.",
      "This decision underscores the sluggish process of prohibiting harmful substances and suggests a need for more regular and rigorous safety evaluations of pesticides.",
      "The situation prompts a discussion on the contrasting regulatory methods between the US and Europe, the role of lobbyists, and the broader impact on public health and environmental policy."
    ],
    "points": 141,
    "commentCount": 87,
    "retryCount": 0,
    "time": 1730288481
  },
  {
    "id": 41992899,
    "title": "Eighteen Years of ABI Stability",
    "originLink": "https://daniel.haxx.se/blog/2024/10/30/eighteen-years-of-abi-stability/",
    "originBody": "cURL and libcurl Eighteen years of ABI stability October 30, 2024 Daniel Stenberg Leave a comment Exactly eighteen years ago today, on October 30 2006, we shipped curl 7.16.0 that among a whole slew of new features and set of bugfixes bumped the libcurl SONAME number from 3 to 4. ABI breakage This bump meant that libcurl 7.16.0 was not binary compatible with the previous releases. Users could not just easily and transparently bump up to this version from the previous, but they had to check their use of libcurl and in some cases adjust source code. This was not the first ABI breakage in the curl project, but at this time our use base was larger than at any of the previous bumps and this time people complained about the pains and agonies such a break brought them. We took away FTP features In the 7.16.0 release we removed a few FTP related features and their associated options. Before this release, you could use curl to do “third party” transfers over FTP, and in this release you could no longer do that. That is a feature when the client (curl) connects to server A and instructs that server to communicate with server B and do file transfers among themselves, without sending data to and from the client. This is an FTP feature that was not implemented well in curl and it was poorly tested. It was also a feature that barely no FTP server allowed and subsequently this was not used by many users. We ripped it out. A near pitchfork situation Because so few people used the removed features, barely anyone actually noticed the ABI breakage. It remained theoretical to most users and I believe that detail only made people more upset over the SONAME bump because they did not even see the necessity: we just made their lives more complicated for no benefit (to them). The Debian project even decided to override our decision “no, that is not an ABI breakage” and added a local patch in their build that lowered the SONAME number back to 3 again in their builds. A patch they would stick to for many years to come. The obvious friction this bump caused, even when in reality it actually did not affect many users and the loud feedback we received, made a huge impact on me. It had not previously dawned on me exactly how important this was. I decided there and then to do the utmost to never go through this again. To put ABI compatibility at the top of the priority list. Make it one of the most fundamental key properties of libcurl. Do. Not. Break. The. ABI (we don’t break the API either) A never-breaking ABI The decision was initially made to avoid the negativity the bump brought, but I have since over time much more come to appreciate the upsides. Application authors everywhere can always and without risk keep upgrading to the latest libcurl. It sounds easy and simple, but the impact is huge. The examples, the documentation, the applications, everything can just always upgrade and continue. As libcurl over time has become even more popular and compared to 2006, used in many magnitudes more installations, it has grown into an even more important aspect of the curl life. Possibly the single most important properly of curl. There is a small caveat here and that is that we occasionally of course have bugs and regressions, so when I say that users can always upgrade, that is true in the sense that we have not broken the ABI since. We have however had a few regressions that sometimes have triggered some users to downgrade again or wait a little longer for the next release that has the bug fixed. When we took that decision in 2006 we had less than 50,000 lines of product code. Today we are approaching 180,000 lines. Effects of never breaking ABI We know that once we adopt a change, we are stuck with it for decades to come. It makes us double-check every knot before we accept new changes. Once accepted and shipped, we keep supporting code and features that we otherwise could have reconsidered and perhaps removed. Sometimes we think of a better way to do something after the initial merge, but by then it is too late to change. We can then always introduce new and better ways to do things, but we have to keep supporting the old way as well. A most fundamental effect is that we can never shrink the list of options we support. We can never actually rename something. Doing new things and features consistently over this long time is hard if not impossible, as we learn new things and paradigms vary through the decades. How The primary way we maintain this is by manual code view and code inspection of every change. Followed of course by a large range of tests that make sure that assumptions remain. Occasionally we have (long) discussions around subtle details when someone proposes a change that potentially might be considered an ABI break. Or not. What exactly is covered by ABI compatibility is not always straight forward or easy to have carved in stone. In particular since the project can be built and run on such a wide range of systems and architectures. Deprecating We can still remove functionality if the conditions are right. Some features and options are documented and work in a way so that something is requested or asked for and libcurl then tries to satisfy that ask. Like for example libcurl once supported HTTP/1 pipelining like that. libcurl still provides the option to enable pipelining and applications can still ask for it so it is still ABI and API compatible, but a modern libcurl simply will never do it because that functionality has been removed. Example two: we dropped support for NPN a few years back. NPN being a TLS extension called Next Protocol Negotiation that was used briefly in the early days of HTTP/2 development before ALPN was introduced and replaced NPN. Virtually nothing requires NPN anymore, and users can still set the option asking for it, but it will never actually happen over the wire. Furthermore, a typical libcurl build involves multiple third party libraries that provide features it needs. For things like TLS, SSH, compression and binary HTTP protocol management. Over the years, we have removed support for several such libraries and introduced support for new, in ways that was never visible in the API or ABI. Some users just had to switch to building curl with different helper libraries. In reality, libcurl is typically more stable than most existing servers and URLs. The libcurl examples you wrote in 2006 can still be built with the modern libcurl, but the servers and URLs you used back then most probably cannot be used anymore. If no one can spot it, it did not happen As blunt as it may sound, it has came down to this fundamental statement several times to judge if a change is an ABI breakage or not: If no one can spot an ABI change, it is not an ABI change Of course what makes it harder than it sounds is that it is extremely difficult to actually know if someone will notice something ahead of time. libcurl is used in so ridiculously many installations and different setups, second-guessing whatever everyone does and wants is darned close to impossible. Adding to the challenge is the crazy long upgrade cycles some of our users seem to sport. It is not unusual to see questions appear on the mailing lists from users bumping from curl versions from eight or ten years ago. The fact that we have not heard users comment on a particular change might just mean that they are still stuck on ancient versions. Getting frustrated comments from users today about a change we landed five years ago is hard to handle. Forwards compatible I should emphasize that all this means that users can always upgrade to a later release. It does not necessarily mean that they can switch back to an older version without problems. We do add new features over time and if you start using a new feature, the application of course will not work, or even still compile, if you would switch to a libcurl version from before that feature was added. How long is never What I have laid out here is our plan and ambition. We have managed to stick to this for eighteen years now and there is no particular known blockers in the known future either. I cannot rule out that we might at some point in the future run into an obstacle so huge or complicated that we will be forced to do the unthinkable. To break the ABI. But until we see absolutely no other way forward, it is not going to happen. APIcURL and libcurlDevelopment",
    "commentLink": "https://news.ycombinator.com/item?id=41992899",
    "commentBody": "Eighteen Years of ABI Stability (haxx.se)140 points by TangerineDream 10 hours agohidepastfavorite53 comments tialaramex 8 hours agoBecause this library is so very widely used, in practice it is subject to Hyrum's law ABI breaks far beyond what is characterised in the SO_NAME. At the extreme Hyrum's law gets you \"spacebar heating\", this is not a demand that somehow nothing must change, but an acknowledgement of our reality. Basically even though Daniel might say \"I didn't change the ABI\" if your code worked before and now it didn't, as far as you're concerned that's an ABI break. This particularly shows up for changed defaults and for removing stuff that's \"unused\" except that you relied on it and so now your code doesn't work. Daniel brings up NPN because that seems easy for the public Internet but there have been other examples where a default changed and well... too bad, you were relying on something and now it's changed, but you should have just known to set what you wanted and then you'd have been fine. reply nuancebydefault 8 hours agoprevI'm a bit confused with the usage of ABI here. I thought compatibility between apps and libs is on the API level, while the ABI sits between machine (cpu intructions) and low level (curl?) lib? reply rwmj 6 hours agoparentAPI would be the source level. ABI would be that you can mix the binary program and the binary libcurl library. (Curl is attempting to preserve both) reply throw_a_grenade 7 hours agoparentprevNope, API compatibility is when you write the code, and ABI compatibility is what happens to already compiled code, but still between app and library. Say you compiled your app against libcurl.so.4 file taken from curl 7.88 packaged by Debian. What happens when, far in the future, you will move your executable file, without recompiling, to a system which has curl 12345.67, but the file will still be libcurl.so.4? It should work fine, that is, the library should export the same symbols (maybe some more added), with more or less the same functionality. Possibly implemented differently, maybe accepting more flags, but the stuff that is there, will be there. To parent's downvoters: would you kindly cut him some slack? It's OK to ask if you don't know. https://xkcd.com/1053/ reply DanielHB 6 hours agorootparentJust for a small example how both are not the same, in your C library if you move the positions of a field in a struct it can actually break ABI compatibility (meaning you need to recompile your software), but not API compatibility (meaning you don't need to update your code). reply thrtythreeforty 5 hours agorootparentAnd the opposite is true too: you can break API (by renaming a field) while preserving the ABI (since it didn't move/change type). reply NekkoDroid 3 hours agorootparentYou can also with certain type of APIs increase the size of structs and still be ABI compatible. This is usually done by encoding the size of the type as a member of the struct that is usually assigned via `x.size = sizeof(x)` and passed around as pointers. Takes real care to maintain that though. IIRC this appears somewhat frequently in Win32. reply nuancebydefault 3 hours agorootparentprevThanks for explaining, people! To me ABI immediately triggers the aarch64 / x86 etc vibes, but that indeed makes sense! Now I'm wondering if/how managed code of e.g. dotnet solves this issue, but that might be too much of a tangent. reply Semaphor 8 hours agoprev> “third party” transfers over FTP, Ohh that takes me back, that feature was used heavily in the FXP warez scene (the one the proper warez people looked down on), you’d find vulnerable FTP servers to gain access to, and the best ones would support this. That way you could quickly spread releases over multiple mirrors without being slowed down by your home internet. reply throw_a_grenade 7 hours agoparentThose were fun times, but torrent fits this use case now. You seed the chunk a single time and it magically gets distributed, like you said, without being slowed down by your home internet... That's progress I believe. reply exabrial 6 hours agoprevThere’s JavaScript code we have that won’t compile after 3 months. Pretty sad state of affairs these days. reply robviren 5 hours agoparentCompile is rather generous. The massive teetering dependency tree certainly is prone to breaking, but I am not certain I can draw much parallel between the API stability of JS vs the ABI stability of libcurl. If anything, I can still properly render some pretty dang old websites just fine and, for the most part, the websites will work just fine. Mainly benefitted by the light use of JavaScript using probably no external dependent libraries. Though your milage will vary depending on if you go back to browser specific APIs when all that browser war nonsense was going on. I love to bash on JS as much as the next guy, but a large portion of the blame is actually the modern use of it, not an inherent quality of the language breaking compatibility over time. reply mrguyorama 54 minutes agoparentprevHow? We have an ancient (in javascript years) app that webpacks stupid template systems and polyfills and all sorts of cruft that should have never been in the first place and we haven't had to touch any of that in years. What dependency or feature forces you to chase versions? reply peterkelly 9 hours agoprevI wish developers of JavaScript frameworks had this level of commitment to stability. reply kragen 8 hours agoparentI agree; it's admirable. I wish the Python core developers had even the level of commitment to stability that developers of JavaScript frameworks do. Instead they intentionally break API compatibility every single release, I suppose because they assume that only worthless ideas are ever expressed in the form of Python programs. reply JimDabell 8 hours agorootparentI’ve been writing Python for 25 years and can’t remember projects I work on ever having compatibility broken from one version to the next (with the exception of 2 to 3, of course). Occasionally it happens to a dependency, but it always seems to be something like Cython and not actual Python code. But then, I normally try to stay on the leading edge. I think it’s more difficult if you leave it 2+ years between updates and ignore deprecation warnings. But with a year between minor releases, that leaves almost a two year window for moving off deprecated things. I think that’s reasonable. I don’t experience the pain you describe, and I don’t get the impression that the Python project treats Python programs as “worthless”. The people working on Python are Python users too, why would they make their own lives difficult? reply andai 2 hours agorootparentI've had programs written for Python 2 run on 3 first time by just changing the print to print(). I guess they weren't very big though. reply kragen 7 hours agorootparentprevWhen you bring up \"ignoring deprecation warnings\", you're implicitly confirming what I said, despite explicitly denying it. Perhaps this is due to a misunderstanding, so I will clarify what I was saying. Nobody has to worry about ignoring deprecation warnings in libcurl, or for that matter in C, in English, in Unicode, or in linear algebra. There's no point at which your linear algebra theorems stop working because the AMS has deprecated some postulates. Euclid's theorems still work just as well today as they did 2000 years ago. Better, in fact, because we now know of new things they apply to that Euclid couldn't have imagined. You can still read Mark Twain, Shakespeare, or even Cicero without having to \"maintain\" them first, though admittedly you have to be careful about interpreting them with the right version of language. That's what it means for intellectual work to have lasting value: each generation can build on the work of previous generations rather than having to redo it. Last night I watched a Primitive Technology video in which he explains why he wants to roof his new construction with fired clay tiles rather than palm-leaf thatch: in the rainy season, the leaves rot, and then the rain destroys his walls, so the construction only lasts a couple of years without maintenance. Today I opened up a program I had written in Python not 2000 years ago, not 200 years ago, not even 20 years ago, but only 11 years ago, and not touched since then. I had to fix a bunch of errors the Python maintainers intentionally introduced into my program in the 2-to-3 transition. Moreover, the \"fixed\" version is less correct than the version I used 11 years ago, because previously it correctly handled filename command-line arguments even if they weren't UTF-8. Now it won't, and there's evidently no way to fix it. I wish I had written it in Golang or JS. Although it wasn't the case when I started writing Python last millennium, a Python program today is a palm-leaf-thatched rainforest mud hut—intentionally so. Instead, like Euclid, I want to build my programs of something more lasting than mere masonry. I'm not claiming that you should do the same thing. A palm-leaf-thatched roof is easier to build and useful for many purposes. But it is no substitute for something more lasting. Today's Python is fine for keeping a service running as long as you have a staff of Python programmers. As a medium of expression of ideas, however, it's like writing in the sand at low tide. reply tialaramex 3 hours agorootparentEven for Mathematics though, which I think is where your point is strongest, this is not actually true. If you're a Mathematician in the nineteenth century (for example Peano) you know what a set is in some sense, and if pressed you'll admit that you don't really have a formal way to explain your intuition. Nevertheless you feel content to write about sets as if they're formally defined, even for the infinite sets. Turns out you've been relying on an unstated Assumption, the Axiom of Choice. When Ernst Zermelo and Abraham Fraenkel write down axioms for a coherent set theory they discover that oops, the system works fine either way with this regard to this Axiom, and many years later it was proved to be entirely independent, and yet mathematicians had been gaily assuming it's true, without saying so. So in a sense Peano and say Turing are working with different, slightly incompatible versions of Mathematics. Euclidean geometry works fine... but today you'll be told that our universe's geometry isn't actually Euclidean, so, if something big enough just doesn't work that's to be expected, Euclid's model is neat but it's not actually a scale model of our universe, our universe is much stranger. reply LegionMammal978 5 hours agorootparentprev> Moreover, the \"fixed\" version is less correct than the version I used 11 years ago, because previously it correctly handled filename command-line arguments even if they weren't UTF-8. Now it won't, and there's evidently no way to fix it. Isn't fixing this the whole point of Python's \"surrogateescape\" handling? Certainly, if I put the filename straight from sys.argv into open(), Python will pass it through just fine: $ printf 'Hello, world!' > $'\\xFF.txt' $ python3 -c 'import sys; print(open(sys.argv[1]).read())' $'\\xFF.txt' Hello, world! Though I suppose it could still be problematic for logging filenames or otherwise displaying them. reply kragen 3 hours agorootparentI didn't realize that surrogateescape (UTF-8B) had become the default! If so, that's a great improvement. Thank you for the correction. (I can confirm that Python does indeed try to open \"\\377.txt\" on my machine with this command line.) reply JimDabell 6 hours agorootparentprev> Nobody has to worry about ignoring deprecation warnings in libcurl, or for that matter in C, in English, in Unicode, or in linear algebra. There's no point at which your linear algebra theorems stop working because the AMS has deprecated some postulates. Euclid's theorems still work just as well today as they did 2000 years ago. Better, in fact, because we now know of new things they apply to that Euclid couldn't have imagined. You can still read Mark Twain, Shakespeare, or even Cicero without having to \"maintain\" them first, though admittedly you have to be careful about interpreting them with the right version of language. I mean, that last part really unravels your point. Linguistic meanings definitely drift significantly over time in ways that are vitally important, and there are no deprecation warnings about them. Take the second amendment to the USA constitution, for example. It seems very obviously scoped to “well-regulated militias”, but there are no end to the number of gun ownership proponents who will insist that this isn’t what was meant when it was written, and that the commas don’t introduce a dependent clause like they do today. Take the Ten Commandments in the Bible. It seems very obvious that they prohibit killing people, but there are no end to the number of death penalty proponents who are Christian who will insist that what it really prohibits is murder, of which state killings are out of scope, and that “thou shalt not kill” isn’t really what was meant when it was written. These are very clearly meaningful semantic changes. Compatibility was definitely broken. If “you have to be careful about interpreting them with the right version of the language”, then how is that any different to saying “well just use the right version of the Python interpreter”? > Today I opened up a program I had written in Python not 2000 years ago, not 200 years ago, not even 20 years ago, but only 11 years ago, and not touched since then. I had to fix a bunch of errors the Python maintainers intentionally introduced into my program in the 2-to-3 transition. In your own words: You have to be careful about interpreting it with the right version of the language. Just use a Python 2 interpreter if that is your attitude. I don’t believe software is something that you can write once and assume it will work in perpetuity with zero maintenance. Go doesn’t work that way, JavaScript doesn’t work that way, and Curl – the subject of this article – doesn’t work that way. They might’ve released v7.16.0 eighteen years ago, but they still needed to release new versions over and over and over again since then. There is no software in the world that does not require maintenance – even TeX received an update a few years ago. Wanting to avoid maintenance altogether is not achievable, and in fact is harmful. This is like sysadmins who are proud of long uptimes. It just proves they haven’t installed any security patches. Regularly maintaining software is a requirement for it to be healthy. Write-once-maintain-never is unhealthy and should not be a goal. reply blenderob 6 hours agoprevWhat are some things you could do in a C project to cause ABI breakage? I ask this because I'd like to know what practices I might want to avoid to guarantee that there is no ABI breakage in my C project. reply pizlonator 3 hours agoparentFor those of us who are in the no-ABI-breakage business (I used to be when I worked on JavaScriptCore, which is a framework on Apple platforms and folks dynlink to it), any behavior change that causes an app that has nontrivial number of users to break is considered an ABI break. Some function in your library used to return 42 and now returns 43, and an app with 10,000 users asserted that you returned 42? That's an ABI break. There are more obvious examples: renaming functions that someone linked to? ABI break. Change the size of a struct in a public header? ABI break, usually (there are mitigations for that one). The list goes on and Hyrum's law very much applies. Another way to define ABI compatibility is that folks who promise it are taking the same exact stance with respect to folks who link against them as the stance that Linus takes regarding not breaking userspace: https://lkml.org/lkml/2012/12/23/75 If I promise you ABI compat, and then I make a change and your app breaks, then I'm promising that it's my fault and not yours. reply DanielHB 6 hours agoparentprevIf you move fields around in a struct that is passed between a library and library-consumer it will cause ABI breakage typedef struct { char name[50]; int age; } Person; vs typedef struct { int age; char name[50]; } Person; Basically anything that moves bytes around in memory for data structures that are passed around. Of course any API breakage is also an ABI breakage. reply pests 1 hour agorootparent> Of course any API breakage is also an ABI breakage. I don't think this is true. You can change things on a superficial level in a source language that still compiles down to the same representation in the end. reply CJefferson 6 hours agoparentprevOne big thing to watch out for is structs. You can’t add extra members later. If you have a struct which might grow, don’t actually make it part of the ABI, don’t give users any way to find it’s size, and write functions to create, destroy and query it. reply masfuerte 5 hours agorootparentThe solution in old Win32 APIs was to have a length field as the first member of the struct. The client sets this to sizeof(the_struct). As long as structs are only ever extended the library knows exactly which version it is dealing with from the length. This got a bit messy because Windows also included compatibility hacks for clients that didn't set the length correctly. reply blenderob 5 hours agorootparentprev> If you have a struct which might grow, don’t actually make it part of the ABI, don’t give users any way to find it’s size, and write functions to create, destroy and query it. Thanks! This is very insightful. What is a solution to this? If I cannot expose structs that might grow what do I expose then? Or is the solution something like I can expose the structs that I need to expose but if I need to ever extend them in future, then I create a new struct for it? reply GolDDranks 5 hours agorootparentYou shall expose the structs as anonymous types behind a pointer, and expose functions that act on that pointer. reply acuozzo 5 hours agorootparentprev> What is a solution to this? If I cannot expose structs that might grow what do I expose then? Option 1: If allocating from the heap or somewhere otherwise fixed in place, then return a pointer-to-void (void *) and cast back to pointer-to-your-struct when the user gives it back to you. Option 2: If allocating from a pool, just return the index. reply tialaramex 3 hours agorootparentUnless I've been wrong all these years in C you can write a header file which says this is a pointer to T, without ever saying what's in T and C will not allow people to access the elements of T, since it doesn't know what they are, but they can have the pointer since it doesn't need to know how T is laid out to know it's a pointer and all pointers are laid out the same in C. Then for your internal stuff you define what's inside T and you can use T normally. Also, even if you're returning an index, learn from Unix's mistake and don't say it's an integer. Give it some other type, even if that type is just an alias for a primitive integer type, because at least you are signalling that these are not integers and you might make a few programmers not muddle these with other integers they've got. A file descriptor is not, in fact, a process ID, a port number, or a retry count, and 5 is only any of those things if you specify which of them it is. reply zabzonk 2 hours agorootparenti think you mean void pointers. the callee will then cast those pointers to an actual type it knows about (and then possibly go horribly wrong) reply tialaramex 2 hours agorootparentNo, I don't mean void pointers, I'm talking about just pointers to some unknown type T. What's inside a T? How can we make one? We don't know, but that's fine since we have been provided with APIs which give us a pointer-to-T and which take a pointer-to-T so it delivers the opacity required. reply gpderetta 27 minutes agorootparentprevIncomplete types. Void is just a special kind of incomplete type. reply dpassens 2 hours agorootparentprevNo, you can just use a pointer to struct S without ever defining the fields of S, no void pointers required. reply doctorpangloss 4 hours agorootparentprevYou reserve fields in them for future use. reply throw_a_grenade 4 hours agoparentprevNext biggest humanity-wide problem in this area will be 32/64 bit time I believe. We store timestamps as seconds since 1.01.1970 00:00 UTC, and it turns out someone thought 32 bits will be enough for everybody, so the counter will wrap some time in 2038 year, which is less than 14 years in the future. How do you fix the fact that, on 32-bit systems (in x86 it's limited to i386/i686, which is less and less common, but the world is not only x86) time-related functions return 32-bit wide variables? You either return wrong values or you break the ABI. Debian chose to do both: https://wiki.debian.org/ReleaseGoals/64bit-time . Wherever they could, they recompiled much of the stuff changing package names from libsomething to libsomethingt64, so where they couldn't recompile, the app still \"works\" (does not segfault), but links with 32-bit library that just gets wrong values. Other distros had flag day, essentially recompiled everything and didn't bother with non-packaged stuff that was compiled against old 32-bit libs, thus breaking ABI. reply rkahbv 6 hours agoparentprevIf you alter signatures or data structures in the published header file, there is breakage. If you add new signatures or data structures, software compiled against the previous version should still work with the new version. In my opinion the whole issue is more important on Windows than on Linux. Just recompile the application against the new library or keep both the old and the new soversion around. Some Linux distributions go into major contortions to make ABI stability work, and still compiled applications that are supposed to work with newer distros crash. It is a waste of resources. reply jedisct1 4 hours agoprevTake note, Rust. reply tialaramex 2 hours agoparentRust has explicit provision for C-style ABI if you want that and are willing to pay for it. The provision could be improved, and valuable work on that has taken place and is ongoing, but I think the harsh lesson in this space isn't for Rust but for C++ which fell into just delivering absolute ABI freeze years ago out of terrorized panic rather than any coherent policy or strategy. Plenty of people told WG21 (the C++ committee) that they need to fix this, P1863R0 (\"ABI: Now or Never\") is five years old on Friday. If you bet \"Never\" when that paper was written, you're ahead by five years, if you understand how this actually works you know that you have much longer. When Titus wrote that he estimated 5-10% perf left on the table. That's a thin margin, on its own it would not justify somebody to come in and pick that up. But it isn't on its own, there are a long list of problems with C++. reply ForHackernews 6 hours agoprev> Before this release, you could use curl to do “third party” transfers over FTP, and in this release you could no longer do that. That is a feature when the client (curl) connects to server A and instructs that server to communicate with server B and do file transfers among themselves, without sending data to and from the client. That sounds like a super useful feature that would be great if more FTP servers supported it. I guess FTP itself is a dying protocol these days, but it's extremely simple and does what it says on the tin. reply raxxorraxor 6 hours agoparentSadly FTP didn't seem to have a smooth TLS transition. There is FTPS (among SFTP), but I have rarely seen it in use. I think it will survive as a protocol as a fallback mechanism. Ironically I used FTP on a smartphone here and there because Smartphone OS are abysmally useless. Don't get me started with your awesome proprietary sync app, I don't do trashy and they all are. Otherwise I do everything today through scp and http, but it is less optimal technically. It just happens to be widely available. FTP theoretically would provide a cleaner way for transfers and permission management. reply crabbone 6 hours agoparentprevFTP is still the best way to transfer files between a phone and a PC. Well, Android anyways. I don't know how things work in the Apple world. It's bizarre that whatever the \"official\" method of file transfer is is so bad. Also, managing files on Android is, on its own very bad. FTP allows connecting a decent file manager to the phone and do the management externally. reply formerly_proven 10 hours agoprev [–] libcurl is part of the macOS API and de-facto standard on any Linux box and commonly available on BSD boxen as well. Microsoft has been shipping curl.exe for a while as well, though not the library. If Microsoft would also ship the library in %system32%, we would have a truly cross-platform and stable, OS-provided and -patched high-level network protocol client. (So that probably won't happen) reply hypeatei 8 hours agoparent> Microsoft has been shipping curl.exe for a while as well, though not the library. I'm not sure if this is accurate. Why do they include a default alias in Powershell for `curl` that points to the `Invoke-WebRequest` cmdlet then? I've always installed curl myself and removed the alias on Windows. Maybe I've never noticed the default one because of that. reply easton 8 hours agorootparentAs of one of the later releases of Windows 10, \"curl.exe\" is in System32 (or somewhere else on PATH), but if you type \"curl\" in a powershell you get the alias. You need to type \"curl.exe\" to get the binary. Guessing this is for backwards compatibility with scripts written for the days when it was just PowerShell lying to you. https://curl.se/windows/microsoft.html reply actionfromafar 8 hours agoparentprevHm, since a DLL is a PE file and EXE is a PE file, could one load the EXE as a DLL instead? Edit, I had a recollection I saw something like that before, this might be that: https://www.codeproject.com/articles/1045674/load-exe-as-dll... reply Pathogen-David 7 hours agorootparentI just checked and the curl.exe on my system does not export any symbols, so not in this case. It is possible to do that in the general sense though. reply pjmlp 8 hours agoparentprev [–] There are more OSes out there. I never needed curl on Windows, because on OSes that provide a full stack developer experience such things are part of the platform SDK, and rich language runtimes. It is only an issue with C and C++, and their reliance on POSIX to complement the slim standard library, effectively making UNIX their \"runtime\" for all practical purposes. reply fallingsquirrel 7 hours agorootparent [–] You missed the point. There are more OSes out there. If you had to relearn a brand new \"full stack experience\" for every OS just to ship a cross-platform app, you wouldn't have any time left for business logic. libcurl is great and it runs everywhere. And now for a personal opinion: I'll take libcurl over .NET's IHttpClientFactory any day. reply pjmlp 7 hours agorootparentI have been programming since the glory days of 8 bit home computers, try shipping cross-platform applications in Z80 and 6502, and we still had plenty of time left to do lots of stuff. Additionally, writing little wrappers around OS APIs is something that every C programmer has known since K&R C went outside UNIX V6, which again is why POSIX became a thing. reply neonsunset 7 hours agorootparentprev [–] What? You don't need to use it explicitly most of the time. Just `new HttpClient` and cache/dispose it. Or have DI inject it for you. It will do the right thing without further input. The reason for this factory existing is pooling the underlying HttpMessageHandlers which hold an internal connection pool for efficient connection/stream(in case of HTTP2 or Quic) reuse for large applications which use DI. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "cURL and libcurl have maintained Application Binary Interface (ABI) stability for 18 years, since the release of version 7.16.0 on October 30, 2006, which initially broke compatibility by changing the libcurl SONAME from 3 to 4.",
      "The commitment to ABI stability allows users to upgrade without risk, despite the codebase growing from 50,000 to 180,000 lines, achieved through careful code review and testing.",
      "The project aims to continue this stability indefinitely, ensuring that applications can always upgrade to newer versions, although unforeseen challenges could necessitate changes."
    ],
    "commentSummary": [
      "The article \"Eighteen Years of ABI Stability\" explores the challenges of maintaining ABI (Application Binary Interface) stability in libraries like libcurl, emphasizing the impact of Hyrum's law, where even minor changes can disrupt dependent code.- It distinguishes between API (Application Programming Interface) and ABI, noting that ABI deals with compiled code compatibility, and shares strategies for avoiding ABI breakage in C projects, such as managing structs carefully.- The discussion also considers the stability of other languages and platforms, like Python and JavaScript, highlighting the complexities of maintaining long-term compatibility."
    ],
    "points": 140,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1730276728
  },
  {
    "id": 41992394,
    "title": "NASA reconnected with Voyager 1 after a brief pause",
    "originLink": "https://scitechdaily.com/15-billion-miles-away-nasas-voyager-1-breaks-its-silence/",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"scitechdaily.com\",cType: 'managed',cRay: '8dada8d59b782dae',cH: 'NR_cJsKic7BC2y9s6vFYBrrkuJce16Iw6PIYNbADqxQ-1730314944-1.2.1.1-rpFCkGAnZb1fMUUa4hcXWES12Dx_Dc6vpvMNkarvRfcKuAk7cr6I2Si7BFsryjX5',cUPMDTk: \"\\/15-billion-miles-away-nasas-voyager-1-breaks-its-silence\\/?__cf_chl_tk=2YnA8.sb_Bu5D_OhPanmzvbYO4jGtOmhOfmUs5dY4B0-1730314944-1.0.1.1-eNTFhXeQ26jBK2.9Kjd8M95Sq0Qo9hJRkDOFUvr9o2M\",cFPWv: 'b',cITimeS: '1730314944',cTTimeMs: '1000',cMTimeMs: '390000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/15-billion-miles-away-nasas-voyager-1-breaks-its-silence\\/?__cf_chl_f_tk=2YnA8.sb_Bu5D_OhPanmzvbYO4jGtOmhOfmUs5dY4B0-1730314944-1.0.1.1-eNTFhXeQ26jBK2.9Kjd8M95Sq0Qo9hJRkDOFUvr9o2M\",md: \"9tbCYIRLSQk6Wm6dvr5i3OonKmJ0BCuQ_1VNKYTI73I-1730314944-1.2.1.1-fKBgC6scny0.D.Ib3QYPTWu39oQ3QboJSCn5uptrLCWLhiLgACkduMfSWO9FhPXKvhYCSS2EZgLdvXW6ANswa2oxBB48oN75Aw2R4uNsa.PgtvsWPM17y5FHMaqFDBblW0TArC09LPQQf.JrnzLTZChZj9aNW_2TmfX5cLa91Eu1.j82cVFaG2YSSgUIM_RVEAY_3_BKNy3H_yZkR1EbTe6MHZ2B8NwG13e0lyczOgH6ZaUdcRjxjmDSuejzLJ_S.updx1sUgmX1WYFWjJrph_Xeun_uxCbLGaI_QPSEKWrT6NSzdZ_CB8v.FWRv8qLCgmTrPS64nGKpTa6dtQJvpWr6nVGM2ZgB6h_e3H_BTIX5MVqlt9aPaeMKEUE5mIN6ud0H0m47nrjgj._UZJKDSrjF_2shbE3ebi1Bb6NGJBDvirEvYyK16FcLggPBazy2npjwQ0V0IAMK1TNSTW37Mn0e.JtY66hpdRyn6T0eUDPPXJvN4R70_xRHal.dsg_X6GrXm.LUk_vJ5of_rpuoPgjxgFIhzVU6K3wu9PSrDVi6DXT7U7Xx8GGdox8GlG7ksjhu8sZvoVZH1ZaKklnydpLOjRvRDCEbVLM17DA4QwF7NFQo7iP9AnrW4vuUaj.K.9_2p0m8y6oCf58iqgo86VyPgX49au11mfvEXBP1y0pIRAEUw4ou3xYpYakElMfoIRlFF0cuxkOwDkxo_96Q81.eOZhA4Eb4G56C0uUq7EyNK7Xk6th5NomE3hcxTTRLImdWbEd9UvZ1C7VPy89p54DClpjYwELTa3n957L60gHrCZY6k7tz9XCmPl_7UzvQSAMSbAp6LDZ8q_d3tBVROCCfB29f7UBuUMggw_1EqpfN2bDao6aEZhSsC9e0dOycYo.v.wWbRA28LjtDlH4tZQF9iz_ZeiMlkN4xRr58ez7ynQpffPkArcgDOikeA.ncej0ICstgpGKVo6vUIoIpCSZOnd5SnNKo91Hn35tVFyyOc2zChi1xe1TjtAuDtHinaI6gdyCzRuJ.gqxCQREA2DgzA894Oyi_MrNEs5jmheciLwa4iDlbF2_0083lzACjb5NfZU3B1wjeXR.Tap1y.QZr8nPksEnGQ53j6FjGV1CaD46dS67nfq35taRrDN39fmTA9FkwFVf_GNbI921oOkLImt75IT.89XXiGAAwX5JQ0OavLN8Ti1hk8.TP4khvTswPqlAp_hE3DZ3KS58OlbnIrI8qSSG_VWTFsXginzEMgqxt3H5Wfyl6Oetw_BtJ.dN71cMwO41Ey_voKMCIobgnrr8kXcvHpP8Yy4E4jd262rcf.NwUH8vu1APGS8fHMNWv8_vg06YNP_iQNmZh5AEeLRuET7xjHnw76glgapaTEKOoSDp1xMoLcJduwvmGVcjo_tzQigbWQtJtN8SQP59ZbxwX_cdG.IzXOjCNNYiJJt6w8SVYrNuj2p8pMJ6hrgAqoiMkOjIg5EEyKZeJKbXBi_wb4ZWxr31.WOXF9EOKD.p08Rr7_Q3rhau540Jf1bG1pVJeY3jDE6rz_dpmi5XpUXdnLMmn_J6OD3dQY0JV1X2AmLhYSBDXVkoriJpkJ_BdJYwmW6yyIEjhRt7ZwIDG3qMx2ybs7_2rn3z5BqO7z45W.Q0eZ5ZAo0k.Xg7TkmqZEa5tAJAkg6REl_eVuuvhOscpRSCbkxIpiLwEgLwmErOOD5y8MMQeXZKwowhwhgZKHon3k7dfcZn5Yt0ABc9fW6Ym7_MWseU4NshErNqyTZ0jPGcYqJBoO._IW2AEbupgkV_5dQqexI0kEigzE8DdsJqamZ7HdK07aPpClhRLrx1BjYS95yplNqIBrjieRpOSmrw4.7ec1cwL1X_zecUJNmhu.fGtmB.oXBA4g0xOzV_41332slJ8dT7aNVAlBbvl.DszvsDJWApZYkfh8UISGsctdXmMnWNzL34YwV1Dq9GoRAgQhTDW4P3fh1y9lB6ly4ER.3GYvwpQ_OShO3M5umoo1mjtj3Mo9csZJbLJnmD1FO_qmoonOWPbvt_UAA0cEJ.FZvileldq6ZIHO3.vSZh8Cj14npJpDHUEjR9I5t9UFK3LjSW4vyd_bOveFpWuf3tf66Xtgaui65Y8J2IAJrBxv1MzynLRTAkcYYjUBjVDLeone69cPiLOwkUKFLKyT07zV8fCRozDtOG1a.fZtZK0n9YSNSq8mwd96cb_lOFJFNHzeYB6Qhs8.uWMTi32LpLczh..aUKtM6b9gwyTH8lEUh5gSPYVsmKeV78aWs3MrZmsDxcNan4hWYw0XiGIWqOlxJbhebFC_X6V.XqdqKa2CPA.qM3dFUdve9iWF_Jtw6sJxN_8Sg.oM7Q.wVNLTRVv2YVFsv5QwM_8VG386n5qVw1gMV8JduL1.gj2yrcLEdPOyv6g74naQYxR1fmLsemPYp_02pdP3bwEY4WsvZ1i6ijiYZLi64dIAyBhdoxLFnyvPyEHoUCzAyclDWcdDWgcfJ3jw_qMaLkp6E1ydgjDvH1oRKBb_m_0L08LIarKnX8IRvyEBPdhBMburBOFU3gl7akcgjbrc52MC3PqfNKI9FDYiKjkWbidEIRF9KBoDzPXRQfZBlOTwEn5TgI_k8Ya7X6ih.g6NJpAEw\",mdrd: \"XIxj_DHcRQU9m2HDCejfDSZU1JWOfm8La4kQoFdPsjU-1730314944-1.2.1.1-H8eGxZWtCxpVYJnMHpe5UPWPVpUsLdKZ3.N0TmRAajUMg1EFGJQxfxKBZJZlTMJ2_MSZ_RKsetRQptUPrFfjEBXEHHKfA3P2ecKFuGL6.Onb_ze0JAnB44sgSn_qi_eFGNi2ekDM03592zyFDLOqUELPMSFu0pICZbPqo1IykBHjyq3H9tVsTUmJBf0qu0JYo7yU8FbV.JehCkWS2uix9MPZtrfQszTB7U87.uPhXIRDoJcqcg6Nzh8WuES7PhLyqqbskBI_1hIf4t668Yy04u1mcdCWxTaW7bZgji.Zfa5fHjLpjkghqqSE0dTQaCOWBrPGrQZ_NARLuZ.CF8EXm6z7jBqTYcShlhCcH2ttL7jWoDtKmTfqvGQhyZCc2O9RCHR.Pg.5IqRpfQTDevX4ex4CoBE_5UDrSVRcpntR06ayxWXjcOTeiJDMdGp_7hTP3qMlH4xBcJSuchk_T6tVwsSu3TZN5jg0dBLqVNWNY_Wnvyk5xJCcaC7ygJOyBFWbBjBV.ZDR9GsNCxdhYI2xNGS3iZKPc9WgKAqxMDjOvf2Ah8Qo.k0aTwqGWZvRTng4MT13lmD7tjtzEDheBatSGvIsyx1SYN5fgbbY6rbAV203mke9lbqd3ysfRmpQ82B9l5.JyattT8tDLodFtQZkqcxfCxNwkPPx3xquWoUUaQ2BOffILh2UTZ0Uopm4Q7YekxkvhyDhJEj9AdLJgs9QlFKi5iQNhAbD2LPV4ygMVmWXSL3nPe6ckpAjqIawt10L7B1GSasOZcNJpPWsRSx2f2HekgbNw9tz.dcolMFEkNTyliDTEyiMQKXszMK3YGKnFOzp1lW_LNTzYZOyRaswsfW5VINfVQWFsZJ9Z4B_88UueZRaTfQPTlpKMUNQekMNQNyZ_TzeMfQziZZYOdIhUUOQddoYnqFMyAdVLdR4ltP7vzfZIHUbmKBp8Kxv9FWTpFWFpb5VWx1d.gTyIC7H2KLVfDLsTO28H15Egid2T7iODNyCqJgnCZ1FXc60EKijEhK3BUtxXG7DSvoE140j49EX.dZua9FBGZsgJzEfruQJNyoIx1BOSOAhr2Cp2U8nGduOMW4cHboLonhE74hR8I_8vWnU5klz2fUCs4ty5cKsa2BCDIHeLh.V_hNUIEmUuVkXjw2aKnjF0PPWGHrUy_LL7cABraFQI0uAFwBfDHbxFtIAn3sMusH.cC6PKwBP4zk4e4SmesmX6q2KxDp0yN4_gdUicmd32_QoiUM8UgTkTAUSdJXxKq.j_3X1OLakblsu.3joryz6jkeX2DKBxiGA_LPUCb7u0eQb2kHBXVkf3V2rrVmyp2PztPm_A6X_46UG7m8PWnu43aiiYGxwsJHx.DbNHLgW55Tqh07MqTR1VgCezkI3Am.fSd3hrtS4ZABp74xSRmjp0aff3C4Jae1zUfq5P8a1tznuuPIRyXT3iSHui5lKVY075zmC07BtE.o5Kd6xxCs6Thrj1u3Ii2DY9ORzmUfcIbJ2n2RrCQnx9GIoeSXsD77PYv9D3kmiuVPyP5iEK6HT4OKbpflrfPw40lC8dHp.Wob.aKh8BTtlKnuzYcefD_O4zLbR.LK_3o1XwO5a2UlEYDVmJz3iWc9CCeEhnNfvXsqEAnhtKtlOhEry.LTAbwt2CYp6XQLBg0JPW6M54K2wJy1AOQ3h9Dc3FpmwTX9D7kIQpfe8wv1i3LOHG80Du8uFBjMItHkL8rlXrGAvj2fxC_01v1S8.H59xpehJO3ktoO0EB5ygAg9MCUF4yUbVpo7OWmn5Scdm_p7KEQHlLupcKWtnmTgFN7qcC2cSu30TxWfSQRcXWCzE6408lcifXyn8uuOxRx_YiznaEurFolBDURI_10YXM.1bRVUzQ6hcFOyQ8kWIzLhDk4whW18mMX0IjmA_XzzLSmMOQYiHXFJN682BiQcRRJEcv3g9G8Io_ITEpbIe0hvbX7PxDYJYr_OQxD2TuwZYOIcjGOh1u_c3qljU6s7GKWOanZljdE10gLz01emebKIKZ_qqNrV4mopBIW22UZWhlziW3U8koLttIw0z9Nm4uIsMyrqqJLSTj0Y9PukY_..qVCtF0ByUVSY9zivm4h5cfStK8IINv1luu5X0u3PbS002N7ejkC_ResJbeEr0fb0YE7P4WE8RB478KvG7mquO6pKcl2MCT3xCOxjKIawlw5UHIBsAhIj1E414tmMfSzb7lfyNyxzVn4pDjUJdPDUoxu4IKgc0CGvxKPwsUWQfY4KjLGKcVLUAzrv4UhK41mRlqBjpVqTMOi4c8ukiXqsA65A7JAgLZhNvBWod3qbhTQFbz760GhgwtiWUwCUYHSQmT0jJPh33a8cPTd8YrCYHtvti5IxNenTdpPKgZ9HXrIfG8773h5Uen1jRt3J_74\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8dada8d59b782dae';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/15-billion-miles-away-nasas-voyager-1-breaks-its-silence\\/?__cf_chl_rt_tk=2YnA8.sb_Bu5D_OhPanmzvbYO4jGtOmhOfmUs5dY4B0-1730314944-1.0.1.1-eNTFhXeQ26jBK2.9Kjd8M95Sq0Qo9hJRkDOFUvr9o2M\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41992394",
    "commentBody": "NASA reconnected with Voyager 1 after a brief pause (scitechdaily.com)133 points by Stratoscope 12 hours agohidepastfavorite92 comments standardUser 5 minutes agoHey smart people, if we were to launch a similar probe today using the most advanced technology available, how long would it take a probe to reach the same distance as Voyager 1? reply jlawson 1 minute agoparentReally depends how much money you want to spend and if you're willing to wait a bit longer for Starship orbital refueling to be tested. We could build a more or less arbitrarily large rocket in orbit by adding more and more fuel. More fuel means more delta-V means the probe is faster. reply Stratoscope 12 hours agoprevSo you're troubleshooting a 47 year old spacecraft that is 15 billion miles away. The round trip time is 45 hours. That is some kind of latency! reply leeoniya 1 hour agoparenti wonder if the commands include some kind of conditions in them, so you could account for various things at once without a 90h round trip reply toomuchtodo 1 hour agorootparenthttps://voyager.gsfc.nasa.gov/Library/DeepCommo_Chapter3--14... (start at pdf page 35) might have context [1]. [1] Sourced via https://voyager.gsfc.nasa.gov/Library/VOY_library.html reply tanelpoder 11 hours agoparentprevAnd “packet” loss! reply tomkarho 11 hours agoparentprevnext [10 more] Maybe Elon Musk could launch a couple of his Starlink satellites into deep space and reduce that latency. That or apply xkcd #303: https://xkcd.com/303. reply tirant 6 hours agorootparentYou can increase throughput by adding repeaters around the solar system, but latency has a hard limit due to the speed of light. Also throughput could be increased by changing or updating the modulation and coding schemes. AFAIK Pioneer and Voyger probes were still using PSK and FSK. reply conradfr 9 hours agorootparentprevSpace lasers? https://www.jpl.nasa.gov/news/nasas-deep-space-optical-comm-... reply Stratoscope 11 hours agorootparentprevA cool idea. But will the additional hops reduce latency or increase it? reply KK7NIL 10 hours agorootparentIt depends on whether they're running at a lower data rate due to the low signal power (which leads to low SNR, reducing channel capacity) or if it's just the speed of light delay. In the former case, a relay could help quite significantly. In the latter case, it would just add even more delay. reply akira2501 10 hours agorootparentYou can alter throughput. You cannot alter delay. You also can only really broadcast at high power from one side. Deep space RTT is unavoidable. reply snovv_crash 9 hours agorootparentThroughput impacts delay when you send non-zero packet sizes. reply akira2501 12 minutes agorootparentThere isn't enough throughput to achieve a negative delay which offsets the actual flight of light time to reach the object. The ratio of throughput delay to actual light delay is so infinitesimal it might as well be zero. reply thrance 7 hours agorootparentprevElon Musk can improve the speed of light? reply me_me_me 7 hours agorootparentprevhow would that even work? On the whole spectrum. From the starlink satellite receiving signal to it being remotely justified in economical terms. reply Aachen 10 hours agoprev> [The S-band] uses a different frequency than the X-band transmitters signal is significantly fainter. The flight team was not certain the S-band could be detected at Earth due to the spacecraft’s distance, but [it turned out to work] This is the most fascinating part to me. Isn't it well-established how sensitive a signal we can hear? Did they implement something like a new signal analysis method that enabled it? And it says this wasn't used or even tried since the 80s anymore, I guess it grew too faint. Looking up the frequencies, X is 8–12 GHz and S is 2–4. Doesn't that mean X gets more data across at the same redundancy level? Why have this slower transmitter at all for only the first years, power conservation despite the fresh RTG? reply jgrahamc 9 hours agoparentDid they implement something like a new signal analysis method that enabled it? Well, we do keep building bigger and bigger antennas and antenna arrays. So while Voyager can't change, we do. And we can build more and more sensitive (i.e. noise rejecting) equipment. X is 8–12 GHz and S is 2–4 I don't know much about the Voyager design but the beam width is related to the frequency and so the S-band transmitter will have a larger beam width and thus can point less accurately that the X-band when trying to talk to Earth. Conversely, X-band is higher frequency than S-band and it's likely they would be able to use more bandwidth. So, interesting trade offs. reply drmpeg 9 hours agoparentprev> Did they implement something like a new signal analysis method that enabled it? They arrayed three antennas together. > Doesn't that mean X gets more data across at the same redundancy level? There's nothing special about the frequency itself. The advantage for X-band is that the antennas at both ends have more gain. 12 dB for the spacecraft and 11 dB for the ground station for a total of 23 dB. reply Keysh 8 hours agorootparent> They arrayed three antennas together. No, they didn’t. The three antennas are in California, Spain, an Australia; they can’t all point at the same point in the sky at once, and even if two could do so, they’re not designed to work as an interferometric array. reply drmpeg 8 hours agorootparentThere's more than one antenna at each site. https://x.com/CanberraDSN/status/1851446497453494663 https://x.com/vlex26/status/1849618522823065655 reply Keysh 8 hours agorootparentAh, OK, thanks for the link. reply shagie 15 minutes agorootparentprevhttps://eyes.nasa.gov/apps/dsn-now/dsn.html for the \"what is it looking at right now\" If you catch a site commutating with Voyager you will sometimes see it using two dishes... though most often it's just the one big one at the site. When they do, its not getting signal on two, but having one of the track the carrier wave (I think). https://www.cdscc.nasa.gov/Pages/antennas.html ... and to \"even if two could do so, they’re not designed to work as an interferometric array.\" They can. > The DSN anticipates and responds to user needs. The DSN maintains and upgrades its facilities to accommodate all of its users. This includes not only the implementation of enhancements to improve the scientific return from current experiments and observations, but also long-range research and development to meet the needs of future scientific endeavours. > Interferometry > The accurate measurement of radio source positions; includes astrometry, very long baseline interferometry, connected element interferometry, interferometry arrays and orbiting interferometry. Measurement of station locations and Earth orientation for studies of the Earth. > Very Long Baseline Interferometry > The purpose of the Very Long Baseline Interferometry (VLBI) System is to provide the means of directly measuring plane-of-the-sky angular positions of radio sources (natural or spacecraft), DSN station locations, interstation time and frequency offsets, and Earth orientation parameters. reply prettyStandard 9 hours agoparentprevI'm wondering also. Based on the wording here. I suspect we have more and better telescopes than we did when it launched. > The flight team was not certain the S-band could be detected at Earth due to the spacecraft’s distance, but engineers with the Deep Space Network were able to find it. reply Aachen 3 hours agorootparentCertainly, but then isn't it expected now with the new antennas? They installed some upgrade but don't know to what sensitivity it goes? Surely they do so the article must be handwavy about it if I'm understanding things correctly Someone else commented about a wider spread in this other band, though. Perhaps the operators were not sure what that does for adsorptions and reflections by intervening dust or so? reply quotemstr 14 minutes agorootparentHaven't you ever written code that you thought should work, but didn't due to a reason you couldn't foresee? I don't think the uncertainty here comes from question marks in the link budget equations but from the possibility of unforeseen problems making detection not work when it should. reply 0x1ceb00da 8 hours agoprevCan't wait for them to open source the code once it finally dies. Right now they probably can't do that because of security concerns. reply Ductapemaster 1 hour agoparentCheck out this talk: https://www.youtube.com/watch?v=dF_9YcehCZo The source code isn't hiding in a repo somewhere for security reasons — it's spread around on various pieces of paper and computers over the last 50 years. There isn't a single source of truth. Adds a whole other level of wizardry to keeping the thing running. reply 0cf8612b2e1e 49 minutes agorootparentLike, maybe that was originally true, but they have had decades. Numerous times contact has been lost, hardware failed, key people died, etc. How has nobody at the top ordered a digitization and consolidation of all known code and supporting documentation during that time frame. reply andyjohnson0 6 hours agoparentprev> security concerns Does anyone know whether the Voyagers even do any command authentication? Probably doesn't matter now as only the dsn has the ability to talk to them, and that happens comparatively rarely. reply evoke4908 4 minutes agorootparentGiven how simple the computer is, I very much doubt it. If anything, it might have a very simple xor encryption or just a passphrase. If anyone were sufficently motivated, it probably would be trivial to snoop on the DSN transmissions and crack any authentication. I'm sure it'd be susceptible to a simple replay attack at any rate The problem is simply that you need a huge transmitter with (AIUI) some special and unique modulation hardware. Also there's nothing to be gained from interfering with the Voyagers. Really the only practical thing you could do is shut them down a couple of years before they die anyway. There's just no point. reply mrsilencedogood 4 hours agorootparentprevEven if you magically had your own DSN, would anyone but NASA even know exactly where they are with enough precision to communicate with them? In a way, that's now your layer 1 authentication key. The coordinates of where to \"point\" your DSN. reply evoke4908 13 minutes agorootparentI'd be very surprised if its exact position in the sky is not public information. Even if not, it should be fairly straightforward to compute its position from the initial flightplan. Once it escaped Jupiter its trajectory is just a straight line. reply 0x1ceb00da 2 hours agorootparentprevI don't think they are the kind of people that will take unnecessary risks. reply wiz21c 10 hours agoprevFTA: \"Voyagers 1 and 2 have been flying for more than 47 years...\" That should be written on a poster that is put on each desk of each employee of each car/washing machine/fridge/television manufacturer. reply akira2501 10 hours agoparentIt only really needs to be on the upper managements desk: \"The $3.57 you save on capacitors per unit will cost you $50 in lost good will.\" On the other hand there is a balance between longevity through simplified maintenance and replacing aged appliances with newer and significantly more efficient models. reply ffsm8 7 hours agorootparentAlternative phrasing: \"the $3.57 you save (per unit) today will give you a $100.000 end of year bonus, but cost the company millions in future lost sales\" Guess what theyre gonna do? reply andsoitis 6 hours agorootparent> but cost the company millions in future lost sales Isn’t the company going to make more sales in the future (and hence more profit)? And isn’t replacing stuff with new versions going to lead to improvements in people’s lives through more efficient, quieter, and more effective technology? reply godshatter 3 hours agorootparentIt's been my experience that newer technology, though being more efficient, etc, breaks much faster than the old powerhouse tech from the 50's, 60's, and the 70's. I don't see my 1950's-something oven dying anytime soon. It will outlive me if I don't replace it for that one shiny new feature I convince myself I just have to have, or because it doesn't match my curtains. So, yes, replacing stuff with new versions will bring more and more sales as opposed to building something that will last. Hence \"planned obsolescence\" and the war on making things repairable that we've seen lately. Great for business, bad for the customer. reply Sanzig 1 hour agorootparentTo be fair, it's a bit more subtle than that. There's a level of survivor bias involved - all the unreliable appliances from the 50s-70s have long since been hauled off to scrap metal recycling, so what's left are the long-lived ones. Modern electronics certainly can be made with much higher reliability than their mid-century ancestors, but the driving factor that prevents this is aggressive cost cutting that happily shaves pennies off COGS to shift the statistical distribution to the left. Unless consumers are willing to pay more for long-lived devices, this is doomed to continue. reply pilchard123 6 hours agorootparentprevSure, but if the exec in question has moved on to another company by then, what do they care? reply tirant 6 hours agorootparentprevOr in other words, the $3.57 in savings will allow the product to compete in a lower price segment and increase sales significantly. It is the behavior of the buyers that drives costs down. People are extremely cost sensitive in the mid to low segments, shifting their purchase decisions from one product to another just because of less than $1 price difference. Some companies cannot survive at all without saving those $3.57. reply soulofmischief 6 hours agorootparentBuyers do not exist in a vacuum, and consumer behavior is commonly manufactured. Consumer behavior has never been a substantial justification for optimizing for wasteful and environmentally business practices in pursuit of quarterly growth. reply llimos 5 hours agorootparent> Buyers do not exist in a vacuum Unlike Voyagers 1 and 2 reply aeyes 6 hours agorootparentprev> replacing aged appliances with newer and significantly more efficient models Are we still expecting to make significant efficiency improvements for appliances in the next 30 years? Will it be enough to justify the production of a new appliance? Legal warranty for appliances like washers, dryers, refrigerators among others should probably be raised to at least 5 years. reply vel0city 1 hour agorootparentThe thing that gets me about modern warranties on appliances is how weasely they'll market their warranties. I've got GE clothes washer and dryer proudly proclaiming their 10 year warranty. It's a 10 year warranty on the motor and the drum (IIRC). Not on the motor inverter unit, which had a one-year warranty. Guess which part is likely to fail? Guess what that GE service tech is going to recommend you do after he prices out several hundred dollars of parts he thinks he might need because he's too lazy to actually diagnose the issue? An LG dishwasher with a similar 10 year warranty on the pumps and what not in the dishwasher. Awesome, great. The display panel has failing LEDs. Is that under that warranty? Nope. Who cares about the pump not technically failing if one can't know what mode the dishwasher is in? If they're going to stick a sticker on the face advertising their warranty on an appliance it should cover the whole appliance. Not just a small handful of parts that should practically never fail under regular use while all the surrounding stuff has a nearly useless warranty. I'm so salty about warranties and support these days I usually try and do every possible thing I can do to fix the problem myself before obviously voiding a warranty before I ever bother calling their support. So worthless most of the time. reply aaron_m04 34 minutes agorootparentNot to mention binding arbitration with opt-out that is a pain in the ass. I had to go through this for an LG washer recently. reply sandworm101 8 hours agorootparentprevAnd being $3.57 more expensive than the other guy will deny you 90% of sales on amazon or any other online marketplace. reply asah 8 hours agorootparentSadly, there's has no system for long term reviews. In my dreams, Amazon/etc would engage customers about their durable products and ask how often you still use the product and it/when you're thinking of replacing it... Given the economics, I wonder if best buy could pay customers $10 for a survey of their old products, knowing that it'll inspire upgrades etc. reply lancesells 6 hours agorootparentThat's Anti-Amazon behavior. Whatever is going on with their Alibaba-like store is not about finding good products. reply me_me_me 7 hours agorootparentprevi lost my faith in amazon. its all alibaba rebrands and mass fake reviews, plus amazon pushing their own chepo brand into every search. its shocking how amazon went from 'me getting a package every week' to 'i go there only if i have too' reply nucleardog 53 minutes agorootparentAmazon is now, largely, just Aliexpress with faster shipping and easier returns (and higher prices). Even in areas where they have brand name products, it's often impossible to surface them through their search. (I've, many times, failed to find something there and then went and searched Google/etc and the top result has been... an Amazon link to exactly what I'm looking for.) And if you purchase through Amazon, there's no reason to believe it's not gray market or something else where you may end up having issues with support/warranty if you ever need. And combined with the inventory commingling, even if you find brand name products there you can't be sure you'll actually receive it and not a knock-off. So it really only makes sense to order things that are already the cheap/knock-off quality anyway. So... yeah, there was a nice period of time there where Amazon was just \"shopping made more convenient\". These days it's \"Aliexpress made more convenient\". Unless I'm setting out to buy cheaply made Chinese imports with no warranty, I'm not even go to start looking on Amazon. There's little reason to. reply kristopolous 7 hours agorootparentprevThey have the data to infer reliability rates based on things like returns, time to purchase similar item, frequency of repeat purchase, etc. Over the volume of say Amazon, The noisiness of varied intent will normalize itself out across a sector. They could surface this as a reliability metric on some kind of relative scale. They could... reply VoodooJuJu 5 hours agorootparentprev>if you cut corners, you may be rich, but then I'll think you're a bad boy! Uh oh, a moral judgement from a peasant? Say it aint so. Anything but that. I'm literally shaking right now. Anyway, here are some actual incentives: - If you do some shady corner-cutting, you'll be legally compelled to trade in your Bugatti and drive a used Kia the rest of your life - If this chemical causes bodily harm to me, we shall inflict bodily harm on thee - A portion of the profits will be placed in a trust and will be passed down to your children, if and only if your product lasts long enough to be passed down to our children - If you (banker) lose our money, you will lose your head reply saturn8601 2 hours agorootparentThese rules discourage new businesses from starting and you end up in a situation like France where their largest company is some fashion company formed eons ago (probably before all the regulations). reply blensor 6 hours agoparentprevVoyager is something that I keep thinking every time I see people talking about what great things musk/spacex are doing with their fail often/fail fast approach. I do get the value of iterating quickly towards a solution but that does not invalidate the conservative engineering approach other people have to take to build something much more stable/reliable where they have to be very cautious and can't just break things until you have a solution. reply glzone1 5 hours agorootparentVoyagers were built by JPL and not contracted out so align to a degree with the spacex model. In part this was because budget got cut badly. “In order to reduce costs and overheads, NASA decided to leave design and construction of the Mariner Jupiter-Saturn spacecraft to JPL, rather than to Boeing, General Electric, Hughes, Martin Marietta, and North American Rockwell, all of which had some level of preparation for a Grand Tour proposal. The largest aerospace firms lobbied NASA Headquarters and Congress for the contracts. In order for expensive projects to pass congressional scrutiny as part of the NASA budget, they often had to include an intention to contract out much of the work” voyager - Andrew J. Butrica I think they also did build a test spacecraft ? Anyways the approach (smaller focused team) contrasts with the big SLS type projects that are contracted out for political reasons. reply jballer 6 hours agorootparentprevThey’re optimizing for different priorities. Obviously you need to be conservative when launches cost so much you can only afford ~one shot. reply askvictor 9 hours agoparentprevOn the other hand, it's environment isn't particularly hostile (no moisture, dust, vibration, though it gets more radiation than on Earth), and I think it doesn't have much in the way of moving parts (?) reply passwordoops 9 hours agorootparentSpace is pretty hostile: https://theconversation.com/explainer-how-hostile-is-space-2... reply tweetle_beetle 6 hours agoparentprevConversely, the system which has been described as the longest running computer system after Voyager is the UK's Police National Computer - turning 50 and still in use today. Most UK citizens will be on it in some way, shape or form. Keeping it alive is a remarkable feat, but costing taxpayers eye watering sums of money, due to the ever increasing shortage of skills, while a modern cloud alternative is developed. Be careful what you wish for. https://en.wikipedia.org/wiki/Police_National_Computer reply raxxorraxor 3 hours agoparentprevTo be fair, space is quite the decent preservation chamber. reply jampekka 8 hours agoparentprev> That should be written on a poster that is put on each desk of each employee of each car/washing machine/fridge/television manufacturer. And consumer. Very few people would use 50 year old devices even if they were/are perfectly functional. reply HKH2 6 hours agorootparentPlenty of people buy secondhand equipment. Manufacturers want to stop that; spare parts are hard to get or needlessly expensive, and manuals are woefully incomplete or nonexistent. reply Arnt 5 hours agorootparentI've contracted for someone whose customers thought so. (My job involved making stuff work with without an important part from a defunct vendor.) Their costs really did increase all the time. Not needlessly, despite what some people thought: their cost per spare part really did grow quite a lot, as the number needed per year decreased and the fixed overhead slowly increased. reply The-Old-Hacker 5 hours agorootparentprevSpeaking as a writer, I would use an IBM Model M keyboard in a heartbeat. Made in 1985, so 40 years old. reply yial 1 hour agorootparentI have a few of those, I love them. They just work perfectly. reply dano 6 hours agorootparentprevMy sunbeam automatic toaster is working just fine thank you very much. :-) reply ajdude 6 hours agorootparentI found one in a thrift store and I was so excited until I realized that they wanted $150 for it... even local thrift stores know what they have now reply pilchard123 6 hours agorootparentprevAlec? Is that you? reply pif 8 hours agoparentprevNice idea, if you want to go out of business! People don't buy quality: people buy cheap! reply ajdude 6 hours agorootparentAbout a decade ago I bought a USB fan to plug into my computer at work. It has been turned on and running for almost 10 years straight. I thought to myself \"I should actually leave a good Amazon review for this fan, it's held up to the test of time for little consumer electronics like this.\" I went to look up my purchase but not only is that listing gone, the brand no longer exists. reply Szpadel 7 hours agorootparentprevand that's why iPhones never catched up reply AxelLuktarGott 6 hours agorootparentIronic that iPhones are both expensive _and_ come with planned obsolescence reply nephy 6 hours agorootparentDog no they don’t lol. My family has been in both ecosystems over the years and by far the iPhones outlast the Android phones they buy both in quality and in updates. reply sangnoir 1 hour agorootparentCounterpoint: one can only unlock the bootloader on Android phones and extend the device life for much longer than intended or supported by the OEM. reply kelnos 58 minutes agorootparentprevBoth what you are saying and what the GP is saying can be true at the same time. reply 05 6 hours agorootparentprevSome products do better as Veblen goods than others. You can't show off your dishwasher as easily as your new Ferrari or iPhone :) reply ck2 3 hours agoparentprevI have a Sharp carousel microwave oven that is 40 years old and works fine. The \"secret\" solution is it was one of the last years made in Japan, not China. I just move it from apartment to apartment over the years while everything else breaks. reply jeffrallen 2 hours agoprevWow: Triggering the protection system a second time turned off the regular radio: \"While the S-band uses less power, Voyager 1 had not used it to communicate with Earth since 1981. It uses a different frequency than the X-band transmitters signal is significantly fainter. The flight team was not certain the S-band could be detected at Earth due to the spacecraft’s distance, but engineers with the Deep Space Network were able to find it.\" Heros, both those who made the S-band radio and those who managed to retrieve the signal. reply andrewstuart 8 hours agoprevIt’s beyond my average brain how it’s possible at all for a machine that far away to get data to us. reply labster 10 hours agoprevFinally, a “breaks one’s silence” headline that’s not a celebrity posting something on social media. reply forinti 8 hours agoparentYou could say that Voyager is a celebrity. It even does cameos on sci-fi movies from time to time. reply whamlastxmas 4 hours agoparentprevBut I really need to know who Brad Pitt is endorsing before I head into the voting booth reply HenryBemis 6 hours agoprev(thinking aloud/voice in my head) If 'those things' are recharged by sunlight, I wonder how will they get the energy to continue transmitting (assuming they have whatever source AND solar panels - for when the fuel runs out and they can't catch any sunlight?) my dialogue with ChatGPT: Voyager 1 and Voyager 2 are powered by \\*Radioisotope Thermoelectric Generators (RTGs)\\*. These RTGs use the natural decay of \\*plutonium-238\\* to generate heat, which is then converted into electricity using thermoelectric materials. Here’s how the process works: 1. \\*Radioactive Decay\\*: Plutonium-238, a radioactive isotope, decays over time, releasing a consistent amount of heat. 2. \\*Thermoelectric Conversion\\*: Thermocouples in the RTGs convert this heat directly into electricity. 3. \\*Power Supply\\*: This generated electricity powers the instruments, computers, and communication systems on each spacecraft. Each year, the power output of the RTGs decreases slightly as the plutonium decays, so the Voyager missions have had to shut down non-essential systems over time to conserve power. Despite this, both Voyager 1 and Voyager 2 have enough energy to continue transmitting until at least the late 2020s, when their power levels will likely drop below the minimum required for communication. reply maples37 5 hours agoparentThat's the problem, they won't have enough energy to transmit anymore. The Voyager probes are powered entirely from their RTGs, they have no solar panels nor batteries[1]. So if the power output from the RTGs drops below the level needed to power the transmitter, Voyager can't talk to us anymore. There's no batteries that can be recharged and no solar panels it ever drew power from. The exciting part from this discovery is the potential to keep talking to Voyager longer than we thought. If the S-band transmitter uses less power and we're still able to detect that signal, we may be able to communicate with the probes with lower RTG outputs than we initially thought. Though at that point, if the radio is the only thing still running and there's no instruments operating, the usefulness is probably pretty low at that point. [1] https://en.wikipedia.org/wiki/Voyager_1#Power, https://en.wikipedia.org/wiki/Voyager_2#Power reply Nginx487 3 hours agorootparentOn such a distance solar panels won't make any difference. Sun looks like just a very bright star from that far. reply whamlastxmas 4 hours agorootparentprevI wonder how long we could make an RTG last today reply daedrdev 9 minutes agorootparentI think the more interesting thing is its suddenly become so much cheaper to put things in orbit, we could simply put a larger satellite with a larger nuclear battery out there. reply Sanzig 1 hour agorootparentprevFundamentally there isn't any change in the underlying physics. You're limited by the half life of the isotope, so you either choose a longer-lived isotope (which actually may be even harder post Cold War as much of the ideal isotopes were byproducts of nuclear weapons manufacturing) or launch a bigger RTG than you need so you have enough power later on in the mission. reply 93po 3 hours agorootparentprevwiki has the answer, ballpark is around twice as long, and they're using this new design for an upcoming probe reply thunderbong 11 hours agoprev [–] > Voyagers 1 and 2 have been flying for more than 47 years and are the only two spacecraft to operate in interstellar space. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "NASA successfully reestablished communication with Voyager 1, which is currently 15 billion miles away, highlighting the probe's impressive durability over 47 years.",
      "If a similar probe were launched today, reaching Voyager 1's distance would require considerations of budget and advanced technology, such as Starship orbital refueling.",
      "Discussions are ongoing about enhancing communication latency and throughput for space missions, potentially utilizing technologies like Starlink satellites or space lasers, and exploring advancements in Radioisotope Thermoelectric Generators (RTGs) for long-term missions."
    ],
    "points": 133,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1730270935
  }
]
