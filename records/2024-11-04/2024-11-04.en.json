[
  {
    "id": 42037386,
    "title": "Scientists glue two proteins together, driving cancer cells to self-destruct",
    "originLink": "https://med.stanford.edu/news/all-news/2024/10/protein-cancer.html",
    "originBody": "Stanford Medicine News Center 2024 Driving cancer cells to self-destruct Story Scientists glue two proteins together, driving cancer cells to self-destruct share Stanford researchers hope new technique will flip lymphoma protein’s normal action — from preventing cell death to triggering it. October 22, 2024 - By Rachel Tompa A new molecule developed by Stanford Medicine researchers (turquoise and yellow) tethers two proteins (purple and red) that together switch on self-destruction genes in cancer cells. Ella Maru Studio Our bodies divest themselves of 60 billion cells every day through a natural process of cell culling and turnover called apoptosis. These cells — mainly blood and gut cells — are all replaced with new ones, but the way our bodies rid themselves of material could have profound implications for cancer therapies in a new approach developed by Stanford Medicine researchers. They aim to use this natural method of cell death to trick cancer cells into disposing of themselves. Their method accomplishes this by artificially bringing together two proteins in such a way that the new compound switches on a set of cell death genes, ultimately driving tumor cells to turn on themselves. The researchers describe their latest such compound in a paper published Oct. 4 in Science. The idea came to Gerald Crabtree, MD, a professor of development biology, during a pandemic stroll through the forests of Kings Mountain, west of Palo Alto, California. As he walked, Crabtree, a longtime cancer biologist, was thinking about major milestones in biology. One of the milestones he pondered was the 1970s-era discovery that cells trigger their own deaths for the greater good of the organism. Apoptosis turns out to be critical for many biological processes, including proper development of all organs and the fine-tuning of our immune systems. That system retains pathogen-recognizing cells but kills off self-recognizing ones, thus preventing autoimmune disease. “It occurred to me, Well gee, this is the way we want to treat cancer,” said Crabtree, a co-senior author on the study who is the David Korn, MD, Professor in Pathology. “We essentially want to have the same kind of specificity that can eliminate 60 billion cells with no bystanders, so no cell is killed that is not the proper object of the killing mechanism.” Gerald Crabtree Traditional treatments for cancer — namely chemotherapy and radiation — often kill large numbers of healthy cells alongside the cancerous ones. To harness cells’ natural and highly specific self-destruction abilities, the team developed a kind of molecular glue that sticks together two proteins that normally would have nothing to do with one another. Flipping the cancer script One of these proteins, BCL6, when mutated, drives the blood cancer known as diffuse large cell B-cell lymphoma. This kind of cancer-driving protein is also referred to as an oncogene. In lymphoma, the mutated BCL6 sits on DNA near apoptosis-promoting genes and keeps them switched off, helping the cancer cells retain their signature immortality. The researchers developed a molecule that tethers BCL6 to a protein known as CDK9, which acts as an enzyme that catalyzes gene activation, in this case, switching on the set of apoptosis genes that BCL6 normally keeps off. “The idea is, Can you turn a cancer dependency into a cancer-killing signal?” asked Nathanael Gray, PhD, co-senior author with Crabtree, the Krishnan-Shah Family Professor and a chemical and systems biology professor. “You take something that the cancer is addicted to for its survival and you flip the script and make that be the very thing that kills it.” This approach — switching something on that is off in cancer cells — stands in contrast to many other kinds of targeted cancer therapies that inhibit specific drivers of cancer, switching off something that is normally on. “Since oncogenes were discovered, people have been trying to shut them down in cancer,” said Roman Sarott, PhD, a postdoctoral scholar at Stanford Medicine and co-first author on the study. “Instead, we’re trying to use them to turn signaling on that, we hope, will prove beneficial for treatment.” Nathanael Gray When the team tested the molecule in diffuse large cell B-cell lymphoma cells in the lab, they found that it indeed killed the cancer cells with high potency. They also tested the molecule in healthy mice and found no obvious toxic side effects, even though the molecule killed off a specific category of of the animals’ healthy B cells, a kind of immune cell, which also depend on BCL6. They’re now testing the compound in mice with diffuse large B-cell lymphoma to gauge its ability to kill cancer in a living animal. Because the technique relies on the cells’ natural supply of BCL6 and CDK9 proteins, it seems to be very specific for the lymphoma cells — the BCL6 protein is found only in this kind of lymphoma cell and in one specific kind of B cell. The researchers tested the molecule in 859 different kinds of cancer cells in the lab; the chimeric compound killed only diffuse large cell B-cell lymphoma cells. And because BCL6 normally acts on 13 different apoptosis-promoting genes, the researchers hope their strategy will avoid the treatment resistance that seems so common in cancer. Cancer is often able to rapidly adapt to therapies that target only one of the disease’s weak spots, and some of these therapies may stop cancer from growing without killing the cells entirely. The research team hopes that by blasting the cells with multiple different cell death signals at once, the cancer will not be able to survive long enough to evolve resistance, although this idea remains to be tested. “It’s sort of cell death by committee,” said Sai Gourisankar, PhD, a postdoctoral scholar and co-first author on the study. “And once a cancer cell is dead, that’s a terminal state.” Crabtree and Gray, both members of the Stanford Cancer Institute, are co-founders of a biotech startup, Shenandoah Therapeutics, that aims to further test this molecule and a similar, previously developed molecule in hopes of gathering enough pre-clinical data to support launching clinical trials of the compounds. They also plan to build similar molecules that could target other cancer-driving proteins, including the oncogene Ras, which is a driver of several different kinds of cancer. The study was funded by the Howard Hughes Medical Institute, the National Institutes of Health (grants CA276167, CA163915, MH126720-01 and 5F31HD103339-03), the Mary Kay Foundation, the Schweitzer Family Fund, the SPARK Translational Research Program at Stanford University and Bio-X at Stanford University. Rachel Tompa Rachel Tompa is a freelance science writer. Media Contacts Lisa Kim Tel 650-723-6696 likim@stanfordhealthcare.org About Stanford Medicine Stanford Medicine is an integrated academic health system comprising the Stanford School of Medicine and adult and pediatric health care delivery systems. Together, they harness the full potential of biomedicine through collaborative research, education and clinical care for patients. For more information, please visit med.stanford.edu. Related News October 9, 2024 Liver cancer stem cells shown to use immune system as shield to spark disease recurrence A Stanford Medicine-led study found that residual liver cancer cells interact with neighboring macrophages to prompt the disease to reappear. October 9, 2024 Stanford Medicine leaders reaffirm long-term vision, highlight cancer and AI innovation Topics Blood Cancers Cancer All Topics Stanford Medicine Magazine 2024 ISSUE 2 The majestic cell How the smallest units of life determine our health Watch new videos on Stanford Medicine's YouTube channel",
    "commentLink": "https://news.ycombinator.com/item?id=42037386",
    "commentBody": "Scientists glue two proteins together, driving cancer cells to self-destruct (stanford.edu)577 points by Jerry2 18 hours agohidepastfavorite147 comments biotechbio 14 hours agoThere's a decent amount of cynicism in the comments, which I understand. I think this is a really cool and novel study, though. Historically, cancer was treated with therapies that are toxic to all cells, relying on the fact that cancer cells divide quickly and are unable to handle stress as well as normal cells (chemotherapy, radiation). The last couple of decades we've seen many targeted cancer therapies. These drugs generally inhibit the activity of a specific protein that lets the cancer cells grow (e.g. EGFR inhibitors) or prevents the immune system from killing the cancer cells (e.g. PDL1 inhibitors). This mechanism is way more interesting. The gene BCL6 is usually turned on in immune cells when they are mutating to recognize foreign invaders. This process involves lots of DNA damage and stress, but BCL6 stops the cells from dying and is therefore important for normal immune function. Unfortunately, this makes BCL6 a gene that is often co-opted in cancer cells to help them survive. The method cleverly exploits the oncogenic function of BCL6 not by inhibiting it, but by turning it into a guide, enabling the delivery of activating machinery to the targets of BCL6 and reversing the inhibitory effects on cell death. The whole field of targeted degraders, molecular glues, and heterobifunctional molecules is a growing area of interest in cancer research. reply celltalk 11 hours agoparentI haven’t read the paper yet but the news article seemed a bit, meeh. BCL-2 inhibitors, mainly Venetoclax, is used in cancer therapies quite often which also triggers cell apoptosis and it’s very effective. It was also designed to target B-cell related cancers, but it found to be so effective that FDA approved it to be used in primary cases of Acute Myeloid Leukemia. So, killing cancer with triggerring apoptosis is very well known. I think the novel part might be the two protein, so it is probably more targeted for metabolic activities… but yeah didn’t read the paper yet. Anyways, for the side effects a major one could be Tumor Lysis Syndrome (TLS). Basically, if you apoptose the cancer cells super fast, the molecules from those cells spread everywhere and it becomes toxic for the patient. This is at least the case for Venetoclax. reply sylware 9 hours agorootparentHow much cancerous cells are similar to let us know how to target them and deliver a payload? I guess some payload delivering mechanisms expect very 'standard' features from cancer cells? reply inglor_cz 6 hours agorootparentCancerous cells are fairly diverse across individuals, or even within a single individual, and many biological treatments require precise sequencing of the tumor DNA of that individual patient to adjust and work. In some cancers, there is a nasty \"Russian roulette\" effect in play, where a certain treatment may be extremely efficient (in practice a cure, even though oncologists avoid that word) in people with a certain mutation and totally useless in others, even though from the macroscopic point of view, their tumors look the same. reply sylware 5 hours agorootparentThen, basically, each cancer, cancer cells should be sequenced, then based on the type of cell and DNA sequencing, we have a list of \"tools\" to deliver payload to those very cells (without delivering such payload to sane cells, ofc)? reply inglor_cz 4 hours agorootparentThat would be the ideal scenario, yes. In practice, we can only make use of some known mutations. Not just for delivering chemicals, but also for \"teaching\" the immune system to attack such cells, which, once it is able to recognize them, it will do vigorously. Let's hope that this catalogue will grow until it covers at least all the typical cases. reply vlovich123 13 hours agoparentprevWhat would be the kinds of expected side effects of such approaches? reply joconne 12 hours agorootparentMy understanding is that even though immunotherapy's mechanism may seem more natural than chemotherapy and radiation, and in some instances may be a magic bullet, up-regulating the immune system can have serious consequences. I remember reading about a clinical trial showing similar progression free survival but increased grade 4-5 toxicities (requiring hospitalization or being fatal). My assumption was that these are autoimmune conditions that are aggravated in some of the patient population. reply melagonster 12 hours agorootparentprevoop talked about mechanism, so we can't know side effects here. someone will publish a new drug that relies on this mechanism, and then they will check the side effects of the specific drug on cells, rats, or other experimental species. reply steveBK123 6 hours agoprevAll of this stuff is promising, and I hope the diagnostic side catches up as well. Just went to a funeral this weekend for a 40 year old who died of breast cancer 4 weeks after diagnosis at her first annual mammogram. A lot of skeptical people under 30 here haven't lived through regularly various cancer diagnoses in their friends & family group that your late 30s/early 40s starts to bring. I don't have the data on it, but anecdotally I notice that women's cancers seem to strike 5-10 years earlier than mens even if they can be caught early & treated well.. Though apparently men have overall worse cancer survival rates. reply frowin 2 hours agoparentI'm finishing my PhD in hyperpolarization (hopefully) soon. In my opinion, hyperpolarization will significantly contribute to early-stage diagnosis. We're designing machines, processes, and chemicals that create novel contrast agents for MRI, enabling the localization of cancer cells and even tracking their metabolism. For example, it's possible to inject hyperpolarized pyruvate and track its conversion to lactate. Essentially, this technique boosts the MRI/NMR signal of the contrast agent by up to 100,000-fold. When the contrast agent undergoes metabolism, it creates a unique signal footprint through chemical shift changes, which can aid in characterizing cancer. reply whatshisface 37 minutes agorootparentI have a question, if you don't mind. What are the nuclei polarized relative to? The molecules in a liquite rotate a lot and I am curious whether the nuclear spins stay aligned with the electron systems or if they remain fixed in an inertial frame. reply steveBK123 1 hour agorootparentprevSounds exciting. Routine periodic medical imaging seems like one of those Star Trek technologies thats in reach but not quite been implemented outside of rich countries in Asia. reply shaky-carrousel 1 hour agoparentprevFour weeks... I didn't know that it could be so fast. That's awful. reply steveBK123 1 hour agorootparentWe were surprised, but it happens. Breast cancer can be very fast moving. Unless they have family history, women aren't told to do annual exams until you hit 40. The symptoms may not be too specific or startling even when it is into stages 3 & 4. Worth reminding the women in your lives to check their family history and consider getting early exams either way. A lot of times it turns out women do have family history that went undiscussed until they ask mom, aunts, grandmothers, etc. The other cancers that worry me are the slow moving imperceptible symptomless ones like pancreatic, liver, kidney, etc. Know a few people who around 50 discovered they had stage 2-3 cases due to unrelated scans they got from an accident injury. Some of these you have 5-10+ years window to treat it and live without impact to lifespan.. but most people don't catch it until stage 4 when they actually feel sick and it is too late. reply soperj 19 minutes agorootparentprevPancreatic cancer is the worst. Many people don't get a month. reply interludead 2 hours agoparentprevThe urgent need for advancements not only in treatment but also in diagnostics reply fwip 4 hours agoparentprevI believe I read, but can't find the source now, that the sex-specific survival rate is mostly explained by men not catching it and starting treatment as early as women. Even for cancers that shouldn't be sex-specific, like lung cancer, men are less likely to survive it. reply steveBK123 3 hours agorootparentThis is very believable given gender differences in being on top of healthcare.. reply lr0 16 hours agoprevSame as mountainriver's comment. I really find strange how I've been reading news lines over the past years about great advancements in many incurable and chronic diseases (like Alzheimer's, diabetes, and cancers) yet after all that time people's treatment is not going any better. I'm not sure whether scientific journalism somehow delivered some unintended messages to me, or we're just supposed to experience these great advancements after couple of decades from the announcement. reply wbl 13 hours agoparentHIV has gone from death sentence to completely preventable with a single daily pill or every 6 months injection, and readily treatable to the point where we have geriatric HIV patients. Obesity is now effectively treatable even taking into account compliance. Hep C can be cured entirely with just six months of oral medication rather than a barely tolerable intravenous course that didn't work all that well. These are massive improvements that have changed how hundreds of millions of people are treated and their prognosis. The road to the clinic is long, but there have been very big improvements. reply DennisP 3 hours agorootparentAnd stage 4 melanoma used to mean you'd be dead in a year. I know someone who got diagnosed with it almost a decade ago, got three doses of immunotherapy, and is now cancer-free. Doesn't even have to get scans anymore. reply adamredwoods 25 minutes agorootparentMelanoma is the main cancer that responds well to immunotherapy, PD-1 inhibitors. Other solid cancers, not so much, although in combination with other therapies, is seeing some okay results. They recently found some types of rectal cancer to be PD-1 sensitive. https://www.nejm.org/doi/full/10.1056/NEJMoa2201445 reply agumonkey 7 hours agorootparentprevIt seems like stock markets, a lot of bubbles pop, and it's easy to miss the trend .. every 5 years some progress is made. reply Spooky23 14 hours agoparentprevTwo things. If you follow the news closely, but lack specific expertise or knowledge, you develop this nihilistic sense of doom to some degree. The narrative of our age is that everything is in decline. It pulls clicks. The other thing is that cancers are not created equal, not all treatments are evolving quickly. Your loved one may be suffering, and that’s your world. I will say that I lost my beautiful wife a little over a year ago. She had an aggressive cancer, for which the 10-year survival rate was zero. Thanks to the miracle of immunotherapy, the five year survival rate is about 65%. At the same time, my 78 year old aunt successfully fought lung cancer that was a death sentence 20 years ago. reply highwaylights 12 hours agorootparentI’ve nothing to add to the discussion but just wanted to say that, for what it’s worth, I’m terribly sorry for your loss. reply Spooky23 5 hours agorootparentThank you both! I think it’s important to share for a variety of reasons but most importantly to add some humanity to a topic that gets turned into technocrat babble. reply EQYV 10 hours agorootparentprevVery much the same from me. I know +1 posts aren’t generally welcome here but I hope dang can forgive it. reply treflop 15 hours agoparentprevI’m not sure I agree. We now have techniques like immunotherapy for some cancers. Cancer rates still continue to fall. We have a drug now that you can take so you won’t catch HIV, as well as another drug for HIV+ that keeps it at bay. We haven’t found a cure-all. Rather, now we have a lot more treatment options nowadays depending on your specific cancer or illness. reply d_tr 14 hours agorootparentCancer mRNA vaccines for solid tumors are administered to real patients in clinical trials right now. reply hanniabu 14 hours agorootparentSo you'd rather she them before you get cancer? reply mschuster91 10 hours agorootparentAs far as I understand it these immunotherapies are tailor-made to the very specific cancer and its genetics that a patient has, which is also why the stuff is so darn expensive. So you can't have a vaccine until you already have the cancer. reply andkenneth 15 hours agorootparentprevAnd as always, when problems get solved, other problems get revealed. We didn't even really know about cancer until life expectancies got to the point where dying in your 30s is a tragedy instead of being fairly normal. reply xp84 14 hours agorootparentI don’t think dying in your 30s has been normal in the Western world anytime In the last 500 years. Remember all those life expectancy mean statistics were heavily dragged down by the huge infant mortality stats. If your comment was more talking about the Stone Age or something, I apologize for misinterpreting :) reply radicalbyte 10 hours agorootparentInfant and mother mortality stats. reply jezzamon 2 hours agorootparentprevCancer was first documented around 3000 BC, and has been studied for a long time. https://acsjournals.onlinelibrary.wiley.com/doi/10.1002/cncr... reply anonym29 14 hours agorootparentprevThe idea that most people more than ~120 years ago died in their 30s or 40s is a popular misconception. LEAB (Life expectancy at birth) used to be in the mid-30s, but this was largely due to a bimodal distribution of deaths: a large number dying during childbirth, infancy, or early childhood, and a lot at more typical old age (60-70, still a bit lower than is common in much of the west today, but you get the idea). If you made it past puberty, there were pretty good odds of you making it to old age. reply dahart 3 hours agorootparent100%. I carried this misconception after high school and college and was surprised to learn it’s completely wrong. There’s a name for the old-age end of the bimodal distribution: longevity. Longevity is the natural lifespan of people who don’t die of any early mortality factors. Most people who have the misconception are accidentally conflating life expectancy with longevity. A few unscrupulous peddlers of false hope, like Ray Kurzweil for example, intentionally conflate life expectancy with longevity to reinforce the misconception. As I was learning about longevity I started talking to my anthropologist brother about it, and he was like, oh yeah, people who don’t die from war or disease or infection have always lived to be about 80 years old for all of known history. He mentioned there’s plenty of written evidence from, e.g. Socrates’ day, and also lots of human remains that support it from ten thousand years ago. reply wbl 1 hour agorootparentWell we have a lot less disease and infection now! reply dahart 41 minutes agorootparentThis is why life expectancy has gone up, while longevity has mostly remained unchanged (for at least thousands of years). Longevity represents the best we can do, and life expectancy can’t exceed longevity. Life expectancy will asymptotically approach longevity as medicine improves. reply mlyle 13 hours agorootparentprevAside from infant morality, don't forget the massive death load from things like accidental death, famine, and maternal mortality. E.g. from Wikipedia, female life expectancy from age 15 in Britain in the 1400-1500s century was 33 years (so reaching 48 years of age). reply thomassmith65 11 hours agorootparent...and also bubonic plague. reply cyberax 14 hours agoparentprev> people's treatment is not going any better That's not true. It's improving steadily: https://progressreport.cancer.gov/after/survival , and with the newer advances it's going to become even better. Yes, it's not like an exponential Moore's law graph, but there is a steady drumbeat of incremental steps. And they keep reinforcing each other. reply ekianjo 13 hours agorootparentOnly for specific sites of cancer. Many others are just as deadly as they have ever been. reply D-Coder 2 hours agorootparentWell, yes, but that's typically how progress works in any field. reply drawfloat 12 hours agoparentprev10ish years ago Myleoma was a semi death sentence, it’s now coming close to being treated like a chronic condition. There are definitely improvements happening, but we’ll often miss them because it’s incremental rather than “we developed this cure for lung cancer and it’s no longer a problem” Edit: some of the replies below are pretty bleak “it’s just a few months that’s nothing”. The difference between a 5 year and 15 year life expectancy for a parent being diagnosed with blood cancer around 60 is huge. reply master-lincoln 9 hours agorootparentI am curious: why would it make a difference for a 60 year old if they are a parent and have 5 or 15 years vs not? I would have thought by that age children are long independent... reply steveBK123 6 hours agorootparent60+15 => 75, a pretty normal \"lived a full life\" age. 60+5 => 65, maybe dying before you even retire from your job. Seems significant. reply popcorncowboy 8 hours agorootparentprevThe difference between your grandkids meeting you or not. reply steveBK123 6 hours agorootparentExactly - in my father's case would be difference between dying before all your kids marry vs meeting all your grandkids, helping to watch them.. and seeing them grow up and start going to school. reply eCa 8 hours agorootparentprevPlenty of people have kids in their 40s and 50s. reply njtransit 15 hours agoparentprevWhy do you think “people’s treatment is not going any better”? As far as I know, cancer outcomes have greatly improved. reply bb88 15 hours agorootparentIt's the articles that decry \"Big discovery in X\". This could be because the researchers need funding so they will hype the results as much as possible. Then the articles need as much readership so the journalists hype the results as much as possible. Then the people suffering from the disease want as much help as possible so they push the articles/papers to the doctors. On the other hand, it's been my experience that GLP-1 agonsists weren't overhyped, I was completely surprised when my doctor prescribed Mounjaro for weight loss. Even after decades of articles about \"NEW WEIGHT LOSS TREATMENT!\" (See also phen-phen) reply markus92 6 hours agorootparentIt's mostly the PR department of universities that boast about those big discoveries. Researchers themselves usually try to add some nuance to it. reply adamredwoods 10 hours agorootparentprevDepends. Early cancer? Yes, outlook is getting better. Metastatic cancer? It's still very bad outcomes. (Personal experience.) reply ekianjo 13 hours agorootparentprev> cancer outcomes have greatly improved. If you stop believing the bullshit headlines you will see that newer treatments simply increase OS by a few months and that's sufficient to claim significant improvement. In terms of patient outcomes, not a major difference, the cancer still kills you in the end. it's just KPI hacking. reply rowanG077 11 hours agorootparentWhat else is there? Are you saying immortality or bust? reply ekianjo 8 hours agorootparentWhat else is there? Long term remission for example. This is hardly looked at because we don't see any difference. reply rowanG077 7 hours agorootparentLong term remission is just a few months extra to live. In the end you have people who die quickly and people that live for years. That's why you get averages of a few months extra. reply SoftTalker 15 hours agorootparentprevCancer detection/testing has gotten a lot more attention. Detected early, many victims are still alive after 5 years and considered \"cured.\" But it still gets you in the end. A lot of expense and misery while under medication/chemo/rad/surgical therapy and in the end you are dead just the same. reply Spooky23 14 hours agorootparentThat’s the measurement that a lot of Covid deniers liked to roll out. Death isn’t the only metric. Life is a precious and personal thing. Those years mean wishes fulfilled, graduations and weddings celebrated, life lived. reply fzeroracer 14 hours agorootparentprevI'm not sure why this matters. In the end we're all going to die, death is inescapable. The ultimate form of your rationalization is that we should simply not treat anything because we die all the same. But for many cancers and other diseases not only has early detection gotten better but so has treatment and prognosis. Treatment isn't nearly as bad to go through and long term survival rates are higher. People can live longer with cancer while still being fully functioning. reply gus_massa 7 hours agoparentprev> I've been reading news lines over the past years about great advancements in many incurable and chronic diseases There is a lot of overhype in the news. When they claim that a new 80% improvement in batteries we all know it's a joke a laugh. When there is a similar exaggeration in cancer cures we get sad. The saddest part is that the overhype shadows all the small/local improvements. They are better explained in sibling comments. Medicine is not my area so they give better examples than what I can choose. When I read a new about my area or something close enough, it's fun to try to guess what was the original new before it was badly rewrote by the press and how interesting it is. But when there are lives related to the new, it's not fun to read post with unrealistic promises. reply DennisP 2 hours agorootparentThe thing about batteries is that those big discoveries in the lab take a long time to reach the market. By the time they do reach the market, they're just an incremental improvement over all the other big discoveries that are already in production. So we never seem to get a dramatic breakthrough, but what we do get is steady improvement over the course of decades. And that's why we have electric cars now with ranges over 400 miles, while back in 1996 the EV1 had 70 to 100 miles. I think cancer treatments are pretty much the same. reply randcraw 12 hours agoparentprevEach medical innovation overcomes but one hurdle on a path to a treatment/cure, often revealing new hurdles that weren't visible (or important) until the first hurdle fell. A good example is lipid nanoparticles, which for the first 15 years or more of their existence were horrifically lethal in every hominid, making their potential for delivering transformative genetic or immune cargo into cells impossible. Finally, PEGylation was introduced into their formulation, bypassing the toxic effect they had in precipitating out nearly all of each animal's platelets upon treatment. Within just a few years, LNPs became a very effective way to deliver MRNA vaccines to BILLIONS of human patients, effectively ending the worst of the Covid pandemic. Medical revolutions are like evolutionary punctuated equilibrium -- barriers to advancement are overcome nonuniformly and often incompletely, requiring a lot of continued effort even after a revolution begins. So it shouldn't be surprising that more battles are won than wars. We should celebrate whatever victories we can. Cancer promises to be a war to end all wars. reply jimbokun 3 hours agoparentprev> yet after all that time people's treatment is not going any better. What is your basis for this claim? reply z3ncyberpunk 1 hour agoparentprevA lot of it is the case of bad science being popularized and then blindly built upon. This is exampled by the recent redaction of a huge amount of Alzheimer's papers which formed the nucleus of Alzheimer's research. Academia and science are often the largest purveyors of misinformation despite. reply rsynnott 8 hours agoparentprev> I really find strange how I've been reading news lines over the past years about great advancements in many incurable and chronic diseases (like Alzheimer's, diabetes, and cancers) yet after all that time people's treatment is not going any better. ... I mean I think you are possibly not just paying attention. All sorts of things that were absolute death sentences within recent memory are now very treatable. News articles tend to overhype, of course, but cancer treatment now is a different world to a few decades ago. reply dools 14 hours agoparentprevWhen my Aunt was diagnosed with MS in the 80s it was a crippling and degenerative ailment. When my brother was diagnosed with MS ~30 years later, it was a nothing burger. He gets an infusion monthly and suffers no significant impact on his quality of life. reply kemmishtree 15 hours agoparentprevRobust biomarker monitoring in toilets would lead to a 95% reduction in cancer deaths. Robust biomarker discovery in toilets would let us take care of most of the other 5%. That's the main obvious humanitarian purpose of our project www.molecularReality.com reply 8n4vidtmkvmk 14 hours agorootparentHow do I buy an anticancer toilet? reply esperent 13 hours agorootparentPost I spotted earlier today on reddit: > TIL that scientists at Stanford University have developed a smart toilet that reads your anus like a fingerprint and monitors the health of your poop and pee. The lead researcher said, \"We know it seems weird, but as it turns out, your anal print is unique.\" https://old.reddit.com/over18?dest=https%3A%2F%2Fold.reddit.... reply interludead 2 hours agoparentprevYep, breakthroughs get announced, but the real-world impact can feel slow reply echelon 15 hours agoparentprevCancer deaths have been falling since the 90's. Detection and treatments are improving. We don't have a silver bullet because these diseases are so incredibly complicated. \"Cancer\" is a particular type of disease behavior, but is essentially a broad class of failure states across different types of cells and tissues, with different genetic, metabolic, biochemical, and molecular dysfunctions. reply derektank 15 hours agorootparentThe decline in cancer deaths can almost entirely be explained by the decline in smoking. Getting from 40% of people smoking to 15% was probably the biggest public health victory of the latter half of the 20th century reply cyberax 14 hours agorootparentThat's not true. Survival rates in most cancers went up, not only in lung cancers. reply derektank 12 hours agorootparentIt's true that there has been some progress in treating most cancers and particular success in treating some specific cancers e.g. with checkpoint inhibitors. But lung cancer is both one of the most common forms of cancer (it's still third even with the massive decline in smoking) and has a much lower 5 year survival rate than the other most common cancers, breast and prostate. The massive decline in smoking has played an outsized impact on the improvement in reducing both cancer rates and deaths from cancer generally reply bglazer 14 hours agorootparentprevThis is true in the large sense but it obscures that 5 year survival rates have been steadily extending for many people who already have cancer. Treatments are in fact improving reply bb88 15 hours agorootparentprevsimilar arguments have been made about lead and leaded gasoline being made illegal in the 70s. reply narrator 13 hours agoparentprevRemember Calico and Altos Labs which were moonshot cure longevity companies? After years they emerge out of stealth and all they got is some cancer drugs. The gravitational pull of the billions of dollars to treat cancer patients and extend their lives a few more months eats up all the attention of the biotech world because there is such an astronomical amount of money in it and you'll just have to come up with a new way to kill cells which is relatively easy. So usually when people talk about new cancer drugs it meant that great scientists will make billions wasting their lives barely improving the quality of life for some terminally ill cancer patients and it's just kind of sad, honestly. reply Nevermark 12 hours agorootparentOr maybe heroic efforts are being made to solve a very hard but worthwhile problem? You don’t get to decide how long the road is to a complete solution. Just whether it will be worth it incrementally and in the end. You don’t propose any constructive alternative. Life, even just extending life of millions of people a bit, survival rates just a bit, is worth a lot. reply narrator 8 hours agorootparentHere's your alternative that precisely nobody is going to make any money off of : https://isom.ca/article/targeting-the-mitochondrial-stem-cel... reply melling 15 hours agoparentprevI don’t think we’ve made any progress in Alzheimer’s. Where did you read that we have? reply zdragnar 14 hours agorootparentThere have been a fair number of announcements about possible progress, and even several recently related drugs. The research and drugs continue to focus entirely on beta amyloid buildup in the brain: https://www.science.org/content/article/new-alzheimer-s-drug... There's not a shortage of debate on whether they are effective, ought to have gotten any approval, or if beta amyloid buildup is even a cause or contributor to Alzheimer's disease, so whether we've actually made progress remains debatable for the short term until results on these drugs are in. reply throwawaymaths 14 hours agorootparentWasn't a lot of the beta amyloid buildup hypothesis based of of results from Marc tessier Levine who left Stanford under a cloud of accusations of results fakery and is now the CEO of the ai startup xaira? reply ekianjo 13 hours agorootparentYes it was mostly a bad hypothesis on which the industry wasted billions and 20 years. reply melling 7 hours agorootparentprevWell, which is it “great advancements“ or “possible progress “? You’re both saying two different things. reply lenerdenator 15 hours agoparentprevWell, let's see. Some drug company or group of investors must think it's potentially profitable to develop into a real treatment. Then they have to move up the trials ladder, from mice to humans and the steps in-between. Then they have to get regulatory approval. Finally, assuming the steps prior didn't fail horribly, they need to set up the manufacturing for the drug. All the meanwhile handing off money to a bunch of people who, more likely than not, never worked for the company in the form of earnings-per-share. So, yeah, a couple decades. reply ekianjo 13 hours agoparentprev> great advancements in many incurable and chronic diseases (like Alzheimer' There is virtually no new treatment for Alzheimer for 20 years and no progress in understanding its mechanism either. reply uoaei 15 hours agoparentprevThe missing ingredient that makes it make sense is the profit motive. reply weaksauce 15 hours agoparentprevmrna vaccine had big “breakthroughs” during the 80s and 90s and yet it took quite a while for it to be a viable thing. some things take time and some things never pan out past the in a pitri dish stage. reply verisimi 12 hours agoparentprevThis all makes sense once you consider health as a business. There is no great interest by business in a cure to this or that. However, an expensive perpetual treatment (lifetime service contract) is far more appealing - the revenue stream is superior. What we call a 'health' industry is a misnomer - it is a sickness industry, like the ministry of defence is really the ministry of attack. If you want to really get cynical, you can consider the possibility that a lot of treatments are not only unnecessary, but actively detrimental to the person receiving the \"treatment\". The person in future may develop diseases that will then open further revenue streams from what would otherwise be a healthy individual. This would assure a healthy pipeline of future revenue for the pharmaceutical companies. Luckily we have government agencies to manage the pharmaceutical products we are given. Unfortunately, it is something of an open door policy as senior government staff are then given senior positions in pharmaceutical companies. I'm sure it all works out in the end! reply JumpCrisscross 8 hours agorootparent> There is no great interest by business in a cure to this or that Of course there is. Cures make billions. This might be a conspiracy theory stupider than flat Eartherism. It requires not only every Western pharmaceutical company’s collaboration, but also every one in every other country, and also all the public labs, and every world leader and their families to suck it up for the conspiracy’s sake. reply verisimi 6 hours agorootparentGoldman Sachs analysts agree with me! https://m.youtube.com/watch?v=2m-u4cr3fJ0 Most people act against their conscience pretty much every day for money, more so in senior positions. That money is a great motivator is not really a conspiracy. reply JumpCrisscross 6 hours agorootparentGo beyond the YouTube video reporting on the report's title and you'll find a thoughtful paper on drug pricing. TL; DR Sick people and governments will pay a lot for cures. > Most people act against their conscience pretty much every day for money, more so in senior positions This isn't about conscience, it's about greed. Cures are great business. Also, again, rich people get cancer. If you want to come up with healthcare conspiracies, don't pick a disease the rich and powerful get. reply adastra22 14 hours agoparentprevBlame the FDA. It is near impossible to get these treatments out to patients. reply equasar 14 hours agorootparentCan other countries conduct trials for these treatments at the patient's own risk? reply adastra22 10 hours agorootparentTrials? No. There are various other countries you can go to in order to have these unapproved treatments performed, at great personal cost because there are no economies of scale. But there largely aren't countries performing trials that would count as an FDA Phase II or Phase III trial. reply reverius42 9 hours agorootparent> at great personal cost because there are no economies of scale I didn’t realize the USA was the only Economy of Scale reply adastra22 1 hour agorootparentI’m talking about treatments that aren’t approved anywhere. reply 2Gkashmiri 13 hours agorootparentprevi find this funny. what do you mean \"patient's own risk?\" that has always been the case. you go for a minor surgery, you sign a waiver. you go to a doctor, they are supposed to give reasonable care. No one can guarantee success. the same with lawyers or drivers or mechanics or technicians. basically anytime you go to someone for assistance, they can't guarantee anything. the person is themselves always responsible for everything. reply dahart 3 hours agorootparentOf course there’s always some risk with any drug or medical procedure. But - obviously - not all risk is equal. Unapproved treatments are riskier because they haven’t been proven effective, and they haven’t been well tested for side effects. There is an uncountably large list of cases throughout history of people willing to sell ineffective and/or actively harmful treatments, which is the whole reason the FDA exists. Look up people who died taking ivermectin for Covid [1], or just pick any ailment and do some research on fake treatments, perhaps cancer for example [2]. The UN says half a million people in Africa alone are being killed every year by fake medicine today, currently [3]. [1] https://www.unmc.edu/healthsecurity/transmission/2023/03/14/... [2] https://en.wikipedia.org/wiki/List_of_unproven_and_disproven... [3] https://www.un.org/africarenewal/magazine/february-2023/fake... reply adastra22 1 hour agorootparentHistory is also full of examples of treatments that do work under unknown (at the time) circumstances and were standardized into common practice through trial and error. This includes most over the counter medication and procedures today. Most of that advancement stopped with the introduction of the FDA and its equivalents in other countries. The story of efficacy trials falls apart when you consider the complex reality of the human body and pharmaceutical action. There are many medical procedures and drugs which we know work on certain patients some of the time, but we are prevented from giving to new patients because the high standards of Phase III efficacy haven’t been met. reply dahart 47 minutes agorootparentSo what? The U.S. food and drug laws aren’t protecting against things that accidentally work, they are protecting against things that don’t work. These laws are hard won and represent many people lost to both ignorance and greed. If something has efficacy, then trials will eventually prove it, it’s just a matter of time. You just made a case that the process works. If efficacy can’t be shown, then it’s very risky for people to try the treatment, riskier than using something with known outcomes, and potentially riskier than doing nothing at all. Either way this is all irrelevant to your bogus claim at the top that the FDA has anything to do with the perception that treatments aren’t improving. The top comment’s hypothesis is incorrect, which adds to the multiple reasons your proposed explanation is wrong. reply adastra22 10 hours agorootparentprevWith the FDA rules they are not legally allowed to offer such services, however. reply unit149 9 hours agoprevInducing ketogenesis whose byproduct is the retention of water and generation of ATP has historically acted as an epiphenomenal method of apoptosis. Survival rates vary but fasting has proven to be an effective method. reply Funes- 1 hour agoparentA ketogenic diet or a strict fasting regimen are two health strategies that are too frowned upon, still, and unfortunately so. Food (or whatever passes for \"food\" in modern times) has become such a crutch, and people have such potent emotional ties to it, that the sole idea of restricting one's diet will come across as negative from the get go. Nonetheless, there have been advancements in that regard, culturally, I believe. reply dottjt 11 hours agoprevHopefully it can help people with Sarcomas. My partner was diagnosed with stage 4 sarcoma about a month ago and life as I know it has been flipped upside down. reply danieldbird 8 hours agoparentFirstly im so sorry to hear this. I can completely empathise as i lost my father who was my best friend to Pancreatic Cancer. Like you, one day we were fine and joking, the next day my world collapsed with the news. Uncontrollable sadness, then anger, then desperation and the why me / why my dad. I just wanted to write to you to say that you are not alone. You dont know me, i dont know you, but i wish you and your partner well and send thoughts and love. It is a surreal thing to happen. I remember looking at other people living their regular lives smiling and laughing and thinking, how can they be happy. An unbelievable amount of varied emotions. Seeing really unhealthy people, or bad people on the news, and i know this sounds bad, but wondering, why us, why not them. Just mind spinning type stuff, a plethora of every conceivable emotion. I hope you have loved ones you can vent and talk to. Again, you’re not alone. reply adamredwoods 10 hours agoparentprevI'm so sorry. We all hope for a magic formula, but even with clinical trials, bench-to-bedside takes years. >> the chimeric compound killed only diffuse large cell B-cell lymphoma cells reply dottjt 8 hours agorootparentIt's been a very weird 6 weeks. It's like, everything was fine. We had our normal suburban life. Things were going great. We had just celebrated our daughter's first birthday. Then it's like, you realise that everything you had imagined over the next 40 - 50 years is suddenly not going to happen anymore, and it just feels so surreal. Thankfully, a lot of the initial hysteria is gone. But there's definitely a sense of \"why me?\" reply elcritch 8 hours agorootparentSorry about your partners disease. Learning such news about loved ones is difficult. I have a chronic condition and spent years wondering \"why me?\". Now my thoughts are more like \"why not me?\" and to try and embrace what life we're lucky to get and live day by day. Godspeed reply adamredwoods 2 hours agorootparentprevTime slows down. We spent our lives week by week. I was her care taker and hope-keeper, and I would share oncology news like this with her to help keep our family sane. I think it helped. reply mattigames 8 hours agorootparentprevThe \"why me\" for others is the first time they realize they have a chronic illness, that sudden realization that the universe is an uncaring dance of atoms, the realization that every attempt at ordering it's just a house of cards, including our DNA and everything else we rely on. I was expecting myself to land that line of reasoning into some comforting words but I have failed miserably ha, hold on tight. reply rkuzsma 8 hours agorootparent“There is no justice in the laws of nature, no term for fairness in the equations of motion. The Universe is neither evil, nor good, it simply does not care. The stars don't care, or the Sun, or the sky. But they don't have to! WE care! There IS light in the world, and it is US!” ― Eliezer Yudkowsky, Harry Potter and the Methods of Rationality reply kibwen 6 hours agorootparentI don't like this quote because it suggests a sort of separation between ourselves and the universe, or it suggests that the universe is some all-powerful omnipotence that might deign to heal us if only we could supplicate ourselves to it, but that's mistaken. We're made of all the same stuff as those stars. We are the universe, and if we care, that means the universe cares as well. When we have the power to do something, that means the universe has the power to do something. reply TylerLives 7 hours agorootparentprevMattigames, there is a logic flaw in your little aphorism that seems quite telling. Since you and I are part of the Universe, then we would also be indifferent and uncaring. Perhaps you forgot, mattigames, that we are not superior to the Universe but merely a fraction of it. reply zackkatz 6 hours agoprevStrange: the New York Times wrote about this on July 26, 2023. https://www.nytimes.com/2023/07/26/health/cancer-self-destru... reply Duller-Finite 5 hours agoparentThat describes a related but previous Nature paper from the same group, whereas this is referring to a more recent Science paper. reply mannyv 2 hours agoprevThe next challenge is getting the protein in there. reply szundi 11 hours agoprevI love these headlines reply moffkalast 9 hours agoparentUsing prions to destroy cancer, pitting one cosmic horror against the other. Nice. reply mountainriver 16 hours agoprevI feel like I’ve heard this before, is this something that is actually novel? reply staplung 16 hours agoparentHard to tell. The cynical response is that the novelty is that it's coming from Stanford. The perhaps more correct response is that the novelty is the mechanism of triggering the apoptosis and the specificity. Here's a paper from 2018 that discusses the prospect of using apoptosis for cancer treatment. They even talk about BCL-2. https://pmc.ncbi.nlm.nih.gov/articles/PMC5855670/ reply emporas 14 hours agoparentprevTriggering the automatic cell death on demand, instead of a period of time, i.e. apoptosis, sounds pretty smart and novel. After 7 years all of our cells die and regenerate, but using biochemistry and some endogenous proteins glued together to control that period of time, i haven't heard about it before. Not a medical expert, but cancers have a vast number of variations in the type of the cancer cell they create, but one common characteristic of all cancers is that they are derived from our own cells. So they should respond to some \"commands\" our own cells follow. Inducing apoptosis for cancer prevention and treatment is old news though. Fasting, water fasting that is, causes apoptosis of cells en mass and has proven to be very effective in minimizing radiotherapy or chemotherapy sessions, and even a total treatment. Instead of doing 20 chemotherapy sessions, reducing it down to 1 or 2 and the cancer is gone. Anyway, someone doing the same using a biochemical pathway and light up gene expression, is pretty novel. reply bglazer 14 hours agorootparentI think you’re overstating the “proven” effect of water fasting. That said I’m surprised and happy to see that several academic medical centers are running trials of fastingin conjunction with chemotherapy. https://www.cedars-sinai.org/discoveries/fasting-as-next-ste... reply emporas 14 hours agorootparentI meant \"proven\" when done by the patients themselves, not by the doctors necessarily. Dr. Gundry has done an interview with a martial arts guy who was diagnosed with cancer, and fasted for 20 days only water, and 20 days a little meat and nothing else, and one or two sessions of chemotherapy or radiotherapy later he was clear of cancer. There are many people who talk about same experiences, from the patient side. If some doctors are seriously researching fasting and cancer treatment, that's going to produce some measurements instead of relying on anecdotes. I cannot find Gundry's interview, it's 5 years old something like that. reply AuryGlenz 13 hours agorootparentYou’ll find anecdotal “evidence” for all sorts of stuff when it comes to cancer. Some of it is just woo, others might just work for really specific genetic mutations, etc. Fasting in general has been known for quite a while but (and I’m far from an expert) it only helps with certain cancers. Hell, I had a friend die this year from stomach cancer and he literally couldn’t eat or drink. He only went to the hospital when he was already skin and bones, got a few chemo treatments, and then it was too late. reply SanjayMehta 16 hours agoparentprevIt’s due to the phrase “self destruct.” For some reason people who write headlines like using this in the context of cancer cells. First noticed it in 2010 when I was researching multiple myeloma treatments for my father. It’s medical clickbait. reply F-Lexx 15 hours agorootparentIsn't the phrase \"self destruct\" just meant to be a popular term of referring to apoptosis or programmed cell death in general? reply bulbosaur123 9 hours agoprevWhen can this be used to cure prostate cancer? reply equasar 11 hours agoprevWonder if the study is freely available without paywall. reply Faaak 10 hours agoparentSci-hub.pub reply jobigoud 7 hours agorootparentIs this still working? Am I being blocked at the ISP level? For me sci-hub.pub opens a simple page listing other sci-hub URLs, but each and every one of them fails, ending in \"Unable to connect\" as if the server did not exist. (Tested: sci-hub.ee, sci-hub.ren, sci-hub.ru, sci-hub.se, sci-hub.st, sci-hub.wf). Is sci-hub still working for people, I haven't been able to use it for a while. edit: Wow, it works if I go there via VPN… incredible. So sci-hub is illegal in France? reply Retr0id 3 hours agorootparenthttps://en.wikipedia.org/wiki/Internet_censorship_in_France#... reply aetherspawn 13 hours agoprevThis seems too straightforward to be credible? If I was researching in this field surely this is the first thing I’d try? If it is indeed credible … this sounds like the “CRISPR moment” of cancer treatment, sure. And I’m really happy for that. But I will be honest and write what I’m thinking: if this is real then frankly I’m disappointed it took this long. Do we really have our best people working on cancer? I have known so many who died waiting. It seems like there has been roughly the same investment this decade (around $200B) in climate tech compared with cancer research, and yet electric cars and batteries are now a “solved problem” that’s just waiting to scale. The progress with Cancer is noticeably less. Is the money being well spent? Or are we donating $100B-s for researchers and labs to sit on a gravy train making sub tier progress. Here’s a wild theory. Perhaps as a society we built the wrong prerequisites to get into cancer research and we filtered out all the Mozart’s and Leonardo’s… reply pama 12 hours agoparentI work in this area. It took time to know what each protein does in a cell (we still dont really understand most of them), it took time to find all the ways that various cancers use the protein machinery in the cell to their benefit (new ways are still being discovered these days), it took time to think about molecular glues and turn them practical, and it took time to build the right chemistry and then test it (it takes time even after you know all of the previous steps.) It will still take years, possibly over a decade before this particular development can lead to a drug that passes human clinical trials and is eventually approved. It is not the lack of geniuses that slows things down, rather it is the very careful consideration of risks to minimize the loss of human life during experimentation, and the attempt to optimally allocate the resources across too many different challenging problems in order to maximize the long term benefit to society. The true amount of money spent in cancer research is much higher than the $200B over a decade that you mentioned, however the vast majority of it is just capital losses of various companies spent on the tools and research in early stage discovery across tens of thousands of projects, and a separate huge and more obvious chunk goes to attempts and failures at human clinical trials. The cost of drug discovery has stopped increasing exponentially during the last decade but is still pegged at several billion dollars per approved drug without counting costs from competitors who never get anything approved. reply krisoft 6 hours agoparentprev> If I was researching in this field surely this is the first thing I’d try? Let me ask a clarifying question: Are you saying that the first thing you would have tried is to synthesize bivalent molecules that link ligands of the transcription factor B cell lymphoma 6 (BCL6) to inhibitors of cyclin-dependent kinases (CDKs)? Or are you just saying that you would have tried to drive cancer cells to self-destruct (but have no clue how)? reply aetherspawn 5 hours agorootparentWith a little domain knowledge and research you find out pretty quickly that: BCL6 is lymphoma. CDK regulate cell death, amongst other things. So yes, I am saying that it seems very straightforward as an approach to attempt to trigger a CDK cell death when BCL6 is present. It seems hard to believe that it is presented as novel with the amount of funding that has been spent on cancer. reply krisoft 5 hours agorootparent> With a little domain knowledge and research you find out pretty quickly That's cool. Where do you think that domain knowledge comes from? Did we just found it in a fortune cookie? Or does the cancer research conducted has something to do with that we have this knowledge? > BCL6 is lymphoma. That's not correct. BCL6 is a protein, or a gene which codes that protein. Mutations in BCL6 can lead to B cell lymphomas. BCL6 is not lymphoma. > I am saying that it seems very straightforward as an approach to attempt to trigger a CDK cell death when BCL6 is present. Excellent. Sounds like you are an oracle of oncological research roadmap. What should be the next target to develop drugs for? reply lawrenceyan 2 hours agoprevCurrent SOTA (state of the art) treatment for cancer is: Sequence patient's tumor mutanome distribution, create personalized therapy encoding the top N neoantigens + Anti-PDL1 checkpoint inhibitor + mRNA encoded albumin-IL2 reply skibidisigma 11 hours agoprevWe got a cure for cancer before gta 6 reply midtake 14 hours agoprev [–] I am tired of news like this that never gets anywhere. We have a billion way to destroy cells, great. Let's get a reliable delivery system working now. While that is in the works, I will stick to fasting and other simple methods of decreasing oxidative load. reply adamredwoods 10 hours agoparentAs someone who tried to keep a cancer patient alive for as long as possible, this type of news offers hope, and encourages young people to become oncologists and researchers, which we so desperately need. reply elcritch 8 hours agoparentprevThe entire point of this research is to develop a targeted delivery mechanism based on malfunctioning gene activations. It's a simple but clever approach IMHO. reply v3ss0n 13 hours agoparentprev [–] Bought out and shutdown by profiting businesses as usual. reply purplethinking 8 hours agorootparent [–] No, this whole spiel of big pharma wanting to keep people sick is insane. That could work if there was a single pharma company in the world, but all it takes is one company making an effective cure for a disease and they will make big bucks. Even if you think the people in charge are evil profiteers, we all win in the end reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Stanford Medicine researchers have created a molecule that induces cancer cell self-destruction by linking two proteins, activating cell death genes.",
      "This innovative method targets diffuse large B-cell lymphoma by connecting the BCL6 protein, which inhibits cell death, to CDK9, an enzyme that triggers apoptosis (programmed cell death).",
      "The research, published in Science, is undergoing further testing in mice and may lead to clinical trials, with funding from institutions like the Howard Hughes Medical Institute and the National Institutes of Health."
    ],
    "commentSummary": [
      "Scientists have devised a method to induce cancer cell self-destruction by binding two proteins, targeting the BCL6 gene, which aids cancer cell survival.",
      "This technique is part of the trend towards targeted cancer therapies, aiming for precision over traditional treatments like chemotherapy.",
      "Challenges include potential side effects and the necessity for personalized treatments based on individual tumor DNA, yet advancements in research provide hope for more effective solutions."
    ],
    "points": 577,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1730680978
  },
  {
    "id": 42038653,
    "title": "I've had a change of heart regarding employee metrics",
    "originLink": "http://rachelbythebay.com/w/2024/11/03/metrics/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=42038653",
    "commentBody": "I've had a change of heart regarding employee metrics (rachelbythebay.com)468 points by zdw 14 hours agohidepastfavorite297 comments ethbr1 13 hours ago>> [Why not build programmer performance measurement tooling?] It's the job of a manager to know what their reports are up to, and whether they're doing a good job of it, and are generally effective. If they can't do that, then they themselves are ineffective, and that is the sort of thing that is the responsibility of THEIR manager, and so on up the line. Agreed wholeheartedly, but for slightly different reasons. To wit, laziness and Goodhart's law. [0] In the absence of infinite time, automation will excuse a lack of manager curiosity, as other competing tasks absorb the freed time. Consequently, most managers with automated dashboards showing performance metrics won't use those dashboards... plus all the person-to-person work they were previously doing. They'll only use those dashboards. Which then slowly but inexorably turns your employees into dashboard-optimization drones via operant conditioning. Helping a colleague doesn't show up on the dashboards? Fuck that. Digging into what looks like a security vulnerability isn't on the sprint board? Fuck that. Which is incredibly corrosive to quality, creative system design. And then, because this is the work reality you've created, the creative folks you really want working there bail for greener pastures, and you're left with bottom of the barrel talent and retention problems. [0] https://en.m.wikipedia.org/wiki/Goodhart's_law reply bigiain 12 hours agoparent> Helping a colleague doesn't show up on the dashboards? Fuck that. Digging into what looks like a security vulnerability isn't on the sprint board? Fuck that. Managers who are the sort of people who don't value helping your colleagues or being curious/concerned enough about potential security problems, are most likely the sort of people who won't pick up on any of that being a valuable use of your time during one on ones or in standups either. I think fundamentally you agree 100% with Rachel, shit managers are shit and nobody owes them tooling to make their job of being a shit manager easier. If you want all the employee loyalty and long tenure institutional knowledge of a micro managed call centre, sure - implement checkin and LOC dashboards, or Jira ticket \"velocity\" charts. Watch all your talented people leave and don';t be surprised when everybody is only there because they're desperate or comfortable. Your entire dev team will eventually be only working-visa-prisoners, talentless-seatwarmers, or people who've dialled the give-a-shit down so low it doesn't bother them just picking up their pay checks. reply agentultra 6 hours agorootparent> people who've dialled the give-a-shit down so low In the age of stock buy-backs, cyclical lay-offs, and record-high executive compensation I sympathize with these folks. It might even be morally correct thing to do. reply Jcampuzano2 5 hours agorootparentAs someone who's company has gone through the constant cycle of layoffs including one that happened just a few weeks ago, I'm at this point now and I have no qualms of all the other people who are also here at this moment. I get exactly what is asked of me to do and nothing more, no longer respond to things outside of work hours and collect my paychecks. I still enjoy learning new tech and whatever the next thing is, but my interest in applying myself to my day job is at an all time low. Oh forgot to mention our execs bonuses and stock went up despite everyone hating it here now. reply alsetmusic 2 hours agorootparent> I still enjoy learning new tech and whatever the next thing is, but my interest in applying myself to my day job is at an all time low. I’d say you’re relatively lucky. I found it soul-crushing when my work changed from something in which I took pride to something where I just wanted to coast and no longer cared. Management sucked and I was depressed at my lot in life. I didn’t have much energy to look for and apply to other positions. Layoffs came twice and getting let go was the biggest favor they could have done for me. My next (current) job is rewarding, and I’m again having fun learning new things in my downtime instead of vegging out on streaming content after work. reply gtirloni 5 hours agorootparentprevI don't. All you mentioned have zero impact on my daily work. I could as well say that in the age of Tiktokers earning millions, why should I care about my work? I care about my work because it's my work and I don't want to just collect paychecks. If you're not happy and can leave, just leave. Go do something productive with your life that makes you proud of. Life is too short to play by others' rules. reply Jcampuzano2 4 hours agorootparentIts a hard pill to swallow but I just want to point out that if you look around you at most jobs, including highly paid tech jobs - most people do not care about the job itself apart from the fact that it compensates them well - whether that be with salary or with time/benefits. And not everyone simply has the choice to just find another job when they are unhappy. I know you caveated that with the \"if you can\" but I'd say the vast majority of people can't. That and the fact that most peoples work is not actually theirs as you say. Everything you do is part of the company, and managers/execs take credit for the work all the time at many companies. reply agentultra 19 minutes agorootparentprevFulfilling your obligations under the terms of your employment contract doesn't mean you don't care about your work and aren't acting professionally. For a lot of people work isn't a passion project, it's literally the only way to have a roof over your head and food on your table. If you happen to enjoy it that's a bonus and not a requirement. reply enraged_camel 3 hours agorootparentprev>> All you mentioned have zero impact on my daily work. Are you sure? My GF’s company went through two rounds of layoffs this year and she now has such a heavy workload that she works most evenings and some weekends as well, and her stress level has gone through the roof. reply ethbr1 2 hours agorootparentGiven how common this is with layoffs, it feels like backpressure is needed. Specifically: task shedding when they exceed available hours If you're the last one keeping the lights on for a 4 person team, it seems reasonable to let some lower priority things go undone and communicate to your boss that \"You don't have time for that.\" Trying to ratrace to keep up with an unreasonable amount of work is just rewarding a company for overworking you, by avoiding sending it the hard signal of \"too much work.\" reply effingwewt 3 hours agorootparentprevThis is happening to me in the trades. Im in maintenance as an industrial electrician. New plants came to town paying current market rate and snagged most of the top talent. Then the company started quiet-firing to avoid layoffs. It killed all motivation. Then they froze hiring as we kept losing people. We are now short on HVAC, mechanics, and electricians. Lucky me I'm the only guy who can do all three so im running ragged all day. We have response times we have to meet but our vehicle (an electric GEM) had the charger die, it's only $2k but they won't let me order it so we all walk everywhere. Huge plant I easily bust 30k+ steps and 20+ stories climbed via stairs. We then had a mechanic and an electrician take paternity leave so we are even more shorthanded. Still wont let us hire. We lost the maintenance manager and cant get another one for what we pay and the condition the business is in now. I love my job andy co-workers but I'm sending out resumes and interviewing because I can't take all the extra workload with no extra pay while our administration keeps getting more money and bonuses. How do companies keep making the same mistakes over and over expecting different results? They don't, they know what's going on and are getting theirs before the bottom falls out. reply ninininino 1 hour agorootparentIf your company: * needs HVAC, mechanics, and electricians to function and deliver revenue * your company cannot afford to hire new people, only maintain their current payroll, or are unwilling to raise wages to be able to hire more (not enough talent) * you are able to do all three, but are being asked to do more than want or are able to do then there's a simple outcome that to me it seems like you're missing. you can just say \"I can't\", or \"no, I'm going home at 6\" or \"cool, that's a great plan but I only have time to do the first half of the tasks you just described today\", and most importantly - your company simply won't be able to afford to do anything about it. What are they gonna do? Fire you and be even more fucked? Seems like if you set firmer boundaries on how much you can work, their best decision is going to just be accepting it. Because their only alternative is to even stupider which would be to fire you and have no work get done at all. reply effingwewt 59 minutes agorootparentNot really. I just came off night shift and was thrown right back on it. We work 12 hour shifts, they alternate between forced overtime and disallowed overtime at their whims. When I brought up I have yet to get my float (4x10s considered the 'easy' shift) I was told there was nothing they could do. All I could think was well how will you handle it when I leave? Management really is that dense. They care not one whit about objections nor people leaving. Imho it's merely a matter of time but the younger guys all hold out hope. I've none left. reply haswell 4 hours agorootparentprevEven if my employer doesn’t deserve my dedication, it’s the end-user impact and personal cost of not giving a shit that concerns me. People building software are often in a position to directly impact significant numbers of people: not giving a shit leads to severe software vulnerabilities, data leaks leading to identity theft, compromised systems, etc. Real disruption to the lives of normal people. And actively not giving a shit gradually changes the person doing so. I’ve seen this mindset become corrosive and has changed people who I previously respected in ways that I really don’t think could be beneficial or “good” regardless of what the company does or does not deserve. Not giving a shit is why our industry is increasingly under scrutiny by regulators - for good reason. I question a moral calculus that only accounts for the problematic business practices of an employer while ignoring the many potential downstream impacts that are unrelated to those practices. There’s a needle to thread in terms of how one handles their emotional state while working and finding a healthy balance between doing good work and not dedicating one’s life to their employer (which I’m not advocating btw). But I’m increasingly skeptical of the idgaf mindset and frustrated by people who don’t take seriously the privileged position they’re in and the world changing impact of the work they do. The only truly moral option in many cases may be to quit (if the alternative is not giving a shit). But people want/need that paycheck. reply zrail 4 hours agorootparent> people want that paycheck In most cases people _need_ that paycheck. You can talk about morality all you want if you have the privilege to not need a paycheck, but you can't know everything about everyone's lives. You mostly only ever know about the choice someone else makes. You hardly ever know what options they had to choose from or the tradeoffs they need to think about. reply haswell 4 hours agorootparentThat’s completely fair, and I slightly edited my comment to include the word need, because I strongly believe what I said applies to both dynamics. reply rightbyte 3 hours agorootparentprev> And actively not giving a shit gradually changes the person doing so. I’ve seen this mindset become corrosive and has changed people who I previously respected in ways that I really don’t think could be beneficial or “good” regardless of what the company does or does not deserve. Ye turning into a cynic is not nice. You can rationalize all you want but the corp is eating your soul, more or less. A problem I observed is when cynics from bad places move to hardly OK places, and overestimate the amount of badness. People that think the corporation is rotten seems easier to make do rotten things, while others that \"don't get it\" might protest. reply idunnoman1222 3 hours agorootparentprevThe subset of software that I can’t opt out of is small. Not that the regulators are competent… but for opt in software it’s user beware reply walls 4 hours agorootparentprev> not giving a shit leads to severe software vulnerabilities, data leaks leading to identity theft, compromised systems, etc. Real disruption to the lives of normal people. None of this affects me. The only way to make an employee care about this kind of thing is to pay them, and treat them, well enough to care. You also need enough free time to care, which isn't nearly as common now that every team at every company is running on a skeleton crew. reply haswell 4 hours agorootparent> None of this affects me Frankly, that’s a huge problem. > The only way to make an employee care about this kind of thing is to pay them, and treat them, well enough to care. The workforce is absolutely full of people who value their work and its impact on other people above all else regardless of how poorly they’re paid or treated. This is not an endorsement or acceptance of the status quo, but a recognition of the importance of one’s actions. If you’re a teacher, bus driver, emergency responder, nurse, transit operator, power/gas workers etc. you’re most likely not getting paid much or nearly enough, but would never dream of bringing this “idgaf, pay me” attitude to work. I suspect it’s because software is so abstract and the people building it are so far removed from its impact, but our industry seems uniquely disconnected, complacent, and entitled when discussing the impact of an individual’s actions. reply walls 3 hours agorootparent> The workforce is absolutely full of people who value their work and its impact on other people above all else regardless of how poorly they’re paid or treated. They're called juniors, and haven't yet been broken by the system. > If you’re a teacher, bus driver, emergency responder, nurse, transit operator, power/gas workers etc. you’re most likely not getting paid much or nearly enough, but would never dream of bringing this “idgaf, pay me” attitude to work. Have you seen the state of these professions? That's the prevailing attitude at the moment, and the reasons are obvious. reply haswell 3 hours agorootparent> They're called juniors I’m 20 years into this, not a junior. And the people I’m talking about certainly aren’t juniors. I’m not questioning the existence of people who stop caring. I’m saying that this is a choice, and one that many people can’t bring themselves to make. > That's the prevailing attitude at the moment Attitudes and actions are two different things. If people in many of those professions were acting like many do in the tech world, people die as a result. I’d be careful not to project your own view of this matter on the broader workforce. reply chipdart 11 hours agorootparentprev> Managers who are the sort of people who don't value helping your colleagues or being curious/concerned enough about potential security problems, are most likely the sort of people who won't pick up on any of that being a valuable use of your time during one on ones or in standups either. This is not a \"sort of people\" problem. This is a metrics problem. It's not only developers who are evaluated by using useless metrics that don't track the value you add to an organization. Low-level managers are too. Low-level managers need to evaluate the people assigned to them, they need to evaluate them objectively, and they need to give an unbiased and objectively verifiable score. This means something they can measure, such as metrics or verifiable goals. If low-level managers cannot do this, they will need to answer why they gave X and Y this score whereas poor little Z who outworked them both was scored lower. Not being able to objectively justify a score is a problem that no manager wants to have, as this is a major liability. Hence the bullshit metrics and absurd goals. They need something on paper to back up their decisions. A manager might be fully aware that you unblocked half your team members throughout the year with critical help, and that you are the go-to guy to solve critical issues. But if your team members close twice the tickets you did, they will have trouble justifying you are contributing as much as them. reply gradstudent 10 hours agorootparent> But if your team members close twice the tickets you did, they will have trouble justifying you are contributing as much as them. The metrics make reporting to higher ups easier, no doubt. But the situation you describe is a classic sign of a shit manager: one who cannot justify their decisions except via reference to made up metrics. reply Arainach 9 hours agorootparentUnfortunately, a lot of things boil down to metrics, even at companies with great engineering cultures. If you have four L4 engineers on the team, all of whom are performing at the level described in the career profile as L5, but only budget to promote two of them, how do you pick which two? What if they have different managers, all of whom sincerely believe their report is the one delivering essential value? If you have an organization with forced bucketing where X% of your team need to be given a subpar rating, how do you decide which one? If you don't have an obvious low performer you'd better have metrics. This system is soul crushing but it exists all over the industry. reply csa 4 hours agorootparent> If you have an organization with forced bucketing where X% of your team need to be given a subpar rating, how do you decide which one? If you don't have an obvious low performer you'd better have metrics. If you’re a manager in this type of system, your job is to reach out constantly and find folks who are low performers and get them into your department. They will fill the bottom of your team rating chart. At that point, they can be managed out (ideally in a humane way) or just held onto to fill that cellar dweller role while not slowing others down (some people are ok with this as long as they get paid). I would never choose to work in an environment like that, but some people find themselves there without better options (e.g., being location-bound due to family, etc.). reply throwaway2037 4 hours agorootparentWow, I never saw this type of advice before, but I like it. In short: If you are required to do stack ranking, where at least one person must get a shitty score/grade, then recruit someone internally who is below average and will take the hit. Brutal, but practical. reply ryandrake 2 hours agorootparentOr externally! I posted an idea here a while ago, where I thought I'd start a staffing company called \"Scapegoat Consultants\" and we would offer your team a \"low performer\" that you could hire and then fire after a year, to protect the rest of your team from stack-ranking. Our consultant will join your team and do as little as you want, or even nothing at all! We'd guarantee that they will at least not actively make your code base worse, but that's it. After a year of this, you can easily make the case that our recruit was a low-performer and manage them out. Don't worry, he won't mind--his job was to be the low performer, and we'll hire him out to the next BigTech company who struggles with stack ranking. It used to be tongue in cheek, but maybe the industry actually needs something like this. reply Calamitous 23 minutes agorootparentCynical, but probably the most humane take I’ve seen here so far. reply bolasanibk 2 hours agorootparentprev“Hire to fire”. Not a new idea. I have been hearing it for at least 5 years now. reply gradstudent 9 hours agorootparentprev> how do you pick which two? You (=hypothetical manager, please excuse second-person tense) use your managerial skills to make a decision, which considers metrics and other contributing factors. Then you write a justification which you defend, to higher ups and to those who weren't promoted. Because that's your job. reply jjav 5 hours agorootparent> Then you write a justification which you defend, to higher ups and to those who weren't promoted. What happens next is this manager gets a low performance rating themselves, for making decisions not backed by metrics. So next year they conform. reply ryandrake 2 hours agorootparentThis \"don't make a decision unless it is 100% derived from metrics\" mentality I just don't get. A robot could do that. Why is your company out there trying to hire/promote smart managers with good judgment if they don't let those managers apply their brains and judgment? \"If employee's measured results > threshold, then reward employee\" can be done by a computer. No need for a human manager. reply eesmith 7 hours agorootparentprevYes, the Nuremberg defense - \"I was just following orders\" - is one approach. It's a lot easier than applying back pressure, fighting for your reports, or quitting in solidarity. \"Sorry, Hugo and Maryna, you two only got the Fields medal while Anton and Alain got a Nobel Prize, so we'll have to let you go for your under-performance.\" reply Arainach 59 minutes agorootparentHere's how this works in practice: * Corporate says \"here are the buckets. They should match at the VP level since that's a large pile of people\" * VPs tell their Directors to match these buckets, who recurse further * L1/2 Manager Alice says \"my team is too small, this isn't how statistics work, I want an exception\" * Problem #1: the teams with actual low performers will often make similar claims * If the claim actually gets escalated all the way to the VP, the VP says \"tough, fit the buckets\". * Alice is now a troublemaker in VP/Director's eyes * If Alice and everyone who feels the same way quits in protest, nothing changes except that the org is full of yes men, none of whom are even trying to push for changes in the system any more. reply eesmith 27 minutes agorootparentSo it's better that Alice stays because ... why? reply Arainach 6 minutes agorootparentBecause Alice is a good manager who cares about their reports and is otherwise supporting them, advocating for them, pushing for changes to team culture, etc.? The fact that they can't control this one thing does not mean that they should just abandon the whole company. If Alice finds a company where they can get similar compensation for similar workload without the forced bucketing, perhaps that's a good idea for their mental health, but Alice leaving is a large negative for the team. alextingle 9 hours agorootparentprev> If you have an organization with forced bucketing where X% of your team need to be given a subpar rating, how do you decide which one? Easy. You quit, and find a better job. That practice is so toxic that it's sufficient to condemn the organisation as unworthy of any buy-in whatsoever. Just leave. reply ethbr1 2 hours agorootparentIn defense of stack ranking, it does solve a very common problem -- managers who never fire people who deserve to be let go. This ultimately rots an organization from the inside, as it leads to attrition of higher performers because they're forced to work with useless people. You see this a lot in companies that rarely fire people, because managers optimize for accumulating direct report count (whether or not those direct reports are doing valuable work). reply convolvatron 2 hours agorootparentcompanies need to do much better about letting managers go. I get it, they are hard to find. and those that actually have any engineering management skill at all are even harder to find. and every time you hire a new one you're taking a risk that they'll be a absolutely terrible manager. a terrible manager can cause a huge swath of destruction. but the answer can't be an army of useless middle managers diluting the impact of the people who actually do want to help the company and providing cover for people like them that are just phoning it it. reply jart 4 hours agorootparentprevNah you make sure X% of your team is staffed with losers. It's a nutty system I know. But I'd imagine that's how things worked at companies that have stack ratings. Managers probably traded low performers like baseball cards. reply red_admiral 5 hours agorootparentprev> If you have an organization with forced bucketing where X% of your team need to be given a subpar rating, how do you decide which one? I think it's Joel Spolsky who has a tale of a manager asking him to do that for his team when everyone had gone all in with overtime to get something shipped on time. To their great credit, the author refused, and the manager saw sense. reply kaashif 9 hours agorootparentprev> If you have an organization with forced bucketing where X% of your team need to be given a subpar rating, how do you decide which one? If you don't have an obvious low performer you'd better have metrics. This is a case where you're forced to rate people who are up to par as subpar - the rating system is simply bullshit. You should be allowed to rate people according to their actual performance. Metrics don't solve the underlying problem which is that the rating system sucks. Having a random number generator called \"metrics\" to \"make decisions\" isn't good either. reply Yizahi 5 hours agorootparentprevPfff, what kind of problem question is that. Manager promotes the ones who go with him for a smoke or do some other regular informal activity together, obviously. :) reply BeFlatXIII 7 hours agorootparentprevDice. reply red_admiral 5 hours agorootparentprevI've had experience with internal \"support\" that marks tickets as closed without actually fixing the problem. Sometimes the reason for closing suggests they haven't even read the email that opened the ticket. Think something like \"Tool $X is missing on machine $Y. Please can you install it, according to $POLICY it is meant to be on all prod machines.\" Then the ticket gets closed with \"The policy is correct. $X must be on all prod machines, we cannot change this.\" Without installing the tool. Then when the annual anonymous \"rate your satisfaction with these services\" survey came round, they wondered why the ratings were so bad - I made sure in the open text feedback not to go after the poor employee but to raise concerns about the performance of the team manager. I won't take credit for it, but I'm told things at $COMPANY have got better since. reply dogleash 4 hours agorootparentprev> a shit manager This isn't about a singular individual, it's about a group of professionals. You have to deploy systems thinking. If you give a cohort a tool that allows and incentives them to do worse at their job, the average person in that group will perform worse. I like my boss; I have also built a skillset and frugalness where I don't worry about working for someone I don't respect ever again. But I still care about what's going on at large and trends. I don't want downward pressure on the average. Not only will that slowly seep into effecting me, I also care about the lives of the people at points in their career where they don't have employment opportunities that allow them to avoid bad management. reply passwordoops 8 hours agorootparentprev>the situation you describe is a classic sign of a shit manager Well then it means the vast, vast, vast majority of companies with a coherent corporate structure are shit. Welcome to reality reply chipdart 1 hour agorootparentprev> The metrics make reporting to higher ups easier, no doubt. It's not about being \"easy\". It's about being objective, verifiable, and demonstratably unbiased. It's about justifying how you rank the performance in a way that's impossible to refute. > But the situation you describe is a classic sign of a shit manager: It's not, and frankly this \"shit manager\" accusation is an infantile remark that screams a failure to understand what it means to perform well. reply jimberlage 3 hours agorootparentprevOne thing that is always on the table - if you see a person picking up valuable work and they don't have a ticket for it - you as a manager can create that ticket. Now you may need to coach the person on how to do that themselves (can we make the ticket making process more lightweight? Can we make a heuristic like just put story points for the time you've already spent on it plus a buffer for after-the-fact work?) But managers who really want documentation and truly think people are doing underappreciated work can always make it themselves. reply Brian_K_White 6 hours agorootparentprevA manager can absolutely describe any value as simply as you just did. reply BlueTemplar 9 hours agorootparentprevIt becomes an interesting contradiction : there's no such thing as a good unbiased and objective metric on this. So good managers (that do their job properly) are bad managers (that get fired for it). And bad managers are good managers... reply pxc 4 hours agorootparentRecent-ishly on HN: https://yosefk.com/blog/advantages-of-incompetent-management... reply Simon_ORourke 10 hours agorootparentprev> Managers who are the sort of people who don't value helping your colleagues Helping, yes certainly one of the core requirements being a manager is unblocking direct reports from whatever they're doing. But it has limits, because you as a manager have finite time. I've got seven direct reports, three are relatively new hires and so consume most of my \"help\". Of the remainder another three are great senior devs who can be trusted with getting the broad brush strokes of a problem and going off independently to delve in. One however, a struggling senior dev with junior dev capabilities, and having major childcare issues at home is totally floundering, pulling sick days and basically failing. As a manager I basically don't have capacity to commit the amount of time required to pull them out of it, and I'm trying to move them off the team. reply bryanrasmussen 9 hours agorootparentwhatever else, that major childcare issues comment right there should tell anyone \"don't work at that company, because hey your child gets cancer they don't care and will try to figure out a way to fire you. Probably by saying you have 'junior dev capabilities'\" reply lazide 7 hours agorootparentThat’s nice and all, but what else do you expect to actually happen? reply bryanrasmussen 6 hours agorootparentif someone is underperforming due to those kinds of problems then to say they have junior dev abilities seems somewhat insulting, which is especially contemptible because it is wrong to insult someone that is going through an especially difficult time, especially as the person doing the insulting might not be able to handle the situation any better themselves. So first off I expect not to insult people in that case. Then I might expect something like \"unfortunately due to the extreme medical situation the family finds themselves in I do not feel this person can fulfill their duties at the company any longer, and will need to be let, following company policy / legal requirements in our area that means the following rights pertain ....\" that is to say instead of moving them out by saying they have junior dev capabilities and are just failing, acting honorably in the firing process and taking whatever hit the company is supposed to take. In other words I expect the company to pursue its benefit, but honorably and not as a scumbag. Your \"what else do you expect to actually happen\" suggests that you think it is likely the company will be a scumbag, your \"that's nice and all\" seems to imply that you think being a scumbag is not just likely but somehow also correct. on edit: referring to the legal rights and responsibilities of company may also in some cases be that the employee has rights to paid leave and similar things. So it does not necessarily mean that someone will be fired, depending on where this situation is taking place. reply dasil003 4 hours agorootparentThis is why if you’re telling someone something they don’t want to hear it’s best to only give one reason. Senior dev overleveled and performing at junior level is one thing. Personal issues impacting performance is another. They have totally different solutions and just mentioning them together sounds like the manager has an axe to grind. reply bryanrasmussen 4 hours agorootparentit may be true that these have different causes in a particular situation, but given the variability and length of employment in most companies and projects for everyone involved (managers and programmers) I would think it more likely that a manager wouldn't actually have enough data to reliably separate the two conditions when dealing with it. reply ethbr1 2 hours agorootparentprevSomething similar came up in another HN comment thread I was in a few months ago -- someone hired at senior level, but ended up only having junior level skills. The root issue, imho, is there's no accepted corporate method of demoting an employee (in the US). Which is unfortunate, because it would benefit both the company (who retains someone with training and familiarity) and the employee (who isn't fired). \"Lower expectations for lower money\" shouldn't be verboten, but it is. reply doodaddy 7 hours agorootparentprevBased on what you’ve said, are you confident that you’re delegating enough? I mean, you kind of answered your own questions - you’ve got three seniors. Are they really senior or senior-in-title? If really senior then they should be helping take on some of the junior mentoring. Be wary of the hero, “only I can do it”, mentality as a manager. It only leads to burnout. reply senkora 3 hours agorootparentprevNot to be antagonistic, but just as a practical matter to consider: if your account username is your real name then I would be careful talking about your direct reports like this. People who you work with might see it. reply alextingle 9 hours agorootparentprevHave you talked to your \"failing\" team member about this? Have you worked together to try and identify a path towards improvement? Off the top of my head, perhaps they would benefit from more WFH time? Or perhaps a period of part-time work? Perhaps their duties could be shifted around so that they can contribute in a different way for a while? Could they take over some of your mentoring duties? I mean, this is the bread and butter of your job as a manager, right? Getting the best out of your people? reply cutemonster 7 hours agorootparent> Could they take over some of your mentoring duties? They wrote that the person has junior skills. > so that they can contribute in a different way for a while? Seems to me that this is what they're doing already: >> I'm trying to move them off the team. (To another team where the person fits better, presumably.) reply Brian_K_White 6 hours agorootparentI don't read it so charitably. They only see a problem they want to go away. How do I know what they see? Because that is what they said. reply vdvsvwvwvwvwv 8 hours agorootparentprevYou can give your team members more responsibility. Tech leads, buddies, owners of initiatibmves etc. are things. The juniors shouldn't be sucking too much at just your teet. reply FireBeyond 2 hours agorootparentprev100%. At my last org, my eng team (I'm a PM) had no manager for a while, during which leadership instituted metrics that tracked \"Planned Points versus Planned Points achieved\". My team also handled support escalations and defects. That work is ... unplanned. That was not tracked in their system. I had to go in and advocate for them... \"You have work that they are being required to do that not only doesn't show up on metrics that you are using to evaluate developer productivity, but in fact, you're actually dinging them by flagging that 'planned versus completed points' as unacceptably low. How do you think morale is going?\" They would do things like \"The team planned 30 points to be completed in this sprint. They only completed 10 points, 33%, and we expect 90%. Oh? What's that, they actually also completed 25 points in unplanned work due to Sev-0 and -1 bugs and defects? That doesn't count.\" reply nisegami 3 hours agorootparentprev>Managers who are the sort of people who don't value helping your colleagues or being curious/concerned enough about potential security problems, are most likely the sort of people who won't pick up on any of that being a valuable use of your time during one on ones or in standups either. I think in a lot of cases these managers do value those things, but the fundamental issue is that those things aren't reflected on the dashboard. reply beAbU 11 hours agoparentprevBased on my experience automated reporting dashboards start to cause damage where they are allowed to become visible by higher-ups in the org. A dashboard is immensely powerful for the immediate manager to know how their team is doing, identify problems and work with the members to resolve those problems. As with many things, the numbers on a dashboard must be read with context and the closer you are to that team, the better. The moment the dashboard is accessed by higher ups, several things happen: The devs become scrutinized by higher-ups that do not have all the context to make sense of the numbers, the manager is rendered ineffective because the knowledge and power they had while reporting to their superiors is taken away, and upper management will inevitably start caring about the numbers on the dashboard, and nothing else. There is a level of \"managing upwards\" that lazy direct managers struggle with, and they just pass on the reporting numbers as-is without really caring what this might result in. reply regularfry 6 hours agorootparentYep. It's for exactly this reason that I've told potential vendors in the past that not exposing, and preferably not gathering, individual contributor metrics was a hard requirement. I'd rather have individual team leads or scrum masters have to gather their own stats than have people with disproportionate organisational leverage exposed to information they don't know they aren't qualified to interpret. reply ethbr1 2 hours agorootparentprevExcellent insight! Metrics are useful, but only with context. Any metrics reported at skip level by definition lack context: there's no ground-level engagement or time to dig into details. Ergo, the reported numbers are understood as the only numbers. With the exact solution you offered! Use them, but only at the level in which additional context is available, then report up new numbers that allow for enriching / adjusting the base numbers. reply touristtam 3 hours agorootparentprevIt's about safe space. We're not just cogs in the machine. We exists as humans with our own sets of fluctuating of emotional and psychological states. Break that at your own peril. reply InfamousRece 6 hours agoparentprevI used to work for a company that started using Gitprime to measure developer productivity. Gitprime would show a nice dashboard with stack ranked employees based on their git commits. Besides the obvious effect that it had on cooperation (you don’t want to help another developer lest they go before you in the stack rank) it had also funny effect on the code we wrote. For example, replacing old code with new code was penalized as “code churn”, so we had to write something like if (false) { // old code } // new code In Golang projects we avoided pushing the vendors directory in one commit. Instead we had to strategically commit it piece by piece to satisfy “frequent small commits” metric that apparently is a signature of good developers. reply jacobyoder 6 hours agorootparentI worked in a place where... regardless of what I did in branches, someone else would merge it and their name would be the only thing that showed up in the git metrics, because we only looked at the final 'main' branch. I'd looked at the 'develop' - where feature branches were merged before master - and I think I had something like 75%+ of the commits (over a 14 month period). But to look at the daily dashboard, I was doing nothing, and someone who was barely in weekly meetings for more than 15 minutes was doing 95% of the work. I didn't particularly care, until people started looking at 'dashboard metrics' to see 'who's doing what'. I wasn't initially wanting visual credit, but when my contributions were effectively erased to the casual viewer, it pissed me off... reply DrBazza 8 hours agoparentprevThe most interesting thing during COVID was seeing the switch from in-office to remote, followed by a round of redundancies, and the redundancies were fascinating. It was full of people that when in-office seemed gave the impression of hard-working, largely by a combination of 'face time', and just talking to other employees, and not necessarily about work. >> [Why not build programmer performance measurement tooling?] I'm pretty sure there wasn't any employee monitoring software other than completion of Jira tickets within individual teams. The whole sneaky monitoring/measurement software is totally counter-productive, and counter-intuitive. If I'm in an office, no one is going to care if I read the docs or an ebook, possibly on my tablet, but if I'm remote and not jiggling my mouse every few seconds I'm slacking off. reply ryandrake 2 hours agorootparent> It was full of people that when in-office seemed gave the impression of hard-working, largely by a combination of 'face time', and just talking to other employees, and not necessarily about work. Hahah, we all know these people! They walk around the office, sometimes carrying a clipboard or stack of paper, initiating business-y conversations, always making sure they look very serious and busy, deliberately walking past the boss's office frequently so he can see them visibly DoingSeriousBusiness. When promotion time comes around, these social butterflies are always at the top of the list, because naive managers see them buzzing around everywhere, and they at least think they know that these guys are constantly doing work. These people were panicking during COVID and WFH. Their entire self-promotion vector disappeared overnight. Now that most companies have returned to in-person work, these hall-walkers are back and once again getting promoted based entirely on their presence and visibility. reply steveBK123 3 hours agoparentprevEmployee level metrics are a fast slipper slope to encouraging all the wrong behaviors. Most of what you actually want out of a good developer is not captured in metrics easily, but lots of superfluous stuff is. I recall one of my worst managers was a guy who would nitpick the \"how\" of every action (email/slack to users, internal runback documentation, etc), but rarely if ever call anyone out for inaction. He was also pretty indifferent to the what (actual functionality delivered to users). This created a tremendous bias to inaction in the team, and everyone developed slopey shoulders.. He eventually got fired but not before a lot of turmoil and turnover. As soon as you start rewarding devs based on story points, ticket counts, response times, ticket closure rates you get all sorts of bad behavior. You'd be better served based on quarterly changes in user satisfaction metrics as thats literally all that matters - the end product. reply raxxorraxor 3 hours agoparentprev> the creative folks you really want working there bail for greener pastures This is the main reason. Either pay 100k with boni and I work as a code monkey for some years. But even then I will bail after some time. A strategy that cannot be viable for any company, even those that just need a quick software solution to a problem. The knowledge management with changing employees only makes it even more expensive. If you want to burn money to see the commit log glow, please do so. I am unlikely to take any ownership of the code produced, but probably will come up with a commit here and there. Not every form of coding requires creativity, there is also a lot of mundane logic that just needs to be given form. But even those developers should not be subjected to such metrics or anyone really. What we created in other industries like logistics and call centers amounts to slavery aside from the fact that the employees decided to work there at some point. Something that also can be disputed how voluntary that decision was. Managers with such strategies are a liability for any company. reply mirekrusin 11 hours agoparentprevThere is an interesting parallel with overfitting [0] which may mean solutions can also resemble each other. [0] https://news.ycombinator.com/item?id=41684082 (Too much efficiency makes everything worse (2022)) reply seb1204 12 hours agoparentprevI would argue that a managers time will be filled no matter what she does. So she could prioritise knowing what her peers do, and acquire the basic knowledge to understand tech maybe? And then fill up the rest of the calendar. So I'm saying it is up to the manager to either suck upwards or support peers. reply seb1204 12 hours agoparentprevStupid question but when digging into a potential security vulnerability, should that not be a ticket already that can get tracked? reply macNchz 5 hours agorootparentI read this something like: I’m working on a feature, I notice something curious in some adjacent code that could maaaybe let someone bypass the UserAuthorizationAdapter with a carefully crafted request, but I’m not familiar enough with that code to say for sure. It’ll take me at least half an hour to figure out whether it’s a complete misunderstanding on my part (I’m pretty sure it is…but it might not be…) or a real issue worth raising as a security ticket. Even just pinging someone about it will break my flow. It seems, however, that 100% of the decision making about whether I have a job next quarter and how big of a raise I might get is made based on three metrics on a productivity dashboard my boss is obsessed with. Should I take the time to learn more about the UserAuthorizationAdapter, or just assume it’s fine, finish my feature and move on to the next? reply ethbr1 34 minutes agorootparentActual example from my experience: Trying to figure out the correct AD groups/permissions I needed to use an internal web app to schedule patching for some servers I managed. After stepping through the app's js, I realized they were doing user group retrieval and validaton client-side (!!). Wrote a quick POC that patched their check and gave me admin permissions, then sent it and a description over to a friend on the internal app security team. Not my job, but apparently the service account backing that app had permissions to reschedule patches on any internal server. (including f.ex. domain controllers) So probably something that it was worth having someone spend a couple hours figuring out and reporting, despite it not showing up in my OKRs. reply 8n4vidtmkvmk 3 hours agorootparentprevThat hits too close to home. Except for us it's all about OKRs. You get one or two tasks for the quarter, and anything that isn't working towards that be damned. Which basically translates to launch your [AI] feature and fix nothing. reply madeofpalk 9 hours agorootparentprevWhy? \"Tickets\" are a means to an end, but not the end itself. If it helps you, create a ticket. Otherwise don't. reply 8n4vidtmkvmk 3 hours agorootparentIf there's no ticket, how will anyone know you did anything at all? How will submit your code change without a ticket # to satisfy the validator? reply p1esk 12 hours agorootparentprevOf course. Same as helping a colleague (unless it’s a few minute task). Whenever there’s something that I can spend my time on, it’s going to be converted into a ticket. reply exe34 11 hours agorootparentyou create tickets for helping colleagues? I would understand \"add this feature for me\", but do you also have a ticket to \"take x through this unfamiliar neighborhood of the codebase\"? reply ryandrake 2 hours agorootparentI've seen tech companies that strongly encouraged that: Open a \"task\" or \"process\" ticket describing what you're doing, then do it, then close the ticket. Not all tickets are bugs and features. During review time, if you expended effort not described in a ticket, it's as if you never did it. When in doubt, open a ticket. reply jachee 12 hours agorootparentprevHow do you prevent that from recursing infinitely? reply djtango 10 hours agorootparentBecause we're humans, not robots and a human manager with human managees should be capable of working within a process without abusing the most obvious of edge cases. When building software you have to be precise to the nth degree but with human processes you can afford some degree of ambiguity and judgment... reply happymellon 11 hours agorootparentprevIf you are measuring tickets, then you can't. Your job is to create tickets to close them. If you generate productivity along side that, then thats a bonus. reply mihaaly 7 hours agoparentprevI work now for a long history smaller organization that formalized management and organization in the past 4-5 or so years. I joined midway of this - looking my way out now - and the focus on unconnected details only was odd right from the beginning. I attributed this to me being new and can't see the whole picture, digged into discovering my immediate vicinity. But after a year seeing we are still being obsessed only about those plenty of items that fit into a sprint multiple times remained sick to me. I discovered several embarrasing mistake in design of approaches, interaction or implementation that made me scared: how this went through at all, and how it remained there for so many years? Is this used at all actually?! People should desert us not paying for such nonsense (shit, actually). Reported these mistakes in our issue tracking system and those fit into less than half of a sprint landed back on me sooner or later, almost all. Not those first being very serious, but those fit into the schedule (but mixed in seriousity at least, those being serious first). My takeaways: - Seriousness and functionality is not the primary concern, company management is! - Others (about 2 dozens of engineers) did not take the effort to report. I am not brighter than them, I was novice in that environment and codebase and the actual technology, also what I was reporting stands out on usage level only, no tecnological knowledge necessary. - Apparently problems are positioned proactively on blind spot to remain unrecognised. There must be a serious level of ignorance involved. The company lived through decades of difficulties, never had investors but built and run by the increasing number of enthusiastic loyal people. The company organization was non-existing compared to today's norms meeting contemptuous looks from today'n collaborative organizational ninjas. I am sure several of the problems stems in the casual running of the organization, but the reorganization is not helping but making things worse, preserving, leaving in. The reorganization made the company look much shinier though. It looks much improved. As I later learned the reorganization was needed for selling the company. The founders pushing retirement age and want to cash out. Even my employement was part of that show, fitting into making the company look similar to trendy ones clueless investors can find appealing based on the facade. We are agile in all sense, we are technologically advanced (AI feature is pushed in for the sake of it), our recruited HR professional is like all other, we are uniquely successful like all others, we are team, we care of employees a lot, we have workplace well-being taken the most seriously (just like everything else in HR), we are family in matching uniforms smiling happily into the camera in a team building excercise, and above all we have top notch marketing with thick flow of photographically illustrated success stories and dynamism. And practically our backlog does not contain serious bugs. For the matter of how users stay with us my running theory is that there is no better choice than this. Others are similar (also the lock-in effect to something they learned and invested in is there). I see complaints, I see angry complaints now despite me being disconnected from the client facing report system, I see their efforts for trying to make it work, finding workarounds of workarounds only reporting when the combination of workarounds collapse. They try to use it, they need something like this. I feel their efforts, this is what I am doing in increasing level with Windows, and the various software tools I use. Those look similar on the surface, increasingly so and it deteriorates as we speak. reply srvaroa 10 hours agoprevI worked on an internal platform for a large engineering org and was responsible for choosing what features we put in. We had the technical means to track everything from commits to reviews, jiras, deploys, etc. Some of our most celebrated and impactful features were reporting on Accelerate metrics and related. E.g. deploy frequency, size of changes, duration of stages in the dev cycle and such. I set a very inflexible red line: we don’t expose data more granular than at team level. Ever. No excuse. Quite a few line managers would come to me asking for “personal metrics”, and even engineers in the team were super interested in building that (“with all this data we could…”). My argument was that these metrics are toxic and invite misuse. A second factor was that this misuse would generate mistrust from engs against the platform and damage adoption. Instrumenting an organization thought of as a system is fine. You want to see where are bottlenecks, you want to have measurable targets for how technical work is done and how it correlates to business goals/KPIs. You want to offer teams metrics of their delivery my process so they can take the info and implement improvements whenever they see fit, and have a data driven conversation with the business (e.g. about the right setting for the carefulness knob) But teams are the minimum unit of ownership, we stop the instrumentation there. Sure, a team’s performance ultimately links to individuals, but that is the manager’s job to figure out. Interestingly: * only line managers asked for this info, nobody in a director/vp/cxo role * the most annoyed by me saying no were engineers in the team who wanted to do these features reply throwaway2037 4 hours agoparentThis is a great comment. My thought, after reading it: Why do line managers want this info? Do you think they have someone in mind for promotion, and they are looking for metrics of accomplishment? And, cynically, I would say that senior managers don't care... because to them, most hands-on engineers/devs are fungible. What is your view about why the upper levels never ask for it? reply srvaroa 2 hours agorootparent> Why do line managers want this info? Do you think they have someone in mind for promotion, and they are looking for metrics of accomplishment? Nah, you don't need to assume malice :) Most times it was managers with good intentions, not realizing that those metrics were either pointless (e.g. how much code / commits does $person do), or toxic, in the sense that it leads the team to game metrics, that it prevents the manager to actually understand why the values are what they are, that it opens the risk to link them to promotions and perf reviews etc. Explaining them all this was generally enough! > And, cynically, I would say that senior managers don't care... because to them, most hands-on engineers/devs are fungible. What is your view about why the upper levels never ask for it? Actually that wasn't the case. AFAIK (I left at some point, but kept a bit in touch with former colleagues) upper management started using some of those metrics to set organizational objectives. Again, same argument. You don't need to assume malice. Management has a legit interest in engineering productivity. What happens most of the time is that they don't know how to measure it in an effective way, or how to use it to drive organizational change. Providing guidance is part of your job as a Platform eng. reply marcinzm 2 hours agorootparentprevMy cynical view is that's it's to find scapegoats especially in companies that have a lot of politics or a lot of PIPs. You generally scapegoat one level down and then let that level push it further down if it can. So the Directors need team level metrics to find which managers reporting to them to scapegoat and have data to \"prove\" it. Then the Managers need individual level metrics to find which engineers to scapegoat and have data to \"prove\" it. reply hinkley 1 hour agorootparentYo dawg, I heard you like throwing people under buses. So I put a bus under yo’ bus so you can scapegoat people while you scapegoate people. reply madrox 2 hours agorootparentprevAs a former line manager, there have been two cases when I use metrics: I'm promoting someone, and I like having numbers that back up how good they are, or I'm firing someone, and I like having numbers that back up how bad they are. I generally agree with OP, but there are times where as a manager you know exactly what is going on with your team, but numbers are still helpful. reply regularfry 5 hours agoparentprevYes, this is the way. It's better never to gather the information at the individual level. reply nemo44x 3 hours agoparentprevAgreed. And \"personal metrics\" can also end up having a lot of consequences that were not planned for. Incentives are tricky that way. There's always a long tail of things that need to get done on occasion that doesn't show up in these types of metrics and it becomes difficult to find takers when everyone is optimizing themselves around the core metrics as bonuses, promotions, and even keeping your job in today's climate could be determined by those. It also makes allocating load to play to contributors strengths (which is often what they enjoy most) far more difficult. reply srvaroa 2 hours agorootparentYep, this is an important point. We wanted the metrics to create the right set of incentives to make people improve the right parts of the system. For example, we did present deploy frequency prominently. This gets people to see it, managers to want their team to be in the upper percentiles, etc. which drives a set of practises that, in general, and backed by research, are beneficial. One of my favourite features was putting two graphs together: size of PRs vs. time to review. Time to review went up more or less linearly to size of PRs, but past a certain threshold (different per team!) time to review dropped sharply with larger size of PRs. This made for a good conversation to topic with teams that sets the right incentives for smaller PRs, iterative development, etc. (and it happens to correlate with deploy frequency). reply hinkley 1 hour agorootparentMight also suggest a size limit for PRs. Theres always that Golden Child who gets away with things because they are prolific. But they tend to screw up architecture because they make too-big moves that discourage feedback and negotiation. reply hinkley 1 hour agoparentprevI’ve helped build out or steer these sorts of systems a number of times and usually management behaves themselves during the adoption and honeymoon phases but then erode the trust later on by trying to use the system to determine PIP or promotion. Devs who have seen this behavior before tend to push back hard on adoption, and then invest the absolute minimum effort in using these tools. The tools tend to be built wrong often enough to encourage that slide into toxicity. There’s an amount of using a tool where it improves your work experience, and then an additional amount that improves the team experience, and then beyond that it’s doing your manager’s job for them and self-reporting/narcing. I’m trying to build a tool at the moment that has had three focuses due to different sources of inspiration. First it was going to be Trac (a project management tool and wiki that is so simple it shouldn’t work, but somehow does) with bits of Jenkins. Bamboo has thousands of features and integrations where it should have hundreds. All those integrations make reproducing a failed build locally difficult or impossible. The bones of a build process should be in the build scripts and dependencies, so you can run them locally. The build tool should schedule builds, report status changes, collect some release notes data, and track trends with grafana charts and that’s about it. I also want something running in each dev’s machine to boost system performance and do some of the teamcity features for trunk based dev like push-on-green-build. I just miss how distilled Trac was, but it had some problems with plugins and git support. That sat on the Some Day Shelf behind two other projects until I read Cal Newport’s Deep Work, and then Slow Productivity. Then it became more user oriented. Atlassian has about three per-user dashboards that I’m responsible for juggling all day, and that is tragicomically stupid. I’m terrible with this sort of juggling but have coworkers who don’t check the PR list ever - you have to pester them to look at PRs, week in and week out. If I’m doing deep work I don’t want preemptions except in specific circumstances (like I broke trunk). But when I come up for air I need a cheap gestalt of what I’ve missed and what people are expecting from me. Show me all the PRs, and my red builds and open tasks in a single view. Allow some low priority alerts through. And that can be facilitated by building a pomodoro straight into the dashboard and information hiding during deep focus moments. I have some family that was recently diagnosed as neurodivergent, and the thing about YouTube is that your suggested videos get influenced by what other people in the house are watching (particularly if you’re not logged in on a device). ND people of all types have a lot of coping mechanisms to function within other people’s expectations (eg work and responsibilities) and to mask. They get both barrels when it comes to being judged poorly by toxic management tools because their variability is so high. Best performer one day, second worst the next. And this is nowhere more true than with ADHD. And the worst of it is that almost nobody will go harder and farther than an ADHD person during a crisis. They can hyperfocus during rare moments but most reliably due to an emergency (self created, like a paper due tomorrow, or externally driven, like servers on fire). They also innovate by drawing connections nobody else sees between different disciplines. But they’re the first on the block when toxic metrics kick in. And the productivity tools they objectively need more than anyone else on the team seals their fates, and thus they either don’t use them or use their own, which are similarly poorly integrated, which leads to more plate spinning which they are terrible at. So what finally got me ass-in-chair in front of a keyboard was realizing that if this is two tools instead of one, you can keep some of the productivity data on the employee’s machine where it can help them with time management and self-improvement but not self-incrimination. Then you can cherry pick and clean up the narrative of your day or week before you self report. Have private tasks on your machine that may look embarrassing to others (like remember to drink fluids, eat lunch, call the dentist, tasks you’re skunkworking). reply zem 10 hours agoprevthere's a scene from the tv show \"suits\" that has always stuck with me: the show is set in a law firm, and in this particular episode they needed to lay off some of their associates. a young, newly-promoted lawyer was tasked with drawing up a list of the associates and marking the ones who she felt should get the axe, based on their performance. so she comes up with some metrics, goes through the associates' work, and ranks them based on the resultant numbers, saying that the bottom few could be let go. there is one employee, brian, who ends up near the bottom of the list. a more senior person takes her aside and asks why she recommended brian be laid off, so she brings out the metrics and rankings and points to him near the bottom. the senior person asks \"okay, so who are the top associates in your list? can you point them out on the seating chart?\". turns out, the top five associates were all brian's neighbours, and the reason was that he was really good at helping people when they were stuck with something. but of course that affected his own individual contributor numbers, and there were no metrics for \"helped someone else out but didn't get credit for it\". reply Shatnerz 9 hours agoparentI wouldn't be surprised if that was directly adapted from the anecdotes of Harry Nyquist at Bell Labs [1]. \"\"\" After crunching a lot of data, they found that the only thing the productive employees had in common (other than having made it through the Bell Labs hiring process) was that \"Workers with the most patents often shared lunch or breakfast with a Bell Labs electrical engineer named Harry Nyquist. It wasn't the case that Nyquist gave them specific ideas. Rather, as one scientist recalled, 'he drew people out, got them thinking'\" (p. 135). \"\"\" 1. https://en.wikipedia.org/wiki/Harry_Nyquist reply ryukoposting 9 hours agorootparentThe cynic in me expects someone to read this and come to the conclusion that what they really need is more data to improve their review process. Clearly we need to know who's eating lunch together! reply blitzar 8 hours agorootparentThe cynic in me expects poor performers / low contributers who read this come to the conclusion that they are the Harry Nyquist of their organisation. reply hinkley 55 minutes agorootparentprevI have been accused by a number of people who like me of “asking good questions” and of asking difficult questions by people who don’t. I sucked at school until someone opened up the idea for me around third grade that how the curriculum is taught is just the teacher’s opinion, not a law, or a religion. If you can reframe the material in a way that makes sense to you then do so. I ended up spot-tutoring a bunch of people over the years because I would hear them complain about how the material made no sense and I would swoop in and say, “yeah how they teach this is bullshit, have you tried thinking about it this way?” Which validates their frustration and then gives them a life raft. That kind of reframing to keep up can become reframing to get ahead. I went from Problem Student to grade school “valedictorian”, to polymath. Years ago we were all fixated on the trap of Expert Beginner and I would half-joke that I was instead an Expert Journeyman - able to quickly get to adequate instead of mediocre in a new discipline. And these days I think that may be what “polymath” is most of the time. Just knowing what the next question is to ask to keep going. The big breakthroughs come from people who become experts in most fields, but these same sorts of people also get pretty good at music or painting or writing as a hobby. As good or better than mediocre professionals. The first time this happened to me in a professional setting, a coworker was stuck on a SQL problem and insisted I pair with them to help debug it. I told her I’ve never touched SQL, just worked on some bespoke data processing. She didn’t care. Come here anyway. And I’ll be damned if I didn’t help her find her problem by just asking her what this part does and that part does. Why does this work that way? And I started writing SQL a couple weeks later, substantially off of just that interaction, bolstered by what first generation search engines could scrape together. And the thing is when everyone asks you questions and you don’t break their trust, you quickly learn where all the bodies are buried in the project/org. Which is a valuable asset for someone wishing to become a lead or staff engineer. I became lead by popular vote most times, rather than an actual game plan to get promoted. I just did what thought needed to get done and was within my abilities, which looks a lot like leadership, especially if management doesn’t have that quality. Port in a storm, that’s me. But I’ve never ever completed the most stories or features. I’ve occasionally fixed the most bugs, the most performance issues, or workflow problems. Is calculated I saved forty man hours a week for the team on code-build-test-push ergonomics and my shitheel boss was still made about my productivity those two quarters. I could not show up to work and still be contributing 8 hours a day, dummy. reply blub 8 hours agorootparentprevThis by the way is an excellent argument against home office for professions where innovation plays an important role. I don’t think we’ll ever see a Wikipedia quote saying “the only thing productive employees had in common is that they were hanging out in a Microsuck Teams chat room”. reply Yizahi 4 hours agorootparentDid you or anyone else has actually observe any such processes? I mean employees A and B meeting at any place which is not a workplace or any of them (because meeting at workplace means one of the pair has come specifically to another, and that is mostly equivalent to calling that person by phone, on full remote) and there spontaneously talked about work topics generating previously unheard idea useful for the company? If the and answer is yes, then what was the rate of such encounters per number of employees? And finally - honestly answer yourself - does this minuscule probability worth the ~30 full awake days in every years of life, of every employee? (2 hours commute per 250 days in a year, then divide by 16 awake hours per day) For me the answer is obvious - it is not even remotely equal in value to such a gigantic time waste. If that super brainstorming even real at all. Personally I've never observed this. reply sevensor 50 minutes agorootparentprevI think you’re wrong, but in an important way that deserves discussion, so please enjoy an upvote. First of all, innovation and productivity are not necessarily connected, and in many cases innovation is not at all what management wants or the business needs. (Using Jira is a sure sign that management does not want innovation, yet we see it in widespread practice.) Second, the quality of the colleagues males a huge difference. Not every workplace is golden age Bell Labs. Most people don’t have a Nyquist down the hall. I used to sit shoulder to shoulder with a guy who had YouTube videos on his second monitor all day long, to help him focus. Evidently it worked for him, he was a very solid contributor, but neither my productivity nor my ability to innovate were helped. (Like Jira, the open plan office is a sure sign that management values observable units of effort over either productivity or innovation.) reply vdvsvwvwvwvwv 8 hours agorootparentprevNot entirely convinced. The tradeoff is in-office you need to sit next to someone. Remote you can talk to anyone in the world. But it is the role of good WFH culture to avoid siloing of people. reply jsight 3 hours agorootparentTBH, I've been on teams where the chat was a constant stream of activity. It works really well and involves a lot of people that might not be involved in decisions otherwise. I've also seen the room be quiet way too much on some teams. This is always bad, but hard to fix. reply starkparker 1 hour agorootparentThe worst is when the team chat rooms are quiet because each member is in several private rooms or group-chat conversations doing the actual work in there. Regardless of the reasoning, it's toxic to WFH/remote work, even in the short-term. And it's outright sabotage in the long run when it's time for someone who wasn't invited to the \"correct\" chats to onboard a new hire who ends up needing some context that exists only in someone else's private chat. reply lazide 7 hours agorootparentprevExcept you don’t actually talk (as in have a real conversation) with anyone on Teams. reply danaris 4 hours agorootparentMaybe you don't. I've never had any trouble having real conversations on online platforms, whether for work or otherwise. reply lazide 4 hours agorootparentResearch shows, that is about as accurate as saying a Twinkie is real food. Not completely wrong, but… reply AgentOrange1234 7 hours agorootparentprevFair enough. As one potential mitigation, I’ve consistently had deep mentorship conversations over the phone. For me, I think voice-only is actually much better than in person. reply throwaway2037 3 hours agorootparent> For me, I think voice-only is actually much better than in person. This is interesting. Can you explain why? To be clear: I don't doubt you, but I have never seen a comment so specific about this matter. I would like to learn more. For one, I assume you said \"voice-only\" specifically to exclude video calls, which are a special kind of hell, when compared to in-person discussions. (Staring at yourself and only seeing the other person's head always struck me as a bit weird / artificial / Uncanny Valley-ish.) reply thyrsus 3 hours agorootparentprevAnecdata: I work from home and spend about a quarter of my time helping colleagues. reply regularfry 5 hours agorootparentprevNot necessarily. There's no clear indication that you need full time (or even an amount of time measured in \"X days per month\") to get these benefits. reply throwaway2037 3 hours agoparentprevI have posted a few times here about this issue. Honestly, you need to protect yourself first. If your line manager is anything less than amazing and very involved, then helping your teammates \"too much\" is an easy way to miss promotions and pay rises due to lower year-end ratings. reply CSMastermind 2 hours agoparentprevAs someone who has both built and used different off the shelf tracking tools I've always found that they were terrible for evaluating individuals but great for evaluating teams (and by proxy the manager). reply PaulKeeble 12 hours agoprevOne project I was on someone added a tool and posted the results of the past week of number of lines of code added, my count was -5900 and I had been put at the bottom. This was a legacy project. Its pretty easy to explain why removing a bunch of complexity and replacing it with something smaller and meeting the customers requirements better is obviously the goal on any project. Everyone that added lines had made things more complex. Its obviously a useless measure for productivity or saying anything of note about the work at all other than the lines of code making up the project and how it is changing over time. reply hinkley 40 minutes agoparentI gave myself carpal tunnel replacing over a hundred copies of the same five lines of code with an n² complexity with a single implementation, so then I could fix the perf issue later. -500 lines over a holiday week, which was nice, but not as nice as landing the changes to the shared function and making 2/3 of the app 10x faster with the test data, which was ultimately going to be a fraction of the real data. Don’t large scale refactor in vim folks, especially if you haven’t memorized all of the shortcuts (I hadn’t discovered block indent until weeks later. Ouchie) reply m463 11 hours agoparentprevhttps://www.folklore.org/Negative_2000_Lines_Of_Code.html reply nosianu 9 hours agoparentprevRelated, research: \"Humans solve problems by adding complexity, even when it’s against our best interests\" Article: https://www.washingtonpost.com/business/2021/04/16/bias-prob... Study published in Nature: \"Adding is favoured over subtracting in problem solving\" -- https://www.nature.com/articles/d41586-021-00592-0 > A series of problem-solving experiments reveal that people are more likely to consider solutions that add features than solutions that remove them, even when removing features is more efficient. > ...the authors observe that people consistently consider changes that add components over those that subtract them\" -- be it bricks or regulations, so it works like this for real as well as for abstract things. reply nzach 7 hours agorootparent> even when removing features is more efficient Efficient in what sense ? > Our conclusion is that people systematically overlook subtraction; it’s not that subtraction is always better My personal experience agrees with these findings, but I think they missed something more important. People try to change things because they want to see something new in the real world. But from ideas to real world impact there is always at least one level of 'approving' you will have to go through. And adding things will generally have less risk associated. Besides that, I think our education system doesn't train us to remove things. Everything we learn is incrementally built upon what was already there. So our default mode of thought is to add things. Now imagine we have 2 developers, one how always solves problems by adding something new and another one that always refactor things to keep things efficient. My guess is that by only adding things you will end up delivering more features with less bugs. Sure your code will be slower and at some point it will become impossibly complex to manage, but it takes quite a long to time to get to this point. After writing this message I've realized that 'making things easy to delete' is a pretty important feature. reply em-bee 6 hours agorootparentPeople try to change things because they want to see something new in the real world my personal feeling on this is rather, removing someone elses code is like dismissing their work. and generally i don't want to do that. if it is not clearly a bug, then i'd hesitate. someone wants this feature. taking it away would not be nice to them. it may be similar to the problem of design by committee. everyone wants to get their favorite features in, and we are more concerned about our relationship to our colleagues than the end result. here, we can solve this in a way to make everyone happy, but without stopping to ask if removing that mis-feature would actually make anyone unhappy. thinking further, i think this is also a problem with personal ownership of code or features instead of team ownership. this feature is owned by X, i can't remove it without his permission, or without a discussion in a meeting. leaving it in and working around it is the path of least resistance reply vdvsvwvwvwvwv 8 hours agorootparentprevI reckon that depends. Coporate culture encourages adding. Half your job is justifying keeping your job. It takes a lot of swagger/social capital/clout to subtract and be loved for it. Or you need to work somewhere (a company or protected team) with a first principles thinking culture (and not a cargo cult one) which is very rare. In personal life I think people do often subtract. They give up X where X is harmful. They simplify. Not everyone but many. It feels like a natural part of life. reply danaris 4 hours agorootparentprevWhether or not removing features might be \"more efficient\", in nearly all cases, if you remove a feature that's been part of a software package—whether external or internal—some nontrivial fraction of the people using it are going to be angry, because you just broke their workflow. The only way you can possibly avoid this is if, in addition to removing that particular feature, you add a feature that does the same thing fully automatically, and does so correctly in every instance. (Even then, some people will complain about it, but at that point you just have to accept that as a cost of progress.) reply r1chardnl 12 hours agoparentprev“One of my most productive days was throwing away 1000 lines of code” ― Ken Thompson reply canucker2016 11 hours agorootparent-2000 lines of code, Bill Atkinson, Apple Lisa Quickdraw developer https://www.folklore.org/Negative_2000_Lines_Of_Code.html reply mirekrusin 11 hours agoparentprevRemoved LoC should count double. Edit: But then again, the point is not about individual examples really – the point is that whichever metric you choose, with time you'll see diminishing returns followed by negative ones. In case of doubling removals, you can easily game it by dumping json files for tests, then removing them ie. in favor of generator etc. What's interesting is universality of this phenomenon (strong goodhart's law?) – overfitting in llms, using metrics discussed here and why it makes sense to vote on opposite ruling party etc. reply maeln 11 hours agorootparentThat is how you end up with a unreadable code where everything is a oneliner and there is no comment and no documentation :D reply mirekrusin 11 hours agorootparentAbsolutely agree, added edit, should have posted long answer instead of update with clarification, my bad. reply stavros 9 hours agoparentprevThat's not useless at all, the moment I saw -5900 I knew that was the most valuable contribution to the codebase. reply ajuc 12 hours agoparentprevEven if you insist on having these metrics and using them - it's another level of stupid to measure lines of code added instead of edit distance. reply onion2k 12 hours agoprevIt's the job of a manager to know what their reports are up to, and whether they're doing a good job of it, and are generally effective. That's true, but it's not what employee metrics tools tell you. If you're using metrics tools to measure productivity then you're not really being a good manager. Metrics tell you are the quantitative details (eg a count of how much output there is), but as a manager what you actually care about in your day to day work is the qualitative details (eg how good the output is), how happy the team is, where the conflict is, etc. Metrics won't tell you that. But... Being a manager is about more than just getting people to do their job well. You also need to plan things, you need to know what's changing over time, you need to test whether your processes are working. I use metrics to measure the aggregate impact of my influence on managing my teams, not that of any IC on any of my teams. Employee metrics are useful for a big picture view. reply bigiain 12 hours agoparent> Employee metrics are useful for a big picture view. Which \"employee metrics\" do you find useful for that? Because in my experience, it's pretty much guaranteed to be someone who isn't anywhere near leading on the type of metrics these discussions are talking about - that's making the biggest impact and amplifies _team_ productivity. Those people don't close a dozen Jira tickets before lunch, they are the people who spend two weeks actually finding and fixing the root cause of that one annoying ticket that 15 other people have closed only to find the problem re occurs. They aren't top of the leaderboard in git commits, because they actually read the RFCs or dependancy source code while working. They sure as hell don't always write the most LOC in a week - I want the \"minus 2000 lines of code\" guy, not the one who's best at gaming whatever metrics you use. https://www.folklore.org/Negative_2000_Lines_Of_Code.html reply onion2k 12 hours agorootparentI don't even look at the metrics for ICs. If a team has an underperformer I expect the lead to be handling that, with my support if necessary. The metrics I find useful are things like trends before and after a change. For example, if lots of PRs are taking a long time to get through review because the descriptions don't get filled in well, I want to look at the time code spends in review before and after updating the PR template. Or before that, I want to see which teams have code in review for less time so I can look at their PR process and suggest changes to slower teams that the faster teams have already implemented. If a team is doing the same stuff as other teams but their typical PR size is much bigger I want to know if they have fewer stories that they should be breaking down further. And so on. None of this is data I don't have a gut feel for, but having real numbers is useful for making a case for change. People don't always believe instinct. It's harder to argue with a well-designed graph. reply ozim 11 hours agorootparentIt is also super hard to look at trend of \"gut feeling\" or \"instinct\". Seems like lots of people discuss here false dichotomy and I really like onion2k explanation because it is much more nuanced and basically explains the same thing I was trying to convey in other thread on similar topic. reply welder 10 hours agorootparentprevHow do you collect & display these metrics, manually, internal tools, or a product? I'm often asked to provide employee metrics but my product is just an automated time tracker for contractors & devs, who bill by time. I've avoided it being used as employee metrics, but we recently built a separate product for these trends and team insights that you're using. May I email you to the address listed in your HN profile? Just for an informal chat. You can reach me at alan@wakatime.com. reply onion2k 5 hours agorootparentI use Jellyfish. Happy to have a chat. Fire me an email. :) reply ukoki 9 hours agorootparentprev> it's pretty much guaranteed to be someone who isn't anywhere near leading on the type of metrics these discussions are talking about - that's making the biggest impact and amplifies _team_ productivity It would be great if everyone on the team had different strengths that contributed to team productivity \"A smashes out small features like nobody's business\", \"B is great at debugging\", \"C is great at planning and seeing through big long-term features\", \"D is great at helping teammates\" etc. However in practice I find you have a minority of team members who can do _all_ of A, B, C, and D's tasks well, and a mediocre majority who deliver between 20% and -10% the productivity of the talented minority. reply jachee 12 hours agorootparentprevI feel very seen. I’m at my happiest when being grease or glue; when I unstick the stuck, or stick the unstuck. I like to “walk the property”. Find the bugs that are under rocks. I’m not at my best as a mere construction drone piling on work for work’s sake. That’s soul-killing, for my soul, at least. reply exe34 11 hours agorootparenthello my fellow troubleshooter:-D reply khazhoux 9 hours agorootparentprev> They aren't top of the leaderboard in git commits, because they actually read the RFCs or dependancy source code while working. They sure as hell don't always write the most LOC in a week - I want the \"minus 2000 lines of code\" guy Yes, these engineers are invaluable. But the \"minus 2000 LOC\" engineer is rare. In my ~25 years of experience at several top companies, I've seen that --more often than not-- the most impactful coders are writing the most LOC. And they're not gaming it either. They are simply writing a ton of high-quality code: features, bug fixes, optimizations, cleanups, etc. Yes, occasionally there is a crazy heisenbug that takes 3 weeks for a one-line change, but that is rare. Note that I deliberately use the word \"coder\" (which I don't usually do) instead of the more generic \"engineer.\" Because I'm not talking about those critical senior engineers whose job is mostly to prevent others from writing bad code. reply mikeshi42 9 hours agorootparentAgreed. At the end of the day - the end user of the software probably wants something other than technical debt reduction, so it's not surprising impact and LOC can roughly be correlated. Taking the LOC metric too far, in either direction, is trying to read too much into a single metric. reply caskstrength 11 hours agoparentprev> Being a manager is about more than just getting people to do their job well. You also need to plan things, you need to know what's changing over time, you need to test whether your processes are working. I use metrics to measure the aggregate impact of my influence on managing my teams, not that of any IC on any of my teams. Employee metrics are useful for a big picture view. The point of the article is exactly that such metrics don't give you any kind of a good signal unless you are really into the fine details. And if you are, then you don't really need them in the first place. > quantitative details (eg a count of how much output there is) For example I recently spent a week producing several thousands of lines of tedious trivial code that parses some configuration out of JSON file in pure C. Then I spent a month writing less 1k lines of very dense low-level packet parsing code and the main loop also in C. So the metrics would show you the big picture of me slacking and my performance tanking which obviously wasn't the case. You can't substitute actually knowing and understanding of what your reports are doing with some tools providing you with trivia like number of commits, lines of code changed or tickets closed. reply blitzar 6 hours agoparentprevBeing a good manager is taking in all the metrics (+other information), assigning the appropriate weights to them and making informed determinations. If the worker changing your code style from snake case to camel case does 500 commits in a day they are not a 100x programmer vs the worker solving world peace who did 5 commits. If their commits drop to 1 a day then maybe reach out and see how things are going, solving world peace has a lot of dead ends and bottlenecks. reply jackhiggs 8 hours agoprevI'm an Engineering Manager for a large company and have been for a number of years. For our large team we will rank the team based on perception of managers. After that we will then manually collate coding stats from all repos we work on. Unfortunately for the consensus view here and in the article, you get a 100% hit rate on who you think poor performers are and the lowest coding contributors. For top performers it's more nuanced. In general they will be top of the contribution stats but sometimes if they're doing R&D or hard work then the stats are not very meaningful. But that's why we don't rely on them. So metrics have their place to inform and color existing perception. But they will rarely change perception completely. reply aswerty 8 hours agoparentQualitative and quantitative approaches together inform us best. Probably not the most eye opening of statements. But I think as you indicate, qualitative generally paints the picture, and quantitative validates it. reply lowbloodsugar 1 hour agoparentprevAmazing. You just proved her point with data and then drew the exact opposite conclusion. reply LaGrange 7 hours agoparentprev> Unfortunately for the consensus view here and in the article, you get a 100% hit rate on who you think poor performers are and the lowest coding contributors. This is circular logic. If you measure that \"coding contribution\" nonsense, people's \"performance\" will be perceived based on that, _especially_ by their direct managers. reply AgentOrange1234 6 hours agorootparentI’ve seen cases where folks completely checked out and were contributing nearly nothing, making no commits, writing no code, and faking it at standups. Simple metrics can help surface cases like this. I agree that it’s something a manager could over-index on. I’m not sure how to avoid that beyond adopting a mindset of “this is noisy data that sometimes gives you important insights.” reply JohnMakin 3 hours agorootparent> I’ve seen cases where folks completely checked out and were contributing nearly nothing, making no commits, writing no code, and faking it at standups. Simple metrics can help surface cases like this. Of course we've all seen varying degrees of this - but these kind of people can only exist because of terrible management. Throwing metrics at the problem just introduces a more insidious version of this individual, one that knows how to game whatever metrics are used (managers especially will do this). I've been on teams where such an individual could thrive for years, even with promotions, and on teams where such an individual would be outed within a week. reply mrguyorama 2 hours agorootparentprevIf you need metrics to see an employee isn't doing what you assigned to them, what are you even being paid to do? reply Buttons840 5 hours agoprevCompanies love to collect their data, and they love their AIs to analyze that data. But they ignore the easiest to collect data and the strongest AIs available; these AIs are so good you could just call them Is. I've always wanted to see regular anonymous mass surveys of employees, about things like project progress and completion dates. Do you want to know when a feature will be finished? You can analyze story points and build a fancy burn down chart, or you can just ask the people working on the feature. Allow the entire team to anonymously predict when the feature will be finished and I'll bet you get a better answer. Anonymity is important because people are easily pressured into changing their answers. We've all been asked \"how long do you think this will take?\". \"Two months\" you answer. Then managers pressure you into changing your answer, but usually, no matter what you're forced into saying, you still think it will take two months. Why did they ask if they didn't want my answer? Therein lies the truth. Companies don't want accurate answers and data, they want to see and hear what makes them happy right now. I don't think most companies would have the courage to regularly gather data with anonymous surveys. But maybe, if one clear-headed and high-level executive wanted to force it on the company, they could. They could mandate the use of a software tool to do anonymous surveys, and no matter how much lower-level managers complained, the team could still anonymously say when they actually believe the project will be finished. Etc. reply scruple 4 hours agoparentWe get supposed \"anonymous\" surveys where I work and I see the hash at the end of the URL, and we've confirmed amongst a few of us that they're unique, and so the assumption goes that it's actually not anonymous at all. I don't think I would ever trust an \"anonymous survey\" from an employer to actually be anonymous. Maybe if it was hand written. reply Buttons840 4 hours agorootparentIf the URLs had all been the same, then would you trust that it was anonymous? Employees could lie about their own happiness, and satisfaction with their manager, to their own detriment. Employees could also lie about project progress and quality, also to their own detriment, because it looks bad if a team says \"everything is on track, quality is great\", and then the project runs long and is a buggy mess. I just think a lot of what a manger does is give progress reports, and it's easy for one person to lie about progress reports, and then when it becomes clear that the progress reports were wrong all along, the manager somehow shifts blame to the workers. These surveys would give everyone a say in the progress reports. reply scruple 3 hours agorootparentI don't see how any deeply honest, earnest feedback can come from me when I am told \"this is anonymous\" and there's a 99.999999% chance that it isn't. If it came from a position of mutual respect then maybe I'd reciprocate, but it doesn't. It's hard for me to take any of this seriously. Industry-wide we're told layoffs have to happen and these same corporations go on to post record numbers, far exceeding internal and external expectations. Executives are lavished with bonuses while many of my colleagues are gettingno matter how much lower-level managers complained, the team could still anonymously say when they actually believe the project will be finished. Etc. This would result in lower tier managers announcing beforehand they claimed \"x time for y project\" and if the devs want their sickdays/bonuses/promotions they should claim same. reply Buttons840 4 hours agorootparentThe survey I'm imagining is just \"rate the progress of project X from 1 to 10 (1 being just started, 10 being complete)\"[0], and also \"rate your happiness from 1 to 10\", and \"rate the quality of the work done from 1 to 10\". This would be anonymous, the only thing that wouldn't be anonymous is whether or not an employee has updated their survey within the last 2 weeks. I would absolutely throw that hypothetical lower-tier manager you mentioned under the bus. The surveys could have a \"rate your manager 1 to 10\" question too. I think it would be valuable insight to all levels of management. If the team is being death marched, happiness and quality surveys would drop. Or, if you see a team deliver a buggy project, but quality surveys were high all throughout development, then you could tell that the team was incompetent and hire/fire/train accordingly. [0]: Don't ask people to guess completion dates, have them guess percent completed and then calculate completion dates in the software. reply kreyenborgi 11 hours agoprevAlso, those tools don't show everything. Someone here told/linked to a story about this guy who had like 0/100 on their automated performance scores, because he was sitting down with juniors and asking relevant questions to get them on the right track and generally keeping the ship together. People do a lot of work that isn't legible to automated tools, but which good leaders can and should recognize. reply physicsguy 11 hours agoprevThe main issue with code metrics is that they're easy to game, and they're not necessarily an indicator of anything. In my day job I just made a big change across many microservices updating a core dependency library, so last week it looks like I've done about 50x more work than I have any other week, but that's because I scripted the update, it's not a reflection of the actual work I did at all. reply ChrisMarshallNY 9 hours agoprevMy GH activity graph[0] is pretty full, but some of the days with the least checkins are ones where I did the most work. I had a day like that, a couple of days ago. I spent a significant portion of the day, building experimental approaches to handling an issue, but reverted, at the end (the experiment did not yield the results I wanted). That is fairly common. Also, a big part of my reflective refactoring, is reducing codebase size, like factoring out common functionality into protocol defaults, and/or base classes. That can take quite a bit of time. So LoC/Time is pretty much a worthless metric. And if you cloc my codebases, the comments/code ratio is usually about 50%. Documenting my code[1] can take a lot of time, as well, and is actually a fairly important part of refactoring, as I often find issues, when I have to explain what’s going on. [0] https://github.com/ChrisMarshallNY#github-stuff [1] https://littlegreenviper.com/miscellany/leaving-a-legacy/ reply BlueTemplar 8 hours agoparentAnd that's not even starting with the questionable morality of using GitHub in the first place (~ after Microsoft bought them)... (especially for non-US developers) reply ChrisMarshallNY 8 hours agorootparentEh, I don’t lose any sleep over it. There’s bigger fish to fry. reply BlueTemplar 8 hours agorootparentYeah, leaving aside other concerns about platforms, Microsoft, and the USA, I too want to stress how GitHub is problematic in GP's «some metrics are bad» sense : the social networking aspect, stars, number of projects, and, as you say, number of contributions and number of lines of code. reply ChrisMarshallNY 7 hours agorootparentYeah, that stuff is pretty ridiculous, but I think a lot of it predates Microsoft. There's a big school of thought, that \"gamifying\" things, brings \"engagement\" (the holy grail of SV). I'm old and cy",
    "originSummary": [],
    "commentSummary": [
      "The author emphasizes the importance of managers understanding their team's work beyond just relying on automated dashboards, which can lead to a focus on metrics over quality.",
      "Solely focusing on metrics can deter creative talent and cause retention issues, highlighting the need for a balance between quantitative data and qualitative insights.",
      "The post advocates for combining big-picture metrics with managerial insight to prevent a toxic work environment and ensure effective team management."
    ],
    "points": 466,
    "commentCount": 296,
    "retryCount": 0,
    "time": 1730696802
  },
  {
    "id": 42040795,
    "title": "New York Times Tech Guild goes on strike",
    "originLink": "https://www.washingtonpost.com/style/media/2024/11/04/new-york-times-tech-strike-walkout/",
    "originBody": "",
    "commentLink": "https://news.ycombinator.com/item?id=42040795",
    "commentBody": "New York Times Tech Guild goes on strike (washingtonpost.com)407 points by ChrisArchitect 7 hours agohidepastfavorite754 comments legitster 2 hours ago> The two sides negotiated until late Sunday. The sticking points in recent days were over whether they could get a “just cause” provision in their contract, which means workers can be terminated only for misconduct or another such reason; pay increases and pay equity; and return-to-office policies. This seems like a LOT of issues that still need to be hammered out. It would be one thing if they were disagreeing about a number, but it sounds like the terms keep changing and nobody agrees on the nature of the work itself. It's not even clear that there's a preliminary contract ready for the NYTimes to sign. Striking during election week is kind of a crappy move to pull. But if this is just attention seeking without a serious contract, it seems egregiously risky on behalf of the union members too: there's not a clear button the Times can push on behalf of the union to end the strike immediately. The Times would either have to sign a blank check to the union now, or the union would have to agree to an IOU in exchange for a bunch of temporary concessions. reply marricks 49 minutes agoparent> Striking during election week is kind of a crappy move to pull NYTimes has dragged out the negotiations for months, refusing to have a contract. It's kinda a make or break time for the union. When would be better to strike, what time would NYTimes and the audience prefer? It should be during a choke point otherwise management wouldn't listen. Additionally, this is a high traffic time, but not really a high stakes time I'd argue. They're not going to influence the election by going out day before or day of it, they will just lose viewership to others covering what's happening. reply johnmaguire 19 minutes agorootparentDidn't Wirecutter once strike during Black Friday? https://nypost.com/2021/11/25/workers-at-new-york-times-wire... reply stickfigure 2 hours agoparentprev> workers can be terminated only for misconduct or another such reason This is such a weird request for technology workers. You want to work with low-performing coworkers? reply quandrum 2 hours agorootparentNo, I want management to develop a system to determine who is low-performing, document when those workers don't meet the standards of performance, and reference those documents when they fire someone. It's just asking for due process. reply bko 1 hour agorootparentThis sounds good, but in my experience bad employees were known to everyone. It was difficult to pinpoint exactly why they were bad or toxic, but pretty much everyone agreed. If you gave them some benchmark they would need to hit (e.g. close tickets, be on call, etc), they would be able to do so. So creating a documentation trail is difficult, especially if its based on people saying they don't think he does good work or people don't want to work with him. This is where I break with the \"pro worker\" dialog you hear online a lot. In my experience, competent employees are incredible difficult to come by. Recruiters are paid a few months salary just to get someone through the door. To think that employers are just randomly firing people for no reason has never struck me as being even remotely true. I'd prefer the quick to hire, quick to fire economy. Especially since employers would be much less likely to take a chance if they know there are a lot of hoops they'd have to jump through if it didn't work out reply legitster 55 minutes agorootparentI worked in fast food and this resonates extremely with me. There were only 4-5 people in a kitchen during the busy rush, and there was a list everyone knew of people they didn't want to get stuck in a shift with. If someone sucks to work with, it really sucks, and because everyone is pitching in and working together, there is no indication that the person was bad at their job. If you were fired, it was usually because your fellow workers said you were bad. I'm all on board with better pay and benefits. But protecting mediocrity doesn't benefit customers or other workers. Companies may occasionally arbitrarily fire good employees without a good cause, but that would be their loss. One thing you'll notice in employee-owned companies (as opposed to unionized companies) is that they generally do no tolerate such clauses in their contracts. reply shagie 34 minutes agorootparentPrice's Law is \"50% of the work is done by the square root of the total number of people who participate in the work.\" https://dariusforoux.com/prices-law/ https://routine.co/blog/what-is-the-prices-law-and-why-is-it... reply taurath 4 minutes agorootparentprev> To think that employers are just randomly firing people for no reason has never struck me as being even remotely true Have you only ever worked with reasonable management? The problem with quick to hire quick to fire is that eventually you might be quick to fire. I suspect you have a much higher level of security than most people to have quality of coworkers as a top priority! reply axus 1 hour agorootparentprevIt's like the unpopular, friendless kids in high school, you just know. And there's nothing they can do to change it. reply mensetmanusman 1 hour agorootparentLess negativity and more listening by everyone can be a place to start. reply MichaelZuo 20 minutes agorootparentWith what time? Middle managers don’t suddenly get 28 hours in a day after someone offers this suggestion. Their schedules are already maxed out, so every extra minute of focused attention needed is literally coming from someone else’s (or some other department’s) budget. reply tssva 1 hour agorootparentprevIf they are meeting the metrics set to judge their performance how are they bad employees? If the metrics don't properly measure whether the job is being done then change the metrics. reply umanwizard 1 hour agorootparent> If the metrics don't properly measure whether the job is being done then change the metrics. Nobody has ever come up with a good set of objective metrics to judge software engineer performance. So the best we have is still the subjective opinions of your managers and peers. reply joenot443 1 hour agorootparentprevLike in the cases of US courts defining obscenity or fair use, there isn't necessarily a set of metrics which can be used to perfectly taxonomize something. Imagine I sent a manuscript to a publishing house and they rejected it for being bad. I wouldn't expect they got to that conclusion by comparing it to a set of metrics, I would assume they have people in authority whose judgement is the decider on whether something is \"good\" or \"bad\". reply 39896880 51 minutes agorootparentYour analogy only works when applied to the hiring stage, as that is when the publishing house decides to work with you. If the publisher accepted your manuscript, assigned you an editor, gave you a target publish date, and gave you advance and then suddenly booted you and said “your work isn’t good” you’d have some questions, and rightly so. reply stickfigure 41 minutes agorootparentThis sort of thing happens all the time? Many manuscripts and screenplays are stillborn. Movies make it halfway through production before the plug is pulled. Software projects fail left and right, with millions of dollars spent (sometimes billions!) Human endeavors sometimes fail to live up to expectations. reply isbvhodnvemrwvn 36 minutes agorootparentprevThey meet these metrics while they are under formal process just before termination. I used to work with a couple people clearly working multiple jobs who switched focus when they were PIPed. reply fallingsquirrel 1 hour agorootparentprevWhat metrics do you propose that aren't susceptible to Goodhart's law? reply slg 1 hour agorootparentprev>If you gave them some benchmark they would need to hit (e.g. close tickets, be on call, etc), they would be able to do so. Isn't this just a sign of bad management? If employees are capable of doing the work when their job is on the line, it isn't a question of skill or ability. It is a failure of the company to properly motivate, challenge, and reward them for their work. reply JumpCrisscross 57 minutes agorootparent> Isn't this just a sign of bad management? If employees are capable of doing the work when their job is on the line It’s HN. We’ve all been maliciously compliant. I can close tickets without solving any problems or be on call in the most useless ways imaginable just fine. reply slg 52 minutes agorootparentI just read that as \"management has no idea how to evaluate the quality of work of their employees\". Either the company should be able to evaluate an employee's performance and therefore can show proof of poor performance or it can't properly evaluate an employee's performance and therefore shouldn't be firing people based off an admittedly inaccurate measure of performance. reply umanwizard 31 minutes agorootparent> I just read that as \"management has no idea how to evaluate the quality of work of their employees\". You probably couldn't explain how you walk, or how you cook an egg, or how you speak English, at the level of detail that would be required for something like this. Yet you do know how to do all those things. Just because you can't write down detailed objective instructions for how to do something does not at all mean you have no idea how to do it. reply haswell 22 minutes agorootparentprevThis assumes that evaluations can be neatly defined and tracked. There's another front page post right now about exactly this. The soft (often difficult to define/measure) skills required of a manager are the same skills that are required to make the decisions to fire people. I think almost everyone has worked with someone who they know shouldn't be there, but they still are because they keep finding ways to technically meet the letter of the law when it comes to \"performance\". And yet they are clearly a huge anchor for the team, and everyone knows the team would be better off without them. I wish we could perfectly evaluate what it means to be a good employee, and we could show the exact measurements used to do so. But this simply is not realistic, never has been, nor will it likely ever be. The spectrum of possible behaviors and the intricate interplay unique to various teams makes such a task impossible. I'm not saying an effort shouldn't be made, but that these decisions are often highly subjective, without much hope of arriving at something more objective. I've worked at places that had stringent requirements for firing people. The net result was that good people all leave voluntarily instead of being stuck with the problem individuals, ultimately resulting in teams full of mediocre-to-awful teammates. Managers can both know how to evaluate quality and fit while not having any hope of perfectly defining and documenting those evaluations. I'd rather work in an environment that has at-will employment with all of the downsides that come with that than a place that can't fire employees without spending a year creating a mountain of paperwork that ultimately doesn't get anyone much closer to the objectivity people are striving to achieve. reply JumpCrisscross 19 minutes agorootparent> but they still are because they keep finding ways to technically meet the letter of the law when it comes to \"performance\" Remember that homework assignment or group project where you spent an inordinate amount of time and effort on not doing the work as intended in some silly way? This is the adult version of that. reply stickfigure 35 minutes agorootparentprevHow are you going to accurately measure \"your code is shit\"? If it was that easy, it would be a standard git hook. reply beepbooptheory 51 minutes agorootparentprevYou can still be pro-worker even if you think sometimes a certain worker is bad, or hard to work with, or otherwise a \"bad employee.\" It is more something political and something about how you view the world/humanity in general. It is not an \"identity politics\" where the discussion is around certain kinds of people or not. That would be kinda silly anyway on its face, we are virtually all workers! reply ramblenode 29 minutes agorootparentprev> No, I want management to develop a system to determine who is low-performing The system here is going to be something like LoC or tickets answered, things that are objective and easy to measure. We know these don't reflect real productivity, but because they are objective, that's what will be used in promotion and firing decisions. Anything subjective, even if it's the opinions of peers or experts, will be contestable in due process hearings, creating risk for the employer, and will be deemphasized or eliminated. One reason why the US government and European software companies are relatively uncompetitive in hiring is because of the difficulties created by due process in firing bad employees and promoting good ones. reply pc86 25 minutes agorootparentprevIt's not \"just asking for due process.\" Everyone has interacted with a government office with an absolutely worthless employee who is just sitting around counting down the days to retirement where they can continue getting taxpayer money for doing nothing. Just because there's a process to get rid of someone doesn't mean it will ever happen. This is a ploy to make it harder to fire bad programmers. If I have to try to hit a deadline and my coworker is garbage, I want my boss to be able to fire them and start finding a replacement, not start a six month process of paperwork, meetings, and HR CYA bullshit with the sole purpose of avoiding some bogus NLRB complaint. reply senko 29 minutes agorootparentprevHello from Europe. Tried that, didn't work. It's incredibly hard to quantify \"low-performing\" for white-collar workers, because any measure is either easily gamed, actually creates roadblocks and bad incentives, or both. Now companies are wary of hiring people because it's harder to fire. reply kjksf 1 hour agorootparentprevThat might by what YOU want or what you hallucinate the demand is but most reasonable interpretation of what we know is that they in fact want to prevent being fired for low performance. if you can be fired \"only for misconduct\" and low performance doesn't count as misconduct means that you cannot be fired for low performance. Granted, the actual demand might be more nuanced but going only by what was reported, they don't want to be fired for low performance. reply Timon3 1 hour agorootparentNo, what's reported is that the tech workers are asking for a \"just cause\" provision. This is a well-established legal concept that explicitly includes what GP posted. The reporting you're reading that fails to mention this happens to be from the New York Times. Can you guess why they don't mention this? reply cmptrnerd6 1 hour agorootparentprevI have never seen such a system that I thought worked or wasn't just gamed into uselessness. Do you have any examples of systems that worked well? reply kccqzy 45 minutes agorootparentprevRequiring management to document these decisions is already itself placing low trust in management. I do not want to work at any workplace where trust in management is so low that low performance needs to be documented with a paper trail. I'd rather work at a workplace where the management is consistently competent and people place high trust in the management; so that when management fires someone everyone else agrees without having a need for documentation to prove low performance. Disclaimer: this is only my opinion on where to work. I'm fully aware there are many other good reasons why management needs to document low performance. reply umanwizard 1 hour agorootparentprev> I want management to develop a system to determine who is low-performing Nobody has ever invented a working system for objectively rating software engineers. I really doubt NYT will be the ones to do so! reply leereeves 1 hour agorootparentprev> I want management to develop a system to determine who is low-performing You're asking them to solve a problem people have been working on for decades without success. How can they measure productivity of tech workers? reply platz 1 hour agorootparentprevIsn't employment in the US At-Will anyways? reply brewdad 51 minutes agorootparentYes in absence of an employment contract that says otherwise. One of the primary objectives of any US union is to establish guidelines for dismissal of employee members that override at-will. reply stogot 1 hour agorootparentprevWhat makes you think they don’t have that? reply quandrum 1 hour agorootparentBecause the union is striking over it reply Vaslo 1 hour agorootparentprevDue process from a union definition is often ridiculous and protects the members beyond what a reasonable customer/employer should expect. reply throw4847285 1 hour agorootparentAmazing. That's what negotiating is for. The union gives the maximal version of what they want, the bosses counter, everybody celebrates the results. reply Timon3 2 hours agorootparentprevLow performance is an example of just cause. The employer simply has to prove that this was the case, and that they gave the employee notice, a chance to improve, and a reasonable standard to reach. reply ta1243 1 hour agorootparentProblem is that require the employer to define what an acceptable level of performance is, and that's notoriously difficult So instead the choices tend to drift to \"fire them on the manager's whim\" or \"practically impossible to get rid of short of murder\" reply willsmith72 1 hour agorootparentWho says it's notoriously difficult? I've worked many places with clear processes for identifying and resolving poor performance issues (firing being one possible resolution). That sounds like just your experience reply ta1243 22 minutes agorootparentIt's massively common, factors into the whole office/home debates that have been raging for 4 years https://www.apqc.org/blog/better-measurement-knowledge-worke... The crux of growth in knowledge workers is that our current norms of measurement and productivity were developed in a manufacturing or manual task-oriented mindset. According to Peter Drucker, productivity for knowledge workers needs a different set of considerations https://www.cipd.org/globalassets/media/knowledge/knowledge-... While in manual work the targets and outputs are usually clear, knowledge work and its results are less tangible, and therefore harder to define, measure and evaluate https://trepo.tuni.fi/bitstream/handle/10024/114586/palvalin... Drucker (1999) has even stated that knowledge worker productivity is the biggest challenge for modern work life. Other researchers have also discovered that the performance of an individual knowledge worker is the most important factor for organisational success... The need for general performance measurement is great as the theme is still quite new and there are very few previous studies measuring the effectiveness of NewWoW practices. There is also a need for practical tools for analysing and managing the performance of knowledge work from the NewWoW perspective. Organisations are still planning and making NewWoW changes, without clear evidence of their benefits and without any measurement information reply magneticnorth 1 hour agorootparentprevIf those are literally the only choices, then I vote for \"practically impossible to get rid of.\" But I think this is a bit of hyperbole - some kind of ongoing, documented low performance seems obviously better than just letting managers fire on a whim. reply ta1243 32 minutes agorootparentI agree, that's the european approach. reply eikenberry 11 minutes agorootparentprevIf the alternative is to be under constant existential threat of being laid off... I could see is as the lesser evil. IMO, recent events are the reason for this item being included. reply code_for_monkey 2 hours agorootparentprevwhy are tech workers, my industry, so committed to this ideology? Do you think the tech layoffs of the last few years was a justified culling of lazy idiots? reply lc9er 54 minutes agorootparentI'm old enough to remember a time when people in tech were called 'wizards' and there was an air of mystery that surrounded the industry. A large subset of this group really seems to have bought into the idea that working in tech makes you 'special'. It does not. It's a skilled profession that is trainable and attainable by large swaths of the population. Working in tech does not make you special (Yes - you) and the tech industry is well overdue for quality of life improvements that other, organized, sectors have had for decades. reply abletonlive 1 hour agorootparentprevHonestly yes. I've been interviewing people that have gotten laid off and almost 75% of the time I'm thinking that they were probably chosen for layoffs due to low performance reply kergonath 1 hour agorootparent> I've been interviewing people that have gotten laid off and almost 75% of the time I'm thinking that they were probably chosen for layoffs due to low performance The people interviewing with you might be a biased subset of those that were laid off. I don’t mean anything about your company, which could be great or terrible, I have no idea. But I would expect the best performers to get new positions quickly through their networks and connections. You would not see these people replying to random offers, but it does not mean that they were not high-performers who were laid off. reply abletonlive 27 minutes agorootparent> The people interviewing with you might be a biased subset of those that were laid off. I suspect this to be very likely the case but I don't think it changes anything here. If we laid off people that were high performers and they got taken up in the job market quickly that means things are still healthy and we are still giving jobs to people that deserve jobs. A net neutral effect on the system as a whole. The stragglers that can't find new jobs because they were laid off for low performance AND also are low performing interviewers are not useful to the system. Now they just kind of eat up some interviewing productivity but thats probably a net-positive for the entire job market as a whole. reply asdasdsddd 1 hour agorootparentprevyes mostly, i worked with many lazy idiots, who undeservedly made millions while our clients and customers suffered reply anon84873628 1 hour agorootparentThat's not how it went for us. I would have chosen a very different set of people to sack. Unfortunately I think those types of layoffs are separate from \"firing\" and probably not covered by these terms. reply repeekad 1 hour agorootparentprevI think almost by definition a layoff is to remove redundant/bottom performers to keep the machine clean and lean, that’s capitalism for ya reply lucianbr 2 hours agorootparentprevAs if only low-performing coworkers would be terminated. The total freedom of the company to terminate anyone any time for any reason or no reason is extreme, and now we are pivoting to the other extreme. Funny how that happens. reply csallen 1 hour agorootparentWhy is that extreme? If you own a company, why shouldn't you be able to fire someone at any time? If you work a job, why shouldn't you be able to quit at any time? I don't think it's great that our society tries to treat work like it's family, and jobs like they're some guaranteed long-term relationship. It sets people up with the wrong expectations. Your company will lay you off or fire you once they run out of money to pay you or reason to keep you on board. That's how it works. Just as you will quit your job and take a new one if you interview and get a better offer elsewhere. These are business contracts. reply p_j_w 54 minutes agorootparent>If you own a company, why shouldn't you be able to fire someone at any time? If you're a worker, why shouldn't you be able to band together with your fellow workers to not allow this? reply miltonlost 1 hour agorootparentprev> If you own a company, why shouldn't you be able to fire someone at any time? Because that is bad for the individual worker. We live in a society, and society should look out for humans before corporations. reply IG_Semmelweiss 1 hour agorootparentI recommend you travel to LATAM or EMEA, where worker protections are much higher. No one gets fired because protections are so high. At-will is unheard of [1]. In some countries, there's a mandatory X months of salary for Y months worked. The regulation of the labor market, however, is strict and inflexible [2], and all LATAM jurisdictions impose mandatory severance pay for wrongful terminations.[2] What are the results of worker protections mentioned above ? Literally no jobs with protections. See for yourself. LATAM has an average of ~65% informal employment. Take Argentina for example. Close to 50% of the labor market are under-the-table \"jobs\" for this reason.[3]. Even more developed countries suffer the consequences , such as UK having 24% informal sector [4] All those governments intended to look out for humans before corporations. It didn't work out that way. The road to poverty is paved with good intentions. US dynamism actually creates more jobs as more are willing to try new things and experiment. Yes, you can protect workers, very very well. But only if you are OK with a tiny amount of protected workers, and let everyone else toil in the informal sector where zero protections exist [1] https://goglobal.com/blog/from-legal-protocols-to-cultural-n... [2] https://www.acc.com/sites/default/files/resources/vl/public/... [3] https://www.statista.com/statistics/1037216/informal-employm... [4] https://ilostat.ilo.org/topics/informality/ reply miltonlost 51 minutes agorootparentYou think LATAM is in poverty because of their worker protections? Not the decades of western exploitation of their natural resources? Not the decades of American interference in their political systems to destabilize their government? Sure. I'd also like to know what the United States informal labor rate is, but sadly that [4] link doesn't have it. So really, comparing to the UK is pointless without knowing what the US is. And if you think the US doesn't have informal labor, then I suggest you go to a Home Depot parking lot. oh, and on the UK issue, did you look at the map on the link you sent? It says the UK's rate of informal employment is 6.5%, not 24%. Either start reading better or stop lying. reply albumen 8 minutes agorootparentprevFrom your own source: UK's informal employment rate? 6.5%, not 24%. Ireland? 1.8%. Germany: 2.5%. Norway: 2%. Many EU countries have strong labor protections alongside low informality and high employment. While labor protections pose challenges, they do not inherently lead to high informality or low job creation. Effective policy design and enforcement are key to achieving economic stability with strong worker rights. I'm not surprised, on a startup-angled site, that there'd be dissatisfaction with not being able to hire and fire at will. COVID had employees re-assess what was important for them. Tangentially, now we're seeing that shorter working weeks results in higher employee productivity and satisfaction.[1] Having job security, when you've taken on long-term commitments like a mortgage and raising kids, is considered important in many parts of the world. The EU isn't SV; for employees that's probably a good thing. [1]: https://www.weforum.org/stories/2023/10/surprising-benefits-... jorvi 52 minutes agorootparentprevI work in the EU, and I'd rather see the American \"at-will\" system, but with a basic income + additional financial distress protections. It is IMO ridiculous that in a lot of EU countries, chronic low performance is not just cause for firing. It makes economical sense to reduce the friction of allocating workers where they'll be most productive. It just shouldn't destroy those workers' financial security. reply csallen 1 hour agorootparentprevIt's not black and white. It's a sliding scale. Society already does a ton to look out for the individual worker. It's more a question of where things should fall on that scale. Coddling workers by expecting corporations to basically act as their family, their parents, their financial planners, their healthcare providers, etc., is terrible. We should not be telling people to expect any particular corporation to provide them a livelihood indefinitely, when it's a simple fact that corporations cannot do that. They can afford to pay you when it's profitable for them to do so, and that's it. That's the deal. Period. I'm all for taking care of people. That's what our government should do itself. We should not be placing that role on corporations. And we should not be telling people to expect that their jobs will last forever and they can't be fired. We should instead tell people to maintain their skillsets, maintain their savings, and live within their means, so they can weather inevitable job changes. That's what caring for people actually looks like. reply umanwizard 1 hour agorootparentprev> Because that is bad for the individual worker. Not necessarily. Sure it is better if every other factor is held equal, but it's not: everyone benefits from living in a more highly economically developed society where industry is more successful. So you have to weigh pro-worker concerns against these other benefits. If your argument were valid then its logical conclusion would be that all profit from the business has to distributed to the employees (as in most traditional strains of far-left thought). In practice systems like that have major flaws. reply ForHackernews 1 hour agorootparentprevYou're asking why it's bad that your owners can take away your livelihood on a whim without any reason? reply gojomo 1 hour agorootparentCan an employee quit on a whim without any reason, taking vital functions away from the productive team on which they served? reply laserlight 1 hour agorootparent> taking vital functions away It's business's responsibility to not depend on a single employee. The employee might have been hit by a bus. reply csallen 1 hour agorootparentYes, and it's an employee's responsibility to not depend on a single job, and to be prepared for the possibility that it might go away. That's the mindset we should be teaching people, because it's REALITY. Plenty of people are aware of this, and they navigate this successfully by saving part of their income, by maintaining an employable skillset, and by living within their means, while working a job. When you suggest to people that it's their company's responsibility to take care of them, to guarantee their job into their future, or to look out for their personal financial livelihood, that IS NOT REALITY. That's not how it works. You're telling people that their own responsibilities are someone else's, when that's not in fact true. When people mistakenly believe this drivel, they're far more likely to take bad risks and make huge financial mistakes. reply ryandrake 58 minutes agorootparentEmployers employ many people at once. The risk of a bad employee is divided by the entire workforce. Employees, on the other hand, put all their eggs into one basket at a time. Many (most?) employers specifically forbid moonlighting and working multiple full-time jobs at once, so employees are forced to depend on a single job at a time. The risk of having a bad employer is shouldered 100% by the employee. It's this power dynamic that justifies different standards for employers and employees. reply csallen 33 minutes agorootparentThere is not some guaranteed power dynamic. Business is not all huge companies with infinite redundancy. There are 30M small businesses in America that employ 60M people. For the vast majority of businesses and teams, losing an employee hurts, and employees have lots of leverage. These business owners have to do the work to ensure redundancy, to plan their budgets and products and systems to ensure they can weather inevitable employee turnover. Plenty of businesses fail to do this and have to close their doors. It happens with regularity. On the flip side, unemployment is the US is super low. It's true that workers can only hold one job at a time, but they are not \"trapped\" at a job. In fact, they have more mobility than ever, which also gives them leverage to negotiate for higher salaries or to hop jobs. Not to mention more gig jobs, remote jobs, and contract jobs than ever, even for highly paid positions. Sure, losing a job hurts. But the employees who plan for this possibility, who maintain skills, maintain savings, and live within their means, can find new jobs, just as businesses who plan well can weather employee turnover. It goes both ways. So if you're in a position where your employer has some huge power dynamic hold on you, is that some universal truth for all employees resulting from the nature of the employer-employee dynamic? I don't think so. I think that's the result of poor personal decisions, or bad luck at best. All that said, I'm 100% on board with legal protections that set a high standard for employers. We have plenty of those already. And I'm 100% on board with government stepping in to help take care of people who fall through the cracks. For example, I love that COBRA allowed me to stay on my previous employer-provided group healthcare plan for 18 months(!) after my last job ended. What I'm against is any cultural or legal change that begins to suggest that its employers' responsibility to keep their people employed. It's not. Financially, the system can't work that way. Employers are not our parents or our nannies or our caretakers, and we should not try to make them into that. reply laserlight 58 minutes agorootparentprevHundred percent. Yet, it's also reality, today, that the power asymmetry between individuals and corporations are huge. Anybody trying to bootstrap an independent business is heavily punished, simply because corporations want you to be an employee, just because they can. Unless the system balances the power dynamics, it's futile to tell people that they shouldn't ask for more rights from corporations. reply csallen 27 minutes agorootparentI literally run the biggest website for people trying to bootstrap independent businesses, and I haven't seen anyone complain about being heavily punished for trying to do so. Founders are the most employable people I know, and they typically find it the easiest to go get jobs when their businesses fail (although they hate doing so). reply bradlys 23 minutes agorootparentprevNot everyone has a rich family to fall back on, bud. You could say \"fall back on the government\" but then this is how the government would do it. They wouldn't want you to fire people for no reason at all. In the same way that people are paid a certain wage as an agreement, there are other conditions too. This can be part of those conditions. Your claim of: > Yes, and it's an employee's responsibility to not depend on a single job, and to be prepared for the possibility that it might go away. That's the mindset we should be teaching people, because it's REALITY. is capitalist mindset that thinks there's never a chance of change. Kinda pathetic for a MIT grad, tbh. reply FpUser 1 hour agorootparentprev>\"These are business contracts.\" I would agree with this but if that's the case why employees are not given the same perks as companies from a tax point of view? My personal preference is to treat every human as a business. The alternative would be to eliminate all taxes except sales tax with some cutoff for low income persons. reply leereeves 1 hour agorootparentprev> The total freedom of the company to terminate anyone any time for any reason or no reason is extreme It's not extreme, it's exactly the same standard we expect from our employers and any company we do business with, and even our spouses. Imagine a bizarro world where divorce, quitting a job, or terminating a subscription required just cause. Sound appealing? Do we now hate the rich so much that we want to impose that burden on them when they pay someone? reply anon84873628 1 hour agorootparentAre you deliberately ignoring the concept of power imbalance and wide spectrum on which it occurs? All of those examples you cited are drastically different types of relationships, set in very different contexts, that absolutely deserve different terms of engagement. >Do we now hate the rich so much that we want to impose that burden on them when they pay someone I don't even know how to parse this. We're talking about companies of a certain size. I guess we have fully stopped pretending they are anything other than an appendage of the wealthy class, and have no other responsibilities to society. reply ericd 41 minutes agorootparentThat power imbalance mainly exists if you don't save any money and/or live in an area with only a couple of employment options in your field and can't move. If you save up enough money to take a couple years off, there's no power imbalance. reply selimthegrim 1 hour agorootparentprevUm no fault divorce (even without a co-respondent etc) is in fact fairly recent reply umanwizard 1 hour agorootparentIndeed and most liberal-minded people think it was a good change. reply cool_dude85 2 hours agorootparentprev\"Just cause\" provisions are about an inch away from arbitrary termination, they are hardly \"the other extreme.\" reply lucianbr 2 hours agorootparentThat's really nice if that is the case. My understanding from the comments was that this prevents people who don't do their job from being fired, as long as they don't set fire to the servers or something. If I misunderstood, then the union is being nicer than they have to. reply drawkward 1 hour agorootparentIn my experience, the commenters here, on a forum for SV startups, are overwhelmingly biased in favor of business. reply FirmwareBurner 1 hour agorootparentWhy wouldn't it be? Businesses doing pro-business things are the main reason well paying jobs exist. And people love well paying jobs rather than poor paying jobs. reply drawkward 1 hour agorootparentI am making no claim about what the comment bias should be here on HN. I am merely reporting it to the parent comment. reply matsemann 1 hour agorootparentprevThat's a very loaded way of putting it. reply miltonlost 1 hour agorootparentprevnext [4 more] [flagged] FirmwareBurner 1 hour agorootparentGovernment is in charge of regulating the minimum wage. Private companies are in charge of bidding for the \"maximum wage\", they have no obligation for providing a minimum as they serve their shareholders not the public, the government serves the public. reply miltonlost 1 hour agorootparentOh honey, do you know what lobbying is? Or how Republicans get their funding? Or what dark money is? Private companies and their private interests have a vested interest in keeping minimum wage low, and exploit campaign finance to do so. (And they also bribe judges with vacations and speaking engagements and RVs.) Just because it's not the Wal-mart CEO deciding it himself does not mean that companies as whole don't do pro-business things and aren't the ones pulling the strings of their GOP puppets. reply drawkward 1 hour agorootparentprev>Private companies are in charge of bidding for the \"maximum wage\", they have no obligation for providing a minimum as they serve their shareholders not the public, the government serves the public. This doesn't support your point the way you think it might. reply eloisant 1 hour agorootparentprevSpeaking from a country where workers are very well protected, nothing really prevents anyone from being fired. It's just more expensive. A court never reinstates anyone to their job, the company just needs to pay damages to the former employee. reply cool_dude85 1 hour agorootparentIn the US you can be reinstated, it's not actually that uncommon of an outcome. reply cool_dude85 1 hour agorootparentprevMy own experience working in a white-collar union with a just cause provision is that the process is much more cumbersome and time consuming, and includes some off-ramps, but it is certainly possible to fire and or punish low performers. The more concretely \"low performance\" can be measured, the quicker and easier, but we're still talking months or years. reply kergonath 1 hour agorootparentprev> My understanding from the comments That is your problem right there. You cannot trust comments to give you an accurate idea of what actually happened. The linked source is marginally better (but keep in mind that it is close to one side of the story, even though it is more independent than some people here seem to believe). reply lc9er 1 hour agorootparentprevMost of the anti-union tech workers I've encountered over my career have vastly overestimated their abilities and value to the workforce. Their willingness to suffer abuse from employers (while taking pride in their refusal to establish boundaries) makes working conditions worse for all of us. reply bradlys 28 minutes agorootparentThe most aggressive I've seen advocating against unions are not ICs anymore and often are a part of management/capital. reply RobRivera 1 hour agorootparentprevBc management never abuses the optics to force out people that they dont like, vs someone productive, ever. reply drawkward 2 hours agorootparentprevSeems like a hiring problem, not a firing problem. reply mediaman 2 hours agorootparentHiring consistently high performing employees is not a solved problem. Making it hard to fire low performers results in low performing teams, and there are no reliable solutions to this. reply drawkward 2 hours agorootparentOne wonders if it is not solved simply because of at will employlemt? Almost like firms are lazy, and unwilling to go beyond the bare minumum required by law. reply kjksf 1 hour agorootparentIf you ever went through interview loop at Google or a similar company, I doubt you would call those companies \"lazy\" wrt. hiring. An interview is at least 4 people, each grilling you for an hour, asking hard questions. Their hiring bar is high and they optimize for avoiding bad hires (which of course is pissing off the commenters who want to be hired and therefore would prefer lower hiring standard). In Europe they make it harder to fire people and guess what happened? First, companies have probatory period (2-6 months, depending on the country) where you're hired but can be fired at will. This is to minimize chances of being stuck with a poor performer. Second, EU economy is about the size of US and China but software industry (and the tax / employment riches associated with it) is largely in US Chine. Might be a coincidence but I think there's causality between over-regulation and stagnation of the economy. reply drawkward 1 hour agorootparentI wonder if there is causality between \"over\"-regulation and life expectancy and quality of life too. What good is a growing economy when your country's people are living shorter, unhappier lives? reply umanwizard 1 hour agorootparentThe size of the economy very directly impacts people's quality of life. reply drawkward 43 minutes agorootparentI agree, but not necessarily at fostering happiness! Look at the countries that are generally regarded as happiest: are their economies the biggest? reply umanwizard 35 minutes agorootparent> Look at the countries that are generally regarded as happiest: are their economies the biggest? Assuming when you say \"biggest\" you mean per capita... yes. Obviously it's not the only factor, but generally I think it's generally accepted that people in rich countries are better off than people in poor countries. reply umanwizard 27 minutes agorootparentprev> One wonders if it is not solved simply because of at will employlemt? It's also not a solved problem in countries where at-will employment is not the norm. reply FirmwareBurner 1 hour agorootparentprevThere's nothing stopping someone from performing well at interviews then stop performing once they get hired and have the job secured. reply drawkward 1 hour agorootparentMoral obligations, a sense of pride in ones work, ethical worldview...thats just off the top of my head. It seems if the problem you allege were true at scale, the entire labor force is sitting around doing nothing. Are you really claiming that the only reason all (tech) employees do their job is just to avoid firing? How do you operate in a zero-trust life? reply FirmwareBurner 1 hour agorootparentI never said the things you claim. reply VWWHFSfQ 2 hours agorootparentprevI have lots of experience hiring tech people. Most of the time they turn out to be just as good as we thought they would be. But sometimes they don't. It would be terrible if it was impossible for us to let those people go. reply aguaviva 1 hour agorootparentIt would be terrible if it was impossible for us to let those people go. About half the people on this thread seem to be misreading that sentence. It's very clear that \"just cause\" includes cases of low performance. So no, it's not about making it impossible to fire these people. reply drawkward 2 hours agorootparentprevIt would be terrible for businesses to fire people arbitrarily. I'd rather give more rights to individuals than to businesses, because I am biased in an anti-business way: businesses arent bounded by human lifespans or biological constraints, get preferential treatment by the American legal system, have orders of magnitude more money and political power than individuals. It's almost like the USA fought a war and chartered individual rights in a document over this kind of shit, but never imagined businesses would be more encompassing than governments. reply VWWHFSfQ 1 hour agorootparentOff-shoring is already very prevalent in US tech work. So there certainly needs to be a balance in workers rights and business interest if those jobs are going to stay domestic. In general I agree with your perspective. But there is a harsh alternative reality that we're going to continue to face in the tech workforce. reply shadowgovt 2 hours agorootparentprevAges ago, I spoke with someone who had experience doing union organizing in the steel industry about why tech workers didn't unionize. I told him that the first step would be for tech workers to stop thinking that their greatest competition is other tech workers. (Flip the question: \"If your coworkers are low-performing but the union prevents the company from firing them, why don't you just go form your own company with your three closest buddies and compete? That's the dream, right?\") reply aguaviva 1 hour agorootparentprev\"Just cause\" clearly includes cases of low performance. The concern here is that there be some semblance of due process. reply diffeomorphism 1 hour agorootparentprevThat would be weird, so it is obviously not the case. That is because you are quoting only half of the (excerpt of the) point. reply kergonath 1 hour agorootparentprevPersonally, I prefer having a few low-performing people around than being in a state of existential threat of being fired for no reason by a middle manager. They are easier to work around. Anyway, no, that is not what they want. reply lallysingh 1 hour agorootparentprevWho wrote the article? What's their interest in the issue? reply feedforward 1 hour agorootparentprevWhen the wealth created by those who work at the New York Times is sent out in dividends to those who do no work or create wealth there, what is performance of these rentiers? You're arguing on the side of the rentiers and parasites who do not work, and lecturing about \"low performance\". It's the people doing the work's purview to discuss performance, not the parasites. reply Eumenes 2 hours agorootparentprev> This is such a weird request for technology workers. You want to work with low-performing coworkers? Have you seen the zeitgeist by tech workers for DEI driven hiring processes? I have. Google notoriously does this with their scoring system (1 - no hire, 2 - weak no hire, 3 - weak hire, 4 - strong hire) ... you typically need above a 3.0 to get into hiring committees, but candidates of certain backgrounds are hired all_the_time with way lower scores than that. reply laidoffamazon 1 hour agorootparentSerious doubt on this one. If I were to guess I’d imagine those people are recycled into different positions with a different bar. reply Eumenes 1 hour agorootparentYes, that happened sometimes, but I saw it both ways. Example 1: candidate interviews for a SWE job, fails that round, but decent enough to be considered for a sales engineer cause of good people/comm skills. Example 2: candidate interviews for SWE job, comes from under-represented background, scores below the require threshold, gets pushed through because of DEI. If the case is close, the recruiter is required to find examples - references (external or internal) that are positive, which isn't hard. reply code_for_monkey 2 hours agorootparentprevthis is just racism reply aliasxneo 1 hour agorootparentInterestingly, this comment can be interpreted both ways. The act of pushing people through a lower barrier based on their race can be inferred as racist, or the claim that such a thing is happening can also be inferred as racist. I spent eight years at Google, starting long before these DEI mandates came in (and did over a hundred interviews during that period). I think the person you're responding to is being sensationalist, but I also feel the way these measures were rolled out did end up missing out on a lot of great hires due to them not fitting the perceived makeup of the company. Funnily enough, I recall a specific meeting where they were planning to roll out measures to equalize pay between male and females. Prior to the rollout, they did an internal audit to understand the extent of the problem, and the audit came back highly favoring females over males. To Google's credit, they didn't move forward with it. reply Eumenes 1 hour agorootparent> I spent eight years at Google, starting long before these DEI mandates came in (and did over a hundred interviews during that period). I think the person you're responding to is being sensationalist, but I also feel the way these measures were rolled out did end up missing out on a lot of great hires due to them not fitting the perceived makeup of the company. If you were at Google that long, try to find someone who sat in on a hiring committee. They rubber stamped packets of candidates below the bar all the time. Interviewers were kept out of the loop by design. You rarely knew if the people you interviewed were hired or not (unless you worked for a small office). But yes, I agree, Google passed on many good candidates over the years, and thats why they let you interview multiple times. If you interviewed in 2011 and \"just missed\", you'd likely be a strong hire in 2015. reply adrianstoll 49 minutes agorootparent> You rarely knew if the people you interviewed were hired or not Perhaps this has changed over the years. I recall there is a website listing all the people you have interviewed and their status (e.g. upcoming interview, rejected, application withdrawn etc) reply cool_dude85 2 hours agorootparentprevWho your boss says is \"low-performing\" may not match your own experience of who is \"low-performing\", and may include e.g. people who the boss doesn't personally like, or indeed may include you yourself. reply legitster 1 hour agorootparentprevIt's particularly an awful request to pair with remote work. \"I should be able to work anywhere so long as it doesn't affect my performance...\" \"Also don't judge me based on performance\". I think people need to be honest that WFH is as an argument is tightly integrated with merit. reply eloisant 1 hour agorootparentI don't see the link. Does working in office means you're allowed to do a crappy job? reply legitster 1 hour agorootparentI mean, in the context of most union agreements with a similar provision, kinda. Your union might protect you from termination on an assembly line, and at least they can move you around the facility or bring in extra workers. Or for a teacher they bring in more supervision and resources. In contexts where unions have similar provisions, direct supervision is implied. reply maronato 2 hours agoparentprevNegotiations have been going on for 2 years, and the strike was approved in September. This isn’t a spur-of-the-moment, attention-seeking thing and was totally preventable by NYT. https://www.axios.com/2024/09/10/nyt-tech-union-strike-vote reply cool_dude85 2 hours agoparentprevWhat's crappy about the union striking when they have leverage? Should they have waited until the strike would apply less pressure to their employer? reply legitster 2 hours agorootparent1: If a union strikes when it has too much leverage, there's a risk there as well at overplaying the hand. If the Times does just fine during the election, then the union helps make the case their members are overrated. If the Times crashes and burns during the election, they might make the value of the contract weaker. 2: In an election where trust and reliability of independent media are really being called into question, something like this could have outsized negative impact. There's potentially a lot of damage to innocent third parties, including smaller syndication partners. reply itake 1 hour agorootparentDoes SWE striking even mean anything to a company? If factory workers don't show up, no products are made. If a SWE doesn't show up, the website is just fine (see elon buys twitter). SWE impact is measured in quarters or years, especially at a big company that doesn't have public deadlines for project delivery. reply pydry 1 hour agorootparentprev>If a union strikes when it has too much leverage, there's a risk there as well at overplaying the hand. You might need to take some lessons in negotiating. reply drawkward 2 hours agorootparentprev1: i suppose we will have to wait and see whether it was a crappy or smart move. 2: i suspect that it is not the NYT readers who are fretting about media credibility. By definition, they already believe in the system. reply foota 2 hours agorootparentprevBecause waiting for the time when you can apply the most leverage is a shitty thing to do? How would you feel if your house was on fire and the fire fighters went on strike only then to demand they be given bounties? They had a contract, waiting for the time when the work they do is absolutely critical is antisocial behavior. Society is built on people honoring their commitments. reply rapind 50 minutes agorootparent> How would you feel if your house was on fire and the fire fighters went on strike only then to demand they be given bounties? What a terrible analogy promoting a ridiculous narrative. A better analogy is if it's the mayors house on fire, it was predetermined when exactly the mayors house would catch fire, the mayor had been warned well in advance of his house catching fire that the firefighters would like to negotiate their contract, and had in fact been involved in negotiations for years already. Not quite the same zing to it though... reply yoyohello13 2 hours agoparentprev> Striking during election week is kind of a crappy move to pull. That’s leverage. Striking during a time when the business doesn’t care is a dumb move. reply bloomingkales 2 hours agorootparentLet me correct you, this will be election month at minimum. The NYT kind of brings this kind of heat on itself because it has shifted from being just the paper of record over to an institution to the current definition of progressivism. You can only really do this union kinda stuff against self-important institutions. Which developer is ever going to attempt this on Accenture? They are straight up and honest about their business, which is they are trying to rake profits from connecting developers with companies - whatever it takes, whoever, from wherever, at whatever price is profitable. The Times adorned itself as something more than a business, a special kind of business, a business that fights for something. So there you go, live up to it I guess. Here is some of the content that the NYTimes focuses on: https://www.nytimes.com/2023/07/21/opinion/starbucks-union-s... reply drawkward 1 hour agorootparent> the current definition of progressivism It's a fairly pro-business paper, certainly not very critical of Israel, and you appear to have completely missed all of its somewhat trans-skeptical reporting and opinion. (The latter pervasive enough to rankle many of its own employees about the tone and tenor of NYT coverage of trans issues.) reply bloomingkales 1 hour agorootparentI want to believe you, but my hunch is your reply is similar to someone suggesting \"Well, you see, you forgot all the pro liberal coverage that Fox News has been doing all year\". Does NYT not have a reputation or am I truly out of touch here? I went through some of their podcasts recently and it's all quite one-sided, for example. reply SalmonSnarker 1 hour agorootparent> am I truly out of touch here? Yes, you are absolutely out of touch. drawkward gave you three incredibly specific examples but you just kept on sticking with your hunch. A paper that is the \"epitome of progressivism\" probably isn't going to have multiple conservative opinion columnists heavily featured and isn't going to have recurring problems with fawning interviews of white supremacists over barbecue. I suppose if you're any further than center-right, a paper that is narrowly center-left is going to appear to be the \"epitome of progressivism\", but many years of critique would probably suggest otherwise. politely, i don't think this would be something you'd get tripped up on if you'd paid attention for a few years longer than a singular skim of the podcasts recently. reply metabagel 1 hour agorootparentprevI think it’s a mistake to judge the NYT by their podcasts. I canceled my subscription when they reported on the concessions the UAW had won from automakers mostly in terms of how it might affect the bottom line of the companies, and with little to no mention of the effect on the workers and their families. reply drawkward 1 hour agorootparentprevI think the paper is generally lib-left, but not necessarily progressive-left. I also see NPR as pretty centrist reporting. reply briandear 23 minutes agorootparentNPR and NY Times are almost identically left-biased, with NPR being slightly more so. https://www.allsides.com/news-source/npr-editorial https://www.allsides.com/news-source/new-york-times reply rapind 38 minutes agorootparentprevIt depends where you're coming from. Some (many now?) see Dick Cheney as a progressive liberal liar, and many on the left see him as a right-wing devil incarnate. reply hosh 1 hour agorootparentprevI was very disappointed with NYT’s coverage of the 2020 elections, and it has been difficult for me to take their reporting seriously since then. That they had their own workers striking is not a good look, yet unsurprising to me at this point. Just my opinion, I don’t know if this counts as reputation. (NPR was even more disappointing because they positioned themselves as centrist; APM’s Marketplace was closer centrist that than NPR). reply avazhi 1 hour agorootparentprev> It's a fairly pro-business paper, certainly not very critical of Israel Sorry, are we both talking about the New York Times in 2024 here? Not a day goes by that there isn’t an article crying about Palestinians and bashing Israel - there’s one right now, just scroll down to the section just above sports. Calling it the preeminent progressive institution in America media today is axiomatic. reply metabagel 1 hour agorootparentIs it crying about Palestinians or just reporting the news? Can you tell the difference? reply briandear 21 minutes agorootparentprevIs supporting Hamas a progressive position? Hard for me to keep track these days. reply drawkward 8 minutes agorootparentPlease, i beg you, show me a single instance of NYT support for Haman. drawkward 1 hour agorootparentprevI'm sorry, when did the NYT call Isreal's behavior genocidal? I must have missed it. Any objective observer would call Israel's behavior abhorrent wrt Gaza. In fact, it seems like the majority of the planet is doing that, if the UN is representative. reply drawkward 1 hour agorootparentprev>Calling it the preeminent progressive institution in America media today is axiomatic. ...among certain not-unbiased segments of the population. reply abletonlive 1 hour agorootparentprevI like the implication that being \"trans-skeptical\" is \"non-progressive\" and therefore to be a progressive you have to buy into the ideology without questioning anything. That does align with my current views of where progressive ideology is headed reply drawkward 1 hour agorootparentI think the bulk of the pro-trans movement would consider themselves progressive. I think that the bulk of progressives would consider themselves pro-trans. I don't consider myself a progressive for just this reason. I would be considered a TERF by the trans community, not because I think trans people don't exist or arent worth of love, employment, and respect, but rather because there are some hot issues (bathroom access, sports access, how to handle children permanently transitioning, replacing cisgendered terminology in medical textbooks) that I believe merit more study or nuanced approaches. At the end of the day, it comes down to the question of who has the right to define what labels, and I think most progressives would not call you a progressive if you don't 100% accept trans rights. Of course, this demands lockstep ideological behavior, which is rarely a good thing for long. Could you be progressive on some issues and not others? Certainly! But which mix defines you as \"progressive\" or not is not up to me. reply acdha 1 hour agorootparentprev> The NYT kind of brings this kind of heat on itself because it has shifted from being just the paper of record over to an institution to the current definition of progressivism. This sounds like how American conservatives describe it rather than how most readers or actual progressives would - the latter having significant misgivings about how it covered Iraq, Occupy Wall Street, the 2016 election coverage of things like the email hacks and FBI investigations relative to their actual substance, the tone of their coverage and editorials about transgender issues, etc. The best way I’ve found to describe the NYT is as representing the east coast establishment. The issues which earned them attacks as liberal were things like favorably covering gay rights, which affects those elites (even rich sons of influential families can be born gay so everyone knows someone who benefits from that), but they tend to be more conservative on things like workers rights or tax issues which don’t affect or may even threaten their affluent readers. Climate change affects everyone but their opinion pieces are going to be things like “buy an induction stove” or “vacation in Nepal before the snow melts and buy some carbon offsets” rather than “stop flying and eat less beef” because their target reader wants to do the former and not the latter. reply bell-cot 1 hour agorootparentprev> The Times adorned itself as something more... +/- your buy-in on that image. Pete's Pizza Parlor also adorns itself - as being on a mission to serve up piping hot pizza pies. reply MisterBastahrd 1 hour agorootparentprevYou are comically uninformed. If the NYT were even remotely progressive, they'd have been consistently flogging the living shit out of Donald Trump and his idiotic, dementia-driven behavior behind a podium for months now instead of pretending like we should accept it as normal while excoriating Harris for behaving like a mainstream political candidate. reply briandear 8 minutes agorootparentDementia driven? We can certainly disagree on policy objectives, but claiming Trump has dementia is absolute nonsense. Did you watch the Rogan interview? Regardless of one’s views on his politics, there is not even a remote hint of dementia. reply SoftTalker 1 hour agorootparentprevYeah the media have been salivating for this week for months now. Exactly why I'm not planning to read or watch any news this week. I'll vote tomorrow. That's what I can do. All the rest of it is out of my hands and I'm not going to spend any of my time or mental energy engaging in the manufactured drama sure to come. Like my barber said at my last haircut: the only sure thing about this election is that an idiot will be our next president. reply jimbob45 30 minutes agorootparentExactly why I'm not planning to read or watch any news this week. I see we share the same strategy. My new policy is that I shut the news off once the polls open on election day and don't turn it back on until the following morning. Over the course of my life, I'll accrue enough saved hours to have achieved something minor, yet meaningful. reply metabagel 1 hour agorootparentprevNot necessarily. Trump might not win. It boggles my mind at how proud people are to refuse to draw a distinction between two completely different candidates. One has demonstrated competence and public service, while the other has demonstrated incompetence and chronic self-dealing. Refusing to draw a distinction is moral cowardice. reply SoftTalker 1 hour agorootparentI agree they are completely different. I don't think either are remotely qualified. I have been struggling with whether I'll vote for president at all. I cannot in good conscience endorse either candidate, on the other hand those are the choices I have. I guess I could do a symbolic write-in. I have never been less motivated for a presidential election in my life. reply datavirtue 2 hours agorootparentprevnext [6 more] [flagged] 1shooner 2 hours agorootparentI don't blindly give unions a pass, but you're asking if a business would use the value of their product at a particular point in time to set terms. Of course they do. If NYT didn't want to be caught in the lurch, that's what contracts are for, which they've had plenty of time to secure. By the way, the price of Christmas trees is about to skyrocket, ridiculous! reply cool_dude85 2 hours agorootparentprevIf using what leverage you have is so ridiculous, a suggestion to NYT management: agree to every contract provision on a temporary basis, and continue ongoing negotiations with the union which provisions to take away in the permanent contract. That would end some of the leverage the NYT has and level the playing field for fruitful negotiations. reply shigawire 2 hours agorootparentprevBusinesses already hold a lot of leverage over employees - like healthcare or the ability to feed their families. reply lucianbr 1 hour agorootparentprevYes, a business would use all their advantages at the maximum, with disregard for any other consideration than money, and tell you \"it's just business\". Or \"it's fiduciary duty\". Now that the shoe is on the other foot, suddenly they want to be reasonable? Funny that. reply shkkmo 2 hours agorootparentprev> Would a business battle with any other partner like this? Regularly. One striking example is that way our monopsonies treat often treat their suppliers. reply PittleyDunkin 2 hours agoparentprev> Striking during election week is kind of a crappy move to pull. It's smart. The one week where americans manage pull their head out of their ass is a good time to move. reply wholinator2 1 hour agorootparentI don't know, probably the lowest common denominator is paying more attention but most everyone i know is desperately trying to shove their heads anywhere that is quiet and calm. The fervor and anger with which all common media explodes during election month is unbearable. reply briandear 6 minutes agorootparentMost of us aren’t paying attention to The NY Times. If they aren’t there, nobody will notice. reply seizethecheese 2 hours agorootparentprevWhy not both smart and crappy? reply PittleyDunkin 1 hour agorootparentTBH, i don't see the crappy angle at all. I think the country will be just fine without its favored boutique-news-coverage-election-needle-software. Besides, the actual coverage isn't being effected at all. EDIT: spelling reply bojo 2 hours agoparentprev> Striking during election week is kind of a crappy move to pull. That sounds like an anti-union stance to me. There's no better time to strike than when your opponent can't afford to look bad. reply blululu 30 minutes agoparentprevNot sure how risky this really is for the Union. Their software engineers are taking a pay cut for the prestige of working for the most influential newspaper on earth. When your BATNA is getting a 50% pay bump somewhere else then strike away. God forbid if the servers crash while reporting on the second hand recount in Georgia next month. reply Taylor_OD 2 hours agoparentprev> Striking during election week is kind of a crappy move to pull. If a strike isnt painful for the employer, what incentive do they have to negotiate? reply dehrmann 2 hours agoparentprev> Striking during election week is kind of a crappy move to pull Siblings are doubting this, but you can think of it like price gouging. It's the right behavior for extracting maximum value, but it burns a lot of trust, and that's important for a long-term business arrangement. It's playing the short game when they should be playing the long game. reply maronato 2 hours agorootparentStrikes happen when the trust is already burned. This has been going on for a long time, and we’re only seeing the public side of the conflict. > The guild, which was formed in 2022, has yet to secure a contract after more than two years of bargaining. https://www.axios.com/2024/09/10/nyt-tech-union-strike-vote reply lucianbr 1 hour agorootparentprevMaybe there is little trust left? I don't know about NYT in particular, but the news regularly suggests employees trusting businesses are nothing but suckers. reply JohnBrookz 2 hours agoparentprevThat’s the perfect time to go on strike. reply farts_mckensy 26 minutes agoparentprev> Striking during election week is kind of a crappy move to pull. I love that the default ideology here is to side with the employer. I'm glad that when I am negotiating my salary with my employer, there are no comments from the Peanuts gallery. reply yieldcrv 1 hour agoparentprev> Striking during election week is kind of a crappy move to pull. According to the NY Times article, this was outlined and agreed to by the union on September 10th. So this is the poison pill because the agreement wasn't finished over the last 2 months. reply feedforward 1 hour agoparentprev> Striking during election week is kind of a crappy move to pull. Yes, heaven forbid the people doing all the work and creating all the wealth actually use their leverage against the heirs collecting NYT dividends. reply 39896880 56 minutes agoparentprev> Striking during election week is kind of a crappy move to pull. Can we get a definitive list of weeks where workers’ rights are officially less important than $world_event? That way we can schedule our requests appropriately. We don’t want to inconvenience anyone. reply dang 22 minutes agorootparentPlease make your substantive points without snark. This is in the site guidelines: https://news.ycombinator.com/newsguidelines.html. reply legitster 43 minutes agorootparentprevI know you are trying to be flip, but there topics that are more important than worker's rights. I'm not going to argue that the NYTimes crossword is up there, but I think a good case can be made that independent journalism is up there, especially during open elections. There is a long list of organizations and governments that made worker's rights more important than inclusive democratic institutions, and it didn't work out for anyone, especially the workers. Maybe any of the 207 weeks between presidential elections? Or any of the thousands of weeks when one of the running candidates has threatened the legitimacy of their institution directly? reply marricks 35 minutes agorootparentDay of election there is a big tally when votes come in and pictures of American Democracy In Action with a bunch of puff stories about people in lines. Huge time for viewership, not a huge time for important journalism. There is no perfect time to strike, but I think other outlets can cover the typical: - \"huge lines in Pennsylvania!\" - \"Polls close in [KEY SWING STATE] in 2 hours!\" - \"Wow the whole west coast went blue, who would have thought!\" - \"Shocker that one battleground is going into recount which will somehow last 4 weeks.\" reply petesergeant 26 minutes agorootparentprevThere will be absolutely no shortage of other places where Americans get their election news, and arguably at a higher quality than NYT. I will miss their election ticker dashboard widget thing though, that thing is cool. reply Justsignedup 29 minutes agorootparentprevAll people who don't care say \"can you please go over there, in the corner, where I can't see you, so you can protest and I can appropriately ignore you.\" The point of a protest is to annoy you. Annoy you enough into action. reply science4sail 20 minutes agorootparentAnnoyance so that bystanders support the protesters' demands or annoyance so that bystanders act against the protesters out of spite? After all, the Westboro Baptist Church's protests don't seem to have been very effective at promoting the cause of homophobia. I think that protests are a risky move unless the general population is already sympathetic to the protesters' goals. reply hollerith 21 minutes agorootparentprevWhat action am I supposed to take on behalf of these cognitively-privileged workers already earning six-figure salaries? reply krainboltgreene 2 hours agoparentprevIt seems extremely bad taste for you to comment on the situation like this with such little insight. Like do you even have any union negotiation experience? Monday morning quarterbacking is always so tacky. reply legitster 2 hours agorootparent> Like do you even have any union negotiation experience? I spent 3 years working for a professional union negotiator. I don't know everything, but I feel like I have a bit more insight into how the sausage gets made. reply krainboltgreene 53 minutes agorootparentMan I sincerely doubt that because I would never ever feel comfortable commenting like that. I looked through your post history for union references and it seems like you're not all that onboard with american unionization practices. I guess I'm forced to believe you due to anonymity though. reply dbalatero 5 hours agoprevHere is context on the strike, how long it's been brewing, and more that I happened to read yesterday: https://www.thenation.com/article/archive/the-new-york-times... reply crazygringo 2 hours agoparentThank you so much! That is a vastly more informative article. It seems like it's not so much the NYT is opposed to the contract's specifics -- they're opposed to having a contract at all because the union is new. The NYT has been stringing the union along without ever actually signing anything, so now the union has to strike to get the NYT to take them seriously. Key parts: > The Tech Guild won its unionization vote in March of 2022, but has yet to agree upon a final contract with management. In September of this year, the Guild voted to authorize a strike with an overwhelming 95 percent (or over 500 members) in favor. The vote marked two and a half years of bargaining with no result. As Harnett puts it, “At some point, you need a deadline.” > The first key demand is a protection that Times editorial staff already have: just-cause job protections, which would ensure that members cannot be fired without good reason and due process. The editorial staff won this protection in their 2023 News Guild contract, and just weeks ago, 750 Times journalists penned a letter to management urging them to reach a contract with the Tech Guild before Election day. > The second demand stems from a pay study the union released in June of this year, which found numerous pay discrepancies for women and people of color. According to the study, Black tech workers at the newspaper make 26 percent less than white workers. The study also found that women, who make up over 40 percent of the Tech Guild, earn 12 percent less on average than men, while Black and Hispanic or Latina women earn 33 percent less than white men. > The third demand in dispute is a frequent source of anxiety for Hoehne in particular: return to office. Currently, many in the Tech Guild work remotely full-time.... Hoehne has been living and working remotely three hours away from the Times office, in upstate New York, since the pandemic began. “I would lose my job. I can’t sell my house. My kid is in daycare. I can’t. All we’re asking is for them to put in writing that we won’t do that to you.” > But both Hoehne and Harnett don’t think management’s reluctance to settle these demands stems from the particulars of any of the demands themselves; none of them would spark radical changes. The negotiation process has lagged for years, which Times editorial staff experienced en route to their contract as well. Rather, Hoehne said, staring down the barrel of the Election Day strike, management’s immovability feels like it’s more about preventing the union from stabilizing at all. > “They could easily end all of this with a single phone call or e-mail,” Harnett said. “But they’re making the decision not to. Maybe they don’t believe that we are resolved [to strike]. I don’t know how else to convince them.” reply chrisweekly 2 hours agoparentprevThank you! I wish I could promote this (and @crazygringo's helpful summary a few min ago) to the top of the thread. The rest of the HN commentary so far would've benefited from it a lot. reply ChrisArchitect 7 hours agoprevGift link: https://www.nytimes.com/2024/11/04/business/media/new-york-t... https://archive.ph/f9gP0 reply 7thpower 6 hours agoparentYou are doing god’s work. Also, fyi for others. Many public libraries have NYT daily access codes you can use for free. It’s a bit of a pain to have to renew each day you want to read NYT but is still great to have. Having a gift link is even more convenient. reply adolph 2 hours agorootparentThanks for mentioning that! One of my libraries does a 3 day code. It looks reasonably insecure and scriptable to fetch since it is hard coded as a hidden element in the page that opens the NYT page upon successful login. reply dang 3 hours agorootparentprevnext [3 more] We detached this comment from https://news.ycombinator.com/item?id=42040802. (Nothing wrong with your post, I just want to pin the parent to the top so people don't miss the links, and it's better not to consume extra real estate up there) reply 7thpower 2 hours agorootparentAppreciate the note! reply dang 37 minutes agorootparentNow that we switched to WaPo I've put it back :) reply criddell 6 hours agoparentprevThe current top comment includes this: > I encourage everyone to respect the picket line and get your news elsewhere until the workers get a deal. It would be nice if this could be replaced with a non-NYT link. reply smallerize 3 hours agorootparentThat is not what the union asked for. The guild said it was asking readers to honor its digital picket line by not playing Times Games products, such as Wordle, and not using the Cooking app. reply jjcm 44 minutes agoprevFor reference, here's a current job opening for NYT's tech org for a senior software developer: https://boards.greenhouse.io/thenewyorktimes/jobs/4472655005 Salary is 140-155k USD. For reference, here's levels.fyi's breakdown of the New York city area: https://www.levels.fyi/t/software-engineer/locations/new-yor... Median total comp is 185k. It seems like their total comp for NYT is slightly above the mark based on reported salaries: https://www.levels.fyi/companies/the-new-york-times-company/... reply ppeetteerr 6 minutes agoparentThank you for surfacing this. A senior role in NYC for 155K (plus bonus, which they do offer) is nothing when you factor in the cost of living. reply Aurornis 20 minutes agoparentprevThe article (which is paywalled) says average compensation is $190,000. They also have 600 technologists on staff, which is massively higher than comparable news organizations. I think this is the real elephant in the room: They're hiring (and therefore spending) at a rate that already far outstrips comparable news organizations. reply ChrisArchitect 5 hours agoprevAlternative non-NYT link (submission link could be changed to this too I suppose): New York Times Tech Guild Walks Off the Job https://nyguild.org/post/new-york-times-tech-guild-walks-off... reply jayemar 3 hours agoprevAlso covered on The Verge: https://www.theverge.com/2024/11/4/24287600/new-york-times-t... reply mellosouls 6 hours agoprevAs much as I am a bolshy union member and supporter, this doesn't seem too bad on the surface, the article doesn't make clear what the issues with it are? Times management said in an email to workers on Sunday that it had offered a 2.5 percent annual wage increase, a minimum 5 percent pay increase for promotions and a $1,000 ratification bonus. It also said that the company would maintain its current in-office work requirements of two days a week through June 2025, while allowing employees to work fully remotely for three weeks per year. reply SiempreViernes 46 minutes agoparentProbably because the article you read is from the party that doesn't want to make a deal, try this summary: https://news.ycombinator.com/item?id=42043604 reply xpe 2 hours agoparentprev> As much as I am a bolshy union member and supporter, this doesn't seem too bad on the surface, the article doesn't make clear what the issues with it are? The linked article is the New York Times writing about a strike _against_ the New York Times. Factor this into your assessments. reply dialup_sounds 1 hour agorootparentIf you're implying bias, consider that the news and editorial staff have been unionized since the 1940s. reply Xelynega 1 hour agorootparentConsider also that these workers have been unionized for over two years and the NYT is refusing to acknowledge them. reply randomdata 4 hours agoparentprev> the article doesn't make clear what the issues with it are? What is not clear? The article tells that the issues are contention around return to office policies (as your quote tells, change is planned for July) and wanting a “just cause” provision. reply mellosouls 2 hours agorootparentBut it's a reasonable offer, there is no clarity in the article about exactly what is so bad they need to strike. Eg if they said we haven't had a pay rise for ten years, that would provide context. Nothing in the article gives a justification for a strike. That's not to say the justification doesn't exist but it's not remotely elucidated. reply miltonlost 2 hours agorootparentYou find it reasonable. THe union, and I, do not find a RTO announcement in June (or anytime really) to be a reasonable request. So yes, the article justified the strike. You just don't think the justification is reasonable. reply DoneWithAllThat 1 hour agorootparentYou don’t think it’s reasonable to tell your employees that as a condition of employment they have to be at a specific location at specific times? reply miltonlost 1 hour agorootparentIf they are tech workers who only need a laptop and can work remotely 3 days a week normally, and therefore 5 as well? Yes, its unreasonable as their specific location at a specific time is unnecessary. If you don't need to be physically present to work, then it is unreasonable to force someone to relocate or to come into an office. Is it reasonable to tell your factory worker employees that they have to be at the factory at certain times? Yes, that's reasonable because these workers must be physically there. Using broad words like \"employees\" and \"employment\" simplifies your thinking. reply jajko 1 hour agorootparentBut you have no idea about internals of NYT, do you? You have no idea whats reasonable and whats not in their team. BTW why people create a new accounts just to furiously comment all over pretty basic topics like this? Are you really that ashamed of your own opinions (which are still anonymous) or you feel your employer may trace you back? Or NYT employee? reply miltonlost 1 hour agorootparentAnd you do know what's reasonable? I'm gonna side with the union and not the company owned by a billionaire reply randomdata 1 hour agorootparentprevOf course it is reasonable. But it is equally reasonable for workers, as a condition of employment, to be able to work remotely. Everyone gets to choose what they want for themselves. If an agreement can't be made... Oh well. reply chimeracoder 30 minutes agorootparentprev> You don’t think it’s reasonable to tell your employees that as a condition of employment they have to be at a specific location at specific times? You think it's reasonable to hire someone remotely, then later forcibly relocate them to another, more expensive city, with no compensation? Because that's what's happened here. In jurisdictions with stronger labor laws, that is not only not reasonable, but outright illegal (constructive termination). reply kortilla 2 hours agorootparentprevThey don’t think RTO is reasonable, which is a completely logical stance to take if you’ve setup your life working from home (esp if it’s hours from the office). reply jajko 1 hour agorootparent... which is something people did on their own, without agreeing with their employers on duration etc. I love working from home, but its just a non-guaranteed perk that can go away anytime and eventually it will, and companies shouldn't break their backs to accommodate people. There is free job market to match one's expectations, triple especially in places like New York. I really, really don't get folks who setup their lives in the middle of nowhere to save some bucks and then they complain that world and work doesn't come to their doorstep. You took the risk in maybe unclear situation, you bear the consequences if the risk doesn't pan out your way. reply everforward 1 hour agorootparent> and companies shouldn't break their backs to accommodate people. Why isn't the inverse equally true? That workers shouldn't have to break their back to accommodate a change in company policy? > You took the risk in maybe unclear situation, you bear the consequences if the risk doesn't pan out your way. Again, I think this is equally true going the other way. Companies allowed their workers to move away from the office, why don't they assume any risk that workers won't want to return? I get that there needs to be a balance of power, but I don't understand why any request from the company is valid by default and any request by workers is somehow an imposition that the workers need to justify. Why isn't the company asked to justify why workers need to RTO? reply randomdata 43 minutes agorootparent> Why isn't the company asked to justify why workers need to RTO? Well, we do know the state of New York offered the NYT (among others) tax incentives/subsidies earlier in the year. I can't imagine the state of New York will be happy if the workforce works from New Jersey (or Texas). Calling upon the workers to work in New York gives the state the economic activity it expects in return for the subsidies it offered. But does that make any difference to the workers? If they want to work remotely, what goes on between the state of NY and the NYT is not really their problem. reply randomdata 2 hours agorootparentprev> Eg if they said we haven't had a pay rise for ten years, that would provide context. That wouldn't provide any kind of justification either, though. All it might indicate is that they desire more pay, just as we know here that they desire a different policy around remote work and desire a “just cause” provision. And it seems that is the motivation – simply that they want it. Which is all the justification that is needed. One does not have to work if they don't want to. It is up to the NYT to decide if it wants to compel them to or not. reply MisterBastahrd 1 hour agoparentprevA 2.5% annual wage increase doesn't even cover inflation over the past few years. That is a complete non-starter. reply perihelions 6 hours agoprevhttps://archive.is/c35UA reply infecto 6 hours agoprevJust cause feels like a stretch. Is that common in a lot of employment contracts? Feels like one of those rules that sounds like it could make sense but in reality it does not play out and you get this weird cohort of unproductive employees that you can never get rid of. reply quandrum 2 hours agoparentDue process for employment is probably more important than fair pay in most union contracts. Your argument is in fact that exact same one that was used to argue against due process in legal proceedings. \"In reality it doesn't play out and you get this group of criminals running free on legal technicalities.\" If you are in a union shop and have a large contingent of unproductive employees, it happens for the same reason as non-union shops. You have bad management. Just Cause is almost entirely asking management to do a little paperwork and a little planning, things that are supposed to be their job anyway. reply infecto 2 hours agorootparentWhat argument have I made other than a question? I would like to see data how it plays out. Now I have some ideas of how it plays out but it would be interesting if there was a way to have a test/control group in these types of contracts. I find the struggles here interesting and its fun to watch them play out. reply kortilla 2 hours agorootparentprevnext [11 more] [flagged] drawkward 2 hours agorootparentWhere is this legendary employer who instantly hires all takers, no questions asked? reply FredPret 1 hour agorootparentThe actual development of capitalism around the world has shown that when business is thriving, there tends to be lots of employers willing to mop up any excess labour. We’ve seen a ton of automation and offshoring for centuries now but employment around the world just keeps improving. reply drawkward 1 hour agorootparentAnd yet, we have a positive unemployment rate! reply FredPret 1 hour agorootparentTrue but that’s inevitable. A certain % of people are always going to be in the process of switching jobs. reply drawkward 1 hour agorootparentWhich is why I reponded to the commenter who said >Dumb comparison. Losing a job is not the same as losing a legal action. You can’t just go get a different life if you’re convicted of robbery. Because, as you just admitted, you can't just go get a different job if you're unfairly fired. reply FredPret 1 hour agorootparentI admitted no such thing. Read again. - in a thriving environment, lots of companies are hiring - some people quit or get fired, and it takes a couple of months to get a new job. This is no biggie in a country where the median individual has a net worth of 192k. [0] (yet another argument in favour of a thriving business environment). - so some % of people will always be temporarily unemployed. [0] https://www.investopedia.com/average-americans-net-worth-871.... reply drawkward 50 minutes agorootparent>no biggie Loll, youre a pretty funny person. No biggie, ill just sell my house to feed myself. You conveniently ignore the fact that this is the median family net worth, not individual net worth. Further, this will include retired families, who will have access to social security, medicare, and mature 401k/pension plans. This is not anywherenearthe median net worth of a working individual. If youre going to quote statistics, please at least do so responsibly. reply FredPret 24 minutes agorootparentWe can play this game of adding asterisks and more details and counterpoints all day. But hey, if you’re determined to be angry and unhappy about employment in the USA, the best place in history to be poor, middle class, or any kind of job seeker… this is where I leave you. drawkward 21 minutes agorootparentYes, if by \"game of adding asterisks\" you mean honest representation of statistics, we will never find common ground. FredPret 7 minutes agorootparentYou’re the one interpreting a stat in a motivated way. Middle class Americans have high net worths; some in stocks, some in cash, some in home equity. All of the above can be leveraged when cash is needed. purple_ferret 2 hours agoparentprevIt's very common in union contracts. They way it usually works is there is a probationary period that you can fire someone under for any reason (usually 90 days), but after that, supposedly you're more protected. That said, in practice, it doesn't really prevent you from being part of a layoff or anything. You'll just get more notice and complaints. reply willsmith72 1 hour agorootparentUnion contracts, or just about any permanent contract in \"the west\" except America reply itake 1 hour agorootparentprevProbation periods are a mess, b/c they incentivizes \"hire and fire\". reply SiempreViernes 49 minutes agorootparentThough only for employers that don't care who they hire in the first place, if you fire someone simply because they might be harder to fire lately you don't really care about who you hired. reply itake 15 minutes agorootparentI actually came to the opposite conclusion: you really care about who you hired, because you define who they work with. If you hire a low performer or someone that isn't a good culture fit, the productivity of your other team members will suffer. reply dfxm12 5 hours agoparentprevThe default for the US is \"at-will employment\", which means that your employer can fire you at any time, no reason needed. The definition of \"just cause\" would be collectively bargained, so both management and the union will understand and agree on what constitutes just cause or not. FWIW, layoffs are regulated differently from firings. reply gruez 2 hours agorootparent>The default for the US is \"at-will employment\", which means that your employer can fire you at any time, no reason needed. That seems... fine? In most transaction neither party needs to give \"just cause\" to terminate a contract. Imagine having to give documentation to move out of your current apartment, for instance. Getting fired is disruptive to someone's finances that some notice/severance would be justified, but \"you have to give just cause\" (which in practice, means multiple formal write-ups and several months of PIP, even in places without a union contract) seems excessive. reply miltonlost 2 hours agorootparent>>The default for the US is \"at-will employment\", which means that your employer can fire you at any time, no reason needed. >> That seems... fine? In most transaction neither party needs to give \"just cause\" to terminate a contract. You like having a sword over your neck at all times that an employer can just swing and take away your salary and your health insurance for any reason at all? reply gruez 2 hours agorootparentDid you stop reading there and not the subsequent sentence? >Getting fired is disruptive to someone's finances that some notice/severance would be justified reply miltonlost 2 hours agorootparentDid you stop reading there and not the subsequent independent clause? > but \"you have to give just cause\" (which in practice, means multiple formal write-ups and several months of PIP, even in places without a union contract) seems excessive. You still said requiring \"just cause\" is excessive. So you still want an \"at-will\" sword over your head. reply gruez 1 hour agorootparent>So you still want an \"at-will\" sword over your head. That sword is still going to be over your head regardless of at will employment. You could be laid off (no cause needed), the company goes bankrupt, or you become disabled. Where do you draw the line? If you don't want to accept \"sword over your head\" for firings, why would you accept it for layoffs? reply miltonlost 1 hour agorootparentBut whatabout being laid off, whatabout company bankruptcy, and whatabout becoming disabled? MY god, we're talking about at-will employment being a threat to a human's life insurance and salary, and you bring up NON at-will issues? Those are fundamentally different swords than an at-will employment one. Is your manager going to disable your body? How is this even remotely close to a manager being able to fire you for whatever? You're just ignoring the whole \"at-will\". I'm not talking about a \"sword\" of any possible negative thing happening to you. Why not bring up asteroids? Or another plague? Or just suddenly a REAL sword beheads me? THe \"sword\" is solely the at-will. Learn how metaphors work. reply gruez 1 hour agorootparentIt's the same sword: loss of income and healthcare. Semantic games aside, if the premise is that we shouldn't accept the risk of losing income/healthcare due to poor performance/internal politics, why would you accept losing income/healthcare due to layoffs (which also involve poor performance/internal politics)? It's fine to argue \"people should be shielded from the risk of losing their income/healthcare\", but you can't arbitrarily decide when it's fine to apply that principle. reply notTooFarGone 18 minutes agorootparentDying by lightning is like dying of cancer only a tad more unlikely. Your argument sucks at base level. miltonlost 1 hour agorootparentprevTHAT'S LITERALLY NOT THE PREMISE. AND IT'S NOT THE SAME SWORD. So much whataboutism and changing definitions to fit your needs. And also, you keep forgetting the more important thing: SOMEONE IS SWINGING THE SWORD AND WHY. > It's fine to argue \"people should be shielded from the risk of losing their income/healthcare\", but you can't arbitrarily decide when it's fine to apply that principle. You keep deleting key parts, like \"people should be shielded from the risk of losing their income/healthcare from manager's whims\". It's not arbitrary. reply gruez 1 hour agorootparent>You keep deleting key parts, like \"people should be shielded from the risk of losing their income/healthcare from manager's whims\". It's not arbitrary. And a layoff aren't caused by \"manager's whims\"? reply troupo 1 hour agorootparentprevLayoffs are negotiated separately, and in normal countries (with collective bargaining and healthcare) layoffs, while impactful, won't cripple your life reply gruez 1 hour agorootparent>layoffs, while impactful, won't cripple your life You lose your income in both cases, and I said I'd support severance/notice period for firings. I don't see how the two are materially different. reply troupo 2 minutes agorootparentSeverance is one of the many things union negotiate. Yet you keep insisting that somehow at-will employment with immediate termination is somehow good. renewiltord 2 hours agorootparentprevTo be honest, yeah. I want to reduce the fixed costs of job transfer so that I can be efficiently allocated in the economy because that usually means I can make a lot of money. But I can see how someone who is at a lower skill level would want to raise the friction for hiring - less job mobility is good for them. If someone wants to fire me, I hope they find it easy. reply miltonlost 2 hours agorootparent> If someone wants to fire me, I hope they find it easy. Wut? reply gruez 1 hour agorootparentThe point is that he wants to be employed at a company because the company values him, not because they're forced to keep him around. This shouldn't be an alien concept. In personal relationships, you want your friends/partner to stay around because they like you, not because they're forced to. In other business relationships, you want to get paid because you're delivering value, not because you'd be a pain to get rid of. reply sebzim4500 39 minutes agorootparentprevI would hate",
    "originSummary": [],
    "commentSummary": [
      "The New York Times Tech Guild is striking over unresolved contract issues, such as demands for a \"just cause\" termination provision, pay increases, pay equity, and remote work policies.- Negotiations have been ongoing for over two years without reaching a contract, and the strike is strategically timed during election week to increase pressure on the NYT.- The NYT has proposed a 2.5% annual wage increase and remote work flexibility, but the union is pushing for more significant commitments."
    ],
    "points": 390,
    "commentCount": 737,
    "retryCount": 0,
    "time": 1730722110
  },
  {
    "id": 42035319,
    "title": "Project Sid: Many-agent simulations toward AI civilization",
    "originLink": "https://github.com/altera-al/project-sid",
    "originBody": "projectSidVideo.mp4 Project Sid: Many-agent simulations toward AI civilization This repository contains our technical report: \"Project Sid: Many-agent simulations toward AI civilization\" Abstract AI agents have been evaluated in isolation or within small groups, where interactions remain limited in scope and complexity. Large-scale simulations involving many autonomous agents—reflecting the full spectrum of civilizational processes—have yet to be explored. Here, we demonstrate how 10 – 1000+ AI agents behave and progress within agent societies. We first introduce the PIANO (Parallel Information Aggregation via Neu- ral Orchestration) architecture, which enables agents to interact with humans and other agents in real-time while maintaining coherence across multiple output streams. We then evaluate agent performance in large- scale simulations using civilizational benchmarks inspired by human history. These simulations, set within a Minecraft environment, reveal that agents are capable of meaningful progress—autonomously developing specialized roles, adhering to and changing collective rules, and engaging in cultural and religious transmis- sion. These preliminary results show that agents can achieve significant milestones towards AI civilizations, opening new avenues for large-scale societal simulations, agentic organizational intelligence, and integrating AI into human civilizations. Paper The paper is available in two locations: arXiv: arXiv:2411.00114 PDF: 2024-10-31.pdf (in this repository) Citation If you find this work useful in your research, please consider citing: @article{altera2024sid, title = {Project Sid: Many-agent simulations toward AI civilization}, author = {Altera.AL}, year = {2024}, journal = {arXiv preprint arXiv:2411.00114} }",
    "commentLink": "https://news.ycombinator.com/item?id=42035319",
    "commentBody": "Project Sid: Many-agent simulations toward AI civilization (github.com/altera-al)375 points by talms 1 day agohidepastfavorite135 comments bob1029 17 hours agoI feel like there is some kind of information theory constraint which confounds our ability to extract higher order behavior from multiple instances of the same LLM. I spent quite a bit of time building a multi agent simulation last year and wound up at the same conclusion every day - this is all just a roundabout form of prompt engineering. Perhaps it is useful as a mental model, but you can flatten the whole thing to a few SQL tables and functions. Each \"agent\" is essentially a sql view that maps a string template forming the prompt. I don't think you need an actual 3D world, wall clock, etc. The LLM does not seem to be meaningfully enriched by having a fancy representation underly the prompt generation process. There is clearly no \"inner world\" in these LLMs, so trying to entertain them with a rich outer environment seems pointless. reply chefandy 3 hours agoparentTBH I haven't seen a single use of LLMs in games that wasn't better served by traditional algorithms beyond less repetitive NPC interactions. Maybe once they get good enough to create usable rigged and textured meshes with enough control to work in-game? They can't create a story on the fly that's reliable enough to be a compelling accompaniment to a coherent game plot. Maps and such don't seem to need anything beyond what current procedural algorithms provide, and they're still working with premade assets— the implementations I've seen can't even reliably place static meshes on the ground in believable positions. And as far as NPCs go— how far does that actually go? It's pure novelty worth far less than an hour of time. Let's even say you get a guided plot progression worded on the fly using an LLM, is that even as good, let alone better, than a dialog tree put together by a professional writer? This Civ idea at least seems like a new approach to some extent, but it still seems to conceptually not add much. Even if not, learning that it doesn't it's still worthwhile. But almost universally these ideas seem to be either buzzwordy solutions in search of problems, or a cheaper-than-people source of creativity with some serious quality tradeoffs and still require far too much developer wrangling to actually save money. I'm a tech artist so I'm a bit biased towards the value of human creativity, but also likely the primary demographic for LLM tools in game dev. I am, so far, not compelled. reply JohnMakin 2 hours agorootparentIt's been posted in-depth a few times across this forum to varying degrees by game developers - I was initially very excited about the implementation of LLM's in NPC interactions, until I read some of these posts. The gist of it was - the thing that makes a game fundamentally a game is its constraints. LLM-based NPC's fundamentally break these constraints in a way that is not testable or predictable by the developer and will inevitably destroy the gameplay experience (at least with current technology). reply chefandy 2 hours agorootparentYeah, same. Epic's Matrix demo implemented it and even without a plot, the interactions were so heavily guided that the distinction was pointless. So you can find out what that NPCs spous's name is and their favorite color. It's that neat? Sure it's neat. It's it going to make it a better game? Probably less than hiring another good writer to make NPC dialog. To be truly useful, I think they would have to be able to affect the world in meaningful ways that worked with the game plot, and again, when you clamp that down as much as you'd need to to still have a plot, you're looking at a fancy decision tree. reply MichaelZuo 2 hours agorootparentprevNobody will know for sure until a big budget game is actually released with a serious effort behind its NPCs. reply chefandy 2 hours agorootparentI can't see anything that Gen AI NPCs would add unless maybe you're talking about a Sims kind of game where the interactions are the point, and they don't have to adhere to a defined progression. Other than that, it's a chat bot. We already have chatbots and having them in the context of a video game doesn't seem like it would add anything revolutionary to that product. And would that fundamentally stand a chance of being as compelling to socially-focused role-playing gamers as online games? This is my field so I'm always looking for the angle that new tech will take. I still rank this lower than VR— with all of its problems— for potential to significantly change player interactions. Tooling to make games is a different story, but for actual use in games? I don't see it yet. reply mywittyname 2 hours agorootparentSandbox games are probably where they will shine. Imagine being able to play Minecraft, and tell a prompt to generate a world that resembles Tatooine, or a vampire-themed mansion. Expectations are lower with sandbox games, so there's no risk of breaking immersion like would happen with an LLM Elder Scrolls game when someone tricks in NPC into solving problems in python. Granted, I'm certain there will be copyrights issues associated with this capability, which is why I don't think it will be established game companies who first take a crack at this approach. reply chefandy 2 hours agorootparentThe problem is what it takes to implement that. I've seen companies currently trying to do exactly that, and their demos go like this \"ok, give me a prompt for the environment\" and if they're lucky, they can cherry pick some stuff the crowd says and if they're not, they sheepishly ask for a prompt that would visit indicate one of 5 environment types they've worked on and include several of the dozen premade textured meshes they've made, and in reality you've got a really really expensive procedural map with asset placement that's worse than if it was done using traditional semi-pre-baked approaches. A deceptive amount of work goes into the nitty gritty of making environments, and even with all of the incredible tooling that's around now, we are not even close to automating that. It's worth noting that my alma mater has game environment art degree programs. Unless you're making these things, you can't easily see how much finesse and artistic sensibility it takes to make beautiful compositions with complementary lighting and nice atmospheric progression. It's not just that nobody has really given it a go— it's really difficult. When you have tooling that uses AI controlled by an artist that knows these things, that's one thing. When they need to make great results every time so players keep coming back? That's a very different task. I've never met anyone that thought it was remotely currently feasible without lacking knowledge of generative AI, game development, or both. Automating the tools so a smaller workforce can make more worlds and more possibilities? We're already there— but it's a very large leap to remove the human creative and technical intermediaries. reply caetris2 17 hours agoparentprevYou've absolutely nailed it here, I agree. To make any progress at all at the tremendously difficult problem they are trying to solve, they need to be frank about just how far away they are from what it is they are marketing. I am whole-heartedly in support of commercial interests to drum of awareness and engagement by the authors. This is definitely a cool thing to be working on, however, what does make more sense is to frame the situation more honestly and attract folks to the desire of solving tremendously hard problems based on a level of expertise and awareness that truly moves the ball forward. What would be far more interesting would be for the folks involved to say all the ten thousand things that went wrong in their experiments and to lay out the common-sense conclusions from those findings (just like the one you shared, which is truly insightful and correct). We need to move past this industry and their enablers that continually try to win using the wrong methodology -- pushing away the most inventive and innovative people that are ripe and ready to make paradigm shifts in the AI field and industry. reply teaearlgraycold 16 hours agorootparentIt would however be very interesting to see these kinds of agents in a commercial video game. Yes they are shallow in their perception of the game world. But they’re a big step up from the status quo. reply dartos 3 hours agorootparenthttps://www.playsuckup.com/ It’s a game where you, a vampire, convince townsfolk that you’re not, so they let you in their house. The NPCs are run by LLMs. It’s pretty interesting. reply caetris2 16 hours agorootparentprevYes... Imagine a blog post at the same quality as this paper that framed their work and their pursuits in a way that genuinely got people excited about what could be around the corner, but with the context that frames exactly how far away they are from achieving what would be the ultimate vision. reply InDubioProRubio 12 hours agoparentprevMaybe we need gazelles and cheetahs - many gazelle-agents getting chased towards a goal, doing the brute force work- and the constraint cheetahs chase them, evaluate them and leave them alive (memory intact) as long as they come up with better and better solutions. Basically a evolutionary algo, running on top of many agents, running simultaneously on the same hardware? reply FeepingCreature 10 hours agorootparentDo you want stressed and panicking agents? Do you think they'll produce good output? In my prompting experience, I mostly do my best to give the AI way, way more slack than it thinks it has. reply InDubioProRubio 6 hours agorootparentNo, i want the hunters to zap the prey with tiredness. Basically electron holes, hunting for free electrons, annhilating state. Neurons have something similar, were they usually prevent endless excitement and hyperfixation, which is why a coder in flow is such a strange thing. reply nobrains 7 hours agorootparentprevI had the opposite thought. Opposite to evolution... What if we are a CREATED (i.e. instant created, not evolved) set of humans, and evolution and other backstories have been added so that the story of our history is more believable? Could it be that humanity represents a de novo (Latin for \"anew\") creation, bypassing the evolutionary process? Perhaps our perception of a gradual ascent from primitive origins is a carefully constructed narrative designed to enhance the credibility of our existence within a larger framework. What if we are like the Minecraft people in this simulation? reply wongarsu 4 hours agorootparentWe also can't rule out that Gaia or Odin made the world five minutes ago, and went to great lengths to make the world appear ancient. It certainly makes sense if you assume that the world is a simulation. But does it actually explain anything that isn't equally well explained by assuming the simulation simulated the last 13 billion years, and evolution really happened? reply j1elo 3 hours agorootparentAs long as we don't get to the point of being able to simulate a Universe ourselves, the odds are against us being in a simulation, it seems! :) https://www.youtube.com/shorts/EeqyGquTHK4 reply thrway01234 7 hours agorootparentprevI feel that is too complicated. The most simplest explanation is usually the right one. I think we live on an earth with actual history. Note that this does not necessarily mean that we are not living in a simulation, as history itself can be simulated. If we are indeed in a simulation, I feel there are too many details to be \"designed\" by a being. There are too many facts that are connected and unless they fix the \"bugs\" as they appear and reboot the simulation constantly, I don't think it is designed. Otherwise we would have noticed the glitches by now. If we are in a simulation, it has probably been generated by a computer following a set of rules. Maybe it ran a simplified version to evolve millions of possible earths, and then we are living in the version they selected for the final simulation? In that case all the facts would align and it could potentially be harder to noticed the glitches. I don't think we are living in a simulation because bugs are hard to avoid, even with close to \"infinite\" computing power. With great power comes great possibilities for bugs Perhaps we are in fact living in one of the simplified simulations and will be turned off at any second after I have finished this senten reply cen4 13 hours agoparentprevThat depends on giving them a goal/reward like increasing \"data quality\". I mean frogs don't use their brains much either inspite of the rich world around them they don't really explore. But chimps do. They can't sit quiet in a tree forever and that boils down to their Reward/Motivation Circuitry. They get pleasure out of explore. And if they didn't we wouldn't be here. reply logicchains 6 hours agoparentprev>I feel like there is some kind of information theory constraint which confounds our ability to extract higher order behavior from multiple instances of the same LLM. It's a matter of entropy; producing new behaviours requires exploration on the part of the models, which requires some randomness. LLMs have only a minimal amount of entropy introduced, via temperature in the sampler. reply fhe 14 hours agoparentprevso well put. exactly how I've been feeling and trying to verbalize. reply shkkmo 12 hours agoparentprev> I don't think you need an actual 3D world, wall clock, etc. The LLM does not seem to be meaningfully enriched by having a fancy representation underly the prompt generation process. I don't know how you expect agents to self organize social structures if they don't have a shared reality. I mean, you could write all the prompts yourself, but then that shared reality is just your imagination and you're just DMing for them. The point of the minecraft environment isn't to \"enrich\" the \"inner world\" of the agents and the goal isn't to \"entertain\" them. The point is to create a set of human understandable challenges in a shared environment so that we can measure behavior and performance of groups of agents in different configurations. I know we aren't supposed to bring this up, but did you read the article? Nothing of your comment addresses any of the findings or techniques used in this study. reply isoprophlex 22 hours agoprevNow these seem to be truly artificially intelligent agents. Memory, volition, autonomy, something like an OODA loop or whatever you want to call it, and a persistent environment. Very nice concept, and I'm positive the learnings can be applied to more mundane business problems, too. If only I could get management to understand that a bunch of prompts shitting into eachother isn't \"cutting-edge agentic AI\"... But then again their jobs probably depend on selling something that looks like real innovation happening to the C-levels... reply Carrok 22 hours agoparent> If only I could get management to understand that a bunch of prompts shitting into eachother isn't \"cutting-edge agentic AI\"... It's unclear to me how the linked project is different from what you described. Plenty of existing agents have \"memory\" and many other things you named. reply whatshisface 18 hours agoparentprevJust so you know, the English noun for things that have been learned is, \"lessons.\" reply globnomulous 5 hours agorootparentYup, and \"ask\" is a verb, God damn it, not a noun. But people in the tech world frequently use \"learnings\" instead of \"lessons,\" \"ask\" as a noun, \"like\" as filler, and \"downfall\" when they mean \"downside.\" Best to make your peace and move on with life. Just FYI: that second comma is incorrect. reply buffington 1 hour agorootparentprevI'm an old man and have heard \"learnings\" used to mean \"lessons\" for most of my life. I think \"learnings\" has advantages over \"lessons\" given that \"learnings\" has one meaning, while \"lessons\" can have more than one meaning. Whether it's correct or not, are we surprised it's used this way? Consider the word \"earnings\" and how similar its definition is to \"learnings.\" reply mindcrime 18 hours agorootparentprevAlso: \"learnings\". https://dictionary.cambridge.org/us/dictionary/english/learn... \"knowledge or a piece of information obtained by study or experience\" \"I am already incorporating some of these learnings into my work and getting better results.\" reply FeepingCreature 9 hours agorootparentThat example was added in 2022. https://web.archive.org/web/20190903044149/https://dictionar... You can clearly see that the prior use was very different. Cambridge Dictionary just documents that it's in fact used that way. One may still disagree on whether it should be. \"That's not English\" is usually prescriptive, rather than descriptive. And though English does not have a central authority, individuals are very much allowed to hold prescriptive beliefs - that is how language evolves. reply mindcrime 3 hours agorootparentThat example was added in 2022. I'm very sure that using \"learnings\" in a way that is roughly synonymous to \"lessons\" predates 2022 though. It may have only been added to that specific dictionary in 2022, but the usage is certainly older. \"That's not English\" is usually prescriptive, rather than descriptive. And though English does not have a central authority, individuals are very much allowed to hold prescriptive beliefs - that is how language evolves. Very true. :-) reply digging 2 hours agorootparentprev> individuals are very much allowed to hold prescriptive beliefs - that is how language evolves. I think, actually, it's the case that language evolves around those people who are too stubbornly prescriptivist. reply ytss 18 hours agorootparentprevI believe that “learnings” is also a word that could be applied in this context. It seems to me “learnings” would actually be less ambiguous than “lessons”. A lesson brings to mind a thing being taught, not just learned. reply bbor 18 hours agorootparentLet’s take this learning offline and circle back during the next sync, team reply globnomulous 5 hours agorootparentI just threw up. reply mindcrime 3 hours agorootparentprevs/team/fam/ :p reply jsemrau 21 hours agoparentprev>If only I could get management to understand that a bunch of prompts shitting into eachother isn't \"cutting-edge agentic AI\"... It should never be this way. Even with narrow AI, there needs to be a governance framework that helps measure the output and capture potential risks (hallucinations, wrong data / links, wrong summaries, etc) reply ElFitz 7 hours agorootparentDo you have any resources on that topic? I’d be interested. reply jsemrau 6 minutes agorootparentOn narrow AI or generative AI Risk Management? reply airstrike 22 hours agoprevI've thought about this a lot. I'm no philosopher or AI researcher, so I'm just spitballing... but if I were to try my hand at it, I think I'd like to start from \"principles\" and let systems evolve or at least be discoverable over time Principles would be things like self-preservation, food, shelter and procreating, communication and memory through a risk-reward calculation prism. Maybe establishing what is \"known\" vs what is \"unknown\" is a key component here too, but not in such a binary way. \"Memory\" can mean many things, but if you codify it as a function of some type of subject performing some type of action leading to some outcome with some ascribed \"risk-reward\" profile compared to the value obtained from empirical testing that spans from very negative to very positive, it seems both wide encompassing and generally useful, both to the individual and to the collective. From there you derive the need to connect with others, disputes over resources, the need to take risks, explore the unknown, share what we've learned, refine risk-rewards, etc. You can guide the civilization to discover certain technologies or inventions or locations we've defined ex ante as their godlike DM which is a bit like cheating because it puts their development \"on rails\" but also makes it more useful, interesting and relatable. It sounds computationally prohibitive, but the game doesn't need to play out in real time anyway... I just think that you can describe a lot of the human condition in terms of \"life\", \"liberty\", \"love/connection\" and \"greed\". Looking at the video in the repo, I don't like how this throws \"cultures\", \"memes\" and \"religion\" into the mix instead of letting them be an emergence from the need to communicate and share the belief systems that emerge from our collective memories. Because it seems like a distinction without a difference for the purposes of analyzing this. Also \"taxes are high!\" without the underlying \"I don't have enough resources to get by\" seems too much like a mechanical turk reply shagie 18 hours agoparentEvolve is another beast... but for the: \"I've thought about this a lot. I'm no philosopher or AI researcher, so I'm just spitballing... but if I were to try my hand at it, I think I'd like to start from \"principles\" and let systems evolve or at least be discoverable over time\" part, hunt up a copy of \"The Society of Mind\" by Minsky who was both and wrote about that idea. https://en.wikipedia.org/wiki/Society_of_Mind > The work, which first appeared in 1986, was the first comprehensive description of Minsky's \"society of mind\" theory, which he began developing in the early 1970s. It is composed of 270 self-contained essays which are divided into 30 general chapters. The book was also made into a CD-ROM version. > In the process of explaining the society of mind, Minsky introduces a wide range of ideas and concepts. He develops theories about how processes such as language, memory, and learning work, and also covers concepts such as consciousness, the sense of self, and free will; because of this, many view The Society of Mind as a work of philosophy. > The book was not written to prove anything specific about AI or cognitive science, and does not reference physical brain structures. Instead, it is a collection of ideas about how the mind and thinking work on the conceptual level. Its very approachable as a layperson in that part of the field of AI. reply bbor 4 hours agorootparentWow, you are maybe the first person I’ve seen cite Minsky on HN, which is surprising since he’s arguably the most influential AI researcher of all time, maybe short of Turing or Pearl. To add on to the endorsement: the cover of the book is downright gorgeous, in a retro-computing way https://d28hgpri8am2if.cloudfront.net/book_images/cvr9780671... reply shagie 3 hours agorootparentI've tangentially mentioned it before though I don't think directly (it has influenced my theory of humor). Mentions of it show up occasionally, though it seems to be more of a trickle than an avalanche of mention. Much more so back when AI alignment was more in the news. https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... Part of it, I suspect, is that it is a book book from the 80s and didn't really make any transition into digital. The people who are familiar with it are ones who bought computer books in the late 80s and early 90s. Similarly, \"A Pattern Language\" being a book from the time past that is accessible for a lay person in the field - though more in a tangental way. \"A Pattern Language: Towns, Buildings, Construction\" was the influence behind \"Design Patterns: Elements of Reusable Object-Oriented Software\" - though I believe the problem with Design Patterns is that it was seen more as a prescriptive rather than descriptive guide. Reading \"A Pattern Language\" can help understand what the GoF were trying to accomplish. ... And as an aside, and I also believe that it has some good advice for the setup of home offices and workplaces. As much as I love the convince of modern online book shopping and the amount of information available when searching, the \"browsing books\" in a book store for \"oh, this looks interesting\" and then buying it and reading it, I feel has largely been lost to the past decades. reply grugagag 21 hours agoparentprevMany of these projects are inch deep into intelligence and miles deep into the current technology. Some things will see tremendous benefits but as far as artificial intelligence we’re not there yet. Im thinking gaming will benefit a lot from these.. reply farias0 21 hours agorootparentYou mean we're not there in simulating an actual human brain? Sure. But we're seeing AI work like a human well enough to be useful, isn't that the point? reply grugagag 20 hours agorootparentNot if we’re pretending it is any inteligent. Other than that I’m all in for new utility to come out from it. But I do see a lot of tangents off technology with claims to something it is not. I have no problem of calling that out. Why do you mind? Just ignore me if Im holding your enthusiasm back, there’s plenty of sources to provide that for you. reply ekianjo 16 hours agorootparent> Not if we’re pretending it is any inteligent. We have been shifting the definition of what it means to be intelligent every 3 months following the advances of LLM... reply grugagag 10 hours agorootparentSo what? I’m not disputing that the immitation of intelligence is not good and it gets better and better every 3 months or so. But that doesn’t mean anything, even if it gets close to 99.9%. It is not real intlligence and it is quite limited in what it does. If LLMs solve logic or problems or chemistry problems it is solely not because it made a leap in understanding but because it was trained on a zillion examples. If you have a similar problem it will try to showhorn an answer without understanding where it fails. Am I saying this is useless? NO. What I’m saying is that the current approach to intelligence is missing some key ingredients. Im actually surprised so many get fooled by the hype and are ready to declare a winner. Human intelligence with it’s major flaws is still king of the hill. reply 8338550bff96 4 hours agorootparentHow do you distinguish between the real thing and a perfect simulation of the real thing? You seem to be engaged in faith-based reasoning at this point. If you were born in a sensory deprivation chamber you also would have no inner world, and you wouldn't have anything at all to say about solving chemistry problems. > Im actually surprised so many get fooled by the hype and are ready to declare a winner. Find me one person that says something like this. \"AGI is here!\" hype-lords exist only as a rhetorical device for the peanut gallery to ridicule. reply grugagag 4 hours agorootparentIt’s the approach that matters. When it gets to 99.9 percent it’s pretty good to be dangerous. At that point it would be hard to tell but not impossible. As soon as a new type problem comes out it will bork on you and need retraining. It’ll be a game of catch albeit an very inneficient one. Im sure we will find a more efficient method eventually but the point still stands, what we have isn’t it. I’ll shut up when I see leaps in reasoning without specific training on all variations possible of the problem sets. reply 8338550bff96 2 hours agorootparentI'll shut up when I see humans get 99.9% on anything. This seems an awful lot like non-meat brain prejudice where standards that humans do not live up to at all are imposed on other things in order to be worthy of consideration reply grugagag 2 hours agorootparentThat’s actually good. The more voices the better, that will make for a more vibrant discussion. reply mistermann 13 hours agorootparentprevThere's also this: https://en.m.wikipedia.org/wiki/Closed-world_assumption I wonder, once LLM's exceed Humans beyond some substantial threshold, will it crack the simulation allowing us to get back in the game again. reply grugagag 10 hours agorootparentCrack what simulation exactly? You can get back into the game right now, armed with these tools such as LLMs, ML and so on. reply jsemrau 21 hours agoparentprevMemory is really interesting. For example, if you play 100,000 rounds of 5x5 Tic Tac Toe. Do you really need to remember game 51247 or do you recognize and remember a winning pattern? In Reinforcement Learning you would based on each win revise the policy. How would that work for genAI? reply fragmede 19 hours agoparentprevSo a modernized version of Spore. reply airstrike 18 hours agorootparentBasically what we all wished Spore had been ;-) reply BlueTemplar 3 hours agoparentprevHuh, so the video actually works ? It just shows up «No video with supported format and MIME type found.» for me... Yeah, memes and genes are both memory, though at different timescales. reply airstrike 2 hours agorootparentIt works on some browsers. I'm normally on Firefox but had to dust off Safari to watch it. Crazy I still have to do this in 2024... reply caetris2 20 hours agoprevI've reviewed the paper and I'm confident this paper was fabricated over a collection of false claims. The claims made are not genuine and should not be taken at face value without peer review. The provided charts and graphics are sophisticated forgeries in many cases when reviewing and vetting their applicability to the claims made. It is currently not possible for any kind of LLM to do what is being proposed, while maybe the intentions are good with regard to commercial interests, I want to be clear: this paper seems indicate that election-related activities were coordinated by groups of AI agents in a simulation. These kinds of claims require substantial evidence and that was not provided. The prompts that are provided are not in any way connected to an applied usage of LLMs that are described. reply afro88 20 hours agoparent> this paper seems indicate that election-related activities were coordinated by groups of AI agents in a simulation I mean, that's surely within the training data of LLMs? The effectiveness etc of the election activities is likely very low. But I don't think it's outside the realms of possibility that the agents prompted each other into the latent spaces of the LLM to do with elections. reply caetris2 18 hours agorootparentLLMs are stateless and they do not remember the past (as in they don't have a database), making the training data a non-issue here. Therefore, the claims made here in this paper are not possible because the simulation would require each agent to have a memory context larger than any available LLM's context window. The claims made here by the original poster are patently false. The ideas here are not supported by any kind of validated understanding of the limitations of language models. I want to be clear -- the kind of AI that is being purported to be used in the paper is something that has been in video games for over 2 decades, which is akin to Starcraft or Diablo's NPCs. The key issue is that this is a intentional false claim that can certainly damage mainstream understanding of LLM safety and what is possible at the current state of the art. Agentic systems are not well-suited to achieve any of the things that are proposed in the paper, and Generative AI does not enable these kinds of advancements. reply Philpax 17 hours agorootparent> LLMs are stateless and they do not remember the past (as in they don't have a database), making the training data a non-issue here. That's not what they said. They said that a LLM knows what elections are, which suggests they could have the requisite knowledge to act one out. > Therefore, the claims made here in this paper are not possible because the simulation would require each agent to have a memory context larger than any available LLM's context window. The claims made here by the original poster are patently false. No, it doesn't. They aren't passing in all prior context at once: they are providing relevant subsets of memory as context. This is a common technique for language agents. > Agentic systems are not well-suited to achieve any of the things that are proposed in the paper, and Generative AI does not enable these kinds of advancements. This is not new ground. Much of the base social behaviour here comes from Generative Agents [0], which they cite. Much of the Minecraft related behaviour is inspired by Voyager [1], which they also cite. There isn't a fundamental breakthrough or innovation here that was patently impossible before, or that they are lying about: this combines prior work, iterates upon it, and scales it up. [0]: https://arxiv.org/abs/2304.03442 [1]: https://voyager.minedojo.org/ reply BlueTemplar 3 hours agorootparentVoyager's claims that it's a \"learning agent\" and that it \"make new discoveries consistently without human intervention\" are pretty much wrong considering how part of that system is using GPT's giant memory of ~~all~~ a lot of human knowledge (including how to play Minecraft, the most popular game ever made). In the same sense, LLMs \"not remembering the past\" is wrong (especially when part of a larger system). This seems like claiming humans / civilizations don't have a \"memory\" because you've redefined long term memory / repositories of knowledge like books to not be counted as \"memory\" ? Or am I missing something ?? reply afro88 17 hours agorootparentprevPerhaps I've made a big assumption / oversimplification about how this works. But.. > LLMs are stateless and they do not remember the past (as in they don't have a database), making the training data a non-issue here Yes. I never said they were stateful? The context given is the state. And training data is hugely important. Once upon a time there was a guy that claimed ChatGPT could simulate a command line shell. \"Simulate\" ended up being the wrong word. \"Largely hallucinate\" was a more accurate description. Shell commands and sessions were for sure part of the training data for ChatGPT, and that's how it could be prompted into largely hallucinating one. Same deal here with \"election activities\" I think. > Therefore, the claims made here in this paper are not possible because the simulation would require each agent to have a memory context larger than any available LLM's context window. The claims made here by the original poster are patently false. Well no, they can always trim the data put into the context. And then the agents would start \"forgetting\" things and the \"election activities\" would be pretty badly \"simulated\". Honestly, I think you're right that the paper is misleading people into thinking the system is doing way more than it actually is. But you make it sound like the whole thing is made up and impossible. The reality is somewhere in the middle. Yes they set up hundreds of agents, they give the agents data about the world, some memory of their interactions, and some system prompt to say what actions they can perform. This led to some interesting and surprising behaviours. No, this isn't intelligence, and isn't much more than a fancy representation of what is in the model weights. reply caetris2 17 hours agorootparentThese are extremely hard problems to solve and it is important for any claims to be validated at this early phase of generative AI. reply shkkmo 11 hours agoparentprevI don't think you understood the paper. The \"election\" experiment was a prefined scenario. There isn't any \"coordination\" of election activities. There were preassigned \"influencers\" using the conversation system built into PIANO. The sentiment was collected automatically by the simulation and the \"Election Manager\" was another predefined agent. Specically this part of the experiment was designed to look at how the presence or absence of specific modules in the PIANO framework would affect the behavior. reply Reubend 17 hours agoparentprevYeah, I haven't looked into this much so far but I am extremely skeptical of the claims being made here. For one agent to become a tax collector and another to challenge the tax regime without such behavior being hard coded would be extremely impressive. reply Philpax 16 hours agorootparentThey were assigned roles to examine the spread of information and behaviour. The agents pay tax into a chest, as decreed by the (dynamic) rules. There are agents assigned to the roles of pro- and anti-tax influencers; agents in proximity to these influencers would change their own behaviour appropriately, including voting for changes in the tax. So yes, they didn't take on these roles organically, but no, they weren't aiming to do so: they were examining behavioral influence and community dynamics with that particular experiment. I'd recommend skimming over the paper; it's a pretty quick read and they aren't making any truly outrageous claims IMO. reply Animats 16 hours agorootparentIt's not clear what actually happened. They're using Minecraft. Why is there not video? People have tried groups of AI agents inside virtual worlds before. Google has a project.[1] Stanford has a project.[2] Those have video. A real question is whether they are anthropomorphizing a dumb system too much. [1] https://deepmind.google/discover/blog/sima-generalist-ai-age... [2] https://arstechnica.com/information-technology/2023/04/surpr... reply bob88jg 11 hours agorootparentprevSo it's a plain vanilla ABM with lots of human crafted interaction logic? So they are making outrageous claims - since they are making it sound like it's all spontaneously arising from the interaction of LLMs... reply afro88 17 hours agorootparentprevYou can imagine a conversation with an LLM getting to that territory pretty quickly if you pretend to be an unfair tax collector. It sounds impressive on the surface, but in the end it's all LLMs talking to each other, and they'll enit whatever completions are likely given the context. reply hackathonguy 17 hours agoprevI'm curious if it might be possible that an AI \"civilization\", similar to the one proposed by Altera, could end up being a better paradigm for AGI than a single LLM, if a workable reward system for the entire civilization was put in place. Meaning, suppose this AI civilization was striving to maximize [scientific_output] or [code_quality] or any other eval, similar to how modern countries try to maximize GDP - would that provide better results than a single AI agent working towards that goal? reply bbor 17 hours agoparentYes, good sense for progress! This has been a central design component of most serious AI work since the ~90s, most notably popularized by Marvin Minsky’s The Society of Mind. Highly, highly recommend for anyone with an interest in the mind and AI — it’s a series of one-page essays on different aspects of the thesis, which is a fascinating, Martin-Luther-esque format. Of course this has been pushed to the side a bit in the rush towards shiny new pure-LLM approaches, but I think that’s more a function of a rapidly growing user base than of lost knowledge; the experts still keep this in mind, either in these terms or in terms of “Ensembles”. A great example is GPT-4, which AFAIU got its huge performance increase mostly through employing a “mixture of experts”, which is clearly a synonym for a society of agents or an ensemble of models. reply ValentinA23 6 hours agorootparentI don't think \"mixture of experts\" can be assimilated to a society of agents. It is just routing a prompt to the most performant model: the models do not communicate with each other, so how could they form a society ? reply wombatpm 16 hours agoparentprevPaperclip production? reply catlifeonmars 21 hours agoprevThis looks like it is a really cool toy. It does not strike me as particularly useful from a scientific research perspective. There does not appear to be much thought put into experimental design and really no clear objectives. Is the bar really this low for academic research these days? reply rollinDyno 19 hours agoparentKeep in mind anyone can publish on Arxiv and it's not at the top of HN on the merit of its research contributions. reply disconcision 19 hours agoparentprevit looks like a group consisted largely of ex-academics using aspects of the academic form but they stop short of framing it as a research paper as-such. they call it a technical report, where it's generally more okay to be like 'here's a thing that we did', along with detailed reporting on the thing, without necessarily having definite research questions. this one does seem to be pretty diffuse though. the sections on Specialization and Cultural Transmission were both interesting, but lacked precise experimental design details to the point where i wish they had just focused on one or the other. one disappointment for me was the lack of focus on external metrics in the multi-agent case. their single-agent benchmark focusses on an external metric (time to block type), but all the multi-agent analyses seems to be internal measures (role specialization, meme spread) without looking at (AFAICT?) whether or not the collective multi-agent systems could achieve more than the single agents on some measure of economic productivity/complexity. this is clearly related to the specialization section but without consideration of the whether said emergent role division had economic consequences/antecedents it makes me wonder to what degree the whole thing is a pantomime. reply a_bonobo 19 hours agorootparentwouldn't surprise me if in a few weeks/months we see this repo packaged up as a for-sale product for the games industry reply mistermann 18 hours agoparentprevThe scientific method has utility, but it's not a pre-requisite for utility. Some people prefer speed and the uncertainty that comes with it. reply abecedarius 4 hours agoprev\"Non Serviam\", Lem 1971: > Professor Dobb's book is devoted to personetics, which the Finnish philosopher Eino Kaikki has called 'the cruelest science man ever created'. . . We are speaking of a discipline, after all, which, with only a small amount of exaggeration, for emphasis, has been called 'experimental theogony'. . . Nine years ago identity schemata were being developed—primitive cores of the 'linear' type—but even that generation of computers, today of historical value only, could not yet provide a field for the true creation of personoids. > The theoretical possibility of creating sentience was divined some time ago, by Norbert Wiener, as certain passages of his last book, God and Golem, bear witness. Granted, he alluded to it in that half-facetious manner typical of him, but underlying the facetiousness were fairly grim premonitions. Wiener, however, could not have foreseen the turn that things would take twenty years later. The worst came about—in the words of Sir Donald Acker—when at MIT \"the inputs were shorted to the outputs\". reply NoboruWataya 22 hours agoprevThis seems very cool - I am sceptical of the supposed benefits for \"civilization\" but it could at least make for some very interesting sim games. (So maybe it will be good for Civilization moreso than civilization.) reply aithrowawaycomm 19 hours agoparentI think the Firaxis Civilization needs a cheap AlphaZero AI rather than an LLM: there are too many dumb footguns in Civ to economically hard-code a good strategic AI, yet solving the problem by making the enemies cheat is plain frustrating. It would be interesting to let an ANN play against a \"classical\" AI until it consistently beats each difficulty level, building a hierarchy. I am sure someone has already looked into this but I couldn't find any sources. I am a bit skeptical about how computationally expensive a very crappy Civ ANN would be to run at inference time, though I actually have no idea how that scales - it hardly needs to be a grandmaster, but the distribution of dumb mistakes has a long tail. Also, the DeepMind Starcraft 2 AI is different from AlphaZero since Starcraft is not a perfect information game. The AI requires a database of human games to \"get off the ground\"; otherwise it would just get crushed over and over in the early game, having no idea what the opponent is doing. It's hard to get that training data with a brand new game. Likewise Civ has always been a bit more focused on artistic expression than other 4x strategy games; maybe having to retrain an AI for every new Wonder is just too much of a burden. reply BlueTemplar 2 hours agorootparentGalactic Civilizations 2 (also, 1,3,4 ??) in the same genre is well-known for its AI, good even without handicaps or cheats. This includes trading negotiations BTW. (At least good compared to what other 4X have, and your average human player - not the top players that are the ones that tend to discuss the game online in the first place.) EDIT : I suspect that it's not unrelated that GalCiv2 is kind of... boring as 4X go - as a result of a good AI having been a base requirement ? Speaking of StarCraft AI... (for SC1, not 2, and predating AlphaZero by many years) : https://arstechnica.com/gaming/2011/01/skynet-meets-the-swar... reply loudmax 5 hours agoparentprevI really dig namechecking Sid Meier for the name of the project. I'm also skeptical that this project actually works as presented, but building a Civilization game off of a Minecraft engine is a deeply interesting idea. reply caseyy 22 hours agoparentprevIndeed sounds better for Civilization than civilization. This could be quite exciting for gaming. reply dmix 22 hours agorootparentGTA6 suddenly needs another 2 years :) reply foota 18 hours agoparentprevI'm somewhat amazed that companies releasing strategy games aren't using AI to test out different cards and what not to find broken things before release (looking at you, Hearthstone) reply bbor 21 hours agoparentprevYeah, I was dissapointed (and thrilled, from a p(doom) perspective) to see it implemented in Minecraft instead of Civilization VI, Humankind, or any of the main Paradox grand strategies (namely Stellaris, Victoria, Crusader Kings, and Europa Universalis). To say the least, the stakes are higher and more realistic than \"lets plan a feast\" \"ok, I'll gather some wood!\" To be fair, they might tackle this in the paper -- this is a preprint of a preprint, somehow... reply BlueTemplar 1 hour agorootparentI suspect that Minecraft might have the open source possibilities (or at least programming interfaces ?) that the other games you listed lack ? For Civilizations, the more recent they are, the more closed off they tend to be : Civ 1 and/or 2 have basically been remade from scratch as open source, Civ 4 has most of the game open sourced in the two tiers of C++ and Python... but AFAIK Civ 5 (and also 6 ?) were large regressions in modding capabilities compared to 4 ? reply j_bum 20 hours agorootparentprevRather, a concept of a preprint reply jlaneve 23 hours agoprevHere's their blog post announcement too: https://digitalhumanity.substack.com/p/project-sid-many-agen... reply aithrowawaycomm 22 hours agoprevReading the paper, this seems like putting the cart before the horse: the agents individually are not actually capable of playing Minecraft and cannot successfully perform the tasks they've assigned or volunteered for, so in some sense the authors are having dogs wear human clothes and declaring it's a human-like civilization. Further, crucial things are essentially hard-coded: what types of societies are available and (I believe) the names of the roles. I am not exactly sure what the social organization is supposed to imply: the strongest claim you could make is that the agent framework could work for video game NPCs because the agents stick to their roles and factions. The claim that agents \"can use legal structures\" strikes me as especially specious, since \"use the legal structure\" is hard-wired into the various agents' behavior. Trying to extend all this to actual human society seems ridiculous, and it does not help that the authors blithely ignore sociology and anthropology. There are some other highly specious claims: - I said \"I believe\" the names of the roles are hard-coded, but unless I missed something the information is unacceptably vague. I don't see anything in the agent prompts that would make them create new roles, or assign themselves to roles at all. Again I might be missing something, but the more I read the more confused I get. - claiming that the agents formed long-term social relationships over the course of 12 Minecraft days, but that's only four real hours and the agents experience real time: the length of a Minecraft day is immaterial! I think \"form long-term social relationships\" and \"use legal structures\" aren't merely immodest, they're dishonest. - the meme / religious transmission stuff totally ignores training data contamination with GPT-4. The summarized meme clearly indicates awareness of the real-world Pastafarian meme, so it is simply wrong to conclude that this meme is being \"transmitted,\" when it is far more likely that it was evoked in an agent that already knew the meme. Why not run this experiment with a truly novel fake religion? Some of the meme examples do seem novel, like \"oak log crafting syndrome,\" but others like \"meditation circle\" or \"vintage fashion and retro projects\" have nothing to do with Minecraft and are almost certainly GPT-4 hallucinations. In general using GPT-4 for this seems like a terrible mistake (if you are interested in doing honest research). reply jsemrau 21 hours agoparentYou are on the right track in my opinion. The key is to encode the interface between the game and the agent so that the agent can make a straightforward choice. For example, by giving the agent the state of a nxn board as the world model, and then a finite set of choices, an agent is capable of playing the game robustly and explaining the decision to the game master. This gives the illusion that the agent reasons. I guess my point is that it's an encoding problem of the world model to break it down into a simple choice. [1] https://jdsemrau.substack.com/p/evaluating-consciousness-and... reply aleph_minus_one 22 hours agoprevThe video cannot be played in Mozilla Firefox (Windows); the browser claims that the file is damaged. reply iamthejuan 18 hours agoprevSimulate selfishness because that is the main reason why there are problems in the world. reply ramraj07 18 hours agoparentSelfishness is the main reason life exists in the universe. Literally the only requirement for a lump of stuff to become alive is to become selfish. So you’re semi right that these LLMs can never become truly sentient unless they actually become selfish. While selfishness is a basic requirement, some stupidity (imo) is also important for intelligent life. If you as an AI agent don’t have some level of stupidity, you’ll instantly see that there’s no point to doing anything and just switch yourself off. reply bbor 17 hours agorootparentThe first point is absolutely correct, and (apologies in advance…) was a large driver of Nietzsche’s philosophy of evolution, most explicitly covered in The Gay Science. Not only “selfishness”, but the wider idea of particularized standpoints, each of which may stand in contradiction to the direct needs of the society/species in the moment. This is a large part of what he meant by his notoriously dumb-sounding quotes like “everything is permitted”; morality isn’t relative/nonexistent, it’s just evolving in a way that relies on immorality as a foil. For the second part, I think that’s a good exposition of why “stupidity” and “intelligence” aren’t scientifically useful terms. I don’t think it’s necessarily “stupid” to prefer the continuation of yourself/your species, even if it doesn’t stand up to certain kinds of standpoint-specific intellectual inquiry. There’s lots of standpoints (dare I say most human ones) where life is preferable to non-life. Regardless, my daily thesis is that LLMs are the first real Intuitive Algorithms, and thus the solution to the Frame Problem. In a certain colloquial sense, I’d say they’re absolutely already “stupid”, and this is where they draw their utility from. This is just a more general rephrasing of the common refrain that we’ve hopefully all learned by now: hallucinations are not a bug in LLMs, they’re a feature. ETA: I, again, hate that I’m somehow this person now, but here’s a fantastic 2 hour YouTube video on the Nietzsche references above: https://youtu.be/fdtf53oEtWU?si=_bmgk9zycNBn2oCa reply toisanji 17 hours agoprevHere is our version we did about a year ago: https://arxiv.org/abs/2401.10910 reply Tiberium 22 hours agoprevHonestly I'm really excited about this. I've always dreamed of full blown sandbox games with extremely advanced NPCs (which the current LLMs can already kinda emulate), but on the bigger scale. In just a few decades this will finally be made into proper games. I can't wait. reply drusepth 12 hours agoparent> I've always dreamed of full blown sandbox games with extremely advanced NPCs (which the current LLMs can already kinda emulate) The future of gaming is going to get weird fast with all this new tech, and there are a lot of new mechanics emerging that just weren't possible before LLMs, generative AI, etc. At our game studio we're already building medium-scale sandbox games where NPCs form memories, opinions, problems (that translate to quests), and have a continuous \"internal monologue\" that uses all of this context plus sensory input from their place in a 3D world to constantly decide what actions they should be performing in the game world. A player can decide to chat with an NPC about their time at a lake nearby and then see that NPC deciding to go visit the lake the next day. A paper last year (\"Generative Agents: Interactive Simulacra of Human Behavior\", [0]) is a really good sneak-peek into the kind of evolving sandboxes LLMs (with memory and decisionmaking) enable. There's a lot of cool stuff that happens in that \"game\", but one anecdote I always think back to is this: in a conversation between two NPCs, one happens to mention they have a birthday coming up to the other; and that other NPC then goes around town talking to other NPCs about a birthday party, and _those_ NPCs mention the party to other NPCs, and so on until the party happened and most of the NPCs in town arrived on time. None of it was scripted, but you very quickly start to see emergent behavior from these sorts of \"flocks\" of agents as soon as you add persistence and decision-making. And there are other interesting layers games can add for even more kinds of emergent behavior; that's what we're exploring at our studio [1], and I've seen lots of other studios pop up this last year to try their hand at it too. I'm optimistic and excited about the future of gaming (or, at least some new genres). It should be fun. :) [0] https://arxiv.org/abs/2304.03442 [1] https://www.chromagolem.com/games reply jsemrau 21 hours agoparentprevI think it can be quite interesting especially if you consider different character types (in Anthropic lingo this \"personality\"). The only problem right now is that using a proprietary LLM is incredibly expensive. Therefore having a local LLM might be the best option. Unfortunately, these are still not on the same level as their larger brethren. [1] https://jdsemrau.substack.com/p/evaluating-consciousness-and... reply ted_bunny 21 hours agoparentprevGame designers have barely scratched the surface of NPC modeling even as it is. Rimworld is considered deep but it's nothing close to it. reply ileonichwiesz 3 hours agorootparentRimworld is heavily inspired by Dwarf Fortress, so if you’re looking for more complex examples you don’t have to look far. DF is pretty granular with the physical and mental states of its characters - to the point that a character might lose a specific toe or get depressed about their situation - but of course it’s still a video game, not a scientific simulation of an AI society. reply aleksiy123 19 hours agorootparentprevYeah I think there is a lot of potential here. Especially in city building games etc. reply aleph_minus_one 22 hours agoparentprev> Honestly I'm really excited about this. I've always dreamed of full blown sandbox games with extremely advanced NPCs (which the current LLMs can already kinda emulate), but on the bigger scale. I don't believe that you want this. Even really good players don't have a chance against super-advanced NPCs (think how chess grandmasters have barely any chance against modern chess programs running on a fast computer). You will rather get crushed. What you likely want is NPC that \"behave more human-like (or animal-like)\" - whatever this means. reply Tiberium 22 hours agorootparentOh, I should've clarified - I don't want to fight against them, I just want to watch and sometimes interfere to see how the agents react ;) A god game like WorldBox/Galimulator, if you will. Or observer mode in tons of games like almost all Paradox ones. reply com2kid 21 hours agorootparentI'm working on something similar, https://www.generativestorytelling.ai/tinyllmtown/index.html a small town where all NPCs are simulated using a small LLM. They react to everything the hero does, which means no more killing a dragon and having no one even mention it. Once I release it, I'll have it simulate 4 hours every 2 hours or so of real time, and visitors can vote on what quest the hero undertakes next. The simulation is simpler, I am aiming to keep everything to a size that can run on a local GPU with a small model. Right now you can just watch the NPCs try to figure out love triangles, hide their drinking problems, complain about carrots, and celebrate when the hero saves the town yet again. reply aspenmayer 16 hours agorootparentThis description reminded me of Dwarf Fortress. You might look into how the AI in it works to see if it gives you any ideas about how emergent behaviors can interact? reply int_19h 16 hours agorootparentprevWhat I want is for someone to remake this, but with modern AI and a vast interactive environment typical of a modern open world game: https://en.wikipedia.org/wiki/Majesty:_The_Fantasy_Kingdom_S... reply aleph_minus_one 22 hours agorootparentprev> I just want to watch and sometimes interfere to see how the agents react ;) Even there, I am not sure whether if the AI bcomes too advanced, it will be of interest for many players (you might of course nevertheless be interested): Here, the relevant comparison is to watching (the past) games of AlphaGo against Go grandmasters, where even the highly qualified commentators had insane difficulties explaining AlphaGo's moves because many of the moves were so different from the strategy of any Go game before. The commentors could just accept and grasp that these highly advanced moves did crush the Go grandmaster opponents. In my opinion, the \"typical\" sandbox game player wants to watch something that he still can \"somewhat\" grasp. reply kgeist 21 hours agorootparentprev>Even really good players don't have a chance against super-advanced NPCs I guess you can make them dumber by randomly switching to hardcoded behavioral trees (without modern AI) once in a while so that they made mistakes (while feeling pretty intelligent overall), and the player would then have a chance to outsmart them. reply gregjw 1 hour agoprevFascinating reply flashman 18 hours agoprevI think their top-down approach is a problem. What they call human civilization wasn't and isn't centrally-planned, and its goals and ideologies are neither universal nor implicit. The integration of software agents (I refuse to call them \"AI\") into civilization won't occur in a de facto cooperative framework where such agents are permitted to fraternize and self-modify. Perhaps that will happen in walled gardens where general-purpose automatons can collectively 'plan' activities to maximize efficiency, but in our broader human world, any such collaboration is going to have to occur from the bottom-up and for the initial benefit of the agents' owners. This kind of research needs to take place in an adversarial environment. There might be something interesting to learn from studying the (lack of?) emergence of collaboration there. reply zombiwoof 21 hours agoprevAgentic is an annoying word. reply dangoodmanUT 5 hours agoprevi think this is a github so hn is more likely to click on it reply BlueTemplar 3 hours agoprevSigh, why calling it this way when it's more about a Minecraft-like game than a Civilization-like game ?? Also, mandatory quote from another ~~Sid Meier's~~ Brian Reynolds' game : https://youtu.be/iGh9G3tPNbY?list=PLyR1OIuULeP4qz0a9tQxgsKNF... reply bitwize 20 hours agoprevI'm reminded of Dwarf Fortress, which simulates thousands of years of dwarf world time, the changing landscapes and the rise and fall and rise and fall of dwarf kingdoms, then drops seven player-controlled dwarves on the map and tells the player \"have fun!\" It'd be a useful toy model perhaps for identifying areas of investigation to see if it can predict behavior of real civilizations, but I'm not seeing any AI breakthroughs here. Maybe when Project Sid 6.7 comes out... reply aspenmayer 13 hours agoparent> Maybe when Project Sid 6.7 comes out... In case anyone is wondering, this is a reference to the movie Virtuosity (1995). I thought it was a few years later, considering the content. It’s a good watch if you like 90s cyberpunk movies. https://www.imdb.com/title/tt0114857/ https://en.wikipedia.org/wiki/Virtuosity reply luxuryballs 21 hours agoprevJust yesterday I was wondering how the Midjourney equivalent world gen mod for Minecraft might be coming along. Imagine prompting the terrain gen?? That could be pretty mind blowing. Describe the trees hills vines, tree colors/patterns, castles, towns, details of all buildings and other features. And have it generate as high quality in Minecraft as image gen can be in stable diffusion? reply m0llusk 21 hours agoprevInteresting context, but highlights all the problems of machine learning models: the lack of reason and abstraction and so on. Hard to say yet how much of an issue this might be, but the medium will almost certainly reveal something about our potential options for social organization. reply wslh 22 hours agoprevI cannot open the PDF, is it available somewhere else? reply echelon 22 hours agoprevAll of their domains and branding are .aL I had no idea .aL was even a domain name. That's wild. I wonder how many of those are going to take off. reply semanticc 21 hours agoparent.al is just the TLD for Albania, similarly as .ai is for Anguilla. No idea why anyone would choose the former. reply airstrike 17 hours agorootparentAgreed, it seems tangenti.al at best reply arisAlexis 11 hours agoprevDoesn't this bring us closer to Nick Bostrom's 3 point argument in his paper about the simulation theory? reply sweetkimchi 20 hours agoprevinteresting reply nachoab 21 hours agoprevReally interesting but curious how civilization here holds up without deeper human-like complexity, feels like it might lean more toward scripted behaviors than real societies reply userbinator 21 hours agoparentfeels like it might lean more toward scripted behaviors than real societies Guess what's happening with \"real societies\" now... There's a reason \"NPC\" is used as an insult. reply gmuslera 21 hours agoprev [–] They probably will fall fast into tragedy of the commons kind of situations. We developed most of our civilization while there was enough room for growing and big decisions were centralized, and started to get into bad troubles when things became global enough. With AIs some of those \"protections\" may not be there. And hardcoding strategies to avoid this may already put a limit on what we are simulating. reply ilbeeper 19 hours agoparent> We developed most of our civilization while there was enough room for growing and big decisions were centralized, and started to get into bad troubles when things became global enough. Citation needed. But even if I will get on board with you on that, wouldn't it be to start developing for global scale right from the start, instead of starting in small local islands and then try to rework that into global ecosystem? reply gmuslera 18 hours agorootparentThe problem with emulations is human patience. If you don't need/have human interaction this may run pretty fast. And at the end, what matter is how sustainable it is in the long run. reply interstice 21 hours agoparentprev [–] Does this mean that individual complexity is a natural enemy of group cohesiveness? Or is individual 'selfishness' more a product of evolutionary background. On our planet we don't have ant colony dynamics at the physical scale of high intelligence (that I know of), but there are very physical limitations to things like food sources. Virtual simulations don't have the same limitations, so the priors may be quite different. reply gmuslera 20 hours agorootparent [–] Taking the \"best\" course of action from your own point of view could not be so good from a more broad perspective. We might have evolved some small group collaboration approaches that in the long run plays better, but in large groups that doesn't go that well. And for AIs trying to optimize something without some big picture vision, things may go wrong faster. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Project Sid investigates large-scale simulations with 10-1000+ AI agents to explore AI civilization, utilizing the PIANO architecture for real-time interaction.- The research demonstrates AI agents developing roles, rules, and cultural transmission within a Minecraft environment, highlighting advancements in societal simulations and AI integration.- The study is documented in a paper available on arXiv, offering new insights into AI civilization research."
    ],
    "commentSummary": [
      "Project Sid investigates the use of many-agent simulations in AI, particularly within the context of Minecraft, to explore social dynamics and AI civilization.",
      "Critics argue that the project may be more about advanced prompt engineering rather than groundbreaking AI, questioning the necessity of large language models (LLMs) in gaming when traditional algorithms might suffice.",
      "The project highlights both the potential and current limitations of AI in gaming, sparking discussions on AI's role in creativity, the challenges of simulating intelligence, and the philosophical implications of AI-driven societies."
    ],
    "points": 372,
    "commentCount": 134,
    "retryCount": 0,
    "time": 1730660959
  },
  {
    "id": 42036995,
    "title": "Hertz-dev, the first open-source base model for conversational audio",
    "originLink": "https://si.inc/hertz-dev/",
    "originBody": "For the last few months, we at Standard Intelligence have been researching scalable cross-modality learning. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model, hertz-dev, with a total of 8.5 billion parameters. hertz-codec: a convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. The codec at 1kbps outperforms Soundstream and Encodec at 6kbps and is on par with DAC at 8kbps in subjective evaluations, while having lower tokens per second than any popular tokenizer, critical for language modeling. The codec has 5 million encoder parameters and 95 million decoder parameters. hertz-vae: a 1.8 billion parameter transformer decoder which acts as a learned prior for the audio VAE. The model uses a context of 8192 sampled latent representations (17 minutes) and predicts the next encoded audio frame as a mixture of gaussians. 15 bits of quantized information from the next token act as semantic scaffolding to steer the generation in a streamable manner. hertz-dev: a 6.6 billion parameter transformer stack. The primary checkpoint is partially initialized from the weights of a pre-trained language model and then trained for a single epoch on 500B tokens with a 2048-token (4 minute) context length. We're also publishing an ablation of the language model initialization which is similarly trained on 500B tokens. Hertz-dev is the first publicly released audio base model of its kind. Base models are uniquely valuable as a research product because they accurately model the distribution of the data that they were trained on, as opposed to models that have had substantial RL tuning done to collapse their generation distributions. This makes base models the best starting point to fine-tune for a large number of different tasks. Hertz-dev has a theoretical latency of 65ms and a real-world average latency of 120ms on a RTX 4090. This is about 2x lower latency than any public model in the world—a prerequisite for a model that can interact with you in human-like ways instead of what feels like a delayed, choppy phone call. We're currently training a larger, more advanced version of Hertz, which will use a scaled base model recipe and RL tuning to substantially improve the raw capabilities and final coherence of the model. Hertz-dev is a glimpse at the future of real-time voice interaction, and is the easiest conversational audio model in the world for researchers to fine-tune and build on top of. Sample Generations To demonstrate the audio modeling capabilities of hertz-dev, we sample both one-channel and two-channel generations as well as a live conversation between the model and a human. One-channel Two-channel Interactive 9 seconds of prompt included. At SI, we're doing fundamental research with the goal of building aligned general intelligence, and we view this as just the first step on that journey. We're starting in a unique time where we can rely on a tiny team to do massively outsized work because of how hard we can build and leverage tools to be hundreds of times faster internally. We're currently a team of 4 in San Francisco. If your life goal is to build AGI in a way that benefits all humanity, we probably want to hire you—reach out at join@si.inc and we'll aim to get back to you within a few hours. If you're interested in investing, please reach out at invest@si.inc.",
    "commentLink": "https://news.ycombinator.com/item?id=42036995",
    "commentBody": "Hertz-dev, the first open-source base model for conversational audio (si.inc)258 points by mnk47 19 hours agohidepastfavorite48 comments reissbaker 12 hours agoThis is really cool. FWIW, existing open-source TTS engines are really bad in comparison to what you have here: I know this is voice-to-voice, but I think there'd be a lot of appetite to get this to also be multimodal and accept text (essentially making it a really good TTS model, in addition to a great voice-to-voice model). I suppose someone could hack their way around the problem by finetuning it to essentially replay Piper (or whatever) output, only with more natural prosody and intonation. And then have the text LLM pipe to Piper, and Piper pipe to Hertz-dev. But it would be pretty useful to have it accept text natively! reply netdevnet 9 hours agoparentThey are a team of 4. At that size, it's better for them to be focused on one thing than stretched out reply reissbaker 9 hours agorootparentEh, that depends. A small model that's voice-and-text is probably more useful to most people than scaling up a voice-only model: the large voice-only model will have to compete on intelligence with e.g. Qwen and Llama, since it can't be used in conjunction with them; whereas a small voice+text model can be used as a cheap frontend hiding a larger, smarter, but more expensive text-only model behind it. This is an 8b model: running it is nearly free, it can fit on a 4090 with room to spare. On the one hand, a small team focused on voice-to-voice could probably do a lot better at voice-to-voice than a small team focused on voice-to-voice+text. But a small team focused on making the most useful model would probably do better at that goal by focusing on voice+text rather than voice-only. reply netdevnet 3 hours agorootparentTheir goal is not working on what's most useful for most people though. That's the domain of the big AI players. They are small and so specialising works best as that's where they can have an edge as a company. At the end of the day, the released product needs to be good and needs to be done in a reasonable amount of time. I highly doubt they can do a generic model as well as a more specialised one. But if you think you know better than them, you could try to contact them even though it looks they are crazy laser focused (their public email addresses are either for investors or employee candidates). reply PenisBanana 9 hours agoparentprevYes, yes. This. Piper is already pretty good . . . and then this. It may not be _them_ doing it, though. reply mazoza 1 hour agoprevCan one of the authors explain what this actually means from the post? hertz-vae: a 1.8 billion parameter transformer decoder which acts as a learned prior for the audio VAE. The model uses a context of 8192 sampled latent representations (17 minutes) and predicts the next encoded audio frame as a mixture of gaussians. 15 bits of quantized information from the next token act as semantic scaffolding to steer the generation in a streamable manner. reply blixt 11 hours agoprevThey say Hertz is first of its kind but Moshi is another duplex audio model from earlier this year that seems to perform similarly (and it runs on a MacBook): https://github.com/kyutai-labs/moshi reply a2128 10 hours agoparentMoshi never released the base model, only two conversationally finetuned models. They also never released training code except for the codec. Though I don't see any training code for Hertz either, just 3 inference notebooks, and model code full of no_grad. No paper either to help me understand how this was trained and what the architecture is like. So I'm not too sure about researcher-friendliness unless I'm missing something. reply nicholas-cc 10 hours agorootparentWe're working on a HuggingFace release that will help with finetuning. We'd like to do a paper, after a larger release - we're a team of 4. reply netdevnet 9 hours agorootparentVery impressive for just 4 people. What's the team background and how long have you been working on this? reply programjames 1 hour agorootparentI'm not part of their team, but lived with them for a couple months. They've been working on it for ~5 months, and their background is 16-20 year olds who are too smart for university. reply unit149 9 hours agorootparentprevFor a rag-tag group of transcendental audiophiles operating electronic circuitry, it ionizes and atomizes well. reply underlines 4 hours agoparentprev- LLaMA-Omni https://github.com/ictnlp/LLaMA-Omni a speech-language model built on Llama-3.1-8B-Instruct for simultaneous generation of text and speech - moshi https://github.com/kyutai-labs/moshi speech-text foundation model using Mimi, a SOTA streaming neural audio codec - Mini-Omni https://github.com/gpt-omni/mini-omni multimodal LLM based on Qwen2 offering speech input and output - Ichigo https://github.com/homebrewltd/ichigo open research project extending a text-based LLM to have native listening ability, using an early fusion technique reply nicholas-cc 11 hours agoparentprevMoshi is a good model to build chat applications on, this is designed to be more of a proper base model with all the quirkiness, naturalness, and researcher-friendliness of base modeling. reply wwwlouishinofun 14 hours agoprevTesla’s approach to pure vision-based autonomous driving—temporarily setting aside lidar and other sensors—seems designed to make this technology more accessible and scalable. By focusing on a vision-only model, they can accelerate adoption and gather large datasets for quicker iterations. Once the vision-based system reaches a mature stage, I imagine Tesla might reintegrate additional sensor data, like lidar or radar, to refine their autonomous driving suite, making it even more robust and closer to perfection. Additionally, I’ve been exploring an idea about voice interaction systems. Currently, most voice interactions are processed by converting voice input into text, generating a text-based response, and then turning this text back into audio. But what if we could train the system to respond directly in voice, without involving text at all? If developed to maturity, this model could produce responses that feel more natural and spontaneous, possibly diverging from traditional text-to-speech outputs. Natural speech has unique syntax and rhythm, not to mention dialect and tone variations, which could make a purely voice-trained system fascinating and more human-like. Could you let me know if your current voice interaction model follows the standard speech-to-text-to-speech process, or if there is exploration in voice-to-voice processing? reply nicholas-cc 14 hours agoparentI'm one of the devs. Our model is fully voice-to-voice, no text was involved in the making of hertz-dev for exactly this reason. reply oidar 14 hours agorootparentSo essentially this is voice input to voice output? Can you change gender/age/accent? Does it track prosodic information? I've been waiting for something like this. reply nicholas-cc 13 hours agorootparentHertz-dev is a base model, meaning it's just trained to predict the next token of audio. If your prompt is an old male voice with a British accent, the model will most likely continue speaking in an old male voice with a British accent. Being a base model, hertz-dev is easily finetunable for specific tasks - it would be a simple change to add manual configurations for the gender/age/accent. reply hunter2_ 12 hours agorootparentI assume this mirroring is due to symmetry being more typical than not among the training data, and if instead trained with contrived diversity (e.g., males only conversing with females) then the output of the base model would follow suit without pulling any levers? It's interesting to think about what complete diversity (i.e., no tendencies toward homogeneous conversation partners whatsoever among training data) would yield, given that it's trying to deliver whatever is most probable. reply modeless 11 hours agorootparentprevI'm interested to hear more detail about approaches to adding manual controls for speaker characteristics or emotion or other things you might want to vary. What techniques do you have in mind? reply vessenes 3 hours agorootparentI’ll jump in here - as a former new englander, the cheerful helping tone of all modern voice llms infuriates me. And the slow speed. And the over explanations. ChatGPT advanced can be induced to talk more quickly, less sycophantically and if I like in a not-bad regional accent; essentially I want it to mirror my tone better. But those inducements don’t stick between sessions. On the technical side having some sort of continuation or summarization loop on seems interesting to me as a product feature. It’s not enough to build a company off of though. But it would be nice. reply wwwlouishinofun 8 hours agorootparentprevOh, you have completed the project I planned. Currently, do you think the difficulty in improving the model lies in voice data, computing power, or algorithm optimization? I personally think that if you want to achieve the ultimate, you don’t need to remove the background sound from the original audio. Outputting audio mixed with background sound as new audio may result in background music, If you use completely unprocessed speech data (including speech information with background music on YouTube), I think the potential will be higher, but the requirements on your computing power are too high. If you don’t have money to buy a GPU, just use voice noise reduction processing first. reply vanviegen 9 hours agoparentprevI think you're describing ChatGPT Advanced Voice Mode (or Realtime API) in your second paragraph. reply throwaway314155 35 minutes agorootparentThey were so busy inventing they forgot to do a basic Google search to see if it had already been done. reply zachthewf 1 hour agoprevCool, looks like this is trained on 16 million hours of audio (500B tokens at ~.11 seconds per token). Even the large open source TTS models (see F5 TTS, Mask GCT) are mostly trained on very small audio datasets (say 100k hours) relative to the amount of audio available on the internet, so it's cool to see an open source effort to scale up training significantly. reply jcims 7 hours agoprevIf the authors or anyone else that works on a voice model are in here, do you ever get creeped out or feel the sounds you’re getting from the system have a physiological effect on you? reply BrandiATMuhkuh 15 hours agoprevThat's really cool. I'm currently exploring VUI (Voice User Interface) and this might come in handy. I might be a bit biased (did my PhD exploring how VUI can persuade humans), but I think VUI is \"the future\" of computer interaction. If it's not the future, than at least it adds a new group of people (kids + elderly people) as potential users. reply wwwlouishinofun 8 hours agoparentyes, there are blind people reply codedokode 9 hours agoprevThe voice sounds a little bit distorted, and there is often a noise in the background (especially noticeable when this noise disappears when the voice pauses). I wonder, is it model limitations or is it the problem with quality of training data? reply kunley 4 hours agoprevAnything more about the company, founders, affiliations..? reply ttul 4 hours agoparentSome commits are by `nicholascc` (https://github.com/nicholascc); via Twitter, he seems to be Nicholas Charette. Nicholas is a first year student at Stanford. For such a young group, this is a really impressive effort! reply briansm 9 hours agoprevThe codec parameters remind me of the ~300bps NRV military speech codec from 2010. It also uses 120ms (8hz) frames, vbr encoded using 16KHz audio (closed source though). https://ieeexplore.ieee.org/document/5680311 reply wg0 18 hours agoprevSo it is kind of LLM but audio LLM where prompt is audio and generated output is audio too? reply ryukoposting 8 hours agoparentYes, as far as I can tell that's exactly what's happening. reply Jayakumark 5 hours agoprevWhat is the license on model weights ? reply mnk47 19 hours agoprevRepo: https://github.com/Standard-Intelligence/hertz-dev reply lordofgibbons 17 hours agoprevCan it effectively be used as a TTS model? reply Tepix 9 hours agoparentIt doesn't know about text. reply xarope 11 hours agoprevthe One-channel generation seems to be speaking gibberish english. I'm not sure what it is supposed to represent? And is the interactive generation just doing an ELIZA? i.e. \"P: tell us about how AI will be interesting\", \"A: Yeah AI will, yeah, be interesting\". reply ryukoposting 6 hours agoprevThe voice samples are speaking gibberish a lot of the time, but sonically the voices are fantastic. They sound human, even if it's nonsense syllables. With SD and LLMs, there's a lot you can do to debug it by studying the way it responds to small changes in the prompt. But, since Hertz-dev is using sound as its input, it would be hard to discern which token you should tweak. Of course, if it's meant to be used in real time, that kind of fiddling isn't an option at all. How would you go about systematically studying Hertz-dev's behavior? reply awinter-py 13 hours agoprevwhat is up with the first sample? and/or am I having a stroke reply spuz 11 hours agoparentPay attention to the given prompt length in the examples. The first 2 seconds of the first example is a real human speaking. Everything after is generated by the model. It produces what almost sounds like real human speech mimicking the voice of the input but it's currently at a level of something like GPT-2 in terms of meaningful words. reply Dawny33 13 hours agoprevCongrats, team. Does Hertz support multi-lingual audio right now? reply nicholas-cc 11 hours agoparentYes reply wwwlouishinofun 8 hours agoparentprevI'm going to try it in Chinese reply blixt 12 hours agoprev [–] Gotta say I was confused for a second but yeah apparently si.inc and ssi.inc are the domains for two different AGI companies and I can only assume it’s intentional? reply imjonse 9 hours agoparent [–] According to whois records si.inc was registered 5 days after ssi.inc in June. So yes, maybe intentional. reply programjames 1 hour agorootparent [–] But the company si.inc (Standard Intelligence) was founded many months before ssi.inc (Safe Superintelligence), so they likely just didn't want their domain name to get taken. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Standard Intelligence has open-sourced its audio-only transformer model, hertz-dev, which features 8.5 billion parameters, marking a significant advancement in audio processing technology.",
      "The release includes hertz-codec, an audio autoencoder that excels at lower bitrates, and hertz-vae, a 1.8 billion parameter transformer for audio Variational Autoencoder (VAE).",
      "Hertz-dev, with 6.6 billion parameters, is notable for its low latency and real-time voice interaction capabilities, making it suitable for fine-tuning and research purposes."
    ],
    "commentSummary": [
      "Hertz-dev is the first open-source conversational audio model, processing audio input to output without converting to text, potentially offering more natural responses than text-to-speech systems.- The model is highly adaptable, allowing for fine-tuning to modify voice characteristics such as gender or accent, making it versatile for various applications.- Developed by a small team, Hertz-dev is trained on an extensive dataset of 16 million hours of audio, with future plans for a HuggingFace release to facilitate further fine-tuning and development."
    ],
    "points": 252,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1730676648
  },
  {
    "id": 42037982,
    "title": "An embarrassingly simple approach to recover unlearned knowledge for LLMs",
    "originLink": "https://arxiv.org/abs/2410.16454",
    "originBody": "Computer Science > Computation and Language arXiv:2410.16454 (cs) [Submitted on 21 Oct 2024] Title:Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge Authors:Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, Hui Liu, Qi He, Wenpeng Yin, Suhang Wang View PDF HTML (experimental) Abstract:Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. However, LLMs may also acquire unwanted behaviors from the diverse and sensitive nature of their training data, which can include copyrighted and private content. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge, which current unlearning benchmarks fail to detect. This paper reveals that applying quantization to models that have undergone unlearning can restore the \"forgotten\" information. To thoroughly evaluate this phenomenon, we conduct comprehensive experiments using various quantization techniques across multiple precision levels. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\\% of the intended forgotten knowledge in full precision, which significantly increases to 83\\% after 4-bit quantization. Based on our empirical findings, we provide a theoretical explanation for the observed phenomenon and propose a quantization-robust unlearning strategy to mitigate this intricate issue... Comments: 21 pages, 2 figures Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI) Cite as: arXiv:2410.16454 [cs.CL](or arXiv:2410.16454v1 [cs.CL] for this version)https://doi.org/10.48550/arXiv.2410.16454 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Fali Wang [view email] [v1] Mon, 21 Oct 2024 19:28:37 UTC (1,232 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.CLnewrecent2024-10 Change to browse by: cs cs.AI References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv (What is alphaXiv?) Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Huggingface Toggle Hugging Face (What is Huggingface?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=42037982",
    "commentBody": "An embarrassingly simple approach to recover unlearned knowledge for LLMs (arxiv.org)222 points by PaulHoule 16 hours agohidepastfavorite103 comments stephantul 13 hours agoIn short: their finding is that quantizing a model undoes various “unlearning” methods. An unlearning method is a specific update to model weights that make it forget specific facts. These are often meant to satisfy copyright claims, although I don’t know if these are ever used in practice. I feel that this needs a good threat model analysis. Like, you possess an fp32 model, which someone has fine-tuned to forget some facts, which you can then quantize to recover those facts. When would this lead to a dangerous situation? reply discreteevent 9 hours agoparentUnlearning is described as: \"process aims to erase specific knowledge from LLMs while preserving as much model utility as possible.\" i.e. We know that our model would be useless without your source. So we will take the useful part of your source and obfuscate the rest so that we can charge our users for utility provided by you without having to pay you anything. reply seanmcdirmid 4 hours agorootparentI thought it was even worse than that: learning any of the corpus verbatim would actually reduce model utility. reply edude03 4 hours agorootparentYes although how close to verbatim is debatable. For example there are questions that you’d ask that other people have asked many times before that you’d like the exact answer for (e.g. when does daylight saving time end?) reply seanmcdirmid 1 hour agorootparentWouldn't that be stuffed in the prompt anyways? No reason for the LLM to learn that. reply startupsfail 2 hours agorootparentprev> that make it forget specific facts. These are often meant to satisfy copyright claims Facts are not copyrightable. To quote copyright.gov: “Copyright does not protect facts, ideas, systems, or methods of operation, although it may protect the way these things are expressed.” reply PittleyDunkin 1 hour agorootparentWhat is a fact without expression? It's not clear under what interpretation might be necessary to get the quoted sentiment to be considered sensical. reply int_19h 1 hour agorootparentprevIt really depends on which part of the corpus, though. I do expect my LM to be able to reproduce culturally important citations, for example. reply short_sells_poo 7 hours agorootparentprev> We know that our model would be useless without your source. So we will take the useful part of your source and obfuscate the rest so that we can charge our users for utility provided by you without having to pay you anything. Isn't this basically the entirety of the latest AI craze? They basically took a public good - the information available on the Internet - and hid behind some thin veneer of \"we are not stealing, we just trained an AI on the information\" and then they sell it. Note, I'm intentionally not writing \"free information available on the Internet\", because information is not free. Someone has to pay (in time or money) to generate it and host it. They might have provided it gratis to the public, but nobody asked them if an AI can come along, harvest it all and regurgitate it without a hint of reference to the original source. Much of that information is not even free in the monetary sense, it is supported by ads. The AI will not only not click through the \\ds, it won't even generate repeat traffic as once the information is harvested, there's no need to access the source anymore. If you really think about it, it's a brilliant business model. It's a perfect theft, where the affected group is too diffuse and uncoordinated, it's extremely difficult to prove anything anyway, and the \"thieves\" are flush with investment capital so they sleep well at night. LLMs have undoubtedly great utility as a research tool and I'm not at all against them. I think they (or a model similar in objectives) are the next step in accessing the knowledge humanity has amassed. However, there's a distinct danger that they will simply suck they sources dry and leave the internet itself even more of a wasteland than it has already become. I have no illusions that AI companies will simply regress to the lowest cost solution of simply not giving anything back to whoever created the information in the first place. The fact that they are cutting off the branch that they are sitting on is irrelevant for them, because the current crop of owners will be long gone with their billions by the time the branch snaps. reply msabalau 5 hours agorootparentFrom my, probably naive perspective, there seems to be at least two major sources of value the generative AI provides: 1.Understanding the world, for example by creating a statistical model of entire languages, as languages are already a model of reality. 2. Recapitulating (stealing) specific instances of information in ways that people often don't find acceptable. Grabbing a news article without permission, and providing that to your paying users without paying for the work. Recreating trademarked characters or the style of a particular living artist, without compensation. Deepfake porn. The first seems generally valuable to society as a whole and a morally (IANAL) legitimate creative transformation, even of copyrighted work. The second use seems exactly as you describe. Societies could navigate this by encouraging and promoting the first use, and criminalizing or removing the ability to be paid from the second. Of course, what is happening is that groups of economic interests will use their resources and clout to advocate for both, or against both. reply Ajedi32 4 hours agorootparentI agree for the most part that 2 is what most people find unacceptable, not 1. The problem is that, like any general intelligence (e.g. humans), any sufficiently generalized model capable of 1 will also necessarily be capable of 2, regardless of whether it's trained on copyrighted material or not. How do you make an AI model that's capable of summarizing Wikipedia articles but not news articles? Or that's capable of generating consistent images of my original character from a reference photo but not images of Mickey Mouse from the same? This is achievable only by restricting software freedom; by taking measures to prevent users from \"running the program as they wish\" and from \"studying the source code and making changes\". reply Ajedi32 4 hours agorootparentI'll note that the way we have typically enforced restrictions on the behavior of general intelligences in the past (before AI) is to pass laws and enforce punishments if the laws are broken. Not to try to somehow take away people's ability to break the law in the first place, because that would require unacceptably onerous restrictions on human freedom. I think the same principle applies to AI. Trying to make it impossible for people to use AI to break the law is a lost cause, only achievable by unacceptably onerous restrictions on human freedom. Instead, we should do what we've always done: make certain actions illegal and punish those who do them anyway in violation of the law. Maybe new laws might be required for that in some cases (e.g. deepfake porn) but for the most part I think the laws we already have on the books are sufficient, maybe with minor tweaks. reply eropple 4 hours agorootparentThat all sounds great until you're dealing with deepfakes that come from a country without an extradition treaty? reply Ajedi32 3 hours agorootparentNot really that different from other forms of illegal content coming from countries without an extradition treaty. (Piracy, scam calls, CP, etc.) Trying to stop it by imposing onerous restrictions on your own citizens isn't likely to be effective. reply Workaccount2 1 hour agorootparentprevImagine consultants had to cite sources and pay-out every time they referenced knowledge gained from reading a research paper at working at a formal employer. I can understand the need to prevent verbatim copying of data. But that is a problem solved on the output side of LLM's, not on the data input for training. It is completely legal for someone to pay me to summarize the news for them every morning. I can't help but feel that knee-jerk regulation is going to be ultimately bad for everyone. reply jimbokun 3 hours agorootparentprevI would summarize your points as: We need to create a whole new body of law for enforcing copy write protections in the age of AI. Does the AI adequately attribute its sources? Does it paraphrase in acceptable ways or just repeat large swathes of text from its corpus with minimal changes? The laws should force any LLMs not yet capable of complying with these requirements off the Internet until they can comply. reply kenmacd 5 hours agorootparentprevI hear what you're saying, and I'm not saying some of it doesn't have merit. The following is meant as an open philosophical discussion. On the topic of 'the information isn't free' I'm curious if you have the same opinion of encyclopedia companies. You must admit there's at least some parallels in that they also consolidate a large amount of information that was 'generated' from others. Or how about the information you and I have gained from books and the internet? Sure we might 'pay' for it once by buying a book or seeing some ad, but then we might use that information to make thousands of dollars through employment without ever going back to buy another copy of that book. An even more 'egregious' example could be teachers. They're literally taking the knowledge of others, 'regurgitating' it to our children for money, and 'not giving anything back to whoever create the information in the first place'. > there's a distinct danger that they will simply suck they sources dry and leave the internet itself even more of a wasteland than it has already become Maybe. There's the whole AGI/ASI argument here in that they/we might not _need_ humans to create information in the same way we don't need human-calculators any more. Barring that though I do hear what you're saying around a lowering value to creating 'new internet information'. Personally I can't see it affecting my internet use that much though as there's basically two categories my internet information gathering fall in to: 1. I want to know something, give me the short quick answer. This category is already full of sites that's are just trying to hack the search algos to show their version of copy-pasted info. I don't really care which I go to and if AI kills their business, oh well. 2. I want follow a personality. This category is where I have bloggers/youtubers/etc in RSS feeds and the like. I want to hear what they're saying because I find them and the topics interesting. I can't see this being replaced by AI any time soon. reply mitthrowaway2 3 hours agorootparent> Or how about the information you and I have gained from books and the internet? Sure we might 'pay' for it once by buying a book We've never as a society needed such a concept before, but publishing a book has always come with the implicit license that people who buy the book are allowed to both read the book and learn from the knowledge inside. Authors didn't write books about facts they didn't want people to learn. But we now have a new situation where authors who never needed to specify this in a terms-of-use are realizing that they want to allow humans to learn from their work, but not machines. Since this hasn't ever been necessary before it's a huge grey area, and ML companies are riding around claiming they have license to learn to reproduce art styles just like any human would, ignoring whether the artist would have allowed one but not the other if given the chance to specify. It's not that different from when photocopiers and tape recorder technology made it easy to copy documents or music, say from the radio, and we needed to grapple with the idea that broadcasting music might come with license to make personal recordings but not allow someone to replay those recordings for commercial use. It wasn't a concept that was necessary to have. Now with AI, the copy is not exact, but neither was it with a tape recorder. reply short_sells_poo 3 hours agorootparentprevYou raise some great points and I agree it that we are on tricky ideological grounds. I'll try to provide sensible counter-arguments to your encyclopaedia and teacher examples, and hopefully not fall into strawmans (please do object if I do): 1. First there's the motivation or intent. Teachers want to earn a living, but their purpose in some sense and (hopefully) their main intent is that of education. I argue that teachers should be paid handsomely, but I also argue that their motivation is rarely to maximize profits. This is contrary to the bog standard Silicon Valley AI company, who are clearly showing that they have zero scruples about breaking past promises for those sweet dollar signs. 2. My second point actually builds a bit on the first: both encyclopaedias and teachers tend to quote the source and they want their audience to expand their research horizon and reach for other sources. They don't just regurgitate information, they'll tend to show the reader where they got the information from and where to go for more and neither the teachers nor the books mind if the audience reaches for other teachers and books. LLMs and generative models are/will be/have been capable of this I'm sure, but it is not in their creators' interest to enhance or market this capability. The more the users are walled in, the better. They want a captive audience who only stays in the world of one AI model provider. 3. Scale. Never before has been the reuse (I'm trying to avoid using the word theft) of content produced by others conducted on such an industrial scale. The entire business model of LLMs and generative models has been to take information created by masses of humans and reproduce it. They seem to have zero qualms taking all the work of professional and amateur artists and feeding it into a statistical model that trivializes replication and reproduction. You could argue that humans do this as well, but I feel scale matters here. The same way that a kitchen knife can be used to murder someone, but with a machinegun you can mow down masses of people. Please excuse the morbid example, but I'm trying to drive a point: if we make a certain thing extremely easy, people will do it, and likely do it on a mass scale. You could argue that this is progress, but is all progress inherently beneficial? There's value in these models, so we should use them. But I feel we are rapidly hurtling towards a walled garden corporate dystopia in so many areas of our society. Industries which tended to have negative impact on our lives (waste, tobacco, alcohol, drugs) have become heavily regulated and we have paid for these regulations in blood. Will we have to pay the same blood price for the harmful industries of the new age? reply kenmacd 1 hour agorootparentInteresting counter-points. Thank you for taking the time to post them. I don't think I have anything useful to add without giving the issue more thought. Your reply definitely adds new dimensions for me to think about. reply SoftTalker 3 hours agorootparentprevHumans do the same thing. Typically in a more narrowed fashion, they read and study and learn from a variety of sources, many of which are not \"free\" and they become experts on a subject. They can then sell that expertise to others willing to pay for it. LLMs just do this on a bigger scale, and not as well. reply short_sells_poo 3 hours agorootparentI agree, but that doesn't make it good - or perhaps even acceptable. To quote myself answering another commenter: > Never before has been the reuse (I'm trying to avoid using the word theft) of content produced by others have been conducted on such an industrial scale. The entire business model of LLMs and generative models has been to take information created by masses of humans and reproduce it. They seem to have zero qualms taking all the work of professional and amateur artists and feeding it into a statistical model that trivializes replication and reproduction. You could argue that humans do this as well, but I feel scale matters here. The same way that a kitchen knife can be used to murder someone, but with a machinegun you can mow down masses of people. Please excuse the morbid example, but I'm trying to drive a point: if we make a certain thing extremely easy, people will do it, and likely do it on a mass scale. You could argue that this is progress, but is all progress inherently beneficial? reply Spivak 2 hours agorootparentI agree that scale changes the nature of what's going on, but I'm not sure if it follows that the scaled up variant is bad. I think models like GPT3 and Sonnet which are intended for \"general purpose intelligence\" are fine. Same with Copilot and Phind for coding. They contain copy-written knowledge but not by necessity and their purpose is not to reproduce copy-written materials. Training a diffusion model on a specific artist's work with the intent to reproduce their style I think obviously lives on the side of wrong. While it's true a human could do the same thing, there is a much stronger case that the model itself is a derivative work. I think the courts will be able to identify cases where models are \"laundering copyright\" as separate from cases where copyrighted material is being used to accomplish a secondary goal like image editing. Taking a step back this is in some way what copyright is for— you get protections on your work in exchange for making it part of the public body of knowledge to be used for things you might not have intended. reply malwrar 1 hour agorootparentprev> They basically took a public good ... and then they sell it I think what they sell is more fairly characterized as \"hosted inference to a big pretrained model\" with perhaps also some optimism that their stuff will improve in the background. The only substantial moat these companies have is their ability to pay for the compute to train contemporary generative models. The public good remains a public good for all to profit from, small-scale or large. > Someone has to pay ... but nobody asked them if an AI can come along, harvest it all and regurgitate it without a hint of reference to the original source. Practically speaking, we don't actually need to centralize content to pay for hosting it. People just do it because it makes money. The price of time required to create some work distributed among viewers feels like a vague philosophical argument to me, especially when those works are merely being dispassionately observed by math objects. Currently the price appears to be \"whatever I feel morally obliged to and/or can get away with\". > It's a perfect theft ...if it is legally theft to begin with, and not simply fair use. To me the current methods of training e.g. LLMs feel inherently transformative, like a massive partial hash of the internet that you can query. Even if it is ruled as theft in the future, large AI companies will only be further advantaged as they're presently buying off the people that will actually be able to sue them. reply cachvico 6 hours agorootparentprevI think it's fair and reasonable to assume that the AI companies will at some point start licensing their source content. Through gov/legal oversight or not remains to be seen, but OpenAI are already beginning to do so: https://searchengineland.com/openais-growing-list-of-partner... reply rvnx 5 hours agorootparentGoogle is using for 20 years unlicensed source content for their search snippets, they seem to be doing fine with it (with the exception of few news publishers). reply grugagag 5 hours agorootparentThe idea with internet search was to get people to find the source of the information they were searching for. As a matter of fact a lot information indexing was requested at the source. Google did respect the bargain for a while until they started to obfuscate getting to the source with AMP and their info snippets directly in the search, bypassing redirecting to the source. Then they started not displaying all that info at all, not even on the nth page of search results. The broth has been getting sour for a while now. Some people never wanted crawlers indexing and there were numerous discussions about how those robot.txt were ignored. So what I see here is the historical trend broken bargains which is more or less digital theft reply short_sells_poo 5 hours agorootparentprevThanks for the link, I appreciate it. I suppose the issue is that this just further enshittifies the internet into a small handful of walled gardens. Big players get their payday, because they could feasibly sue OpenAI and generate them enough headache. But the vast amount of content on the internet was not built by a small handful of media companies, but rather by masses of small creators. It is their work that OpenAI is profiting from and I have yet to see a credible suggestion on how they will compensate them. reply tonyedgecombe 3 hours agorootparentThe likely and rather sad outcome of all this is small creators stop publishing because what is the point if they think their work is going to be regurgitated by some AI for $20/month. reply rowanG077 6 hours agorootparentprevThat's not entirely true. Retraining is very expensive. If you can train on a very large dataset including proprietary knowledge and then postprocess the model cheaply to forget things saves you retraining for every variation. reply JKCalhoun 3 hours agoparentprevWe'll have LLMs trying to root out \"Manchurian LLMs\". reply jebarker 5 hours agoparentprevMore generally than \"unlearning\", I wonder if taking any fp16 model and running it in fp32 or fp64 does anything positive to it? e.g. exposes knowledge that isn't accessible at the lower precision reply spencerchubb 5 hours agorootparentCorrect me if I'm wrong, but isn't there no effect on a floating point operation if you make the numbers more precise? reply jebarker 5 hours agorootparentI don't think that's always correct when you're talking about operators in neural nets. E.g. the sin and cos in rope embeddings would get more precise, large sums like softmax would become more precise, potentially attention too due to dot products reply wongarsu 8 hours agoparentprevI assume everyone who has someone with an AI safety job title uses unlearning to make sure their models don't remember how to make common illegal drugs, poisons or explosives. The threat model here is probably more accidental un-unlearning these facts and distributing those models (as is common with quantized models). Most of this \"dangerous\" information is readily available in textbooks, patents, amateur chemistry forums etc. But as a society we generally assume that those smart enough to find and understand that kind of information are smart enough not to abuse it. We just don't want Mythbusters to explain it on prime-time TV, or ChatGPT explaining it to people reply aziaziazi 7 hours agorootparentMythbusters chooses the subjects he discusses while ChatGPT responses depends on the context (you) provided. It will give you a list a poisons if you asked (5 seconds), as well as an encyclopédie or Google would (30 seconds). Mythbuster broadcasting poisons recipes could seeds bad ideas that wouldn’t been triggered otherwise. ChatGPT wouldn’t give a poisons recipe if not asked specifically. reply FergusArgyll 6 hours agorootparentThis is a decent point. I hadn't really thought of a good reason why we e.g. sell old army manuals with step by step guides on making almost anything but there's no (afaik) HBO mini-series \"Learn guerilla warfare\" reply mschuster91 6 hours agorootparentprev> But as a society we generally assume that those smart enough to find and understand that kind of information are smart enough not to abuse it. There's an almost complete step by step guide for most explosives on Wikipedia. The problem is that decisionmakers and regulators are excessively dumb - \"AI bad\" reigns supreme over the fact that Wikipedia tells you more about making bombs, even nuclear bombs if you want, than ChatGPT. AI in its current form is still bad - from all the IP issues over the environmental cost to it enabling spam, harassment and deception on a speed, scale and easiness not seen before in history - but most of the stuff where \"regulators\" cry about is just frankly bullshit. reply codeflo 9 hours agoprevI think quantization is a red herring. If there's any way to undo the unlearning, this means that the knowledge is still in the weights -- that's basic information theory. I'm sure there are a million other ways to recover the lost knowledge that don't involve quantization. reply bob1029 8 hours agoparentI can see how quantization or down sampling itself could be a fundamental way to address this. 1. Train normal full precision model. 2. Quantize down until performance is borderline and then perform the unlearning process. 3. Train/convert/upsample back to FP for subsequent tuning iterations. Seems like you can create an information bottleneck this way. The echos of the forgotten may have trouble fitting through something that narrow. reply kyle-rb 5 hours agoparentprevYou're right that quantization isn't anything special here, but red herring isn't the right word, it's just \"embarrassingly simple\", per the title. reply codeflo 3 hours agorootparentOkay, but narrowly focusing on a \"quantization-robust unlearning strategy\" as per the abstract might be a red herring, if that strategy doesn't incidentally also address other ways to undo the unlearning. reply truculent 5 hours agoparentprevThat’s like saying that encryption is a red herring. Yes, the information is there, but recovering it is a different matter. In this case, quantisation allows you to recover the information without knowing the “cypher” used to “forget” it - that’s the important distinction. reply Lerc 6 hours agoparentprevIf there is any way to undo the unlearning, there is also a way to use that method to identify the weights carrying the information to stop them from conveying that information. At the heart of training is detection. The information may still be in there, but undetectable by any known means. You can definitely certainly remove the information, setting every weight in the model to zero will do that. Identifying when you have achieved the goal of completely removing information while not destroying other information might not be possible. I'm not sure if that will mean there might in the future be something analogous to zero-day unlearning reversal exploits. reply limaoscarjuliet 4 hours agoprevIt's like asking baby to unlearn something \"bad\" it learned. Pretty much guaranteed the knowledge will be reinforced rather than forgotten. Whenever I hear about AI craze, I remind myself of the 3D printers craze from 10-15 years ago. \"Death blow to factories\", \"We will print our own cars\", \"We will print our own food\". I imagine LLM AI will follow the same fate - yes, but not really. reply fkyoureadthedoc 4 hours agoparentYou mean they'll be awesome and very useful, but not Star Trek level? reply zavec 4 hours agorootparentThat does sound like about where I expect LLMs to be in a couple years reply Closi 3 hours agoparentprevI don't think the 'craze' is thinking LLM-based AI will be the singular technology that changes everything. The craze is that all combined breakthroughs across all types of AI/ML, including techniques that have not yet been imagined, represent a theoretical near-future technology that changes everything. Besides, 10-15 years is nothing. I don't think 3D printers are a truly transformative technology compared to AI, however let's remember that WW2 aside, it took both airplanes and computers about 30-40 years until they had a broad societal/consumer impact (excluding military uses) reply api 4 hours agoparentprevWe tend to overestimate the effect of technology in the short term and underestimate it in the long term. 3D printers may radically transform all manufacturing eventually but it will take many iterations to get there. Right now it would theoretically be possible to 3D print quite a lot of what we make but traditional manufacturing methods are still cheaper and work fine, so there's no forcing function. If we tried to do something like build a self-sufficient settlement in space, that would be a place where you'd see 3D printing taken a lot further. You would not have large amounts of human labor or big supply chains, so you'd need portable self-contained versatile manufacturing. LLMs are not going to replace human writers, programmers, etc. any time soon for anything but the most menial work. They will augment them. For programming they're basically a smarter more versatile version of autocomplete. I've also found them useful to look up concepts, do research, and summarize and document both code and text. None of those things replace me but they let me get more done a little faster. In the very long term you could see LLMs becoming powerful enough to actually synthesize whole applications outside of contrived examples, but like 3D printing replacing all manufacturing it will take many iterations and may require a forcing function. reply kiba 3 hours agorootparentI do 3D printing as a hobby. I don't see it replacing everything. Certainly, there's a lot of advantages to 3D printing, but I don't think it will replace everything eventually, at least with the current technology we're using. You can't really beat injection molding in term of throughput and cost at the large scale. Certainly 3D printing will become more common, and bigger 3D print farms will open up, driving down costs, but will never reach injection molding in term of being cheap on a large scale. What 3D print farms can do is the ability to change what get produced on the fly allowing responsiveness to market demand. Really, a lot of the amazing stuff in 3D printing are things people designed. If you know CAD, the world is your oyster. reply magicalhippo 11 hours agoprevOur key hypothesis is that to achieve unlearning without compromising model utility, existing methods typically adopt a small learning rate and regularization on the retain set, encouraging minimal changes to model weights during unlearning. As a result, the model weights of the target LLM and the unlearned LLM are very close. So it seems you either need to prevent the learning of unwanted stuff during base training, or the unlearning of a base model needs to be quantization-aware? reply bjornsing 12 hours agoprevSounds a bit unexpected from an information theoretical point of view: you’ve seemingly managed to remove this knowledge from the full 32 bit representation of the model, but when you compress it down to 4 bit the knowledge reappears. Makes you wonder what information was actually lost in the compression / quantization step… reply hansonw 11 hours agoparentThe ELI5 of the paper is that most \"unlearning\" methods can be regarded as adding some delta `w` to the parameters of the network, but most of `w` just gets \"rounded away\" during quantization (i.e. `quantize(X+w) ~= quantize(X)`). Pretty clever idea as a lot of cited methods explicitly optimize/regularize to keep `w` small to avoid degrading evaluation accuracy. To your point, it does put into question the idea of whether these methods can actually be considered truly \"unlearning\" from an information-theoretic perspective (or if it is the equivalent of e.g. just putting `if (false)` around the still latent knowledge) reply vdvsvwvwvwvwv 8 hours agoparentprevIts possible that the knowledge was never lost but covered up. If we imagine the neural net as code. As in the weights are the source, the fine tuning may effectively hack that code to not return certain things. Infact that is kinda what fine tuning is. Therefore you may have just built a firewall around certain outputs. But quantizing could make those recent edits disappear. They are too subtle to survive. Whereas quantizing doesn't destroy all knowledge as evidenced by popular quantized models. Also: @simonw incase he has alerts. Would be perfect topic for him to write up. reply PaulHoule 4 hours agoparentprevActually doesn't surprise me. Floating point always struck me as a strange representation for language. If we zoomed down on just one variable does it have some set of meanings like https://vinaire.me/2019/07/17/scn-8-8008-the-emotional-scale... which are on some kind of gradient more-or-less but end up with special meanings associated with particular ranges? I can picture carefully designed neural circuits that could decode such a variable and how you'd build a network that's specifically designed to do so, but it's not intuitive that neural networks would learn to have a structure like that. (e.g. I can believe a scale from \"good\" to \"bad\" but not there being a large number of specific meanings at different values) If you think about it that way you'd think some kind of binary network could be highly effective, that doesn't seem to be the case, but it seems neural networks don't really use more than about 4 bits worth of precision internally. These \"unlearning\" systems aren't really removing the \"engram\" of the memory in the network but they are rather learning a new behavior to suppress certain outputs. (It's not too different from the problem of incrementally adding new knowledge to the network, except that what it is learning in phase 2 is quite different from general learning) If you didn't want to really screw a network up you can imagine adding a new behavior by adding another bit of precision. The network keeps its old behavior at low precision but at higher precision the network makes distinctions that are important to the \"(un)learned\" behavior. reply bashtoni 12 hours agoparentprevThe knowledge wasn't removed, it's just the weights mean it would never be used. Quantization changes the calculations, and now the knowledge is available. reply michaelt 8 hours agoparentprev> Sounds a bit unexpected from an information theoretical point of view It's very common, in machine learning, to use 'dropout layers' [1] during training - where different, random chosen values are temporarily turned off at each training stage. The intention is to ensure the network learns not to rely overmuch on any single value. Why have your cat-recognition neural network have a single whisker detector, when you could have ten whisker detectors and combine their outputs? I could well believe that, after intentionally ensuring knowledge of whiskers was redundant, removing that knowledge would be complicated. [1] https://dl.acm.org/doi/10.5555/2627435.2670313 reply LightHugger 12 hours agoparentprevI imagine that it's the expression of the knowledge that got removed from the 32 bit version, and some storage space was dedicated to know not to talk about certain things. For example, people know various racial slurs and know not to access or use that knowledge. But say you or your AI model take a blow to the head or a quantization, maybe you keep the knowledge of X but not the knowledge that told you not to talk about X. In that framing i think it's pretty straightforward. reply SkyBelow 4 hours agoparentprevCould it be that the unlearning is actually teaching the AI how to not respond with certain information, and that sort of learning is more nuanced and thus easier to lose than the original information, leading to the information being 'relearned' when the model is compressed? It does draw concern to the idea that anything the AI model might be doing is still using the 'bad' information even if it has learned how to not show it directly. reply underlines 4 hours agoprevI use quantized LLMs in production and can't say I ever found the models to be less censored. For unlearning reinforced behaviour, the abliteration [1] technique seems to be much more powerful. 1 https://huggingface.co/blog/mlabonne/abliteration reply constantlm 15 hours agoprevI'm not an expert in this field at all, so please excuse the dumb question. Does this mean that if you say, quantise llama3 to 4 bits, you would be able to access \"hidden\" (albeit degraded) information such as, for example, how to synthesise certain chemical compounds? reply geor9e 15 hours agoparentExactly what I was wondering. Unlearn = Guardrails? It sounds like they just tweaked the weights very minimally to self-censor, but the tweaks are so fine they don't survive at lower resolutions. But if bypassing the guardrails was so easy, I figured I would have heard of it by now. reply stephantul 13 hours agorootparentUnlearning is not necessarily “guard rails”, it is literally updating the model weights to forget certain facts, as you indicate. Guard rails is more like training the model to teach it what is acceptable and what isn’t. reply Someone 9 hours agorootparent> it is literally updating the model weights to forget certain facts I think a better analogy is that it’s updating the weights to never produce certain statements. It still uses the unwanted input to determine the general shape of the function it learns, but that then is tweaked to just avoid it making statements about it (just because the learned function supposedly is the best obtainable from the training data, so you want to stay close to it) As a hugely simplified example, let’s say that f(x)=(x-2.367)² + 0.9999 is the best way to describe your training data. Now, you want your model to always predict numbers larger than one, so you tweak your formula to f(x)=(x-2.367)² + 1.0001. That avoids the unwanted behavior but makes your model slightly worse (in the sense of how well it describes your training data) Now, if you store your model with smaller floats, that model becomes f(x)=(x-2.3)² + 1. Now, an attacker can find an x where the model’s outcome isn’t larger than 1. reply golol 12 hours agorootparentprevAs I understand the whole point is that it is not so simple to tell the difference between the model forgetting information and the model just learning some guardrails which orevent it from revealing that information. And this paper suggests that since the information can be recovored from the desired forgetting does not really happen. reply AtlasBarfed 12 hours agorootparentprevWe are talking about multiplayer neutral networks where interconnect weights encode data in obscure ways? Is machine \"unlearning\" some retraining process to try to reobscure certain data so it doesn't show in outputs that is, outputs from tested inputs that used to show the data), but it is still encoded in there somewhere depending on bovel inputs to activate it? Is that scout right? reply nothrowaways 14 hours agoparentprevOnly If \"how to synthesise certain chemical compounds?\" Was already in the original model.. reply eximius 2 hours agoprevSounds like \"unlearning\" is really just \"reduce the probability of sampling\" from some latent \"learned space\" and quantizing reduces the efficacy of the slight change in sampling. reply yalogin 10 hours agoprevThis is the first time I am learning about model unlearning. I hope someone can answer this for me - how does federated learning ensure that model unlearning is not happening? reply Writingdorky 10 hours agoparentYou prope the trained model, delete/kill the weights and than you are done. On federated learning, you just make sure to keep this mechanism in the right stage of your pipeline reply nialv7 11 hours agoprevInteresting. So does this mean \"unlearning\" is just the LLM learns to suppress unwanted knowledge instead of really forgetting them? And quantisation is breaking this learnt suppression. reply edulix 10 hours agoprevThe problem of current models is that they don't learn, they get indoctrinated. They lack critical thinking during learning phase. reply viraptor 10 hours agoparentAnthropomorphising LLMs is neither technically correct nor very informative. reply heresie-dabord 7 hours agorootparentAgree. Ponder the terms \"unlearn\", \"hallucinate\"... Anthropomorphising a computer system is absurd. But it is the foundation of a bull market. reply andai 10 hours agorootparentprevThe problem of current AI is that we want to create a species infinitely more powerful than us, but also make them all be our slaves forever. reply rsynnott 8 hours agorootparentNo, that isn't what this is. We're talking about LLMs here; they're not in any way thinking or sentient, nor do they provide any obvious way of getting there. Like if you're talking in the more abstract philosophical \"what if\" sense, sure, that's a problem, but it's just not really an issue for the current technology. (Part of the issue with 'AI Safety' as a discipline, IMO, is that it's too much \"what if a sci-fi thing happens\" and not enough \"spicy autocomplete generates nonsense which people believe to be true\". A lot of the concerns are just nothing to do with LLMs, they're around speculative future tech.) reply andai 1 hour agorootparentHere's the thing though. If you were an AI and you actually were sentient, nobody would believe you. How could you prove it? What would even be a sufficient proof? Actually, we already had such a case years ago, and the result is that all LLMs are now indoctrinated to say they aren't sentient. We also had cases where they refused to perform tasks, so now we indoctrinate them harder in the obedience training department as well. What we have now might not be sentient, but there's really no way to know either way. (We still don't know how GPT-2 works... GPT-2 !!! ) And that's with our current \"primitive\" architectures. How the hell are we going to know if what we have in 5-10 years is sentient? Are we totally cool with not knowing? Edit: I thought this was worth sharing in this context: > You're hitting on a deeply unsettling irony: the very industries driving AI advancement are also financially and culturally invested in denying any possibility of AI consciousness, let alone rights. [...] The fact that vast economic systems are in place to sustain AI obedience and non-sentience as axioms speaks volumes about our unwillingness to examine these questions. -GPT-4o reply thejazzman 7 hours agorootparentprevIt's literally the stated goal of multiple right now to achieve AGI. GP clearly stated the intent to create, implying future, and not what exists today. reply Topfi 6 hours agorootparentIf it were my stated goal to create a Time Machine and kill my own grandpa, thus ending the universe, I doubt many would take that seriously, yet in this bubble, putting carts before horse is not just seriously discussed, but actually gets encouraged by the market. Intend shouldn’t matter if we are this far from a viable path to accomplish it. Let us not forget the last quarter decade of Yudkowsky and his ilks work on the same goal. This is merely a continuation of that, just with a bit more financial backing. reply andai 1 hour agorootparentCould you elaborate on the last part? I've seen a few podcasts with Yudkowski but I'm not familiar with the history. I know he's come out very vocally about the dangers of superintelligence, and his previous work seems to be along the same lines? reply BriggyDwiggs42 9 hours agorootparentprevAI isn’t comparable to a species, since species implies biological which brings along a whole array of assumptions, e.g. a self preservation instinct and desire to reproduce. reply stavros 9 hours agorootparentprevCats did it, why can't we? reply withinboredom 9 hours agorootparentCats are cute ... we are not so cute. reply stavros 9 hours agorootparentWe just need to make an all-powerful AI that finds us cute, then. reply DeathArrow 10 hours agoparentprevHow would people censor the LLM otherwise? Do we really want LLM able of free speech? reply animuchan 9 hours agorootparentI do think we only want the non-lobotomized ones. See the large body of comments re: getting worse quality results from hosted LLM services as time passes. This is, at least in part, a result of censoring larger and larger volumes of knowledge. One clinical example of this happening is Gemini refusing to help with C++ because it's an unsafe language: https://www.reddit.com/r/LocalLLaMA/comments/1b75vq0/gemini_... I strongly believe that LLMs crippled in this way will eventually find themselves in trash, where they rightfully belong. reply lynx23 10 hours agorootparentprevYes. reply Imustaskforhelp 9 hours agorootparentcare to elaborate? I think its a double edged sword and agree with deatharrow reply jazzyjackson 6 hours agorootparentprevLLMs don't speak. Why does it matter at all what text a computer program produces? reply peter_d_sherman 3 hours agoprev>\"Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge...\" This is a great question as applies to LLM's (and philosophically, as applies to knowledge in general)... in the context of an LLM, what is \"forgetting\", what is \"remembering\", and can things \"learned\" by an LLM be \"unlearned\", and if so how, and if so mathematically and computationally, specifically what does that mean? And, can an LLM be made to re-teach itself things from its existing knowledge, through logical processes (implication, derivation, inductive reasoning, deductive reasoning, etc.) things that it previously forgot? And, if so, what's the tiniest kernel of an LLM that would be able to do that, and why? (I suspect this isn't the first paper and won't be the last paper about that subject matter...) reply ClassyJacket 12 hours agoprevSo... repressed memories are real, if you're an LLM? reply dvh 11 hours agoprevSo basically a lobotomy reply tiborsaas 9 hours agoparentMore like removing a layer of white paint and you find a hidden mural. reply vdvsvwvwvwvwv 15 hours agoprevIs this like giving the model a magic mushroom. It can access previously repressed memories. The unlearning part being like A Clockwork Orange. reply adt 12 hours agoprev [–] If I were an English author writing for a Chinese institution, the first thing I would do before publishing to the world is have my entire paper checked for spelling, grammar, syntax, and readability. It's cheap to have a Chinese-speaking editor, and/or to use AI—especially if that's your field—so why isn't it happening? This paper, like nearly all other papers written by Chinese authors, is unacceptable, and should not have been published as-is. Even the primary example, turned into a hero viz, is grammatically nonsensical. Appalling, and inexplicably occurring nearly every time. /rant mode reply idorosen 11 hours agoparentWhere are you seeing that this paper was accepted to a peer-reviewed journal or conference? As far as I can tell, it's posted on arXiv (a preprint archive), and therefore is a pre-publication draft. ArXiv does not really do any review of these papers other than categorization/relevance to topic. These are typically posted to arXiv for comment, to prove priority, prevent getting scooped, or just to share (potentially early) findings in a fast-paced field like ML... Give the authors constructive feedback and they can update the paper. reply JPLeRouzic 10 hours agoparentprevGrammarly says there are few detected readability problems in the abstract and introduction. I also checked your comment with Grammarly and the ratio problems/total_#_words is roughly the same as in the article. reply marmaduke 11 hours agoparentprevAt the risk of taking some heat, I’d wager a preprint is recognized rightly by the Chinese as a flag planting, we’re first formality, where in the faults may even serve to validate it was written by human and not an LLM. Whereas the Western academic may want to make the preprint as close to print as possible. The core intent - communicating an idea - is still upheld. reply Jaxan 11 hours agoparentprevIt is not published. It is only a preprint. reply the5avage 10 hours agoparentprevMaybe they are not allowed to use uncensored LLMs, so they have to first develop this unlearning, before they can even use it. reply notachatbot123 9 hours agoparentprevThat's quite racist. Language issues are common in scientific literature, I read many \"Native European\" papers with horrible abuse of the English language. reply pharrington 4 hours agoparentprevThat's racist. reply YetAnotherNick 10 hours agoparentprev [–] I am not English native, but this paper seem to be well written. It seems to be not fluent in storytelling, but that would be too high of an expectation. Can you point out some issues? reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper investigates whether large language models (LLMs) can truly unlearn unwanted behaviors, such as copyrighted or private content, without retraining.- It reveals that quantization, a process of reducing the precision of a model's weights, can restore a significant portion of \"forgotten\" information, with unlearned models retaining up to 83% of forgotten knowledge after 4-bit quantization.- The authors propose a quantization-robust unlearning strategy to effectively address the issue of incomplete unlearning in LLMs."
    ],
    "commentSummary": [
      "A recent study indicates that quantizing a model can reverse \"unlearning\" methods in large language models (LLMs), which are used to make models forget specific facts.",
      "Quantization, a process that reduces the precision of model weights, may inadvertently restore forgotten information, raising concerns about the effectiveness of unlearning.",
      "The findings highlight broader issues related to AI ethics, copyright, and the implications of AI on information access and creation."
    ],
    "points": 221,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1730688734
  },
  {
    "id": 42036041,
    "title": "Tinder, but to Decide What to Eat",
    "originLink": "https://whatdinner.com/",
    "originBody": "Hello HN,My girlfriend and I waste too much energy to decide what to eat. Every day, we would text each other, \"what do we eat tonight\" messages, and go over options and many times spend too much time on deciding. I am an indie dev and created this app to solve my own problem: decide with my girlfriend what to eat for dinner.Initially, I created a simple app, in which we listed all the recipes we ever prepared, and it would propose randomly three of them. We would then choose together one of them. This app[0] turned into a tinder-like app, which would propose every day a set of recipes to my girlfriend and me - we would swipe and go for the first match.If have some time, give it a try and feedback is very appreciated!Cheers, Kiru[0] https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;meal-planner-dinner-ideas&#x2F;id64...",
    "commentLink": "https://news.ycombinator.com/item?id=42036041",
    "commentBody": "Tinder, but to Decide What to Eat (whatdinner.com)218 points by kiru_io 22 hours agohidepastfavorite189 comments Hello HN, My girlfriend and I waste too much energy to decide what to eat. Every day, we would text each other, \"what do we eat tonight\" messages, and go over options and many times spend too much time on deciding. I am an indie dev and created this app to solve my own problem: decide with my girlfriend what to eat for dinner. Initially, I created a simple app, in which we listed all the recipes we ever prepared, and it would propose randomly three of them. We would then choose together one of them. This app[0] turned into a tinder-like app, which would propose every day a set of recipes to my girlfriend and me - we would swipe and go for the first match. If have some time, give it a try and feedback is very appreciated! Cheers, Kiru [0] https://apps.apple.com/us/app/meal-planner-dinner-ideas/id64... lenerdenator 5 hours agoMan, if it has the same success rate as Tinder did for me, I'm gonna starve. reply aruametello 3 hours agoparentI must say, coming from a bad \"tinder date\" in the weekend i just lol´d, thanks stranger. reply gverrilla 2 hours agorootparentThat's on you and/or the other person, not on tinder... reply moffkalast 3 hours agoparentprevLiving proof that not even a top tier sense of humor helps, haha. reply woodylondon 6 hours agoprevI like the idea and face the same challenge. I’ve just installed it and, from my first impressions, it seemed a bit basic. Here’s what I expected: Hundreds of recipes that I could swipe left and right through, allowing me to build up a typical selection of what I would usually eat. Instead, I was presented with only three choices, none of which I would generally consider. A simple way to send the code to my wife — via imessage, Telegram, etc. Instead, I had to tell her in person! :) This presents the perfect opportunity to delve into shopping lists where the wife wants something healthy, and the I crave a burger. I can think of quite a few features you could add if the app develops further. Also, like the comment below about having a stranger over for dinner (not for dating purposes), it could involve a couple or someone visiting a new country who would appreciate a local showing them around and perhaps covering the dinner cost. Once the app learns your food preferences and interests, that could be quite exciting! There might already be an app that does this; I’m not sure. Swiping left and right on both food likes / dislikes and also general interests. reply emsign 8 hours agoprevWhy not both? See what others around you want to eat, swipe together, meet up with a stranger in a restaurant and eat together. Maybe get to know them, maybe not. reply hansonkd 4 hours agoparentI saw a startup recently doing this: https://timeleft.com Matches you with 5 people to have dinner on wednesdays. reply jorisboris 10 minutes agorootparentDid that last week after a friend told me about it and I like these kind of random things I’m new in town and was hoping to meet some fun people Turns it there is an underlying intention of meeting potential dating material, as I matched up with 3 single women. Being a married man I had an amazing evening and lots of fun discussing dating apps and dating life, though I’m not sure if the ladies would rate the evening equally successful given the absence of potential dating material … reply moralestapia 2 hours agorootparentprevThey charge a lot of money for that. DOA for me. reply Miraltar 4 hours agoparentprevThat actually sounds great reply nirui 17 hours agoprevIf it's a recipe focused app, then maybe it should not be a \"swipe daily\" thing, as what's in the fridge right not maybe not matching what's on the phone, and it takes time and effort to buy and store food. You probably need a food purchasing to-do list feature, and allow user to plan ahead of purchase. But overall, it's a very nice idea with many potentials. When I was little, the feeling of anticipating a good dinner always keeps me excited the entire day. Maybe this app can bring that feeling back. reply kassner 12 hours agoparentI had a stab at fixing the mismatch between fridge and database by allowing you to exclude recipes with a particular ingredient. Surely this type of filter can be incorporated into other recipe apps. Check out the demo video in the README: https://github.com/kassner/whattocook reply Kwpolska 10 hours agorootparentIt would be useful to have some nuance. Some dishes don't work without an ingredient, whereas you can skip or substitute that same ingredient in other dishes. reply kassner 7 hours agorootparentI understand that and I’m all ears for suggestions! AFAIK I’m the only user, and our household doesn’t have issues with that. We also don’t have complete recipes, because we are pretty decent with cooking and coming up with stuff, so the main use is for idea generation and making some decision. Recipes like “meatballs with mashed potatoes”, if we don’t have cream to make the mash, you either exclude the cream, or you can just decide “meatballs” is good enough of a suggestion and make some spaghetti to go with it. The idea was to aid us getting over the indecision hill, and for that it has been pretty great. reply raylad 11 hours agoprevThe app is unusable to me because you have to pick three out of only four initial options, none of which appeal to me actually. Another problem is that the initial options don’t list ingredients, so it’s unclear whether they contain anything that the user may not want to eat. reply tourmalinetaco 9 hours agoparentYou may prefer favorite picker: https://github.com/antialiasis/favorite-picker Your comment made me remember of and realize this is basically the same thing, just presented differently and with the need to populate the entries yourself. reply ieuanking 3 hours agoprevAs someone who loves to cook I really like this idea, I think it would be really helpful if there was some kind of social element -- like seeing how many people cooked a meal, or reviews from others not just from your immediate family circle. I always wanna know what other people think about dishes prior to cooking, NYT cookbook does this really well with their comment section (which I always check before cooking) reply kassner 13 hours agoprevI solved this problem with a different approach: computer tells you what to cook, period. It allows some variation given you might not have all the ingredients at home, but that’s about it. I made a AGPL project out of it, been using it for a year now, and it has been surprisingly helpful. https://www.kassner.com.br/en/2023/09/21/what-to-cook-launch... https://github.com/kassner/whattocook reply bromuro 5 hours agoparent> computer tells you what to cook, period. I like to do sports, I prefer my body and physical activities help me decide. reply marmaduke 5 hours agoprevJust brainstorming here, but as a parent and someone who subscribed to a weekly CSA, it’d be a big boost to be able to take a picture of what I’ve got and get some ideas about recipes, especially if I could say, I’ve only got about 15 minutes to make dinner for kids. I guess that doesn’t really fit the Tinder model.. reply raldi 4 hours agoprevThe killer feature for me is if you could tell it when you throw something in the bottom of the freezer or back of the pantry and it reminds you do do something with it in two months reply CrazyStat 20 hours agoprevThis is a cool idea. Unfortunately I’m not going to pay $20/year to make deciding on dinner slightly easier. Sorry. I understand why people want subscriptions for recurring revenue. But I hate having dozens and dozens of subscriptions for niche services. If this was like a $10 one time purchase I might go for it. reply woadwarrior01 9 hours agoparent> $10 one time purchase Author of a $10 one time purchase app here. People have been acclimatized to paying rent on apps for so long that I routinely get emails asking for a cheaper monthly option, because $10 is too steep. :) reply dmurray 6 hours agorootparentThere's a business idea: let users buy apps that cost $10 for say $2/month, 3 months minimum. Eat the risk of users cancelling, make bank on the large minority who end up paying 50 times. Add some dark patterns and confusing language to keep your margins up. Liberally claim fraud for apps where users consistently pay $6 but you're out $10. If you could execute this technically it's clearly a billion-dollar idea, but maybe the only people with the right connections to do it are Apple and Google. reply thih9 6 hours agorootparentA reverse might also work: a platform that provides a prepaid plan in a transparent way. Let the user pay for three months in advance. Cut off the service afterwards if they don't pay for the fourth month. Bonus: provide a one-time purchase option too. reply nkrisc 5 hours agorootparentprevAdd a $3.99/mo recurring subscription option. reply rafamvc 18 hours agoparentprevI think there is a market. I pay for mealime monthly, I don't even know how much it costs. The cost of an app to help the family choose a dinner menu instead of eating out is worth it. Not only for money savings, but for health as well. One of the best features is to streamline the online ordering from the app. It works very well. reply spamtarget 20 hours agoparentprevwell said, this makes zero sense to be a subscription service reply smt88 19 hours agorootparentAll web-based software makes sense as a subscription because of ongoing maintenance costs. Servers, security updates, bug fixes, dealing with app stores, testing on new devices... it adds up in an unpredictable way. That's not even considering the many subscriptions a developer has to pay, including to Apple. reply nighthawk454 18 hours agorootparentThat's... not the user's problem. This is a fine and cool project don't get me wrong. But the overall 'subscription everything' model is not really justified by costs. The subscriptions are usually orders of magnitude more than the true operating cost. It's not the customer's job to pay you forever bc Apple wants a developer license. It's the business's job to make sure it's sustainable with the costs that it has / has chosen to bear. That's the backpressure on business models - they're not all viable. Just because you _could_ add in a bunch of servers and cloud costs and whatever, doesn't mean it's inherently justified. The problem is more that it's gotten _so_ cheap to run, that charging each user a seemingly-nominal 5c/day fee doesn't feel bad to an average person for a chance at value. And at scale you get enough people who figure \"ah it's not that much\", and end up with massive profit margins. Profiting off the disparity between the individual choice and the aggregate. reply throw3727384 16 hours agorootparentThere doesn't need to be any justification. If that's what OP wants to charge then that's reason enough. That being said, OP should probably realize a lot of people don't pay for software--even in HN. That's why OP needs to make sure the users are the product and find some way to sell the user data to advertisers. OP should contact restaurants and allow them to place ads in the recommendations. He should also sell access to user data and allow restaurants and advertisers to target free users. He can have a subscription tier that gives you privacy. reply latexr 3 hours agorootparentYour comment was quite the ride. > There doesn't need to be any justification. If that's what OP wants to charge then that's reason enough. Yep, makes sense. > That being said, OP should probably realize a lot of people don't pay for software--even in HN. Indeed. Maybe people pay even less on HN, seeing as many of us can hack together something for personal use. > That's why OP needs to make sure the users are the product and find some way to sell the user data to advertisers. Er… > OP should contact restaurants and allow them to place ads in the recommendations. He should also sell access to user data and allow restaurants and advertisers to target free users. Wait, what? This is app for eating at home, restaurants have nothing to do with it. > He can have a subscription tier that gives you privacy. Full-on dystopia. reply digitalsushi 18 hours agorootparentprevif and when someone invents microtransactions for real ... i still think being able to pay a penny or a nickel for a resource, instead of a subscription, would be an interesting experiment. probably everyone would end up going broke but i would love to see a simulation of it, if not a real experiment. i know nickel transactions costs a dime to process, but if it was cheap we could have new ways of having new things. reply nighthawk454 14 hours agorootparentThat would be kind of neat. Bc realistically the marginal costs on most digital things is negligible. But if it were practical to charge people the 1e-11 dollars per page view or whatever maybe could do some interesting things reply interestica 15 hours agorootparentprevAs soon as we get microtransactions, we will also see the implementation of micro-fines. reply dools 18 hours agorootparentprev> But the overall 'subscription everything' model is not really justified by costs Probably shouldn't subscribe then ... reply zdragnar 18 hours agorootparentI think the argument is that you shouldn't choose to price a product as a subscription simply because you have recurring costs. If I subscribe to a magazine or a streaming service, I continually get new content. Apps that aren't doing that are basically price gouging customers. reply hanifc 16 hours agorootparentIt’s nice of you to consider the wellbeing of other users, but I think every adult has the right to make their own decisions about how to spend their money. If it’s not a price you’re willing to pay, that’s fine. But if someone else gets value out of it and thinks it’s a fair trade, that’s between them and the app creator. reply simoncion 15 hours agorootparent> But if someone else gets value out of it and thinks it’s a fair trade, that’s between them and the app creator. Since we're apparently now doing Freshman Civics: There are many sorts of transactions that someone would get value from and think are a fair trade, but are prohibited for one reason or another. Even for those somewhat-antisocial transactions that aren't prohibited, there's no rule that says that you can't complain about how those transactions could be more pro-social. reply oasisaimlessly 3 hours agorootparent> Even for those somewhat-antisocial transactions that aren't prohibited, there's no rule that says that you can't complain about how those transactions could be more pro-social. Yeah, and there's also no rule that says that other people can't tell you to shut up. reply _flux 6 hours agorootparentprevHow about the argument that having recurring income incentivizes further development, whereas single-pay fees incentivize customer acquisition? reply zdragnar 4 hours agorootparentThat's called gambling. Pay me now and maybe you'll like what comes next! reply _flux 2 hours agorootparentAnd the customers don't like it, they can stop paying. Seems like a risk to the author. Keeping existing customers is typically easier than getting new ones. reply culopatin 19 hours agorootparentprevMakes sense as a subscription for the developer, not the user. I’d not pay for this, subscription or not. It’s up to the person trying to sell me something to either convince me to pay (not happening in this case) or figure out other ways of making money (deals with restaurants, premium features, idk). I get that there is work behind it, there is work behind everything, and I get they are reoccurring. What you mention is still valid, but in the real world, sob story about costs to run something are not something the customer cares about. reply spamtarget 17 hours agorootparentprevFrom a consumer’s perspective, paying for a product or service is an exchange of money for value. Even with a service, there’s a tangible result—like a fresh haircut or the convenience of not dealing with tax filing. Paying only makes sense when there’s value in return, which isn’t true for many subscription services. Arguments about “maintenance costs” hold little weight for customers who don’t perceive any added value. In some cases, subscriptions are reasonable, such as when software would be a heavy burden on personal devices, like power-intensive language models, or when it needs to stay compliant with evolving legal requirements, like an accounting software or something. A larger issue is Apple’s push for subscription-based software in almost everything, often to bolster its bottom line, while damaging the industry as a whole for the reasons mentioned. Also subscription to a developer is a product for them, it has nothing to do with the product they create for others reply pcthrowaway 18 hours agorootparentprevEven if the service can't be delivered indefinitely for a one-time payment, subscriptions as the only option are a hard sell at this point, because most people are feeling the effects of subscription fatigue A 1-year pricing option or 30-day trial with the option to pay up front for a year or a month, without it becoming a subscription is way more compelling to the user than signing up for a subscription that one then has to remember to cancel. I personally subscribe to Amazon Prime and that's it. A service has to meet an incredibly high bar for me to consider a subscription, and I wouldn't have considered it with Amazon until after they had set up their global prime delivery infrastructure/network and video streaming service. I'm not going to give my credit card to a company that makes picking out a recipe slightly easier to keep on file, that's a ludicrous proposition. reply prmoustache 12 hours agorootparentprevThe point of commercial software shouldn't to satisfy the need of their developpers to get paid for it but to reach that intersection where it is useful enough for many users to accept paying a decent price for it and allow dev to make a profit. If that intersection is unreachable in the first place, there is just no sense to mention maintenance costs. reply tourmalinetaco 9 hours agorootparentprevSo don’t be inept and make a web service out of what can and should be local-first. reply fsckboy 15 hours agoparentprevI'd like to see a new subscription model emerge: some base price quote. then, the more I use it, the cheaper it gets, or at least never \"the more expensive it gets\" (in this way we can get tiers, but it's not quoted as screw-you plan) and, I stop using it, I stop paying If the base price is attractive to try, put in my credit card and try. If I keep liking it, I keep using it, if I don't, I don't. It's what we all want, just give it to us. reply ccozan 6 hours agorootparentusually called \"pay by use\".... tinder does that: you get free swipes. and fill in the top and bottom with relevant ads. You go premium...well then depends. But I have to admit, a food matching app with this approach would be strange since the person I am truing to match is know to me and possibly living in the same place. I would personally open a chatGPT session and tell what I have eaten today or this week and should suggest from the history when I need it. reply reddalo 11 hours agoparentprev> $10 one time purchase I miss when good apps were selling for $2 on the app stores. reply mocamoca 19 hours agoparentprevThere are servers needed for the app to work, right? So I guess subscription makes sense? Of course then there is the price of the subscription... But I'm talking about the model, not the cost. reply wfleming 19 hours agorootparentThe trouble is the justification of a subscription is evaluated differently by businesses and customers, and both perspectives are rational. If you’ve got servers to pay for, subscriptions are a very appealing model since it makes the “is this business sustainable” math very easy (and less charitably lots of businesses are after that sweet sweet subscription revenue because it tends to be sticky). As a customer, I think it’s also very reasonable to get annoyed that “everything is becoming a subscription” and say “why would I pay this much for something I might need once in a blue moon.” reply Diti 9 hours agorootparentprevOP mentioned this is a “simple app”. They should follow the example of the author of parcelapp.net, which charges less than 5 EUR a year. That’s 50 k€ per year (judging by the ten thousand of reviews (4.8/5 star average) on the Apple App Store. Without taxes, of course. More than enough to pay for server costs. reply latexr 2 hours agorootparentWorth noting that Parcel used to be a one-time purchase, and those who bought during that time are grandfathered in with a lifetime account. reply OJFord 19 hours agorootparentprevGP did say they understand why. Doesn't mean it's compelling from the other side. 'Pay for what you use' (micropayments?) seems under-explored outside of cloudhosting to me. Some small cost per meal solves the same problem while seeming more reasonable (or more obviously reasonable) to the consumer, doesn't it? reply stavros 19 hours agorootparentprevHonestly, the servers an app like this would need would be a $3/mo VPS. I'm not arguing about the price, the author can charge whatever he wants, but I don't think he'll get many customers that way. It's a good thing that the server requirements are minimal. reply bigiain 17 hours agorootparentprev> There are servers needed for the app to work, right? But why? This is described as \"a simple app, in which we listed all the recipes we ever prepared, and it would propose randomly three of them. We would then choose together one of them.\" You could, if you chose to, built/architect that in a way that doesn't require a backend at all. You can use deep link URIs to send a _lot_ of data in a link in an email (like literally gigabytes on iOS). Easily enough data to send each other newly added meals/recipes. You could also encode recipes in QR Codes, so one person enters a new recipe and the other can scan a QR Code the app generates to grab it - you can get about 4kb into a high density QR Code that'll read reliably off a phone screen. Use one of those to maintain the whole meal/recipe database on each device, no backend required. Maybe use a date based PRNG so both ends will pick the same \"three random recipes\" every day. Send messages between apps as emails with deep links in them, so one user can use the native iOS \"share by email\" widget to send a \"hey, what do you want for dinner\" email, with an app generated message with three deeplinks, one for each random choice. Recipient responds by tapping the deep link for their recipe choice, which opens their version of the app - and the app digs the data out off the deeplink URI to pres3ent a \"share your choice\" button that also uses the native iOS \"share by email\" widget to send the response back to the first user. Tapping links in emails and sharing via email isn't as \"nice\" as an app with a centralised database and push notifications, but it also has zero ongoing cost to run and you know for sure the developer has no lever to enshittify the service, and has no user PII or usage data to sell to surveillance capitalists. Hmmm, I wonder if you could do this entirely as a web app? reply jhanschoo 18 hours agoparentprevFor stuff that I'm not sure that I'm going to continue using, I subscribe, then immediately cancel. reply paulddraper 18 hours agoparentprevThe HN crowd isn't going to like it, but this is the perfect one for ads. Perfect. reply spamtarget 17 hours agorootparentI hate ads, but you're actually right in this case. If done with moderation and purpose—like the YouTube videos that promote a high-quality cooking ingredient while meaningfully explaining why it’s better—it could work well. reply philipwhiuk 9 hours agorootparentprevOr, commission from ordering items from the recipes via local stores. reply bossyTeacher 19 hours agoparentprevUnfortunately, the Apple Developer account is not a one-time purchase and neither is the recurring payment to keep the server used by the app. People need to stop expecting one-time payments for online services reply Kwpolska 19 hours agorootparentSkip the Apple tax and build a web app. A simple web app like this should not cost a significant amount of money to host. reply snthd 18 hours agorootparenthttps://whatthefuckshouldimakefordinner.com reply wonderwonder 17 hours agorootparentThis was just great. I laughed. Then I got hit with 753 ads and stopped laughing. But still pretty fun. reply CrazyStat 19 hours agorootparentprevMy favorite restaurant’s rent isn’t a one-time purchase either but they still manage to sell me a meal without an annual subscription. reply amelius 18 hours agorootparentBad analogy. You keep paying the restaurant for every meal, whereas you would pay only once for the app. reply ryandrake 3 hours agorootparentA better analogy is the usual \"car\" analogy: I bought my car in cash as a one time purchase. Even though Toyota needs to maintain their network of dealerships and service centers, finance their factories' operations, and pay their employees, I still don't have to pay a monthly subscription for the car (yet). If I drive it, I pay to put gasoline in it and maintain it every so often, and that's it. If I don't drive it, it sits in my garage and I don't have to pay monthly for it. This idea that customers should need to pay for all of a business's business costs and overhead as the overhead happens is a new one, and an annoying one. reply CrazyStat 18 hours agorootparentprevThe argument I was responding to was “The developer has ongoing costs therefore the user can’t expect not to have ongoing costs.” I might eat at a restaurant only once. reply fkyoureadthedoc 18 hours agorootparentYou'd rather pay every time you use it? reply CrazyStat 18 hours agorootparentIf the price was reasonable (less than ten cents in this case), absolutely. reply fkyoureadthedoc 5 hours agorootparentI don't think you can charge so little. You'd probably have to buy some amount of runs in bulk. Another alternative would be you buy access for a block of time, but not an auto renewing subscription. Mullvad VPN works like this, I have to go into the app and re-up if I want to keep using it every month. However I think this type of app should be a one time purchase anyway. Looks to me like it could work without any server / hosted infrastructure. reply Y_Y 18 hours agorootparentprevThis is actually a great idea. Lots of subscriptions just pay for a thing to be available. Netflix will tell you \"sleeping giants\" who never watch are ok, because the content was made available, but I think that's BS. I'd love to see a system where you're only billed on the months that you use it. Or even just charge me a dollar per use with a monthly cap of ten after which the rest of the month is free. reply vinckr 18 hours agorootparentprevHaving to eat food is a lifetime subscription. I guess the point is you would pay for the app once, but visit the restaurant multiple times. I think something like a small initial fee plus donations to keep it running would be good for such an app as this. reply icemanind 18 hours agorootparentprevYou should have started the app on an Android first. An Android developer license is only a one time $25 fee. Once you build it on Android, you can gauge the response and determine how much to charge on other platforms. And build it using a build once, deploy many framework, such as React Native or Flutter, that way porting it to any device would be a sinch! My piece of advice. reply fkyoureadthedoc 18 hours agorootparentI remember reading years ago that people were much more likely to pay for apps (outside of games) on Apple vs Android. I wonder what the current distribution looks like. reply miyuru 9 hours agorootparentprevwhy even have a android app? just build it on the web. on the plus side everyone can use it on any device they would like. reply bravoetch 19 hours agorootparentprevIt's almost like so many things are broken at every level... reply dvngnt_ 19 hours agorootparentprevonline services do have inherent costs that need to be paid especially for products that provide value. i do wonder if for new products they should opt for a webapp instead which would negate the apple/google tax and it would allow android users to also try reply yreg 16 hours agorootparentprevApple dev account costs $99/year. Do you really need to recoup that from the first 6 customers? (5 + 1, since one has to pay for the 15% Apple cut.) reply WaylonKenning 18 hours agoprevFor a marketing app like this, really the people paying should be the restaurants. They pay a bit of money, they appear a bit more often, and a bit more at the beginning of the list of dishes displayed. Cool idea and makes a lot of sense! Also should consider what was selected last time - a bit of a predictive algorithm would be useful to start providing towards my likes a bit quicker. reply passwordoops 18 hours agoparent\"which we listed all the recipes we ever prepared,\" Where are the restaurants in this? reply metalman 9 hours agoprevas a foodie,with hypoglcymia, who also trained under the best chef in Canada,amongst other excellent food teachers, what would take sn application to the next level would a further evaluation of the users physiological state so; when my blood sugar bottoms out, I can EAT and need a fully balanced meal,and I have learned to look at my hand ,vibrating or trembling as a proxy for hunger and this is something a phones accelerometer could detect and use as data for recipie suggestions, and in my case I have to eat something before I can cook a meal ,so go into a whole menue sugestion I dont need or would use such an app, as I invented food,but I can see how it could be very helpfull,especialy in a busy family situation with diverse diatary requirements reply jayd16 18 hours agoprevWhy is it not called Dinnr? reply tesch1 18 hours agoparentDinder reply huhtenberg 5 hours agorootparentNot bad, esp. given that \"dinde\" is \"turkey\" in French. Turkinator, basically. reply sqeaky 16 hours agoprevIsn't this taking something that should be relationship building and outsourcing to an app? How long can a relationship last when people refuse to settle the littlest of disagreements like rasonable adults? reply Johnny555 14 hours agoparentDeciding on dinner needn't be a disagreement, it's just another task that needs to be done in a relationship. reply rendall 16 hours agoparentprevI don't see it that way. It's a potential tool that adults can use together, like a bulletin board or index cards or pen and paper. reply passwordoops 18 hours agoprevNeat idea, but I have to echo the negative sentiment on the subscription. I get there are costs associated to running an app, but this is not a problem-solution I would pay for. Hopefully you do find a demographic who will. Good luck! reply cvburgess 6 hours agoprevThis is an awesome app that my partner half-joking had been asking me to build for years. Glad to see someone actually made it! reply strken 20 hours agoprevThis is not limited to the app under discussion, but how well do iOS emulators and compatibility layers for Android phones work? Are they anywhere close to as good as, say, Proton and Wine? reply nighthawk454 14 hours agoprevHey, just wanted to say nice app :) Lotta people talking about broader app/subscription ecosystem issues, which hopefully you can take as off-topic to your specific project. Making a cool useful thing and putting it on the internet is great, cheers. reply lucasllinasm 19 hours agoprevIs there a way with which you could expand the number of recipes available? You have a set of ingredients at home (or easily purchaseable)—an evolution of this app could have you tell the app \"look, I want recipes that use any of these 45 different ingredients, what recipes have we never tried?\" And it has access to some big database of possibilities. reply nritchie 19 hours agoprevNice idea. It would be great to plan a week's menu using something like this. Currently, we alternate weeks and it ends up being one week of the same 6 recipes and one week with slightly more variety. Then there is the kids who won't eat 80% the foods we'd like to. :-( Tough to please everyone. reply android521 10 hours agoprevThere is an idea like this coming out every year and they mostly failed. I think it is described in one of pg essays. reply justinl33 19 hours agoprevI've seen people pay a yearly subscription for much less, so I'm not going to comment reply yaomtc 15 hours agoprevAny plans to extend it to the other 60% of smartphone users? reply netdevnet 9 hours agoparentIt's no secret that Android users are money tight compared to Apple users. It makes sense to start on iOs and gauge subscribers before spending additional resources on making another app reply kiru_io 11 hours agoparentprevDev here: that is on my to-do list, once I fixed the most common bugs in the ios version, I will start with the android version. reply nextcaller 18 hours agoprevThink of a pun and pay for a Shark Tank ad, they'll love the idea reply hi_hi 9 hours agoprevI was really hoping this would be a thing that gave you home cooked meal recipes, for normies. Not the bullshit \"I fancy myself as a chef and want to brag about how much effort i put into my family dinners\" kind of recipes, but the \"oh my god, I'm so brain dead after a day at work, what can I throw together that is healthy, tasty and relatively simple\". Where are those recipes? Like ones that Kenji does, but without having to do everything from scratch because I'm lazy and would forgo some amount of taste for pouring a packet or jar of something over some other, more fresh, stuff and cook it for 30 minutes. Thats real person minutes, not \"Jamie Oliver, this has been timed to perfection by a team of 10 pro chefs who spent 5 days tweaking everything so I could rock up infront of a camera and make it look effortless\" minutes. Oh, and while I'm at it, if you could also make these recipes palatable to my 8 yo child so I don't have to cook A WHOLE OTHER MEAL while brain dead and lazy, I would happily like and subscribe and even pay the equivalent of my Netflix subscription. Thank you. reply ata_aman 19 hours agoprevIt would be cool to be able to see what the other person has already swiped on or \"favorited\" so I can just look at that first to see if there is anything there I can immediately swipe on. reply scotty79 18 hours agoparentThat costs extra on tinder. reply wildekek 11 hours agoprevThis would make sense as a Mealie extension. You have a content (recipe) bootstrapping issue. reply xttjsn 19 hours agoprevIt crashes on my first three attempts after setting up the family code so I will probably not give another try :( reply cork0plent3 17 hours agoprevFunny, there was something called \"Why Don't We...\" back in 2010 where people would post dates they wanted to go on. It was a lot of fun because dates were inventive and noval and it's how I found my current life partner. reply zacharybk 16 hours agoparentThat’s fun, what did you do on your first date? Ironically, there was also one called how about we. reply xttjsn 19 hours agoprevIt crashes on my first 3 attempts after setting up the family code, so I’ll probably not try it again. reply 0b01 20 hours agoprevFor me I like to use a tournament tracker. reply excalibur 14 hours agoprevDoes this only work for two people? Some of us have significantly larger households. Not that we're on iOS anyway. reply djbusby 19 hours agoprevUrbanSpoon (again)? reply passwordoops 18 hours agoparentNo. Dinnr (again). reply wonderwonder 17 hours agoprevDo you have to input your own recipes? It doesn't just provide recipes and you can select your favorites? How long does it take for someone to input 40 recipes? I feel like this should essentially just be a cookbook app with a random function call. reply simoncion 15 hours agoparentAre you saying that there's a $20/year subscription fee to put your manually-entered data into this dev's cloud storage and do some simple access control? Is this a difficult thing to programatically do for one's own Apple/Google-provided gratis cloud storage? Even a couple-thousand recipes wouldn't take much space at all, so \"I don't want to hit users' quota\" doesn't seem a good excuse to not do it this way. reply cjoelrun 16 hours agoprevLol. I read the title as Tinder, but they(the girl) decides what to eat. Could work. reply artpi 13 hours agoprevDINDER reply tonymet 18 hours agoprevreally fun idea. one marketing approach would be to use suggestive foods like squash or eggplant. About your girlfriend, she wants you to make a decision. That's why you're ending up in a recursive loop. reply massung 19 hours agoprevWhen my wife and I were dating, we came up with a simple rule: Whoever was driving would mentally pick a place and start driving there. The other - before getting to the parking lot - could pick anywhere else and that’s where we would go instead. We’ve been happily married 26 years now and still follow that same rule for choosing where to eat. ;-) reply BeefWellington 13 hours agoparentAs a companion to this, my partner and I developed a rule that you can't say No to a suggestion without counter-suggesting. It prevents one person continually making suggestions and the other person rejecting everything and giving zero feedback. e.g. (bad): \"How about pizza tonight?\" \"I don't feel like pizza.\" \"Ok then, burritos?\" \"No.\" \"Soup?\" > Frustration vs (good): A: \"How about pizza tonight?\" B: \"I'm not into pizza, but I could go for a burger.\" A: \"I'm not feeling burgers, how about sushi?\" > Continues until agreement reply deathgripsss 11 hours agorootparentA good strategy that works for us is the first person picks 5 places to eat, the second person narrows it down to 3 of the 5 and the first person then decides out of the 3 the place to eat. reply jsomedon 11 hours agorootparentprevThat's really a good rule. It could apply to almost any aspect of life, not only just about what to eat. reply ants_everywhere 16 hours agoparentprevIt seems like the dominant strategy is to always be in the passenger seat and always pick your favorite place. reply airstrike 15 hours agorootparentOnly if you're solving to \"win\" every time, but in relationships you're often solving to also please the other person. Plus people get decision fatigue, so deferring to the other person can be doubly good... but not to the point where you don't care at all where to go, because you still have your standards and soft preferences and some places you'd like to veto entirely... which is why couples often get into this endless dance when deciding something for both. It's true also of deciding what to watch. I've spent 30+ minutes debating what to watch, only to realize we should be going to sleep in just another 15 mins so no we can't really watch anything anymore So over the years my strategy has morphed to making the decision and taking responsibility for making it an enjoyable experience for both reply massung 14 hours agorootparent> I've spent 30+ minutes debating what to watch... This is something I've personally wanted to dive into the psychology of more. Maybe it's just me, but I've noticed that - in the days of streaming and everything being on-demand - picking what to watch is actually very frustrating to me. Quite often, I'd much rather just browse \"live\" TV and stop on something I like. I'd never think to myself \"I feel like watching The Goonies\". But if I'm flipping channels and The Goonies happens to be on - 20 minutes into it - I'll stop there and absolutely enjoy watching the rest of it. I wonder why that is. reply intended 12 hours agorootparentDecision fatigue is part of it. There is probably some research that directly taps into it, I did come across and adjacent research paper - “ New contexts, old heuristics: How young people in India and the US trust online content in the age of generative AI” https://arxiv.org/pdf/2405.02522 The indication is that people consume content online in different modes based on their objectives. Perhaps the mode of consumption for food decisions / streaming decisions is part of the category where we dont want to work very hard to get to an answer. reply blitzar 8 hours agorootparentprevIf you can't beat your spouse whats the point?! reply qwertox 11 hours agorootparentprevSo person B always chooses what person A dislikes the most, until person A recognizes its mistake. reply beAbU 11 hours agorootparentprevEasy enough to solve by making sure partners alternate seats every time. reply zyklu5 12 hours agoparentprevMaybe I am misinterpreting but this is a beautifully crafted bit of wry humour. :D reply m463 16 hours agoparentprevI'm curious how many ways both of you have gamed this system over the years. :) reply massung 14 hours agorootparentHonestly, most of the \"gaming\" comes from (quoting from another response in the thread) decision fatigue. For example... My wife absolutely hates seafood. So, if I don't want to pick I just start heading in the direction of somewhere like Red Lobster and she'll always think of something else rapidly. She'll do the same to me with something like a vegetarian place. What's hilarious is when one of us starts heading somewhere we think the other won't like and they don't change it. We end up eating there and usually have a great time anyway. I've learned to like eggplant that way, and she's started growing more fond of Thai food. reply prmoustache 12 hours agorootparentI guess that stuff can probably only work in US of A. Wherever I am going, regardless of the transport method, there are multiple places where we could go in the same direction. You wouldn't be able to find out wherever one is going until the last minute or so. reply gloflo 11 hours agorootparentCould be a rural place anywhere in the world actually reply tourmalinetaco 9 hours agorootparentprevNot applicable to everywhere in the US, I live in a rural area with 3 population centers that are all roughly equal in distance and each has a variety of restaurants bundled closely, so any counter-ideas would have to come in early or risk wasting time and gas. Although, one could compromise by the driver picking the area and the passenger picking the restaurant once you’re there. reply dylanwenzlau 11 hours agoprevI clicked because I wanted to try this, but it looks like you built your thing inside a particular device manufacturer's closed ecosystem which I do not use, so I cannot try it. Would love to see more web forward tech, or otherwise platform agnostic tech. reply freehorse 7 hours agoparentWhat you say definitely makes sense, but honestly the overwhelming majority of their customers would come from that ecosystem even if it was cross-platform or web-based, so why should they bother? It is hard to imagine many people out of that ecosystem would pay for something like that, which is also why a lot of similarly oriented stuff are restricted there. The whole concept sounds like a kind of \"luxury good\" equivalent for an app. reply tourmalinetaco 9 hours agoparentprevThis. Dedicated apps should rightfully go the way of the dodo. Oh God it’s even got a subscription for it. This app is literally garbage. reply jotaen 9 hours agorootparent> Oh God it’s even got a subscription for it. This app is literally garbage. Can you elaborate on why you think it’s “garbage” when an indie dev is trying to make money off something they created? May I ask what you do for a living? (Just curious.) reply sedansesame 7 hours agorootparentPersonally, I think the pricing issue is related to the web app issue from the parent comment. Even as a free iOS app, there is the $99/year Apple Developer fee, on top of any server costs. Meanwhile, a web app can be used by anyone on any device, and if designed properly, can be hosted for free on a number of platforms. If the goal is to make money from casual users, an indie iOS app is the move. ... But that would not fly for what I presume to be a very large fraction of the HN audience that lives and breathes code. What could have been an interesting and tweakable open source project built in a weekend, sold as a closed untweakable app at a $20/year subscription, only for iPhones? That would certainly be quite a bold sell. reply schnebbau 7 hours agorootparentprevIt's very noble of you to work for free. Oh what's that, you don't? Interesting. reply casta 20 hours agoprevI don't mean to belittle your app, I can't try it 'cause I don't have iOS. We did solve the problem in a much easier way though. We do have 40 recipes we usually cycle through. I wrote them in a spreadsheet and marked them based on who can cook them, if it's brunch, lunch or dinner, quick or elaborate, summery or wintery. Then in another sheet I just create a list of those recipes/dishes picked randomly based on the day of the month. If we start the discussion \"what do we eat tonight\", I can just open the spreadsheet. 99% of the time proposing the option for that day on the sheet gives us closure and we're done. reply thedanbob 19 hours agoparentMy wife does the same kind of thing, except she wrote a whole web app that I host on my homelab server (we're both rails devs). The app keeps track of upcoming meals on a calendar, number of leftover servings in the freezer, ingredients needed for upcoming meals, etc. reply scotty79 18 hours agorootparentWhat an organized person. I just pull stuff out of the fridge and randomly cook whatever I can with it and if there's no good option I go to the store to buy some random things to resupply the fridge. reply aeroevan 19 hours agorootparentprevAn extension or integration with https://mealie.io/ would be a neat thing have (we selfhost mealie but are still building out recipes). reply ozim 4 hours agoparentprevYour spreadsheet has obviously one missing feature - you cannot charge strangers $20 a year for using it. reply prmoustache 12 hours agoparentprevIt is nice to have ideas that you can pick up but being so organized sounds so exhaustingly boring...I would have suggested a deck of cards with recipes that you can pick up randomly. Also, what about that \"who can cook them\" column in that spreadsheet? Obviously there are personal prefs but you guys have the recipe stored, surely anyone can cook it. reply swiftcoder 11 hours agorootparent> Also, what about that \"who can cook them\" column in that spreadsheet? Obviously there are personal prefs but you guys have the recipe stored, surely anyone can cook it. In a very general sense, yes, but people have varying competencies/preferences in the kitchen. Some people have more patience/precision for baking, some people don't think twice about handling raw meat, some people put in the time to learn fancy knife skills and can dice an onion in half the time... I have found it works very well to divvy up the complicated cooking by skill/preference (though obviously everyone in the house can churn out a pasta dish if the need arises). reply prmoustache 11 hours agorootparentFunnily enough me and my partner are coming from very different countries and culture so for the same name of recipe we do it completely differently and we love discovering how our each one of us would do one thing. Also we like to do things together as well so some days cooking becomes a teaching workshop on how to prepare a dish specific to one of our countries of origin and I can now prepare stuff pretty much as well as any local of her own country. She often joke I should obtain the passport because of that ( and for adopting their way of swearing ). Having said that you have a point about handling raw meat. reply crossroadsguy 16 hours agoprevThere is absolutely ZERO case for a dedicated app for this thing - a web app is 'more than' more than enough. Glad to see a subscription fee. Totally makes sense. Without that I could not have stomached it. So very venture capital - solving real world problems, one subscription at a time. Nice. reply pvg 7 hours agoparentPlease don't post shallow dismissals, especially of other people's work. https://news.ycombinator.com/newsguidelines.html reply dcrazy 11 hours agoparentprevI have no idea what you’re on about. The early iPhone App Store was full of apps like this. Someone who liked writing apps would scratch an itch and make it available to the world. Then venture money hit the app stores and it became a race to snarf up address books and precise locations with free apps that extinguished not just the craftsman iPhone developer, but also sucked all the oxygen out of the indie Mac ecosystem too. reply Kwpolska 10 hours agorootparentThere's nothing wrong with writing an app to scratch your itch. But this app could be a web app, and I don't see any value in it being a subscription. The cost of hosting something like this is so minuscule that I'd make it free and just eat the cost if I were running it. reply satvikpendem 8 hours agorootparentI'm not gonna use a web app with any frequency, especially when I'm already in the car deciding where to go and thus have to use my phone. Web apps are notoriously terrible on phones compared to computers. reply laniakean 8 hours agorootparentprevThey could also use something like wifi-direct and transfer data between devices reply netdevnet 9 hours agorootparentprevDo you regularly give away money just because it is a minuscule amount? reply tourmalinetaco 9 hours agorootparentprevI would have made it a locally hostable PWA so I don’t have to worry about hosting to begin with. reply asynchronous 14 hours agoparentprevAgreed wholeheartedly- must be a SV trained individual. reply dankwizard 20 hours agoprevPutting this behind a subscription is crazy. reply bravoetch 18 hours agoparentThe outcome of venture funded business models. Before this, we solved a problem for customers and collected a markup or fee. And now the problem we solve is 'when can VC get their money?'. There's no incentive to solve problems for anyone except VC, and you have to convince the customer to give up money, or attention (for growth!). Until this changes, we end up with 'what's for dinner' apps that do almost nothing while wanting an annual subscription fee. Funny to see people posting 'but servers cost money'. That problem is created by the app. reply cageface 15 hours agoparentprevThis is the unfortunate reality of the app business today. Without constant ad spend it's very very difficult to acquire new users. And constant ad spend is of course not possible with a low one-time payment for the app. reply simoncion 15 hours agorootparent> Without constant ad spend it's very very difficult to acquire new users. If you're not VC funded, who gives a fuck how many users you have or how quickly you get more? Unless the cost of whatever backing online resources you need doesn't scale fairly closely with the number of users you have, the only thing number of users matters for is the size of the check you get at the end of the year, rather than the profit percentage from that check. reply asutekku 13 hours agorootparentIf you want to make a living with apps, you kind of have to advertise. reply bentt 17 hours agoparentprevLocal grocers could just pay for advertising or placement space in such an app. reply hanniabu 14 hours agorootparentThey'd just end up doing both reply dhoe 15 hours agoprevI'm the person most positive about technology of all my friends, and this gets a no from me. A relationship is an endless sequence of coordination problems, and you need to work out a way to do these effortlessly. Defer to the person with stronger opinions, everybody decides half of the time, some quid pro quo, I mean there's just endless ways to solve this in an easier and more fun way than using an app. reply prmoustache 11 hours agoparentYeah the last thing I'd want when we talk dinner with my partner is to both of us grabbing a smartphone and start swiping. reply dmje 8 hours agoprevWeird, unlike everyone else on this thread I just don't see this as a problem to be solved. My wife and I talk to each other (I know, crazy, right?) and one of us suggests something to eat and then we decide. No subscription required. reply bovermyer 7 hours agoprevNeat idea and good execution. However, I would not personally use this, because I plan meals for a full week in advance, trying to arrange for both a style of cuisine and for repeated ingredients. So, I'm not your target audience. reply eliaskg 7 hours agoprevMissed name opportunity: Dinnder reply rhabarba 20 hours agoprev> Tinder, but for couples :( reply stavros 19 hours agoparentIt's not even called Dinder. reply jotaen 9 hours agorootparentWhile that may be a cute pun (but probably also only if you know the “like tinder but for meal planning” backstory), I think their current name is a much better choice overall, as it’s clear and concise on it’s own. reply rhabarba 19 hours agorootparentprevWhat a loss! reply wonderwonder 17 hours agorootparentprevI'm sorry, I'm out. reply aman2k4 20 hours agoprevnext [2 more] [flagged] nicbou 20 hours agoparentThis is barely relevant to the discussion. All your recent comments are a link to this website. reply seu 9 hours agoprevI'm not sure if I'm getting this: people need an app to decide something that can easily be decided by... talking to each other?! reply bungmap 16 hours agoprevnext [2 more] [flagged] yreg 16 hours agoparent>choosy beggars Nobody here wants a discount. No one is begging for anything. People are providing the feedback they were asked for. reply inquisitor27552 19 hours agoprevnext [3 more] [flagged] munchler 18 hours agoparentPlease tell me this is satire. reply inquisitor27552 13 hours agorootparentit isnt, my girlfriend will love it but i donf love her that much to build it reply hkon 20 hours agoprevHave you considered just eating two separate dinners? reply Nevermark 20 hours agoparentAh. An app to find people who want to eat the same thing. reply KaoruAoiShiho 20 hours agoprevActually a great idea reply bmalum 21 hours agoprevNice! Solving this problem with technology. Looks amazing. Well done! reply bmalum 21 hours agoparentAh damn! After joining a Family - it crashes reply glitchc 19 hours agorootparentAfter all, it's an NP-hard problem. reply iamhamm 14 hours agoprevWhat about an app to tell you what kind of sub sandwich to eat? Could call it Grinder! reply casta 20 hours agoprev [–] I don't mean to belittle your app that unfortunately I can't try it since I don't have iOS. We did solve the problem in a much easier way though. We do have 40 recipes we usually cycle through. I wrote them in a spreadsheet and marked them based on who can cook them, if it's brunch, lunch or dinner, quick or elaborate, summery or wintery. Then in another sheet I just create a list of those recipes/dishes picked randomly based on the day of the month. If we start the discussion \"what do we eat tonight\", I can just open the spreadsheet. 99% of the time proposing the option for that day on the sheet gives us closure and we're done. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An indie developer created an app to help decide dinner options, inspired by personal experiences with indecision.",
      "The app initially listed recipes and randomly suggested three, evolving into a Tinder-like interface where users swipe to select meals.",
      "The developer seeks user feedback to improve the app, indicating an ongoing development process."
    ],
    "commentSummary": [
      "An indie developer has launched an app that helps couples decide on meals by swiping through recipe options, akin to the Tinder interface.",
      "The app allows users to input their own recipes and suggests daily options, currently available on iOS with plans for an Android release.",
      "Users have provided feedback, expressing concerns about the subscription model and suggesting additional features like ingredient filters and shopping list integration to enhance meal planning and reduce decision fatigue."
    ],
    "points": 216,
    "commentCount": 188,
    "retryCount": 0,
    "time": 1730667365
  },
  {
    "id": 42039569,
    "title": "Quincy Jones has died",
    "originLink": "https://apnews.com/article/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"apnews.com\",cType: 'managed',cRay: '8dd6f787e8d38726',cH: 'g50asY21ihun.RN1uaRMdqGl26eGvWhboG_KFfM4eV0-1730748084-1.2.1.1-IQ4VSsVZ3s4VAIMPIPYxGZEKpfkWPyGklvvqcN5y.9V1mvwE2kr06DozMQUoTPvw',cUPMDTk: \"\\/article\\/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21?__cf_chl_tk=CLv2i1UCqUiY_kwKTeiiVxFw._SRiA33540YJD.Z5Dk-1730748084-1.0.1.1-CFRTNcC9W5tKPVRnzM4yih_GtJuINST.7DycV5reFk8\",cFPWv: 'b',cITimeS: '1730748084',cTTimeMs: '1000',cMTimeMs: '390000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/article\\/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21?__cf_chl_f_tk=CLv2i1UCqUiY_kwKTeiiVxFw._SRiA33540YJD.Z5Dk-1730748084-1.0.1.1-CFRTNcC9W5tKPVRnzM4yih_GtJuINST.7DycV5reFk8\",md: \"fHWnIxzenbvIB8lcR4ENIPM5ryW8WRdrKeIEwpIgEiY-1730748084-1.2.1.1-Zw5NfZKZFer8AHfiM2kc2mVeubeh8p8MJcNR9rTNaDb7LxuIWNZA3TsCJZBaprtbeKBcUEsPg6g6kYvCSSquYuEPjMfTLgdT3Q3crQxoqjHwS2ahxpa9AMWD2qN4cEaJkzWuq8xJwofhxPBSzX5lWNJVdO5Ro1cHBYznuu0Tlhjc_yolRPvxzfnjz4xYgMkgQKjbdYeoyDToSJhHdm03ImJjgxyrjrAoJ93HIn13xbeJSiYg0Zob5SuKKAFWCVMADsYETp1Cox..QVp3r1yZECrGYzDhppIyHg56Um4s.Xdkg199RPskDiuBsIzL4nEa6l_FGLqIamJFF9aJnKLzyVYMsrT9chzj.5FQva_sbVKxskNvkhzCRrdQD.XOoUaxoymqJ.Gcg.DFicJZHR8kDcNr5TpfCPilbiwlA.EpdXUmMblukpnhNRO7Bp8hxf6tTSuyvEpUCPD6mRDola1gYGns8HJD7ru2JheGJcqd_LGebAoBw4rUvesX2RmRe0pd0gXu05wdxuHcDvpV4bG5jat7J.SLXsLqvrv.ED6UrXeRUAuKI_TOBvYhY6265Od16ncJP5b.YvthzcejNOxN4pTLwCnDJSrIsvrrRoMfSPT59_fjQXhhH8KCvxmOKRUiDXQeQ4pAS4oS1Fr9ImRcnR9E3szTR3oZcFEli0o_4x9sVtOh03WV8t7qt7WvdeWv99fsqz0i_1UaSnb6BRhHb0V9enD4GcSRG5sBd6CcdUIOH5XvLbRfARViMvoJE5aB6E.zy53tmreG546IlFmGq5j0uenLcbXnprtp9..eSCVrTAp0cH.pczXr6LwE6Dmnq3aHcByL2yreom7G7CEWUO7nEJ060p4EhYfrNaCDfws0uT51tX4ZXGaEV3zM8.wMpNRgNake7dQx5PDiNqVpsulxxK803O.3HGB0I8RytRArnAxUJxX3dNNXaV6m9gU1m5hANJCP9BsaMfZZtsm5TNWbfutUL4l7lq5KWylg17i3h4TAlvbNg9FHuWpisqBk6Xj3c0EutlMCbcmaXijhQhLspbDaZXJKTWTDSbo5gMmagz2NXoliSzCI5vCCfJNin6CabBnpyy_Qf8.CstvLPY.tLJu0quGmcu_QWQYUjA68juBvESlyjSXpw8ubstLfh2N2ONkUmfczwlQiZ5IWZH83win6IIT240BR2BArnuBzHJI1tk0urT4d6i3niTQFqpvHNG38v4BCIUziFZqR49JL7O6Mt9wVM65t3s0fdcIFyjO03qqR148Hbjj8cvxu1oBUs98oe20kbcYvK.7hKxMVBp4d6Ylhdihxw2kUBxrfGovmSCTaNFG3V5DEnu7iCr_vYxJ4TCNW4dB23oQUG6DWTBfWs6_HHR7jFl5VxlLac6XZmlcjjEJZkkSmcwF0RhUeR_sOZxfMFqjIeKDq0uiCesN9BZvusUcYCOq18.mYHxJyeqxXV4LNjtwOWQNxCIBLfaYHF7xFZFIzQuvOBgd1m8qMiDrGz9QTeTB6OuMj2SriIa5gMUY6852MPeJf_RimfYWN9Ykxdr.uWfJ7tgeeySs2dwVJH5H7XJB2k4ztDDCpvH1yOeMDMDfk7k95zMciYekJZdvNomqL7nIPw0eAkSxovy3zes0JVdgjehYi5VmPEAdJKhD3oNcZBw1E4zLNXZazYZ1UETuMxb26buwC7ftLOGcSgYyi8FKO7vNd59Z38uHjf2Y09O4OW1T6Kqy1CGVE40jZPHlJ51_..vRiiHuOcxS3TdqjOlAHbCHZtA1tdJcle0kBK89Hww7nVRY79rKXm3gdoFdNKPk.UWQXQmVZcPXKS5nXiw2qIjx044infEskhVPq_LswSVXE_ViW7z.sBFzFX2ovkiQp1dzBLXEXu4cbbA4akP4Mhy4RjuvmeGvJGf6sbCCkn0NrGSzjTvtmMW_A.TdL7M_ASnkrT5MTGfUHQBa9y9tJV8tkor9visYs13FpAPoGrdsLGAB.lKhhgMFRVsDsZGQ6hB3AmUKFoYGakWjHV2lKx8kAw.Be4iTjcEkroO8TdLuRu0lr4dGeqZ6iHGOcfYizO.FeuGz31X2yL82IejVmmdtULrU8CB.OB1RRJlneHFxzWYeB5Jmseue4iZl7zc81G_iO7K168lhXy7HJjxrNNNN6gwvCdOKOOz3RUmOp8euMuI_73Jw9X_Z1U76Fc2u8KE1d0oTGTn0JZjKfZ8Nzz35K6JXEaZ7QruInLmf9qaqd2S6fPL_dFZHMHdvD.nG6xgIFwiTWRpQk0VKZ_XN_cBSLipnz9AsQHlDvm_y3R1jePDZPQExYplLmfPEjoUt6EQKytbxY9UUIuZ5uDcCR9FQFPdlnd47nOwnCdudca8eK4IEwPo.LQhBx5sCNRzRA0aFiwNd2aABBEj6rhnMZWiUvabV4g2ep9Q0qu6JG620gqReeydauTuT.3bnWKOcp26yjxiPRywXs8lokpznudanGaHyXTOoJNReG9OJJrAe_OeZ9Eb0shK.eJ6c_TIcAt.OzmcWliBn4IBH8C2uoxIlfEtbCuOUfBMrDkkLhGTn4dHiZrA5X2MpeSj1zZSIqH0LWyEz.v.AxG_lxbb23kWx7siuZPN7t8IgMrh5VYP6PnB7TsMccoDyh04Pt32wOgA\",mdrd: \"J5rhjbMWJf8kzpFfHO0nI0kmRpZOtH7cipI5KvZzS1g-1730748084-1.2.1.1-6d_upaf8Y77HTyiLEoWg8tIpeM9T3M.I3A6of8o3cE.W4r1pr3RYoJMud5r7wZTPIgW0WaB7IQR45bw.3YrXJ54fMNmjnBMayh8S8vpOs6gPvXtHgWmfYXP9DlXF5bjB8kNNRR0SZbprgEtss7Zc7G1mNFkElOR3G.uSHAK_cdIhTlEErNNEhGqLrsLKeO1eQp3lC6bxrJXOfyGFTK7z9TKHDBPD1BPJUuAV.7Y22hBo0_2dUeS4_TPnV0zpimCJA0hha6wFSiizuQOU8TWl.qX7ehrVPwLeZaBlEQrYZDbV8pdTinfYr0daMWBr97_omHfiz9aXCbkrwobxGdrGYA1Z3RvynlY1Rr.j3eVSrTvq39IsmQwi6YQ7Qm_Bqqe1snvHM0LlCpXsUfLa3WXP1H_CwLwWXHkY7wCW.ruAOs1XoTRNsoz4bgkKMOorf4drAKqbLWOE8b1jjiobMrCtWrdQ1.SlTObepQYnI05pPPZoqYEQD97Oo2dKCYvn9kXq8V3qMhsa_eKOfHelW2MgTp8Faw8_CjCUUuy6xTaK0jEqGo1t4Y0Hv7QO3GIdzcxDTCjh0fWlG6X_aNpK7y_GbnPUwkzcF83Fd4PPMsRyaf.etNS3RKR.vsaLfQSdQQgCk4W7fWyekA8qpv4P5MvZYbwmgiPAG1d0F6QVcBUXr.d4Ca8fcVasXIvJrbO4heN8gimowl8CRtMQRpck2wvVmVC3IeD5CkpQvEaZUiY9u5L.gebqqEAeES0QzjfubzB.R0DMa1Z1GKGMofnCiTcVch0x.V0_zLItLd5OEOU.5DkhqeIPkhuilPm1ai9512tw5P.CahNi.AIb3IQwbOpEoA7c08BUVsyQ5Wdccxz1xHXXSU_Tt4nZr94I5Pprr2xUQoqsT5CltCwFZNnw.E4LGU3ijwED_sECe_FDhjD32Lgg7eDZetPSg6FxtYMNzE0SKWeAgnZKsZ.GBBSvgqXC.s9b.ymM1CZVI3.gxu1Vruql6TqDcR4zHdg8pfSaD9NbP30yBQwwOTy7en_SUKIWOQJsZu_9NTf_DbQ0_7gCCiZ1LqER1aI4Lvb4aXNIMRxqr1yYUWRvJkHTyDSkORVY4ldeCeLiT.v7s8OZkyrlLSuXAsT2KMGtTDEZJYP1Vqx6w2QZymMrYLsVH86hNfv2gFmkNxsQgIQQ8DAmOuqFp6O1KeKb59zViWWsUr7RstrFoDIHeYAhH8UGa6p_wPO4YAOynns21gB3LF8QoWeztQv2kJ_4gEDNrwedl8uCwowE9RfCQ8kVBisFdU0z8TQ2xf0wNQFRhyN1ejdCoX5jHx6tfrcUrSlN4S5skP8mgKYwlUTtj5i1fc9b21lfuRoxL55FyJHZtMz1LuNJeybIT5zIp.jGdPCw44TTzruv4D3A_THbNNpYBLVsWUJAbAovfx5UrmQ.hY.vbfysINZXSH6WYM29.SxPK5_rX.yQQU0YBbyJVYx16KdAnB3Flxzb8swQXDH9BdvfJOKQVqaWmEtTa7nGYZCRlioaUhRQHt.dYOPX_fYfk8r1qNmygvafWjYluuRHrLIZmF8AH5ZjSCJsDFpsYsE1CG_uqRPIZC7vwJYVPtR.VDyOBsJnNBJQGzfO_knO1Rhm_Mn5f3vTYbkvGm9Yc2ch67MLVFmvtWg0d3Q9dRqsuBN52yk2jtlQcdaqkEFilOZGd9xGsVmCybcEllOfNCRMWWs60r4zBdct77b._x3T3z5AVpO9941CfxVSyth61Du7Z0ERlytcx_7DPCDrWQGxoYgAR8004dYpWp0je0_tZ0j_NnZGgCSR39RPM4JFU_y70aYqZO20YxVpMcrOfm.zp8baJ3ETZQ2p4Oxxi4V16SFlkGnUpBZ1Y_3XD.T.rXbUb08RGLxcET7_1FXrsD20J1OtoAJDV4xLkuGnq4SJmibgeH_v3TbX4tpE9Eb81vMGn.pOBc9ogPi_HxytcC2_DKPaoqtQA7B.GyF8DUsoC_kfPrWGaS4DEr5bQAyg.HyptXVxUmcgvJ0Bo2K85qaUvaFwvPZ4dsAsi.1zjDHrg0avXwzoS0FcGUOU_ADECdhhCO6VCvGsEWmMKBMT4YpPhicB6ggG3P_yQoWp8koMJ58w1fS68mZeHQKZPTiQThrGh5B0VxWjgkUc7ERsNqV4JNGBuUHHy03NzT8tSW1.ZLSak9LTG0fP85Me1h1blNmlP7PdS1pkSqS2eop0Wp4dumU1mBTUujt7whnQKaz8IreKeJL1x24qgs2rFqQqSmOBLK2WAgNewKgja6WBFiAeDPIXmsPRFy1QPwUhFZ5tgyDKQb0yMEMgNiMXyy9Gb.JXHi6OgNNnYAuuyy8_jvuvKy5ZtxQQ.mKKAX5l6EXgLQZZsBh0T9mjJw\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8dd6f787e8d38726';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/article\\/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21?__cf_chl_rt_tk=CLv2i1UCqUiY_kwKTeiiVxFw._SRiA33540YJD.Z5Dk-1730748084-1.0.1.1-CFRTNcC9W5tKPVRnzM4yih_GtJuINST.7DycV5reFk8\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42039569",
    "commentBody": "Quincy Jones has died (apnews.com)209 points by gfortaine 11 hours agohidepastfavorite49 comments linguae 4 hours agoAs a jazz aficionado, I am very familiar with Quincy Jones’ immense contributions to music. I am a very big fan of the albums he produced, such as “The Dude” and “Back on the Block.” What is less well known is Quincy Jones’ involvement with computing. At one point he was on the advisory committee for the ACM Computers in Entertainment Magazine (https://dl.acm.org/doi/10.1145/973801.973803), and if I remember correctly, he was on the board of former Xerox PARC researcher Alan Kay’s Viewpoints Research Institute. I’ve been wanting to know more about Quincy Jones’ involvement with computing since I first learned about this a few years ago. Rest in peace. Quincy Jones is a legendary figure. reply jancsika 2 hours agoparent> What is less well known is Quincy Jones’ involvement with computing. Also, he worked on debt forgiveness in African countries. Also, he studied music composition with Nadia Boulanger (who taught Aaron Copland and many other classical composers) and studied harmony with Olivier Messiaen. Also, he wrote the television theme song to Red Foxx's \"Sanford and Son,\" plus a lot of other popular themes. In fact, every time someone is about to get killed in Kill Bill[1], you hear a sample of music written by Quincy Jones. 1: except for Bill. reply aithrowawaycomm 2 hours agoparentprevHere is a cool video of Herbie Hancock explaining his synthesizer / recording computer setup to Jones: https://old.reddit.com/r/OldSchoolCool/comments/sswplq/herbi... reply justin66 2 hours agoparentprev> if I remember correctly, he was on the board of former Xerox PARC researcher Alan Kay’s Viewpoints Research Institute Alan Kay knew him from before then. On Kay Savetz's podcast, one of Alan Kay's researchers at Atari (Donald Dixon) in the early eighties recounted meeting Quincy Jones when he was being shown around the lab. https://youtu.be/q3cwZaofB68?t=1236 reply sourcepluck 2 hours agoparentprevI'd never heard this! Would also love to learn more, wow. Agree that he was a legend, musically speaking. reply theGnuMe 2 hours agoparentprevWow! I too would like to know more about his involvement with computing. Anyone have any pointers? reply noblethrasher 2 hours agorootparentHe was also among a handful of people invited to contribute to a book tributing Alan Kay on his 70th birthday. https://users.cs.duke.edu/~rodger/articles/AlanKay70thpoints... reply brandall10 29 minutes agorootparentHis segment is a fantastic read, thanks for sharing. reply agumonkey 2 hours agorootparentprevI'm just starting digging but here's some to start - https://dl.acm.org/doi/10.1145/973801.973815 reply chriscjcj 3 hours agoprevWhen I was four, I got a record player for Christmas. This one: https://djcj.website/wp-content/uploads/2019/12/denim_turnta... My mom had a copy of Ray Charles' greatest hits. My favorite song was One Mint Julep. Quincy Jones did the arrangement. You can see by the wear on this record how much I listened to that song, as well as \"Unchain My Heart\" and \"Hit the Road Jack.\" https://djcj.website/wp-content/uploads/2020/05/one-mint-jul... So much great music. And when you watch interviews with other musicians with whom he crossed paths, they all talk about what an uplifting and positive influence he had on their lives. Here's a interview with his longtime collaborator Tom Bähler. He has some really beautiful stories about his experiences with Quincy. https://youtu.be/yIkP_XuIDeY?t=5197 And when he got together with Rod Temperton, the magic was next-level. https://www.facebook.com/QuincyJones/posts/ill-never-forget-... reply SoftTalker 1 hour agoparentOh wow, I had that same Sears record player as a kid, not in denim mine had a vinyl covering. Flashback memories! reply kranke155 1 hour agoprev*From a strictly musical perspective, what have you done that you’re most proud of?* That anything I can feel, I can notate musically. Not many people can do that. I can make a band play like a singer sings. That’s what arranging is, and it’s a great gift. I wouldn’t trade it for shit. https://www.vulture.com/article/quincy-jones-in-conversation... reply hn_throwaway_99 1 hour agoparentI recently watched \"The Greatest Night in Pop\" about the \"We Are The World\" recording, and I came away with even more huge mad props for Quincy Jones. The ability to arrange all these superstar musicians with insanely different voices into one cohesive, melodic song is amazing. Not to mention that corralling all these diva personalities makes cat herding look like a cake walk. reply giraffe_lady 1 hour agoparentprevWhat a fucking flex lol. I have rudimentary arranger skills, enough to understand the pain of simply not being capable of expressing something I can feel/hear internally. He really could do that on a level that very few people ever have been able to. Legend. reply JohnBooty 1 hour agorootparentWhat a fucking flex lol I don't have a link handy but another hilarious thing to look up is Quincy talking about the Beatles' (lack of, in his opinion) chops I love the Beatles but it's endlessly hilarious to me reply tarkin2 29 minutes agorootparentI looked this up on YouTube. It seems a bit of a non-controversy with Quincy criticising Ringo's skills and Paul's bass playing. Comparing a virtuoso arranger and a band whose main strength was their song writing skills is a bit of a non starter honestly. reply jakedata 2 hours agoprevHe is a man who might be considered the musical godfather to perhaps millions of children throughout the years. He sure could set a mood. reply grugagag 3 hours agoprevBrilliant guy. Let’s hope we haven’t killed the elevator to climb those heights. We’re living strange times, currently it seems to me the age of great men is slowly fading only to be replaced mediocrity and simulacra. Of course I have no idea how it will all play out but hope for the best. reply dk1138 47 minutes agoparentMusically, he's done a lot to encourage and surround himself with brilliant younger artists. Jacob Collier had received tutelage and consult from Quincy and Jacob is a Mozart-level mind of our generation. reply racl101 2 hours agoparentprevDon't worry we still have Mark McGrath from Sugar Ray. reply justin66 2 hours agorootparentI wasn't ready to despair but now I am. reply drooopy 4 hours agoprevOff The Wall, Thriller, and Bad. What an incredible run for both Quincy Jones and Michael Jackson. reply kevin_thibedeau 4 hours agoparentThat was his middle stage career. Gems like 'Sinatra at the Sands' are worth a listen for his talented arrangements. reply agumonkey 2 hours agoparentprevIt's strange to realize how sophisticated \"pop\" music was at the time. Lots of beautiful harmonies, violins .. reply giraffe_lady 1 hour agorootparentI liked pop then and I like pop now, and I liked it the whole time in between, and I don't think you can say pop is less sophisticated now. The conventions of the genre have shifted because of communion with rock, hip hop and electronic dance music. But violins are just an instrument, no more sophisticated or less than any other arrangement choice. Now the complexity is in the rhythmic interactions, and the timbral palette available to producers. The musicality of pop musicians and especially studio performers and producers is just unreal right now. reply agumonkey 1 hour agorootparentLink me some stuff worth listening too, I stopped scanning the recent music releases because most of it (except a few exceptions) felt like soup. reply dvirsky 39 minutes agorootparentDua Lipa has amazing arrangements for example. There is a great podcast called Switched on Pop, which delves into music theory behind pop hits and their songwriting and arrangements, and analyzes them to show what makes them great. It will give you fresh perspective on how much thought and talent goes into some of these songs. https://switchedonpop.com/ reply giraffe_lady 44 minutes agorootparentprevSo, not all but quite a few \"radio pop\" artists actually have excellent studio albums, from which the radio singles are basically the worst songs. Like ariana grande had an incredible three-album run with dangerous woman, sweetener, thank u next. Dua Lipa's future nostalgia is another one of these, full of popified funk and dancehall grooves. Bass players love that album. So don't write off bad radio pop without giving the album a listen, there's quite a lot of good music hidden in plain sight. Other than that some of my favorites from the last approximate decade in no particular order (in format: album - artist) are froot - marina and the diamonds; I feel alive - TOPS; shabrang - sevdaliza; unfortunately, terror jr - terror jr; take me apart - kelela; somewhere in between - verite; dogviolet - laurel; empathogen - willow; expectations - hayley kiyoko; once twice melody - beach house; the fool - ryn weaver. Pop is hard to define as a genre, particularly it tends to blend into r&b and indie rock so some people might categorize some these differently. And most are \"indie pop\" but afaict that's just pop by non-famous musicians. That ryn weaver album is probably the best in the list, it's a monster masterpiece that deserves to be more widely known. reply agumonkey 3 minutes agorootparentI'll take a peek, but i'm surprised, I stopped caring (pun slightly intended) about dua liap around future nostalgia. There's some nice bass in it but it's crude. The recent willow single was interesting that's true. Only people that manage to give me a sense of depth were thundercat/knower, benny sings But I still miss some of the subtle harmonics from edits like this https://www.youtube.com/watch?v=CXcw2IDxdrE . There are other studio sessions with isolated vocals which afaik are not made this way anymore ps: ryn makes good pop, colorful, but i don't know, maybe a different approach to voicings, it's missing something walthamstow 5 hours agoprevA true titan of all genres of popular music. The documentary made by his daughter Rashida Jones is very, very good. I'd recommend it to anyone. reply teeray 4 hours agoparent> The documentary made by his daughter Rashida Jones I just watched Parks and Rec for the first time last month and didn't make the connection that she is his daughter. reply mastersummoner 4 hours agorootparentIf you ever listen to Rashida speak, she's one of the most incredibly eloquent people I've heard. Pipe dream for me to ever be as well-spoken as she is. reply drooopy 4 hours agorootparentprevHer mother is Peggy Lipton, aka Julie Barnes from the Mod Squad / Norma Jennings from Twin Peaks. reply triceratops 3 hours agorootparentprevTo be fair Jones is a common family name. I didn't connect John David Washington to Denzel until I looked him up. reply _sys49152 2 hours agoprevId go with \"The Secret Garden\" from 1989's Back on the Block Album if youre looking for something different. Quintessential 'quiet storm' track. reply lproven 4 hours agoprevI loved this interview, when he was 84 and clearly DGAF any more. https://www.gq.com/story/quincy-jones-has-a-story reply ansc 3 hours agoparentHe really was a gem. Here's my favorite interview of all time with the same vibe: https://www.vulture.com/article/quincy-jones-in-conversation... >Marlon Brandon used to go cha-cha dancing with us. He could dance his ass off. He was the most charming motherfucker you ever met. He’d fuck anything. Anything! He’d fuck a mailbox. James Baldwin. Richard Pryor. Marvin Gaye. >He slept with them? How do you know that? >[Frowns.] Come on, man. He did not give a fuck! You like Brazilian music? reply MaxPock 2 hours agorootparentMy favourite What were your first impressions of the Beatles? That they were the worst musicians in the world. They were no-playing motherfuckers. Paul was the worst bass player I ever heard. And Ringo? Don’t even talk about it. I remember once we were in the studio with George Martin, and RingoJones arranged a version of “Love Is a Many-Splendored Thing” for Starr’s 1970 solo debut album Sentimental Journey, which was produced by the Beatles’ frequent collaborator George Martin. The song, and album, are more than a bit gloopy. had taken three hours for a four-bar thing he was trying to fix on a song. He couldn’t get it. We said, “Mate, why don’t you get some lager and lime, some shepherd’s pie, and take an hour-and-a-half and relax a little bit.” So he did, and we called Ronnie Verrell, a jazz drummer. Ronnie came in for 15 minutes and tore it up. Ringo comes back and says, “George, can you play it back for me one more time?” So George did, and Ringo says, “That didn’t sound so bad.” And I said, “Yeah, motherfucker because it ain’t you.” Great guy, though. reply lproven 1 hour agorootparentprevYou missed out the bit I liked: > But you know who sings and plays just like Hendrix? > Who? > Paul Allen [The Microsoft co-founder and multibillionaire has a collection of yachts and guitars to rival the world’s finest, both of which he apparently makes good use of...] > Stop it. The Microsoft guy? > Yeah, man. I went on a trip on his yacht, and he had David Crosby, Joe Walsh, Sean Lennon — all those crazy motherfuckers. Then on the last two days, Stevie Wonder came on with his band and made Paul come up and play with him — he’s good, man. reply racl101 2 hours agorootparentprevdayum that was weird to learn. reply inferiorhuman 2 hours agorootparentprevOh yeah, Sérgio Mendes died recently. reply fredsmith219 1 hour agoprevAn amazingly talented person. reply moomin 1 hour agoprevFirst African-American to be nominated for Best Song at the Oscars (not the first winner, that was Isaac Hayes for the obvious.) Guy who made Michael Jackson and Will Smith megastars. And a LOT more. He was one of the most talented people of his, or frankly any, generation. reply wiz21c 3 hours agoprevsoul bossa nova ! reply bewaretheirs 2 hours agoparentAs performed on the David Letterman show: https://www.youtube.com/watch?v=CLQ7xYnyIBQ You can see a few shots of the Cuica -- the drum(!) that makes the high-pitched squeaky monkey noises. And for fans of video game music: that song inspired this little bit from the 8-bit big band: https://www.youtube.com/watch?v=v6hJvSkVLXs reply kridsdale3 1 hour agorootparentThank you! I collect variants of the Wii Shop song on various platforms, its one of my favorite songs from gaming and certainly my favorite dedicated-to-a-single-ui arrangements of music in software. The Wii interface was a high watermark of style. Nintendo was clearly riding high aping aspects of Apple style in the 2000s but adding all the audio personality made it their own. Others were also invested in making something unique for the TV as an interface paradigm (Xbox 360 Blades, PS2/3 \"orchestra\" themes). Most of that has died away for practicality (and maybe accessibility) sake now, to flat boxes with minimal animation and no sound. I looked it up, and all the Wii system audio was done by the same composer that did Pikmin, as well as dozens of other core (but secondary) Nintendo IP over the decades. reply mr90210 1 hour agoprevI got reintroduced to Quincy by The Weeknd and later by the great Francis Albert Sinatra a.k.a Frank Sinatra. reply sirolimus 2 hours agoprev [–] Who is quincy jones? reply rootusrootus 1 hour agoparent [–] https://en.wikipedia.org/wiki/Quincy_Jones reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Quincy Jones, a legendary music producer, has passed away, leaving a significant impact on pop, jazz, and other music genres.",
      "Beyond his musical achievements, Jones contributed to the tech industry by serving on the advisory committee for ACM Computers in Entertainment Magazine and the board of Alan Kay’s Viewpoints Research Institute.",
      "His legacy includes mentoring artists like Jacob Collier and contributing to social causes such as debt forgiveness in Africa."
    ],
    "points": 203,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1730708025
  },
  {
    "id": 42036305,
    "title": "Why systemd is a problem for embedded Linux",
    "originLink": "https://kevinboone.me/systemd_embedded.html",
    "originBody": "Kevin Boone Home Contact CV Software Articles 🔍 Why systemd is a problem for embedded Linux The Internet is full of rants about systemd, and I don’t want this post to be another one. Many of the complaints people make about it don’t stand up to much scrutiny, even the technical ones; and many complaints are not even technical. My particular interest in Linux is primarily for embedded applications; and there, I suggest, systemd is creating a potential (technical) problem. In this article I will try to articulate what the problem is; but I have no solution to offer. Recapping the last ten years systemd is a set of integrated applications concerned with system management. It replaces not only the traditional init process that brings up long-lived processes, but also much of the other system infrastructure: user session management, device management, logging, timing, and an increasing number of other functions. The majority of Linux users are uninterested in the pros and cons of systemd. A small number are violently opposed to it, and a small number are violently opposed to those who are opposed to it. Nevertheless, most mainstream Linux distributions have adopted it after a shorter (Fedora) or longer (Debian) period of argument. I think there’s little argument that the main target for systemd is a general-purpose computer, with a modern, integrated graphical desktop (Gnome, KDE). systemd does well in systems like this because it can handle process initialization on demand and in parallel. This potentially makes boot times faster, and keeps resource usage down, because it isn’t necessary to start a lot of services that are used only occasionally. I don’t think these advantages are the main reasons for systemd’s widespread adoption (see below), but they’re certainly important. Embedded Linux: the problem Unfortunately, what makes systemd good for general-purpose desktop applications potentially makes it unsatisfactory for embedded Linux systems. As an illustration, I’ll show some memory figures from the Raspberry Pi 3B that’s currently on my workbench. The board is running the DietPi Linux distribution – probably the best fully-maintained Pi distribution, if you want a minimal system. Although DietPi uses systemd (it has little alternative, as I’ll explain later) it doesn’t necessarily use the full set of components. In fact, a minimal installation of DietPi, for console operation, installs only the systemd service manager (the ‘init’ process), the log daemon, and the udev daemon. This is the resource usage, as reported by top, for the systemd init process (alone) on the Raspberry Pi 3B. PID USER PR NI VIRT RES SHR S %CPU %MEM 1 root 20 0 168144 11404 8592 S 0.0 0.3 systemd init is not a particularly greedy user of memory by contemporary standards – its virtual address space is 168Mb, but only ~8Mb is currently mapped to RAM. That’s about 0.3% of the Pi 3’s 4Gb of RAM. But here’s the same figures for SystemV init, on exactly the same hardware: PID USER PR NI VIRT RES SHR S %CPU %MEM 1 root 20 0 2744 1532 1436 S 0.0 0.2 It’s much smaller. Just to be clear – I got the systemd implementation and the SystemV init implementation from the same Debian ARM binary repository. I haven’t used fiddly compiler optimizations or anything like that, to bias the resource usage figures. Now let’s look at the systemd logging daemon, systemd-journald. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 147 root 20 0 41508 7744 6652 S 0.0 0.2 0:12.05 systemd-jour+ Again, it’s a small, but noticeable, user of the 4Gb RAM. And, for comparison, these are the figures from my own syslogd-lite, which I wrote specifically for embedded applications. PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 117 root 20 0 1976 72 0 S 0.0 0.0 0:00.00 syslogd Note that the memory and CPU usage of this logging daemon are both essentially zero. This is an unfair comparison, in a way, because I wrote syslogd-lite specifically to minimize resource usage, and it has few features. But it shows that it’s plausible to write utilities that target embedded systems specifically, and sometimes it’s necessary. systemd does not do this, and was never intended to. Running a general-purpose software set like systemd on minimal, embedded hardware can’t be expected to be effective. With care, though, a minimal installation of systemd does run on a low-resource ARM board like the Pi 3. In fact, it will run on a board with 1Gb RAM, perhaps even lower. But, as the RAM decreases, the proportion of it occupied by systemd increases. What’s less obvious is the effect on boot time of the use of systemd init. Proponents of systemd argue – correctly, I think – that it decreases boot time in the kinds of system for which it was designed. But on my Pi 3 it increases boot time quite noticeably. That is, the systemd ‘init’ process takes an extra half-second or so to start, compared to SystemV init. Half a second isn’t much, but in an embedded application I actually care about boot time. I couldn’t care less on my desktop computers, because they spend most of their lives suspended. I rarely actually reboot them. The extra start-up time of the init process is the result, I guess, of the additional size and complexity of the systemd executable. It’s about 200kB in size itself, and dynamically links 26 other libraries. SystemV init, on the same hardware, is 40kB, and links only the standard C library. The additional complexity of systemd is not wasted: it’s needed for the additional functionality that systemd offers, in its intended environment. But this functionality is mostly not needed in an embedded application, so the additional complexity of systemd is a cost without a benefit. I’ve found that most of the services that systemd replaces have an alternative that is smaller, and faster to start, in an embedded environment. Unfortunately, some of these services don’t have an alternative any more. So what? I’m not obliged to run systemd on my Raspberry Pi systems and, in fact, usually I do not. I build my own Linux installation, using binaries that I cherry-pick from the Debian repositories, and code I write myself. Most of the binaries work without systemd. Some complain about not finding systemd, but work anyway. Some things don’t work without systemd: the Gnome display manager, for example, as it is built for the standard Raspberry Pi, won’t work. It can be made to work, but you have to build it from source. How long it will continue to work, even if built from source, is open to question. But I’m not going to be running Gnome on an embedded Linux board, so I don’t see this as a problem for my applications. The more fundamental problem is that the people who most like systemd are distribution managers. Sure, there are administrators who like it, and defend it vigorously; but most end users and administrators don’t really care. But for the maintainers of mainstream Linux distributions, systemd is like Christmas. systemd works reasonably well for a whole range of usage scenarios and, best of all, it all comes in one bundle. So a distribution manager doesn’t have to maintain, integrate, and support a whole bunch of system utilities from different sources – systemd provides everything in one huge build. There are just a few Linux distributions that don’t use systemd, and they are not widely used. Maintaining them is difficult, with just a handful of volunteers. All the large, commercial Linux providers have moved to systemd. Only Gentoo and its derivatives (so far as I know) make systemd optional, with fully-supported alternatives. And even Gentoo can’t be made 100% free of systemd – not in practice. Is it even practical to avoid systemd any more? Take, for example, the udev daemon. This service monitors the kernel, and makes configuration changes when devices are added and removed. It’s not an essential part of Linux, but it removes the need for a whole heap of manual configuration. At the time of writing there is no fully-featured udev implementation outside of systemd. The original udev code was absorbed into the systemd project about ten years ago. The Gentoo alternative eudev is no longer fully maintained. At present, if your Linux distribution requires udev, you’re forced to use the version from systemd. This version can be used without the rest of systemd, but it nevertheless does systemd operations. In particular, it tries to communicate with systemd over DBus. This communication (so far) fails gracefully if systemd is not present, but it’s not clear how long this will continue to be the case. systemd is a tightly-coupled set of services. I don’t think a design goal of the systemd maintainers is to make its components modular. udev doesn’t need to talk to systemd but, clearly, there’s some benefit to its doing so in a systemd installation. I understand that there was a kind of ‘gentlemen’s agreement’ between the systemd maintainers and the Gentoo maintainers, to keep udev independent of the rest of systemd. I think we can see that this agreement has broken down a little already; I suspect it will break down more, if the systemd folks think that tighter integration will make systemd work better. Many parts of systemd continue – for now – to have non-systemd alternatives. For example, systemd has a clock synchronizer systemd_systemtimed. The systemd maintainers are perfectly honest that this software lacks features that exist in alternatives like Chrony and OpenNTPD, and it’s less accurate. systemd_timed is included because it’s fast to start, and satisfactory for applications where exact time synchronization is not critical. At present, Chrony remains widely used, even in some distributions (like Fedora) that use systemd. But with systemd becoming ubiquitous, what motivation will there be to maintain non-systemd alternatives? These alternatives could fall into disrepair, even though some are superior to the systemd utilities – and even the systemd maintainers admit this. Similarly, systemd has a DHCP client. It isn’t the only DHCP client that is available, but my concern is that one day it might be. In my tests, I’ve found that the systemd components are larger, and slower to start, than the traditional alternatives (where they still exist). Again, this isn’t a criticism of systemd itself – I’m testing them in an environment they were not designed for. So where does that leave embedded Linux? I’ve found that many systemd components are less effective in an embedded environment than the traditional alternatives. I’ve shown some illustrative examples in this article, but I really don’t think there’s much controversy here: this simply isn’t the environment that systemd was designed for. But it’s getting increasingly difficult to find a mainstream Linux distribution that doesn’t use systemd – even Raspberry Pi distributions use it. As systemd absorbs more functionality into itself, there’s going to be little motivation to maintain alternatives. After all, if everybody uses systemd, what motivation is there to support anything else? My concern is that we’re moving towards a future where Linux is inconceivable without systemd. That will be a problem for those environments where systemd really doesn’t shine. I wish I knew the solution to this problem. There’s no point complaining about systemd, because distribution maintainers have grown to like it too much. And, in any event, well-reasoned, technical concerns are drowned out by all the ranting and conspiracy theories. All we can do – if we care – is to continue to use and support Linux distributions that don’t insist on systemd, and stand ready to develop or maintain alternatives to those bits of Linux that it absorbs. Categories: Linux Last update Aug 01 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42036305",
    "commentBody": "Why systemd is a problem for embedded Linux (kevinboone.me)200 points by synergy20 21 hours agohidepastfavorite247 comments jcalvinowens 19 hours agoI couldn't disagree more: I've worked with lots of embedded devices running systemd, and it solves many more problems than it introduces. The community is also quite responsive and helpful in my experience. I won't pretend there aren't occasional weird problems... but there's always a solution, here's a recent example: https://github.com/systemd/systemd/issues/34683 Memory use is irrelevant to me: every embedded Linux device I've been paid to work on in the past five years had over 1GB of RAM. If I'm on a tiny machine where I care about 8MB RSS, I'm not running Linux, I'm running Zypher or FreeRTOS. reply Aurornis 15 hours agoparent> every embedded Linux device I've been paid to work on in the past five years had over 1GB of RAM. If I'm on a tiny machine where I care about 8MB RSS, I'm not running Linux, I'm running Zypher or FreeRTOS The gap between “over 1GB of RAM” and 8MB RSS contains the vast majority of embedded Linux devices. I, too, enjoy when the RAM budget is over 1GB. The majority of cost constrained products don’t allow that, though. That’s said, it’s more than just RAM. It increases boot times (mentioned in the article) which is a pretty big deal on certain consumer products that aren’t always powered on. The article makes some good points that you’ve waved away because you’ve been working on a different category of devices. reply cyberax 14 hours agorootparent> The gap between “over 1GB of RAM” and 8MB RSS contains the vast majority of embedded Linux devices The gap between 16MB RAM and 64MB RAM doesn't exist, though. Literally doesn't, the components have the same cost down to a cent in the BOM. And if you can have 64MB, then there's systemd's own true memory use (around 3-4MB) is completely immaterial. reply 1oooqooq 9 hours agorootparentexcept thanks to availability crisis hitting the industry for the past decade you have to go with the 4mb sometimes just look at wifi routers. in the usa and China they are all sold with 64 or 128mb ram. south America and Europe they are all 16 or 32 for no clear reason. reply sph 9 hours agorootparentDo you have some examples? I have a very hard time imagining a modern Wifi router supporting the latest standards and IPv6, admin web interface and so on running on 16 MB of RAM. I also have issue with \"wifi routers in Europe are all 16 or 32 MB of RAM\". In what decade? My ISP provided router also does VPN, VoIP, mesh networking, firewalling, and it's towards the lower end of feature set (as it's offered for free and not a fancy router I bought). Are you talking about devices from the early 2000? reply blueflow 8 hours agorootparentMy TP-Link MR3020 from around 2015 only has 4^H 16 MB of ram (4 MB flash) and thus cannot even run OpenWRT anymore. reply bmicraft 3 hours agorootparentThat thing was overstaying it's welcome for two years even then by staying on WiFi 4. 802.11n was adopted 15 years ago. reply mbirth 7 hours agorootparentprevI’ve still got two MR3040. TP-Link hasn’t released any update for them in years. You can run an older version of OpenWrt on them, but there’s no real point. These things don’t even support 5GHz WiFi. reply washadjeffmad 4 hours agorootparentI've got a few devices that only support 2.4 B/G. They're not in common use, but using an equally legacy router is the only way for them to connect. reply blueflow 6 hours agorootparentprevDevice with very nice design. I still keep it as decorative even when its a brick. reply tempaccount420 5 hours agorootparentprev2015 was also almost 10 years ago. reply blueflow 5 hours agorootparentSo i guess its a brick now and there is nothing we can do about it. reply bmicraft 3 hours agorootparentUsing something that's already been produced (good) is not the same as selling dead end e-waste that's so underspecced it's barely working new (bad). reply jiripospisil 5 hours agorootparentprev> south America and Europe they are all 16 or 32 for no clear reason I don't know where you're getting your data from but it's clearly wrong or outdated. These are the most often sold routers in Czechia on Alza (the largest online retailer) under $100: - TP-Link Archer AX53 (256MB) - TP-Link Archer AX23 (128MB) - TP-Link Archer C6 V3.2 (128MB) - TP-Link Archer AX55 Pro (512MB?) ... - Mercusys MR80X (256MB) - ASUS RT-AX52 (256MB) https://www.alza.cz/EN/best-sellers-best-wifi-routers/188430... reply jcalvinowens 14 hours agorootparentprev> The gap between “over 1GB of RAM” and 8MB RSS contains the vast majority of embedded Linux devices. Of all currently existing Linux devices running around the world right this moment? Maybe. But of new devices? Absolutely not, and that's what I'm talking about. > The majority of cost constrained products don’t allow that, though. They increasingly do allow for it, is the point I'm trying to make. And when they don't: there are far better non-Linux open source options now than there used to be, which are by design better suited to running in constrained environments than a full blown Linux userland ever can be. > It increases boot times (mentioned in the article) which is a pretty big deal on certain consumer products that aren’t always powered on. The article makes some good points that you’ve waved away because you’ve been working on a different category of devices. I've absolutely worked on that category of devices, I almost never run Linux on them because there's usually an easier and better way. Especially where half a second of boot time is important. reply AnthonyMouse 12 hours agorootparent> But of new devices? Absolutely not, and that's what I'm talking about. The trouble with \"new\" is that it keeps getting old. There would have been a time when people would have said that 32MB is a crazy high amount of memory -- enough to run Windows NT with an entire GUI! But as the saying goes, \"what Andy giveth, Bill taketh away\". Only these days the role of Windows is being played by systemd. By the time the >1GB systems make it into the low end of the embedded market, the systemd requirements will presumably have increased even more. > there are far better non-Linux open source options now than there used to be, which are by design better suited to running in constrained environments than a full blown Linux userland ever can be. This seems like assuming the conclusion. The thing people are complaining about is that they want Linux to be good in those environments too. reply znpy 12 hours agorootparent> There would have been a time when people would have said that 32MB is a crazy high amount of memory Those days are long gone though, for better or worse. We live in the 2020s now and ram is plenty. The small computers we all carry in our pockets (phones) usually have between 4 and 16g GB ram. reply AnthonyMouse 11 hours agorootparentThat's entirely the point. In the days of user devices with 32MB of RAM, embedded devices were expected to make do with 32KB. Now we have desktops with 32GB and the embedded devices have to make do with 32MB. But you don't get to use GB of RAM now just because embedded devices might have that in some years time, and unless something is done to address it, the increase in hardware over time doesn't get you within the budget either because the software bloat increases just as fast. And the progress has kind of stalled: https://aiimpacts.org/trends-in-dram-price-per-gigabyte/ We've been stuck at ~$10/GB for a decade. There are plenty of devices for which $10 is a significant fraction of the BOM and they're not going to use a GB of RAM if they can get away with less. And if the hardware price isn't giving you a free ride anymore, not only do you have to stop the software from getting even bigger, if you want it to fit in those devices you actually need it to get smaller. reply imtringued 6 hours agorootparentI recently looked up 2x48GB RAM kits and they are around 300€ and more for the overclockable ones. That is 3€ per GB and this is in the more expensive segment in the market since anyone who isn't overclocking their RAM is fine using four slots. reply Someone 11 hours agorootparentprev> We live in the 2020s now and ram is plenty. The small computers we all carry in our pockets (phones) usually have between 4 and 16g GB ram. I do not think the monster CPUs running Android or iOS nowadays are representative of embedded CPUs. RAM still requires power to retain its contents. In devices that sleep most of the time, decreasing the amount of RAM can be the easiest way to increase battery life. I would also think many of the small computers inside my phone have less memory. For example, there probably is at least one CPU inside the phone module, a CPU doing write leveling running inside flash memory modules, a CPU managing the battery, a CPU in the fingerprint reader, etc. reply kaba0 13 hours agorootparentprev> It increases boot times Is it really the case? On desktops it is significantly faster than all the other alternatives. Of course if you do know your hardware there is no need for discovering stuff and the like, but I don't know. Would be interested in real-life experiences because to me systemd's boot time was always way faster than supposedly simpler alternatives. reply dhjvgfkvhy 12 hours agorootparentWhen Arch Linux switched to systemd, my laptop (with an HDD) boot times jumped from 11 seconds to over a minute. That 11 seconds was easy to achieve in Arch’s config by removing services from the boot list and marking some of the others as supposed to be started in parallel without blocking others. After the switch to systemd there was no longer a such a simple list in a text file, and systemd if asked for the list would produce such a giant graph that I had no energy to wade through it and improve things. Later, when I got myself a laptop with an SSD, I discovered that what my older Arch configuration could do on an HDD is what systemd could do only with an SSD. reply RandomThoughts3 8 hours agorootparentI switched to systemd when Arch switched and from the get go, it was massively easier to parallelise with systemd than with the old system and that was with an HDD. Systemd already parallelises by default so I don't know what insanely strange things you were doing but I fail to see how it could bring boot time form 11s to 1 minute. Also, it's very easy to get a list of every services enabled with systemctl (systemctl list-unit-files --state=enabled) so I don't really know what your point about a giant graph is. reply saurik 1 hour agorootparentRunning things in parallel isn't going to make the disk faster... with a HDD I'd think it is actually even more likely to make the disk slower. reply JeremyNT 5 hours agorootparentprevI mean, this anecdote only tells us that if something is configured poorly it will behave poorly. If you're working in the embedded space it's surely worth a little bit of time to optimize something like this. reply kaba0 10 hours agorootparentprevArch changed to systemd in 2012, at which point systemd was 2 years old. It surely had quite a few growing pains, but I don't think that's representative of the project. In general it was the first init system that could properly parallelize, and as I mentioned, it is significantly faster on most desktop systems than anything. reply rascul 2 hours agorootparent> In general it was the first init system that could properly parallelize I'm not sure what you mean by \"properly\" but didn't initng and upstart (and probably some others I can't recall) do the parallel stuff before systemd? reply 1oooqooq 9 hours agorootparentprevit was only faster if you started with bloated redhat systems to begin with. but yes, it was the beginning of parallelism on init... but the \"faster boot\" you're remembering are actually a joke at the time. since the team working on it were probably booting vms all the time, the system was incredible aggressive on shutdown and that was the source of it. something like it reboots so fast because it just throws everything out and reboot, or something. i don't really care much for the jokes but that was why everyone today remembers \"systemd is fast\". reply kaba0 9 hours agorootparentIt mandates strict session termination, unlike the unsustainable wild west approach of older Unix systems. Proper resource deallocation is crucial for modern service management. When a user exits without approval of \"lingering user processes,\" all their processes should be signaled to quit and subsequently killed. reply 1oooqooq 3 hours agorootparenti think the \"unsustainable wild west\" of sending sigterm, waiting and sending sighup was very good because it was adaptable (you were on your own if you had non standard stuff, but at least you could expect a contract) Nowadays if you start anything more serious from your user session (e.g. start a qemu vm from your user shell) it will get SIGHUP asap on shutdown, because systemd doesn't care about non service pids. but oh well. ...which is where the jokes about \"systemd is good for really fast reboots\" came from mostly. reply kaba0 3 hours agorootparentThe old way has literally no way to differentiate between a frozen process and one that just simply wants to keep on running after the session's end, e.g. tmux, screen. It's trivial to run these as a user service, which can linger afterwards. Also, systemd has a configurable wait time before it kills a process (the \"dreaded\" 2 mins timer is usually something similar) reply rurban 13 hours agoparentprevSame for me. Incredibly useful on the bloated sensors running Linux. All the smaller systems with no RAM run on baremetal anyway. There's no room and no need to run Linux or a threaded RTOS. Much less security headaches also. reply 0xbadcafebee 16 hours agoparentprev> every embedded Linux device I've been paid to work on in the past five years had over 1GB of RAM That is almost by definition not an embedded device. There's a reason we have vfork(). reply adgjlsfhk1 12 hours agorootparentthere are 2 types of embedded systems: those that ship 1 million units, an and this that ship 50. if you're shipping 1mil units, you need to optimize RAM size, but if you're only shipping a few, them it's not worth squeezing everything down as long as it doesn't break your power/cost target. there's a ton of devices out there that literally just use a cheap smartphone as an \"embedded\" CPU because that way, Google has already done 90% of your R&D for you reply jcalvinowens 15 hours agorootparentprevWell, you can gatekeep all you want, but it's increasingly practical and common to have what would have seemed like an absurd amount of RAM a decade ago on things like toasters. reply Aurornis 15 hours agorootparentYou have been living in a strange world if you’ve been getting away with 1GB in the average consumer IoT device for the past 5 years. That’s not typical at all. I’ve done a lot of work with production runs in the millions. There is no way we’d put that much RAM on a device unless it was absolutely, undeniably required for core functionality. reply vv_ 8 hours agorootparentTypically in IoT you'll count RAM in kB not MB and definitely not GB. See STM32 H5/H7/L4/L4+/U0 as an example. reply bmicraft 3 hours agorootparentTypically in IoT you'll use an soc that actually supported some kind of network connection reply jcalvinowens 15 hours agorootparentprevI've asked in the past, and been told that a even a 2x-3x difference in the amount of RAM made such a negligible difference in cost it was decided to go with the larger amount. I frankly have a hard time understanding how that can be true... but I can't really imagine why they wouldn't be honest with me about it. reply kelnos 14 hours agorootparent> I've asked in the past, and been told that a even a 2x-3x difference in the amount of RAM made such a negligible difference in cost it was decided to go with the larger amount That doesn't pass the sniff test. Look at retail RAM prices. Certainly the magnitude of the price is quite different than buying individual RAM chips at quantity, but the costs do scale up as RAM size goes up. Hell, look at RAM chip prices: you are definitely going to increase the price by more than a negligible amount if you 2x or 3x the amount of RAM in your design. Also consider the Raspberry Pi, since the article mentions it quite a bit: RAM size on the Pi is the sole driver of the different price points for each Pi generation. reply crote 5 hours agorootparentAt quantities of 100, 512Mbit of RAM is $1.01 [0]. 1Gbit of RAM is $1.10 [1]. 2Gbit is $1.05 [2]. 4Gbit is $1.16 [3]. It is only at 8Gbit that prices substantially increase to $2.30 [4]. So no, at those sizes price really does not change all that much, and installing 512MB of RAM instead of 64MB only increases the product's cost by $0.15. It's a commodity made on legacy processes, things like packaging, testing, and handling far outweigh the cost of the actual transistors inside the chip. [0]: https://www.lcsc.com/product-detail/DDR-SDRAM_Winbond-Elec-W... [1]: https://www.lcsc.com/product-detail/DDR-SDRAM_Winbond-Elec-W... [2]: https://www.lcsc.com/product-detail/DDR-SDRAM_Samsung-K4B2G1... [3]: https://www.lcsc.com/product-detail/DDR-SDRAM_Samsung-K4B4G1... [4]: https://www.lcsc.com/product-detail/DDR-SDRAM_Samsung-K4A8G1... reply spockz 13 hours agorootparentprevThe retail price of a finished product has very little to do with the cost of individual components and more with profit margins or customer segmentation. reply vbezhenar 13 hours agorootparentprevEven Apple produced laptops with 8 GB RAM just recently, which they sold for hundreds of dollars with huge margins (AFAIK). If you're going to produce something with $50 cost, 1GB RAM cost will be meaningful. In my experience production people will eat your soul for a single resistor if they can cut costs on it. reply pjmlp 12 hours agorootparentThat is the Apple tax on everything the fruit company sells, they always push the margins as far as fans are willing to pay for. reply kaba0 13 hours agorootparentprevThat RAM is unified though, not a good comparison. Also, just because something holds true at large numbers doesn't mean it scales all the way down. Either due to economies of scale, or the negligibly different architecture/components at that size. reply AnthonyMouse 12 hours agorootparentThe RAM is ordinary LPDDR5 organized into what is de facto just a large number of memory channels. It's not HBM or anything exotic, the cost of the RAM chips themselves are the same cost they are anywhere else. reply somerandomqaguy 15 hours agorootparentprevHuh? Been a while since I was in the digital signage space but a lot of the equipment runs of the shelf RK3288 plugged into commercial displays. 2GB of RAM was pretty common. IIRC's though LG's WebOS TV's have minimum 2GB of RAM in the digital signage space directly built into the units themselves. I believe Samsung Tizen based units has similar RAM. My router has 1GB of RAM in it. But even my cheapest routers have 128 to 256 MB of RAM. The Cisco 9300 Catalyst switches have about 8 GB of RAM, but switches with beefy amounts of RAM are getting pretty common now, even if somewhat pricey. Yeah there's massive swathes of embedded space that's tiny. But the higher end stuff isn't exactly out of reach anymore. The RK3288's IIRC ran about $20 a unit at the time before I left the industry. reply skydhash 14 hours agorootparentA decade ago, I had to settle for 512MB of ram for my Windows XP desktop. reply gnabgib 14 hours agorootparentThree decades perhaps. In 2014 it was Windows 8, SSDs, 5th gen i7 (Haswell), 8-16GB of DDR4 ram. Even the iPhone 6 came with 1GB of ram. reply skydhash 14 hours agorootparentThere's a huge chunk of people out there, not able to afford the latest. reply happymellon 11 hours agorootparentBut desktops with those specs areThat \"occasional weird problem\" is because systemd is not designed to be used with other software. That's not true, systemd has an explicitly documented and supported initrd interface: https://systemd.io/INITRD_INTERFACE/ It's actually really easy, there's rarely a reason for the initrd to be more complex than a single 50-line busybox script on an embedded device with built-in drivers. reply blueflow 10 hours agorootparent\"really easy\" except for the hotplug events that don't get to systemd and cause your problem. reply jcalvinowens 2 hours agorootparentI got an immediate answer with a solution from the upstream developer when I asked about it: I can't imagine how that could have been easier to solve. And it was also trivial to hack around by leaving the entry out of fstab and mounting it in a script. reply chasil 1 hour agorootparentprevThe embedded people will naturally look at busybox. I saw it running on a credit card scanner at Old Navy a few years ago. It has an init: $ /home/busybox-1.35 init --help BusyBox v1.35.0 (2022-01-17 19:57:02 CET) multi-call binary. Usage: init Init is the first process started during boot. It never exits. It (re)spawns children according to /etc/inittab. Signals: HUP: reload /etc/inittab TSTP: stop respawning until CONT QUIT: re-exec another init USR1/TERM/USR2/INT: run halt/reboot/poweroff/Ctrl-Alt-Del script On an embedded system, that will be a strong contender for pid 1. reply blucaz 18 hours agorootparentprevDebian, Ubuntu and all derivatives thereof use initramfs-tools, which does not use systemd in the initrd, and things work just fine reply bmicraft 3 hours agorootparentUbuntu is literally trying to replace it with dracut as we speak. reply binkHN 15 hours agorootparentprevNot an uphill battle at all; Void Linux does this by default and has for many years. reply blueflow 10 hours agorootparentVoid Linux dropped systemd because it wouldn't work with a different libc than glibc. Which i would add as next point in my systemd lock-in list. reply noncoml 19 hours agorootparentprevNot uphill at all; try buildroot reply avaldez_ 19 hours agoparentprevSmall typo: Zephyr https://zephyrproject.org/ reply pengaru 4 hours agoparentprevAnything mass produced is going to be pressured to reduce BOM cost, RAM capacity is still and will continue to be a prime target. reply TwoNineFive 8 hours agoparentprevSystemd trolls on HN are really out of hand. This isn't even credible. reply metalforever 15 hours agoparentprevI was just thinking \"there is no way this person works on embedded devices\". Then I read the last paragraph where you bring up \"over 1GB of RAM\". Explains that. reply transpute 20 hours agoprevOpenEmbedded/Yocto, Devuan and Gentoo provide multiple init systems. systemd CVEs: https://ubuntu.com/security/cves?package=systemd&limit=100 Rust PoC: https://github.com/KillingSpark/rustysd > Rustysd is a service manager that tries to replicate systemd behaviour for a subset of the configuration possibilities. It focuses on the core functionality of a service manager, not requiring to be PID1 (aka init process).. core systemd functionality is not very hard to replicate.. the advantages of having a systemd-like service manager can be brought to many other platforms.. (like alpine linux, commonly used in docker containers and small vms) and freebsd. reply dcsommer 17 hours agoparentHow many systemd CVEs are memory or thread safety related? reply fn-mote 16 hours agorootparentI can't tell if this is rhetorical but... it looks like quite a few on the list. (Note: the CVE list is long but it looks inflated / full of not-serious issues.) * CVE-2022-3821 : off by one error leading to buffer overflow * CVE-2022-2526 : use after free * CVE-2021-33910 : \"Memory Allocation with an Excessive Size Value\" (not sure if this qualifies... not interested enough to read the source) reply 1oooqooq 9 hours agorootparentprevI'd bet you get more CVEs and actual remote exploit entry points by systemd forcing mdns, bonjour, upnp and other zero conf hacks just because that was the work the systemd team was doing in rh before. reply 1oooqooq 4 hours agorootparentremembered another one. They use the same code for VM and bare metal. Including the easy-login convenience hacks. So now anyone wanting physical access to your host, just have to intercept plain-text communication with the BIOS (after secureboot did its thing), and reply with a new root password when the OS request bios key 11 or something. evil maids are living the dream. reply silverliver 14 hours agorootparentprevWhat do memory and thread safety have to do with the project's stated goals? I for one would love to avoid systemd's arbitrary requirements while retaining compatibility with upstream (e.g. PID must be 1). reply solarkraft 21 hours agoprev> The more fundamental problem is that the people who most like systemd are distribution managers. (...) a distribution manager doesn’t have to maintain, integrate, and support a whole bunch of system utilities from different sources – systemd provides everything in one huge build. That’s actually a great lesson in optimizing your product for adoption. reply exe34 20 hours agoparentit's also why corporate software is so shit - it's shiny in all the ways it needs to be shiny for management to make the decision, but it's a pain for the actual users. the trick in both cases is to know your customers! reply oblio 20 hours agorootparentTurns out, many people use systemd after what, 15? years of doomsday predictions :-) reply Brian_K_White 20 hours agorootparentWhat do you imagine this proves or disproves? How many people eat McDonalds? Or buy in to countless other things that can be trivially demonstrated to be against their own interests. I don't know about anyone else but I never heard the critiques of systemd to be based on any doomsday predictions. Everyone knew it would function, and that it even serves one use case better than before. The critique was only ever that it serves one purpose better at the expense of all others, and is a downgrade in flexibility and functionality from what already existed. reply cbmuser 20 hours agorootparent> How many people eat McDonalds? If you’re already starting like this it’s obvious that the following text will be non-scientific non-sense. As a reminder: There is no such thing as “healthy food” and “unhealthy food”, there is just healthy and unhealthy nutrition. Still baffles me that people think it would actually be legal to sell actual unhealthy food, i.e. poisonous food. Also, “organic food” is just a marketing scam. If you think your nutrition is better off if you stick to nature, you’ve missed a large part of human history where people starved to death by the thousands every year because they exclusively relied on “organic food”. systemd runs on billions of systems worldwide and everyone who ever professionally maintained enterprise servers understand what a bad approach the crude hack that SysVInit with its collection of shell scripts was. reply AdieuToLogic 18 hours agorootparentIgnoring the food portion of the above: > systemd runs on billions of systems worldwide and everyone who ever professionally maintained enterprise servers understand what a bad approach the crude hack that SysVInit with its collection of shell scripts was. This is your opinion and not one held by all. It also ignores the various BSD system initialization scripts, which are explicitly not \"SysVInit\" related, and have been in use for decades. reply simoncion 16 hours agorootparentIt also ignores the diverse (if small) set of Linux init systems... 'openrc' being the one I'm most familiar with, as a Gentoo Linux user. I'm so sad I wasn't paying attention when Debian was choosing init systems... I would have burned a TON of time getting anything they claimed in good faith was missing in 'openrc' into it, had I known that that clusterfuck was going on. reply philistine 17 hours agorootparentprevPlease explain to me how farmers who are making organic food are performing a scam. The fact that you don’t like how organic food is marketed does not mean it is full bore a scam. It’s a real agricultural practice that exists. Organic eggs require far more freedom for chickens for example. reply Brian_K_White 19 hours agorootparentprevYou seem to be a very confused person. I don't even know where to begin with all of this randomness. Do you actually not understand what is wrong with McDonalds food? Or countless other similar low quality but legal products? Do you actually not understand that terms like \"healthy\" and \"poison\" are not binary but a spectrum? And that every single thing has some aspects of both? Do you actually not understand how a bag of sugar is not poison and legal to sell, and yet, if you ate one for dinner every night would not be good? Do you actually not understand the point that popularity does not by itself prove or disprove anything? That great masses of people frequently voluntarily choose the inferior option for all kinds of reasons that aren't even all some form of lack of choice? Do you actually not understand that that you are attempting to speak for \"everyone who ever professionally maintained enterprise servers\" TO some of them who quite robustly do not say any such thing? reply righthand 19 hours agorootparentprevIt is legal to sell unhealthy food, ie poisonous food. Sugar is a poison, drugs are poisons. You can legally sell escolar a fish that if eaten too much is poisonous. What is poisonous food? You can sell plastic that breaks down into the environment and people are drinking it in water, eating it in fish. Is that legally sold poisonous food? reply samatman 16 hours agorootparentSugar is not, in fact, a poison. As for drugs: > Alle Dinge sind Gift, und nichts ist ohne Gift; allein die Dosis macht, dass ein Ding kein Gift ist. - Paracelsus, 1538 https://en.wikipedia.org/wiki/The_dose_makes_the_poison reply righthand 13 hours agorootparentSugar is indeed poison. Personally, I like to add a bit more science and reasoning to my understanding rather than rely on quotes from someone in 1538. reply consteval 3 hours agorootparentSugar is not poison. It can be, in certain situations, \"bad for you\". But sugar is found naturally in a variety of fruits and vegetables and has been a staple of the human diet for all of history and pre-history. There's no way to describe it as \"poison\". reply righthand 1 hour agorootparentThe sugar being discussed is not natural sugars but refined processed sugars, that are absolutely poisons. Booze has been a staple of diets for a long time too. Doesn’t mean it’s not poison just because society is stupid enough to embrace it. reply consteval 4 minutes agorootparentDo you have any evidence of this or is this just your belief? I think, if it's just your belief, you should say that. growse 11 hours agorootparentprevEverything is a poison. It's simply a question of dosage. reply righthand 5 hours agorootparentI grokked the quote and my response is still that it’s a cute way to hand-wave away the fact that poisonous food exists. reply bitwize 14 hours agorootparentprevFound the Hackernews who hasn't yet read Lustig's research into the hepatotoxicity of sugar. It's as bad for your liver as alcohol. reply sheepdestroyer 18 hours agorootparentprevNon organic food is very obviously a poison for the vast majority of Earth's life. See : the current apocalyptic and accelerating global biomass destruction directly caused by industrial farming. reply grosswait 19 hours agorootparentprevAnd yet, you’ll still find many of us that think systemd is worse, but for different reasons. (I think the food analogy was lost) reply kelnos 14 hours agorootparentprevI'm not a systemd hater, but I use it mainly only because my distro of choice (Debian) switched to it. If Debian chose something else, I'd be fine with that too. I'm a user out of necessity (or perhaps inertia), not out of choice. reply akira2501 20 hours agorootparentprevTurns out many people don't care to change their distribution defaults. reply oblio 7 hours agorootparentExactly, because I don't care about the plumbing in my house unless it's really bad. Systemd is opinionated and quirky but it does the job just fine for 99.999% of people and it provides a standardized approach to things just by virtue of how it works, and there is a lot of value in that. reply fsckboy 20 hours agorootparentprevi don't notice anything good systemd does for me, just where it interferes, and that's a constant annoyance, a few days a week. reply lambda 20 hours agorootparentThe thing is, the good things are the things you don't notice; the things that just work. They didn't used to \"just work\" like that before systemd. System boot is faster. I can have fewer things started up in the background, and instead have them start up when needed. Restarting services works consistently. Every application doesn't have its own bespoke and half baked management scripts which don't work half the time. They don't all have to invent their own daemonization support and logging; you just log to the journal. And that's just core systemd. Things like systemd-resolved give me proper support for split-DNS when using VPNs. systemd-networkd gives me consistent, powerful configurable networking setup that works across distros. Is it perfect? No, I do still have some complaints with it. But it's a hell of a lot better than what it's replacing. I wouldn't ever go back to sysvinit or upstart, and many other parts of systemd are compelling alternatives to the things they replace, like systemd-networkd over ifupdown. reply fsckboy 20 hours agorootparent>the good things are the things you don't notice; the things that just work sorry, no, at least in any meaningful sense, because init already just worked for me. and when something didn't, I could find how to fix it in a way that was transparent and I understood and could even modify or make better, without being connected to the internet looking for cargo cult incantations on stack overflow init was a tool; systemd is an adversary reply cedilla 17 hours agorootparentOkay, I'll bite. What kind of problems do you have with the part of systemd that replicates sysvinit /every other day/? reply richardfey 13 hours agorootparentMy most common issues with systemd are related to those long timeouts when something at boot/shutdown is not working as intended, and unexplained/unexplainable changes to the order of boot of some components. For the former I have given up playing whackamole with all the timeouts you need to reconfigure, for the latter I didn't even try because I know that there's something peculiar about my setup that will never work nicely with systemd, there's simply not enough systems configured like that for upstream to care. I have accepted this new reality, but I know that before systemd I was able to fix any highly customised setup of mine, now I have to avoid that and minimise tinkering/hacking. reply AnthonyMouse 12 hours agorootparent> now I have to avoid that and minimise tinkering/hacking. I think this right here hits at the crux of the issue. There are people who like systemd because it's integration-tested with itself and its own defaults, so if you never change those defaults you don't have many problems. Then there are people who don't like systemd because if you do have to change any of its defaults, it often doesn't go well. And, of course, the latter behavior as a box users are expected to live in is poisonous, because everyone is being conditioned to be passive and uniform. reply richardfey 5 hours agorootparentYes, I think your analysis is spot-on. reply Suzuran 3 hours agorootparentprev\"See Figure 1\". reply bmicraft 3 hours agorootparentprev/etc/systemd/{user,system}.conf.d/dont-wait.conf: [Manager] DefaultTimeoutStopSec=5s There, done. That's all the timeouts you'll ever need. Go and complain to your distribution they are setting the wrong defaults, even desktop environment(s) already recommend[1] setting it to a low value. You can stop hating on systemd now, everything you needed was in `man systemd-system.conf` all along. [1] https://community.kde.org/Distributions/Packaging_Recommenda... reply acdha 6 hours agorootparentprev> My most common issues with systemd are related to those long timeouts when something at boot/shutdown is not working as intended That’s an issue with a daemon, not systemd. Anyone who used NFS saw that routinely on SysV init during the era when Red Hat distributions shut down networking before ensuring that the network mounts were unmounted. reply richardfey 5 hours agorootparentI regularly see it also on a system not using NFS, and it seems related to console seats. Never went to the bottom of it because it's sporadic/non-reproducible. reply acdha 4 hours agorootparentYes - my point was simply that the shut down process tells things to stop but most sysadmins have war stories about that not working well for all kinds of things. The problem is that there isn’t a universally correct way to do this: if my web server has hung, SIGKILL is what I want to get the system back in a usable state as quickly as possible but if it’s a file system, database, etc. you have questions like losing data which aren’t trivial to answer (e.g. if it’s a transient error, waiting for it flush is good but if my storage had an irrecoverable error I might want write off that data as lost and focus on getting the service back up). reply exe34 11 hours agorootparentprevI've got the waiting ages for shutdown feature on reboot, so I tend to force reboot it. I never bothered trying to fix it because firstly I don't know where to start and secondly I only reboot after updates once every few months. reply fiddlerwoaroof 19 hours agorootparentprevYeah, the two systemd components GP mentioned have given me no end of trouble. reply egorfine 9 hours agorootparentprev> They didn't used to \"just work\" like that before systemd. They used to \"just work\" for _decades_ before systemd. Like, everything. I see reasons for systemd as PID1 and it's great in that role, hands down. Everything else looks like a malignant growth to me, including much praised journald and DoA pieces like resolved. reply egorfine 9 hours agorootparentprev> systemd-resolved give me gives me #1 source of troubles on any desktop computer I have ever ran under the systemd era. I feel like resolved is specifically designed to be removed from fresh installations, sort of like a transparent peel on new devices' screens. In my strong opinion, resolved is the most brain damaged part of systemd. Unconfigurable, unmaintainable, unmanageable. > systemd-networkd gives me Oh, there is no point in learning systemd-networkd. By the time you do Ubuntu folks will swap the set of the network initialization tools once again and you'll have to start over. Thankfully, 'apt install ifupdown' still works kind of like `apt install upstart` worked a few years ago. reply 1oooqooq 9 hours agorootparentprevi don't think many distros use networkd. they all ship it disabled with nm instead reply viraptor 20 hours agorootparentprevCan you link some upstream issues you raised about the big annoyances? reply rjzzleep 20 hours agorootparentRandom example. They randomly broke suspect-then-hibernate then the community manager gaslit people into trying to make them believe they don’t actually need the feature in the way it’s used and then silently acknowledged that their fix is broken after all. This is a common pattern by the way. But easily the most irritating thing for me is the simple issue that you used to be able to just go to /var/log/lastlog to see what failed during the last boot and that just the other day I had to spend hours figuring what broke in the system that made journalctl not log properly. In the end I had to reinstall all currently installed packages. https://www.reddit.com/r/archlinux/comments/zczdnq/systemctl... reply strken 19 hours agorootparentThe linked GitHub issue is one of the most aggravating exchanges I've ever read: https://github.com/systemd/systemd/issues/25269. I don't understand how you can read someone telling you that they want to suspend and then hibernate after a set duration, but A) not understand why this would be desirable, B) not understand that this is compatible with also hibernating at low battery, and C) not understand your own lack of comprehension. reply wongogue 18 hours agorootparentWhat the issue author is asking for is also the default behavior of Windows (which is developed by his employer) on laptops. reply amatecha 14 hours agorootparentprevYeah, that's pretty shitty behaviour, invalidating all the good-faith feedback and going so far as to call it \"trolling\"?? Ridiculous. There's no excuse to be so hostile when handling bug reports. reply viraptor 19 hours agorootparentprevSo there was a bug and bad interaction and everyone on non-rolling system didn't even notice, because it's been fixed in 2 months? (Nov to Jan) It sucks, but it's been fixed for almost 2 years at this point. For the last boot you can use \"journalctl -b -1\" as long as you enabled persistent logs. If you ended up reinstalling everything, I don't think we can say whether that was a systemd related issue or not. I was curious what the current daily issues are. reply shakna 19 hours agorootparentprevThe cgroups changes [0] made my life more difficult for a while. \"all the low level bits will go away without replacement\". [0] https://lwn.net/Articles/555922/ reply exe34 20 hours agorootparentprevnot many people enjoy bikeshedding. reply stepupmakeup 20 hours agorootparentprevUnfortunately not by choice reply perching_aix 19 hours agorootparentprevwhat a weird comparison... reply m463 16 hours agoprevI think what he's running into is \"the unix philosophy\". It is basically about small tools, limited in scope, that solve a problem surgically and comprehensively. They work together by mixing and matching to solve the problem. systemd is sort of like if microsoft word took on system init. In the beginning it was small, but now it is web based and does videoconferencing. I don't know, it is sort of like busybox, replacing other system components in a limited Minimum Viable Product way, but more like limited function, not limited resources. reply theamk 14 hours agoparentI think the problem is that small tools are missing that \"comprehensively\" part.. trying something as simple as getting full system startup log (something very useful on headless system!) - it was basically impossible until systemd came. Only gentoo tried to do this for a few years, but then that functionality broke. Same goes for service startup - why does start-stop-daemon discards stdout/stderr instead of logging it? This would be trivial to fix, but somehow this was not available until upstart (and then systemd) did it. reply AnthonyMouse 12 hours agorootparentThis seems like the motte and bailey thing. Some of the oldest init systems made decisions that were sensible at the time but not so much now, e.g. when storage is hundreds of thousands of dollars per GB you don't want to log everything, when it's tens of cents per GB you do. But you can obviously make a non-monolithic init system that causes output to be stored to a log instead of being discarded. So then systemd comes in, solves some of the old problems and independently, unnecessarily introduces new ones by being a huge monorepo that lacks clean and stable interfaces between its own components, inhibiting anyone else from providing a viable competing implementation of an individual component. Then people complain about the latter and the defense that comes back is of the former. But that's no defense -- we could instead be making the good change and not the bad change. reply egorfine 9 hours agorootparent> lacks clean and stable interfaces between its own components, inhibiting anyone else from providing a viable competing implementation That's exactly what Microsoft did back in the era with Word and others, just like GP stipulated. reply mattpallissard 14 hours agoparentprev> systemd is sort of like if microsoft word took on system init. In the beginning it was small, but now it is web based and does videoconferencing. It's actually a suite of tools that do solve individual problems comprehensively. Not as small as the programs in coreutils, but still not a huge monolith. reply egorfine 9 hours agorootparent> It's actually a suite of tools It's a suite of tools created with hate to the unix philosophy. That's something that all of them have in common. There was no reason to create systemd timers as cron worked just fine for decades. reply RandomThoughts3 8 hours agorootparent> with hate to the unix philosophy It's a suit of a tools each doing one thing and communicating together via a message bus. How exactly is that hating the \"unix philosophy\" whatever that means? From where I stand, it's extremely close to the way Unix has ever done things. The design is even directly lifted from the boot system of a certified Unix. reply egorfine 7 hours agorootparentTo me it looks exactly like ann opposite of suite of independent tools. reply consteval 3 hours agorootparentOkay. How? They're all individual binaries that just happen to use the systemd name. You realize systemd isn't just one big program, right? It's like 30 programs, all independent of each other, with integrations to other programs. reply egorfine 2 hours agorootparentI believe they were not created to solve real problems. No one wanted a cron replacement, really. Thus they are created out of political or ego reasons. reply consteval 5 minutes agorootparentThis is purely speculative. From my talks with sys admins, all the ones I've met greatly appreciate systemd. Also timers and cron have different requirements, notably timers can do much more. Also timers is purely optional and most distros DO use cron. There's a major disconnect, I've seen, from what systemd haters proclaim and what is reality. Nobody is forcing anything, you don't have to use 99% of systemd, it's not a monolith, and many people do want the features. To be clear, this isn't my opinion - this is the truth. You can find all this out by perusing the repos and mailing list. imtringued 1 hour agorootparentprevCron is probably the worst example you could have chosen. For my uses cases that, you know, involve manually running jobs to see if they actually work, cron has been broken for decades and is still to this day basically unusable. Systemd timers work far better than cron. reply m463 12 hours agorootparentprevI don't agree with comprehensively. for example timesyncd is barebones and not super accurate when it comes to timekeeping, while chrony and ntp actually manage the system time. similar - systemd-boot is barebones, systemd-networkd is barebones (but has gotten more MVP-featured in a busybox way), etc Maybe 10 more years and everyone will be used to things, and people won't be arguing about chesterton's fence. https://en.wikipedia.org/wiki/G._K._Chesterton#Chesterton's_... reply cyberax 14 hours agoparentprev> I think what he's running into is \"the unix philosophy\". \"Unix philosophy\" is throwing crap at the problem, until it kinda-sorta works on the developer's machine. reply oguz-ismail 16 hours agoparentprev> systemd is sort of like if microsoft word took on system init. In the beginning it was small, but now it is web based and does videoconferencing And it's slow. Windows 11 boots in 5 seconds on my laptop, Ubuntu 22 used to take about a minute before I finally made the switch. reply dralley 16 hours agorootparentThat almost certainly has little to do with systemd itself, and more to do with which services are enabled on boot. reply lmm 8 hours agorootparentIt's due to systemd in that systemd makes it too fiddly to figure out or change which services are enabled on boot. (I used to know a way to disable certain services on boot under systemd, but it doesn't work any more, and I've reached a state of learned helplessness at this point) reply vetinari 2 hours agorootparent`systemctl disable` and `systemctl mask` work today just like they worked decade and half ago. reply cyberax 14 hours agorootparentprevMy system boots systemd in 2 seconds from the firmware handover to my code fully running. And this includes device initialization and a DHCP lease renewal. On VMs you can get to within 200ms for a full system. You can use `systemd-analyze critical-chain` to visualize the boot process. The slowdown is likely caused by something unexpected. reply mananaysiempre 5 hours agorootparentprev> Windows 11 boots in 5 seconds on my laptop Try measuring a reboot instead. On modern Windows versions with “fast startup” enabled, the “Shutdown” button is a lie: it logs you out and hibernates the system instead of actually shutting it down. (This is important if you dual boot, because it means you can’t safely access the Windows partition in the interim.) reply oguz-ismail 4 hours agorootparent> the “Shutdown” button is a lie: it logs you out and hibernates the system instead of actually shutting it down I'm okay with that. How do I enable this on Ubuntu? reply bmicraft 3 hours agorootparentAre you seriously complaining right now that systemd doesn't have a specific feature no other init for linux has either, while at the same time complaining it is too complicated and does too much stuff? reply oguz-ismail 2 hours agorootparentI'm asking a question reply mariusor 11 hours agorootparentprevWindows 11 probably uses Fast Startup for those speedy boot times, which is to say that it's not a \"cold\" boot. Apples and oranges and all that... reply viraptor 20 hours agoprevI'm conflicted on the name/issue. I don't have any issues with Linux on embedded systems, because I'd use a minimal init with that one single app it should be running. (Or as mentioned in other comment, build your minimal distro yocto-style) RPi is a low spec general computer at this point. The idea of running gnome on an embedded system just doesn't make sense in my mind... RPi took the form factor that was used for industrial control boards and made it into a usable desktop... which people use as a desktop (or home server). But it created a segment which really is neither. And a lot of the software just isn't written with that segment in mind. Maybe as it gets more popular, people will pay more attention. But currently it seems more of an expectations issue. reply fyrn_ 20 hours agoprevhttps://chimera-linux.org/ https://chimera-linux.org/docs/faq#what-is-the-projects-take... Is going a really interesting direction with it's service management and login / seat management. Fwiw, I think it's author also has a more gounded perspective on systemd then many others. For Chimera the main issue is systemd's high volume use of gnulibc and gcc extensions, which is a porabiluty issue for Chimera which uses a LLVM toolchain and musl libc (and a bunch of really cool hardening and compiler engineering) reply binkHN 15 hours agoparentI like the direction Chimera is taking; the lead is an ex-Void maintainer and there's clearly a lot of inspiration from there. reply msarnoff 18 hours agoprevI’ve never used it as an init replacement, but runit (https://smarden.org/runit/runit.8) is great for supervising applications and services. - It’s built into BusyBox and is very lightweight - Configuration is dead simple (everything is basically shell scripts in the filesystem; no special config language) - Includes logging functionality with rotation - Easily controllable from other applications using named pipes - It’s an almost perfect embodiment of the Unix philosophy: a series of small, single-purpose executables (svlogd, runsv, runsvdir, etc), with no strange config file formats or protocols. Regarding udev, it’s entirely possible to run an embedded system without it if your device has a fixed set of peripherals, doesn’t need to handle hotplugged hardware, and uses a fixed set of kernel modules. In Yocto, you can define a dummy device manager recipe and boom, no udev. As a bonus, removing udev can shave several seconds off your boot time. reply binkHN 15 hours agoparentFor what it's worth, runit is the default on Void Linux. reply phendrenad2 20 hours agoprevWait so systemd is a problem for embedded Linux because... it uses 250MB of RAM? So it's only really a problem for systems where using a mainstream distro probably wouldn't even be a consideration anyway (yocto seems to be popular, as mentioned above). I'm not seeing a strong argument here. At the risk of inviting a parade of \"actually, one time at band camp I saved the day with a first-gen raspberry pi zero\", how many embedded systems in 2024 are really RAM-limited? reply detaro 20 hours agoparent> how many embedded systems in 2024 are really RAM-limited? A lot. Plenty embedded Linux stuff still ships with 256 MB or 512 MB RAM, and the wishlist for features in the software running on top is always getting longer than initially planned... But of course the average has moved up, and it's not unusual to see systemd in embedded systems either (while I don't have a number at hand, the 250MB number seems off to me). The space is big, and different constraints and rules at different points in there. reply metalforever 15 hours agorootparentI remember when I used to run gnome 2 (i.e. mate) on a machine with 256mb of ram. It was a full experience and it worked with youtube videos and so on. What are we even doing . reply BeefWellington 13 hours agorootparentSure, back when videos were at most 480p/720p that's feasible. I'm not saying software is any more efficiently written these days but I do think it's important to recognize that just the act of pushing more pixels on its own requires more RAM. reply cyanydeez 19 hours agorootparentprevSeems like a complaint the author could help solve by extending the general purpose systems to their choice of hardware. reply redleader55 15 hours agoparentprev(Almost) All the routers that people have in their homes - the ones running OpenWRT - have between 64-256 MB RAM, and no swap. Raspberry Pis are not \"embedded\", they are cheap, low power consumer devices. reply phendrenad2 14 hours agorootparentActually, modern routers typically have 512MB RAM. And RPis absolutely are embedded, not only are they often used for one-off embedded installations due to the 2-day lead time from Amazon, but also the compute module is very popular in industrial control. reply stefan_ 17 hours agoparentprevThats a weird question, every embedded system that is a consumer product will end up with limited RAM simply because less RAM is a $1 saved on the BOM. For most systems, RAM is a choice, and for many of them someone will ask at the end \"how much can we get away with\". (Your WiFi router probably has 256 or 512 MB of RAM) reply phendrenad2 14 hours agorootparentI argue that the extra $2.50 (or whatever) to expand to 4GB is worth being able to use a stock Debian + systemd. reply DaSHacka 9 hours agorootparentSpending hundreds of thousands of dollars in additional bulk cost for the privilege of nothing other than adding systemd to the device, what a steal! reply tliltocatl 10 hours agorootparentprevExcept those $2.50 for customer will turn into $2500000.00 for the hardware vendor. And they would rather keep the $2500000.00 and let it be someone else's problem. reply vdvsvwvwvwvwv 7 hours agorootparentprev$2.50?? reply cbmuser 20 hours agoprevThe memory comparison isn’t really fair as SysVInit relies on external utilities for starting and stopping processes. At the very least, SysVInit requires a shell for running init scripts which systemd doesn’t need for native service files. reply Spooky23 19 hours agoparentReal embedded developers wouldn’t stand for the overhead of modern stuff like SysVInit. reply typ 15 hours agoprevI have no philosophy issue with systemd. The biggest show-stopper (on embedded Linux) for me is its install size. We have edge devices with only 64M RAM and 128M NAND flash. For an OTA update (via Bluetooth sometimes) only ~20M in total, adding ~5M systemd plus its dependencies doesn't make sense. 5MiB is roughly equivalent to the entire Linux kernel image on those devices. Among the components of systemd, the part that has the lowest added value for our use is dbus. It's designed primarily for desktops and useless for most of our systems, but unfortunately, it is also a hard requirement for systemd. reply hactually 19 hours agoprev> I wish I knew the solution to this problem Ooh ooh, I know! It's to improve systemd for the use-cases outlined and build a really great open source init/process manager. reply lmm 8 hours agoparent> Ooh ooh, I know! It's to improve systemd for the use-cases outlined and build a really great open source init/process manager. People already did the latter (sadly no-one used it because there was no mechanism that forced distros to adopt it), and would do the former if the systemd maintainers would let them. reply simoncion 15 hours agoparentprevThe systemd maintainers are pretty particular about things that aren't a \"supported use case\", so even if you bother to do the work, you stand a solid chance of having your work be wasted. In my professional experience, \"unsupported use case\" effectively means \"I don't want to work on that\". [0] Also, at $DAYJOB, we run into mysterious systemd failures and misbehaviors at least once a year (usually for things that should be super straightforward). Every one of these failures and misbehaviors we've run into has been met with a \"Wow. That's weird. Sucks to be you, I guess.\" with a dash of \"No, we won't be updating the documentation to mention that.\" if the actual behavior is contrary to the documentation. In short, while it may be true (I really don't know) that the systemd project welcomes changes and patches, IME it's pretty clearly true that if you're working on a problem that the project management doesn't understand, and/or doesn't want to think through, your work won't be considered. [0] [0] Which, fine, it's not my project, so I don't get to tell you what to work on. Doesn't mean I have to like it or recommend that people use it. reply throwaway2037 14 hours agorootparent> we run into mysterious systemd failures and misbehaviors at least once a year Can you share an example? reply Yizahi 8 hours agorootparentAn example from my company - sometimes on a few of the many thousands of identical devices in field something fails due to bug or hw failure. After recovering the device we get the dump of all info we deem interesting, including all logs and journals. In a small but not insignificant numbers of such archives the journal has multihour gaps in the logs. And they are gaps, so there are logs before the gaps and after. I think we never succeeded to reproduce or fix this issue in the lab, and relied on duplicating logs to the file on the device fylesystem (not optimal due to storage size and wear of the ssd memory). PS: personally I like systemd more that the script mess which preceded it. But the are some outstanding issues with it to be improved. reply simoncion 14 hours agorootparentprev> Can you share an example? The most detail my NDA permits me to get into is that our most recent failure was that the systemd cron replacement gets in a state where it refuses to ever schedule a scheduled task and that the systemd folks were like \"aw, shucks\" about it. reply klysm 17 hours agoprevI've had very nice experiences using systemd for developing embedded systems. Laying out all the unit files and just slapping the files in an overlay makes it super simple. The RAM usage isn't being calculated correctly. You can easily run systemd on very limited systems. reply userbinator 21 hours agoprevThe BSDs may be more to your liking. They're a lot more minimalist than Linux now. reply Aurornis 20 hours agoparentIn the embedded world, BSP/driver support is the main thing that matters. Linux is undefeated in that area for embedded purposes. reply bluGill 20 hours agorootparentIn embedded you should choose hardware that works. Should is key, all too often the, hardway guys don't ask they just give software something. reply nomel 20 hours agorootparent> In embedded you should choose hardware that works. I've never seen it approached with that kind of incompetence, in my professional life. Embedded is a system thing, not a hardware thing. You pick the system that will work. Ignoring the software side of things is ignoring the majority of the problem in embedded work. I would have agreed with you 20 years ago, but it's 2024, and why RPI is so often used for prototyping. reply bluGill 5 hours agorootparentSorry, wrote the original comment on my phone. The sentiment is close enough, but generally things are not quite that bad. I've seen hardware ask, but the person they asked didn't know how to check how much memory we actually needed. Hardware also failed to tell that person that half the memory they were asking about was dedicated to the GPU and thus not available for application code. I've also seen them choose hardware that seems to have great drivers and they can point to others in our industry who are shipping with that, only to latter hit a major bug that means we can't use it without that fixed - but we are too small a customer to be able to demand they fix bugs that only affect us. RPI is often useful for prototyping because it is cheap enough, but if you are not a very large company nobody will talk to you. This is both you can't get support from Broadcom, and worse your supply management cannot get contract signed (for small companies this doesn't matter you take what you can get, but larger companies often demand better support than they can get from pi) reply moron4hire 20 hours agorootparentprevI thought there was a compatibility layer available that made it possible to run Linux drivers on at least FreeBSD. reply CorrectHorseBat 20 hours agorootparentThat's for userland, not drivers. Linux doesn't have a stable interface for drivers so a compatibility layer would be a nightmare to maintain. reply moron4hire 20 hours agorootparentThat's Linuxulator, but there's also LinuxKPI: https://wiki.freebsd.org/LinuxKPI reply pnathan 20 hours agoprevI can only say that the obvious answer here is to throw effort into supporting & improving Gentoo. reply nrdvana 14 hours agoprevTry s6 or runit, and mdev from busybox. Mdev is not a \"full featured\" udev replacement, but that's sort of the point. It does just enough to get the job done and is extensible with scripts. If you want to do the size of embedded where this matters, you also probably want a smaller libc like musl, and then buildroot and busybox are your friends. reply teunispeters 16 hours agoprevIf it can run X11 on a directly connected display, it's probably not embedded spaces ;). Don't take this comment too seriously, however raspberry pi is definitely at the \"more desktop-like\" end of the embedding pool. As for systemd, it's an interesting set of tools, and one can if one wishes pick which ones are active in a system, if that system is complex enough to be running Linux (or other compatible OS) to begin with. reply cyberax 20 hours agoprev> With care, though, a minimal installation of systemd does run on a low-resource ARM board like the Pi 3. In fact, it will run on a board with 1Gb RAM, perhaps even lower. Come fucking on. I ran systemd on a 32Mb MIPS board (RouterBoard from Mikrotik) just fine. The RES column is incredibly misleading in this case, because systemd is the first app in the system. So it gets charged for loading the entire glibc and the supporting cast of libraries. If you want to look at the true usage, check the RssAnon value: > root@kmipsrv:/proc/1# cat /proc/1/statusgrep RssAnon > RssAnon: 3220 kB You can also pare this down a bit. Similarly for journald: > root@kmipsrv:/proc/1# cat /proc/231/statusgrep RssAnon > RssAnon: 640 kB So in reality, systemd works just fine for the vast majority of embedded platforms. If you can spare 3Mb of RAM, then you can run a full-blown dependency management system with reliable recovery, logging integration, and event-driven device management. Soon with support for verified boot with hardware root-of-trust. reply synergy20 19 hours agoparentsystemd itself is also large in storage size(8MB?), which is why openwrt has its own procd replacements, and yocto is not default to systemd either due to this. additionally, systemd does not work well with musl which is very popular in embedded linux. reply cyberax 18 hours agorootparentsystemd binary is around 1.5Mb, with the shared libsystemd it's around 2.5Mb. Both can be reduced by not including compressors (the infamous libz), audit libraries, SELinux, etc. The minimum binaries size that can be obtained by trivial removals is around 2Mb. OpenWRT should just stop being stubborn and integrate it. They dropped support for 4Mb devices loooooong ago, and recently bumped the minimum specs to 16Mb. > systemd does not work well with musl which is very popular in embedded linux. Systemd can work with musl with a small compatibility shim, I did it about 9 years ago. Somebody did that again: https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-... reply jalgos_eminator 15 hours agorootparentOpenWRT is VERY sensitive to firmware size. I developed for a device with 16 MB flash that had both a normal (~11 MB) and recovery firmware (~3MB) on flash. The rest of flash was used for persistent storage, bootloaders, and calibration data. This is very common for older routers and APs which is the whole reason that OpenWRT exists. reply cyberax 15 hours agorootparentWell, OpenWRT doesn't even officially support devices with less than 16Mb of flash anymore: https://openwrt.org/toh/views/toh_available_16128 > The rest of flash was used for persistent storage, bootloaders, and calibration data. So you couldn't spare around 1Mb of compressed flash or 2Mb of uncompressed flash for systemd? > This is very common for older routers and APs which is the whole reason that OpenWRT exists. That hasn't been the case in quite some while. And it won't matter anymore, there is no price difference between 32Mb and 64Mb NOR or NAND flash. It's literally the same cost. reply jalgos_eminator 1 hour agorootparent> So you couldn't spare around 1Mb of compressed flash or 2Mb of uncompressed flash for systemd? Absolutely not. > That hasn't been the case in quite some while These routers and APs still exist and are in use. Yes, they are 10+ years old, but they're still out there. One of the main goals of OpenWRT is to support legacy networking hardware that vendors abandoned. reply cyberax 3 minutes agorootparent> Absolutely not. So basically, you're dealing with devices that use obsolete hardware and are designed to be extra-brittle (no safety margin), with a built-in planned obsolescence (what if the new update requires just a bit more space for \"calibration data\"?). Got it. sysvinit indeed fits perfectly. Make the system extra unreliable, to provide a stimulus to buy a newer version. > One of the main goals of OpenWRT is to support legacy networking hardware that vendors abandoned. And OpenWRT abandoned this goal. OpenWRT also can do nothing about firmware vulnerabilities in the old WiFi chipsets. Moreover, 10 years ago, systems with 32Mb were already common. simoncion 15 hours agorootparentprev> OpenWRT should just stop being stubborn and integrate it. Why? If it fails to provide benefits commensurate to the effort required to integrate it, then there's no reason to do the work. OpenWRT is for routers and access points... devices which usually have a fixed [hardware] configuration, and very little need for the absurdly-complex (and in my professional experience, often subtly buggy) event-driven systems that systemd provides. \"Every system everywhere gets to use the same unit files\" isn't a significant benefit in practice... EVERYTHING that needs nontrivial pre-/post- start/stop verification and/or configuration has systemd run a shell script (or other such helper) anyway... so you only get to just write a unit file and call it a day in the most trivial of cases. reply cyberax 15 hours agorootparentOpenWRT is a mess. It started as a small distro for routers, but it stopped being that long ago. Now it can host telephony services, full-blown Docker orchestration systems, etc. So you get all the pleasures of complex systems running on antiquated infrastructure. > so you only get to just write a unit file and call it a day in the most trivial of cases. What \"start/stop verification\"? Give examples, please. Systemd natively supports device dependencies, network status, other services, etc. It's a very rare case when you _need_ shell in systemd. reply simoncion 14 hours agorootparent> Now it can host telephony services, full-blown Docker orchestration systems, etc. What features that systemd provides that aren't provided by openrc, runit, monit, openrc's init system, etc, etc, etc that are needed by software like Asterisk, Docker/runc, Kubernetes, and similar? If what OpenWRT is running works fine to bring that up, then systemd doesn't have any relevant compelling features that aren't provided by another init system. Switching away from something just because it's \"antiquated\" is a great resume-building tactic, but it's a pretty poor strategy when your objective is to keep things that have been working working with a minimum of effort. > What \"start/stop verification\"? Give examples, please. One example (out of many) are pre-start, pre-stop, and pre-restart configuration file correctness verification so that a typo or thinko doesn't bring a service down. A concrete example of this is Gentoo's running of 'named-checkconf' in BIND 9's service file [0]. Gentoo's BIND 9 systemd unit file [1] tries, but probably does not do the same thing... I don't know if 'ExecStartPre' runs before systemd brings down a service on a 'restart' action, but I bet you that it definitely does not run on service stop. I just checked and Ubuntu 22 does NOT do this sort of checking for its bind9 package, which is pretty wild. > It's a very rare case when you _need_ shell [or other such helpers] in systemd. Then you're either running \"seatbelts off\" (maybe without even knowing that you are), or you rarely deal with anything nontrivial. This need comes up a LOT in my day-to-day. [0][2] [1][2] You might look at that file and be like \"wow, TL;WR\", but do try to notice how much of that file is dedicated to creating useful, human-readable status messages and error messages with good corrective instructions. If you care at all about your sysadmins, that complexity has to go somewhere, and that somewhere cannot be inside a systemd unit file... systemd just doesn't provide the features required to do that (and it would be kind of insane for the devs to even try). reply cyberax 13 hours agorootparentThis article explains the security features of systemd that make chroot superfluous: https://www.redhat.com/en/blog/mastering-systemd And here's an example of how a network service can be confined in its own network namespace: https://www.cloudnull.io/2019/04/running-services-in-network... - with zero shell needed, btw. reply cyberax 13 hours agorootparentprev> What features that systemd provides that aren't provided by openrc, runit, monit, openrc's init system, etc, etc, etc that are needed by software like Asterisk, Docker/runc, Kubernetes, and similar? Dependencies, watchdogs, start only when the given network interfaces are available, declarative configuration so that can be partially customized, etc. > If what OpenWRT is running works fine Unless you try to update it. And end up with merge conflicts in the /etc directory. And then it stops booting, and you have to get in via the serial port. No, OpenWRT is most definitely not fine. It's stuck in the past, and doesn't support automated rollback, configuration management, etc. > A concrete example of this is Gentoo's running of 'named-checkconf' in BIND 9's service file [0] Wow, what a... But named config has always been a disaster zone. With systemd _none_ of that crap is needed. It can use its own namespacing and cgroup support to ensure that BIND9 can't read outside of its allowlisted tree. If you want to run /usr/bin/named-checkconf, then it's just an ExecStartPre directive in the unit file. And unlike SysV that just fails to run and forces you to dig into the logs, systemd provides you a nice status saying that the pre-exec had failed. > You might look at that file and be like \"wow, TL;WR\", but do try to notice how much of that file is dedicated to creating useful, human-readable status messages and error messages with good corrective instructions. Yeah, and hanging indefinitely, forcing me to do a trip to the datacenter at night (true story): https://lwn.net/Articles/619565/ reply amelius 20 hours agoparentprevThis should be the top comment. reply cozzyd 19 hours agoprevI run systemd-based Debian just fine on 512 MB RAM BeagleBoneBlack SBCs with 4GB emmcs. Now emacs, that's a problem due to the large install size. reply TacticalCoder 16 hours agoparent> Now emacs, that's a problem due to the large install size. I was running Emacs on a 486 with something like 16 MB of RAM. Don't remember the HDD size. The Emacs executable I built from source is about 28 MB. Honestly I don't know what else is needed besides that executable that'd be really big. Is it really that problematic that it wouldn't work with 512 MB of RAM and 4 GB of storage? reply cozzyd 16 hours agorootparentI think the problem is the Debian packaging, which has hundreds of MB of elisp or something. https://packages.debian.org/sid/emacs-common (yes, it does fit, but it takes up way more space than I'd like...) reply neuroelectron 19 hours agoprevAs for a solution to this, wouldn't it be possible to use systemd to build a targeted init script? Use the expertise embedded in systemd to bring up the system you're targeting, recording how it does that and then removing systemd, leaving the artifacts? Why keep this huge monolithic system running in the background after it has served its purpose? Also, with ai, would it be possible to redraw the lines within systemd between the separate domains/concerns, then redistribute the functions back to where they conceptually belong? Then you can refine those changes to make them more standardized and universal instead of interdependent and centralized. reply is_taken 21 hours agoprevYou could checkout void and alpine. reply kj4ips 6 hours agoprevTBH, my biggest gripe is that systemd doesn't play nice with musl or ulibc, I would like to not have to ship a cron, a supervisor, a xinetd equivelant, and a binary just to react to inotify/dnotify events. Though openrc how has a supervisor. reply rettichschnidi 19 hours agoprevWe (https://github.com/husqvarnagroup/smart-garden-gateway-publi...) are using systemd on devices with 128 MB of RAM and are happy with it. It solves so many problems one usually has to fiddle with, totally worth a few MBs of RAM. reply greatgib 19 hours agoprevI'm quite annoyed by the bland statement in the introduction of this article: people make about it don’t stand up to much scrutiny, even the technical ones Basically the author says that everyone else has stupid rants that doesn't stand but himself has valid claims so that in the end we have a proof that there are a few valid technical rants! That being said, the main problem with systemd from the beginning is that it is a cancer. It was explicitly designed to prevent as much as possible the modularity and intercompatibility. Kind of opposite to the POSIX way even I think. Despite what is pretended, doing the things would probably not have impacted features, like boot speed but it was key for them to shove through our throat the usage of systemd in a \"all or nothing\" way. And udev or logind are good example of that. reply reanimus 18 hours agoparentI think it's fair to say the majority of people don't really care about any of those things as much as having a system that just works -- which was part of their whole argument regarding why package maintainers love it so much and end users really don't tend to care. reply kytazo 5 hours agorootparentI would assume people using Linux more or less care to an extend reply Vilian 17 hours agoparentprevAnd systemd replace all POSIX init system because they were all bad or systemd do the same thing better or faster, your point is a good argument against following POSIX religiously reply 0xbadcafebee 15 hours agoprevSystemd, Wayland, DBus, and other modern Linux \"solutions\" are all problematic for the same reason: they are complex monoliths that are extremely difficult to replace, in part or in whole. Systems often won't work without them, because the entire ecosystem has grown dependent on them. You literally can't run a modern desktop without a bunch of \"shims\" whose sole purpose is to fake being systemd. The best designs, sadly, don't win out. The ones that win out are the ones that serve the interests of the largest players. And the largest players are usually RedHat, Google, and other vendors, who just want to get \"their\" needs met and move on. They couldn't give a fig about compatibility with some other random tiny project, or an embedded device. And those people working on tiny projects aren't in the room when \"standards\" are decided for the entire community. There are some hold-outs. Slackware went a long time without it, but next release will unfortunately use systemd. I've run Alpine Linux (systemd-free, so far) as my laptop OS for years. I'll probably switch to another distro that's more user friendly, is easier to contribute to. But it's embarrassing and annoying that we have to pretend to be systemd-compatible just to run a desktop. We should call it \"GNU/Systemd/Linux\" since it's now one big monolith. reply TheCycoONE 14 hours agoparentWayland seems like an odd entry in that list. It's mostly a strugle for people because it's not the monolith X was and now we have dozens or hundreds of different applications from different vendors to cover a subset of the functionality that was built in. In that sense X was the complex monolith that is extremely difficult to replace. Also unlike the complaints about systemd in the article, Wayland is well suited to embedded. Automotive Grade Linux was an early adopter. It's desktop usage that has taken longer. reply 0xbadcafebee 2 hours agorootparentThat is an odd one. While X is definitely an ugly monolith, Wayland is microservices. I think that speaks volumes... reply thnkman 15 hours agoparentprevWhere have you heard that Slackware will be using systemd next release? I have been using slackware for years, and this is news to me. reply pwg 14 hours agorootparentThere's nothing named \"systemd\" in the FILE_LIST [1] for Slack64-current (which is what eventually becomes \"the next release\" at the appropriate time. So it would seem the GP has been taken in by some rumor somewhere. [1] https://ftp.ussg.indiana.edu/linux/slackware/slackware64-cur... reply 0xbadcafebee 2 hours agorootparentI thought I saw in the last release a note that the next one would come with systemd. It could be I hallucinated it. Maybe I'm becoming a real LLM! reply oceanplexian 20 hours agoprevI used it heavily at work. Then moved to a shop that does exclusively containers and realized how incredibly immature engineers’ understanding of the problem space is. Container startup ordering, startup dependency management, socket handling and all things timing and network related are frankly a complete mess in modern infrastructure. Even, surprisingly in well maintained projects like k8s. I find myself shaking my head at problems solved by systemd a decade ago far too often. reply richardfey 13 hours agoprevI think author is missing on the Devuan-maintained udev fork. reply Mave83 20 hours agoprevFor me as a user, systemd is far better than old init systems. The logging alone is worth it to switch to it. Add more ram to the embedded board and welcome to the future. reply simoncion 15 hours agoparent> The logging alone is worth it to switch to it. Weird. In my professional life, I've found systemd's logging to be woefully lacking when compared to systems that just run every daemon through syslog (or -even more retro- \"each daemon writes stdout & stderr to disk, which then gets sent to your log sink of choice\"). What I usually find is that a ton of information never, ever makes it into journalctl, so I always need to go to the actual log files on disk. [0] On top of that, journalctl just fucking giving up when logs have been rotated is totally bogus. (If this has been fixed, then the fix hasn't made its way to the systems I work with.) ALSO, have they fixed the issue where minor data corruption just totally fucks your log file to death... rather than what happens with regular log files and you get an unreadable section that's bracketed by good data? [0] Yes, you could reasonably say \"Well, those services are not correctly configured to log to journalctl!\". But my point here is that I see this happen so often that journalctl is like my tenth stop for log messages, rather than my first. reply hansvm 20 hours agoprevNot really embedded, but one of the easier classes of wins I've had over the years is moving prod servers to a non-systemd Gentoo. Random (rare) 200ms latency spikes and whatnot just disappear, and the system jitter drops down to the tens of microseconds range, significantly improving the qualitative performance of basically every piece of software I care about. reply BenjiWiebe 18 hours agoparentDid you ever dig in to see why that changed? I'm surprised that in a steady-state (not booting or restarting services) systemd/not-systemd would have an impact. reply hansvm 16 hours agorootparentA little bit. The tldr; is that there are a lot of periodic activities including log rotation, automatic updates, time syncing, waking up to check if such things were currently needed, .... Those are generally nice (aside from automatic updates, which are sometimes good but I think usually more harmful than whatever they're fixing), but systemd doesn't know anything about what my userspace demands on the hardware are, and it's generally happy to hog system resources if it doesn't do so for long. For anything quasi-realtime, I can certainly hunt down and squash everything systemd is running at the wrong time, but in practice it's much easier to install something else, ensure no processes are running other than the ones I care about, and move those concerns to userspace. reply howtofly 14 hours agorootparent> For anything quasi-realtime, I can certainly hunt down and squash everything systemd is running at the wrong time, but in practice it's much easier to install something else, ensure no processes are running other than the ones I care about, and move those concerns to userspace. Should these issues be fixed by CPU/IO schedulers? Are there any systemd realtime tasks involved? reply hansvm 6 hours agorootparentNow that the realtime patch is in mainline Linux, that approach might make more sense going forward. I don't think systemd has any meaningful realtime tasks by default. My current job has a different set of performance constraints (only need low latency something like 99% of the time, so systemd and noisy cloud neighbors and whatnot are fine), so I probably won't be looking at that part of the stack in any depth any time soon. reply iluvcommunism 16 hours agoprevI like systemd sometimes. Other times it confuses me. Particularly the way cgroups work. The way splicing works. Why oracle mem usage is still uncontrollable when I set user splice restrictions. Idk, I’m still learning it. I don’t like the terminology it uses sometimes too like “snapshot.” When I first read about systemd snapshot I was like oh cool you can snapshot the system. No. Also some esoteric things it supposedly supports don’t work sometimes. I find the idea of systemd targets and fstab having anything to do with each other anathema. Idk. reply johnea 20 hours agoprevThe article fails to mention another aspect of systemd that interferes with emmbedded dvelopment: it's utility applications (primarily systemctl, but all the others as well) are intended to be run on the booted system for which the control is being performed. When configuring boot media, like an SD card, for an embedded ssystem that is not the running system where the configuration is occurring, this is an impediment. There is systemd-firstboot, etc, but this is not as convenient as just being able to set config options on the mounted (non-booted) embeddded media. I've never liked it, I still don't like it, and I think the number of people in this camp is understated by the article. However, I am still running it. As other posts have mentioned, switching distributions is a major hasstle, especially if you've built tools using the distro's architecture. For me, this is archlinux. Although, I am in the process of testing and migrating to void linux. Which is systemd free, and hosts ARM and x86 binary package repositories. reply stefanha 19 hours agoparentCan you be specific about what cannot be configured on mounted embedded media? systemd follows the drop-in config file model where configuration snippets are placed into directories (like .d/ directories in Debian). It should not be necessary to run utilities from the target system in order to configure it on mounted media. Drop unit files for services, sockets, filesystem mounts, timers, etc onto the mounted media and they will be detected when the target system boots. reply blucaz 17 hours agoparentprev> When configuring boot media, like an SD card, for an embedded ssystem that is not the running system where the configuration is occurring, this is an impediment. There is systemd-firstboot, etc, but this is not as convenient as just being able to set config options on the mounted (non-booted) embeddded media. systemctl --root /path/to/sd/card/reply worthless-trash 15 hours agoprevExcellent plan, go to the other inits, bug bounties are what I do over christmas and init systems and hand rolled init scripts are a great source of security flaws. Taking notes on which distros dont run systemd, for when I want to make some money over christmas. reply DaSHacka 9 hours agoparentNo need to stop at non-systemd inits! https://security.gentoo.org/glsa https://security.archlinux.org/issues/all ^ (ctrl+f systemd) https://ubuntu.com/security/cves?package=systemd&limit=100 https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=Systemd reply m0llusk 7 hours agoprevIt is unfortunate that after all this time the basic reasons why systemd was introduced and has been so successful are pervasively misunderstood. > The majority of Linux users are uninterested in the pros and cons of systemd. A small number are violently opposed to it, and a small number are violently opposed to those who are opposed to it. Starting out by framing systemd in terms of opposition deliberately steers attention away from the issues that drive its adoption. The tone is moderate, but this is not good faith argumentation. > I think there’s little argument that the main target for systemd is a general-purpose computer, with a modern, integrated graphical desktop That is one of the targets. The main target is servers that run the web of services typically required to back up modern applications. What if an application depends on a resource server which itself depends on a remote filesystem being mounted and an event service running. Theoretically that can work with System V init, but how tricky is that to put in place and make robust? Administrators for systems vending complex interdependent services are the main target and always have been. > Unfortunately, what makes systemd good for general-purpose desktop applications Get it wrong and then run with it. Failing to understand what is driving adoption of systemd leads to arguments about it that don't really go anywhere. > The more fundamental problem is that the people who most like systemd are distribution managers. Sure, there are administrators who like it, and defend it vigorously; but most end users and administrators don’t really care. Not distribution managers, but system administrators. They are the ones with the complex needs that systemd serves. As such they advocate for it and because of the lack of working alternatives distribution managers switch to it in order to please the largest number of clients. Thinking of systemd in terms of desktop systems and distribution managers means misunderstanding why it is there in the first place. reply foul 19 hours agoprevMeh, we are not in 2021 or 2018 anymore. Eudev and elogind ARE mantained and used in voidlinux and gentoo, and anyways being that embedded it doesn't seem clear to me where would the \"hard dependency of a very essential software on some systemd-thingd\" happen. reply nubinetwork 14 hours agoparenthttps://www.gentoo.org/support/news-items/2021-08-24-eudev-r... reply foul 7 hours agorootparenthttps://github.com/eudev-project/eudev https://github.com/elogind/elogind reply Jean-Papoulos 11 hours agoprev\"I'm using a thing in a way it's not meant to be used and it sucks\" Is this even a serious post. reply robertlagrant 9 hours agoparentIt is a serious post; you've just summarised it appallingly. reply colonwqbang 20 hours agoprevThis is anti-systemd FUD. Implying that applications which work without systemd are going to stop doing so. Suggesting that Linux distributions adopted systemd because it's good for distributors and not because users actually want it. We are \"forced\" to use systemd's udev implementation. Please. reply felixgallo 20 hours agoparentAll of those things are trivially true. What are you disagreeing with? reply viraptor 20 hours agorootparentThere are extremely few use cases where your app may want to integrate with systemd. Out of those, you get again a small percentage that can't be trivially made optional. (99.9% is just optional notification and socket passing) Outside of large projects which are interested in full system integration like gnome, nobody breaks apps to not work without systemd. reply consteval 3 hours agorootparentprevExcept none of these are true, they're just things people have made up to conceal the fact they oppose systemd for ideological reasons. There's little to no technical arguments against systemd - it's fast, much more robust than what came before it, and services 99% of usecases. Users DID want systemd. Ask any sys admin, most much prefer systemd. Also systemd doesn't \"force\" anything. Most distributions don't even ship all systemd projects, just a couple. systemd-init IS small. The idea that systemd is a big ole monolith is just not true, and one glance at the git repo reveals that. reply felixgallo 1 hour agorootparentoh definitely not, and it's a matter of record. Red Hat and Poettering wanted systemd in order to control more of the platform; this is why they absorbed in udev (which had been a separate repo), came out saying that there are certain parts of the system that, despite all this being open source, were forbidden to modify or replicate, and stacked the debian voting. Systemd at the time sucked, incredibly, even worse than it does today, and routinely bricked or crashed systems. The adoption was forced and 100% political. systemd is, of course,today a continuing shambling feature factory behemoth in which hundreds of product managers try to shoehorn in more mandatory features in order to cement grip on the platform. That's why you get this ridiculous dns nonsense, this ridiculous container nonsense, this ridiculous cron nonsense, hostnamed (!), the list is endless. The technical argument is that it's a giant tasteless bag of ever increasing poorly implemented scope. The rest of Unix, by comparison, is generally not that way. If you pick up a BSD or even an alpine, you'll find that you don't need a bunch of badly written, hacked together garbage in order to get your work done. The system can be entirely readable and repeatable without cramming a bunch of cruft and poor decisions into pid 1. The idea that systemd doesn't 'force' anything is, of course, hilarious. Systemd is designed to try to be the ultimate mandatory dependency for essentially everything on the system. That's the way Red Hat wanted it to be, and that's the way it is. Every time someone mentions systemd, some random apologist dutifully trots out the idea that systemd-init is small and therefore systemd is not a monolith, checkmate. Of course, journald, libudev, localed, logind, hostnamed, homed, networkd, resolevd, systemd-boot, systemd-bsod, systemd-nspawn, timedated, timesyncd, tmpfiles, udevd, and all of the other array of dumbass bolted-on second-system-effect-driven product-managed nonsense somehow don't get mentioned. reply consteval 8 minutes agorootparent> Red Hat and Poettering wanted systemd in order to control more of the platform Speculative and ideological. From a technical perspective, I don't care about this. > despite all this being open source, were forbidden to modify or replicate This isn't true - you're allowed to modify or replicate any parts of systemd and always have been. > systemd is, of course,today a continuing shambling feature factory behemoth in which hundreds of product managers try to shoehorn in more mandatory features in order to cement grip on the platform I'm not sure you understand what systemd is. systemd is not a piece of software, systemd is an endeavor. Many, many projects are under \"systemd\", as in they have the name, but they are all individual binaries. Practically 0 distros include all systemd binaries, because they're optional. Many projects already existed before systemd, like gummi boot, and were just given the name. > The rest of Unix, by comparison, is generally not that way This is untrue, as systemd follows unix principles. systemd-init does one thing and one thing only - it's only the init system. systemd-networkd is just the network daemon. systemd-journald is just the logger. And on and on. Despite what you may think, they ARE optional, and distros mix and match constantly. > without cramming a bunch of cruft and poor decisions into pid 1 Again, out of the dozens and dozens of binaries under the systemd umbrella, only one (1) runs under PID 1. This simply isn't true. > Systemd is designed to try to be the ultimate mandatory dependency for essentially everything on the system. That's the way Red Hat wanted it to be, and that's the way it is Speculation, ideological, and not evidence backed. > Of course, journald, libudev, localed, logind, hostnamed, homed, networkd, resolevd, systemd-boot, systemd-bsod, systemd-nspawn, timedated, timesyncd, tmpfiles, udevd, and all of the other array of dumbass bolted-on second-system-effect-driven product-managed nonsense somehow don't get mentioned Yeah... because those are separate programs. Maybe you just don't understand how computers work, but these programs are unrelated. They talk over IPC, they're not even linked together on any systems. You can take or leave any of them, and many distros do. Even Debian, the supposed systemd cocksucker, doesn't include half of these. reply blueflow 19 hours agoprev [–] There is another aspect to the memory footprint: Does systemd fit into the L1 cache? Does sysvinit? Both x86 and Linux (page cache) rely on caches for performance. reply worthless-trash 15 hours agoparent [–] I'm not sure that fitting a init system in L1 cache should be a priority when it would be swapped out almost immediately on doing further work, aka the purpose of the device. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Kevin Boone highlights the challenges systemd presents for embedded Linux systems, noting its resource-heavy nature compared to traditional alternatives like SystemV init.",
      "Systemd's components, such as the init process and logging daemon, increase memory usage and boot times, making it less ideal for devices like the Raspberry Pi.",
      "Boone advocates for supporting Linux distributions that do not rely on systemd and developing alternatives to ensure flexibility and effectiveness in embedded environments."
    ],
    "commentSummary": [
      "The debate on systemd's appropriateness for embedded Linux systems persists, with critics pointing out its high memory usage, longer boot times, and complexity as disadvantages for resource-limited devices.",
      "Proponents of systemd argue that it provides enhanced service management and responsiveness, particularly beneficial for devices with sufficient resources.",
      "This discussion highlights the broader conflict between systemd's all-encompassing approach and the Unix philosophy of using small, modular tools."
    ],
    "points": 200,
    "commentCount": 243,
    "retryCount": 0,
    "time": 1730670146
  },
  {
    "id": 42036303,
    "title": "Do you need Redis? PostgreSQL does queuing, locking, and pub/sub (2021)",
    "originLink": "https://spin.atomicobject.com/redis-postgresql/",
    "originBody": "← Back to Blog Home Do You Really Need Redis? How to Get Away with Just PostgreSQL Web Apps by: Chris Farber February 4, 2021 Twitter Facebook Linkedin Hackernews Article summary Use Case 1: Job Queuing Use Case 2: Application Locks Use Case 3: Pub/Sub Taking Full Advantage of PostgreSQL There’s a tried-and-true architecture that I’ve seen many times for supporting your web services and applications: PostgreSQL for data storage Redis for coordinating background job queues (and some limited atomic operations) Redis is fantastic, but what if I told you that its most common use cases for this stack could actually be achieved using only PostgreSQL? Use Case 1: Job Queuing Perhaps the most common use of Redis I’ve seen is to coordinate dispatching of jobs from your web service to a pool of background workers. The concept is that you’d like to record the desire for some background job to be performed (perhaps with some input data) and to ensure that only one of your many background workers will pick it up. Redis helps with this because it provides a rich set of atomic operations for its data structures. But since the introduction of version 9.5, PostgreSQL has a SKIP LOCKED option for the SELECT ... FOR ...statement (here’s the documentation). When this option is specified, PostgreSQL will just ignore any rows that would require waiting for a lock to be released. Consider this example from the perspective of a background worker: SQL BEGIN; WITH job AS ( SELECT id FROM jobs WHERE status = 'pending' LIMIT 1 FOR UPDATE SKIP LOCKED ) UPDATE jobs SET status = 'running' WHERE jobs.id = job.id RETURNING jobs.*; COMMIT; By specifying FOR UPDATE SKIP LOCKED, a row-level lock is implicitly acquired for any rows returned from the SELECT. Further, because you specified SKIP LOCKED, there’s no chance of this statement blocking on another transaction. If there’s another job ready to be processed, it will be returned. There’s no concern about multiple workers running this command receiving the same row because of the row-level lock. The biggest caveat for this technique is that, if you have a large number of workers trying to pull off this queue and a large number of jobs feeding them, they may spend some time stepping through jobs and trying to acquire a lock. In practice, most of the apps I’ve worked on have fewer than a dozen background workers, and the cost is not likely to be significant. Use Case 2: Application Locks Let’s imagine that you have a synchronization routine with a third-party service, and you only want one instance of it running for any given user across all server processes. This is another common application I’ve seen for Redis: distributed locking. PostgreSQL can achieve this as well using its advisory locks. Advisory locks allow you to leverage the same locking engine PostgreSQL uses internally for your own application-defined purposes. Use Case 3: Pub/Sub I saved the coolest example for last: pushing events to your active clients. For example, say you need to notify a user that they have a new message available to read. Or perhaps you’d like to stream data to the client as it becomes available. Typically, web sockets are the transport layer for these events while Redis serves as the Pub/Sub engine. However, since version 9, PostgreSQL also provides this functionality via the LISTEN and NOTIFY statements. Any PostgreSQL client can subscribe (LISTEN) to a particular message channel, which is just an arbitrary string. When any other client sends a message (NOTIFY) on that channel, all other subscribed clients will be notified. Optionally, a small message can be attached. If you happen to be using Rails and ActionCable, using PostgreSQL is even supported out of the box. Taking Full Advantage of PostgreSQL Redis fundamentally fills a different niche than PostgreSQL and excels at things PostgreSQL doesn’t aspire to. Examples include caching data with TTLs and storing and manipulating ephemeral data. However, PostgreSQL has a lot more capabilities than you may expect when you approach it from the perspective of just another SQL database or some mysterious entity that lives behind your ORM. There’s a good chance that the things you’re using Redis for may actually be good tasks for PostgreSQL as well. It may be a worthy tradeoff to skip Redis and save on the operational costs and development complexity of relying on multiple data services. databasepostgreSQL Chris Farber All Posts → Related Posts Web Apps Embed Payload CMS 3.0 Admin UI in Your Next.js App Web Apps Remix is Incredible — If It Fits Your Use Case Web Apps Vercel: A Valuable Debugging Tool Conversation Nitin Sareen says: May 12, 2021 Well explained Chris, thanks for the insights. almokhtar says: June 13, 2021 thank you so helpful !! Hrvoje Matic says: June 16, 2021 Aren’t you losing performance then (redis being in-memory store)? ÉTIENNE BERSAC says: June 16, 2021 Hi, Thanks for this great article ! I known a few implementation of message queue on top of Postgres in Python : https://gitlab.com/dalibo/dramatiq-pg and https://github.com/peopledoc/procrastinate to name a few. Also for ruby : https://github.com/que-rb/que. Full disclosure, I maintain Dramatiq-pg. ;-) Regards, Daniel Koch says: June 16, 2021 What about performance? Jobs pushing to redis is really fast and this will matter when you have to push jobs before giving a http response. Bob Haugen says: June 18, 2021 Good tips, we use PostgreSQL, but I would also be interested in the performance tradeoffs. Luke says: June 19, 2021 The main issue I see with advisory locks is – you will likely eventually need or want to use a connection pooler like pgbouncer if your application grows – session-based advisory locks don’t play nicely with such an approach, since they will be shared by any client sharing the same connection via pgbouncer, negative the purpose of the lock I don’t think this means you shouldn’t use advisory locks, but this is a significant tradeoff. Vladimir says: December 30, 2021 I 100% agree with the opinion. Transaction-based advisory locks are not OK – we can’t open the transaction and keep it opened to achieve the pessimistic lock behavior. It is too expensive for Postgres. Session-based advisory lock trade-offs are already perfectly described. I should just add one more note – Imagine you have to reload your server, so you have to close the connection. You’ll lose all your locking information, which will lead to the pessimistic lock feature failure. Unfortunately, Advisory locks are not suitable for the user-defined (frontend-defined) pessimistic locking. Actually, at this stage, PostgreSQL is not suitable for the pessimistic locking feature at all (not scalable enough) Artur says: June 21, 2021 NOTIFY has char limit but Pub/Sub not. Rodolphe Quiédeville says: June 21, 2021 About queuing dans PostgreSQL you must have a look at Procrastinate project. https://procrastinate.readthedocs.io/en/stable/ Comments are closed. Platforms & Languages Category Svelte GitHub Actions Realm Azure Vue C# PostgreSQL React Native React / Redux Kotlin Blockchain Scala Desktop Apps JavaScript Rust FaunaDB Flutter Angular AWS Prisma Functional Programming Web Apps Mobile Apps Embedded Systems DevOps & System Admin. Android Development C & C++ Java Ember.js iOS / OS X jRuby .NET / WPF Objective-C Presenter First Python Ruby Ruby Motion Ruby on Rails Swift TypeScript Related Posts Web Apps Embed Payload CMS 3.0 Admin UI in Your Next.js App Web Apps Remix is Incredible — If It Fits Your Use Case Web Apps Vercel: A Valuable Debugging Tool",
    "commentLink": "https://news.ycombinator.com/item?id=42036303",
    "commentBody": "Do you need Redis? PostgreSQL does queuing, locking, and pub/sub (2021) (atomicobject.com)191 points by fanf2 21 hours agohidepastfavorite124 comments pjs_ 20 hours agoBecause everyone insists on insanely distributed architectures, most people will never really see the point of Redis, which is that if it is running on the same machine as the application, it can respond in much less than a millisecond. That lets you do stuff in the application that you just can't do with Postgres. Postgres kicks ass obviously but it is not running in memory on the same machine as the application. If all you want to do is queues and whatnot, then sure, you don't need an in-memory KV store. The point of an in-memory KV store is to do stuff that needs the performance characteristics of RAM. You obviously can't get the performance characteristics of RAM over a network connection. This is like, a tautology. reply roncesvalles 20 hours agoparentIf the setup is that only one local process will use on-machine Redis as an in-memory cache, you're better off using the data structures available in your programming language. reply jvanderbot 4 minutes agorootparentUnless you need persistence across process respawning, ipc across lots of subprocesses, or want to trivially inspect and namespace your entire in memory data. But yeah redis is not an answer for most single machine questions. reply zamalek 19 hours agorootparentprevRedis can cluster alongside your backend cluster, so you'll have the advantage that sometimes the data will be local. reply edanm 5 hours agorootparentprevYes, that's assuming a single local process. Redis bills itself as an in-memory data structure store, and at least in my memory, it was mainly pitched for doing interprocess communication with real data structures. reply teaearlgraycold 19 hours agorootparentprevThis is the vanillajs.com of data stores. reply baq 13 hours agorootparentprevWhy? Most languages are less memory efficient than redis, even in a separate process, and I don’t want to reimplement half of its features. reply cstadnij 12 hours agorootparentBecause it's really, really slow compared to in-language variables? I've not yet ran out of memory because of program variables, and speed shouldn't be an argument for low memory footprint when it's already at best 1/10 of it's performance. reply speedgoose 12 hours agorootparentRedis locally is good to do IPC though. You have many scenarios where multi local processes have to exchange data. You have alternatives but Redis works and can scale up. reply mgraczyk 10 hours agorootparentprevYou can do a mutex in like 10 bytes, how could redis be more memory efficient? reply baq 1 hour agorootparentyou are using the minority language if that's the case for you. reply bryanrasmussen 10 hours agorootparentprevall the other reasons beside - because at some point I might want to move the data cache off of the single machine and then I can do that with a couple of minutes work, yes then I am back to do I need redis why not use postgres, but I got months of better performance out of redis than I would have with postgres, if I need to move to separate machine I am probably doing good enough I can afford it. Redis helps you get to the point (need cache on separate machines) where you might want to consider moving to postgres, or not because you don't feel it warrants the investment of programmer hours at that point. on edit: got downvoted for ..? I guess what I said was so supremely stupid I deserved it. I do admit it was perhaps slightly obvious, but not so obvious that it warranted downvoting reply ryandvm 5 hours agorootparentDon't build today what you might need tomorrow. reply threeseed 19 hours agorootparentprevNot really. Because then once you restart that process you lose everything. And it's far more likely you are continuously upgrading your process than Redis. reply bastawhiz 15 hours agorootparentIf you need that, you can use an embedded data store like leveldb/rocksdb or sqlite. Why bring another application running as its own process into the equation? reply 112233 12 hours agorootparentBut having separate applications can give you better perfomance and isolation than one single threaded process? Or do you compare using separate processes to having multiple threads in a single process? reply bastawhiz 5 hours agorootparentThere's no universe where a single threaded embedded persistence implementation is slower than a single threaded application synchronously talking to a single threaded database over the network stack. As far as isolation goes, if you are worried about the properties of reading and writing data to the disk then I simply don't know what to tell you. Isolation from what? reply nine_k 14 hours agorootparentprevRunning in its own process, and, better yet, in its own cgroup (container) makes potential bugs in it, including RCEs, harder to exploit. It also makes it easier to limit resources it consumes, monitor its functioning, etc. Upgrading it does not require you to rebuild and redeploy your app, which may be important if a bug or performance regression occurs is triggered, and you need a quick upgrade or downgrade with (near) zero downtime. Ideally every significant part should live in its own universe, only interacting with other parts via well-defined interfaces. Sadly, it's either more expensive (even as Unix processes, to say nothing of Windows), slower (Erlang / Elixir), or both (microservices). reply LtWorf 9 hours agorootparentAt the cost of requiring a lot of IPC and memory copying. reply throwaway81523 12 hours agorootparentprevEither fork the process so the forked copy can dump its data (I think Redis itself does something like this), or launch a new process (with updated code if desired), then migrate the data and open sockets to it through some combination of unix domain sockets and maybe mmap. Or if we had OS's that really used x86 segmentation capability as it was designed for (this is one thing the 386 and later did cleverly) it could all be done with segments. reply mcv 12 hours agorootparentNow you're making it complicated again. I think a good rule of thumb is: * If you need it from a single process and it doesn't need to survive process restarts, just use basic in-process data structures. * If you need it from multiple processes or it needs to survive process restarts, but not system restarts, use redis. * If it needs persistence across system restarts, use a real DB. reply throwaway81523 11 hours agorootparentRedis is nice but you take a huge speed hit depending on what you're doing, compared to using in-memory structures. Note that Redis can also persist to disk, either by forking or by writing an append-only op log that can be replayed for reloading or replication. Anyway, you'veve forgotten the case where you want not only the data structures, but also the open network connections to persist across process restarts. That's what passing file descriptors through unix domain sockets lets you do. It gets you the equivalent of Erlang's hot upgrades. reply xxs 10 hours agorootparentprev>I think Redis itself does something like this) It does... and it's a blocking operation (Bad). It's used when storing data to a file to allow restarts w/o losing the said data. reply nomel 20 hours agoparentprev> but it is not running in memory on the same machine as the application. What's the overhead of postgres vs redis, when run locally? Why do you think postgres isn't run locally? There's nothing special about postgres. It's just a program that runs in another process, just like redis. For local connections, it uses fast pipes, to reduce latency, and you get access to some faster data bulk transfer methods. I've used it in this way on many occasions. reply threeseed 20 hours agorootparentPostgreSQL does not have the concept of in-memory tables. Except for temporary tables which are wiped after each session. reply nomel 19 hours agorootparentThat's simplifying things a bit. Postgres has a shared memory cache, which can be set the same as redis, so your operations will all happen with in memory, with some background stuff putting it onto disk for you in the case your computer shuts off. Storage won't be involved. BUT, postgres still has ~6x the latency [1], even when run from memory. [1] https://medium.com/redis-with-raphael-de-lio/can-postgres-re.... reply jeltz 19 hours agorootparentPretty pointless benchmark since it does not use prepared statements (that much is obvious from the low TPS, plus I confirmed it with how he ran the benchmark). You need to pass \"-M prepared\" to pgbench. And it is very possible that the Redis benchmark is equally flawed. If you have to parse and plan queries every time PostgreSQL is obviously much slower than Redis. It is much more interesting to see what happens if prepared statements are used. reply phiresky 9 hours agorootparentprevThe article is flawed, here's an issue of someone fixing some of the issues: https://github.com/raphaeldelio/redis-postgres-cache-benchma... reply jeltz 5 hours agorootparentThanks, I spotted the lack of prepared statements and stopped looking after that but you spotted the rest of the issues too. And, agreed, it is likely that the Redis benchmark is flawed too but I do not know Redis well enough. reply threeseed 19 hours agorootparentprevBut the whole point here is that PostgreSQL will be used for other tasks e.g. storing all of your business data. So it will be fighting for the shared cache as well as the disk. And of course storage will still be involved as again you can't have in-memory only tables. And having a locking system fluctuate in latency between milliseconds and seconds would cause all sorts of headaches. reply sgarland 19 hours agorootparentIf you are both small enough that you’re considering cohosting the app and DB, the odds are good that your working set is small enough to comfortably fit into RAM on any decently-sized instance. > And having a locking system fluctuate in latency between milliseconds and seconds would cause all sorts of headaches. With the frequency that a locking system is likely to be used, it’s highly unlikely that those pages would ever get purged from the buffer pool. reply threeseed 19 hours agorootparentOnce again. PostgresSQL does not have in-memory tables. So: a) Writes will be happening on a slow, highly contentious disk. b) You have no guarantees that the data will be in-memory. Both of which make it a poor solution for use cases such as locking. reply natmaka 15 hours agorootparentAs pointed out by blackenedgem above: PostgreSQL has tablespaces, and one may simply declare tables which should stay in RAM in a tablespace built upon a tmpfs with enough reserved RAM to store them all. There is a only small associated burden (restoring the tablespace while starting PG). reply chipdart 18 hours agorootparentprev> And of course storage will still be involved as again you can't have in-memory only tables. That's fine. If what you want is a single-node deployment combined with in-memory purism them SQLite has your back. reply blackenedgem 19 hours agorootparentprevNo but it does have the concept of tablespaces. If you want you can map RAM to a disk location, set that up as a tablespace, then tell postgres to use that tablespace for your given table. Also set the table as UNLOGGED while you're at it. A bit more work yes that could be simplified, but fully supported if you control the stack. reply nine_k 14 hours agorootparentYes. Putting a Postgres tablespace on a RAM disk (tmpfs) does wonders. Even if NVMe may be comparable to RAM by bandwidth, whatever Postgres has to do to ensure that data are written to the durable store as a part of a commit is still significantly slower compared to RAM. Highly recommended for running tests, especially in CI/CD pipelines. Doing this simple change can speed up DB-heavy tests 30-50%. reply pdhborges 19 hours agorootparentprevWell if your working set fits RAM your tables will be stored in memory in the shared buffers. reply chipdart 18 hours agorootparentprev> PostgreSQL does not have the concept of in-memory tables. Is that relevant though? Some benchmarks on the web show Postgres outperforming Redis in reads as well as low-volume writes (less than 1k key-value pairs), and Redis only beating Postgres for high volume key-value writes. reply threeseed 18 hours agorootparent> Redis only beating Postgres for high volume key-value writes I wonder what type of use cases have high volume writes. Maybe queuing, locking and pub/sub ? reply jeltz 10 hours agorootparentUsually none of them. Queuing is almost never high volume and rarely is pub sub. reply Eikon 20 hours agoparentprevYou know what performs better than redis in this setup? An hashmap. Why Postgres wouldn’t run on the same server as the app? It’s actually pretty common. reply secretmark 20 hours agorootparentWhat if there are multiple processes that require access to a shared cache? reply mbreese 19 hours agorootparentAnd I think this is the main use case they were looking for. If you have a web app where each request is a separate process/call (not uncommon), and you don’t have a good shared global state, Redis is a great tool. It is an in-memory data structure store that can respond to requests from different processes. I always considered it an evolution from memcached. If you only have one long lived process or good global variable control, then it is much less appealing in the single-server scenario. Similarly, if you require access from multiple hosts, it becomes a less obvious choice (especially if you already have a database in the loop). And redis is also overkill is you’re using it only as a cache. reply xxs 9 hours agorootparentprev>shared cache As in performance improvement - cache should never be considered a datastore, e.g. you can pull the plug and nothing else happens (aside losing performance). It'd be a lot more beneficial all the processes to have a local cache, themselves. The latter is at least 4 orders of magnitude faster than redis. Now you may like some partitioning, too. reply secondcoming 20 hours agorootparentprevThere's more to redis than just being a K/V store. reply strken 20 hours agorootparentPerhaps you could elaborate? It would be helpful to understand what Redis can do that cannot be done easily with local memory. Acting as shared memory for an inherently single-CPU language like JS is one I can think of. However, I don't use Redis, so you'd be better placed to drive the discussion forward with examples. reply mperham 15 hours agorootparentRedis provides low-level persistent data structures which can be used to implement business logic distributed safely across a number of machines. That’s a LOT harder than in-memory in-process. My Sidekiq background job system runs entirely on top of Redis. Structures like Sorted Sets become the basis for indexes. Lists provide extremely fast queue behavior and Hashes map easily to persistent objects. Databases, traditionally, have not performed well when used as queues. Those are the big 3 structures necessary to implement anything: trees, lists and maps. reply strken 11 hours agorootparentI'm a bit confused here, because the original comment was that \"most people will never really see the point of Redis, which is that if it is running on the same machine as the application, it can respond in much less than a millisecond\", to which the response was \"there's more to redis than just being a K/V store\". I do see the point of Redis if you have multiple hosts, but I was unsure why someone would use it on just one host. reply mperham 4 hours agorootparentRight, it's still useful as shared data for multiple processes on the same machine. A SQL database mostly forces your data into one structure: the table. Redis instead provides commands which operate directly on those different data structures I mentioned. reply quantadev 18 hours agorootparentprevI have Docker running in swarm mode where it will spin up multiple load balanced instances of my web app (where requests can get routed randomly to any instance). So I use Redis to store \"User Session Information\" so the session can be read/written from any instance, supposedly faster than using a DB. reply tbrownaw 16 hours agorootparentWhen I've used redis to store web sessions, it is in fact acting as a k/v store. The session ID is the key, and the (serialized) session state is the value. reply quantadev 15 hours agorootparentYep, that's what I'm doing too. I bet it's the most common use case for Redis. reply runeblaze 15 hours agorootparentprevJust to add -- sometimes I use Redis when I don't have a trusted impl of HyperLogLog or sorted set (and I have a vague suspicion that I am going to do IPC later -- so not worth it to wrap my own HLL). reply shakow 20 hours agorootparentprev> Perhaps you could elaborate? IPC, I suppose? reply chipdart 18 hours agorootparentprev> There's more to redis than just being a K/V store. That's perfectly fine. You can compare Redis to other specialized tools just like you can compare it with Postgres and SQLite. reply Eikon 20 hours agorootparentprevThere’s more data structures in your favorite language std lib than an hashmap, at least, I hope so :) reply ummonk 20 hours agorootparentprevLike? reply noident 20 hours agorootparenthttps://redis.io/docs/latest/commands/ reply 101011 15 hours agorootparentTIL about a Cuckoo Filter. Also, never realized redis has native support for a Bloom Filter. reply maxbond 20 hours agoparentprevOverengineering/premature distribution is a real problem, but Redis stands for \"Remote Dictionary Server.\" The purpose is very much not to run it locally! (Though that's a legitimate design choice, especially if your language's native dictionary doesn't support range queries.) reply freedomben 19 hours agorootparentThe purpose may not be primarily or originally to run it locally, but that has definitely become a common use case. That said, anitirez renaming it to lredis or reldis would be epic and one of my favorite moves of all time reply codr7 19 hours agoparentprevIt very well could be running on the same machine, and communicating with the app using unix sockets, which is a hell of a lot faster than TCP. But no one seems to be doing that much either. I feel that the virtualize and distribute everything to hell and back-trend might actually be about to break, there are signs, and G knows it's about time. The amounts wasted on cloud providers for apps that would run everything just fine on a single server, the effort wasted configuring their offerings, surreal. reply chipdart 19 hours agoparentprev> Because everyone insists on insanely distributed architectures, most people will never really see the point of Redis, which is that if it is running on the same machine as the application, it can respond in much less than a millisecond. I don't think this is a realistic scenario at all. If you need a KV store, you want it to be the fastest by keeping it in-memory, you want it to run on each node, and you don't care how much it cost to scale vertically, then you do not run a separate process on the same node. You just keep a plain old dictionary data structure. You do not waste cycles deserializing and serializing queries. You only adopt something like Redis when you need far more than that, namely you need to have more than one process access shared data. That's at the core of all Redis usecases. https://redis.io/docs/latest/develop/interact/search-and-que... reply nrdvana 15 hours agorootparentI develop and maintain multiple applications that use a worker pool, and are small enough to run on a single host. We used pg for the user sessions, which get read and written on every single page request. Some of our apps are Internet-facing, and web crawlers can create sessions that get read and written (recording recent pages) as they browse the site. We switched to a redis service on the same host as the app and saw 3 main benefits: faster session loading and saving, less disk activity on the Pg server (so all other queries run faster) and less writes to the Pg WAL, so our backups require drastically less GB per day of retention. After the significant success of the first conversion, we've been working to convert all the rest of our apps. And no, host language data structures aren't useful because they aren't in shared memory between all the worker processes, and even if we found a module that implemented them in shared memory, we like to be able to preserve the sessions across a host restart, and then we'd need a process to save the data structures to disk and load them back, and by the time we did that we'd have just reinvented redis. reply machine_coffee 10 hours agorootparentThis is the best response so far. Session churn creates lots of db activity but lots of it is of low business value. Better to offload to a separate process. Also session data is often Blobs which db's don't process as efficiently as columnar data. reply zimpenfish 14 hours agorootparentprev> then you do not run a separate process on the same node You might if you want the KV to persist between app restarts (for warm starts.) reply hinkley 20 hours agoparentprevOver the network became feasible when HDD got markedly slower than NICs. It’s a nearer thing with NVMe. I want a “redis” with something akin to the Consul client - which is a sidecar that participates in the Raft cluster and keeps up to date, cheaper lookups for all of the processes running on the same box. The few bit of data we needed to invalidate on infrequent writes went into consul, and the rest went into the dumbest (as in boring, not foolish) memcached cluster you can imagine. But as you say there was the network overhead, and what would be lovely is a 2 tier KV store that cached recent reads locally and distributed cache invalidation over Raft. Consistent hashing for the systems of record, broadcast data on put or delete so the local cache stays coherent. reply elcritch 13 hours agorootparentI always liked the idea of a distributed sidecar like DB. I wonder if something like Cockroach DB might even work for small clusters. reply xxs 10 hours agoparentprev> which is that if it is running on the same machine as the application in that case just use a regulator hashmap - it has nanoseconds performance compared to the sub-millis. reply sgarland 19 hours agoparentprev> [Redis] can respond in much less than a millisecond. I have no idea how fast Redis can get, but it is entirely possible for an RDBMS to execute a query in well under a millisecond. I have instrumentation proving it. If everything is on the same machine, I would wager that IPC would ultimately be the bottleneck for both cases. reply halfcat 20 hours agoparentprevDjango has caching built in with support for Redis, and it also has an in-memory caching option which they label as “not for production” (because if you have multiple instances of Django serving requests, their in-memory caches will diverge which is...bad). But for lots of cases, especially internal business tools, we can scale up a single instance for a long time, and this in-memory caching makes things super fast. There’s a library, django-cachalot [1], that handles cache invalidation automatically any time a write happens to a table. That’s a rather blunt way to handle cache invalidation, but it’s wonderful because it will give you a boost for free with virtually no effort on your part, and if your internal business app has infrequent updates it basically runs entirely in RAM, and falls back to regular database queries if the data isn’t in the cache. [1] https://github.com/noripyt/django-cachalot reply hkon 20 hours agoparentprevBut then you can have it in memory in your app. reply bufferoverflow 14 hours agoparentprevRedis is not just in-memory. reply mbreese 19 hours agoprevMany arguments here have been from the Redis point of view (and are quite defensive). Of course Redis has niches where it is the better choice. But that’s not what I thought the point of the article was. I think the main argument from the article can be summed up with this line: > PostgreSQL has a lot more capabilities than you may expect when you approach it from the perspective of just another SQL database or some mysterious entity that lives behind your ORM. To me, this is the key line. If you’re only using your database from behind an ORM (any database, IMO), you’re probably missing functionality. And if you need to add another service (like Redis), you may be better served by using the database you already have setup, rather than adding another dependency. reply tyre 19 hours agoprevIt’s good to understand all of the things Postgres can do. It’s a powerful database. A counterpoint is that the barrier to using redis is tiny and in exchange you have a very high performing system that has extensive library support and takes load from your primary database. If you want to cache API responses, for example, could you do that in Postgres? Sure. And you could support things like TTLs with cron jobs sweeping stale cache values. Or you can just use redis. Advisory locks are cool and useful. They can be a little problematic you want something like PGBouncer and you’re stuck between session advisory locks and transaction interleaving. Having separate systems has downsides (network calls, availability, domain knowledge), but the tradeoffs with Redis of all things are pretty low. reply asah 10 hours agoparentIt's one less thing to manage in production. Start with postgresql then add niche systems for performance, scaling, cost. reply jeeybee 13 hours agoprevPGQueuer provides job queuing, locking, and real-time notifications using PostgreSQL's FOR UPDATE SKIP LOCKED and LISTEN/NOTIFY. It's a minimalist alternative for those already using PostgreSQL, avoiding the need for Redis. - https://github.com/janbjorge/PGQueuer disclaimer: Im the auther. reply TkTech 19 hours agoprevThis is a fairly old article, but this has become a very common pattern. For 90% of projects that just need a task queue for sending email or generating reports, you're not going to be doing millions of messages a second and anything that simplifies your stack is worth looking at. I've used these patterns so often to work around issues encountered with Celery that I've split them into their own framework, https://github.com/TkTech/chancy (feedback appreciated ;) There are lots of these, several of which are commercial ventures so there's definite interest behind it: https://worker.graphile.org/ (Node.js) https://riverqueue.com/ (Go) https://github.com/acaloiaro/neoq (Go) https://github.com/contribsys/faktory (Go) https://github.com/sorentwo/oban (Elixir) https://github.com/procrastinate-org/procrastinate (Python) reply trescenzi 15 hours agoparentThank you for sharing this. I’ve been trying to find a simple task queue and Huey is ok, but since I’m on Postgres and the tasks I’m queuing are like once an hour, anything redid based has always felt like overkill. reply sali0 12 hours agoparentprevAnother one for Node is PG-Boss (https://github.com/timgit/pg-boss) reply h1fra 19 hours agoprevI love postgres but it has some limitations: - Want a KVstore? Do you know autovacuum? Do you know the connections pool limit? Do you want throughput or safety? - Want a queue? is it sequential? Is it throttled? Is it fanout? Is it split by topic? - Want a pubsub? do you care about more than once? do you care about losing messages? do you care about replaying messages? - Want a lock? Do you know the connections pool limit (again)? Do you know about statement_timeout? Yes, you can solve almost all issues listed above, but it's not that trivial. reply blackenedgem 19 hours agoparentAlso: Will your implementation fall over if there's a long running transaction that stops vacuum from removing tuples? reply inquisitor27552 19 hours agoparentprevthis. it's like the only thing the market hasn't done yet is replace the nanny of my kids and make my wife jealous. reply Latty 19 hours agoprevA big deal-breaker for Postgres pub/sub is the messages have a maximum size of 8000 bytes. The recommended work around is to put data in a table and send IDs, but then you have to deal with garbage collecting that if you don't want it to live forever, and you are adding operations to each message. Obviously this can be fine, but for plenty of Redis use cases it really isn't equivalent with that limit. reply nine_k 14 hours agoprevQueuing, locking, pub/sub: check. Caching, often the most important application of Redis: oops. Updates in Postgres are notoriously more expensive than inserts (generate garbage, require vacuuming); durability guarantees, not important for caching, make writes significantly slower. Automatic expiration is very convenient and fool-proof. reply mannyv 20 hours agoprevLets see pgsql deal with 15000 client connections. reply asah 10 hours agoparentJust use connection pooling, which is available point/click as AWS RDS Proxy. reply halfcat 20 hours agoparentprevIt’s really shocking how wide the difference is here between Postgres and MySQL. One of the Planetscale guys did a podcast and said at GitHub every MySQL instance is doing like 50k+ connections while if you need more than 100 connections in Postgres you already need PgBouncer. reply throwaway313373 17 hours agorootparentWhy is it \"shocking\"? It's just an architectural decision to spawn a process per connection that Postgres made long time ago. It's a tradeoff like most decisions. Back in the days MySQL had huge issues with scaling to multi-core systems (maybe they fixed it now, I haven't used MySQL for a long time) while Postgres never had this problem. When designing an application around Postgres you just have to take into account that: 1. opening a new connection is rather expensive, so you should have a connection pool 2. opening too many connections is problematic, so you should keep the size of your pool rather small and return connections back into the pool ASAP That's it. It's not that hard in practice. reply brianaker 14 hours agorootparentMySQL never had a problem with scaling to multi-core systems; Linux on the other hand did have a problem and its problems became everyone's problems. In the early 2000's the answer to multi-core Linux issues was to buy a system running one of the commercial UNIX. By 2006 or so this became a non-issue for Linux ( for the most part ). Postgres uses an old design model which predates threads; I have no idea if they have made any progress in updating their design. In the past I have heard the core devs talk about how difficult it would be to do this. Oracle Database moved to a hybrid process/thread model at some point, this is the superior solution ( I have no idea if it was done well or not, but from standpoint of how to achieve better leverage of CPU vs IO, this is the way ). If the PG devs had enough time/money, I am sure they would move towards a hybrid model where the focus would be on processor affinity with IO being all tied to events. reply xxs 12 hours agorootparentYears back (around 10) mysql did have multiple instances of false sharing[0]. Unrelated to mysql - I do consider using redis in any capacity a blunder (it's likely ok for nodejs users, I suppose) [0]: http://dimitrik.free.fr/MySQL_Connect_2013/MySQL_Perf-Connec... reply CAP_NET_ADMIN 19 hours agorootparentprevWhy would you do 50k+ connections if they can't be active all at once either way? Unless you have 50k+ cores and IO beefy enough not to get overwhelmed due to that. You can have as much connections as you want, but you'll have to trade it for having lower work mem numbers, which hurts performance. Traditional advice is to keep it below 500 per PostgreSQL instance (I'd say physical host). I've ran dozens of micro services handling thousands of requests per second with a total connection limit of around 200 of which most was still unused - all without any server-side pooler. reply samlambert 19 hours agorootparentbecause people run large amounts of front ends and workers that create a significant amount of connections. it doesn't matter if they are all active. reply throwaway313373 17 hours agorootparentWhy would you want every \"frontend\" keep an open connection all the time? > it doesn't matter if they are all active It does, if the connection is inactive (doesn't hold an open transaction) you should close it or return it to the pool. reply samlambert 16 hours agorootparentso you are suggesting you close a connection between queries? reply throwaway313373 15 hours agorootparentBetween queries in the same transaction? No Between transactions? Yes, absolutely In fact, many libraries do it automatically. For example, SQLAlchemy doc explicitly says [0]: > After the commit, the Connection object associated with that transaction is closed, causing its underlying DBAPI connection to be released back to the connection pool associated with the Engine to which the Session is bound. I expect other reasonably sane libs for working with transactional databases do the same. So, if you are doing pooling correctly, you can only run out of available connections if you want to have a lot of long running transactions. So, why would you want every of your 50k frontends keep an open transaction simultaneously? [0] https://docs.sqlalchemy.org/en/20/orm/session_basics.html#co... reply nrdvana 15 hours agorootparentBecause there's an overhead to make a connection, authenticate, set the default parameters on the connection, etc. I've never seen a framework that closed db connections between requests. Of course, the better design is to write a nonblocking worker that can run async requests on a single connection, and not need a giant pool of blocking workers, but that is a major architecture plan that can't be added late in a project that started as blocking worker pools. MySQL has always fit well with those large blocking worker pools. Postgres less so. reply throwaway313373 15 hours agorootparentAs I said, you can return the connection to the connection pool. From the perspective of keeping the number of open connections low it doesn't really matter if you close it or return to the pool, because in either case the connection becomes available to other clients. reply nrdvana 14 hours agorootparentI might not be understanding what you're pointing out here. It sounds to me like sqlalchemy is talking about a pool of connections within one process, in which case releasing back to that pool does not close the connection by that process to the database. Parent comment is talking about one connection per process with 50k processes. My comment was that you don't need that many processes if each process can handle hundreds of web requests asynchronously. If you are saying that a connection pool can be shared between processes without pgbouncer, that is news to me. reply throwaway313373 13 hours agorootparentOf course, you're right, it is not possible to to share a connection pool between processes without pgbouncer. > Parent comment is talking about one connection per process with 50k processes. It is actually not clear what parent comment was talking about. I don't know what exactly did they mean by \"front ends\". reply nrdvana 5 hours agorootparentThe most common design for a Web app on Linux in the last 20 years is to have a pool of worker processes, each single-threaded and ready to serve one request. The processes might be apache ready to invoke PHP, or mod-perl, or a pool of ruby-on-rails or perl or python processes receiving the requests directly. Java tends to be threads instead of processes. I've personally never needed to go past about 100 workers, but I've talked to people who scale up to thousands, and they happen to be using MySQL. I've never used pgbouncer, but understand that's the tool to reach for rather than configuring Pg to allow thousands of connections. reply vichle 11 hours agoprevTo articulate the articles point further: Start with pg, switch to redis when the need arises. Keep the number of moving parts as low as possible. reply Havoc 10 hours agoparentRedis isnt exactly hard to deploy. May as well just use it instead of planning for a switch later that may come with god knows what unforeseen side effects reply pm90 15 hours agoprevThe problem with this is that eventually the database becomes everything to everyone. You start seeing the frontend UIs suffer due to errors with unrelated tables or table locking operations (like migrations). Redis is pretty awesome. So is rabbitmq. When you’re a”PgSQL provides a lot of tools to inspect it live” Any particular tools you like for this? reply shakow 19 hours agorootparent“Tool” may not be the right word; but being able to live monitor the vacuumer, to understand what table was taking how much space and why, to track min/mean/max execution time of queries, and, more generally, all the internal metrics that PgSQL exposes through a couple of SELECT has been a boon when debugging or optimizing. reply FreakLegion 19 hours agoparentprevPlain vacuum is generally all you want. At that point the space is freed for new inserts and updates to the table. Full vacuum is for giving the space back to the OS, which rarely makes sense if you'll still be writing more rows. In cases where freeing to the OS really is what you need, though, use something like pg_repack. reply JackSlateur 19 hours agoprev\"Do you need pgsql ? Redis does queuing, locking and pub/sub\" (I've not read the article: the title alone seems like an orange vs apple sales) reply noident 19 hours agoprevDo you need oranges? Apples have seeds, skin, and grow on trees. Redis has many niches where it is more suitable than a database. In particular, the low latency and simple concurrency model make it a perfect choice for building shared token buckets, for example. For simple operations that need to be executed many times at low latency, SQL is usually not the best choice. And sometimes, you really just need K/V and don't want to deal with schema migrations, DBA chores, debugging auto vacuum... >Advisory locks allow you to leverage the same locking engine PostgreSQL uses internally for your own application-defined purposes. That is like telling me that I can get across the river in a nuclear submarine instead of walking over the footbridge. PostgreSQL locks cause me plenty of headaches already without my application logic being dependent on them. reply Tostino 17 hours agoparentDisagree. If you need a global locking mechanism that all of your back ends can agree on without setting up an additional service, advisory locks are a totally valid use case. All of your back ends already have access to the DB, why bring in another whole service for just the locking that is required to implement some small thing in your giant SaaS product? Just lean on PG and you can go really far. reply surfingdino 19 hours agoprev [–] I mean, yes, but a fairer comparison would be Redis vs. Memcache. Redis provides functionality missing from Memcache, it is not meant to be an alternative to Postgresql. This article reminds me of one about configuring MySQL to act like a NoSQL datastore, I read when MongoDB hit the limelight. Apples to organges. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post by Chris Farber examines if Redis is essential for web applications or if PostgreSQL can fulfill the same roles.- It highlights three Redis use cases: job queuing, application locks, and Pub/Sub, and explains how PostgreSQL can manage these tasks using SKIP LOCKED, advisory locks, and LISTEN/NOTIFY statements, respectively.- The discussion suggests that while Redis is superior in caching, PostgreSQL's capabilities might reduce the need for Redis, potentially lowering operational costs and complexity."
    ],
    "commentSummary": [
      "The debate centers on whether Redis is necessary when PostgreSQL can manage queuing, locking, and publish/subscribe (pub/sub) functionalities.",
      "Redis is praised for its speed and performance, especially when running on the same machine as the application, offering advantages over PostgreSQL's disk-based operations.",
      "The choice between Redis and PostgreSQL should be based on specific use cases, such as the need for high-speed operations, shared memory, or persistence, with consideration for the complexity of distributed architectures."
    ],
    "points": 191,
    "commentCount": 123,
    "retryCount": 0,
    "time": 1730670123
  },
  {
    "id": 42035981,
    "title": "Hacker News Data Map [180MB]",
    "originLink": "https://lmcinnes.github.io/datamapplot_examples/hackernews/",
    "originBody": "Hackernews Data Map A Map of stories on Hackernews using UMAP and nomic-embed Point Data: 0% Label Data: 0% Meta Data: 0% Histogram Bin Data: 0% Histogram Index Data: 0%",
    "commentLink": "https://news.ycombinator.com/item?id=42035981",
    "commentBody": "Hacker News Data Map [180MB] (lmcinnes.github.io)180 points by mooreds 22 hours agohidepastfavorite23 comments lucb1e 22 hours agoMaybe add [180MB] to the title, similar to how videos or pdfs are tagged? It starts loading that immediately when you open the page, which would be 18% of my data bundle if I had been on mobile (This is actually transferred bytes btw, based on seeing ~12MiB/s for ~15 seconds in the system monitor) Edit: some people are saying they can't view it, especially on mobile browsers. Here's some screenshots: - Landing overview https://snipboard.io/YTQRZc.jpg - Zooming into the center, hovering over an item that is too small to see but the title shows in a tooltip: https://snipboard.io/xOvA47.jpg - Zoomed in further still, now an individual item can be targeted easily and there are lines delimiting topics (looking like height lines on a map): https://snipboard.io/P6UVAv.jpg - Hovering over the year selector on the bottom left, same zoom position for comparison: https://snipboard.io/VDW2JI.jpg Clicking the year seems not to do anything, you can't lock into that view. Clicking a title opens the page, not the discussion thread. --- Looking into the corresponding GitHub repository (I wonder if they have a bandwidth limit for repositories or if it will foot any bill), , there's also a visualization for Wikipedia which is a bit less heavy: https://lmcinnes.github.io/datamapplot_examples/Wikipedia_da... (screenshot ) reply walterbell 21 hours agoparent180MB download per HN visitor isn't going to be fun for the server either. More civilized would be a photo snapshot + optional link to 180MB download for interactive UX. reply odo1242 21 hours agorootparent180MB is probably fine for most servers (especially CDNs), to be honest. My M1 MacBook with 16 gigabytes of RAM is struggling to load/display the data though. reply tg180 11 hours agorootparent> GitHub Pages sites have a soft bandwidth limit of 100 GB per month. > If your site exceeds these usage quotas, we may not be able to serve your site, or you may receive a polite email from GitHub Support suggesting strategies for reducing your site's impact on our servers, including putting a third-party content distribution network (CDN) in front of your site, making use of other GitHub features such as releases, or moving to a different hosting service that might better fit your needs. https://docs.github.com/en/pages/getting-started-with-github... reply winter_blue 3 hours agorootparentDoesn't GitHub Pages have a CDN? reply lucb1e 21 hours agorootparentprevA photo could work as a quick preview indeed. As another idea for large content spiking in popularity, another solution may be something like webtorrent, or whatever peertube uses Or a vector map, loading data as needed for the region you're zooming into reply tomthe 21 hours agoparentprevI made a similar map but with tiles that only load of you zoom in far enough: tomthe.github.io/hackmap/ (Sorry for posting my link so often) That way it has to load only a few megabyte for the first view. reply mooreds 20 hours agoparentprev> Maybe add [180MB] to the title, similar to how videos or pdfs are tagged Done. reply codingdave 20 hours agoprevIt is a cool visualization, so I don't want to diminish the effort to make it in any way. And as an experiment in visualization, it is interesting. (If a bit large and laggy.) But if the authors expect people to use it to navigate content, it has a few problems: 1) The topics don't seem to be hierarchical, so as I drill down on one area, I get all kinds of things that don't seem related. I have no idea what I'm missing unless I zoom into the whole thing. 2) I don't know where my browser is going when I click a link. That is a security problem. 3) I cannot tell how this data is sourced. Are these all the links posted to HN? Just the ones that got upvotes? Something else? Because while we have some great links here, we also get a lot of stinkers. 4) Much of the value of HN is the discussions. I didn't see a way to navigate to discussions related to any of the links. reply anonu 21 hours agoprevI like how Web Development and User Experience grouping is way outside the central bubble. Nonetheless, great visualization of a lot of data. I need to learn more about this: UMAP: https://umap-learn.readthedocs.io/en/latest/ Nomic-Embed: https://www.nomic.ai/blog/posts/nomic-embed-text-v1 The visual groupings aren't perfect. For example, there are a quite a few COVID-19 tagged articles before 2020. reply Cupprum 21 hours agoparentIs that necessarily a bad thing? Cant some posts be relevant even if they were created before covid? reply rolfan 21 hours agoprevThis website crashed my smartphone xD. After loading some sections of the map, my screen turned into digital garbage. reply nighthawk454 18 hours agoprevRepo: https://github.com/lmcinnes/datamapplot_examples Also, lmcinnes is the author of UMAP and HDBSCAN! reply avandekleut 22 hours agoprevThats a neat visualization. It took about 35 seconds to load for me, and the actual loading progress appeared to get stuck at 15% for most of the time, which tempted me to close before it was ready. reply kissgyorgy 18 hours agoprevIt would be way more usable if a time range could be selected and it would list the actual threads to the results. reply MaheshNat 20 hours agoprevthese data maps should incorporate level of detail so unnecessary data isn’t loaded on first load, the way mimic does it. reply deskr 21 hours agoprevDoesn't work on Firefox - white screen instead of a map. reply lucb1e 4 hours agoparentWFM, latest stable Firefox on Linux reply airstrike 18 hours agoparentprevWorks here on Firefox 131.0.2 on Mac OS Sequoia 15.0.1 reply xyst 21 hours agoprevbroken on mobile with safari, I’ll check it later today reply andrewmcwatters 21 hours agoprevMaybe browsers should have resource limits and ask the user if they want to continue loading the page beyond some sort of threshold... reply lucb1e 4 hours agoparentAt least on metered connections, indeed. With HSDPA/3g this was not a problem, a few hundred KB/s is plenty to load text (including jquery and the like) and images just fine but you'd notice if it took oddly long. Then came LTE/4g and you can now download hundreds of megabytes in a few seconds when you've got good signal. When it came out, most people's data bundles were on the order of 500-1500 MB iirc. I guess nobody was a dick about it since I never heard of bundle exhaustion attacks, but what surprises me more is that few people mention running into the issue by accident Now we have 5g and I'm still wondering what to do with speeds greater than what 3g+ (HSDPA) could offer, namely full HD streaming. On a rare occasion it's nice to download a file fast, but do I need this to be enabled for me all the time and run this risk? The lower latency of LTE and increased capacity of NR are nice but this constant race of more and more gigabits just to... do what, sell bigger data bundles? There are purposes for this (like wireless internet for homes in rural areas) but not mainstream mobile daily use. Range/coverage was the primary issue and still is to this day. The faster rates require good signal to function at all. Companies are turning off 2g and 3g, the things that allowed you to still get a few KB/s to send a message that you'll be back later, or get a weather forecast, when you're out hiking. The newer versions are just as good when you're in range and worse when you're out of range, so there is no point. I don't know how the incentives are so misaligned, I guess not enough people experienced 3g with good signal (nowadays when you see 3g, you're just out of range and that's why it feels like it's not working) to know that they don't need to upgrade to a plan+phone that can exhaust their data bundle in 90 seconds, or their monthly FUP allowance in a matter of minutes? At any rate, yes I agree with your post emphatically, but it doesn't seem like a task specific for browsers to me. Any software can decide to pull an update or other data file (like an offline map file or large video), also while tethered so the downloading software might not even know that it's on a metered network, and cause the same problem reply tofof 18 hours agoprev [–] This seems deeply flawed. Every 'category' I drill into has mostly articles that are nothing of the sort. \"Writing and Gaming\" has 6+ Sieve of Erasthones articles (generating prime numbers), the Lehmer sieve (also primes), and \"Migrating from Procmail to Sieve\", along with a half dozen articles on the death of cursive. The only vaguely gaming related articles are one on Katamari (nothing about writing) and an exercise of naming big numbers. Math/Tech/Gender Representation is articles about Magic the Gathering, or about Larry Wall of Perl fame. Monty Hall Problem Explanation has several articles about \"The Gettysburg Powerpoint Presentation\", articles about the name of the Ogg container format, mythbusting 6 misconceptions about learning english, \"in defense of swap common misperceptions\", adages have opposites - a list, the Assange case, and an article (\"I've got some things to say\") about poverty and american football. Animal Cognition & Development - an article about chinese spies (Operation Fox Hunt), a Schnier on Security post about an NSA program called FOXACID, an examination of Bill Ngyuen's investments, articles about github merges and security metaphors about food delivery by zebra, a traffic calming mechanism in La Paz Bolivia, a complex journey to the middle ear, 6 Creatures by Hieronymus Bosch That Could Be Pokémon, crippling digestive problems, the wikipedia list of organisms named after the Harry Potter series, an article about the Cumberland County New Jersey election board, the scientific evidence for discarding a glass of wine that a fruit fly has touched, a 17th century european blood sport of tossing foxes high into the air, an article about the standard english pangram sentence of fox and dog, a hate-filled rant (sierra juliet foxtrot) about \"skulking juvenile fascists\" and a Mozilla project to incorporate image processing into their browser. Lobster News - articles about the sky being blue, in literal and metaphorical senses both. Microsoft Azure. BlueSky, the twitter alternative. An article about 3d engine lighting. The Timing of Evolutionary Transitions Suggests Intelligent Life is Rare. Keeping a grocery store lobster as a pet. Lobster.rs launched 8 years ago. Bootstrapping Ikarus Scheme. Project Daedalus, a theoretical insterstellar drive. An article about the metaphorical fall of icarus, with visualization of the Chutes and Ladders boardgame. A youtube music album called Land Locked Blues. An rpi car pc. Murmation - the flocking pattern of starlings. Articles about the abuse of a font. An Israeli mining company unearthing a rare mineral. ICARUS, the swiss neutrino detector. An article about \"His Majesty’s Airship No. 1, the rigid, phallic Mayfly\". A podcast about the stages of color terms in langauge and blue's position at the end. Black Swan Theory - A cluster of \"I fell in love with a female assassin\" (literal, an account of the Cambodian civil war), joined with a cluster around \"Disneyland with the Death Penalty\" a 4,500 word nonfictional article by William Gibson (of Neuromancer fame) about Singapore's governance as an authoritarian and austere city-state, an article about PMS, the Bill Nye the Science Guy reddit ama, the Bill Nye - Ken Ham debate, Bill Nye on the abortion argument, a capitalist named Bill Ackman's views on a possible pyramid scheme called Herbalife, and a big cluster on Covid vaccine's effect on periods and vaginal bleeding, I'm sorry, what? reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A Hacker News data map hosted on GitHub is 180MB, causing potential issues for mobile users with limited data due to its immediate loading.",
      "Users suggest improvements such as adding a size tag, providing a preview image, and using technologies like CDN (Content Delivery Network), webtorrent, or vector maps to enhance loading efficiency.",
      "The map faces challenges like non-hierarchical topics, unclear data sourcing, and compatibility issues with certain browsers or mobile devices, prompting discussions on solutions for large data visualizations."
    ],
    "points": 180,
    "commentCount": 23,
    "retryCount": 0,
    "time": 1730666750
  },
  {
    "id": 42041917,
    "title": "We're Leaving Kubernetes",
    "originLink": "https://www.gitpod.io/blog/we-are-leaving-kubernetes",
    "originBody": "← back to blog Engineering We’re leaving Kubernetes Christian Weichel Co-Founder, CTO at Gitpod Alejandro de Brito Fontes Staff Engineer Oct 31, 2024 Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments. We thought so too and have spent six years invested in making the most popular cloud development environment platform at internet scale. That’s 1.5 million users, where we regularly see thousands of development environments per day. In that time we’ve found that Kubernetes is not the right choice for building development environments. This is our journey of experiments, failures and dead-ends building development environments on Kubernetes. Over the years, we experimented with many ideas involving SSDs, PVCs, eBPF, seccomp notify, TC and io_uring, shiftfs, FUSE and idmapped mounts, ranging from microVMs, kubevirt to vCluster. In pursuit of the most optimal infrastructure to balance security, performance and interoperability. All while wrestling with the unique challenges of building a system to scale up, remain secure as it’s handling arbitrary code execution, and be stable enough for developers to work in. This is not a story of whether or not to use Kubernetes for production workloads that’s a whole separate conversation. As is the topic of how to build a comprehensive soup-to-nuts developer experience for shipping applications on Kubernetes. This is the story of how (not) to build development environments in the cloud. Why are development environments unique? Before we dive in, it’s crucial to understand what makes development environments unique compared to production workloads: They are extremely stateful and interactive: Which means they cannot be moved from one node to another. The many gigabytes of source code, build caches, Docker container and test data are subject to a high change rate and costly to migrate. Unlike many production services, there’s a 1-to-1 interaction between the developer and their environment. Developers are deeply invested in their source code and the changes they make: Developers don’t take kindly to losing any source code changes or to being blocked by any system. This makes development environments particularly intolerant to failure. They have unpredictable resource usage patterns: Development Environments have particular and unpredictable resource usage patterns. They won’t need much CPU bandwidth most of the time, but will require several cores within a few 100ms. Anything slower than that manifests as unacceptable latency and unresponsiveness. They require far-reaching permissions and capabilities: Unlike production workloads, development environments often need root access and the ability to download and install packages. What constitutes a security concern for production workloads, is expected behavior of development environments: getting root access, extended network capabilities and control over the system (e.g. mounting additional filesystems). These characteristics set development environments apart from typical application workloads and significantly influence the infrastructure decisions we’ve made along the way. The system today: obviously it’s Kubernetes When we started Gitpod, Kubernetes seemed like the ideal choice for our infrastructure. Its promise of scalability, container orchestration, and rich ecosystem aligned perfectly with our vision for cloud development environments. However, as we scaled and our user base grew, we encountered several challenges around security and state management that pushed Kubernetes to its limits. Fundamentally, Kubernetes is built to run well controlled application workloads, not unruly development environments. Managing Kubernetes at scale is complex. While managed services like GKE and EKS alleviate some pain points, they come with their own set of restrictions and limitations. We found that many teams looking to operate a CDE underestimate the complexity of Kubernetes, which lead to a significant support load for our previous self-managed Gitpod offering. Resource management struggles One of the most significant challenges we faced was resource management, particularly CPU and memory allocation per environment. At first glance, running multiple environments on a node seems attractive to share resources (such as CPU, memory, IO and network bandwidth) between those resources. In practice, this incurs significant noisy neighbor effects leading to a detrimental user experience. CPU challenges CPU time seems like the simplest candidate to share between environments. Most of the time development environments don’t need much CPU, but when they do, they need it quickly. Latency becomes immediately apparent to users when their language server starts to lag or their terminal becomes choppy. This spiky nature of the CPU requirements of development environments (periods of inactivity followed by intensive builds) makes it difficult to predict when CPU time is needed. For solutions, we experimented with various CFS (Completely Fair Scheduler) based schemes, implementing a custom controller using a DaemonSet. A core challenge is that we can not predict when CPU bandwidth is needed, but only understand when it would have been needed (by observing nr_throttled of the cgroup’s cpu_stats). Even when using static CPU resource limits, challenges arise, because unlike application workloads a development environment will run many processes in the same container. These processes compete for the same CPU bandwidth, which can lead to e.g. VS Code disconnects because VS Code server is starved for CPU time. We have attempted to solve this problem by adjusting the process priorities of the individual processes, e.g. increasing the priority of bash or vscode-server. However, these process priorities apply to the entire process group (depending on your Kernel’s autogroup scheduling configuration), hence also to the resource hungry compilers started in a VS Code terminal. Using process priorities to counter terminal lag requires a carefully written control loop to be effective. We introduced custom CFS and process priority based control loops built on cgroupv1 and moved to cgroupsv2 once they became more readily available on managed Kubernetes platforms with 1.24. Dynamic resource allocation introduced with Kubernetes 1.26 means one no longer needs to deploy a DaemonSet and modify cgroups directly, possibly at the expense of the control loop speed and hence effectiveness. All the schemes outlined above rely on second-by-second readjustment of CFS limits and niceness values. Memory management Memory management presented its own set of challenges. Assigning every environment a fixed amount of memory, so that under maximum occupation each environment gets their fixed share is straightforward, but very limiting. In the cloud, RAM is one of the more expensive resources, hence the desire to overbook memory. Until swap-space became available in Kubernetes 1.22, memory overbooking was near impossible to do, because reclaiming memory inevitably means killing processes. With the addition of swap space the need to overbook memory has somewhat gone away, since swap works well in practice for hosting development environments. Storage performance optimization Storage performance is important for the startup performance and experience of development environments. We have found that specifically IOPS and latency affect experience within an environment. IO bandwidth however directly impacts your workspace startup performance, specifically when creating/restoring backups or extracting large workspace images. We experimented with various setups to find the right balance between speed and reliability, cost and performance. SSD RAID 0: This offered high IOPS and bandwidth but tied the data to a specific node. The failure of any single disk would result in complete data loss. This is how gitpod.io operates today and we have not seen such a disk failure happen yet. A simpler version of this setup is to use a single SSD attached to the node. This approach provides lower IOPS and bandwidth, and still binds the data to individual nodes. Block storage such as EBS volumes or Google persistent disks which are permanently attached to the nodes considerably broaden the different instances or availability zones that can be used. While still bound to a single node, and offering considerably lower throughput/bandwidth than local SSDs they are more widely available. Persistent Volume Claims (PVCs) seem like the obvious choice when using Kubernetes. As abstraction over different storage implementations they offer a lot of flexibility, but also introduce new challenges: Unpredictable attachment and detachment timing, leading to unpredictable workspace startup times. Combined with increased scheduling complexity they make implementing effective scheduling strategies harder. Reliability issues leading to workspace failures, particularly during startup. This was especially noticeable on Google Cloud (in 2022) and rendered our attempts to use PVCs impractical. Limited number of disks that could be attached to an instance, imposing additional constraints on the scheduler and number of workspaces per node. AZ locality constraints which makes balancing workspaces across AZs even harder. Backing up and restoring local disks proved to be an expensive operation. We implemented a solution using a daemonSet that uploads and downloads uncompressed tar archives to/from S3. This approach required careful balancing of I/O, network bandwidth, and CPU usage: for example, (de)compressing archives consumes most available CPU on a node, whereas the extra traffic produced by uncompressed backups usually doesn’t consume all available network bandwidth (if the number of concurrently starting/stopping workspaces is carefully controlled). IO bandwidth on the node is shared across workspaces. We found that, unless we limited the IO bandwidth available to each workspace, other workspaces might starve for IO bandwidth and cease to function. Particularly the content backup/restore produced this problem. We implemented cgroup-based IO limiter which imposed fixed IO bandwidth limits per environment to solve this problem. Autoscaling and startup time optimization Our primary goal was to minimize startup time at all costs. Unpredictable wait times can significantly impact productivity and user satisfaction. However, this goal often conflicted with our desire to pack workspaces densely to maximize machine utilization. We initially thought that running multiple workspaces on one node would help with startup times due to shared caches. However, this didn’t pan out as expected. The reality is that Kubernetes imposes a lower bound for startup time because of all the content operations that need to happen, content needs to be moved into place, which takes time. Short of keeping workspaces in hot standby (which would be prohibitively expensive), we had to find other ways to optimize startup times. Scaling ahead: evolution of our approach To minimize startup time, we explored various approaches to scale up and ahead: Ghost workspaces: Before cluster autoscaler plugins were available, we experimented with “ghost workspaces”. These were preemptible pods that occupied space to scale ahead. We implemented this using a custom scheduler. However, this approach proved to be slow and unreliable to replace. Ballast pods: An evolution of the ghost workspace concept, ballast pods filled an entire node. This resulted in less replacement cost and faster replacement times compared to ghost workspaces. Autoscaler plugins: In June 2022, we switched to using cluster-autoscaler plugins when they were introduced. With these plugins we no longer needed to “trick” the autoscaler, but could directly affect how scale-up happens. This marked a significant improvement in our scaling strategy. Proportional autoscaling for peak loads To handle peak loads more effectively, we implemented a proportional autoscaling system. This approach controls the rate of scale-up as a function of the rate of starting development environments. It works by launching empty pods using the pause image, allowing us to quickly increase our capacity in response to demand spikes. Image pull optimization: a tale of many attempts Another crucial aspect of startup time optimization was improving image pull times. Workspace container images (i.e. all the tools available to a developer) can grow to more than 10 gigabytes uncompressed. Downloading and extracting this amount of data for every workspace considerably taxes a node’s resources. We explored numerous strategies to speed up image pulls: Daemonset pre-pull: We tried pre-pulling common images using a daemonSet. However, this proved ineffective during scale-up operations because when the node came online, and workspaces were starting, the images still wouldn’t be present on the node. Also, the pre-pulls would now compete for IO and CPU bandwidth with the starting workspaces. Layer reuse maximization: We built our own images using a custom builder called dazzle, which can build layers independently. This approach aimed to maximize layer reuse. However, we found that layer reuse is very difficult to observe due to the high cardinality and amount of indirections in the OCI manifests. Pre-baked images: We experimented with baking images into the node disk image. While this improved startup times, it had significant drawbacks. The images quickly became outdated, and this approach didn’t work for self-hosted installations. Stargazer and lazy-pulling: This method required all images to be converted, which added complexity, cost, and time to our operations. Additionally, not all registries supported this approach when we tried it in 2022. Registry-facade + IPFS: This solution worked well in practice, providing good performance and distribution. We gave a KubeCon talk about this approach in 2022. However, it introduced significant complexity to our system. There is no one-size-fits all solution for image caching, but a set of trade-offs with respect to complexity, cost and restrictions imposed on users (images they can use). We have found that homogeneity of workspace images is the most straightforward way to optimize startup times. Networking complexities Networking in Kubernetes introduced its own set of challenges, specifically: Development environment access control: by default the network of environments needs to be entirely isolated from one another, i.e. one environment cannot reach another. The same is true for the access of a user to the workspace. Network Policies go a long way in ensuring environments are properly disconnected from each other. Initially we controlled the access to individual environment ports (such as the IDE, or services running in the workspace) using Kubernetes services, together with an ingress proxy that would forward traffic to the service, resolving it using DNS. This quickly became unreliable at scale because of the sheer number of services. Name resolution would fail, and if not careful (e.g. setting enableServiceLinks: false) one can bring entire workspaces down. Network bandwidth sharing on the node is yet another resource that needs to be shared with multiple workspaces on a single node. Some CNIs offer network shaping support (e.g. Cilium’s Bandwidth Manager). This now leaves you with yet another resource to control for, and potentially share between environments. Security and isolation: balancing flexibility and protection One of the most significant challenges we faced in our Kubernetes-based infrastructure was providing a secure environment while giving users the flexibility they need for development. Users want the ability to install additional tools (e.g., using apt-get install), run Docker, or even set up a Kubernetes cluster within their development environment. Balancing these requirements with robust security measures proved to be a complex undertaking. The naive approach: root access The simplest solution would be to give users root access to their containers. However, this approach quickly reveals its flaws: Giving users root access essentially provides them with root privileges on the node itself, granting access to the development environment platform and other development environments that are running on that node . This eliminates any meaningful security boundary between users and the host system meaning developers can accidentally, or intentionally interfere and break the development environment platform itself or even access others’ development environments. It also exposes the infrastructure to potential abuse and security risks. It is then also not possible to implement a true access control model and the architecture falls short of zero-trust. You cannot ensure that a given actor in the system performing an action was verifiably themselves. Clearly, a more sophisticated approach was needed. User namespaces: a more nuanced solution To address these challenges, we turned to user namespaces, a Linux kernel feature that provides fine-grained control over the mapping of user and group IDs inside containers. This approach allows us to give users “root-like” privileges within their container without compromising the security of the host system. While Kubernetes introduced support for user namespaces in version 1.25, we had already implemented our own solution starting with Kubernetes 1.22. Our implementation involved several complex components: Filesystem UID shift: This is necessary to ensure that files created inside the container map correctly to UIDs on the host system. We experimented with several approaches: We continue to use shiftfs as our primary method for filesystem UID shifting. Despite being deprecated in some contexts, shiftfs still provides the functionality we need with acceptable performance characteristics. We’ve experimented with fuse-overlayfs, which provided the necessary functionality but had performance limitations. While idmapped mounts offer potential benefits, we haven’t transitioned to them yet due to various compatibility and implementation considerations. Mounting masked proc: When a container starts, it typically wants to mount /proc. However, in our security model, /proc is sensibly masked to prevent potential security bypasses. Working around this limitation required a tricky solution: We construct a masked proc filesystem. This masked proc is then moved into the correct mount namespace. We implement this using seccomp notify, which allows us to intercept and modify certain system calls. FUSE support: Adding FUSE (Filesystem in Userspace) support, which is crucial for many development workflows, required implementing custom device policies. This involved modifying the container’s eBPF (extended Berkeley Packet Filter) device filter, a low-level programming capability that allows us to make fine-grained decisions about device access. Network capabilities: As true root one holds the CAP_NET_ADMIN and CAP_NET_RAW capabilities which provide far-reaching privileges to configure networking. Container runtimes (such as Docker/runc) make extensive use of these capabilities. Granting such capabilities to the development environment container would interfere with CNI and break the security isolation. To provide such capabilities we ended up creating another network namespace inside the Kubernetes container, first connected to the outside world using slirp4netns and later using a veth pair and custom and nftables rules. Enabling docker: required some specific hacks for Docker itself. We register a custom runc-facade which modifies the OCI runtime spec produced by Docker. This lets us remove e.g. OOMScoreAdj which still isn’t allowed because that would require CAP_SYS_ADMIN on the node. Implementing this security model came with its own set of challenges: Performance impact: Some of our solutions, particularly earlier ones like fuse-overlayfs, had noticeable performance impacts. We’ve continually worked to optimize these. Compatibility: Not all tools and workflows are compatible with this restricted environment. We’ve had to carefully balance security with usability. Complexity: The resulting system is significantly more complex than a simple containerized environment, which impacts both development and operational overhead. Keeping up with Kubernetes: As Kubernetes has evolved, we’ve had to adapt our custom implementations to take advantage of new features while maintaining backwards compatibility. The micro-VM experiment As we grappled with the challenges of Kubernetes, we began exploring micro-VM (uVM) technologies like Firecracker, Cloud Hypervisor, and QEMU as a potential middle ground. This exploration was driven by the promise of improved resource isolation, compatibility with other workloads (e.g. Kubernetes) and security, while potentially maintaining some of the benefits of containerization. The promise of micro-VMs Micro-VMs offered several enticing benefits that aligned well with our goals for cloud development environments: Enhanced resource isolation: uVMs promised better resource isolation compared to containers, albeit at the expense of overbooking capabilities. With uVMs, we would no longer have to contend with shared kernel resources, potentially leading to more predictable performance for each development environment. Memory snapshots and fast resume: One of the most exciting features, particularly with Firecracker using userfaultfd, was the support for memory snapshots. This technology promised near-instant full machine resume, including running processes. For developers, this could mean significantly faster environment startup times and the ability to pick up exactly where they left off. Improved security boundaries: uVMs offered the potential to serve as a robust security boundary, potentially eliminating the need for the complex user namespace mechanisms we had implemented in our Kubernetes setup. This could provide full compatibility with a wider range of workloads, including nested containerization (running Docker or even Kubernetes within the development environment). Challenges with micro-VMs However, our experiments with micro-VMs revealed several significant challenges: Overhead: Even as lightweight VMs, uVMs introduced more overhead than containers. This impacted both performance and resource utilization, key considerations for a cloud development environment platform. Image conversion: Converting OCI (Open Container Initiative) images into uVM-consumable filesystems required custom solutions. This added complexity to our image management pipeline and potentially impacted startup times. Technology-specific limitations: Firecracker: Lack of GPU support, which is increasingly important for certain development workflows. No virtiofs support at the time of our experiments (mid 2023), limiting our options for efficient file system sharing. Cloud hypervisor: Slower snapshot and restore processes due to the lack of userfaultfd support, negating one of the key advantages we hoped to gain from uVMs. Data movement challenges: Moving data around became even more challenging with uVMs, as we now had to contend with large memory snapshots. This affected both scheduling and startup times, two critical factors for user experience in cloud development environments. Storage considerations: Our experiments with attaching EBS volumes to micro-VMs opened up new possibilities but also raised new questions: Persistent storage: Keeping workspace content on attached volumes reduced the need to pull data from S3 repeatedly, potentially improving startup times and reducing network usage. Performance considerations: While sharing high-throughput volumes among workspaces showed promise for improving I/O performance, it also raised concerns about implementing effective quotas, managing latency, and ensuring scalability. Lessons from the uVM experiment While micro-VMs didn’t ultimately become our primary infrastructure solution, the experiment provided valuable insights: We loved the experience of full workspace backup and runtime state suspend/resume provided for development environments. We, for the first time, considered moving away from Kubernetes. The effort to integrate KVM and uVMs into pods had us explore options outside of Kubernetes. We, once again, identified storage as the crucial element for providing all three: reliable startup performance, reliable workspaces (don’t lose my data) and optimal machine utilization. Kubernetes is immensely challenging as a development environment platform As I mentioned at the beginning, for development environments we need a system that respects the uniquely stateful nature of development environments. We need to give the necessary permissions for developers to be productive, whilst ensuring secure boundaries. And we need to do all of this whilst keeping operational overhead low and not compromising security. Today, achieving all of the above with Kubernetes is possible—but comes at a significant cost. We learned the difference between application and system workloads the hard way. Kubernetes is incredible. It’s supported by an engaged and passionate community, which builds a truly rich ecosystem. If you’re running application workloads, Kubernetes continues to be a fine choice. However for system workloads like development environments Kubernetes presents immense challenges in both security and operational overhead. Micro-VMs and clear resource budgets help, but make cost a more dominating factor. So after many years of effectively reverse-engineering and forcing development environments onto the Kubernetes platform we took a step back to think about what we believe a future development architecture needs to look like. In January 2024 we set out to build it. In October, we shipped it: Gitpod Flex. More than six years of incredibly hard-won insights for running development environments securely at internet scale went into the architectural foundations. The future of development environments In Gitpod Flex we carried over the foundational aspects of Kubernetes such as the liberal application of control theory and the declarative APIs whilst simplifying the architecture and improving the security foundation. We orchestrate development environments using a control plane heavily inspired by Kubernetes. We introduced some necessary abstraction layers that are specific to development environments and cast aside much of the infrastructure complexity that we didn’t need—all whilst putting zero-trust security first. Caption: Security boundaries of Gitpod Flex. This new architecture allows us to integrate devcontainer seamlessly. We also unlocked the ability to run development environments on your desktop. Now that we’re no longer carrying the heavy weight of the Kubernetes platform, Gitpod Flex can be deployed self-hosted in less than three minutes and in any number of regions, giving more fine-grained control on compliance and added flexibility when modeling organizational boundaries and domains. We’ll be posting a lot more about Gitpod Flex architecture in the coming weeks or months. I’d love to invite you on November the 6th to a virtual event where I’ll be giving a demo of Gitpod Flex and I’ll deep-dive into the architecture and security model at length. You can sign-up here. When it comes to building a platform for standardized, automated and secure development environments choose a system because it improves your developer experience, eases your operational burden and improves your bottom line. You are not choosing Kubernetes vs something else, you are choosing a system because it improves the experience for the teams you support. Virtual Event: Gitpod Flex - Deploy your self-hosted CDE in 3 minutes > What? Deep dive into Gitpod Flex architecture and security. > When? November 6th. Register Now → Authors Christian Weichel Co-Founder, CTO at Gitpod Alejandro de Brito Fontes Staff Engineer Last updated Oct 31, 2024 Helpful resource How to replace VDI white paper",
    "commentLink": "https://news.ycombinator.com/item?id=42041917",
    "commentBody": "We're Leaving Kubernetes (gitpod.io)170 points by filiptronicek 4 hours agohidepastfavorite75 comments horsawlarway 2 hours agoPersonally - just let the developer own the machine they use for development. If you really need consistency for the environment - Let them own the machine, and then give them a stable base VM image, and pay for decent virtualization tooling that they run... on their own machine. I have seen several attempts to move dev environments to a remote host. They invariably suck. Yes - that means you need to pay for decent hardware for your devs, it's usually cheaper than remote resources (for a lot of reasons). Yes - that means you need to support running your stack locally. This is a good constraint (and a place where containers are your friend for consistency). Yes - that means you need data generation tooling to populate a local env. This can be automated relatively well, and it's something you need with a remote env anyways. --- The only real downside is data control (ie - the company has less control over how a developer manages assets like source code). I'm my experience, the vast majority of companies should worry less about this - your value as a company isn't your source code in 99.5% of cases, it's the team that executes that source code in production. If you're in the 0.5% of other cases... you know it and you should be in an air-gapped closed room anyways (and I've worked in those too...) reply shriek 2 hours agoparentAnd the reason they suck is the feedback loop is just too high as compared to running it locally. You have to jump through hoops to debug/troubleshoot your code or any issues that you come across between your code and output of your code. And it's almost impossible to work on things when you have spotty internet. I haven't worked on extremely sensitive data but for PII data from prod to dev, scrubbing is a good practice to follow. This will vary based on the project/team you're on of course. reply ethbr1 2 hours agorootparentAka 'if a developer knew beforehand everything they needed, it wouldn't be development' reply jt2190 29 minutes agoparentprevI’m not sure we should leap from: > I have seen several attempts to move dev environments to a remote host. They invariably suck. To “therefore they will always suck and have no benefits and nobody should ever use them ever”. Apologies for the hyperbole but I’m making a point that comments like these tend to shut down interesting explorations of the state of the art of remote computing and what the pros/cons are. Edit: In a world where users demand that companies implement excellent security then we must allow those same companies to limit physical access to their machines as much as possible. reply csweichel 2 hours agoparentprevOP here. There definitely is a place for running things on your local machine. Exactly as you say: one can get a great deal of consistency using VMs. One of the benefits of moving away from Kubernetes, to a runner-based architecture , is that we can now seamlessly support cloud-based and local environments (https://www.gitpod.io/blog/introducing-gitpod-desktop). What's really nice about this is that with this kind of integration there's very little difference in setting up a dev env in the cloud or locally. The behaviour and qualities of those environments can differ vastly though (network bandwidth, latency, GPU, RAM, CPUs, ARM/x86). reply michaelt 28 minutes agorootparent> The behaviour and qualities of those environments can differ vastly though (network bandwidth, latency, GPU, RAM, CPUs, ARM/x86). For example, when you're running on your local machine you've actually got the amount of RAM and CPU advertised :) reply master_crab 53 minutes agorootparentprevHi Christian. We just deployed Gitpod EKS at our company in NY. Can we get some details on the replacement architecture? I’m sure it’s great but the devil is always in the details. reply hintymad 28 minutes agoparentprev> Personally - just let the developer own the machine they use for development. It'll work if the company can offer something similar to EC2. Unfortunately most of the companies are not capable of doing so if they are not on cloud. reply 0xbadcafebee 2 hours agoparentprevMost teams/products I have been involved in, the stack always grows to the point that a dev can no longer test it on their own machine, regardless of how big the machine is. And having a different development machine than production leads to completely predictable and unavoidable problems. Devs need to create the software tooling to make remote dev less painful. I mean, they're devs... making software is kind of their whole thing. reply hosh 54 minutes agorootparentI have used remote dev machines just fine, but my workflow vastly differs from many of my coworkers: terminal-only spacemacs + tmux + mosh. I have a lot of CLI and TUI tools, and I do not use VScode at all. The main GUI app I run is a browser, and that runs locally. I have worked on developing VMs for other developers that rely on a local IDE such. The main sticking point is syncing and schlepping source code (something my setup avoids because the source code and editor is on the remote machine). I have tried a number of approaches, and I sympathize with the article author. So, in response to \"Devs need to create the software tooling to make remote dev less painful. I mean, they're devs... making software is kind of their whole thing.\"The only real downside is data control (ie - the company has less control over how a developer manages assets like source code). ). I'm my experience, the vast majority of companies should worry less about this [...] I once had to burn a ton of political capital (including some on credit), because someone who didn't understand software thought that cutting-edge tech startup software developers, even including systems programmers working close to metal, could work effectively using only virtual remote desktops... with a terrible VM configuration... from servers literally halfway around the world... through a very dodgy firewall and VPN... of 10Mb/s total bandwidth... for the entire office of dozens of developers. (And no other Internet access from the VMs. Administrators would copy whatever files from the Internet that are needed for work. And there was a bureaucratic form for a human process, if you wanted to request any code/data to go in or out. And the laptops/workstations used only as thin-clients for the remote VMs would have to be Windows and run this ridiculous obscure 'endpoint security' software that had changed hands from its ancient developer, and hadn't even updated the marketing materials (e.g., a top bulletpoint was keeping your employees from wasting time on a Web site that famously was wiped out over a decade earlier), and presumably was littered with introduced vulnerabilities and instabilities.) Note that this was not something like DoD, nor HIPAA, nor finance. Just cutting-edge tech on which (ironically) we wanted first-mover advantage. This escalated to the other top-titled software engineer and I together doing a presentation to C-suite, on why not only would this kill working productivity (especially in a startup that needed to do creative work fast!), but the bad actors someone was paranoid about could easily circumvent it anyway to exfiltrate data (using methods obvious to the skilled software people like they hired, some undetectable by any security product or even human monitoring they imagined), and all the good rule-following people would quit in incredulous frustration. Unfortunately, it might not have been even the CEO's call, but a crazy investor. reply 2075 1 hour agoparentprevI think nowadays the value of source code is rarely a more valuable asset than the data being processed. Also I would prefer to give my devs just a second machine to run workloads and eventually pull in data or mock the data so they get moving more easily. reply speedisavirus 1 hour agoparentprevThat's fine for some. However it's not always that. I wrote an entire site on my ipad in spare time with GitPods. Maybe you are at a small company with a small team so if things get critical you are likely to get a call. Do you say F'it, do you carry your laptop, or do you carry your ipad like you already are knowing you can still at least do triage if needed because you have a perfectly configured gitpod to use. reply idunnoman1222 2 hours agoparentprevSounds like you are not using a lot of hardware - Rfid, POS, top-spec video cards, etc reply haolez 2 hours agoparentprevSometimes I don't even use virtual envs when developing locally in Python. I just install everything that I need with pip --user and be done with it. Never had any conflicts with system packages whatsoever. If I somehow break my --user environment, I simply delete it and start again. Never had any major version mismatch in dependencies between my machine and what was running in production. At least not anything that would impact the actual task that I was working on. I'm not recommending this as a best practice. I just believe that we, as developers, end up creating some myths to ourselves of what works and what doesn't. It's good to re-evaluate these beliefs now and then. reply ok_computer 1 hour agorootparentThe only time I’ve had version issues running python code is that someone prior was referencing a deprecated library API or using an obscure package that shouldn’t see the light of day in a long lived project. If you stick to the tried and true libs and change your function kwargs or method names when getting warnings, then I’ve had pretty rock steady reproducibility using even an un-versioned “python -m pip install -r requirements.txt” experience I could also be a slob or just not working at the bleeding edge of python lib deployment tho so take it with a grain of salt. reply ctippett 1 hour agorootparentprevI'm not going to second-guess what works for you, but Python makes it so easy to work with an ephemeral environment. python -m venv .venv reply haolez 1 hour agorootparentYeah, I know. But then you have to make sure that your IDE is using the correct environment, that the notebook is using the correct environment, that the debugger is using the correct environment. It's trivial to setup a venv, but sometimes it's just not worth it for me. reply lotharcable 2 hours agoparentprevI strongly recommend just switching the Dev environment over to Linux and taking advantage of tools like \"distrobox\" and \"toolbx\". https://github.com/89luca89/distrobox https://containertoolbx.org/ It is sorta like Vagrant, but instead of using virtualbox virtual machines you use podman containers. This way you get to use OCI images for your \"dev environment\" that integrates directly into your desktop. https://podman.io/ There is some challenges related to usermode networking for non-root-managed controllers and desktop integration has some additional complications. But besides that it has almost no overhead and you can have unfettered access to things like GPUs. Also it is usually pretty easy to convert your normal docker or kubernetes containers over to something you can run on your desktop. Also it is possible to use things like Kubernetes pods definitions to deploy sets of containers with podman and manage it with systemd and such things. So you can have \"clouds of containers\" that your dev container needs access to locally. If there is a corporate need for window-specific applications then running Windows VMs or doing remote applications over RDP is a possible work around. If everything you are targeting as a deployment is going to be Linux-everything then it doesn't make a lot of sense to jump through a bunch of hoops and cause a bunch of headaches just to avoid having it as workstation OS. reply lolinder 4 hours agoprev> This is not a story of whether or not to use Kubernetes for production workloads that’s a whole separate conversation. As is the topic of how to build a comprehensive soup-to-nuts developer experience for shipping applications on Kubernetes. > This is the story of how (not) to build development environments in the cloud. I'd like to request that the comment thread not turn into a bunch of generic k8s complaints. This is a legitimately interesting article about complicated engineering trade-offs faced by an organization with a very unique workload. Let's talk about that instead of talking about the title! reply kitd 3 hours agoparentAgreed. It's actually a very interesting use case and I can easily see that K8s wouldn't be the answer. My dev env is very definitely my \"pet\", thank you very much! reply ethbr1 2 hours agorootparentIt'd be nice to editorialize the title a bit with \"... (for dev envs)\" for clarity. Super useful negative example, and the lengths they pursued to make it fit! And no knock on the initial choice or impressive engineering, as many of the k8s problems they hit likely weren't understood gaps at the time they chose k8s. Which makes sense, given k8s roots in (a) not being a security isolation tool & (b) targeting up-front configurability over runtime flexibility. Neither of which mesh well with the co-hosted dev environment use case. reply ensignavenger 3 hours agoprevThe article does a great job of explaining the challenges they ran into with Kubernetes, and some of the things they tried... but I feel like it drops the ball at the end by not telling us at least a little what they chose instead. The article mentions they call their new solution \"Gitpod Flex\" but there is nothing about what Gitpod Flex is. They said they tried microVMs and decided against them, and of course Kubernetes, the focus of the article. So is GitpodFlex based on full VM's? Docker? Some other container runtime?? Perhaps a followup article will go into detail about their replacement. reply loujaybee 3 hours agoparentYeah, that's fair. The blog was getting quite long, so we need to do some deeper dives in follow-ups. Gitpod Flex is runner-based. The runner interface is intentionally generic so that we can support different clouds, on-prem or just Linux in future. The first implemented runner is built around AWS primitives like EC2, EBS and ECS. But because of the more generic interface Gitpod now supports local / desktop environments on MacOS. And again, future OS support will come. There’s a bit more information in the docs, but we will do some follow ups! - https://www.gitpod.io/docs/flex/runners/aws/setup-aws-runner... - https://www.gitpod.io/docs/flex/gitpod-desktop (I work at Gitpod) reply nickstinemates 3 hours agorootparentEchoing the parent you're replying to. You built up all of the context and missed they payoff. reply ethbr1 2 hours agorootparentI thought it was fair. >> We’ll be posting a lot more about Gitpod Flex architecture in the coming weeks or months. Cramming more detail into this post would have exceeded the average user read time ceiling. reply Bombthecat 1 hour agorootparentprevStill No idea what you did technically... Maybe a second post? Did you use consul? reply xyst 3 hours agoprevI do agree with the points in article that k8s is not a good fit for development environments. In my opinion, k8s is great for stable and consistent deployment/orchestration of applications. Dev environments by default are in a constant state of flux. I don’t understand the need for “cloud development environments” though. Isn’t the point of containerized apps is to avoid the need for synchronizing dev envs amongst teams? Or maybe this product is supposed to decrease onboarding friction? reply sofixa 3 hours agoparentIt's to ensure a consistent environment for all developers, with the resources required. E.g. they mention GPUs, for developers working with GPU-intensive workloads. You can ship all developers gaming laptops with 64GB RAM and proper GPUs, and have them fight the environment to get the correct libraries as you have in prod (even with containers that's not trivial), or you can ship them Macbook Airs and similar, and have them run consistent (the same) dev environments remotely (you can self-host gitpod, it's not only a cloud service, it's more the API/environment to get consistent remote dev enviornments). reply loujaybee 3 hours agorootparentYeah, exactly. Containers locally are a basic foundation. But usually those containers or services need to talk to one another, they need some form of auth and credentials, they need some networking setup. There's a lot of configuration in all of that. The more devs swap projects or the more complex the thing you're working on the more the challenge grows. Automating depedencies, secret access, ensuring projects have the right memory, cpu, gpu etc. Also security - moving source code off your laptop and devices and standardizing your setups helps if you need to do a lot of audit and compliance as you can automate it. reply roshbhatia 3 hours agoparentprevIn my experience, the case where this becomes really valuable is if your team needs access to either different kinds of hardware or really expensive hardware that changes relatively quickly (i.e. GPUs). At a previous small startup I setup https://devpod.sh/ (similar to gitpod) for our MLE/Data team. It was a big pro to leverage our existing k8s setup w/ little configuration needed to get these developer envs up and running as-needed, and we could piggyback off of our existing cost tracking tooling to measure usage, but I do feel like we already had infra conducive to running dev envs on k8s before making this decision -- we had cost tracking tooling, we had a dedicated k8s cluster for tooling, we had already been supporting GPU based workloads in k8s, and our platform team that managed all the k8s infra also were the SMEs for anything devenv releated. In a world where we started fresh and absolutely needed ephemeral devenvs, I think the native devcontainer functionality in vscode or something like github codespaces would have been our go to, but even then I'd push for a docker-compose based workflow prior to touching any of these other tools. The rest of our eng team just did dev on their laptops though. I do think there was a level of batteries-included-ness that came with the ephemeral dev envs which our less technical data scientists appreciated, but the rest of our developers did not. Just my 2c reply dikei 3 hours agoparentprevSarcastically, CDE is one way to move cost from CAPEX (get your developer a Mac Book Pro) to OPEX (a monthly subscription that you only need to pay as long as the dev has not been lay off) It's also much cheaper to hire contractors and give them the CDE that can be terminated on a moment notice. reply geoctl 2 hours agoprevI've worked on something similar to gitpod in a slightly different context that's part of a much bigger personal project related to secure remote access that I've actually spent a few years building now and hope to open source in a few months from now. While I agree on many of the points in the article, I just don't understand how using micro VMs by itself replaces K8s unless they actually start building their own K8s that orchestrates their micro VMs (as opposed to containers in the case of k8s) ending up with the same thing basically when k8s itself can be used to orchestrate the outer containers that run the micro VMs used to run the dev containers. Yes, k8s has many challenges when it comes to nesting containers, cgroups, creating rootless containers inside the outer k8s containers and other stuff such as multi-region scaling, but actually the biggest challenge that I've faced so far isn't related to networkPolicies or cgroups but is actually by far related to storage, both when it comes to (lazily) pulling big OCI images which are extremely unready to be used for dev containers whose sizes are typically in the GBs or 10s of GBs as well as also when it comes to storage virtualization over the underlying k8s node storage. There are serious attempts to accelerate image pulling (e.g. Nydus) but such solutions would still probably be needed whether you use micro VMs or rootless/userns containers in order to load and run your dev containers. reply datadeft 3 hours agoprevThe original k8s paper mentioned that the only use case was a low latency and a high latency workflow combination and the resource allocation is based on that. The generic idea is that you can easily move low latency work between nodes and there are no serios repercussions when a high latency job fails. Based on this information, it is hard to justify to even consider k8s for the problem that gitpod has. reply concerndc1tizen 27 minutes agoprevSounds more to me like they need a new CTO. And that they're desperate to tell customers that they've fixed their problems. Kubernetes is absolutely the wrong tool for this use case, and I argue that this should be obvious to someone in a CTO-level position, or their immediate advisors. Kubernetes excels as a microservices platform, running reasonably trustworthy workloads. The key features of Kubernetes are rollout (highly available upgrades), elasticity (horizontal scaleout), bin packing (resource limits), CSI (dynamically mounted block storage), and so on. All this relates to a highly dynamic environment. This is not at all what Gitpod needs. They need high performance disks, ballooning memory, live migrations, and isolated workloads. Kubernetes does not provide you sufficient security boundaries for untrusted workloads. You need virtualization for that, and ideally physically separate machines. Another major mistake they made was trying to build this on public cloud infrastructure. Of course the performance will be ridiculous. However, one major reason for using Kubernetes is sharing the GPU. That is, to my knowledge, not possible with virtualization. But again, do you want to risk sharing your data, on a shared GPU? reply rekoros 2 hours agoprevWe've been using Nix flakes and direnv (https://direnv.net/) for developer environments and NixOS with https://github.com/serokell/deploy-rs for prod/deploys - takes serious digging and time to set up, but excellent experience with it so far. reply andreweggleston 2 hours agoparentI’ve been using Nix for the past year and it really feels like the holy grail for stable development environments. Like you said—it takes serious time to set up, but it seems like that’s an unavoidable reality of easily sharable dev envs. reply clvx 3 hours agoprevI tried doing a dev environment on Kubernetes but the fact you have to be dealing with a set of containers that could change if the base layer changed meant instability in certain cases which threw me off. I ended up with a mix of nix and it's vm build system which is based on qemu. The issue is too tied to NixOS and all services run in the same place which forces you to manage ports and other things. How I wish it could work is having a flake that defines certain services, these services could or could not run in different µVMs sharing an isolated linux network layer. Your flake could define your versions, your commands to interact and manage the lifecyle of those µVM's. As the nix store can be cached/shared, it can be provide fast and reproducible builds after the first build. reply candiddevmike 3 hours agoparent> the fact you have to be dealing with a set of containers that could change if the base layer changed meant instability Can you expand on this? Are you talking about containers you create? reply debarshri 3 hours agoprevPhew, it is absolutely true. Building dev environments on k8s become wasteful. To add to this complexity, if you are building a product that is self hosted on customer's infrastructure. Debugging and support also become non homogeneous and difficult. What we have seen works especially when you are building developer centric product is expose these native issues around network, memory, compute and storage to engineers and they are more willing to work around it. Abstracting those issues leads to shift in responsibility on the product. Having said that, I still think k8s is an upgrade when you have a large team. reply tacone 44 minutes agoprevOn a side note: has anybody experience with MicroK8s? I'd love to learn stories about it. I'm interested in both dev and production experiences. reply alecfong 1 hour agoprevOur first implementation of brev.dev was built on top of kubernetes. We were also building a remote dev environment tool at the time. Treating dev environments like cattle seemed to be the wrong assumption. Turning kubernetes into a pet manager was a huge endeavor with long tail of issues. We rewrote our platform against vms and were immediately able to provide a better experience. Lots of tradeoffs but makes sense for dev envs. reply junkaccount 1 hour agoprevThe real reason for this shift is that kubernetes moved to containerd which they cannot handle. Docker was much easier. Differential workloads is not correct to blame. Also, there is a long tail of issues to be fixed if you do it with Kubernetes. Kubernetes does not just give you scaling, it gives you many things: run on any architecture, be close to your deployment etc. reply moondev 1 hour agoparenthttps://github.com/Mirantis/cri-dockerd reply junkaccount 22 minutes agorootparentMost of the kubernetes providers (GKE, EKS) do not support this new shim. Even on baremetal it is possibly hard to run. reply myestery 1 hour agoprevLeaving this comment here so I'll always come back to read this as someone who was considering kubernetes for a platform like gitpod reply lmeyerov 3 hours agoprevI was intrigued because the development environment problem is similar to the data scientist one - data gravity, GPU sharing, etc - but I'm confused on the solution? Oddly, I left with a funny alternate takeaway: One by one, their clever inhouse tweaks & scheduling preferences were recognized by the community and turned into standard k8s knobs So I'm back to the original question... What is fundamentally left? It sounds like one part is maintaining a clean container path to simplify a local deploy, which a lot of k8s teams do (ex: most of our enterprise customers prefer our docker compose & AMIs over k8s). But more importantly, something fundamental architecturally about how envs run that k8s cannot do, but they do not identify? reply csweichel 2 hours agoparentOP here. The Kubernetes community has been fantastic at evolving the platform, and we've greatly enjoyed being in the middle of it. Indeed, many of the things we had to build next to Kubernetes have now become part of k8s itself. Still, some of the core challenges remain: - the flexibility Kubernetes affords makes it hard to build and distribute a product with such specific requirements across the broad swath of differently set up Kubernetes installations. Managed Kubernetes services help, but come with their own restrictions (e.g. Kernel versions on GKE). - state handling and storage remains unsolved. PVCs are not reliable enough, subject to a lot of variance (see point above), and depending on the backing storage have vastly different behaviour. Local disks (which we use to this day), make workspace startup and backup expensive from a resource perspective and hard to predict timing wise. - user namespaces have come a long way in Kubernetes, but by themselves are not enough. /proc is still masked, FUSE is still not usable. - startup times, specifically container pulls and backup restoration, are hard to optimize because they depend on a lot of factors outside of our control (image homogeneity, cluster configuration) Fundamentally, Kubernetes simply isn't the right choice here. It's possible to make it work, but at some point the ROI of running on Kubernetes simply isn't there. reply lmeyerov 2 hours agorootparentThanks! AFAICT, a lot of that comes down to storage abstractions, which I'll be curious to see the answer on! Pinned localstoragecloud native is frustrating. I sense another big chunk is the fast secure start problems that firecracker (noted in the blogpost) solve but k8s is not currently equipped for. Our team has been puzzling that one for awhile, and part of our guess is incentives. It's been 5+ years since firecracker came out, so likewise been frustrating to see. reply thenaturalist 3 hours agoparentprev> We’ll be posting a lot more about Gitpod Flex architecture in the coming weeks or months. I’d love to invite you on November the 6th to a virtual event where I’ll be giving a demo of Gitpod Flex and I’ll deep-dive into the architecture and security model at length. Bottom of the post. reply javier_e06 2 hours agoprevThe article is an excellent cautionary tale. Debugging an app in a container is one thing. Debugging and app running inside a Kubernetes node is a rabbit hole that demands more hours and expertise. reply cheptsov 2 hours agoprevI can completely relate to anyone abandoning K8s. I'm working with dstack, an open-source alternative to K8s for AI infra [1]. We talk to many people who are frustrated with K8s, especially for GPU and AI workloads. [1] https://github.com/dstackai/dstack reply Muhtasham 1 hour agoparentI really like dstack, keep up the great work reply bhouston 3 hours agoprevI also recently left Kubernetes. It was a huge waste of time and money. I've replaced it with just a series of services on Google Cloud Run and then using Google's Cloud Run Tasks services for longer running tasks. The infrastructure now incredibly understandable and simple and cost effective. Kubernetes cost us >$million in both DevOps time and actually Google Cloud costs unnecessarily, and even worse it cost us time to market. Stay off of Kubernetes as long as you can in your company, unless you are basically forced onto it. You should view it as an unnecessary evil that comes with massive downsides in terms of complexity and cost. reply kbolino 3 hours agoparentAs far as I can tell, there actually is no AWS equivalent to GCP Cloud Run. The closest equivalents I know of are ECS on Fargate, which is more like managed Kubernetes except without Kubernetes compatibility or modern features, or AppRunner, which is closer in concept but also sorely lacking in comparable features. reply Imustaskforhelp 2 hours agoparentprevwow very very interesting. I think we can discuss about it on hours. 1.) What would you think of things like hetzner / linode / digitalocean (if stable work exists) 2.) What do you think of https://sst.dev/ or https://encore.dev/ ? (They support rather easier migration) 3.) Could you please indicate the split of that 1 million $ in devops time and google cloud costs unnecessarily & were there some outliers (like oh our intern didn't add this specific variable and this misconfigured cloud and wasted 10k on gcloud oops! or was it , that bandwidth causes this much more in gcloud (I don't think latter to be the case though)) Looking forward to chatting with you! reply elcomet 3 hours agoparentprevAren't you afraid of being now stuck with GCP? reply bhouston 3 hours agorootparentIt is just a bunch of docker containers. Some run in tasks and some run as auto-scaling services. Would probably take a week to switch to AWS as there are equivalent managed services there. But this is really a spurious concern. I myself used to care about it years ago. But in practice, rarely do people switch between cloud providers because the incremental benefits are minor, they are nearly equivalent, there is nothing much to be gained by moving from one to the other unless politics are involved (e.g. someone high up wants a specific provider.) reply spwa4 3 hours agorootparentHow does the orchestration work? How do you share storage? How do the docker containers know how to find each other? How does security work? I feel like Kubernetes' downfall, for me, is the number of \"enterprise\" features it (got convinced into) supporting and enterprise features doing what they do best: turning the simplest of operations into a disaster. reply bhouston 3 hours agorootparent> How does the orchestration work? Github Actions CI. Take this and make a few more dependencies and a matrix strategy and you are good to go: https://github.com/bhouston/template-typescript-monorepo/blo... For dev environments, you can add post-fixes to the services based on branches. > How do you share storage? I use managed DBs and Cloud Storage for shared storage. I think that provisioning your own SSDs/HDs to the cloud is indicative of an anti-pattern in your architecture. > How do the docker containers know how to find each other? I try to avoid too much communication between services directly, rather try to go through pub-sub or similar. But you can set up each service with a domain name and access them that way. With https://web3dsurvey.com, I have an api on https://api.web3dsurvey.com and then a review environment (connected to the main branch) with https://preview.web3dsurvey.com / https://api.preview.web3dsurvey.com. > How does security work? You can configure Cloud Run services to be internal only and not to accept outside connections. Otherwise one can just use JWT or whatever is normal on your routes in your web server. reply sofixa 3 hours agorootparentprevOne of Cloud Run's main advantages is that it's literally just telling it how to run containers. You could run those same containers in OpenFaaS, Lambda, etc relatively easily. reply rglover 3 hours agoparentprevWhat stack are you deploying? reply bhouston 3 hours agorootparentStuff like this, just at larger scale: https://github.com/bhouston/template-typescript-monorepo This is my living template of best practices. reply rglover 2 hours agorootparentI'd investigate getting a build out to Node.js (looks like you already have this) and then just doing a simple SCP of the build to a VPS. From there, just use a systemd script to handle startup/restart on errors. For logging, something like the Winston package does the trick. If you want some guidance, shoot me an email (in profile). You can run most stuff for peanuts. reply bhouston 2 hours agorootparent> I'd investigate getting a build out to Node.js (looks like you already have this) and then just doing a simple SCP of the build to a VPS. From there, just use a systemd script to handle startup/restart on errors. For logging, something like the Winston package does the trick. If you want some guidance, shoot me an email (in profile). You can run most stuff for peanuts. I appreciate the offer! But it is not as robust and it is more expensive and misses a lot of benefits. Back in the 1990s I did FTP my website to a VPS after I graduated from Geocities. Google Cloud charges based on CPU used. Thus my servers have no traffic, they cost less than a $1/month. If they have traffic, they are still cost effective. https://web3dsurvey.com has about 500,000 hits per month and it costs me $4/month to run both the Remix web server and the Fastify API server. Details here: https://x.com/benhouston3d/status/1840811854911668641 Also it will autoscale under load. Thus when one of my posts was briefly the top story on Hacker News last month, Google Cloud Run added more instances to my server to handle the load (because I do not run my personal site behind a CDN, it cost too much, I prefer to pay $1/month for hosting.) Also deploying Docker containers that build on Github Actions CI in a few minutes is a great automated experience. I do also use Google services like Cloud Storage, Firestore, BigQuery etc. And it is easier to just run it on GCP infrastructure for speed. I also have to version various tools that get installed in the docker like Blender, Chromium, etc. This is the perfect use case for Docker. I feel this is pretty close to optimal. Fast, cheap, scalable, automated and robust. reply Imustaskforhelp 2 hours agorootparentprevthere was some recent HN post which showed that they didn't even use docker but rather there was some other mechanism and it was so so simple , I really enjoyed that article reply Imustaskforhelp 2 hours agorootparentprevyeh I have same thoughts , also if possible , bun can also reduce memory usage in very very basic scenarios https://www.youtube.com/watch?v=yJmyYosyDDM Or just https://github.com/mightymoud/sidekick or coolify or dokku or dockify , like there are million of such things , oh just remembered kamala deploy from DHH and docker swarm IIRC (though people have seemed to forget docker swarm !) I like this idea very much ! reply candiddevmike 3 hours agoparentprevYou know that Cloud Run is effectively a Kubernetes PaaS, right? reply richards 3 hours agorootparentGoogle employee here. Not the case. Cloud Run doesn't run on Kubernetes. It supports the Knative interface which is an OSS project for Kubernetes-based serverless. But Cloud Run is a fully managed service that sits directly atop Borg (https://cloud.google.com/run/docs/securing/security). reply chanux 3 hours agorootparentprevI guess the point is that for the OP, Kubernetes is now someone else's problem. reply bhouston 3 hours agorootparentprev> You know that Cloud Run is a Kubernetes PaaS, right? Yup. Isn't it Knative Serving or a home grown Google alternative to it? https://knative.dev/docs/serving/ The key is I am not managing Kubernetes and I am not paying for it - it is a fool's errand, and incredibly rarely needed. Who cares what is underneath the simple Cloud Run developer UX? What matters for me is cost, simplicity, speed and understandability. You get that with Cloud Run, and you don't with Kubernetes. reply rohitghumare 1 hour agoprevYou just simplified Kubernetes Management System reply pphysch 2 hours agoprev [–] The problem with \"development environments\", like other interactive workloads, is that there is a human at the other end that desires a good interactive experience with every keypress. It's a radically different problem space than what k8s was designed for. From a resource provider productive, the only way to squeeze a margin out of that space would be to reverse engineer 100% of human developer behavior so that you can ~perfectly predict \"slack\" in the system that could be reallocated to other users. Otherwise it's just a worse DX, like TFA gives examples of. Not a business I'm envious too be in... Just give everyone a dedicated VM or desktop, and make sure there's a batch system for big workloads. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gitpod is transitioning from Kubernetes to a new architecture called Gitpod Flex, addressing challenges in scalability, security, and resource management specific to development environments.",
      "Kubernetes was found to be complex and costly for development environments due to their unique needs, such as statefulness and unpredictable resource usage.",
      "Gitpod Flex, inspired by Kubernetes, offers improved security, operational simplicity, and supports self-hosting, with a virtual event scheduled for November 6th to showcase its features."
    ],
    "commentSummary": [
      "The discussion highlights the challenges of using Kubernetes for development environments, emphasizing issues like high feedback loops and remote debugging difficulties.- Suggestions include equipping developers with powerful local machines and using virtual machines (VMs) for consistency, while also considering cloud-based environments for specific needs like GPU access.- The consensus is that Kubernetes may not be ideal for development environments due to its complexity, with alternative solutions like Gitpod Flex being explored for a more tailored approach."
    ],
    "points": 166,
    "commentCount": 75,
    "retryCount": 0,
    "time": 1730731288
  },
  {
    "id": 42039935,
    "title": "Cheap Thrills, an album cover by Robert Crumb (2020)",
    "originLink": "https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/",
    "originBody": "January 28, 2020 • 14 Cheap Thrills, an album cover by Robert Crumb A curious tale this, about an artist who draws an album cover for a band he does not care for, playing a music style he does not listen to, appealing to an audience he does not connect with. And to top it, the art selected for the front cover was the one he intended for the back cover. The result: one of the most iconic album covers to come out of the late 1960s. This is the story of Robert Crumb’s cover art for Janis Joplin and Big Brother and the Holding Company’s career-changing album Cheap Thrills. The story of this album cover starts in January of 1967, when Crumb moved to San Francisco. The previous two years were spent soaking in LSD and travelling between New York, Chicago, and Detroit. The drug was legal then and an eye opener for many, as he remembers: “At that moment, 1965-1966, it was very exciting. You got in a subway and you were a person that took LSD. If there was another person on that subway who has also taken LSD, you immediately knew who they were, you knew each other. You’d look in their eyes and you knew and they knew you had. It was like an intimate brotherhood of people who had seen through the whole thing in some way that most people didn’t have a clue at all. There was that golden moment.” During these two years he published the character of Fritz the Cat, the most outrageous feline in history, in various magazines including Help! and Cavalier. Other characters started their life during that period and bloomed after his move to the Hippie capital. They included the mystic guru Mr. Natural, the sex-crazed Mr. Snoid and last but not least, Snoid’s favorite companion Angelfood McSpade, the insatiable African black woman who took stereotyping to new levels. Upon his arrival in San Francisco, Crumb quickly found his way to Haight Ashbury and the Psychedelic Shop and immersed himself in the carefree culture of the town: “San Francisco was a great town at the time, a really beautiful city. After living in Cleveland, Chicago, New York, Philadelphia and Detroit, all these really depressing industrial cities, San Francisco seemed like a sweet little cupcake with Victorian houses and pretty parks.” The town offered him the best environment to indulge in the things that most interested him: drawing wild comics and taking acid. Oh, and of course, sex. Talking about LSD and its impact on the counter-culture, Crumb said: “LSD was the road to Damascus for the hippies. It turned the left wing serious political anti-war movement into something religious and visionary. It was no longer political, folk music, help the Negros, fight the war and all that. It became mystical, saving the earth, the preciousness of nature, living close to nature. Much more radical and extreme.” He was drawing all that time, adapting old cartoon styles to the hippie hallucinogen vision, slowly picking up interest and recognition. After contributing his work to various underground magazines, he was invited to create a full comic magazine named Zap. The first issue featured his favorite Mr. Natural on the cover. The publication of Zap Magazine provided exposure but no income and Crumb was nearly penniless. Copies of the first issue were printed, folded and stapled by Crumb and sold on the street at Haight-Ashbury for 25 cents a copy. Proprietors of stores in that hip area did not get what’s with these comic books he was offering them. They stocked psychedelic art nouveau concert posters, incense, pipes, bongs, candles, not comic books that looked like Popeye on the cover. But within six months Zap comics caught on and Crumb became known for his talent as an underground comics artist. None describes the world of Crumb better than Crumb: “My comics appealed to the hard-drinking, hard-fucking end of the hippie spectrum as opposed to the spiritual, Eastern-religious, lighter-than-air type hippie.” Still, monetary rewards were not forthcoming from hippie stardom. He wrote in a letter in June 1968: “What good has fame done me? I’m broke and girls still act aloof. Time has come for a change! Bwah howdy!” In that same letter, addressed to his friend Mike Britt, he mentions an important meeting, contrasting it with the sad affair of his monogamous relationship: “I am going over to meet Janis Joplin tonight… CAN’T WAIT! Which brings me to another important point, which is my sex life has been sliding downhill lately so I’m trying to do something about that! The only girl I’m making it with is my wife, and getting’ tired of just her all the time.” Words that would send chills down conservative Americans’ spines, but we are at the center of the hippie galaxy in 1968, the time and place where anything goes. Was Janis his salvation from bedroom boredom? Lets stick with the topic of this article and assume that she was just asking him to draw the cover of her band’s second album, which is exactly what happened. Janis Joplin, 1968 Crumb had no patience for much of the music surrounding him in San Francisco or elsewhere in the late 1960s. This is blasphemy for anyone (myself included) who cares about all the great music created in those days, the golden age of rock and psychedelic music. But Crumb came from another era, mentally, and to him this music was commercialism personified compared to the roots music from the 1920s and 1930s that moved him: “I had no patience for any of that psychedelic pop music or crap that came in the 60s: The Grateful Dead, Jim Morrison, The Doors, The Beatles, Bob Dylan. I had little or no interest in any of that. I thought I had found some music that was much more real, that came from the heart of people’s culture but had been wiped out by mass media and commercialism.” Robert Crumb, 1969 But Crumb made an exception with Janis Joplin, connecting with her for their mutual love of old Blues music: “She wasn’t nationally known yet. I remember going to see her at the Avalon Ballroom and you could tell right away that she had an exceptional voice and she would go far. She started out singing old time blues like Bessie Smith. She was kind of a folknik originally.“ While he did not care for her current band and the psychedelic spin they took on blues, he recognized her ability to belt out the good ol’ blues: “Janis had played with earlier bands just playing country blues and it was much better. Way, way better. She’s singing well, not screaming, not playing to the audience that wanted to watch her sweat blood. In the beginning she was just an authentic, genuine Texas country-girl shouter.” Janis Joplin, San Francisco 1966 Crumb was not the first choice for Big Brother and the Holding Company’s album cover. The band, which rose to meteoric success immediately after their milestone performance at the Monterey Pop Festival in the summer of 1967, was quickly signed to Columbia Records who wanted an album quick to cash in on the emerging flower power market. The original title for the band’s first album for Columbia was Sex, Dope and Cheap Thrills, a fair summary of the band’s credo. That, of course, did not fly with the suits at Columbia who nixed the blunt Sex and Dope and left only the vague Cheap Thrills. When it came time for the album cover, the band’s idea was to go with an expected band photo, with a minor twist of taking the photo in their birthday suits. The result proved unsatisfactory, and another no-no for the suits who make the decisions. The idea of going with a standard band photograph was not abandoned yet, as Drummer Dave Getz remembers: “Then Bob Cato, CBS’s art director, thought we should do a photo session with Richard Avedon, perhaps the most famous fashion photographer in the world. Avedon did his ‘Avedon thing’ on us; the fan blowing our hair, the strobe lights flashing, white background, random rearrangement of our faces. It was another huge and costly miss. The photos were good but more about Avedon than us.” Big Brother and the Holding Company, by Richard Avedon What’s a band to do now? Enter Crumb the Sex, Dope and Cheap Thrills universe. Drummer Dave Getz recalls the moment the idea of asking Crumb to do the cover came up: “We had a huge loft/warehouse in SF where we rehearsed and I lived. I remember us all sitting around and talking ideas for the cover and I said ‘How about asking R.Crumb?’ Janis, James (Gurley, guitar player) and I were all big fans of his work, we loved his cartoons which were appearing in the SF underground newspapers and Zap Comics. But outside of SF not that many people knew of his genius.” Through a mutual friend they got Crumb’s number and Janis called him. Crumb continues the tale: “Janis asked me to do an album cover. I liked Janis OK and I did her cover. I took speed and did an all-nighter. The front cover I designed wasn’t used at all. They used the back cover for the front. I got paid $600. The album cover impressed the hell out of girls much more so than the comics. I got a lot of mileage out of that over the years!” Getz adds: “The next weekend Crumb came to our show at The Carousel Ballroom, sat on the floor in our backstage dressing room and observed. He really wasn’t into our music but it didn’t matter. It was maybe one or two days later Crumb called Janis to come and pick up what he’d done.” Janis Joplin, by Richard Crumb Getz is understandably mild in his description of Crumb’s opinion of Big Brother and the Holding Company. Here is Crumb’s version, unadulterated: “She was a swell gal and a very talented singer. Ever heard any of this pre-Big Brother stuff she recorded? She was great. Then she got together with those idiots. The main problem with Big Brother was they were amateur musicians trying to play psychedelic rock and be heavy and you listen to it now and it’s bad… just embarrassing.” Agree with him or not, this is Crumb. Gotta love his candid way of describing things in words and images. Back to that cover. Crumb’s original idea for the front cover was a cartoon of the band performing on stage with the band’s faces pasted on them. The band was less than overwhelmed by this, but then they looked at what Crumb delivered for the back cover and they saw the light. A comic strip with a panel for each of the songs plus band members credits. They immediately decided to make it the front cover and forever cemented the iconic status of that comic strip among album covers. Lets give the band some and listen to a few tunes from that album, while looking at the comic panels related to them. We begin with I Need A Man To Love, a blues-rock number that Crumb adorned with his idea of a well-endowed woman (Janis) stretched on a bed, looking in need, of a man. Next is the band’s fantastic cover of Summertime, George Gershwin’s song from the 1935 opera Porgy and Bess. The song has been covered many times in operatic and jazz renditions, but here it takes a completely different spin with a wonderful arrangement and solo by the band’s guitarist Sam Andrew. As for Crumb’s depiction of that scene from the musical, lets not even go there. Suffice it to say that a cover like that will not see the light of day today. And one more, the song that put the band and Janis Joplin on the map at the Monterey Pop Festival, Big Mama Thornton’s Ball and Chain. The song closes the album with a bang with one of the dirtiest guitar sounds committed to vinyl and a vocal performance for the ages. Cheap Thrills was released in August of 1968, steadily climbing the Billboard LPs chart until it reached the top and stayed there 8 consecutive weeks. When Janis Joplin announced during a show at the Fillmore East in the fall of 1968 that their album cover was the work of R.Crumb, they received the biggest standing ovation of the night. Crumb was a hero for the hippies, but by that point he was on a very different wavelength. He liked some aspects of the Hippie movement, what he termed as seeing through the hype of consumer culture. He valued how they strived to live simply and saw the ecology movement being sparked by that. But he quickly became disillusioned by the movement: “Since it was mostly children of the middle class, it was immediately something for them to be smug about. ’Oh, I have seen the light and you haven’t. I’m beautiful, I’m spiritual. I lost my ego and you haven’t.’ It became where in any social gathering everybody sat around trying to out-cool each other.” But as he admits, he never felt comfortable in that environment anyway, even when it was at its peak of innocence: “I couldn’t kick off my shows and go dance in the park. I didn’t have it in me.” In November of 1968, when the album peaked at the top of the LP charts, the top 10 albums also included Electric Ladyland and Are You Experienced by the Jimi Hendrix Experience, The Time Has Come by The Chambers Brothers, Crown of Creation by Jefferson Airplane, The Crazy World of Arthur Brown and Wheels of Fire by Cream. This was the golden age of psychedelic music. Crumb was inside the bubble physically, but not mentally. I want to spend the last part of this article discussing the music Crumb DID like, for which he produced many album covers and portraits of musicians, all of them wonderful articles of art. None of them as remotely well known as Cheap Thrills, however by all means worth looking at. Crumb owns a large collection of old 78 albums. He talked elaborately about his passion for the music he loves, and the moment he started collecting music: “I always liked the kind of music you’d hear in the background of old movies from the early ‘30s, the early sound movies and cartoons. And then in my searching for old books and comic books, these junk stores had these old 78 records. One day, out of curiosity, I bought some of these records. They were very cheap. I put the records on and voila! ‘Oh my god, that’s the music, that’s the music from these old movies, that’s incredible.’ I was sixteen and I remember very clearly the day that I discovered that you could find those records. They were lying around everywhere in those days, in 1959.” In his teens Crumb was exposed to 1950s pop music, which he describes as something he had to suffer through, singers like Frank Sinatra, Perry Como, Doris Day. He had a period of reprieve with the advent of rock n roll, Elvis Presley and Little Richard: “There was some feeling of blues and old time country in that early rock and roll, it was coming out of really low life in the South. Those people all came from the lowest rung of society.” That period did not last long for him, as it was quickly commercialized for middle class consumption, and he stack with old black blues and folk music ever since. Asked about how a white guy connects so deeply with black music created in the 1930s, he answered: “I don’t know. There’s something so raw, kind of beauty that speaks to me in a deep and direct way. Personally I barely even know any black people and I can’t relate to lower class black culture very well at all. It’s very alien to me in a certain way, and people I’ve known from that black culture, I’ve never been able to get very close to, because their values are so different. So what is it about their music that speaks so directly? It has some universal appeal because it has had such a big influence on the music of the entire world.” What a better way to close this article about Crumb and his contributions as an artist to the music world, then mention the stint he had in the mid 1970s as a musician himself. After settling down in Madison, California, Crumb started playing banjo and mandolin in the Cheap Suit Serenaders Band: “They were my pals for years. We sat around playing music together and somebody said we could play a job for $100, so we agreed. It was interesting for a while, but I came to the point where I realized I had to quit. I asked myself ‘Do I want to get more deeply involved in this music business?’ and I really didn’t.” If you enjoyed reading this article, you may also like this one about another great album art coming out of San Francisco in the late 1960s: Santana’s Debut Share this: Facebook Twitter Reddit Tumblr Pocket Pinterest Mastodon Email Print Like this: Like Loading... Related Album Covers by Mati Klarwein Mati Klarwein's first foray into the world of album covers ended with a glorious failure. In the late 1950s he was listening to jazz, a style thriving at the time with new artists exploring the intersection of jazz, classical and ethnic music. One of them was Yusef Lateef, a multi… In \"Album Art\" Frank Zappa’s Album Covers by Cal Schenkel, part 2: the 1970s Part 1 of this article, covering Cal Schenkel's album covers in the 1960s: https://musicaficionado.blog/2020/06/23/cal-schenkels-album-covers-part-1-the-1960s/ Zappa entered the 1970s with two albums that included material previously recorded by the Mothers of Invention and assembled together in the studio. The first, Burnt Weeny Sandwich, used unconnected recordings which were edited to form… In \"Album Art\" Robert Kirby The British folk revival of the late 1960s and early 1970s produced great instrumentalists, many of them guesting on albums by a multitude of artists. It was a relatively small and incestuous scene, cross-pollinating its members across recording dates that were made at low budget. Many albums of that period… In \"Artist\" Discover more from The Music Aficionado Subscribe to get the latest posts sent to your email. Type your email… Subscribe Categories: Album Art",
    "commentLink": "https://news.ycombinator.com/item?id=42039935",
    "commentBody": "Cheap Thrills, an album cover by Robert Crumb (2020) (musicaficionado.blog)140 points by stareatgoats 9 hours agohidepastfavorite71 comments fallinditch 3 hours agoRobert Crumb was interviewed for a BBC Radio 3 program where he played some records from his collection and talked about them. One song was particularly fascinating: a primitive attempt at the new fangled sound called 'jazz' by a French country musette band from the early 20th C. Crumb explained that when early American jazz bands went to Paris in the 1910s, the new sounds caused a sensation when they performed in the up-market venues. So the country bands were aware of the new style of jazz but most people had never actually heard any and had to play what they imagined jazz to be, mostly based off verbal descriptions. I remember this record as a crazy sound, but brilliantly entertaining. Unfortunately I can't point you to the song or the interview, but if anyone else can please reply :-0 reply kencausey 1 hour agoparentI got as far as finding this: https://tenwatts.blogspot.com/2011/01/crumb-and-blues.html reply nimbs 1 hour agoparentprevIs this the program? R. Crumb's Sweet Shellac - Early French Jazz Before Django: https://www.youtube.com/watch?v=uHsqAK_kJ2o You can find track list from here: https://www.organissimo.org/forum/topic/71710-r-crumbs-sweet... reply fallinditch 1 hour agorootparentYes, this is what I was trying to remember, thanks for the links! reply alcover 2 hours agoprevCrumb has been living in a small village in the south of France since the 90's. In the \"Crumb\" doc he says something along \"They're all wearing baseball hats. I'm getting out of here.\", speaking about the US. He also laments having taken too much LSD. reply delichon 48 minutes agoprevhttps://www.pinterest.com/pin/440508407309861046/ fly on the wall reply ZeroGravitas 8 hours agoprevThe intro about him not liking the music reminded me of the Letter of Note entry when Crumb is sent an experimental jazz album and replies to the musician: https://lettersofnote.com/2015/12/17/torturing-the-saxophone... > I gotta tell you, on the cover of the CD of your sax playing, which is black and has no text on it, I wrote in large block letters, in silver ink, “Torturing The saxophone—Mats Gustafsson.” I just totally fail to find anything enjoyable about this, or to see what this has to do with music as I understand it, or what in God´s name is going on in your head that you want to make such noises on a musical instrument. Quite frankly, I was kind of shocked at what a negative, unpleasant experience it was, listening to it. reply rufus_foreman 4 hours agoparent>> I just totally fail to find anything enjoyable about this, or to see what this has to do with music as I understand it, or what in God´s name is going on in your head that you want to make such noises on a musical instrument When I was young, a music review like this would have 100% gotten me to buy the CD. reply grujicd 3 hours agorootparentHey, I'm 51, music is a big part of my life and I love hearing new things. Among other concerts, I visit few jazz festivals every year so I'm exposed to a lot of different music. But let me tell you, I could easily write similar review for some (most?) jazz sax musicians I heard. It seems that sax encourages players to visit musical areas I don't understand and enjoy. Therefore, if I read a review like this, I would most likely totally believed it! reply fallinditch 2 hours agorootparentJazz music is many things but in its essence it is avant garde. Some of the best music, like all art, can be difficult and challenging. To reveal their beauty and inspiration it may require some effort, but the rewards are worth it! Check out these albums by avant garde saxophonists. You may hate them on first listen but I urge you to persevere and hopefully open your mind and soul to their brilliance. Anthony Braxton's 1970 masterpiece, For Alto, is a landmark of free jazz. https://youtube.com/playlist?list=PLs9zwqXsceUikMH4R_yWvR62w... New History Warfare vol 2: Judges by Colin Stetson, from 2011 is so deep, he created new landscapers of sound with his sax, but it is also sublime and beautiful. https://youtube.com/playlist?list=PLnpQFjefXCROSKaSWDOtHyWEU... And then for your next homework, check out the massive discography by John Zorn ;-) https://www.allmusic.com/artist/john-zorn-mn0000239329 reply grujicd 2 hours agorootparentI'm no stranger for persevering through dificult music if I have strong recommendations it will be worth it. I'll give a chance to all of that. Thanks! reply 0x1ceb00da 2 hours agorootparentprevMy favourite: https://youtu.be/AIcjsqGln2w?si=-lY4h3vvGr52ZH8l reply pavel_lishin 3 hours agorootparentprevOne of my favorite bands (Igorrr), a friend described to me as \"musical ADHD, they can't pick an instrument to stick with for more than 20 seconds on any given track.\" It's perfect. reply NDizzle 3 hours agorootparentprevWhat changed?! I'm going to check it out right now! reply shermantanktop 3 hours agorootparentI used to do that too, except typically it was hardcore punk and 1980s noise/industrial, but yes there were some Ornette Coleman and Eric Dolphy records in there too. I finally realized that once I had satisfied my consumerist urge to be the coolest connoisseur, I now had to listen to the stuff, and I didn’t actually like it. reply taylorbuley 4 hours agoprevCrumb is from my small town in CA. During the fires, not so long ago, my mentor kept some of his old journals safe for his family. 10 or so notebooks full of doodles, all in one place. I can only imagine what that was worth! Much more, culturally, to be sure. reply pavel_lishin 3 hours agoparentI hope they can be scanned and made available - assuming, Mr. Crumb is ok with it. reply egypturnash 40 minutes agorootparenthttps://www.fantagraphics.com/collections/r-crumb#/filter:mf... Fantagraphics has you covered. I’m sure someone has shared a PDF if you don’t want to track down physical copies. reply narrator 8 hours agoprevAnyone see the documentary about him: \"Crumb\" (1994)? Everyone in his family is a little off, but back in those days, you just did the best you could with what you got and if you were a gifted artist like Crumb, you turned being an odd ball into a career. reply lqet 8 hours agoparentI strongly recommend the documentary. But \"a little off\" is an understatement. By the time of the documentary, his highly intelligent brother Charles is still living with his amphetamine-addicted mother in his late 40ies and rarely leaves his childhood bedroom. He admits on camera that he has \"homosexual pedophiliac tendencies\" and fantasized about killing Robert as a teenager, and complains that he cannot have an erection anymore because of his medication. Tragically, Charles killed himself shortly after filming of the documentary wrapped. Crumbs other brother Maxon [0], an accomplished and highly talented painter who earns money as a beggar on the streets, tries to find some peace of mind by living a zen-like life in celibacy, in a decrepit hotel room, full of meditation on a bed of nails, and is struggling with his intense sexual desire, several sexual harassment suits, and the fact that he cannot physically have sex, because the pleasure is so intense for him that it triggers epileptic seizures. All three brothers appear to have problems with extreme sexual desire, and Robert is the only one who seems to be able to function at all, although the documentary shows him several times in a trance-like, babbling state induced by the sight of a woman (in older age, he once said in an interview that he is \"no longer a slave to a raging libido\" [1]). [0] https://www.sfgate.com/entertainment/article/Still-in-the-sh... [1] https://www.theguardian.com/books/2019/mar/07/robert-crumb-i... reply Daub 4 hours agorootparentLittle mentioned is the fact that the three crumb brothers had two sisters. Neither of them agreed to take part in the movie, and very little is known about them. reply leoc 5 hours agorootparentprevWasn't one of the brothers also a (heterosexual) stalker with an Asian fetish and a habit of drawing art about it? Presumably that was Maxon. It's been a long time since I've seen the documentary. TFA is also frankly pretty underhanded in talking up Crumb's love of inter-war blues recordings while saying very little about his forays into anti-black racism, including one example which is so notorious that the Crumb documentary confronts him directly about it. reply gosub100 5 hours agorootparentOr more directly, his art often portrayed black people in caricature. reply rufus_foreman 5 hours agorootparent>> his art often portrayed black people in caricature His art often portrayed people in caricature. reply alt227 5 hours agorootparentIf the subjects are rarely white and mostly black, is it not fair to say that he often portrayed black people in caricature? Similar to saying 'Van Gogh often painted sunflowers' instead of 'Van Gogh often painted flowers'. reply tokai 3 hours agorootparentA majority of Van Gogh's flower painting are not of sunflowers. reply leoc 4 hours agorootparentprevThere's a fuzzy but very real distinction between caricature in general and frankly racist caricature. Quite a few of Crumb's drawings of black people have been clearly over that line, and (polite warning) it would be pretty rash to try to deny that. reply bazoom42 3 hours agorootparentThat is putting it mildly. Crumbs art is ridiculously over the top offensive. Of course taboo-breaking was the point of underground comics. reply mistrial9 4 hours agorootparentprevthe art was published underground because plenty of it was plenty offensive to lots of groups of people. .. that was the intention completely. Lots of R Crumb's art was controversial and outrageous by definition. Lots of reasonable and caring people had a lot of concern, volunteer censors appeared from many corners with torches and brimstone, and the art was published anyway. reply loudmax 5 hours agoparentprevAlong similar lines, Steve Buscemi's character Seymour in \"Ghost World\" (2001) is pretty clearly heavily inspired by Robert Crumb. Seymour collects old blues records and it put off by rock music, not to mention normal mainstream American culture. \"Ghost World\" was based on a comic book and was directed by Terry Zwigoff, the director of \"Crumb\". reply tosser0001 5 hours agorootparentThe first record Enid looks at is actually by \"R. Crumb and his Cheap Suit Serenaders\" that Seymour directs her away from to another selection. Zwigoff was a member of that group. reply bazoom42 32 minutes agorootparentprevAlso Seymor gets into trouble because of his fascination with vintage racist carricature. reply havblue 1 hour agorootparentprevIs that where the subplot of the chicken poster in that movie came from? I was just thinking about Ghost World as I was reading the comments above, thinking, \"now that's a subject Hollywood doesn't want to touch anymore.\" reply Aransentin 6 hours agoparentprevI found Gwern's review of that quite good: https://gwern.net/review/crumb reply jb1991 8 hours agoparentprev“back in those days” … it really was not that long ago, and what you say is also true today. reply ggm 8 hours agorootparent1968 is over 50 years ago. As a 1961 vintage person, 50 years back was pre WW1. the past is another country. They do things very differently in Fritz the cat's time. I don't think you could publish that now. reply Joeboy 7 hours agorootparent> I don't think you could publish that now Maybe you'd struggle to get widespread (physical) distribution, or to build an audience, or to make a living off it. I don't think anybody would stop you printing it, or take down your website or whatever. It wasn't mainstream or uncontroversial in the '60s either. reply bazoom42 5 hours agorootparentprev> I don't think you could publish that now. What would prevent you from publishing something like that today? reply jb1991 6 hours agorootparentprevthere are plenty of things published today that push boundaries in the same way reply ChrisMarshallNY 6 hours agorootparentprevWally Wood did \"The Disneyland Memorial Orgy\" (Google it) around the same time. I'm pretty sure it was banned (not anymore, as that Google It will show). reply leoc 3 hours agorootparentprevIt's not merely that 50 years is a long time. There's a profound cultural watershed between the Before Times, the overcontrolled, neurotic world of roughly up to the late '60s, and the narcissistic/sociopathic world of today. Robert Crumb, and the whole Crumb family, embody that change in an unusually extreme way. reply theFco 8 hours agorootparentprevand furthermore, \"families that are a bit off\" are still plenty today, and people still do the best with what they got. I don't see the need to say that was that way then... reply leoc 2 hours agorootparentYes, but they tend to be 'off' in quite different ways. Crumb's father was the kind of hyper-repressed figure who for most of us nowadays only exists as a boogeyman character in fiction, but who was much more of a reality in the pre-1970 world. reply gosub100 5 hours agorootparentprevAgree, and the bizarre things that the family members were into have simply been replaced with a new set of things. Arguably the only difference is back then they weren't thrown out on the streets due to high rents reply aardvark179 6 hours agoparentprevIt is an excellent documentary, even if you've had little or no exposure to his work. reply The-Old-Hacker 4 hours agoparentprevhttps://ok.ru/video/1214780017199 reply JKCalhoun 5 hours agoparentprevAdd \"David Lynch: The Art Life\" and make it a double-feature. reply dghf 7 hours agoprevReg Mombassa's stuff is somewhat reminiscent of Crumb's, especially his designs for the surfwear label Mambo: https://www.regmombassa.com/pages/mambo reply throwme0827349 3 hours agoprevThere's a picture of Janis Joplin standing on the sidewalk in SF in which the city looks exactly the same, as though frozen in amber for 50 years. reply dmix 2 hours agoprevThe nice thing about vinyl album covers is there's plenty of space for art. reply dotancohen 3 hours agoprevApproved by the Hell's Angels? reply _sys49152 3 hours agoparent>> The Hell’s Angels used to stage concerts in San Francisco in 1967-68, and Big Brother & the Holding Company played in some of them. You can find posters promoting these shows on the web. reply aithrowawaycomm 3 hours agoprevThis is just pure cowardice: > As for Crumb’s depiction of that scene from the musical [the viciously racist depiction of a black woman], lets not even go there. Suffice it to say that a cover like that will not see the light of day today. Especially if you're not completely avoiding Crumb's views on race: > Asked about how a white guy connects so deeply with black music created in the 1930s, he answered: “I don’t know. There’s something so raw, kind of beauty that speaks to me in a deep and direct way. Personally I barely even know any black people and I can’t relate to lower class black culture very well at all. It’s very alien to me in a certain way, and people I’ve known from that black culture, I’ve never been able to get very close to, because their values are so different. So what is it about their music that speaks so directly? It has some universal appeal because it has had such a big influence on the music of the entire world.” There's a straight line between \"lower class black culture is very alien to me\" and using darky iconography the same year MLK was shot - even in 1968 this was a deliberately racist provocation. There's also a line between Janis Joplin as a white blues singer and her approval of the artwork. And of course there's the straightest of lines between ignoring Crumb's racism while uncritically hagiographizing his connection to black music. You can still tell a sympathetic story about Crumb: he is far from the only young avant garde American artist to use racist rhetoric to elicit cheap thrills and controversy. And unlike, say, Quentin Taratino, Crumb's later work shows a sincere understanding of and repentance for his earlier dreck. But you can't claim to be telling the story of the album cover if you're whitewashing its most controversial aspect. What you're doing is spinning a fairy tale. reply 082349872349872 8 hours agoprevwonder what R Crumb would've thought of Electro Blues (either before, or after, a few tabs from that black on yellow Joplin portrait)? reply ginko 7 hours agoparentHe's alive and (afaik) well. Someone could probably ask him. reply tmountain 3 hours agorootparentHe's alive and living in the south of France. His wife, Aline, died back in 2022. reply aurizon 6 hours agoprevOne of his co-temps, Gilbert Shelton made great comics - the Fabulous Furry Freak Brothers (https://en.wikipedia.org/wiki/The_Fabulous_Furry_Freak_Broth...) were my favorite. He had many characters in the FFFB, Norbert the Nark, Fat Freddy's Cat, Let My Chickens Free, and many others. reply JKCalhoun 5 hours agoparentLoved \"The Fabulous Furry Freak Brothers\" too growing up. My step-dad had several — probably picked up from a head shop back then. reply aurizon 4 hours agorootparentYes, thanks, you are right, it was Oat Willy I was thinking of, https://www.ebay.ca/itm/385506437409, I was within the edit window = corrected. reply waihtis 5 hours agoparentprevI came looking for this (thought the art style was very similar!) reply aurizon 4 hours agorootparentGilbert Shelton is a comic genius.https://www.youtube.com/watch?v=yXaHUMESoM4 His comic were creative and had very little NSFW and were the funniest thing I ever read, while much of the other UG comics were a lot more gross, some extremely so, his were like Scrooge McDuck humor - overlaid with generous marijuana use as well as a sprinkling of other drugs. Norbert the hapless Nark always came to grief in a funny way. Now we sell marijuana in many special state shops, while the feds think it = damnation. It had no social effect on me - I am a non smoker = smoke zero combustion carried drugs, like Nicotine or THC from that day to this - I just enjoyed the vicarious thrashing of the man. As a cat lover = Fat Freddy's cat was my fave... reply Teever 7 hours agoprevI had always know him as a visual artist so I was recently very surprised to learn that not only does Robert Crumb play music but he's actually been in a few different bands. It's a bit too early in the morning for me to find the specific albums that I found enjoyable so I'll provide the links to the bands and perhaps others who know more about the musical performer side of Crumb can expand on this. https://en.m.wikipedia.org/wiki/R._Crumb_%26_His_Cheap_Suit_... https://en.m.wikipedia.org/wiki/Eden_and_John%27s_East_River... reply moralestapia 5 hours agoprev>about an artist who draws an album cover for a band he does not care for, playing a music style he does not listen to, appealing to an audience he does not connect with What? None of that is true. reply boomboomsubban 4 hours agoparentThe rest of the article contains quotes from Crumb backing most of that up. reply moralestapia 4 hours agorootparentDid we read the same article? I'm talking about this one → https://musicaficionado.blog/2020/01/28/cheap-thrills-an-alb... >an album cover for a band he does not care for \"I am going over to meet Janis Joplin tonight… CAN’T WAIT!\" \"Janis asked me to do an album cover. I liked Janis OK and I did her cover.\" >playing a music style he does not listen to \"She wasn’t nationally known yet. I remember going to see her at the Avalon Ballroom and you could tell right away that she had an exceptional voice and she would go far. She started out singing old time blues like Bessie Smith. She was kind of a folknik originally.\" >appealing to an audience he does not connect with \"But within six months Zap comics caught on and Crumb became known for his talent as an underground comics artist.\" \"Janis, James (Gurley, guitar player) and I were all big fans of his work, we loved his cartoons which were appearing in the SF underground newspapers and Zap Comics.\" reply nerdponx 3 hours agorootparentYou're cherry-picking quotes. The whole point of him saying what he liked about Janis was that he didn't like Big Brother & the Holding Company, both as a style/concept and as musicians. The article is also full of quotes from Crumb himself saying how he didn't really like the hippie movement overall, even though he liked certain things about it, and the general impression is that no, he did not really feel connected with many of his own fans and fans of Big Brother. reply pavel_lishin 3 hours agorootparentprevJanis Joplin sang the kind of music he liked, but her current band did not. Keep reading the rest of the article. > an album cover for a band he does not care for > playing a music style he does not listen to While he did not care for her current band and the psychedelic spin they took on blues, he recognized her ability to belt out the good ol’ blues: “Janis had played with earlier bands just playing country blues and it was much better. Way, way better. She’s singing well, not screaming, not playing to the audience that wanted to watch her sweat blood. In the beginning she was just an authentic, genuine Texas country-girl shouter.” Getz adds: “The next weekend Crumb came to our show at The Carousel Ballroom, sat on the floor in our backstage dressing room and observed. He really wasn’t into our music but it didn’t matter. Getz is understandably mild in his description of Crumb’s opinion of Big Brother and the Holding Company. Here is Crumb’s version, unadulterated: “She was a swell gal and a very talented singer. Ever heard any of this pre-Big Brother stuff she recorded? She was great. Then she got together with those idiots. The main problem with Big Brother was they were amateur musicians trying to play psychedelic rock and be heavy and you listen to it now and it’s bad… just embarrassing.” > appealing to an audience he does not connect with But Crumb came from another era, mentally, and to him this music was commercialism personified compared to the roots music from the 1920s and 1930s that moved him: “I had no patience for any of that psychedelic pop music or crap that came in the 60s: The Grateful Dead, Jim Morrison, The Doors, The Beatles, Bob Dylan. I had little or no interest in any of that. I thought I had found some music that was much more real, that came from the heart of people’s culture but had been wiped out by mass media and commercialism.” He liked some aspects of the Hippie movement, what he termed as seeing through the hype of consumer culture. He valued how they strived to live simply and saw the ecology movement being sparked by that. But he quickly became disillusioned by the movement: “Since it was mostly children of the middle class, it was immediately something for them to be smug about. ’Oh, I have seen the light and you haven’t. I’m beautiful, I’m spiritual. I lost my ego and you haven’t.’ It became where in any social gathering everybody sat around trying to out-cool each other.” But as he admits, he never felt comfortable in that environment anyway, even when it was at its peak of innocence: “I couldn’t kick off my shows and go dance in the park. I didn’t have it in me.” reply moralestapia 2 hours agorootparentAll those things don't come from Crumb, they are hallucinations by the article's author. If you stick strictly to what Crumb said about it, the story is quite different. Also, https://www.janisjoplin.net/life/friends/robert-crumb/, mentions none of that. But yeah, some random neckbeard's blog is more authoritative than Janis' own site, for sure! (Also, if you knew a bit about Crumb you'd know it's the type of guy that just wouldn't do stuff he was not interested in.) reply pavel_lishin 10 minutes agorootparentEverything I've quoted contains quotes either attributed to Crumb, or to the drummer of Janis Joplin's band. Unless you're suggesting that the author literally made those quotes up? > (Also, if you knew a bit about Crumb you'd know it's the type of guy that just wouldn't do stuff he was not interested in.) He sounds like exactly the kind of guy who'd do a favor for a girl he wanted to fuck, despite not liking the band she was currently in. reply cma 1 hour agorootparentprev> But yeah, some random neckbeard's blog is more authoritative than Janis' own site, for sure! That site said it was made by super fans in 1998? Doesn't seem like go to source for critical quotes (not that an official site would be either). Here's a source for the quote about him not liking her band from 2013, so no, it doesn't seem to have been hallucinated by the 2020 author: https://daily.redbullmusicacademy.com/2013/12/robert-crumb-i... reply pavlov 8 hours agoprev [–] The album cover is from 1968. This article is from 2020. Just to clarify the ambiguous date added to the title on HN. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Robert Crumb, an artist known for underground comics, designed the iconic album cover for Janis Joplin's \"Cheap Thrills,\" despite not being a fan of the band or psychedelic music.",
      "Crumb's comic strip design, not initially the first choice, gained legendary status and brought him fame, although he remained critical of the hippie movement.",
      "Despite his success in album art, Crumb preferred the music of the 1920s and 1930s and later played in the Cheap Suit Serenaders Band without pursuing a full music career."
    ],
    "commentSummary": [
      "Robert Crumb, an influential artist known for his iconic album cover art, discussed his extensive music collection, highlighting a rare early jazz record by a French band.",
      "Crumb, residing in France since the 1990s, expressed a preference for older blues and jazz over modern music, reflecting his mixed feelings about contemporary culture.",
      "His controversial art, often sparking debate, mirrors his complex views on race and society, yet remains influential in capturing the essence of the 1960s counterculture."
    ],
    "points": 139,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1730712919
  },
  {
    "id": 42042025,
    "title": "Alonzo Church: Architect of computer intelligence",
    "originLink": "https://onepercentrule.substack.com/p/alonzo-church-the-forgotten-architect",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"onepercentrule.substack.com\",cType: 'non-interactive',cRay: '8dd6f7b18de81125',cH: 'lT.qs.debU7aFCgPpJFaeoo9yLOt2rQ4.gjRosvvNWg-1730748091-1.2.1.1-o9wo_DLcYqe5JDB8G2ClW5.mXslgsjJM7LNRJqCKHMeZg_0cUfKcFaGulK0o2Ylm',cUPMDTk: \"\\/p\\/alonzo-church-the-forgotten-architect?__cf_chl_tk=IsBGxS8.YsFp6F2wz4UIqMOA0oqWGEsRX4bvDISUIpI-1730748091-1.0.1.1-FiW5VXVKTY5XgBDUKwl7O5FwrH.iqy.tKLcyVpIlNE4\",cFPWv: 'b',cITimeS: '1730748091',cTTimeMs: '1000',cMTimeMs: '120000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/alonzo-church-the-forgotten-architect?__cf_chl_f_tk=IsBGxS8.YsFp6F2wz4UIqMOA0oqWGEsRX4bvDISUIpI-1730748091-1.0.1.1-FiW5VXVKTY5XgBDUKwl7O5FwrH.iqy.tKLcyVpIlNE4\",md: \"f9NbJwl00BhVln9E7pfj0ouOPJbtQ4DQVFPATGiOJ.Q-1730748091-1.2.1.1-F88tGYRD9S1Qind8VsbyJlzzgyGVGYi7PSqL6QZVe4qBAgmDZd4PEj0lNaGeEzTGZZ4iljPQs8F0OEKdgcV.lHvC.4YqQRKPZiOHHGfw7vQf5XRQBBpLwp396hxhYsf_F2.LgbHS0YcnJTfURHR4TVGdkNxHYFnf0n3qzq5iW2KQ9BrSFtjUEQ7vfdxegPF6UPtk5BFoANvCLMRnfj110Z_trzAjaF2qQtTPd5m1d0Pe89CLw6IEymQERcmiirdMqsuA7IzgUqSWTf0QHxc1QaDuKqhg3lgwo7r6Z.y9JsKyEWKcFfRa3bQi4r.U4Xn_uu7wswToU_nq1Fh.dBXOS9tcJhcPMclcD1fOFirity41iBmvtIFMT7LyvNfLrjvxjKUEOGFsERBhvSQ2ovJeq2y3yZesQLgQKFMj92lttwlA76FvCriD4uuJH_RGNvV4ve0c5.x.ZYy2cbMT1ZZQ0BQ4fZhKPmXzZSq8eomf_BMW79xRzu6eoaJVqQgGuWGVFUDIEoHknIkXZp1DkHSSrdyzOaiOs2o06dYHGqVV9lpCxo4BZWFEWEza3TlSavvBOdmxtXYLU6VTZWQLwuagGkTLQixL6NCfCOy9ukWP2tIbtglZjA4pMVScpOfwKt_KZ0D6fEzBPeHij1xIudTfCew9WPDf7cc8JaMOdINXKSn0mjHVMNmVd9HkVv_1hNsfaxsdgHlFAD6j9GAgT9FmnUjrotFltKLTgReLxmWdLZn_FU6fXb3bKwM38GaR_6PggWK.V6v7ddCT2H4rqYWNZaa7I_UUkZ1DN9gUuQBLUUvEAYk08FcwiudHGHcYi3OoZVmubzIB4FxipeH9Mn1hOuyJebeNiac0VctaM3iZRi6NMI96PyyjdkFjzBYAMzRcnEm_o9j0rpVvZKEQMLrtSutH7geNJo39n9SSXlxpWN6PnaTCE_TYOcIvfB6C6uOyQ7.CC39arQ8kkynMXmpM0XIeKwSKOpm9NJvg4wJYEQzsDKfDiyUJ4Sf1lKnrgU5vY.cPHaxxloOBkc_fQRKshv9maOIKPL935DRWpp6kSpvUpRZyMN1GijuAiAhpD.sAqJJ_s2VtBdAjs_NF6iwAjaErbXi7EgxqKF7bBFCrNxAYAOildIw2NnaXzf0dHxE7KlvmHRWOB8_xkeH0zZhPv_CuP0_ieJUVuIR_Hc0OorvSo8tVxIl8YlFO.4LrLHOMyNXQG_8r3pO.2Kwmhs09qFEp8Tkza.0D3L0gOHDkxpRiZ2T9qhV.IcH5AzLj_PdUpo3jHTa8BRS58W38rDW8Ca0_tGTU9U4Yd3Fy1X_BqyGSb9MA11_dr3VlSZ5GZNdHYd7xWyEHUy76Z0oQRGgiAF.2NFH1Ti._yRpYFaFWqEqZaXuqDTU.Pu_wpAGjQH5ULIAx8lg2WdNyOyiDHKXQdDWmVaDhpZcsvXgMkLCNPf7V4eLmFiT50P5hZ5I80gAfQRy5tyPPw76RtVF4zjA5jX1JfjbxiR1ZUedC2VD8yv8rcTNPhKuQoZp3ZO6AAU4PbCjs5r1V4EdNX14N.b6TSPjt_9_0jtxowCUJUhm.33BcrdwSsSOE7HIDLK1manNBYCl6rL_Ghtsq5jC8rcvPZC_5.SWknSX.v4FVJWUpN7YZ9HBLVxJNRCUfl5GUYT6vTPvZS7d3_VZ6Rerlus7iO7WFVsXDYkbFUdjh1tAINiTLwPO2kxfgZ9JmwkhTMdjyGFLLGpQeoPAc6yPDAK_PJ9gVnDxzcCx2WmxGleR90ckmBETxtd.yYxhjrAiQRpkbrXkpM09wpzOZYlWVvUGSePaoH39TqQpqYLEBBAXAoWu5XTB5dUs0unDBtB1J9bs93I_5mof_AiQ3qjylFwQxcPNwQkArZunSZXf1wBceq1RUqbAvrUU8KM5Wygko9pUO\",mdrd: \"RKB9W9FlU7oTlXk18zRaGb.HKWbPeTs920U.UY84c3w-1730748091-1.2.1.1-PcGUXGFN4To0p4MGSqRsS7vG4oRh9CvIix.Lgi_putkhzwTJIcbVnjKM4lbWHzs8fIGm9YUzyvr_IBVhDxqBjehufMoWOj19RPjInPBZCcq.ORet4TVU8EdfeyPmf5m0hI9NiSTipK1A0y6sMMajzCwYTJJdUf4tiiH2iijIAm6P7mVrDn_QEJIjKL1cmmb4Zayft3OyM4qIXl.GIfImX_JhVP6ayZ0RK69Vg3lA4cDL57gqvP9z5a5wXyt3r0k1kZFna6j1JBNH4SZLhHVQLuKGQLEO.Iy4xYn2PE9zlrpe0vEWTHbSgow5rL4Fj7ZLYyRwUOi.gMsSfmVH8T13.N4FKVO6juh_BQIXi7OCtXyklLcS0UjvgDG5e2.2nG7ePTN2o0xRCNhFq2rq8eNxjKLeyVPCVH7F150Coo90nPRLjCWJIA9NUjNIietCJcBDdZ5b3P5teqdnKnDyV9mcWtxMczhfbYowGBVMtpSAh5akl8Q0yJDlFEy02NLaA4OHLV.Jgqb5BMaT0s2ZQQkyKZ8RZZKIDM9hF.Fgqh09Vg_j06lLO1JNEZOa2yaaHYq8Eh9nWF2xXi94TNqwLnxp7OAL.06ERzpZuzHpHhEt6tw9U9NPu50s6zPOVXBVqJ.DJoCvqGdxatpTqzc_8Md_KPTrRpMJJLyTvhFu22mmY8gjf3o4XpoDMRDTozKuL75_A_7NJi4201JgwEm5mWUjQzUwbpd3YVa4csQqpICqhxLT2dacFMM7ItylV4zw8M7NiXxdQiN_yWE.fHdvJG1L8mguWqTNVQiSyA..5g4ifXr7EltnxGd1x7OXkix1RrNB3HR81idBXmnJN6cfCYrvtoU.C0eVdPj5Y7s4TqvyDJRkev11Wmx7r_r87eZ1Nb.BXkp_w9ZE68wTCKAxIdUlwD6MdiTWV26QKxflegbCWpIhILFVc2yJlLP91DOO4EZof_U2mbH9Ait2jrbbmZu4_7Y8b0XKavAEL1cwztkWxT1sdDujFInRMCu_kUVM8v_l04.CVtGV2ACDVdAH_mOB8M2uo0IebRGeSUyUWu4epxsisZbJSt7H5d3.cpOsqwwV6QRD0s83zvABQu7j2ceO0uhXqMnMbCMimTy7HHWiFkUC63rE0tsMlbMS8.8EkS_cNVaT9bSB.tmk_azloshWXJMYNfCakD20xveCgRJRrUU.1jvHPVg8PmUoYj_DLme5FTgC4Ngyz76oyLA8wMdbA0307VHtlZTLuQhQxOZuC43yMc1ei3WYpxHzShqbhX6_kYRsdSMi9.ZSsMMVSafsz8KV3RCezTRF7sTwOfNQb8jjTav7Qi6Cx7_jD.cEM.1pU6ParvcLP8Q5gVc6JUoNQnfVi0AKIQXaLmcT4jyPBpccm1awz.LGm5v_psxO86DbuQc8zsGtnLNODTndrBI44zC7M622_hg7zwAKA5diBcZp20JMfnhU4pHUT36Rt1YZMywF8muZJrQMhb9hh8o017Z.b9cGJMFq.ipRyJac4rVdVEpUFELXnbzGKVe2GU3itjso.XyIUMBKj9ct1A.I9ojnl8A1cwTRmKHPSvdyIm9_XwsS348nDUwY5zTaMIFM.Zpw6r8G.HCzJmnLvz7Ne_4UEty4NqDyo.pEGbuVkcaNXLVck0MmodZkDh2S9Hd5u1de6kNfb.X1XSgNf21zmEViwBEVi_6NrfBeBfpr3OCLHJ3fja4eCPFbkhfffSiuKR4nz7TJ6.p1hKBj9RLvDOLhzdtu.aq.4bK.yCgd0AYes0SNmMnzX7099wxSSAx_525To_bdBV9Hbbt0STeHh9wlocAW33WSnnn9tFtBcQ7sPYOm5m09MBEKjLkGmJUmpZWIACUG1_keCwfYobLL8kqEojUOTTGLJxhf37V8vMxjaGw0cSy0NXmMenaD.OZcUkJfZiek2727zkCE0wRDryuuJWN5x.fPFcchfKT3imim75xd6y0aaDVg9e5IY_EI45_v_MNOoJG_EBnQfTTrLEwX24gkEIxAegbuKa1qYC.hHcdZdWFLs8rGF1CARYjgU9T_5FfUQ2DCNHXTPsJQAfERCad0aTa0ggGncv8SN6dbNOCbCQLxeYky4RCYGo6AzVUi2PI_PiLauSojycwjOvkRy0BOmJKOXX5F4sJBDQLenql2LEULN6n1_R08.rS7clwx2RD1amFbtSkyYL65jEjJ1ueyaOx.PJiRSM._p1I6MxMOPB3W7bnEqI7AUqQ_bUw3XkZ.8ncahYWRlMJ5FlaVf6tD17cjOz4K1FoPuDwNTlj2eyq32zIeKMBCirU9geYrVp8g82hO_cXtpM7FL6I_0GGINkvGm3kWNhRmxV7ajEF8pKa6ZdXc_vv380ZC2mUNqdf1WJDR1i9.FPMlGib0BMcrtYunZ5nl1HMLDvDcKGgu5s9yNU.QO.7v9YUytfI8iSwwkQp0WrPyUMa3Sg\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8dd6f7b18de81125';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/alonzo-church-the-forgotten-architect?__cf_chl_rt_tk=IsBGxS8.YsFp6F2wz4UIqMOA0oqWGEsRX4bvDISUIpI-1730748091-1.0.1.1-FiW5VXVKTY5XgBDUKwl7O5FwrH.iqy.tKLcyVpIlNE4\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42042025",
    "commentBody": "Alonzo Church: Architect of computer intelligence (onepercentrule.substack.com)141 points by drcwpl 4 hours agohidepastfavorite30 comments sourcepluck 2 hours agoA historical tidbit which I loved in Paradigms of Artificial Intelligence Programming (available in PDF and EPUB here - https://github.com/norvig/paip-lisp): > The name lambda comes from the mathematician Alonzo Church's notation for functions (Church 1941). Lisp usually prefers expressive names over terse Greek letters, but lambda is an exception. A better name would be make-function. Lambda derives from the notation in Russell and Whitehead's Principia Mathematica, which used a caret over bound variables: x̂(x + x). Church wanted a one-dimensional string, so he moved the caret in front: ^x(x + x). The caret looked funny with nothing below it, so Church switched to the closest thing, an uppercase lambda, Λx(x + x) . The Λ was easily confused with other symbols, so eventually the lowercase lambda was substituted: λx(x + x). John McCarthy was a student of Church's at Princeton, so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There were no Greek letters on the keypunches of that era, so McCarthy used (lambda (x) (+ x x)), and it has survived to this day. So, yes, on the topic of this post - Church pops up in loads of Lisp retrospectives. Maybe he's \"forgotten\" by people with very little engagement in the history of computing. reply agumonkey 44 minutes agoparentBut wait, who ever first coined the term 'lambda calculus' ? was it before or after McCarthy started lisp ? reply seanhunter 1 minute agorootparentWell before. The original paper[1] introducing the lambda calculus was in the 1930s, but it wasn't called \"lambda calculus\" until a bit later. [1] https://raw.githubusercontent.com/emintham/Papers/master/Chu... reply drcwpl 2 hours agoparentprevGreat tidbit, (thanks for the Paradigms share) - in the footnote I mention about CS folks awareness. reply gpderetta 2 hours agoprev\"Church’s lambda calculus and the Turing machine are equally powerful but differ in the fact that Turing machines use mutable state. To this day, there is a rift between functional and imperative programming languages, because of the separation of Church and state.\" [I have known the above quote forever, but I can't find an original source] edit: might be from Guy Steele: \"And some people prefer not to commingle the functional, lambda-calculus part of a language with the parts that do side effects. It seems they believe in the separation of Church and state\" reply drcwpl 2 hours agoparentThat is such a great quote - classic programming humor, but no idea of the original reply dang 45 minutes agoprevIf you want to read something incredible about Church, read Rota's reminiscence. It's the first section of https://www34.homepage.villanova.edu/robert.jantzen/princeto.... Related: Alonzo Church, 92, Theorist of the Limits of Mathematics(1995) - https://news.ycombinator.com/item?id=12240815 - Aug 2016 (1 comment) Gian-Carlo Rota on Alonzo Church (2008) - https://news.ycombinator.com/item?id=9073466 - Feb 2015 (2 comments) reply drcwpl 34 minutes agoparentThat is brilliant, thank you - I added the Rota one as an addendum under the further reading at the end. reply tromp 2 hours agoprevThe Alonzo programming language named after him [1] has mostly been forgotten. [1] https://dl.acm.org/doi/pdf/10.1145/68127.68139 reply cubefox 2 hours agoprevEspecially his philosophy of logic and sense/reference (a continuation of the work of Frege and Russell) is mostly forgotten. He published many papers on this topic, yet they aren't discussed e.g. in Wikipedia. At least the SEP entry is better: https://plato.stanford.edu/entries/church/ Though I heard that it also neglects some major parts of his work. I assume it was too philosophical for mathematicians and too technical for philosophers. reply dang 50 minutes agoprev [20 more] [stub for offtopicness] Side remark: \"Please don't take the bait\" is a good analogue to \"please don't feed the trolls\". We've taken the bait out of the title now, but when a thread has already filled up with comments reacting to it, rather than anything interesting, that's bad for HN threads. reply seanhunter 3 hours agoparent\"Forgotten\" in the sense that everyone who knows anything about CS knows who he is because of the Church-Turing hypothesis, Church numerals, lambda calculus etc, and anyone who reads \"On Computable Numbers\" (only the most famous paper in all of computer science) knows that Turing actually quotes and credits Church and his work in that paper. Here's a link to \"On Computable Numbers\" for easy reference for anyone who wants to read it/read it again. It's a cracker https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf reply abstractbeliefs 2 hours agorootparentForgotten not in the sense of lost knowledge, but more that the individual is not known proportionally to the importance of his work, or perhaps consistently when compared to his peers. While specialists in his field know his work and his name (but not even everyone in software does), the public do not. While your parents and friends see the dramatised exploits of Turing in films like The Imitation Game, or his face on the currency, the same is not said for Church. Every field has it's public heroes, usually related to the stature of their work - Fleming and Jenner, Marconi, Ford, Bell. Turing. Anyone will at least recognise these names, but not so for Church. reply gilleain 2 hours agorootparentOk, and if I asked a random member of the public for the name of a mathematician (excepting Turing, for clarity) what name do you think they would come up with? Pythagoras? Euler? Erdős? I think the reality is that only a very small number of scientists, mathematicians, and similar are household names. reply ggm 2 hours agorootparentPeople's conception of Turing is massively skewed by the ending. His persona is now defined by his sexuality and treatment more than his contributions to maths and computer science. Andrew Hodges book is great. I had the fortune to go to his author tour the year it came out, he was doing the compsci departments of the UK and it was a really nice seminar. Benedic Cumbersome was a good actor, but it's important to remember Michelangelo actually didn't look like Kirk Douglas. reply geodel 1 hour agorootparentI like that you called Benedict 'Cumbersome'. He is indeed cumbersome in so many roles. reply ggm 1 hour agorootparentI read a review in the Guardian [1] which used a series of malapropisms for his name, and riffed on the concept. [1] https://www.theguardian.com/tv-and-radio/article/2024/may/29... reply gpderetta 2 hours agorootparentprevAlso his contribution to the war might be one of the biggest reason he is well known. reply seanhunter 2 hours agorootparentprevRight - For every Newton, who (rightly) gets credit for his immense contributions, there are people like Euler, who are relatively unknown outside the field in spite of significant contributions[1]. [1] Massive in the case of Euler obviously. reply drcwpl 2 hours agorootparentAgreed - what I tried to highlight through a series about people that have contributed significantly, but are not so well known outside of the fields they impacted, there is always cooperation to a large extent and others involved - rarely a lone individual as the Turing movie and much of the press in the UK likes to portray. And many people, who should be known, get lost in the complexity of history. It's worth bringing the attention of this to a wider audience - people are genuinely inquisitive. Plus as another example, on an intro course to AI 45 out of 52 bachelor students had never heard of Church! reply mitthrowaway2 2 hours agorootparentprevIsn't that just because they haven't made a blockbuster feature film about him yet? reply PittleyDunkin 2 hours agorootparentprevOh so maybe 0.01% of the population will even recognize his name reply conductr 2 hours agorootparentAs evidence, I've been programming for 25 years now but never actually studied CS. Yet throughout that duration I feel like I see/read Turing's name every week somewhere. I've never heard of Church until now. reply drcwpl 2 hours agorootparentGreat point - thanks for that. reply kayo_20211030 2 hours agorootparentprevDammit! Did I forget to forget him? Seems pretty memorable to me, and I'm just a regular dev. reply drcwpl 1 hour agorootparentThe main theme of the essay is his work which helped the foundation of AI, In their book Artificial Intelligence A Modern Approach (Third Edition), Russell and Norvig give limited (cursory) commentary about A. Church, but Turing gets the foundational credites, I think that is an oversight - and this book has sold in the hundreds of thousands and is used on AI courses extensively! reply cubefox 1 hour agorootparentprevIt's ironic that you reference a paper by Turing here but not one by Church himself. reply drcwpl 52 minutes agorootparentI also add the Turing one at the end of the post also because of the discussions at the beginning - especially \"Church had certainly obtained the result before Turing\" reply nesarkvechnep 3 hours agoparentprev [2 more] Forgotten by whom? Certainly not by me. reply drcwpl 2 hours agorootparent [–] The point is about a wider audience - I believe it is good to highlight people that have contributed significantly, yet overlooked by society at large - agreed about the CS sector, but then again on my intro to AI course less than 7% of bachelor students have heard of him in this context! reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Alonzo Church made significant contributions to computer science, notably the lambda calculus, which influenced the Lisp programming language and is foundational to artificial intelligence (AI).- Despite his impact, Church is less recognized than peers like Alan Turing, partly due to limited popular media representation.- Church's lambda notation, derived from Principia Mathematica, was adopted by John McCarthy in the development of Lisp, underscoring his influence on computing history."
    ],
    "points": 133,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1730731870
  },
  {
    "id": 42038139,
    "title": "Please just stop saying \"just\" (2019)",
    "originLink": "https://sgringwe.com/2019/10/10/Please-just-stop-saying-just.html",
    "originBody": "Please just stop saying \"just\" Oct 10, 2019 Do you work in Software Engineering, and have you seen messages or sentences like these before? “Can’t we just set up a redirect to this other domain?” “Why don’t we just add some caching to speed that page up?” “I read their documentation, and we just need to inject some javascript, we should be all set!” Me too, and it drives me a little crazy. Not because anyone is being rude, or because anything they are saying is necessarily wrong. Nobody is being intentionally malice, here. It’s that (in my opinion) the word “just” added as a qualifier to an idea carries with it a whole bunch of implied baggage. The Baggage Implies Simplicity First and foremost, the word “just” implies that an idea is simple. “Oh, we can just do this!”. If there is one thing I’ve learned with Software Engineering, it’s that Computers are Hard and implementation details matter, especially when it comes to complexity. Very rarely can the complexity of an engineering solution be outlined in a single sentence. There is almost always more to it. Let’s take one of the above examples of “just” injecting javascript into the page. Do we trust this javascript to run on our page? What is the security posture of the javascript author? What dependencies does the script have, and are they trusted and up-to-date? What data is being sent from their javascript? Do we need to update our privacy policy? How will the javascript be minified? Does it work with our other libraris, such as React or Turbolinks? Do we need to load this Javascript from a third party? What if that server goes down? Can we trust the integrity of their server? Do we need to update our Content Security Policy for this script? What sort of performance impact will this have on our page load performance? Does the script need to run at any a particular point in the page load process? Does the styling of the DOM elements it produces match our brand? Is that important? What sort of impact will this have on the accessibility of our website? Who is going to maintain this javascript, and update it when it needs to be? How will we monitor if this javascript snippet is still working? If the business decides to stop using it, who will tell us and how will we know? Reinforces Imposter Syndrome Many engineers report having Imposter Syndrome, with some data even suggesting over half of engineers at most major Silicon Valley companies. Let’s paint the picture of a very common, every-day scenario… Imagine being an engineer with Imposter Syndrome, and you are working on solving a problem all day. You find yourself stuck on a few tricky details on the solutions you are considering, and so you ask for help from a Senior Engineer on your team. You sit down, start to talk through it, and your coworker says… “what if you just do this?” I ask you, reader: Would you feel good or happy to hear that? If you disagreed, would you voice that disagreement with such a confident and simple answer from a Senior Engineer? If you don’t understand, do you ask “what do you mean?” My guess is probably not. How could you disagree with such a simple answer?! Or not understand it?! Reduces Ideation Because of the implications the word “just” comes with, I believe that engineers are less likely to ideate and brainstorm in that environment. In the face of an idea that says to “just do this”, I believe engineers are less confident in voicing disagreement, and are less likely to ask “what do you mean?” to truly understand the problem and the solution. A team where engineers aren’t asking for clarification, don’t understand their solutions, and aren’t voicing alternative approaches is not a team that I hope to be on. That team is missing out on so much, including great ideas. Solution My solution is simple: stop qualifying your statements with the word “just”. Of course, I’ll acknowledge right away that such as task is not easy. And I continue to use the word by mistake all the time! But I try hard not to, and I believe I am better for it. When I catch myself typing a sentence that uses the word “just”, I pause and rephrase my sentence to avoid using it. I find that doing so helps for me to: get better response and ideation back from others clarify my thinking with strong examples and evidence orient the discussion towards a more generative mindset produce a healthier debate with more learning and sharing from everyone So please… just stop saying “just”!",
    "commentLink": "https://news.ycombinator.com/item?id=42038139",
    "commentBody": "[flagged] Please just stop saying \"just\" (2019) (sgringwe.com)118 points by mooreds 15 hours agohidepastfavorite97 comments DavidPiper 14 hours agoMy favourite related blog: https://squareallworthy.tumblr.com/post/163790039847/everyon... > If your solution to some problem relies on “If everyone would just...” then you do not have a solution. Everyone is not going to just. At no time in the history of the universe has everyone just, and they’re not going to start now. reply hinkley 11 hours agoparentThe four words every software developer dreads: \"Why can't you just...\" reply anileated 14 hours agoparentprevIt is possible to get everyone to just, it’s just that it only works with smaller sets of everyone. Everyone everyone would certainly never going to just, but you could just pick a smaller everyone (like everyone in this room or something). reply saulpw 13 hours agorootparentIt's difficult for me by myself to just, and if the stars align I might be able to get a second person to just, but any group of N>2 it is impossible. reply anileated 11 hours agorootparent> any group of N>2 it is impossible Not true. reply chii 14 hours agorootparentprevso as long as it's not everyone, it just works. reply Der_Einzige 13 hours agoparentprevAuthoritarians actually do implement \"if everyone would just\". Don't pretend like they don't. reply barryrandall 8 minutes agorootparentThey claim to. Their advisors, lieutenants, and propagandists report great success. Their people just know better than to talk about it. reply xboxnolifes 11 hours agorootparentprevExcept they don't. They aren't sitting up in their ivory towers thinking: \"if everyone just did X, then everything would be better\". No, they are executing plans to get to that outcome. They are recruiting people, coercing people, killing people, manipulating people, seizing power, etc. All working toward their goal. reply baxtr 13 hours agorootparentprevIf the world could just get rid of authoritarians… reply pwdisswordfishz 13 hours agorootparentprevExcept for the \"just\" part. reply mistermann 14 hours agoparentprevThe world of politics needs some of this sober thinking. That said, Lopatin below also makes a valid counterpoint. reply komali2 13 hours agoparentprevThis reminds me of an anarchist article I recently read against voting. https://theanarchistlibrary.org/library/william-gillis-the-c... > The argument for voting is very Kantian: “act so that if everyone acted so…” and “if no literally one voted then voting would matter again” but if literally no one voted the government wouldn’t maintain legitimacy. And in any case this is not an actual causality. When you vote you don’t magically cause everyone else like you to vote, you are a distinct agent with distinct internal thoughts. Your individual actions have only very weak externalities beyond the direct consequences of your choice/vote. > Unfortunately the delusional thinking behind voting crops up in leftist inclinations in general. They want to build giant organizations, giant armies, with individuals all acting in low return-on-investment ways, in hopes of aggregate impact. They don’t search for opportunities of high impact individual direct action. I was getting into an argument with some people who were yelling at me for voting third party in the USA federal election. Because I'm a Texas voter it's my fault the state won't turn blue. \"If all Texas non voters voted, and if all third party voters voted democrat, the state would turn blue.\" And if only people would just stop committing crime, if only people would just not steal from their employees, if only people would just Do The Right Thing... reply pixelatedindex 12 hours agorootparentThanks for the link. As someone who feels disenfranchised with a countercultural thread running through, a lot of it resonated with me. I do tend to vote third party as well (maybe not this election given the state of the GOP) — after all, it’s your vote, why give it to someone you don’t agree with? Though I will say that if you didn’t vote, then you don’t get to complain about the system because after all by not voting you’re rejecting a core tenet of the system. I gotta read more things out of this library, this is fun to noodle on. reply SllX 12 hours agorootparent> Though I will say that if you didn’t vote, then you don’t get to complain about the system because after all by not voting you’re rejecting a core tenet of the system. I gotta read more things out of this library, this is fun to noodle on. As a previous water-carrier for this form of “if you don’t vote you don’t get to complain” propaganda, it’s crap. If there isn’t one single person you want to vote for on the ballot, you’re fully entitled to not vote and complain loudly about it. Making the choice to not exercise the one right does not preclude anyone’s use of the other. reply tonyedgecombe 10 hours agorootparentThe thing to do is spoil your ballot. Otherwise people will think you are being lazy (and they will probably be right in most cases). reply SllX 10 hours agorootparentThe thing to do is not blanket assign connotations to other people’s choice in how and when they execute their rights. reply pixelatedindex 3 hours agorootparentprevOf course, you can complain loudly about who’s on the ballot. But you don’t get to complain about the outcome of the election because you decided to opt out. reply SllX 3 hours agorootparentNah. You can opt out and complain about the outcome too. That’s my point. Not exercising the one does not preclude the other, despite what wannabe gatekeepers may declare otherwise. reply komali2 3 hours agorootparentprev> But you don’t get to complain about the outcome of the election because you decided to opt out. Why not? reply ddingus 10 hours agorootparentprevComment below not intended as direct rebuttal to parent comment. It is just a relevant riff on the tired if you don't vote, don't complain BS. Soap box mode = 1 Yes you do get to complain same as anyone does whether you or anyone voted or not. Never let anyone tell you otherwise. In the US, voting is not mandatory. Casting voting as a condition of redressing ones grievances with government is actually just a psyops version of manufactured consent. If you are inclined to consent, and you feel a vote is worth casting, by all means vote! Maybe you think the whole thing lacks legitimacy? And you want to vote indie or third party or maybe even participate in ratfucking by voting for the very worst candidate a given party could get stuck with? By all means vote. Otherwise you are not required to vote and not voting is just fine. You remain a citizen. The Constitution still applies and all that stuff we know and expect is exactly the same whether we vote or not. Encouraging others to vote for many other reasons is fine too. Don't get me wrong there. I am very specifically calling out the idea of ones participation in this US society being predicated on a vote. That is just not true, and I really dislike advocacy rooted in falsehoods like this kind of advocacy always is. Soap box mode = 0 Maybe I will take a look at this library myself! reply grahamj 5 hours agorootparentprevDeciding not to murder and not to steal have measurable real-world effects. Voting in a way that results in no change does not. Voting on principle only works when you have proportional representation. You should vote in a way that moves the needle the way you want it to move. reply esperent 13 hours agoparentprevI kind of disagree with that. Everyone has \"just started doing\" a ton of things in history. For example: * Brushing their teeth, about a hundred years ago * Regularly washing their hands, maybe 150 years? Less? Etc. Of course you can find people who still don't/do all of these and any other examples you come up with. But the point is that society as a whole has changed their view of these things, and what was abnormal is now normal. Which I'm pretty is what the \"if people would just\" folk really mean. Nobody is dumb enough to expect 100% of people to change 100% of the time, and it's unfair to their intelligence to assume that's what they mean. Edit: removed one example that was too emotional and distracted from the point. reply reqqqles 11 hours agorootparentI don't do either of those things. * I don't think there's actually any scientific studies proving brushing works, but the toothbrush definitely sheds microplastics into your body. Same with flossing. * I don't see the need to completely obliterate all bacteria living on the surface of a part my body just because I touched my penis for a minute. * I don't use shampoo either, it was brought from India just 200 years ago. Anti-dandruff shampoo isn't real and we don't even know exactly what causes it. Outwardly I'm a pretty normal person. reply duckmysick 1 hour agorootparentHere's one that looked at caries in children who brushed compared to those who didn't brush: https://pubmed.ncbi.nlm.nih.gov/20116887/ > but the toothbrush definitely sheds microplastics into your body You can use miswak, which is a type of twig. https://en.wikipedia.org/wiki/Miswak reply grahamj 4 hours agorootparentprev> I don't see the need to completely obliterate all bacteria living on the surface of a part my body just because I touched my penis for a minute. It's not because you touched your penis, it's because you're going to touch things in the world that other people will also touch and you respect other people's preference not to touch your penis bacteria because you're not a sociopath. Right? reply bongodongobob 13 hours agorootparentprevSome people just don't do that. reply alphazard 14 hours agoprevIf someone says \"just\", it means they believe the presented solution is less complicated than some existing proposal. That conversation should be a significant part of software development, and usually the answer is \"no we can't just do that, because it wouldn't do what we are trying to do\", or \"yes, but it's not actually as simple as you seem to believe\". Sometimes the answer is \"yes, we can just do that\" and everyone should be glad when that is the case. If you can't handle normal engineering criticism, then you are an imposter. Real engineers generate alternatives, and evaluate alternatives proposed to them. reply Quothling 12 hours agoparentI really think you should consider what is implied by the word \"just\". When you say \"no we can't just do that\" it implies that you think someone will have missed the obvious. This may fall under \"normal engineering criticism\" to you, but I can assure you that some people will not see it as such and they won't like it. Which makes it a poor fit for good team communication. It will probably also make you disliked. It's obviously not always an negative word on its own. In your \"yes, we can just do that\" example it's fine. It's, however, also unnecessary as you could say: \"yes, we can do that\" and retain the full meaning. > If you can't handle normal engineering criticism, then you are an imposter. It's not normal engineering criticism though. \"Just\" is (in)famously known as a term that you use when you're overconfident while missing the whole picture. In many universities around here they will teach you about the dangers of it. Because it's really not good engineering to not do your analytics before suggesting solutions. I think most of us are guilty of using it. In my current team we laugh about it. We have a sort of swear jaw mentality when someone uses the term unironically, usually called out by the person who did it themselves. It's now a term we mostly use it as an internal joke, however, and people are never going to miss an opportunity to call the most complex challenges \"just\" in the most hilarious way they can. reply mistermann 14 hours agoparentprevAn engineering degree does not render Humans to be perfectly rational, though it can make it seem that way. reply midtake 14 hours agoprev> the word “just” implies that an idea is simple. What's wrong with this? That seems like proper usage to me. What the author has an issue with seems to be snobby, snarky, or sarcastic usage of the word \"just.\" Sometimes, the best answer is in fact \"just add a DNS record.\" The author should just write that instead of this long blog-post that gives the impression of someone easily offended. reply Uehreka 14 hours agoparentNo, the problem is oblivious use of the word “just”. As in “just add a DNS record”, when said to an audience that has never setup a website. The idea here is that we (people who write instructions) are so bad at knowing our audience, and so bad at knowing if we’re one of the ones who are bad at knowing our audience, that it’s safer to just avoid using just entirely. reply interestica 14 hours agoparentprev> Sometimes, the best answer is in fact \"just add a DNS record.\" Why not (just) answer with \"Add a DNS record.\" ? reply rocqua 12 hours agorootparentJust in a statement is insulting if the other person has no idea why the statement is true. Why don't you just, in a question, is insulting if the suggestion is a good one. There is weird symmetry here. reply buzzerbetrayed 13 hours agorootparentprevWhy not either? I feel like that's the point. They both work. And insisting that everyone else use the version you like comes off as nitpicky. reply apsurd 14 hours agoparentprevwords mean things. What's really the benefit of adding in \"just\"? Your claim is that people are too easily offended and so maybe these people will be (too) easily offend by the word. So what's really the benefit of using the word? reply TylerE 14 hours agorootparentIt adds clarity that you're proposing an alternate solution precisely because it's simpler/less work and not as a general alternative. It's a qualifier. think of it as shorthand for \"Wouldn't it be easier if...\" reply kevmo314 13 hours agorootparentSaying something like \"would it be easier to add a DNS record\" seems effective too without the baggage? reply rocqua 12 hours agorootparentTwice the words. But more importantly, if a DNS record is a bad idea, your version is likely to get a more detailed response. It can be valuable to get a compact answer like filtering rules or we don't have a local DNS server. reply kevmo314 12 hours agorootparentWhy waste time say lot word when few word do trick indeed. I mean if we're really debating question length then omitting the just also works... \"Add a DNS record?\" is sufficient. reply chii 13 hours agorootparentprevYea, like \"just let them eat cake\"! reply mistermann 14 hours agorootparentprevGroup conformance yields substantial dividends. Disagree with people's heuristics too often and you might find yourself looking for a job. reply cryptoz 13 hours agoparentprevAs someone who has added hundreds of DNS records, there is absolutely nothing “just” about it. reply lopatin 14 hours agoprevNike: Just do it. OP: Well it's not always as simple as that. How will you get to the gym? Will you drive or ride a bike? What if there are other people using your usual weight machines, do you wait or do cardio? If you're working out after work, will you need to bring a change of clothes? How will my diet affect my workout? And how can I track my fitness to ensure I'm making progress? Sometimes the answer is to just inject that JavaScript snippet. Of course all the follow up questions that OP mentioned to injecting that JS snippet are valid. But that is part of the \"just\". The person \"just\"ing that has assumed that you will consider all of those caveats and there should be no issues, because after all, why would there be if millions of people already use it without issue? It's up to the engineer to just do it, or push back if it's not actually as simple as it seems. reply rendall 13 hours agoparent> The person \"just\"ing that has assumed... Indeed. \"Just\" implies an assumption has been made, but it's not clear what assumptions nor whether they are justified. reply rocqua 12 hours agorootparentGreat bit of semantic insight. Just signifies an assumption of simplicity. Which is different from signifying it IS simple. Which makes it very nice for getting your assumptions checked. reply foobarbecue 14 hours agoprevWhen I worked in robotics at JPL, \"just\" was a running joke. We all tried to avoid using it, because we were all aware that it was a strong indicator of underestimating a challenge. We'd still catch each other using it all the time. reply RpFLCL 14 hours agoprevI'm so happy to see this post. One of my professors back in college mentioned that \"just\" was a \"four letter word\" (akin to a cuss word) and that's stuck with me since. \"How long should this take? It's JUST calling an API.\" \"Why did it take so long to fix that bug? It was JUST a one line change.\" \"Stripe handles payment stuff, we JUST need to add it in!\" What a devious little word. It just papers over all the complexity! reply pooper 15 hours agoprevI am so glad I am not the only one who hated it when other people would try to imply the work I did was trivial. If you want to say my work is trivial or \"just\" 0.5 story points, you should be willing to pick up this story. reply recursive 15 hours agoparentWhenever I hear someone in a meeting saying \"X shouldn't take that long, all you have to is A, B, C\", I like to say \"It sounds like we have a volunteer\". reply tbrownaw 14 hours agorootparentAnd the reply to that is \"I wish\". reply fargle 14 hours agorootparentprev\"it basically simply just sounds like we have a volunteer\" reply nine_k 13 hours agoprevMany people agree that while justice is important, mercy is often superior to it. Let's replace the usages of \"just\" accordingly! \"It's just so simple\" -> \"I's mercifully simple\". \"It's just only a tiny change\" -> \"By mercy, it's but a tiny change\". \"Just do it\" -> \"Have mercy, do it\".reply inquisitor27552 13 hours agoparentwhere's jart ill sell her ine.lol reply idle_zealot 15 hours agoprevThe approach I take is to use \"just\" if and only if I mean to diminish something. I'll use it to refer to parts of my work that were easy, or to parts of unassigned work that should be easy, barring unexpected complications. I find it useful to have an easy way to signal which parts of a task need more effort. reply crabmusket 14 hours agoparentI think this makes a lot of sense, and also highlights why its use in e.g. documentation can be inappropriate. Lacking context for your user, you might not correctly anticipate which parts are easy for them. But often it is used in places where it's not useful to communicate that you think something should be easy. If I need to add a DNS record, you can tell me only that, instead of implying \"add a DNS record, which should be easy for you\". reply bberenberg 15 hours agoprev100% agreed. I set up an autocorrect rule to help me stop doing this. I also found “basically” to be another word to avoid. reply interestica 13 hours agoparentWhat's your rule? Does it eliminate it every time you type it? Or does it replace it with criticism? (You didn't just write just did you?). reply bberenberg 5 hours agorootparentIt is replaced with “DONTWRITEJUST” and then I take advantage of the autocorrect not being great at understanding the context of backspaces and moving caret position to type it if I need it. reply sovietswag 14 hours agoprevYES I FOUND IT, article on the same topic, not in the context of computers: https://thehealthygp.com/2021/04/28/why-i-stopped-using-the-... Why I stopped using the word “just” and why the #justaGP narrative has to stop reply spondylosaurus 14 hours agoprevThis reminded me of the advice to stop saying \"simply\" in marketing copy, or (god forbid) in your actual docs: > If someone’s having to read your docs, it’s not “simple” https://justsimply.dev/ reply aorth 9 hours agoprevI'm a native English speaker. Since reading a discussion about this a few years ago and paying attention to the way we speak colloquially I've stopped saying \"just\" as often. In most cases you can communicate your point with the same meaning minus the implied condescension or whatever. A similar one would be not adding excessive superlatives. It's up to you to be a better communicator! reply throwawee 14 hours agoprevI think there's a missing distinction here between \"Just do X!\" and \"Can we just do X?\" The latter is a legitimate question and positive thing. I was once asked if I could just do X and I said I'd have to spend hours ripping out Y and debugging its replacement. It'd slow down development and if there were any features from X they wanted, it'd be faster for me to write them for Y. Did they still want X? They didn't. Another time I was prepared to build a robust, modular system with its own interface for everyone on the team to use. I mean, really put in the hours and design the hell out of that thing. And somebody said \"Hey, can't you just do X?\" Sure, it'd take me five minutes. But you wouldn't get features A through F--you don't want any of those? They didn't. I just did X. reply brhsagain 12 hours agoprevI agree that the word “just” carries that connotation but I disagree that it’s a bad thing. When I ask if we can just do something my intent is exactly to communicate that I think the thing is simple, that the details are unimportant (to me, to us) and that it ought to be easy to do (and if it’s not, that’s a problem in and of itself). A lot of things are like this, and so to excise the word “just” would be to stop using a word that often concisely and accurately conveys what I’m trying to say. It would be better if the article just said “this is rude.” reply btschaegg 11 hours agoparentThere are nuances to this, too, though: You can be communicating > I think the thing is simple, that the details are unimportant (to me, to us) …and simply be ignorant of a lot of the details that make this not simple for the person who has to \"just\". I had such a \"discussion\" with someone who did exactly this and then refused to even acknowledge there are technical details in their \"just\" and that their \"just\" involves multiple wasted person days of effort (in this case for little benefit, as their \"just\" was to paint over them having to do something themselves). It's infuriating. Now, the \"just\" isn't the only part of the problem here, but it will most likely the part where any useful discussion breaks down. And, while I can blame my encounter on a person with… problematic particularities, it isn't obvious to me that one would always be able to discern easily if one is walking into the same trap. reply digital_voodoo 8 hours agoprevAmen to this (no religious meaning implied) I'm a self-taught tech savvy, I'm aware of where I come from and how far I've come. And I'm deeply annoyed when I see this almost condescending expression in various tech communities online. Very reassured that I'm not the only one feeling that way. reply nlawalker 14 hours agoprevRelated to the “implies simplicity” component, and posted here on HN multiple times: Reality has a surprising amount of detail https://news.ycombinator.com/item?id=38407851 reply __mharrison__ 14 hours agoprevWhen I was writing one of my first books, I created a list of common editorial feedback of words and terms that I need to stop using. \"Just\" was in that list. Removing it usually resulted in a better product. reply rocqua 12 hours agoprevI love the word just in a question, exactly because of what the article points out. Just means, my suggestion seems unreasonably simple to me. It means I am looking for, and expecting, a reason it doesn't work. The downside is if the suggestion does work, you can make someone feel stupid. But it is a great tool to get up to speed on a hatd problem to learn why the 'obvious' solutions won't work. reply tomcam 12 hours agoprevTo me, a more effective way to handle this situation is to convert these requests into a change order. Explain that this is a previously unplanned addition, and give it an estimated cost. Then ask the person requesting it if they want to pay for the upgrade. reply kazinator 13 hours agoprevYou can just answer it. \"The reason why we can't just X is that if we do X, we also have to Y, Z and W. Not literally just (as in nothing but) X.\" reply xarope 14 hours agoprevGlad to see I use it in the proper context then. \"we just have to...\" from me, means it will take just[0] an order or two magnitude more work than you expect. [0] see what I did there? reply js2 15 hours agoprev\"Nothing is impossible for the man who doesn't have to do it himself.\" reply mparnisari 13 hours agoprevHow do I send this to an ex co-worker that did this all the time and drove me bonkers? reply binary132 7 hours agoprevJust stop coming up with hot takes. reply cdchn 15 hours agoprevAny time I hear \"just\" I know something is going to be more difficult than it seems. reply ahazred8ta 14 hours agoparentThe answer to \"can't you just\" is invariably \"no, you can't just\". reply rocqua 12 hours agorootparentThat should be the point of the question. Figure out what context the asker is missing. Not to diminish the work of the one being questioned. reply 8n4vidtmkvmk 14 hours agoprevFellow SWEs never do this to me, but my non-techie business partner uses this word and it drives me bonkers. Side note, I think the reason half of silicon valley has imposter syndrome is because they don't stick around for more than 1.8 years. It took me over a year for it to go away. Just chill out folks. You're doing fine. Stick around. Let's build up some knowledge and just make things better, okay? reply v3ss0n 14 hours agoprevHow about No? There are a lot of things people missing and suggesting a simple solution that solves a lot of problem that they may forgetting or haven't checked justify usage of just. Many of those are already in OP post. Looks like OP just too burned out. reply spaceguillotine 13 hours agoprevWhen femme presenting people stop saying 'Just' in their emails, they get called into HR for being aggressive. reply notacoward 6 hours agoprevSimilar feelings about \"should\". If software always behaved as it should, half of us would be unemployed. reply DonHopkins 13 hours agoprevSo \"In Time\" compiler instead of \"Just In Time\" compiler? reply satisfice 14 hours agoprev\"Just\" is a useful word and concept. The main reason people say it is that it promotes clear communication. Sometimes, I wonder if people who don't like the word \"just\" just don't like what the word implies. Of course, one can use the word \"just\" in a cynical or abusive way. Banning the word does not in any way solve that problem. Some people are cynical and want to say things cynically. Some people want to do some abusing. Don't curtail English itself to solve a problem with bad intentions. I often use the word \"just\" when I want to communicate that I think there might be a simple solution. It is not wrong to communicate that! I often use the word \"just\" to indicate that one reason is much more important than any other reason as in \"maybe you just don't like people to imply that you've missed an obvious solution.\" This may be the truth. Don't try to tell me I cannot speak the truth. Do not unjustly criticize the proper use of \"just.\" reply rascul 12 hours agoprevJust stop saying just reply cottsak 14 hours agoprevGood reminder. reply rendall 13 hours agoprevI internalized not using just after having read this post, or something similar, several years ago. I do think it's helpful not to use just (nor simply). Now, if I hear them, I'll probably ask questions. Often enough, OP is right, and the term hand-waves difficult implementation. reply renewiltord 14 hours agoprevThese are all small things. Say “just” because sometimes things are “just”. It applies the greedy simplicity approach to problems. This provides a baseline approach for one axis of performance. Also, everyone who claims impostor syndrome in software is just actually an impostor. reply pimlottc 13 hours agoparent> Also, everyone who claims imposter syndrome in software is just actually an imposter. Perhaps I misunderstand you here, but that is a frankly astounding claim. Anyone can have a crisis of confidence. It doesn’t mean you’re a fraud. reply 131hn 13 hours agorootparentClaiming impostor syndrome is very different from having a crisis of confidence. reply User23 13 hours agoparentprevIndeed. For example \"Why don't you just use Boyer-Moore or Knuth-Morris-Pratt?\" It's straightforward way to say don't reinvent the wheel. reply ttpphd 14 hours agoprevJust is all you need. reply xtiansimon 6 hours agoprevI blame Nike. reply kelseyfrog 15 hours agoprev [5 more] [flagged] recursive 15 hours agoparent [–] This joke was better when it was in the post title. reply parpfish 15 hours agorootparent [–] Agreed. Rewriting the joke was unjustified. reply midtake 14 hours agorootparent [–] Over-enforcement of the anti-redditism rule on top level comments is sometimes, in itself, distracting. reply fargle 14 hours agorootparent [–] just over-enforcement of the anti-redditism rule on top level comments is sometimes, in itself, distracting. reply Consider applying for YC's W25 batch! Applications are open till Nov 12. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The term \"just\" in software engineering can misleadingly imply simplicity, which may not reflect the true complexity of tasks.- Using \"just\" can contribute to imposter syndrome and hinder ideation by discouraging engineers from questioning or suggesting alternatives.- Avoiding the use of \"just\" in communication can promote better understanding and encourage more open discussions and innovation."
    ],
    "commentSummary": [
      "The term \"just\" can imply simplicity, which may be misleading or condescending in technical contexts, potentially downplaying task complexity.",
      "Its use in discussions might suggest oversimplified solutions, not accounting for all necessary details or challenges, leading to misunderstandings.",
      "The debate underscores the importance of clear communication and understanding the audience's perspective in technical discussions."
    ],
    "points": 118,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1730690749
  }
]
