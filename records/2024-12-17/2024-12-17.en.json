[
  {
    "id": 42441333,
    "title": "Getting to 2M users as a one woman dev team [video]",
    "originLink": "https://brightonruby.com/2024/getting-to-2-million-users-as-a-one-woman-dev-team/",
    "originBody": "Getting to Two Million Users as a One Woman Dev Team // Friday, 28th June 2024 Nadia Odunayo download Gold Nadia Odunayo has been so often the smiling face on the door of this event, but did you know she’s the founder and (more impressively!) one woman development team behind The StoryGraph, a reading community of over a million book lovers. Her story is one of grit, insight and technical insights into what it takes to execute on the “one person framework”. Nadia Odunayo is the founder and CEO of The StoryGraph, the app that helps you to track your reading and choose which book to read next based on your mood and favorite topics and themes. She previously worked at Pivotal Labs as a software engineer and originally learnt to code at Makers Academy in London. In her spare time she loves to take dance class and, naturally, read!",
    "commentLink": "https://news.ycombinator.com/item?id=42441333",
    "commentBody": "Getting to 2M users as a one woman dev team [video] (brightonruby.com)461 points by vinnyglennon 5 hours agohidepastfavorite187 comments phildenhoff 2 hours agoStoryGraph is an excellent tool and I continue to use it daily. I’ve also found Hardcover.app, which I quite like. It has an API and a slightly more refined UI, but it’s clearly more than one person working on it. Of course, if your focus is book clubs, Fable is likely the app for you reply phildenhoff 27 minutes agoparentSolidifying my dislike of Goodreads, I got my “year in books” email from them today and the first thing that loaded, at the top of the email, is an ad. For pillow cases. Folks, don’t do that reply ryangs 1 hour agoparentprevExcited to hear about Hardcover! I like StoryGraph but the lack of API frustrates me - I want to be able to sync back to my general notes store (Obsidian). Hopefully Hardcover works better with that. reply northrup 41 minutes agorootparentWhich is funny, StoryGraph is a Ruby on Rails app, exposing an API is a doable thing, which leads me to believe it is not a priority or a purposeful design decision. reply burkaman 19 minutes agorootparentIt is on the long-term roadmap https://roadmap.thestorygraph.com/features/posts/an-api reply phildenhoff 24 minutes agorootparentprevYeah Hardcover seems to have a GraphQL API they use for their UI, which they expose. There’s not a lot of extra polish for third party devs — it feels like “this is the API we use, use it or not, things may break”. On the other hand, StoryGraph does server-side rendering and so it doesn’t have an API already. So adding one would be a decent amount of work reply magnio 1 hour agoparentprevI also use Hardcover.app, but the community there is tiny compared to Goodreads, with the only possible exception being fantasy readers. reply bwb 1 hour agorootparentIt will get there, its growing :) reply schneems 4 hours agoprevNadia is an amazing speaker. Look up her other talks. You won’t regret it. She blends technical info with an interesting story/mystery in a very thoughtful and well delivered package. Here’s a recent one https://m.youtube.com/watch?v=pOW4vepSX8g&pp=ygUOTmFkaWEgT2R... reply graypegg 10 minutes agoparentHer skills with story telling really show there, that was really engaging but stayed technical and information dense! Thanks so much for the link! reply adamgordonbell 1 hour agoprevCouple years ago I talked to Nadia. Crazy story. End of year is a big time for her as people setup reading goals for the year I think. My wife is now using it. I wouldn't have guessed a book site would be so seasonal. https://corecursive.com/the-story-graph-with-nadia-odunayo/ reply bwb 3 hours agoprevNadia does a great weekly dev log email that I enjoy as well. I highly recommend it -> https://buttondown.com/nodunayo reply skrebbel 4 hours agoprevLooks like a pretty cool app! \"Amazon-free Goodreads\" is a pretty good pitch. I'm curious how freemium model works out for them though, I could imagine a lot of people thinking the free version is good enough for them. reply bwb 3 hours agoparentI think they do around $500k+ a year based on the numbers they have shared in a few spots. The new giveaway platform for authors should help jump that revenue up too. reply Vegenoid 2 hours agoparentprevMy wife loves Storygraph, and has said that she thinks they give away too much for free and need to put more value behind premium. reply soneca 4 hours agoparentprevI am curious of more about the business as well, but I imagine even a very small proportion of paying users could be sufficient to maintain a 3-people team with that scale reply skizm 3 hours agoprevI always wonder, how do sites like this get their list of books and book metadata? Do publishers have an API? What about Amazon? reply bwb 3 hours agoparentIt is so bad!!! I use Nielsen's API, but the data is pretty rough, and you have to spend a lot of time cleaning it. Plus, the archaic industry standards around genre are hard to translate to what readers use - https://www.bisg.org/complete-bisac-subject-headings-list. Ingrams and Bowker are the other big metadata providers. Ingram's is good but expensive, but the data faces the same issues. reply wood_spirit 31 minutes agorootparentDo any of the sites use collaborative filtering for “uses who like x also like y” for a nice filter bubble? I imagine it complements or my even supersede tags. (Admit I haven’t looked at all the sites people are mentioning in the comments yet- lots of good leads!) reply matwood 3 hours agorootparentprevIf you have an ISBN you can also check Worldcat, but at scale it's also probably not free. And if you're working with anything that might have an academic slant, Crossref can be useful. Book metadata is very challenging. Even the publishers of said books are pretty bad at delivering good metadata. reply rafram 1 hour agorootparentWorldCat doesn't have an official API for anyone but member libraries, scraping the site is not fun, and the quality of the data isn't great (it's essentially bulk-imported from member libraries' catalogs). National databases like the Library of Congress are significantly better - WorldCat is best used as a fallback for books that aren't included in the high-quality databases. reply compootr 2 hours agorootparentprevI forgot if Anna's archive contains metadata but that'd be my free-ish solution reply jamiek88 8 minutes agorootparentI thought Anna’s was dead? reply atrus 3 hours agoparentprevhttps://openlibrary.org/ has a pretty good set of data and a decent API. You can mix and match too, since openlibraries covers kinda suck half the time. reply rafram 35 minutes agorootparentIt's alright. I would use it for a tool where the most important part is having a more-or-less accurate authortitleISBN mapping, but not for anything where I need precise bibliographic metadata. reply PaulHoule 3 hours agoparentprevFreebase got about 50% of the way to a good book database but Google killed it. reply shahzaibmushtaq 1 hour agoprev> the app that helps you to track your reading and choose which book to read next based on your mood and favorite topics and themes. If these requirements are constant then one woman dev team is sufficient until the requirements become thick enough to handle with 2 hands. And Pinterest reached 11 million users with 6 engineers, if interested https://read.engineerscodex.com/p/how-pinterest-scaled-to-11... reply kwakubiney 2 hours agoprevShe talks about the story on this podcast episode[1] [1]https://open.spotify.com/episode/5AGrLoFgkYZ0KxLXBOjbwB reply max_ 1 hour agoparentPlease don't use Spotify links as they are heavily geolocked reply nonconstant 3 hours agoprevRuby on Rails community is so lucky to have Nadia reply zeroonetwothree 3 hours agoprevI tried using this but it was too onerous to import my existing list of books I’ve read (1000+). So I gave up after a bit. I usually don’t really have trouble finding books to read anyway. BTW my library (and probably yours too) has a free service where librarians will actually recommend books for you based on other books you liked or other criteria. I found those recommendations to be very good. reply bilbo0s 4 hours agoprevOnly tangentially relevant to the story I guess, but StoryGraph is kind of a brilliant idea. reply pavel_lishin 3 hours agoparentI should really migrate from GoodReads; since Amazon bought them, development has effectively stopped, and there's a lot of QoL issues. reply wiether 2 hours agorootparentIt took me a while to migrate (you upload a CSV and it can take a few days to process it) but now I'm happy with it and a paid subscriber. I won't say that it's great, there's a few things that annoys me, but it sure is better than GoodReads already and improvements are regularly added. reply acdha 1 hour agorootparentprevThe export/import process was painless and after switching the main thing I noticed is how obvious it is that StoryGraph is under active development and Goodreads is effectively orphaned. reply jumperabg 4 hours agoprevPretty nice, 1 dev 3 team members in total and 1 million users? Are there any other products with such a small team and a huge userbase? Does this scale and when the business requires more coding and technical debt comes how do they manage it? reply laborcontract 3 hours agoparentLook at almost anything that Marco Arment has been a part of.. Tumblr and Overcast (probably at least a 5% share of the whole podcast player market) became massively successful with only a dev or two. Stardew Valley sold over 30m copies on a solo dev's work. I think you'd be surprised I'm building my own product right now and never have I wished I had more technical help. It's all the other junk like sales, marketing, distribution, that makes the business so hard. Marketing and sales, in isolation, I've had success with in prior jobs. I'm a fairly productive solo developer. However, being able to context switch and do both dev and marketing? Now that's hard. I have beyond massive respect for anyone that's even attempted it, let alone been successful doing it. reply jezzamon 2 hours agorootparentFor Stardew Valley, that's 30m copies after 4 and a half years of unpaid, 10 hour a day, 7 days a week work. reply Workaccount2 2 hours agorootparentWhich was all just to sit at the table for a chance at massive success. Nobody sees the extensive graveyard of massive time sink projects that got no traction and went nowhere. Even if they would have been big had they caught on. reply diggan 2 hours agorootparent> Nobody sees the extensive graveyard of massive time sink projects that got no traction and went nowhere Of course everybody sees that, and many can't stop thinking about those things when working on their own project, trying to fight the demons that say \"This is a huge waste of time\" and so on. But what is the point of bringing that up when someone explicitly asks for examples of small teams with big success? reply stale2002 1 hour agorootparent> But what is the point of bringing that up when someone explicitly asks for examples of small teams with big success? The point here is to explain how much of a risk these small teams are making. So that is the relevance of the example. It shows how much more difficult and risky these successes are, by pointing out that even if someone puts in a lot of work, it is actually more impressive because of the large risk. This is relevant because the sub thread/topic was this: \"Now that's hard. I have beyond massive respect for anyone that's even attempted it, let alone been successful doing it.\" Therefore, bringing up failures or the fact that there is large risk, supports this point that someone else brought up, which is that it is both hard and deserving of \"massive respect\". So that is why someone would bring it up and why it is definitely relevant and correct to bring it up, in response to this point. reply nightski 1 hour agorootparentThere are countless AAA teams that fail at game dev as well. It's just a really hard industry to garner success in. I'm not sure team size is the most relevant factor. reply nine_k 2 hours agorootparentprevIt's only work if your sustenance depends on it, or if you bet on it to make it big, if you need to be compensated for it. Otherwise it's a hobby, and enjoying your hobby 10 hours a day, 7 days a week is an envious life, if you can afford it. (Barone specifically could not; he had to have a part-time job as an usher in a theater; that was work.) reply nightowl_games 2 hours agorootparentAs someone who's done game dev professionally for a decade, as well as had countless personal projects and has known others to have done the same: don't underestimate the toll game dev can take on you, it's a cruel mistress. Stardew Valley is a massive outlier. reply nine_k 1 hour agorootparentCan't disagree. But, you know, making love can be pretty physically taxing, but people do it, because the process itself is its own reward. It's only work if you tolerate it for the reward on the payday. reply eptcyka 2 hours agorootparentprevThere is no such thing as a 10-hours-a-day-7-days-a-week hobby. reply s1artibartfast 2 hours agorootparent^This is obviously a tangent, but sure there is, if you consider a hobby to be non-professional activities. It is trivial to come up with activities that can consume a lot of time, but don't provide financial rewards. reply short_sells_poo 1 hour agorootparentI suppose maybe parent is mixing up difficult work and difficult hobbies. There are plenty of hobbies which are difficult and require a lot of hard work. Hobbies can be frustrating and yet still enjoyable when you overcome whatever it is that hindered your progress. Someone who does painting as a hobby might face a period of no inspiration - it can be immeasurably frustrating and it completely blocks you from painting. And then one day you see a particular way that the stained glass window reflects light onto the pavement and something gets switched inside and then you proceed to feverishly paint every waking hour and it will feel like it is not you who wield the brush but that you yourself are some sort of instrument being used by something greater. Game dev is an arduous and draining process that both requires the patience to go through periods of dreary work where no progress seems to be made and yet the creative spirit to devise art, concepts, mechanics, rules, etc. If I had the time, I could easily see myself spending multiple years on a project like that without the need to see any financial reward. I wouldn't see it as work, I would see it as Work with a capital W. A hobby that requires a lot of personal effort but something I do because purely for the joy of doing it. reply nine_k 1 hour agorootparentprevWhy, a number of people would e.g. play games they enjoy all day, every day, if the other aspects of their lives were taken care of. Imagine being a schoolchild.during the summer recess :) Same applies to reading books, sailing boats, etc. reply jimnotgym 33 minutes agorootparentprevFarming? reply staticman2 1 hour agorootparentprevStardew Valley didn't follow any of the entrepreneurial advice you'd find on this site, either. There wasn't a \"minimum viable product\" launched in year 1 followed by finishing the product in year 4. I've literally seen a post here where someone scolded a failed game developer for finishing their financial failure of a game before launch. The comment was something along the lines of: \"Read a business book. You shouldn't have spent a lot of time making your game. Instead you should have released a minimum viable product after doing market research.\" reply intelVISA 2 hours agorootparentprevDid they build the engine from scratch? 114975 man hours on a 2D game is unthinkable! reply fmbb 2 hours agorootparentBuilding an engine from scratch cannot be the hard part. It’s not complicated. Iterating on all the things that make the game fun is hard, and making all the ”content” in a game like Stardew Valley is very time consuming. reply fhd2 2 hours agorootparentAs someone who's built a few engines and also worked with third party ones: It really isn't the hard part for a 2D game. High fidelity 3D, different story. But something like Stardew Valley, I'd dare to say custom engine and something like Unity is pretty similar in effort, considering that you need to deal with doing things in the engine's way, which requires workarounds and what not. Bringing it to many platforms gives the engine a head start, but I'd say it's comparable. Iterating on the game content itself: _Insane_ amounts of effort, in my experience. reply AlotOfReading 2 hours agorootparentprevBuilding an engine is a famously huge time sink, to the point where the standard advice is to make a game or an engine, but not both if you want to ship. reply diggan 2 hours agorootparentAs always, it depends. Building something like Unity/Unreal that should support everything and everyone under the sun, one way or another? Yeah, huge time sink. But a 2D engine that should only support exactly what the features need from Stardew Valley? Doesn't seem insurmountable, although I wouldn't exactly take that approach myself. reply rimunroe 2 hours agorootparentprevHe wrote it in C# and used XNA for some stuff, but the engine itself is custom[1] [1] https://community.playstarbound.com/threads/game-development... reply lelandfe 2 hours agorootparentprevAfter Windows, Stardew Valley was ported to consoles by other companies, like Chucklefish, Sickhead Games, and The Secret Police (not dev work but console Q&A was handled by others too, as was localization). Barone is still a beast, just making sure the \"one guy did the whole thing\" thing has some nuance. reply RenThraysk 2 hours agorootparentprevFlappy Bird had 50m+ installs. reply grog454 4 hours agoparentprev> Are there any other products with such a small team and a huge userbase? My game Nebulous was 1.5 devs (one full time one part time) and multiple millions of MAU. 9.5 years later it's still going well. > when the business requires more coding and technical debt comes how do they manage it Delete bad code. Replace with good code. Sounds simple enough but in my experience at mega and mid corps, step 1 is almost never done. Whether that's because of ego or chasing local optima I'm not sure - probably a mix of both. reply cbm-vic-20 3 hours agorootparentIt's due to fear. Fear of breaking something that may depend on that bad code. Test automation rarely covers every possible case, and nobody wants to be on the hook when some code changes cause other stuff to break. reply klabb3 3 hours agorootparentCan confirm. One of my proudest moments was deleting thousands of LOC of copy-paste-modify garbage. However I introduced one bug that broke another team which used an undocumented feature. It was fixed soon, but yeah, still not great. And very few people would have taken that on, I was not a career chaser. Some would say it’s the other teams fault for not adding a cross-test against my teams code. And while that would have solved it, some things are hard to test. Even in companies who have good testing standards some things are still hard-to-impossible to test. In my humble opinion tests are great if and only if they are hermetic and fast. Unfortunately, the important things that can go wrong are usually the least testable. In either case, in a non-perfect world (ie ~all large companies and most small ones) people optimize for not breaking things, and there’s a solid argument for that being a local optima, both for short term stability and career wise. reply giantrobot 2 hours agorootparent> In my humble opinion tests are great if and only if they are hermetic and fast. Unfortunately, the important things that can go wrong are usually the least testable. Integration tests are hard. A lot of time it's because deployment is very seat of the pants. Even with tightly managed deployment the test environment needs to be representative of the production environment. Just setting that up is time consuming and expensive. Then actually doing tests where the test environment has useful amounts of instrumentation without major performance or behavioral penalties. reply atomicnumber3 3 hours agorootparentprevThat, and most orgs simply do not reward or even pretend to care about these kinds of improvements. If you delete bad (but working) code, and replace it with good (and, let's assume best-case scenario - also working) code, what has actually changed for the business? Nothing. Except that in 3 years the junior dev that gets a ticket about doing something in this area will come in and not notice the code isn't a dumpster fire. Or, in 3 years, you won't notice that you didn't have to optimize this code a year ago. What they do notice is that you were insisting on working on some mumbo jumbo and ok good they're done now they can actually work on something useful. Haha aren't these devs quirky? Sometimes they take a few days and work on something weird, and all the other senior devs nod and salute solemnly and I'm too scared to ask for more details, but they don't usually take too long so let's just indulge them for a few days to keep them happy so they don't leave too. It takes a very, very deeply engineering-first org to really cultivate this intentionally. And similarly it seems like succeeding as a startup requires at least a decent amount of shipping some shit code fast so you get a series B, so usually you don't start in this posture and never shift into it before it's far too late. And also unfortunately, devs often _do_ spend time optimizing/refactoring personal pet peeves as opposed to things that might have a good chance of mattering. I once saw another senior dev spend a week optimizing string allocations on our hot path. Our owner loves people who can do this kind of stuff, so it got a lot of praise. The microbenchmarks looked great, pretty graphs. Users noticed nothing, the actual metrics we track literally did not change, and now the already-complicated hot path is decorated with some contorted string-allocation-avoiding warts here and there and the next person to go in and change the code is _definitely_ going to keep doing that pattern, for sure. Meanwhile our oauth flow is still a tortured, unloved, twisted writhing mass of pain and suffering that prints bug reports like CVS receipts. So... extraordinarily difficult to intentionally cultivate a culture that does this judiciously. reply block_dagger 2 hours agorootparentOne of the most rewarding aspects of my previous career at a company spanning from a startup to an IPO and beyond was deleting bad code and replacing it in a massive Rails app that was touched by hundreds of devs in a high churn environment. I also took on fixing massive schema inefficiencies that had a lot of risk of breaking nearly every other team's flow. It took a lot of careful work and communication across multi-year goals that I managed, mostly alone. I was allowed to do this by a few early folks who believed I was doing a good service for the company in the long run but kept hinting it was a bad career choice for me personally. I believe I was eventually let go for making these massive improvements instead of adding that green button that the new Product guy wanted. No regrets. reply BubbleRings 2 hours agorootparentI think I’ve taken some considerable career hits for that kind of attitude, but mostly no regrets here either. But I think I was affected by how, once you leave that company, your contribution to the effort can seem kind of gone, gone gone. That’s part of why I came back to trying to create a physical invention that someone might care about. Something for the grandkid to put on his mantlepiece and say “my granddaddy made this and patented it and (hopefully) it was the start of his big company.” reply gerad 2 hours agorootparentprev> Meanwhile our oauth flow is still a tortured, unloved, twisted writhing mass of pain and suffering that prints bug reports like CVS receipts. Wow, this line is a keeper. This whole comment is so insightful. Reminds me of how awesome HN can be sometimes. reply fmbb 2 hours agorootparentprevGood code and bad code are not objective values. I have worked with many people that spend days replacing good code with bad code because they are ”paying down technical debt”. reply BubbleRings 3 hours agorootparentprevYou should write a book on this stuff. reply shadowgovt 3 hours agorootparentprevAnd for all of the benefits of process, I have never met a level of documentation, verification, or testing that matches the advantages of having the entire code base originating from one mind. Generally this is not tractable because it cannot scale. But there are certain applications where it scales fine. reply mattgreenrocks 2 hours agorootparentI don't think we need nearly as many devs as we think. We do need someone who is taking a hardline approach on limiting the amount of scope tackled at once, and then fewer devs that are downstream of that. It is hubris to think that every problem admits the same solution, namely, throw as many devs as we can at it and hope for the best. But business isn't really known for being reflective. reply swiftcoder 1 hour agorootparentprev> Generally this is not tractable because it cannot scale The real question here is scale in terms of what? Because a lot of folks are out here trying to scale people/careers, not software. It's extremely noticeable at BigCorps. Why do we need to scale this project from 3 -> 30 -> 300 developers? Because that's the number of reports to promo from Manager I -> Manager II -> Director reply mritchie712 3 hours agorootparentprevit's always fear for me. I'd rather leave it commented out for a decade or so to be safe. reply Feathercrown 2 hours agorootparentI'm a monster, I see code that's been commented out for more than 2 months or so and nuke it unless I know it's needed. We have Git, it'll be fiiine reply johnmaguire 2 hours agorootparentRight. The only time I sometimes leave a commented out line of code is if it's temporarily broken and will be uncommented soon; or if it's by-far the most obvious way to do something, but does not work for some reason, and then there's a comment above about why not above. reply devjab 2 hours agorootparentprevI never understood commenting out code when you have version control. I get why people do it, I’ve done it myself and then two days later been confused which of the 3 commented out function was actually the most recent. It’s infinitely more clear from the version control since the history is there for you to zoom through. reply wink 2 hours agorootparentYou would find it if you knew it was there. I only leave it commented out because it has a reason (they all say that, right?). I suppose the best way would be to provide a meaningful comment \"This is the place where 15 lines of coded finally found their resting place, deleted after the bug they solved was eliminated elsewhere\". But in reality, I've never seen a single of the \"we could find it it in git\" ever actually find it in git. reply devjab 22 minutes agorootparentWell yes, but you’re not leaving commented out code for anyone other than you. A “sane” git structure will automatically decline your pull request if it contains commented out code. I say “sane” because I know a lot of places probably allow you to do it. You really don’t want to pollute a code base like that though. reply swiftcoder 1 hour agorootparentprev> It’s infinitely more clear from the version control since the history is there for you to zoom through Only if you already know it is there. There is like... zero history discoverability built in the git. and git's historical search story is pretty bad too. reply devjab 20 minutes agorootparentWell, who other than you would need to know about your commented out code? I’m not suggesting you keep the commented out code as part of your git history, that would never be allowed through a pull request. The changes will be there in the history though, I doubt you’ll need to go back for them, but you could. reply block_dagger 2 hours agorootparentprevI think a lot of devs prefer the hover-to-blame feature in their IDE vs searching through history on GitHub. reply noprocrasted 2 hours agorootparentprev> Delete bad code. Replace with good code Your points are valid but there's also the issue that the more developers you have the more communication overhead there is, which makes large changes to the codebase hard/impossible. With a handful of devs you can jump on a call, brainstorm for an hour or two and come to a mutual agreement, then one can submit a several-thousand-line PR refactoring the whole thing and nobody would bat an eye. This kind of coordination is impossible in larger teams, if anything just because everyone is busy and can't afford to spend a couple hours brainstorming + subsequently get acquainted with the new code, but also because the more people the more opinions and mismatched incentives (bad or overly complex code might imply busywork which some people thrive on, so refactoring it to no longer require said busywork is a downside in their eyes). reply dowager_dan99 3 hours agorootparentprevI go further and simplify: \"delete code\" whenever and where possible. The term \"Tech Debt\" is really overloaded; I think the idea that \"all code is liability\" is better for framing the issue and strategies. reply BubbleRings 3 hours agorootparentIt is so good to see someone say that. I don’t code anymore, but as a systems engineer on different (often troubled) projects, I started developing a bit of a specialty in deleting crufty old collections of files. Sometimes multiple terabytes in a day, directories sitting around looking like they might be important, in some random corner of storage. You have to be good at your job, good at the specialty, and more interested in doing the right thing for the company (and more irritated at the stupidity of the files being there 10 years after they were needed) than you are at looking productive to management. Management does not want to hear “well there was a directory structure of two million files that was a backup of a Linux machine from 8 years ago, I spent two days extracting the dozen files that we might need some day, getting the okay to proceed, and deleting the files.” reply moritonal 3 hours agorootparentprevFleet commander or I'm guessing .IO? reply grog454 2 hours agorootparent.io. There have been more Nebulous's since I last checked :) reply Consultant32452 1 hour agorootparentprevI have no incentive to delete bad code and replace it with good code when doing megacorp work. For things I own, it's situational. reply open592 3 hours agoparentprevFrom a long time ago (~2009) but this comment instantly reminded me of the gem which was Plenty Of Fish https://highscalability.com/plentyoffish-architecture/ \"POF has one single employee: the founder and CEO Markus Frind. Makes up to $10 million a year on Google ads working only two hours a day. 30+ Million Hits a Day\" reply TheJoeMan 1 hour agorootparentThank you for sharing! Only issue with the article I see is that \"CPM\" is already \"cost per mille (thousand)\". So any lines such as \"$15 per CPM\" make me hesitate. reply imachine1980_ 3 hours agoparentprevLichess is one guy for the web and server and one guy for the mobile app Cool video about the topic https://youtu.be/7VSVfQcaxFY?si=UP5txyUCoYYY024h reply skizm 4 hours agoparentprevInstagram and WhatsApp (pre-acquisition) were both pretty legendary for how small their teams were vs how many users their apps had. Instagram had 13 employees, and WhatsApp had 55 employees at the times of their sales. reply julianeon 2 hours agorootparentIn Instagram's case I think it was very clear they were \"borrowing from the future\": they were accumulating a lot of technical debt and continuing to pile it on. It was not sustainable. The goal was to either hire more or get acquired. When the latter happened, the codebase quickly benefitted from the work of many more Facebook engineers. reply swiftcoder 1 hour agorootparentBorrowing from the future is exactly what a VC-funded startup is supposed to do. If you aren't borrowing from the future, you're probably wasting your initial VC investment. reply sangnoir 57 minutes agorootparent> Borrowing from the future is exactly what a VC-funded startup is supposed to do That's too broad, the hope is you're borrowing from a point in the future when you're able to pay the debt. If you borrow too much, or from a point too close to the present - though it's hard detangle those 2, then you may fail to scale at a critical time such as positive press attention or going viral, because you're paying down tech debt. From the article: if it had taken 6 months to fix their importer instead of the 2 weeks it did, the product may have died. reply jedberg 1 hour agoparentprevWe had ~10M users on reddit with three engineers and one non-engineer. Got up to about ~20M with five eng and two non-eng. reply insane_dreamer 4 hours agoparentprevWhile not as tiny, Craigslist has a huge user base all over the world and still has less than 50 employees total (not just devs). IMO it's the poster child of being able to scale worldwide while keeping the product highly focused, highly operational, and avoiding feature and technical fluff. reply vanviegen 4 hours agorootparentFrom what I can tell, craigslist is not really a player outside of the US. Just about every country seems you have its own 'craigslist'. reply insane_dreamer 3 hours agorootparentWhile it's true that most countries have their homegrown version by now, I've used Craigslist myself in other countries, and it does have enough of a presence that it's actually maintained in over 50 countries which is no small feat. reply nolito 2 hours agorootparentWell, they are present in Denmark. I only managed to find a single item - an expensive apartment. In Denmark the place to go is dba.dk or facebook marketplace. Checking the portugese version - its 3 items in Lisbon. reply input_sh 3 hours agorootparentprevI just checked the Croatian version and it has a total of 5 things listed for sale and 3 jobs. Needless to say, there's a far more popular local alternative that basically every person in Croatia knows about (njuskalo.hr). reply dowager_dan99 3 hours agorootparentprevreally even regionally. In Canada i've seen geo popularity across Kijiji, Craigs List, FB Marketplace, domain-specific communities with markets reply steventruong 3 hours agoparentprevEric Barone as a one man team built, designed, animated, wrote, and composed the entire game of Stardew Valley by himself. The game sold over 30 million copies and had an all time high of over 230K concurrent players at one point earlier this year. reply zerkten 3 hours agoparentprevStack Overflow was an example of this. They had a relatively small dev team and they also maintained a very small hardware footprint for delivering their product. Over time they expanded their scope into products beyond the Stack Overflow and Stack Exchange sites which seems to have increased their team size. At least a big part of their success was containing technical by avoiding product debt. They had a clear vision and very tight control of their product which is different from 99% of startups. They were experimenting but not throwing any crap at the wall which was never cleaned up or iterated on. There was a very strong product-engineering connection and alignment which is unusual. Misalignment there is the genesis of much tech debt. Many product features are thrown out with little iteration to get them right but use \"shipping so we can iterate\" as an excuse to throw them out to users. reply schneems 3 hours agoparentprevIIRC urbandictionary is/was a one man show, Aaron Peckham. Deployed on Heroku https://blog.heroku.com/heroku-xl (post from 2014, not sure if he is still a customer). reply InsideOutSanta 3 hours agoparentprevIt's not a small team, but Valve seems to have a very similar proportion of employees to users. I think they have about 400 employees, and a user base of 140 million. That's roughly 3 employees per million users. reply mikepurvis 3 hours agorootparentThey’re running a marketplace though, and that’s a bit of a special case — obviously why VCs are always very excited for anything that is or looks like it might able to become marketplace-shaped. Certainly there aren’t 140M MAU fore the steam deck or any of the games they’ve built themselves, that’s for sure. reply piva00 3 hours agorootparentprevWhatsApp pre-acquisition by Meta was also very lean, some 40-50 people total serving 200 MAU. reply philipwhiuk 2 hours agoparentprevDwarf Fortress is another obvious one - basically small successful indie games are all gonna be this. But that's not a VC product market. reply eucki 2 hours agoparentprevPieter Levels is creating the kind of software I’ve always dreamed of building: https://www.youtube.com/watch?v=oFtjKbXKqbg reply eek2121 2 hours agoparentprevI owned a website with over a million users. Used cloudflare and a $20 cloud instance to run it. Also relied on certain other CDNs. Don’t own it anymore, but considering starting a new project. reply huma 2 hours agorootparentWhat was the app about? reply kumarm 55 minutes agoparentprevStarted on Android Market in 2010. First hire (designer) after 12 Million downloads and started hiring other Dev's after crossing 50 Million downloads. Still run decently popular apps on App Store and Play Store. reply stronglikedan 3 hours agoparentprev> when the business requires more coding and technical debt comes Tech debt doesn't come because the business requires more coding. It comes from poor planning and rushed implementation, often spurred by overzealous and naive management. This is a small team with one dev, so they likely do things correctly from the start and don't acquire much if any technical debt. Nothing has to be done yesterday, ever. reply vergessenmir 2 hours agorootparentTech debt is a function of your code base, it's age, team turnover and number of pivots. Many factors to consider but I'll focus on pivots. You can't plan for a pivot because it's a known unknown. The same way you can't plan for a specific financial event in the market but you can brace yourself for a category of scenarios. Even with that, you can't predict the impact or the appropriate response your business needs to take. In the same way so is the pivot. The nature of the pivot is the market revealing the debt you didn't know you had. The magnitude of that readjustment to the market, in the time it has to happen and the time to the next pivot is unknowable because it's information not present at design time. reply hoppp 3 hours agorootparentprevExactly. Technical debt often comes when a lot of developers work on the same codebase. Everyone contributed and nobody refactors. If the project is well thought out in advance a single developer is enough and will do perfect code reply OJFord 1 hour agoparentprevWhatsApp & Instagram were I think both very small teams with very many users when Facebook bought them (I think was FB not Meta at the time) for very much money. Which maybe goes some way to your second question, as they were slightly and slowly scaled up versions of solo serving 1M. (And obviously have continued that under FB/Meta with probably now a much less impressive/unusual staff:user ratio.) reply noprocrasted 2 hours agoparentprevIt turns out you can go quite far when your objective is to solve a business problem rather than building an overcomplicated mess to solicit VC money. reply mdswanson 1 hour agoparentprevMy one-person indie company released many apps, and one of them (Halftone) had over 6 million users by the time I shut it down. It's definitely possible. reply PaulHoule 3 hours agoparentprevI got a voice chat service for Brazil to nearly 500,000 users as a single dev. Of course we co-branded somebody else's application but I made the user database, sign up systems, contests and other web-based parts. reply rwmj 3 hours agoparentprevSupport would be the biggest thing, especially if the website needed any kind of login, payment, or user contributions. Back when we ran a website for UK schools (so, probably 50K-100K users maximum), we only answered support calls or emails during UK working hours, and still needed a 2-3 member team doing that. That was a shoestring even at the time. Nowadays just the safety aspect of running a service for children would demand something larger. reply bcrosby95 2 hours agoparentprevBack in the Facebook app days we had some apps with 2-8mil daily unique users on anywhere from 1-3 devs and team sizes anywhere from 2-5. reply edm0nd 2 hours agoparentprev>Are there any other products with such a small team and a huge userbase? Tons of FOSS projects. See the entire JiaTan fiasco. reply mattgreenrocks 2 hours agoparentprevWrite good enough code that can be easily replaced. It really is no different than what you'd write on the job. reply ffsm8 3 hours agoparentprevWhatsapp pre Facebook. It has reportedly around 50 employees at acquisition, and 450 million users at the time. reply gwd 3 hours agoparentprevI mean, SQLite is what, 4 developers? And it's by some estimations is one of the top five deployed software modules of any description: [1] https://sqlite.org/mostdeployed.html reply insane_dreamer 4 hours agoparentprevPinboard probably reply burkaman 3 hours agorootparentPinboard peaked at about 30,000 users: https://x.com/Pinboard/status/1810893626274128048/photo/1 reply insane_dreamer 3 hours agorootparentFair point. But they were 30K _paying_ users, which is a huge difference. What's the free-to-paying users in a service like the OP's? reply dowager_dan99 3 hours agorootparentprevha! kind of funny to read the comments in this thread and see this at the top of the Pinboard website: Notice (Dec 13): code cleanup continues; please keep reporting bugs to support@pinboard.in reply tptacek 2 hours agorootparentWhy? reply kbutler 2 hours agoparentprevMinecraft? Not sure how big it was before Notch hired anyone else, but this reddit post encouraging him to hire somebody says he'd \"brought in $67,903,100.72\" https://www.reddit.com/r/Minecraft/comments/kbiuv/notch_youv... reply cactusplant7374 4 hours agoparentprevBasecamp has always been a good example of that. reply tptacek 2 hours agorootparentBasecamp has a full-sized team and has for many, many years. reply dheera 3 hours agoparentprevI don't know StoryGraph's story, but it's a lot easier if: - You don't take VC money - You are okay with it not becoming a billion dollar unicorn - You are okay with occasional downtime (this isn't being deployed in a hospital emergency room after all) - You don't plan to feature bloat it - You are okay with it living its life and eventually being out-competed I had a webapp once with 250K monthly active users for several years (Fooplot). I was the sole developer. It eventually got increasingly out-competed by VC-funded Desmos and eventually got involuntarily shutdown when AWS decided to stop supporting EC2 classic instances. But I just let it be. Its ad revenue made me a good amount of side income when I was a PhD student. It had frequent downtime when people would try to export an overly complicated graph, which would crash the server. I just restarted it when I noticed. Sometimes it would be a few days later. It died eventually when AWS terminated it. I moved onto other things. Yeah, I wasn't the best maintainer, but the ~$30K I made from its ad revenue over the years was a pretty good payout for about 10 hours of work. reply scotty79 3 hours agoprev> the app that helps you to track your reading and choose which book to read next based on your mood and favorite topics and themes. I'd like to have that for games and music. Stores are mostly terrible at recomending anything. Steam does better than most but still far from good. And syncing recommendations with my mood is pretty much non-existent. reply myth_drannon 4 hours agoprevThe app is hugged to death by HN... reply aniforprez 4 hours agoparentI don't think that's the case. I've found it to be fairly janky and it has frequent down times every so often. I'm much more inspired to give a small one-person team some leeway about it though for a free app vs. Amazon and all its resources not even bothering to properly maintain Goodreads. reply jahnu 2 hours agorootparentAmazon don’t even properly maintain their Prime Video app for TVs. It’s so bad on my good LG TV that I gave up waiting three seconds for button presses to register while trying to start watching their billion dollar show they kept urging me to watch. reply alternatex 2 hours agorootparentWait till you try HBO's Max app. I used to plan my watches half an hour ahead. LG TVs do have quite the shoddy hardware though. Every penny goes to the panel. reply jahnu 27 minutes agorootparentNetflix and Apple seem to have no problem making a good client. We won’t have HBO here until 2026. The Austrian national broadcaster have a decent if not brilliant player. Even the built in dnla player works great. Amazon are ridiculous and should be ashamed of such crappy software. reply quesera 4 hours agoprev> Nadia Odunayo is the founder and CEO of The StoryGraph, the app that helps you to track your reading and choose which book to read next based on your mood and favorite topics and themes. https://thestorygraph.com/ reply dang 52 minutes agoprev [46 more] [stub for offtopicness] [good grief] reply madeofpalk 1 hour agoparentMeta: It's a shame all the [dead] comments here over the title of this post are hidden to most. I think it's a good reminder of the opposition some face in this (and other) industries for merely existing. reply sebastianz 1 hour agorootparentI understand your point, but in reality we all know the world is full of mean and petty people. I am thankful for the moderation on the platforms I read for (at least some of the time) sparing me the frustration and sadness I would get from otherwise constantly reading their opinions. reply qup 1 hour agorootparentprevI don't have them hidden. I can't find anything derogatory about women; rather, the comments point out perceived hypocrisy around naming genders in titles. The comments about Nadia specifically were great, including a dead comment saying what a blessing she is to the rails community. > Ruby on Rails community is so lucky to have Nadia Another dead comment says it's not impressive, but doesn't mention gender. Two dead comments calls the title sexist. One dead comment predicts there will be misogyny. Two comments say \"who cares if it was a woman\" One comment laughs about \"woke\" complaints while being the only comment to use the word. I think that's all of them. I understand that putting \"woman\" in the title triggers a lot of talk about gender, which is off-topic and boring, but I don't really find any of the specific comments notable, hateful, or oppositional. reply ziddoap 1 hour agorootparent>I don't really find any of the specific comments notable, hateful, or oppositional. The fact that gender is mentioned at all, when it's never mentioned in posts that have \"one man dev team\" in the title, doesn't imply anything to you? reply Alupis 1 hour agorootparentAre we not at a point where it would be vastly more appropriate to title this \"one person dev team\"? The reality is your gender has nothing to do with your ability to write software. Software is the greatest of equalizers. There is definitely a subset of society that feels it necessary to thrust gender into discussions where they have no place - such as this article. Are we supposed to be more impressed because it was a female? Why? reply ziddoap 58 minutes agorootparent>Are we not at a point where it would be vastly more appropriate to title this \"one person dev team\"? Sure! I just find it interesting that these discussions only happen when \"woman\" is in the title, and never when \"man\" is in the title. >There is definitely a certain subset of society that feels it necessary to thrust gender into discussions where they have no place - such as this article. As long as you feel the same way whenever you see \"one man dev team\" or similar, I think that can be a good discussion. reply Alupis 52 minutes agorootparentI agree with you entirely - however allow me to illustrate a point: I think the difference often is the intention of the writer. We get these types of headlines when people want to really promote how cool it is a female is capable of doing something - and we're all supposed to be amazed. That's pretty sexist if you think about it... of course a female is capable of writing high quality software! We should be amazed at what this person achieved because it is impressive on it's own merit - not because of the person's gender. However, nobody is reading a headline like \"one man dev team\" and thinking \"you go dude!\". It's a two-way double-standard that we should work on ending. reply qup 1 hour agorootparentprevYes, it implies that calling attention to things done by women is a trigger for gender discussions. I think trying to make arguments about why they are triggering requires you to make a lot of assumptions about people who aren't yourself. reply ziddoap 1 hour agorootparent>discussions That is a charitable way to read the flagged comments. reply s1artibartfast 46 minutes agorootparentprevMy take as well. People seem to think this should be a noteworthy accomplishment irrespective of gender. The source seems to be objection to perceived patronization of women, not not hate or disparagement of women. reply ghaff 45 minutes agorootparentprevI probably wouldn't have written the title that way. In the body of the article, identifying the gender feels much more natural. reply anonfordays 1 hour agorootparentprevPlease don't fulminate. Please don't sneer, including at the rest of the community. Please don't comment about the voting on comments. It never does any good, and it makes boring reading. https://news.ycombinator.com/newsguidelines.html reply cynicalsecurity 4 hours agoparentprevnext [8 more] [flagged] carlgreene 4 hours agorootparentWell, your username certainly checks out. I am not sure how many solo projects you have embarked on, but providing a product to 2 million people is no small feat even for a team. Iterating to product market fit takes a lot and not many people are ever able to do it. Whether it is simple or not it's obviously providing value for the users that are using it, and is reliable enough because it keeps growing. reply bovermyer 4 hours agorootparentprevI doubt \"support\" is all that necessary for an app of this type, as you yourself mentioned. Making something that millions of people use and appreciate? That's worthy of praise. reply zeroonetwothree 3 hours agorootparentI actually emailed the story graph with a support question and got a prompt response. I imagine you do have to provide it since you have paying customers. reply bovermyer 3 hours agorootparentIt's expected, I'm sure. But there is not an inherent law of the universe that requires companies to provide support for their services or products. That StoryGraph provides it is a nice extra touch. I personally would not expect it. reply simonw 3 hours agorootparentprevThis comment reads like one of those Bluesky \"polite disagreers\" LLM-generated replies that's designed to farm for engagement: https://boingboing.net/2024/12/05/blueskys-bot-invasion-ai-a... reply deberon 4 hours agorootparentprevThis was a thoughtful comment but I’m not sure how useful it is at all due to the typo. Commendable vs commandable? I have a pet peeve for typos so your highly accomplished comment is really unworthy of the photons used to display it. Or maybe we can be more supportive of each other and our accomplishments. reply quesera 4 hours agorootparentprevUh. So you're saying that this person made a smart decision by building a thing which is valued by users, and which they are able to create and support as a single individual? So what is your complaint exactly? reply tolerance 2 hours agoparentprevnext [4 more] [flagged] giancarlostoro 2 hours agorootparentThe person who submitted this followed HN guidelines which state to use the original title of the article. I'm not sure why people need to freak out. HN didn't name the content, the content publisher did. reply qup 2 hours agorootparentprevYou're the only person who used \"woke\" in this thread, at the time of my comment. reply evan_ 2 hours agorootparentLook harder, there are several- at least three comments older than yours say \"woke\" in them. Several comments have also been flag killed and the replies suggest they said something effectively synonomous reply jbverschoor 2 hours agoparentprevnext [6 more] [flagged] dsco 2 hours agorootparentThings are the way they are. Sometimes you can’t be rational about things. reply culi 2 hours agorootparentprevnext [5 more] [flagged] Vegenoid 2 hours agorootparentUnfortunately, as someone with a wife who works as a software engineer, it is rather unsurprising to me. reply louwrentius 2 hours agorootparentprevIt’s sad that text got flagged. Which proved a point. I voted up. Words and behavior matter. If your identity is so hung up on being a man and believing that men are “better” than women, your identity is a frail illusion. Try to imagine being so “weak” that you can’t accept that there are women who are successful and some do better than you. reply bozhark 2 hours agorootparentprevTechies are sexiest. reply morkalork 2 hours agorootparentprevMale is the default gender and anything that goes against the defaults of society triggers people. That's it. reply ternnoburn 3 hours ago [flagged]parentprev [18 more] HN, let me confront you with done data. Doing a quick analysis, there are four comments complaining about the use of \"one woman\" in the title. That's ~10% of the comments as of the time of writing. Looking back over the previous year, I found many stories that used the equivalent \"one man\". For example: https://news.ycombinator.com/item?id=41104293 https://news.ycombinator.com/item?id=41260345 https://news.ycombinator.com/item?id=40004349 And many, many others. Not a single comment complaining that \"he thinks he's special because he's a man\". Not a single one, and certainly not approaching 10% of the comment volume. I suspect someone with more time could find more examples of this disparity. Downvoted and flagged or not, the way that HN appears to respond to the same concept (\"one human\") based on that human's gender is quite surprising to me. reply NeveHanter 1 hour agorootparentThe more popular HN gets the more clickbait-y, attention-seeking and polarising titles and articles we're getting. I also think the more popular it is the less weight each down-vote/flag has, we will see more and more of such content being posted. I and most of the people I know or work with really don't care whether something is/was made by a man or a woman. IMO that's totally unnecessary part of the title and its some kind of the usual \"clickbait\" you see in the news titles everywhere. BTW: I was used to seeing \"one-man\" being used everywhere regardless whether the person in context was a man or a woman and only today I've discovered that both one-woman and one-person are valid by couple of UK/US dictionaries (even the older ones). Maybe that's one of the reason why some non-native speakers see this as an clickbait/attention seeking. reply ternnoburn 39 minutes agorootparentThe thing is, I don't think it's click bait in this case. One person running a large service is notable, appropriate content for HN. And she's a woman, so one woman is per reasonable, factual, non editorializing headline given that \"one woman\" is a descriptor that's been in widespread use for some time. People seem to be reacting to it like it's poison. reply rsynnott 2 hours agorootparentprevA certain fraction of this website's user base are, and always have been, basically Quark from DS9. Some really bizarre attitudes to women. reply sgt 2 hours agorootparentHilarious! But even on DS9, there was room for a Quark. reply rsynnott 2 hours agorootparentOne, sure. If there had been about 15 per episode, as there are on any threads which so much as imply the existence of FEEEEEMALES here, it would've gotten old. (There were other Ferengi sometimes, but they were far less strident on this particular matter, in general.) reply sgt 1 hour agorootparentBtw, glad I am not the only one making a mental note of someone being a \"ferengi\". It is such a perfect description somehow. And our industry is full of them. reply krapp 1 hour agorootparentWell, the Ferengi were intended to be a parody of American capitalism. And the tech industry in many ways has turned itself into a parody of American capitalism. And the worst of Hacker News might as well be a parody of the tech industry. reply sgt 5 minutes agorootparentNever mind Twitter these days. I still follow Elon for his rocket stuff but his fanboys are relentless if you criticize him or his universe even slightly. Or criticize aspects of capitalism even, like the one guy who said the purpose of a company is to make an impact, not primarily to make money. I think he was toast after they were done with him. ternnoburn 38 minutes agorootparentprevAnd Quark tried to learn, or adapt. He wasn't always successful, and he was cut out of a lot of situations where his behavior was considered unacceptable, but he did at least make some efforts. reply sabbaticaldev 3 hours agorootparentprevit does make it story more interesting tho reply tomp 3 hours agorootparentprevnext [7 more] [flagged] spillguard 3 hours agorootparentShe's a woman, so it's correct to call her a \"woman\". No agenda here, necessarily. reply cies 3 hours agorootparentI think user \"tomp\" means that \"a one man team\" basically means \"one person team\" in English (and many other languages). Saying \"one woman\" is shifting the attention to the fact that the one person dev team consists exclusively of women. Which, I think, is pretty cool and note worthy because it is uncommon. Say a startup is run from an tiny island in the pacific, that would also be noteworthy. To me the thing becomes \"woke\" when we are told not to use \"one man dev team\" to mean \"one person dev team\". Basically when it becomes political correct speech policing. But then the word \"woke\" is rarely defined, so it mean whatever to whomever at this point. reply afavour 2 hours agorootparent> To me the thing becomes \"woke\" when we are told not to use \"one man dev team\" to mean \"one person dev team\" Is it not a simply a more accurate term? Especially when it's literally a single person. A \"one man dev team\" that consists of a woman strikes me as unnecessarily confusing. We're constantly told about these woke scolds that police language but in this instance I'm just seeing conservative scolds trying to police language for no actual logical reason beyond \"I don't like it\". reply dom96 3 hours agorootparentprev> To me the thing becomes \"woke\" when we are told not to use \"one man dev team\" to mean \"one person dev team\" call it what you will, but yeah, you shouldn't use the word \"man\" to mean \"person\" reply sabbaticaldev 2 hours agorootparentprevso you want the title to be one man dev team which is composed by one woman? this is conservative wokeness reply Permit 3 hours agorootparentprev> people recognise when you have an evil agenda Can you not do this here? reply shadowgovt 3 hours agorootparentprev [–] I wish I could say it's surprising to me, but I've been here for a while. Hackers are not the philosopher kings that a generation before hoped they would be. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nadia Odunayo, founder and CEO of The StoryGraph, manages a reading community with over a million users as a solo developer, highlighting her determination and technical skills.- Her background includes experience as a software engineer at Pivotal Labs and coding education from Makers Academy in London.- Her story exemplifies the potential of a \"one person framework\" in tech entrepreneurship, balancing professional and personal interests like dance and reading."
    ],
    "commentSummary": [
      "StoryGraph, a book tracking app developed by a single developer, Nadia Odunayo, has reached 2 million users, sparking discussions about alternatives and the limitations of competitors like Goodreads.",
      "Nadia Odunayo is recognized for her significant contributions to the Ruby on Rails community, highlighting the impact of individual developers in tech.",
      "The discussion also explores the broader theme of small teams achieving substantial user bases, with comparisons to successful projects like Stardew Valley and WhatsApp."
    ],
    "points": 461,
    "commentCount": 187,
    "retryCount": 0,
    "time": 1734443622
  },
  {
    "id": 42443229,
    "title": "Moon",
    "originLink": "https://ciechanow.ski/moon/",
    "originBody": "Bartosz Ciechanowski Blog Archives Patreon X / Twitter Instagram e-mail RSS December 17, 2024 Moon In the vastness of empty space surrounding Earth, the Moon is our closest celestial neighbor. Its face, periodically filled with light and devoured by darkness, has an ever-changing, but dependable presence in our skies. In this article, we’ll learn about the Moon and its path around our planet, but to experience that journey first-hand, we have to enter the cosmos itself. Let’s take a look at the Moon as seen from space in all its sunlit glory. You can drag it around to change your point of view, and you can also use the slider to control the date and time: Loading... In this convenient view, we can freely pan the camera around to see the Moon and its marvelous craters and mountains from various angles. Unfortunately, we don’t have that freedom of motion in our daily experience – the Moon wanders on its own path across the daily and nightly skies. We can simulate these travels below, where you can see the current position of the Moon in the sky. You can drag that panorama around to adjust your viewing direction – this lets you see the breadth of the sky both above and below the horizon. By dragging the sliders you can witness how the position of the Moon changes in the sky across days and hours of your local time. As the Moon’s placement in the sky shifts, the little arrow will guide you to its position. You can also drag the little figurine on the globe in the bottom-right corner to see how the sky looks at that location on Earth. If your browser allows it, clickingtapping the button will automatically put the figurine at your current location. This may all feel quite overwhelming at the moment, but we’ll eventually see how all these pieces fit together: Loading... Over the course of one day, the Moon travels on an arc in the sky almost completing a loop around the Earth. As the days pass, the Moon’s illumination also visibly changes. You’ll probably admit that it’s a little hard to focus on the tiny Moon as it shifts its position in the sky. To make things easier to see, I’ll zoom in the camera and lock its position on the Moon: Loading... Notice that across a single day the Moon seems to rotate, and over many days it quite visibly wobbles. These wobbly variations let us occasionally see some hidden parts on the “edges” of the Moon, but our neighbor ultimately shows us only one of its sides. In our space-floating demo we could easily see the Moon from all sides, but on Earth we can never see most of the far side of the Moon. Over the course of days, the lighting on the Moon also changes dramatically. The line between the lit and unlit parts of the Moon, known as the terminator, sweeps across the Moon, revealing the details of its surface. Although the Moon has a spherical shape, the fully lit Moon looks more like a flat disk. In this article I’ll explain all the effects we’ve just seen, and we’ll also learn about gravity, ocean tides, and eclipses. Let’s begin by exploring how celestial bodies move through space and how their mere presence influences the motion of their neighbors. Motion in Space Let me introduce a little cosmic playground in which we’ll do our experiments. Inside it, I put a little planet that floats freely in space. You can drag the planet around to change its position. The arrow symbolizes the initial velocity of this body – you can tweak this velocity by dragging the dashed outline at the end of the arrow. To get things going, you can press the button in the bottom-left corner: Notice that I’m drawing a ghost trail behind the moving planet, making it easier to track its motion. As you can see, once you let the planet go, it travels through space in a straight line, only to eventually get out of visible bounds. Let’s complicate things a little by adding another body to this sandbox. You can tweak the positions and velocities of both bodies to see how their mutual presence impacts one another. I’m also marking the thin lines of trajectories that the bodies will take even before you let things go, making it easier to plan their motion: The motion we see now isn’t as straightforward as before. In some scenarios, the two bodies travel past each other after tweaking their initial trajectories. In other configurations, both objects roam through space together, permanently locked in a swinging dance. You may have also managed to make the two bodies run into each other. We’ll eventually see a more realistic visualization of that scenario, but in this simplified simulation when two objects collide, they just stick together and continue their coupled journey. What’s responsible for all these effects is the force of gravity acting on the objects. Let’s explore that interaction up close. As before, you can drag the two bodies around, and you can also change their masses using the sliders below: The arrows represent the force of gravity acting on the two bodies – the longer the arrow, the larger the force. For completeness, I’m displaying the values and units of masses and distances, but the numbers aren’t particularly important here. What matters is that when we increase either the mass of the first body m1 or the mass of the second body m2, the force of gravity grows too. Moreover, the magnitude of gravity also depends on the distance r between the objects. As bodies move farther apart, the gravity weakens. Notice how the forces acting on each body have the same magnitude, but they point towards the other body, which indicates an attractive force. If you paid close attention to the lengths of the arrows, you might have noticed that the force decreases quite rapidly with distance. We can visualize this with a plot, in which the white line shows the magnitude of gravity as a function of distance. More precisely, it shows that gravity is inversely proportional to the square of that distance: Let’s take a very brief mathematical interlude to describe what we’ve seen in more detail. All these dependencies are captured in the following equation for the force of gravity F, between two objects with masses m1 and m2 separated by distance r: F = G × m1 × m2 / r2 The gravitational constant G seen in front of the right-hand side of the equation is incredibly small, making gravity a very weak force. We have no issues lifting everyday objects despite the might of the mass of the entire Earth pulling them down. While the strength of gravity between any two bodies is equal, the resulting change in motion is not. You may recall from elementary physics classes that force F is equal to mass m times acceleration a. We can encapsulate this idea in a pair of simple formulas that tie these values for the first and second body: F = m1 × a1 F = m2 × a2 By plugging in the equation for the force of gravity F and reducing the masses, we end up with a set of two equations for accelerations of the bodies: a1 = G × m2 / r2 a2 = G × m1 / r2 Notice that the acceleration of the first body a1 depends on the mass of the second body m2. Similarly, the acceleration of the second body a2 depends on the mass of the first body m1. Let’s see this in practice in the demonstration below, where I’m temporarily making the big body twenty times more massive than the small body: Notice that the body with smaller mass drastically changes its course, while the motion of the larger body is only marginally affected. This tracks with our day-to-day experience, where every item left hanging in the air very visibly accelerates towards the staggeringly massive Earth, but our planet doesn’t jump out of its way to meet the falling object. Now that we understand that it’s the force of gravity that makes the bodies move towards each other, let’s do a better job of tracking the motions of these objects over time. Right now our camera is fixed in space, so the two bodies often fly out of visible bounds. Thankfully, we can easily fix this by moving the camera with the bodies. In the demonstration below, I’m presenting the same scenario from two different vantage points. On the left, I’m showing the scene from the familiar point of view that’s fixed in space – you can plan the trajectories of the two bodies on that side. On the right, you can see this simulation from the point of view of the camera that’s tied to the motion of the these objects. I’m marking the position of that camera with a white dot on the thin line joining the bodies. By dragging the slider you can move the camera between them: With the camera following the bodies we can now track their motion forever. More importantly, we can also see the relative motion of the two objects. When you make the bodies move together, you can witness how from the perspective of the teal body, it’s the yellow body that orbits around the teal body, but from the perspective of the yellow body, it’s the other way around. Better yet, if we position the camera halfway, or even anywhere else between the two bodies, both objects seem to orbit the camera. The perception of relative motion depends on the point of view, but there is one point that’s particularly useful for observation. In this next demonstration, I’ve added a little white trail to the camera itself. Watch how the path of the camera in space changes as you reposition it with the slider: In general, the camera traverses some squiggly path in space. However, there is one special position between the two bodies for which the camera travels in a perfectly straight line. This point is known as the barycenter, and it’s located at the center of mass of these objects. Let’s explore the concept of the barycenter a little closer. In the demonstration below, you can once again drag the bodies around to change the distance between them, and you can also use the sliders to tweak their masses. The center of mass of these two bodies is marked with a black and white symbol: The equation in the bottom part explains the placement of the center of mass of these two objects – it is located at a point where its distance from the first body r1 multiplied by that body’s mass m1, equals that point’s distance from the second body r2 multiplied by its mass m2. This simple rule becomes slightly more complicated when more than two bodies are involved. In those scenarios, the position of the center of mass is the weighted average of the positions of all the bodies, where the masses of these bodies serve, very appropriately, as weights. We’ll only be interested in the center of mass of two bodies, so the demonstration we’ve just seen fits our needs well. Notice that as the bodies move farther away, the barycenter also migrates to stay in the constant proportion of the distance separating the objects. Moreover, if one of the bodies is much more massive than the other, the center of mass could lie inside that larger body. In our space simulator, the mass of the teal body is three times the mass of the yellow body, so the barycenter of this system lies three-quarters of the way between the yellow and teal objects: The motion of the barycenter shows us that the tangled dance of two celestial bodies hides a much simpler linear motion through space and some additional motion of the two bodies around that barycenter . Let’s try to see that other motion more clearly by making one more modification to the right side of the demonstrations we’ve seen. Notice that the trails left by the bodies linger in space, but ideally, we’d also want to see the paths taken by the bodies relative to the moving camera. To make this work we can attach a little drawing plane to the camera itself – I’m outlining that plane below with a thin rectangle. Then, as the bodies move around, they can trace their trails on that plane as well: With this new method we can see the paths the bodies took relative to the moving camera . When seen from this perspective, we can finally reveal that, in most practical scenarios, the two orbiting bodies trace ellipses relative to each other. Depending on the initial conditions, some of those ellipses are larger, and some are smaller. Some are almost circular, and some are quite elongated. Changing the position of the camera with the slider changes the relative sizes of these two ellipses, but they maintain their overall proportions. The ellipse of motion of one body seen from the perspective of the other is the same for both bodies, it just shifts in space. As you may have seen on this blog before, an ellipse can be more formally characterized by its eccentricity and the size of its semi-major axis, which you can control using the sliders below: Eccentricity specifies how elongated an ellipse is. It can be defined as the ratio of the length of the dark pink segment to the length of the semi-major axis. That segment spans the distance between the center of the ellipse and one of the two focus points, which are also jointly known as foci. When we watch orbital motion from the perspective of the orbited body, that body is always in one of the focus points of the orbital ellipse of the orbiting body. I’ve also marked two special points on the orbital ellipse. At apoapsis, the orbiting body is at its farthest distance from the orbited body, and at periapsis the orbiting body is closest to that body. These two points are collectively known as apsides, and the line joining them is known as the line of apsides. The simple rule for remembering which apsis is which is that apoapsis is the one that’s farther away from the orbited body. We’ve just described the orbital ellipse and its apsides as seen from the point of view of the larger body, but in our cosmic playground we’ve seen how moving the camera around with a slider can change the perception of motion: With a two-body system like this one we actually have some flexibility in describing which body orbits which. We typically say that it’s the less massive object that orbits the more massive one, but the observer on the smaller body would just see the motion of the larger neighbor around it. For us, it will be often useful to describe things from the point of view of the barycenter – we’ve seen earlier how that special point lets us decompose the motion of two solitary bodies into the movement on a straight line and the orbiting motion around that barycenter. That particular viewpoint also lets us explain another irregular motion we can see in these elliptical orbits. Notice that as the two bodies are close to each other, they swing across their trajectories much faster. You can see it best when looking at the dashed segments I’ve drawn on the elliptical orbits – traversal of each brighter or darker section takes the same amount of time. These lines are visibly longer when the bodies are close, which reflects their faster motion as they travel longer distance over the same period. This non-uniform motion can also be seen in the angular velocity of the orbital motion, which describes how many degrees per second an orbiting body sweeps through. In this next demonstration the blue line rotates with constant angular velocity, so in every second it goes across the same number of degrees. As you can see, the orange line joining two bodies rotates with varying speed: Notice how the orange line is sometimes ahead of and sometimes behind the blue line, which shows that the orbital motion doesn’t have a constant angular velocity. This unusual behavior is more easily explained with the following contraption, where I put the two bodies on a giant bar that spins around on an axis placed right at the center of mass of the two bodies. Using the slider you can change the distance between these objects: As the bodies get closer, the rotation speeds up. Conversely, as the bodies move farther apart, the rotation slows down. You can easily recreate a version of this experiment by holding heavy items in your hands and spinning on a desk chair with your arms spread out. As you pull them towards your torso, your rotation will speed up. These are examples of conservation of angular momentum in which the speed of revolution and the mass distribution of a system are inherently tied together. Broadly speaking, when we double the distance from the axis of rotation, the angular velocity becomes four times smaller. The space playgrounds we’ve looked at earlier work just like the demonstration with the bar, but instead of a slider, it’s the force of gravity that determines the distance between the bodies. Gravity pulls the objects closer together, increasing the speeds at which they swing by each other. As the bodies move past their closest distance, that increased speed shoots them out away from each other and the cycle continues. The details on how this action creates elliptical paths are beautifully covered in the video on Feynman’s Lost Lecture, but for our needs it will be enough to just witness once more how all the initial values of masses, positions, and velocities of the two bodies decide everything about their motion: With a firmer grasp on orbital motion in space, we can finally see how everything we’ve learned affects movement of our planet and its closest celestial neighbor. Moon and Earth Let’s first look at the Moon and Earth side by side to compare their masses and sizes in imperial unitsmetric units:Moon Earthmass 0.016190.07346 1.3175.972 × 1025 lb24 kg mean radius 1079.61737.4 3958.86371.0 mikm volume 0.52702.1968 25.9876108.321 × 1010 mikm3 mean density 208.83344 344.25513 lb/ft3kg/m3 The Earth’s mean radius is only around 3.67 times larger than that of the Moon. Since the volume of a sphere grows with the third power of its radius, and the Earth is on average much denser, our planet’s mass ends up being around 81.3 times larger than the Moon’s. Let’s try to replicate this table in our space simulator, where I added two bodies with sizes and masses matching those of the Earth and the Moon. Let’s see how these values affect the motion of the two objects: With our simulated Earth being so massive, we can quite easily make this Moon orbit the Earth with various ellipses. Unfortunately, while this simulation correctly mimics the relative sizes of the real Earth and Moon, it doesn’t reflect the cosmic scale of the distance between these two bodies. Let’s see how far away the Moon really is. In the demonstration below, you can use the slider to zoom away from the Earth until the Moon’s position becomes visible: If you drag the slider all the way to the right, you’ll notice that I’m actually marking three distances between the centers of the Earth and the Moon. The orbit of the Moon doesn’t form a perfect circle, so the separating distance varies as the Moon gets closest to the Earth at periapsis, and farthest away at apoapsis. The values shown here in mileskilometers are the predicted maximum, mean, and minimum of that distance in the 21st century. Let’s see the orbit of the Moon in more detail. The following demonstration shows the motion of our neighbor from the perspective of the Earth itself. You can drag around the following demonstration to change the viewing angle. The slider lets you control the speed of time: With all the sizes and distances replicated realistically, it may be hard to see these tiny bodies. To make things more legible, you can press the button in the bottom right corner to toggle between the real and ten times larger artificial sizing of these bodies. With this three dimensional view we can now see that the Moon’s motion lies in the orbital plane that I’m marking with a faint gray disc. To help us orient ourselves in space, I’ve also added a line that marks a fixed reference direction pointing at some very distant stars. On average, it takes the Moon 27.322 days27 days, 7 hours, and 44 minutes to complete the whole orbit, as measured by crossings of the reference line. That period is known as the sidereal month, where sidereal means “with respect to stars”. This is only one of the four different types of lunar months that we’ll explore in this article. As the Moon orbits the Earth, it traces the familiar elliptical shape. We can quite clearly see how the elliptical eccentricity shifts the Moon’s path relative to the perfect circle of the visualization of the orbital plane that I’ve drawn above. Let’s take a closer look at some of the parameters of the Moon’s orbit. In this next demonstration I’m using the current position and velocity of the Moon to calculate an ellipse that best describes the Moon’s orbit at that moment of time. I’m drawing this ellipse with a dashed line, while the solid trail shows the actual path the Moon took: Since we’re making the ellipse fit the current orbital motion, this idealized ellipse matches the actual trail very well in the vicinity of the orbiting Moon. However, farther away from the Moon this best-fitting ellipse diverges from the path the Moon actually took. This shows us that while it’s pretty close, the Moon’s trajectory doesn’t form a perfect ellipse. As we see in the labels, both eccentricity and the length of the semi-major axis of this “currently best-fitting” ellipse vary over time. Measured over a long period, the eccentricity of the Moon’s orbit has the average value of 0.0549, while the semi-major axis has the average length of 239,071 mi384,748 km. Moreover, the fitted orbital ellipse not only changes its shape, but also its orientation. The line of apsides of the ellipse which joins the apoapsis and the periapsis wobbles over time in a quite chaotic manner. These effects happen because the Earth and the Moon aren’t the sole bodies in space – they’re both part of the Solar System. True to its name, the Solar System is dominated by the Sun itself, and it’s primarily the effects of the Sun’s gravity that cause all these perturbations of the Moon’s orbit. We’ll soon explore the influence of the Sun in more detail, but for now let’s focus on the changes of the positions of apoapsis and periapsis. In the demonstration below, I’ve made time flow even faster than before. Additionally, every time the Moon is at its closest to the Earth, that is when it’s at the periapsis, I’m leaving a little marker on the orbital plane: Notice how the line of apsides wobbles back and forth, but across many months it overall makes steady progress rotating, when seen from above, in the counter-clockwise direction. Averaged over long time, this line of apsides makes a full rotation in 8.85 years8 years and 310 days, which defines the period of the Moon’s apsidal precession. The markers that I drop when the Moon crosses the periapsis measure the anomalistic month. Notice that the lengths of anomalistic months vary a lot as they happen on different parts of the orbit. Sometimes it takes the Moon less than 25 days to get closest to the Earth again, but sometimes it takes it over 28 days to reach periapsis again. Over long time the anomalistic month has a mean length of 27.554 days27 days, 13 hours, and 3 minutes. This period is a bit longer than the 27.322 days27 days, 7 hours, and 44 minutes of the sidereal month, which is tracked by the crossings of the reference line. When averaged over time, the line of apsides rotates steadily in the same direction as the Moon’s orbital motion, so it takes the Moon a bit more time to catch up to periapsis. All the demonstrations we’ve seen also show one more effect that we didn’t account for in our simple playground simulations – both the Earth and the Moon spin around their axes. You can see this more clearly in the demonstration below where I glued a blue arrow to the surface of the Earth, and a gray arrow to the surface of the Moon: When viewed from the side, we can see that the axes of rotations of these two bodies aren’t neatly perpendicular to the orbital plane, and they also spin at very different rates. Our planet takes roughly 23.93 hours23 hours and 56 minutes or almost one day to complete a full revolution and point towards the reference direction again. The Moon rotates much slower, taking 27.322 days27 days, 7 hours, and 44 minutes to revolve just once and align with that direction again. From above we can see that the gray arrow fixed to the Moon’s surface generally points towards the Earth, as indicated by the thin line joining the two bodies. If you pay close attention, you’ll notice that this arrow is sometimes pointing a bit ahead of that direction and sometimes a bit behind that direction. This is a consequence of the Moon’s non-circular orbit – we’ve seen earlier how the angular velocity of an orbiting body changes as it sweeps through its orbital ellipse. The Moon rotates around its axis with more or less constant speed, but the Moon’s angular position relative to the Earth doesn’t advance at a constant rate. As a result, the two rotating motions don’t always perfectly cancel each other out. In a close-up view of the bodies you might have also noticed that the rotation axis of the Moon is tilted relative to its orbital plane. Similarly, the axis of rotation of our planet is also tilted relative to that plane. Let’s briefly switch our point of view to align ourselves straight-up with the Earth’s rotation axis: From this perspective we can see that the Moon’s orbital plane is inclined to our planet. Notice how the Moon’s position relative to the Earth changes during its orbital motion – it is sometimes “above” and sometimes “below” our planet, revealing the truly three dimensional aspects of the Moon’s motion. All the orbital observations we’ve made will help to explain some of the effects we’ve seen at the beginning of this article, where we looked at the Moon through the eyes of an observer on the ground. Before we investigate these effects, we need to build a bit more intuition on how objects in space look to someone viewing them from the surface of Earth. Eyes on the Heavens Let’s first place ourselves on Earth and look at the sky in which I artificially put three colorful celestial bodies. You can drag the demonstration around to change which part of the sky you’re looking at. If you lose track of these bodies, the little arrows will guide you back to their area of the sky: Loading... Although the markers of the compass directions are of some help, it may be quite hard to grasp how this view from the Earth’s surface corresponds to the more external view from space we’ve gotten used to. Let me clarify things in the next demonstration, where the left side shows the same view we’ve just seen, and the right side shows the same scene, but as seen from space. I’ve also outlined the sky view on the left with the four colored lines – as you pan around the landscape on the left, you can see that square outline reflected on the right. I’ve also added a figurine that represents a vastly enlarged observer standing on the ground. The figurine’s body and its right hand always point in the current direction of observation: Loading... With that external view, we can see how the observer on the ground can’t see the sky in every possible direction. Half of it is obscured by the Earth itself, with the horizon clipping the whole breadth of the surrounding sky to only the visible hemisphere. Moreover, notice how the actual size of an object doesn’t match its size seen in the Earthly observer’s sky. For example, both yellow and teal bodies are of the same physical size, but the latter looks smaller in the sky. Similarly, the pink body is physically larger than the yellow one, but they share similar size from the observer’s point of view. We can understand these sizing effects with the help of cones that shoot out from the position of the observer towards the bodies in space. Note that these cones start on the ground here, because the actual observer is much smaller than the gigantic illustrative figurine. The size of the intersection of those cones with the hemisphere of the sky, or the size of the projected area, determines the visible size. Intuitively, the farther away the object, the smaller it appears. If the projection occupies a larger fraction of the total hemisphere, the object will look larger as well. We can conveniently describe the size of objects in the sky by measuring the angle spanned by the visible cone. In the demonstration below, I’m showing a flat side view of this cone. You can drag the yellow body around to change its distance from the observer. You can also use the slider to change the size of that body: The closer the object is to the observer, or the larger the body, the greater the angle of the visible cone. That angle is known as the angular diameter or angular size of the observed object. Having experienced how objects in the night sky may look at a fixed moment in time, let’s see how the Earth’s rotation affects observations done from the ground. In the demonstration below, you can scrub through time with the slider to witness the effects of the spin of our planet: Loading... This scene may seem a bit contrived, because the three objects are just magically floating in space at fixed positions. Fortunately, it’s a decent representation of how all the stars in the night sky appear to Earthly observers – they’re distant enough that over the course of a day they essentially don’t move relative to the Earth’s center. As our planet spins, these three objects seem to rise over the horizon, travel across the visible sky, and then set below the horizon again. You’ll probably agree that it’s a little annoying to have to manually keep panning through the night sky to look at these objects, so on the left side of this next demonstration I’m automatically adjusting the viewing angle to track the teal body. On the right side, I’m locking the camera on the figurine itself. Don’t be misled by what you see here – the Earth is still rotating around its axis, the camera just rotates with it: Loading... As seen through the observer’s eyes on the left side, the other objects now seem to rotate around the teal one, but this is purely a consequence of the observer turning on the ground to keep facing the teal body. You may have experienced something similar when watching an airplane flying over your head. As the plane is approaching, its front is closer to you and its tail is in the back, but after the plane has passed over, you see the plane’s tail as being closer to you, and its front is more distant. In your eyes the plane has rotated, but in fact the plane has kept its course the entire time, and it was you who turned to keep an eye on it. When these celestial bodies disappear beneath the horizon, it becomes impossible to track them, but thankfully in these computer simulations I can make the Earth transparent, giving us an unobstructed view of the full sphere of the surrounding space: Loading... With this approach we can now see the entire trajectory of the three objects as an observer on Earth sees them. Because these objects don’t move relative to the center of our planet, they travel on closed paths, returning to where they came from after the Earth completes one revolution around its axis over the course of 23.93 hours23 hours and 56 minutes. Let’s bring back the Moon into the picture. In the simulation below, we can see the Moon in the starry sky as seen from the surface of the Earth. Note that I removed all the visual effects related to sunlight, including the daytime blue sky and any illumination changes on the surface of the Moon itself. We’ll bring in those effects later on, but for now we’ll just look at the artificially lit Moon over the course of the next 24 hours – you can scrub through this time with the slider. You can now also drag the little figurine around the globe to change the observer’s location, or clicktap the button in the corner to jump to your location: Loading... Notice how small the Moon actually is in the sky – it only spans around 0.5° of the viewing angle. Just like our colorful objects did, the Moon also travels across the sky as the Earth rotates. However, because the Moon moves relative to the center of our planet, it doesn’t quite close up its path. This is easily observable from space: Notice that over the course of 24 hours the Moon moves ahead on its orbit, so a bit more time has to pass for the Earth to rotate to have our neighbor be over roughly the same spot on the Earth again. Moreover, the inclined orbital plane shifts the Moon to be a little lower or higher relative to the Earth, so its arc in the sky shifts too. Let’s go back to observing the Moon from Earth. To see our neighbor more clearly I’ll increase the zoom level of the camera, and I’ll lock it on the Moon: Loading... When viewed this way, the Moon seems to rotate over the course of one day, but this effect is purely a consequence of the observer turning around to face the Moon – we’ve already seen this behavior with colorful objects seemingly rotating in space. The observer stands up vertically on the ground, so as the Earth rotates, the observer’s “up” and “towards the Moon” directions change in space. How much these directions change depends on the latitude of the observer’s location. When seen from the equator, the Moon “rotates” quite rapidly as it passes over the observer’s head. On the North and South Poles, the “up” direction is fixed in space, which removes that daily rotation. Notice that even on the poles the Moon still visibly turns a little over the course of a day. To investigate these subtler aspects of the Moon’s motion in the sky we have to give ourselves a bit more time for observations. In the demonstration below, you can track the Moon over the next 30 days. You can still drag the figurine to some other location, but the observer’s Moon-facing rotation can make things pretty nauseating outside of the poles, so you can always get back to that stationary location: Loading... Notice that over the course of a month the Moon wobbles visibly, and it also changes its size. The oscillations we see here are caused by the Moon’s orbital motion. Let’s see this more clearly from space by drawing the cone of visibility of the Moon for the observer on the surface of the Earth. Unlike in previous examples, where I’ve aligned the rotation of the camera to the reference line, this time I’ve synchronized our perspective with the orbital motion of the Moon, giving us an unchanging perspective on that body: As we’ve discussed earlier, the Moon’s orbit around the Earth isn’t perfectly circular. The Moon changes its distance to our planet, which affects how large it looks in the sky. Below you can see a side-by-side comparison of the Moon’s visible size when it’s at apoapsis and periapsis: Loading... Loading... The Moon’s orbital motion is also responsible for the periodic wobbles, which we can see clearly by once more gluing an arrow to its surface: We can see from above that the Moon appears to wobble from side to side, because the angular speed with which it sweeps the orbit varies over time, while its angular speed with which it rotates around its axis is almost constant. Similarly, in a side view we can see that the axis of rotation of the Moon is tilted relative to its orbital plane, so we sometimes see more of the Moon’s top, and sometimes more of its bottom. All the effects we’ve seen here are known as librations. Over the course of many days, librations make it possible to see around 59% of the Moon’s surface. However, because of the Moon’s synchronized spin and orbital motion, a large part of the Moon’s surface is never visible from Earth. It’s finally time to investigate how the Moon got locked into that motion by taking a more detailed look at gravity and the structure of celestial bodies. Gravity at Scale So far we’ve only been experimenting with gravitational interactions between two objects, but it’s time we vastly increased the number of participating entities. In the demonstration below, I randomly distributed over 1200 bodies – they all gravitationally attract each other: We’re watching this scene from afar, so the individual bodies we see here are very big – each on the order of dozens of mileskilometers across. Initially, these objects move very slowly, but the mutual gravitational forces consistently accelerate them towards each other, increasing their speed and kinetic energy. This simple simulation doesn’t reflect this, but once these bodies collide, this energy gets released by heating up the matter constituting the objects. When hot enough, the matter loses its solid form and starts to behave more like a fluid that can relatively easily change its shape. The pushing pressure from the surrounding neighbors and the heat from the decay of radioactive isotopes also help to maintain that liquid form. When in this state, this mass of matter can’t really maintain any rigid shape, and after wobbling for a while, it reaches an equilibrium forming a sphere. When no other forces are involved, this liquid spherical shape balances itself perfectly – any mountain that stands out gets gravitationally pulled towards the center, and any valley gets squeezed out by the surrounding matter trying to fill the empty space. In the simulation we’ve just seen, all the bodies started frozen in space. Let’s see what happens when we give these objects some initial random velocity: After a while we end up with the similar spherical shape, but this time this blob rotates. What we’re witnessing here is another example of the conservation of angular momentum in action. From our previous examples you may associate angular momentum with some kind of spinning or orbital motion, but even the simplest movement on a straight line contains a rotational component when seen from an appropriate point. Below you’ll find a replica of the very first space simulation we’ve played with in this article, but this time I’m also drawing an additional dashed line spanned between the yellow planet and the central blue point: That dashed line turns as the body moves in a straight line, revealing the rotational motion relative to the blue point. Even in this scenario the angular momentum of the system is maintained. Through all the collisions in our complex system the velocity and the angular momentum of each of the hundreds of bodies constantly change, but, relative to some fixed point, the sum of the angular momenta of all the bodies remains constant. Whatever original value of angular momentum this system had, persists forever. In the initially chaotic motion of all the bodies there is some average amount of rotational motion. Once all these bodies get closer to each other, the angular velocity grows high enough to be visible. This is the exact equivalent of two planets orbiting each other more quickly as the distance between them decreases, but it happens here at much larger scale. There is one more aspect of these self-aggregating blobs that we should explore. In this next demonstration, one fourth of the objects is colored blue. These bodies are much denser than the others, therefore, each is also more massive: Notice that in the final liquefied planet these denser objects have a tendency to aggregate at the center of the body. We’re basically observing buoyancy in action, where this denser material sinks to the “bottom” of the planetary blob and the lighter one floats to the surface. These accumulation, or accretion processes that I’ve crudely simulated with a small number of bodies, happened at absolutely massive scale during the formation of Earth and other planets. The whole fascinating history of the early Solar System is beyond the scope of our discussions, but the simple simulations we’ve seen highlight the origins of the Earth’s rotation, and illustrate why it’s differentiated with heavy iron core in the middle. A few different theories have been suggested to explain the origin of the Moon itself. These days the leading one is the giant impact hypothesis, in which a large body hit the early Earth around 4.5 billions years ago. Scientific opinions differ not only on the size, speed, and composition of the impacting body, but also on the subsequent process of formation of the Moon from the resulting debris. Some earlier papers assume the Moon simply formed from the matter scattered into space after the collision. Other authors suggest that the energy released during impact created a huge, partially vaporized cloud of matter from which small moonlets condensed and accreted to create the Moon. Some other recent research shows with beautiful computer simulations that the proto-Moon may have formed immediately after the impact. Any theory of the Moon’s origin has to end up with a similar state as the Earth and the Moon are in right now. For example, if we estimate that during the collision only a small amount of matter got ejected out of reach of the Moon’s and Earth’s gravity, the total mass of the two bodies before and after the impact should be more or less the same. Moreover, the Moon is on average much less dense than Earth, because the Moon’s iron core is comparatively much smaller than that of Earth’s. If we assume that the colliding body and proto-Earth formed in the same area of the Solar System and therefore had similar composition, then this implies that a large part of the impacting object’s iron core must have transferred to our planet. The Moon and Earth also share very similar ratios of isotopes of some elements, suggesting that the ejected material that formed the Moon was a mix of the proto-Earth and the other proto-planet. Let’s try to recreate some simple collision scenarios using our rudimentary simulations. In the demonstration below, you can drag the impacting body around and change its initial velocity, similarly to how we did this in the introductory orbital simulations: We don’t know what the initial conditions of this collision actually were, but when everything finally settled, we most likely ended up with the Moon orbiting Earth and both bodies spinning around their axes. The simulation below gives a rough overview of this situation. Note that it doesn’t try to accurately reflect the distances, speeds, or surface details involved in those early stages, but it will be enough to help us explore the other details of gravitational effects between the Earth and the Moon: Let’s try to first understand what forces the Earth imposed on this early Moon when we incorporate the more fine-grained scale of gravitational interactions we’ve been playing with. In the demonstration below, I put three small bodies far away from the Earth. Initially, these three objects are evenly spaced, but notice what happens to the distances between them over time: The dashed circles show the original positions of the pink and teal objects relative to the central yellow body. Quite clearly, the three bodies seem to drift apart. Recall that the force of gravity is proportional to the inverse of the square of distance between the objects. When an object is close to its massive neighbor, it’s also close to each tiny parcel of matter that makes up that neighbor. We can visualize this with a plot and arrows that show the Earth’s gravitational forces acting on these equally spaced objects placed at a varying offset – you can control it with the slider below: The pink body is closest to Earth, so it experiences the strongest force and the strongest acceleration. Conversely, the teal body is the most distant, so it feels the weakest force and it doesn’t increase its velocity as fast as the closer bodies. It’s this variation in forces that increased the distance separating the objects in the previous simulation. Even though all three bodies were moving towards the planet, from the perspective of the central body both its neighbors moved away from it. It’s easiest to understand this effect by calculating the difference between the forces acting on that central body and its neighbors. I’m drawing these force differences with yellow arrows that have been scaled up to be more legible: These yellow arrows show actual forces on the pink and teal body relative to the yellow body. As seen by the yellow body, its two neighbors are pulled away by these so-called tidal forces, which arise from differences in gravity experienced by the bodies. Our early Moon isn’t immune to these effects either. Because of its orbital motion it doesn’t crash into our planet, but its parts closest to the Earth feel a stronger pull than the Moon’s central sections. Those central parts are in turn pulled more forcefully than the Moon’s parts most distant from the Earth. We can visualize these forces by putting the gravity arrows on small sections of the Moon: If we then calculate the difference between the force acting on each of those small sections and the force acting on the center of mass of the Moon, we can visualize the tidal forces acting on the Moon itself. For clarity, I’m drawing the arrows much larger than the gravity differences actually are: As you can see, the tidal forces are trying to flatten and stretch the Moon both towards and away from the Earth. Thankfully, the self-gravity of the Moon is strong enough and the Moon is far away enough that these differences in the Earth’s gravity don’t pull the Moon’s body apart. However, the Moon does stretch a little, forming an elongated shape. In the demonstration below, you can visualize this stretching with the second slider, but be aware that the distortion you’re playing with here is vastly exaggerated: As this early Moon keeps spinning around its axis, its different parts get closer and farther away from the proto-Earth. The elongation travels across the Moon’s surface, continuously morphing its shape. As you can imagine, it takes a lot of energy to deform a celestial body, and some of this energy inevitably gets lost due to friction. These losses introduce a delay to the entire deformation process, and the maximum elongation is reached a little after that area of the Moon has been closest to the Earth. As a result, the elongated bulge doesn’t point directly at the Earth, but it’s carried ahead by the spin of the Moon – the elongated shape is a bit off-axis. In the demonstration below, you can play with an overemphasized degree of this delay: Let’s pause here for a minute to understand what effect the tidal forces may have on this stretched and skewed body. In the demonstration below, I’m drawing a long bar that gets pulled by two ropes attached to its ends. Using the slider you can scrub through time to see how this contraption would behave when pulled by these forces: Notice that initially the bar is rotated, so it’s a little off-axis with the directions of the pulling forces. This gives the ropes some leverage, and the pulling forces rotate the entire bar clockwise until it’s aligned with those forces. This is very similar to what happens to our spinning early Moon deformed by tidal forces. Since the elongation is slightly off-axis, the tidal forces rotate the Moon clockwise, which gently decreases the Moon’s existing counterclockwise spin! The actual elongation and the off-axis skew of the early Moon were much smaller than what I’ve depicted here, and its non-circular orbit complicated things even more, but the net result of tidal forces was to slow down the Moon’s spin until it was synchronized with the Moon’s average orbital motion. In this whole process the angular momentum of the Moon had to be conserved, so as the Moon’s spinning motion slowed down, its distance from the Earth increased. This kept the overall balance of how quickly all the matter rotated and how far from the center of rotation it all was. In the last few paragraphs we’ve only focused on the effects of Earth’s gravity on the Moon, but everything we’ve discussed also manifests in the influence of the Moon’s gravity on Earth. The Moon also creates a slightly elongating bulge on Earth that travels across our planet as Earth rotates. Earth also used to rotate faster, but tidal forces slowed down its rotation, transferring some of the angular momentum from the rotational motion to the joint orbital motion. This has also increased the distance between the two bodies. Even today, Earth is very gently slowing its rotation, with the average day getting shorter by about 2 milliseconds per century. As a result, the Moon is also moving away from our planet at the rate of around 1.5 inches3.8 centimeters per year. Part of the present-day energy dissipation is caused by the deformation of Earth itself, but most of the energy gets lost in the oceans in the form of tides. The forces driving the ocean tides have the very same nature to the ones we’ve just discussed. To understand how they work, let’s look at a fictional planet completely covered with a deep layer of water and orbited by a smaller neighbor. The white arrows symbolize the neighbor’s gravity forces acting on the water at that location. The slider lets you control the speed of time: Water closer to the orange body experiences a stronger pull than the water farther away. The solid part of the water-covered planet also gets gravitationally pulled by the neighbor with some force. Like before, we can calculate the difference between the force acting on each parcel of water and the force acting on the center of the solid body, which will show us the tidal forces acting on the water: Subject to these tidal forces the surface of the water will deform until it reaches a new balance with the gravitational forces of the planet itself. It’s actually pretty hard for tidal forces to just raise the water against the force of gravity of the planet. The tidal deformation is primarily caused by “sliding” the water away from the regions where the tidal forces act tangentially to the surface. Here we’ll make an idealized assumption that, on this planet, water can very quickly travel and deform under the influence of gravity. It’s not super realistic, but this simplification will help illustrate some fundamentals of tidal motions. The demonstration below shows an exaggerated view of that tidally deformed ocean. I’ve also added a little figurine that you can drag around to more easily see the water level at that location: The plot below shows the water level over time at the observer’s location. As the planet spins, different areas of the ocean are directly in line with the orbiting body, so the water level oscillates over time. Notice that the tidal forces create two bulges, so during a single rotation of the planet the observer experiences two high tides and two low tides. In this perfectly aligned system the smaller planet orbits the bigger one right around the equator and that’s where the water bulges have their highest amplitude, creating the largest difference between low and high tides. As you drag the observer to the region where the bulges aren’t as pronounced, the tides become weaker. Let’s disturb this equatorial symmetry by making the orbit of the small body inclined relative to the big planet: Notice that we still experience two bulges, but they no longer happen at the same latitude. In most areas the two high and low tides are no longer even, because the observer may be closer or farther away from the nearby bulge. This creates some additional once-per-day variation on top of the regular twice-per-day oscillation. Moreover, the body’s motion on the inclined orbit now also moves the bulges up and down the globe, adding once-per-month variation to these tidal amplitudes. Any additional body present in the system would also exert its tidal forces, creating another pair of bulges. As the relative positions of these bodies change, their bulges could line up to create tides of greater amplitude. These bulges could also be shifted relative to each other with a low tide caused by one body partially cancelling out the high tide from the other. What we’ve explored here is only a simplified model of what would happen on a planet fully covered with water. For example, we didn’t account for tidal deformation of the crust itself, or any latency in the water displacement caused by energy dissipation. However, the underlying principles roughly match the system that drives the tidal forces on Earth. The Moon, and to a lesser extent the Sun, both impose tidal forces on the bodies of water on Earth. How the water on Earth reacts to these forces is very heavily influenced by geography of the land itself. The size and placement of the continents and islands, the shape of coastlines, gulfs, bays, and straits, the depth of the sea floor, they all significantly affect the actual amplitude and frequencies of tides observed at any given location. In some areas of the world the mean difference between a high and low tide can reach over 38 feet11 meters, but in some seas the tides can be barely perceptible. A global view on the tidal motions reveals complicated patterns that clearly don’t neatly fall into the simple bulge model, but the local changes in tide levels can still be broken down into cycles that follow the relative motions of the Moon, the Earth, and the Sun. We’ve already seen some other glimpses of the influence of the Sun, like how it affected the Moon’s orbit by changing its eccentricity and semi-major axis. To understand the full impact of the Sun on the Moon’s trajectory we have to finally properly introduce our home star. Moon, Earth, and Sun Let’s put the three celestial bodies side by side to compare their statistics in imperial unitsmetric units:Moon Earth Sunmass 0.016190.07346 1.3175.972 438,4701,988,500 × 25 lb24 kg mean radius 1079.61737.4 3958.86371.0 432,300695,700 mikm volume 0.52702.1968 25.9876108.321 338,800 × 1010 mikm3 mean density 208.83344 344.25513 87.91408 lb/ft3kg/m3 With a mass 332,950 that’s times larger than that of the Earth, the Sun completely dwarfs the other two bodies. Even though the Sun has much lower density, its radius is still over 109 times larger than our planet’s. At normal zoom scale, you may barely be able to see the speck of the Earth, and the Moon will most likely be almost completely invisible. To remedy this, you can use the slider to zoom in on all three bodies letting you witness how absolutely massive the Sun is. The distance to the Sun is even more staggering. In the demonstration below, you can zoom away from the Earth-Moon system until our star is seen: The seemingly large distance between the Earth and the Moon almost completely disappears when put in this perspective, and the smallness of those two bodies makes them vanish into the darkness. The values shown here in mileskilometers are the maximum, mean, and minimum distance between the Sun and the barycenter of the Earth-Moon system in the 21st century. While the distances and sizes we’ve just seen are correct, the positions and motions of the Earth and the Moon relative to the Sun are a little more involved. In the demonstration below, you can see a three dimensional simulation of the Earth and the Moon on their joint path around the Sun. You can drag it around to change the viewing angle, use the first slider to zoom in on these bodies, or tweak the speed of time with the second slider: With these three bodies involved, we can no longer describe the entirety of the motion of the Earth and the Moon in a simple, two dimensional manner. Let’s dissect what’s going on by first focusing on the path of the Earth-Moon barycenter around the Sun: From a top down view, we can clearly see the familiar elliptical shape. When observed from the side we see that the motion of the barycenter lies in a flat plane, which I’m highlighting with blue color. This plane is known as the ecliptic. Traditionally, the ecliptic has been defined as the plane of motion of the Earth around the Sun, but the modern definition is based on the average motion of the barycenter of the Earth-Moon system. If you zoom in on the barycenter up close, you can see how the Moon and, to a much lesser extent, the Earth, bob up and down through this plane as they orbit around the Sun. In some sense both bodies orbit the Sun, and the Moon also orbits the Earth at the same time. With the Sun present, the barycenter no longer travels on a straight line like it did in our simple two-body space simulations. In general, the gravitational motion of three bodies can get very chaotic, but, luckily for us, the Moon and the Earth have settled into a balanced and predictable system. The Earth-Moon barycenter is located inside the body of our planet, so the barycenter’s motion around the Sun very closely matches the familiar yearly motion that we experience on Earth. You can read more about the Earth’s journey in my earlier article, but for our needs here it will be enough to assume that it takes the Earth-Moon system roughly one year to orbit the Sun. Let’s take a closer look at the motions of the Earth and the Moon around their barycenter. We’ve already discussed how the motion of the Moon around the Earth forms the Moon’s orbital plane – I’m marking it with a faint gray disc in the demonstration below: The orbital plane of the Moon doesn’t lie flat in the ecliptic, but it is instead inclined to it at an angle. This inclination angle varies a bit over time, reaching an average value of 5.145°. The inclination angle lets us specify one aspect of the orientation of the Moon’s orbital plane, but there is also another angle we need to consider. Notice that the intersection of the inclined orbital plane with the ecliptic forms a straight line called the line of nodes: This line gets crossed by the Moon in two places: on its way below and above the ecliptic. These two points are known as orbital nodes. The red point is the descending node because the Moon submerges, or descends under the ecliptic. Similarly, the green point is the ascending node because the Moon rises, or ascends above the ecliptic. To orient the line of nodes in space, we have to bring in our reference direction. The angle between that reference direction and the ascending node direction of the line of nodes is known as the longitude of the ascending node: Even when running this simulation 200,000 times faster than real life, the longitude of the ascending node seems to fluctuate only a little, keeping the line of nodes relatively stable in space. However, when we speed things up even more, we begin to notice some predictable movement: The line of nodes consistently rotates over time, which we can see reflected in the angle very slowly looping through all 360 degrees. This effect is known as nodal precession and it is primarily caused by the gravitational force of the Sun disturbing the Moon’s path. When seen from above, the orbital plane of the Moon rotates clockwise, which is the opposite direction of the Moon’s orbit around the Earth. It takes around 18.61 years 18 years and 223 days for the orbital plane to complete one rotation. The period between passages of the Moon through the ascending node is known as the draconic month. Because of the nodal precession, it takes the Moon a little less time to get back to the ascending node than it takes it to cross the reference line, so a draconic month averages at 27.212 days27 days, 5 hours, and 5 minutes. The nodal precession has two other consequences for the relative motion of the Earth and the Moon, but to see them, we first have to visualize the spinning motion of these two bodies in more detail. Below I’ve marked two angles between the axes of rotation of the Earth and the Moon, and the direction perpendicular to the ecliptic plane. This measures the axial tilt of these bodies relative to the ecliptic: The Earth’s axis of rotation holds steadily in space, with the current value of its axial tilt at around 23.44°. Right now this value very gently decreases at the rate of roughly 0.013° per century. On the other hand, the Moon’s axis of rotation is almost exactly perpendicular to the ecliptic plane. The Moon’s axial tilt measures on average only 1.543°, with small fluctuations similar to the inclination changes its orbital plane experiences. Let’s take a top-down view of these axes of rotation. In this next demonstration, I’m marking the two angles between the reference direction and the two planes that contain the axes of rotation of the Earth and the Moon, and are also perpendicular to the ecliptic: This rotating motion of the axis of rotation of a celestial body is known as axial precession. The Earth’s axis rotates very slowly, completing a full cycle in roughly 26,000 years. Compared to the Earth’s, the Moon’s axis rotates much more rapidly, finishing one turn in 18.61 years 18 years and 223 days. You may recall that this is the exact same duration as the Moon’s nodal precession, where the line of nodes rotates over time. In fact, the orientation of the Moon’s axis of rotation is strictly controlled by the orientation of the Moon’s orbital plane. This dependence is reflected in the demonstration below, where I’m drawing a blue line that’s perpendicular to the ecliptic plane, a dark gray line that’s perpendicular to the Moon’s orbital plane, and the white line of the Moon’s rotation axis: These three lines always lie flat in the same plane. This relation is summarized in Cassini’s third law, which states that the Moon’s rotational axis stays in the plane formed by the other two lines. As the Moon’s orbital plane rotates in nodal precession, so does the Moon’s axis of rotation. The final aspect of nodal precession that we need to consider deals with its impact on observers on Earth. As the Moon’s orbital plane rotates, it can be aligned with the Earth’s axis of rotation to a higher or lower degree. In the simulation below, I rotated the camera’s “up” direction to match the Earth’s axis of rotation and I also keep rotating the viewing angle with the Moon’s orbital plane, giving us an unchanging outlook on these elements. I then mark the angle between the Earth’s axis and the direction perpendicular to the Moon’s orbital plane: Notice that this angle oscillates over a long period of time, reaching a minimum of around 18.13° and a maximum of around 28.72° – I’m marking these extremes with fainter lines. Over the course of 18.61 years 18 years and 223 days, the orbital plane goes through its entire tilting cycle. Depending on that relative angle of the Moon’s orbital plane, observers on Earth can see the Moon sweeping through the sky in a broader or narrower band. In the demonstration below, the trail we see marks 30 days of the Moon’s path in the sky. The slider lets you jump through time over the whole period of the next 18.61 years 18 years and 223 days: Loading... Notice that the width of the “band” of the Moon’s position gets thinner and thicker over the years, in correlation with changes between the relative orientation of the Moon’s orbital plane and the Earth’s axis of rotation. It’s primarily the Sun’s gravity that disturbs the Moon’s orbit from the pristine elliptical path. As the Moon orbits around Earth and those two bodies orbit around the Sun, the distance between the Sun and the Moon varies. This changes the strength of those gravitational interactions, causing the precessing effects. What I’ve discussed here were only the major and most visible components of the Moon’s motion through space. Historically, the science of lunar theory tries to decompose the motion of the Moon into various cyclical elements that depend on the relative position of the Moon, the Earth, and the Sun. Many of these effects even have their own names. The modern developments in prediction of the Moon’s position rely on direct computer simulation of the motion of all the planets, their moons, and hundreds of other small bodies in the Solar System. These calculations also account for other effects like non-spherical shape of the bodies or more complicated gravitational interactions arising from general relativity. For us, it’s time to stop observing merely the gravitational influences of the Sun. We’re finally ready to cast some light on the visual aspects of its presence. Sunlight Let’s see how the Earth and the Moon actually look in space. To make it easier to find the Sun when you’re zoomed in, the yellow lines indicate the “towards the Sun” direction for the two bodies: Since the Sun is so far away, at any given time the sunlight splits the Moon and the Earth into pretty much even halves of lit and unlit parts. As these bodies spin around their axes, they experience their respective solar days. In the demonstration below, I added the familiar arrows glued to the surface of these bodies, letting us track their orientation more precisely: For our planet, it takes, on average, 24 hours for the same location on the ground to point at the Sun again. The Moon rotates much more slowly, so the equivalent cycle of one solar Moon day lasts 29.530 days29 days, 12 hours, and 44 minutes of Earth time. These periods are longer than a single spin around the axes of rotation, as measured by crossings of the reference direction. These bodies keep moving on their orbit around the Earth and the “towards the Sun” direction keeps advancing too, requiring more body rotation for the arrows to line up with that direction again. Let’s jump back onto the surface of Earth to see how the sunlight affects what we see in the sky. You can use the sliders below to independently change date and time: Loading... Notice that the sunlight scatters through Earth’s atmosphere, giving the sky the familiar blue color during daytime, and a yellowish and reddish tint at sunrise and sunset. I’m once more making Earth transparent, letting you look below the horizon where I’m hiding any atmospheric effects. Notice that we can often see the Moon visible in the daily blue sky, because the sunlight reflected from the Moon’s surface contributes additional light to the light coming from the sky itself. The dark part of the Moon doesn’t reflect any light, so we only see the bare blue shade of the sky in that unlit area. Most importantly for us, over the course of many days, the lighting on the Moon changes too, but to see it better we have to zoom in and lock the camera on the Moon’s lit surface: Loading... As time passes, the Moon goes through its phases, progressing between being fully lit and not lit at all. Traditionally, these phases have particular names, which you can scrub through in the demonstration below: Loading... Northern Hemisphere Southern Hemisphere To see the progress of light with minimal distraction, I’m showing these phases as seen from the North or South Pole and with all the atmospheric effects removed. As we’ve seen earlier, a more typical observer will see the Moon go through its phases embedded in the dark or bright skies, and the Moon will rotate as the observer shifts around to keep it in view. The Moon phases are caused by changes in relative position of the Moon, the Earth, and the Sun. In the demonstration below, you can see the space view of these bodies, with the cone of visibility showing what an observer on Earth sees as time passes. For clarity, you can change the size of the objects with the button in the bottom right corner: The Sun always lights up roughly half of the Moon, and the phases seen from Earth change because we see different portions of the Moon’s lit surface. The period between occurrences of the same phase is known as the synodic month – this period averages at 29.530 days29 days, 12 hours, and 44 minutes. The average synodic month has the same duration as the average Moon solar day, because the locked spin and orbital motions keep them even. The synodic month is the longest of the four lunar months we looked at. As the Moon and the Earth progress on their path around the Sun, it takes the Moon a bit more time to be in the same relative position to the Earth and the Sun. The length of a calendar month is based on the synodic month, but the length of each of the twelve months has been adjusted to make them all fit neatly into a whole calendar year. When we look at the new or full moon from above the ecliptic plane, the Sun, the Moon, and the Earth are all aligned. However, because of the inclination of the Moon’s orbital plane, the three bodies typically don’t form a straight line, and the side view shows that the Moon is a little below or above the ecliptic. We can see this best when we look at shadows cast in space by the Earth and the Moon. To make the dark cones of the shadows cast by the two bodies visible, I’m filling the entire space with the Sun’s light: When the Moon, the Earth, and the Sun align, and either the Earth or the Moon are in their neighbor’s shadow, we get to experience truly breathtaking astronomical events – eclipses. To grasp the details of eclipses let’s first try to understand the conical shapes of the shadows we’ve just seen and what impact they have on the observers. The demonstration below shows an illustrative example of the Sun, some celestial body, and an observer looking at the Sun. The right side shows how the observer, wearing darkening equipment, sees the Sun. You can drag that celestial body around to see how its placement affects the visuals for the observer: Notice that the sunlight forms three distinct zones. Inside the blue zone, the observer doesn’t see the Sun at all – it’s completely obscured by the planet. In the orange zone the observer sees the Sun partially occluded, with the Sun getting more exposed as the observer is closer to the outer border of the orange zone. Outside of the orange zone the observer always sees the entire Sun. When the Moon obscures the Sun, causing Earth to be in the Moon’s shadow, a solar eclipse occurs. These conditions can only be met around a new moon, but a new moon doesn’t guarantee that a solar eclipse will occur. In the previous simulation, it was easy for us to just drag the planet around to hide the Sun from the observer floating somewhere in space. Unfortunately, the Moon’s inclined orbit makes it much harder for its shadow to land in the right spot to occlude the Sun for observers on Earth. We can see it more clearly in the Earthly skies by tracking the position of the new moon over the course of several synodic months – you can flip through them with the slider. I’m drawing the outline of the Moon with a dark pink line: Loading... Coincidentally, notice that the Moon during a new moon is never visible to the naked eye because the sunlight hits the Moon’s surface almost entirely on its opposite side. The Moon is also either placed in the blazingly bright skies nearby the Sun, or it’s hidden under the horizon in the night sky. However, if the Moon’s position relative to the ecliptic is fortunate enough, the fringe of its lit new moon surface can be just barely visible in carefully taken telescope photography. For the Sun and the Moon to visually overlap, the Moon has to be very close to the ecliptic plane. For this to happen, the line of nodes that joins the locations at which the Moon sinks under or rises above the ecliptic needs to more or less point towards the Sun. You can experience this below by scrubbing through time with the second slider to arrive at the conditions leading to the solar eclipse that passed across North America on April 8, 2024: Let’s analyze the shadow cast on the Earth on that day in more detail. In the demonstration below, the right side shows the observer on the sunlit Earth with the visible Moon’s shadow sweeping across the Earth. The left side shows the zoomed-in view of the Sun, as seen by that observer through eclipse glasses: Loading... Notice the blue and orange curves on the Earth. They match the shadow zones we’ve seen before, and they divide the surface of our planet into three distinct regions. Outside of the orange shape the Sun isn’t occluded by the Moon, so these areas of the Earth don’t experience any effects of the eclipse. On the inside of the orange shape, the Sun is partially occluded by the Moon – these areas experience partial solar eclipse. The closer the observer is to the blue shape, the more obscured the Sun is, and the darker the area on the ground. Finally, inside the blue region the Sun is completely occluded by the Moon and a total solar eclipse occurs. Below you’ll find a re-enactment of this event, showing visible Sun’s corona and prominences shooting out from the Sun’s surface: Although the Sun is very big, it’s also very far away, so it ends up having almost the same size as the Moon in the visible sky, making total solar eclipses possible. Recall, however, that the Moon traverses a non-circular orbit, so its visible size in the sky changes over time. When the Moon is farther away from Earth it may never completely cover the Sun. This happened during the solar eclipse of October 14, 2023: Loading... This type of eclipse is known as an annular eclipse, and when it happens, the critical blue region of totality ceases to exist, because some parts of the Sun are always visible. When it’s Earth that casts its shadow onto the Moon, a lunar eclipse occurs. A lunar eclipse occurs only around a full moon. In the demonstration below, you can see the total lunar eclipse that occurred on November 8, 2022. The orange and blue shapes yet again define the regions where, from the perspective of the Moon, the Sun is partially or fully occluded. Note that, to reflect the perceptual effects of this event, I’m adjusting the camera’s brightness setting as the Moon gets obscured: Loading... During the totality, the dim red light on the fully occluded areas of the Moon is revealed. This red tint happens because the sunlight scatters and refracts through Earth’s atmosphere – the surface of the Moon “sees” the red ring of sunset and sunrise all around our planet with the Sun hidden right behind the horizon of the entire globe. Eclipses are so rare because many orbital motions, each with a different period, need to align for them to happen. If the Moon’s orbit wasn’t inclined, somewhere on Earth we’d experience a solar eclipse during every new moon and a lunar eclipse during every full moon. There is one more sunlight-related effect you might have observed in the night sky. When looking at a crescent Moon, you’ll sometimes see that even the part that isn’t sunlit is still somewhat visible. I’m simulating this event here: Loading... What lights up the dark part of the Moon is actually the sunlight reflected from Earth in an effect aptly known as earthshine. The intensity of earthshine depends on the cloud coverage on Earth and the relative positions of the three bodies. At this point we’ll once more leave the surface of Earth to venture back into space, giving us the full freedom of motion to explore the interaction of sunlight with the surface of the Moon: Loading... As we look at the lit Moon, its surface features become distinguishable only by the variation in color as well as the shadows cast near the terminator area where the light hits the surface at an oblique angle – you might have noticed the edges of all the craters and mountains. Let’s explore the details of lunar surface up close. Lunar Surface Although a realistic view of the Moon gives us an impression of its surface, we can get a much better look at its shape with the help of two visual tweaks. First, I’ll color the elevation – the brighter the color, the higher the altitude of that area. The Moon has no sea level to speak of, so the altitude equal to the Moon’s mean radius is typically designated as the baseline of 0 feet0 meters. Second, I’ll make the height differences in the 3D model ten times as large as they actually are, making the elevation changes much more prominent: Loading... This mode reveals the enormous variation on the Moon’s surface. The highest point on the Moon rises 35,387 feet10,786 meters over the Moon’s mean radius, while the lowest point sinks 30,112 feet9,178 meters below that average value. Large swaths of the Moon are covered with impact craters, and many of them have even more craters inside them. These craters formed when various impactors like meteoroids and asteroids hit the Moon’s surface. Depending on the size and speed of the impactor, different types of craters can develop. Smaller impacting projectiles form simple craters with bowl-like shapes and raised rims. Larger objects hitting the surface form complex craters. In complex craters, the area under impact can spring back up to form a central rebound – a mountain peak formed in the middle of the crater. The most energetic impacts create multi-ring basins with concentric ridges surrounding the central site of impact. If you look closely, you can see all these types of craters on the surface of the Moon. Notice that all craters share a circular shape. Impactors hit the Moon with extremely fast velocity, on the order of 12 to 45 miles20 to 70 kilometers per second. When a colliding body slams into the ground, it creates a strong compressive shockwave, which hemi-spherically expands in the ground in all directions. The propagation of this explosion-like shockwave is responsible for the rounded shape of the crater, even when the impacting body itself isn’t spherical or when it strikes the Moon at an angle. In fact, an impactor is most likely to hit the surface of a planet at a 45° angle and only very oblique strikes create elongated craters. This shockwave excavates the ground matter, ejecting it all around the crater. As the debris falls, it often forms smaller secondary craters. The material ejected during impact can also cover much greater distances, creating ray systems. You can see them as streaks on the surface of the Moon. In the demonstration below, the little draggable indicator pinpoints the same location on both views, letting you see the elevation of the features visible in regular sunlight: Loading... You may have noticed that many of the largest basins have relatively smooth, crater-less bottoms – these are lunar maria. Maria is a plural form of Latin word mare, which stands for a sea. These impact basins were flooded by lava around three billions years ago, erasing the history of any existing craters in that area. Because of the different chemical composition of that lava, the maria are darker, which we can easily see on the Moon’s surface. Maria are readily visible with the naked eye from Earth, forming the Moon’s unique splotches. The early solar system was a violent place, but the Moon continues to be struck by meteoroids even in the present day. While the accumulated effects of all larger and smaller impacts are immediately visible in the forms of craters, many micro impactors also affected the Moon’s surface. The Moon has a virtually nonexistent atmosphere, so even the tiniest pieces of space dust can hit the Moon’s surface without burning up in the air, as they do on Earth. Over the billions of years since the Moon’s formation, each impact has continued to break the surface rocks spreading them across a larger area. All of these impacting processes covered the Moon’s surface with a layer of lunar regolith, which consists of minuscule pieces of rock, often bonded with melted glass formed during impact. The powdery nature of lunar regolith is perhaps best captured by the iconic photograph of Buzz Aldrin’s footprint from the Apollo 11 mission: The very fine-grained form of lunar regolith is also responsible for the unusual brightness of the full moon, so let’s explore that phenomenon in the last section of this article. Lunar Brightness Let’s establish the baseline for how common objects behave when lit by light. Below I’m showing you a simple sphere covered with matte gray paint. I’m illuminating this sphere with a distant Sun-like light source coming from the direction indicated by the yellow arrow. You can use the slider to tweak that light direction and you can drag the sphere around to change your viewing angle: For the sake of clarity, I’m only drawing one light arrow, but every place on this sphere is hit by light coming from that direction. The brightness of each part of this matte sphere depends only on the angle at which the light strikes it. Moreover, the brightness of each area doesn’t change as we pan the camera around. You can see this in the small circle under the demonstration – its brightness matches the brightness of the place marked on the sphere, at least as long as we can see that spot. Most importantly, when the observer is positioned straight on with the direction of the incoming light, the sides of the sphere are visibly darker, giving it a familiar three-dimensional appearance. This matches our daily experience with how many matte surfaces look, and perhaps you already had a chance to explore the details of these effects. However, if I were to cover this sphere with lunar soil, its appearance would change – you can experience this below: Notice that when you pan the camera around, the brightness of the marked patch changes subtly. Moreover, as your viewing angle approaches the angle of the incoming light, the surface gets brighter and brighter and it also becomes increasingly uniformly shaded. When viewed straight on with the incoming light, a sphere covered in lunar soil looks more like a flat disc than a three dimensional object. For the same patch of surface, the amount of light reaching the observer now also depends on the relative position of the observer. Let’s try to understand these view-dependent interactions. In the left side of the next demonstration, we’re once more seeing a sphere covered in lunar soil with a marked patch on it. On the right side, I’m visualizing the same marked patch, the direction of light hitting it, and the viewing direction from which we’re looking at that patch on the left side. I symbolically draw that viewing direction on the left side with just one arrow that always points into the screen, but every part of the sphere shares pretty much the same viewing direction since we’re watching it from afar. As you drag the camera on the left-side, you’ll see that viewing direction changing on the right. This gives you a different perspective of these two directions, letting you see how they change relative to the spot: Notice the angle marked between the light direction and the viewing direction. This angle is known as the phase angle, and its value strongly affects the brightness of each section of this sphere. As we decrease the phase angle by aligning the viewing direction with the light direction, the surface covered with lunar soil becomes brighter. In the demonstration below, we can compare the visuals of a classic matte sphere on the left, with a lunar soil sphere on the right. The plots below track the dependence between the phase angle and the total amount of reflected light reaching you from the surfaces of each sphere: As you drag the view around, your phase angle changes. This obscures or reveals a larger fraction of the lit surface, affecting how much light we see. As expected, for a maximum phase angle both surfaces get completely dark because the light illuminates the hidden halves of the spheres. However, when the phase angle is very small and we’re looking at the lunar sphere from the similar direction as the incoming light, the brightness of the lunar sphere rapidly increases with the effect known as opposition surge. You may have noticed this when watching the night sky – the Moon is significantly brighter during a full moon than even a few days before or after that phase. On Earth, we have borderline no control over the phase angle – the position of our planet, the Moon, and the Sun predetermine the light direction, the viewing direction and the resulting phase angle for us: These interactions between the lunar soil and light aren’t just visible from Earth, but also directly on the surface of the Moon. Below you can find a photograph from the Apollo 11 mission showing brighter halo right where the camera’s viewing direction is very close to the direction of the sunlight hitting the surface: To understand how opposition surge arises, we have to investigate the interactions between the grains of lunar regolith and the light shining on them. Let’s first take a look at some simple models of grains of Moon dust casting shadows on a gray disc. You can change the direction of the light with the slider: As you change the direction of the incoming light, the shadows also move around to be on the opposite side of the light. When you then look at the scene from the direction of the light, you’ll notice that all the darkness of the shadows disappears – they’re hidden behind the grains themselves. Naturally, the shadows are still there, they’re just not visible from that specific angle. Even in this simple scene, we already witness how a few shadow-casting grains can visibly affect the perceived darkness, so let’s scale things up by viewing a large collection of grains from a bit farther away. You can once more control the direction of the incoming light with the slider: All the randomly oriented grains cast shadows on each other, and when viewed from the side, these shadows make the surface look visibly dark. However, when we glance at the surface from roughly the same angle as the incoming light, the surface becomes much brighter. This happens even when the light hits the surface at a very shallow angle. These conditions are met almost exactly during a full moon, or in the center of the astronaut’s camera pointed at the ground – the phase angle is small because the viewing direction is very strongly aligned with the incoming sunlight. The effect we’ve just seen is known as shadow hiding. It was originally believed that shadow hiding is the principal cause of the opposition surge, but in the 1990s another effect started to gain traction as the possible explanation of this phenomenon. This other effect is slightly more complicated, and it requires looking at the wave nature of light. I’ve briefly discussed these concepts before, but to recap, light is an electromagnetic wave that travels through space with its electric and magnetic components oscillating with a set frequency. In the demonstration below, I’m drawing a simple, pulsating spherical source that emits light in every direction. The light emitted from this source spreads out spherically, but if I drew the emitted waves as a set of overlapping spheres it would be quite difficult to grasp how the electric field varies over time. Instead, I’m showing the changing amplitude of just one slice through this field, and I’m using two colors to distinguish positive and negative values. The slider below lets you control the wavelength of this light, which determines the distance between two consequent peaks or valleys: Notice that the amplitude, or “height” of the wave decreases with distance, which we can also see in the decreasing intensity of the red and blue colors. Let’s take a closer look at how these waves spread over a longer distance. On the left side of the next demonstration we can see a top-down view of a source emitting light, while on the right side we see how this wave looks to an observer that looks at this source from far away. You can drag the source around to change its position: Far away from the source, the radii of spheres of propagating waves become very large, so the arcs of individual peaks or valleys look like straight lines. An electromagnetic wave like this could travel through the vacuum of space completely uninterrupted. However, any tiny object put in the light’s path will scatter it to some extent, creating a new wave. In the demonstration below, I put a small grain of lunar regolith in the path of the incoming light – you can drag this speck around to change its position. You can also control the direction of this light with the second slider. This little dust speck scatters the incoming light and acts like a new light source emitting waves that eventually reach the observer: In general, the amplitude of this newly scattered wave can vary with direction, but for simplicity I’m showing it here as a simple spherical wave that spreads uniformly in all directions. Let’s add one more lunar grain to our scene. The light will now scatter from both particles, and the resulting waves will interfere with each other – where two peaks or two valleys overlap perfectly their amplitude doubles, but when a peak meets a valley they cancel each other out, creating dark areas: As you drag the wavelength slider, or you change the direction of the incoming light, or you move the grains around, you’ll see that the interference patterns of light reaching the observer change drastically. So far we’ve only looked at the scattering of the directly incoming light, but the light scattered by each grain interacts with the other grains as well. Those grains scatter the originally scattered light, which can then be scattered by other grains, and so on. Let’s take a closer look at the light interactions across two scattering events, that is when incoming light scatters from the first grain, then scatters from the second grain, and then reaches the observer, or when the incoming light scatters from the second grain, then scatters from the first grain, to finally reach the observer: Now it’s really hard to see what’s going on, so I’m going to make two changes. First, I’ll split all the light into the incoming, scattered once, and scattered twice components – you can choose between them in the next demonstration. Second, I’ll make the source light continuously emit light, letting us see the resulting interference patterns in more detail: incoming scattered once scattered twice We can now easily how the singly scattered light reaching the observer is very sensitive to the placement of the grains, the wavelength and the direction of the incoming light. If a rough surface is lit with a light of a single frequency, e.g. created by a laser, one could indeed see a speckle of these constructive and destructive interference regions hitting the observer from various elements of the surface. Thankfully, sunlight contains a whole spectrum of various frequencies, so all these patterns average out to some baseline intensity of light that the observer can see. It may seem that the light reaching the observer after scattering twice is equally messy as it was after just one scattering event. However, when the incoming light hits the two particles from the viewing direction, the doubly-scattered waves reaching the observer always interfere constructively, regardless of the light’s wavelength, or how those particles are positioned! To understand why this happens, we need to trace the path that the light travels. In the demonstration below, you can scrub through time with the second slider to look at the path that one peak and valley of an incoming wave takes. For clarity, I’m hiding the wave of the incoming light after it has scattered on the two grains. Similarly, I’m also hiding the waves generated by the first scattering events, leaving only the waves of the second scattering: The dark pink trail shows the path of light hitting and scattering from the first particle, then hitting and scattering from the second particle, and then eventually arriving at the observer. The light pink trail shows the path of light hitting and scattering from the second particle, then hitting and scattering from the first particle, and then arriving at the observer as well. If the incoming light direction matches the viewing direction, both trails traverse the exact same path, just in the opposite order. As the peaks and valleys on the two paths travel the same distance from the source all the way to the observer, they always add up constructively for all grain positions. This positive interference creates consistently brighter light that reaches observer when the incoming light and viewing directions are aligned. Light waves incoming from some other direction traverse different paths of different lengths, so they interact with each other more or less randomly, with various degree or constructive or destructive interference. Across all the grain positions and light wavelengths, this results in some average, base intensity of this second scatter. This entire effect is known as coherent backscattering. The same interactions happen for any two, three, or more consequent scattering events between the same collection of grains. As long as the scattered incoming light has a path to eventually leave the surface, it also means it can travel the same path, but in the other direction. Coherent backscattering is currently believed to be the primary contributor to the opposition surge, with a smaller influence from shadow hiding, but both of these effects make the full moon a bright presence in the night skies. Our journey around the Moon ends here, and so does this article. As we leave the darkness of space, let’s take a final look at the Earth and Moon so beautifully captured in a photograph taken from space: Further Reading For a short and approachable read, Moon Owners' Workshop Manual discusses many of the general facts and discoveries about the Moon, all presented with great photographs and illustrations. The same publisher also has guides on the Apollo 11 and later Apollo missions – they very accessibly cover the technical aspects of that wondrous era of lunar exploration. Lunar Sourcebook is a book on many aspects of lunar history and geology. Although the title is three decades old and many of its data-dense sections are only useful as a reference, its free availability makes it unbeatable for deeper dives into lunar sciences. Finally, Luna Cognita can only be described as a labor of love. Over the course of three thick volumes, Robert A. Garfinkle presents a wealth of information on the Moon, including thorough description of every crater, ridge, and mountain one can observe on each day of the entire synodic month. Final Words The Moon may be just an unassuming neighbor in the sky, but its presence affects our lives in many subtle ways. When it reflects sunlight off its scarred surface to guide the way in the darkness of night, or as it breathes life into oceans by rhythmically raising tides, or when it cloaks the Sun in a rare and awe-inspiring total solar eclipse, the Moon reminds us of the celestial world right outside of the safe confines of our planet. Traveling through the cold and empty space by Earth’s side, the Moon is always just there. It may be barren and dull, but, undeterred by its own lifelessness, it never leaves us completely alone. Perhaps the next time you catch a glimpse of the Moon’s shiny surface beaming in the night sky, you’ll see it a little differently – not as a mundane fixture of the heavens, but as a fellow companion that gently affects our own existence. If you enjoy these articles, consider supporting on Patreon. Copyright © 2024 Bartosz Ciechanowski",
    "commentLink": "https://news.ycombinator.com/item?id=42443229",
    "commentBody": "Moon (ciechanow.ski)452 points by todsacerdoti 1 hour agohidepastfavorite59 comments jcims 1 hour agoThis is wonderful!!! Generalizing here but we really do take the moon for granted. I bought a 'big ass telescope' a few years ago in an effort to bootstrap a hobby that I'd flirted with for decades but never really committed to. It's a Celestron 11\" SCT and I really had no idea what I was getting into. When I think of space I think of things that are really small in the night sky, planets, galaxies, nebula...(turns out most of them aren't *that* small and I overshot the targets I had in mind) I kept trying to photo galaxies and star clusters and all of these exotic things but had a bunch of trouble with tracking with long exposures. Out of frustration I ended up just pointing it at the boring ol' moon to at least get used to the equipment and workflows. I fell in love with Luna. The magnification of this scope really allowed me to explore the surface in a way I never had before. I got to know the 'map' and suddenly related to our celestial neighbor in a whole new way. It was also the very first image I was actually not embarrassed to share - https://imgur.com/a/t9b1Uug I since then improved my knowledge and technical skill but the month of the moon at the end of 2021 was really pretty spectacular for me. reply dylan604 0 minutes agoparentWelcome to the hobby (even if a few years late). Pretty much everyone has the same experience as you. You buy the telescope, and then realize you need to buy a telescope for your telescope to use as a guide scope for accurate tracking for longer exposures. However, those long exposures are much more likely to get photobombed by an airplane or satellite. So you're really better off taking shorter exposures with the highest ISO you can get away with, and then just stacking them. I have a much wider scope that I can do 30s exposures unguided before trailing starts to become noticeable. If you can get away with 15s, you'd be amazed at what you can achieve with newer sensors. Just some hints to help the disappointment at bay and maybe get you playing with the toys reply js2 15 minutes agoparentprevAn 11\" SCT is a commitment to use. Do you have it on a permanent mount? I've had an 8\" Celestron SCT for almost 40 years that I bought as a teen during the Haley's Comet craze. Getting it out and set up is 15-30 minutes. My family or guests look through it for 10 minutes. Then everyone goes back inside and I'm left outside alone. Which is fine for a bit. But it's a bunch of friction to put it away again. So I hardly ever use it. I realize modern mounts make things a bit easier but it's still a hassle due to the sheer size. A 5\" SCT is really the sweet spot. Maybe even just a tabletop model. Bigger than that goes from being a hobby to being a job. Unless you're someplace dark with good seeing the extra size doesn't do a whole lot of good. reply swifthesitation 17 minutes agoparentprevIt really is a great shot. I always daydream of showing today's technology to the great the great minds from centuries ago. Not sure why, but I do. reply PUSH_AX 45 minutes agoparentprevIt’s a lovely shot. reply DiggyJohnson 10 minutes agoprevReally excellent. Since I live in a high rise I've marked the cardinal directions on the floor and walls and been trying to develop a spatial intuition for the ecliptic, essentially trying to be able to easily imagine myself tilted in the northern hemisphere subtropics rotating around a sphere rotating around the sun. End goal would be an automatic intuition of where to look for the Sun, Moon, and all the visible planets. This sounds insane typing it out but its very passive and genuinely satisfying. Not being on the equator and the natural tilt of the Earth are the two factors that make this most difficult, of course. reply hosolmaz 19 minutes agoprevWake up babe, new Bartosz Ciechanowski post dropped reply bbx 4 minutes agoparentI saw the domain name and thought the same thing. Always an event to see a new post of his. reply wcrossbow 1 hour agoprevThe Moon also plays currently a very special role in my life and my work days are dictated to a large extent by the current Moon phase :) It's not discussed in the article but we have detailed models (ROLO[0] and LIME[1]) for how much light is reflected from the Moon and can be captured by a telescope. Like this one can radiometrically calibrate a telescope, that is, find a mapping between the digital numbers coming out from the sensor and actual radiance values. [0] https://www.usgs.gov/media/files/rolo-lunar-model-and-databa... [1] https://acp.copernicus.org/articles/24/3649/2024/ reply max_ 1 hour agoprevThis is the future of STEM education. Well written, decently comprehensive interactive documents. I think such formats should be prioritised instead of textbooks for creating learning materials. I am really surprised almost no one is doubling down on something like this. Brilliant comes close, but its not at this level. Everyone in Edtech seems to be running towards AI gimmicks. Thank you Ciechanowski! reply simonw 53 minutes agoparentI've seen these called \"explorables\" or \"explorable explanations\" before and I really like them. I've been collecting notes on them here: https://simonwillison.net/tags/explorables/ Here's the website that coined the term: https://explorabl.es/ reply jasonjmcghee 15 minutes agorootparentThis is a really nice collection. Thanks for putting them together. I'm very partial to this writing style as well. I took a crack at making it slightly nicer to write this style of blog post via markdown with codeblocks you can mark to execute instead of display (and hot reload + gist rendering support) It makes the source easy to read, even on GitHub preview, etc. It's what I've been using to write my recent posts. https://github.com/jasonjmcghee/mdxish But at the end of the day, content itself and the code that powers it is more important than any framework you might use. reply BuyMyBitcoins 43 minutes agorootparentprevThank you for collecting and sharing these. I was so impressed by the submission that my first thought was to find some repository that contains the samples of a similar caliber. reply BuyMyBitcoins 45 minutes agoparentprevI consider Kerbal Space Program to be the most rewarding game I have ever played. Going into this page I was already somewhat familiar with many of the concepts it presented because I had encountered them during gameplay. However, having the ability to modify parameters was very helpful for visualizing different kinds of gravity assists. The game does not provide a way to do this, so it augments my understanding massively. I agree that these interactive learning materials are incredibly promising towards actually understanding what is being presented. In other words, this is how I actually grok the concept. reply mattkevan 43 minutes agoparentprevBrilliant.org[1] does a good job of using explorables in their learning materials, some of the best I’ve seen in that category. That said, Ciechanowski is on another level entirely. [1] https://brilliant.org/ reply xnx 55 minutes agoprevThe very first interactive element is a great example of why ciechanow.ski is so great. Similar animations from other sources would probably limit to 28 frames and fake the image (using a simple mask). On ciechanow.ski there are hundreds(?) of frames and uses a bump map(?) to show accurate crater shadows on the moon's surface. reply doctoboggan 1 hour agoprevAs a big fan of both the Moon and ciechanow.ski this article is right up my alley. During the 2024 solar eclipse I was explaining to people how an eclipse must occur during a new moon, and this article would have really helped. The discussion also made me realize how little most people spend thinking about the solar system and the relationship between the moon, sun, and earth. These things fascinate me (I think it's just the sheer scale of it all), and I hope to be able to get more people interested as well. The solar eclipse was great for that! reply BoxOfRain 45 minutes agoparentThe really satisfying thing for me was when I was on a sailing course and was instructed in how the moon causes the tides, and how the phase of the moon corresponds to springs and neaps. reply lifestyleguru 1 hour agoparentprev> solar eclipse I was explaining to people how an eclipse must occur during a new moon Hey, that's the first the time I realized this. reply rqtwteye 55 minutes agorootparentAnd a lunar eclipse only during full moon…. These constraints made it easier to predict eclipses in the past. reply halyconWays 1 hour agoparentprevPeople are impressed if you can name the current moon phase and tell them what it'll be next. But it only takes a mental model of where the sun, earth, and moon orbits are relative to each other. I also find people are intrigued by the concept of earthshine, and often haven't noticed it until you point it out. reply Terr_ 26 minutes agoprevThere's a collection of little facts I imagine being useful if a human got stranded somewhere in the universe and helpful aliens weren't sure where to take you. Without books and electronics, what could you memorize that would help them search and identify Sol/Earth in their big astral database? This is one of them, the seemingly-pure-coincidence of solar eclipses where the apparent size of the moon equals the apparent size of the sun. Ratios in general would be handy, since they would not depend on difficult-to-calibrate units: The moon is ~1/6 times the mass of our Earth; the biggest planet Jupiter/#5 is 2.5x the mass of all the rest and 5.2x the distance from the sun compared to Earth/#3, etc. reply siavosh 26 minutes agoprevIt really is a marvel. I'm grateful society has such subject matter experts, that they have the technical skills to share it, have a passion to share it, and dedicate the time and effort to do so at such a level. reply mbb70 18 minutes agoparentBartosz Ciechanowski is a subject matter expert of everything, given enough time: https://ciechanow.ski/archives/. I still remember reading 'Gears' and being completely blown away. reply praptak 17 minutes agoprevThe initial simulations might give you a slightly wrong idea about the shape of Moon's orbit around the Sun. It doesn't form any loops (you can see that in the later more precise simulation) and is in fact convex (this one is a bit harder to see). reply parpfish 52 minutes agoprevyears back i came across this moon-related modeling problem on stackoverflow (i'm not the original poster)[0] and it's stuck with me that this seems like something that should have an easy solution. An HN thread about how cool the moon is seems like a good place to resurface it. But the question is this: The crescent of the moon face is tilted based and the angle of that tile depends on the viewer's latitude on earth. Is there an equation that maps viewer latitude to the tilt of the moon crescent? [0] https://stackoverflow.com/questions/22392045/calculating-moo... reply belfalas 40 minutes agoprevThe moon is so interesting, easy to forget how much it affects life on Earth because we see it all the time. Like others in the thread, I have a telescope and it's a wonderful experience pointing it skyward while it's still light out and the moon is visible. Then I can really see all the craters and \"pock marks\" on the surface. (My telescope isn't good enough to be able to see anything during a full moon, it all just becomes washed out.) reply divbzero 39 minutes agoprevWhat an amazing exploration, from watching the sun set over moon craters in the first graphic to the simulation of how the Moon formed and the lucid explanations of tidal locking and axial precession. As with many of the author’s posts, the underlying code can be an interesting read as well: https://ciechanow.ski/js/moon.js reply eitau_1 47 minutes agoprevOn an unrelated note, on the Sunday we had a major lunar standstill i.e. the full Moon at its highest orbit (as seen from northern hemisphere). It happens every 18.5 years. reply guax 1 hour agoprevIs there a name for this category of website? I am seeing content like this — elaborate, animated, interactive — more often here and I wonder if its part of a new corner of the internet I am not familiar with. Looks dope. reply rom1v 1 hour agoparentI think this category is named ciechanow.ski. reply simonw 51 minutes agoparentprevhttps://explorabl.es/ calls them \"Explorable Explanations\". reply banannaise 1 hour agoparentprevIt's hypertext - a text-based format enhanced with other elements. reply nuancebydefault 1 hour agorootparentAmazing idea! reply lifestyleguru 56 minutes agorootparentThere are even dedicated markup and scripting languages for this. I predict this technology will be hot in 2025. reply axus 52 minutes agoprevOne thing I've noticed while looking at the Moon, the \"dark\" part is lit enough to see that it's an orb and not really being eaten by darkness. This webpage doesn't do that, I guess it's from a different perspective without the earth shining on the Moon. reply pierrec 21 minutes agoparentI guess you alreay know this, but for reference this is caused by earthlight (light diffused and reflected by the earth): https://en.wikipedia.org/wiki/Earthlight_(astronomy) Sometimes it's clearly visible, but often I agree that it's hard to tell if you're imagining it or not. reply ribcage 43 minutes agoparentprevI often wonder if it's just my imagination or is it really like that. I am still not sure. reply bradarner 1 hour agoprevThis is why the internet is amazing! Awe-inspiring. Beautiful. How does the author build these pages? Looks like it is React. The entire blog must be custom built, no? Or is this built on top of an existing CMS? reply adrianh 50 minutes agoparentNo React to be found (and good riddance). It's two vanilla JavaScript files: https://ciechanow.ski/js/base.js https://ciechanow.ski/js/moon.js reply bradarner 41 minutes agorootparentCheers...Chrome dev tools must have tricked me. Also nice that the author didn't minify it. Interesting to read through. reply jasonjmcghee 31 minutes agoparentprevYou definitely don't need a CMS for a blog. I'd expect most HNer blogs you see here are either html files or markdown processed/styled into html files. I bet various templating solutions are popular too, which just output html files. reply maest 1 hour agoparentprevHand crafted, artisanal JavaScript. reply 725686 1 hour agoprevYou might also enjoy minutephysics video: https://www.youtube.com/watch?v=KBcxuM-qXec reply edferda 48 minutes agoprevI haven’t read the article but Bartosz articles are so good and enjoyable to read that I get excited whenever I see a new one pop up. I have already set some time aside tonight to read it with care. Bartosz if you are reading this: thank you so much for these articles. You truly are an inspiration and I can only hope one day I get to be as good a communicator as you are. reply RALaBarge 49 minutes agoprevThank you, I am going to show parts of this to my daughter! reply d42muna 37 minutes agoparentThis cracks me up. \"Look at these beautiful orbital paths. Cover your eyes when it's explaining the barycenter. Cover your eyes!\" reply zombiwoof 14 minutes agoprevAmazing reply hassleblad23 15 minutes agoprevDs reply MaxGripe 39 minutes agoprevDe revolutionibus orbium coelestium reply rogual 1 hour agoprevThis is what JavaScript is for. reply sbaner2k 1 hour agoprevthe author is different gravy reply gclawes 1 hour agoprevMoon should be a state reply dheera 43 minutes agoprevRelated personal story: On January 6, 2023, at approximately noon, I happened to take a flight from Svolvær, Norway to Bodø, Norway, which, took me from 21.8 degrees latitude to 22.8 degrees latitude, which took me from [just inside polar night] to [just inside daytime]. I saw the moon at takeoff and the sun at landing. It was an absolutely miraculous, specatular coincidence -- the latitudes I was flying over, the time, the date, the moon phase, the flight path. This flight allowed me to have a full 3D view of space -- the moon, the Earth, the sun, all within an hour. It was the first time I felt that the moon and sun weren't just discs flying around the sky randomly, but rather that I was the one flying through space, had a 3D sense of where the moon was behind me and where the sun was peeking ahead of me, and that the Earth felt curved as I moved out of the view of the moon and into the view of the sun. My pictures and whiteboard illustration: https://imgur.com/TYFAdoP reply throw-the-towel 33 minutes agoprevciechanow.ski on the frontpage? Instantly upvoted. reply empath75 43 minutes agoprevI can't tell you how excited I get everyone time he does a new one of these. They have all the delight and wonder of a child's pop-up book, but with the depth of a college text book. Consistently one of the best things on the internet. reply halyconWays 1 hour agoprevWe like the moon! Because it is so close to us. reply buildsjets 1 hour agoparentAnd now I want a hot toasty sandwich. reply akshayrajp 59 minutes agoprev [–] wake up babe new ciechanow.ski article dropped reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article provides an in-depth exploration of the Moon's orbit around Earth, its surface features, and its influence on phenomena such as tides and eclipses.",
      "It discusses the Moon's phases, surface craters, and the phenomenon of earthshine, highlighting the Moon's subtle impact on human life and its role as a constant presence in the night sky.",
      "The piece reflects on the Moon's gravitational interactions with Earth and the Sun's influence, offering a comprehensive understanding of our celestial neighbor."
    ],
    "commentSummary": [
      "A user recounted their journey with a Celestron 11\" SCT telescope, initially facing challenges with long exposure photography but finding success and appreciation in lunar photography.",
      "The discussion included shared experiences, telescope usage tips, and praise for educational content, particularly Bartosz Ciechanowski's interactive explanations of celestial phenomena.",
      "The conversation underscored the moon's significance in both personal enjoyment and educational contexts, with users expressing gratitude for detailed and engaging astronomical content."
    ],
    "points": 459,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1734456386
  },
  {
    "id": 42435972,
    "title": "Always go to the funeral (2005)",
    "originLink": "https://www.npr.org/2005/08/08/4785079/always-go-to-the-funeral",
    "originBody": "Opinion Always Go To The Funeral August 8, 200512:00 AM ET Heard on All Things Considered By Deirdre Sullivan Always Go To The Funeral Listen Toggle more options Download Embed EmbedTranscript Deirdre Sullivan Nubar Alexanian hide caption toggle caption Nubar Alexanian I believe in always going to the funeral. My father taught me that. The first time he said it directly to me, I was 16 and trying to get out of going to calling hours for Miss Emerson, my old fifth grade math teacher. I did not want to go. My father was unequivocal. \"Dee,\" he said, \"you're going. Always go to the funeral. Do it for the family.\" Deirdre Sullivan grew up in Syracuse, N.Y., and traveled the world working odd jobs before attending law school at Northwestern University. She's now a freelance attorney living in Brooklyn. Sullivan says her father's greatest gift to her and her family was how he ushered them through the process of his death. So my dad waited outside while I went in. It was worse than I thought it would be: I was the only kid there. When the condolence line deposited me in front of Miss Emerson's shell-shocked parents, I stammered out, \"Sorry about all this,\" and stalked away. But, for that deeply weird expression of sympathy delivered 20 years ago, Miss Emerson's mother still remembers my name and always says hello with tearing eyes. That was the first time I went un-chaperoned, but my parents had been taking us kids to funerals and calling hours as a matter of course for years. By the time I was 16, I had been to five or six funerals. I remember two things from the funeral circuit: bottomless dishes of free mints and my father saying on the ride home, \"You can't come in without going out, kids. Always go to the funeral.\" Sponsor Message Sounds simple — when someone dies, get in your car and go to calling hours or the funeral. That, I can do. But I think a personal philosophy of going to funerals means more than that. \"Always go to the funeral\" means that I have to do the right thing when I really, really don't feel like it. I have to remind myself of it when I could make some small gesture, but I don't really have to and I definitely don't want to. I'm talking about those things that represent only inconvenience to me, but the world to the other guy. You know, the painfully under-attended birthday party. The hospital visit during happy hour. The Shiva call for one of my ex's uncles. In my humdrum life, the daily battle hasn't been good versus evil. It's hardly so epic. Most days, my real battle is doing good versus doing nothing. In going to funerals, I've come to believe that while I wait to make a grand heroic gesture, I should just stick to the small inconveniences that let me share in life's inevitable, occasional calamity. On a cold April night three years ago, my father died a quiet death from cancer. His funeral was on a Wednesday, middle of the workweek. I had been numb for days when, for some reason, during the funeral, I turned and looked back at the folks in the church. The memory of it still takes my breath away. The most human, powerful and humbling thing I've ever seen was a church at 3:00 on a Wednesday full of inconvenienced people who believe in going to the funeral. Sponsor Message Deirdre Sullivan grew up in Syracuse, N.Y., and traveled the world working odd jobs before attending law school at Northwestern University. Sullivan says her father's greatest gift to her and her family was how he ushered them through the process of his death. Related NPR Stories Diversions Fatherly Advice This I Believe This I Believe: Be Cool to the Pizza Dude This I Believe This I Believe: Good Can Be as Communicable as Evil Facebook Flipboard Email",
    "commentLink": "https://news.ycombinator.com/item?id=42435972",
    "commentBody": "Always go to the funeral (2005) (npr.org)416 points by NaOH 20 hours agohidepastfavorite246 comments cobbaut 4 hours agoPlease visit people when they are still alive. My aunt was alone for the last three years of her live, up to 94 years old. She had almost no visitors, and was not able to go out by herself. I went there about every week, and was always the only visitor. Then came the funeral, with well over 400 people there, and around 200 people at the coffee table after the funeral. And I was like: Where the hell were you guys the past three years? She was alone (after her husband died) and most of you never visited her since (and no they were not living far away or unable to visit). Go to the funeral yes, but don't wait until. reply seanhunter 4 hours agoparent^ this. Also, don't allow yourself to be put off by the idea that you don't know what to say or whatever. Just go. If you think it's hard for you it's doubly hard for the person who is dying and noone is visiting them because they don't know what to say. My cousin was in hospital dying of cancer. I spoke to my mum and she said she wasn't sure what to say etc, so she ended up not going. I went. I said to him \"hey this situation really sucks\". We had a great conversation. He died. I'm really glad I went. Fast forward a few years and my uncle (his dad) was in hospital dying of cancer. I spoke to my mum and she said she wasn't sure what to say etc. I said \"you remember what happened last time. Just go.\" She went[1]. It was a good way to bring finality and say goodbye to her brother and she was really glad she went. [1] I also went separately but that's slightly beside the point reply ljf 3 hours agorootparentI so heartily agree - when my brother was dying I was at a loss to know what to say - we didn't share a lot of history as he 'joined' the family later in life - but just chatting rubbish helped him hugely. Later a friend was dying and when she could no longer talk, I'd head out for a walk and just describe what I could see, what my plans were, and great things I remembered from our past - I wasn't able to visit, but her parents said she really enjoyed the voice notes she got - almost as much as the visitors. But if you can see people, just do it. Not long ago my mum decided to try and visit a whole heap of friends across England, just as she realised after my dad died, that she never knew the last time she'd see these people - and wanted it to be occasions they both enjoyed, before too much time had passed. I loved the idea. reply smugma 3 hours agorootparentprevSo much humanity in this. Thank you for sharing and for advocating. reply CooCooCaCha 37 minutes agorootparentprevI can understand if it’s a distant relative but you don't know what to say to your friggin brother??? Sorry but I’m finding it hard to not call your mom a bunch of expletives. So I’ll just say if your brother is dying and you don’t want so see him because you awkwardly don’t know what to say then you’re not a good person. reply maleldil 28 minutes agorootparentYou have zero context other than what they said. What about withholding judgement about things you know nothing about before saying people are bad? The full story is likely much more complex. reply georgebcrawford 27 minutes agorootparentprevThat's really harsh. Grief affects people in different ways. It can be overwhelming. reply jasode 3 hours agoparentprev>Please visit people when they are still alive. [...] Go to the funeral yes, but don't wait until. Thank you for bringing this up. To add to that ... sometimes, circumstances (i.e. long distances) dictate that only 1 of those trips can be made and they may have to choose. I had a family member with a terminal illness and a friend of the family from out of state decided to visit 2 months before the end to say goodbyes. They were elderly and on a fixed income so they could only budget the money for 1 trip. As a result, they had to skip the funeral. From my standpoint, they made the correct choice of prioritizing the conversation with a living person instead of attending a funeral. reply miroljub 4 hours agoparentprevPeople didn't go to visit her while being alive because they genuinely didn't care about her, or didn't care enough to bother to visit. They showed up in a funeral not because of her, but because they were afraid of what others would say about them if they didn't show up. This is the sad reality of human behaviour in this day and age. reply freedomben 3 hours agorootparentIndeed, anecdotally I think there's an epidemic of uncaring going on in the world right now. I think the hyper-connectivity of always-on internet-based and smartphone-based stuff just overwhelms our capacity to care, but that's purely a theory. reply matthewowen 3 hours agoparentprevReading the whole thing, I think the author would agree. \"Go to the funeral\" isn't just about the funeral. It's a specific example of \"if you have a chance to show up for someone, show up for them: even if (maybe _especially_ if) it's awkward or inconvenient\". reply hk1337 1 hour agoparentprev> Where the hell were you guys the past three years? Maybe they were there when you weren't there and they're asking the same question about you? Maybe your aunt never really thought to bring up that so-and-so had come to visit while you were there, so then as far as you know, nobody came to visit? Maybe they called, sure it's not the same as visiting but it's something. It's true though, as humans we tend to not think about things and other people until they are gone. Don't be angry and upset, if anything, pity them for not having the time that you had. reply aeronaut80 52 minutes agorootparentMaybe the aunt was in a care facility where a record of visitors is kept, and so they know for sure how many visitors there were. Anyway regardless of the specifics of this situation, there are many others where far more people turn up for the funeral than did for the person in their later years. reply dachris 2 hours agoparentprevAs a corollary, if a person you're responsible for \"goes dark\" socially (due to dementia, unable to go out anymore, moved to nursing home etc), do let their friendly social circle know (friends, neighbors) that the person would still be happy about visitors. I've seen this with a relative with dementia - many people just weren't aware that she had no contact with them anymore due to this. reply anshulbhide 4 hours agoparentprevYes. I just found out that my favourite teacher from school passed away today. I've been meaning to visit her for the past five years, but never got around to it - and now never will. reply pjmlp 1 hour agoparentprevAlso don't leave for later things you can do today. I lost family members the day after having phone calls, or planning stuff to do together the upcoming weekend. Leaving something to do later instead of now, that later might be too late. reply keybored 23 minutes agoparentprev> Please visit people when they are still alive. This is very selfless advice. > My aunt was alone for the last three years of her live, up to 94 years old. She had almost no visitors, and was not able to go out by herself. I went there about every week, and was always the only visitor. So selfless. reply ToucanLoucan 4 hours agoparentprevOne of my best memories of college: I was going to a tech school that was just down the street from the nursing home my grandpa was at. Most family were busy so my mom pressured me to go spend time with him. Initially I thought it would suck but after a few times, both the nursing staff and a few patients near my grandpa knew me, it was like getting a minor, second home right next to school. I would go to my classes, get my homework, then drive a few minutes down the road and spend hours there doing the homework, playing games, what have you. I got so much time with him just before he passed. It was truly a blessing, even though he was already a huge part of my childhood, to get one last hurrah before I entered adulthood and he... well, took the next step. I'm not a religious person, I don't honestly think there's an afterlife, and on this point my parents disagree. Maybe they would've made more time to visit him if they weren't sure he was going to a better place and they'd see him again. reply rralian 4 hours agoprev> In my humdrum life, the daily battle hasn't been good versus evil. It's hardly so epic. Most days, my real battle is doing good versus doing nothing. Wow. This part really resonated with me. I will try to keep this in mind. reply sgt101 9 hours agoprevI had a friend who died young, I was young as well. I went to his funeral and there was an opportunity to speak about him and our memories of him. No one stood up to speak. It was awful. I wanted to stand up and say he was a good friend, and to say I would miss him, but I didn't. I've regretted that ever since - 30 years now, and I think about it frequently. reply WillAdams 4 hours agoparentWhen my best friend from high school took his own life, necessitating that I travel to a county I hadn't been to in over a decade, when we gathered to remember him, I started things off by introducing myself as I would have liked to have thought he would have introduced me to everyone else present --- that seemed to afford a structure which bridged the gap between people I hadn't seen in decades (including his eldest niece whom I had not seen since she was a babe in arms) --- we went around the room with everyone declaring their connection and sharing some memories. reply wvlia5 9 hours agoparentprevBut it's a somewhat odd custom no? Funerals. Probably no one stood up to talk because it felt awkward, as it is. It's not like you hurt your friends feelings for not speaking up. reply vitiral 4 hours agorootparentFunerals are an \"odd custom\"? What an entirely odd thing to say, I cannot imagine what you mean. Why is meditating on the passing of a friend, remembering their life and being present with the grief of their family \"odd\"?? reply jzb 1 hour agorootparentAs they are observed in the U.S., I'd argue they _are_ an odd custom, because it's so free-form. I'm old enough that I've been to a number of funerals -- ranging from distant, much older family members when I was a kid, to funerals for an aunt not quite out of her 30s, a cousin not yet 20, and some friends or for family of my spouse. A lot of the time the customs are _unclear_. The services vary a lot. There's a great deal of uncertainty around \"what should I do?\" Because we don't have a coherent funerary custom here. We have plenty of conflicting ideas and expectations around funerals. So, on top of grief, you have the fear of \"doing it wrong\" and compounding someone's else's grief when you attend the funeral of a friend or family member. People have hurt feelings because friends and family members don't live up to their assumptions about what someone else should (or shouldn't) do at a funeral. In some ways, it'd be comforting if it were more scripted and you knew exactly what you were expected to do, say, and so forth. reply bluGill 4 hours agorootparentprevSpeaking at a funeral like that is an odd custom. Note that custom for funerals comes from the local culture and customs of how previous funerals are run. So that it isn't to you is just a reflection on your culture, other people come from different cultures where such a thing is not normal and because it is not normal- for their culture - it harms their meditations which would be done in the way they have grown up doing. As such I'm not making a statement of right and wrong for your culture, only that in OPs culture it is wrong and so asking for someone to speak like that was in fact wrong on the part of whoever asked. Whoever asked may well have come from a different culture where this behavior is normal and so made a mistake by not recognizing that they were in a different culture! reply balfirevic 4 hours agorootparentprevI initially interpreted it to mean that expecting people to give impromptu speeches at funerals was an odd custom (that certainly doesn't happen where I live), but now I'm not so sure. reply 01HNNWZ0MV43FF 44 minutes agorootparentprevIt is odd to only offer 5 seconds for people who are crying to organize their thoughts and speak reply sgt101 8 hours agorootparentprevIt was my failure that hurt me, I think. reply mgkimsal 5 hours agorootparentI get it. I didn't say anything at my grandfather's funeral, although I was this close. I just... didn't. Easier in that moment to stay seated for a few extra seconds, but it bothered me. Years later, at my grandmother's funeral, I spoke. Not long, but I said some of the things I'd wanted to say years earlier, though with the benefit of a bit more hindsight and perspective. But not speaking all those years earlier had bothered me. FWIW, it still does, but a little less than before. reply wvlia5 8 hours agorootparentprevI don't get why it is a failure. reply Tistron 8 hours agorootparentI see it as a strong example of what happens often. We have an impulse from what I will call our authenticity and we decline and suppress it because of some sort of fear. As I've learned to pay attention to this, I've found that it always leads to slight disconnection, and following instead tends to lead to more connection and aliveness. Every time we avoid the alive impulse is a failure of sorts, but usually we don't notice it like in this story above. reply ngr 7 hours agorootparentThis idea is also explored in The Anatomy of Peace by The Arbinger Institute. Reading it was truly transformative for me. It makes a strong point that we experience self-betrayal whenever we choose to ignore our moral compass and how this can harm our relationships. reply wvlia5 7 hours agorootparentprevInteresting. Do you think this other thing might be related? I usually supress emotions in order to perform, solve problems. I ignore all frustration, sadness, boredom and just focus or executing the steps to solve the current problem. Convinced that good performance is what leads to good quality of life. It's like the kid who jumps and cries around the father saying \"I want to play\". The father ignores him and says \"go away, don't bother me please, I'm working\", thinking \"what he really needs is a nice house, food and clothes, that's why I work\". But this has lead me to a pervasive state of unsatisfaction, even though I now have many shiny things to enjoy. reply zmgsabst 6 hours agorootparentI think it’s related, but not in the way you’re implying: He seems to view it as a personal failing that he didnt ignore the awkwardness to “solve the problem” of no one memorializing his friend and thinks about that inability to perform in the moment often, because he wants to be someone who can “rise to the occasion” in such moments. You seem to have a different problem, eg a bad work-life balance or lack of meaningful duties to perform. reply pmarreck 6 hours agorootparentprev\"Fear-repressed authenticity\" is something to gnaw on. reply hoseja 6 hours agorootparentLike 80% of your authentic urges have to be repressed to, erm, live in a society. It's then hard to find a good point to stop doing that. reply pmarreck 3 hours agorootparentI have a 3.5 year old son and the thought HAS occurred to me- \"if we never learned to 'behave' (i.e., conform to societal norms), would we all just continue to be little selfish dopamine monsters?\" lol You might say the foundation of polite society itself rests heavily on the shoulders of millions of weary parents with varying amounts of care and effort expended reply lo_zamoyski 3 hours agorootparentprevAuthenticity is not a great guide for living. Psychopaths are authentic, but no one of sound mind would praise them for it. Our motives are not always pure and good, and our culture's feels-before-reals elevation of \"authenticity\" into a supreme virtue has been a source of much grief. Now, having the courage to act according to what you know by prudence is the right and just thing to do is something else. Here, you are acting according to what is objectively good, and not only that, but what you know is objectively good. And yes, you could say that acting out of genuine courage does make a person feel more alive, as he isn't shrinking out of fear and cowardice. He is acting against the comfort of mediocrity, and as we all know, a little danger and risk does get the blood moving. reply criddell 4 hours agorootparentprevIn another thread, the_snooze wisely pointed out that \"your actions are a reflection of your values\"[1]. If you want to be a person who is part of a community, who cares for the people around them, and doesn't look at everything as a transaction, then you maybe go to a funeral even if you can't measure some benefit for yourself. [1]:https://news.ycombinator.com/item?id=42436832 reply zanderwohl 9 hours agoparentprevMy grandfather died a few years ago. By all accounts, he was opinionated, mean, and yelled at people a lot -- until a stroke humbled him. When it was time to speak, nobody got up to say anything, until I did. I mentioned so many of us had negative feelings about him, and then recalled what good things he did for us. That ice broken, several of my cousins also stood up and spoke. My uncle, who had arranged the funeral, closed it off by saying to everyone in the audience that if you wanted your own funeral to have more good stories, it was a good idea to patch relationships while still alive. I think I would have regretted not standing up to speak. My grandfather did good and bad -- he invented the type of artificial voicebox given to people with throat cancer. He performed lifesaving surgeries on hundreds of people. He also yelled at his grandchildren during every dinner. He leered at my mother and aunts. And yet, I would have regretted not going to his funeral, and not speaking. reply 01HNNWZ0MV43FF 43 minutes agorootparentI wanted to say that at my mom's funeral. \"Her good parts deserved better than her bad parts\". But I was crying a lot, and trying to act normal around extended family who hadn't seen me for several years and at least one gender ago, so I didn't want to say anything vaguely negative. reply ct0 4 hours agoparentprevWe must have gone to the same funeral and had the same friend. I regret not speaking up either to share a story I think about often which highlighted my friends better qualities. Maybe I'll make a post about him after thinking about it for a few more years. reply octopoc 4 hours agorootparentYou might want to call up his parents or siblings and tell them the story. I had a friend die young and whenever I remembered a story about him, I would make a note and call his dad next time the guy’s birthday came around. Actually I forgot his birthday so I just did his birth month but it really seemed to encourage his dad. reply BurningFrog 4 hours agoparentprevPublic speaking isn't for everyone. Especially at such a sensitive occasion. reply chasd00 4 hours agoparentprevIn my experience losing those close to me, you don’t regret the things you said instead you really regret the things you didn’t say. So don’t beat yourself up too bad it happens to all of us. reply lo_zamoyski 3 hours agoparentprevYou have nothing to regret. Eulogies are kind of a modern thing. It's one thing to have fond memories of someone, or to share them with others during a conversation at the wake or whatever, but a public speech that sums up a person is something like passing judgement on a person, and I would dread putting myself in that position as no one really has the authority to do that. (That's why Catholics do not traditionally eulogize at a funeral mass or a wake, as passing judgement on a person, as opposed to, say, judging certain facets of their actions, is something reserved for God alone, as only God could know the heart of a person. A proper Catholic funeral mass is, in fact, entirely focused on making a sacrificial offering for the soul of the departed; there is no presumption made about the fate of the deceased.) reply m3kw9 4 hours agoparentprevSaying it won’t matter, it’s in your heart reply p2detar 9 hours agoprevAs a kid, I went to so many funerals, I remember I started somewhat liking it. I grew up in Eastern Europe. My grandmother was a devoted christian with a lot of community work around church events. As a kid my parents would leave me often with her for the holidays. She took me with her to pretty much every funeral that was happening in the town, since she had to attend. It sounds crazy but these events were large social gatherings, people bringing food, chatting. Often other kids would be there as well. Someone had died, but it wasn't necessarily a sad event. It was people being there for the deceased one and their relatives. There was also something like the \"crying group\" - that would be old ladies crying for the deceased one as an act of support of the relatives rather than expressing genuine feelings. The coffin would sometimes be placed on a trailer towed by a tractor to the graveyard. The \"crying group\" would hop onto the trailer and they would cry around the coffin. They were really good. I realize how strange this may sound, but it was just the way it was back then. None of these funerals could prepare me for the loss of my 2 grandmothers. Still, without meaning it in a disrespectful way, death is an important part of our life-experience, and even as a kid, I'm thankful to have had seen it that often and in a non-violent way. reply shever73 8 hours agoprevThis is a very Irish thing. Funerals in Ireland are always well-attended and going to a funeral - even of someone you don't know - is important in the community (see this recent news article, for example[0]). I notice the author's surname is Sullivan. As my grandmother liked to repeat: \"If you don't go to someone's funeral, they won't come to yours.\" [0] https://www.breakingnews.ie/ireland/crowd-shows-up-to-funera...) reply io84 8 hours agoparentI was raised like this and find it heart warming to see funerals filled with wider community. I did misjudge it once: I was living in a different country with two fellow Irish people and the relative of a good friend died. In Ireland it would have been expected that we attend the funeral, in this case we showed up and there were only six closest relatives there, and our presence just felt inappropriate. I now know your place at a funeral is about your place in a wider community. That often overlaps with being a connection-of-a-connection, but not always. reply jll29 5 hours agorootparentI refuse to believe for a second that your attendance was considered inappropriate; the person being burried at least would have surely been happy for you to be there and think of him or her. Also, your intentions are to be commended regardless of what the relatives thought (it's not the relative's funeral, so they are not the yardstick). reply bluGill 4 hours agorootparentNo, different culture. That are many different cultures and OP made the common mistake of not understanding until it was too late that he was intruding on a different culture. Even though OP was in the wrong I cannot fault him for the mistake, there often is no way to know if you are not very close to the family what the correct culture is. reply nytesky 5 hours agorootparentprevWe had a similar issue. We ended up at a funeral for our daughter’s teacher (we brought the kids as she knew all of them), and somehow ended up in the family greeting line intended for close friends and family. It felt so intrusive and they were like “why are you here”. The cherry on top was our youngest started getting restless during service and we had to leave early and we didn’t sit in the back. I had only been to my parents funerals at this point, and never experienced a more formal religious service, but we were the worst in so many ways. I still regret it 10 years later. reply jll29 5 hours agorootparentTo ask \"why are you here?\" suggests these people were poorly raised or just plain rude. Attendees of a funeral make an effort to pay their respects to the deceased and to express their condolences to the family left behind. reply myko 3 hours agorootparentIf I understand correctly I think they and ended up in the line of folks being given condolences as if they were close family. Sounds extremely awkward and like a plot Michael Scott would get himself wrapped into. reply wbl 1 hour agorootparentThere are much gentler ways to point out the mishap and correct it but a funeral is not likely to have people on their best manners. reply ivanche 1 hour agoparentprevAh now I understand why it was a lot of fun at Finnegan's wake! reply MrDrDr 4 hours agoparentprevI can agree with this. Growing up in the UK, with an Irish mother, I was taken to funerals as a child that I really did not want to attend. Like the author I now always go the funeral, and have found it strange this attitude is not more pervasive. reply circlefavshape 6 hours agoparentprevAlso it's weird as an Irish person to see people saying \"the time came to speak, and nobody did\". I've never been to a funeral that didn't have a eulogy. Someone always prepares a speech and delivers it reply bluGill 4 hours agorootparentAs I've said a couple different time, culture matters. There are many different cultures and they handle this differently. I've been to funerals where only the preacher talks, I've been to funerals where someone prepares a speech beforehand. I've been to funerals where opportunity is given for anyone to speak. This is just in my small area of life, as you go around the world cultures have many many different customs around death. reply HWR_14 5 hours agorootparentprevA formal eulogy is a different part from when they ask if anyone from the audience wants to get and share a few words about the departed. reply hindsightbias 3 hours agoparentprevMore than once a bar stranger has said “I thought this was a wedding party” at my family Irish Wakes. reply steveBK123 19 hours agoprevIt’s also a matter of regret minimization. 9+ times out of 10 when I’m on the fence about going to a major life event and go, I’m glad I did. Can’t think of the last thing I regretted going to. I’ve certainly missed some like graduations I regret not making it to. Funerals are towards the top of the list of big life events and I’ve never regretted one. reply pjmorris 7 hours agoparentAbout 25 years ago, a friend offered 'Prioritize things that only happen once in life' as an idea for helping me decide whether to go to my friend's wedding or an important work event. The wedding was great, and the idea has been useful in many other situations, none more so that funerals. reply hombre_fatal 15 hours agoparentprevSame with social events. All my life, I always get this last second resistance to going, yet I'm always glad I went. The reasons my brain comes up with for why I shouldn't go are just lies. Just go. And take what you can get while the opportunities are still coming. reply consf 11 hours agorootparentThat last-second resistance is so real. It’s like your brain becomes a master negotiator for staying home reply anal_reactor 9 hours agorootparentprevThat's bad advice to always go to social events. I tried to follow it in order to expand my social circle, but I ended up staying in places that sucked, with people I didn't like. I try to dedicate some effort to tell whether I actually want to attend or not, and then follow through. I follow my gut, but never change my mind after making the decision. reply hombre_fatal 32 minutes agorootparentI don’t think that’s a counterpoint. That’s just the reality of taking a chance in life. Just go. It’s like saying it’s bad advice to approach women because of some bad experiences you had. Meanwhile the next woman you meet might be your wife. reply soco 7 hours agorootparentprevOf course if the only offer you get is places who suck and people you don't like, it's a bummer. Although I don't think the OP meant that - going for going's sake. In a hypothetical situation when the place would be just okay and the people too, some people's brains (mine too) tend to say \"meh don't bother, nothing stellar gonna happen anyway\". That is the impulse we ought to fight: don't save yourself for exceptional events, but be surprised by the small pleasures in regular ones. And still avoid the bad ones, that goes without saying. reply XorNot 18 hours agoparentprevConversely I went to one high school reunion I was feeling iffy about, had an okay time but was also completely happy just never going to anymore (and haven't). But there's definitely some other effects in play there: revisiting people from your past who you've lost touch with is a pretty fraught experience, at least for me because ultimately the relationship is at best frozen in time from whenever you last talked: high school is particularly bad IMO, because it tends to feel like just trying not to be who you were a decade ago as everyone remembers you, rather then getting to be who you are now. reply pavel_lishin 17 hours agorootparentI've never been to a high school reunion, and I don't intend to go to any future ones. But I went to a high school friend's 40th, and caught up with the people who were my good friends - and still are - and it was worth every penny just to hear their voices face to face for a few days. reply steveBK123 17 hours agorootparentAgreed, I think a reunion differs in that its an impersonal gathering compared to coming of age, weddings, funerals, etc. reply consf 11 hours agoparentprevThe cost of showing up is usually small but the cost of not showing up can linger forever. reply ilamont 26 minutes agoprevThe best arrangement I've witnessed (for family friends from my hometown) was a private funeral for the close family members, followed 6 weeks later by a memorial service in a nice rented space with a slideshow going, drinks, and a general air of a big reunion. The large amount of time between the two events was better for the family, who didn't feel the same sting of fresh grief. There was no awkwardness, either. Everyone could remember the deceased in a way that she would have appreciated - old memories, laughter, and positivity. reply felixnm 17 hours agoprevThe only regret I have in life (I'm in my mid-50s) is not attending the funeral of my friend's Mom. I didn't know her, so I figured I didn't have to go (I was in my early 20's, not that my age excuses anything). Another friend made me realize that I should've been there for my friend. After that, my friend moved away and things were never the same, no matter how hard I tried to keep in touch. Ever since, I always go to the wake/funeral. reply mgkimsal 5 hours agoparentSimilar here. Good friend of many years - his mother passed a few years back, then his dad earlier this year. In both cases it was relatively sudden, but the compounding factor is I live 800 miles away. In both cases, I debated whether to go up for the funeral, but one case scheduling was near impossible. In the other... I rationalized that... he'd just be too busy with other family issues, and that was the case. I feel like I still should have gone, but we did catch up in person a couple months later, and he'd had time to process and reflect a bit more. Lots of drama was going on (and still is a bit) so being there in the moment might have been more about me trying to feel like I was doing something (\"being there\") instead of actually being of any real benefit for his family. I've only got a couple of other friends that close that I would consider attending their parents' funeral. One parent passed away during covid and there was no service. When that other parent passes, I think I will go, even though we've not seen each other in years. Several states away, again, but I will plan on going. reply ethagnawl 2 hours agoparentprev> Ever since, I always go to the wake/funeral. I was going to add a top-level comment adding that there's a bit of nuance here between _the wake_ (calling hours, as the author puts it) and _the funeral_. I actually have a similar regret about not attending the _funeral_ for a friend's mother, although I did attend the wake. In retrospect, I absolutely should have gone to the funeral but, at least in the US, the expectations around who should attend _the funeral_ vary between religions/backgrounds/etc. and it can sometimes be hard to tell what the most appropriate move is. This is especially true if you're no longer/not very close to the family in question. Some families want _the funeral_ to be a more intimate, private affair and will sometimes even mention that it will be in the announcement. But, to your and the author's point, I think as a general rule, _going_ is the better bet. reply anonymousDan 12 hours agoparentprevYeah I'm the same, did it twice unfortunately. reply wvlia5 9 hours agoprevI think I won't go to my parents funeral (when the time comes). I don't see the value of standing next to their corpses. I didn't go to my grandma funeral, I don't regret it. I regret not having had deeper relationship with her. Same with my parents. Will have many regrets, but I believe not saying goobye to their corpses won't be one. reply mikedelfino 6 hours agoparentAssuming that your parents die separately, you being there will make it easier for the other parent still alive. The same goes for their relatives and friends attending the funeral. There's some comfort in seeing that the person was loved. reply guappa 8 hours agoparentprevThey are dead but the other people who attend aren't reply Popeyes 4 hours agorootparentI went to a friends mothers funeral to support him and to pay my respects. However, his brother who had a fractious relationship with his siblings did not. I can't tell you how many relatives viewed his absence negatively. reply SoftTalker 2 hours agorootparentThat's a shame, I'd like to think I would not judge someone for their decisions on something like that, having not walked any miles in their shoes. reply liotier 8 hours agorootparentprevSolidarity with the living is the whole point of the funeral. reply slfnflctd 7 hours agorootparentWell, you could argue that's most of the point. Remember, though, there are funerals where only one person attends. And publicly acknowledging one's loss - even if it only consists of going to a building with strangers and posting an obituary - can be one of the most important steps in processing grief for some people. reply peppyh 6 hours agorootparentprevIt's certainly a large part of it. There was a recent Cantonese movie that featured this as one of the themes, it's well worth a watch. https://en.wikipedia.org/wiki/The_Last_Dance_(2024_film) reply circlefavshape 6 hours agorootparentprev+1 You're showing the other grieving people that you care about them reply SoftTalker 2 hours agoparentprevNeither of my parents had a funeral. They both said they didn't want people coming in and looking at their dead body. reply Merad 2 hours agorootparentIt's not about looking at the body (in my area at least, funerals usually don't even display the body), it's about grieving and mourning. Or supporting other people who are going through grief and mourning, even if you don't feel it very strongly yourself. My mom died of cancer about a month after lockdown started in 2020 so we couldn't have any kind of service, but we had a \"celebration of life\" a year later. I'm glad that we did. reply SoftTalker 1 hour agorootparentWell, they both said they didn't want any of that, so we didn't do it. reply bsuvc 5 hours agoparentprevIt's not about you. reply jll29 5 hours agoparentprevFix your points of regret while this is still possible. If you do so, you will find that very likely, you will want to go once successful. reply bowsamic 8 hours agoparentprevCan you really not think of the situation beyond your personal immediate material experience? reply wvlia5 7 hours agorootparentThink in what specifically, example? I don't see what else I should think of. reply bowsamic 6 hours agorootparentSocially, i.e. about other people? reply astura 4 hours agoparentprevIf being around corpses is your main objection, know that you don't have to have corpses in the room to have a memorial service. reply unholyguy001 19 hours agoprevYou should go to the funeral if you think the right thing is to go to the funeral You should do it for yourself, out of respect for the person who died and respect for the loved ones remaining. Not out of societal obligation The corollary to that is there are plenty of times where the right thing is to not go to the funeral. If you lack those things. There have been times I don’t go the funeral. Because the dead person was a horrible person. When people asked, I said exactly that and many times the response I got was “man I wish I had not gone” reply coldtea 11 hours agoparent>You should go to the funeral if you think the right thing is to go to the funeral. You should do it for yourself, out of respect for the person who died and respect for the loved ones remaining. Not out of societal obligation In 2024 it would be quite better if we did more things out of societal obligation, instead of each individual placing themselves (and their whims) as the moral authority. reply brabel 7 hours agorootparentA world where people only do what they want or feel like doing is indeed a pretty depressing world, I know because that's exactly the world I am living in. The world I grew up on was very different, and I absolutely miss it - Christmas parties, lots of birthday parties, church events, school events, local neighbourhood events... you name it, there were lots of things to do and go to and you were expected to. I think half of the time I didn't really want to, but it didn't cross my mind to say I didn't want to go, and I think that was much, much better - today I barely go anywhere, but I know people also won't come if I call them :( it's just such a sad world. reply athenot 4 hours agorootparentThese things still exist, but they sometimes take time to discover and even longer to gain a sense of belonging. I like to call them \"tribes\" but really it's just a community. Sometimes the intersection of your { interests + location } may not have a vibrant community which happens to contain members who readily welcome new people, and so it requires a bit more effort. Some examples of communities I've been a part of over the years: - Family - Church groups - Bar buddies (overlapping with the previous category :)) - Biker community - Startup community - Technology groups - Queer communities - Neighbor groups It was a lot harder to get into groups when I used to be introverted, I distinctly remember how afraid I was. My startup was the thing that forced me way out of my comfort zone and led me to learn how to overcome my fears of joining groups full of unknown people. The \"ah-ha\" moment was when I realized many others had the same fears and insecurities as I did, and yet that's ok. reply anal_reactor 9 hours agorootparentprevI'm tired, boss reply coldtea 9 hours agorootparentYou haven't tried... reply D13Fd 18 hours agoparentprev> There have been times I don’t go the funeral. Because the dead person was a horrible person. The funeral is a ritual for the people who knew and loved the dead person. The question should really be about them, rather than the deceased who is dead and gone. reply plorkyeran 16 hours agorootparentAnd if those people are going to be talking about how great someone I despised was, it's best for all of us if I stay home. reply throwaway346434 9 hours agorootparentSlightly disagree, only in that the people who supported the horrible person should hear the terrible acts done. Otherwise, yes. No comfort to those who comfort/enable abusers. reply soco 7 hours agorootparentprevI hear this argument again and again, that the dead was despised thus the funeral should not be attended. Really folks, if all people you know are to be despised, then maybe the problem is not with them? Sure, there always is the occasional asshole, but it's not always the one in the coffin, so indeed then there might be times when we should just stay home for the better of everybody. reply the_snooze 19 hours agoparentprev>You should go to the funeral if you think the right thing is to go to the funeral More broadly, your actions are a reflection of your values. If there's a mismatch, then one of two things must be true: you fell short of your ideals and you should strive to do better in the future, or your stated values really aren't your values. reply lambdaphagy 12 hours agoparentprevI recently had the occasion to visit the deathbed of a relative who died with much of his family deeply wounded by, and angry at, him. Had you known him, you might have called him a horrible person and not without some backing for that claim. But I went because I felt a duty to my relatives that isn’t released just because they didn’t hold up their end of the bargain: he had indirectly given me life, even if he had done much ill besides. And moreover I felt an obligation to the office of the head of my family that transcended the particular man. It would be a grim world in which comfort for the grieving is a service the deceased must have earned in advance, and we the comforters decide whether they have really earned it. reply I-M-S 52 minutes agorootparentBy being too lenient towards those who have not deserved it, we are being unjust towards those who have. reply watwut 10 hours agoparentprev> Not out of societal obligation Societal obligation in this case is literally basic minor respect towards the remaining people. And frankly, the loneliness epidemic HN like to talk about is closely related to the ideology where the only thing that matters is yourself. reply NoMoreNicksLeft 17 hours agoparentprevYou aren't punishing the dead person by not going. Just punishing what friends and family he or she had, out of spite. Making enemies. I mean when you say \"horrible person\" you're not talking about Adolf Hitler or Pol Pot, you're just talking about someone you thought (rightly or wrongly) an asshole. Now you've made yourself the asshole to other people. Not a great life strategy. reply qup 4 hours agorootparentYou made a lot of assumptions in your post just so you could wag your finger at the GP. reply NoMoreNicksLeft 4 hours agorootparentI assumed that the deceased wasn't Pol Pot. Was there another assumption? reply elvis10ten 12 hours agoprevPersonal opinion: I find funerals to be a waste of time and money. Especially, coming from a culture where they are a big event. People spend enormous money on funerals —- money that they wouldn’t help you with while you are alive and struggling. Maybe attending one in a less flamboyant culture will change my mind. But I wish more people in general don’t wait for terminal events to do or say nice things. reply litenboll 10 hours agoparentI shared your opinion until I attended my first funeral as an adult. They are very important for the grieving process, at least to me. That doesn't mean much money needs to be spent, I've only been to scaled down funerals where there's a short ceremony and a meal afterwards. reply throwaway346434 9 hours agorootparentEh. For children of less than stellar parents, a funeral is: - A bad person gets celebrated in a way that is not aligned to your understanding - A bunch of people who don't know about the less than stellar bits offering what feels like performative grief - Others who enabled the less than stellar bits angry their applecart has been upset, looking to lash out at a scapegoat. Obviously not everyone has this negative experience, but narcissism is in about 6.2-7.7% of the population; other \"dark traits\" are also around in a long tail. So it's not unreasonable to expect around 12-15%? of people risk a potential increase to trauma at an already complex time of their lives. reply wvlia5 7 hours agorootparentOh, 2 significant figures, you cherish your stats. reply DHPersonal 4 hours agoparentprevI feel much the same. I hope that when I die, the people around me will remember the many times that I have asked to have my body disposed of as quietly and cheaply as possible, and to not perform a funeral for me, and if they wish to use my death as an excuse to gather, to make the event as joyful as possible and as little about me as they can. reply SoftTalker 2 hours agoparentprevThe funeral industry is also very predatory. They know full well they have people in grief making decisions and they end up getting pressured into buying a casket that's just going to be buried in the ground in a few days, but they will be paying for for the next 10 years. That a family can come out of a funeral tens of thousands of dollars in debt is just absurd. reply consf 11 hours agoparentprevShowing up before the funeral is what makes showing up at the funeral matter more reply bananatype 6 hours agoparentprevIt probably depends on one's culture. In the Philippines, it's customary for funeral visitors to give a small donation to the bereaved family members (typically, around 20-40 USD). And since funerals are considered a big social event, it's not uncommon to hear of fmilies who were able to recoup (or pay off) their funeral expenses through the donations alone. reply gwbas1c 5 hours agoprevI pretty much always go. The only time I missed a funeral was during the pandemic for one of my teachers, and my wife was due at any moment. His funeral was well attended. For one particular funeral, it was for a childhood friend who I had lost touch with. One of the photos, in the rotation, was from a bus trip where I said, \"hey, give me your camera.\" It was touching. His brother showed up at my mother's funeral a few years later. reply gaoshan 17 hours agoprevLarger message about doing the thing you really should do aside, ever since my parents dissuaded me from going to my grandfather's funeral (a man that I loved and respected but who's funeral came at an \"inconvenient\" time in my life) I have greatly regretted it. Not going burned itself into my mind and since that time I have never missed a funeral. Even for someone I only knew a little or hadn't seen in many years. If I had a connection with them, thought fondly of them, I make every effort to go. It just feels like the right thing to do. reply lordnacho 20 hours agoprevBig life events are always worth a visit if you get invited, and you always learn something from the mix of people who attend. Whether it's a funeral, wedding, baptism, and so on. Does this person have friends from childhood? Do his friends come from the same place, or all sorts of places? Do they know each other, or does he have a lot of singletons there? Who considers themselves close family? Second cousins? Or did their cousins not even come? How well represented are various social classes? I always find these things super interesting when I go to one of these. reply consf 11 hours agoparentFunerals, especially, tell stories without words reply mooreds 20 hours agoprevWholeheartedly agree with both the nominal and underlying advice here. Doing the right thing all the time is painful, tedious and can cost you. But doing the wrong thing will cost you too. Both compound. The literal advice about going to the funeral is about showing up for people who meant something to you. There are only a few special times in your life when you get to see a large chunk of other people's important people: * graduations * coming of age ceremonies * weddings * funerals Being there gives you a special chance to know the person better. Just do it. reply coldpie 3 hours agoparent> Just do it. I've tried, man. I'm deeply uncomfortable in social situations, and events with lots of wacky, nonsense traditions and rules that I don't understand makes things exponentially worse. Going to events like weddings and graduations makes me utterly miserable. I feel like shit for days before & afterwards, and I always regret going for months & years afterwards. I guess there's a chance someone there is glad I'm off being miserable in a corner, but I doubt it. So I've mostly stopped going to these things. reply aziaziazi 17 hours agoparentprevI'd love too but a crowd -even mostly loved ones- is for some the hardest way to engage with others. Last weddings I tried to attempt were disasters. Funerals are obviously easier as no/weirdly-interacting is accepted so at least there's less self esteem to loose. I feel the more confortable in one or one to one, three is already to much possible micro-ostracisms to deal with. To end with a lighter note loosely related, a funny citation of the marshal Foch: > \"An assembly must have an odd number of members in order to make a decision, but three is already too many.\" reply antonchekhov 13 hours agoparentprev\"other people's important people\" is a very astute phrase - one has to see the value in that concept in order to understand the deceased's survivors that you think you already know. I've been to a few events where some folks were flabbergasted to discover different fresh aspects of the deceased - \"what the...? He/she was tight with that crowd?!\" reply SoftTalker 2 hours agorootparentI wonder how many people have lived a secret side of their life and finally get outed at their funeral, to the shock of the people who only knew one side. reply jmbwell 18 hours agoprevYou gotta go to people’s funerals, otherwise they won’t come to yours — Yogi Berra reply aantix 20 hours agoprevThere's been a lot more reflective, humanity stories on HN. Or maybe I'm just noticing more. I've been on HN since 2007. There was that story a few weeks ago with the aging parents and their daughter that took a picture of them waving goodbye, each year she visited. I like these stories. It gives me pause and to wonder what it's all been for. Probably for my kids. My second oldest (9) loves creating levels in Geometry Dash. He'll probably be an engineer. He asks great questions. He can teach himself new tricks from YouTube videos. He asks for critical feedback on his levels. That's a good start. I'm just rambling. reply fuzzy_biscuit 18 hours agoparentI like seeing these on HN. Occasionally the hyper focus on tech makes me feel inhuman. Stories like these remind me not to forget how much else there is beyond my narrow world as a web dev. You kid sounds amazing. Be proud and ramble on. reply khoo 19 hours agoparentprevI feel like the major life events always put our life span into a perspective that otherwise might be missed or overlooked. It makes life feel shorter than it is. Btw, which post are you referring to? I am curious to read it as well. reply speg 19 hours agorootparenthttps://news.ycombinator.com/item?id=42113113 reply pavel_lishin 17 hours agoparentprevWe're aging. This is becoming more appealing. reply anal_reactor 9 hours agoparentprevThere are three groups of people on HN: - kids who just graduated and realize that they've been told lies and need some life advice - midlife crisis - retirees who can see the death slowly approaching and reevaluate their lives in panic reply 01HNNWZ0MV43FF 34 minutes agorootparentPersonally I intend to have as many midlife crises as I can afford reply jjw1414 3 hours agorootparentprevWhich group are you in? reply ChrisMarshallNY 4 hours agoprevA slight modification for my own philosophy: I always go to the wake/memorial. The funeral (burial/internment) is usually for close family only. I will go, if it is appropriate, but usually, not. Sometimes, the funeral mass is more open than the actual burial. I had a friend propose that we hire a woman and a child to stand a hundred yards away from the burial of a [male] friend, and leave before anyone can approach them, to add some mystery to the event. reply strict9 20 hours agoprevI agree with this completely. A small but important suggested addition: if it's someone who's funeral you would go to, tell that person now what they mean to you. Then they can hear it while they are still alive. It is not a given that you will have enough time to tell them later. reply dylan604 20 hours agoparentsometimes, not going to the funeral is the message to be said and saying it to them \"now\" is considered rude. clearly, the message of not attending is being said to others not to the person, but you get the gist reply elzbardico 20 hours agorootparentThe person died, what message can you want to send to a dead person. He/She is dead. He can't hear it. But you can forgive and believe me, feel better about whatever happened that made you want to send a message that would never be received. reply dylan604 19 hours agorootparent> what message can you want to send to a dead person you ask me that after I said \"clearly, the message of not attending is being said to others not to the person, but you get the gist\" so clearly, you didn't get the gist. not attending says something to the other friends/family that did attend. the knee jerk reaction is \"what an asshole to not attend\" typically followed by \"I wonder what happened that would make them not attend\". then the gossiping begins and the person sending the message smiles a wry smile reply elzbardico 19 hours agorootparentYeah, I got that. It is just that I think it is now pointless. Like, he/she is dead. reply dylan604 19 hours agorootparentwhy do you keep referring to the dead person like that's the point of the not going? you're sending a message to those that do go by not going. the subject of the message is the deceased not the recipient. reply elzbardico 19 hours agorootparentAh. I thought you had a beef with the dead. Ok. I can respect that. It is just that as I was thinking the dead was the target, it would be better to make sure you get whatever retribution while he is alive. reply ludwigvan 10 hours agoprevA corollary of this is “Always visit when a baby is born.” (In the first few months, if not at the hospital) I have noticed my love and respect for my friends who never visited after our newborn declined significantly, and it has never been the same. Does anyone have a similar experience? reply JansjoFromIkea 7 hours agoparentHow much of this is due to them not visiting and how much is due to the change in dynamics though? Think it's conceivable them not wanting to see the baby early on or in the hospital might suggest a fairly critical divergence of interests reply xandrius 5 hours agoparentprevWell, if you don't see someone for over a span of a year then probably you're not too close anymore? Then I'd assume that if 1 person had a really good reason not to be physically around for the first few months, you wouldn't think less of them if they make it up afterwards. reply mettamage 9 hours agoparentprevThanks, this teaches me quite a bit. I will be more mindful of this reply block_dagger 4 hours agoprevI declined to attend one of my grandfathers’ funerals. I did not consider him a good man and did not feel love for him while he was alive. I have never regretted it. reply qup 4 hours agoparentIt's not about attending in spite of disdain or contempt. I think you would be advised to skip that one. reply colanderman 4 hours agoprevI'm surprised in all this discussion not to see the distinction between a wake and a funeral. The advice I've heard is, go to a wake to support those who are grieving, go to a funeral to grieve yourself. (For this reason, the wake is held at more \"convenient\" hours.) Do others make this distinction? Is the practice of holding a separate wake a regional/cultural thing? reply seanhunter 4 hours agoparentI think the naming varies. In the UK for example, the funeral typically indicates a religious thing and the wake is the reception thing you go from the funeral to .It's usually in a pub. There's usually bad food. You have a drink. You have a good conversation with all the people you haven't seen for ages. You remember your friend/family member/colleague whatever who is dead. reply colanderman 3 hours agorootparentOh interesting! My background is northeast US; the wake (a.k.a. calling hours) precedes the funeral, typically the evening prior. There's no food, it's not religious (held at the funeral home), and well-wishers stop by for the reasons you mentioned. There's a sign-up sheet for those who will be attending the funeral. There is also a reception at a restaurant immediately after the funeral; this is almost strictly for close friends and family though. reply mattl 4 hours agoparentprevI think the wake is more of a Catholic thing perhaps? reply colanderman 3 hours agorootparentMaybe (I was raised Catholic), but I also attended a wake of a teacher of mine who was Jewish (culturally if not religiously). Thinking more now, where I'm from (northeast US), \"wake\" and \"calling hours\" are synonymous, whereas they might not be in other parts of the world. So I may be perpetuating some confusion of terms. reply JKCalhoun 2 hours agoprevThat was a beautiful piece. Well written, concise. My grandmother was the only relative of that generation that lived in the same city when I was young — the only funeral I went to. But as an adult, having my mother recently die, it was my turn to more or less head up the funeral. I too was touched by, in this case, relatives of my wife that showed up. They didn't know my mom from Adam but came anyway. reply fraserphysics 2 hours agoprevI agree with the article, and I find many of the comments here insightful. Relationships with some of my old school adversaries were healed when they attended my son's funeral. The movie Charade is sort of about the bad effects of a poorly attended funeral. See https://www.youtube.com/watch?v=a8FA5zBHiFA reply jaydeegee 19 hours agoprevFunerals aren't for the one who passed they're for the ones left behind. Be there for the ones left behind and remember you are one of the ones left behind. reply Neil44 10 hours agoprevEvery time you go to a funeral you sit a bit closer to the front. reply begueradj 11 hours agoprevTotally agree. In my culture (Berber), each time any of your relatives gets sick, you also must visit him/her and bring something with you for him/her (usually nice food/fruits and/or money). reply keybored 25 minutes agoprev> \"Always go to the funeral\" means that I have to do the right thing when I really, really don't feel like it. I have to remind myself of it when I could make some small gesture, but I don't really have to and I definitely don't want to. I'm talking about those things that represent only inconvenience to me, but the world to the other guy. You know, the painfully under-attended birthday party. The hospital visit during happy hour. The Shiva call for one of my ex's uncles. In my humdrum life, the daily battle hasn't been good versus evil. It's hardly so epic. Most days, my real battle is doing good versus doing nothing. This hinges on your level of self-importance. reply nlavezzo 3 hours agoprevHN has never made me cry before, but here I am crying. This is really a wonderful article and discussion. Makes me appreciate this community even more. reply JansjoFromIkea 7 hours agoprev\"By the time I was 16, I had been to five or six funerals\" May be an Irish specific thing but I probably had been to 16 by the time I was five or six. reply 01HNNWZ0MV43FF 28 minutes agoparentI think I'm the most sheltered person I've ever known. 1 funeral, mid-30s. I'm expecting 1 more regular one when my dad dies, then a horrible one when my brother dies, and then my cohort will be called. reply Aachen 2 hours agoparentprevI'm 30 and haven't been to 5 funerals. Not that many people that I know died, or at least not that I know of (maybe a primary school teacher did in the meantime but I'm not living in the same area anymore). Might going to so many be a village culture thing, where everyone knows everyone and so you know of a lot more deaths? reply bananatype 6 hours agoparentprevI'd say it's also likely an Asian thing. In my country (the Philippines), it's not uncommon for people to bring their children with them to funerals. I've been to the wakes of almost every elderly family member. It was also a good opportunity, however morbid the circumstances, to connect with the rest of the extended family, even those people who I didn't realize---until then---were my relatives after all. reply searls 13 hours agoprevAs somebody whose dad died last night, this one hits hard. reply demarq 9 hours agoparentThat's terrible and I can't imagine how you feel, Sorry for your loss. reply Sn0wCoder 11 hours agoparentprevSorry for your loss. Hope they lived a great life, and you can make it to the funeral. reply crabbone 2 hours agoprevIdk. Nobody ever invited me and I don't know anyone closely enough for even knowing if anyone in their family died. I'll be fifty soon, and, I have an impression that the only funeral I'll ever attend will be my own, if there even will be a funeral :| reply chairmansteve 17 hours agoprevYes. And always go to the wedding. reply Etherlord87 17 hours agoprevLuke 9:60 > Let the dead bury the dead reply bluGill 4 hours agoparentWe don't know for sure, but it is often said that the father wasn't dead in that story. That is the person in question was really saying \"I don't want to tell my family what I'm doing, once they are gone I'll follow you\". (timelines are not clear, but Jesus likely died a couple years latter so the opportunity to follow Jesus would have ended long before the parents died) reply lambdaphagy 19 hours agoprevSound advice. Conversely: always have a funeral. I know several people who expressed a wish not to have a funeral. Sometimes this wish stems from a desire not to be an inconvenience, or a sense of guilt or shame that one's life was not well-lived. Sometimes, simply the view that funerals don't matter, so why bother. In every case, I think this desire is mistaken. The need to mourn the dead is an instinct older than our species itself, and in dismissing it we wound the people closest to us. If you're the sort of person to whom the idea of skipping your own funeral sounds tempting, I kindly ask you for the sake of your loved ones that you reconsider. reply Baeocystin 12 hours agoparentI (politely) disagree. My father did not wish a funeral, and, per his wishes, we did not hold one for him. And honestly, standing at his gravesite paying my respects, I do not have the painful memories that I had with my mother's funeral, trying to organize, trying to handle everyone and everything, and not being able to grieve in the way that I wanted until long after. Instead, I am able to simply talk to him, and not have such a frustrating coda. They say that funerals are for the living. Sure. But going to funerals of loved ones has never made me feel better in the long run compared to more private goodbyes, and I am not the only one to feel this way. reply cheema33 6 hours agorootparentI am in this camp. I have been to the funerals of loved ones and once helped arrange one for a close family member. It was a very stressful affair. But I also recognize that other people got more out of it than did I. They cried and hugged and shared memories. That experience I am assuming was very valuable to them. But not to me. I was stressed the entire time. The lesson I learned was that funerals are valuable to some while not others. reply blahedo 18 hours agoparentprevYes, agreed. My dad said he didn't want a wake or funeral---I think he didn't want to put anyone out---but we overruled him, because the services weren't for him. Once he thought about that, he agreed (and gave some input on their planning, which was interesting). In the end it brought together a lot of people who hadn't seen each other in a very long time, which I appreciated, and I got to hear some stories I'd never heard before, which I also appreciated, and it made the whole process just feel a lot easier to deal with. reply jfengel 19 hours agoparentprevA memorial service is a very good thing to do, for those left behind. The body does not need to be present for a memorial, as it is for a funeral. That makes it a somewhat easier event to arrange. reply lupire 19 hours agoparentprevI don't think a significant number of people have ever written a will that actively prevented a funeral. A funeral doesn't require the deceased. It's fine to skip it. reply lambdaphagy 17 hours agorootparentMaybe a more charitable reading is: \"make every good faith effort to cooperate with your family's attempts to mourn your death\" reply o11c 19 hours agoprev> By the time I was 16, I had been to five or six funerals. Is it just me or does this actually seem kind of low? They say your social cluster is 150 people, so you should be going to about 2 funerals every year (this ignores age-clustering, but that's counterbalanced by the fact that you often go to funerals slightly outside your cluster and the fact that the cluster changes over time). reply sanderjd 2 hours agoparentI was going to write this at the top level because I hadn't seen anyone make this point yet: The thing that made me sad about this article is that it made me realize how lacking I am in community. My eldest child is six, and I can't think of more than a couple people who are likely to pass from natural causes by the time she is sixteen, who we are close enough with to definitely know about their funeral. And I have no idea how we would find out about the funerals of people we aren't so close to. It's not like there is a local paper with obituaries that we read... Of course the elephant in the room is that when I was a kid, the coordinating organization for this was my family's church. Without having that community fixture, I find myself unsure how this sort of thing actually works. reply blahedo 18 hours agoparentprevMy sister and I were talking about this recently (at a funeral in our family). We're in our 40s, and people older than us had largely been to a dozen funerals or more by their teenage years, while people younger than us often went to their first in their 20s or later (or perhaps when their own parents or grandparents died and to no others). We have not-entirely-negative memories of growing up going to funerals, because that's where we saw and caught up with extended family, so funerals are... well, not exactly easy, but they're not traumatic in their own right. For some of our slightly younger friends, though, even attending the wake and funeral in our family, they were having a harder time than we were. And almost none of our cousins brought their kids. For the author, six by 16 probably was a lot more than any of her friends, yes. It's an interesting shift. A loss, I think. reply smeej 7 hours agorootparentI was forbidden from going to my great-grandmother's funeral with my parents even though I was 11 and an extremely well-disciplined child. \"We want you to remember her as she lived, not as she died\" was the reason given at the time, but leaving me out of the event where people were remembering her as she lived didn't make sense to me. When my grandfather died when I was 15, not only wasn't I allowed to go, but I had to stay home and watch my siblings as my parents traveled a thousand miles away for a week. We more than had the money for plane tickets. They just didn't want to bring us (youngest was 10, and also not troublesome). For my other older relatives, they've all insisted on not having services, and I can't help but feel it's both an effect and a cause of the fact that my extended family is very disconnected and fragmentary. reply 01HNNWZ0MV43FF 23 minutes agorootparentOkay, same here. It's not like I'm cutting people off because I'm a millennial. My parents are / were just very distant from their families, didn't make much effort to tie their children into their adult social networks, etc. I went to the only funeral I was ever invited to lol. reply michaelt 18 hours agoparentprevGenerally the number of your friends who have funerals is heavily biased towards the end of your life. America's average lifespan is 77. When you're 16, your parents are perhaps 46, and their parents are maybe 76. And a lot of people live for 10+ years after retirement, so your teachers might all be alive too. If you've got a big extended family, or you're part of an organisation like a church where 16 year olds come are getting to know 70+ year olds, you might have gone to more than 6 funerals. But generally? At 16 your parents, their friends, your aunts and uncles, your 16 year old friends, their parents? Good chance they're all still alive. Your grandparents - maybe, maybe not. reply bluGill 4 hours agorootparentYour grandparents also have siblings, and your parents would drag you to those funerals. You should also have people of many different ages in your social group and some of them will die of old age (and once in a while someone young). reply sanderjd 2 hours agorootparent> You should also have people of many different ages in your social group \"Should\" seems right, but in practice, do young people have this? How? (Thinking of the US here.) When I was a kid, this came through church. But church attendance among the young has fallen off a cliff, with (to my knowledge) no replacement. reply dspillett 4 hours agoparentprevSounds within the right range to me. By that time I think I'd have been to five that I remember (a great-grandparent, a grandparent, an uncle, a great aunt, a school friend who was skittled on his morning paper-round). There may have been others that I was too young at the time to remember now. For me, funerals and similar services are more for family and close (or at least close-ish) friends. My social cluster might number 150, but there are many in it for whom I'll pass on my regards & regrets from afar rather than attending a funeral or wake. Are you attending 2 funerals every year, even averaged over a couple of decades to allow for clustering? I can think of one year when there were three, but that nowhere near makes up for the years when there were none or just one. reply o11c 1 hour agorootparentI'm not sure I'm quite hitting 2, but it's pretty close. I just sat down and made a list purely from memory, and got 1 per year since I started persisting memories. And I have to be forgetting some. In fact, the actual number includes a significant decrease due to excluding \"funerals I would've gone to if I didn't have a more important funeral to go to\" and \"people who moved away before they died\". Thankfully in recent years remote recording is usually a thing in some form (live or not, video or just audio; the quality depends significantly on the funeral home). reply wat10000 17 hours agoparentprevI’m in my 40s and I’ve been to four, for each of my grandparents. That age clustering thing seems very important to me. For most of my life, my grandparents were the only people I knew well who were around that age. Even now, there aren’t anywhere near 150 people whose funeral I’d attend. reply Spooky23 5 hours agoparentprevDepends on your relative age and family size. For me, my 40s are for funerals like my late 20s were for weddings. Nowadays many families have just one or two kids and everyone is spread over all of country and world. reply tivert 19 hours agoparentprev>> By the time I was 16, I had been to five or six funerals. > Is it just me or does this actually seem kind of low? Not for someone who's young and mostly disconnected from their grandparents' generation. In my case, my family lived far away from pretty much all my relatives, which meant I'm not very close to any of them and going to a funeral meant lots of short-notice plane tickets. I think I've only gone to two funerals in my life: one grandparent who died geographically close to use when I was a kid, and the father (who I never met) of a friend of mine. I think it would have been better if it had been different, and I had gone to more funerals, because now my lack of exposure adds a whole extra layer of awkwardness onto dealing with death. reply jerlam 18 hours agorootparentEven if I was close to my grandparents' generation, I only have four of them and that number doesn't increase over time. I don't think I know 16 * 2 = 32 people of my grandparents' generation, especially not now, way past my teenage years. reply tivert 11 hours agorootparent> Even if I was close to my grandparents' generation, I only have four of them and that number doesn't increase over time. The scenario I was thinking of to get to more than \"five or six\" funerals by age 16, was to have \"always go to the funeral\" parents who took you to the funerals of grandparents and great aunts/uncles living nearby. reply jfengel 19 hours agoparentprevI don't know if I'd go to the funerals of all 150 people in my set. Most of them are acquaintances rather than friends or family. I go to much fewer than 2 funerals per year. But now that I'm 55 it will likely start picking up. reply seryoiupfurds 18 hours agoparentprevReally? I'm in my 30s and I've been to fewer than that. > They say your social cluster is 150 people Maybe yours is. reply D13Fd 18 hours agoparentprevHonestly that seemed really high to me. I went to my first funeral at 41. I did go to a couple of viewings/wakes before that. I’m not religious, and I guess I just don’t know enough people who would invite me to a funeral. reply SoftTalker 2 hours agorootparentI'm almost 60 and have only been to a handful of funerals. One or two as a kid for my grandparents who I don't even really remember, one in high school for a friend, and a few other relatives and friends on my wife's side of the family. reply dennis_jeeves2 19 hours agoparentprev>Is it just me or does this actually seem kind of low? Yes, it's low. reply lupire 19 hours agoparentprevSome of us had our family dispatched in bulk, but thanks. reply zamadatix 19 hours agorootparentE.g. the article is about their 5th grade math teacher. reply consf 11 hours agoprevFunny how we spend so much time optimizing the big things in life while it's often the small, inconvenient gestures that stick with people forever reply smitty1e 20 hours agoprevEcclesiastes 7:4 \"The heart of the wise is in the house of mourning; but the heart of fools is in the house of mirth.\" https://bible.com/bible/1/ecc.7.4.KJV reply 01HNNWZ0MV43FF 19 hours agoparentMy dad is an atheist but he believes in that. He hates seeing other people happy reply pavel_lishin 17 hours agoparentprevThe House of Mirth would be a great name for a bar, or a theater. Or anything, really. Come to think of it, so would The Heart of Fools. reply antonchekhov 14 hours agorootparentCoincidentally there is literally the novel \"The House of Mirth\" by Edith Wharton - published in 1905, it's an excellent late-Victorian/Gilded-Age period novel about the slow downfall of Lily Bart, a woman who was in New York's high society, then through a series of unfortunate events and social reproaches, descended into lonely poverty. It was quite influential at the time, portraying the materialism and shallowness of the moneyed crowd. reply einpoklum 20 hours agoprevA valid point and a good approach. But it's quite a bad pun when used as a title here on HN - and with the capitalization, too. reply lupire 19 hours agoparentWhat pun/title? reply einpoklum 10 hours agorootparent\"Always Go\", like the programming language. But - I see the editors changed the capitalization, so it's good that you didn't notice. reply EVa5I7bHFq9mnYK 18 hours agoprevClever marketing by the funeral services industry. And no, I don't want my last act on Earth to be inconveniencing people. reply throw_pm23 3 hours agoparentWhy do you think it is an inconvenience for people to meet other people they know and/or like? You could see it as a last gift from you to bring them together. reply throw4847285 3 hours agoparentprevOK, so go to the wake or the shiva or whatever. You don't have to buy into the funeral industrial complex to believe it's important to honor the dead. In fact, I think you have it exactly backwards. The industry popped up in order to exploit a deep human need. It did not create that need. reply ksenzee 18 hours agoparentprev> I don’t want my last act on Earth to be inconveniencing people. There’s no way around that. Death inconveniences the living. Your death will probably make a mess of some kind. Your dead body will have to be buried or cremated, or it will be an even bigger inconvenience. Your effects will have to be split up among the living in some way. And if you find funerals to be an inconvenience, don’t go. But don’t kid yourself into thinking that everyone will be happier if you insist on no funeral. Many of us want to gather with everyone else who cared about the person who died, and it feels strange and wrong to be denied the opportunity. Funerals are for the living anyway. Let the living make their own decisions about what events they want to hold and attend. reply EVa5I7bHFq9mnYK 18 hours agorootparent>> There’s no way around that. But that could be minimized. For example, by not taking precious square meters of Earth surface from the living. >> Your effects will have to be split up among the living in some way. That's not inconvenience :) reply ksenzee 16 hours agorootparent> But that could be minimized. For example, by not taking precious square meters of Earth surface from the living. I understand and even agree with the sentiment here, but to me “I don’t want to be buried” or “I don’t want a funeral” is micromanaging. I’ve expressed a preference for as little inconvenience to the people I love and as little damage to the Earth as possible. My children or whoever else survives me can make whatever decisions work for them. I don’t want my last act to be ordering them around. My dad, for example, had always planned to be buried, but when he was nearing death he suddenly said he wanted to be cremated, which was distressing to some of the family and was going to mean redoing a bunch of plans. When we asked him what was behind this sudden change of mind, it turned out he didn’t actually care one way or the other, he’d just recently found out cremation was less expensive and he was trying to save us money. Turns out it’s important to say what you really mean—“I love you and want to save you inconvenience and grief”—rather than “I don’t want a funeral” or “I don’t want to be buried” or whatever. > That’s not inconvenience :) Heh. You must not have been executor of anyone’s estate. It’s pretty inconvenient. All I can hope for is to have enough money that it’ll be worth it to whichever kid ends up doing it. reply EVa5I7bHFq9mnYK 12 hours agorootparentAs part of my plan of not inconveniencing anyone, I already doled out kids' inheritance in cash and real estate, and will donate the rest. I also rented 100-years storage at forever.com, so nobody has to deal with my old photos, memorabilia etc. Everything else is a matter of 2 hours' work by a garbage disposal team. Executors can walk. reply throw_pm23 3 hours agorootparentI predict your 100-years storage to last about 2 years. reply EVa5I7bHFq9mnYK 51 minutes agorootparentWonna bet? reply foobarchu 14 hours agorootparentprev> That's not inconvenience It frequently is. In fact, it tends to be a more difficult form of grieving in my opinion because now they are forced to throw away things that were yours because they know nobody else wants them. Your bedding, your old spice cabinet, the magazines you never threw out. All of those are more for your heirs to deal with emotionally and physically. reply pavel_lishin 17 hours agorootparentprevA funeral isn't the same thing as a burial. reply pessimizer 4 hours agoparentprevhttps://en.wikipedia.org/wiki/The_American_Way_of_Death reply kayo_20211030 19 hours agoprevAlways go to the funeral! It's not for you, and it's not for other people. It's just a thing. It's not an analogy about doing the right thing. It's just going to the funeral. That's what you should do, for lots of reasons. When you do it, you'll know why; maybe later, but you'll know. reply etskinner 12 hours agoparentIt definitely is for you and for other people. I challenge you to describe what it's for if not those two things reply santoshalper 20 hours agoprevDo the right thing even when you really don't want to is a valuable lesson, but I'm not sure I believe that the right thing to do is attend funerals for people who you were not actually close to. It feels extremely insincere. reply massysett 20 hours agoparentIt's not just whether you were close to the deceased; it's do you know the survivors. I've attended funerals where I never met the deceased but knew a survivor. reply AnimalMuppet 19 hours agorootparentYeah. Went with my cousin-in-law to his grandmother's funeral. I had maybe met her twice. It wasn't for her. Meant a lot to him, though. reply sellmesoap 20 hours agoparentprevI've gone to the funeral of a community leader who I only met a couple of times, but the stories of their life and seeing how they had touched the people around them was inspiring and I hold those stories dearly and feel the loss of the community. Hardly insincere. reply bloodyplonker22 19 hours agoparentprevI've attended the funerals of my enemies just to pay my respects for the rivalry that we had. reply tivert 19 hours agorootparent> I've attended the funerals of my enemies just to pay my respects for the rivalry that we had. What? You have enemies? Like the Joker and Batman or Lex Luthor and Superman? Honestly, to me, that word describes a kind of relation that mainly exists in comic books and between nation states. reply schmookeeg 18 hours agorootparentI have a few folks who I felt wronged me significantly in my life's travels, and they take a bit of rent-free space in my head every once in awhile. I don't actively search for their obits or anything, but if I learned about a funeral, I'd make the time to visit, stand quietly, and reflect. Probably not the healthiest thing, but not my unhealthiest quality either. At the moment it is only theoretical. But I can think of 3 or 4 I'm now likely to google up and see what they're up to and assess who is closer to the pine box. :) reply tivert 11 hours agorootparent> I have a few folks who I felt wronged me significantly in my life's travels, and they take a bit of rent-free space in my head every once in awhile. Do you have grudge against those people, such that put effort into trying to undermine or defeat them? I feel the word \"enemy\" has connotations of a kind of direct, sustained opposition that just seems like it'd be really unusual (and unhealthy) in real life. reply sneak 11 hours agoprevAlternately; this anachronistic idea that not going to a religious ceremony is “the wrong thing” can be disregarded. I never attend funerals, and I rarely attend weddings. I skipped my father’s funeral. It simply doesn’t matter if you go or not. reply colanderman 4 hours agoparentIt matters a lot to those who are grieving. Consider that funerals may have developed over millennia as a component of the grieving process. There is nothing necessarily religious about them. reply throw_pm23 3 hours agoparentprevReminded me of the famous quote by Twain: \"When I was a boy of 14, my father was so ignorant I could hardly stand to have the old man around. But when I got to be 21, I was astonished at how much the old man had learned in seven years.\" reply wvlia5 8 hours agoprevLosing relationships to death feels strangely not bad to me. Losing relationships for other reasons that shouldn't happen, like fights, feels bad. It's like eating a cake. You eat and at some point there will be no more cake, and you can rest content. But if the cake falls to the floor while you are eating, it's sad. reply smeej 7 hours agoparentThis sounds like you're only thinking of people who die very old. When my 99yo grandmother died, it felt natural, like it was the time for such things. She'd eaten all her cake. When my 29yo sister died, it was completely different, even though her death was also natural and did not involve suffering (sudden cardiac death, because invariably someone will ask). Sure, she'd had some cake, but it seemed like most of it was ahead of her, and the cake didn't fall to the floor, it just sat there, uneaten and uneatable, which feels both sad and wrong. At least if there had been a fight, there would be hope for reconciliation, or even if that weren't possible, we could still be glad to hear good news about each other's life. (Rarely does so much hatred endure forever that you can't ever be glad when good things happen to somebody.) Death is worse. reply 01HNNWZ0MV43FF 19 minutes agoparentprevSome people are just more accepting and more living-in-the-moment types. As for me, I could always use more cake. I have high expectations! reply wvlia5 8 hours agoparentprevI remember my first death. My mum came and said: \"your cousin died\". I felt nothing, I different. I had a great relationship with him. Seeing my non-reaction, my mum said : \"you can cry\". So I thought: \"oh, so I should cry now, that's the appropiate thing to do in these situations\", then I started crying. reply throw4847285 3 hours agorootparentSure, there's nothing special about that. Many people are too young to understand the finality of death when they first encounter it. Death becomes harder the older you get. When my grandmother died this year I felt a much heavy series of emotions than just sadness. It's the finality of it that gets you. reply pessimizer 4 hours agoparentprevBe careful, or they'll lock you up. The appropriate reaction to death has been determined, and deviations are considered at best a form of mental illness, and at worst a form of terrorism. The appropriate reaction is the wailing and gnashing of teeth, an enormous amount of discussion, imitating as closely as possible the dress and decor of previous death gatherings that you have references to, varnishing, buttressing, and putting makeup on the corpse so that it looks alive, then looking at it longingly. If you don't do this you're a psychopath. reply 01HNNWZ0MV43FF 20 minutes agorootparentThe appropriate response is certainly not to make fun of people online, and yet here we stand. reply a3w 1 hour agoprev [–] I will not attend any more funerals, unless I get the church to stay out of it. The priests at the last events I attended to did not know the diseased. Even the wedding speeches I heard took place with nothing concrete on the people in questions. As for mostly church funerals in my significant others or my family: - Boring while overwhelming, - a farce since everyone planning it is either fighting or not caring enough to start a fight, - and not at all about dealing with death in a good way (grief, laughter, moving on. Something cultural should happen, but no one at the events ever found it. Only jealousy and nepotism were present if you heard any discussion about real values of having those funerals. And those came up behind closed doors.) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [],
    "points": 416,
    "commentCount": 246,
    "retryCount": 0,
    "time": 1734386670
  },
  {
    "id": 42434947,
    "title": "Go Protobuf: The New Opaque API",
    "originLink": "https://go.dev/blog/protobuf-opaque",
    "originBody": "The Go Blog Go Protobuf: The new Opaque API Michael Stapelberg 16 December 2024 [Protocol Buffers (Protobuf) is Google’s language-neutral data interchange format. See protobuf.dev.] Back in March 2020, we released the google.golang.org/protobuf module, a major overhaul of the Go Protobuf API. This package introduced first-class support for reflection, a dynamicpb implementation and the protocmp package for easier testing. That release introduced a new protobuf module with a new API. Today, we are releasing an additional API for generated code, meaning the Go code in the .pb.go files created by the protocol compiler (protoc). This blog post explains our motivation for creating a new API and shows you how to use it in your projects. To be clear: We are not removing anything. We will continue to support the existing API for generated code, just like we still support the older protobuf module (by wrapping the google.golang.org/protobuf implementation). Go is committed to backwards compatibility and this applies to Go Protobuf, too! Background: the (existing) Open Struct API¶ We now call the existing API the Open Struct API, because generated struct types are open to direct access. In the next section, we will see how it differs from the new Opaque API. To work with protocol buffers, you first create a .proto definition file like this one: edition = \"2023\"; // successor to proto2 and proto3 package log; message LogEntry { string backend_server = 1; uint32 request_size = 2; string ip_address = 3; } Then, you run the protocol compiler (protoc) to generate code like the following (in a .pb.go file): package logpb type LogEntry struct { BackendServer *string RequestSize *uint32 IPAddress *string // …internal fields elided… } func (l *LogEntry) GetBackendServer() string { … } func (l *LogEntry) GetRequestSize() uint32 { … } func (l *LogEntry) GetIPAddress() string { … } Now you can import the generated logpb package from your Go code and call functions like proto.Marshal to encode logpb.LogEntry messages into protobuf wire format. You can find more details in the Generated Code API documentation. (Existing) Open Struct API: Field Presence¶ An important aspect of this generated code is how field presence (whether a field is set or not) is modeled. For instance, the above example models presence using pointers, so you could set the BackendServer field to: proto.String(\"zrh01.prod\"): the field is set and contains “zrh01.prod” proto.String(\"\"): the field is set (non-nil pointer) but contains an empty value nil pointer: the field is not set If you are used to generated code not having pointers, you are probably using .proto files that start with syntax = \"proto3\". The field presence behavior changed over the years: syntax = \"proto2\" uses explicit presence by default syntax = \"proto3\" used implicit presence by default (where cases 2 and 3 cannot be distinguished and are both represented by an empty string), but was later extended to allow opting into explicit presence with the optional keyword edition = \"2023\", the successor to both proto2 and proto3, uses explicit presence by default The new Opaque API¶ We created the new Opaque API to uncouple the Generated Code API from the underlying in-memory representation. The (existing) Open Struct API has no such separation: it allows programs direct access to the protobuf message memory. For example, one could use the flag package to parse command-line flag values into protobuf message fields: var req logpb.LogEntry flag.StringVar(&req.BackendServer, \"backend\", os.Getenv(\"HOST\"), \"…\") flag.Parse() // fills the BackendServer field from -backend flag The problem with such a tight coupling is that we can never change how we lay out protobuf messages in memory. Lifting this restriction enables many implementation improvements, which we’ll see below. What changes with the new Opaque API? Here is how the generated code from the above example would change: package logpb type LogEntry struct { xxx_hidden_BackendServer *string // no longer exported xxx_hidden_RequestSize uint32 // no longer exported xxx_hidden_IPAddress *string // no longer exported // …internal fields elided… } func (l *LogEntry) GetBackendServer() string { … } func (l *LogEntry) HasBackendServer() bool { … } func (l *LogEntry) SetBackendServer(string) { … } func (l *LogEntry) ClearBackendServer() { … } // … With the Opaque API, the struct fields are hidden and can no longer be directly accessed. Instead, the new accessor methods allow for getting, setting, or clearing a field. Opaque structs use less memory¶ One change we made to the memory layout is to model field presence for elementary fields more efficiently: The (existing) Open Struct API uses pointers, which adds a 64-bit word to the space cost of the field. The Opaque API uses bit fields, which require one bit per field (ignoring padding overhead). Using fewer variables and pointers also lowers load on the allocator and on the garbage collector. The performance improvement depends heavily on the shapes of your protocol messages: The change only affects elementary fields like integers, bools, enums, and floats, but not strings, repeated fields, or submessages (because it is less profitable for those types). Our benchmark results show that messages with few elementary fields exhibit performance that is as good as before, whereas messages with more elementary fields are decoded with significantly fewer allocations: │ Open Struct API │ Opaque API │ │ allocs/op │ allocs/op vs base │ Prod#1 360.3k ± 0% 360.3k ± 0% +0.00% (p=0.002 n=6) Search#1 1413.7k ± 0% 762.3k ± 0% -46.08% (p=0.002 n=6) Search#2 314.8k ± 0% 132.4k ± 0% -57.95% (p=0.002 n=6) Reducing allocations also makes decoding protobuf messages more efficient: │ Open Struct API │ Opaque API │ │ user-sec/op │ user-sec/op vs base │ Prod#1 55.55m ± 6% 55.28m ± 4% ~ (p=0.180 n=6) Search#1 324.3m ± 22% 292.0m ± 6% -9.97% (p=0.015 n=6) Search#2 67.53m ± 10% 45.04m ± 8% -33.29% (p=0.002 n=6) (All measurements done on an AMD Castle Peak Zen 2. Results on ARM and Intel CPUs are similar.) Note: proto3 with implicit presence similarly does not use pointers, so you will not see a performance improvement if you are coming from proto3. If you were using implicit presence for performance reasons, forgoing the convenience of being able to distinguish empty fields from unset ones, then the Opaque API now makes it possible to use explicit presence without a performance penalty. Motivation: Lazy Decoding¶ Lazy decoding is a performance optimization where the contents of a submessage are decoded when first accessed instead of during proto.Unmarshal. Lazy decoding can improve performance by avoiding unnecessarily decoding fields which are never accessed. Lazy decoding can’t be supported safely by the (existing) Open Struct API. While the Open Struct API provides getters, leaving the (un-decoded) struct fields exposed would be extremely error-prone. To ensure that the decoding logic runs immediately before the field is first accessed, we must make the field private and mediate all accesses to it through getter and setter functions. This approach made it possible to implement lazy decoding with the Opaque API. Of course, not every workload will benefit from this optimization, but for those that do benefit, the results can be spectacular: We have seen logs analysis pipelines that discard messages based on a top-level message condition (e.g. whether backend_server is one of the machines running a new Linux kernel version) and can skip decoding deeply nested subtrees of messages. As an example, here are the results of the micro-benchmark we included, demonstrating how lazy decoding saves over 50% of the work and over 87% of allocations! │ nolazy │ lazy │ │ sec/op │ sec/op vs base │ Unmarshal/lazy-24 6.742µ ± 0% 2.816µ ± 0% -58.23% (p=0.002 n=6) │ nolazy │ lazy │ │ B/op │ B/op vs base │ Unmarshal/lazy-24 3.666Ki ± 0% 1.814Ki ± 0% -50.51% (p=0.002 n=6) │ nolazy │ lazy │ │ allocs/op │ allocs/op vs base │ Unmarshal/lazy-24 64.000 ± 0% 8.000 ± 0% -87.50% (p=0.002 n=6) Motivation: reduce pointer comparison mistakes¶ Modeling field presence with pointers invites pointer-related bugs. Consider an enum, declared within the LogEntry message: message LogEntry { enum DeviceType { DESKTOP = 0; MOBILE = 1; VR = 2; }; DeviceType device_type = 1; } A simple mistake is to compare the device_type enum field like so: if cv.DeviceType == logpb.LogEntry_DESKTOP.Enum() { // incorrect! Did you spot the bug? The condition compares the memory address instead of the value. Because the Enum() accessor allocates a new variable on each call, the condition can never be true. The check should have read: if cv.GetDeviceType() == logpb.LogEntry_DESKTOP { The new Opaque API prevents this mistake: Because fields are hidden, all access must go through the getter. Motivation: reduce accidental sharing mistakes¶ Let’s consider a slightly more involved pointer-related bug. Assume you are trying to stabilize an RPC service that fails under high load. The following part of the request middleware looks correct, but still the entire service goes down whenever just one customer sends a high volume of requests: logEntry.IPAddress = req.IPAddress logEntry.BackendServer = proto.String(hostname) // The redactIP() function redacts IPAddress to 127.0.0.1, // unexpectedly not just in logEntry *but also* in req! go auditlog(redactIP(logEntry)) if quotaExceeded(req) { // BUG: All requests end up here, regardless of their source. return fmt.Errorf(\"server overloaded\") } Did you spot the bug? The first line accidentally copied the pointer (thereby sharing the pointed-to variable between the logEntry and req messages) instead of its value. It should have read: logEntry.IPAddress = proto.String(req.GetIPAddress()) The new Opaque API prevents this problem as the setter takes a value (string) instead of a pointer: logEntry.SetIPAddress(req.GetIPAddress()) Motivation: Fix Sharp Edges: reflection¶ To write code that works not only with a specific message type (e.g. logpb.LogEntry), but with any message type, one needs some kind of reflection. The previous example used a function to redact IP addresses. To work with any type of message, it could have been defined as func redactIP(proto.Message) proto.Message { … }. Many years ago, your only option to implement a function like redactIP was to reach for Go’s reflect package, which resulted in very tight coupling: you had only the generator output and had to reverse-engineer what the input protobuf message definition might have looked like. The google.golang.org/protobuf module release (from March 2020) introduced Protobuf reflection, which should always be preferred: Go’s reflect package traverses the data structure’s representation, which should be an implementation detail. Protobuf reflection traverses the logical tree of protocol messages without regard to its representation. Unfortunately, merely providing protobuf reflection is not sufficient and still leaves some sharp edges exposed: In some cases, users might accidentally use Go reflection instead of protobuf reflection. For example, encoding a protobuf message with the encoding/json package (which uses Go reflection) was technically possible, but the result is not canonical Protobuf JSON encoding. Use the protojson package instead. The new Opaque API prevents this problem because the message struct fields are hidden: accidental usage of Go reflection will see an empty message. This is clear enough to steer developers towards protobuf reflection. Motivation: Making the ideal memory layout possible¶ The benchmark results from the More Efficient Memory Representation section have already shown that protobuf performance heavily depends on the specific usage: How are the messages defined? Which fields are set? To keep Go Protobuf as fast as possible for everyone, we cannot implement optimizations that help only one program, but hurt the performance of other programs. The Go compiler used to be in a similar situation, up until Go 1.20 introduced Profile-Guided Optimization (PGO). By recording the production behavior (through profiling) and feeding that profile back to the compiler, we allow the compiler to make better trade-offs for a specific program or workload. We think using profiles to optimize for specific workloads is a promising approach for further Go Protobuf optimizations. The Opaque API makes those possible: Program code uses accessors and does not need to be updated when the memory representation changes, so we could, for example, move rarely set fields into an overflow struct. Migration¶ You can migrate on your own schedule, or even not at all—the (existing) Open Struct API will not be removed. But, if you’re not on the new Opaque API, you won’t benefit from its improved performance, or future optimizations that target it. We recommend you select the Opaque API for new development. Protobuf Edition 2024 (see Protobuf Editions Overview if you are not yet familiar) will make the Opaque API the default. The Hybrid API¶ Aside from the Open Struct API and Opaque API, there is also the Hybrid API, which keeps existing code working by keeping struct fields exported, but also enabling migration to the Opaque API by adding the new accessor methods. With the Hybrid API, the protobuf compiler will generate code on two API levels: the .pb.go is on the Hybrid API, whereas the _protoopaque.pb.go version is on the Opaque API and can be selected by building with the protoopaque build tag. Rewriting Code to the Opaque API¶ See the migration guide for detailed instructions. The high-level steps are: Enable the Hybrid API. Update existing code using the open2opaque migration tool. Switch to the Opaque API. Advice for published generated code: Use Hybrid API¶ Small usages of protobuf can live entirely within the same repository, but usually, .proto files are shared between different projects that are owned by different teams. An obvious example is when different companies are involved: To call Google APIs (with protobuf), use the Google Cloud Client Libraries for Go from your project. Switching the Cloud Client Libraries to the Opaque API is not an option, as that would be a breaking API change, but switching to the Hybrid API is safe. Our advice for such packages that publish generated code (.pb.go files) is to switch to the Hybrid API please! Publish both the .pb.go and the _protoopaque.pb.go files, please. The protoopaque version allows your consumers to migrate on their own schedule. Enabling Lazy Decoding¶ Lazy decoding is available (but not enabled) once you migrate to the Opaque API! 🎉 To enable: in your .proto file, annotate your message-typed fields with the [lazy = true] annotation. To opt out of lazy decoding (despite .proto annotations), the protolazy package documentation describes the available opt-outs, which affect either an individual Unmarshal operation or the entire program. Next Steps¶ By using the open2opaque tool in an automated fashion over the last few years, we have converted the vast majority of Google’s .proto files and Go code to the Opaque API. We continuously improved the Opaque API implementation as we moved more and more production workloads to it. Therefore, we expect you should not encounter problems when trying the Opaque API. In case you do encounter any issues after all, please let us know on the Go Protobuf issue tracker. Reference documentation for Go Protobuf can be found on protobuf.dev → Go Reference. Previous article: Go Turns 15 Blog Index",
    "commentLink": "https://news.ycombinator.com/item?id=42434947",
    "commentBody": "Go Protobuf: The New Opaque API (go.dev)276 points by secure 22 hours agohidepastfavorite167 comments dpeckett 20 hours agoTo be honest I kind of find myself drifting away from gRPC/protobuf in my recent projects. I love the idea of an IDL for describing APIs and a great compiler/codegen (protoc) but there's just soo many idiosyncrasies baked into gRPC at this point that it often doesn't feel worth it IMO. Been increasingly using LSP style JSON-RPC 2.0, sure it's got it's quirks and is far from the most wire/marshaling efficient approach but JSON codecs are ubiquitous and JSON-RPC is trivial to implement. In-fact I recently even wrote a stack allocated, server implementation for microcontrollers in Rust https://github.com/OpenPSG/embedded-jsonrpc. Varlink (https://varlink.org/) is another interesting approach, there's reasons why they didn't implement the full JSON-RPC spec but their IDL is pretty interesting. reply elcritch 19 hours agoparentMy favorite serde format is Msgpack since it can be dropped in for an almost one-to-one replacement of JSON. There's also CBOR which is based on MsgPack but has diverged a bit and added and a data definition language too (CDDL). Take JSON-RPC and replace JSON with MsgPack for better handling of integer and float types. MsgPack/CBOR are easy to parse in place directly into stack objects too. It's super fast even on embedded. I've been shipping it for years in embedded projects using a Nim implementation for ESP32s (1) and later made a non-allocating version (2). It's also generally easy to convert MsgPack/CBOR to JSON for debugging, etc. There's also an IoT focused RPC based on CBOR that's an IETF standard and a time series format (3). The RPC is used a fair bit in some projects. 1: https://github.com/elcritch/nesper/blob/devel/src/nesper/ser... 2: https://github.com/EmbeddedNim/fastrpc 3: https://hal.science/hal-03800577v1/file/Towards_a_Standard_T... reply bccdee 14 hours agoparentprevWhat I really like about protobuf is the DDL. Really clear schema evolution rules. Ironclad types. Protobuf moves its complexity into things like default zero values, which are irritating but readily apparent. With json, it's superficially fine, but later on you discover that you need to be worrying about implementation-specific stuff like big ints getting mangled, or special parsing logic you need to set default values for string enums so that adding new values doesn't break backwards compatibility. Json-schema exists but really isn't built for these sorts of constraints, and if you try to use json-schema like protobuf, it can get pretty hairy. Honestly, if protobuf just serialized to a strictly-specified subset of json, I'd be happy with that. I'm not in it for the fast ser/de, and something human-readable could be good. But when multiple services maintained by different teams are passing messages around, a robust schema language is a MASSIVE help. I haven't used Avro, but I assume it's similarly useful. reply perezd 17 hours agoparentprevThe better stack rn is buf + Connect RPC: https://connectrpc.com/ All the compatibility, you get JSON+HTTP & gRPC, one platform. reply jcmfernandes 3 hours agorootparentI'm using connectrpc, and I'm a happy customer. I can even easily generate an OpenAPI schema for the \"JSON API\" using https://github.com/sudorandom/protoc-gen-connect-openapi reply rochacon 15 hours agorootparentprevConnectRPC is very cool, thanks for sharing. I would like to add 2 other alternatives that I like: - dRPC (by Storj): https://drpc.io (also compatible with gRPC) - Twirp (by Twitch): https://github.com/twitchtv/twirp (no gRPC compatibility) reply bbkane 12 hours agorootparentprevBuf seems really nice, but I'm not completely sure what's free and what's not with the Buf platform, so I'm hesitant to make it a dependency for my little open source side project ideas. I should read the docs a bit more. reply bheadmaster 11 hours agorootparentBuf CLI itself is licensed under a permissive Apache 2.0 License [0]. Since Buf is a compiler, its output cannot be copyrighted (similar to proprietary or GPL licensed compilers). DISCLAIMER: I am not a lawyer. Buf distinguishes a few types of plugins: the most important being local and remote. Local plugins are executables installed on your own machine, and Buf places no restrictions on use of those. Remote plugins are hosted on BSR (Buf Schema Registry) servers [1], which are rate limited. All remote plugins are also available as local plugins if you install them. It's worth to mention that the only time I've personally hit the rate limits of remote plugins is when I misconfigured makefile dependencies to run buf on every change of my code, instead of every change of proto definitions. So, for most development purposes, even remote plugins should be fine. Additionally, BSR also offers hosting of user proto schemas and plugins, and this is where pricing comes in [2]. [0] https://github.com/bufbuild/buf/blob/main/LICENSE [1] https://buf.build/blog/remote-plugin-execution [2] https://buf.build/pricing reply bbkane 3 hours agorootparentOk, that makes sense. Thanks! reply jeffrallen 11 hours agorootparentprevSoftware lives forever. You have to take the long view, not the \"rn\" view. In the long view, NFS's XDR or ASN.1 are just fine and could have been enough, if we didn't keep reinventing things. reply dpeckett 7 hours agorootparentIt's mind-blowing to think XDR / ONC RPC V2 were products of the 1980s, and that sitting here nearly forty years later we are discussing the same problem space. Probably the biggest challenge with something like XDR is it's very hard to maintain tooling around it long-term. Nobody wants to pay for forty years of continuous incremental improvement, maintenance, and modernization. Long term this churn will hopefully slow down, it's inevitable as we collectively develop a solid set of \"engineering principles\" for the industry. reply jeffrallen 7 hours agorootparent> Nobody wants to pay for forty years of continuous incremental improvement, maintenance, and modernization. And yet somehow, we are willing to pay to reinvent the thing 25 times in 40 years. reply dpeckett 6 hours agorootparentIt's a different company paying each time ;) I'm actually super excited to see how https://www.sovereign.tech turns out long-term. Germany has a lot of issues with missing the boat on tech, but the sovereign tech fund is such a fantastic idea. reply crabmusket 19 hours agoparentprev> I love the idea of an IDL for describing APIs and a great compiler/codegen (protoc) Me too. My context is that I end up using RPC-ish patterns when doing slightly out-of-the-ordinary web stuff, like websockets, iframe communications, and web workers. In each of those situations you start with a bidirectional communication channel, but you have to build your own request-response layer if you need that. JSON-RPC is a good place to start, because the spec is basically just \"agree to use `id` to match up requests and responses\" and very little else of note. I've been looking around for a \"minimum viable IDL\" to add to that, and I think my conclusion so far is \"just write out a TypeScript file\". This works when all my software is web/TypeScript anyway. reply dpeckett 8 hours agorootparentNow that's an interesting thought, I wonder if you could use a modified subset of TypeScript to create a IDL/DDL for JSON-RPC. Then compile that schema into implementations for various target languages. reply IggleSniggle 6 hours agorootparentTypia kinda does this, but currently only has a Typescript -> Typescript compiler. reply hansvm 15 hours agoparentprev> efficiency State of the art for both gzipped json and protobufs is a few GB/s. Details matter (big strings, arrays, and binary data will push protos to 2x-10x faster in typical cases), but it's not the kind of landslide victory you'd get from a proper binary protocol. There isn't much need to feel like you're missing out. reply lowbloodsugar 13 hours agorootparentExcept gzip is tragically slow, so crippling protobuf by running it through gzip could indeed slow it down to json speeds. reply hansvm 11 hours agorootparent\"gzipped json\" vs \"protobuf\" reply lowbloodsugar 2 hours agorootparentThen something is very wrong. reply girvo 19 hours agoparentprevSame; at my previous job for the serialisation format for our embedded devices over 2G/4G/LoRaWAN/satellite I ended up landing on MessagePack, but that was partially because the \"schema\"/typed deserialisation was all in the same language for both the firmware and the server (Nim, in this case) and directly shared source-to-source. That won't work for a lot of cases of course, but it was quite nice for ours! reply malkia 20 hours agoparentprevApart from being text format, I'm not sure how well JSON-RPC handles doubles vs long integers and other types, where protobuf can be directed to handle them appropriately. That is a problem in JSON itself, so you may neeed to encode some numbers using... \"string\" reply dpeckett 20 hours agorootparentI'd say the success of REST kind of proves that's something that for the most part can be worked around. Often comes down to the JSON codec itself, many codecs will allow unmarshalling/marshalling fields straight into long int types. Also JS now has BigInt types and the JSON decoder can be told to use them. So I'd argue it's kind of a moot point at this stage. reply tikhonj 19 hours agorootparentSure, but you can work around gRPC's issues too—\"workable\" might be the only bar that matters in practice, but it's a remarkably low bar. The risk with JSON is that too many systems understand it, and intermediate steps can mess up things like numeric precision as well as being inconsistent about handling things out of spec (field order, duplicate fields... etc). This definitely bites people in practice—I saw an experience report on that recently, but can't find the link just now :/ reply dagss 10 hours agorootparentprevJS having BigInt type has nothing to do with JSON. Backend languages have had BigInt types forever. It isn't relevant to JSON as a format. Just one example: Azure Cosmos DB stores JSON documents. If you try to store integers larger than 53 bits there those integers will be silently rounded to 53 bits. I know someone who got burned by this very badly loosing their data; I was able to explain them exactly why... JSON basically does not define what a number is; and that is a disaster for it as an API format. reply malkia 17 hours agorootparentprevIt's not, because some middleman (library, framework, etc.) would assume that JSON is really about sending integers as doubles, hence you are getting only 53 or was it 54 bits precision, and then you end up sending an integer as \"string\" - but then what is this really? I get it, it's probably not a concern for a lot of applications, but when comes to science, games, data it's of big concern... and this excluding the fact that you have to convert back and forth that number a... number of times, and send it on the wire inefficiently - and also miss a way to send it more efficiently using gorilla encoding or something else like that. JSON is great for a lot of things, but not for high throughput RPC. reply eadmund 15 hours agorootparentprev> I'd say the success of REST I think that you mean the success of JSON APIs. REST is orthogonal to JSON/Protobuf/HTML/XML/S-expressions/whatever. reply paulddraper 19 hours agorootparentprev> Also JS now has BigInt types and the JSON decoder can be told to use them. The parser needs to know when to parse as BigInt vs String. reply mirekrusin 8 hours agoparentprevAlso json parsers are crazy fast nowadays, most people don't realize how fast they are. reply Cthulhu_ 6 hours agorootparentWhile true, it's still a text and usually http/tcp based format; data -> json representation -> compression? -> http -> tcp -> decompression -> parsing -> data. Translating to / from a text just feels inefficient. reply ajross 19 hours agoparentprevThat's sort of where I've landed too. Protobufs would seem to fit the problem area well, but in practice the space between \"big-system non-performance-sensitive data transfer metaformat\"[1] and \"super-performance-sensitive custom binary parser\"[2] is... actually really small. There are just very few spots that actually \"need\" protobuf at a level of urgency that would justify walking away from self-describing text formats (which is a big, big disadvantage for binary formats!). [1] Something very well served by JSON [2] Network routing, stateful packet inspection, on-the-fly transcoding. Stuff that you'd never think to use a \"standard format\" for. reply bboygravity 12 hours agorootparentAdd \"everything that communicates with a microcontroller\" to 2. That means potentially: the majority of devices in the world. reply thadt 4 hours agorootparentPerhaps surprisingly, I think microcontrollers may be a place where Protobufs are not a bad fit. Using something like Nanopb [1] gives you the size/speed/flexibility advantages of protocol buffers without being too heavyweight. It’ll be a bit slower than your custom binary protocol, but it comes with quite a few advantages, depending on the context. [1] https://github.com/nanopb/nanopb reply ajross 2 hours agorootparentWe carry a nanopb integration in Zephyr. And even there... meh. It's true that there are some really bad binary protocols in the embedded world. And protobufs are for sure a step up from a median command parser or whatever. And they have real size advantages vs. JSON for tiny/sub-megabyte devices, which is real. But even there, I find that really these are very big machines in a historical sense. And text parsing is really not that hard, or that big. The first HTTP server was on a 25MHz 68040! Just use JSON. Anything else in the modern world needs to be presumed to be premature optimization absent a solid analysis with numbers. reply dpeckett 5 minutes agorootparentAmen to that. kyrra 21 hours agoprevThe opaque API brings some niceties that other languages have, specifically about initialization. The Java impl for protobuf will never generate a NullPointerException, as calling `get` on a field would just return the default instance of that field. The Go OpenAPI did not do this. For many primative types, it was fine. But for protobuf maps, you had to check if the map had been initialized yet in Go code before accessing it. Meaning, with the Opaque API, you can start just adding items to a proto map in Go code without thinking about initialization. (as the Opaque impl will init the map for you). This is honestly something I wish Go itself would do. Allowing for nil maps in Go is such a footgun. reply ynniv 21 hours agoparentThe Java impl for protobuf will never generate a NullPointerException, as calling `get` on a field would just return the default instance of that field. This was a mistake. You still want to check whether it was initialized most of the time, and when you do the wrong thing it's even more difficult to see the error. reply kyrra 21 hours agorootparentDepends on your use. If you are parsing a message you just received, I agree that you want to do a \"has\" check before accessing a field. But when constructing a message, having to manually create all the options is really annoying. (I do love the java builder pattern for protos). But I do know the footgun of calling \"get\" on a Java Proto Builder without setting it, as that actually initializes the field to empty, and could call it to be emitted as such. Such are the tradeoffs. I'd prefer null-safety to accidental field setting (or thinking a field was set, when it really wasn't). reply tantalor 20 hours agorootparent> you want to do a \"has\" check before accessing a field You should only do that if the semantics of the not-set field are different than the default value, which should be rare and documented on the field. reply ynniv 17 hours agorootparentI too enjoy defining my default attribute values at the protocol level, so they can never, ever be changed, and then defensively coding library functions in case the arguments are not constructed under the same semantic assumptions as I had years ago. Also everything needs to be marked optional or you'll need to restart the whole service mesh to change the schema. reply kyrra 14 hours agorootparentDefault values in proto are considered an anti pattern and was removed from the language in proto3. Agreed that protocol level required is bad, and it's with proto3 made optional the default. Our team enforces required fields via proto annotations, which can be much more flexible (we have transitional states to be able to upgrade or downgrade the check) reply rad_gruchalski 19 hours agorootparentprev> Depends on your use. Okay, but look… If I wanted that, I’d create a wrapper library for it and call it a day. But not by default, please. reply usrnm 10 hours agoparentprevIt's so fun to watch go devs rediscover all the patterns that they so happily threw out in the beginning. It's like watching a person grow up from a sunny little kid to a mature disgruntled alcoholic. reply rad_gruchalski 5 hours agorootparentAn alternative explanation is that non-go people got their hands on go and complain that go is not x or y. Like with generics. Now they’re in go. They’re not great, they have some sense but they may as well not exist as far as I’m concerned. I find them pretty useless anyway without lower and upper type bounds. reply mxey 3 hours agorootparentWhich non-Go people brought generics into Go? reply rad_gruchalski 2 hours agorootparent„go can’t be taken seriously because it doesn’t have generics” has been a mantra for years before they finally arrived. there must have been a ton of them. reply mxey 3 minutes agorootparentThat does not mean that generics were somehow forced in against the wishes of the Go Team. Their position has always been that they just need to find a good design. the_gipsy 11 hours agoparentprev> The Java impl for protobuf will never generate a NullPointerException, as calling `get` on a field would just return the default instance of that field. This is NOT the solution lmao reply parhamn 18 hours agoprevIt's interesting, to everyone but but the mega shops like Google, protobuf is a schema declaration tool. To the megashops its a performance tool. For most of my projects, I use a web-framework I built on protobuf over the years but slowly got rid of a lot of the protobufy bits (besides the type + method declarations) and just switched to JSON as the wire format. http2, trailing headers, gigantic multi-MB files of getters, setters and embedded binary representations of the schemas, weird import behaviors, no wire error types, etc were too annoying. Almost every project I've tracked that tries to solve the declarative schema problem seems to slowly die. Its a tough problem an opinionated one (what to do with enums? sum types? defaults? etc). Anyone know of any good ones that are chugging along? OpenAPI is too resty and JSONSchema doesn't seem to care about RPC. reply danans 11 hours agoparent> It's interesting, to everyone but but the mega shops like Google, protobuf is a schema declaration tool There are lots of other benefits for non performance-oriented teams and projects: the codegen makes it language independent and it's pretty handy that you can share a single data model across all layers of your system. If you don't care about the wire format, the standard JSON representation makes it pair well with JSON native databases, so you can get strict schema management without the need need for any clunky ORM. reply notyourwork 5 hours agoparentprevAt scale, the performance gains can be dramatic. For example, moving a json web service to CBOR, I was able to squeeze 15% more throughput out of existing hardware. When you’re dealing with hundreds, if not millions of requests per minute this can be financially prudent. reply tinthedev 8 hours agoparentprev> OpenAPI is too resty I'm curious as to why would you think that? There's a bit of boilerplate in there if you want to use it for a naive implementation, but I don't find it exceedingly resty. From my POV, using protobuf as a schema declaration tool (as opposed to being a performance tool) is blind follower behaviour. Getting over all the hurdles doesn't seem worth it for the payoff, and it only becomes less valuable when compared to all the OpenAPI tooling you could be enabling instead. This being for a web-based problem, where we're solving schema declaration. reply shepherdjerred 16 hours agoparentprevFrom Amazon: https://smithy.io/2.0/index.html (internally known as Coral) reply bobnamob 11 hours agorootparentnit: Coral and smithy are not comparable. Coral is a schema definition language, yes. But it’s also a full rpc ecosystem. Smithy at this point is only really an IDL that (in most cases, at least before I left) is “only” used to generate Coral models and then transitively Coral clients and services. The _vast_ majority of Amazon is still on “native” Coral reply the_gipsy 9 hours agoprev> syntax = \"proto2\" uses explicit presence by default > syntax = \"proto3\" used implicit presence by default (where cases 2 and 3 cannot be distinguished and are both represented by an empty string), but was later extended to allow opting into explicit presence with the optional keyword > edition = \"2023\", the successor to both proto2 and proto3, uses explicit presence by default The root of the problem seems to be go's zero-values. It's like putting makeup on a pig, your get rid of null-panics, but the null-ish values are still everywhere, you just have bad data creeping into every last corner of your code. There is no amount of validation that can fix the lack of decoding errors. And it's not runtime errors instead of compile-time errors, which can be kept in check with unit tests to some degree. It's just bad data and defaulting to carry on no matter what, like PHP back in the day. reply 9rx 5 hours agoparent> It's like putting makeup on a pig, your get rid of null-panics How so? In Go, nil is the zero value for a pointer and is ripe for panic just like null. Zero values do not avoid that problem at all, nor do they intend to. reply bbatha 3 hours agorootparentIll give you that nil is a fine default for pointers, and pointer like things (interfaces, maps, slices). Its mostly fine to use empty string. However 0 has semantic meaning for just about every serialized numeric type I've ever encountered. The zero value also does really poorly for PUT style apis, \"did the user forget to send this or did they mean to set this field to empty string\" is very poorly expressed in Go and often has footguns around adding new fields. reply srockets 1 hour agorootparentAs is often the case, Go's designed anachronism creates more problem than it solves: had Go had a modern, expressive type system, rather than staying with one from the 70s, this problem would never exists. reply the_gipsy 4 hours agorootparentprevThat's just that they picked a worse case of zero value for slices and maps, presumably for performance gains. reply 9rx 4 hours agorootparentThe slice type is an implicit struct, in the shape: struct { data uintptr len int cap int } Which is usable when the underlying memory is set to zero. So its zero value is really an empty slice. Most languages seem to have settled on empty slice, array, etc. as the initialized state just the same. I find it interesting you consider that the worst case. Maps are similar, but have internal data structures that require initialization, thus cannot be reliably used when zeroed. This is probably not so much a performance optimization as convention. You see similar instances in the standard library. For example: var file os.File file.Read([]byte{}) // panics; file must be initialized first. reply bbatha 3 hours agorootparent> Maps are similar, but have internal data structures that require initialization, thus cannot be reliably used when zeroed. Its a performance thing, the map structure requires a heap allocation even with zero elements. This is because the map structure is type generic without being fully monomorphized. reply tsimionescu 4 hours agorootparentprevIt should be noted that slices and maps are completely opposite ends of how they behave in relation to nil in Go. A nil slice is just an empty slice, there is no operation you could do with one that will fail if done with the other. In contrast, a nil map doesn't support any operation whatsoever, it will panic on doing anything with it. reply the_gipsy 4 hours agorootparentYou're quite mistaken. You can use len() on both nil maps and slices, and it will return zero (as with empty ones). Panic occurs on both nil assignments. But then, access only panics on nil slices - nil maps produce the zero value. It's horrible. https://go.dev/play/p/2KFOoJ0oyWB reply tsimionescu 3 hours agorootparentRight, forgot that len() works on nil maps, and I was really not aware that reading from a nil map is not an error, that's crazy. For the nil slice though what I said remains true: a nil slice is the same thing as an empty slice. Of course reading from or writing to its first element panics, given that it doesn't have any elements. The same would have happened if you had initialized it as `var ns []int = make([]int, 0)` or `ns := []int{}`. reply the_gipsy 2 hours agorootparentAh now I get it, yes you're right, they behave the same. Ironically, just today I read that in the next release they will add some JSON annotation to distinguish nil slices (omitzero): https://tip.golang.org/doc/go1.24 reply mxey 3 hours agorootparentprevAccess on an empty slice would also panic because of out of bounds. So there’s no useful distinction there. However, nil slices work just fine when calling append on them, while writing to a nil map in any way will panic. reply tech132 7 hours agoparentprevFrom what I remember, proto3 behavior happened to map to objective c since iOS maps coincidentally happened at around the same time so they could be loud. It was partially reverted with proto3 optional and fully reverted finally. Go's implementation happened to come around the same time as proto3 so allowed struct access, despite behaving quite differently when accessing nil fields. That is also finally reverted. Hopefully more lessons already learned from the Java days will come sooner than later going forward... reply knodi 4 hours agoparentprevYes, as much as I love Go and love working with it every day. This inner workings of Go with zero-values has been an design issue that comes up again and again and again. reply delusional 9 hours agoparentprevI don't think the reason for zero values has anything to do with \"avoiding null panics\". If you want to inline the types, that is avoid using most of your runtime on pointer chasing, you can't universally encode a null value. If I'm unclear, ask yourself: What would a null int look like? If what you wanted was to avoid null-panics, you can define the elementary operations on null. Generally null has always been defined as aggressively erroring, but there's nothing stopping a language definition from defining propagation rules like for float NaN. reply the_gipsy 9 hours agorootparentSorry, I don't follow you. If you don't have zero values, you either have nulls and panics, or you have some kind of sum-type á la Option and cannot possibly construct null or zero-ish values. Is there a way to have your cake and eat it too, and are there real world examples of it? reply TheDong 6 hours agorootparentThere is a way to have your cake and eat it too: rust. In rust, you have: let s = S{foo: 42, ..Default::default()}; You just got all the remaining fields of 'S' set to \"zero-ish\" values, and there's no NPEs. The way you do this is by having types opt in to it, since zero values only make sense in some contexts. In go, the way to figure out if a type has a meaningful zero value is to read the docs. Every type has a zero value, but a lot of them just nil-pointer-exception or do something completely nonsensical if you try to use them. In rust, at compiletime you can know if something implements default or not, and so you can know if there's a sensible zero value, and you can construct it. Go doesn't give you your cake, it gives you doc comments saying \"the zero value is safe to use\" and \"the zero value will cause unspecified behavior, please don't do it\", which is clearly not _better_. reply the_gipsy 5 hours agorootparentI agree that rust, with Option and Default, is the only right choice - at least from what I've tried. Elm for example has Option but nothing like Default, so sometimes it's tedious that you have to repeat a lot of handmade defaults, or you're forced to use constructor functions everywhere. But at least the program is correct! Go is like PHP in regards to pushing errors forward. You simply cannot validate everything at every step. Decoding with invariants is the right alternative. reply delusional 5 hours agorootparentprev> There is a way to have your cake and eat it too: rust. Suppose my cake is that I have a struct A which holds a value, that doesn't have a default value, from your library B. Suppose that at the time I want to allocate A I don't yet have the information I need to initialize B, but I also know that I won't need B before I do have that information and can initialize it. In simple terms. I want to allocate A, which requires allocating B, but I don't want to initialize B, yet. What do I do? If you answer involves Option then you're asking me to to grow my struct for no gain. That is clearly not _better_. reply tsimionescu 4 hours agorootparentDoesn't Rust have explicit support for uninitialized memory, using the borrow checker to make sure you don't access it before initializing it? Or does that just work for local variables, not members of structs? reply steveklabnik 2 hours agorootparentYou can’t do the “declare before initializing” thing with structs, that’s correct. reply the_gipsy 4 hours agorootparentprevThen you can't eat it too (or else you'll get very sick with NPEs/panics), sorry. reply whytevuhuni 1 hour agorootparentMore specifically, it could result in undefined behavior, if a panic happens between the allocation and initialization (i.e., it was allocated, not initialized, panicked, and something observed the incomplete struct after the panic). Alternatively, the allocation would always have to leak on panic, or the struct would have to be deallocated without a destructor running. reply dingnuts 4 hours agorootparentprevWhat is with Rust evangelicals shitting up Go posts? Shut up and go away! Go talk to other Rust users about it if you love it so much! it's for different things! the things I build in Go simply do not need to be robust in the way Rust requires everything to be, and it would be much more effort to use Rust in those problem domains Is Go a more crude language? maybe! but it lets me GET SHIT DONE and in this case worse really is better. All I know is that I've spent less time over the last ten years writing Go dealing with NPEs than I have listening to Rust users complaining about them! if you love Rust so much, YOU use it then! We like Go, in threads about Go. I might like Rust too, in the same way I like my bicycle and my car, if only the cyclists would shut up about how superior their choices are reply bborud 6 hours agorootparentprevNo, there isn't. It is just other versions of the same problem with people pretending it is somehow different. People generally like to complain about NULL/nil whatever, but they rarely think about what the alternatives mean and what arrangements are completely equivalent. No matter what you do, you have to put some thought into design. Languages can't do the design work for programmers. reply masklinn 9 hours agorootparentprev> or you have some kind of sum-type á la Option and cannot possibly construct null or zero-ish values. Option types specifically allow defaulting (to none) even if the wrapped value is not default-able. You can very much construct null or zero-ish values in such a langage, but it’s not universal, types have to be opted into this capability. reply the_gipsy 8 hours agorootparentExactly my point, you have to opt-in, and in practice you only do precisely where it's actually necessary. Which is completely different than \"every single type can be a [nullzero value]\". You cannot possibly construct some type A (that is not Option or A@nullable or whatever) without populating it correctly. Of course you need some way to represent \"absence of a value\", the matter is how: simple but incorrect, or complex but correct. And, simple/complex here can mean both the language (so performance tradeoff), and (initial) programmer ergonomics. That's why I ask if you can have your cake and eat it too, the answer is no. Or you'll get sick sooner than later, in this case. reply delusional 5 hours agorootparent> You cannot possibly construct some type A (that is not Option or A@nullable or whatever) without populating it correctly. Except you can. The language runtime is clearly doing it when it stores [None|Some(x)] inline in a fixed size struct. reply tsimionescu 4 hours agorootparentThere is no way to store NoneSome(x) in sizeof(x) bytes, for simple information theory reasons. What you can do is store between 1 and 8 optional fields with only 1 byte of overhead, by using a single bit field to indicate which of the optional fields is set or not (since no commonly used processor supports bit-level addressing, storing 1 extra bit still needs an entire extra byte, so the other 7 bits in that byte are \"free\"). reply delusional 5 hours agorootparentprevYou're thinking in abstract terms, I'm talking about the concrete implementation details. If we, just as an example, take C. and int can never be NULL. It can be 0, compilers will sometimes tell you it's \"uninitialized\", but it can never be NULL. all possible combinations of bit patterns are meaningfully int. Pointers are different in that we've decided that the pattern where all bits are 0 is a value that indicates that it's not valid. Note that there's nothing in the definition of the underlying hardware that required this. 0 is an address just like any other, and we could have decided to just have all pointers mean the same thing, but we didn't. The NULL is just a language construct, and as a language construct it could be defined in any way you want it. You could defined your language such that dereferencing NULL would always return 0. You could decide that doing pointer arithmetic with NULL would yield another NULL. At the point you realize that it's just language semantics and not fundamental computer science, you realize that the definition is arbitrary, and any other definition would do. As for sum-types. You can't fundamentally encode any more information into an int. It's already completely saturated. What a sumtype does, at a fundamental level, is to bundle your int (which has a default value) with a boolean (which also has a default value) indicating if your int is valid. There's some optimizations you can do with a \"sufficiently smart compiler\" but like auto vectorization, that's never going to happen. I guess my point can be boiled down to the dual of the old C++ adage. Resource Allocation is NOT initialization. RAINI. reply the_gipsy 4 hours agorootparentThen your point is tangent to the question of zero values, and even more so to the abstract concept of zero values spilling over into protobuf. reply remram 2 hours agoprev> version: 2, 3, 2023 (released in 2024) I call this Battlefield versioning, after the Battlefield video game series [1]. I bet the next version will be proto V. [1]: in order: 1942, 2, 2142, 3, 4, 1, V, 2042 reply h4ch1 9 hours agoprevSurprisingly I saw this on the front page mere minutes after deciding to use protobufs in my new project. Currently I'm not quite sold on RPC since the performance benefits seem to show up on a much larger scale than what I am aiming for, so I'm using a proto schema to define my types and using protoc codegen to generate only JSON marshaling/unmarshaling + types for my golang backed and typescript frontend, with JSON transferred between the two using REST endpoints. Seems to give me good typesafety along with 0 headache in serializing/deserializing after transport. One thing I also wanted to do was generate SQL schemas from my proto definitions or SQL migrations but haven't found a tool to do so yet, might end up making one. Would love to know if any HN folk have ideas/critique regarding this approach. reply kubb 22 hours agoprevI hate this API and Go's handling of protocol buffers in general. Especially preparing test data for it makes for some of the most cumbersome and unwieldy files that you will ever come across. Combined with table driven testing you have thousands upon thousands of lines of data with an unbelievably long identifiers that can't be inferred (e.g. in array literals) that is usually copy pasted around and slightly changed. Updating and understanding all of that is a nightmare and if you miss a coma or a brace somewhere, the compiler isn't smart enough to point you to where so you get lines upon lines of syntax errors. But, being opaque has some advantages for sure. reply GeneralMayhem 20 hours agoparentI find that the best way to set up test cases, regardless of language, is usually to use string constants in the proto text format (https://protobuf.dev/reference/protobuf/textformat-spec/). For arrays, and especially for oneofs, it's way less verbose than how things are represented in Go, C++, or Java, and generally at least on par with the Python constructors. Maps are the only thing that suffer a bit, because they're represented as a list of key-val pairs (like in the wire format) instead of an actual map. Your language's compiler won't help you debug, but the parse-text-proto function can point to the source of the issue on a line/character level. With Go generics - and equivalent in most other languages - you can write a 5-line helper function that takes a string in that format and either returns a valid proto value (using the generic type param to decide which type to unmarshal) or `t.Fatal()`s. You would never do this in production code, but as a way to represent hand-written proto values it's pretty hard to beat. reply kubb 10 hours agorootparentUnless someone with authority in your workplace makes a rule against doing that… reply GeneralMayhem 3 hours agorootparentIf your problem is humans making arbitrary and nonsensical decisions about how you can do your job, then you have a non-technical problem, and it's unlikely that any technical solution will solve it. reply kubb 18 minutes agorootparentFair. Best not to code. reply atombender 2 hours agoparentprevThe generated Go code situation has always been wild to me. For example, every message embeds protoimpl.MessageState and a bunch of other types, which contain mutexes. That means proto structs cannot be copied or compared byte-for-byte like normal Go structs can. For several years I used the GoGo Protobuf SDK. It was vastly superior to the awful Javaesque Go code that the official compiler generated. It allowed structs to be pure data structs, was much more performant, and supported a bunch of options to generate native-feeling, ergonomic Go code. But the Google team refused to partake in any such improvements, and GoGo was shut down as the burden of following the upstream implementation became too big. [1] I'm not an expert, but as far as I understand, the extra struct junk is mostly to avoid having a parallel set of types for metadata (including reflection). It's unclear to me why these can't simply be generated as internal types with some nice API on top. Clearly the new field metadata adds to this extra information, and the Go team is moving in the opposite direction of what I thought the future was — they're doubling down on stuffing metadata into the structs, and making the structs bigger and even less wieldy. I understand how this might make things more performant, but I was hoping this sort of thing could be solved with the type system, especially now that we have generics. For example, surely lazy field access could be done like this: type Info struct { User LazyProto[User] } userName := user.Get().Name [1] https://x.com/awalterschulze/status/1584553056100057088 reply alienchow 13 hours agoparentprevThe testing practice I've seen is to have a testdata/ directory with a bunch of textprotos for different test cases. If you're using Bazel, just include the entire directory glob as data dependency for the unit tests. The test tables are essentially just appropriately named textproto filenames that are unmarshaled into the proto message to be tested. Then again I've also seen people do these thousand line in-code literal string protos which really grind my gears. reply lalaithion 16 hours agoparentprevWe put test inputs and outputs in testdata/test_name.in.textpb and testdata/test_name.out.textpb, respectively. Way nicer than defining both your inputs and your desired outputs in go code, even compared to not using protobuf at all, to the point where we occasionally write some proto definitions just for test inputs and outputs. reply throwaway894345 21 hours agoparentprevI haven't used protocol buffers, but in general any kind of code generation produces awful code. I much prefer generating the machine spec (protocol buffers, in this case) from Go code rather than the other way around. It's not a perfect solution, but it's much better than dealing with generated code in my experience. reply MobiusHorizons 17 hours agorootparentGenerated code tends to look very formulaic, but it doesn’t have to be unreadable. As a primative it is incredibly powerful, and can be easier to maintain than alternatives. You definitely need good build tooling though. Ideally you won’t need to look at the generated code and can infer the interface from the input file. reply matrix87 16 hours agoprevI recently used code-gen'd protobuf deser objects as the value type for an in-memory db and was considering flattening them into a more memory-efficient representation and using bitfields. That was for java though, not sure if they are doing the same thing there Glad to see this change, for that use case it would've been perfect reply fofoz 13 hours agoparentHave you considered this? https://flatbuffers.dev/ reply matrix87 12 hours agorootparentat the time, no, but this would've been perfect :/ reply jeffbee 22 hours agoprevProtobuf 3 was bending over backwards to try to make the Go API make sense, but in the process it screwed up the API for C++, with many compromises. Then they changed course and made presence explicit again in proto 3.1. Now they are saying Go gets a C++-like API. What I'd like is to rewind the time machine and undo all the path-dependent brain damage. reply sa46 21 hours agoparentWhen I was at Google around 2016, there was a significant push to convince folks that the proto3 implicit presence was superior to explicit presence. Is there a design doc with the rationale for switching back to explicit presence for Edition 2023? The closest docs I've found are https://buf.build/blog/protobuf-editions-are-here and https://github.com/protocolbuffers/protobuf/tree/main/docs/d.... reply akshayshah 14 hours agorootparentBest bet is likely https://github.com/protocolbuffers/protobuf/blob/main/docs/f..., which predates editions. reply jeffbee 21 hours agorootparentprevI was only there for the debate you mentioned and not there for the reversal, so I dunno. reply IX-103 19 hours agorootparentI wasn't there for the debate, but was there for the reversal. I don't remember there being anything explicitly said about it. The only thing I can think of is that I know of some important projects that couldn't migrate to proto3 because of this implicit field issue. So some people were still writing new code with proto2. reply summerlight 18 hours agorootparentAnd... most of the important projects are still using proto2 and there is no realistic way to do interop between those two formats. IIRC, you cannot use proto2 enum in proto3 for some obscure technical reason! This creates a backsliding issue; you cannot migrate old protos with thousands of different messages, fields and enums where new proto2 messages to use them are added everyday. This is an important distinction from the proto1->proto2 migration, which was in a much better compatibility situation yet still took years to complete. AFAIK, this is the main reason why the proto team decided to create a superset approach (edition) so migration can be handled as a flag at each message level. reply jcdavis 21 hours agoparentprev> it screwed up the API for C++, with many compromises The implicit presence garbage screwed up the API for many languages, not just C++ What is wild is how obviously silly it was at the time, too - no hindsight was needed. reply kubb 10 hours agorootparentIt was but when the wrong fool gets a say, they will mess a perfectly good thing up for everyone. Organizations often promote fools who don’t second guess their beliefs and think they have it all figured out. reply dekhn 20 hours agoparentprevI work mainly in Python, it's always seemed really bad that there are 3 main implementations of Protobufs, instead of the C++ being the real implementation and other platforms just dlopen'ing and using it (there are a million software engineering arguments around this; I've heard them all before, have my own opinions, and have listened to the opinions of people I disagree with). It seems like the velocity of a project is the reciprocal of the number of independent implementations of a spec because any one of the implementations can slow down all the implementations (like what happened with proto3 around required and optional). From what I can tell, a major source of the problem was that protobuf field semantics were absolutely critical to the scaling of google in the early days (as an inter-server protocol for rapidly evolving things like the search stack), but it's also being used as a data modelling toolkit (as a way of representing data with a high level of fidelity). And those two groups- along with the multiple language developers who don't want to deal with native code- do not see eye to eye, and want to drive the spec in their preferred direction. (FWIW nowadays I use pydantic for type descriptions and JSON for transport, but I really prefer having an external IDL unrelated to any specific programming language) reply lmm 16 hours agorootparent> It seems like the velocity of a project is the reciprocal of the number of independent implementations of a spec because any one of the implementations can slow down all the implementations (like what happened with proto3 around required and optional). Velocity and stability/maturity are in tension, sure. I think for a foundational protocol like protobuf you want the stability and reliability that come from multiple independent implementations more than you want it to be moving fast and breaking things. reply elcritch 12 hours agorootparentAdditionally calling C++ from other languages is a pain and you're forced to make a bridge C API. Doing so from Go is even less than ideal from what I gather. It requires using cgo and forces Go to interface with C call stacks, slows down the compilation, etc. reply charleslmunger 17 hours agorootparentprevYou'll be thrilled to hear about upb then, which was designed to be embeddable to power other languages without a from-scratch implementation - and now powers python protos. https://github.com/protocolbuffers/protobuf/tree/main/upb reply sbrother 20 hours agoparentprevI still use proto2 if possible. The syntactic sugar around `oneof` wasn't nice enough to merit dealing with proto3's implicit presence -- maybe it is just because I learned proto2 with C++ and don't use Go, but proto3 just seemed like a big step back and introduced footguns that weren't there before. Happy to hear they are reverting some of those finally. reply boulos 14 hours agoparentprevThat's not how I remember it. I thought proto3 was all about JSON compatibility. No? reply ein0p 11 hours agoparentprevNice to see my comments on their proto3 design doc vindicated, lol. There were a lot of comments on that doc, far more than what you'd usually see. Some of those comments dealt with the misguided decision to basically drop nullability (that is, the `has_` methods) that proto2 had. The team then just deleted all the comments and disabled commenting on the doc and proceeded with their original design much to the consternation of their primary stakeholders. reply favflam 12 hours agoprevOh, this is great. I just did an implementation in gRPC in Go whereby I had to churn through 10MB/s of data. I could not implement any kind of memory pool and thus I had a lot of memory allocation issues which lead to bad memory usage and garbage collection eating up my CPU. reply alecthomas 7 hours agoparentThis is probably what you want: https://github.com/planetscale/vtprotobuf reply alakra 22 hours agoprevIs this like the FlatBuffers \"zero-copy\" deserialization? reply mort96 22 hours agoparentI'm not done reading the article yet, but nothing so far indicates that this is zero-copy, just a more efficient internal representation reply kyrra 22 hours agoparentprevNope. This is just a different implementation that greatly improves the speed in various ways. reply neonsunset 19 hours agoprevThe absolute state of Go dragging down the entire gRPC stack with it. Oh well, at least we have quite a few competent replacements nowadays. reply cyberax 19 hours agoprevThanks. I hate it. Now you can not use normal Go struct initialization and you'll have to write reams of Set calls. reply oefrha 17 hours agoparentLike the sibling said, there's a complimentary _builder struct generated with a Build() method. For instance, for the sample message in the blog post, here's the public API of the generated _builder: type LogEntry_builder struct { BackendServer *string RequestSize *uint32 IpAddress *string // contains filtered or unexported fields } func (b0 LogEntry_builder) Build() *LogEntry reply cyberax 16 hours agorootparentSo they managed to screw up even that. The naming system is not idiomatic Go. You still will need to create temporary objects (performance...) and for an unclear gain. reply oefrha 15 hours agorootparent> The naming system is not idiomatic Go. Underscores are commonly used in names in generated code to avoid conflicts (this applies to all sorts of codegen, not just protobuf). You can easily have both Foo and FooBuilder messages in your protobuf. See also generated enum consts since day one of protobuf-gen-go. reply akira2501 13 hours agorootparent> used in names in generated code Fair enough but now this name leaks out into code I have to type. I don't dig highly opinionated languages with tooling that complains at me over style guidelines breaking their own style guidelines to solve a problem that they themselves have created. They painted themselves into a corner and their solution is for me to hit myself in the head with a hammer. reply xyse53 19 hours agoparentprevIt's not in the post but when this was rolled out internally at Google there was a corresponding builder struct to initialize from. reply g0ld3nrati0 20 hours agoprevjust curious, why do use protobuf instead of flatbuffers? reply akshayshah 13 hours agoparentThe whole FlatBuffers toolchain is wildly immature compared to Protobuf. Last I checked, flatc doesn’t even have a plugin system - all code generators had to be upstreamed into the compiler itself. reply mort96 12 hours agorootparentIsn't protoc mostly the same? I mean I know the code generators are separate binaries (which is quite annoying frankly) but protoc needs to know of them all upstream to expose options like --go_out and --go_opt, right? reply Zababa 8 hours agorootparentI'm not sure. We have a few private plugins at work and they work fine with regular protoc. I think the --go_out and friends are automatically created by the plugins. Something like, they declare themselves as \"toto\" and to protoc now has a --toto_out option. reply mort96 3 hours agorootparentI see, interesting! reply majormajor 13 hours agoparentprevIf you work with both the ergonomic advantages of protobufs become quickly apparent - starting the first time you nest things a few times. Unless you are very very frequently not going to deserialize your entire messages and so can get huge benefits from the better selective-deser of only what a given consumer cares about at a certain time, I find using flatbuffers hard to justify. reply tonyhart7 15 hours agoparentprevYeah idk why we didnt just send binary data representation therefore eliminate entire serialize and deserialize part reply tsimionescu 10 hours agorootparentWhich binary data representation? If I'm sending a Java object, do you think a C program will be able to just use it? Or for that matter, do you think two different C++ implementations, maybe on different platforms, will use the same binary representation of a class object? reply tonyhart7 5 hours agorootparentjust need an standard for that reply tsimionescu 4 hours agorootparentJava has a standard, each C implementation has a standard, Python has a standard, etc. The problem is that each of these standards is different, and impossible to modify. So, we need something that can serialize one standard to a wire format, and then deserialize from that wire format to another standard. Oh wait... reply strawhatguy 22 hours agoprevGreat, now there's an API per struct/message to learn and communicate throughout the codebase, with all the getters and setters. A given struct is probably faster for protobuf parsing in the new layout, but the complexity of the code probably increases, and I can see this complexity easily negating these gains. reply secure 22 hours agoparent> Great, now there's an API per struct/message to learn and communicate throughout the codebase, with all the getters and setters. No, the general idea (and practical experience, at least for projects within Google) is that a codebase migrates completely from one API level to another. Only larger code bases will have to deal with different API levels. Even in such cases, your policy can remain “always use the Open API” unless you are interested in picking up the performance gains of the Opaque API. reply jrockway 21 hours agoparentprevI always used the getters anyway. Given: message M { string foo = 1; } message N { M bar = 2; } I find (new(M)).Bar.Foo panicking pretty annoying. So I just made it a habit to m.GetBar().GetFoo() anyway. If m.GetBar().SetFoo() works with the new API, that would be an improvement. There are some options like nilaway if you want static analysis to prevent you from writing this sort of code, but it's difficult to retrofit into an existing codebase that plays a little too fast and loose with nil values. Having code authors and code reviewers do the work is simpler, though probably less accurate. The generated code's API has never really bothered me. It is flexible enough to be clever. I especially liked using proto3 for data types and then storing them in a kv store with an API like: type WithID interface { GetId() []byte } func Put(tx *Tx, x WithID) error { ... } func Get(tx *Tx, id []byte) (WithId, error) { ... } The autogenerated API is flexible enough for this sort of shenanigan, though it's not something I would recommend except to have fun. reply hellcow 22 hours agoparentprevI'd recommend transforming protobuf types to domain types at your API boundary. Then you have domain types through the whole application. reply AYBABTME 17 hours agorootparentI found that this ends up being a giant amount of useless code, and a ton of memory allocation noise, that only satisfied my desire for elegance. I've given up that approach and just use protobuf types throughout as the base type. I got sick of writing dumb conversion funcs. reply mrbadguy 8 hours agorootparentIt’s fairly mindless boilerplate for sure, but it does mean that when something happens that causes a change like this protobuf update, the change in your codebase is isolated just to the interface between it and your code ie your dumb conversion funcs. Otherwise you end up with the problem the original commenter had. It’s good to isolate your dependencies within the code :) reply mxey 21 hours agorootparentprevAt which point I loose all the benefits of lazy decoding that the accessor methods can provide, so I could just decode directly into a sensible struct, except you can’t with Protobuf. reply mort96 21 hours agorootparentAccessor methods aren't for lazy decoding but for more efficient memory layouts. reply mxey 21 hours agorootparentBut that will also not transfer over to the domain struct reply mort96 11 hours agorootparentWell it depends. If your data model doesn't include \"this bool is optional\", you can just include the bool directly in the struct and get all the memory layout advantages, and then you decide in your protobuf -> domain type conversion code whether it's an error if that field is missing or if it just defaults to 'false'. You only need to make ways for a field to be optional (such as naming it a pointer where nil represents \"missing\") when that actually makes sense in your data model. reply matrix87 17 hours agorootparentprevI've done this, it only makes sense to me if you're trying to recycle some legacy code that's already using the domain types. Or else there's a bunch of extra conversion logic and unnecessary copying, feels like an antipattern reply mort96 22 hours agoparentprevI mean calling it \"a new API per message\" is a bit of an exaggeration... the \"API\" per message is still the same: something with some set of attributes. It's just that those attributes are now set and accessed with getters and setters (with predictable names) rather than as struct fields. Once you know how to access fields on protobuf types in general, all message-specific info you need is which fields exist and what their types are, which was the case before too. reply tonymet 20 hours agoprevwhy is code generation under-utilized? protobufs and other go tooling are great for code generation. Yet in practice i see few teams using it at scale. Lots of teams creating rest / json APIs, but very few who use code generation to provide compile-time protection. reply kevmo314 20 hours agoparentCode generation leaves a layer of abstraction between the API and the actual implementation which works great if that code generation is bug-free but if it's not, you're like... totally fucked. Most commonly people say you can read the generated code and step backwards but that's like saying you can read the compiled JavaScript and it's basically open source. That layer of abstraction is an underrated mental barrier. Of course, code generation is still practical and I'm a lot more likely to trust a third-party writing a code generator like protobufs, OpenAPI specs, etc, but I would not trust an internal team to do so without a very good reason. I've worked on a few projects that lost hundreds of dev hours trying to maintain their code generator to avoid a tiny bit of copy/paste. reply kccqzy 20 hours agoparentprevCode generation is under utilized because most people don't have a build system good enough for it. Traditional make is fine: you just define dependencies and rules. But a lot of people want to use language-specific build systems and these often don't have good support for code generation and dependency tracking for generated code. Yet another subtlety is that when cross-compiling, you need to build the code generation tool for the local target always even though the main target could be a foreign architecture. And because the code generation tool and the main code could share dependencies, these dependencies need to be built twice for different targets. That again is something many build tools don't support. reply tuetuopay 17 hours agoprevI can’t wait to try this new Protobuf Enterprise Edition, with its sea of getters and setters ad nauseam. /s However I can get behind it for the lazy decoding which seems nice, though I doubt its actual usefulness for serious software (tm). As someone else already mentioned, an actual serious api (tm) will have business-scope types to uncouple the api definition from the implementation. And that’s how you keep sane as soon as you have to support multiple versions of the api. Also, a lot of the benefits mentioned for footgun reductions smell like workarounds for the language shortcomings. Memory address comparisons, accidental pointer sharing and mutability, enums, optional handling, etc are already solved problems and where something like rust shines. (Disclaimer: I run several grpc apis written in rust in prod) reply cyberax 19 hours agoprevBTW, if you care so much about performance, then fix the freaking array representation. It should be simple `[]SomeStruct` instead of `[]*SomeStruct`. This one small change can result in an order of magnitude improvement. reply lakomen 20 hours agoprevGraphql won the race for me. Grpc is no longer relevant. Too many hurdles, no proper to and from Web support. You have to use some 3rd party non free service. reply nicce 20 hours agoparentAren’t their usecases completely different? reply lmm 16 hours agorootparentNo, they're both possible choices for your basic client-server communication layer that you build everything else on. (I mean, technically gRPC rather than protobuf, but protobuf is the biggest part of gRPC). reply pensatoio 2 hours agorootparentprevYes. The use cases are very different, as far as these things go. To say otherwise is borderline misinformation. You can build services internally with gRPC and serve a public graphQL API that aggregates them. reply revskill 15 hours agorootparentprevWhat are differences ? reply asmor 20 hours agorootparentprevIntersects quite heavily if you're defining a schema for your API reply Naru41 14 hours agoprevWhy not just use a naive struct from the beginning? memcpy is the fastest way to get serialize into a form that we can use in actual running program. reply schmichael 14 hours agoparentThe article goes into great detail about the benefits of an opaque api vs open structs. Somewhat unintuitively open structs are not necessarily the “fastest” largely due to pointers requiring heap allocations. Opaque APIs can also be “faster” due to lazy loading and avoiding memcpy altogether. The latter appears in libraries like flat buffers but not here IIRC. reply akira2501 13 hours agoparentprev> memcpy is the fastest way To bake endianess and alignment requirements into your protocol. reply abtinf 14 hours agoprev [–] This looks like an attempt to turn Go into Java/C#. I certainly won’t allow this to be used by the engineering teams under me. reply pensatoio 14 hours agoparentWhy? I'm going to encourage my engineers and other teams to use it. Using this API would 100% have prevented bugs created by accessing the generated structs directly, especially in the presence of an optional value. reply cpuguy83 13 hours agoparentprevIt's attempt to provide a much more efficient and harder to misuse implementation to a project used in tons of places. reply Zababa 8 hours agoparentprev [–] I don't think it is. Effective Go says that Go doesn't provide automatic support for getters and setters but there's nothing wrong with providing them yourself. Since in that case they are actually doing something (checking/updating the bitfield that contains the presence of each field), it makes sense to use them. They are called `GetFoo()` instead of the idiomatic `Foo()`, but that is to ensure compatibility with the API where the fields are directly exposed as `Foo`, which also makes sense. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Go Blog announces the introduction of a new Opaque API for Go Protobuf, enhancing memory efficiency and reducing pointer-related bugs by hiding struct fields and using accessor methods.",
      "The Opaque API supports lazy decoding, optimizing performance by decoding fields only when accessed, and is recommended for new development, with a Hybrid API available for gradual transition.",
      "The Protobuf Edition 2024 will make the Opaque API the default, and feedback is encouraged on the Go Protobuf issue tracker, with reference documentation available on protobuf.dev."
    ],
    "commentSummary": [
      "The discussion highlights the complexity and unique characteristics of using Protobuf and gRPC in the Go programming language, with some developers finding it challenging.- Alternatives such as JSON-RPC, MsgPack, and Varlink are considered simpler, while tools like ConnectRPC and Buf are suggested for improved compatibility and performance.- The conversation underscores the trade-offs between different serialization and communication protocols, including the benefits of Protobuf's schema language and the challenges of using JSON for APIs."
    ],
    "points": 276,
    "commentCount": 167,
    "retryCount": 0,
    "time": 1734380281
  },
  {
    "id": 42438175,
    "title": "MIT study explains why laws are written in an incomprehensible style",
    "originLink": "https://news.mit.edu/2024/mit-study-explains-laws-incomprehensible-writing-style-0819",
    "originBody": "The convoluted “legalese” used in legal documents conveys a special sense of authority, and even non-lawyers have learned to wield it. Anne TraftonMIT News Publication Date: August 19, 2024 Press Inquiries Caption: MIT cognitive scientists believe the convoluted language of legalese acts to convey a sense of authority. Credits: Credit: iStock Legal documents are notoriously difficult to understand, even for lawyers. This raises the question: Why are these documents written in a style that makes them so impenetrable? MIT cognitive scientists believe they have uncovered the answer to that question. Just as “magic spells” use special rhymes and archaic terms to signal their power, the convoluted language of legalese acts to convey a sense of authority, they conclude. In a study appearing this week in the journal of the Proceedings of the National Academy of Sciences, the researchers found that even non-lawyers use this type of language when asked to write laws. “People seem to understand that there’s an implicit rule that this is how laws should sound, and they write them that way,” says Edward Gibson, an MIT professor of brain and cognitive sciences and the senior author of the study. Eric Martinez PhD ’24 is the lead author of the study. Francis Mollica, a lecturer at the University of Melbourne, is also an author of the paper. Casting a legal spell Gibson’s research group has been studying the unique characteristics of legalese since 2020, when Martinez came to MIT after earning a law degree from Harvard Law School. In a 2022 study, Gibson, Martinez, and Mollica analyzed legal contracts totaling about 3.5 million words, comparing them with other types of writing, including movie scripts, newspaper articles, and academic papers. That analysis revealed that legal documents frequently have long definitions inserted in the middle of sentences — a feature known as “center-embedding.” Linguists have previously found that this kind of structure can make text much more difficult to understand. “Legalese somehow has developed this tendency to put structures inside other structures, in a way which is not typical of human languages,” Gibson says. In a follow-up study published in 2023, the researchers found that legalese also makes documents more difficult for lawyers to understand. Lawyers tended to prefer plain English versions of documents, and they rated those versions to be just as enforceable as traditional legal documents. “Lawyers also find legalese to be unwieldy and complicated,” Gibson says. “Lawyers don’t like it, laypeople don’t like it, so the point of this current paper was to try and figure out why they write documents this way.” The researchers had a couple of hypotheses for why legalese is so prevalent. One was the “copy and edit hypothesis,” which suggests that legal documents begin with a simple premise, and then additional information and definitions are inserted into already existing sentences, creating complex center-embedded clauses. “We thought it was plausible that what happens is you start with an initial draft that’s simple, and then later you think of all these other conditions that you want to include. And the idea is that once you’ve started, it’s much easier to center-embed that into the existing provision,” says Martinez, who is now a fellow and instructor at the University of Chicago Law School. However, the findings ended up pointing toward a different hypothesis, the so-called “magic spell hypothesis.” Just as magic spells are written with a distinctive style that sets them apart from everyday language, the convoluted style of legal language appears to signal a special kind of authority, the researchers say. “In English culture, if you want to write something that’s a magic spell, people know that the way to do that is you put a lot of old-fashioned rhymes in there. We think maybe center-embedding is signaling legalese in the same way,” Gibson says. In this study, the researchers asked about 200 non-lawyers (native speakers of English living in the United States, who were recruited through a crowdsourcing site called Prolific), to write two types of texts. In the first task, people were told to write laws prohibiting crimes such as drunk driving, burglary, arson, and drug trafficking. In the second task, they were asked to write stories about those crimes. To test the copy and edit hypothesis, half of the participants were asked to add additional information after they wrote their initial law or story. The researchers found that all of the subjects wrote laws with center-embedded clauses, regardless of whether they wrote the law all at once or were told to write a draft and then add to it later. And, when they wrote stories related to those laws, they wrote in much plainer English, regardless of whether they had to add information later. “When writing laws, they did a lot of center-embedding regardless of whether or not they had to edit it or write it from scratch. And in that narrative text, they did not use center-embedding in either case,” Martinez says. In another set of experiments, about 80 participants were asked to write laws, as well as descriptions that would explain those laws to visitors from another country. In these experiments, participants again used center-embedding for their laws, but not for the descriptions of those laws. The origins of legalese Gibson’s lab is now investigating the origins of center-embedding in legal documents. Early American laws were based on British law, so the researchers plan to analyze British laws to see if they feature the same kind of grammatical construction. And going back much farther, they plan to analyze whether center-embedding is found in the Hammurabi Code, the earliest known set of laws, which dates to around 1750 BC. “There may be just a stylistic way of writing from back then, and if it was seen as successful, people would use that style in other languages,” Gibson says. “I would guess that it’s an accidental property of how the laws were written the first time, but we don’t know that yet.” The researchers hope that their work, which has identified specific aspects of legal language that make it more difficult to understand, will motivate lawmakers to try to make laws more comprehensible. Efforts to write legal documents in plainer language date to at least the 1970s, when President Richard Nixon declared that federal regulations should be written in “layman’s terms.” However, legal language has changed very little since that time. “We have learned only very recently what it is that makes legal language so complicated, and therefore I am optimistic about being able to change it,” Gibson says. Share this news article on: X Facebook LinkedIn Reddit Print Paper Paper: “Even laypeople use legalese” Check for open access version(s) of the research mentioned in this article. Press Mentions Los Angeles Times A study by researchers at MIT and elsewhere has found that both lawyers and non-lawyers use legalese when asked to write about laws, reports June Casagrande for The Los Angeles Times. The \"researchers tested the hypothesis by asking 200 participants to write laws prohibiting crimes like drunk driving and burglary,” explains Casagrande. “Then they asked them to write stories about those crimes. The laws they wrote contained unnecessarily long, labyrinthine sentences with lots of parenthetical explanations crammed in. The stories, however, were written simply, without the parenthetical information stuffing.” Full story via Los Angeles Times → Fast Company Researchers at MIT have uncovered a possible reason why legal documents can be so difficult to read, finding that “convoluted legalese often acts as a way to convey authority,” reports Joe Berkowitz for Fast Company. The researchers “tested whether nonlawyers would end up using legalese if asked to write legal documents,” explains Berkowitz. “In the end, all subjects wrote their laws with complex, center-embedded clauses.” Full story via Fast Company → Futurism Researchers at MIT have found that the use of legalese in writing “to assert authority over those less versed in such language,” reports Noor Al-Sibai for Futurism. “By studying this cryptic take on the English language, the researchers are hoping to make legal documents much easier to read in the future,” explains Al-Sibai. Full story via Futurism → Previous item Next item Related Links Gibson Lab Eric Martinez Department of Brain and Cognitive Sciences School of Science Related Topics Research Language Law Writing Communications Literature, languages and writing Brain and cognitive sciences School of Science Related Articles How “blue” and “green” appeared in a language that didn’t have words for them Even lawyers don’t like legalese Objection: No one can understand what you’re saying",
    "commentLink": "https://news.ycombinator.com/item?id=42438175",
    "commentBody": "MIT study explains why laws are written in an incomprehensible style (news.mit.edu)224 points by keepamovin 15 hours agohidepastfavorite265 comments GrantMoyer 3 hours agoMostly, I think, legalese is a collection of superstitous incantations built up over millenia, which lawyers use because \"you need to say it exactly like this or vague, bad stuff will happen.\" Except sometimes the superstitions are right. I also think lawyers don't find it worth optimising the language much, because the target audience is other lawyers who know all the incantations anyway. The target audience is lawyers instead of laypeople, because the language isn't what matters in the first place. What matters is all the relevant case law, which can vary so much from the \"obvious\" or even \"right\" interpretaion of the written language, that a layperson not using a lawyer for all but the most trivial legal needs is a recipe for disaster. reply coliveira 3 hours agoparentThat's not true at all. Law is written like it is because courts give a lot of importance to what is written and changes in these written forms have many possible consequences. This, combined with the fact that our judicial principles go very far back (starting already in ancient times with the Romans), makes it very inconvenient to change language and terms used. reply jimmydddd 2 hours agorootparentThis is correct. If 50 cases interpret and define the word \"includes\" in a contract, and you decide to use the word \"comprises,\" you may end up burning time and money in court and negotiations. reply unethical_ban 1 hour agorootparentDo engineering specifications use the same center embedded sentences as legal documents? IETF defines may, must, shall, etc. in every document but doesn't use the same format as law. reply psychlops 1 hour agorootparentprevDespite your opening sentence, you didn't disagree with OP. \"Courts\" are a venue for other lawyers. reply sdwr 1 hour agorootparentThere's a constant tendency here to assume other people don't think, they blindly copy what's popular. Everybody learns partially through pattern recognition, partially from trial and error, partially from armchair reasoning. And functions mostly by repeating what they already know. But it's emotionally satisfying to put all the negative parts onto others (cargo cult sheeple reciting magic spells), and save all the positive identifiers for yourself (brave scientist uncovering truths about the universe) reply alexisread 3 hours agoparentprevI think this is the crux of the problem, case law exists to help 'refine' and 'classify' a case ie. a crutch for an incomplete specification (the actual law). The 'workflow' is that the judgement on the current case informs the next ones and so on. I'd prefer it if previous cases had a bearing on rewriting/amending laws, rather than influencing a current case, and if the feeling is that a current judgement was not correct, rewrite/refine the law taking the case into account. That way a judgement does not require previous case research, this does mean that law needs to become a more well specified, and unambiguous language. We have decades of classification and computer language theory to draw from, and LLMs to stub-translate existing law, with exceptions going to a dead-letter-queue for individual appraisal. Law should be understandable by the layman, else how does someone know if they have broken it? reply kristianbrigman 50 minutes agorootparentI'd prefer to keep the separation of powers intact (legislature writes/modifies laws, judiciary can strike them down but can't (or isn't supposed to) make up law... the exchange is not that different between development and QA :) your process seems reasonable though. reply bonoboTP 45 minutes agorootparentprevThat's called civil law and is used in almost all of Europe. Common law seems quite strange, nebulous and inefficient seen from a civil law continent. reply wbl 34 minutes agorootparentprevCongress can do this but chooses not to. reply hansvm 1 hour agorootparentprev> Law should be understandable by the layman, else how does someone know if they have broken it? This is especially important in a world where precious few scenarios allow ignorance as a legal defense. reply dotancohen 3 hours agoparentprev> What matters is all the relevant case law Not in all jurisdictions. And even in those places, the laws are often difficult to decipher. I think that the problem is trying to encode both intent and formal instructions in the same language. If a law were to state clearly \"our intent is to prevent people from falling off tall buildings\" and then specifying building code, then any ambiguities in implementation or new materials or new methods could be addressed by referencing the intent. This would be especially helpful in e.g. criminal law, where ambiguities or oversights in language (e.g. with regard to women raping men) often lead to both innocent people sitting in jail, and guilty people going free. reply JumpCrisscross 3 hours agorootparent> If a law were to state clearly \"our intent is to prevent people from falling off tall buildings\" and then specifying building code, then any ambiguities in implementation or new materials or new methods could be addressed by referencing the intent This is how American laws are usually written. Courts even venture into the debate records to discern intent. reply dmoy 2 hours agorootparentThe intent bit in the laws is also is very brittle to changes in language. When the underlying words morph and mean different things, then hundreds of years later people kinda forget, and now we have a law that people think has a different intent. Similar to the way it's brittle when there are money numbers that don't include inflation (either on purpose or not), or (rarely) use a hilariously wrong inflation number instead of an index (say for a law passed during a time of very high inflation). Then the numbers change (or don't), and everything gets weird. reply jonhohle 1 hour agorootparentThat may be why the Supreme Court has chosen “history, text, and tradition” for constitutional evaluation. Changing the meaning of a word in an effort to change a law is frighteningly Orwellian. reply exe34 1 hour agorootparent> Changing the meaning of a word in an effort to change a law is frighteningly Orwellian. reminds me of this: https://themedialine.org/by-region/irelands-push-to-alter-ic... reply hansvm 1 hour agorootparentprevIf we didn't have a two-party nightmare willing to filibuster perfectly good policies as a tool to ramrod in alternative agendas, I think it'd work well to have laws with expiration dates. You'd have a natural forcing function by which language would be refined over time, laws would stay relevant, and the total body of legislation would stay at a manageable size. As something of a litmus test, if a crime is so minor that the police wouldn't do anything if you brought them multiple eyewitnesses, video evidence, and an address to knock on, then having that law on the books probably does more harm than good (many petty crimes like mild speeding would fit those criteria). reply bobthepanda 5 minutes agorootparentThe budgeting process already works like this and is a hot mess. And so do other things like the PATRIOT Act, the authorization of various agencies like FAA, etc. thfuran 23 minutes agorootparentprevI don't think (all) laws should expire. It'd mean that any delay in the legislature could potentially cause a real mess. But I do think a well-functioning legislature should spend a fair amount of time reviewing and perhaps revising the existing body of law. reply xeromal 1 hour agorootparentprevI don't know anything about anything but a good example of what you're talking about has to be \"a well regulated militia\" or just the second amendment in general. It's wild how different people interpret it reply SoftTalker 2 hours agorootparentprevThis is why laws should sunset after some period of time, maybe 50 years, maybe 100 years. At that time they should be reviewed, debated again, and decisions made as to whether each law should be renewed as-is, revised, or (the default) allowed to lapse. reply wholinator2 1 hour agorootparentThat's certainly an interesting idea, but i can imagine about 1000 different ways it could go wrong. Any sufficiently disruptive party could easily destroy the government just by preventing all laws from being reinstated. You could also just filibuster past the deadline for renewal to give your buds a couple days to break the law and then let it pass finally. You also would probably need a parallel bureaucracy just to handle the massively increased work load of governing. Maybe with a new nation that had time to adapt to the scenario it could form a functional system, but if implemented in America today I'd give it a not insignificant chance of actually crashing the entire government like a computer attempting to open a zip bomb reply SoftTalker 52 minutes agorootparentFair point. I'd like to think nobody would filibuster against popular laws such as those against murder, rape, theft, etc. but more that it's an opportunity for laws like \"you can't sell a car on Sunday\" or various controlled substance laws to quietly expire as public attitudes change. reply kristianbrigman 1 hour agorootparentprevThere have been some people pushing for every new law to include a sunset clause, but I don’t know how you could enforce it for new laws. reply bryanrasmussen 28 minutes agorootparentprev> If a law were to state clearly \"our intent is to prevent people from falling off tall buildings\" and then specifying building code, then any ambiguities in implementation or new materials or new methods could be addressed by referencing the intent. I see you are not American, and evidently are not really familiar with the second amendment. reply HPsquared 3 hours agoparentprevIt's a lot like C++, come to think of it. reply coldtea 3 hours agoparentprev>Mostly, I think, legalese is a collection of superstitous incantations built up over millenia Careful past that Chesterton fence reply TacticalCoder 3 minutes agoparentprevAnother form of hilarious incantation in legalese are the way \"patches\" do work. There's a complete vocabulary and way to formulate sentences to, literally, apply patches to older texts. It's \"diff\" but for legal text, using natural language (well as much as legalese is natural). I don't know in english but in french you can definitely have a legal text (say for your company statuses) and then patches when you did modify things. Or you can have the \"consolidated\" text, which is the text with the patches already applied (it's definitely more of an easier read as there's no need to jump back and forth between the patches). And of course the patches can reference another legalese text, which itself can reference another legalese text. And all of these can have... Patches. These patches/revisions going out of their way to introduce a patching logic using natural language is plain weird. Besides these patches/revisions, I'd say the second most WTF legalese thing is that somehow, at some point, where there were already rules and laws governing what a person could and could not do, someone, somewhere (in Rome probably), decided that we could create new persons, but not physical persons: entities dealt with as if they were individuals. But virtual. I did set up a company: I created a person. And we do shareholders meetings and vote stuff and go in front of a notary and that notary comes up with revisions and we patch the person I created by sending the patches to the authorities. It's completely mindboggling. reply mihaaly 1 hour agoparentprevBut the target audience is for laymen and not lawyers because we all have to abide the law and contracts and have to sign incomprehensive text that will have punishable consequence on us! How to obey the law/regulations/rules when you do not understand? My lawer should sign all my incomprehensible contracts and be punished for violations then, if the text is for them. reply llamaimperative 1 hour agorootparentThe target audience isn’t laypeople. That’s why you have a right to legal representation. “Laypeople” language is way, way too ambiguous. Same reason you can’t write computer code in lay language. … there are consequences for lawyers if they fail to do this translation effectively… reply dfxm12 1 hour agoparentprevDon't bad things happen anyway, via what we call \"loopholes\", et al? It seems like laws are sometimes written to be intentionally evaded by the lawyered class. reply LiquidSky 3 hours agoparentprevNew York attorney here. You're kind of getting it, though put in a silly way. It's not that \"vague, bad stuff will happen\" it's that, in common law jurisdictions at least, precedent controls. So if you use language that has been upheld for decades or even centuries you can be as confident as possible that whatever you're doing will also be upheld. Any novelty or variation introduces greater risk of a ruling against you. This naturally creates inertia and a conservative approach in legal practice. reply cowl 27 minutes agorootparentThis doesn't explain the legalese in Civil case juridistictions which almost all of Europe is. There is no case that can change whether something is legal or not. My pet theory is legalese is just to sound different, authoretative and if we want to go into conspiracy theories, than it is to make sure that lay people will need you even for the simple cases. reply bombcar 4 minutes agorootparentPart of it is that lawyers are paid. If you pay a repairman to come to your house and fix something, even if he does fix it in five seconds, you're going to feel a bit cheated because you paid him assuming it would take hours. Same with a lawyer - if you pay one to write something for you, or review a contract, they WILL write something or find something that makes you feel like you got your money's worth. reply mlinhares 1 hour agorootparentprevNah, it's all a gentlemen's agreement, given Roe vs Wade, if you want it enough you can bend it the way you want. reply dehrmann 1 hour agorootparentOn which end of Roe? The reasoning for the decision was sketchy, and Dobbs overthrew decades of case law. reply wbl 30 minutes agorootparentAll of the original case, and Kennedy's sweet mystery opinion in Casey, and then the transparently political overturning emphasize how political courts can be. I read some of the argument transcripts and usually it is a bunch of lawyers trying to sort out what the law should be given it works this way in this case and that way in that case and this one goes up the middle or the circuits disagree. But sometimes it is much more nakedly political. reply mlinhares 6 minutes agorootparentYeah, people often think there's some magical value to words, but they only have value in the political environment they sit in. If you decide not to enforce it, it doesn't exist, if you decide to over enforce it, everyone will think about it. It's all people's decisions, there's no magic about it. reply zo1 50 minutes agoparentprevMy pet half-serious quip about laws/lawyers. Imagine writing a complex program without loops and functions, but you have access to C++ templates, and if statements can only be written as in-line switch statements that can't have any function calls. Oh and any \"changes\" to the code have to be done in the form of diff files that are included in the next program that may or may not be related. That's how laws are written. reply taneq 2 hours agoparentprevMuch like systems code, right? :D (Mostly what I’m saying is that legalese is essentially natural(ish) language ‘software’ that has been developed and maintained over centuries by non-coders[1] and that most of the seemingly pointless or obtuse stuff is probably actually significant in weird edge cases.) [1] Not by any means saying that systems code is written by non-coders! But some of it is written by wizards and becomes Deep Magic that gets repeated by less eldrich contributors because if it isn’t then the authors sometimes meet a fiery doom. reply kristianbrigman 16 minutes agorootparentIt's not _written_ by non-coders, but it is _used_ by non-coders who do not always follow the way you expect them to use it... reply gosub100 3 hours agoparentprevThe harder they make it to join their club, the more exclusive their service becomes. And thus they can command a higher salary. reply fao_ 2 hours agorootparent\"(layperson looking at the Intel opcodes listing) The harder they make it to join their club, the more exclusive their service becomes. And thus they can command a higher salary\" I know this might be difficult for those of us who have specialized in computer science and have found a lot of things very easy, but sometimes, other professions are difficult and complicated too! Not everything is gatekeeping, and needing to consult an expert otherwise you'll footgun yourself, isn't a personal blow to you, as a person! reply Zak 15 minutes agorootparentThe law is special because everyone has to obey it or face punishment. It is an injustice if most people can't figure out whether things they want to do are legal or not without employing a lawyer. reply dragonwriter 12 minutes agorootparent> The law is special because everyone has to obey it or face punishment. In theory, yes. In practice, not “everyone”, and very much not equally true of everyone to whom the law practically applies at all, even in the places which tout “equal protection of the laws” as a bedrock principle. reply zo1 57 minutes agorootparentprevExcept we go out of our way in programming to make everything as easy as possible. If you think about it, half the non-video and non-social media internet is just programming related, with guides, tutorials, and various tools to make it as easy as possible to get somebody doing something. And yes to be fair, yes some stuff in a field is simply complicated and we need to use complicated tools, specifications, processes and other such things in order to describe it accurately. But lets face it - most lawyer stuff is not complicated, the field is just swamped with complexity, \"technical debt\" and they are relying on processes and fluid human-driven interpretations in order to make it all chug along. What makes the whole thing complicated are the unspoken, verbally and experience-driven pieces of arcane knowledge. Nothing is documented in simple flows, nothing can be automated according to them, and they require actual human actors to drive the process forward from one step to the next. This is why they are so against automation and simplification of their field. They know that if they automate the processes, that their field becomes very focused on knowledge, and at that point we'll all just realize that most of what they know can be codified in some sort of unambiguous specification format. reply gosub100 2 hours agorootparentprevComputing has become substantially cheaper and more accessible in the past couple decades. Can the legal industry make any such claims? Is it faster and more efficient to use the judicial system than it was in the 90s, 2000s? Why is the NY bar one of the hardest in the nation? Couldn't have anything to do with all the biglaw and money to be made in the city, no? reply goatlover 1 hour agorootparentIs it substantially easier and cheaper to become a medical doctor? Are there lots of technical jaron to learn in medicine? reply gosub100 18 minutes agorootparentNo, thats yet another cartel. reply GrantMoyer 3 hours agorootparentprevI've thought a lot about how absurd it is that the rules we must follow are so obtuse that an entire profession exists to advise and argue if we and others are following the rules. But I've come to believe we just live in an absurd reality, and there's no possible way to communicate a set of rules to everyone, or even to get everyone to agree to one set of rules in the first place, so the legal profession is an unfortunate necessity. Of course, that doesn't preclude lawyers from sometimes being unscrupulous. reply Enginerrrd 2 hours agorootparentWriting laws to cover complex situations is really not THAT different from writing software. Laws are programs. In that context, does it really seem so absurd that the rules are \"obtuse\"? Many people feel that way when reading someone else's code, but that doesn't mean all the weird conditionals are unnecessary. reply dragonwriter 1 hour agorootparent> Writing laws to cover complex situations is really not THAT different from writing software. I’ve done software (a lot) and worked in a legislative office (a little), they are extremely different. > Laws are programs. Laws are not programs, or even meaningfully analogous to anything so deterministic. They are more like, if we must make a computing analogy, components of prompt templates (other portions of which will be filled by evidence and…well, a bunch of other stuff you don’t control when writing the laws) that will be used by an extremely high temperature LLM. Which you can’t actually test freely against, though you can observe past behavior – but, even then, you are stymied by the fact that the LLM itself is constantly updated with retrained, and sometimes rearchitected, versions, without useful release notes. reply unyttigfjelltol 1 hour agorootparentNo, law is code. It's just that the programming language is mushy-- 400 definitions of the word \"set\" is the example my AI offers-- and the interpreters vary. In a pinch, the code writers know that nearly anything they write can be rescued by the chief interpreter, which has led to a model of legislatures intentionally writing ambiguous code and top-level courts interpreting with an emphasis on public good. But, when you go down some arcane rabbit hole that will normally be interpreted by functionaries -- bankruptcy comes to mind-- suddenly everything is prescribed with remarkable precision and it becomes obvious again, law is code. reply dragonwriter 14 minutes agorootparent> But, when you go down some arcane rabbit hole that will normally be interpreted by functionaries -- bankruptcy comes to mind-- suddenly everything is prescribed with remarkable precision If this were really true, there would be zero appellate cases (and probably not even trial cases, as the clear and only correct resolution would be apparent to all parties without a trial which would only add expense) in these areas, and yet... That's very much not the case. If law, even in these areas, is “code”, it is so more in the sense of the Pirates Code in Pirates of the Carribean, not computer software. reply echoangle 1 hour agorootparentprevThe problem is that the output of the program determines if you’re going to jail. There are laws that many people might break just because they have no clue that there’s even a law about that. Realistically, you’re probably not going to go to jail immediately but you can have a bad time if you’re caught doing some things you didn’t even know were illegal. reply gosub100 3 hours agorootparentprevI think of case law as like a git repo of every function and subroutine anyone ever wrote. So on one hand it makes sense to need a specialized education to use it (so we don't waste time arguing the same noob points over and over). But on the other hand, you shouldn't need a law degree and bar license to sue an insurance company to pay up. Their client hit you, you're injured, now pay up or have a judge order you to. But the lawmen have carved out their own moat that puts ordinary people in a position to rely on them. reply coldtea 3 hours agorootparentprevThere are literally 1.33 million lawyers in the US... reply aleph_minus_one 2 hours agoparentprev> I also think lawyers don't find it worth optimising the language much, because the target audience is other lawyers who know all the incantations anyway. The target audience is both lawyers and laymen. Every lawyer and politician who claims that it is not worth optimizing this also claims that they don't want ordinary citizens to be capable of obeying the law. Tell this to every politican that if they don't work brutally hard on changing this fact they don't want ordinary citizens to be capable of obeying the law, and that they are thus (in the view of the ordinary citizen) working on to establish a arbitrary justice. Thus, they work on destroying (in the view of the ordinary constitutional state) on actively destroying the constitutional state. So, what makes these politicians and lawyers than differ from a despicable high traitor? reply QuercusMax 1 hour agorootparentHalf the politicians are lawyers, so it makes sense they'd want to protect their own interests. reply escapecharacter 2 hours agoparentprevI find there’s a similar hidden alternate semantic reality for business reviews. “Rustic” means the building is falling apart. “Bustling” means it’s impossible to find a seat. “Wholesome” means there’s no professional standards or consistency. It’s always an y in under-emphasis. It’s like two generations of reviewers ago, there were a bunch of defamation lawsuits and every reviewer has mimicked this style since. reply lenerdenator 3 hours agoparentprev> Mostly, I think, legalese is a collection of superstitous incantations built up over millenia, which lawyers use because \"you need to say it exactly like this or vague, bad stuff will happen.\" Except sometimes the superstitions are right. If the American legal system is any indication, the vague, bad stuff is the desired outcome. It's amazing the regulations that the EU has where it says \"no, do not do this\", and not only do people generally not do it, the people who do get caught doing it are fined into oblivion for it. There's no culture of hiring teams of lawyers to poke holes in the law to get around something society clearly desired, because the court is going to do what society desired. Why, yes, I am talking about data privacy, but there are other examples. reply JumpCrisscross 3 hours agorootparent> no culture of hiring teams of lawyers to poke holes in the law to get around something society clearly desired, because the court is going to do what society desired Wat. I’ve literally seen tax laws in Germany and Sweden which could only possibly apply to one family. European law is in sans serif; that doesn’t mean it’s less convoluted than American law. reply lenerdenator 3 hours agorootparentIt seems like we do that not only with tax law in the US, but with every other law, too. reply JumpCrisscross 2 hours agorootparent> seems like we do that not only with tax law in the US, but with every other law, too You’re seriously arguing that the EU bureaucracy is streamlined and comprehensible without lawyers? Why do you think every rich person and powerful firm in Europe has fleets of lawyers? reply lenerdenator 38 minutes agorootparentI'm arguing that when court cases in the US are judged, the letter of the law (and thus all of that arcane language) matters more than the spirit of the law, while it seems to be the opposite in the EU for a lot of things. reply sys32768 3 hours agoprevWhen I went toe-to-toe with a debt collector, I quickly discovered that many laws are vaguely written by lawyers to encourage litigation. The language in both the federal and state debt collection laws was so ambiguous that my research only lead me to consumer agencies saying I needed to ask an attorney. Or, I would find court cases where both sides argued over the language but the settlement did not alter the law, so I would have to litigate when push came to shove. I stood my ground with the debt collector on refusing to pay interest on medical debt after paying off said debt, but they never admitted I was right, and I am still baffled by their arguments that only an attorney could navigate. reply floxy 2 hours agoparent>...In the real world, people usually attempt to solve problems by forming hypotheses and then testing them against the facts as they know them. When the facts confirm the hypotheses, they are accepted as true, although subject to re-evaluation as new evidence is discovered. This is a successful method of reasoning about scientific and other empirical matters because the physical world has a definite, unique structure. It works because the laws of nature are consistent. In the real world, it is entirely appropriate to assume that once you have confirmed your hypothesis, all other hypotheses inconsistent with it are incorrect. > In the legal world, however, this assumption does not hold. This is because unlike the laws of nature, political laws are not consistent. The law human beings create to regulate their conduct is made up of incompatible, contradictory rules and principles; and, as anyone who has studied a little logic can demonstrate, any conclusion can be validly derived from a set of contradictory premises. This means that a logically sound argument can be found for any legal conclusion. The Myth of the Rule of Law https://drive.google.com/file/d/1I-JhqpU3_0r_HL06hP-5DABhEtG... reply mjburgess 2 hours agorootparentThe law is not a set of propositions, so this issue does not arise. The law is a linguistic artefact which requires interpretation to derive propositions, ie., pragmatics. The pragmatic context of interpretation, hemmed-in by precedent, dramatically narrows the range of admissible \"legal propositions\" in any given legal context. The idea that the law is, or should be, a canonical set of propositions is the real \"myth\" here, one espoused by people who haven't thought for a moment how such a set of propositions could ever be constructed. reply Aachen 2 hours agoparentprev> where both sides argued over the language but the settlement did not alter the law, so I would have to litigate when push came to shove. It does not matter what the law says, you always have to litigate if you want to force another party to do what you want. If the law says it and they don't do it, you have to. If case law confirms it and they don't do it, you also have to. Commonly referred to as the 90% of the law: they have what's yours, but it's up to you to put in the effort to prove it and get anything back at all Judges never alter law made by the legislator, in any (trias politica) legal system that I know of (Netherlands mainly, but also what I read of UK law and friends), but in all of the aforementioned: the case law is an important aspect of your obligations and rights. One refers to it as basically equal to law, but it doesn't alter the law itself reply bux93 3 hours agoprevFrom the linked article, this particularly stands out: Among the features identified as more common in legal documents, one stood out as making the texts harder to read: long definitions inserted in the middle of sentences. [..] “For some reason, legal texts are filled with these center-embedded structures,” Gibson says. “In normal language production, it’s not natural to either write like that or to speak like that.” - notice how there's a definition right in the middle of the article, and not at the beginning. Anyhow, there is a specific reason for having a definition not in chapter 1, article 1 (definitions) but somewhere down in article 15; lexical scope. That definition is not meant to be used in article 8 or 64, where the same word or phrase may be interpreted \"as normal\" (that is, still as a legal term, but not the one from article 5). This research seems to ignore that there are different styles of legal texts; you'll find that the civil code of any country is usually written in a different (more modern) style than the ancient \"thou shalt not kill\" bits of the penal code. Even if new crimes are added, those will be written in the same ye olde style, rather than an updated one (with definitions in chapter 1). Also, legal texts dealing with finance tend to be written in a different style from legal texts pertaining to consumer protection. reply dylan604 3 hours agoparentGreat, so definitions have scope applied to them. Sounds like definitions defined in chapter 1, article 1 are global while the lexical scope is just a local. We should force them to use the key word \"let\" in front of the term (or which ever equivalent for your favorite language). reply Clamchop 2 hours agoparentprev> notice how theres a definition right in the middle of the article, and not at the beginning. The criticism is of sentence structure, not document structure. > That analysis revealed that legal documents frequently have long definitions inserted in the middle of sentences — a feature known as “center-embedding.” Linguists have previously found that this kind of structure can make text much more difficult to understand. https://en.wikipedia.org/wiki/Center_embedding reply Swizec 13 hours agoprevIs legalese not just the result of trying to use English as a programming language? Any time I try to write English (or other natlang) precisely and unambiguously and robust against adversarial interpretations, it comes out looking like legalese. reply aragonite 3 hours agoparentIt’s true that trying to state complicated necessary and sufficient conditions will inevitably involve a ton of essential complexity due to the nature of the subject matter, but there may still be room for improvement by eliminating additional accidental complexity introduced by e.g. cumbersome syntax. I think by \"legalese\" the authors probably have in mind only the accidental complexity introduced by the distinctive, convoluted syntax of legal language. For instance, here [1] is a random paragraph I found in a contract that I think is pretty good example of \"legalese\", and here [2] is my attempt to rewrite it for readability. All the essential complexity remains, but I think (hope!) much of the accidental complexity has been removed. :) [1] 3.3.4 Date of Issuance. Each person in whose name any book entry position or certificate for shares of Common Stock is issued shall for all purposes be deemed to have become the holder of record of such shares on the date on which the Warrant, or book entry position representing such Warrant, was surrendered and payment of the Warrant Price was made, irrespective of the date of delivery of such certificate, except that, if the date of such surrender and payment is a date when the stock transfer books of the Company or book entry system of the Warrant Agent are closed, such person shall be deemed to have become the holder of such shares at the close of business on the next succeeding date on which the stock transfer books or book entry system are open. [2] 3.3.4 Date of Issuance. To determine the record date for ownership of Common Stock shares (whether issued as a book entry or certificate), ask: Were the Company's stock transfer books and the Warrant Agent's book entry system open when the Warrant was surrendered and the Warrant Price was paid? If yes, the record date is that same date of surrender and payment. If no, the record date is the close of business on the next day when the books and systems are open. reply Arelius 3 hours agorootparentOne problem I see with your rewrite, is it's written in a style such that it appears to be a responsibility of a party of the contract, but failes to specify which party. Where the original reads as a statement of state and fact. reply torstenvl 3 hours agorootparentprevWhat's a \"record date\"? How is it significant? What other provisions use that term? reply aragonite 2 hours agorootparentIt's when a company takes a static snapshot of who officially owns shares which is then used to determine who's eligible for things like dividends or voting on company decisions. You'll often see it in dividend declarations (e.g. \"shareholders of record as of March 1st will receive ....\" Then if you want that dividend, you need to be officially listed as a shareholder by March 1st.) reply pasc1878 2 hours agorootparentYes but that definition is not in the rule you rewrote - so you need to add to what you wrote. I suspect you will end up with something similar to the original. reply mdaniel 13 hours agoparentprevAside from the few proposals that I know of to literally use programming languages in laws, I have wondered if actually lowering the language expressiveness would help (e.g. https://simple.wikipedia.org/wiki/Simple_English_Wikipedia ) The thinking being that the less nuanced the vocabulary, the less ways it could be interpreted and thus one may not have to write so many laywerly guard phrases to artificially constrain \"normal\" vocabulary. It may very well run the risk of having to use a bazillion more cross-references as one builds up a \"library\" of word-subroutines, but still could be a net win But I guess I can navel-gaze all I like because for this specific domain, any change might as well be all the changes since there's no prayer reply caseyohara 13 hours agorootparentThe US government has the Plain Language movement which is rewriting policy and legal documents in clear, plain language. The plainlanguage.gov site is an excellent all-around writing resource. I direct junior developers here when they are trying too hard to sound fancy when communicating technical concepts in documentation and design documents. Here are some great examples: https://www.plainlanguage.gov/examples/before-and-after/ambi... https://www.plainlanguage.gov/examples/before-and-after/mont... https://www.plainlanguage.gov/examples/before-and-after/use-... reply falcor84 4 hours agorootparentThat's a great initiative, but even with these, I feel there's further opportunity to make these clearer. As a particular example, is there any reason to keep the vague \"second month\" in the second example [2], rather than \"subsequent month\" or \"next month\"? [2] https://www.plainlanguage.gov/examples/before-and-after/mont... reply iterateoften 3 hours agorootparentLots of ambiguity with “next”. It’s always so hard to describe “next Wednesday” if it’s Monday or “next week” if it’s Saturday. My friends from non English countries get very confused that somehow “next Wednesday” when it’s Monday might not mean two days from now but 8 days from now. And how two days in that instance would be referred as “this Wednesday” or “this coming Wednesday” Which is different way of talking. If you were sitting by the road counting cars and you are at car “n”, Saying “the next car” would refer to car n+1. If your counting wednesdays you experienced “next Wednesday” technically refers to n+2 I stopped saying “this ” or “next ” and now just say “Wednesday the 25th” for instance. reply pxc 2 hours agorootparent> It’s always so hard to describe “next Wednesday” if it’s Monday 'Next Wednesday' is always the Wednesday of the calendar week following the current calendar week; doesn't matter what day of the week it currently is. 'This Wednesday' is always the Wednesday of current week on the calendar— even if that day is in the past. Is it quirky that this expression doesn't instead mean 'the next Wednesday that will occur'? Yes, definitely. But I don't see how it's difficult to describe what it actually does mean. > I stopped saying “this ” or “next ” and now just say “Wednesday the 25th” for instance. I love this. Indexicals in general can be tricky, and I love expressions that rely less or very little at all on context. Sometimes when a friend is telling a complicated story I'll ask them to repeat something tbey just said but with no use of pronouns, for instance, and it always makes interpretation much easier. As much as I think the actual idioms are perfectly describable, they are somewhat prominently misused. One of my pet peeves is how YouTube's search filters uses its time restriction phrases incorrectly: it says 'today' to mean 'within the past 24 hours', 'this week' to mean 'within the past week', 'this year' to mean 'within the past year', etc. It's Tuesday, and when I search for videos with an upload date from 'this week', I get results including videos uploaded 4 days ago, but this week is not yet 4 days old under any standard convention (e.g., starting the week on Mondays rather than Sundays)... -_- reply anon84873628 7 minutes agorootparentYour pattern of: '' is always ; doesn't matter . Is never going to be true in spoken language. Otherwise we wouldn't be having conversations about confusion and ambiguity in the first place. marcellus23 2 hours agorootparentprevI've taken to saying \"Wednesday\" or \"this Wednesday\" to refer to whichever Wednesday is coming up, and then \"the Wednesday after this Wednesday\" to refer to the following Wednesday. It is a bit wordy but at least it's unambiguous. reply im3w1l 3 hours agorootparentprevYeah it's not that clear to me. My interpretation would be that if I'm reporting (whatever that means) April, then May would be the first month following, and hence June would be the second month following. Hence the last day I could submit would be June 15th (paper) or June 25th (electronic). reply falcor84 1 hour agorootparentOh, wow, I think you're absolutely right and I entirely misread that (supposedly \"plain\") explanation. Having an example, like the one you gave, in the text would be really useful! reply fudged71 2 hours agorootparentprevAm I crazy or does the guidelines page not contain the guidelines? https://www.plainlanguage.gov/guidelines/ Maybe because I’m on mobile? reply aurareturn 12 hours agorootparentprevThis is a great resource for UX design as well. reply mdaniel 12 hours agorootparentprev> The Plain Writing Act of 2010 was signed on October 13, 2010. The law requires that federal agencies use clear government communication that the public can understand and use. well, no shit! that's amazing Thanks so much for bringing that to my attention, I'll try to see how I can incorporate those into my own process reply archermarks 12 hours agorootparentprevWow TIL. Those before and afters are awesome and I have definitely seen this showing up in government documents. Thanks for sharing. reply kookamamie 12 hours agorootparentprev[X] Good. reply ketzo 12 hours agorootparentprev> the less nuanced the vocabulary, the less ways it could be interpreted I genuinely don't mean this in a dickish way -- isn't this, like, tautologically untrue? By definition, more nuanced, more descriptive language describes a narrower, more precise view of reality than broader language otherwise would. When would plainer language allow less room for interpretation? I do generally think writing laws and other documents in plainer language would be beneficial for society, but not for this reason. Sometimes you do have to describe a really, really precise concept. \"Kill\" is different than \"murder\" is different than \"manslaughter\" in ways that are meaningful and important to preserve. Although even as I write that, I guess you could say \"kill\", \"kill a person with intention\", \"kill a person without intention\". That's kind of what you mean by word subroutines? At a certain point this just seems like a similarly-complex vocabulary, just with more words, though. reply mdaniel 12 hours agorootparentYes, sorry, it's the latter idea that you arrived at: if a law cannot be understood by a 9th grader, then one might argue it is mal-specified. I grew up hearing stories of folks that dropped out in the 9th grade so it seemed like a reasonable cut-off I am 100% open to the fact that it may not be possible to do this, since nat-lang is its own special little thing, and trying to apply fixes to it may be nonsensical themselves The word subroutines would be cross-references to potentially more complex concepts akin to \"one cannot end life (§3.14.159) unless working (§8.6.753) in a job (§127.0.1) that allows State violence\" where the boundaries of what this legislation cares about 'ending life,' the boundaries around 'working,' the boundaries of a 'job' would then be composed into 'citizen cannot kill other citizen'. I always got the impression that the nuance between murder and manslaughter wasn't in their degree of unlawfulness but rather in their sentencing, but I am deeply thankful that I haven't needed to know reply btown 3 hours agorootparentLaw does have subroutines like this... but they're implicit via \"as used in this section, X is defined as\" clauses that may be pages away or defined decades prior, as well as de facto definitions scattered through centuries of case law. New legislation can't simplify things unless the entire graph of implicit definitions is considered. All this was inscrutable before LLMs, but LLMs bring their own challenges: to summarize something in plain text, is it using a deep graph of definitions that are sourced and verifiable, or hallucinating their existence? IMO architectures as in https://arxiv.org/html/2410.04949v1 and https://arxiv.org/html/2409.13252v1 are useful; one uses LLMs to create local knowledge graphs and integrate them, then translates natural language queries into (successive) graph queries or graph-based RAG approaches. Things are still evolving in real time here, and IMO we've only scratched the surface of what's possible. reply dghlsakjg 12 hours agorootparentprev> I always got the impression that the nuance between murder and manslaughter wasn't in their degree of unlawfulness but rather in their sentencing, but I am deeply thankful that I haven't needed to know As an aside the difference between murder and manslaughter is in the intent of the perpetrator. Murder is typically when you intended for the outcome to be death (and is additionally divided into whether or not it was premeditated/planned). Manslaughter is reserved for when there was not intent to kill, but your actions caused a death. reply mdaniel 12 hours agorootparentRight, but that's why I said the sentencing part because to the best of my knowledge one doesn't become \"more unlawful\" in either case, rather if found guilty of the \"lesser\" of the two evils(?) you are unlikely to get capital punishment. The nuance is in the severity, not the crime Err, having written that out I now guess there is also some social component to it: you may still be received at a party if convicted of manslaughter but maybe not murder so we need different words to describe the act for purposes outside of the legal system reply dghlsakjg 2 hours agorootparentI mean… they represent two very different acts, albeit with the same outcome. It makes sense that we use different words for it. We even draw the distinction between degrees of murder since sitting down and planning a murder in cold blood (murder in the first degree) is far different than a road rage incident with a gun (murder 2) which is different still than a shove in a bar where someone falls down and hits their head and dies (manslaughter). Hell, some places even distinguish between voluntary and involuntary manslaughter. The point is that all these words have meaning, and we deeply care about the nuance. reply JumpCrisscross 2 hours agorootparentprev> if a law cannot be understood by a 9th grader, then one might argue it is mal-specified You want to administer nuclear weapons, the U.S. military and toxic-waste rules based on a high-school freshman’s knowledge of the world? reply ajmurmann 1 hour agorootparentprevI think you'd just end up going through the motions of this again: https://youtu.be/_ahvzDzKdB0 reply johnecheck 4 hours agorootparentprevCare to elaborate on the proposals to do laws via formal languages? Seems like there's a lot of pitfalls there, but that comes with the territory of writing laws in general. Seems like a concept worth exploring. reply bluGill 4 hours agoparentprevPrecise and unambiguous is important, and so legal documents will always have features that make them wordy and complex. However according to the article the grammar of legal documents is often much more complex than needed, and you could get the same precise and unambiguous language with a much easier to read grammar. reply bunderbunder 2 hours agorootparentSpeaking as a non-lawyer who works in the legal industry, I question the idea that legalese is generally more precise and unambiguous. From what I've seen the purpose of a lot of these legal incantations is actually to be more vague. This isn't necessarily a bad thing. A more precisely worded contract, for example, is arguably more likely to have unambiguous loopholes that people can abuse without you being able to easily fight back. The well-known reductio ad absurdum of this phenomenon is Etherium smart contracts. You see this in laws, too. The US's Federal Rules of Civil Procedure and associated case law, for example, contain all sorts of explicit refusals to say things more precisely. The stated rationale, here, is that it's impossible for the people drafting these rules to anticipate every possible situation and contingency, and instead they must trust that reasonable attorneys and judges are able sort things out in the course of litigation. reply Demonsult 7 hours agoparentprevI was pulled into a tough legal case and my lawyer explained that engineers have the hardest time working with law because they expect things to be logical. It's really a squishy mess full of ambiguities that are resolved with sophistry and head games. reply JumpCrisscross 3 hours agorootparent> engineers have the hardest time working with law because they expect things to be logical This sounds like something a lawyer would say to a client who wants to think that. Law and coding have remarkable parallels. reply internetter 2 hours agorootparentTo some extent, but in my experience developers struggle to understand that ultimately, the law is interpreted by humans, instead of a strict rule based system. I understand this frustration, to be clear, but this distinction is obvious. reply JumpCrisscross 2 hours agorootparent> in my experience developers struggle to understand that ultimately, the law is interpreted by humans, instead of a strict rule based system True. But this isn’t because someone is more logical. Honestly, that was a great line by a lawyer who probably wanted to focus on the case and not bill hours for a philosophy of law discussion. reply tiahura 4 hours agorootparentprevThe funny part is that engineers and doctors typically think they’re the smartest one in the room. To prove this, they over think and over explain their deposition responses. All this does is give a skilled interlocutor more avenues to question and develop inconsistencies. At which point ego is triggered and they become super-defensive. reply quesera 3 hours agorootparentAh, the always-entertaining moment when a person who is technically-correct (the best kind?) realizes that the socially-correct interpretation carries greater weight in the minds of everyone except themselves. Been there. Learned eventually. Sometimes still forget. :) reply Demonsult 3 hours agorootparentprevI won through a little bit of advice suggested by a layperson. I simply got the case moved to another room. The old judge hated us and the new judge loved us. All we had to do was decline magistrate jurisdiction. My lawyer was really reluctant for reasons I believe had to do with his standing with the court and not my case. And to think that layperson could be jailed for suggesting it. reply JumpCrisscross 2 hours agorootparent> to think that layperson could be jailed for suggesting it Who told you forum shopping is illegal to talk about? reply echoangle 1 hour agorootparentGiving legal advice when not being a lawyer is illegal, it’s probably very unlikely that this already counts as legal advice though. reply LiquidSky 3 hours agorootparentprevNo, they wouldn't, nor is this some kind of secret trick as you seem to be implying. This is a fairly common practice sometimes called \"judge shopping\" similar to \"forum shopping\" (where you try to get your case moved to the jurisdiction most friendly to your claim). It's not illegal, though it is (in theory) discouraged. As an example, if you're not familiar, look up the Eastern District of Texas and patent litigation. reply echoangle 1 hour agorootparentI think they were going for „giving legal advice while not being a lawyer“, not the suggestion of judge shopping. reply hooverd 2 hours agorootparentprevThank god we don't have a jury of morons making medical or safety critical decisions. Edit: Actually we do. Skilled interlocutors like that doing their thing are how we got leaded gasoline. reply bluepizza 13 hours agoparentprevIt reminds me of the pre-symbolic mathematical notations where equations would be described in long paragraphs. reply bunderbunder 2 hours agoparentprevI'd say it's more like a combination of trying to use natural language as a programming language in combination with behaviors that are analogous to indiscriminately using object-oriented idioms and enterprise design patterns (or overusing monads, for that matter) even when a much simpler way to express the same concept will do. Incidentally, I think that the reasons why programmers tend to do that are quite similar to the reasons for using legalese that the paper identifies. reply devjab 12 hours agoparentprevIn Denmark there is some part of legalese being the way it is because of what you talk about here. Legalese is essentially something you write for a “compiler”. Unlike a compiler, however, the legal system isn’t going to throw up and tell you that you are wrong when they interpret your legalese. Well I suppose it’s a little like JavaScript where it’ll continue and just replace bad parts with “any”. Which is bad if you intended a part of a contract to mean something very specific. reply taeric 3 hours agoparentprevNot just as a programming language. One that is being executed by adversarial agents. They won't just dumbly interpret the rules. They will do so with specific intent for gain. (I don't say this as a judgement.) reply gizmo686 13 hours agoparentprevI don't think so. Based on the article, the definition of legalese is a high prevalence of center-embedding. Center embedding is one of the most ambiguous ways to write sentences, so it does not make sense as a style of writing presisly. reply cryptoz 12 hours agorootparentThat’s not the definition of legalese and I protest the focus of the article and study: that center embedding is seemingly the sole issue. reply godelski 11 hours agoparentprevOn a side note, I find this interesting how accepting everyone here is that language is ambiguous. The conversations seem to drastically change when you start talking about LLMs. But this is exactly why I don't see them replacing programmers even if they didn't write shit code. Because like with law, you don't really even know what you're trying to describe until you start doing it. And then you gotta keep updating it and be thinking really hard about all your edge cases. Though for law, I think some ambiguity is beneficial. We should be going after the intent of the law, not the letter. This isn't just about bad encoding, as in not well aligned with the intent, but that there's always exceptions. Having that human judge be there to determine if something is actually reasonable or not is beneficial, even if there's a strong bias to follow the letter. reply gehwartzen 4 hours agorootparentI agree with your second point about intentionality of the law. I would love to see strict requirements that new laws should have sections explaining: -the intention in writing the law. -societal and economic situation that lead to it being needed. -what measurable outcomes the law should achieve in x years reply im3w1l 3 hours agorootparentPolitics is a game of making coalitions. People may be in favor of a law for disparate reasons. Take a law against prostitition. One person may be in favor of it to reduce trafficking. Another to reduce premarital sex. A third to reduce husbands' opportunities to cheat. A fourth to reduce the spread of std's. On the other side there may be one person that wants to have sex with prostitutes himself, another that believes women should be able to do what they want with their bodies, a third that believes prostitutes can be an important way for young men to gain sexual experience and skill, a fourth that thinks prostitution is bad but legalization to be a way of harm reduction. Not all of these people may be willing to admit their reasoning in writing. You could say that only following the written down reasoning is a feature. I haven't thought a lot about that subject, so I haven't made up my mind on it. reply tmalsburg2 10 hours agorootparentprev> Though for law, I think some ambiguity is beneficial. Ambiguity means that there are two or more possible interpretations and it's not clear which of them is intended. That's hardly useful. What's beneficial, and what you perhaps had in mind, is some amount of under-specification where the meaning is clear but leaves gaps to be filled in by judges. reply palmfacehn 12 hours agoparentprevI expect there is a correlation between frequency of use and broadness of interpretation. Commonly used words may be more likely to mean multiple things. Words cul-de-sac'd in arcane contexts may be less likely to evolve in the popular sphere. When someone says: \"That's so random\", it isn't a commentary on determinism. There are many cases where adhering to a precise definition becomes problematic in popular discourse. reply bruce511 13 hours agoparentprevNatural language is indeed ambiguous. Words tend to vary in meaning from time to time. So legal documents gave to precisely define a lot of terms, and Latin is also used (because meanings there dont change.) Take the phrase \"Open Source\" as an example. Us old folk ascribe specific meaning to that term - typically based on the legalese in Open Source licenses. However the next generation have imbued it with their own (various) definitions. This leads to endless back and forth. For example I recently pointed out that SQLite is Public Donain, not Open Source. (With predictable pushback.) Today, in other thread someone claimed \"its not really open Source unless its in git, and on github\". And the distinction between Free Software and Open Source is seldom understood. So yeah, legal documents are gard to parse because they can't take \"common meaning\" for granted. reply mdaniel 13 hours agorootparent> \"its not really open Source unless its in git, and on github\". Heh, mine is even more strict: to me, it's not really open source unless I can build it since if I cannot compile the project, I cannot change it for my needs and/or send those tested changes back upstream I have a second 2nd level \"requirement\" about packaging it in a sane distribution format, because I don't think any reasonable person wants to have a .desktop file that is $(cd /home/src/foo; npx run whatever \"$@\"). I'm looking at you, Chromium, since I can get it to build just fine but count the number of hand-rolled /usr/bin/install calls https://github.com/archlinuxarm/PKGBUILDs/blob/741f8edf84c7b... because evidently the $(make DESTDIR= install) is just kidding reply Gigachad 6 hours agorootparentprevOpen source only became confusing because Richard stallman made it his life mission to try to redefine the meaning of free in a way that would confuse people for decades to come. reply liontwist 4 hours agorootparentThere is no open source without stallman. After decades of advocacy and organizing his ideas have been moderated for mainstream success. Work on big technical projects like Linux was also a strong signal for employers. For years now that signal has been a target to emulate so a. Lot of “open source” became FAANG resume building. reply Terr_ 8 hours agorootparentprevOr like the old quip: \"Free as in speech, not free as in beer.\" reply the_clarence 13 hours agoparentprevIt's verbose english with a stubborn attitude against any kind of formatting. Maybe I'm part of the problem here. BRB. reply IceHegel 4 hours agoparentprevAnd very often means or in English - recent Supreme Court case about this. reply akoboldfrying 12 hours agoparentprevPossibly, but here's a data point in the opposite direction: Learning mathematics, especially higher forms of mathematics. Before students can learn directly from symbolic representations like formulae, mathematics teachers must communicate mathematical ideas to them using natural language -- and with just a few iterations of correcting misunderstandings, this process somehow converges on the students having the same understanding of these abstract ideas. That is, natural language succeeds here in bootstrapping a more precise form of communication. reply GrantMoyer 4 hours agorootparentMathematics can be unambiguously communicated because teachers are describing a system with only one or a few self consistent interpretations. Effectively, there's a natural error correction scheme built in (the state I've been described is invalid, so find the closest valid state and assume that). Note that even then, very many people struggle to communicate about math. reply somenameforme 11 hours agoprevMany people here are claiming that it has to try to do with being unambiguously expressive, but many laws are excessively verbose, largely incomprehensible, and still extremely ambiguous, most often in sections that constrain the scope of a law. By contrast some of the most fundamental laws in the nation, the Constitution's Bill of Rights, are generally just a sentence or two - and that works just fine. In my ever cynical opinion it's largely just a means of accumulating power without accountability. For instance in the terms and conditions of basically all major software now a days it says little more than \"You forfeit all rights, we reserve any and all rights imaginable, and we can change this whenever want.\" But if it actually said this then people might be inclined to say 'hey that's not cool.' But when it's instead wrapped in page after page of incomprehensible legalese, people don't even bother trying to see what they're agreeing to. reply GrantMoyer 4 hours agoparent> By contrast some of the most fundamental laws in the nation, the Constitution's Bill of Rights, are generally just a sentence or two - and that works just fine. To be fair, the Bill of Rights only works because it's been endlessly litigated, developing a large body of specific interpretaions. Together, all these interpretations would take far, far more than a couple of sentences to write out. However, any issue of contention will be endlessly litigated regardless of how specific the written law is. reply runako 3 hours agorootparent> the Bill of Rights only works because it's been endlessly litigated, developing a large body of specific interpretaions. As a follow-on to that, it is still being litigated and the interpretations continue to shift over time. For example, it wasn't until relatively recently that the Court began reading the Second Amendment in such a way as to limit the ability of jurisdictions to enact laws that prevent people from carrying firearms most places. Similarly, there is a current push to change the interpretation of the Fourteenth Amendment as well. Your central point is key: The Law is more about the judiciary's current understanding of what's written than what is actually written. reply sidewndr46 3 hours agorootparentprevAnd to that extent, the Bill of Rights only works because the government finds it generally does not apply. For example, practically none of it applies to students at this point. reply cynicalpeace 3 hours agorootparentThe Bill of Rights works because of the genius of the people who wrote it at the time. It starts to not work because of the lust for power of the people in charge of our bloated government now. This is a minority opinion on HN, but it's the correct one. reply pavel_lishin 4 hours agoparentprev> By contrast some of the most fundamental laws in the nation, the Constitution's Bill of Rights, are generally just a sentence or two - and that works just fine. I don't think that's an accurate representation of the Constitution. I'd that we've seen clear examples of when the plain language of even the first two amendments has not worked just fine, and resulted in harm and litigation all the way to the Supreme Court. reply ffk 2 hours agorootparentSince the 90s, New Zealand laws have been written in clear, modern, accessible English. The end result is the broader population understands it more and can also reason about it while it’s up for debate before being passed. I think the ambiguity in the first two amendments has to do more with the specific text rather than plain English itself being deficient. reply mjburgess 4 hours agoparentprevThere's a difference between regulations, laws and constitutional principles -- which in my view, shouldn't really be regarded as laws at all. At highest fidelity, and least ambiguity, is a regulation since it applies to a highly specific context, and seeks to regulate relatively easy to name and describe practices. The audience for a regulation is typically a regulator, ie., a part of the government. Regulations quantity over a finite number of institutions/bodies/practices which are generally identifiable explicitly at the time, even if the law is written more broadly. Many socially inadept engineering types assume either all law should be like regulation, but this would be tyranny, since you cannot easily enumerate or describe the vast majority of scenarios \"of legal concern\", and the attempt reduces social interaction down to the worst sort of prescribed interactions. The audience for ordinary laws is judges (and somewhat, the police) -- to guide their decision-making when interpreting an unenumerable social scenario \"of legal concern\". These nevertheless concern scenarios with describable features, and its generally clear at least when they apply. These \"general laws\" quantify over an infinite number of possible \"similar scenarios\" whose similarity is giving by legal precedent and developed traditions of intepretation. Finally constitutional principles, in being \"one sentence\" are nothing really like laws at all. In my view their audience is a very strange sort of judge who is much closer to a moral philosopher. These principles are so radically underspecified that they can apply to almost any scenario relative to some philosophical framework. The purpose of constitutional principles is to limit the government under very broad ethical guidelines. So the audience there is the government, broadly. They exist to deter excessively immoral government action. As you can see each of these has radically different purposes and audiences, and none make any sense as anything like a programming language -- nor are they anything like each other. reply afiori 9 hours agoparentprevI think that it is more about working around limitations, a TOS saying \"I can do whatever I want, you cannot\" might not hold on the basis of being too general, so you list all the areas where you can do whatever you want. Also if by law the user has some rights sometimes you might want to be careful to avoid contradicting them. Overall the cost of adding another paragraph is fixed and negligible and the possible gain in loss prevention is considerable reply cynicalpeace 3 hours agoparentprevThe article backs up the common sense that laws are written in order to accumulate as much power for the State as possible. \"The nine most terrifying words in the English language are: I'm from the Government, and I'm here to help.\" reply pnut 3 hours agorootparentThat's some lame brained Reagan BS. I can think of other terrifying words like \"Your child's multimillion dollar hospital bill for livesaving procedures isn't covered and you must pay\" \"Police arrested you and provided no evidence, we're going to imprison you without due process\" \"Neighbour broke into your house while you were grocery shopping, changed the locks and now claims to own the property\" reply cynicalpeace 2 hours agorootparentYou've obviously never had the government show up at your door saying these words. reply poncho_romero 2 hours agorootparentI've had lots of very helpful interactions with government employees throughout my life. As a matter of fact, there have clearly been many more unambiguously positive experiences than negative ones. Of course, we are both just playing the anecdote game here, but why should that stop anyone from asserting opinion as fact? reply cynicalpeace 2 hours agorootparentI have also had \"helpful interactions\" with the government. However, I have also had people from the government show up at my door, unannounced, and these were indeed some of the most terrifying experiences of my life. Talk to other victims of state violence under communism, fascism, imperialism or even modern western democracies and it's quite obvious that this fear is justified. One way to frame it: \"government showing up at your door\" has murdered millions (billions?) of people. This is a historical fact. Not opinion. Not anecdote. reply crazygringo 3 hours agoparentprev> By contrast some of the most fundamental laws in the nation, the Constitution's Bill of Rights, are generally just a sentence or two - and that works just fine. No, that hasn't worked fine at all. Do you realize the amount of judicial interpretation and flip-flopping that has gone on over just the first two amendments? They're like the poster children for being under-specified. reply runako 3 hours agorootparentI would say they are specified well, but the ramifications of those specifications are not politically palatable much of the time. As a current event, look at the push to reinterpret the Fourteenth Amendment provision on birthright citizenship. That provision is written quite clearly, but people do not like what it says and as a result we may as a country go through a period where we ignore it. reply crazygringo 3 hours agorootparentNo, they are not specified well. They are not specified well because they come into conflict with other rights, and it is not spelled out which rights take precedence in which circumstances. Nor does it have anything to do with \"palatability\". When the Bill of Rights was passed, they were never understood to be absolute. The first amendment was never understood to make defamation allowed, nor was the second meant to prohibit towns from preventing people from carrying their guns into taverns. All of this is extremely clear from commentary and practice at the time. Birthright citizenship is relatively unambiguous, as it is hard to imagine it in conflict with other rights. This is not the case, however, for many other rights. reply runako 2 hours agorootparent> Nor does it have anything to do with \"palatability\" Conflicts with other rights is a really good point that I missed. > Birthright citizenship is relatively unambiguous And yet it is currently a topic of debate. It's entirely possible it gets tossed in the coming years, at least until fashion changes again. reply crazygringo 2 hours agorootparent>> Birthright citizenship is relatively unambiguous > And yet it is currently a topic of debate. Its constitutionality and meaning are not under debate. It is quite clear. There's a debate about repealing it, which would require a new amendment. But there's no serious debate about the existing amendment's interpretation. reply ANewFormation 1 hour agorootparentThere is a debate on the meaning, but one that has not yet made it's way to the Supreme Court who will ultimately decide. The nuance that you run into is that legal opinion defining what 'subject to the jurisdiction of the US' means (from the 14th amendment) was made in 1898, but at that time the border was relatively open. Immigration restrictions started amping up exponentially in the 20th century, especially amidst the world wars. It seems unlikely that the court would have ruled as it did in the context of these new laws. reply crazygringo 3 hours agoprev> That analysis revealed that legal documents frequently have long definitions inserted in the middle of sentences — a feature known as “center-embedding.” Linguists have previously found that this kind of structure can make text much more difficult to understand. Can anyone provide an example sentence from a legal source with center embedding? Multiple examples, ideally? It is maddening that so much of the article is about this, but they refuse to actually show it to us. reply sbelskie 3 hours agoparent> “In the event that any payment or benefit by the Company (all such payments and benefits, including the payments and benefits under Section 3(a) hereof, being hereinafter referred to as the ‘Total Payments’), would be subject to excise tax, then the cash severance payments shall be reduced.” > The paper offers this as a more understandable alternative, with the definition separated out: > “In the event that any payment or benefit by the Company would be subject to excise tax, then the cash severance payments shall be reduced. All payments and benefits by the Company shall hereinafter be referred to as the ‘Total Payments.’ This includes the payments and benefits under Section 3(a) hereof.” https://bcs.mit.edu/news/objection-no-one-can-understand-wha... reply JumpCrisscross 2 hours agorootparentWould note that when drafting contracts, this is extremely natural to do. You notice you’re reusing a concept and so define it at first mention. Or you write something and later notice an ambiguity. Speaking as a non-lawyer who drafts things from time to time (to be reviewed by a lawyer). reply crazygringo 2 hours agorootparentIndeed, I find the original to be less ambiguous. Why does the second version refer to payments and benefits in the first sentence, and then give them a name in the second sentence? In the revised version, I'm now very unclear whether Section 3a payments apply to the first sentence or not. The original makes it crystal-clear that they do; the revised version almost suggests they don't, since they were explicitly added to sentence 2 but not sentence 1. reply gosub100 3 hours agoparentprevAny person or persons who tampers, alters, misrepresents, enhances, or otherwise knowingly $VERBs the $NOUN, $NOUNs, or other representations of $NOUN, shall be in violation pursuant to regulations §175.4 ($VERBing) and subject to penalties pursuant to §96.3 (hereinafter PENALTIES). reply veeter 4 hours agoprevI always thought it was some kind of protectionist mechanism amongst the academic trades. Can't do your own taxes if you don't speak accounting, you have to pay somebody. Can't represent yourself in court if you can't even comprehend what's being said, either. reply n144q 4 hours agoparentProbably not the best place for a programming joke, but here I am: This is exactly why I write code that nobody can understand. Can't get fired. reply bitshiftfaced 4 hours agoparentprevThat sounds plausible. You also see an abundance of center embedding in older philosophical works. In highschool I tried reading through these, and they way they write forces you to read slowly and constantly backtrack. I think you see it with more complex subject matter because you have more tangents shooting off. It means the writer needs to think ahead and do more mental work in order for the sentences to be read more easily. It was also more burdensome to edit your manuscript back then, so you had physical as well as mental friction. reply goatlover 1 hour agoparentprevOr it takes expertise to do anything sophisticated in those fields. Representing yourself is not a good idea because you probably don't have the courtroom experience arguing cases, and likely don't have an in depth understanding of the law. reply dvh 8 hours agoprevI once asked on free law advice website how do I find if certain paragraph of certain law is still in effect (i.e. was not overridden by newer law) and the lawyer just didn't understand what I want. I think he couldn't comprehend that someone would just want to point at a paragraph and asks \"is this still a law?\" As a programmer this seems like essential information to know, right? In code I can write \"asdf\" on the line and if it's still used it fails to compile or throws a runtime error but in law there is no such thing. And there is no incentive to simplify it. reply tpmoney 3 hours agoparentThe answer to this is that lawyers spend a lot of money paying for “codified” versions of the law, usually compiled by publishers like LexisNexis or Thompson-Reuters. And those companies in turn spend a lot of money on their own lawyers and developers to try to compile 51+ different formats of documenting and distributing law and law changes into a format that allows lawyers to not only know what the law is NOW but also often more pertinent, what the law WAS at the moment the issue in question occurred. From my time in that world: A) it’s amazing anyone at all is confident about anything B) it’s amazing how bad the states and feds are at getting this information out in any usable form C) it’s amazing how complex the problem domain is and how many exceptions to exceptions to the rules there are D) if you might go to jail over it, you probably want to be paying a lawyer to look it over reply webstrand 3 hours agoparentprevThe worst part is, you have to have to actually violate the law to even get standing to ask the court \"is this actually illegal\". reply JumpCrisscross 2 hours agoparentprev> he couldn't comprehend that someone would just want to point at a paragraph and asks \"is this still a law?\" What are you pointing at? If it’s in the code, it’s a law. If you’re reading a random bill from who knows when, no, there isn’t an easy answer, it would be like pulling a random git commit and asking what has been rewritten. reply crazygringo 3 hours agoparentprevIsn't that what law codification is? It assembles and organizes all the laws, removing anything that has been repealed. So if you're looking at a codified version, then you know it hasn't been repealed as of its publication. I don't know how often the codified versions get updated, and therefore how long of a lag there can be. Any lawyers here? reply showerst 2 hours agorootparentNAL but I have written legal database software, and helped to get a few bills passed. Codified laws are \"full\" printings that include new laws that were passed, and laws that were explicitly repealed. This is not the whole scope though: perhaps a court opinion invalidated some law but the legislature hasn't gotten around to removing it. Or perhaps some new interpretation keeps means a law's applicability has changed (this happens a lot with laws that are pre-internet). Sometimes there are old laws that were superseded but never repealed due to obviousness: Laws allowing redlining, penalties for witchcraft, that sort of thing. Though that's more likely at the local level than state. Just looking up the laws on the books is not _that_ helpful to knowing is a specific part applies to you. PS: Laws are generally codified yearly in the US, except the feds who do it a few times a year. States have 'session laws' that are a running collection. These are a pain to 'merge' into the laws, hence Lexis and West having big budgets and large work forces doing it. reply JumpCrisscross 2 hours agorootparent> Codified laws generally list new laws that were passed, and laws that were explicitly repealed Codes aren’t just lists, not in any state I’ve been in. And annotated codes exist to expand on the case law. reply showerst 2 hours agorootparentOops, I meant to say generally 'include', not list. I'll reword that. reply pavel_lishin 4 hours agoparentprevI'm going to throw out the worst analogy I'll probably ever make: The law is written in higher-level languages, and the courts are the compilers. It's just that most written laws probably never go through the compilation stage, until it becomes a problem for someone. reply tivert 11 hours agoprev> In this study, the researchers asked about 200 non-lawyers (native speakers of English living in the United States, who were recruited through a crowdsourcing site called Prolific), to write two types of texts. In the first task, people were told to write laws prohibiting crimes such as drunk driving, burglary, arson, and drug trafficking. In the second task, they were asked to write stories about those crimes. > ... > “When writing laws, they did a lot of center-embedding regardless of whether or not they had to edit it or write it from scratch. And in that narrative text, they did not use center-embedding in either case,” Martinez says. How can such a study explain \"why\" legal documents \"are written in an incomprehensible style?\" Seems to me it would only tell you that legal documents conventionally have a particular style that even laymen are aware of an know how to mimic. If you wanted to get at the \"why,\" I'd think you'd need to do historical analysis and talk to and test lawyers instead of laymen. reply efitz 12 hours agoprevI think that all kinds of jargon and style canons (like using latex for academic papers or the special unwritten rules for formatting movie scripts) are primarily an in-group/out-group mechanism. By communicating in the “expected” way, you are communicating that you are part of the in group. As a side note, writing for a broad audience is harder than writing stylistically. You have to not only understand all the concepts involved, but you have to be able to accurately convey those concepts in simple sentences without the use of jargon. I believe this is a rare skill. In academia, for the last few years there has been a push for Plain Language Summaries (PLS) as an accompaniment to traditional abstracts. This is a step in the right direction IMO, because many people don’t even bother reading the paper, or give up quickly, if it’s overly obtuse. Law could take a lesson from this. reply max_ 12 hours agoparentThis is my experience when studying material on cryptography. You need a cryptography library implementation for language X: - Crypto implementation for language X doesn't exist - You try to read papers defining the crypto scheme.And they use variables like K and phrases like \"oh this is from the group G\" - You spend weeks trying to understand what G and K are. - You finally implement the crypto algorithm in language X Academic cryptographers that write papers and no code: Only \"academic cryptographers\" have the right to implement crypto schemes. It's very frustrating working on cryptography schemes in obscure languages and their are no ready libraries. And reading original papers often feels like there is alot of proactive gate keeping. reply tcoff91 12 hours agorootparentMost of the time, obscure language can call out to C. Therefore you should almost certainly just use FFI and leverage a C implementation of whatever crypto algorithm you want to leverage. reply max_ 12 hours agorootparentWell, that's a possible solution. But often FFIs pollute the reason one chooses to use obscure languages. reply tcoff91 1 hour agorootparentYou shouldn't be rolling your own crypto primitives. You can completely implement the algorithm 100% 'correct' according to the research paper but introduce a side channel that could cause key extraction by an attacker. For instance, if it doesn't always take the exact same amount of time to process something, a timing attack can be used to figure out what the private key is. Always use the battle tested implementation. Power analysis, timing attacks, acoustic cryptanalysis, etc... there's many forms of side channel attacks that can be used to defeat a theoretically sound cryptosystem. reply bluGill 4 hours agorootparentprevTrue, but encryption should generally be an exception to that rule. Not that C is good for writing encryption, but because there are so many weird issues with encryption which can result in an implementation that passes all the test to still be severally broken. At least the C version has had a lot of experts looking at it and preventing those issues. reply SilasX 3 hours agorootparentprevRelated: in tptacek’s Cryptopals/Matasano security challenge, there are two kinds of problems: A) Implement this off-the-shelf cryptosystem based on the public documentation about it. B) Given this cryptosystem and these hints, find and exploit a vulnerability. Surprisingly, I found the type A problems harder — because the documentation was always missing some critical knowledge you were just supposed to know. reply ashton314 12 hours agoparentprev> like using latex for academic papers Have you, like, tried to write an academic paper without LaTeX? It’s only in the past few years that viable alternatives (Sile, Typst) have been available, and they all owe a lot of their design to LaTeX. LaTeX made quality typesetting readily available to non-typographers. It’s the opposite of gatekeeping. reply cynicalpeace 3 hours agoparentprevThis is one of the reasons why it's so important to be able to explain your specific field in simple language. Not only does it mean you understand your field, but it also means that you have developed your personality to look at things from an outsider's perspective. You have matured to be empathetic. This is also why having kids is a major step in being mature. You have to explain things from their perspective. reply openrisk 12 hours agoparentprevTeX/LaTex has revolutionized technical publishing, enabling the easy (and free) typesetting of very complex documents. Its strange to cast it as \"jargon and style canon\" and does not help the rest of your argument. reply adelpozo 12 hours agorootparentAnd you are 100% right but I do not think the point is against LaTex. But I am willing to bet money that after seeing thousands of pdfs formatted for icml/cvpr/nips, a reviewer would have an unconscious bias towards a pdf printed from msword or markdown. That's just a group thing and not that unexpected. reply spockz 12 hours agorootparentprevYes it has. And documents created with it have a distinct recognisable look which is instantly recognisable to others that also use it. This goes to the in-group/out-group argument of the GP. reply openrisk 10 hours agorootparentI agree about the recognizable look and its subtle second-order effects, but using LaTex as the typical in-group/out-group example is problematic when its use is a precondition for achieving a workable outcome. Its like saying that carpenters are using their toolkit to merely signal professionalism. In fact the same ambiguity applies to in certain cases to the original post (see my other comment). If people are forced to use a certain communication technology / form by technical or legal reasons then this is not a good example of in-group/out-group. Such examples are much better served by discretionary choices. reply ashton314 12 hours agorootparentprevWhat look are you referring to? Computer Modern font? Most journals I work with (ACM related mostly) use something other than the default. reply openrisk 10 hours agorootparentIts the forbidding look of well typeset equations and tables, not to mention the amazing tikz package :-) reply sampo 11 hours agorootparentprev> Have you, like, tried to write an academic paper without LaTeX? It's only the core hard sciences that use LaTeX. Mathematics, computer science, physics, part of statistics, part of economics, part of engineering. When you move away from this core to e.g. chemistry, biology, applied physics, then it's all MS Word. reply 0xDEAFBEAD 12 hours agoprevTax contracts by character length. The longer and more complex the contract, the greater the burden of enforcement by the state. Since long and impenetrable contracts impose a cost on the court system, they should be taxed. If no \"contract registration tax\" is paid at the time the contract is signed, the contract should be considered null and void. Contracts could still be kept secret under this scheme. Register the SHA256 hash of the contract, alongside its length in characters, in a government database. One welcome effect of such a tax: You'd eliminate, or greatly abbreviate, those long EULAs whenever you sign up for an online service. I don't think legalese is actually useful, I think it's just a bad habit. reply whatshisface 12 hours agoparentThe most expensive court cases aren't over clearly written contracts that have a clause for the dispute, they're over ambiguous ones. Contracts are written to minimize costs already, and that's why they're long. Legal cases are often much more expensive for the parties than they are for the US (you could have a dozen lawyers on each side plus staff, and one judge). The existing incentives favor minimizing the amount of time spend in a courtroom. A sign that this is working is that breach of contract doesn't show up in the supreme court very often. The big legal battles involving major corporations are usually regulatory, copyright or patent disputes wherein the parties were opposed even before the thing the case is about happened. reply 0xDEAFBEAD 11 hours agorootparent>Contracts are written to minimize costs already, and that's why they're long. See OP. There seems to be this thing called \"legalese\" that makes contracts harder to understand than necessary. In any case, if litigation risk is a major cost of a contract, then people drafting contracts will incorporate that factor alongside character length. Overall, I think you may have a point. So my updated take is: Make the per-character tax low enough that it's not a factor for B2B contracts where it's standard for lawyers on both sides to review. However, make it high enough so that it's a factor in rental contracts, employment contracts, and EULAs, where at least one party typically doesn't retain a lawyer. reply whatshisface 11 hours agorootparentLegalese is a cost-reduction technique founded on the principle of making your potential future case look as much like a previous case, even word for word, as possible. reply bluGill 4 hours agorootparentLegalese features complex grammar, anyone with good English skills and a lot of time could rewrite most laws so they are much easier to understand without losing all the cost reduction legalese provides. reply decatur 3 hours agorootparentprevSurely, your claim would only apply to contracts or court decisions, but not to laws. reply 0xDEAFBEAD 11 hours agorootparentprevHm, interesting thesis. You should post that as a toplevel comment. reply pyuser583 11 hours agoparentprevIsn’t this common in other countries, where a “notary” has to sign contracts as well? reply BartjeD 11 hours agorootparentIn most Western legal traditions the notary is used or required in a small subset of transactions. For example real estate. Normal commercial purchase contracts don't need the added insurance that offers. And no one wants to pay for it. reply bluGill 4 hours agorootparentEvery medium sized and larger company I know of has several notaries on staff who will put their stamp on anything you place in front of them. Typically company policy says you can bring your personal contracts to that person during work hours to have them notarized at no cost. I would assume normal commercial purchase contracts are notarized just because it is so easy to get someone to do it. (I've never been in this process so I wouldn't know, but that would be my guess) reply sib 2 hours agorootparent>> I would assume normal commercial purchase contracts are notarized just because it is so easy to get someone to do it. (I've never been in this process so I wouldn't know, but that would be my guess) Having been involved in the negotiation and signing of many, many commercial purchase contracts (primarily in the US), I have never seen one be notarized. This includes at three giant publicly-traded companies and at three venture-funded startups. reply sidewndr46 3 hours agorootparentprevThis is false, you don't need a notary to do real estate transactions in most of the West. Also it's sort of moot, the notary effectively just puts a stamp on it. If I write up a quit claim deed, there exists no mechanism to prove my ownership of that anyways reply BartjeD 44 minutes agorootparentIt's not false, it's an example of Italy and the Netherlands, and there are many more. The exception I dare say are the UK and US. The legal tradition in the west largely stems from the Roman Iius civile. Even the so called common law. And there too we see a role for civil officers to authenticate real estate transactions. So... your statement is false reply akoboldfrying 12 hours agoparentprevI love this! The rationale too. I wonder if people would try to get around length limits by referring to other, existing contracts or clauses. Would we wind up with npm, but for contracts? We'd want to have certain well-chosen \"primitives\" defined, at least. What a \"person\" is, etc. reply 0xDEAFBEAD 11 hours agorootparentYep, sounds great. How about a EULA that just consists of a few icons representing standard legal statements about what the corp will do with my data? reply croemer 1 hour agoprevActual paper, not the press release: https://www.pnas.org/doi/10.1073/pnas.2405564121 Preprint via SSRN: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4933363 One should generally avoid press releases as much as possible, they usually exaggerate. reply joshuaissac 1 hour agoprevSo many words and not a single example. This research also seems to be a little bit shallow. There is a lot of existing scholarship on legal language (Legal English and Legal French in Anglophone countries, Juristische Fachsprache in German, etc.). Maybe the underlying paper addresses this already, but the article makes it seem as if this is all groundbreaking. reply roughly 1 hour agoprevA friend described software engineering as wizardry, in the D&D 5E sense - you study the arcane systems that underpin the modern world, learn how they worked, and then learn how to manipulate them to affect the world in the way you want - and described lawyers as clerics: you learn how to appeal to the gods (courts, cops, the myriad powers of the state) to cause those powers to intercede on your behalf, mostly by learning the phrases and chants that impel those powers to act. (And I suppose in that taxonomy, sorcerers are the wealthy: either by birth or by some form of ritual they have gained a power that causes things in the world to happen the way they want them to.) reply rich_sasha 11 hours agoprevI convinced myself that it is a semi-conscious effort to justify their existence and fees. Everyone interacts with law at some point, it is unavoidable. And since legalese can be impenetrable, you just have to hire a lawyer. This bakes in their societal necessity and guarantees fees for lawyers if all kinds. reply bunderbunder 2 hours agoprevHere's a draft of the actual paper: https://www.researchgate.net/profile/Eric-Martinez-6/publica... reply miffy900 11 hours agoprevI think their study is flawed as it ignores what I think is the biggest reason: and that's the courts, or specifically judges. There's been centuries of legal disputes, in both civil and criminal cases, and judges have over time through their rulings have influenced what is the acceptable wording to enforce whatever it is legislators intended for a particular law. When judges render a verdict, it becomes case law, and although that itself is regarded as part of the law, where there's ambiguity, over time, legislators have been prone to abrogate laws with more exact wording. This is reflected in the tendency for judges to fall in groups that favour one way of interpretation over another, like Intentionalism, Purposivism, Textualism etc. The fact that statutory construction is something that is almost exclusively driven by judges themselves seems also pretty important when studying the language of the law and it's kind of absurd they ignore it in this study. reply DoingIsLearning 10 hours agoparent> There's been centuries of legal disputes, in both civil and criminal cases, and judges have over time through their rulings have influenced what is the acceptable wording ... When judges render a verdict, it becomes case law, and although that itself is regarded as part of the law, where there's ambiguity, over time, legislators have been prone to abrogate laws with more exact wording. Anglosphere applies Common Law but that is not the case across the rest of the world. It is very much a 'style' expectation irrespective of an attempt to precision (which it often lacks). I would even argue that Common law countries follow simpler legal language because of an inherent pragmatism when compared with Civil Law. If we look at the legal output from countries that directly or indirectly are influenced by old 'cathedra' university heritages (old French, Italian legacy or influence) it is far more convoluted IMO. reply keepamovin 12 hours agoprevThis was my favorite part: Just as “magic spells” use special rhymes and archaic terms to signal their power, the convoluted language of legalese acts to convey a sense of authority, they conclude. But also the idea of distance to create authority is interesting. In symbols through history, power lives behind the veil: in the veiled faces of monarchs, in the secrets, in their 'inaccessibility' to 'commoners'. As if these walls create something that would perhaps otherwise not exist? Interesting :) reply andrewhillman 12 hours agoprevI was reading old law school book last year and it literally said it’s written the way it is because lawyers were being paid by the word way back when. reply mdaniel 12 hours agoparentit seems you have submitted twice: https://news.ycombinator.com/item?id=42438850 reply WBrentWilliams 2 hours agoprevI'm not certain is if this is because I live in a city with a well-known law school, or if Lawrence Lessig dropped the idea into my thoughts first. The idea: The first duty of any court of law is to defend its own existence. My thesis is that this first duty colors in the rest of the legal profession, including why laws, orders, and proclamations are written in a certain way. Minor point: The article calls out in-place definitions. Useful, if unwieldly, when footnote and endnote conventions have yet to have been defined and practiced. reply JackFr 2 hours agoprevCenter embedding = lexical scoping for clauses which need to withstand adversarial interpretations. reply notatoad 1 hour agoprevevery time i have cause to go and check the text of a law in my country, i'm always a bit surprised about how understandable it actually is. there's the reputation for legalese, but, for example, this is perfectly legible to me, a person with no legal experience https://laws-lois.justice.gc.ca/eng/acts/P-21/page-2.html#h-... reply ma2rten 13 hours agoprevThe study seemed not very convincing to me, at least the way it was described in the article. To summarize: they asked crowdworkers to write a law who used legalese, but not when writing news stories about it or when explaining the law. From that the researchers concluded that people use legalese to convey authority. But what if people just imitated the writing style of existing laws, but not with the intention to make it authoritative but because that is what they understood their task to be? reply District5524 11 hours agoparentI agree. Building on 200 Prolific answers and inventing names for their \"own hypothesis\" called \"magic spell\"? Odd. Lawyers have written like entire libraries on this subject, there are specialized journals examining the legal language used (e.g. in English: https://link.springer.com/journal/11196, https://www.languageandlaw.eu/jll, but there are probably separate journals for this in every language with 10M+ speakers, like https://joginyelv.hu/) I understand this is not about the lawyers' approach to the problem, even if the author has a law degree, but a \"cognitive sciences\" department trying their hands on a",
    "originSummary": [
      "MIT cognitive scientists compare the complex language of legal documents, or \"legalese,\" to magic spells, suggesting it conveys authority through its archaic and intricate style.",
      "The study, published in the Proceedings of the National Academy of Sciences, highlights that legal documents often use complex structures like \"center-embedding,\" which contribute to their difficulty in comprehension.",
      "Despite efforts to simplify legal language since the 1970s, progress has been slow, and the study aims to promote clearer legal writing for better understanding."
    ],
    "commentSummary": [
      "An MIT study indicates that legal documents are complex due to traditional practices and the specific audience they target, primarily lawyers.",
      "Lawyers use \"legalese\" for its familiarity and precision, despite its difficulty for non-experts to comprehend, as it must align with varying case law.",
      "The study underscores the challenge of simplifying legal language while preserving its authority and legal integrity, as changes can have significant legal consequences."
    ],
    "points": 224,
    "commentCount": 265,
    "retryCount": 0,
    "time": 1734407546
  }
]
