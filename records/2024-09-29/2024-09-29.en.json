[
  {
    "id": 41684082,
    "title": "Too much efficiency makes everything worse (2022)",
    "originLink": "https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html",
    "originBody": "Too much efficiency makes everything worse: overfitting and the strong version of Goodhart's law 2022-11-06 • Jascha Sohl-Dickstein Increased efficiency can sometimes, counterintuitively, lead to worse outcomes. This is true almost everywhere. We will name this phenomenon the strong version of Goodhart's law. As one example, more efficient centralized tracking of student progress by standardized testing seems like such a good idea that well-intentioned laws mandate it. However, testing also incentivizes schools to focus more on teaching students to test well, and less on teaching broadly useful skills. As a result, it can cause overall educational outcomes to become worse. Similar examples abound, in politics, economics, health, science, and many other fields. This same counterintuitive relationship between efficiency and outcome occurs in machine learning, where it is called overfitting. Overfitting is heavily studied, somewhat theoretically understood, and has well known mitigations. This connection between the strong version of Goodhart's law in general, and overfitting in machine learning, provides a new lens for understanding bad outcomes, and new ideas for fixing them. Overfitting and Goodhart's law In machine learning (ML), overfitting is a pervasive phenomenon. We want to train an ML model to achieve some goal. We can't directly fit the model to the goal, so we instead train the model using some proxy which is similar to the goal. For instance, as an occasional computer vision researcher, my goal is sometimes to prove that my new image classification model works well. I accomplish this by measuring its accuracy, after asking it to label images (is this image a cat or a dog or a frog or a truck or a ...) from a standardized test dataset of images. I'm not allowed to train my model on the test dataset though (that would be cheating), so I instead train the model on a proxy dataset, called the training dataset. I also can't directly target prediction accuracy during training1, so I instead target a proxy objective which is only related to accuracy. So rather than training my model on the goal I care about — classification accuracy on a test dataset — I instead train it using a proxy objective on a proxy dataset. At first everything goes as we hope — the proxy improves, and since the goal is similar to the proxy, it also improves. As we continue optimizing the proxy though, we eventually exhaust the useable similarity between proxy and goal. The proxy keeps on getting better, but the goal stops improving. In machine learning we call this overfitting, but it is also an example of Goodhart's law. Goodhart's law states that, when a measure becomes a target, it ceases to be a good measure2. Goodhart proposed this in the context of monetary policy, but it applies far more broadly. In the context of overfitting in machine learning, it describes how the proxy objective we optimize ceases to be a good measure of the objective we care about. The strong version of Goodhart's law: as we become too efficient, the thing we care about grows worse If we keep on optimizing the proxy objective, even after our goal stops improving, something more worrying happens. The goal often starts getting worse, even as our proxy objective continues to improve. Not just a little bit worse either — often the goal will diverge towards infinity. This is an extremely general phenomenon in machine learning. It mostly doesn't matter what our goal and proxy are, or what model architecture we use3. If we are very efficient at optimizing a proxy, then we make the thing it is a proxy for grow worse. Though this pheonomenon is often discussed, it doesn't seem to be named4. Let's call it the strong version of Goodhart's law5. We can state it as: When a measure becomes a target, if it is effectively optimized, then the thing it is designed to measure will grow worse. Goodhart's law says that if you optimize a proxy, eventually the goal you care about will stop improving. The strong version of Goodhart's law differs in that it says that as you over-optimize, the goal you care about won't just stop improving, but will instead grow much worse than if you had done nothing at all. Goodhart's law applies well beyond economics, where it was originally proposed. Similarly, the strong version of Goodhart's law applies well beyond machine learning. I believe it can help us understand failures in economies, governments, and social systems. Increasing efficiency and overfitting are happening everywhere Increasing efficiency is permeating almost every aspect of our society. If the thing that is being made more efficient is beneficial, then the increased efficiency makes the world a better place (overall, the world seems to be becoming a better place). If the thing that is being made more efficient is socially harmful, then the consequences of greater efficiency are scary or depressing (think mass surveillance, or robotic weapons). What about the most common case though — where the thing we are making more efficient is related, but not identical, to beneficial outcomes? What happens when we get better at something which is merely correlated with outcomes we care about? In that case, we can overfit, the same as we do in machine learning. The outcomes we care about will improve for a while ... and then they will grow dramatically worse. Below are a few, possibly facile, examples applying this analogy. Goal: Educate children well Proxy: Measure student and school performance on standardized tests Strong version of Goodhart's law leads to: Schools narrowly focus on teaching students to answer questions like those on the test, at the expense of the underlying skills the test is intended to measure Goal: Rapid progress in science Proxy: Pay researchers a cash bonus for every publication Strong version of Goodhart's law leads to: Publication of incorrect or incremental results, collusion between reviewers and authors, research paper mills Goal: A well-lived life Proxy: Maximize the reward pathway in the brain Strong version of Goodhart's law leads to: Substance addiction, gambling addiction, days lost to doomscrolling Twitter Goal: Healthy population Proxy: Access to nutrient-rich food Strong version of Goodhart's law leads to: Obesity epidemic Goal: Leaders that act in the best interests of the population Proxy: Leaders that have the most support in the population Strong version of Goodhart's law leads to: Leaders whose expertise and passions center narrowly around manipulating public opinion at the expense of social outcomes Goal: An informed, thoughtful, and involved populace Proxy: The ease with which people can share and find ideas Strong version of Goodhart's law leads to: Filter bubbles, conspiracy theories, parasitic memes, escalated tribalism Goal: Distribution of labor and resources based upon the needs of society Proxy: Capitalism Strong version of Goodhart's law leads to: Massive wealth disparities (with incomes ranging from hundreds of dollars per year to hundreds of dollars per second), with more than a billion people living in poverty Goal: The owners of Paperclips Unlimited, LLC, become wealthy Proxy: Number of paperclips made by the AI-run manufacturing plant Strong version of Goodhart's law leads to: The entire solar system, including the company owners, being converted to paperclips As an exercise for the reader, you can think about how the strong version of Goodhart's law would apply to other efficiencies, like the ones in this list: telepresence and virtual reality personalized medicine gene therapy tailoring marketing messages to the individual consumers or voters who will find them most actionable predicting the outcome of elections writing code artificial intelligence reducing slack in supply chains rapidly disseminating ideas generating entertainment identifying new products people will buy raising livestock trading securities extracting fish from the ocean constructing cars Listing 1: Some additional diverse things we are getting more efficient at. For most of these, initial improvements were broadly beneficial, but getting too good at them could cause profound negative consequences. How do we mitigate the problems caused by overfitting and the strong version of Goodhart's law? If overfitting is useful as an analogy, it will be because some of the approaches that improve it in machine learning also transfer to other domains. Below, I review some of the most effective techniques from machine learning, and share some thoughts about how they might transfer. Mitigation: Better align proxy goals with desired outcomes. In machine learning this often means carefully collecting training examples which are as similar as possible to the situation at test time. Outside of machine learning, this means changing the proxies we have control over — e.g. laws, incentives, and social norms — so that they directly encourage behavior that better aligns with our goals. This is the standard approach used to (try to) engineer social systems. Mitigation: Add regularization penalties to the system. In machine learning, this is often performed by penalizing the squared magnitude of parameters, so that they stay small. Importantly, regularization doesn't need to directly target undesirable behavior. Almost anything that penalizes deviations of a model from typicality works well. Outside of machine learning, anything that penalizes complexity, or adds friction or extra cost to a system, can be viewed as regularization. Some example ideas: Add a billing mechanism to SMTP, so there's a small cost for every email. Use a progressive tax code, so that unusual success is linked to disproportionately greater cost Charge a court fee proportional to the squared (exponentiated?) number of lawsuits initiated by an organization, so that unusual use of the court system leads to unusual expenses Tax the number of bits of information stored about users Mitigation: Inject noise into the system. In machine learning, this involves adding random jitter to the inputs, parameters, and internal state of a model. The unpredictability resulting from this noise makes overfitting far more difficult. Here are some ideas for how to improve outcomes by injecting noise outside of machine learning: Stack rank all the candidates for a highly competitive school or job. Typically, offers would be made to the top-k candidates. Instead, make offers probabilistically, with probability proportional to \\(\\left(\\right.\\)[approx # top tier candidates] \\(+\\) [candidate's stack rank]\\(\\left.\\right)^{-1}\\). Benefits include: greater diversity of accepted candidates; less ridiculous resources spent by the candidates tuning their application, and by application reviewers reviewing the applications, since small changes in assessed rank only have a small effect on outcome probabilities; occasionally you will draw a longshot candidate that is more likely to fail, but also more likely to succeed in an unconventional and unusually valuable way. Randomly time quizzes and tests in a class, rather than giving them on pre-announced dates, so that students study to understand the material more, and cram (i.e., overfit) for the test less. Require securities exchanges to add random jitter to the times when they process trades, with a standard deviation of about a second. (An efficient market is great. Building a global financial system out of a chaotic nonstationary dynamical system with a characteristic timescale more than six orders of magnitude faster than human reaction time is just asking for trouble.) Randomize details of the electoral system on voting day, in order to prevent candidates from overfitting to incidental details of the current electoral system (e.g. by taking unreasonable positions that appeal to a pivotal minority). For instance randomly select between ranked choice or first past the post ballots, or randomly rescale the importance of votes from different districts. (I'm not saying all of these are good ideas. Just ... ideas.) Mitigation: Early stopping. In machine learning, it's common to monitor a third metric, besides training loss and test performance, which we call validation loss. When the validation loss starts to get worse, we stop training, even if the training loss is still improving. This is the single most effective tool we have to prevent catastrophic overfitting. Here are some ways early stopping could be applied outside of machine learning: Sharply limit the time between a call for proposals and submission date, so that proposals better reflect pre-existing readiness, and to avoid an effect where increasing resources are poured into proposal generation, rather than being used to create something useful Whenever stock volatility rises above a threshold, suspend all market activity The use of antitrust law to split companies that are preventing competition in a market Estimate the importance of a decision in $$. When the value of the time you have already spent analyzing the decision approaches that value, make a snap decision. Freeze the information that agents are allowed to use to achieve their goals. Press blackouts in the 48 hours before an election might fall under this category. One of the best understood causes of extreme overfitting is that the expressivity of the model being trained too closely matches the complexity of the proxy task. When the model is very weak, it can only make a little bit of progress on the task, and it doesn’t exhaust the similarity between the goal and the proxy. When the model is extremely strong and expressive, it can optimize the proxy objective in isolation, without inducing extreme behavior on other objectives. When the model's expressivity roughly matches the task complexity (e.g., the number of parameters is no more than a few orders of magnitude higher or lower than the number of training examples), then it can only do well on the proxy task by doing extreme things everywhere else. See Figure 1 for a demonstration of this idea on a simple task. This cause of overfitting motivates two final, diametrically opposed, methods for mitigating the strong version of Goodhart’s law. Mitigation: Restrict capabilities / capacity. In machine learning, this is often achieved by making the model so small that it's incapable of overfitting. In the broader world, we could similarly limit the capacity of organizations or agents. Examples include: Campaign finance limits Set a maximum number of people that can work in companies of a given type. e.g. allow only 10 people to work in any lobbying group Set the maximum number of parameters, or training compute, that any AI system can use. Mitigation: Increase capabilities / capacity. In machine learning, if a model is made very big, it often has enough capacity to overfit to the training data without making performance on the test data worse. In the broader world, this would correspond to developing capabilities that are so great that there is no longer any tradeoff required between performance on the goal and the proxy. Examples include: Obliterate all privacy, and make all the information about all people, governments, and other organizations available to everyone all the time, so that everyone can have perfect trust of everyone else. This could be achieved by legislating that every database be publicly accessible, and by putting cameras in every building. (to be clear — from my value system, this would be a dystopian scenario) Invest in basic research in clean energy Develop as many complex, inscrutable, and diverse market trading instruments as possible, vesting on as many timescales as possible. (In nature, more complex ecosystems are more stable. Maybe there is a parallel for markets?) Use the largest, most compute and data intensive, AI model possible in every scenario 😮6 This last mitigation of just continuing to increase capabilities works surprisingly well in machine learning. It is also a path of least resistance. Trying to fix our institutions by blindly making them better at pursuing misaligned goals is a terrible idea though. Parting thoughts The strong version of Goodhart's law underlies most of my personal fears around AI (expect a future blog post about my AI fears!). If there is one thing AI will enable, it is greater efficiency, on almost all tasks, over a very short time period. We are going to need to simultaneously deal with massive numbers of diverse unwanted side effects, just as our ability to collaborate on solutions is also disrupted. There's a lot of opportunity to research solutions to this problem. If you are a scientist looking for research ideas which are pro-social, and have the potential to create a whole new field, you should consider building formal (mathematical) bridges between results on overfitting in machine learning, and problems in economics, political science, management science, operations research, and elsewhere7. This is a goldmine waiting to be tapped. (I might actually be suggesting here that we should invent the field of psychohistory, and that overfitting phenomena will have a big role in that field.) The more our social systems break due to the strong version of Goodhart's law, the less we will be able to take the concerted rational action required to fix them. Hopefully naming, and better understanding, the phenomenon will help push in the opposite direction. Figure 1: Models often suffer from the strong version of Goodhart's law, and overfit catastrophically, when their complexity is well matched to the complexity of the proxy task. If a model is instead much more or much less capable than required, it will overfit less. Here, models are trained to map from a one-dimensional input \\(x\\) to a one-dimensional output \\(y\\). All models are trained on the same 10 datapoints, in red. The model with 4 parameters is too weak to exactly fit the datapoints, but it smoothly approximates them. The model with 10,000 parameters is strong enough to easily fit all the datapoints, and also smoothly interpolate between them. The model with 10 parameters is exactly strong enough to fit the datapoints, but it can only contort itself to do so by behaving in extreme ways away from the training data. If asked to predict \\(y\\) for a new value of \\(x\\), the 10 parameter model would perform extremely poorly. For details of this toy experiment, which uses linear random feature models, see this colab notebook. 1 Accuracy is not differentiable, which makes it impossible to target by naive gradient descent training. It is usually replaced during training by a proxy of softmax-cross-entropy loss, which is differentiable. There are blackbox training methods which can directly target accuracy, but they are inefficient and rarely used. 2 This modern phrasing is due to Marilyn Strathern. Goodhart originally phrased the observation as the more clunky any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes. 3 This glosses over a lot of variation. For instance, there is an entire subfield which studies the qualitative differences in overfitting in underparameterized, critically parameterized, and overparameterized models. Despite this variation, the core observation — that when we train on a proxy our target gets better for a while, but then grows worse — holds broadly. 4 It's not simply overfitting. Overfitting refers to the proxy becoming better than the goal, not to the goal growing worse in an absolute sense. There are other related, but not identical, concepts — for instance perverse incentives, Campbell's law, the Streisand effect, the law of unintended consequences, Jevons paradox, and the concept of negative externalities. Goodhart's curse is perhaps the closest. However, the definition of Goodhart's curse incorporates not only the phenomenon, but also a specific mechanism, and the mechanism is incorrect8. Edit 2022/11/9: Andrew Hundt suggests that similar observations that optimization isn't always desirable have been made in the social sciences, and gives specific examples of “The New Jim Code” and \"Weapons of Math Destruction\". Kiran Vodrahalli points out connections to robust optimization and the \"price of robustness.” Leo Gao points me at a recent paper which uses the descriptive term “overoptimization” for this phenomenon, which I think is good. 5 I also considered calling it the strong law of unintended consequences — it's not just that there are unexpected side effects, but that that the more effectively you accomplish your task, the more those side effects will act against your original goal. 6 Note that for suficiently strong AI, limitations on its capabilities might be determined by the laws of physics, rather than by its compute scale or training dataset size. So if you're worried about misaligned AGI, this mitigation may offer no comfort. 7 For instance, take PAC Bayes bounds from statistical learning theory, and use them to predict the optimal amount of power unions should have, in order to maximize the wealth of workers in an industry. Or, estimate the spectrum of candidate-controllable and uncontrollable variables in political contests, to predict points of political breakdown. (I'm blithely suggesting these examples as if they would be easy, and are well formed in their description. Of course, neither is true — actually doing this would require hard work and brilliance in some ratio.) 8 The definition of Goodhart's curse includes the optimizer's curse as its causal mechanism. This is where the word 'curse' comes from in its name. If an objective \\(u\\) is an imperfect proxy for a goal objective \\(v\\), the optimizer's curse explains why optimizing \\(u\\) finds an anomalously good \\(u\\), and makes the gap between \\(u\\) and \\(v\\) grow large. It doesn't explain why optimizing \\(u\\) makes \\(v\\) grow worse in an absolute sense. That is, the optimizer's curse provides motivation for why Goodhart's law occurs. It does not provide motivation for why the strong version of Goodhart's law occurs. (As I briefly discuss elsewhere in the post, one common causal mechanism for \\(v\\) growing worse is that it's expressivity is too closely matched to the complexity of the task it is performing. This is a very active research area though, and our understanding is both incomplete and actively changing.) Thank you to Asako Miyakawa and Katherine Lee for providing feedback on earlier drafts of this post. BibTeX entry for post: @misc{sohldickstein20221106, author = {Sohl-Dickstein, Jascha}, title = {{ Too much efficiency makes everything worse: overfitting and the strong version of Goodhart's law }}, howpublished = \"\\url{https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html}\", date = {2022-11-06} }",
    "commentLink": "https://news.ycombinator.com/item?id=41684082",
    "commentBody": "Too much efficiency makes everything worse (2022) (sohl-dickstein.github.io)701 points by feyman_r 17 hours agohidepastfavorite295 comments refibrillator 13 hours agoI recognize the author Jascha as an incredibly brilliant ML researcher, formerly at Google Brain and now at Anthropic. Among his notable accomplishments, he and coauthors mathematically characterized the propagation of signals through deep neural networks via techniques from physics and statistics (mean field and free probability theory). Leading to arguably some of the most profound yet under-appreciated theoretical and experimental results in ML in the past decade. For example see “dynamical isometry” [1] and the evolution of those ideas which were instrumental in achieving convergence in very deep transformer models [2]. After reading this post and the examples given, in my eyes there is no question that this guy has an extraordinary intuition for optimization, spanning beyond the boundaries of ML and across the fabric of modern society. We ought to recognize his technical background and raise this discussion above quibbles about semantics and definitions. Let’s address the heart of his message, the very human and empathetic call to action that stands in the shadow of rapid technological progress: > If you are a scientist looking for research ideas which are pro-social, and have the potential to create a whole new field, you should consider building formal (mathematical) bridges between results on overfitting in machine learning, and problems in economics, political science, management science, operations research, and elsewhere. [1] Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks http://proceedings.mlr.press/v80/xiao18a/xiao18a.pdf [2] ReZero is All You Need: Fast Convergence at Large Depth https://arxiv.org/pdf/2003.04887 reply tablatom 11 hours agoparentInteresting timing for me! Just a couple of days ago I discovered the work of biologist Olivier Hamant who has been raising exactly this issue. His main thesis is that very high performance (which he defines as efficacy towards a known goal plus efficiency) and very high robustness (the ability to withstand large fluctuations in the system) are physically incompatible. Examples abound in nature. Contrary to common perception evolution does not optimise for high performance but high robustness. Giving priority to performance may have made sense in a world of abundant resources, but we are now facing a very different period where instability is the norm. We must (and will be forced to) backtrack on performance in order to become robust. It’s the freshest and most interesting take on the poly-crisis that I’ve seen in a long time. https://books.google.co.uk/books/about/Tracts_N_50_Antidote_... reply vlovich123 7 hours agorootparentI don’t think it’s smart to proactively back track without being very careful. One thing that’s needed is for corporate death to be allowed to occur. Right now the downsides of risky behavior is bailed out for large enough risk. Then the companies that fail aren’t robust and the ones that don’t are but bailouts let non robust companies keep going. Otherwise “robustness” is a property without a measure which means that you’ll get robustness theater where actions are being taken in the name of being robust but it’s not actually making a difference at best and could be making things worse. As for society itself being robust, it’s a much harder property. Being robust is nice but no one actually wants to live in a metered society where there’s insufficient resources - they’d generally rather kill for resources greedily and let others fail without helping them. That’s why socialized healthcare struggles - while it guarantees a minimum of care for everybody, the care provided has longer wait times and most people are not willing to wait their turn. reply wongarsu 6 hours agorootparentIn a free market economy we shouldn't demand robustness, we should create a system that promotes and rewards robustness. A strict commitment against bail-outs would certainly be part of that. Companies (and private people) can decide to lower their risk exposure (at the cost of efficiency/profit) or take out insurance against risks. And if they go the insurance route they have to assess how likely their insurance is to go insolvent at the next insurance event. That's how you reward those that are actually resilient. Healthcare is more complicated. It can never work as an efficient free market since nobody goes comparison shopping for the hospital with the best value-for-money when they have a car crash. That's why socialized healthcare achieves much better results per dollar spent. But it's often hamstrung by attempts at efficiency. I think a better societal example is disaster relief: helping people back up after they have been hit by a hurricane is the humane thing to do, but how much is that encouraging people to settle in high risk areas with insufficient precautions? reply CuriouslyC 5 hours agorootparentThat solution is never going to work when black swan events occur on the order of every 5-10 years and executive vision is focused on the next quarter with little concern paid to anything outside the next 2-3 years. Nobody is going to want to give up short term performance to mitigate risks that probably won't manifest until after they've left for a better job. reply kortilla 3 hours agorootparentThat solution is how it already works for the vast majority of companies in the US. “Too big to fail” is a meme that only applied to a tiny handful of companies during the financial crisis. Take a look at SVB for how fast a stalwart huge bank can implode with zero fucks given by the government. reply collingreen 2 hours agorootparentBy \"zero fucks given by the government\" do you mean the government got involved, effectively bought the bank, and took responsibility for 100% of deposits (most of which were the balances of startups, ie venture capital investments)? reply jppope 2 hours agorootparentprevPretty sure Boeing should have failed 3 times by my count. reply WillPostForFood 2 hours agorootparentprevBusinesses won't plan long term or for black swan events if they don't have to; it is rational not to if they know a bailout is coming. reply wongarsu 4 hours agorootparentprev5-10 years is a perfectly normal investment horizon, and in the end investors are the ones electing the CEO and setting goals and rewards for the executive. If betting on the long term is a winning strategy companies absolutely have the means to do that. But right now it usually isn't. reply bumby 5 hours agorootparentprev>private people) can decide to lower their risk exposure I think the complexities of modern societies make it too difficult to measure this risk adequately. We just don’t have the bandwidth to think about the second-and-third order effects for every social/financial interaction we encounter. And people are generally very poor at estimating high-consequence/low-probability events. This means people will often take very outsized risks without realizing it; when bad things happen it creates an unstable society. I don’t think we’ve evolved to personally manage all the c risks in a large complex society and farming those risks out to institutions seems to be the current way most societies have decided to mitigate those risks. reply Zach_the_Lizard 2 hours agorootparent>...farming those risks out to institutions seems to be the current way most societies have decided to mitigate those risks Unfortunately, those institutions --be they governments, insurance companies, UL Labs, banks, venture capitalists, etc.--also need to be vetted. Even when staffed with impeccably well credentialed and otherwise highly capable people, their conclusions may be drawn using a different risk framework than your own. The risk that they mitigate may even be the risk that you won't vote for them, give them money, etc. There is also the risk of having too little risk, a catastrophe no worse than too much risk. The balloon may not pop, but it may never be filled. reply bumby 1 hour agorootparentI don’t think anyone reasonable is advocating believing institutions on blind faith (possibly with the exception of religious institutions). They need to be transparent and also strive to reflect the values (risk and otherwise) of their constituents. reply whatshisface 5 hours agorootparentprevI don't see why people can't comparisons shop for hospitals before they get in a car crash. Unless I am literally unconscious I would go to the hospital in my area that I trust the most, and I have plans for which urgent care, clinics and hospitals I would take someone else to if they needed a driver. In fact I think a pretty small fraction of patients arrive at the ER unconscious. reply RandomLensman 5 hours agorootparentHow would develop the \"trust\" and why would it be correct? How would you diagnose yourself or others before selecting a hospital if those have different trust for different things? How do you balance urgency vs different trust levels if the hospitals are not all the same distance? reply mikeyouse 5 hours agorootparentIt also ignores that huge swaths of the country have no choice at all and the only hospital within a hundred miles is only viable due to huge Federal subsidies. We’ve been helping a close family member navigate that scenario and sure, he could vote with his dollars but it would involve a three hour drive to a neighboring state for an 80-yr old. I’d rather just enforce minimum quality standards on everyone like most other civilized countries rather then relying on “the free market” which so far in my experience has just led to PE goliaths swallowing entire health systems to focus on bill collection and union busting. reply nradov 3 hours agorootparentCMS does enforce minimum clinical quality standards on hospitals (at least those that accept Medicare). The problems in areas without meaningful competition tend to be more around shortages of qualified practitioners, high prices, and abusive billing policies. reply whatshisface 4 hours agorootparentprevI can't imagine anyone would object to minimum quality standards for anything receiving federal subsidies. reply collingreen 2 hours agorootparentedit: didn't realize I was feeding a troll. Feel free to ignore. I expect the objections are in how quality is measured and enforced. It reminds me of education system in the US - most people (project 2025 aside) think it's good to have a public education system; having a pipeline of skilled workers makes it easier to build an economy filled with a diverse set of businesses. However, the attacks start to fly when there is disagreement about who should be allowed to teach, how they should be measured, and how they should be paid. reply whatshisface 1 hour agorootparentSettling everyone's differences about rural medical subsidies might be a good stepping stone to an NHS. reply whatshisface 4 hours agorootparentprevYou could ask the same questions about grocery shopping or buying a PC. reply RandomLensman 4 hours agorootparentA mis-assessment there might be far less consequential and those also do not require a medical diagnosis before making a decision where to go. reply whatshisface 2 hours agorootparentI've never needed a medical diagnosis to decide between calling my GP and going to an urgent care. It's just a bit surreal to hear everyone else say my ordinary survival skills are impossible and more than could be asked of anybody! reply RandomLensman 1 hour agorootparentYou said you have a hospital selected you trust (by whatever your metric is). Hospitals tend not be all equal for all things, so trust should probably be differential - how do you assess yourself as a patient then to decide on where to go? And if you do not differentiate the trust any further than to a single hospital regardless of what the issue is: why is that sufficient? I think it is fine to have some preferences for a hospital, but not sure how much benefit that confers outside of some narrow situations. reply whatshisface 1 hour agorootparentSinply replace hospital with any other service, take your own answers and then translate it back. In economic terms I researched medical facilities until the expected marginal benefit of the information fell below the marginal cost. There are a lot of reasons to reform the US healthcare system but you can't argue that consumer choice is too complex to be realized. reply RandomLensman 1 hour agorootparentI don't know the US system well enough to say much about it. reply unethical_ban 2 hours agorootparentprevJust to be clear: You're asserting that the average citizen * has the same capacity to research an unknown number of medical procedures and the doctors performing them as they do researching onion prices or CPU specs * faces a similar scale of consequences when failing to properly analyze medical procedures as they do when they fail to properly price-compare onions or PC services * has the same freedom of choice to \"purchase their preference\" in an emergency, life-threatening situation as they have when shopping for PCs or groceries reply whatshisface 2 hours agorootparentDietary and metabolic problems are an epidemic that outweights malpractice in terms of quality and quantity of life by more than two orders of magnitude - so yes, I am saying people face \"shopping problems\" of life or death magnitude every day. reply nradov 4 hours agorootparentprevPatients have time to shop for most healthcare services. Only a small fraction of healthcare spending is for emergencies. The highest cost stuff is mostly elective procedures. If you need a colonoscopy or hip replacement then you have time to shop around. Socialized healthcare has its advantages and is probably more cost effective on average. But we also see affluent Canadians coming to the USA as medical tourists and paying cash for MRI scans in order to avoid the queues back home. reply yuliyp 1 hour agorootparentprevThe problem with this is principal-agent problems. The owners of the business don't want it to fail. The people working there want to make money. They generally live their life and enjoy what money they make before the chickens come home to roost. It can be hard for the owners to realize the business is fragile before that fragility becomes apparent. In the mean time the people running the business made a bunch of money, potentially jumped to other jobs or retired or died. And the owners could have sold when the business was propped up by unknown fragility. Human lives are too short for these kinds of feedback loops to be all that effective. reply WalterBright 6 hours agorootparentprevThe usual cycle for business in a free market is it appears young and fresh, lacking any parasites. It grows rapidly, displacing existing mature businesses. Then, it accumulates bureaucracy and parasites, becoming less and less efficient, strangled by bloat and inability to adapt, and slides into bankruptcy, replaced by the next generation of new businesses. The remains of the business are then reallocated to the next generation of businesses. (This is quite unlike the common view that businesses inevitably grow to take over the world.) I.e. business is much like a living organism. Problems set in when the government bails out failing businesses. Even worse are government \"businesses\". They are not allowed to fail, and the inefficiencies, parasites, corruption, grow and grow. When can you remember a government agency being abolished? Eventually, the government will collapse. reply normie3000 6 hours agorootparent> When can you remember a government agency being abolished? In the UK the last I specifically remember is DFID, which shut down in 2020. reply vlovich123 3 hours agorootparentprev> Even worse are government \"businesses\". They are not allowed to fail, and the inefficiencies, parasites, corruption, grow and grow. When can you remember a government agency being abolished? In Commonwealth countries and the UK itself there are plenty of businesses called “crown corporations” which are owned by the government. Change in attitudes towards more liberalism led governments to deregulation and selling off bits and pieces or the entire corporation. Here are some Canadian examples: https://www.cbc.ca/news/politics/canada-post-it-innovapost-s... https://policyoptions.irpp.org/magazines/march-2024/mulroney... America is a relatively young country and has very peculiar philosophies sometimes not found in the rest of the world. Be very careful extrapolating an American perspective abroad or as capturing some elemental truth of the universe. reply fireflash38 6 hours agorootparentprevOne of the primary reasons people bail out companies are the knock-on effects. People losing jobs, etc. If society itself is robust enough to cover for people in those situations, we could let companies fail far more. reply karmonhardan 1 hour agorootparentPeople los jobs anyway, from the knock-on effects of the bail out. The bail out is more about controlling who loses jobs. reply ghaff 6 hours agorootparentprevThere's a sentiment on here often that, even if a company has been essentially blown up by technology or market change, they should have transformed themselves to adapt. But that implies they probably needed to rototill their workforce in any case. At some point, you're probably better off just declaring bankruptcy and starting fresh or letting someone else do so. reply nradov 4 hours agorootparentprevTrue, but for some companies there are also national security concerns. If we lose the domestic supply chain for certain items then that limits our freedom of action and leaves us vulnerable to supply disruptions. reply AdrianB1 34 minutes agorootparentIf you depend on a single company to supply certain items, you have a big problem already. Pouring money in that company will mostly help the executive bonuses, not the national security. reply RandomLensman 5 hours agorootparentprevSocialized healthcare seems to kind of work in many developed economies - where does it struggle and by what metrics regarding the health outcomes? reply AdrianB1 32 minutes agorootparentI would love to see a good proof that it works, all the discussions, rumors and anecdotal evidence suggest the contrary. I am open to learn the truth, with hard numbers. Very long waiting times are the first thing that comes to mind regarding such failures, with UK and Canada at the top spot. It is not uncommon to die waiting for a consultation to be diagnosed in 1-2 years. reply Terr_ 8 hours agorootparentprevThat reminds me of a study on \"lazy\" ants as a reserve/replacement labor force. [0] Maximizing efficiency in the short-term is not the same as maximizing survival in the long term. [0] https://www.sciencedaily.com/releases/2017/09/170908205356.h... reply bmsan 2 hours agorootparentprevUnedited bullet points on a related topic (same prefixes are linear, different prefixes connect to the others, but I haven't decided where yet): >capital concentration increases >expectations for what capital owners can do with money increases >expectations exceed available capital >investment returns must increase (race to the top) >cooperation among capital owners must increase to get better returns >capital owning group begins to self-select and become less diverse, if this wasn't already caused by the background/personality required to accrue capital >investment theory converges on a handful of \"winning\" ventures >because this is where capital is flowing, workers are forced to divert to these ventures >competition increases, hyperspecialization increases >expertise in and sophistication of other areas begins to decline, causing quality decline, garnering less investment; feedback loop ----- *debt cannibalizes future productivity ----- )diversity in capital ownership and management increases likelihood of diversity in investment venture target )increased competition, increased likelihood that ventures will cover needs, decreased likelihood of overweighting in one area/overproduction )solution: capital redistribution. Perhaps globally reply jfim 9 hours agorootparentprevWe've seen this during the COVID pandemic supply chain disruptions as well, where just in time supply chain management doesn't work as expected when operating in an abnormal environment. reply soulofmischief 8 hours agorootparentI'd always thought this conclusion was just a given. Highly optimized systems take full advantage of their environment and rely on a high degree of predictability in order to avoid redundant operations. These systems minimize the free energy in the system, and so very little free energy is available to counteract new forces introduced to the environment which act on the system. You'll find parallels in countless domains, since the very basis for learning and stabilization of a system revolves around becoming more or less sensitive to a given stimulus. Examples could be attention, supply chain economics, institutions, etc. reply jimkleiber 6 hours agorootparentprevI was gonna come here to say that, especially how there was a shortage on toilet paper. I remember reading it was becuase factories were so efficient that when people started using the toilet at home instead of the office, it was hard to switch the factories from making commercial to residential toilet paper. I think someone even made the pun of paper-thin margins. reply naasking 2 hours agorootparentprev> Contrary to common perception evolution does not optimise for high performance but high robustness. It does both, eg. if the environment is stable then fitness is correlated with efficiency, if the environment is unstable then it's robustness. reply rglullis 9 hours agorootparentprev> We must (and will be forced to) backtrack on performance in order to become robust. This is something that Nassim Taleb and the people working on https://realworldrisk.com/ have been saying for decades already. reply JeremyNT 2 hours agorootparentprevThe \"slack\" is important in an unstable environment because it allows for reallocation of resources without causing a system to fail. It's tempting to minimize waste, but excess capacity is required to adapt if things are evolving quickly. reply __MatrixMan__ 4 hours agorootparentprevI don't know that the poly-crisis is bit this does feel timely. I know I'd tolerate a digital experience of far lower fidelity (fewer pixels, for instance, or even giving up GUIs altogether) if I could get it in a way that doesn't break every time some far away person farts near a cloud console: A trade of performance for robustness. reply 3abiton 5 hours agorootparentprevThe acceleration of knowledge is producing so much content, real gems are passing by unnoticed. Thanks for pitching in! reply bumby 5 hours agorootparentprevThere are also a lot of engineering examples where the goal is to optimize for reliability. I think the most common domain is marine platforms where it is prohibitively expensive to induct and repair (you have to send a team out by helicopter, for example). reply nradov 4 hours agorootparentAnd yet most large merchant ships are designed with a single engine, propeller, and rudder to optimize for cost instead of reliability. We have seen some spectacular failures of that approach recently, although it probably still makes sense in aggregate. A major mechanical casualty beyond what the crew can repair usually means a tow to a shipyard. Flying more engineers in by helicopter would seldom help, and often isn't feasible. reply bumby 3 hours agorootparentThis is true, but different than the maritime platforms I was talking about. The ones that tend to focus on reliability-centered optimization are platforms used for drilling, not transport. Even then, you will see instances where they decide to optimize for cost/schedule (eg Deepwater Horizon). IMO, that is a company-cultural issue. Btw- reliability optimization doesn’t necessarily mean it is optimized to not fail. They are optimized to fail within some predetermined risk level. What that risk level should be is an entirely different discussion. reply maxerickson 7 hours agorootparentprevGiving priority to performance may have made sense in a world of abundant resources, but we are now facing a very different period where instability is the norm. Why do you think this? reply nradov 4 hours agorootparentprevTo a first approximation, humans have never lived in a world of abundant resources. That has mostly only applied to a minority of affluent people in developed countries. But resource abundance continues to improve on average worldwide. reply bbor 5 hours agorootparentprevHis main thesis is that very high performance (which he defines as efficacy towards a known goal plus efficiency) and very high robustness (the ability to withstand large fluctuations in the system) are physically incompatible. …what about humans? We’re far more efficacious than any other animal, and far more capable of behavioral adaptation. Plus, isn’t “physically impossible” a computer science argument, not a biological one? Unless we’re using the OG “physis”==“nature”, I guess reply thomasahle 11 hours agoparentprevI love the idea of ReZero, basically using a trainable parameter, alpha, in residual layers like this: Deep Networkxi+1 = F(xi) Residual Networkxi+1 = xi + F(xi) Deep Network + Normxi+1 = Norm(F(xi)) Residual Network + Pre-Normxi+1 = xi + F(Norm(xi)) Residual Network + Post-Normxi+1 = Norm(xi + F(xi)) ReZeroxi+1 = xi + αi F(xi) However, I haven't actually seen this used in practice. The papers we have on Gemma and Llama all still seem to be using layer norms. Am I missing something? reply immibis 5 hours agorootparentIsn't this already part of F? reply aoeusnth1 3 hours agorootparentYour sound system has a volume dial to turn up and down the gain of the track even though you could get the same effect by re-recording the track at a higher volume; isn’t that curious? reply thomasahle 3 hours agorootparentprevI should add that alpha is initialized to 0. reply lubujackson 12 hours agoparentprevThe exciting thing about this idea is if you can correlate, say, economics with the works of ML, that means a computer program which you can run, revise and alter can directly give you measurable data about these complex system interactions that mostly have existed as a platonic idea since reality is too nuanced and multiple to validate concepts formally. With the idea that there is some subset of logic that sits below economics that is provable and exact. That is a powerful idea worth pursuing! reply nerdponx 11 hours agorootparentThis idea has been pursued several times in the past, and it always ends up producing lots of interesting academic results and no practical conclusions. It's certainly an interesting perspective on the development of complex systems. The idea that an economy can be somehow overfitted to its own incentives and constraints I don't think is entirely new, cf the Beer Game. But as a general concept, it's certainly not something that usually finds its way into policy discussion, beyond some very specific talk about reshoring of certain critical industries. However, I think the most important benefit of this perspective is going to be providing yet another counterargument against the Austrian economics death cult. reply ahartmetz 10 hours agorootparentIt seems to me that something similar to Adam Smith happened to the Austrians: their ideas have been cherry-picked. According to German Wikipedia, their main things were / are a focus on individual preferences, marginal utility, and a rejection of mathematical modeling(!) There was also something about lower state expenditures (...taxes...) giving better results for the people - that's the one that seems to be very popular with rich people for some reason. Go figure. reply jampekka 9 hours agorootparentAustrian economics also rejects empirical assesment of its claims. Instead, universal thruths are derived \"logically\" (formal logic banned though) from \"obviously true\" axioms using a method called praxeology. It seems a lot like Scientology: the more you learn about it, the more bizarre it gets. And of course it's used to extract a lot of money for few benefactors. reply naasking 59 minutes agorootparentUnlike scientology, Austrian economics made some important contributions to mainstream economic understanding. reply mrfox321 5 hours agoparentprevMore importantly, he invented diffusion models: http://proceedings.mlr.press/v37/sohl-dickstein15.pdf reply salawat 13 hours agoparentprev>> If you are a scientist looking for research ideas which are pro-social, and have the potential to create a whole new field, you should consider building formal (mathematical) bridges between results on overfitting in machine learning, and problems in economics, political science, management science, operations research, and elsewhere. Translation to laymen: ML is being analogized to the mathematical structure of signaling between entities and institutions in society. Mathematician proposes problem that plagues one (overfitting in ML, the phenomena by which a neural network's ability to generalize is negatively impacted by overtraining so the functions it can emulate are tightly coupled to the training data), must plague the other. In short, there must be a breakdown point at which overdevelopment of societal systems or signaling between them makes things simply worse. I personally think all one need do is look at what would happen if every system were perfectly complied with to see we may already be well beyond that breakpoint in several industrial verticals. reply LarsDu88 13 hours agoparentprevAdding to my reading list! reply whizzter 2 hours agoprevThis has become a societal problem in Sweden during the past 20 or so years. 1: Healthcare efficiency is measured by \"completed tasks\" by primary care doctors, the apparatus is optimized for them handling simple cases and they thus often do some superficial checking and either send one home with some statistically correct medicine (aspirin/antibiotics) or punt away cases to a specialized doctor if it appears to be something more complicated. The problem is that since there's now fewer of them (efficient) they've more or less assembly line workers and have totally lost the personal \"touch\" with patients that would give them an indication on when something is wrong. Thus cancers,etc are very often diagnosed too late so even if specialized cancer care is better, it's often too late to do anything anyhow. 2: The railway system was privatized, considering the amount of cargo shipped it's probably been a huge success but the system is plagued by delays due to little gaps in the system to allow late trains to speed up or to even do more than basic maintenance (leading to bigger issues). reply EasyMark 38 minutes agoparentI wish these were the biggest problems facing US train and healthcare industries. reply t_mann 12 hours agoprevThe argument rides on the well-known Goodhart's law (when a measure becomes a target, it ceases to be a good measure). However, it only puts it down to measurement problems, as in, we can't measure the things we really care about, so we optimize some proxies. That, in my view, is a far too reductionist view of the problem. The problem isn't just about measurement, it's about human behavior. Unlike particles, humans will actively seek to exploit any control system you've set up. This problem goes much deeper than just not being able to measure \"peace, love, puppies\" well. There's a similar adage called Campbell's law [0] that I think captures this better than the classic formulation of Goodhart's law: The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor. The mitigants proposed (regularization, early stopping) address this indirectly at best and at worst may introduce new quirks that can be exploited through undesired behavior. [0] https://en.wikipedia.org/wiki/Campbell%27s_law reply EasyMark 36 minutes agoparentI think a big portion of that is humans don’t like to be viewed only as numbers and will rebel and manipulate any system you try to put the thumbscrews to them with. So the quote to mean rings golden and isn’t fallible to much of an extent reply Edman274 1 hour agoparentprev> Unlike particles, humans will actively seek to exploit any control system you've set up. Well, agents will. If you created a genetic algorithm for an AI agent whose reward function was the amount of dead cobras it got from Delhi, I feel like you'd quickly find that the best performing agent was the one that started breeding cobras. In the human case and in the AI case the reward function has been hacked. In the AI case we decide that the reward function wasn't designed well, but in the human case we decide that the agents are sneaky petes who have a low moral character and \"exploited\" the system. reply layer8 6 hours agoparentprev> Unlike particles, humans will actively seek to exploit any control system you've set up. But that’s only possible because the control system doesn’t exactly (and only) control what we want it to control. The control system is only an imperfect proxy for what we really want, in a very similar way as the measure in Goodhart’s law. Another variation of that is the law of unintended consequences [0]. There is probably a generalized computational or complex-systems version of it that we haven’t discovered yet. [0] https://www.sas.upenn.edu/~haroldfs/540/handouts/french/unin... reply etiam 4 hours agorootparentDisagree. Even if it was striving to regulate exactly the right thing in the first place, most of these issues occur for systems where no single actor could be expected to exert complete control and could well be vulnerable anyway. Start working with a nice, clean, fully relevant system, end up modelling that plus the whole range of adversarial perturbations from agents of pretty high complexity. reply layer8 3 hours agorootparentI don’t exactly see how this is different from what I was describing. reply netcan 11 hours agoparentprevThis is true, these \"laws\" are approximations and imperfect reductions. Which one is useful or descriptive will depend on the specific example. Optimizing ML VS Optimizing a social media algorithm VS using standardized testing to optimize education systems. There is no perfect abstraction that applies to these different scenarios precisely. We don't need that precision. We just need the subsequent intuition about where these things will go wrong. reply onethought 8 hours agorootparentI missed the citation on his education point. Has someone proved that “teaching to the test” leads to lower educational outcomes than not having tests? reply schrectacular 1 hour agorootparentNot a citation, but I believe it's a mediocritizing measure. For some teachers and some students, teaching to the test is probably better. I suspect more heavily concentrated in the bottom 50% of each group. For a subset of great teachers and great students, it's a detriment. reply netcan 4 hours agorootparentprevIDK. I don't think we can actually have a discussion about education where all statements are supported by indisputable evidence. There do happen to be citations for this question but I doubt any really clears an \"indisputable evidence\" standard. That's the nature of the field. Even if the whole discussion was evidence based and dotted with citations, we'd still be working with a lot of intuition and speculation. reply ismailmaj 7 hours agorootparentprevI saw some professors share the least about their tests to make sure we truly understand the material, sounds to me like a real-life usage of a train/test split. It’s not far fetched to think they employed this technique because teaching to the test didn’t work well by itself. reply thomassmith65 1 hour agoprevI noticed an example of this rule at my local hardware superstore. Around a decade ago, the store installed anti-theft cages. At first they only kept high-dollar items in the cages. It was a bit of an inconvenience, but not so bad. If a customer is dropping $200+ on some fancy power tool, he or she likely doesn't mind waiting five minutes. But a few years later, there was a change - almost certainly a 'data-driven' change: suddenly there was no discernible logic to which items they caged and which they left uncaged. Now a $500 diagnostics tool is as likely to sit open on a shelf, as a $5 light bulb to be kept under lock and key. Presumably the change is a result of sorting a database by 'shrinkage' - they lock up the items that cumulatively lose the hardware store the most money, due to theft. But the result is (a) the store atmosphere reads as \"so profit-driven they don't trust the customers not to steal a box of toothpicks\" and (b) it's often not worth it for customers to shop there due to the waiting around for an attendant to unlock the cage. I doubt the optimization helped their bottom-line, even if it has prevented the theft of some $3 bars of soap. reply tshaddox 1 hour agoparentIt’s much more convenient to buy from Amazon than to try to find someone to unlock a glass case at the pharmacy. Especially since any pharmacy with glass cases for basic items will also be understaffed. reply crazygringo 1 hour agoparentprev> they lock up the items that cumulatively lose the hardware store the most money, due to theft. > I doubt the optimization helped their bottom-line These seem to be in direct contradiction, unless you really think people have stopped going there because of it, to such an extent it outweighs the thefts. Especially when, if they stop going there, the competing local hardware superstore is probably doing the exact same thing. And remember, retail margins aren't usually huge -- for every item stolen, how many more do they need to sell to recoup the loss? Even if some people go to Amazon instead, it can still be worth it to avoid the theft. It's much more likely that it has indeed had the biggest impact on reducing theft, and that your \"discernable logic\" simply doesn't have experience with these things -- that theft often isn't about item value, but rather about reliable resellability. A single expensive niche power tool takes a long time to resell; laundry detergent and razor blades can be unloaded in quantity the same day. People go through detergent and razors a lot faster than light bulbs. I understand you dislike the inconvenience. But I really think you should be blaming the thieves or the factors behind theft, not the stores. reply thomassmith65 36 minutes agorootparentI doubt the optimization helped their bottom-line; I do not know it. It is possible for a business to make money without customers actually liking the company: hey, it works for some of the FA*NG companies! That said, there is something that feels 'off' about management obsessing over shrinkage to the point that the shopping experience begins to suck. It's not a truckstop or a drug store in a bad area... it's a hardware superstore. With too much data, some manager can fixate on $3 screwdriver thievery and not think about the bigger picture: like shoppers finding the store to be a pain in the ass, and therefore no longer an attractive place to buy expensive riding-lawnmowers and floor jacks. A store can quantify lower sales figures, but it may not be obvious that the lower sales were related to the choice of 'caged vs uncaged' inventory. But again, I do not know. I only suspect. reply netcan 6 hours agoprevAnother example of this approximate law is in exercise physiology. To a normal person, there are a lot of good proxy indicators of fitness. You could train sprinting. You could hop up and down. Squat. Clean and jerk.. etc. Running faster,hopping higher, squatting heavier... all indicators of increasing fitness... and success of your fitness training. Two points: 1 - The more general your training methodology, the more meaningful the indicators. Ie, if your fitness measure is \"can I push a car uphill,\" and your training method is sprinting and swimming... pushing a heavier car is a really strong indicator of success. If your training method is \"practice pushing a car,\" then an equivalent improvement does not indicate equivalent improvement in fitness. 2- As an athlete (say clean and jerk) becomes more specialized... improvements in performance become less indicative of general fitness. Going from zero to \"recreational weighlifter\" involves getting generally stronger and musclier. Going from college to olympic level... that typically involves highly specialized fitness attributes that don't cross into other endeavors. Another metaphor might be \"base vs peak\" fitness, from sports. Accidentaly training for (unsustainable) peak performance is another over-optimization pitfall. It can happen when someone blindly follows \"line go up.\" Illusary optimizations are actually just trapping you in a local maxima. I think there are a lot of analogies here to biology, but also ML optimization and social phenomenon. reply naasking 48 minutes agoparentI think that's more an indication that \"general fitness\" is not a rigorous metric. It's fine as a vague notion of \"physical ability\" up to a point, and past that it loses meaning because improvements in ability are task-specific and no longer translate to other tasks. reply bob1029 6 hours agoparentprevClean & jerk is one of those movements that I would almost consider \"complete\". Especially if you are going to mix in variants of the squat. Not sure these are the best example. I don't know of anyone who can C&J more than their body weight for multiple repetitions who isn't also an absolute terminator at most other meaningful aspects of human fitness. Human body is one machine. Hormonal responses are global. Endurance/strength is a spectrum but the whole body goes along for the ride. reply netcan 4 hours agorootparentPerhaps. And you could probably test this but I would gamble that the principle still applies. IE, these weightlifters are probably also very capable (eg) shotputters because of all that weightlifting. But also... their shotput, sprinting and other tangential abilities probably peak at some point. From then on, they are mostly just getting stronger at clean and jerk. > Hormonal responses are global. Endurance/strength is a spectrum but the whole body goes along for the ride. This is true, and that is why most exercise is a general good for most people, and has similar physiological effects. However, at some point \"specialization\" (term of art), kicks in. At that point, a bigger clean and jerk no longer equates to a longer shot put. Fwiw... This isn't a point about exercise or how to exercise. Most people aren't that specialized or advanced in a sport and the ones who are have coaches. My point is that the phenomenon speculated to be broad in this post applies (I suspect) to physiology. Probably quite broadly. It's just easy to think about it in terms of sports because \"training & optimization\" directly apply. reply travisjungroth 2 hours agorootparentI agree with your overall point, but also the person you’re replying to. I think that clean and jerk may be the example that least supports your argument. If I had to optimize an athlete for one movement and then test them on 20, C&J would probably be my pick. Bench press would be lower down the list. This isn’t just nit picking exercises here. There are some measures to optimize for that lead to broader performance. They tend to be more complex and test all components of the system. reply orcim 3 hours agoprevIt's an effect that exists, but the examples aren't accurate. An overemphasis on grades isn't from wanting to educate the population; obesity isn't from prioritizing nutrient-rich food; and increased inequality isn't from wanting to distribute resources based on the needs of society. Living a well-lived life through culture, cooking, or exercise doesn't make you more susceptible to sensationalism, addiction, or gambling. It's a lack of stimulus that makes you reach for those things. You can argue that academia enables rankings, industrial food production enables producing empty calories, and economic development enables greater inequality. But that isn't causation. It also isn't a side effect when significant resources specifically go into promoting education as a private matter best used to educate the elite, that businesses aren't responsible for the externalities they cause, and that resources should be privately controlled. In many ways, it is far easier to have more public education, heavily tax substances like sugar, and redistribute wealth than it is to do anything else. That just isn't the goal. It used to be hard to get a good education, good food, and a good standard of living. And it still is. For the same reasons. reply bilsbie 5 hours agoprevThis is why I don’t like focusing on GDP. I think a quarterly poll on life satisfaction and optimism would be a better measure. If you’re curious about GDP. I my car breaks and I get it fixed, that adds to GDP. If a parent stays home to raise kids, that lowers GDP. If I clean my own house that lowers GDP. Etc. Unemployment is another crude metric. Are these jobs people want or do they feel forced to work bad jobs. reply jebarker 4 hours agoparentI'm not really disagreeing (as GDP is a crude measure), but rather thinking out loud. I don't think my individual life satisfaction and optimism should be influenced by nation-state economics to the extent that that's what they're optimizing for. The job of my government is to create the conditions for security, prosperity and opportunity without oppressing the rest of the world or destroying the planet. But it's up to me to find a satisfying life within that and that is possible within drastically different economic and social structures. Similarly, there's probably not a set of conditions that gives universal satisfaction to all citizens, so what summary statistics of life satisfaction and optimism do we optimize for? reply vladms 2 hours agoparentprevI find ironic that we are talking about ML where we have vectors of thousands of quantities and then we go to measure social/economic stuff with one (or a couple of numbers). The general discourse (news, politicians, forums, etc.) over a couple of measures will always be highly simplifying. The discourse over thousands of measures will be too complex to communicate easily. I hope that at some point most people will acknowledge implicitly that the fewer the number of measures the more probable is that it is a simplification that hides stuff. (ex: \"X is a billionaire, means his smart\"; \"country X has high GDP means it's better than country Y with less GDP\" and so forth). reply durumu 2 hours agorootparent> I hope that at some point most people will acknowledge implicitly that the fewer the number of measures the more probable is that it is a simplification that hides stuff. But the larger the number of measures, the more free variables you have. Which makes it easier to overfit, either accidentally or maliciously. reply klysm 4 hours agoparentprevThe point is it doesn’t matter what you measure reply swed420 5 hours agoparentprevAgreed, and that goes for capitalism at large. Here's a rough outline for one proposed alternative to capitalism and the failed central planning alternatives of the past: https://jacobin.com/2019/03/sam-gindin-socialist-planning-mo... Some relevant snippets: > Though planning and worker control are the cornerstones of socialism, overly ambitious planning (the Soviet case) and overly autonomous workplaces (the Yugoslav case) have both failed as models of socialism. Nor do moderate reforms to those models, whether imagined or applied, inspire. With all-encompassing planning neither effective nor desirable, and decentralization to workplace collectives resulting in structures too economically fragmented to identify the social interest and too politically fragmented to influence the plan, the challenge is: what transformations in the state, the plan, workplaces, and the relations among them might solve this quandary? > The operating units of both capitalism and socialism are workplaces. Under capitalism, these are part of competing units of capital, the primary structures that give capitalism its name. With socialism’s exclusion of such private units of self-expansion, the workplace collectives are instead embedded in pragmatically constituted “sectors,” defined loosely in terms of common technologies, outputs, services, or simply past history. These sectors are, in effect, the most important units of economic planning and have generally been housed within state ministries or departments such as Mining, Machinery, Health Care, Education, or Transportation Services. These powerful ministries consolidate the centralized power of the state and its central planning board. Whether or not this institutional setup tries to favor workers’ needs, it doesn’t bring the worker control championed by socialists. Adding liberal political freedoms (transparency, free press, freedom of association, habeas corpus, contested elections) would certainly be positive; it might even be argued that liberal institutions should flourish best on the egalitarian soil of socialism. But as in capitalism, such liberal freedoms are too thin to check centralized economic power. As for workplace collectives, they are too fragmented to fill the void. Moreover, as noted earlier, directives from above or competitive market pressures limit substantive worker control even withinthe collectives. > A radical innovation this invites is the devolution of the ministries’ planning authority and capacities out of the state and into civil society. The former ministries would then be reorganized as “sectoral councils” — structures constitutionally sanctioned but standing outside the state and governed by worker representatives elected from each workplace in the respective sector. The central planning board would still allocate funds to each sector according to national priorities, but the consolidation of workplace power at sectoral levels would have two dramatic consequences. First, unlike liberal reforms or pressures from fragmented workplaces, such a shift in the balance of power between the state and workers (the plan and worker collectives) carries the material potential for workers to modify if not curb the power that the social oligarchy has by virtue of its material influence over the planning apparatus, from information gathering through to implementation as well as the privileges they gain for themselves. Second, the sectoral councils would have the capacity, and authority from the workplaces in their jurisdiction, to deal with the “market problem” in ways more consistent with socialism. > Key here is a particular balance between incentives, which increase inequality, and an egalitarian bias in investment. As noted earlier, the surpluses earned by each workplace collective can be used to increase their communal or individual consumption, but those surpluses cannot be used for reinvestment. Nationwide priorities are established at the level of the central plan through democratic processes and pressures (more on this later) and these are translated into investment allocations by sector. The sector councils then distribute funds for investment among the workplace collectives they oversee. But unlike market-based decisions, the dominant criteria are not to favor those workplaces that have been most productive, serving to reproduce permanent and growing disparities among workplaces. Rather, the investment strategy is based on bringing the productivity of goods or services of the weaker collectives closer to the best performers (as well as other social criteria like absorbing new entrants into the workforce and supporting development in certain communities or regions). ... > No one paid greater economic homage to capitalism than the authors of The Communist Manifesto, marveling that capitalism “accomplished wonders far surpassing Egyptian pyramids, Roman aqueducts, and Gothic cathedrals.” Yet far from seeing this as representing the pinnacle of history, Marx and Engels identified this as speaking to a new and broader possibility: capitalism was “the first to show what man’s activity can bring about.” The task was to build on this potential by explicitly socializing and reorganizing the productive forces. > In contrast, for Hayek and his earlier mentor von Mises, capitalism was the teleological climax of society, the historical end point of humanity’s tendency to barter. Hayek considered it a truism that that without private property and no labor and capital markets, there would be no way of accessing the latent knowledge of the population, and without pervasive access to such information, any economy would sputter, drift, and waste talent and resources. Von Mises, after his argument that socialism was essentially impossible was decisively swept aside, turned his focus on capitalism’s genius for entrepreneurship and the dynamic efficiency and constant innovation that it brought. > Despite Hayek’s claims, it is in fact capitalism that systematically blocks the sharing of information. A corollary of private property and profit maximization is that information is a competitive asset that must be hidden from others. For socialism, on the other hand, the active sharing of information is essential to its functioning, something institutionalized in the responsibilities of the sectoral councils. Further, the myopic individualism of Hayek’s position ignores, as Hilary Wainwright has so powerfully argued, the wisdom that comes from informal collective dialogue, often occurring outside of markets in discussions and debates among groups and movements addressing their work and communities. reply remram 15 hours agoprevThose are great points! Another related law is from queuing theory: waiting time goes to infinity when utilization approaches 100%. You need your processes/machines/engineers to have some slack otherwise some tasks will wait forever. reply toasterlovin 14 hours agoparentI’m remembering reading once that cities are incredibly efficient in how they use resources (compared to the suburbs and rural areas, I guess), and, in light of your comment about waiting time, I’m realizing why now why they’re so unpleasant: constant resource contention. reply nuancebydefault 10 hours agorootparentOn the other hand, in cities people are queueing up and talking at the bakery counter. While people in the suburbs are listening to the radio while driving to the bakery. I guess you choose to live where you feel most comfortable. reply naming_the_user 13 hours agorootparentprevAmusingly this is something that I see as being a huge divide in rural and urban politics. Yes, it’s inefficient. Yes, some people want that! reply fragmede 13 hours agorootparentRight. Living is not an optimization problem. reply badpun 12 hours agorootparentUnless not until the oil and other essential stuff run out. reply tambourine_man 8 hours agorootparentOur problem is not that we are running out of stuff, but that we’re drowning on it. reply exe34 12 hours agorootparentprevwhat it means to not optimise though is that some people end up better off and many others are worse off. reply wizzwizz4 3 hours agorootparentAnd what it means to optimise is also that some people end up better off and many others are worse off. reply exe34 1 hour agorootparentYes, the point is to find a balance so that the first number is maximised. reply bmicraft 7 hours agorootparentprevSorry to put it so bluntly, but you're basically saying: \"I don't care it the climate's fucked, I want to live away from civilization and drive 100 miles a day everywhere\" Of course we shouldn't hyper-optimize everything, but sooner people realize our environment depends on not everyone getting exactly what they want whenever they want the better. Living in a (walkable) city is just one such concession towards the environment we ought to make, even if we don't \"want\" to. reply naming_the_user 7 hours agorootparentOr we could just compete with each other for resources as we have since forever. I’d rather do that than have no choice but to live in Kowloon. Just whack an externality tax on fossil fuels and things like cutting down wilderness, job done. reply xerox13ster 3 hours agorootparentOr we can stop acting like there’s only two options: living in wide-open fields with a clear horizon or the fucking walled city of Kowloon. Also, you have the mindset of a typical anti-social coastal elite who thinks “oh no big deal we can just raise the cost of living for all the poor rural types by sticking on a tax because I want to go LARP as a Victorian manor lord. And people don’t bend to my every whim immediately or live exactly like me so I want to be in total control of the 50 miles around me.” reply llm_trw 7 hours agorootparentprevIf you think cities don't fuck the climate just as much as suburbs do I have a well you can carry water 40 flights of stairs from. reply r3d0c 5 hours agorootparentcities do because they exist in a system that generate carbon, but they are vastly more resource & carbon efficient than suburbs per person https://usa.streetsblog.org/2015/03/05/sprawl-costs-the-publ... https://news.berkeley.edu/2014/01/06/suburban-sprawl-cancels... reply fragmede 51 minutes agorootparentprevThat’s not remotely what I’m saying. I live in a city and don’t drive most days because I can walk and take public transit and there’s never any parking. What I’m saying is that in the bigger picture, approaching life as a set of problems to be optimized is the wrong way to approach life. reply Jensson 12 hours agorootparentprevThe efficiency results in abundance not possible in less dense areas, you are waiting for things that are simply not available elsewhere. reply nerdponx 11 hours agorootparentSort of. Compare doing laundry at the laundromat to doing laundry in your basement. reply mgfist 5 hours agorootparentThey meant things like bars, restaurants, sports stadiums, concerts, plays. Things that require sufficient density to make economic sense. reply kortilla 3 hours agorootparentLA has multiple of all of those and nearly entirely suburbs reply georgeburdell 14 hours agoparentprevYep, I used to work in a factory. Target utilization at planning time was 80%. If you over-predict your utilization, you waste money. If you under-predict, a giant queue of “not important” stuff starts to develop reply scott_w 12 hours agorootparentThis reminds me of something my mother told me she aimed for when she ran her catering businesses: she always wanted 1 serving of pie leftover at the end of every day. If she had 0, she ran the risk of turning customers away and losing money. Any more than 1 is excess waste. Having just 1 meant she’d served every possible customer and only “wasted” 1 slice. reply rzzzt 11 hours agorootparentAnd then you can eat the pie as a reward. reply immibis 5 hours agorootparentprevCustomers don't want to buy the last one. reply eru 13 hours agorootparentprevFor some scenarios that's fine, and you can slash the queue whenever necessary. Eg at Google (this was ten years ago or so), we could always spend leftover networking capacity on syncing a tiny bit faster and more often between our data centres. And that would improve users' experience slightly, but it also not something that builds up a backlog. At a factory, you could always have some idle workers swipe the floor a bit more often. (Just a silly example, but there are probably some tasks like that?) reply 082349872349872 8 hours agorootparentUnlike merchantmen, naval vessels were crewed at a level allowing for substantial attrition (bad attrition would be casualties; good attrition would be prize crews); I believe they traditionally (pace Churchill) had many, many activities which were incidental to force projection (eg polishing the brightwork) but could be used to occupy all hands. reply eru 4 hours agorootparentYes. And, well, you can also always train more. Especially in the age of sail. reply eru 15 hours agoparentprevYou can add a measure of robustness to your optimization criteria. You can explicitly optimise for having enough slack in your utilisation to handle these unforeseen circumstances. For example, you can assign priorities to the loads on your systems, so that you can shed lower priority loads to create some slack for emergencies, without having to run your system idle under during lulls. I get what the article is trying to say, but they shouldn't write off optimisation as easily as that. reply remram 43 minutes agorootparentA task \"shed\" is one delivered with infinite latency. If that's fine for you then the theorem doesn't hurt you, do what's best for your domain. It's just something to be aware of. reply hinkley 14 hours agorootparentprevThe problem is that people who agree to a task being low priority still expect it to be done in nine months and all of a sudden they become high priority if that doesn’t happen. So you’re fixing the micro economics of the queue but not the macro. Queues still suck when they fill up, even if they fill with last minute jobs. reply eru 13 hours agorootparentThis totally depends on the system in question and what the agreements with your users are. Eg if you are running video conferencing software, and all of a sudden you are having bandwidth problems, you typically first want to drop some finer details in the video, and then you want to drop the audio feed. In any case, if you dropped something, you leave it dropped, instead of picking it back up again a few seconds later. People don't care about past frames. (However, queuing instead of outright dropping can still makes sense in this scenario, for any information that's younger than what human reaction times can perceive.) Similarly in your scenario, you'd want to explicitly communicate to people what the expectations are. Perhaps you give out deep discounts for tasks that can be dropped (that's what eg some electriticy providers do), or you can give people 'insurance' where they get some monetary compensation if their task gets dropped. (You'd want to be careful how you design such a scheme, to avoid perverse incentives. But it's all doable.) > So you’re fixing the micro economics of the queue but not the macro. Queues still suck when they fill up, even if they fill with last minute jobs. I don't know, I had pretty positive experiences so far when eg I got bumped off a flight due to overbooking. The airline offered decent compensation. Overbooking and bumping people off _improves_ the macro situation: despite the occasional compensation you have to pay, when unexpectedly everyone who booked actually showed up, overbooking still makes the airline extra money, and via competition this is transformed into lower ticket prices. Many people love lower airfares, and have shown a strong revealed preference of putting up with a lot of stuff eg RyanAir pulls as long as they get cheap tickets. reply vishnugupta 13 hours agoparentprevI feel that a 100% efficient system is not resilient. Even minor disruptions in subsystems lead to major breakdowns. There’s no room to absorb shocks. We saw a drastic version of this during COVID-19 induced supply chain collapse. Car manufacturers had built near 100% just in time manufacturing that they couldn’t absorb chip shortages and it took them years to get back up. It also leaves no room for experimentation. Whatever experiment can only happen outside a system not from within it. reply kelseyfrog 11 hours agorootparentThis is coincides with my headcannon cause of the business cycle. 1. Firms compete 2. Firms either increase their efficiency or die 3. Efficient firms are more susceptible to shocks 4. Firm shutdown and closures are themselves shocks 5. Eventually the system reaches a critical point where the aggregate susceptibility is higher than the aggregate of shocks that will be generated by shutdowns and closures 6. Any external shock will cause a cascade There's essentially a \"commons\" where firms trade susceptibility for efficiency. Or in other words, susceptibility is pooled while the rewards for efficiency are separate. reply NeoTar 10 hours agorootparentIt sounds similar to how animal/plant species often work. A species will specialise for a niche, and outcompete a generalist. But when conditions change, the generalist can adapt and the specialist suffers. reply Eddy_Viscosity2 6 hours agorootparentprevBut in practice we see that: 1. Firms compete 2. Some firms get ahead 3. Accrued advantages to being ahead amplify 4. A small number of firms dominate 5. New competition is bought or crushed 6. Dominate firms become less efficient in competition-free environment reply kelseyfrog 1 hour agorootparentThey aren't mutually exclusive. And, not xor. reply yannis 8 hours agorootparentprevGood analysis, but one also needs to look at the definition of `efficiency`, what is your definition of efficiency in this context. reply kelseyfrog 3 hours agorootparentThe ability to do more with fewer resources. Profit is a great starting point when answering, \"What is efficiency to a firm?\" reply tacitusarc 13 hours agorootparentprevThere is a fundamental tension between efficiency and resilience, you are completely correct. And yea, it’s a systems problem, not limited to tech. There is an odd corollary, which is that capitalistic systems which reward efficiency gains and put downward pressure to incentivize efficiency, deal with the resilience problem by creating entirely new subsystems rather than having more robust subsystems, which is fundamentally inefficient. reply hyperadvanced 12 hours agorootparentThis is exactly the subthread of this conversation I’m interested in. Is what you’re saying that capitalism breaks down resilience problems into efficiency problems? I think that’s an extremely motivating line of thinking, but I’ll have to do some head scratching to figure out exactly what to make of it. On one hand, I think capitalism is really good at resilience problems (efficient markets breed resilience, there’s always an incentive to solve a market inefficiency), on the other (or perhaps in light of that) I’m not so sure those two concepts are so dialectically opposed reply tacitusarc 45 minutes agorootparentTo understand the effects, we first have to take a step back and recognize that efficiency and resiliency problems are both subsets of optimization problems. Efficiency is concerned with maximizing the ratio of inputs to outputs, and resiliency is concerned with minimizing risk. The fundamental tension arises because risk mitigation increases input costs. Over a given time horizon, there is an optimal amount of risk mitigation that will result in maximum aggregate profit (output minus input, not necessarily monetary). The longer the time horizon, the more additional risk mitigation is required, to prevent things like ruin risk. But here’s the rub: competition reduces the time horizon to “very very short” because it drives down the output value. So in a highly competitive market, we see companies ignore resiliency (they cannot afford to invest in it) and instead they get lucky until they don’t (another force at work here is lack of skin in the game). The market deals with this by replacing them with another firm that has not yet been subject to the ruinous risks of the previous firm. This cycle repeats again and again. Most resilient firms have some amount of monopolistic stickiness that allows them to invest more in resiliency, but it is also easy to look at those firms and see they are highly inefficient. The point is that the cycle of firms has a cost, and it is not a trivial one: capital gets reallocated, businesses as legal entities are created, sold, and destroyed, contracts have to be figured out again, supply chains are disrupted, etc. Often, the most efficient outcome for the system is if the firms had been more resilient. So there is an inefficient Nash equilibrium present in those sort of competitive markets. reply maximus-decimus 10 hours agorootparentprevI mean, car companies also just straight out cancelled their chip orders because they initially thought people would stop buying cars during COVID. reply I_AM_A_SMURF 14 hours agoparentprevThat tracks. I worked at a lot of places/teams where anything but a P0 was something that would never be done. reply hinkley 14 hours agorootparentSolution: everything is a P0! reply jaggederest 13 hours agorootparentThen you just get Little's law, which is not usually what people want. Preemption is usually considered pretty important... Much like preemptory tasks. reply hinkley 13 hours agorootparentNo what you get is alcoholism. It was sarcasm. reply jaggederest 13 hours agorootparentPorque no los dos? The purpose of a beverage is what it does. reply robertclaus 14 hours agoparentprevInteresting. My gut reaction is that this is true in reverse: infinite wait time leads to 100% utilization. However, I feel like you can also have 100% utilization with any queue length if input=output. Is that theory just a result of a first order approximation or am I missing something? reply Aeolun 13 hours agorootparentI think it comes from tasks not taking an equal amount of time, coming in at random, and not having similar priorities. reply immibis 6 hours agorootparentprevThe average queue length is still infinity. Whatever the queue length happens to be at the start, it will stay there, and it could be any positive number up to infinity. Besides, angels can't really balance on pinheads. reply appendix-rock 8 hours agoparentprevFor some it may go without saying, but for the uninitiated, y’all should be reading https://en.wikipedia.org/wiki/The_Goal_(novel) reply redsparrow 5 hours agoprevThis makes me think of going to chain restaurants. Everything has been focus-grouped and optimized and feels exactly like an overfit proxy for an enjoyable meal. I feel like I'm in a bald-faced machine that is optimized to generate profit from my visit. The fact that it's a restaurant feels almost incidental. \"HI! My name is Tracy! I'm going to be your server this evening!\" as she flawlessly writes her name upside down in crayon on the paper tablecloth. Woah. I think this place needs to re-calibrate their flair. reply LarsDu88 14 hours agoprevI was trying to remember where I remember where I heard of this author's name before. Invented the first generative diffusion model in 2015. https://arxiv.org/abs/1503.03585 reply Arech 11 hours agoparentAnd for me it was this ingenious 2019 paper co-authored by Stephan Hoyer and Sam Greydanus on doing structural optimization by employing a (constrained) neural network as a storage/modifier/tuner of the physical model describing the structure to optimize: https://arxiv.org/abs/1909.04240 Super interesting approach and very well written paper. reply jrochkind1 6 hours agoprevCalling this the \"strong version of Goodhart's law\" was immediately brain-expanding for me. I have been thinking of goodhart's law a lot, but realized I had been leaning toward focusing on human reaction to the metric as the cause of it; but this reminded me it's actually fundamentally about the fact that any metric itself is inherently not an exact representation of the quality you wish to represent. And that this may, as OP argues, make goodhart's law fundamental to pretty much any metric used as a target. Independently of how well-intentioned any actors. It's not a result of like human laziness or greed or competing interests, it's an epistemic (?) result of the neccesary imperfection of metric validity. This makes some of OP's more contentious \"Inject noise into the system\" and \"early stopping\" ideas more interesting even for social targets. \"The more our social systems break due to the strong version of Goodhart's law, the less we will be able to take the concerted rational action required to fix them.\" Well, that's terrifying. reply usaphp 14 hours agoprevI think it also applies to when managers try to overoptimize work process, in the end creative people lose interest and work becomes unbearable...little chaos is necessary in a work place/life imo... reply hinkley 14 hours agoparentI kill my desire to work on a lot of side projects by trying to over optimize the parts I’m not going to like doing. I should just do the yucky parts and get past them. But at least nobody is paying me to spiral. reply kzz102 4 hours agoprevI think of efficiency as one example where naive economic thinking has poisoned common sense. Economists view inefficiency as a problem. Because a healthy economy is efficient, therefore inefficiency is unhealthy. Any inefficient market is a \"market failure\". Efficiency is also the primary way a manager can add value. But the problem is, efficiency assumes existence of metrics, and indeed is counter productive if your metrics are wrong. reply marcosdumay 3 hours agoparent> Efficiency is also the primary way a manager can add value. That's not right. The primary task of management is alignment. reply kzz102 2 hours agorootparent> That's not right. The primary task of management is alignment. Fair enough.. at least they think they can add value by improving efficiency. reply marcosdumay 1 hour agorootparentIt's a way they can add value. It's far from their primary way, and it's a task that is not primary done by management. But yes, there are plenty of managers that focus on it. reply otherme123 3 hours agoprev> Goal: Distribution of labor and resources based upon the needs of society > Proxy: Capitalism > Strong version of Goodhart's law leads to: Massive wealth disparities (with incomes ranging from hundreds of dollars per year to hundreds of dollars per second), with more than a billion people living in poverty Please, show me a point in all human history when we have less than 90% global population living in poverty, pre-capitalism. Yes, there are 1 billion people (out of 8 billion) living in poverty today. But they were 2 billion (of 4.5 billion total) living in poverty as recently as 1980 (https://www.weforum.org/agenda/2016/01/poverty-the-past-pres...). Poverty is steadily going down (https://www.weforum.org/agenda/2016/01/poverty-the-past-pres...) since we have data. The first countries to get rid of recurrent famines were the same that first adopted capitalism. The same countries where their population started having higher expectations than to live another day. Paraphrasing Churchill about democracy, \"[capitalism] is the worst economic system except for all other systems that has been tried from time to time\". reply jaco6 3 hours agoparentThere is no such thing as capitalism. “The first countries to get rid of recurrent famine” were those that began using the steam engine and field enclosure. These are not “capitalism”, they are “capital”, in tge jargon of the economist Marx, or, in modern parlance, technology. All of the parts of the world that are not starving are not starving due to their adoption of a variety of technologies, both mechanical and bureaucratic: fertilizer, machine tractors, and centralized governance using telephone lines and now internet. When people claim “capitalism” ended starvation, they ignore places like China and Russia which also ended famine despite adopting state ownership of farms. There was indeed famine during the transition period, but Russia ended famine by the 50s and China ended famine by the 70s, long before many “capitalist” countries in the 3rd world. That’s because the world isn’t about the phony field of “economics,” it’s about technology. Likewise, the other advancements of society that are claimed to be associated with “capitalism”—the end of smallpox and other old high-casualty diseases, the development of reliable air and trans-oceanic transport, instant global communications: all are due to the efforts of scientists working in labs mostly funded by governments and wealthy patrons, not “capitalism.” Capitalist enterprises almost never take major innovative risks. Even the latest glorious advancement that will doubtless be claimed by “capitalism,” Wikipedia-scraping chat bots, was developed by a non-profit. Everything is about technology—stop letting economists drag you into stupid, poorly formed debates using undefined terms like “capitalism.” reply d0gsg0w00f 2 hours agorootparentTechnology is a large factor but not the core driver. It's individual human motivation that drives the efficiency of the system. When you centralize the function of human motivation into a governing body like socialism aims to do, the goal is that the central body can optimize the system. However, the system is too complex and always misses something that was never predicted. When you \"outsource\" those motive drivers back to the people with capitalism you let the system optimize itself. reply efitz 20 minutes agoprevI am skeptical of the analogy to overfitting, although I understand where the author is coming from and agree with the sentiment. The basic problem is stupid simple. Optimizing a process for one specific output necessarily un-optimizes for everything else. Right now much of commerce and labor in the United States is over-optimized for humans because tech businesses are optimizing for specific outcomes (productivity, revenue, etc) in a way that ignores the negative impacts on the humans involved. The optimizations always turn into human goals, eg my manager needs to optimize for productivity if they want a bonus (or not get optimized out themselves), which means they need to measure or estimate or judge or guess each of their employees’ productivity, and stupid MBA shit like Jack Welch’s “fire the lowest 10% every year”) results in horrible human outcomes. Sure there are people who need to be fired, but making it an optimization exercise enshittified it. Same for customer service. Amazon wants to optimize revenue. Customer service and returns are expensive. Return too many things? You’re fired as a customer. Call your mobile providers customer service too often? Fired. Plus let’s not staff customer service with people empowered to do, well, service. Let’s let IVRs and hold times keep the volumes low. All anecdotes but you’ve experienced something similar often enough to know it is the rule, not the exception, and it’s all due to over-optimization. reply raister 15 hours agoprevThis reminds me of Eli Goldratt's quote: \"Tell me how you measure me, I will tell you how I behave.\" reply tirant 11 hours agoparentParallel to Munger’s “Show me the incentives and I will show you the outcome” which I think all of us have or will realize for ourselves at some point in life. reply whack 15 hours agoparentprevCorollary: \"If you do not measure me, I will not behave\" reply ryandv 14 hours agorootparentThis is coming very close to denying the antecedent, one of the most basic formal logical fallacies. reply hinkley 14 hours agorootparentprevNo, I’m gonna do what I want to do. If you hire good people “what they want to do” is going to be what they think is right. Which may or may not be. reply eventuallylive 15 hours agorootparentprevStrictly speaking this is not the contrapositive and therefore the proof is yet to be seen. A sound corollary: \"If I do not behave, it is because you did not measure me.\" reply lotsofpulp 15 hours agorootparentIs a contrapositive a corollary? P implies Q is logically equivalent to Not Q implies Not P. A corollary would be some other relation that can be deduced as a result of P implies Q, not simply a restatement of P implies Q. (Using the discrete math definition of imply, not the colloquial definition of imply). reply moefh 14 hours agorootparentYes, a corollary can be just the contrapositive of something you just proved. Sometimes it's even more trivial, like a special case of a general theorem you proved. A very common use is to re-state something so it's in the exact form of something you said you'd prove. Another common case is to highlight a nice incidental result that's a bit outside the path towards the main result -- for example, it immediately follows (perhaps logically equivalent to) something that's been proven, but it's dressed in a way that catches the attention of someone who's just skimming. reply cb321 6 hours agoprevI do like it when researchers try to connect the deep ideas within their work to broader more general systems, but caution is warranted to the optimism. This article is the kind of formal analogy that inspired/drove much of the marketing appeal of the Santa Fe Institute back in the 1980s. It's honestly always pretty fun, but the devil is usual in the details here (as is usual in making anything \"work\", such as self-organized criticality [1] which if you enjoyed this article you will also probably enjoy!). As just one example to make this point more concrete (LOL), the article mentions uncritically that \"more complex ecosystems are more stable\", but over half a century ago in 1973 Robert May wrote a book called \"Stability and Complexity in Model Ecosystems\" [2] explaining (very accessibly!) how this is untrue for the easiest ideas of \"complex\" and \"stable\". In more human terms, some ideas of \"complex\" & \"stable\" can lead you astray, as has been appearing in the relatively nice HN commentary on this article here. Perhaps less shallowly, things go off the rails fast once you have both multiple metrics (meaning no \"objective Objective\") and competing & intelligent agents (meaning the system itself has a kind of intrinsic complexity, often swept under the rug by a simplistic thinking that \"people are all the same\"). I think this whole topic folds itself into \"Humanity Complete\" (after NP-complete.. a kind of infectious cluster of Wicked Problems [3]) like trust/delegation do [4]. [1] https://en.wikipedia.org/wiki/Self-organized_criticality [2] https://press.princeton.edu/books/paperback/9780691088617/st... [3] https://en.wikipedia.org/wiki/Wicked_problem [4] https://en.wikipedia.org/wiki/Demarcation_problem reply smokel 12 hours agoprevI was listening to an episode of the \"inControl\" podcast [1], in which Ben Recht suggested that overfitting is not always well understood. Perhaps it is interesting to read his blogpost \"Machine Learning has a validity problem\" alongside this article. [1] https://www.incontrolpodcast.com/ [2] https://archives.argmin.net/2022/03/15/external-validity/ reply projektfu 14 hours agoprevAnd that's leaving out Jevon's paradox, where increasing efficiency in the use of some scarce resource sometimes/often increases its consumption, by making the unit price of the dependent thing affordable and increasing its demand. For example, gasoline has limited demand if it requires ten liters to go one km, but very high demand at 1 L/10km, even at the same price per liter. reply hinkley 14 hours agoparentWhen people know the answer is always “no” they save their energy to plea for stuff they really can’t do without. You start saying yes and they’ll ask for more. The trick is as always to find out the XY problem. What they really need may be way easier for you to implement than what they actually asked for. reply eru 13 hours agorootparentSometimes you can just embrace it, instead of looking for tricks. If you are in the business of selling any product or service, then it's great that finding a way to make it cheaper also generates more demand for you. reply hinkley 13 hours agorootparentI’m confused, because the “not trick” I’m talking about is the boondoggle created by giving people exactly what they ask for, making nobody happy and jamming up your throughput in the process. reply eru 13 hours agorootparentTo be specific: if you can find a way to make fridges for half the previous cost, and you can sell them for three quarters the previous price, you don't want to talk people out of buying more fridges. In fact, them buying vastly more fridges is exactly what you want. reply its_bbq 10 hours agorootparentAnd not necessarily the long term result anybody wants reply eru 7 hours agorootparentSame happened with Walkmans or desktop computer, or mobile phones etc. It's pretty normal that people want less of stuff when it's expensive, and more when it's cheap. reply projektfu 3 hours agorootparentprevYeah, but it is also second-order effects where the efficient use of a resource opens it up for more uses as well as for more exploitation. Perhaps this is most visible with farmland. Efficient use of water (center-pivot sprinkler) causes much more land to be arable, causing more use of that same water as well, depleting aquifers. reply chrisweekly 3 hours agoprevEfficiency tends to come at the cost of adaptability. Don't put it on rails if it needs a steering wheel. So many enterprises suffer from extreme rigidity - often caused by optimizations that lead to local maxima. reply dooglius 15 hours agoprevOverfitting may be a special case of Goodhart's Law, but I don't think Goodhart's Law in general is the same as overfitting, so I don't think the conclusion is well-supported supported in general; there may be plenty of instances of proxy measures that do not have issues. I'll also quibble with the example of obesity: the proxy isn't nutrient-rich good, but rather the evaluation function of human taste buds (e.g. sugar detection). The problem is the abundance of food that is very nutrient-poor but stimulating to taste buds. If the food that's widely available were nutrient-rich, it's questionable whether we would have an obesity epidemic. reply feyman_r 15 hours agoparentWe realize now or at least in recent past, the value of true nutrient-rich food or a balanced diet. Carbohydrate abundance was likely important in moving people out of hunger and poverty but excesses of the same kind of diet are a reflection on obesity. My guess is that calorie-per-gram-per-dollar of carbohydrates is still lower than fat and protein. reply ezekiel68 3 hours agoprevThis certainly tugs at all the right levers of the intuition. Not sure how to \"buck the trend\" in any established organization/regime to adjust expectations according to the theory. Looks like this might need to be demonstrated in the wild at a new concern or as a turnaround job, where the leaders could have a strong influence on the culture (similar to how Jim Keller steered AMD and is now steering TensTorrent). reply gond 9 hours agoprev“Though this pheonomenon is often discussed, it doesn't seem to be named. Let's call it the strong version of Goodhart's law“ I wonder why the author called it that way when this seems to me clearly derived from Ross Ashby‘s law of Requisite Variet[1], predating Goodhard by 20 years. As I see it, it is not even necessary to put more meaning it Goodhard as there actually is. Requisite Variety is sufficient. Going by his resume, I strongly assume the author knows this. Russel Ackoff, building on countless others, put into two sentences for which others needed two volumes: “The behaviour of a system is never equal to the behaviour of its parts. - It is the product of their interactions.“ [1] https://en.m.wikipedia.org/wiki/Variety_(cybernetics) reply appendix-rock 8 hours agoparentLove myself some cybernetics! All engineers are doing themselves a disservice by sitting here writing smooth-brained rants about “dumb MBAs making my job hard” instead of reading up on this field and understanding the true complexities that are inherent in people working together. reply gond 7 hours agorootparentAgreed. I wonder if this is still the aftermath of the chasm which resulted when ‘Marvin Minsky et al‚ disowned Cybernetics, took some parts out of it and gave it a shiny new name. Especially Systems Theory in its second manifestation (Maturana, Luhmann, von Förster, Glasersfeld - and Ackoff) is extremely powerful, deep and, reasons beyond me, totally overlooked. Have to say tho, most MBA‘s I encountered sadly never ever heard of Cybernetics or Systems Theory. :-( reply pradn 4 hours agorootparentHow has Systems Theory changed how you think? Is there a good book you recommend on the topic? Thank you! reply lynguist 9 hours agoprevI would claim in a completely informal way that the optimal degree of utilization is ln(2)=0.693, around 70%. This stems from the optimal load of self-balancing trees. A little bit of slack is always useful to deal with the unforeseen. And even a lot of slack is useful (though not always as it is costly) as it enables to do things that a dedicated resource cannot do. On the other hand, no slack at all (so running at above 70%) makes a system inflexible and unresilient. I would argue for this in any circumstance, be it military, be it public transit, be it funding, be it allocation of resources for a particular task. reply Tade0 8 hours agoparentI would put it at 1 - e^(-1) ~= 0.6321 As e^x is a commonly occurring curve and at that point its derivative goes below 1, meaning from that point on it's diminishing returns. reply LUmBULtERA 8 hours agorootparentI was thinking how this string of thought could connect to our daily lives. As a family with a toddler, if we fill up too much of our schedule/time in a day, a perturbation to the schedule can break everything. If instead we fill up 63-70% of the schedule and build in Flex Time, we're good! reply slashdave 6 hours agoprevI am surprised that the author left out another mitigation. To build solutions (models) that are constructed to be more transferable (amenable to out of domain data). For example, in machine learning, using physics informed models. Perhaps this is simply a sign that the author is a proponent of generic, deep-learning. reply yldedly 3 hours agoparentMost people in ML, even if they are very proficient, don't understand why models should generalize out of domain. They just don't think about it. reply tpoacher 13 hours agoprevThere was no need to invent a new law named \"strong version\", it already exists: Campbell's law. The subtle difference between the two being exactly what the author describes: Goodhart's law states that metrics eventually don't work, Campbell's law states that, worse still, eventually they tend to backfire. reply zmmmmm 11 hours agoprevMaybe I'm misunderstanding this but this doesn't seem like an accurate explanation of overfitting: > In machine learning (ML), overfitting is a pervasive phenomenon. We want to train an ML model to achieve some goal. We can't directly fit the model to the goal, so we instead train the model using some proxy which is similar to the goal One of the pernicious aspects of overfitting is it occurs even if you can perfectly represent your goal via a training metric. In fact it's even worse simetimes as an incorrect training metric can indirectly help regularise the outcome. reply practal 9 hours agoparentYou might be misunderstanding here what the \"goal\" is. Your training metric is just another approximation of the goal, and it is almost never perfect. If it is perfect, you cannot overfit, by definition. reply leeoniya 3 hours agoprev\"Efficiency trades off against resiliency\" https://blog.nelhage.com/post/efficiency-vs-resiliency/ reply whatever1 13 hours agoprevWhen we optimize we typically have a specific scenario in our head. With the proper tools one can probably make the mathematically optimal decisions to deal with this exact scenario. However: 1) This exact scenario will likely never materialize 2) You have not good quantification of the scenario anyway due to noise/biases in measurements. So now you optimized for something very specific, and the nature throws you something slightly different and you are completely screwed because your optimized solve is not flexible at all. That is why a more “suboptimal” approach is typically better and why our stupid brains outperform super fancy computers and algorithms in planning. reply tikkun 7 hours agoprevMakes me think of: some of Taleb's ideas about just-in-time manufacturing (no slack eg covid supply shocks) https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack Also, can't recall it but a long time ago I read a piece about how scheduling a system to 60% of its max capacity is generally about right, to allow for expected but unexpected variations (also makes me think of the concept of stochastic process control and how we can figure out the level of expected unexpected variations, which could give us an even better sense of what %-of-capacity to run a system at) reply naitgacem 9 hours agoprevUpon reading the title at first glance, I thought this was going to be how \"effecient\" computers nowadays. Such as MacBooks and such, who started this efficient computers thing in the recent times. And they are, but as a result computers are all worse off for it. I mean soldered RAMs and everything is a system on a chip. reply throwuxiytayq 9 hours agoparentThe existence of the Framework Laptop proves that this is largely an imaginary tradeoff, or at least one badly taken by Apple. reply naitgacem 9 hours agorootparentUnfortunately once one company does something and gets away with it, or makes even more money, everyone will follow. I was looking at Thinkpads and was somewhat shocked to see they started doing that too! reply CooCooCaCha 3 hours agorootparentThis is also why the libertarian solution to bad work environments “just leave” doesn’t work at scale. reply appendix-rock 8 hours agoparentprevThat wouldn’t be worthy of the front page of HN. “I don’t like the current tradeoffs that laptop manufacturers make” has been talked through to absolute death. It’s the opposite of interesting. reply throwuxiytayq 5 hours agorootparentIf anything, there should be more space for this topic in our collective consciousness. reply o-o- 6 hours agoprev> FTA: This same counterintuitive relationship between efficiency and outcome occurs in machine learning. The \"examples abound, in politics, economics, health, science, and many other fields\" isn't a relationship between efficiency and outcome, but rather measuring and efficiency, or measuring and outcome. I think a better analogy is Heissenberg's uncertainty principle – the more you measure the more you (negatively) affect the environment you're measuring. reply idunnoman1222 4 hours agoprevThe statement overfits its own idea. Testing students is not an example of an efficiency reply numbol 7 hours agoprevThere is a book on this topic, \"Why Greatness Cannot Be Planned\" https://link.springer.com/book/10.1007/978-3-319-15524-1 There are many youtube videos where Ken explain those ideas, this one for example https://www.youtube.com/watch?v=y2I4E_UINRo reply hedora 16 hours agoprevI don’t think the author understands what efficiency measures. All of the examples involve a bad proxy metric, or the flawed assumption that spending less improves the ratio of price to performance. reply mirekrusin 13 hours agoparentThe argument is that regardless of what metic is chosen, it'll create deminishing returns followed by negative returns. What it means is the objective can't be static - for example once satiated, you need to pick different one to keep improving globally. Or do something else that moves the goalpost. reply feyman_r 15 hours agoparentprevMy take was that initially the metric is appropriate, but then with overfitting, it’s not enough. It eventually becomes a bad proxy metric. reply atoav 15 hours agoparentprev> [..] it signifies the level of performance that uses the least amount of inputs to achieve the highest amount of output. It often specifically comprises the capability of a specific application of effort to produce a specific outcome with a minimum amount or quantity of waste, expense, or unnecessary effort. to quote wikipedia quoting Sickles, R., and Zelenyuk, V. (2019). \"Measurement of Productivity and Efficiency: Theory and Practice\". Cambridge: Cambridge University Press. Offering that criticism without clarifying what efficiency measures in your opinion doesn't allow us to follow your viewpoint without us just taking your word for it. Needless to say this isn't considered good style in a discourse. A 100 percent \"efficient\" system can be one that is overfitted to certain metrics and it is the typical death sin of management to confuse metrics with reality and miss that their great numbers hollow out anything that makes a system work well and reliable, because guess what: having 1 critical employee and working them like a mule is good when things work, but bad when they suddenly don't, because that second employee you thought was fat that could be cut, was your fallback. In that case your metric of efficiency was slightly increased while another, less easy to quantify (and therefore often non-existent) metric of resilience went down significantly. This means if your goal was having an efficient and resilient company, but your metric only measured the former, guess what. Same is true in engineering, where you can optimize your system so much to fit your expected problem, one slight deviation within the problem now stops the whole thing from working alltogether (F1 racing car when part of the track turns out to be a sucky dirtroad). Highly optimized systems are highly optimized towards one particular situation and thus less flexible. Or in biology, where everybody ought to know that mixed woods are more resilient to storms and other pests, while having great side effects for the health of the ecosystem, yet in pure economic terms it is easy to convince yourself the added effíciency of a monoculture is worth it economically, because all you look at is revenue, while ignoring multiple other metrics that impact reality. reply brilee 15 hours agoparentprevAccusing these examples of involving \"bad proxy metric\" is identical to the no true scotsman fallacy. reply hinkley 13 hours agoparentprevMight need to read some Goldratt. We generally don’t understand efficiency that well. reply mppm 12 hours agoparentprevYeah, every single example listed looks like gaming of bad metrics. Framing it as overfitting is unproductive, IMHO, and discounts the essentially adversarial context. I also discounts the stupidity of equating \"efficiency\" with a high score on a simple metric. Reality has a Surprising Amount of Detail, and all that. reply nottorp 3 hours agorootparentgaming of metrics. Not of bad metrics. The point is all metrics will become bad because they will be gamed for. reply godelski 13 hours agoprevI find this article a bit odd, considering what the author is an expert in: generative imagery. It's the exact problem he discusses, the lack of a target that is measurable. Defining art is well known to be ineffable, yet it is often agreed upon. For thousands of years we've been trying to define what good art means. But you do not get good art by early stopping, you do not get it by injecting noise, you do not get it by regularization. All these do help and are essential to our modeling processes, but we are still quite far. We have better proxies than FID but they all have major problems and none even come close (even when combined). We've gotten very good at AI art but we've still got a long way to go. Everyone can take a photo, but not everyone is a photographer and it takes great skill and expertise to take such masterpieces. Yet there are masters of the craft. Sure, AI might be better than you at art but that doesn't mean it's close to a master. As unintuitive as this sounds. This is because skill isn't linear. The details start to dominate as you become an expert. A few things might be necessary to be goo",
    "originSummary": [
      "The strong version of Goodhart's law suggests that over-optimizing a proxy measure can lead to worse outcomes in the actual goal, as seen in standardized testing and machine learning overfitting.",
      "This concept is applicable across various fields, including politics, economics, and health, indicating the broad relevance of the phenomenon.",
      "Mitigation strategies from machine learning, such as aligning proxy goals with desired outcomes, adding regularization penalties, injecting noise, and using early stopping, can help manage these issues."
    ],
    "commentSummary": [
      "Over-optimization in machine learning and other fields can lead to negative outcomes, as suggested by ML researcher Jascha Sohl-Dickstein.",
      "This concept aligns with Goodhart's law, which states that when a measure becomes a target, it ceases to be a good measure.",
      "Examples of negative outcomes from over-optimization include COVID-19 supply chain disruptions and inefficiencies in healthcare and railways in Sweden, highlighting the need for systems to maintain some slack for robustness and adaptability."
    ],
    "points": 701,
    "commentCount": 295,
    "retryCount": 0,
    "time": 1727572784
  },
  {
    "id": 41683293,
    "title": "How Discord stores trillions of messages (2023)",
    "originLink": "https://discord.com/blog/how-discord-stores-trillions-of-messages",
    "originBody": "COLLECTIONS Community Discord HQ Engineering & Developers How to Discord Policy & Safety Product & Features FeaturedDiscord.com Engineering & DevelopersHow Discord Stores Trillions of Messages Bo Ingram March 6, 2023 Tags In 2017, we wrote a blog post on how we store billions of messages. We shared our journey of how we started out using MongoDB but migrated our data to Cassandra because we were looking for a database that was scalable, fault-tolerant, and relatively low maintenance. We knew we’d be growing, and we did! We wanted a database that grew alongside us, but hopefully, its maintenance needs wouldn’t grow alongside our storage needs. Unfortunately, we found that to not be the case — our Cassandra cluster exhibited serious performance issues that required increasing amounts of effort to just maintain, not improve. Almost six years later, we’ve changed a lot, and how we store messages has changed as well. Our Cassandra Troubles We stored our messages in a database called cassandra-messages. As its name suggests, it ran Cassandra, and it stored messages. In 2017, we ran 12 Cassandra nodes, storing billions of messages. At the beginning of 2022, it had 177 nodes with trillions of messages. To our chagrin, it was a high-toil system — our on-call team was frequently paged for issues with the database, latency was unpredictable, and we were having to cut down on maintenance operations that became too expensive to run. What was causing these issues? First, let’s take a look at a message.CREATE TABLE messages (channel_id bigint,bucket int,message_id bigint,author_id bigint,content text,PRIMARY KEY ((channel_id, bucket), message_id)) WITH CLUSTERING ORDER BY (message_id DESC); view raw gistfile1.sql hosted with ❤ by GitHub The CQL statement above is a minimal version of our message schema. Every ID we use is a Snowflake, making it chronologically sortable. We partition our messages by the channel they’re sent in, along with a bucket, which is a static time window. This partitioning means that, in Cassandra, all messages for a given channel and bucket will be stored together and replicated across three nodes (or whatever you’ve set the replication factor). Within this partitioning lies a potential performance pitfall: a server with just a small group of friends tends to send orders of magnitude fewer messages than a server with hundreds of thousands of people. In Cassandra, reads are more expensive than writes. Writes are appended to a commit log and written to an in memory structure called a memtable that is eventually flushed to disk. Reads, however, need to query the memtable and potentially multiple SSTables (on-disk files), a more expensive operation. Lots of concurrent reads as users interact with servers can hotspot a partition, which we refer to imaginatively as a “hot partition”. The size of our dataset when combined with these access patterns led to struggles for our cluster. When we encountered a hot partition, it frequently affected latency across our entire database cluster. One channel and bucket pair received a large amount of traffic, and latency in the node would increase as the node tried harder and harder to serve traffic and fell further and further behind. Other queries to this node were affected as the node couldn’t keep up. Since we perform reads and writes with quorum consistency level, all queries to the nodes that serve the hot partition suffer latency increases, resulting in broader end-user impact. Cluster maintenance tasks also frequently caused trouble. We were prone to falling behind on compactions, where Cassandra would compact SSTables on disk for more performant reads. Not only were our reads then more expensive, but we’d also see cascading latency as a node tried to compact. We frequently performed an operation we called the “gossip dance”, where we’d take a node out of rotation to let it compact without taking traffic, bring it back in to pick up hints from Cassandra’s hinted handoff, and then repeat until the compaction backlog was empty. We also spent a large amount of time tuning the JVM’s garbage collector and heap settings, because GC pauses would cause significant latency spikes. Changing Our Architecture Our messages cluster wasn’t our only Cassandra database. We had several other clusters, and each exhibited similar (though perhaps not as severe) faults. In our previous iteration of this post, we mentioned being intrigued by ScyllaDB, a Cassandra-compatible database written in C++. Its promise of better performance, faster repairs, stronger workload isolation via its shard-per-core architecture, and a garbage collection-free life sounded quite appealing. Although ScyllaDB is most definitely not void of issues, it is void of a garbage collector, since it’s written in C++ rather than Java. Historically, our team has had many issues with the garbage collector on Cassandra, from GC pauses affecting latency, all the way to super long consecutive GC pauses that got so bad that an operator would have to manually reboot and babysit the node in question back to health. These issues were a huge source of on-call toil, and the root of many stability issues within our messages cluster. After experimenting with ScyllaDB and observing improvements in testing, we made the decision to migrate all of our databases. While this decision could be a blog post in itself, the short version is that by 2020, we had migrated every database but one to ScyllaDB. The last one? Our friend, cassandra-messages. Why hadn’t we migrated it yet? To start with, it’s a big cluster. With trillions of messages and nearly 200 nodes, any migration was going to be an involved effort. Additionally, we wanted to make sure our new database could be the best it could be as we worked to tune its performance. We also wanted to gain more experience with ScyllaDB in production, using it in anger and learning its pitfalls. We also worked to improve ScyllaDB performance for our use cases. In our testing, we discovered that the performance of reverse queries was insufficient for our needs. We execute a reverse query when we attempt a database scan in the opposite order of a table’s sorting, such as when we scan messages in ascending order. The ScyllaDB team prioritized improvements and implemented performant reverse queries, removing the last database blocker in our migration plan. We were suspicious that slapping a new database on our system wasn’t going to make everything magically better. Hot partitions can still be a thing in ScyllaDB, and so we also wanted to invest in improving our systems upstream of the database to help shield and facilitate better database performance. Data Services Serving Data With Cassandra, we struggled with hot partitions. High traffic to a given partition resulted in unbounded concurrency, leading to cascading latency in which subsequent queries would continue to grow in latency. If we could control the amount of concurrent traffic to hot partitions, we could protect the database from being overwhelmed. To accomplish this task, we wrote what we refer to as data services — intermediary services that sit between our API monolith and our database clusters. When writing our data services, we chose a language we’ve been using more and more at Discord: Rust! We’d used it for a few projects previously, and it lived up to the hype for us. It gave us fast C/C++ speeds without having to sacrifice safety. Rust touts fearless concurrency as one of its main benefits — the language should make it easy to write safe, concurrent code. Its libraries also were a great match for what we were intending to accomplish. The Tokio ecosystem is a tremendous foundation for building a system on asynchronous I/O, and the language has driver support for both Cassandra and ScyllaDB. Additionally, we found it a joy to code in with the help the compiler gives you, the clarity of the error messages, the language constructs, and its emphasis on safety. We became quite fond of how once it compiled, it generally works. Most importantly, however, it lets us say we rewrote it in Rust (meme cred is very important). Our data services sit between the API and our ScyllaDB clusters. They contain roughly one gRPC endpoint per database query and intentionally contain no business logic. The big feature our data services provide is request coalescing. If multiple users are requesting the same row at the same time, we’ll only query the database once. The first user that makes a request causes a worker task to spin up in the service. Subsequent requests will check for the existence of that task and subscribe to it. That worker task will query the database and return the row to all subscribers. This is the power of Rust in action: it made it easy to write safe concurrent code. Let’s imagine a big announcement on a large server that notifies @everyone: users are going to open the app and read the message, sending tons of traffic to the database. Previously, this might lead to a hot partition, and on-call would potentially need to be paged to help the system recover. With our data services, we’re able to significantly reduce traffic spikes against the database. The second part of the magic here is upstream of our data services. We implemented consistent hash-based routing to our data services to enable more effective coalescing. For each request to our data service, we provide a routing key. For messages, this is a channel ID, so all requests for the same channel go to the same instance of the service. This routing further helps reduce the load on our database. These improvements help a lot, but they don’t solve all of our problems. We’re still seeing hot partitions and increased latency on our Cassandra cluster, just not quite as frequently. It buys us some time so that we can prepare our new optimal ScyllaDB cluster and execute the migration. A Very Big Migration Our requirements for our migration are quite straightforward: we need to migrate trillions of messages with no downtime, and we need to do it quickly because while the Cassandra situation has somewhat improved, we’re frequently firefighting. Step one is easy: we provision a new ScyllaDB cluster using our super-disk storage topology. By using Local SSDs for speed and leveraging RAID to mirror our data to a persistent disk, we get the speed of attached local disks with the durability of a persistent disk. With our cluster stood up, we can begin migrating data into it. Our first draft of our migration plan was designed to get value quickly. We’d start using our shiny new ScyllaDB cluster for newer data using a cutover time, and then migrate historical data behind it. It adds more complexity, but what every large project needs is additional complexity, right? We begin dual-writing new data to Cassandra and ScyllaDB and concurrently begin to provision ScyllaDB’s Spark migrator. It requires a lot of tuning, and once we get it set up, we have an estimated time to completion: three months. That timeframe doesn’t make us feel warm and fuzzy inside, and we’d prefer to get value faster. We sit down as a team and brainstorm ways we can speed things up, until we remember that we’ve written a fast and performant database library that we could potentially extend. We elect to engage in some meme-driven engineering and rewrite the data migrator in Rust. In an afternoon, we extended our data service library to perform large-scale data migrations. It reads token ranges from a database, checkpoints them locally via SQLite, and then firehoses them into ScyllaDB. We hook up our new and improved migrator and get a new estimate: nine days! If we can migrate data this quickly, then we can forget our complicated time-based approach and instead flip the switch for everything at once. We turn it on and leave it running, migrating messages at speeds of up to 3.2 million per second. Several days later, we gather to watch it hit 100%, and we realize that it’s stuck at 99.9999% complete (no, really). Our migrator is timing out reading the last few token ranges of data because they contain gigantic ranges of tombstones that were never compacted away in Cassandra. We compact that token range, and seconds later, the migration is complete! We performed automated data validation by sending a small percentage of reads to both databases and comparing results, and everything looked great. The cluster held up well with full production traffic, whereas Cassandra was suffering increasingly frequent latency issues. We gathered together at our team onsite, flipped the switch to make ScyllaDB the primary database, and ate celebratory cake! Several Months Later… We switched our messages database over in May 2022, but how’s it held up since then? It’s been a quiet, well-behaved database (it’s okay to say this because I’m not on-call this week). We’re not having weekend-long firefights, nor are we juggling nodes in the cluster to attempt to preserve uptime. It’s a much more efficient database — we’re going from running 177 Cassandra nodes to just 72 ScyllaDB nodes. Each ScyllaDB node has 9 TB of disk space, up from the average of 4 TB per Cassandra node. Our tail latencies have also improved drastically. For example, fetching historical messages had a p99 of between 40-125ms on Cassandra, with ScyllaDB having a nice and chill 15ms p99 latency, and message insert performance going from 5-70ms p99 on Cassandra, to a steady 5ms p99 on ScyllaDB. Thanks to the aforementioned performance improvements, we’ve unlocked new product use cases now that we have confidence in our messages database. At the end of 2022, people all over the world tuned in to watch the World Cup. One thing we discovered very quickly was that goals scored showed up in our monitoring graphs. This was very cool because not only is it neat to see real-world events show up in your systems, but this gave our team an excuse to watch soccer during meetings. We weren’t “watching soccer during meetings”, we were “proactively monitoring our systems’ performance.” We can actually tell the story of the World Cup Final via our message send graph. The match was tremendous. Lionel Messi was trying to check off the last accomplishment in his career and cement his claim to being the greatest of all time and lead Argentina to the championship, but in his way stood the massively talented Kylian Mbappe and France. Each of the nine spikes in this graph represents an event in the match. Messi hits a penalty, and Argentina goes up 1-0. Argentina scores again and goes up 2-0. It’s halftime. There’s a sustained fifteen-minute plateau as users chat about the match. The big spike here is because Mbappe scores for France and scores again 90 seconds later to tie it up! It’s the end of regulation, and this huge match is going to extra time. Not much happens in the first half of extra time, but we reach halftime and users are chatting. Messi scores again, and Argentina takes the lead! Mbappe strikes back to tie it up! It’s the end of extra time, we’re heading to penalty kicks! Excitement and stress grow throughout the shootout until France misses and Argentina doesn’t! Argentina wins! Coalesced messages per second People all over the world are stressed watching this incredible match, but meanwhile, Discord and the messages database aren’t breaking a sweat. We’re way up on message sends and handling it perfectly. With our Rust-based data services and ScyllaDB, we’re able to shoulder this traffic and provide a platform for our users to communicate. We’ve built a system that can handle trillions of messages, and if this work is something that excites you, check out our careers page. We’re hiring! Contents IntroductionOur Cassandra TroublesChanging Our ArchitectureData Services Serving DataA Very Big MigrationSeveral Months Later THE AUTHOR Bo Ingram Senior Software Engineer @ Discord MORE FROM Engineering & Developers Engineering & Developers Learning From Structure: Discord’s Entity-Relationship Embeddings Engineering & Developers Meet DAVE: Discord’s New End-to-End Encryption for Audio & Video Engineering & Developers Presenting Your App Pitches 2024 Winners! English, USA българскиČeštinaDanskDeutschΕλληνικάEnglish, USAEspañolSuomiFrançaisहिंदीHrvatskiMagyarItaliano日本語한국어LietuviškaiNederlandsNorwegianPolskiPortuguês do BrasilRomânăРусскийSvenskaไทยTürkçeУкраїнськаTiếng Việt中文繁體中文 English Product DownloadNitroStatusApp DirectoryNew Mobile Experience Company AboutJobsBrandNewsroom Resources CollegeSupportSafetyBlogFeedbackStreamKitCreatorsCommunityDevelopersGamingQuestsOfficial 3rd Party Merch Policies TermsPrivacyCookie SettingsGuidelinesAcknowledgementsLicensesModeration Sign up",
    "commentLink": "https://news.ycombinator.com/item?id=41683293",
    "commentBody": "How Discord stores trillions of messages (2023) (discord.com)379 points by jakey_bakey 20 hours agohidepastfavorite209 comments foobazgt 18 hours agoThis blog post seems to blame GC heavily, but if you look back at their earlier blog post [0], it seems to be more shortcomings in either how they're using Cassandra or how Cassandra handles heavy deletes, or some combination: \"It was at that moment that it became obvious they deleted millions of messages using our API, leaving only 1 message in the channel. If you have been paying attention you might remember how Cassandra handles deletes using tombstones (mentioned in Eventual Consistency). When a user loaded this channel, even though there was only 1 message, Cassandra had to effectively scan millions of message tombstones (generating garbage faster than the JVM could collect it).\" And although the blog post talks about GC tuning, there's mention here [1] that they didn't do much tuning and were actually running on an old version of Cassandra (and presumably JVM) - having just switched over from CMS (!). 0) https://discord.com/blog/how-discord-stores-billions-of-messages 1) https://news.ycombinator.com/item?id=33136453 reply Aeolun 16 hours agoparentBut then it’s still nice that they’re using ScyllaDB and now it’s not a concern at all right? Even if they were using their original solution wrong, I think the solution that cannot use wrong is superior. reply ericvolp12 14 hours agorootparentThe funny part is ScyllaDB still uses tombstones for deletions, though they do have configurable compaction strategies and iirc Discord uses Scylla's Incremental Compaction Strategy that I suppose solves the specific issue they were dealing with. iirc that compaction strategy will trigger a compaction once a certain threshold of a partition is tombstones and then the table is rebuilt without the tombstoned content (which effectively pauses writes on that specific node and that specific table and partition for the duration of that process). Compacting a massive partition is really expensive. Scylla defaults to warning you that a partition is too large if it has at least 100,000 rows in it. My guess is when they moved to ScyllaDB they also adopted a new strategy for partitioning messages in a channel that keeps partition sizes reasonable so compactions don't take a super long time. reply sroussey 48 minutes agorootparentGood default configurations can mean quite a lot if people don’t tune them. reply jhgg 2 hours agorootparentprevWe did not change schema or partitioning strategy. reply roenxi 14 hours agorootparentprevI don't see anything here that looks untoward. They increased their data storage by 3 orders of magnitude and decided to use a different DB system. Fair enough, maybe they've learned more about the nature of their data. But that logic isn't sound. When dealing with huge amounts of data there are going to be trade-offs. Picking a system that makes different trade-offs to an existing system is not automatically helpful. Yes you don't have the old problems. However, you are about to discover new problems. There is always something of a gamble around which will be more of a problem to your business. reply vips7L 3 hours agoparentprev> having just switched over from CMS (!) This is really interesting. CMS was removed in Java 14 after being replaced by G1GC in Java 9. They were probably running an antiquated Java 8 or 11 runtime. So that means that in 2022 they were either running a 4 year old Java 11 runtime or an 8 year old Java 8 runtime. They were really leaving a lot of performance on the table. reply gorset 2 hours agorootparentThey could also have gone the commercial route and gotten Zing with their pauseless GC. It’s been around forever and they even cover Cassandra in their marketing. https://www.azul.com/technologies/cassandra/ reply aaptel 11 hours agoprevThis whole problem wouldn't exist if we used distributed chat protocols which have been around for over 40 years (IRC). With the added benefit of having an open specification and multiple implementations. No walled gardens. And if you think IRC is too old for the modern world take a look at matrix or xmpp. How did we let discord take over is a mystery to me, or rather a tragedy. reply rollcat 10 hours agoparentIRC does not store messages, it only relays them to clients. You need an add-on solution to store chat history, something we've been taking for granted for ~30 years. IRC all but requires using a bouncer to follow a conversation from more than a single device. IRC does not encrypt messages, only (optionally) the clientserver connection. Without E2EE, you have no privacy against the server/operator, which is an easily targeted SPOF. Matrix (the protocol) is still in flux, and the implementations are lagging behind the spec. If you're not using Element, you're behind on features and security. XMPP is (similarly to IRC) relying on optional protocol add-ons for basic things, like E2EE, which clients may or may not support fully or correctly. I recommend reading these breakdowns by soatok: https://soatok.blog/2024/08/04/against-xmppomemo/ https://soatok.blog/2024/08/14/security-issues-in-matrixs-ol... 2013/Snowden happened 11 years ago. E2EE should by now be considered a basic feature, a commodity, something we should be calling for as relentlessly as we did for HTTPS. (Discord of course does not implement E2EE.) reply grishka 7 hours agorootparentTruth is, E2EE isn't a \"basic thing\". It's an add-on feature that most people don't want. It is impossible to have E2EE that doesn't leak into the UX, and most people would rather have a streamlined UX than deal with key management. It is also much more complex to have robust E2EE in a group chat. The thing that sets E2EE apart from HTTPS is that HTTPS requires nothing from the end user. It just works. And as a site owner, you just set it up once and forget about it. reply rollcat 5 hours agorootparent> It is impossible to have E2EE that doesn't leak into the UX True, but one is also free to study the UX solutions implemented on platforms such as iMessage, WhatsApp, and Signal, which all have strong E2EE and see plenty of mainstream usage. > [...] HTTPS requires nothing from the end user. Depends on how you define \"nothing\". We've collectively put an insane amount of work to bring HTTPS to where it is today. Also, HTTPS continues to rely heavily on each server operator's skills and diligence. There's also plenty of edge cases where HTTPS clients need to go an extra mile, such as containers (many base images do not include a cacert bundle), IoT/retrocomputing/other underpowered devices, and so on. There's always a cost, but it's usually worth it. reply grishka 3 hours agorootparentI should've said \"true E2EE\". On iMessage, your keys are managed by Apple. You effectively fully trust them (which seems to be the assumption in most of Apple products anyway). I wouldn't call this a \"real\" E2EE implementation. In WhatsApp, you're limited to one device logged into your account, and the rest are proxied through it. And message backups, those are annoying. In Signal, you have all those stupid backups too, and while you're able to log into multiple devices (it seems), your past messages don't load \"for your own security\", and there's also this stupid time component so you get logged out on your computer if you haven't used the Signal desktop app for some weeks (which I don't). Whereas on Discord, Telegram, Slack and other IM services without end-to-end encryption, you log in on a new device and that's it. You instantly get access to all your messages since the beginning of time, and stay logged in forever. reply brobdingnagians 2 hours agorootparentJust spitballing, but couldn't you have a new device login as three fields, username, password, and encryption key? Then if you don't add the encryption key you don't get the history, but still access the account. Then if password managers really saved all three, then would simplify it for more people (at least those with password managers). But there still has to be a cultural shift for a lot of people to password managers asking non-tech people reply iknowstuff 2 hours agorootparentprevI think whatsapp no longer proxies via a single device. On iMessage, you can verify keys now. reply saberience 4 hours agorootparentprevYes but see the group size limits on iMessage which is 32!! Effectively making it useless for so many people, the reason is due to e2e encryption. In contrast, Telegram has groups with 1000s of participants, but only possible as they don’t use e2e encryption. reply Zambyte 6 hours agorootparentprev> IRC does not encrypt messages, only (optionally) the clientserver connection. Without E2EE, you have no privacy against the server/operator, which is an easily targeted SPOF. FWIW this point isn't relevant to the IRC vs Discord discussion, since Discord is also very not E2EE. That said, XMPP my preferred protocol that checks all of the boxes. reply rollcat 5 hours agorootparent> [...] since Discord is also very not E2EE. I have stated that at the end of my original comment. I'm not advocating for Discord (merely enumerating IRC's and XMPP's shortcomings), but I would like to point out once again, that post-2013 any solution that does not enable strong E2EE by default should not be advocated for - at all. > That said, XMPP my preferred protocol that checks all of the boxes. Read up soatok's breakdown on the design & status of OMEMO. I'm not a cryptographer, but I do trust a cryptographer when they say some protocol's design/crypto is broken. reply vidarh 3 hours agorootparentMaybe for your your use. For my use, not a single thing that goes over discord are things I'd object to being posted on a public website. That includes DM's. Not having E2EE means something isn't a solution for actually private conversations, but a lot of conversations happens in setting that are not actually private in any sense. reply collingreen 2 hours agorootparentI personally think I am unable to perfectly guess today what I will want/need to have private forever. This is one of the tenets underpinning my thoughts about why privacy matters. reply crtasm 4 hours agorootparentprevNothing stopping a server also acting as a bouncer and storing messages: https://ergo.chat/about reply timeon 1 hour agorootparentprev> IRC does not encrypt messages Wasn't SILC later used for this instead of IRC? reply AnonCoward42 8 hours agorootparentprev> IRC does not encrypt messages, only (optionally) the clientserver connection. Without E2EE, you have no privacy against the server/operator, which is an easily targeted SPOF. Same as Discord. > Matrix (the protocol) is still in flux, and the implementations are lagging behind the spec. If you're not using Element, you're behind on features and security. Discord also only has one reference client, but for me even with that client Matrix/Element was not as reliable. I still use and like it, but it's not a like for like in that regard. > XMPP is (similarly to IRC) relying on optional protocol add-ons for basic things, like E2EE, which clients may or may not support fully or correctly. But if you use current clients like Conversations or Dino or the likes it does work. There is no point in counting the clients that don't support it if these aren't the reference or biggest ones. The problem here is more that it's not meant to be used like Discord in any way. Not for big group chats/channels nor for big voice chats (not even sure this possible). reply voidnap 9 hours agorootparentprev> IRC does not store messages, it only relays them to clients. Some people consider this a feature and prefer using IRC bouncers to discord. OMEMO solved encryption for XMPP a decade ago. I haven't seen it on IRC yet though. reply brysonreece 9 hours agorootparentSome (most) people want to easily talk to their friends or interest groups without having to worry about it. reply dakom 8 hours agorootparentprevI do consider it a feature, in hindsight. Learning to program by asking \"dumb\" questions was great, because chats were ephemeral, nobody cared if the same question was asked for the 10 millionth time or risk of embarrassment being like 12 years old and asking greybeards for help. Nobody also felt bad saying \"RTFM\" because, whatever, it blows over in a minute, there's no permanent record of having a harsh moment, more free to just move on. The same old questions being asked due to no search also provided more opportunities to answer those questions, so, newbies could start to learn by teaching. So, yeah, I think something beneficial was lost, even if I wouldn't go back to that approach- it's more of a tradeoff than a definitive improvement reply znpy 8 hours agorootparent> I do consider it a feature, in hindsight. Learning to program by asking \"dumb\" questions was great, because chats were ephemeral, nobody cared if the same question was asked for the 10 millionth time or risk of embarrassment being like 12 years old and asking greybeards for help. I pity the new generations for not having this kind of opportunity: the opportunity to make mistakes, say dumb stuff and goof off with all these things vanishing in a matter of minutes, hours at most. I miss the old internet: at any point you could pick a new nickname and get a fresh and clean new email address from many of the webmail providers and just start a new online life. And it was considered normal. It was actually a \"best practice\" to never use nicknames. I miss the old internet. reply sham1 4 hours agorootparentRemember when phrases like \"Never use your real name online\" used to be near universal? Yeah, this is something I also miss about the old Internet. Like, even back then you could absolutely tie your IRL identity up with your online identity, but the difference of course was that it wasn't a requirement of existing online, like it is now. Like yeah, you can stay anonymous but a) it's super difficult since the modern day assumption is that you're not doing that and b) that you're up to no good, because why would you be hiding who you are, unless you were doing something shady. And now even \"normal\" people lament just where we went wrong and what happened to online privacy. To the aware, privacy dying like this was clear as day, but I suppose most just didn't hear, or chose to ignore, the alarm bells. And now everything is logged, analysed, and associates with the people who produced the messages and other sundry content. There is no ephemera, we need laws just to be forgotten by services (as an EU citizen, I'm glad about law existing here, but it shouldn't need to be a law, it ideally should be assumed), and we're constantly getting watched by both states and surveillance capitalists alike. Not actively in most cases, mind you, but passively, with our movements, our interactions online, and just what we do, just getting aggregated into these humongous data sets of Big Data, to train statistical models on. Mostly to surveil us even harder, or to manipulate us in the form of advertisement, which can be even more insidious in some ways. I'm sure that stuff like the Cambridge Analytica fiasco could have occurred even without this destruction of privacy, anonymity, and ephemeral content, but I posit that it would have been way more difficult had people not been encouraged to put everything about themselves into services that would log them and build evermore complex models about them and their thoughts. And now this kind of stuff can be used to destroy democracies, and as alluded to earlier, manipulate for example our spending habits. And now we all wonder just where this all went wrong. I miss the old Internet. reply MichaelZuo 3 hours agorootparentprevThis approach simply doesn’t work when users are allowed to vote or have any sort of scoring mechanism. Since bad actors will also create multiple “online lives” and manipulate those systems with a few clicks reply Ecoste 6 hours agoparentprev> How did we let discord take over is a mystery to me, or rather a tragedy. The fact that you're baffled why discord took over is exactly why it took over. You can't even acknowledge that the user experience is 10x better and it's suitable for a general non-technical audience. reply throw16180339 2 hours agoparentprev> How did we let discord take over is a mystery to me, or rather a tragedy. Anyone can set up or join a Discord server. If you give users the choice between a complex open platform and an easy proprietary solution, they will pick the latter every time. reply dewey 11 hours agoparentprevI’m a huge IRC fan and I dislike Discord, but all these other services are way too clunky and IRC is really only usable through IRCCloud that has a relatively okay mobile app these days. Recently a very technical group I’m part of migrated from Telegram to Matrix and the user experience is just not very good. The apps are buggy, don’t look good, then in the new “Element” app SSO isn’t supported so I can’t use my account with it. There’s lots of paper cuts that are okay for someone like me who likes to figure it out but I’d never try to convince my friends to use it. reply nunobrito 7 hours agorootparentFor telegram refugees then maybe SimpleX is an option, except it has no bots nor other options for clients at the moment. What I personally use is the nostr protocol through a client like Amethyst or OxChat. Messages and groups can be E2EE private, or you can just use the public groups. The biggest advantage is that you are joining a bigger community of apps and services built on top of the same protocol, rather than joining some isolated island (again). reply dewey 7 hours agorootparentI recently listed to a nostr podcast and even people working in it said it would not be reasonable to recommend it for a secure messaging app at this point. Just because very early things like metadata leaking are not addressed yet. So not really an alternative. reply nunobrito 5 hours agorootparentI don't know what podcast you are mentioning or the context. Anyone can say anything on youtube. We are talking about a transition from telegram, when comparing to that platform then NOSTR is undoubtely more secure when noticing that telegram doesn't even encrypt conversations by default and this isn't informed to users. Whereas in NOSTR you are made aware when a conversation is private between both parties. Metadata is fetchable for 99% of messaging apps out there. If you'd ask me about making a more secure app then this involves continuous streaming of data, padding of messages to avoid content guessing and avoid the usage of internet as data channel. So it really depends on what you consider secure and what it is compared against. Compared to Telegram it is more secure. Compared to a piece of paper encrypted with a custom algorithm and delivered by a trusted human transporter? Not really. reply high_na_euv 9 hours agoparentprev>How did we let discord take over is a mystery to me, or rather a tragedy. Orders of magnitude better product than anything competition had at the time? reply doublerabbit 2 hours agorootparent> Orders of magnitude better product than anything competition had at the time? Nah, it just comes down to non-techy folk wanting to play/chat with their friends in a just-work configuration. Mumble, TeamSpeak were always janky, needed a hosted server. IRC is multiplayer notepad. Geeks care about E2E, and all that glory but these folks don't. And that's what Discord dishes; as did Y!M, MSN, ICQ, AIM back in the day. All discord has done is replaced those above as GitHub has replaced SourceForge. We didn't care if the message were encrypted or not back then. Why do we now? reply StableAlkyne 1 hour agorootparent> Geeks care about E2E *Some* geeks. Specifically those who are into encryption. There is nothing wrong with wanting an application to just work, especially when it's significantly better than what came before (contemporary competitors were Skype and IRC) reply pphysch 55 minutes agorootparentprevYou're just describing why Discord was a much better product. reply tannhaeuser 9 hours agoparentprevThere’s no lack of open chat protocols and federated services but those have mostly torpedoed themselves: by usability and discoverability problems, holier–than–you attitudes, and plain nerd attention wars. Such as XMPP (used a lot until around 2010 but easily dragged into the mud because XML and overengineering), Mastodon (saw a surge as twitter was faltering but then seemingly stopped to be everyone‘s darling as its limitations became obvious, among them Mastodon admins taking their audience hostage; also ActivityPub fans going around advertising it for each and everything when RSS is just fine for web sites, damaging news feeds alltogether in the process). Where spamming, or the systematic exploitation of digital communication by the „ad industry“, was killing it in the past (Usenet, and arguably the web), today there‘s also the problem of being consumed by LLMs to push non-public messaging. Though I‘m not sure the latter is really a concern for many, as developers not only are giving away their code, but their entire activity log/issues and their solutions on github such that they can easily be digested and replaced by coding assistant LLMs, git being a distributed system in the first place. reply Terr_ 9 hours agorootparent> among them Mastodon admins taking their audience hostage I was excited first hearing all the \"fediverse\" stuff, but having to hand over control of your online identity to a particular node forever felt a little bit like \"old boss, same as the new boss.\" (Yes, I know some folks are working on the identity issue.) reply nunobrito 6 hours agorootparentReminds when I joined the largest mastodon server for my country. Advertised by the owner as a bastion for free speech, democracy and fair treatment. Then in 2020 started mass banning everyone \"that went against science\" on the covid fraudemia at our country. Twitter on those days was bad, but that mastodon server sure became even worser. Nowadays found a fresh air of innovation with Nostr. No more servers with your data and followers locked inside. You can silence the people you don't want to hear, you won't hostage them into forced silence any longer. reply paulryanrogers 4 hours agorootparentprevMastodon means you can at least pick your boss, be your own boss, and take your identity and followers to a new boss. (Possibly even taking your content too, though maybe not links) reply StableAlkyne 1 hour agorootparentDid they ever address the problem of migration from a bad server? For example, a scenario where your server dies and does not return. Or a malicious actor takes over and bans the user base. Or a honeypot encouraging user account migration, followed by bans. In all 3 cases, you are effectively screwed the moment you migrate to a malicious server, or your server becomes malicious. I remember blue sky trying to address this by tying your identity to a DNS record or something, but it's a severe limitation in anything trying to be decentralized reply MichaelZuo 3 hours agorootparentprevPicking a ‘boss’ in a system where the average ‘employee’ has no credible way of assessing or evaluating them, or their superiors, and zero prospects of ever getting a face to face meeting with, is effectively no different to having the boss picked by an anonymous shareholder meeting in SF. If all of the potential bosses have roughly the same degree of accessibility… which is the case for Mastodon for anything over a few hundred users. reply paulryanrogers 2 hours agorootparentCompared to closed gardens like Discord and Xitter, Mastodon is a significant improvement. reply ThrowawayTestr 2 hours agorootparentprevWhat's stopping you from messaging server owners or stalking their profile to see they're ideologically compatible? reply maccard 11 hours agoparentprevIf you want to know why, look at the App Store reviews for discord and tea speak and compare them. Discord just works. reply elcomet 10 hours agoparentprevIRC and distributed protocols un general had a big issue : you loose history every time you disconnect reply menaerus 10 hours agorootparentIn the age we are living this starts to sound more like a feature to me. reply StableAlkyne 1 hour agorootparentYou and your friends lost history, but the server owner never did :) reply MatthiasPortzel 4 hours agorootparentprevThe other reply goes to airplanes but there are much more common ways to get disconnected. Locking my phone or closing my laptop lid disconnects me from IRC. A lot of Discord users have desktops that are always on (since Discord originally advertised to gamers), but a lot of Discord users don’t. Discord is fundamentally a very versatile platform. If you lose one seemingly unimportant, you lose a lot of versatility. Maybe I’ll write a blog post just with examples of how I’ve used it. It replaces IRC, but it also replaces Facebook groups, Skype, a lot of group texts, and a lot of email for me. reply agumonkey 4 hours agorootparentprevIt does alter the meaning of chat tremendously. In discord, often things become heavy, because we're not talking, we're accumulating information, and you have to stay on purpose so data is manageable and seekable. The few times I join IRC I know we're only here to chat, it's semi-transient (a little bit more if logs are stored) and I feel lighter. reply rtpg 8 hours agorootparentprevIs it really that much of a jump to say \"I would like to see the chat that has happened between my friends between the time I got on a plane and then got back off\"? Does that sound odd? Imagine if you couldn't receive e-mail while you were offline! This isn't to disparage IRC and friends too much, obviously there's huge value in it existing as a synchronous chat room. Just... async chat is a thing that totally happens for most people. reply serf 6 hours agorootparenta non-technical person wouldn't consider the implications of a history log with regards to security or data hoarding, they just see it work and think of it as a convenience. this value sell shifts in the mind of the non-technical person once they're told that the feature they want implies non-ephemeral data that will be systematically sifted through either for legal or financial benefit by a third party. in other words : the reason why 'async chat is a thing that totally happens for most people.' is because a vast majority of people are simply unqualified to even see the problem, much less seek alternatives or solutions to the data hoarding that they must comply with. this creates a social effect and pulls everyone into Discord, regardless of their beliefs on the matter, simply because it has become 'the only game in town'. regardless of personal preference, centralization of these kind of things is BAD for the user in nearly all circumstances aside from convenience. reply Shog9 1 hour agorootparentPlease stop pretending that \"data hording\" didn't / doesn't happen on IRC. There's nothing inherently friendly to security or privacy in the protocol; if anything, it's quite the opposite. That you can, with augmentation and diligent op-sec, get something a bit better than Discord isn't a great selling point unless you have the time and resources and buy-in already, not just for yourself but from everyone in your group. At which point, there are still better options than IRC. For decades now, the main draw of IRC has remained a fetish for conspicuous configuration, as it embodies a sort of brutalist architecture of communication software. The excuses change every few years, but the love for cobbling together a barely workable system from parts remains core. reply menaerus 7 hours agorootparentprevSure, the advantages of async communication are obvious but the crucial difference is that in that case vendor has to store your data somewhere in the data center. Reusing that data for unsolicited purposes is what many people will have a concern with. reply indeyets 5 hours agorootparentBut logs are stored on IRC as well. It’s not a part of standard protocol, but a lot of ir c-servers can do that automatically and there are boys which do that not to mention personal archives. The difference is that end-users don’t have easy access to this logs. And on discord they do (because it is a part of protocol) reply cmiller1 6 hours agorootparentprevHow about a secure async chat where the vendor simply stores a list of message IDs, and then the client requests if anyone has a copy of any message you haven't received yet from the other users in chat when you log on reply menaerus 4 hours agorootparentSuch vendor would have a hard time finding a business model since plenty of chat-services are already existing on the market and all of them have access to the data of their users in one way or another. Thus I don't know what other type of leverage they would be able to pull off to sustain their business. reply weaksauce 1 hour agoparentprevbecause the voice chat function is so leaps and bounds better than anything out there and it was primarily used for that to game in real time. the text was an afterthought for gamers. reply Intralexical 8 hours agoparentprev> How did we let discord take over is a mystery to me, or rather a tragedy. I think I'm reasonably technically competent, and I also dislike Discord's issues with privacy, data sovereignty, siloing information away from the open web, etc. But you know what I think whenever I click a Matrix link, or IRC? I just don't want to deal with it. You get a list of apps you've never heard of, some of which may not be feature-complete, some with more than one version, some which are advertised using words like \"GNOME\", \"Rust\", \"Qt5\", and \"C++\" that have no meaning or relation to actually using them as a chat app, and all of which I guess are different and would need to be tried and learned separately. Then picking and clicking one tries to open an outside program which probably isn't installed and I don't want to install because I don't really know/care what it is. And if at that point, out of the dozen or so app options it showed you, you happened to choose one with a web version like Element, and you figure out you can click the \"Continue in your browser\" button out of the four or five unexplained buttons that pop up as a result (\"XDG-Open\", \"Cancel\", \"FlatHub\", \"Download\", and \"Continue in Browser\")— You get a static screen that shows just enough message history to not be useful, with a confusing UI you can't seem to interact with, hidden behind a login wall that still hasn't really explained what in the Internet tubes you're actually looking at. E.G.: https://matrix.to/#/#invidious:matrix.org If you try to Google \"What is Matrix\"— You get pages about math. So then you Google \"What is Matrix chat\". And all the results harp on using words like \"open network\", \"decentralised\", \"protocol\", \"real-time communication\", \"open standard\", \"federated\"— Which, again, may be technically interesting if you're into that, but doesn't actually have anything to do with how it directly serves the user as a chat app and how you can use it or sign up for it. It takes way too many clicks, and you get bombarded with way too much information… To still not end up using the app, and in fact end up more confused than before about what a \"Matrix\" even is. Let's say you lose 15% of incoming users at each step. That rapidly scares off most of the mainstream, before they've even tried it. Maybe Matrix and Element are great. But it just seems like such an ordeal. Compare that with Discord. You click a link. And then either you're already in the server, or it has a single text box and a single button you click to funnel you through making an account and joining the server. It doesn't try to convince you to install a Desktop app until you're already fully using it in the web version. You get clear answers and reasons to use it if you search \"What is Discord\" or go to the website. It doesn't overwhelm you with options and then hound you with technical explainers that you didn't ask for. IRC goes the other way in usability. People want voice chat, message history, different channels in the same \"server\", PM channels, etc. /rant reply RadiozRadioz 1 hour agoparentprevThere are loads of comments exactly like OP's, and they always make the mistake of mentioning IRC alongside XMPP and Matrix. Inevitably repliers can't help themselves and spend their replies discussing IRC's unsuitability for modern IM and how it's not federated. When IRC is mentioned, commenters ignore XMPP and Matrix and attack the point in terms of IRC. (Though this thread in particular is better than average). Matrix and XMPP are the far more appropriate competitors for Discord, we need to steer the conversation toward them. I deliberately never mention IRC when I make these types of comments so people don't latch onto it and ignore everything else I said. reply Krasnol 11 hours agoparentprevUsability did it. You download an exe, install it, make an account and it runs. Just like that. Everybody can do it. There are tons of useful and great software out there. Most of it is not easy for the public. Some (most?) of it doesn't even have an GUI. People rather sell their identity and even pay than suffer through too many hops. reply Intralexical 8 hours agorootparentNot even a EXE. The web version is feature-complete, so you only need to click a link. reply Krasnol 7 hours agorootparentYou're right. I forgot about that. I also forgot all those people who came from the TeamSpeak servers. reply lofaszvanitt 10 hours agoparentprevDiscord wrapped irc in shiny paper. reply EGreg 9 hours agoparentprevI keep writing about this tragedy, but few people care. Even on HN: https://cointelegraph.com/news/how-a-web-that-lost-its-way-c... and https://community.qbix.com/t/the-debate-about-end-to-end-enc... reply philipwhiuk 5 hours agorootparent> Own this piece of crypto history I would argue that the web lost it's way as much with \"web3\" as with the platforms of web 2. reply EGreg 1 hour agorootparentI didn’t write that. You must be quoting an ad, and dismissing everything else reply leetrout 19 hours agoprevNeeds (2023) That services layer reminds be of a big, fancy, distributed Varnish Cache... they don't mention caching and they chose the word coalesce so I assume it doesn't do much actual caching. But made me think of Varnish's \"grace mode\" and it's use to prevent the thundering herd problem (which is where I first heard of 'request coalescing') https://varnish-cache.org/docs/6.1/users-guide/vcl-grace.htm... Also love to see consistent hashing come up again and again. It's a great piece of duct tape that has proven useful in many similar situations. If you know where something should be then you know where everything is gonna come look for it! reply mnutt 4 hours agoparentGrace mode itself doesn’t prevent thundering herd; varnish coalesces all requests automatically and grace mode is used to increase the likelihood of clients receiving cached (albeit stale) responses. reply loloquwowndueo 19 hours agoparentprevCoalescing and “origin shielding” tend to be more common terms for that - I’ve never heard of “grace” until today :) reply hinkley 13 hours agoparentprevNginx always more businesslike. proxy_cache_use_stale updating; reply dang 14 hours agoparentprevYear added above. Thanks! reply dorlaor 10 hours agoprevSome additional nuggets by ScyllaDB co-founder: - Discord couldn't complete repair with Cassandra. Not the case with Scylla - Scylla has a lot in common with Cassandra, from a good reason, like the LSM tree, compaction etc. However, Scylla has a unique CPU&IO schedulers which allows us to prioritize the queries over compaction, and defer compaction to the half milisecond where we have enough idle bandwidth. We have plenty of articles about it - Scylla has a new (1.5 years) tombstone_gc=repair - a much safer mode - Scylla's new architecture of Raft and tablets was recently launched and is the next big thing for our users. Watch the cool youtube video of those tablet load balancing reply dean2432 10 hours agoprevThey make it literally impossible to delete your old messages. It's a privacy nightmare and I wonder why the EU hasn't stepped in. reply Intralexical 5 hours agoparentI do think there is a balance to be struck, because directed communication means the recipients of old messages are also stakeholders, such that maintaining a consistent record by default is a fundamental part of the \"service\" they offer. The message contents are different from e.g. secretly hoovering up click patterns. Matrix had some thoughts when they faced the same questions: The key question boils down to whether Matrix should be considered more like email (where people would be horrified if senders could erase their messages from your mail spool), or should it be considered more like Facebook (where people would be horrified if their posts were visible anywhere after they avail themselves of their right to erasure). Solving this requires making a judgement call, which we've approached from two directions: firstly, considering what the spirit of the GDPR is actually trying to achieve… https://matrix.org/blog/2018/05/08/gdpr-compliance-in-matrix... reply Xen9 8 hours agoparentprevIn Discord culture, indeed, users usually share a shit-ton of PII in \"introduction\" messages from images to specific hobbies to medical information (EG \"support\" communities). The problem from GDPR perspective is that Discoed makes it impossible to delete those, since once thet detect your interest in trying to delete any of your accounts' data, they will try to get to \"anonymisize\" it. Then at least publicly your username isdisconnected from thos messages, but they can still be traced back to specific persons. Now if this also is done server side, then they would be in a situation where you'd either have to go through ton of messages or to bulk delete past messages of all to enforce the GDPR demands of an user wanting their PII deleted. EU Parliament is not a real Parliament in the sense that ONLY the Comission can propose new laws, and the elected parliament basically just votes on those. Who controls the Comission if not the people? The US State Department. Newsguard and non-Musk US bigtechs including Discord are in the same poli-financial bed of the establishment here. And they are full of previous state department workers.* Unless there is public outrage, the EU-level bodies at least will probably be owned. But Public opinion is controlled by the cyberpunk establishment that trains their LLMs & targets their campaign ads using that illegal Discord data to get political advantage. You in my view ought to \"worry\" about the fact that it's possible there will sooner or later no longer be escape from a permanent establishment, Orwell-style. Goes along with the theme that \"cybersecurity\" is the United States government level has been \"war against hate speech\" for years, and of course \"hate speech\" meaning \"censorship of internal and external enemy speech.\" Budd Dwyers if I recall correctly shot himself in TV after writing to Biden (???) that under some conditions (that became true), the Department of Justice should have \"Justice\" removed from its name. --- Most of this I hold only at 50+% confidence of being broadly correct. Take with lots of salt. reply r3d0c 5 hours agorootparentincoherant babbling reply intelVISA 4 hours agoparentprevGiven the sheer size and extent of the user data collected and processed one imagines the EU is working on a big case... quietly. reply robmccoll 7 hours agoprevCassandra is essentially an append-mostly distributed fault-tolerant hash table. If you need specifically that with high write throughput, it's a good choice. I don't understand why people use it as a database. You run into it's limitations immediately and the pain of trying to use it like a database only gets worse with scale. reply LeifCarrotson 3 hours agoparentFTA: > In Cassandra, reads are more expensive than writes. This makes it insane as a message store for a chat server to me. It seems appropriate for a logging destination for a distributed system, one where you want lots of clients to dump data but most of the time you don't even need to audit the logs, so the number of reads for a given item is less than one. This is obviously not true for Discord messages. reply Squeeeez 3 hours agorootparentNot too sure - I would have guessed that most of the messages are written once, read by the constant number of participants (say 1-100 or so) and then they disappear off the screen and are never accessed again, ever. Maybe a few people will scroll or search, or use some custom extension to load and export the history, but very rarely. reply mianos 6 hours agoparentprevAll the Casandra documentation and web site say it is a database. You can't blame anyone from getting confused. In my experience, I have never seen a project that started to use it, continue to use it after a year or so it may take a year to run into its limitations before having to replace it, with a database, like Postgres. reply crakhamster01 54 minutes agoprevInteresting technical read, but I appreciated the lighthearted jokes/comments the author threw in as well. Felt like they struck the right balance - nice work! reply PaulHoule 5 hours agoprevHow is they just can’t shard the thing? Isn’t each Discord ‘server’ isolated from the others (can’t send a message from one to the other?) Why can’t they address trillions of messages by having thousands of shards that each handle billions? reply hun3 5 hours agoparentLast time I checked the Discord bot API, it had explicit provisions for sharding. reply jimkoen 19 hours agoprevMy takeaway from this is maybe somewhat different from what the authors intended: > The last one? Our friend, cassandra-messages. [...] To start with, it’s a big cluster. With trillions of messages and nearly 200 nodes, any migration was going to be an involved effort. To me, that's a surprisingly small amount of nodes for message storage, given the size of discord. I had honestly expected a much more intricate architecture, engineered towards quick scalability, involving a lot more moving parts. I'm sure the complexity is higher than stated in the article, but it makes me wonder, given that I've been partially responsible for more than 200 physical nodes that did less, how much of modern cloud architecture is over engineered. reply romanhn 19 hours agoparentThey are talking about 177 database nodes, which is not an indicator of architecture complexity. I assume they have dozens/hundreds of services consisting of multiple highly available nodes each across various geographies. Having seen a much smaller set of Cassandra nodes used to store billions (rather than trillions) of records, I can say that Cassandra was definitely a total PITA for on-call, and a cause of several major outages. reply nicholasjarnold 19 hours agoparentprev> ...how much of modern cloud architecture is over engineered. I would wager a good majority of it is. The Stack Overflow architecture[0] sticks out to me in this regard as an example on the other end of the spectrum. [0] https://news.ycombinator.com/item?id=34950843 reply hiyer 16 hours agoparentprevAlso bear in mind that they're now doing the same with just 72 nodes. reply hiyer 16 hours agoprevVery well-written article. I'm happy for them that part of the solution was switching from Cassandra to drop-in replacement Scylla, rather than having to deal with something entirely different. reply bofaGuy 5 hours agoprevI’m lost at why a DB (Cassandra) with better write performance than read performance was ever selected for a messaging system. I feel like it’s obvious that a message will be read more than it is written (once). reply remram 3 hours agoparentThe fact that it has better write speed than read speed doesn't mean that it has bad read speed. It just happens to have even better write speed. It's like how I connect my phone to my home's cable connection to send a big file. It is better at downloading than uploading, but that doesn't mean it's not the best solution for uploading. reply SpikeMeister 5 hours agoparentprevWhile it’s true that messages are read more, reading can be cached so not every read necessarily results in a DB call. reply axelthegerman 4 hours agorootparentWhich seems something they added recently but was not part of the original design of using Cassandra reply airocker 2 hours agoprevJust wondering if anyone considered using Postgres or another relational db. I understand it won’t do multi master replication as well but it is much more stable and predictable if you give it right amount of traffic. I guess the team had to do that part anyways for ScyllaDB reply crop_rotation 2 hours agoparentI don't think anyone runs Postgress at that scale (unless very specialized sharding setup). Given the choice between using ScyllaDB like everyone else and using Postgres in a super specialized best in the world setup, the choice becomes clear. Also keep in mind that Discord is not a huge super profitable company, so for them to develop something like vitess for Postgress would not make sense. For a small company with huge data like discord, using existing data solutions makes a lot more sense. reply airocker 48 minutes agorootparentThey could use vitess, citus or alloydb. They could use read replicas for read operations and single master in a shard for write. They would get many SQL features (upgrades, referential integrity etc) for free. It would allow them to extend their business logic considerably. reply codexon 19 hours agoprev> The ScyllaDB team prioritized improvements and implemented performant reverse queries, removing the last database blocker in our migration plan. I wonder how much they paid ScyllaDB to do this before even using ScyllaDB. reply jsnell 19 hours agoparentThe article says they were using ScyllaDB for everything except the message store two years before they did the migration for messages. reply dang 14 hours agoprevDiscussed (a bit) at the time: How Discord Stores Trillions of Messages - https://news.ycombinator.com/item?id=35048410 - March 2023 (10 comments) reply tcfhgj 15 hours agoprevStoring is one thing. Performing data mining on them is another reply philipwhiuk 5 hours agoparentThat's a separate problem with hugely different latency concerns, likely done on a separate copy. reply CamperBob2 15 hours agoparentprevAlso, people need to keep in mind that those trillions of messages are archived nowhere. Thanks to the walled gardens we're obsessed with building, far-future anthropologists will know more about Pompeii and Machu Picchu than San Francisco. reply squigz 12 hours agorootparentFirstly, no they won't. That's silly. Secondly, how would such an archive work? Who would pay for it? How would it be safeguarded in such a way that it can be read by 'far future anthropologists' but not the people paying for the storage? reply geysersam 7 hours agorootparentIf we're only talking about public chat rooms, it shouldn't be difficult to archive the content of those. There are open repositories of the entire internet text content (common crawl). These scrapes are periodically repeated. That's orders of magnitude more data than all discord messages ever. So technically it's not a problem making such an archive. The financing is of course always an issue, but not because the costs are large. reply xboxnolifes 15 hours agorootparentprevI don't think every single individual message ever needs to be archived. Every text, every email, every post-it, every poke, every emoji, every reaction GIF... reply ktosobcy 12 hours agorootparentWell, considerting annoying push for \"let's resolve the issue on discord\" it's very annoying. With things like github issues you can search for a problem and find a solution. Even ancient mailing lists most of the time have archives. Not so much with all those fancy \"realtime\" :/ reply klabb3 9 hours agorootparentI agree with the sentiment but GitHub issues is not a good replacement. First, it’s also owned by a corporation and is available on the open web today because they let us (is it even scrape/api available today? Can people build tooling on top?). Anyway, this “openness” can easily be changed once the “value extraction knob” is turned. Secondly, GitHub is a developer platform, not a user/enjoyer platform. Issue reports are high-barrier even for devs. People get upset if you’re asking a random question, don’t check for duplicates, etc. Some people even get upset about issues without a PR. Again, I’m all for good open alternatives but when HN is like “you just configure Gentoo and type 30 commands” we don’t stand a chance to actually win users over, gotta accept reality before we can improve it… reply famahar 15 hours agorootparentprevDefinitely not everything, but it's still wild to me that so many products and services have all their troubleshooting and customer support in a discord server. reply proteal 12 hours agorootparentIt makes sense to me. The number of people who actually create useful open source software is so vanishingly small compared to the number of people who use OSS, it seems obvious that we should optimize for their time, not the other way around. I agree with you that using mailing lists or GitHub issues or whatnot would be globally more efficient, but if I’m working on a product, I’m going to work in the way that is most efficient for my time. I owe my “customers” nothing because they are not paying for my work. We keep seeing discord as a means to communicate about products because devs see it as the best use of their time. The fact that so many people use it should be an indictment on the alternatives, not the devs who choose to use discord. reply foobazgt 15 hours agorootparentprevSadly, I can understand why Discord doesn't have a lot of incentive to do this. Maybe the community should popularize an open-source free/low-costing bot and hosting solution for exported chat? (I couldn't find one in a few minutes of searching). reply tbrockman 12 hours agorootparentHere ya go: https://github.com/AnswerOverflow/AnswerOverflow reply ekianjo 14 hours agorootparentprevEven FOSS communities. shame on the devs who decide to do so. reply Kiro 12 hours agorootparentIt used to be IRC channels on Freenode and I didn't see anyone complaining back then. reply CamperBob2 4 hours agorootparentThat's the thing. No one ever complains at the time. reply squigz 12 hours agorootparentprevWhy do you and GP think so many FOSS projects choose to use Discord like this? reply daedrdev 13 hours agorootparentprevFor many people the fact that discord is not easily discoverable is a benefit, just like in many other messaging services reply m-hodges 16 hours agoprevFun article. Also fun to think about how many people have decided to document their crimes in these Cassandra nodes. reply cynicalpeace 18 hours agoprevIs there a fundamental reason you wouldn't use postgres for something like this? Scale certainly wouldn't be it. reply ericvolp12 14 hours agoparentScyllaDB scales horizontally on a shard-per-core architecture with a ballpark throughput of 12,500 Reads and 12,500 Writes per second per shard. If you're running Scylla across a total of 64 cores (maybe on 4 VMs with 16 vCPUs each), you can get up to 800k Reads 800k Writes per sec of throughput with P99 writes ofYou will not be able to get that performance out of Postgres if writes are batched, I get this and higher performance from postgres. If 800k on 64 cores is Scylla's best result, it is not that impressive. But also you probably mean writes/reads to indexed table, then it is another story. reply ryanjshaw 12 hours agorootparentprevOkay but this is where I get confused. Why does Discord need a single database system when discord servers are independent, right? And the volume of traffic per Discord server must be human-processable or what would the point be? A Discord server doing 800k writes per second makes no sense. So why not a RDBMS per Discord server, and if you want to ship all that out to a warehouse for analytics you do that as a separate problem? Or is it that spinning up a Postgres instance per Discord server ends up being significantly more expensive than these mega distributed database systems? reply jhgg 12 hours agorootparentThere are ballpark of a few hundred million discord servers... do you really want to run that many Postgres instances? And even so what do you do about DM/GDMs? Easier to just run one big mega cluster for messages. reply ryanjshaw 12 hours agorootparentOkay so the latter then - economies of scale. Surprised to hear that few hundred million figure - I thought it'd be 1/10th of that at most! Wow. Although I did expect there'd be a very long tail, and you might choose to host a bunch of servers on a single RDBMS, at that scale yeah it wouldn't solve much. Thanks for coming back to me, appreciate it. reply Drew_ 2 hours agorootparentprevApple kind of does something like this with iCloud however their per user \"databases\" are only virtual: https://news.ycombinator.com/item?id=39028672 reply justnoise 17 hours agoparentprevI'd guess that Discord's storage systems lean towards processing a lot more writes than reads. Postgres and other databases that use B-tree indexing are ideally suited for read heavy workloads. LSM based databases like Cassandra/Scylla are designed for write intensive workloads and have very good horizontal scaling properties built into the system. reply Aeolun 15 hours agorootparentWould you actually have more writes than reads? Are messages read by fewer people than post them? reply sadeshmukh 14 hours agorootparentWhen you send a message, afaik it sends to all people looking at it at the time. So there is no read when in a conversation, and maybe the reads are batched when reading multiple. reply jhgg 12 hours agorootparentprevRead traffic is much higher than write traffic due to mobile clients needing to sync chat history more often as their sessions are much shorter lived. Also search queries execute 1 query per result. And don't forget people doing GDPR data dump requests. It adds up. reply cowthulhu 18 hours agoparentprevI’m not sure if Postgres would have enough horizontal scaling to accommodate the insane volume of reads and writes. I would be super interested to be proven wrong though… anyone know of a cluster being run at that scale? reply riku_iki 17 hours agoparentprev> Scale certainly wouldn't be it. vanilla postgres can't scale to such size, you need some sharding solution on top, which likely will be much harder to maintain than ScyllaDB.. reply pavel_lishin 19 hours agoprevAnyone else reading this and being quite happy that they're not working at this scale? reply wavemode 18 hours agoparentI don't mind scale. I mind the bureaucracy and promotion-driven-development that comes with working in a bloated engineering org. reply pm90 17 hours agorootparent+100 Many companies have products that operate at “scale”. They manage to do so with pretty boring techniques (sharding, autoscaling) and technologies (postgres, cloud storage). Because of the insane blog driven tech culture, many of these teams get questioned by clueless leadership (who read these blogs) and ask why the company isn’t using cassandra / some other hot technology. And it always causes much consternation and wastage. reply rnts08 9 hours agorootparentAnyone wanting to introduce $new/$other language, database, library, deployment system, build system into a large enough system that doesn't solve any actual problem is a nightmare for someone working at this scale. I don't mind the scale, I like it. I don't like having to fend off questions and complaints why we aren't deploying the latest shiny new thing in our core this week. reply secondcoming 2 hours agorootparentprevWell we use Cassandra (actually ScyllaDB) because Redis no longer cut it. reply Twirrim 18 hours agoparentprevBut that's where the really fun and complicated problems are. The ones that really make you stop and think, and not just think, but be creative. 95% of the work is still the same \"treading in well trod paths\", same old same old tech work, but that 5% is really something. reply Olreich 6 hours agorootparentThis was a “double-pump” migration to a faster database and building a caching service. There’s nothing particularly fancy or creative about their solutions. The migration efforts and working out issues with the reverse table scan were probably way more creative, but they didn’t get into that unfortunately. reply pavel_lishin 6 hours agorootparentprevI think I can understand the appeal, but it's just not there for me. I have enough complicated problems outside of work, some of which are even fun to solve. reply twelve40 6 hours agoparentprevI'm happy I'm currently not working at this scale. I'm not happy when idiots (including one of our self-important ex-Google VP's) set this as a benchmark for backend interviews (for careers that 99% likely will never come close to such problems). reply est 16 hours agoparentprevI am happy that I dont have to deal with this. I am sad that my business aren't as big as this scale. reply Aeolun 16 hours agoparentprevHonestly, 77 nodes doesn’t sound like a terrific scale? The more I scale things up, the more I realize that the tone of the problems doesn’t really change. You just get more layers to your data structures. reply mystified5016 19 hours agoparentprevAny time I read anything about any web-adjacent technology I'm incredibly thankful that I don't work anywhere near that industry. Embedded can be complex, but web stuff is just a Lovecraftian nightmare in comparison reply milesvp 18 hours agorootparentI have stared into the abyss and seen the eyes of cthulu. I am much happier writing embedded drivers than I was trying to make sense of why previous devs thought it was a good idea to move bounded tunable server side api calls to the client, allowing it to effectively write arbitrary sql calls across multiple databases. reply bdcravens 17 hours agorootparentFortunately the web is starting (very slowly) to return to sanity, pushing back towards the simpler server-rendered pattern with Javascript being relegated to specific use cases. reply Aeolun 16 hours agorootparentI really like the client rendered UI part. It’s a lot more efficient than sending the whole page again every time. reply bdcravens 15 hours agorootparentWhich is precisely what is meant by specific use cases. We don't have to throw out the first 25 years of the web and reimplement all of our business logic in a minified JS blob. Even when client side code is necessary, the trend of pushing rendered HTML rather than JSON that must be parsed and rendered keeps us as close to browser primitives as possible. reply Aeolun 14 hours agorootparentWhy would you implement the business logic there? You can still keep (most of) that in the backend. The client just does orchestration. reply bdcravens 3 hours agorootparentOnce you move beyond basic CRUD business requirements work their way into the UI. For instance, making fields read-only based on access level. Adding additional form fields, etc. Conditionally hiding and showing entire portions of the UI. All of which requires you to either pass around UI-directives in your data or implement business logic in your client code. Better to just ship HTML, and if we're worried about full page loads, just use one of the many over-the-wire options to only change small bits of a page. This is before we get into having to implement application primitives like authentication on the client, and all of the state management that goes with. The absolute amount of scaffolding and plumbing we've built up just to save a few ms is always worth questioning. Doesn't mean the answer is no, just that we need to ask the question and not assume the default is carved in stone. reply gonzo41 15 hours agorootparentprevBut you can cache the whole server side page and the cost is once. Whereas if you have the client side do the render then every client wears the cost. reply Aeolun 14 hours agorootparentThat’s your generation that happens once. The browser still needs to render it. Sure, rendering it on the client may cost the client a bit more, but the client generally has the computational power to spare. reply bdcravens 15 hours agorootparentprevWhich becomes a far more important issue when dealing with bandwidth or CPU constrained devices, or artificially imposed constraints due to data usage costs. reply iknowstuff 15 hours agorootparentprevYou usually can't because of users who are signed in needing slightly different pages etc. reply bdcravens 15 hours agorootparentWhile not as fast as a purely client cached page, the server can selectively cache content, even when some bits of the page are dynamic. reply asynchronous 15 hours agorootparentprevWe can also cache some of the dynamic JavaScript, depending on the scenario but your point stands. reply qudat 18 hours agorootparentprevIteration speed is significantly fast on the client. Perf is an afterthought — for better or worse reply swyx 17 hours agorootparentspoken like someone who doesnt deploy clients at discord scale? the 200 backend nodes surely update significantly faster than the hundreds of millions of clients. reply artursapek 17 hours agorootparentprevSounds like a fun time lol reply qntmfred 5 hours agoprevi usually start projects with postgres this days. i have reached the tens of millions of rows threshold without breaking a sweat, but is there any good reason postgres can't handle into the billions or trillions? any well known products at that scale that are known to use postgres? reply bastawhiz 1 hour agoparentPostgres can pretty easily scale to billions or trillions of rows. It forces you to think carefully about how you query that data, though, and I think most beginners would find themselves in deep trouble jumping into the deep end. reply qntmfred 1 hour agorootparent> most beginners would find themselves in deep trouble jumping into the deep end probably true for any database platform. postgres probably easier for beginners than cassandra reply mxscho 4 hours agoparentprevJust the raw amount of data is not enough metrics to judge whether postgres is \"enough\". They seem to value horizontal scalability e.g. in terms of write throughput, which is easier to handle with something like their solution compared to postgres. reply tonetegeatinst 19 hours agoprevMy love of embedded stuff is growing. I'm self teaching C and assembly....to get better at low level programming and interactions with hardware but it all seems much simpler than the big data systems. Granted I'm sure it call be broken down into steps and issues to solve like any programming issue but I'm happy focusing on low level stuff for now. reply SupremumLimit 16 hours agoprevI see more people mixing up past and present tense randomly, as in this post. It’s confusing to read. Is the concept of tense starting to disappear entirely in US English, I wonder? reply GrantMoyer 6 hours agoparentThe post appears to consistenly use past tense for things that were true in the past at time of writing, and present tense for things that are true in the present or are always true. So the use of tense appears to be valid, though not following commonly prescribed style. reply phist_mcgee 10 hours agoparentprevYour question is rude and I hope you know that. He's walking us through the process of designing the solution. Why wouldn't present tense work for this? We're discovering things with him as he takes us along for the journey. reply nerdponx 11 hours agoparentprevNo, what a ridiculous thing to say. Storytelling in the present tense is not new. reply KaoruAoiShiho 17 hours agoprevDid they go with ScyllaDB just because it was compatible with Cassandra? Would it make sense to use a totally different solution altogether if they didn't start with that. reply jhgg 17 hours agoparentYes, we wanted to migrate all our data stores away from Cassandra due to stability and performance issues. Moving to something that didn't have those issues (or at least had a different set of less severe issues) while also not having to rewrite a bunch of code was a positive. reply ericvolp12 14 hours agorootparentDid you guys end up redesigning the partitioning scheme to fit within Scylla's recommended partition sizes? I assume the tombstone issue didn't disappear with a move to Scylla but incremental compaction and/or SCTS might have helped a bunch? reply jhgg 12 hours agorootparentNope. Didn't change the schema, mainly added read coalescing and used ICS. I think the big thing is when Scylla is processing a bunch of tombstones it's able to do so in a way that doesn't choke the whole server. Latest Scylla version also can send back partial/empty pages to the client to limit the amount of work per query that is run. reply gigatexal 10 hours agoprevWhat a fun write up and a huge confidence building post for me in ScyllaDB. reply yas_hmaheshwari 7 hours agoparentDoes this article imply that don't use Cassandra. Use ScyllaDB when you think you want Cassandra reply akimbostrawman 12 hours agoprevin cleartext reply jaimehrubiks 18 hours agoprevUntil they don't, or they can't, and they need to start deleting. (Not trying to undermine the engineering efforts, or the welcoming engineering blog posts though! I really think all these is needed) reply dobin 7 hours agoprevSo the TL;DR is: Cassandra and ScyllaDB have bad performance when reading. So they put a cache in front. reply jhgg 2 hours agoparentNo cache. Just read coalescing. There is a big difference. Coalescing just ensures that while a query is executing if an identical query arrives, rather than sending the same query as an already executing query to the database it will wait for the existing query to complete and duplicate the result. If after this the same query arrives again, it will be issued against the database. This means we don't have to deal with cache invalidation/consistency issues while also being able to handle thundering herds, for example a large server pinging @everyone and having a bunch of people click into the channel or launch their apps in response. reply 7bit 11 hours agoprevThe blog posts shows how great the technical expertise is at Discord. I work in IT and in my company devs are so incompetent, they don't even know how to create an M365/Azure dev tenant and constantly request *.Read write.All to our production tenant. I'm so envious! On the other hand, the HOME/END keys jump to the beginning of the input field rather than the line and the frontend devs are unable to fix this non-default behaviour for years, which makes it a fucking pain in the ass to use the Posts feature within a Discord channel. I believe the budget for the backend geniuses meant that frontend had to be juniors only. reply crop_rotation 1 hour agoparentHiring good is probably the most important thing for a company and also one of the hardest problem. I have seen a team of competent engineers outperform their sibling teams by 5-10x as long as each member of the team is good enough. Just 2 bad hires will slow down a team drastically. One terrible hire can do -5x work of a normal engineer. reply fastball 11 hours agoparentprevIn their defense, Azure is terrible. reply andrewstuart 12 hours agoprevWhen you get to scale like this, I wonder if the access patterns of the application and its data might be best served by a custom data retrieval and storage application. I may be wrong but I just wonder if efficiency is lost to the generalized nature of any data storage system. The other question that comes to mind is, to what extent have the developers made a systematic effort to optimize how data is stored and retrieved? If you’re building a gigantic back end system and simply accepting that the system load is what it is then you might be missing a chance to dramatically impact the size of the task of managing that data. reply lyu07282 8 hours agoparentThey did give one example, if someone does a @everyone in a big channel, they specifically optimized their architecture to make that efficient using their custom data services. reply pawelduda 17 hours agoprevPretty fun read, even tho I'll never work at such scale lol reply znpy 8 hours agoprevInteresting read on one had, a bit disappointing on the other: when the solution is just \"we moved to this other product\" it smells of lack of serious and rigorous investigation. Also, having worked with the JVM and with GC issues I don't buy the \"GC problems\" point: there are a number of improvements in recent JVM release, the main being ZGC (and generational ZGC in particular). ZGC is great, I've personally witnessed sub-millisecond GC pauses (and i mean sub-millisecond stop-the-world pauses) on machines serving millions of requests per second. Garbage Collection is largely a solved problem in the industry as of today, thanks to ZGC. Other than this, also comparing latencies for machines with 9TB disks rather than 4TB disks is a bit like comparing apples and oranges: we will never know if issues at the storage layer were affecting tail latencies. Were the node having, i don't know, filesystem fragmentation issues? Does the 9TB storage configuration deliver higher iops than the previous 4TB storage configuration? Is the same kind of hardware underneat (same disk type? same disk bus? or are we talking ssd vs nvme?). As somebody that's been doing performance engineering for work, this piece is a bit appalling. Glad to see they've solved their issue though! reply ozgrakkurt 4 hours agoparentGC is a problem, and it always will be at some level. You can improve it but that doesn’t mean it is not a problem. Memory allocation and management is a problem even in c/c++ problems if you want to optimize your program, there is no universe where gc is not a problem reply zombiwoof 19 hours agoprevI think it’s annoying they interview engineers like they are Google and reading the blog they made it up and learned some basic “pitfalls” as they went along reply xyst 14 hours agoprevHaving used discord in the past. Most of the conversations were just shit posts. Nothing serious. Why even bother storing a trillion messages of garbage in the first place? reply huimang 14 hours agoparentMany people within niches have discord servers for researching and discussing specific things. There is a large wealth of information locked away behind them that can be lost pretty much whenever discord decides to start pursuing different monetization strategies. reply adzm 14 hours agoparentprevBecause that is literally what Discord is for reply squigz 12 hours agoparentprevThat sounds like it was a problem with the communities you engaged with. reply jerryspringster 11 hours agoparentprevHow do you sort the good from the bad? I'm sure most of my conversations were shit posts aswell but some weren't, especially when it figuring out how something new worked or how to fix a problem. reply hypeatei 14 hours agoparentprevThat's why I laugh when people say discord content needs to be indexed on the web so things are more discoverable. 99% is garbage and the useful messages are scattered across channels. reply retsibsi 10 hours agorootparentI'm not trying to be a smartarse but doesn't this describe the entire internet? The good stuff is rare and scattered, and that's why search is so important. reply hypeatei 4 hours agorootparentAt least with forums, there are dedicated pages for whatever is being discussed. Discord is just a collection of channels with topics being split up across multiple messages and shitposts in the middle. reply jcgrillo 8 hours agorootparentprevJust wait until the LLM bots start arguing with each other on discord ;) reply aurareturn 14 hours agoparentprevHow do you differentiate shit posts vs quality ones if you’re Discord? reply robertclaus 13 hours agoprev [–] Very cool that even at this scale the right vanilla SQL database just works. No fancy document store, map-reduce, or GPU implementations needed. reply salomonk_mur 12 hours agoparentHow is ScyllaDB (the solution used in the article) a vanilla SQL DB? Its the complete opposite! reply melodyogonna 10 hours agorootparentThe syntax is SQL reply biorach 6 hours agorootparentThat... doesn't necessarily mean that it's a \"vanilla SQL server\" reply hinkley 13 hours agoparentprevIt annoys me sometimes how effective B-trees are. Every decade has some cool breakthrough in compression, and a handful of other disciplines. But OLTP databases are still basically better B-trees. reply menaerus 12 hours agorootparentLSM trees? ScyllaDB is LSM-based storage engine. RocksDB as well. reply asjfkdlf 4 hours agoparentprev [–] Aren’t they using a NoSQL store? They migrated from Casandra to Scylla DB reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Discord initially used MongoDB for message storage but switched to Cassandra for better scalability and fault tolerance, which later led to performance and maintenance issues.",
      "In 2022, Discord migrated from Cassandra to ScyllaDB, a more efficient, C++-based, Cassandra-compatible database, reducing nodes from 177 to 72 and significantly improving latency and performance.",
      "The migration involved dual-writing new data and using a Rust-based migrator for historical data, resulting in fewer issues and better handling of increased traffic during major events like the World Cup."
    ],
    "commentSummary": [
      "Discord transitioned from Cassandra to ScyllaDB to address performance issues, especially with deletes and garbage collection (GC).",
      "ScyllaDB provides better compaction strategies and performance, despite still using tombstones for deletions.",
      "Discord maintained their existing schema and partitioning strategy during the migration, emphasizing the importance of good default configurations."
    ],
    "points": 379,
    "commentCount": 209,
    "retryCount": 0,
    "time": 1727561263
  },
  {
    "id": 41683306,
    "title": "SpaceX launches mission for 2 NASA astronauts who are stuck on the ISS",
    "originLink": "https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"apnews.com\",cType: 'managed',cNounce: '16763',cRay: '8cae3960bd191042',cHash: 'd90130d8a699e86',cUPMDTk: \"\\/article\\/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b?__cf_chl_tk=DNbG9FP0clBDGaEY6ihq0ckJTyBFQckWeCZI7KW_XVU-1727636510-0.0.1.1-4927\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '390000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/article\\/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b?__cf_chl_f_tk=DNbG9FP0clBDGaEY6ihq0ckJTyBFQckWeCZI7KW_XVU-1727636510-0.0.1.1-4927\",md: \"WCe_Qlb_suKT2SPdCSXK8vW3WNC6lmwlyw1rxJ3hXe0-1727636510-1.1.1.1-1NXA.JNfRvsWRgOHHA7NaKBlKZR4ojo3pu2V9urH0B6fXSUuvGPOf6tCFFna_kJ6c5rqe5BaKCZBCx6YEPfF65EuLysEmxZMWx6M7HYgSr9DAX4J4.5aCewvO5CRDwXB_m8vou4DwR7c07ZwuO_C5zWjbqb9ZWy3eOCz53uueP3zAi4cDut7qzlv6nCja3wWT4iW84VFV45bAnyk4nOWbgFKRftw3WOVdSYDOspkwX8uPYIv14K4PcloPonKvUTK80.dllNxw277BJ0n3GlyBc2TnKDGi2nCh3PmbXN5dEwMd_aKgdoAaOXwtA0t7UsZ_NcU_OKyJXo2sBg866YUXOWVwbE8Yg77.foQyFTXXlNeW7KPkOW.Z8bLwEneHInCS979Q4aNSVXJ64ltlKyZ99TdcxvVJYYHktB0dn3VLvzS7ndzuy048XIisPKxHz_UJirZkLHHdgNLqZS_0Is44Eu6Foa2PDvHglMMYQd0ovGyvYFjMyiCjtCuAF2swTccbGN.cP_nXinf_GUjWL2VR_tAEE0pWkT4cVOKu4wCH27LdqKSAcOasZn_4rt3c_ESbz_ky552woEAEDsele6XY2P847_5aGYtJRMIzZzch57RgxYyE1pfG5rQRVNi83Uzemt8IKmXg7IyfPd8RvWS1ukxGiv3x9D06qQ.xoBRc4V9Io6DmMwOiRLUUtu0xvpSjCbgwA.ZwOOUEACzbD97p4rTUeax4qSokupReTcCV6vvuHYj1rCdVm4YkitfDJ2AzSCIugKU0fGSWkMfz69KUvb1qutLOhdLiHvfBsOnY9OEarR1M.rYmonndb1Df.Hxj2uUNqbUbvCLeHFDejb6yrA1D2yFZA10hA_JKpcQtKt9U3d1pTgeIlOj8F.XRTeIp9Clf0EfGwMfe543DXbDSCrM2ZsSm3wzSfhCvAa0YZ8nAhDciDNgMduOYGz2.L1ENLAdqqXcp8Ro79pqxwu53xk7NghGk5C9ZybT01o.KK1xKc7esB5yJZ1RQ6pwkbBiUm8MLVDiMdiGhl8f9cQDnjXRJ26MfdTd8uwW3CtUYRnsp9MOdDybxwQ1NK1gIUDVw8sUe_Lx9W_W8AkGFgpGzKLMql.JKHm08Q10cg2OUoCfjF.GdvtZ4bg85YNzggnVbqEOFFfA6b.gWXAJq05mjp1APSw063ENgqM3Klrcnd4eh48p9GybknPPLLNfDctTglr3hGrV9vqqBB_jcFtxtqnas8I4WhdMY1.r6orh7l4J3zY_Al8IHo.1e0tknMusrVFVGJqTloMlqraLnZkEY1JicM8.hPRaw61wBhcdPeRjfYFl8YttS5cbH66eoVj6CyboKIANNMf31thxd2qayPMDVpA.gRtNy761PdA9Xc3aJO5i0cd2bH5OKsKb8CgKkDr16BtZEtVvFu8LiuQzdvVmdAIrrisWRVXY1Nn4CnZOcHkwCYrWuxsLrLQnQblx7Zq7CEQu4IsCeggGPw7KXfnCoZimMd2FlDWmO9f17D4eZyudJ_TK.2kSkyBSz7uXpp0svITsneZTqEznlunCpws0SDiV6n15s29cBnTEjQrPftgZSNm7Aw1F9N2eXJMh6DeVIJkk8yNivQg9BQVyI184BxiGS_RJTlBBsh4pcpKlv2yFGSeqOJaN9J.CZeD4OmPCnktWhpgkZYzZuINCUFc2qs_chexuXoW6VROvZWiApmtPKoyw_SySGZDwjTgMrTs7OITRWmZIfcf5OXKzYxG6ljBYsLDcFYUtHe7prLgM9pcJeydmNvzibFJgIQBs9z8yRl5RDX3EHjPyl75tQcJmxstJb0GWJO1aPzPVsWJw_TJwu6V_XExxW6Y4HYrh.HaZb9Eud_hJZgMV8tkcIoFaVR.Sb9fZzQ_CKgjhFIAyiG75D0iJqTM2zba9t8wyPe94bMOFhrpHMI3gGFsOCyBgleQMDC79pm87NnEale7YYrpTkuq_.iMo0r7Kyyit288T2e4xBXnkR9OYnAMEtWUh5nRbWOFA5qaaHJaP6gXhn2PhXyZLd7pDl9qORiJyYlvKRzIUV9VaUQOFeLjFDU3XFwnS_ntNqxstpk_.lIPeSzSaW7WMujDTtEXaQ.A6i.SDdssG1jHzcUiPaMDBl0ZwvE_Ha8litNiNLUuln50xsOh3WOc4twsBJn.T1Faop5nICC8zKfZj6S1v4MlfNPwquVQJAGH1Q6l.nDmfeoVaJwcIg9oKJjbZLYI4mXbmp50P517xEY2M3.EcDKRQ0ZN3l5CkT6bo2FhVJwK.1FLR4T.OOb1kLDpXe8X_iErYTrFinIosclJoo60ApdP2HA_8utWCzIEVGsBpadUlysNRgOXM3VuAAgY6OCTI2sES4.rkNpEAh9bMBQyF40t0S6QPnC6QFbxJ14.0PautyE9.pAffTd2hhCkqtQRTUxTfSA8MmlY.V8aNa7tbLdz7zA\",mdrd: \"_i0YDwRtHmX9xnnHAoKXT0vRcE6F6zPnIv5ZZxoYkmI-1727636510-1.1.1.1-5nnAFZbD.xgCiXbsuyFA3eiLnmlvkLDPmrBeTvLo0L1ERyn6f3c0Ox0FjsSTOtn3ZMPn_DzunbjtNqoa3yHlM20AWR2doNBzNsuKGyC1S1PcczdiMXmtId46mnsDKzch_wyjS7RdSETuC_k87OKs_WwOLS7evlFzeKwZGI8CukfeaYIeGFIEyWATWFw48vhn.NBBNB7WfB7lcGwV_8UccjZboBIS5GYnyXcu9nJGY1fX5HRpDstdJLpJCWtJ9kRs.6Bq8yqRaq9AwGuh6gs.CpComZh8FI0E0OALgsR1F1gXiLTSdi8eiZLG1h3LrYbiG_GjZ1G5rVSwa9LIyZ6RXORz3ZwBHZFa4.9PxeA4epLBqWbdIHEj.d_yA3gW8BiosSM85pGkzDhy3p0XelciNZcqxQKHQfsE_cUI4HZtv2xJSLcVFIGpz_4ULs9uvGP0OX2SpiWR4FZ6eEysLYcRZk9C.PnVitPjc6xJ9_KsVqMeChtWeFGFC_uYtaKmQ34O2L1DstEvBupvR.adp.Yv.siucaBIv42kftLvGfxmhNDjKsJfVa.txpketisp4VVp9LHD7CjA4yr.K9jGff4sf_2fDdJoHhDdlVYvJOviQv02Z73JBs3lUxFb9nBOJrE47DaqK4l.KdMrx9rUhIMNNnIAVIvwL3XAGMIPbncgjGx2jwrPfiEevli0G8KKYkxlZW.oc7EWpG7O4l6th42AIrhYsc.pjYFDuNVnxrqbwdtcsa2s1Ubjk3ZIPD49MsVRqro_IaSgu6i7GgubisUs.NS6xBvzvSFMnL41xlajZgQuKv6_xb9PkGh2ZHXjG8GnY1i6xRCYbtCvUo1IksE3HX_AQauQ3Htnwys2lInZbhDv8fmSykoMTY1HGDP8v9bnmkgpcZGVIjwqwLgdJ46V68rCloqGGUy1O6na.xwa5Y20s9c460s.D5FYWBOukINSbWTtDwo214IghNOn0SmmOmnXAnkReOwPZ4gPGkjdrRpk9XKpLtMhOTaMhWUg4T7imXGEG2DovDgdU0fJpJDIlmxujXFuBvzr8KCwP8.APDDme8X4x1aaQxij_XUUSgo1DmN_e7mnboglZdgTUaSZlST2v5MDnUJmzDgaW7A9gAj8sYhkva2jpkAg.Dmxm4JdlR2aXkJx_YOYYe6iOy5XcmB_g3IN5Ep3i5yyU7TBkxjLnSrQb4d6e2oYZAoa3rKhuTXGeXfKwoMN.miYj27ls.Ywv2hsDh5vO90IOESh8S3vWptf0QzcQU_kHMAee5aNke_gabktJEfThsDl.jJ9Pm5l5UmG.Bqcif.Ziz5MreHAiq47Ow1._QanhK5ddEbeV9QxMCXoqDn4kpF3t.D8xIsbwDdBiLzOAJbYFftTERmJL_ZZOOhR_V1guepdxFOLZKY0Z9GVXefWEukjSkzb7sWGB1sZbaDQPGxLsKq02qM7ACRybJ6FT6B.BgSnhYu0wjkDBv5iwnjU4Bcw4KUVUNNoykt1AbQdipTGAtd6nmMnjTrTdO2yyMG13bfF4YGT3_0oXV3JwqV2LmwUB9kIpFQLcUeKglh8BbrJMsGhhkdyGb86cAO0tS29tqhD56dVKey6qJL_cAPqu4le.lcGbjMim6Oxu3YBFSKhZPD4rbeOtgdgp_kWqQIwHG2eLlFOHmtiqAZ9OFIYxvgCKr9e7wx_7S2kHXkA2NvGRKtzCblWtE.DF9FdlKWgz1G8.MxaBB9vTYqkYE9ZdVZRk0M8DWKJ8RgUsMyRoZJdMrx99oh.ieqko8ZmDzrWG6bgp6qNRpIHJpbFwVO3kv6XqADGKrzRXrKnPPQwouUU9VTjGiPkHwJdNNQA3g_AI1lInbpLDb_L_gDLFmNVU9Ea_WUR9A192co4Kft4dsOBWVz2Hzb.hZxs2rpmGLE7n4Nio9jHsxpIqvV1SMeq9.QQG5qWA2rd.gFqqCaimgf.Z3h7M5BtGg7ve0H.zeazeGdvim1Coq0oKuqq3JafzxcIzJ4NsBctt_68kkXoCuwJSePSPwS8CS3nFHozTgCBVLI0BCF4eosF8CVQ4Z8YUrm_L18YuQ96sjnmILk5JpaEChnwepyo4_nv0yBCSC181aFV8ENNhCRr_uJLLjWh8eNlSDgdSoWfIaTeqJPZEG3d2oY9W4cv87_UqX9sf6_yhiRJaxluuDUZDdPaquI9LtnL3XT3ZLS8uTTo6xDlK7jBb.AKc3xht8UuqiN24WeM0OclRkbi8URr_.52_EBqGfKRy_Rk2Crl_FVwRQ083jBXdAqNVSyDLq9xOwAY74YSggIob7G5pp85I8yHfW2F2xnqikWtr8RPV2rz63HT_cu62hXtqTY\",cRq: {ru: 'aHR0cHM6Ly9hcG5ld3MuY29tL2FydGljbGUvc3BhY2V4LWxhdW5jaC1ib2VpbmctbmFzYS1zdHVjay1hc3Ryb25hdXRzLWUxNzlkMGRjNmM3N2QyMjQyNzhmZDA0MzAxNDhmZjhi',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',d: 'j7wUG6/ycOMOtZCL/5P+ytv2s1iSfsEWFoq5siMJywFQfpVWgZ6MPkX80id1gCQ12ZaMcQTRDGQQfJcL3JOYIrkPqgVGg+yRDNBzjcFKcQFy26siI1LJ783JrAGdsQ+WGF+HzLaRhqm2vjRxxxMFmN1IMA0TdzKfpMLArZ1bYp8EJeXMy5MLwCOjAhLTjz/E+1W11ztr+9e9LH9TTHX1D8Q7PWWzqQBRCPOjfCCg5XRnQPvXZEuLm8LB32Drw622AVzzw7PtKOTjtR2KGYG88BtY5AGMge28DP4uJj/JfzUbDZK9wSitfcPRVtWKwluoDlgQW7YgYI7oC6cEuOTcNOncIwzf/dGT5mXOeU2IhWfQhtIOTnDLG3v7JYBLlTeY2wskmUSZ26K0hJmJAOaWv/eEv0WVvQM4iG9ToQyDhWa5Gqb/eo/mDQRp+pdScLFvD9N9qIXSq/Y8LOxSdjU8aecqeviqtYZhuSeiOglxfXoNMYI10Pbjq4Sv7DdQo84fH+cFS2w2+26iocy9/+kLeQLUvgl6FMhFG6V6cRY+AH77XEVglCcWVBlj+hn8vwWFYPZuaLXlkGd0uu9xTQeXCA==',t: 'MTcyNzYzNjUxMC4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: 'xB65pyp7gfCJ6LCVnKVF4btt/9oJa/A2/Fsga7dhOtM=',i1: 'hb/U5C9Q6hYjBZuwFJksaw==',i2: 'E5jjBhFjr6PB1ZEJeQ8kDg==',zh: 'epBc2OQ/Ahg2gj3LykPX5hFBK2QjoN7dhK2pwCoeLUE=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'InkYRNsscAcxVbWf5MVSqiZFW1/kdqOnZTeBMj91/8w=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8cae3960bd191042';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/article\\/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b?__cf_chl_rt_tk=DNbG9FP0clBDGaEY6ihq0ckJTyBFQckWeCZI7KW_XVU-1727636510-0.0.1.1-4927\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41683306",
    "commentBody": "SpaceX launches mission for 2 NASA astronauts who are stuck on the ISS (apnews.com)334 points by JumpCrisscross 20 hours agohidepastfavorite309 comments perihelions 8 hours agoThere was an anomaly in the second stage deorbit burn (which did not impact the payload). Falcon is apparently grounded. https://www.space.com/spacex-pause-launches-crew-9-falcon-9-... (\"SpaceX pausing launches to study Falcon 9 issue on Crew-9 astronaut mission\") - \"After today’s successful launch of Crew-9, Falcon 9's second stage was disposed in the ocean as planned, but experienced an off-nominal deorbit burn. As a result, the second stage safely landed in the ocean, but outside of the targeted area. We will resume launching after we better understand root cause\" reply foxyv 1 hour agoparentFor those not familiar with the launch profile of the Falcon 9, the second stage de-orbit burn occurs after the crew/service module separates from the second stage. reply philipwhiuk 6 hours agoparentprevFAA pedantry will tell you they are not ground, they merely may not have a license to fly more missions. Also, it's unclear yet whether the FAA has pulled the license - SpaceX has potentially paused voluntarily. reply schiffern 1 hour agorootparentFor anyone out of the loop, the aforementioned FAA pedantry: https://www.youtube.com/watch?v=3TobeGL4Ma8&t=80 reply wannacboatmovie 2 hours agoparentprevIf something happens to Dragon (non-zero chance) they are going to regret not coming back on Boeing's space-Yugo. reply rvnx 3 hours agoparentprev\"the second stage safely landed in the ocean, but outside of the targeted area. We will resume launching after we better understand root cause\" reality: \"It crashed somewhere in the ocean, we don't know why but we pretend it was safe, though we just got lucky\" reply perihelions 3 hours agorootparentUncontrolled reentry has been the norm for most of the space age (and is still standard practice for the Chinese, and their boosters). The far more important issue is that this a human-rated booster, and an unidentified defect impacts the safety of crew launches. This issue showed up on a de-orbit burn, but it's unlikely to be limited in scope to de-orbits only. edit: Turns out this isn't accurate; it's still actually normal for US rocket *upper stages* to do uncontrolled reentries [0]. This is a subject of ongoing FAA rulemaking [1]. The Chinese examples are still exceptional because they involve far larger first-stage/core-stage boosters (>50 meters in length). edit 2: If anyone was curious about the Europeans, the answer is that Ariane 5/ECA has actually *never* done a controlled upper-stage deorbit, because its LH2/LOX engine isn't designed to be able to ignite twice (deorbit burns are excluded)[2]. [0] https://outerspaceinstitute.ca/osisite/wp-content/uploads/OS... (\"Uncontrolled reentries are currently used for 35% of U.S. missions (62% if we exclude SpaceX)\") (as of 2023?) [1] https://spacenews.com/new-upper-stage-disposal-rules-help-no... [2] https://www.sciencedirect.com/science/article/abs/pii/S00945... (\"it is not possible to perform a controlled reentry of the Upper Composite\") reply schiffern 3 hours agorootparentprevIs it \"luck\" if you intentionally chose a place smack in the middle of nowhere, such that even an off-nominal reentry will overwhelmingly occur in an extremely sparsely populated area (ie the middle of the ocean)? Sounds like planning, not luck. reply deepsun 3 hours agorootparentLanding area is one thing, but more important and dangerous is reentry profile. Too steep, and the capsule melts down or crew inside becomes very flat from the deceleration. reply HPsquared 2 hours agorootparentThis isn't the capsule; it's the second stage. reply ceejayoz 2 hours agorootparentprevThere are no humans on the second stage reentry. It burns up. reply api 2 hours agorootparentprevAll rockets before Falcon always crashed in the ocean. reply perihelions 1 hour agorootparentThere's a nuance here: non-SpaceX rocket *first*-stages typically fall into the ocean, but they do that within controlled exclusion zones, which are notified and restricted for air- and marine- traffic. *Upper*-stages are a different beast. Most (see my sibling comment) deorbit uncontrollably and impact somewhere at random. reply whimsicalism 2 hours agorootparentprevwith the scale of the planet, it would be more like really unlucky if it actually hit someone reply jbkkd 11 hours agoprevWhat's the suit situation here? Did SpaceX make two new suits for them to use on the way back, or are they using their Boeing suits to fly back? I'd imagine the former, but genuinely curious this time. reply chainingsolid 6 hours agoparentI believe new suits where made/available somehow. The SpaceX and Boeing suits are not compatible with the others space craft. reply mab122 4 hours agorootparentThey should be! Have we not learned anything from Apollo? :D Or atleast provision an adapter or something. reply nycdotnet 2 hours agorootparentThe goal of two commercial vehicles was dissimilar redundancy. But yeah this should be worked on in the not too distant future. reply wonderwonder 1 hour agorootparentprevNot sure how soon if ever Boeing is going to be putting astronauts in space again. I see Blue Origin stepping up and taking their place. Agreed though, should be a set of compatible standards for space suits. reply EasyMark 34 minutes agorootparentNormally I would disagree with you, but Boeing is facing death by a thousand cuts right now. I could see the US government not letting them fail however. So I’d give it 50/50, not 100% no-fly-again reply jbkkd 5 hours agorootparentprevFound the answer: > Stich said there is a space suit already on the ISS that one of the astronauts can use for the return trip, and the Crew 9 mission will bring another suit. https://fortune.com/2024/08/24/boeing-starliner-astronauts-n... reply Aardwolf 11 minutes agoprevOver 50 years ago we got people to the moon and back, now we can't even easily get 2 people out of orbit :/ reply DylanSp 5 hours agoprevSeparate from everything else, I'm glad the first crewed launch from SLC-40 went smoothly. Being able to use that pad for Crew Dragon launches provides some helpful flexibility for important Falcon Heavy launches at LC-39A. reply JumpCrisscross 15 hours agoprevIs there a good link for the unexpected science these two have been doing and will do? reply freedomben 4 hours agoparentA fellow Star Trek fan? reply JumpCrisscross 1 hour agorootparentI am, but I’m missing the reference? reply Seattle3503 19 hours agoprev> By the time they return, the pair will have logged more than eight months in space. They expected to be gone just a week when they signed up for Boeing’s first astronaut flight that launched in June. What kind of overtime do you think they are clocking? reply dyauspitr 7 minutes agoparentHow much do astronauts get paid anyways? According to chatGPT they don’t get overtime pay though might receive bonuses for situations like this. reply dools 16 hours agoparentprevAnd will that overtime take into account the effect of time dilation?! reply s1artibartfast 14 hours agorootparentThey are probably salary, not hourly. I wonder if they astronauts are like the military where they get extra on deployment. reply lanewinfield 13 hours agorootparentSalary is set by the year, and with the calculated 6.7 milliseconds of time dilation in the reverse direction (i.e. they will be 6.7ms younger when they arrive), sounds like they should be docked a cent or so. reply jamesjyu 12 hours agorootparentThis brings up an interesting question of salary for near-lightspeed travel. Is it Earth's frame of reference, or the astronauts? reply sobellian 4 hours agorootparentNaturally, a firm located in the local frame of reference has a comparative advantage when it comes to employment. Remote work just isn't viable when you can't even agree on simultaneity. reply jamesjyu 1 hour agorootparentTime to deploy trusted AI managers to all reference frames. reply pixl97 3 hours agorootparentprevDear sir Your packets are too blueshifted for my receiver to decode, please slow down. reply EasyMark 32 minutes agorootparentprevMaybe they could pay them in advance, and then put it in a safe growth account of some sort and by the time they get back they’ll never have to work again? Win-win reply Majromax 2 hours agorootparentprevFor an extensive discussion of similar issues, see Paul Krugman 1978, \"The Theory of Interstellar Trade:\" https://www.princeton.edu/~pkrugman/interstellar.pdf. reply dools 10 hours agorootparentprevYou'll have to take that up with HR: Human Relativity. reply tgsovlerkhgsel 12 hours agorootparentprevhttps://www.marketwatch.com/story/boeing-starliner-saga-do-n... claims \"[There’s] no hazard pay, there’s no overtime, there’s no comp time\". The top two threads on https://www.reddit.com/r/nasa/comments/1f0hi3o/how_do_astron... a) suggest a government pay scale with hazard pay for NASA astronauts, b) point out that they are likely paid as active duty Navy members instead. On https://www.facebook.com/AstroClay/posts/do-astronauts-get-p... an astronaut (verified account of a NASA astronaut) mentions only a small per-diem. https://space.stackexchange.com/questions/2264/do-astronauts... has a lengthy, but inconclusive discussion. ChatGPT 4o-mini generates a vague \"it depends\" answer with no useful sources or statements that could be used to follow up with actual sources. This is a question where I would have expected an authoritative answer to be easier to find. At least regarding your \"like the military\" statement, it seems like some astronauts are military, but what kind of extra pay they get seems to be hard to find. reply chasd00 19 hours agoparentprevHeh I’d hate to be their families too. Sometimes I travel for work, if a week turned into 8 months it would be mayhem. reply aylmao 14 hours agorootparentThe return flight will be in February too— they'll be missing thanksgiving, and all the winter holidays oof reply mp05 2 hours agorootparentprevIt’s almost laughable how the general public tries to apply their own soft feelings to these people built for high-stakes work. None of these people are bothered by this and their families have become accustomed to this sort of thing and too obscenely full of pride to let their own emotions get in the way. reply jajko 3 hours agoparentprevThere is some irreversible degradation happening in space to human body, discussed recently on similar topic here. If they have ie measurably messed up heart or eye sight they could potentially sue Boeing, maybe. reply fracus 17 hours agoparentprevAnd wasn't the mission already on the schedule? The title says \"launches mission for 2 astronauts..\" reply largbae 2 hours agorootparentThe original mission was to bring 4. Two astronauts got bumped to make room for the Starliner crew. reply servbot 16 hours agoprevSo is this a reflection on Boeing engineering culture? Seems it would be, I remember comments from previous articles saying it is. reply ncr100 3 hours agoparentBigger than that, legacy US defense contractors ARE the US Military / Space Force / etc. So IMO the golem whose values are being reflected in this failure / recovery from it is a US GovernmentCommercial organism. And indirectly the United State's civilian population since the Government is formed (over centuries) to be a care-taker reflection of the civilian pop. reply xenospn 9 hours agoprevMakes for a fantastic story tho. “Did I ever tell you about that time I was stuck in space for eight whole months? No?” reply api 2 hours agoprevBill should be sent to Boeing. reply Animats 16 hours agoprevDo those guys get paid overtime? reply wildzzz 1 hour agoparentThey do get a per diem for incidentals but no overtime or any extra duty pay for being in space. This astronaut said it was only an extra $1.20/day. Meals and lodging are provided for so maybe that's deducted from the standard govt per diem. https://www.facebook.com/story.php?story_fbid=53939670306845... reply gnarbarian 13 hours agoprevI declined a job offer from Boeing recently because they can't execute anymore. Complete clown show run by accountants. reply ncr100 3 hours agoparent+1 (not me) opened job, interviewed, withdrew job, months later, re-opened job. Illustrated that the hiring people were just fine, but the larger Organization was, in this case, disorganized. reply dotnet00 20 hours agoprevMan the reporting on this ordeal has been so awful and so representative of how media misleads the public into thinking things are worse than they actually are. It isn't a rescue mission, it's a regular crew rotation mission with modifications to account for the extra crew left on the station, and those crew are 'stuck' only in the sense that they're expected to stay there as part of their duties and it would be unnecessarily disruptive to operations to bring them back early. Starliner was still deemed to be safe enough to be the emergency escape option while it was docked, then the emergency escape option became seats setup in the cargo portion of the Crew-8 capsule. reply mannyv 16 hours agoparentWell hmm. NASA decided Starliner wasn't safe enough to use for the return journey, so the astronauts stayed on the ISS until the next ride became available. Originally the astronauts were supposed to go back on Starliner. Now they're taking another ride back. Is that considered a rescue? Well, it depends. If you get left behind on an island because your ride wasn't safe and another boat picks you up, is that a rescue? Now what if you're 420 kilometers up and another boat has to come get you. Is that a rescue? If there wasn't another ride from the ISS available, would the astronauts be stranded? Yes. In that case, if a ride suddenly became available would it be considered a rescue? Probably, yes. reply iterance 16 hours agorootparentFollowing the analogy... you're on an island. A ferry has showed up at the island every six months or so for the last 40 years. The last ferry that showed up broke before it could leave the harbor. No need to worry, though. Another ferry's coming in six months and there are plenty of supplies on the island. Is it rescue? Maybe in the sense that you can't leave when you wanted to and now you have to wait. But not in the sense that you were ever in any real danger. (Admittedly, maybe there is a bit more danger for these astronauts because a malfunctioning spacecraft is inherently a bit of a safety hazard. And the SpaceX operation is certainly not as routine as a ferry showing up at a dock, though it's still safe.) It seems that it is both a bit subjective whether one calls it \"rescue,\" and also a bit sensationalized to put in a headline too. reply bnralt 14 hours agorootparentMaybe this is better: Cruise line A and cruise line B drop their passengers off at a remote island for 5 days, and then come to pick them up and take them home. After cruise line B drops theirs off, the cruise ships breaks down, and the passengers can't be picked up after 5 days, so they're stuck on the island with no immediate way to get off. Cruise line A says \"OK, the next cruise ship we send will be at half capacity, so we can get the passengers from cruise line B off the island and get them home.\" Is cruise line A rescuing the passengers from cruise line B? I'd say yes. reply mc32 7 hours agorootparentThe main reason people don’t want to call it a rescue is because they dislike Musk. If there were no politics involved people wouldn’t be handwringing themselves so much over the word rescue. If the spaceship that took you somewhere wasn’t able to get you back as planned and cannot get you back as planned and someone else has to go get those people, that’s a rescue. reply throwaway290 7 hours agorootparent> If the spaceship that took you somewhere wasn’t able to get you back as planned and cannot get you back as planned and someone else has to go get those people, that’s a rescue. If you were on cruise then yes, if you are a professional team who trained for years to stay in dangerous conditions and the only thing out of ordinary is delayed transport back then not. If politics were not involved no one would call it a rescue. reply mc32 6 hours agorootparentSeems like similar things in the past were called rescues: https://www.pbs.org/newshour/amp/science/russia-launches-res... reply throwaway290 5 hours agorootparentGood point. If this situation is equivalent then why not I guess. But note the PBS one says \"urgent need for the capsule\". Unclear why. Is it urgent in this case? In case of Russians there was a coolant leak If you are working in Antarctica and need to wait for another transport home it sounds okay. If you urgently need treatment and must perform a surgery on yourself then that's an emergency reply JumpCrisscross 1 hour agorootparent> In case of Russians there was a coolant leak Starliner’s manoeuvring thrusters weren’t working! reply throwaway290 9 hours agorootparentprevCruise passengers stuck on an island without other transport would be rescued because personally for them it is completely out of ordinary. Workers who signed up to get paid to be on the island and do some work? Knowing that there is only one line of transport and it can be irregular? Going through months or years of training beforehand? Maybe \"rescue\" is a sensationalization when used in a news headline. reply TeMPOraL 11 hours agorootparentprev> Is cruise line A rescuing the passengers from cruise line B? I'd say yes. IMO that's only true in line A's PR campaign, assuming they're adversarial enough to run with it. In your analogy, the passengers are always \"stuck on the island with no immediate way to get off\" for at least 5 days, as they have no alternative way to get back during their planned stay. If B's cruise ship breaks down - and AFAIK in this case, \"breaks down\" doesn't mean the ship can't move, just that the risk of catastrophic failure during the trip crossed a preset threshold - that's more of an operational disruption. The stranded passengers are still safe and sound, they just need to wait for the next scheduled cruise to take them home. The schedule bit matters IMO. It would be a rescue if the next scheduled ride would be way too late to help them and thus it had to be moved up to save their lives. reply mgfist 5 hours agorootparentprevIt's slightly more nuanced than that, in that starliner didn't actually break down. It had some issues which presented increased risk for the astronauts, but it was still operational. If there was a true emergency on ISS, they would've gone on starliner. But because there was no danger of them staying longer till the next ride, they opted out of using starliner given the increased risk. reply JumpCrisscross 1 hour agorootparent> It had some issues which presented increased risk for the astronauts, but it was still operational We didn’t know that! > because there was no danger of them staying longer till the next ride I suppose it’s a step forward that we’ve normalised the baseline dangers (and costs, personal and financial) of being in space. reply Dylan16807 15 hours agorootparentprevIf you took a different boat separate from the normal ferry, intending to leave right away but now stuck unable to use it, I would say the next ferry is rescuing you. reply karlgkk 15 hours agorootparentNo? Because if you’re not in danger, you’re not being rescued. You’re just being transported. If I miss the last train across the bay, my uber isn’t rescuing me. I can always stay up to 5am by making a shady deal at the endup. But yeah, this is a black eye on boeing and definitely something that nobody wants to have to deal with. reply aylmao 15 hours agorootparentLooked up two definitions of rescue. First, is the default that shows on Google (via Oxford Languages) [1]: > verb. 1. save (someone) from a dangerous or distressing situation. 2. informal, keep from being lost or abandoned; retrieve. Per this one, if you miss the last train across the bay the the Uber _would_ indeed be \"rescuing\" you if you felt distressed. If we consider the informal definition, I'd say you're also being rescued since one could say you were abandoned by the train and thus being retrieved by the Uber. Next, Merriam Webster [2]: > transitive verb. to free from confinement, danger, or evil Similarly, if you understand \"rescue\" as freeing someone from danger, this isn't a rescue. The astronauts aren't in danger really— they have all the supplies and support they need. Nonetheless, they certainly are in confinement, so this could still be called a rescue. I personally do see how the fact this mission was already scheduled, and the little danger around all this, can make \"rescue\" feel like a little much. It's the same word used in The Martian, after all. But nonetheless I would still call it a rescue mission. These two astronauts are confined up there not by will but by circumstance, and the taxi flight was modified to sending only two people instead of the usual four, specifically to make space for these two astronauts to come back [3]. [1] https://www.google.com/search?q=rescue%20meaning [2] https://www.merriam-webster.com/dictionary/rescue [3] https://apnews.com/article/boeing-spacex-nasa-astronauts-sta... reply JumpCrisscross 15 hours agorootparentprev> if you’re not in danger, you’re not being rescued. You’re just being transported The ISS isn’t Treasure Island. There is always an elevated degree of peril. Particularly in an emergency condition. reply kedv 10 hours agorootparentThese individuals are professionals who signed up for this and are paid to do the job. This isn’t a rescue; the media is simply sensationalizing the entire story. reply YeahThisIsMe 11 hours agorootparentprevBut there's no emergency situation at the moment. reply JumpCrisscross 10 hours agorootparent> there’s no emergency situation at the moment It’s space. The ground state is emergency. I am training to be a pilot. Anything going off flight plan is an emergency. If ground control gives me corrective instructions, in the course of a mistake, I hope I will have the humility to not refuse its designation as a rescue. Like, if you want an Exhibit A for why Boeing doesn’t deserve forward trust, it’s this response. reply throwaway290 9 hours agorootparentWhen the ground state is emergency the definition of emergency changes because emergency cannot be the same as ground state... If we go by technical definition of \"emergency\" then anything not by the plan is an emergency, but it's not used that way normally and it's not a technical publication. If you are stuck in space with no lifeboat back then I agree it is an emergency, but they apparently have Starliner and it works. If they or Nasa are more comfortable with another option maybe that makes it an emergency or maybe not. If it turns out Starliner doesn't work, that's an emergency. If there is radiation event coming then it's an emergency, but it is always an emergency in space regardless. reply dotancohen 10 hours agorootparentprevActually, NASA protocol requires more than a single layer of safety. The astronauts currently do not have a lifeboat home - that is extraordinarily irregular and I believe that it constitutes a danger to the astronauts. The spacecraft are not only for down transport, they are also shelters for radiation and particle events - which could be declared with days or hours notice. For a month these astronauts have had no viable shelter nor transport in case of emergency. Danger is not when the last later of safety fails. Danger is when the level of risk exceeds a set threshold - and that level has been exceeded as per NASA protocol. reply nick3443 14 hours agorootparentprevIf you stay until 5am at the endup, you'll probably have to get rescued anyway. reply JumpCrisscross 15 hours agorootparentprev> not in the sense that you were ever in any real danger The analogy breaks down because an island isn’t space. Your default state on an island tends towards remaining alive. Your default state in space is dead. A closer analogy is a plane in flight. It takes energy and effort to keep everyone alive. Externally-assisted recovery from peril, in that situation, is a rescue. Even if it’s convenient. reply panick21_ 15 hours agorootparentNo astronaut has died on ISS in 30 years. Claiming they are in significant danger simply isn't accurate. Saying 'the default state in space is dead' when historically basically nobody has died in space. reply JumpCrisscross 15 hours agorootparent> No astronaut has died on ISS in 30 years. Claiming they are in significant danger simply isn't accurate Nobody claimed as much. A jet liner is safer than the ISS. The analogy is conservative. > Saying 'the default state in space is dead' when historically basically nobody has died in space Our default state at cruising altitude is dead. Note: I’m not suggesting anyone would have died. Just that they were in a perilous place where things were going wrong. Being relieved from that position is a rescue. reply oaththrowaway 14 hours agorootparent> A jet liner is safer than the ISS. Maybe not if the jet is a Boeing though? reply dotancohen 10 hours agorootparentTo be fair, I'd rather be in a 737 Max at 30,000 ft than without the 737 Max at 30,000 ft. And I'd rather be with the Starliner at 400 km up than without the Starliner at 400 km up. But neither seem to be of comparable safety to the other options available. reply elif 5 hours agorootparentprevNo speeder has ever died on the highway either. It's only the crashing drivers who died. It is likewise as foolish to try decoupling the peril of space and the peril of orbit and deorbit. reply closewith 12 hours agorootparentprev> Your default state on an island tends towards remaining alive. I'm guessing you spend most of your life indoors? On Earth, outside of the carefully regulated homes we've built as a society, the default state is dead and it takes tremendous work and constant vigilence to avoid that fate, only ever temporarily. reply dotancohen 10 hours agorootparentAnd that is why if somebody finds a child wandering in the park alone, we say that the man rescued the child. Exactly as SpaceX is doing in this situation. reply throwaway290 9 hours agorootparentYes and we also say you rescued me if I am bang out of cash and you lend me a fiver at checkout... If you see a news headline \"man rescues child\" you expect a direct threat like something like from a burning house. > if somebody finds a child wandering in the park alone, we say that the man rescued the child. Exactly as SpaceX is doing in this situation. Plus, saying astronauts, professionals who signed up for the job knowing what it entails and went through years of training are like children wandering in the park, to paint SpaceX as their savior, is... wow. reply elif 5 hours agorootparentprevOn an island you can call for a boat or a helicopter. You can relax and eat all your food knowing those options exist. On a space station your options are considerably more limited. reply wongarsu 4 hours agorootparentWith SpaceX's launch cadence they could easily shift some flights. Of course you'd need a Crew Dragon that has completed refurbishment, and need to integrate it with a rocket. A month sounds like a reasonable timeline to get an unexpected rescue mission to the ISS. Which isn't great if you need a medevac, but that's why they have enough space craft docked reply colordrops 15 hours agorootparentprevIt sounds like everyone in this thread is in complete agreement about the complex parameters and details and yet we are arguing on the scope of the label. reply msravi 14 hours agorootparentThe real problem is that the company doing the rescue is SpaceX, and that's owned by Elon. And HN does not like Elon. reply sunshinerag 12 hours agorootparentYes, the comments are a reflection of that. What a level of moral twisting reply bofadeez 11 hours agorootparentIt's become the normal way of thinking here on HN. Everyone is so deep inside a box that they can't even see the edges. They're brainwashed with cult behavior. reply transcriptase 14 hours agorootparentprevreddit and tv says mars man BAD ergo mars man BAD reply JumpCrisscross 15 hours agorootparentprev> yet we are arguing on the scope of the label It’s Saturday, can’t we have a semantic punt? reply adamsb6 5 hours agorootparentI’m on the other side of the international date line, you insensitive clod. reply dotancohen 10 hours agorootparentprevIf I can't bikeshed at the office on Saturday, I'll bikeshed on HN on Saturday. reply 14 15 hours agorootparentprevThat is what is great about HN. We discuss a broad range of topics which sometimes brings us discussing off subject matter but that are still relevant to the heart of HN. Media reporting and how they influence people is definitely a topic appropriate for HN so I can see how it was brought up. reply sph 10 hours agorootparentprevThere's plenty of middle managers on HN on the weekends. reply Gud 9 hours agorootparentprevYour analogy is flawed. Starliner has not been in service for 40 years, as in your example. It’s a fairly new vehicle, newer than the Dragon capsule. reply wh-uws 15 hours agorootparentprevYour analogy might (and even that's a stretch ) work for 6 hours not for 6 months! reply starfezzy 13 hours agorootparentprevYou’re not just “on an island.” You’re LITERALLY STUCK on the island FAR past when you were supposed to leave. So the boat coming to get you off the island is literally rescuing you. I know you hate Elon musk—I don’t care for him much nor do I harbor animosity towards him—but a rescue is a rescue lmao. You guys would never be this ridiculous if the situation wasn’t politically charged, or if the circumstances favored your political leaning (almost certainly progressive left). reply paul7986 13 hours agorootparentYeah not a fan of his cause all his big promises / lies like a used car salesman but him buying X and trying to put the brakes on the radical lefts real out there stuff I personally think did just that. He's in the middle / an independent with both conservative & liberal leanings. reply maxerickson 6 hours agorootparentprevThe thing is that rescue implies they were imperiled by not using Starliner to return. That isn't the case, there has been a way to get them back without Starliner since they got there. Sending this SpaceX capsule up with seats reserved for their return fixes the overall operating tempo, but it doesn't make the 2 astronauts any more or less safe. reply philipwhiuk 6 hours agorootparent> That isn't the case, there has been a way to get them back without Starliner since they got there. That is pushing it until Crew 9 arrives. It's a set of straps attached to cargo pallets in the luggage compartment of the Crew 8 capsule. It's like jamming a kid in your trunk when you're out of seats. They've never had to use this reserve plan and it was only first dreamt of when Soyuz had issues recently. reply brianshaler 8 hours agorootparentprev> If there wasn't another ride from the ISS available, would the astronauts be stranded? Yes. Seems like the answer to this would be no. Starliner's risk was elevated, not guaranteed to fail. The presence of a flight-proven option was the limiting factor. reply eru 4 hours agorootparent> Starliner's risk was elevated, not guaranteed to fail. That's a pretty weird bar to set? reply hinkley 13 hours agorootparentprevSells ads I guess. If your friend bails and you get someone else to give you a ride home, they’re getting you or retrieving you. You only call it “rescue” if you’re trying to add some drama to connect with the person who comes to get you. Like a relative, or someone you’re trying to flirt with. reply beau_g 13 hours agorootparentAgreed, but only in the circumstance that the flirty someone else picks you up from the International Space Station after your other friend bails, otherwise seems like a poor analogy reply hindsightbias 15 hours agorootparentprevWhat if NASAs decision was largely influenced by social media hysteria and not objective engineering? Of course NASA would never give into outside pressures - cough, Challenger, cough. And what I read on the internets is so massively factual. reply anonylizard 14 hours agorootparentWell, that was probably Boeing's line for the MAX disasters, until the second one occurred. Boeing is clearly undergoing systemic collapse in engineering ability, so anything Boeing has to be treated with extreme suspicion. Its like hiring a 3-time-felon to babysit, like you can do it, but there will be 0 tolerance for any deviance. reply hindsightbias 14 hours agorootparentThey build a plane with 15M parts every single day. Their worst engineer is better than 99% of those on HN. reply fastball 11 hours agorootparentTheir worst engineers are the ones responsible for shipping planes + systems that have resulted in the deaths of hundreds of people. I don't think I'm a fantastic engineer, but I'm certainly doing better than those people when considering the metric of \"how many people has my software killed\". reply pferde 10 hours agorootparentYou need to add a metric of \"how many people can my software kill if it misbehaves\", otherwise your point is moot. reply uaas 11 hours agorootparentprevThese are big words. reply gwbas1c 16 hours agorootparentprev> Is that a rescue? Well, was there an accident? It seems like the astronauts staying extra long is to avoid an accident. Does their need to be an accident to call it a rescue? reply ethbr1 15 hours agorootparentThere was not, considering Starliner landed safely about a month ago. NASA was uncomfortable with the amount of risk in a new vehicle exhibiting anomalous behavior, for its first crewed re-entry. The headline here should be: \"US glad to have two separate suppliers for crewed transport\" reply nick3443 14 hours agorootparentThree, if you are willing to count Soyuz. Are we still using Soyuz? reply dotancohen 10 hours agorootparentSoyuz could not be used to take Jeb and Val back down. Riding a Soyuz requires a custom fitted suit, and though these astronauts had both riden Soyuz in the past, those old measurements are not good enough for a current flight. reply philwelch 14 hours agorootparentprevYeah, we have an active seat-trading arrangement with the Russians where they send cosmonauts to ride Dragon and we send astronauts to ride Soyuz. reply manuelmoreale 11 hours agorootparentprevFrom the Cambridge dictionary: > Rescue: to help someone or something out of a dangerous, harmful, or unpleasant situation. These are professional, paid astronaut. They both have decades of experience and both have experience being up in space. If I were to bet they’re probably happy to spend more time on the ISS because I doubt they have many more missions left to do in their careers. They’re in no danger. There’s no harm done to them. reply IshKebab 11 hours agorootparentOf course there is danger. They're in space! Even when things are going to plan it's dangerous. reply manuelmoreale 8 hours agorootparentIf that is your reasoning then they might as well “rescue” all the other astronaut on board the ISS and shut the entire thing down. You’re not rescuing someone from a danger that was already there and part of the mission. Them being “stuck” for a few more months doesn’t make them “in danger” If they weren’t up there now two different astronauts would be up instead of them. And it would be part of a regular mission. Those would not need to be “rescued” reply kevin_thibedeau 8 hours agorootparentThey were in danger because the Crew-8 escape plan exposed them to elevated risk on descent without proper seating or suits that could be connected to the capsule. A loss of pressure would kill them. reply JumpCrisscross 16 hours agoparentprev> it's a regular crew rotation mission with modifications Standard but modified is an oxymoron. This is an irregular mission. NASA plans with tonnes of redundancy. That’s paying off here. Being prepared doesn’t poof away a fuck-up, it just means you can take it in stride. Starliner stranded two astronauts in space. Dragon is fixing that. Being saved from being stranded sure as hell sounds like being rescued, even if it’s close to routine. > Starliner was still deemed to be safe enough to be the emergency escape option while it was docked This is a threshold met by a torn parachute on a jet. reply dotnet00 15 hours agorootparent>This is a threshold met by a torn parachute on a jet. Not when it was the preferred option over sticking seats in Crew-8, right up until Starliner's software changes for uncrewed return started. reply JumpCrisscross 15 hours agorootparent> when it was the preferred option over sticking seats in Crew-8 It was the preferred option before it failed. Between first failure and return it was not the preferred option as it was. It was preferred assuming it worked. But the assumption couldn’t be proven, in part due to Boeing’s shoddy ground sims. reply ethbr1 15 hours agorootparentprev> Starliner stranded two astronauts in space. It didn't, because it wasn't simply broken -- it had unexpected behavior. It ended up landing fine. I'm uncomfortable heaping pejoratives on what we should expect NASA to do: make engineering decisions to minimize risk and maximize chance of mission success. Increasing the reputational or financial penalties to suppliers incentivizes exactly the sort of decisions that blew up Challenger and Columbia. reply rdtsc 10 hours agorootparent> it wasn't simply broken -- it had unexpected behavior. Unexpected behavior for NASA was broken enough to send it back empty. That was not the plan to start with. The mission was supposed to be a few days only not this long. > what we should expect NASA to do: make engineering decisions to minimize risk and maximize chance of mission success. The criticism is of both NASA and Boeing on what they should have done prior to the trip. How the money was spent and such. I don’t think anyone criticizes NASA for opting to keep the astronauts safe by delaying their return. It’s about what happened before that point. reply ethbr1 5 hours agorootparent> Unexpected behavior for NASA was broken enough to send it back empty. It's not a question of broken / not-broken. It's a question of known-risk / unknown-risk. The return mission had too much of the latter. I'm as much of a Boeing skeptic as anyone here, but the knee-jerk-ism to vilify them over this is unreasonable. NASA manages risk. SpaceX blows up rockets, so they can move fast, until they get it right. Boeing is trying to operate as a legacy space company (read: endlessly trying to reduce risk) while also competing with SpaceX. I'm glad they launched Starliner for a crewed mission! No one died, because it was safe enough. No one would have died, had they returned on it, because it was safe enough. And why should NASA have delayed a manned test flight further when there was an acceptable Plan B? reply JumpCrisscross 1 hour agorootparentprev> it had unexpected behavior. It ended up landing fine By this measure the door blowing off the Alaska Airlines flight wasn’t an emergency. reply thfuran 12 hours agorootparentprev>It ended up landing fine. Were the astronauts in it when it landed? reply ethbr1 5 hours agorootparenthttps://news.ycombinator.com/item?id=41684804 reply charles_f 15 hours agoparentprevCalling it rescue or not doesn't matter. The primary objective was test flight for Starliner. Mission is a success, in that it proved Starliner is not safe. Now they're coming down using Dragon, which is the very expensive backup plan, and which is absolutely not what was planned. Whether you want to call it a rescue or not and play semantics or metaphors all night is your absolute right, but it doesn't change the failure of Starliner in this case. reply AdamN 13 hours agorootparentWhen I was a kid a lifeguard helped me out in rough waves in the Atlantic. I was doing ok but not great and probably should have gone in earlier. I asked if he had rescued me because I wasn't really sure what was going on ... he said he had given me an 'assist'. It probably is the right word here too. reply lupusreal 7 hours agorootparentThe lifeguard spared you the word rescue because he didn't want to hurt the feelings of a child. Are we now extending the same courtesy to corporations? Corporations like Boeing no less, with hundreds of negligent homicides under their belt? reply manuelmoreale 11 hours agorootparentprev> very expensive Is it though? > the face value of each seat has been estimated by NASA's Office of Inspector General (OIG) to be around US$55 million. This contrasts with the 2014 Soyuz launch price of US$76 million per seat for NASA astronauts reply ethbr1 14 hours agorootparentprev>> \"If we'd have had a crew on board the spacecraft, we would have followed the same back away sequence from the space station, the same deorbit burn and executed the same entry. And so it would have been a safe, successful landing with the crew on board,\" said Steve Stich, manager of NASA's Commercial Crew Program... https://www.msn.com/en-us/news/technology/astronauts-would-h... reply charles_f 13 hours agorootparentThey didn't come back, though. It's still a success in the sense that it was a test mission and determining there was a problem is valuable, but Starliner is not ready reply ethbr1 5 hours agorootparentConsidering both recent US vehicle losses have been on re-entry, I feel NASA is vindicated on being ultra-conservative around that stage. So anomalies that might be acceptable during ascent would be unacceptable during decent. Personally? I'm glad Boeing launched. I wish they were perfect technically, but I also realize that an infinite amount of time and money doesn't protect against unknown-unknowns. IMHO, they should be operating more like SpaceX (and the earlier days of the US space program) -- using calculated risk and engineering to decide when it's reasonable to do an inherently risky thing, when doing so is needed to move the entire program forward. reply nick3443 14 hours agorootparentprevRussian roulette is safe! I played once and didn't die! reply ethbr1 14 hours agorootparentThe point that half this comment section is missing is this is the sort of thing we want to encourage. The US spent extra money funding two separate vendors. One vendor exhibited a high level of risk in their first return. The astronauts were able to be returned on the second, already proven vendor. That's a great place to be in! The alternative, having to return astronauts on a high risk vehicle because it's the only option, is not a place we ever want to be in. reply dotancohen 10 hours agorootparent> One vendor exhibited a high level of risk in their first return. > The astronauts were able to be returned on the second, already proven vendor. Anyone reading this five years ago would be absolutely shocked to discover which vendor is which. reply inglor_cz 11 hours agorootparentprevWhat is not great is the fact that vendor 1 exhibited a string of concerning anomalies and accidents. Vendor 1 may be institutionally unfit to be a leg on which the US space program stands. reply hcks 12 hours agorootparentprevThis is actually an incredibly stupid thing to say which reflects poorly on NASA management reply DLA 33 minutes agoparentprevIt is a rescue mission. The original mission was supposed to be a couple weeks and that extended to nearly 8 months due to unrecoverable issues with Starliner. That’s not a crew rotation, it’s a major failure of Starliner. As for the escape option while docked, even a leaky boat is better than no boat if the ship is sinking, but the fact is NASA elected to not return the crew on Starliner for safety reasons. reply neverrroot 19 hours agoparentprev“Ultimately, NASA felt it was not able to understand why the thrusters malfunctioned and decided that it was too risky to return its astronauts to Earth aboard Starliner, which will attempt to return uncrewed.” Too risky? Stranded? Rescued (hopefully)? reply justin66 17 hours agoparentprevSo “regular” they had to bump two astronauts who had trained for a mission on ISS. reply nimbius 16 hours agoparentprevOcchams razor might say the reasons to downplay this incident are overwhelmingly more attractive. - Boeing is a fortune 50 company and is a direct contributor to news media advertising revenue. - Boeing is a darling of US aerospace and a bulwark of us international projection of soft power and defense. Telling the truth will destroy the us aircraft market. - china does not have this problem with its space program. The comac airliner also directly competes with Boeing's beleaguered 737 - loss of confidence in the us space program at the vehicle level jeopardizes trust from consumers and insurance companies in the us space products market like satellite launches. reply wannacboatmovie 2 hours agorootparent> The comac airliner also directly competes with Boeing's beleaguered 737 Thanks but I'll take my chances on a MAX. Do you know what happens when a Chinese-built plane crashes in China? There is no fancy congressional inquiry, no lawsuits, no crying families on TV. No, they hose off the crash site and put them in unmarked graves and build a shoddily-constructed apartment building over top of it. Maybe the pilot's family is jailed and never heard from again. Pretend it never happened and life over there continues as usual. reply tjpnz 11 hours agorootparentprev>The comac airliner also directly competes with Boeing's beleaguered 737 Not in any remotely meaningful way. Some estimates suggest it will be more than a decade before Comac will have the manufacturing capacity to fill existing domestic orders (as of now they've built 9). Then there's the fact that their planes aren't nearly as fuel efficient as those from Boeing and Airbus - the engines may be imports but are neutered due to export restrictions. China's own airlines aren't even interested. reply dotancohen 10 hours agorootparent> it will be more than a decade before Comac will have the manufacturing capacity to fill even domestic orders If you think that a decade is enough time for Boeing (or Airbus) to react to losing one large market and having a new competitor encroach on existing markets, then I suggest looking at past airliner development programs. A decade is nothing in this industry. And China, specifically, is known for being able to scale manufacturing - so they may not have a decade like us Westerners think. reply anonylizard 14 hours agorootparentprevWell no one is losing confidence in US space program. Since SpaceX has the overwhelming global lead in space engineering. The main issue is, NASA for political reasons, has to keep the delusion of the 'have 2 suppliers'. Boeing is clearly nonviable anymore, but as you said, it has tremendous influence in US congress, so NASA pays them billions. NASA's programs would be simpler if they simply just dumped all the money to SpaceX, but that could cause longer term issues. The other solution would be partnering with Airbus as the backup supplier, but that would cause political earthquake. reply ascorbic 14 hours agoparentprevCalling it a rescue may or may not be accurate, but the replies to your comment show that it is at least open to discussion by people who presumably don't have a vested interest in the number of clicks on the article. That would mean that it's not really clickbait to call it this. reply elif 5 hours agoparentprevWhen you have extremely limited supplies, are as isolated from humanity as possible, and there are only 2 vehicles capable of transporting you, and one of them is reigniting a cold war with you, you are considered imperiled. I'm sorry. If dragon did not exist, the rescue mission would still be embroiled in diplomacy and not in orbit already. You only get the luxury of your non-rescue position due to hindsight. reply ericpauley 5 hours agorootparentBut dragon does exist. This is like saying you’re stranded when you’re car camping in the woods. reply ceejayoz 5 hours agorootparentHelicopters exist, but when one picks me up from my campsite in the woods, I'm probably being rescued. reply mensetmanusman 15 hours agoparentprevIf your car dies at night in the middle of a desert. Is the tow truck rescuing you? reply jmyeet 16 hours agoparentprevI see this claim a lot and I honestly don't understand why people refuse to see this for the disaster it is (for Boeing). An 8 day mission turned into a months-long mission unexepctedly and SpaceX ultimately had to bump 2 trained astronauts to return them to Earth. That's the very definition of a rescue and just a wildly massive PR disaster to boot. Beyond this, we still have no idea of what it will take to return Starliner to flightworthiness and give NASA the confidence that it can carry out an entire mission. It may be completely or just practically doomed at this point. reply dotnet00 16 hours agorootparentIt was a disaster for Boeing, it was not a disaster for the astronauts. Extending stays at the station is not unheard of for test flights, the Crew Dragon test flight also involved the crew staying longer than initially intended, as NASA decided that it'd be a more effective use of resources to do so. SpaceX did not have to bump 2 trained astronauts to return them to Earth. That was simply the cheapest, least disruptive way to bring them back. There has always been the option of sending a dedicated Dragon for them, but that would require NASA to pay for an entire additional Dragon mission just to bring two people back who are in no urgent need of bringing back. You go to an island for your employer, and the ferry breaks down once you get there. While your employer can send another ferry soon to bring you back, they ask if you'd be okay staying for a rotation because that'd be more convenient for them. They also arrange a means for you to leave in case of an emergency. You're enjoying the island, so you agree. The replacement ferry is not a rescue. Starliner made the uncrewed return just fine, which means that on NASA's side, the return to flight should not be too complicated (well, besides showing that the doghouse deformation issues have been resolved) and should not involve a redo of this flight. What remains to be seen is what position Boeing takes on it, as they have been very quiet over if they're going to continue in Commercial Crew. reply sneak 15 hours agorootparentThey could also pay Russia to bring them back to Kazakhstan on a Soyuz. Another American ISS astronaut, Tracy Dyson, came back in this manner last Monday. reply dotnet00 15 hours agorootparentnext [5 more] [flagged] sneak 15 hours agorootparentI don’t think the geopolitical issues directly affect ISS operational stuff whatsoever. The missions of the Roscosmos and NASA (and ESA and JAXA and CSA) teams have nothing to do with nationalism or geopolitics and I assume everyone managing them and participating in them is smart enough to realize that. They didn’t fuck with NASA when Dubya invaded a country, after all. Every spacefaring superpower has its fingers in a bunch of mass murder pies somewhere. There is no geopolitical upside to Russia or geopolitical downside to the US for NASA to contract Roscosmos to rescue some Americans from space. I imagine SpaceX was just faster and cheaper and already had a mission scheduled. reply lupusreal 15 hours agorootparentprevQuit talking out your ass. Americans have continued and will continue to fly on Soyuz, and Russians have flown and will continue to fly on Dragon. You can look all of this up on Wikipedia, there's no reason for you to be making shit up when the real information is all freely and readily available to you. Soyuz MS-27, scheduled for March 2025 with the American Jonny Kim, or Christopher Williams as the backup. SpaceX Crew 10, scheduled for February 2025 with the Russian Kirill Peskov. reply dotnet00 15 hours agorootparentnext [3 more] [flagged] skissane 14 hours agorootparentNASA still gives Roscosmos money, in exchange for Roscosmos doing ISS-related stuff for NASA. NASA has a contract with Roscosmos for \"joint spaceflight activities\" which does not expire until the end of this year. I don't know if it can be extended past this year or not, but since the contract dates to 1993, I suspect they will continue to extend it year-by-year until the ISS program is terminated. https://www.usaspending.gov/award/CONT_AWD_NAS1510110_8000_-... So far this year NASA has executed 7 contract modifications (from February through September), under which it has paid Roscosmos an additional US$2.6 million. While that's not a huge amount of money, it doesn't look like there is a hard prohibition on NASA paying Roscosmos for services. reply dotnet00 14 hours agorootparentnext [2 more] [flagged] lupusreal 7 hours agorootparentWhy are you still making up bullshit? NASA isn't cooperating with Russia because their hands are tied by prewar contracts. They're cooperating with Russia because it's a mutually beneficial arrangement which was extended in 2023 after Russia's war began. https://www.reuters.com/technology/space/russia-us-agree-add... August 25, 2023 > Aug 25 (Reuters) - Russian and U.S. space authorities have agreed an additional flight for an American astronaut on board Russia's Soyuz MS spacecraft, Interfax news agency said on Friday, in a rare sign of bilateral cooperation at a time of high tension over Ukraine. You have the same internet I do, you should be able to find this information yourself. Stop being a dumbass, unsubscribe from your reddit or wherever it is that's influencing you to think you can know things by bullshitting instead of researching. reply joe_the_user 17 hours agoparentprev\"It isn't a rescue mission, it's a regular crew rotation mission with modifications...\" Rescue definition: an act of saving or being saved from danger or distress. The mission to take astronauts off the space station clearly fits this definition - an extended, unplanned and indefinite stay in space has to be distressing at the least. Has the HN standard become that you can argue the most ridiculous thing if you make that argument against the media? Edit: \"regular crew rotation\" implies normal and expected but the point is, even if the crew is in no danger, this wasn't regular or expected. reply gpm 17 hours agorootparentThis launch was normal and expected crew rotation, they just kicked a few people off the mission so that there would be open seats on the way back. reply JumpCrisscross 16 hours agorootparent> normal and expected crew rotation, they just kicked a few people off the mission so that there would be open seats That’s neither normal nor expected! Go back to the age of exploration. A crew’s ship strands them on an island. Another ship was due to come anyway in 6 weeks, and the crew have enough food to last them that interval. They use witches to tell the coming crew of their problems, and that ship agrees to lighten its load to make room for the stranded. This is a rescue! It’s an easy rescue. But so was, like, pulling my puppy out of the neighbor’s pool when it went under the cover. reply gpm 15 hours agorootparentIs it a rescue? Maybe. Is it a rescue mission? No. It's a normal crew rotation mission that has happened to (arguably) rescue a few people on the way. The mission itself is ordinary, expected, and planned prior to any crisis. Arguable because everyone has a way back already, the modification to the crew rotation mission just provides a somewhat safer way back. Edit: And the distinction here matters. A rescue mission would be an expensive unexpected endeavour. The regular crew rotation is an expected operating cost. The modification to the details of the plan for the crew rotation haven't significantly impacted the mission goals - i.e. for the same cost there are still the same number of fresh qualified crew members up there for the same duration, just a slightly different set of people. reply JumpCrisscross 15 hours agorootparent> Is it a rescue mission? No. It's a normal crew rotation mission that has happened to (arguably) rescue a few people on the way I like this. Nit: it’s not a normal mission. Normal missions don’t leave two seats for folks trained on a different spacecraft. It’s a scheduled mission. reply ghodith 15 hours agorootparentprevOnly seems like a rescue if you specify that they're alone on the island to be honest. If you had said that they were left at an outpost with other people for six months it somewhat loses it's \"rescue\" vibes. reply JumpCrisscross 15 hours agorootparent> If you had said that they were left at an outpost with other people for six months it somewhat loses it's \"rescue\" vibes When a country pitches into instability and nations evacuate their citizens, are they not rescuing them? I suppose I’d invert the question: why does framing the mission as a rescue bug you? reply tedunangst 15 hours agorootparentI think rescue implies a higher degree of imminent peril. reply nick3443 14 hours agorootparentI agree. The dictionary definitions mostly involve urgency or distress in the situation. This would be more like a retrieval I think. \"SpaceX capsule used to retrieve astronauts stranded on ISS by malfunctioning starliner.\" reply bmitc 16 hours agorootparentprevYes, to rescue two other people stranded on the ISS who were supposed to return home weeks ago. reply Natsu 16 hours agorootparentprevI can sorta see why some would quibble over \"rescue\", because it's not like they're in immediate danger, but at the same time they're stranded because their ride malfunctioned and left them somewhere rather inhospitable. And I think \"normal and expected crew rotation\" as someone put it undersells the fact that while there isn't a special trip for them only, they had to bump other people off the flight just to get them, specifically. Would people really be that much happier if it was said instead that they were making room for crew marooned by an unsafe spacecraft? I think I'd normally use the word \"rescue\" there if it was a ship. But yet it is true that they plan for this kind of thing and that's why they're not in any particularly significant danger due to being marooned. reply lupusreal 6 hours agorootparent> I can sorta see why some would quibble over \"rescue\", because it's not like they're in immediate danger, but at the same time they're stranded because their ride malfunctioned and left them somewhere rather inhospitable In any other context this wouldn't be quibbled. If my car broke down a mile outside town and my friend gave me a lift the rest of the way, I would say he rescued me and nobody would quibble it. The only reason it's being quibbled is because people have a stick up their ass about Elon Musk personally and that stick extends to the way they feel about SpaceX. reply unethical_ban 16 hours agorootparentprevIf my car breaks down while I'm at my fully-loaded villa on day 2 of my 30 day vacation, my friend coming to pick me up isn't a rescue mission. You shift from talking about danger or distress, to \"not regular or expected\". Which is it? I think danger and urgency are marks of \"rescue\". If they had supplies and were in no immediate danger, I don't see how the term or the alarmism qualifies. reply raspasov 16 hours agorootparentYour villa is totally incomparable to space or a space station. Hypothetically: - you can walk outside, hitch a ride home - fully loaded means there’s electricity and phones? Call a Taxi? - walk to a near town shop, buy car parts and fix the car if you have the skills None of those hypotheticals are even remotely possible in space. It’s a bad comparison. reply raspasov 15 hours agorootparentprevI would describe rescue as: Whenever I travel to a location, the planned return transport fails AND I would eventually be dead without outside human assistance. That’s a rescue. In your villa example that is correct: your friend helping you is not a rescue. It’s a convenient helping hand. A space station is a different beast though. If your villa was on a remote isolated island without anyone else on it, it would be closer to the space station but still not exactly the same. The island, depending on its size might have bountiful food/animals you can hypothetically harvest, not to mention attempting to plant and grow some seeds from the hypothetical fruits and vegetables you already have. Very little of this is realistically possible in a space station like the one we have. reply moralestapia 16 hours agorootparentprevYou mixed the numbers there. \"day 30 of my 2 day vacation\" is more accurate. reply lupusreal 6 hours agorootparentprev> If my car breaks down while I'm at my fully-loaded villa on day 2 of my 30 day vacation, my friend coming to pick me up isn't a rescue mission. If you chose to say it was, nobody would be doing the \"Well ACKSHULLY...\" routine with you because that is in fact totally in line with common use of the word rescue and not worth making a stink about even if you think it sounds a little melodramatic. The ISS situation is more extreme than your example in every way, but you're pulling the ackshully bullshit because you don't like the company that has done it. reply unethical_ban 1 hour agorootparent>but you're pulling the ackshully bullshit because you don't like the company that has done it. I wonder if you, like me, have taken a vacation to travel half-way across the United States to watch a SpaceX launch, or had discussions with former heads of NASA as far back as 2011 about what the company meant/means for manned spaceflight. I wonder if you grew up around astronauts or knew people who died on Columbia. This isn't an appeal to authority, it's a statement of experience. I'm in a pedantic HN subthread and threw in my subjective opinion regarding the use of the term \"rescue\" - please don't jump to assuming I'm some evil troll. reply joe_the_user 16 hours agorootparentprevIf my car breaks down while I'm at my fully-loaded villa on day 2 of my 30 day vacation, my friend coming to pick me up isn't a rescue mission. I don't think being in a leaky space station for eight months, where you suffer the effects of accelerated aging due to zero gravity, is equivalent to a being in a fully loaded villa for a month. I'm using the \"distress\" part of \"danger or distress\". The average person would view the situation as distressing for the astronauts, for the average person \"rescue\" is appropriate term. Jeesh. reply marcosvm 12 hours agoparentprevEasy to say while we're safe down on Earth. reply jiggawatts 20 hours agoparentprevThis is a matter of perspective. The mission is what you call it. Sure, it’s not a “rescue”, it’s just an “unplanned itinerary change to another vessel”. Also, they’re not “marooned”, they’re “getting an extended work opportunity”. reply tw04 20 hours agorootparentSo if you ride a ferry on a regular basis (which I'm sure at least a handful of HN folks do) - if that ferry breaks down before the return trip, when you catch the next ferry is that a \"rescue mission\", or are you just catching the next ferry? Replace ferry with bus, car, taxi, airplane, your transportation mode of choice. Calling this a rescue is, to OPs point, just dramatizing the situation for clicks. In pretty much any other circumstance, it wouldn't even make the news. reply wpasc 17 hours agorootparentI respectfully partially disagree. Sure, the term \"rescue\" is a bit over the top and evokes \"Apollo 13\" vibes. OTOH, Boeing has \"$14.8bn in Pentagon contracts in 2022\" [1]. Boeing has plane crash issues for years now across more than 1 model. And its space program just had an embarrassing failure. Given their failures, the amount of revenue they get from the US federal gov, and their level of influence over various aspects of defense funding/spending, I do not think this story should be dismissed as an overly sensational, run-of-the-mill story that does not make the news. IMO, US citizens/taxpayers would be very justified to be pissed about the failures of a company that their tax dollars heavily fund (from the same article I referenced above, its like 37% of their revenue). The series of very public failures that affect people directly (planes) and affect their tax dollars (recent series of failures of their space program) certainly warrants outrage and coverage. that's my 2 cents [1]: https://www.airforce-technology.com/features/boeing-pleads-g... or https://www.forbes.com/sites/greatspeculations/2020/01/02/ho... reply joe_the_user 17 hours agorootparentprevIf you're on an island, the ferry breaks down and the next one is in three months, yeah it's a rescue mission. I don't know why people want to quibble about usage that seems clear. reply mkl 16 hours agorootparentI'd just call it the next ferry. If there was an extra boat sent before the next ferry was due, that could be a rescue mission (or just a replacement boat). reply JumpCrisscross 16 hours agorootparent> just call it the next ferry The next ferry doesn’t have room. It has to change its plans to accommodate you. reply hatsunearu 16 hours agorootparentprevWhen my friend's car broke down on the mountain 15 minutes from both of our homes and I brought them a jacket and McDonalds while they wait for a tow, that was a rescue. Like it's not much, but come on. reply elteto 17 hours agorootparentprevA more apt analogy would be: You are the captain and pilot of the ferry. And it is such a complicated ferry that you are extensively trained on how to navigate it. It is, in fact, so complicated and different that there are other ferries around but you can only sail yours. You can't just hop on another one and do the same trip. You took this ferry to an island in the middle of nowhere and after you got there you realized the ferry was broken. Nobody knows how bad... it might snap in half in the middle of the return trip. You have plenty of provisions for the next few months and you are not alone on the island. Other ferries still come and go but you can't just hop on those, you don't know how to operate them. They sent one of those other ferries just for you with a smaller crew to accommodate you. Without it you are not coming back. Is it a rescue? reply wrsh07 16 hours agorootparentprevIf you're in the ocean and your ship breaks down and another ship adjusts its plans to come pick you up, is that a rescue? If there were no changes needed to the subsequent flight to accommodate two additional riders, sure, not a rescue. But there are, and that's important from multiple perspectives (not least of which is cost) reply teruakohatu 19 hours agorootparentprevI agree that calling it a rescue is a bit much, but this is hardly a case of missing a bus or ferry and catching the next one. If you missed a ferry, expecting to be away from your family for a week, only to find you are stuck on a desolate island for 8+ months you would probably feel like you were being rescued. reply jwagenet 19 hours agorootparentMy understanding is the astronauts don’t mind staying longer because they enjoy it and for some (all?) it may be their last mission in space, in part due to the decommissioning. reply blackoil 17 hours agorootparentAnd most people like visiting islands. That doesn't change the fact that this was supposed to be 8 days not 8 months. reply inglor_cz 11 hours agorootparentprevWe don't really know. Some of them may have missed out on something personally important back on Earth (graduation, wedding, funeral, birth) etc. reply glenstein 17 hours agorootparentprev> Replace ferry with bus, car, taxi, airplane, your transportation mode of choice. I mean I've certainly been stuck at an airport because I had a ticket for a flight that ended up getting canceled, which necessitated me remaining at the airport for an extended period of time. I had an expectation of getting a new ticket for a new flight, but none of that changed the fact that I was indeed stuck. reply blackeyeblitzar 17 hours agorootparentprevIt’s a downsized crew, right? As in they purposely are sending up fewer people so that there is room to bring back everyone? reply macinjosh 19 hours agorootparentprevYou are leaving out the tiny detail that compared to a ferry there are very limited opportunities to catch the next ferry. If a ferry breaks down you aren’t stuck in the island for 8 months. You could charter a boat, get a helicopter, go for a swim. Significant unexpected planning and spending have to go into getting them a different ride home. It’s closer to your car breaking down in a remote area. Would a tow truck be a rescue? I would think so. reply Loughla 18 hours agorootparentIt's similar to your car breaking down in a remote area only if you've trained extensively for that area (almost your entire life), have food and supplies for the entire duration, have friends and entertainment, and can do your job as well as novel career options the entire time as well. It's overly dramatic to call it a rescue mission. It just is. It's not great that they're up there longer than planned, but they're not going to explode or fly off into space. reply dotnet00 20 hours agorootparentprev\"Rescue\" conveys a much more negative situation than \"unplanned itinerary change where the astronauts are safe and which they are happy about because they get to spend more time in space\". reply natch 14 hours agorootparentBone deterioration equating to decades in a matter of months, heart health impact, time away from family... it's negative. reply LightBug1 11 hours agorootparentI bet if you asked each of them if they could extend such a unique experience - one they're unlikely to experience again - would they say yes? IN. A. FCKING. HEARTBEAT. The postive's overwhelm the negatives by an infinite amount. reply sunshinerag 12 hours agoparentprevIt is a rescue mission reply rig666 14 hours agoparentprevLet's be honest. The mental gymnastics to avoid calling it a rescue is just a political knee jerk reaction to Elon Musk's ownership in SpaceX. If you lose your ability to become objective based on your view no amount of philosophical discourse is going to be meaningful. It's comments like this why \"cope & seeth\" has flourished in the modern lexicon reply dotnet00 13 hours agorootparentAccusing me of taking issue with Elon's ownership is funny, considering that usually I'm accused of being an Elon shill :) reply gertop 10 hours agorootparentThen maybe you're just a contrarian? reply Teever 14 hours agorootparentprevThe government would be doing the exact same thing to avoid bad PR if this didn't involve him. reply LightBug1 11 hours agorootparentprevPersonally, that's a part of it. I might it find more tasteful if Shotwell and her team (the actual heroes) were ones getting the credit here, but Musk will get the headlines. But it's not a political knee jerk reaction. It's an actual jerk reaction to him being such an actual jerk. The guy, and his current cohot, are distateful wankers. Excuse my English. reply iknowstuff 1 hour agorootparentwhat gives you the idea that Shotwell is more responsible for SpaceX’s success than Musk? reply hayd 6 hours agorootparentprevPoliticians should not, indeed in the US it can be illegal for government branches to, make decisions based on the political views of a vendor’s CEO. Clearly the current administration have been doing this willy nilly. Excuse my English. reply exe34 9 hours agoparentprevcould I ask, under what conditions would you consider it a rescue? reply huijzer 19 hours agoparentprevI read somewhere someone who compared news to the presenters at a horse race. If you just look, it might be a boring uneventful race. But if you listen to the presenters, it’s very exciting. “Now horse A is in front!!! Oh wait. Horse B takes the lead!! Wait. Horse A is coming back.” For example, EV taxes in Europe “There are rumors on EV taxes!! Wait some guy says there will be no extra taxes!! Oh wait. Rumors for 40%!! No 30%!! Breaking news!! It’s 40%!” reply throwaway4aday 19 hours agorootparentUnfortunately, they've taken to doing things like saying Horse C is in the lead when it's actually Horse B and telling everyone Horse A has gone lame when it's clearly neck in neck with Horse B while pretending that Horse D doesn't exist because they don't like the jockey. reply walterbell 18 hours agorootparentCommunity Notes template for multiple contexts. reply Loughla 18 hours agorootparentprevI am absolutely convinced that the 24 hour news cycle is the problem in society at large, at least in the US. Everything else draws from that. Social media, full of bullshit to drive eyes to constant news feed. Political divide literally caused by the 24 hour cycle. It needs to end. reply aidenn0 19 hours agorootparentprevSee also Jelle's Marble Runs e.g. https://www.youtube.com/watch?v=0sHu99vdz-A reply moralestapia 16 hours agoparentprevLol, people still shilling for Boeing at this point. Unbelievable. reply dotnet00 16 hours agorootparentPointing out overly sensational and misleading reporting is not shilling for Boeing. reply eth0up 19 hours agoparentprevI guess I'm a victim of this reporting to some extent, because I remember this situation going on for months, and I keep thinking every time it's mentioned (often) how terrible it must be for these astronauts and why something isn't done about it. But I know almost nothing regarding details. I know I despise Boeing and that I admire astronauts and that reading this headline, I thought 'its about fucking time!' But if I realize the entire situation has been misrepresented, I think I will be annoyed with myself. Is this really all nonsense? Is the situation normal, or common? reply addaon 18 hours agorootparent> Is the situation normal, or common? They went up on an experimental spacecraft on its shakedown cruise. They’re coming down on a different spacecraft than planned — a different make of spacecraft, even. That’s never happened before, and is neither normal nor common. The spacecraft type they flew up will almost certainly never fly again because of how badly the shakedown went. That’s never happened before to a manned design to my knowledge — certainly not normal or common. reply nick3443 14 hours agorootparent>>The spacecraft type they flew up will almost certainly never fly again because of how badly the shakedown went. I haven't seen this in the reporting. Can you share any context for it? reply addaon 5 hours agorootparentThere’s been a bit of reporting on Boeing “considering” whether to cancel the remains of this program. There’s been no reporting on any decision — likely because Boeing hasn’t made one. But there’s zero financial upside to continuing, and zero PR upside to continuing… and I just don’t see any world in which Boeing, in its current state, continues to spend billions of dollars of its own money to set up more and more elaborate shows of its own (well understood, internally) incompetence. So, complete speculation on my side, but I’m comfortable enough making that speculation without a throwaway account. reply eth0up 18 hours agorootparentprevBecause I cannot upvote comments on HN, I'll clutter the thread by thanking both you and the other fellow who gave pretty good explanations. reply EgregiousCube 15 hours agorootparentWhy can't you upvote comments on HN? reply samatman 17 hours agorootparentprevIt appears you're referring to this: https://news.ycombinator.com/item?id=30742539 The most likely explanation of the effect you're observing is that the server, having done a database fetch to get you the profile once, is not interested in doing it over and over again. It's cached. You do not have a uniquely broken upvote button. reply eth0up 3 hours agorootparentNo. Definitely no. I've tested this many times by up-voting predictably stable comments, noting the karma number before and hours later. No effect. No exceptions. Additionally, there was a time where this limitation didn't exist. I am pretty sure I triggered a flag for my tendency to up-vote controversial and underdog content. I don't think dang is right about everything, but I get the impression that he's honest and expect he'd confirm this limitation on my username. Ask. But I'm not grovelling for equal rights on HN and will make no inquiries to insiders. Also, if your interpretation was correct, there's this really big parallel contrary reality where the upvote system works and entries are accepted and processed, hence the ever changing karma number of each active user. Perhaps it's the ad blocker, but it's not normal reply philipkglass 1 hour agorootparentI don't think dang is right about everything, but I get the impression that he's honest and expect he'd confirm this limitation on my username. Ask. But I'm not grovelling for equal rights on HN and will make no inquiries to insiders. I once had this limitation on my own account. It was because I had upvoted certain grayed out comments that were flamewar fodder. I did that because there were equally bad counter-comments in the thread that weren't voted down (grayed), and out of a misguided commitment to balance I wanted to fight for the losing side. When I emailed dang to ask about my voting limitation he explained why my account had been penalized. I said I wouldn't vote up bad comments in the future and he restored my comment voting. Now when bad arguments attract bad counter-arguments I just downvote instead of trying to boost the somewhat-less-bad side. You don't have to send email about this if you don't want to, but it doesn't require groveling to fix. reply samatman 1 hour agorootparentprevAs an experiment, I upvoted your comment. But first, I loaded your profile. Then I refreshed it several times. At no point did your karma score change on your profile. It's caching. reply dotnet00 18 hours agorootparentprevThere were issues with Boeing's Starliner that made it difficult for NASA to quantify the risk of bringing the test crew back on it. NASA still believed that the risk was likely to be negligible, but since they had the option of taking a fully proven spacecraft back home, they opted to send Starliner home empty. The astronauts were/are comfortable on the ISS. There are plenty of supplies, and more have gone up as part of regular resupplies. IIRC the only discomfort for them was having to use makeshift sleeping places until the previous crew departed. As astronauts, they pretty much live to go into space, so they were happy, of course with the minor caveat of the disappointment regarding their primary mission not panning out and of having to be away from family for a few months. Especially considering that they are unlikely to get to be in space again as the ISS is due for retirement by the end of the decade and NASA wants to give space travel experience to the astronauts intended for the Moon. Putting it differently, the biggest issue/inconvenience with this situation was that Starliner was taking up a docking port and causing things to have to be rescheduled. Prior to launch, crew are trained to operate certain experiments, or to do servicing space walks. Since the crew being launched had to be reordered, these plans had to be reworked. There are a lot of people focusing in on the fact that they will be returning in February, but they're completely ignoring the fact that they're perfectly capable of coming back early, that option is actively not being chosen as having them stay till then would be more optimal for station operational planning. reply floating-io 15 hours agorootparentIt's worth noting that the astronauts in question have little to no control over the schedule, so \"perfectly capable of coming back early\" isn't a fair assessment in this context. Coming back \"early\" would also occur at a cost of either tens of millions of dollars for an extra launch, or at a cost of valuable experiments not getting run because the space station was empty of personnel. NASA policy would prohibit the remaining astronauts from... well, remaining, because they have to have a lifeboat, which the two \"rescuees\" would have just used to go home. Thus, all of them would have to go home. IOW, painting this as \"normal operations\" in any sense is disingenuous. The danger levels may not be overly exacerbated, but it was a very costly failure, and it may well be a drastic inconvenience to the astronauts. We likely won't know the truth of the latter until they write their memoirs. It's easy to manage spin when the opinions being spun are in orbit on a restricted communication system. reply peeters 11 hours agorootparentprev> I guess I'm a victim of this reporting to some extent, because I remember this situation going on for months, and I keep thinking every time it's mentioned (often) how terrible it must be for these astronauts and why something isn't done about it. I'm not Butch or Suni, but I think the astronauts most negatively affected by this would be the two that got bumped from Crew 9. Astronauts define their careers by the amount and quality of the time they are blessed to spend in space. Chris Hadfield, e.g., has taken it for granted that the pair would feel lucky to be \"stranded\" for a few months, and would have plenty of meaningful work to occupy their time. reply a1445c8b 19 hours agorootparentprev“Normal” and “common” would still be the last words on my mind considering the amount of planning and money that goes into sending people to space and back. The only normal situation would be they go there and then back alive on the same mission as originally planned. Any divergence from that is totally abnormal. reply renewiltord 16 hours agoparentprevYeah, something people forget is routine things happen. But people like to think of events as singular unexpected grand things even if they’re just part of an older expected thing. Take D-day for instance. We make movies about the landings and how dramatic it was, but the truth: a regular troop rotation into territory, something routine for the armed forces. reply lostlogin 16 hours agorootparentI can’t tell if you’re joking? D-Day being ‘a regular troop rotation’ is an amazing description. reply nick3443 14 hours agorootparentprevNo reply natch 14 hours agoprevWas the title edited after the fact by mods? The original title has the word \"rescue.\" The top comment is questioning the use of this word. It seems likely that when the story originally appeared on HN, it had the accurate title reflecting the title of the article. Thus the comment from dotnet00, which I'm neutral on. But then, it would appear, the title was altered, to dampen a controversy? Is this how things are done around here? Anyone know more? reply dang 33 minutes agoparent> Is this how things are done around here? Yes. Often I add a comment (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...), but this time I didn't. When a single word starts sucking most of the thread's attention and leading to acrimonious nitpickery, it's an easy call to take that word out of the title. Striving for accurate and neutral titles is one of the best established principles of HN moderation (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...). It has a huge influence on discussion quality. In the present case, for example, it behooves us all to learn about the real situation that is actually happening, rather than arguing about whether or not it deserves the term 'rescue', a semantic dispute which seems correlated with people's priors on the most divisive associations (e.g. the Elonian Dimension) and is therefore mostly a proxy for a repetitive and tedious argument. reply natch 19 minutes agorootparentThank you for explaining that! Seems a tough call doing that versus flagging the root comment of the acrimony, but maybe that alternate approach would have a bigger (too big) cost in disruption once there is such a small continent of comments built out under the top comment. reply mlyle 14 hours agoparentprevThey regularly tamp down on sensationalist headlines. reply AdamN 13 hours agorootparentI'd prefer they just block articles that use sensationalist headlines (when possible without blocking the entire topic). reply dang 30 minutes agorootparentMany good and substantive articles have sensationalist headlines, so that wouldn't work. Particularly at large publications, headlines are written by specialists in sensationalism (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...). reply whimsicalism 2 hours agorootparentprevi prefer the current approach especially when comments are already attached reply make3 11 hours agorootparentprevthey changed it to match the title of the article itself from AP, not to tamp it down necessarily. This is what they actually usually do. reply mlyle 11 hours agorootparent> they changed it to match the title of the article itself from AP No-- AP: SpaceX launches rescue mission for 2 NASA astronauts who are stuck in space until next year Original HN title: SpaceX launches rescue mission for 2 NASA astronauts who are stuck on the ISS Current HN title: SpaceX launches mission for 2 NASA astronauts who are stuck on the ISS reply afh1 6 hours agorootparentprevIs that even possible to do in an unbiased way? reply lcnPylGDnU4H9OF 6 hours agorootparentI would think it’s not. I’ve also never once seen dang claim that the moderation team do their job without bias. Indeed, I suspect he’d even go as far as to say that the primary purpose of moderation is to promote a certain bias. That said, it’s also very easy to see what HN’s intended bias is since the publish it; it’s explained in the “on-topic” and “off-topic” paragraphs at the top of the guidelines page. reply criddell 5 hours agorootparentprevI don’t think they’ve ever claimed to be unbiased. They want shorter headlines with less sensationalism. That’s a bias. reply gr3ml1n 11 hours agoparentprevIt was definitely changed. reply LeroyRaz 15 hours agoprevTo everyone saying \"oh, the astronauts like having to be up there. It is an opportunity.\" You get that they have no choice, right? And that for multiple reasons they are going to put the best spin on the event. For one, for their own sanity, they are going to be as positive and optimistic as possible. For two, there is likely a huge PR pressure to be as positive and optimistic as possible. Being in space is a pretty big deal. It comes with lots of health risks, and they are isolated from their loved ones. For example, they might be missing funerals for friends or family members, they might be missing milestones of their children, etc... etc... reply JumpCrisscross 15 hours agoparent> It comes with lots of health risks It also means their forward flight time is curtailed. The near future holds manned missions more exciting than the ISS. There is a real possibility someone who might have gone to the Moon or even Mars doesn’t, now, because of Boeing. reply dotnet00 15 hours agorootparentNeither Sunita, nor Butch are candidates for Artemis missions. They are both very experienced senior astronauts in their early 60s (kind of why they were chosen to be test pilots). This was likely to be one of their last trips to space as NASA astronauts regardless. reply JumpCrisscross 15 hours agorootparentFair enough. Didn’t look at their profiles. Was generally pushing back on the notion that the ISS is an orbiting beach. reply tw04 15 hours agorootparentprevMars??? That’s more than a bit of a stretch. The astronauts in the ISS right now weren’t up there for a significantly longer period of time compared to their peers. Absolutely no way it would disqualify them from a mission happening a decade from now which is an absolute best case scenario for mars and frankly even the moon the way the current political climate is in the US. reply JumpCrisscross 15 hours agorootparent> Absolutely no way it would disqualify them from a mission happening a decade from now Astronauts have lifetime radiation limits. Crewed Mars missions already push the envelope; the margins are especially meaningful. reply tw04 15 hours agorootparentIgnoring the fact that, again, the astronauts in question weren’t in space for any appreciably longer time than anyone else on the ISS. They’ll be too old to participate in the mars mission a minimum of a decade from now. You have literally no idea what the radiation exposure allowances will be for a manned mission to mars when it happens, or what advancements we’ll make to radiation shielding should we ever actually send a manned mission to mars. reply JumpCrisscross 15 hours agorootparent> You have literally no idea what the radiation exposure allowances will be for a manned mission to mars when it happens These are well known and documented, to the degree we know things about human deep spaceflight. > what advancements we’ll make to radiation shielding should we ever actually send a manned mission to mars These are unknown. But they will, barring new technology, require mass. Which means more shielding comes at a cost. Which incentivises low-rad experienced astronauts. reply sneak 15 hours agoparentprevIt’s still an opportunity. You can have more kids, but most people probably only get maximum one chance in their life to spend half a year in space, even if they are extremely lucky. It’s also not like they didn’t know that death or delay or anomalous/inconvenient conditions weren’t possibly on the table. They’re test pilots, after all. Any landing you can walk away from is a good one, even if it takes a year. Sunita Williams (one of the two stranded) is up there for her fifth(!) trip to the ISS. I can’t speak for her but if I had to guess I don’t think she minds being in space, even if it’s unplanned. reply aylmao 14 hours agorootparent> You can have more kids, but most people probably only get maximum one chance in their life to spend half a year in space That's not generally how having kids works haha. As you mentioned Sunita Williams has been to space five times. She's also 59 and the only information I found on kids is that she was looking to adopt a kid in 2012. It doesn't sound like she'll be having any more kids. > Sunita Williams (one of the two stranded) is up there for her fifth(!) trip to the ISS [...] I don’t think she minds being in space, even if it’s unplanned. Personally, I've been many times to New York. It's a very fun city. But if I booked a weeklong trip that against my will it became a yearlong one, I'd mind it. I also can't speak for Sunita Williams, just for me in this hypothetical NYC stranding. It could be a very fun year, for sure. I'd certainly try to make the most of it. But I'd mind it. [1] https://archive.ph/20130126165056/http://articles.timesofind... reply philwelch 13 hours agorootparent> Personally, I've been many times to New York. It's a very fun city. But if I booked a weeklong trip that against my will it became a yearlong one, I'd mind it. You didn’t spend years of your life and beat out 1,000 other candidates just to earn the opportunity to visit New York. Your full time job does not primarily consist of preparing and training to go to New York. You don’t get up every day and go to a job that earns a federal government salary when you could earn twice as much in the private sector because that’s the only way you can achieve your childhood dream of occasionally visiting New York. You certainly didn’t volunteer to take a test flight on a vehicle that could very plausibly catastrophically fail and kill you because that was the only way you’d ever be able to go to New York again. And if you did get stuck in New York, you probably wouldn’t become mayor. reply philwelch 14 hours agoparentprevMillions of people have “become an astronaut” as their childhood dream. Less than one in a thousand people who apply to astronaut selection actually become astronauts. And then they have to wait years to actually go to space. I don’t know why anybody would go through all of that if they didn’t really want to go to space. And while everyone else is either getting full ISS rotations or planned to fly to the moon, Butch and Suni have been assigned to an eight day test flight that’s been repeatedly delayed for years. It’s arguably the worst assignment you can get these days other than no assignment at all (and to be fair, it’s also not the first assignment for either of them). I’m sure they would have preferred if their six month stay on the ISS was planned as such ahead of time, but spending six months on the ISS is the normal mission that everyone else gets anyway—and it’s not like a normal ISS flight is scheduled for the personal convenience of the astronauts assigned to it, either. Yeah, they don’t have a choice now that they’re in space, but if you’re an astronaut you can also just retire and make a lot more money in the private sector if you don’t really want to go to space again, and I think that it’s a pretty slim chance that a veteran astronaut would stick around and devote years of their career to an eight day flight test but would be really unhappy about being “stuck” on ISS for an otherwise normal rotation period. reply neverrroot 20 hours agoprevThank you Elon! reply electriclove 19 hours agoparentSpaceX is pretty much America’s space program at this point - absolutely incredible! reply justin66 17 hours agorootparentWeird way of looking at it. Was Roscosmos “America’s space program” when they were selling the rides? reply dylan604 16 hours agorootparentNo. They were just the rescue (to stay on theme) for America's space program. reply ls612 16 hours agorootparentprevCurrently SpaceX makes up 90% of global launch mass in the past year. It may as well be the western world’s space program pretty soon, with China and Russia only launching their own military payloads. reply justin66 15 hours agorootparentWhat I was really driving at was that some are using the wrong definition of \"space program.\" It's a good thing that space transportation is becoming a reliable service or utility, but that's something quite different than being the space program. If we came to think of launch as a very large part of what constitutes a space program, that's only because we allowed the costs of launch to become entirely too high, such that it dominated budgets. reply neverrroot 19 hours agorootparentprevKinda is, and it’s all Elon’s fault. reply yarg 17 hours agorootparentOr perhaps blame Boeing and NASA, rather than the single competent organisation that's managing to hold the whole damned thing together. reply neverrroot 2 hours agorootparentI meant to give Elon credit for being able to deliver a viable program where nobody else can. reply freedomben 4 hours agorootparentprevWhy not both? I think it's both the incompetence of the incumbents, and the impressive work of SpaceX that got us to where we are. With the vast majority of companies, especially tech companies, I think the leadership gets far too much credit. In most organizations I have been a part of, they succeed in spite of the leadership, not because of it. In the case of SpaceX though, I am less sure. Reading the Walter Isaacson biography on Elon Musk was quite fascinating and illuminating about his leadership style. I would never work for him myself, but he does have some really fascinating philosophies. reply nordsieck 18 hours agorootparentprev> Kinda is, and it’s all Elon’s fault. Not sure what you mean by that. Are you suggesting that Elon/SpaceX sabotaged Boeing Starliner program? Because it seems pretty obvious that Boeing did that all on their own. reply neverrroot 11 hours agorootparentI mean to give Elon credit for being able to deliver a viable program where nobody else can. reply sneak 15 hours agoparentprevHow much of SpaceX’s boring day to day stuff (including ~all of the F9 stuff) do you think he has a hand in anymore? Isn’t he running Tesla, Twitter, Neuralink, The Boring Company, Starlink, and the Starship R&D, including its first-of-it’s-kind Raptor engine design which just hit major version 3? And also raising the remainder of his 12 kids (~8?) that are still speaking to him? I’m fairly certain that most of the “boring” stuff at SpaceX happens despite Musk, not because of him. Ms. Shotwell’s (the SpaceX COO) name doesn’t come up nearly as often as his does, and I suspect she does at least an order of magnitude more work there. Indeed, several SpaceX staff wrote an open letter complaining about him and his antics being a distraction that hinders them. https://arstechnica.com/tech-policy/2024/01/spacex-illegally... reply dotnet00 15 hours agorootparentMusk is pretty clear about the fact that Shotwell handles the 'boring' operational stuff, so, F9, FH, and very likely includes Starlink now. These have customer-related constraints, which Gwynne is much better at handling. Elon does decision making for the R&D programs, i.e. Starship, where his style works better. reply panick21_ 15 hours agorootparentprevIn literally every thread about SpaceX people who don't like Musk (and sometimes others), people bring up Shotwell. Of course her name doesn't come up as often as Musk, Musk is literally one of the most famous people on earth, a highly controversial public figure and one of the richest people on the plant, who also owns and leads the company. For most other tech companies people done even know the Nr.2 person in the company, and that includes companies much bigger then SpaceX. So if anything Shotwell comes up more often then literally any other Nr.2 person in a major tech company. I couldn't tell you the relevant people at Nvidia, or Google, or Microsoft. Also the letter was more about the external image, that Musk reflected on them. There was no actual argument in the later work inside SpaceX was slowed down because of it. And from the continued progress SpaceX has made before and after that, there is no evidence of that it actually did. But of course its also self evident that the CEO isn't doing 'boring day to day stuff', but neither is Shotwell. reply sneak 4 hours agorootparentThe numbers 2-4 at Apple come up quite often, but “how annoying it is to work with Tim Cook” isn’t a recurring thread, despite his also being one of the most famous, wealthy, and powerful people on Earth as well. Joel Spoksky’s meeting with Bill Gates about Excel is famous lore in our circles as well, although I doubt Spolsky was ever even top 10 at Microsoft. Werner Vogels comes up fairly often, too. reply barfingclouds 3 hours agorootparentI’ve never heard of those people reply wonderwonder 1 hour agorootparentprevImagine being so petty and filled with Elon derangement syndrome that you have to not only comment on his family but cast dispersions on his relationship with his children. Pathetic and speaks volumes on the person making the statement. reply blowsand 13 hours agoprevnext [14 more] I’ve nothing substantive to add, but I note that the logic gymnastics on display in comments from all perspectives is somehow telling. Of something. Not sure what. reply notahacker 6 hours agoparentIt's HN, arguing about semantics is what people do :) If the half page of arguing by analogies to holidays about what is and isn't a rescue feels like an unwarranted response to a headline, the comments insisting the only reason people could consider labelling accommodating them on the next scheduled return flight a 'rescue mission' overly dramatic is deep love for Boeing or deep hatred for Elon's politics are wild. reply ncr100 3 hours agoparentprevAwkwardness could be a sign of conflicting values at play. And a desire to find an accepted homogeneous mindset. reply Mountain_Skies 12 hours agoparentprevIt's just more evidence of the corrosive effect that injecting politics into everywhere has had, especially intersectional politics where unrelated domains are pushed to influence each other for political or ideological reasons in unrelated domains. reply heraldge",
    "originSummary": [],
    "commentSummary": [
      "SpaceX launched a mission to return two NASA astronauts from the ISS due to issues with Boeing's Starliner.",
      "An anomaly occurred during the Falcon 9 rocket's second stage deorbit burn, prompting a pause in launches for investigation.",
      "The astronauts will return using SpaceX's Crew Dragon, with new suits provided, sparking debate over whether this is a \"rescue\" mission or a routine crew rotation."
    ],
    "points": 334,
    "commentCount": 309,
    "retryCount": 0,
    "time": 1727561465
  },
  {
    "id": 41686715,
    "title": "Building a robust frontend using progressive enhancement",
    "originLink": "https://www.gov.uk/service-manual/technology/using-progressive-enhancement",
    "originBody": "Technology Building a robust frontend using progressive enhancement Give feedback about this page From: Technology community (frontend development) Contents Start with HTML Using CSS Using JavaScript Single page applications Testing your service Case studies and related guides For users to experience a quality service it must be built in a robust way. Progressive enhancement is a way of building websites and applications based on the idea that you should make your page work with HTML first. Only after this can you add anything else like Cascading Style Sheets (CSS) and JavaScript. All government services must follow progressive enhancement, even if part of the service or a parent service needs JavaScript Building your service using progressive enhancement will: ensure your service is robust and of a high quality make it more likely your service will work regardless of which browser or device is being used mean your service’s most basic functionality will work and meet the core needs of the user improve accessibility by encouraging best practices like writing semantic markup help users with device or connectivity limitations to use your service If you are using a ‘commercial off the shelf’ (COTS) solution or asking an external supplier to build the service, you should consider including this in your requirements as part of your purchasing strategy. Start with HTML Government services should be functional using only HTML. This includes services such as: transactional services, for example forms that let the user provide information to government smart answers, for example the Registering a birth abroad service content-based websites, for example GOV.UK’s foreign travel advice page The HTML layer is fault-tolerant by design. The browser ignores markup that it does not understand and continues to parse it as best as it can. This means that older browsers will be very likely to be able to load the HTML for your service, even if there are bugs in the HTML or you use features that only exist in more modern browsers. A user should be able to navigate through your service using only the HTML. You should use correct semantic markup and structure your source order and document outline logically. Using CSS You can style your service using CSS to make it look like GOV.UK. The CSS layer is reasonably fault-tolerant. This means the browser will ignore individual declarations that it does not understand, for example if you use a property that only exists in newer browsers. Be aware that the browser will ignore the entire ruleset if it encounters a selector that it does not understand. There are also other reasons why the CSS may fail to load. Avoid techniques such as ‘CSS-in-JS’ to ensure that your site still looks correct even if the JavaScript fails to load. Using JavaScript JavaScript can be used to add interactive elements to your service. The JavaScript layer is not fault-tolerant. If your JavaScript uses a syntax or calls an API that is not supported in the user’s browser, it will error and the rest of the JavaScript will not run. There are other reasons why the JavaScript may fail to load or run. If your service is not designed with this in mind, users may be unable to use it. You can increase the chances that your JavaScript will work correctly in all browsers by: using feature detection for browser APIs including polyfills for newer browser features transpiling your JavaScript to a common syntax that your target browsers can understand using automated tests or linters doing regular manual testing, including testing with older or lower-powered devices Transpilation and polyfills can significantly increase the size of your JavaScript. You should consider the trade offs involved and revisit these decisions regularly as browser usage changes. Where possible the JavaScript should enhance HTML and CSS that provides the same core functionality. For example, an autocomplete could enhance a element, or something similar. This still lets the user do what they need to do, even if the JavaScript fails. Alternatives to JavaScript If you believe your service can only be built using JavaScript, you should think about using simpler solutions that are built using HTML and CSS and will meet user needs. For example, if you want to use use JavaScript to provide interactive graphs, other options are to: display the data in a table allow the data to be exported so that it can analysed in another application pre-render the graphs as images If the core functionality of your service cannot be provided without JavaScript, you’ll need to consider how users can access your service through other channels. This might be telephone calls or in-person visits to offices. Using client-side JavaScript frameworks If your service is mostly built using components from the GOV.UK Design System and doesn’t have a complex user interface, you do not need to use a client-side JavaScript framework. The components in the GOV.UK Design System include how to import JavaScript to your service without the need for a framework. If you do choose to use client-side JavaScript frameworks, be aware that although they can be helpful when building a service with a complex user interface, they can introduce problems. Using a client-side JavaScript framework can: increase the overall size of your code base and push processing to the client-side, causing performance issues for users with a slower network connection or lower powered device create a reliance on third-party code that your developers do not have control over, requiring you to make major changes to your service in order to stay up to date with changes in the framework make it difficult to find people with the skills required to maintain the code, if the framework’s loses popularity over time If you use a JavaScript framework you should: be able to justify with evidence, how using JavaScript would benefit users be aware of any negative impacts and be able to mitigate them consider whether the benefits of using it outweigh the potential problems only use the framework for parts of the user interface that cannot be built using HTML and CSS alone design each part of the user interface as a separate component Having separate components means that if the JavaScript fails to load, it will only be that single component that fails. The rest of the page will load as normal. If you use JavaScript, it should only be used to enhance the HTML and CSS so users can still use the service if the JavaScript fails. Reasons why CSS or JavaScript may fail to load or run CSS and JavaScript can fail to load or run because of, for example: temporary network errors third-party browser extensions like ad blockers third-party supplier downtime, such as when using a content delivery network DNS lookup failures bugs introduced by browser updates bugs introduced in third party JavaScript intentionally running on the same page corporate firewalls blocking, removing or changing content (large institutions like banks or government departments may use these) mobile network providers changing content to speed up load times and reduce bandwidth usage personal firewalls or antivirus software changing or blocking content the use of unsecure connections, where internet providers insert their own code into the page that accidentally conflicts with your own Some users may deliberately turn off features in their browsers. You should respect their decision and make sure those users can still use your service. Single page applications Do not build your service as a single-page application (SPA). This is where the loading of pages within your service is handled by JavaScript, rather than the browser. Single page applications rarely bring benefits and can make the service inaccessible because: users of assistive technology would be unaware of changes in context, for example when moving to a new page it would fail to handle focus when moving between pages the user would be unable to navigate using the back or forward buttons in their browser users would be unable to recover from an error, for example if there is an interruption to their network connection Testing your service If any components in your service rely heavily on JavaScript or JavaScript frameworks you will need to make sure they: work on a wide range of browsers and devices work with assistive technologies are tested to ensure good performance Ideally you should check that these components work in your service by testing it for accessibility. Case studies and related guides Why we use progressive enhancement to build GOV.UK Designing for different devices How to test for front end performance Understanding WCAG 2.2 From: Technology community (frontend development) Last updated 2 days ago Last update: 27 September 2024 Updated to include the use of JavaScript in progressive enhancement and the potential impact on user experience. + Show all page updates (3) 16 December 2019 Added browser update bugs to the list of reasons why JavaScript or CSS might fail to load 21 May 2019 Updated to reflect progressive enhancement's effect on a service's resilience, plus clarified guidance on building more complex services that use JavaScript 23 May 2016 Guidance first published",
    "commentLink": "https://news.ycombinator.com/item?id=41686715",
    "commentBody": "Building a robust frontend using progressive enhancement (gov.uk)208 points by artbristol 7 hours agohidepastfavorite141 comments projectileboy 6 hours agoOMG it feels so good to not be the lone voice in the woods. I would say about 3/4 of my frustrations as a user are from sites that should have simply been built with HTML + CSS and minimal Javascript. The front end community most days feels like a jobs program. reply stavros 6 hours agoparentYou aren't alone, I'm a technical director and even I can't win this battle. We have a ton of complexity on what could be a simple SSR site, but frontend devs don't like writing anything but SPAs, so it's hard to change. reply dazzawazza 5 hours agorootparentMy constant battle in the last 15 years (of 30 years of development) has been the unending torrent of completely unneccesary complexity that teams inflict on themselves. I feel it's often just to pad their CVs or because the current *perfectly usable* stack is boring. Limiting complexity to where it's *really* needed is the hidden magic of a great leader in my opinion. A great engineer knows how to wall that complexity off from the rest of the system as well because complexity spreads like cancer through a codebase. I've never been a TD but I can imagine your pain. reply tarsinge 5 hours agorootparentEverybody is incentived to use the tools FAANG+ are using even if completely unnecessary, ie follow fashion. Developers for Resume Driven Development, and execs because it reassure investors and is good for marketing. The industry doesn’t reward smart engineering choices. reply stavros 5 hours agorootparentprevHey, at least I managed to consolidate all our services into a monolith, which developers ended up really liking, and it works well for us. One battle at a time, I guess, but the \"let's simplify the frontend\" effort is meeting much more resistance from people who are interested in the frontend having a lot of state. reply Frost1x 5 hours agorootparentprevPart of the issue in the complexity battle is competition and levels of expectations from features. Non technical decision makers (and there are lots of them, I’d say most of them) see services from Facebook, Google, etc. and have the same level of feature expectations in their one off small app. They have no clue how much effort exists behind it to maintain what seems simple and now even standard (across large services). Ultimately they come up with ideas and write feature requirements (indirectly) based around this premise with their shoestring budget and ad hoc team. And we end up in a world with not so well developed applications attempting to create similar features to competitors in budget which leads to a lot of corner cutting and barely working implementations with no thought towards long term maintenance requirements. At least, this has been mostly my experience. There are of course those out there simply bored with life who want to build unnecessary complexity because they have to be doing something (heaven forbid there be idle time in any work environment either from their own pressure and/or internal organizational pressures) and they start trying to be clever or skill up to some wider marketable skillset (e.g. react). It’s really business environments that create this sort of complexity requirement from needless feature requests to wide adoption of specific trendy skills in their stack to make hiring easier/cheaper, etc. reply ksec 3 hours agorootparentprevAnd it doesn't help when the Browser, the Web Spec and front end dev are all aligned into making SPAs with JS. I really wish something like HTMX is built into the browser or part of HTML5 spec. reply imacrayon 2 hours agorootparentThere’s a draft proposal to get some of HTMX in the browser: https://github.com/alexpetros/triptych reply arp242 5 hours agorootparentprevOur frontend is a bunch of barely working wonky react-soup, and we really need to rewrite it. It's mostly a \"tables and forms\"-type frontend with a lot of complexity in the backend: it's a great use case for htmx (or even vanilla/jQuery). But I'm not really sure how we're going to handle that or who we'll hire for it, because I fear we'll end up with another react-soup. My current strategy is to make a MVP in my spare time to show it can be done and that it'll be quite nice. reply bdangubic 2 hours agorootparentafter you re-write it (either immediately or with time) you will end up with the same thing, just a different kind of soup. using vanilla-whatever you will eventually notice you are doing “X” over and over again and then you’ll start writing small libraries (or even worse, some internal “framework”) which over time will get stale or will get bunch of features from devs that need “just that plus a few more things..” ad infinitum… reply stavros 5 hours agorootparentprevThe main part is to avoid holding state in two places (frontend and backend) if you can do with holding state in only one (either frontend or backend). reply redman25 5 hours agorootparentUnless you're building an app that holds data locally, for most web apps, you should be pushing state down into the backend. Fat models should be your single source of truth, skinny controllers, and service functions in order to separate data from code for testability. Avoid caching as much as possible until you absolutely need to. As soon as you introduce caching you now have multiple sources of truth instead of one. reply bdangubic 2 hours agorootparentprevor be stateless… ;) reply eddd-ddde 2 hours agorootparentprevThen why hire front end devs for a project that doesn't need one? Probably 80% of websites could do with a good designer that knows how to get their designs from concept to CSS and a good backend engineer that know how to output decent markup. reply stavros 2 hours agorootparentBecause someone needs to turn the concept to browser-ready, responsive, cross-browser, lightweight markup, and that person is a developer who specializes in the frontend, ie a frontend developer. reply paulddraper 43 minutes agorootparentprevAn SSR site needs to have full stack devs, not front end devs. Else you will have exactly this problem reply stavros 32 minutes agorootparentAn SSR site needs a frontend dev to produce the HTML/CSS/JS and a backend dev to provide the template variables. You don't need a developer to do both when the interface is so small. reply haliskerbas 6 hours agorootparentprevHope next.js 14 isn’t the framework behind the “simple SSR site” reply stavros 6 hours agorootparentIt's Django. Next.js fails the \"simple\" part. reply j45 5 hours agorootparentprevThings like Livewire, and alpine.js are showing simpler ways. You can build a SPA SSR as well. reply willcipriano 5 hours agorootparentprev> I can't win this battle You are fighting the wrong battle. You harp on the technology used rather than the specific functionality you desire. The bad way to do it: \"You made a single page app with PHP and {other tech} and {database}! I hate those! Don't you read (reddit, twitter, hacker news)? Best practices say...\" The good way to do it: \"Our users often share links within the application with each other to navigate and the new single page app you demoed doesn't allow that.\" Or: \"While the page load times look great on the metrics in your power point, as everything is lazy loaded it takes 10 seconds for the page to actual become usable, the old site loaded in under a second why are we regressing the user experience here?\" Or the evergreen: \"What does that buy us?\" reply stavros 5 hours agorootparentThis is fairly basic advice, and it feels a bit insulting to assume I'm just hating on some tech. Obviously, if things were as easy as \"here's the immediate and unambiguous problem with this approach\", I would have gone that way. Things would be great if the risks were as simple as this. The actual problem is \"six years later, the frontend is a ball of spaghetti code and it takes you two sprints to change a component\". How many developers do you think heed those warnings? reply j45 5 hours agorootparentNot enough. But they will scoff at other technologies old and new. reply willcipriano 5 hours agorootparentprev> heed those warnings It's not a warning. It's a functional requirement that you put into the ticket. The project isn't done if the rewritten page takes longer to load than the old one did. Don't ship it, don't pay bonuses based on shipping it. reply stavros 5 hours agorootparentPlease read my comment more carefully, you're being patronizing. I can't put \"I want feature development on this codebase to be faster than two sprints in six years\" in the requirements. reply jonathrg 6 hours agoparentprevIt seems that the pendulum of public opinion is swinging back towards simple, mostly HTML-based solutions, with the rise of intermediate solutions like htmx. reply pjmlp 6 hours agoparentprevSame here as developer, I only put up with SPAs at work, because job title isn't doing fronted stuff. However on side projects it is pretty much vanilla.js without any kind of SPA related stuff. reply wruza 5 hours agoparentprevI don’t make sites like gov.uk or any random-user facing sites, but they are fast, frustrationless and “frontend”. I use them myself. Coming from desktop UIs (from most of them, and they are like 100x superior), writing 1.0 websites is a sort of bdsm to me. I actually avoided web programming before 2.0 became a thing. I’m sure, and it will be hard to convince me otherwise, that it’s NOT a client model (thin client, thick client, mixed approaches) that is a source of your frustrations, but the amount of bullshit that “frontend developers” tend to serve to everyone including themselves and at the same time leave ends loose by e.g. never checking for errors or assuming incorrect lifetimes or phases of page loading. If you just write a regular non-wEbApp app with js as a scripting lang and dom as a poor man’s ui lib, it works like any other ui app. All problems arise from trying to jump over the head to render empty frames 200ms faster out of total 12 seconds of loading. My “stack” is mithril.js, bootstrap.css and just js runtime for “state”, for those curious. Yes, I manage “state” by storing it in js objects and transform it via assignment operators (shocking I know). reply layer8 5 hours agorootparentI started avoiding web programming after 2.0 became a thing, because it turned into an unmanageable time sink and usability nightmare, and it still is. reply wruza 5 hours agorootparentAnd I remember when 1.0 sites erased most of the form on an apparent mistake on my part and took ages to load aspx. There are facets in each version of web that we tend to see or ignore, but it’s clear that the common facet is poor and/or overcomplicated programming, not a paradigm itself. reply bigfatkitten 6 hours agoprev> If you use a JavaScript framework you should: > > be able to justify with evidence, how using JavaScript would benefit users Steady on, guys. reply joseferben 6 hours agoparentfor real, do you want swarms of developers to lose their jobs because software complexity collapsed? reply mrthrowaway999 5 hours agorootparentIf we want full employment, we should mandate people use spoons instead of shovels. reply joseferben 5 hours agorootparenthttps://en.wikipedia.org/wiki/Perverse_incentive reply j45 5 hours agoparentprevUse? I look at all the time to keep it running. reply WA 6 hours agoprevA good rule of thumb is: if your app can/could run offline-first like a desktop app, it's ok to make it a single-page application. They can be snappier and better than a multi-page browser app. Examples would be stuff like Photopea, Google Docs/Sheets, tldraw, etc. This way, the biggest downsides (moving between pages & requiring an internet connection) are eliminated. But if your app requires an internet connection and multiple pages, it's better to let the browser handle navigation in a fault-tolerant way. reply synergy20 6 hours agoparentThis is a good point. Web platform is now doing both websites and GUIs cross-platform. If you need anything offline or desktop GUI alike across multiple OSes, SPA is your friend, if you just want to build a website, SPA might not be the best fit. reply layer8 5 hours agoparentprevYou have to test a lot though, especially in contexts like gov.uk, since a significant number of users is still using older phones with browsers that aren’t updated anymore (like for example iOS 15 Safari). reply j45 5 hours agoparentprevSnappier is an outdated concept. HTML has lots of tools in it now. SPA's are one thing, the complexity to create it is another. reply truculent 6 hours agoprevGood advice, but > - users of assistive technology would be unaware of changes in context, for example when moving to a new page > - it would fail to handle focus when moving between pages > - the user would be unable to navigate using the back or forward buttons in their browser > - users would be unable to recover from an error, for example if there is an interruption to their network connection These aren’t strictly true, are they? You can achieve these things in an SPA, even if many (most?) don’t bother reply ljm 6 hours agoparentYou kind of get it out of the box with plain old HTML though. Once you get into SPA territory you’re reinventing a lot of wheels to get back to parity, or replacing native functionality with JS alternatives. Consider multi-page forms: how many SPAs just store all of that in memory and then make one request at the end? Without JS, the BE would be saving the state for each step so you could come back to the form later or refresh without losing anything. reply earnesti 6 hours agoparentprev> These aren’t strictly true, are they? You can achieve these things in an SPA, even if many (most?) don’t bother Yes you can, but then it is way more difficult, and the fact that most don't even bother means that it is not exactly trivial to implement. Why to force that garbage when basic HTML basic web sites work just fine out of the box. reply c0wb0yc0d3r 6 hours agoparentprevI think that section could be more clear if something like \"without more effort\" was added. reply edelbitter 6 hours agoparentprevHow could you possibly make them true, if you are told to respect even deliberately disabled features? If the user does not permit retroactively messing with their navigation history, then you are left with only one option: get the history right, at the time it is written. reply pensatoio 6 hours agoprevI wish the whole internet followed this advice. reply fouronnes3 6 hours agoparentWe could shutdown a few dozen powerplants easy. reply EasyMark 12 minutes agorootparentWait until you hear about the next big thing, AI compute centers, and those plant shutdowns will be a drop in the ocean… reply mfenniak 6 hours agorootparentprevGreat idea, more capacity for LLMs! /s reply noop2714 6 hours agoprevWhat’s old is new again. Maybe we should prioritize the simplest possible solution rather than what’s trendy today. reply devoidskeleton 6 hours agoparentFollowing trends is why 99.9% of developers are useless and should never hold an engineering title. reply TimReynolds 6 hours agoparentprevNot really. The UK government has never supported the use of JavaScript in its web services and has heavily invested in design systems which use html and css with accessibility at their core. Just because the rest of the industry has been high on JS doesn’t mean everyone has. reply pjmlp 6 hours agoparentprevJust watched the recent DHH keynote at Rails World, I might not do Rails, but fully on-board with his point of view with where modern Web has gone. reply ksynwa 6 hours agoprevGenuine question: Judging from the comments, seems like people like this approach. So why is the general trend more towards approaches that use javascript (sometimes unnecessarily) and frameworks like React? reply EasyMark 8 minutes agoparentI think it’s a nice idea, but given the bean-counting-efficiency-experts that run the company, this will never fly “build for the 90-95%” is what I constantly heard from bosses before I left frontend and went to backend, and eventually leaving the cloud industry all together. I can see it working for government sites though because profit isn’t the sole purpose of the website, it’s more there to serve the public as a whole. reply entuno 6 hours agoparentprevAs an end user, I really like the style of applications that GOV.UK write and endorses - lightweight, clean layouts, accessible, and generally work with minimal (or no) JavaScript. And I dislike most SPAs, because they usually end up breaking lots of expected browser functionally, are useless without JavaScript, and often load all kinds of heavy dependencies from various third party sites. But what users like and what developers like (and can quickly develop) are often very different things. reply nonrandomstring 5 hours agorootparentAmbivalence is a weird thing. People often speak in two minds. We hate AI, but we love AI. I love ice-cream and crisps. but I tell my kid not to eat that. As George Carlin said, when you're driving everybody going 5 mph slower than you is an idiot, and everybody going 5 mph faster is a maniac. Here on HN we often see the schism between speaking \"as a developer\" and \"as a user\". As a user I hate a lot of the shit we gleefully enthuse about here. As a coder it's super cool. reply mrthrowaway999 5 hours agoparentprevThere's no cost to building slow, fragile, and inefficient websites. When you build programs that run on _your_ computers, you have to pay for that. Or at least have to deal with the finance folks asking why your cloud spend increased 5%. But if you run your software on other people's devices, like frontend devs do, there's barely any cost to that. Any negative signals need to trickle in through user reports, support tickets, and maybe Twitter posts. There's a ton of selection going on there so you're likely not getting the full picture. Ie. It's all about incentives reply margarina72 6 hours agoparentprevNobody got fired for building an app in React? When something is an accepted as an industry standard, it's safe to make a decision that goes with the flow. Also, nobody is doing devrel for html/css/vanilla js - if you search how to do things you will find nearly only exclusively framework related content. reply stavros 6 hours agoparentprevBecause the people who like this approach aren't frontend developers. In fact, I think that people dislike this approach because they are frontend developers, as otherwise there would be very little frontend to develop. reply andyjohnson0 5 hours agoparentprev1. Complexity. Devs like complexity like cats like catnip. 2. Tools. React+JavaScript is the industry monoculture. If they're all you know (and for a significant number of frontend devs this is unfortunately true) then you're invariably going to build something complex because its in the nature of your chosen tools. 3. Career anxiety. Building something simple using simple tools isn't sufficiently hardcore and braggable to get that juicy comp increase at the next performance review, never mind a promotion or hopping to that next job. reply andyjohnson0 4 hours agorootparentA couple of anecdotes relating to point 3 above: a. I once worked on a project where the webapp frontend went through a time-consuming, mid-project framework swapout because the \"senior full-stack developer/architect\" decided it needed server-side rendering for SEO purposes. Never mind that it was a niche industrial app that required a login to use and simply wasn't visible to search engines. b. I remember being advised to stay quiet when I asked why a different web developer, upon being asked to build a simple static website, had nevertheless built it in React. reply bogtog 6 hours agoparentprevMy gut is that the government wants services that work for 100% of people. In terms of purely costs, people who can't use a site may need to be serviced anyway by more expensive means (e.g., voter registration by mail). A business probably thinks that it doesn't need 100% accessibility. A nicer site may be thought to get more users/customers, even if the site doesn't work for many (or maybe devs just want to fit in with the other cool devs making cool dev sites) reply philipwhiuk 6 hours agoparentprevBecause the trend is also towards doing more over the web. The web is replacing traditional thick clients, which also assumed a fairly stable network connection and platform specification. Government systems need to work with the lowest denominator - even if it's not that common. Tech startups only need 1 client to exist at the start (and can mostly trust that their requirements will become commonplace as they scale). reply scarmig 6 hours agoparentprevUIs in general are pretty hard unless you have a set of primitives that do everything you want. HTML + CSS used to be lacking (and still are in some respects). A thin layer of vanilla js on top of them has a tendency to turn into a mess of spaghetti as more and more features are added. So, you organize it into a framework. But a framework needs to be able to assert control over anything that would affect how it renders, which is pretty much everything a browser might do, leading to an SPA. reply dtech 6 hours agoparentprevFirstly it's what looks good in demos, both internally to management and when trying to sell things to consumers. Government services have users without a choice and usually that they have to provide it has been decided top down. Secondly it's less \"boring\" for developers and arguably less work. Thirdly you have a large amount of only-frontend (often only-React) devs know who won't think of alternatives. reply _dain_ 5 hours agorootparent>Secondly it's less \"boring\" for developers and arguably less work. Humphrey: But what happens to us? Bernard: Well, much less work. Humphrey: Yes! Much. Less. Work. So little that fullstack engineers might almost be able to do it on their own! reply slashdave 6 hours agoparentprevBecause browsers are being used as application frameworks (i.e. for making applications) rather than what they were designed for. reply dariusj18 5 hours agorootparentThe dream has long been to have code distributed to thin clients while allowing intensive tasks to be run on servers. reply shadowgovt 5 hours agorootparentThat's one dream. There are advantages to thick clients as well... less network traffic if the device can do processing on site, A much easier to maintain and update distribution model over the traditional desktop experience for what is essentially application software, etc. reply nfw2 6 hours agoparentprevBecause the ux and dx are better once you reach a certain amount of complexity. Companies know what is best for their business. There were will always be a group of devs that don’t like it because it isn’t the same web as in their heyday, and they all will eagerly pile on anything remotely JS-critical is posted on HN. There is a selection bias to the comments that does not accurately reflect the industry opinion. reply arp242 5 hours agorootparent> Companies know what is best for their business. \"Companies\" don't really know anything. The decisions get made by people, with all the flaws that people have. I have seen many developers make decisions that are detrimental to the company. I do agree that there is a section of HN that will pile on these kind of topics, and I have flagged dozens of low-effort swiped against JS over the years that add nothing. But two things can be true at the same time: 1. there is an unpleasant section of HN that will rant about all things JS, and 2. SPAs (or our current approach to them) bring a lot of downsides and are often not worth it. Are entirely compatible. reply nfw2 29 minutes agorootparentI agree there are tradeoffs to SPAs, and I shouldn't have implied that companies are a perfect decision-making apparatus. That said, I think if a certain technology becomes an industry standard, especially one that demonstrates some staying power, as React has, it should not be dismissed out-of-hand, and most of this comments section is doing. reply endemic 5 hours agorootparentprevJS-heavy sites are frustrating to me due to generally worse UX — links can’t be opened in a new tab, because they’re not actually anchor tags. Forms can’t be submitted by the “return” key. Navigation using back/forward buttons is broken. There might be a few companies who get it right, but most don’t. reply mrthrowaway999 5 hours agorootparentprevHow is increased FCP, LCP, ttvc better ux and DX? We've had hard data that decreasing page load time make for better user experience[0]. Please don't make this an Us vs. Them thing. [0]: http://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.... reply nfw2 35 minutes agorootparentThe OP was asking for an explanation why the preferences of the industry diverge from the preferences of this comment section. The question itself identifies two groups. The top comment on this page said the frontend community seems like a jobs program. It's interesting that you are only criticizing the view you disagree with as being too divisive. reply shadowgovt 5 hours agorootparentprevBecause we also have hard data that users absolutely hate a blank or frozen screen and \"CONFIRM FORM RESUBMISSION.\" Users are allowed to hate multiple things at the same time and it's up to the web developers to stack rank those. reply amelius 5 hours agoprevWhy is Linux not in this list: https://www.gov.uk/service-manual/technology/designing-for-d... reply arp242 5 hours agoparentWhy should it be on that list? When does a webpage work on macOS and Windows but not Linux? reply layer8 5 hours agoparentprevLess than 2% of users? reply shadowgovt 5 hours agoparentprevThe flippant answer: because it's a kernel. The non-flippant answer that is related to the flippant answer: because there are dozens of distros and within those distros about a dozen browsers if you factor in all of the Mozilla forks. They could probably choose a blessed one, but any individual blessed one turns out to have an incredibly small user base (Even Ubuntu, to the extent that numbers can be generated as a secondary signal, looks to be about 1% desktop OS share). reply twooclock 6 hours agoprevThis is what I try to follow - serving html with prefetch data from the server, what could be done on client I do on client to minimize server round trips, minimum css (responsive layout) and vanilla js. Separate web pages as needed. Somehow that sounds weird and oldfashioned with my colleagues since I'm using only html, css and vanilla js? I don't miss a thing... reply jt2190 6 hours agoprevEven the article notes that mindless server-side is not good software engineering. (Note the use of the phrase \"can cause problems\" instead of \"does cause problems\".): > If you do choose to use client-side JavaScript frameworks, be aware that although they can be helpful when building a service with a complex user interface, they can introduce problems. > Using a client-side JavaScript framework can: > - increase the overall size of your code base and push processing to the client-side, causing performance issues for users with a slower network connection or lower powered device > - create a reliance on third-party code that your developers do not have control over, requiring you to make major changes to your service in order to stay up to date with changes in the framework > - make it difficult to find people with the skills required to maintain the code, if the framework’s loses popularity over time > If you use a JavaScript framework you should: > - be able to justify with evidence, how using JavaScript would benefit users > - be aware of any negative impacts and be able to mitigate them > - consider whether the benefits of using it outweigh the potential problems > - only use the framework for parts of the user interface that cannot be built using HTML and CSS alone > - design each part of the user interface as a separate component > Having separate components means that if the JavaScript fails to load, it will only be that single component that fails. The rest of the page will load as normal. reply simmerup 6 hours agoprevUser first programming rather than work inflating bloated frameworks mainly used to justify further dev work. Which one do engineers choose reply bigfatkitten 6 hours agoparentThe one they can put in their promo packet, obviously. reply andrepd 6 hours agoparentprevI think SWE must be the only (allegedly) engineering discipline where developer convenience is overtly prioritised above product quality or user experience. If you doubt this, think how many times you've seen a framework advertised due to its ease of use for developers vs due to e.g. performance in low bandwidth. reply endemic 5 hours agorootparentThe funny thing is that DX for JS apps is usually _worse_: 2x the code just so we don’t have a page transition. reply simmerup 5 hours agorootparentAnd also screw up the browsers back functionality in the process reply ksec 6 hours agoprevIf only the rest of the UK Gov IT system is as good as their Web Design teams. Instead they pay huge sums of money to Oracle or Accenture. On another note a lot of the UK Gov Web services runs on Ruby Rails. https://github.com/alphagov reply Elfener 6 hours agoprevA lot of (younger?) people seem to think that you need JS when just a regular html form would do. reply icedchai 6 hours agoparentI’ve run into developers that don’t understand how regular HTML forms work and think everything needs a REST call with JSON. Many of them were not young. reply sscarduzio 5 hours agorootparentMe too, I was devastated. The guy was a super expensive senior react dev. He literally went like: “Wdym multipart form data?” reply Already__Taken 6 hours agoparentprevah ageism. If younger guys think that it's the old lot writing shit docs/blogs giving them the idea. reply earnesti 6 hours agoprevSinge page apps suck arse. This really isn't news to anyone, except for those who make money by developing that garbage. reply randomifcpfan 6 hours agoprev“You should consider using this in your requirements” implies that this is not a hard rule, it’s just an ignorable suggestion. It would be interesting to audit gov.uk web pages over time to see whether this advice is being followed. reply philipwhiuk 6 hours agoparentHaving > You should consider Is Gov UK's way of allowing people internally to point to it and say 'Well, did you consider it?'. UK Digital don't have any direct power to force change - they have to use sensible advice and internal process to encourage better design. reply etothepii 6 hours agoparentprevDon't forget the rules of British English that make it very clear that the grammatical construction: \"you should consider\" means \"you must in all circumstances save for the immediate alternate outcome being a genocide.\" reply randomifcpfan 5 hours agorootparentThanks for explaining! That’s quite different from the US English (and RFC English) meaning of “should”. reply layer8 5 hours agorootparentTo be fair, here is the RFC meaning: SHOULD This word, or the adjective \"RECOMMENDED\", mean that there may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course. It means you can’t simply ignore it, and instead have to have compelling reasons to justify any deviation. reply etothepii 5 hours agorootparentprevThis translation guide is usually helpful. https://polish2english.files.wordpress.com/2011/11/55551980-... I'm afraid I don't know what RFC English is and neither does Google. reply synergy20 6 hours agoprevFor medium to large projects, SPA or not basically boils down to the question where you want to manage the state and logic, is it at frontend(SPA) or backend(MVC,CRUD,etc), you still have to do that somewhere with complexity. If the website is simple then definitely no SPA is needed, either htmx or alpinejs or vanilla can get the job done. reply redman25 4 hours agoparentUnless you're building a local first app (i.e. google sheets), the backend for most web apps is the source of truth. SPAs that lazy load tons of data on the frontend are introducing a lot of complexity trying to sync state between the frontend and backend. Having a single source of truth by push things down into the backend is a godsend in terms of limiting complexity. reply endemic 5 hours agoparentprev> you still have to do that somewhere with complexity Don’t forget about the other “invisible” requirements with a JS solution — more tests, more code, longer builds, more 3rd party libraries. reply synergy20 4 hours agorootparentor you have to test Model View and Controller at the backend, the backend can be messy as well over time, not to mention it has to sync with frontend team. it depends on team experience, e.g. stronger at backend or frontend and more importantly, how they work together. reply Frost1x 4 hours agoprevI’ve helped build significant portions (nearly all, technically speaking) of a few small US government services through contracts, so I’ll share my opinion although I realize US government agencies may be a bit different than those in the UK government. In the US, tech you can deploy varies significantly agency to agency. In my case they were using a dated PHP CMS and we’d have to go through significant efforts and sign offs to get our own simple RDBMs in place on their services. Deploying to cloud infrastructure also was filled with red tape, especially for small applications. Internally they had little experience so forget just spinning up and hosting some AWS service. Then there’s costs, it’s not that such services might be too costly so to speak but money has color in the government and money to build the application is often a different color, maybe entirely different group, than those who will maintain it. So deployment/transfer for handoff is pretty much a nightmare, yet agencies often want (for good reason I’d say) full ownership of the application and surrounding infrastructure. Stakeholders pop up from the agency your working with and any sort of collaborations between other agencies they’re trying to leverage, then if you have your own organization you end up with a superset of “idea makers” from a couple agencies and your own coming up with “wouldn’t it be nice” features from what otherwise should be a simple application. Ultimately for deployment to arbitrary infrastructure and maintenance, SPAs simplify a lot if you absolutely need dynamic content and absolutely struggle to get real server side service infrastructure (eg most government organizations from my experience). So you pack as much complexity as you can into JS because it can somewhat take it, and you rely on user browsers to pickup the slack. This only goes so far of course, as there’s only so much you can do in an SPA that actually runs on a lot of devices but needs some real application functionality, so think small desktop applications, wizards, small computational models (a lot of what I do), etc. So SPAs are the land I’ve been pushing in this space, no matter how much I loathe them in general, they’re one of the best fits for the constraints in these environments (which is why they get them a lot). reply lousken 6 hours agoprevhopefully developers will start paying attention some day, if i see a webpage that renders blank with js off, i leave reply layer8 5 hours agoparentI do the same for sentences starting in lower case and missing punctuation. reply pjmlp 6 hours agoprevGreat that government organisations are putting a break into the insanity of SPA frameworks for static content. reply mentalgear 6 hours agoprevThis advise may have been correct for old-school SPAs, but most if not all points should be fixed in the current generation. E.g. first page load is static or SSR, and then the page is hydrated as a accessible SPA including url manipulation. Also automatic a no-js fallbacks are provided with many. reply wild_egg 6 hours agoparentHaving to deploy a dedicated server unit to render your frontend is a lot of additional complexity for zero benefit when you still require an API server to actually drive everything. Have your API server render the HTML itself and your entire stack becomes radically simpler. Iteration speed goes through the roof. If you're not building Google Sheets, skipping the entire SPA universe provides massive benefits with no notable downsides. The same UX can be provided either way but often with improved performance which actually means a better UX reply mrthrowaway999 6 hours agoparentprevWhy bring in all that extra complexity in the first place, even if it works? Unless there's a good reason to, like long-lived sessions or a complex, updating UI, then I can't think of a reason to send a truckload of js to the user that eats through their CPU like a baby eats through a tub of icecream. Not everyone in the world is sporting the newest MacBook and iPhone. Hell, I'm using a pixel 8 and some sites or components take _seconds_ to load (eg. Twitter search drop-down). reply pylua 6 hours agoparentprevYeah— I was thinking the article was not being fair. That said, try using a website across a wide variety of browsers and os and you will get a wide variety of interpretations. Since it’s a government website that is not acceptable. reply hnarayanan 6 hours agoprevThis is very good advice. reply hakanderyal 5 hours agoprevIn the frontend dev land, there is a constant tension between user experience(UX) and developer experience(DX). Providing good UX with HTML/CSS/Progressive enhancement usually means less-than-ideal DX. And good DX with JS frameworks tends to end up with less-than-ideal UX. Poor DX usually results in slower development, thus devs are usually incentivized to prefer DX over UX. The holy grail of good UX/DX requires exceptional developers whatever path you choose. reply wg0 6 hours agoprevWhen even governments knows the web better than the tech industry by and large itself. I despise React, ended up with Svelte+Typescript and now I realise that could do it all mostly with HTMX + templating with bit of alpine.js if at all. reply mentalgear 6 hours agoparentDespise React's unnecessary complexity and non-standard-compliant non-separation-of-concerns squeeze-it-all-in-js approach as well. Svelte(kit) is still the most W3C compliant of the major frameworks out there. Also, it's not even a runtime-framework but a compiler, meaning you're left with nothing but the necessary HTML, JS & CSS just relevant for your page. reply avaldez_ 49 minutes agorootparent>Svelte(kit) is still the most W3C compliant of the major frameworks out there. Also, it's not even a runtime-framework but a compiler, meaning you're left with nothing but the necessary HTML, JS & CSS just relevant for your page. I'd argue that it's way easier to master the internals of a library than a whole bespoke compiler. reply wg0 6 hours agorootparentprevReact in the hook's era has gotten overly complex. The cods is unreadable and hard to reason about. Check any longer/complicated component as an example riddled with hooks. Comparatively, Svelte has a much simpler mental model and at the end, leaves nothing but basic plain old javascript. But I tend to question these days that do we need this much Javascript? reply shadowgovt 5 hours agorootparentMostly for reactive rendering in response to incoming small data packets (or user supplied changes) mutating state. I have not seen an example of how to do that using vanilla HTML and CSS without some JavaScript support. Maybe it exists and I haven't come across it. reply mhoad 6 hours agorootparentprevLit is also totally web standards compliant to be fair. reply arendtio 5 hours agoprevIn Germany, a government service is considered digital when there is an online form where you can enter the data. Afterward, it doesn't matter if you must print it out and send it via postal services (no kidding); all that is required is an online form. I don't know why many HN users don't like SPAs but I don't know any sites where I have a problem with it from a user perspective. IMHO there are far more badly designed sites. From a developer side it is a completely different story, due to the added complexity and I get it if someone doesn't want to build an SPA/PWA. However, I would take any SPA any day, compared to what the German government offers... reply gryzzly 1 hour agoparentI on the contrary applaud whoever built the new citizenship application form as HTML. It saved state money and users time. I’m quite sure it would have taken longer and worked worse if it was a SPA built by the gov. contractors. reply arendtio 9 minutes agorootparentBut what value does an HTML form alone have? Compared to the old offline version, you have more trouble authenticating before filling it out (which isn't worth anything because you have to sign it anyway...). reply pylua 6 hours agoprevI am definitely one that believes the fronted is way too complicated. That said, however, there is a list of four inaccessibilities in the article, and I was thinking that spas have work around for these. reply globular-toast 6 hours agoprevI started web stuff in the 90s as a child. I didn't know what CSS or JS were, except the latter you could copy/paste some magic scripts to make things flash and suchlike. Later I built dynamic sites with PHP for local businesses. I learnt JS and CSS at this point (to some extent as least). Then I decided to quit web development because I couldn't stand spending so much time things to work with the shittiest browser available (IE6). After almost 6 years away I came back around 2015 when I realised a web server would be useful for whatever I was doing. I was shocked to find the world had forgotten about so much regarding HTML and CSS. We used to build multiple stylesheets for our sites. That was forgotten. We used to make stuff work without JS first, then add JS as a nice-to-have afterwards. That was forgotten. I saw web devs just doing all their form validation in js and the server doing none. Shockingly, this is still common today. I'm not aware of a common pattern where you get the server to do validation and just display it in js. Everyone seems to either duplicate or not even do it on the server at all! When I saw this I was no longer impressed by what people were doing on the web because it wasn't the web I knew, it was just \"applications\" built in JS. Trying to argue for \"web first\" was a losing battle. reply mrthrowaway999 6 hours agoparentSimilar experience. Started with html 3.2/xhtml and css as a kid. Some years later got a job and did Django + jQuery, but found myself drawn into infra. A year ago I worked alongside a web dev team and decided to peek into their work--nothing made sense anymore. The amount of complexity was staggering. It seemed like they spent most of their time managing that complexity, eg. reducing build times, solving dependency problems, solving weird TS issues, handling errors in different components, etc. In the Django+jQuery days, the emphasis was still always on what user got to see and use. reply Gooblebrai 6 hours agoparentprevI'd argue that doing client validation saves your server from superfluous requests just to validate that your username input has less than 16 characters. Of course, you later still do it in the server again because you can't never trust the clients Reducing server workload is useful reply amazingamazing 6 hours agoprevThere are bad sever side apps and “single page apps”. reply sscarduzio 5 hours agoprevCan Gov.uk become the new W3C? Pretty please? reply layer8 5 hours agoparentYou mean the new WHATWG. reply raddan 6 hours agoprev> If your JavaScript uses a syntax or calls an API that is not supported in the user’s browser, it will error … Pet peeve: when did “to error” become a verb? Otherwise, I wish the rest of the web were designed this way. reply margarina72 6 hours agoparentit depends which release of the english language you are using reply voidr 2 hours agoprevI love simple and accessible websites as much as everyone else, but I believe this leans way too much into extremity and dictates solutions instead of requirements. JavaScript has appeared in 1995, it's now technically impossible to use a browser that doesn't support JS, because it will fail to load the website due to its old SSL/TLS stack, worrying about JS support is just insane. Not using JavaScript doesn't give you accessibility by default, see:The whole article feels like it was written my someone stuck in the early 2000s, you can make a well designed and accessible SPA. Using stone age technology should not be the goal, accessibility should be the goal. The tax section of the gov.uk domain follows these guidelines and it's a mess, other pages can also be very difficult to use. reply andrepd 6 hours agoprevSome different type of praise: I absolutely love the voice used throughout gov.uk (this page being no exception). The language and tone is clear, straightforward, to the point, neutral, as technical as it needs to be and no more, and stripped of unnecessary flourish, without being dry. Amazing! reply shadowgovt 5 hours agoprevThey can have whatever rules they want, but for what it's worth there's nothing about SPAs that makes those four bullet points a reason not to do them. You can write an SPA that is accessibility friendly, maintains focus, and respects the back button. But, when you were writing one you do take on all of those responsibilities as the author. You are substituting the browser's standard behaviors with behaviors of your own choice. reply locallost 6 hours agoprevIt's not entirely the fault of developers that we are in this state, where they follow every \"fad\" (if it's a fad). People get paid better when they do modern tech, especially if they do slightly mundane work, e.g. apps that boil down to forms and CRUD, that have a lot of detail to get right, but aren't that challenging on its own (they often end up being). I remember about 10 years ago, I did a bit of Angular in some projects and there was a client that knew that and insisted I was working for them. I even heard my boss on the phone once saying \"yes so and so is not the only one that does Angular\". So I had it good just because I dabbled in tech that was hot at the moment. Other devs also want to be in that place so they follow the trends. It is partially the fault of developers because they do their best to make this field what Alan Kay calls \"pop culture and not really a field\". I spent recently a lot of time questioning certain tools we use that I consider useless for us, but it's \"standard\" because someone else uses it and it spreads around because again you don't want to be left behind in your CV. For a lot of people the most important is to check all the tech boxes (spa, docker, kubernetes, cloud), but that the actual product is poor is less relevant. The outcomes are poor because a lot of this stuff is actually really hard, but if you take that approach it will take you forever to really master all the details of your craft. So instead you make it barely work on the happiest path and you've shipped your app as a full stack developer. I don't know the solution, but articles like these are a good start. reply IshKebab 6 hours agoprevOk but let's not deify gov.uk. Yes it's very good compared to most government websites but it's not the peak of web design. They are so anally averse to any form of JavaScript or interactivity that often the web pages become quite tedious to use, e.g. when picking dates for payments, they don't have a \"tomorrow\" button even though that's what you want 99.999% of the time because that would need the dreaded JavaScript. reply philgyford 5 hours agoparentPersonally I'd always want \"today\", never \"tomorrow\". So now we have two extra buttons on the form. And perhaps the extensive user testing that gov.uk do would discover that for most people this added UI complexity makes the form less usable than keeping it as simple as possible. reply IshKebab 3 hours agorootparentToday isn't an option for the form I'm thinking of (tax free childcare); you can't set up payments for the same day. Really you want \"asap\" but I was simplifying for discussion. reply dracos 2 hours agorootparentI agree the tax-free childcare form could certainly be improved (I've even written a script to do the three-monthly reconfirmation for me, see my latest gist, though that's policy rather than tech!), but you can set up payments for the same day, you put today's date in (that is what I do; it gives a \"You've asked for a payment of £x to be made to [site] today\" extra confirmation step). There's nothing in the service manual page that says they couldn't enhance this form with a button as you're suggesting, and hopefully one day they will, though you're always actually worrying it could get worse... reply lupire 5 hours agoparentprevThere is no need for JavaScript for a Tomorrow button. reply meindnoch 6 hours agoprev [–] Amen. Amen. Amen. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Progressive enhancement starts with HTML, then adds CSS and JavaScript, ensuring basic functionality and accessibility for all users, including those with device or connectivity limitations.",
      "JavaScript should enhance, not replace, HTML and CSS functionality; use feature detection, polyfills, and transpiling to ensure compatibility.",
      "Avoid Single Page Applications (SPAs) as they can hinder accessibility and navigation; ensure your service remains functional despite potential CSS/JavaScript failures."
    ],
    "commentSummary": [
      "The post discusses the benefits of building frontends using progressive enhancement, focusing on HTML and CSS with minimal JavaScript, as exemplified by gov.uk.",
      "Many developers express frustration with the unnecessary complexity introduced by Single Page Applications (SPAs) and modern JavaScript frameworks, advocating for simpler, more maintainable solutions.",
      "The conversation highlights a growing trend towards reconsidering simpler, HTML-based solutions, with tools like htmx gaining attention for their ability to reduce frontend complexity."
    ],
    "points": 208,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1727610895
  },
  {
    "id": 41683577,
    "title": "Notion's mid-life crisis",
    "originLink": "https://www.jjinux.com/2024/09/notions-mid-life-crisis.html",
    "originBody": "JJinuxLand: Notion's Mid-Life Crisis */ /* BEGIN CUT */ { \"font:Text\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"color:Text\": \"#333333\", \"image:Background\": \"#EEEEEE none repeat scroll top left\", \"color:Background\": \"#EEEEEE\", \"color:Header Background\": \"#F3F3F3\", \"color:Primary\": \"#333333\", \"color:Menu Text\": \"#FFFFFF\", \"font:Menu\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"font:Link\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"color:Link\": \"#009EB8\", \"color:Link Visited\": \"#009EB8\", \"color:Link Hover\": \"#009EB8\", \"font:Blog Title\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"color:Blog Title\": \"#555555\", \"font:Blog Description\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"color:Blog Description\": \"#555555\", \"font:Post Title\": \"'Helvetica Neue Light', HelveticaNeue-Light, 'Helvetica Neue', Helvetica, Arial, sans-serif\", \"color:Post Title\": \"#333333\", \"color:Ribbon\": \"#666666\", \"color:Ribbon Hover\": \"#AD3A2B\", \"view\": \"classic\" } /* END CUT */ /* Really wide code blocks overflow in an ugly way without this. */ pre { overflow: auto; } /* I don't like the way it's spacing out h2s. See \"Embracing Risk Responsibly\" near https://www.jjinux.com/2022/06/security-bsidessf-2022.html */ .article .article-content { text-align: left; /* Was justify. */ } -->window.onload = function() { blogger.ui().configure().view(); }; window['__wavt'] = 'AOuZoY6XEEE3oAAKnjYbFvs1VMDjPmO5Dg:1727622518842';_WidgetManager._Init('//www.blogger.com/rearrange?blogID\\x3d11788780','//www.jjinux.com/2024/09/notions-mid-life-crisis.html','11788780'); _WidgetManager._SetDataContext([{'name': 'blog', 'data': {'blogId': '11788780', 'title': 'JJinuxLand', 'url': 'https://www.jjinux.com/2024/09/notions-mid-life-crisis.html', 'canonicalUrl': 'https://www.jjinux.com/2024/09/notions-mid-life-crisis.html', 'homepageUrl': 'https://www.jjinux.com/', 'searchUrl': 'https://www.jjinux.com/search', 'canonicalHomepageUrl': 'https://www.jjinux.com/', 'blogspotFaviconUrl': 'https://www.jjinux.com/favicon.ico', 'bloggerUrl': 'https://www.blogger.com', 'hasCustomDomain': true, 'httpsEnabled': true, 'enabledCommentProfileImages': true, 'gPlusViewType': 'FILTERED_POSTMOD', 'adultContent': false, 'analyticsAccountNumber': '', 'encoding': 'UTF-8', 'locale': 'en', 'localeUnderscoreDelimited': 'en', 'languageDirection': 'ltr', 'isPrivate': false, 'isMobile': false, 'isMobileRequest': false, 'mobileClass': '', 'isPrivateBlog': false, 'isDynamicViewsAvailable': true, 'feedLinks': '\\x3clink rel\\x3d\\x22alternate\\x22 type\\x3d\\x22application/atom+xml\\x22 title\\x3d\\x22JJinuxLand - Atom\\x22 href\\x3d\\x22https://www.jjinux.com/feeds/posts/default\\x22 /\\x3e\\x3clink rel\\x3d\\x22alternate\\x22 type\\x3d\\x22application/rss+xml\\x22 title\\x3d\\x22JJinuxLand - RSS\\x22 href\\x3d\\x22https://www.jjinux.com/feeds/posts/default?alt\\x3drss\\x22 /\\x3e\\x3clink rel\\x3d\\x22service.post\\x22 type\\x3d\\x22application/atom+xml\\x22 title\\x3d\\x22JJinuxLand - Atom\\x22 href\\x3d\\x22https://www.blogger.com/feeds/11788780/posts/default\\x22 /\\x3e\\x3clink rel\\x3d\\x22alternate\\x22 type\\x3d\\x22application/atom+xml\\x22 title\\x3d\\x22JJinuxLand - Atom\\x22 href\\x3d\\x22https://www.jjinux.com/feeds/6002837042073203452/comments/default\\x22 /\\x3e', 'meTag': '', 'adsenseHostId': 'ca-host-pub-1556223355139109', 'adsenseHasAds': false, 'adsenseAutoAds': false, 'boqCommentIframeForm': true, 'loginRedirectParam': '', 'view': '', 'dynamicViewsCommentsSrc': '//www.blogblog.com/dynamicviews/4224c15c4e7c9321/js/comments.js', 'dynamicViewsScriptSrc': '//www.blogblog.com/dynamicviews/d9db63b9119a00a5', 'plusOneApiSrc': 'https://apis.google.com/js/platform.js', 'disableGComments': true, 'interstitialAccepted': false, 'sharing': {'platforms': [{'name': 'Get link', 'key': 'link', 'shareMessage': 'Get link', 'target': ''}, {'name': 'Facebook', 'key': 'facebook', 'shareMessage': 'Share to Facebook', 'target': 'facebook'}, {'name': 'BlogThis!', 'key': 'blogThis', 'shareMessage': 'BlogThis!', 'target': 'blog'}, {'name': 'Twitter', 'key': 'twitter', 'shareMessage': 'Share to Twitter', 'target': 'twitter'}, {'name': 'Pinterest', 'key': 'pinterest', 'shareMessage': 'Share to Pinterest', 'target': 'pinterest'}, {'name': 'Email', 'key': 'email', 'shareMessage': 'Email', 'target': 'email'}], 'disableGooglePlus': true, 'googlePlusShareButtonWidth': 0, 'googlePlusBootstrap': '\\x3cscript type\\x3d\\x22text/javascript\\x22\\x3ewindow.___gcfg \\x3d {\\x27lang\\x27: \\x27en\\x27};\\x3c/script\\x3e'}, 'hasCustomJumpLinkMessage': false, 'jumpLinkMessage': 'Read more', 'pageType': 'item', 'postId': '6002837042073203452', 'pageName': 'Notion\\x27s Mid-Life Crisis', 'pageTitle': 'JJinuxLand: Notion\\x27s Mid-Life Crisis'}}, {'name': 'features', 'data': {}}, {'name': 'messages', 'data': {'edit': 'Edit', 'linkCopiedToClipboard': 'Link copied to clipboard!', 'ok': 'Ok', 'postLink': 'Post Link'}}, {'name': 'skin', 'data': {'vars': {'link_color': '#009EB8', 'post_title_color': '#333333', 'blog_description_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'body_background_color': '#EEEEEE', 'ribbon_color': '#666666', 'body_background': '#EEEEEE none repeat scroll top left', 'blitzview': 'classic', 'link_visited_color': '#009EB8', 'link_hover_color': '#009EB8', 'header_background_color': '#F3F3F3', 'keycolor': '#ffffff', 'page_text_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'blog_title_color': '#555555', 'ribbon_hover_color': '#AD3A2B', 'blog_title_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'link_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'menu_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'primary_color': '#333333', 'page_text_color': '#333333', 'post_title_font': '\\x27Helvetica Neue Light\\x27, HelveticaNeue-Light, \\x27Helvetica Neue\\x27, Helvetica, Arial, sans-serif', 'blog_description_color': '#555555', 'menu_text_color': '#FFFFFF'}, 'override': '/* Really wide code blocks overflow in an ugly way without this. */pre { overflow: auto;}/* I don\\x27t like the way it\\x27s spacing out h2s. See \\x22Embracing Risk Responsibly\\x22 near https://www.jjinux.com/2022/06/security-bsidessf-2022.html*/.article .article-content { text-align: left; /* Was justify. */}', 'url': 'blitz.css'}}, {'name': 'template', 'data': {'name': 'Dynamic Views', 'localizedName': 'Dynamic Views', 'isResponsive': false, 'isAlternateRendering': false, 'isCustom': false, 'variant': 'classic', 'variantId': 'classic'}}, {'name': 'view', 'data': {'classic': {'name': 'classic', 'url': '?view\\x3dclassic'}, 'flipcard': {'name': 'flipcard', 'url': '?view\\x3dflipcard'}, 'magazine': {'name': 'magazine', 'url': '?view\\x3dmagazine'}, 'mosaic': {'name': 'mosaic', 'url': '?view\\x3dmosaic'}, 'sidebar': {'name': 'sidebar', 'url': '?view\\x3dsidebar'}, 'snapshot': {'name': 'snapshot', 'url': '?view\\x3dsnapshot'}, 'timeslide': {'name': 'timeslide', 'url': '?view\\x3dtimeslide'}, 'isMobile': false, 'title': 'Notion\\x27s Mid-Life Crisis', 'description': 'Notion sat down on the curb, crushed his cigarette into the pavement, put his face into his hands, and sobbed. It felt good to finally let i...', 'url': 'https://www.jjinux.com/2024/09/notions-mid-life-crisis.html', 'type': 'item', 'isSingleItem': true, 'isMultipleItems': false, 'isError': false, 'isPage': false, 'isPost': true, 'isHomepage': false, 'isArchive': false, 'isLabelSearch': false, 'postId': 6002837042073203452}}]); _WidgetManager._RegisterWidget('_BlogView', new _WidgetInfo('Blog1', 'main', document.getElementById('Blog1'), {'cmtInteractionsEnabled': false, 'lightboxEnabled': true, 'lightboxModuleUrl': 'https://www.blogger.com/static/v1/jsbin/3155624978-lbx.js', 'lightboxCssUrl': 'https://www.blogger.com/static/v1/v-css/13464135-lightbox_bundle.css'}, 'displayModeFull')); _WidgetManager._RegisterWidget('_HeaderView', new _WidgetInfo('Header1', 'sidebar-right-1', document.getElementById('Header1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_NavbarView', new _WidgetInfo('Navbar1', 'sidebar-right-1', document.getElementById('Navbar1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_BlogSearchView', new _WidgetInfo('BlogSearch1', 'sidebar-right-1', document.getElementById('BlogSearch1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_ImageView', new _WidgetInfo('Image1', 'sidebar-right-1', document.getElementById('Image1'), {'resize': true}, 'displayModeFull')); _WidgetManager._RegisterWidget('_PopularPostsView', new _WidgetInfo('PopularPosts1', 'sidebar-right-1', document.getElementById('PopularPosts1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_TextView', new _WidgetInfo('Text1', 'sidebar-right-1', document.getElementById('Text1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_BlogArchiveView', new _WidgetInfo('BlogArchive1', 'sidebar-right-1', document.getElementById('BlogArchive1'), {'languageDirection': 'ltr', 'loadingMessage': 'Loading\\x26hellip;'}, 'displayModeFull')); _WidgetManager._RegisterWidget('_LabelView', new _WidgetInfo('Label1', 'sidebar-right-1', document.getElementById('Label1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_LinkListView', new _WidgetInfo('LinkList1', 'sidebar-right-1', document.getElementById('LinkList1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_SubscribeView', new _WidgetInfo('Subscribe1', 'sidebar-right-1', document.getElementById('Subscribe1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_BloggerButtonView', new _WidgetInfo('BloggerButton1', 'sidebar-right-1', document.getElementById('BloggerButton1'), {}, 'displayModeFull')); _WidgetManager._RegisterWidget('_HTMLView', new _WidgetInfo('HTML1', 'sidebar-right-1', document.getElementById('HTML1'), {}, 'displayModeFull'));",
    "commentLink": "https://news.ycombinator.com/item?id=41683577",
    "commentBody": "Notion's mid-life crisis (jjinux.com)201 points by krishna2 19 hours agohidepastfavorite140 comments Aurornis 17 hours agoI enjoyed Notion at first for certain tasks, but it became much less enjoyable as everyone tried to force everything into emoji-laden Notion docs. The Notion spaces used by the Product and Program managers I worked with in the past few years have become a collection of half-finished documents that are always out of date, hard to find, and often superseded by some new Notion page they created but forgot to tell us about until we had spent weeks following the old one. In a way, Notion has come to occupy the same space as Jira for me: A tool that tries to be everything to everyone and gets abused by people who feel like using as many features as possible is a best practice. I’ve had better success lately asking people to step outside of Notion and instead work in an old-fashioned shared Google doc. It’s amazing how much more productive we can all be when the tools are simplified to exactly what we need and people don’t feel like they need to sprinkle emojis and checklists and other features into everything just because they can. reply redsparrow 5 hours agoparent> a collection of half-finished documents that are always out of date I think of company wikis as a place where information goes to die. A useful feature, which I'm sure exists somewhere, would be \"freshness\" checks on pages. A timestamp for the last time someone looked at this and said \"yes, this is still valid\". For pages that are important, a team could set up recurring tasks for people to do periodic freshness checks. Surely this is already a common practice, although not any team I've been on. Undoubtedly there is some ISO-9000 process for this... reply dgunay 16 hours agoparentprevI don't get why Notion is so popular either, but your complaints about it seem like a skill issue on the part of your managers. I see this a lot too, but in my experience it happens no matter the medium - Google Docs, Figma, Jira, etc. People who don't obsess over keeping it organized eventually spaghetti their documentation all over the place. I wouldn't expect the kinds of people who need to be convinced of the worth of refactoring and getting rid of old code to also understand that out of date documentation needs to be updated or it is often more harmful than just deleting it. reply more_corn 3 hours agorootparentTry writing documentation in confluence and you’ll get why Notion is preferable. Also go try to find something you wrote in confluence six months ago. reply hnthrowaway121 17 hours agoparentprev> but forgot to tell us about until we had spent weeks following the old one. To be fair that’s not on Notion per se, there’s an underlying communication problem (which it sounds like your google doc solves!). reply 1123581321 6 hours agoparentprevEmoji overuse aside, you are describing the challenge of maintaining a team wiki, regardless of software. Google Docs is taking people out of the wiki mindset, I suspect. I agree there are issues any time the bored folks in “product” are allowed to set up, well, anything, honestly. reply threeseed 17 hours agoparentprev> A tool that tries to be everything to everyone Jira doesn't try to be everything. It's a project management app. It does nothing else. Notion is wiki, CRM, project management, calendar etc. reply Supermancho 16 hours agorootparent> It's a project management app. It does nothing else. I would say it doesn't do that very well. You can't manage projects without mapping out dependencies, visually and with integrated relationship tracking. JIRA is miserable at this. reply paulddraper 14 hours agorootparentIt's an issue tracker, with some project management/agile bolted on reply dartos 17 hours agorootparentprevpeople also use jira as a support ticket system. Sprint planning system. Kanban system. I’ve seen it set up so that it can track work across kanban teams and scrum teams. Jira has deep integration with bitbucket, confluence, and GitHub. It can manage your CI pipelines as well. Jira is an anything app with a bend towards project management. Setting up jira workflows is a whole career. Source: I worked at Atlassian for 5 years and they use jira as the backbone for _everything_. It all flows into jira. reply threeseed 15 hours agorootparenta) Support tickets, sprint planning, kanban etc are all part of project management. b) It can't manage your pipelines. It can visualise deployments and link them to work but you still need some sort of CI/CD tool like Bitbucket, Github etc. c) It is not an anything app. I can't use it as a wiki, CRM, database, calendar etc. reply llamaLord 16 hours agorootparentprevYeah but saying Jira is like Notion makes fundamentally no sense when Confluence is sitting like... Right there... reply ethbr1 14 hours agorootparentSssh. You'll remind the Jira feature team that Confluence exists! reply refulgentis 16 hours agorootparentprevpeople also use email as a support ticket system. Sprint planning system. Kanban system. I’ve seen it set up so that it can track work across kanban teams and scrum teams. Email has deep integration with bitbucket, confluence, and GitHub. Email can manage your CI pipelines as well. Email is an anything app with a bend towards project management. Setting up email workflows is a whole career. Source: I worked at Google for years and they use email as the backbone for _everything_. It all flows into email reply 015a 15 hours agorootparentprevIts kind of funny that you'd list four features of notion, three of which people absolutely do regularly and normally use Jira for (e.g. https://support.atlassian.com/jira-work-management/docs/use-...). The 4th, a Wiki, is of course more-so just Confluence, but I have seen echoes of a wiki make their way into Jira; e.g. in one place I worked, every release was a ticket that was duplicated from a previous ticket, and that ticket had step-by-step instructions on how to run different parts of the release. You're just wrong on this, bro. Notion tries to be everything to everyone. Jira is everything to everyone, it doesn't matter what it tries to be. reply threeseed 14 hours agorootparentIt's amazing how people think Project Management = Issues (and only issues). Release Management is a fundamental part of IT Project Management. So of course companies use Jira to track releases. And of course you can tie milestones and OKRs to releases. And of course tickets can have small amounts of text content associated with them. How else would you describe the ticket without them ? But the idea of Jira being remotely like a Confluence style wiki is just ridiculous. And your comment is out of some parallel universe where Jira is Confluence. reply 015a 13 hours agorootparentYou must of missed the multiple points where I said \"three out of four\" and \"echoes\" of a wiki; but reading comprehension is hard, don't worry you'll get 'em next time. reply btown 18 hours agoprevI've often thought that, looking historically, Notion only exists because product innovation in Google Docs is decoupled from revenue growth for Google Workspace. Putting a draggable handle, at the user's election, alongside every paragraph in Docs, and adding a customizable shortcut for search across docs, would go a long way towards Docs being 90% of what Notion's value proposition was as of a few years ago. But most startups using Notion already had Google Workspace for email anyways, so there was no growth story there for Google to invest in this mandate. Now, Notion's done a lot since then. If you want a knowledge base that can also have semi-structured tabular data, and portability in that data, it's hard to beat. Notion AI, pulling from disparate sources with the context of the current planning document, is really neat, too! But not every company will want to pay the per-head cost for this, unless it can replace other existing tools. And when it comes to spaces like CRM in that context, looking at https://www.google.com/search?q=notion+crm&udm=14 ... there's a lot that could be said about Notion's (lack of) SEO/advertising there, but more concretely, a CRM solution nowadays has to bring a wealth of integrations as a near-prerequisite, and Notion doesn't have a mature story there - nor can they easily, because different customers will have different data models that make it hard to have a standardized notion of \"what fields can I count on to be present for an Account.\" Notion is a really powerful system. If it didn't already have a $10B valuation, it would be in tremendously good shape. But it has a long way to go to find the areas of growth it needs to grow beyond $10B. reply replwoacause 16 hours agoparentIt’s just too bad Notion AI can’t see data stored in databases, which is arguably Notions biggest value add and differentiator. So given that it can’t use that data with AI queries really limits the usefulness of it. reply PaulHoule 16 hours agorootparentRight now tabular data is where LLMs go to die but that's an active research area. reply euroderf 13 hours agorootparentprevI don't see why Notion-adjacent apps don't just deeply integrate SQLite for everything table-related. What am i missing ? reply apsurd 17 hours agoprevAnother anecdote added to the \"I don't get notion\" pile. I just don't get notion. I use Apple Notes for everything id use notion for + scratch.txt on every project folder root. (i've used notion, quip, gdocs, dropbox paper) Notion lives rent free in my mind because while im indifferent to it, people seem to LOVE it. and that's so fascinating. even this article, I upvoted it because the conversation about notion is interesting, the article itself is a dud after reading it. we live in a world where Notion is a multi billion dollar company and i have no idea why—now that's interesting! reply BadHumans 17 hours agoparentNotion is popular because it is infinitely customizable. Want to draw in your Notion database? Done. Want to do Kanban? Easy. Gantt Charts? Child's play. Whatever you want Notion to do it likely can be and it is available on any device you want and you can share it with your team so working with other people is not a pain in the ass like it is with most plain text note taking. reply dboreham 17 hours agorootparentSpeaking as someone who tried quite hard to make it do the thing I wanted, not sure that's true. reply pants2 13 hours agorootparentprevJust don't try to center text on the page! reply rchaud 2 hours agoparentprevNotion is popular with college/university students, which is why there are a billion \"Notion Template\" videos online. Many have productized their templates and turned them into something to sell -- sort of like selling notebooks with Cornell note-taking method pattern built in, back in the old days. I see it at similar to Figma in the sense that both tools are cloud-based and free, and their users love yapping about it. reply JojoFatsani 17 hours agoparentprevGod I hate notion. The way it splits columns until you have like two horizontal inches to type in, the rubber-band linking of documents, just the total lack of opinionation outside of templates.. I might be strange but I just really vibed with Confluence and I’d be happy with it if people would commit to it. reply apsurd 16 hours agorootparentlol you reminded me when i very first onboarded to notion i kept trying to write something and the magic paragraph thing kept popping up and im like WTF can i just… i'm trying to… wtf… and i wanted to try to use it, so i looked up the magic and i kept trying to magic and it just went zero to a million i guess in my understanding. no idea how to get collapsible sections. I felt very dumb. Like i just want to write this thing and it wants me to be more magical about what i'm trying to write and fuck it's just text, get the fuck out of my way. i think it's just there are notion users and then there's everyone else. I recovered in my self love again. I use txt files in my ancient sublime editor :) reply iforgotmysocks 17 hours agoparentprevApple Notes is underrated. There is no flashy features to distract you. Just you and your notes. reply luckman212 16 hours agorootparentI strongly disagree for these reasons: - note data stored in a proprietary format - no way to access note data from other apps/api - no way to export in bulk, or in any other format than PDF (a terrible format for notes) - iCloud sync is a mildly terrifying thing to entrust important data to I use Apple Notes for the occasional quick grocery list but that's about it. reply 015a 15 hours agorootparentI don't get the \"note data is stored in a proprietary format\" hate. There's a dozen different open source tools you can find which will one-shot export your Apple Notes to markdown, when you want to leave the ecosystem. Its not like Notion where the exports are messy, non-bulk, and destructive; they're proprietary, but parseable and sitting in a file on your MacOS filesystem. I've never had iCloud Sync display any weird behavior in Apple Notes, and I've got thousands in there. I have, absolutely, seen Obsidian Sync delete notes I did not delete, and fail to upload notes; both of these were generally remediable via their recycle bin, but still very concerning. All of these complaints are of the nature of \"I don't actually have anything valuable to write down so I'd rather worry about the nature of the tool than what I'm writing\". And, to be clear, I think this is why Notion is so popular, just for different reasons than your's; it looks great, and makes you feel productive because you've got amazing cross-referenced tables and hyperbacklinks and h1h2h3s and then wait where's the content? reply vunderba 32 minutes agorootparentCounterpoint, I have seen sync issues on very popular large note, cloud-based solutions that use proprietary formats - Evernote comes to mind. When you have tens of thousands of notes, it's hard to even know if at some point, the note has been suddenly changed, reverted, or modified in a way that you didn't even realize occurred. With an open format, specifically a text based one like Markdown, I can sync all my notes to a git repository in a diffable manner that I can quickly review. reply threeseed 13 hours agorootparentprevNotes data is stored in an open SQLite3 database as Protocol Buffer data: sqlite3 \"~/Library/Group Containers/group.com.apple.notes/NoteStore.sqlite\" This is because it needs to support CRDT style syncing. But the schemas have been decoded so you can access it using pretty much any language. reply jazzyjackson 15 hours agorootparentprevIf you sync your notes to icloud you can bulk export to flat text files via https://privacy.apple.com/ > \"request a copy of your data\" I've never experienced data loss due to icloud sync YMMV reply apsurd 16 hours agorootparentprevGreat points i also agree with. That's Apple being Apple. I'd want an open format for sure. Thing about Apple Notes is in spite of the open ideals, if you're in the apple ecosystem, it's just easily there, on all devices, very unassuming and simply, and that's so so very valuable. It's the long view that gets me. Over the last 20 years, if i'm in the Apple ecosystem, notes are there, synced across everything, and it's just text. and it's simple. reply jen729w 16 hours agorootparentprev#tag support across shared Notes is also abysmal. The new tag doesn’t appear as an actual tag in person 2’s system until they ‘initiate’ it. I tried really hard to love Notes. I wanted to. For the reasons you note, and this one, and many others, I couldn’t. reply personjerry 14 hours agorootparentprevThere's ways to export the notes btw, for example https://github.com/storizzi/notes-exporter reply antifa 3 hours agorootparentpreviCloud notes really needs a markdown mode or a non-WYSIWYG mode. reply pbh101 16 hours agorootparentprevAgree on all the above except that iCloud sync seems to have been rock-solid for years now. reply easeout 16 hours agorootparentprevYou say that, but there are tons of features in Notes. They're just successfully kept out of your way until you go looking for them, so when you just want a note that's what you get. This is progressive disclosure, a longtime tenet of Apple GUI design. A relevant and somewhat meta example: This year they added disclosable sections, which were previously a differentiator for Notion. That's in addition to handwriting selection and editing, voice memos, collaborative editing… Not to mention it's still a regular app and you can have as many note windows as you want. reply DavidPiper 15 hours agorootparentI'm in the process of moving all (~2000) of my Apple Notes to Logseq. I still think Apple Notes is excellent, and I'll still be using it for Inbox-style notes. But it just needs to be a bit more open and extendable. Give me good tables, proper linking between notes and a graph view (or at least an API so I can build that myself) and I'll be back forever. reply two_cents 16 hours agorootparentprevApple Notes is pretty close to perfect for me - it's just missing Markdown support and backlinks. I did just figure out how to link notes together with the '>>' shortcut, which is a game-changer. I've tried a bunch of other apps, but I always come back to Notes. reply apsurd 8 hours agorootparenthttps://www.pronotes.app/ gives you markdown and back links on mac. I've been pretty happy with it since i use notes so often. reply jaynate 16 hours agorootparentprevTotally agree. Use it for everything. Even replaced my handwritten notebooks since I got new iPad Pro w pencil. reply richardlblair 16 hours agoparentprevI was thinking about a super simple app I wanted to whip together today... Then I realized I can just do what I want in Notion with almost 0 effort. reply apsurd 16 hours agorootparentdo tell? reply ilrwbwrkhv 17 hours agoparentprevHumans naturally love to twiddle knobs and move things around. Notion attaches that behavior with money making through an affiliate program. Result is a billion dollar company. reply tucnak 12 hours agorootparentthia is the best assay i read on notion ever reply curious-tech-12 17 hours agoparentprevcant agree more, I initially used to think I am using it wrong but seriously I cant get notion. reply karakanb 17 hours agoprevIt still blows my mind that Google Docs still haven't taken over Notion's business altogether. I have used Notion for ~6 months for my own company, ended up going back to Google Docs because it was not worth it. I am sure there are a billion other uses of it, we weren't using any of its database-like features, just as an internal documentation platform, but still fascinating to see a business thrive on the lack of innovation of a giant. In practice, Google could put a tree-like organization of docs on the sidebar, make the search a bit comfier, and make draggable blocks, and get 80% of the Notion users. I guess they don't have a financial incentive to make docs better, but I would gladly pay extra to have everything there. I guess someone could build a browser extension that adds that UI to Google Docs, or eventually I'll go and do it myself. reply lmm 15 hours agoparent> Google could put a tree-like organization of docs on the sidebar, make the search a bit comfier, and make draggable blocks, and get 80% of the Notion users. Technically they can. Organisationally they can't. > I guess someone could build a browser extension that adds that UI to Google Docs, or eventually I'll go and do it myself. You won't though, or at best you'll make a rough-and-ready version that works for you. Polished stuff doesn't get created without a business model, and you can't make a business model out of a browser extension that messes with a third-party site, not these days anyway. reply nunez 4 hours agoparentprevI am not a huge fan of Notion either, but documentation organization is a huge strength of the tool. Google Docs is too heavy by comparison. Additionally, Notions database capabilities cannot be ignored. You can easily make Notion a task tracker that lives with your documentation. Huge. reply mvkel 17 hours agoparentprevAll of the GSuite was an acquisition, so it's kind of amazing that it has been maintained, let alone continues to exist, at all reply tucnak 12 hours agorootparentAll of Google is acquisitions reply epiccoleman 18 hours agoprevI like Notion but I share the sense that it's not really targeted at my use case anymore. I think I could essentially move everything into Obsidian and lose almost nothing in the process. I just use it for taking notes and writing stuff down. I like how easy it is to drop an image, video, or document into a notion page, but I've only barely used features like databases which seem to be the big selling point, and none of my usage of those is really anything that couldn't just be a plaintext table in a markdown doc. One of these days I'll get up the gumption to crawl through, excise what's worth keeping into Obsidian , and cancel my subscription. But not today, lol. reply diego_sandoval 18 hours agoparentI started as an Obsidian user, and generally I like the fact that it's just Markdown, but markdown tables really suck, to the point that I simply ended up avoiding them at all costs, and I used OnlyOffice's Excel equivalent in parallel to Obsidian for a while. But Notion has good tables by default, so I can have both good tables (and tableviews) and normal text files in the same app. I could have tried Obsidian plugins, but I suspect that it would have been a time sink, and Notion offered everything in a neat package, so in the end, it won. reply strken 16 hours agorootparentI would find markdown tables easier to use if they were just CSV and some delimiters for start/header/end. Imagine being able to write +------------------------------+ Product,Cost per seat,Importance +------------------------------+ GSuite,$7.20,Critical Notion,$10,High \"Something, \"\"with\"\", commas and double-quotes\",$5,Low +------------------------------+ reply vunderba 17 hours agorootparentprevI think that's fair. I will say that Obsidian's tables have gotten a lot better in terms of reflow, sorting, etc. At some point Obsidian might add some additional config to their tables to allow users to manually control column widths, etc., but it would have to be non-standard markdown - like how you can scale down images by adding a width parameter. ![[./media/example_image.png|Custom caption|450]] reply base698 18 hours agorootparentprevI just migrated everything out of Notion into Ibsidian. Notion was unusable after more than a few hundred items in a DB. I migrated to using dataview and lists in Obsidian and haven't had a problem since. And it works offline. I use it for my workout logbook and cooking/recipe log with hundreds of entries. reply remram 1 hour agorootparentI find DataView to be clunky as well. Data entry is not easy (I'm currently using \"DB Folder\" and it helps but it's quirky) and each-row-is-a-file does not give great performance. reply abhinavk 15 hours agorootparentprevObsidian needs to officially embed SQLite. reply TheDong 17 hours agorootparentprevnotion doesn't have normal text files. You can click \"export to markdown\" on a notion page, you can click \"import from markdown\", but those two markdown dialects are totally incompatible. Most of the time notion can't even read what it exported. The notion web editor for me has very noticeable lag, so I really want to just be able to write some text somewhere to represent a notion table or whatever, but there's simply no supported way to do that I'm aware of. I mean, it's fine, using a i7 core at 100% at all times just to produce text at a 2 second delay is totally fine for a text editor, I'm sure notion's doing its best. reply abhinavk 15 hours agorootparentYes. I use Notion (or Logseq or any other Electron-based note-taking apps) as a filing cabinet. I cannot type in it. The typing latency is too much. reply hackernewds 18 hours agoparentprevI'm very curious how and why to use Obsidian well. It's so confusing I've given up multiple times. reply muppetman 17 hours agorootparentDon't buy into all the crazy around it. It's a Markdown editor with some organisation features. If you read Reddit, people treat it like some sort of second coming, making sure EVERY NOTE THEY TAKE is linked at least one other, tagged, etc. Like somehow that makes notes better. I was confused at first too but once I realised most of these people are insane and it's a note taking app, it's very easy simple and quick to use. I love it. reply theshackleford 6 hours agorootparent> Like somehow that makes notes better. And for many, it does. It may not for you, but everyone has their own system. reply crooked-v 18 hours agorootparentprevIt's just (\"just\" in the good sense) a fancy Markdown editor with a bunch of plugins, including for most of the core features (which are just bundled-in plugins and can be turned off). reply vunderba 17 hours agorootparentprevIt's a pretty simple note organizer for markdown notes. That's literally it. Vaults/folders/subfolders are 1:1 representations of the folders on your physical computer. It's WYSIWYG, so even if you don't know markdown, you can just use standard shortcuts like Ctrl-B to bold something, Ctrl-I to italicize, etc. But it's only as valuable as the notes that it contains. If you are a fastidious note taker (for your projects, work, etc), like to ontologically tag things, and appreciate building inter-related knowledge (like wikipedia links), then you'd be hard pressed to find a better substitute even compared to other heavy hitters like Joplin and Logseq. reply tomjakubowski 18 hours agorootparentprevThink of it like maintaining your own personal Wiki, comprised of flat-file markdown reply cityzen 18 hours agorootparentprevAt its simplest, it is a UI to markdown files. When I was first looking into it, it seemed very tightly coupled with the zettelkasten method which I know nothing about. At first I thought that I was missing something but have since used it as just a markdown note app. I will asked ChatGPT to output responses in a note form in markdown so I can copy/paste it in. You can wrap code with: ‘’’elixir Code here ‘’’ To get syntax highlighting Todo lists are as simple as -[ ] to do item You can use iCloud/dropbox to sync. reply charlie0 18 hours agoparentprevSo far, the only weakness I've found with Obsidian are the tables. Someone needs to build in a killer tables feature. Obsidian is an Electron app; it shouldn't be too hard to build a stripped down version of Google Sheets. reply crooked-v 18 hours agorootparentCheck out the Advanced Tables plugin - https://github.com/tgrosinger/advanced-tables-obsidian reply maleldil 17 hours agorootparentUnfortunately, it's nowhere close to Notion tables or spreadsheets in general. Formulas are very primitive (eg aggregation is either sum or mean), the syntax is confusing, and you have to manually re-evaluate them. Tables are Obsidian's main weakness to me. reply refulgentis 14 hours agorootparentprev> it shouldn't be too hard to build a stripped down version of Google Sheets. HN, never change. reply lovethevoid 18 hours agoparentprevFor basic notes, the ones that come with most devices imo are very good. Apple notes, Samsung notes, Onenote, all very good. So good I find it difficult to recommend anything else to people, like Notion still doesn’t even have proper pen/stylus support. Obsidian to me fits a good niche of being extensible with plugins but I get why some people can’t get into it. Notion shines with database use, and was how I used to write my blogs and connecting the API directly to my site to auto update. I’m surprised you’re a paying customer and barely use the database stuff! reply dottjt 18 hours agoparentprevI think once I started using databases it made other note-taking tools seem primitive in comparison. It's hard to explain why, but it just allows you to organise and categorise hundreds of notes seamlessly. I also really like how it treats everything as blocks, that's another thing that I can no longer live without. If you're not interested in features like this, then yeah. Obsidian would be a good use-case. reply danpalmer 19 hours agoprevThis is a fun piece of creative writing, but I’m not quite sure of the point it’s trying to make about Notion. Is it that Notion is no longer cool? That might be true but isn’t the most insightful comment. Is it about Notion the company languishing in some way? reply Multicomp 19 hours agoparentNotion is jumping the shark by moving from being a notes organization / mini database product to trying to compete with Salesforce and Hubspot. Just completely a different sector / product. reply anonygler 18 hours agorootparentThis is an issue for all the low/no code tools. Every meaningful problem has a first class SaaS product that solves it well. Notion/Retool/Airtable/Coda/Etc are fighting over a cursed long tail and their employees are slowly going insane trying to generalize asymptotic industries. The “AI” rebranding has no doubt made them want to put a gun in their mouths. reply nunez 4 hours agorootparentprevI can see it. I've been doing the sales engineer thing for a few years now. Salesforce management is a big part of my job, as this is what the salespeople use to track opportunities and deals. The data that goes into SFDC is a big part of what gets reported on in sales/revenue forecasts, so it existing is extremely important and is a big reason why Marc Benioff has, like, a billion yachts. At its core, SFDC is nothing more than a database and a shitload of plugins that enter stuff into that database. Notion can, theoretically, do this as well. Given how large the TAM is for revenue management software and how much Marc pays to acquire anything in his space, Notion chasing that market makes a lot of sense. reply arduinomancer 16 hours agorootparentprevI feel like that’s unavoidable because once you get big company clients your PMs start prioritizing their feature requests And those companies will inevitably want it to do everything reply muzani 17 hours agorootparentprevOften this happens when companies raising more funds when there are no funds available for that sector. Suddenly it's not cool to be a car rental company, they also need to become a logistics platform or bank. reply sanex 19 hours agoparentprevIt's middle aged and not exciting anymore? Doesn't know what else to do so it buys a sports car (adds AI). Just guessing but I know I am much less excited about notion than I was 4 years ago and maybe that's the point or maybe that's just how it resonated with me. reply PaulHoule 18 hours agoparentprevI imported a friend of mine's Notion into Fraxinus, some software I wrote that is a bookmark manager and a webcrawler and an image sorter and a search engine and annotation system and a visualization tool and is likely to get merged with my YOShInOn RSS reader and model trainer (might eat all my side projects that aren't about images and VR.) It's a tool for understanding, organizing and harvesting a collection of documents (so I got some insight into how he uses Notion.) In his case, he uses it as a CRM for prospecting and it really isn't that bad at the business development end where you don't have a lot of people doing a structured process. But if you could somehow add some structure to notion, in the UI or with some AI interpretation of the text, or both, I could see Notion becoming a CRM or something else, think of something like a spreadsheet for notes. Of course it might not be Notion that does it, it might be a startup that does it, it might be an established company. Saleforce is a good comparable because you can customize Salesforce to build many kinds of application but you still need programmers to do it. Is somebody in 2024 going to build a system which is as flexible, maybe even more flexible, but doesn't need the programmer? reply canadiantim 2 hours agorootparentIs there a way to try your Fraxinus system? reply staplers 19 hours agoparentprevI used to use Notion daily. I switched to Anytype when Notion launched an AI tool that trains on your data. A bit more of a learning curve but that's an absolute no-go when a tool contains the inner workings of my brain. Plenty of comparable private options. Intellectual capital is rapidly being migrated from workers to shareholders under the guise of \"AI\". Imagine a world where C-suites no longer rely on or support creative minds. EDIT: They may say they don't train on user data currently but there's nothing stopping them in the future, especially if they are moving upmarket. reply nunez 4 hours agorootparentYou can turn Notion AI off in your tenant. It takes a few days, but support will do it. It's annoying that we have to ask instead of toggling a switch, but there you go. reply jitl 16 hours agorootparentprev(I work at Notion but not on AI) There’s far more for Notion to lose “training customer data on AI” than for Notion to gain. Like if an AI feature ever disclosed private information of one customer to another, that would be a huge blow to the company. The closest thing to that that makes sense for us is building “learn to rank” style search models to improve search results, but this is not usually considered “AI” and is typical for any product trying to make search good. reply n_ary 13 hours agorootparentFor me, it seems that most of the notion users in my circle(very small one) are non-technical people. Even if your AI vomits some other user’s private data, it’ll be considered a glitch and will be forgiven because non-technical users does not panic or gets flame-baited because these are irrelevant to them. That being said, I appreciate that you understand the risk, and want to believe that the people on the helm of the AI feature and people on the leadership also share your opinion. reply theshackleford 6 hours agorootparent> it seems that most of the notion users in my circle(very small one) are non-technical people. All the users in my circle are the opposite, they are all technical individuals. Largely developers for whatever reason. reply dcre 18 hours agorootparentprevThanks for the Anytype rec. I have similarly been looking for a good alternative since they turned on AI features you can’t easily opt out of. And I’m not some anti-LLM zealot — I use them every day. I’m not even worried about them training on user data. The more immediate problem is that if you accidentally type something in the Ask AI box (which is very easy to do because it looks like search), the page you’re on and god know what else is sent to god knows where. When I use LLMs, I like to know which one I’m using and exactly what I’m sending them. I felt their AI integration was very cavalier and it completely changed my opinion of them as a company. On top of that, the YouTube and Tik Tok productivity grifters thrive on the ecosystem of template BS that Notion seems very happy to encourage. I guess they can’t help it but it is not my vibe. I also want something more stripped down and programmable. Obviously a programmer is not a typical consumer. reply jitl 16 hours agorootparent(I work at Notion but not on AI) We maintain a list of data su processors here: https://www.notion.so/notion/Notion-s-List-of-Subprocessors-... It’s not as specific as citing the actual model version in use from each vendor, though. reply light_hue_1 11 hours agorootparentThat isn't reassuring at all. It's pretty much the worst case scenario. I don't want my private notes sent to places like openai who will use them to train models and who don't have any reasonable corporate governance. They have leaked customer data before. And I'm not anti AI. I'm an ML researcher who uses LLMs all the time. But there's a big difference between that and revealing all my private information to them. reply skissane 18 hours agoprevI use Notion because I have to, not because I like it. Other teams still use Confluence. People said Notion is a lot better than Confluence. Well, I agree I'd rather use it over Confluence, but that's a very low bar for comparison. For ages they didn't have a find-and-replace feature. I just checked, it looks like they've finally added it in the last few months, but this is the first I notice. They claim you can export stuff as markdown, but if I export as markdown, edit and reimport, I lose half of the formatting – even basic formatting which is part of the markdown spec. Their native format (which their API exposes) is a bunch of extremely complex JSON blobs. I thought about writing a tool to let me download stuff, edit it in a sane text editor, then reupload it, but when I saw the complexity I just gave up. reply jitl 16 hours agoparent(I work at Notion) Our public API format is not the \"native\" format used by the Notion editor. The overly-nested format we designed the public API is aimed at supporting statically typed programming languages like Java or Golang that do not have (tagged) union types natively. Instead we represent each option in the union type as a nullable field pointing to a nested object. This makes the structure much easier to decode in these kinds of languages, but does make it more verbose. For a hypothetical typescript union type:{ type: 'plain', text: string, format: Formatting }{ type: 'link', text: string, href: string, format: Formatting }{ type: 'page-mention', page: { id: UUID, spaceId: UUID }, format: Formatting } we end up producing a Java-style object like this: { plain?: { text: string, format: Formatting } link?: { text: string, href: string, format: Formatting } pageMention?: { page: { id: UUID, spaceId: UUID }, format: Formatting } } You can see the native format by looking at API traffic in your browser devtools. Generally the native format is more confusing without type annotations. reply threeseed 17 hours agoparentprevActually today's Confluence is much better than Notion in my opinion. It has a built in Figma style diagram/flow-chart editor which is handy for architecture documents, infinite array of plugins and the interface is simple, clean and focused. Notion has become this kitchen sink app where even editing a table is a convoluted mess of an experience. reply kiratp 18 hours agoparentprevTry sending the bob straight to an LLM and have it give you markdown. Bet it works. reply Pi9h 17 hours agoprevIf you are looking for a self-hostable Notion alternative, I am building Docmost, which is open source. It has real-time collaboration and support for diagrams (drawio, excalidraw and mermaid). It can be tempting to want to do it all, but I am focused on building a great wiki and documentation software. GitHub: https://github.com/docmost/docmost reply amai 5 hours agoprevI never understood the hype about Notion. It will vendor-lockin your data like sharepoint, Word, Google Docs, Apple Notes and Confluence already do. Why do we need another solution like this on the market? reply beryilma 1 hour agoprevNotion and Obsidian will be dead in couple years. I see academics going crazy with Obsidian to organize and link their precious little ideas and research articles together. But, only to create an overwhelming mess that they will be afraid to look back to in couple years. Anybody, remember MindMap? Same idea as Obsidian and it is all but dead at this point. reply n_ary 13 hours agoprevNotion is cool and many new project owners/managers love it while grumpy oldies live by Jira/Conflience. However, Notion kind of gives me the vibes Evernote cult of the ancients we have forgotten. That being said, I used Notion on early days as my brain-dump for everything until I found that my needs are just putting some text and images, then I moved to simplenoteapp(also from forgotten stone age) and substitute with Bear or Apple Notes. reply anh690136 14 hours agoprevI started as a Notion user, but then it gets complicated and overwhelming quickly. It can be a good database and beautiful system, but for individual use cases, it’s too much for ADHD. I tried to use Apple Notes and Docs from then, but with too many notes, insights get buried and cannot be found easily. So I built an AI note app called saner.ai since & it worked better for me at least. reply tiffanyh 12 hours agoprevCuration. Much like how SharePoint at most companies turn into a zombie wasteland of random unorganized documents, this also happens with Notion. All of these types of products need their customers to effectively have someone dedicated to curation, organization and do librarian task - to maintain a good hygiene. Otherwise, any type of team collaboration tool will get unwieldy super fast. reply eedeebee 17 hours agoprevWhenever I have to use Notion, I find it a waste of time compared to other tools :( reply remram 1 hour agoparentWhy? reply dcchambers 17 hours agoprevI generally think Notion is a pretty great product but IMO it's the poster child for \"jack of all trades, master of none.\" Yes, lots of things can be done in Notion, but most of them are done better elsewhere with dedicated tools. I think it's core functionality as a team wiki (aka a confluence replacement) is the one thing it does best and better than most competitors... reply bastawhiz 16 hours agoparentThat's sort of the draw. I don't need the best bug tracker, I need a bug tracker that I can get pretty much whatever I need to do done in. I don't need the best wiki, I just need to be able to write reasonably formatted docs with syntax highlighting and links. Notion explicitly isn't the best at any of these things, it's maybe an 8/10 on the best of days. But it's priced at an 8/10 and the search works across the whole damn thing, and nothing that it does is really all that bad. On the other hand, Confluence does really just one thing. But it doesn't do it especially well, and there's lots of things that it can do that are bolted on haphazardly. Go ahead, try to embed that Loom video. I double dog dare you to try to configure it to show Git commits from GitHub. IMO something that isn't good that's purpose built is actively worse than something that does everything pretty okay. reply saltcod 17 hours agoprevHasn't come up much here, but part of the appeal is that Notion is extremely flexible. You can create a regular old company knowledge base, but also feed in/out things from a ton of other systems and organize them. Notion's main strength and stickiness imo is as a hub. reply bigyikes 19 hours agoprevFunny, but how wrong are they? I haven’t had the misfortune of using Salesforce, but isn’t it a glorified relational DB in the same way that Jira is? I know a few people at Notion, and one thing I can say is that they have taste, in the way Apple has taste. I think this shows in their product. reply lovethevoid 19 hours agoparentWe’re all glorified relational DB when you think about it lol Notion was one of THE new tastemakers. Every startup copying their designs, now there’s AI generators to make “notion style art”. To see their new pages and additions have such clunky copyrighting is disappointing and I hope just temporary, not a sign the tastemakers have left the company. reply jprete 18 hours agorootparentCopyrighting, or copy-writing? reply lovethevoid 18 hours agorootparentMaybe I should hire a copy-writer! reply jprete 4 hours agorootparentI really wasn't sure! But to give you a more substantive response, I think the tastemakers are not in control in the slightest. Everything about Notion now screams \"we don't give a crap about note-taking or personal wikis, we want a piece of that juicy enterprise market\". reply makeitdouble 19 hours agoparentprevNotion defnitely had something to it when it only had to be a documentation platform. It was fast, clean and elegant, and that helped to forgive the missing bits (table support or plantUML kind of plugins) But now that they've added a ton of features requested left and right, and effectively presented Notion as a one-stop solution to every documentation problem, I don't see much taste and elegance persisting. Not that the people you know lost their taste, more that it doesn't matter if they have to say yes to absolutely everything to keep being a one-stop solution that does it all. In my or people started changing the way they write to stop triggering Notion features, and on the other side figjam and spreadsheet documents are coming back even as it could have been a Notion page. There's definitely a shift IMHO. Notion will keep being used, but it might not be the first choice when other simpler options are available. reply talldayo 18 hours agoparentprev> I think this shows in their product. I really don't. Notion is one of those tools that entrepreneurs gravitate towards for it's simplicity, and then engineers rip out for being a parasite. At the end of the day it's an overpriced CMS that can very easily be replaced by any number of different alternatives. Their \"taste\" is just as overrated and overpriced as Apple's is. reply anonygler 18 hours agoprevNotions kinda funny. It has this stickiness among a college aged, tech savvy demographic that’s not generating any revenue for them but has garnered a massive valuation relative to their revenue. They want business from me, a tech savvy technical leader in an enterprise who mostly doesn’t care about what they offer. I want all my docs to live in Git, the way it does in Google’s g3doc. We use Notion and, while it seems better than Confluence, I’ve never actually authored a single thing in it. It has no overlap with my goals. The world should be accessible from my IDE, and if I were them that’s where I’d really focus: a bi-directional sync and a first class VS Code plugin for whatever their file format looks like. reply lmm 15 hours agoparentThey have no value-add for developer-only documentation that exists in Git. Most of the value of Notion comes from it being usable by non-developers (but still tolerable for developers). reply supriyo-biswas 18 hours agoprevI don't think is as big of a deal the author is making out to be - such pages are usually written out of SEO considerations. If there's a conversation within a company about getting dedicated CRM software and they're already a Notion user or strongly considering Notion for their wikis and documentation, getting the word out there that Notion can also function like a reasonable CRM replacement can help close that deal or prevent a conversation about how Notion might not meet their needs. reply ryanschneider 16 hours agoprevNot that I expect them to fix it at this point since it seems to be a known issue, but just in case anyone from Notion is watching please fix the macOS app’s CPU usage. On a brand new M3 MacBook Pro each tab takes about 10% of one core _non-stop_ even in the background. I have to constantly cull tabs or my machine becomes noticeably less responsive. reply euroderf 13 hours agoparentGood grief. How is this even possible ? What on earth is going on ? Extra points for answers in the form of questions. reply niyogi 16 hours agoprevnotion was the beneficiary of the mass exodus of users who felt betrayed by evernote's weird pricing change many years ago. they had a great evernote importer which made it easy to migrate and then grew way beyond the elegant simple product they once were. a new notion is lurking somewhere waiting to ride in the wake of a growing disgruntled pile of notion users reply euroderf 13 hours agoparentVisualising another in a series of great migrations, where a mass of leaderbirds takes wing and suddenly the entire flock is in the air and heading south. reply felipefar 17 hours agoprevIt seems that Notion is a kind of product that tries to solve issues from many areas, so it has everything that almost solves a meaningful problem for the user, but not quite. So the burden is on the user to go that extra mile, who will have to search for templates, memorize how non-standard tech works just to setup and maintain a system that only the maintainer knows how it works. Some people use Notion for research and academic writing, which is the same use case for my software (https://getcahier.com). By specializing on this specific use case, I've been able to: offer a standard data model that's widely used in the field (bibtex), innovate in the PDF reader in the direction that my users need (by adding scrollbar markers for the relative position of highlights), and provide clear instructions to users on how to use the software. In principle, learning to use the software is learning how to perform an activity better - in this case, formal or informal research. When working with a software that's too general the user will always have to ask himself an additional question: \"now, how do I make it do what I need?\". As the mathematician Hardy used to say, a beautiful theorem is one that is not too specific but also that is not too general - it has to strike a balance between the two. reply wokwokwok 19 hours agoprevhttps://www.notion.so/templates/category/crm > Streamline your customer relationships with Notion's CRM Templates It's a joke, but it's also not a joke. I mean, come on. Is notion really pitching itself as a CRM? It's not a CRM. Anyone who uses it as a CRM is an idiot, bluntly. ... https://www.notion.so/use-case/crm Oh, wait. I guess it's a supported use case. I uh... take it back... I guess... > If you don’t want to use a dedicated CRM platform or start from a template, you can use a no-code platform like Notion to build a knowledge base or team homepage and modify it to fit your CRM needs. Yeah, I guess some people will think that's a good idea. reply makeitdouble 18 hours agoparentThis is definitely a thing. Saw it happen first hand for project management: Notion started promoting the Task Board/GANTT like view of the databases as a fully supported use-case, and the bean counters came straight away to ask if we really needed a dedicated ticket management system. As our use case was relatively simple it was borderline doable, and our dedicated system went away, even as we knew there will be rough edges. It's not great, but not bad enough to justify paying a full license price for a more polished product. reply mvkel 17 hours agoprevWe switched from Google Workspace to Notion around 2018. It worked really well as a company wiki. A lot of the exec team lived in there. The most painful part, the part that led to us switching back, was how painfully slow Notion was. Thanks to Electron, it used an obscene amount of ram, and a lot of opportunities to jot an idea down, or file something in the right place, were lost because of that slight lag. Like being forced to cold-start Chrome to visit any website. Knowing it would feel tedious to open Notion made me reconsider if the idea was worth writing down at all. In some cases, it was! reply pentagrama 16 hours agoprevNotion feels like early Tarantino. reply ilikerashers 18 hours agoprevI use notion and like using it. But it’s high contrast Jira. Yes it’s decluttered but it’s not a very sticky product. reply nsonha 17 hours agoprevIt's always amazed me that Notion got as popular as it did. It's not exactly user-friendly nor technically cappable (not having API or any kind of external integration for most of its existence). There seems to be a group of nerds that's apparently pretty huge and have enough decision making power that it was able to tap into. reply meindnoch 18 hours agoprevIs anyone still using Notion? Serious question. reply qudat 18 hours agoparentCompanies love it because it’s an all-in-one knowledge base reply theGnuMe 17 hours agoprevI just want an AI assistant that can organize things for me in some kind of note taking /wiki/something… it needs to take raw data and make it useful… you know like an assitant would, specifically around projects etc… reply breck 17 hours agoprevIt turns out, language matters. The PPS stack is about to eat the software world. https://en.wikipedia.org/wiki/Babe_Ruth%27s_called_shot reply Ali_Jiwani 17 hours agoprevIf you wrote a book. I would buy it. reply moralestapia 18 hours agoprev*yawn* I wish I had a 70 million/year mid-life crisis funded by web-based notepad. reply semiinfinitely 18 hours agoprevNotion sucks and I hate it! reply boiler_up800 18 hours agoprevNot sure what the point of this is. Every company I’ve worked at stores everything in notion. Managers and ops people keep it up to date and organize processes in there. reply prdonahue 18 hours agoprev [–] Notion was clearly made by people who do not use or understand keyboard shortcuts; you can't even properly select text without using the mouse. It's been somewhat maddening switching from Confluence. reply remram 1 hour agoparentI have the opposite complaint: you can't even reliably select text without also using the keyboard! Half the time I drag to select, it starts moving a block. Half the time I click to navigate, it starts a selection instead (as if I had not released the mouse from previous click). I need to press the Escape key and try again. Notion to me is the prime example for \"too much JavaScript\". Opening a note in a tab take 10 seconds and interrupts me half the time with some random news or a prompt to try some AI feature. reply hinkley 18 hours agoparentprev [–] I’ve gotten out of the habit but I could definitely see how in a set of dependent code reviews one might want to be able to update a sequence of statuses in a matter of minutes to land a bunch of changes back to back to back, plowing through using a CLI or keyboard shortcuts. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Notion, initially popular for its customizable and versatile features, is facing criticism for becoming cluttered and less effective, similar to other overused tools like Jira.",
      "Users express frustration with outdated and hard-to-find documents, suggesting that simpler tools like Google Docs might be more productive.",
      "Despite its issues, Notion's database capabilities and flexibility still make it a strong contender for organizing and categorizing notes, though some users are considering alternatives like Obsidian."
    ],
    "points": 201,
    "commentCount": 140,
    "retryCount": 0,
    "time": 1727565276
  },
  {
    "id": 41683098,
    "title": "Britain buys semiconductor factory for defence purposes",
    "originLink": "https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/",
    "originBody": "Home Air Britain buys semiconductor factory for defence purposes Image BAE Systems. Air Britain buys semiconductor factory for defence purposes By George Allison - September 27, 2024 67 Share Facebook Twitter Pinterest WhatsApp Email The UK government has acquired a semiconductor factory in Newton Aycliffe, County Durham, in a move to strengthen the defence supply chain and support the Armed Forces. This facility is the only secure site in the UK capable of manufacturing gallium arsenide semiconductors, a vital component in military platforms such as fighter jets. Defence Secretary John Healey visited the site, which was previously owned by Coherent Inc. and will now be known as Octric Semiconductors UK. The acquisition is expected to secure up to 100 skilled jobs in the North East and safeguard a critical part of the UK’s defence infrastructure. “Semiconductors are at the forefront of the technology we rely upon today, and will be crucial in securing our military’s capabilities for tomorrow. This acquisition is a clear signal that our government will back British defence production. We’ll protect and grow our UK Defence supply chain, supporting North East jobs, safeguarding crucial tech for our Armed Forces and boosting our national security.” Semiconductors are an essential component of modern electronics, from phones and computers to military applications. The government has stated that this acquisition will enhance the UK’s defence capabilities and increase its industrial capacity, with plans to invest further in the facility over the coming years. The acquisition comes ahead of an Investment Summit aimed at strengthening the UK’s trading relations and supporting high-quality jobs at home. With global semiconductor demand rising, this move positions the UK to meet future technological needs, including advancements in artificial intelligence, quantum technologies, and 6G. Background In 2023, Coherent, the former owner of the Newton Aycliffe semiconductor facility, announced plans to cut over 100 jobs due to a drop in business demand, leaving the future of the site in doubt. With the facility’s long history of ownership changes since it first opened in 1991, there were growing concerns about whether it could continue producing the crucial semiconductor components needed for industries like defence and aerospace. The recent government acquisition is a key move to secure the future of this vital facility. By stepping in, the government is protecting jobs and ensuring the production of important semiconductors used in military applications, such as boosting fighter jet capabilities. This not only stabilises the plant after last year’s uncertainty but also strengthens the UK’s ability to maintain control over critical technology in the defence sector. Share Facebook Twitter Pinterest WhatsApp Email George Allison George has a degree in Cyber Security from Glasgow Caledonian University and has a keen interest in naval and cyber security matters and has appeared on national radio and television to discuss current events. George is on Twitter at @geoallison RELATED ARTICLESMORE FROM AUTHOR Air Queen had to tell Boris Johnson about F-35B crash Air British military aircraft to cease strikes in Iraq and Syria Air Historic Scotland to use ‘Drone Assist’ take-off approvals Air Britain’s new electronic warfare radar takes to the air Air Key E-7 Wedgetail facility opened by Royal Air Force Air Ukraine joins NATO counter-drone exercise for first time Air Britain to build 20 large one way attack drones per month Air UK, US, and Canada Join Forces on cybersecurity and AI Air Britain developing new long range strike weapon Air Royal Marine makes history as first to command jet squadron Subscribe Notify of new follow-up comments new replies to my comments I allow the sending of notifications about new comments and replies (you can unsubscribe at any time). {} [+] 67 Comments oldest newest Inline Feedbacks View all comments Chris (@guest_857657) 2 days ago #857657 Good news. With recruitment of experienced and qualified management team the company Should do well. Reply Jim (@guest_857689) 2 days ago #857689 Reply to Chris Bad news, we are using the defence budget to buy failing companies on the grounds of “national security” That’s a very slippery slope. Reply Supportive Bloke (@guest_857703) 2 days ago #857703 Reply to Jim I’d tend to partly agree. On the other hand we appear to have woken up to a ‘global supply chain’ particularly for munitions not being a very good idea! But I agree that if we buy every failing business we create the 1970’s money pit all over again. Reply Spyinthesky (@guest_857735) 2 days ago #857735 Reply to Supportive Bloke It’s not ‘every’ though is it, indeed it’s so far one. I would have been happy if they had bought Sheffield Forgemasters too tbh as it’s the only provider of many vital steel products for defence and have recently developed welding techniques that greatly speed up and reduce costs for Nuclear reactor vessels. I presume RR amongst others will be happy about that. Oh and on that point should we have let RR go to hell in a bucket back in the day? The French on the other hand saved Renault from a similar fate and unlike the ill fated… Read more » Reply ChariotRider (@guest_857745) 2 days ago #857745 Reply to Spyinthesky Hi Spyinthesky, Actually MoD does own Sheffield Forgemasters, just search “who owns Sheffield Forgemasters”. Apparently they were acquired back in 2021. As far as I can tell MoD seems to have a canny investment advisor squirreled somewhere in a backroom. Cheers CR Reply Jim (@guest_857797) 1 day ago #857797 Reply to ChariotRider They bought it for £2 million and now it has to have £400 million invested. Fingers crossed it works out and the work Forge Masters does is vital but that’s £400 million that could have be spent on ammunition and kit. The Chinese military spends a lot of time investing in industries. Everything from airlines to luxury hotels and apartment blocks. It’s spends most of it’s time and resources doing this instead of training fight. It’s not a model I think we should emulate. Reply Jim (@guest_857795) 1 day ago #857795 Reply to Spyinthesky Does Britain struggle to compete in economic terms? Who are we struggling against? Japan has been in recession for two decades, Germany had a decent run over the past 10 years but its now looking at the kind of structural problems we had in the 70’s. Apparently America is doing well as its debt to GDP ratio passes Italy Canada slowing deflating away as its population heads to the US, Italy is on the verge if ceasing to be an advanced industrial economy and then there’s France. The IMF has the UK pegged as the second fastest growing economy in… Read more » Reply Enobob (@guest_858242) 4 hours ago #858242 Reply to Spyinthesky Er, they DID buy Sheffield Forgemasters! Reply Grizzler (@guest_857787) 1 day ago #857787 Reply to Supportive Bloke Yep the first line of the article says it all.We need to be very careful regards the availability of this sort of kit. Just need to look at steel production now. Reply Exroyal. (@guest_857973) 1 day ago #857973 Reply to Grizzler I have mentioned steel on here before. We are going down a crazy route with steel. If you want high quality steel the recipe is fairly simple. A blast furnace, coal, iron ore, limestone. More technical than that I know but that’s the basics. Electric arc furnaces are okay for car parts and washing machines. So any high quality steel will have to be imported very soon. We are then a hostage to events beyond our control. Reply William Robson (@guest_858043) 1 day ago #858043 Reply to Exroyal. You also need plants that produce molten iron Blast furnaces being closed in south Wales and north east by Indian and Chineese owners Reply William Robson (@guest_858042) 1 day ago #858042 Reply to Grizzler Steel production killed by the Tetley tra makers with help from Labour Reply Sjb1968 (@guest_857710) 2 days ago #857710 Reply to Jim The fourth pillar of defence is the economic and industrial base of a nation, which we are historically very poor at understanding and protecting. It didn’t matter quite so much when our economy was comparatively large and our military footprint matched it but it does now. A good example of what happens when this not fully understood by politicians was the production of heavy calibre guns for battleships post WW1 and armour plate. The two businesses that produced these weapons amalgamated because of a lack of orders and when in the 1930’s we need an uptick it was not possible… Read more » Reply Spyinthesky (@guest_857740) 2 days ago #857740 Reply to Sjb1968 Well said, one might have thought that the lessons of history let alone simple logic might have made that obvious but I fear not. What a lovely future sight to see Tempests stuck on the ground because they don’t have the chips installed to make them functional. The Russians might have the last laugh there. Geez even the Americans were shitting themselves when Apple originally bought the chip company to produce their A-series chips because that company happened to produce the most advanced micro processors for their ICBMs. Indeed they would never have accepted those Arm based chips ever being… Read more » Reply Ian (@guest_857746) 2 days ago #857746 Reply to Spyinthesky Politicians prefer to pretend that there’s a ‘Peace Dividend’, which would negate the need for such concerns if it could be guaranteed to endure indefinitely. They then try to pretend that said ‘Dividend’ still exists when it doesn’t, because otherwise the realities of national security require them to spend money on things other than their pet projects or bribes for the electorate. Reply Jim (@guest_857801) 1 day ago #857801 Reply to Ian So you want to run a permanent war time economy like North Korea then? 40% of GDP to the military? Reply Jim (@guest_857800) 1 day ago #857800 Reply to Spyinthesky You want to start adding up how many chips are inside a tempest and how many suppliers they come from? This is one small factory, do you really think it’s making a significant number of chips as a percentage of something as complicated as a modern aircraft. A standard chip fab cost $20 billion to build and has to knock out hundreds of millions of chips to be viable. Just my standard car has 1500 different chips in it. It’s a fallacy to think we or anyone else can control modern supply chains. Reply Meirion X (@guest_857747) 2 days ago #857747 Reply to Sjb1968 👍Exactly! Reply Jim (@guest_857798) 1 day ago #857798 Reply to Sjb1968 Actually we are very good at this, the RAF and the RN have gone out of their way for centuries (RN) to do preserve and grow the industrial base. The army is shit at this and always has been. Reply Sjb1968 (@guest_857817) 1 day ago #857817 Reply to Jim A few points to consider The 1957 Duncan Sandys Defence White Paper almost destroyed the U.K.’s aerospace industry. When the U.K. seriously tried to rearm in the 1950s we did not have the economic or industrial base to renew our conventional forces whilst developing our independent nuclear deterrent. We had to have the US assist us with the Astute programme because we had lost so much expertise from the end of the last nuke builds in the 1990s and the new boats. The U.K. now hasn’t got the capacity or enough skills to build a Fleet Solid Support Ship without… Read more » Reply Michael Hannah (@guest_857730) 2 days ago #857730 Reply to Jim Given the importance of GaAs tech to several future military projects, including Tempest I think it is a wise move . There are several technologies this country needs to have control of. Reply Jim (@guest_857802) 1 day ago #857802 Reply to Michael Hannah It probably is but spending our slim defence budget on nationalisation of defence companies should be a last resort and it should be temporary. Companies like BAE and RR can develop sensitive technologies with no government subsidy and the use of a single golden share is more than sufficient for control. Reply Michael Hannah (@guest_857826) 1 day ago #857826 Reply to Jim I disagree. Managed properly and given the increasing use of GaAs tech, due to not least its speed and power consumption compared to Silicon , it very probably will pay for itself in the medium to long term. Reply Spyinthesky (@guest_857732) 2 days ago #857732 Reply to Jim Well that is perhaps an argument over where the money should come from. however to have no capability to produce these hi tech components would short sightedly leave us in a potentially crippled state to defend ourselves without others control over it or even military exports, which would be beyond short sighted in the present environment let alone future unknowns. I note you said previously that Ai and hypersonics were gimmicks, sorry but these comments sound so 1st WW cavalry officer stuff that doesn’t seem to fit with much of your otherwise sensible views on matters, so it really confuses… Read more » Reply Julian (@guest_857736) 2 days ago #857736 Reply to Spyinthesky Do we actually know where the money is coming from? Jim said ‘we are using the defence budget to buy failing companies on the grounds of “national security”’ but I see 2 things in this article, the report that the government is buying a company and an awful lot of mentions of defence applications of that company’s products. While the funds for this acquisition might be coming from the defence budget I don’t see that explicitly stated in this article and, unless other reporting is definitively stating that the defence budget is the source of the funding, then I think… Read more » Reply ChariotRider (@guest_857750) 2 days ago #857750 Reply to Julian If you search “who owns Sheffield Forgemasters” the page comes up with MoD all over it so I think it is fair to assume that the MoD has paid for these companies. However, I would hope that the MoD benefits from any dividends payable… Cheers CR Reply SRamshaw (@guest_857765) 2 days ago #857765 Reply to ChariotRider Straight into the Treasury coffers, do not pass go. Reply Jim (@guest_857806) 1 day ago #857806 Reply to Julian It can be counted as defence expenditure under NATO rules and out budget is right on the NATO floor so even if it comes from another department it will be counted against our defence spending just as with Ukraine aid and the MOD budget will be changed accordingly. Reply Jim (@guest_857805) 1 day ago #857805 Reply to Spyinthesky It’s not really a fair comparison in that semi conductors are so expensive to build at scale and so ubiquitous in every product that not even the USA has the capability for internalisation of the supply chain. Maybe at a NATO + level adding in the likes of Japan and South Korea we can do this and if this factory is part of an overall plan like that then it’s worth it but on its own it’s not doing anything. Big questions like why did it go bust and what does no one else suitable want to buy it are… Read more » Reply Grizzler (@guest_857822) 1 day ago #857822 Reply to Jim Maybe we should ask the Chinese,they like to buy semi-conductors..maybe they know something we don’t. It would save em invading Tiawan I suppose Reply Lonpfrb (@guest_857857) 1 day ago #857857 Reply to Jim The US internalisation has started with the Chips Act which led TSMC and Intel to build state of the art fabrication plants within the continental USA. The semiconductor eco system is deep and complex but the gravitational effect of multiple new builds is big and sucks in a lot, especially when USA had many chip fans before. So it might not achieve a sovereign capability for all situations but it will make a big difference and encourage TSMC not to be Taiwan only.. Strategy investment Reply DRS (@guest_857763) 2 days ago #857763 Reply to Jim If we have low production order it sustains skills and capabilities. Vital we have this. You can’t buy stuff from the Chinese if you are arming to fight against them. Not everything has to be private , some key industries need to be owned by the government. Other countries protect key infrastructure. Reply Jim (@guest_857808) 1 day ago #857808 Reply to DRS Can you point to the civil servant or politician in charge in Whitehall who knows anything about semi conductors? As a general rule government should avoid industry. Reply Lonpfrb (@guest_857860) 1 day ago #857860 Reply to Jim Since they allowed ARM to be bought, that evidenced no understanding. Reply Lonpfrb (@guest_857859) 1 day ago #857859 Reply to DRS The US and Netherlands already agreed not to sell key x-ray lithography tools, critical for high performance chips, to the CCP. So CCP will be stuck on commodity mid range chips until they work out lithography for themselves. Not a problem if you make washing machines and low end smartphones.. However CCP does have leverage on rare earth metals supply required for high technology products. So prices may go up as CCP decides to keep those for themselves. Alternative sources and freedom from coercive relationships that restrict supply require attention… Belt and Road, bad! Reply Grizzler (@guest_857820) 1 day ago #857820 Reply to Jim Where has it said we are using the ‘Defence Budget’ to purchase it? Reply Enobob (@guest_858241) 4 hours ago #858241 Reply to Jim It’s not a failing company, it is a tiny part of a huge US company that has just lost an enormous Apple contract and is looking to rationalise its global footprint. Reply Peter S (@guest_857673) 2 days ago #857673 Excellent. Just like the MOD purchase of Sheffield Forgemasters, this will protect our defence industrial base. It must be obvious even to those most wedded to market forces that a small country like UK has to have control and ownership of critical capabilities. If we don’t, the subsidized US defence companies, enjoying legal monopoly of the US defence market, will become even more dominant. Reply Spyinthesky (@guest_857741) 2 days ago #857741 Reply to Peter S Sadly judging by some comments here it’s not so obvious and that stuns me that people don’t understand the importance of such technologies and why other countries are spending billions just trying to jump on the bandwagon of technology we already possess. Jeez even China is frantically trying to attain self sufficiency in micro processor technology so much of which is under western control Reply SRamshaw (@guest_857768) 2 days ago #857768 Reply to Spyinthesky I think people are pointing out that it is a mixed blessing. Yes we need these industries not to be dependent on China, but on the other side we are both broke and the British Govt doesn’t exactly have a stellar record in managing Nationalized Companies. Reply William Robson (@guest_858046) 1 day ago #858046 Reply to SRamshaw Now we have Labour in charge America has Bob hope Johnny Cash and Biden We have no hope, no cash and Starmer Reply DRS (@guest_857764) 2 days ago #857764 Reply to Peter S Completely agree! Commercial priorities will always take production to a cheaper (read abroad) places. See Tata Steel and we now can’t produce virgin steel that is needed for defence and other needs. If India has a opposing view to us they can easily choke off supply. This is just one scenarios for one industry. Else china will buy it up cheap and then copy the IP and look to sell it to us (or not) as it chooses – see rare earths restrictions). Reply DJ (@guest_857680) 2 days ago #857680 About time. Previously quite a few defence establishments were government owned. Government does not need to run such sites (they are particularly bad at it), but if they own it, they get to decide who runs it & what the rules are. Reply Spyinthesky (@guest_857742) 2 days ago #857742 Reply to DJ The French manage such matters so much better than us, they have a water company that owns large parts of Hollywood for heaven sake. It’s how you manage things that’s important rather than taking ill conceived political (too often party political) stances on the matter that refuse to take an objective view. Reply William Robson (@guest_858047) 1 day ago #858047 Reply to DJ We make poor quality loose money and are full of leaks Reply Daniele Mandelli (@guest_857688) 2 days ago #857688 Interesting. MoD owned? Reply Supportive Bloke (@guest_857704) 2 days ago #857704 “ including advancements in artificial intelligence, quantum technologies, and 6G.” Brave statement as nobody has defined what 6G is yet! Reply Spyinthesky (@guest_857753) 2 days ago #857753 Reply to Supportive Bloke No one has really defined a 6th Gen fighter yet but hey we are designing one, which I guess is the point you don’t wait until what is an understandably nebulous concept to be set in actual concrete before you start imagining it in reality even if it changes along the way. Fact is whatever 6G becomes it will rely on very advanced chip technology, it may be a little chicken and egg but you don’t get there unless both are developed to enable the other. Software both dictates and is dictated by the hardware, TSMC dominates the Arm chip… Read more » Reply Supportive Bloke (@guest_857769) 2 days ago #857769 Reply to Spyinthesky It is a little bit different with telecoms like 6G which are agreed to international standards! 6th gen fighters are built to the most advanced achievable and affordable tech. 6G has to be cheap to bulk manufacture and install across the world. I’m bemused about this semiconductor plant as I didn’t think it had the most recent generation of fabrication tech. But it appears to have quietly been doing military fabrication for a long time. Reply tomuk (@guest_857814) 1 day ago #857814 Reply to Supportive Bloke It doesn’t it has been described as aging and the prior owners were going to close it down if a buyer couldn’t be found after losing a big contract with Apple. Reply Jonathan (@guest_857715) 2 days ago #857715 Probably a sensible way to go, in reality semi conductors are a massive western nation supply chain weakness..one in which any war with china over Taiwan would be a major problem. china has been hammering away at the semi conductors market really hitting other nations market share of the business..it’s basically upped its segment of the market by 62% over the last year, Korea is down 20%, Taiwan is down 31%, U.S. down 19%, Europe down 41%. when you think around 80% of the Market share in semiconductor sales sits with china, Korea and Taiwan..any western pacific war will essentially… Read more » Reply Spyinthesky (@guest_857754) 2 days ago #857754 Reply to Jonathan Someone who gets it, the MoD and Govt takes a whacking on here for its short sightedness, sadly that quality goes far deeper, as even as we see on UKDJ there are strong indications. Reply ChariotRider (@guest_857755) 2 days ago #857755 Reply to Jonathan Yup, very good point. Any large scale war in the future would be all about industrial capacity something our politicians are rediscovering in Ukraine. However, the lessons were already there to learn. Germany’s Spring Offensive in WW1 was defeated by the industrial response of the Western Allies. In the UK General Haig issued a call for support on the home front. It was answered in some style as production of everything from SE5a fighters to coal shot up – with production records being broken all over the place. In Germany, industrial output fell as the population were starving and revolution… Read more » Reply Jonathan (@guest_857777) 2 days ago #857777 Reply to ChariotRider Most people really have no idea what the idea of war means to the Chinese. I cannot remember exactly how many it was but the Chinese war book contains between 50-70 types of warfare it engages in…and most of that it does all the time..it does not believe in the concept of peace and war as different states..to china war is not the continuation of politics by other means..that’s very western…to china politics is simply the continuation of war by other means..as is everything else…the CCP has a uniquely warlike take on the world..it just believes that kinetic military operations… Read more » Reply Michael Hannah (@guest_857725) 2 days ago #857725 That will be the first thing the Tories sell off at a knock down price as soon as they get back into power. Reply Peter S (@guest_857734) 2 days ago #857734 Reply to Michael Hannah Neither Conservative nor Labour ( new or old) have shown any long term competence at protecting the defence industrial base. In manufacturing generally, new labour oversaw a bigger loss of manufacturing jobs than the Thatcher/Major governments. But there are some signs that even the hapless dimwits in Westminster have begun to understand. Reply Michael Hannah (@guest_857739) 2 days ago #857739 Reply to Peter S Wishful thinking more like Reply ChariotRider (@guest_857761) 2 days ago #857761 Reply to Peter S Ukraine..! It’s the one can they cannot kick down the road. Although to be fair it is also the one can that they all seem to agree on. Which is a bit sad really given that so many of our country’s ills could be sorted with a bit of common sense and cross party consensus. Oh well… Cheers CR Reply Meirion X (@guest_857758) 2 days ago #857758 Reply to Michael Hannah Who had the foresight to buy Sheffield Forgemasters, then? Did they finely sell off S.F ? If the tories do plan to sell strategic industries off in the future, they are obviously PRC/CCP agents really. Last edited 2 days ago by Meirion X Reply Michael Hannah (@guest_857783) 1 day ago #857783 Reply to Meirion X One moment of common sense doth not make a less clueless government. The stories did sell off the DRA who were making a tidy sum for the U.K. government selling parents. Btw you have them to thank for Flat screen TVs Reply DRS (@guest_857766) 2 days ago #857766 Reply to Michael Hannah Sheffield steel master was bought back under Tory watch, but yes look at sales by prior chancellors, tory or labour both as bad as each other. Reply Coll (@guest_857799) 1 day ago #857799 Maybe the government should take back the GPSS. From what i hav3 read, the goverment sold it for 85 million to a Spanish firm (CHL) and charge the MOD nearly 240 million to use. We do need prorect semiconductor manufacturing in the UK. Reply RB (@guest_857913) 1 day ago #857913 It’s sadly becoming a trend that the last factory in the UK manufacturing XXX has to be nationalised to stop it closing or falling into Chinese ownership. The next big call is H&W and FSS. Navantia wants to build the ships in Spain, but if suitably incentivised it will take over the H&W Belfast shipyard where nearly half the work was to be undertaken. However, it has no interest in the other companies/shipyards in the H&W Group. It’s a tough call for the MOD and the government – a retender will almost certainly result in the hulls being built in… Read more » Reply Bazza (@guest_857919) 1 day ago #857919 Reply to RB Isn’t Babcock the most likely candidate for a H&W takeover? If they bought even just the Belfast yard, then they would become the preferred bidder for all future RN and RFA vessels bar the tier one escorts (which BAE will likely remain the builder of). As long as Babcock still thinks there is profit to be made in shipbuilding, then they have good reason to pursue a H&W takeover in my opinion. Last edited 1 day ago by Bazza Reply William Robson (@guest_858038) 1 day ago #858038 Thank you for telling everyone where it is and how important it is. Well done Reply William Robson (@guest_858041) 1 day ago #858041 Where do you get the wafers from? Japan. Reply William Robson (@guest_858050) 1 day ago #858050 People on here talk of strategic industries. The steel works in Port Talbot was one of those. 80 inch rolling mill capable producing steel for ships and tanks. Now thanks to the Tetley tea folk they are now relegated to refrigerators and washing machines, you don’t need an 80 inch mill for that. The predicted electric arc furnace has gone from Three years to four How long before they pull the plug on that. They have stated they will import slabs to finish here. Teafolk TaTa Reply",
    "commentLink": "https://news.ycombinator.com/item?id=41683098",
    "commentBody": "Britain buys semiconductor factory for defence purposes (ukdefencejournal.org.uk)199 points by incognitojam 21 hours agohidepastfavorite102 comments tonetegeatinst 19 hours agoSmart to buy a preexisting fab. From what I understand via from various blogs and YouTube research, building a Feb even if your not doing cutting edge tech like tsmc, say going with an openpdk, still requires that special infrastructure. You need seismic dampening for the fab and to be located in a low activity region preferably, you need cheap water that can be refines, you need affordable electricity, and then supporting infrastructure to get the chemicals, the water, the machines delivered. Doing all of this isn't cheap and I'd bet is a lot of paperwork. Imagine going to some rural area and trying to build a fab, chances are the town has no clue what your impact or needs are and you would be spending lots of money to basically speed up development of the area. Side not to Semiconductors fab, where do you even buy one. Sure you can buy talent or machinery and then hire engineers to help get everything working, but if you wanted to for some reason buy a fan that already exists, say just the fab location and the equipment, how do you know what company to approach that might even consider selling. Who can even afford these purchases except massive fortune 500 company's breaking a piggy bank, or some massive credit institution, which I doubt would even do this because it would probably be a massive loan to any buyer. Seems like you need to have the money to build part of a fab if you want to buy one, idk who would even consider loaning that amount of money to a third party. reply spacebanana7 19 hours agoparent> Seems like you need to have the money to build part of a fab if you want to buy one, idk who would even consider loaning that amount of money to a third party Governments are happy to subsidise fabs, and VCs are even happier to invest in AI flavoured semiconductors if you can market it that way. reply quacksilver 11 hours agoparentprevAlso, they bought a fab, and by extension a bunch of knowledgeable employees who can work it and are eligible for UK security clearances. Once the knowledge of the workers is gone then it would be really hard to spin something up in country, and being the UK we would likely be forced to buy stuff from the US (or go to the far east anyway). If you built a fab in country then you would probably have to get staff from an existing fab to help run it and iron out any issues and gradually switch them out for local staff. reply momoschili 19 hours agoprevSeems like it was previously owned by Coherent, like some kind of III-V (specifically GaAs mentioned) photonics processes there in the past. This kind of technology is typically quite useful for lasers, LEDs, or potentially image sensors as well. Many LIDAR sensors and even light sources can notably depend on III-V semiconductor sensors. Also widely used by the telecom industry. Outside photonics definitely useful for high speed electronics, but that would probably take more process development to get going. reply hx833001 7 hours agoparentThey were closing because their major contract had been with Apple for FaceID components https://www.euronews.com/business/2024/05/27/apple-changes-l... reply RyJones 17 hours agoparentprevGen III night vision relies on it; I don't know if they ever made it there, tho. reply momoschili 17 hours agorootparentI didn't realize that! That seems like the most practical application from a defense perspective. reply chasil 18 hours agoprevWhy gallium arsenide? It's quite fussy. \"This facility is the only secure site in the UK capable of manufacturing gallium arsenide semiconductors, a vital component in military platforms such as fighter jets.\" reply pstrateman 17 hours agoparentIt's much more effective at extremely high frequencies used in compact radars, like the kind used on fighter jets. https://en.wikipedia.org/wiki/Gallium_arsenide#GaAs_advantag... reply rwmj 7 hours agorootparentThere was a whole Byte magazine dedicated to it back in the day. It was thought (at the time) that the only way we'd ever break the 1 GHz barrier was to use GaAs, which obviously turned out to be wrong. reply amy-petrik-214 14 hours agorootparentprevYea fo sho', and it was the Cray 3 supercomputer actually based on gallium arsenide at the time, meaning faaasssttt clock rates, about 6x faster than compeititors in terms of Hz. So that would be something like a 50 ghz processor today, wild reply chasil 14 hours agorootparentMy phone is faster. reply heeton 10 hours agorootparentYour phone operates roughly 10x slower in terms of Hz. reply ben_w 9 hours agorootparentAccording to page 10, the Cray 3's clock speed was 500 MHz: https://archive.computerhistory.org/resources/access/text/20... Phones beat that by a factor of x2-x4. And has 1-16 processors of 1 gigaflop each; depending on how much precision you want, a phone can beat that by a factor of just over x2000. reply PHGamer 13 hours agoprevwhats the process node it can do. im suprised a fab built in 1991 is stil valuable. the us is trying to build a 5nm fab in arizona and by the time its done well be at 1 or less. granted still probably worth it since it would only be about 7 years old process but 1991. thats gotta be old unless they kept upgrading it reply nine_k 11 hours agoparentMaybe it's not about processors at all, but about camera sensors, lasers, high-speed analog electronics, high-power semiconductor devices, etc. These are also really important parts of military gear. reply pjmlp 11 hours agoparentprevThe way things are going having any kind of chips is more valuable than whatever build process they use. Same applies to maybe starting having again some kind of national OSes, and programming languages, not subject to export regulations. reply riiii 19 hours agoprevWasn't the last British owned semiconductor factory in the UK sold to Chinese investors within the last year it so. The last steel furnace closing too? reply spacebanana7 19 hours agoparentThe last of the steel industry is Indian/Chinese owned and is in the process of closing down [1]. There’s actually 23 semiconductor fabs in the UK, presumably with a diversity of owners [2]. [1] https://www.theguardian.com/business/article/2024/sep/10/bri... [2] tech uk report: https://pixl8-cloud-techuk.s3.eu-west-2.amazonaws.com/prod/p... reply johnfarrelldev 18 hours agorootparentIt's not closing down, from the article they are moving to newer furnace technology which requires less workers to run. reply Reason077 13 hours agorootparentCorrect. There are two major steel producers still operating in the UK: British Steel's Scunthorpe steelworks in the North East of England, and Tata Steel's Port Talbot steelworks in South Wales. Both have announced plans to convert from blast furnaces to modern electric arc furnaces. This will greatly reduce emissions - they are among the largest industrial polluters in the UK (along with the Drax wood-burning power station). But conversion to arc furnaces also means that fewer workers will be required. reply musiciangames 13 hours agorootparentAs I understand it, Britain will no longer be able to produce steel from iron ore, only from scrap. Which doesn’t sound good strategically. reply Reason077 12 hours agorootparentIt actually makes sense strategically. Britain already has more steel than it will likely ever need, in fact it's one of the world's major exporters of scrap metals. But it depends on imports for iron ore. Why import iron ore (and coking coal, for that matter) when the resource you need to make better, more valuable steels more efficiently is already here? reply leg100 10 hours agorootparentBecause it's questionable whether that's even possible. reply Reason077 8 hours agorootparentOf course it is possible! Around 25% of the world's steel is already produced by electric arc furnaces. 100% in some countries, and over 70% in the USA. The UK exports 7-8 million tonnes of scrap steel every year, while producing about 5 million tonnes in blast furnaces. There's more than enough feedstock to replace all the UK blast furnace steel production with EAFs and still have some left over. reply librasteve 19 hours agoprevIt’s hardly gonna be mass production with 100 staff, hardly worth mentioning. I think Motorola had a fab in the South West once upon a time. And Inmos in Newport in the South East. reply youngtaff 2 hours agoparentMotorola’s plant was in Swindon, not sure what’s there now Newport, South Wales has a fab that specialises in silicon for power electronics reply leg100 10 hours agoparentprevNewport is in South Wales. reply Havoc 19 hours agoprevWhat lith node is that? reply osnium123 14 hours agoparentThe most advanced optical lithography for 6 inch wafers is I-line (365 nm wavelength). For compound semiconductor fabs, they can use e-beam lithography which allows for shorter gate lengths. Some companies are also clever about taking I line lithography and patterning tricks to make smaller features for gates. reply Dylan16807 11 hours agorootparent> Some companies are also clever about taking I line lithography and patterning tricks to make smaller features for gates. Well that's the critical question. Is that being used? Lithography using 193nm light varies from 130nm down to 10nm, if not wider. 365nm probably doesn't vary as much, but just saying the wavelength doesn't give a clear answer about the node size. reply osnium123 5 hours agorootparentA lot of the tricks used on 193 immersion tools for lithography scaling requires sophisticated deposition and etch processes which are not available on old 6 inch tools. Given that this factory was used for faceID parts, I suspect it was making VCSELs or other optoelectronics. These components don’t require fine lithography so it’s probably a 0.35 um capable fab. reply 6SixTy 19 hours agoparentprevAll I can find is that the plant works with 6 inch Gallium Arsenide wafers. reply _heimdall 18 hours agoprevThis sure feels like yet another sign that major global powers are all gearing up for war. This could be as benign as a government ensuring that the 100 jobs aren't lost, but given everything going in in both Europe and the Middle East it sure seems like more than saving such a comparatively small number of jobs. They could have just signed large(r) contracts with the company to financially secure the company, acquisition is a stronger play when the government needs more direct (and more private/secure) control. reply naming_the_user 16 hours agoparentA credible deterrent is required in order to prevent the mighty from simply taking everything. For the last few decades Western countries aside from the US have basically just sat on their laurels assuming that, well, we're in the end of history and nothing will ever go wrong again. A rude awakening. A sure fire way to ensure that there _is_ war is to sit about and sing kumbaya around the fire until the invaders turn up. reply onlypassingthru 16 hours agoparentprevIf you've been watching the Russian invasion closely, you'll have noticed that while it's good to have friends and allies with necessary ingredients, it's even better to be as self sufficient as possible. Relying on a foreign orange cheeto might ruin your recipe for self defense. reply bdjsiqoocwk 4 hours agorootparentYeah. As a European I feel humiliating how fumbling the EU has been to respond to the Russian invasion of Ukraine, and feel glad that our American friends are around to pick up the slack even though I'd be happier if we didn't need them :-/ so thank you on behalf of my moronic continent. reply rappatic 18 hours agoparentprevOff-topic as far as the article above goes, but do you think it's more likely for global(-ish?) war to erupt because of Europe/Middle East compared to Taiwan? A lot of the discussion around global war pre-2022 was for the late 2020s when China attempts to invade Taiwan. I personally doubt the major global powers will allow the conflicts in Israel and Ukraine to escalate to Western countries actually engaging in combat (but they do seem to want to personally defend Taiwan). reply _heimdall 15 hours agorootparentI have been expecting that, if another world war were to kick off, theaters of war would exist both in Europe/Africa/East Asia as well as the Pacific. A big risk for Taiwan, at least in my amateur view, is China feeling emboldened both by seeing an anemic response to other major conflicts and a West that is already distracted by said major conflicts. I grew up with the story that Hong Kong was just as off limits to China as Taiwan was. No one came to Hong Kong's defence though, even the British who should be on the hook for that situation just sat by in silence while the Chinese took complete control of HK and installed their own puppet government to manage the transition. reply whimsicalism 14 hours agorootparent> I grew up with the story that Hong Kong was just as off limits to China as Taiwan was Not sure when you grew up but that has been obviously false for at least 40 years reply PHGamer 13 hours agorootparentthe brits gave up hong kong in the 90s. as soon as that happened no one was expecting them to back the case. however, i suppose the brits were optimistic so they didnt have to have regret about losing a colony. i think taiwan might get some defense but only cause shit is made there and the west cant pretend the chinese wont flex their power reply youngtaff 1 hour agorootparentWith the New Territories due to be handed back at the end of their 99yr lease, Britain decided it wasn’t viable to keep the rest of Hong Kong reply csomar 15 hours agorootparentprevWar is momentum based. If the US gets dragged in a war with Iran and is also supplying Ukraine with weapons, China might perceive this particular moment as an advantage to start their Taiwan campaign. From there, more countries will see the chaos as an advantage to settle their border disputes. And there you have it, a global world war. reply sudjdkdn 18 hours agorootparentprevThe most likely reason for war is to move the competition with China onto a military footing rather than an economic one. The US would win the first, and that result would help the second. If you’re seeing western powers gear up for war, it might be to secure their economic future rather than a just intervention reply FpUser 17 hours agorootparentSo they would start a war and kill people for economy's sake? In this case what make them any different from any other war criminals? reply h18483djdj 7 hours agorootparentI think that’s the point. I’m old enough to remember Bush and Blair wanting UN support for Iraq but ditched the idea when they wouldn’t get it. And young enough that my parent’s generation have never seen a war and so don’t remember why the UN was created in the first place. We live in dangerous times with very poor leaders and politics reply knodi 17 hours agorootparentprevYa just don’t buy EU or UK would start ww3. There are much smarter and better economics and influence strategies to play out that are much less bloody to its own population. reply h18483djdj 7 hours agorootparentIt may not make WW status and they might not be directly involved in fighting it reply groby_b 18 hours agorootparentprevSome major global powers (i.e. China) have a vested interest in that escalation. Having the US tied down in two other conflicts means significantly less resources. Which means Middle East and Ukraine are already part of a global-ish war. Proxy wars, so far, but in service of a larger goal. (No, I don't think China necessarily instigated, but they're sure supporting ongoing conflict) As part of that, I'd also assume that the US nudged the UK to maybe consider their supply chain in case the US can't cover Europe's ass. (They can't, not if they expect a Taiwan conflict) reply cue_the_strings 17 hours agorootparentI'm under the impression that time is actually working for China and that they don't really require a war; they'll catch up economically soon enough (5-10y) that a war doesn't benefit them at all, and only the US would benefit from one right now, while they still have a chance of nipping their primacy in the bud. reply SllX 14 hours agorootparentIf Nationalism weren’t a factor, there is essentially zero reason for the PRC to ever invade Taiwan. Nationalism is a factor and the PRC is a totalitarian dictatorship. They’re going to go after what they consider their “rogue province” sooner or later, and whether it benefits them economically or not is a footnote. reply cue_the_strings 1 hour agorootparentThem being a totalitarian dictatorship doesn't necessarily mean they're stupid. I doubt they would risk their economy just because of Taiwan. They may go after it at some point in the future when the odds are in their favor (because they're obviously not right now), but I doubt it'll be soon. reply morkalork 17 hours agoparentprevThe list of countries \"casually arming up\" and talking about bringing back conscription is a little concerning. reply Barrin92 16 hours agorootparentAs someone who went through conscription in Germany, the last year to do so (I think), it's a huge relief to me. Almost three decades of neglect and naivete have made the world less safe, not more. Deterrence works. reply ethbr1 14 hours agorootparentDeterrence + democracy. Deterrence + autocracy is pretty unstable, because eventually the generalissimo gets to thinking that if he already has military capability sitting around... reply bdjsiqoocwk 4 hours agorootparentprevQuestion from a fellow European - Germany has conscription? What? reply guitarbill 3 hours agorootparentHad, until July 2011. This isn't unique. Austria, Denmark, Finland, Estonia, Greece, Norway, Sweden, Switzerland, and others have something similar, varying in details. (I think it's more commonly called military service or equivalent.) reply phil21 17 hours agoparentprevBased on contract ramp-ups from folks I know in sales having record years/quarters tied to the US DoD (while the rest of the sales divisions miss their numbers by huge margins) - I think that it's a foregone conclusion the powers that be expect a major uptick in hostilities sooner than later. But that's just my opinion, man. Could also be the tail wagging the dog. Either way, I think it's pretty clear we are moving from a unipolar world to at least a \"more\" multipolar world in the near to midterm future. Covid laid bare how utterly fragile the current supply chains are for almost everything from raw material to base chemicals to advanced chips and beyond in the western hemisphere - so it only makes sense for this to happen regardless. reply makeitdouble 16 hours agoparentprevHaving access to chips independently has deep economic effects as well, and that was the trigger in most countries. Defense though can be a much more easier talking point from a political and budgeting perspective, especially when trying to unlock an ungodly amount of money towards a potential risk. reply firecall 17 hours agoparentprevNot an expert at all, but wasn't part of The Cold War playbook to outspend the USSR? Investing in capability isn't necessarily a signal that we expect to deploy that capability. But it does force the enemy to level up, then when that enemy runs out of money, they tend to implode. I literally have no idea, so more than happy to be educated! reply _heimdall 15 hours agorootparentWell I'm shooting from the hip here and sharing only my gut intuition, so welcome to the party! In my opinion, governments buying (or taking over) producers that are necessary for the military feels like a drastic departure to how the military industry has operated for decades. At least in the US, though I think also in Europe, governments have been happy to keep up the status quo of writing massive checks to military contractors that, at least on face value, provide military equipment and training at a massive markup. In the US that markup also tends to be shared with those in power writing the checks through \"gifts\", campaign donations, and high paying jobs. Military contractors generally don't seem to be hurting for capital to pay employees, especially the actually vital contractors. If the government takes them over, the most likely motivator I see is for the military to have full control over production, projects, and information security. reply AStonesThrow 16 hours agoparentprev> This sure feels like yet another sign that major global powers are all gearing up for war. Keep an eye out for analogues to Aktion T4: https://en.wikipedia.org/wiki/Aktion_T4 Enacted in October 1939, and retroactive to 1 September, it was the final domestic coup-de-grace necessary to activate the Reich's war machine. Don't expect for a moment that it will be any different for the Allied powers. reply neximo64 19 hours agoprevso it wasnt to save them from insolvency? reply kragen 19 hours agoprevwhat a load of crap 'With global semiconductor demand rising, this move positions the UK to meet future technological needs, including advancements in artificial intelligence, quantum technologies, and 6G'? advancements in artificial intelligence depend on mass production of 4nm silicon cmos, not 100 people doing gallium arsenide for high-speed analog. 'quantum technologies' is vague enough to not be literally a lie (transistors depend on quantum physics to work, as do wires) but in this context it's clearly designed to trick people into thinking 'quantum computing' which is also unrelated to what these guys are doing reply momoschili 18 hours agoparentI think this view is a bit narrow in terms of what \"AI\" advancements may depend on. I think it's very easy to argue that large scale AI adoption will require orders of magnitude higher bandwidth than what we currently have. It's not clear that long term electronics will win in all applications, especially with the strong resurgence in interest of photonic computing. Fundamentally, photonic platforms have much higher potential bandwidth (at the cost of power and size currently) than electronics. GaAs (and other III-V) would likely be an essential material for some kind of photonic or hybrid compute system. The response below addressed the quantum sensors, but I would be careful of calling \"everything\" quantum such as image sensors. Sure they rely on the photoelectric effect which is quantum, but not really in the sense of what we would consider a 'quantum sensor' today. I suspect what could be more relevant are III-V based SQUID Qubits. These are highly sensitive systems that multiple nations are exploring for submarine detection. More near term, quantum communication via quantum light sources also can leverage a III-V platform. reply kragen 17 hours agorootparentsure, it's totally possible that the advantages of photonics or optoelectronics could win out, and iii–v semiconductors are pretty important for optoelectronics, though not for pure photonic systems like second-harmonic generation. sometimes people even use gaas for that, especially historically what are iii–v based squid qubits? google scholar is not helpful except for finding https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResea.... i thought a squid was a josephson junction device made out of superconductors and insulators, not semiconductors. gaas isn't a superconductor, is it? this doesn't sound like a quantum communication and squid research lab though. it sounds like a 50-year-old radar chip fab that's being put on life support as a pork barrel project reply momoschili 17 hours agorootparentbrain fart on my end, you're definitely correct that SQUIDS are not something demonstrated quite yet, I should have said Josephson junction, but even that seems more niche than I had thought when I wrote the comment. reply kragen 8 hours agorootparentyour comment oscillates between incorrect and incoherent. squids have been demonstrated for decades (i didn't assert they hadn't been) and are made of josephson junctions, whose nicheness is not at issue in this discussion. i hope you get better because you clearly were not well when you wrote this reply 1oooqooq 17 hours agoparentprevgood point. I'd bet this tech is completely useless by now (maybe used in 60s radar and night vision), the company was going to shut down, some politician saw a way to turn a news of layoffs into \"I'm bringing AI to my county\" reply blitzar 5 hours agoparentprevAlways pivot to Ai. reply adastra22 19 hours agoparentprevQuantum sensors rely on very precise control of doping conditions. Also these kinds of alloys are used in photonics computing, which is used to interact with qubits. Sounds like that’s what they’re talking about here. reply kragen 18 hours agorootparentsure, photonics could make sense. what do you mean by 'quantum sensors'? are there any sensors which are not quantum? reply adastra22 9 hours agorootparentIn the sense in that literally everything in the world is quantum, sure. But no, I mean sensors which derive their input channel from explicitly quantum effects. Gravometers, magnometers, atomic clocks, etc. are often quantum sensors. reply kragen 5 hours agorootparentpossibly you meant 'gravimeters'; a gravometer is evidently a 19th-century density measurement instrument. plenty of gravimeters are as purely classical as anything electrical is, and those that prominently feature quantum effects are superconducting gravimeters. i don't see how a gaas fab is relevant to either mems gravimeters or superconducting gravimeters! similarly 'magnometers' are not a thing, and magnetometers are generally either superconducting or pretty classical, so i am getting the feeling you are just trolling me to see if you can get a reaction by posting stuff without any consideration for whether it is true or not reply stainablesteel 18 hours agoprevmicrochips aren't going to do much in a fire fight, they should probably re-industrialize reply ineedasername 18 hours agoparentSmall arms dumb weapons aren’t going to do much by themselves either. Anything more than a rifle? Chips reply jldugger 18 hours agorootparentI think it's the [artillery shells](https://www.reuters.com/investigates/special-report/ukraine-...) that's been a bottleneck thus far in Ukraine. It's like NATO keeps around 3 serious war days worth of ammunition on stock. reply rightbyte 11 hours agorootparentThey estimate that radiation poisoning and starvation will prevent the armed forces from running out of shells. reply whimsicalism 14 hours agorootparentprevin an actual great power conflict, it will be more about cruise missiles and drones - at least initially reply dboreham 19 hours agoprevEveryone who worked for Inmos rolls their eyes.. reply tonyedgecombe 11 hours agoparentYes, it's difficult to see how this won't end up needing constant infusions of cash whilst delivering very little to nothing. reply zombiwoof 19 hours agoprevHere come the warm jets reply zx8080 16 hours agoprevIsn't it not how market works, by paying good price and allowing fabs to compete for it? reply zx8080 10 hours agoparentAnyone care to share why downvoting? reply thebruce87m 19 hours agoprev [–] > The acquisition is expected to secure up to 100 skilled jobs in the North East and safeguard a critical part of the UK’s defence infrastructure. The “North East” in the context of the UK and “the North East of England” are not interchangeable. reply gpjt 19 hours agoparentI'd love to know more about what you mean by that -- is it that the North East of England (which this factory is certainly in, it being in County Durham) is not the same as the North East of the UK (which I guess would be Aberdeen)? Or is there more to it than that? reply thebruce87m 19 hours agorootparentThat’s pretty much it. If you visit somewhere like r/CasualUK you will get people talking about “up north” and “being a proud northerner” and such like. They are all English people talking about England. Which is fine, but it’s supposed to be a UK subreddit. Even when foreigners are asking about travel advice. Must confuse the hell out of them. Or maybe some foreigners think that England = UK anyway so it all balances out? reply steve_adams_86 19 hours agorootparentEngland == UK isn’t a thing here in Canada, but I imagine it isn’t in any commonwealth nation. I think we learned more about the UK as kids than we did about the United States. reply murrayb 19 hours agorootparentSame in Australia. But my Dad was a Scotsman so I had it well emphasised reply bdjsiqoocwk 6 hours agorootparentprevIn the same way that England isn't the UK, reddit isn't HN. If you want to complain about a subreddit, go there. reply moomin 19 hours agoparentprevIt makes no sense but it’s common parlance. It’s like “Northern Rivers” in Australia meaning “an area on the east coast south of Queensland”. Similarly “The North East” rarely means an area containing Aberdeen, which would make more sense. reply thebruce87m 19 hours agorootparentMy experience is that only people in England think it is common parlance. If you are taking to someone in Scotland about the uk and mention the “north east” with no further context, they are not thinking about England. reply dboreham 19 hours agorootparentNorth East of London, obviously. reply mmoskal 19 hours agorootparentprevDon't get me started on Midwest in the US... reply SllX 14 hours agorootparentComing from the Best Coast I’d call it the Mideast if that wasn’t already taken. I begrudgingly accept calling it the Midwest for only that reason. reply modernpink 19 hours agoparentprevThe \"North East\" is the proper name of a NUTS 1 [0] region of the UK. It is distinguished from your interpretation of it as the \"north east of the UK\" by its use of capital letters, as is standard in English [1]. [0] https://en.wikipedia.org/wiki/International_Territorial_Leve... [1] https://en.wikipedia.org/wiki/Proper_noun#Modern_English_cap... reply thebruce87m 19 hours agorootparentUnless I am missing it, all references to “North East” in your first link are accompanied by “England” directly after. reply mkl 13 hours agorootparentIt seems to be used both with and without. In the main table with the maps it's not directly after, there's a comma. The \", England\" is specifying the country, same as where it says \"Yorkshire and the Humber, England\", \"East Midlands, England\", etc. There's no comma part for \"East of England\", because there it is part of the name. In the demographics table it is directly followed by \"England\". A more official source puts \"England\" in brackets, as if it's not part of the name but just to disambiguate: https://www.ons.gov.uk/methodology/geography/ukgeographies/e... reply kitd 12 hours agoparentprev [–] It's a UK website. In common parlance in the UK, they are interchangeable. reply thebruce87m 11 hours agorootparent [–] I live in the UK. In my experience only English people think they are interchangeable since they use it a lot implicitly. reply kitd 5 hours agorootparent [–] I also live in the UK. I mean, sure I agree with you, but that doesn't stop it being common parlance. reply thebruce87m 5 hours agorootparent [–] It’s definitely not common parlance in Scotland to say “north east” when talking about the UK and mean England, but I can’t speak for NI or Wales. A UK website making international articles should at least use “North East of England”, or perhaps “North East (England)” to comply with the official ONS ITL name as someone else pointed out. Even UK wide articles should do this. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The UK government has acquired a semiconductor factory in Newton Aycliffe, County Durham, now named Octric Semiconductors UK, to support the defence supply chain and Armed Forces.",
      "This facility is the only secure site in the UK capable of manufacturing gallium arsenide semiconductors, essential for military platforms like fighter jets, securing up to 100 skilled jobs.",
      "The acquisition ensures the continued production of critical semiconductors for military applications, stabilizing the plant and enhancing the UK's defence capabilities and industrial capacity."
    ],
    "commentSummary": [
      "The UK has purchased a semiconductor factory for defense purposes, highlighting the strategic importance of domestic semiconductor production.",
      "The factory, previously owned by Coherent, specializes in gallium arsenide semiconductors, crucial for military applications like fighter jets and high-frequency radars.",
      "This acquisition secures up to 100 skilled jobs and ensures the UK maintains a critical part of its defense infrastructure, especially as global semiconductor demand rises."
    ],
    "points": 199,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1727558614
  },
  {
    "id": 41685917,
    "title": "Floating megabomb heaves to near the English coast",
    "originLink": "https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/",
    "originBody": "Insights & Analysis Article Baltic Sea Floating Megabomb Heaves to Near the English Coast By Eitvydas Bajarūnas September 27, 2024 The MV Ruby, a ship carrying a highly explosive Russian cargo, is damaged and looking for a port. Whether or not this is hybrid warfare, the threat is clear. The Maltese-registered cargo ship, carrying 20,000 tons of explosive ammonium nitrate, triggered alarm bells in Western capitals when the vessel sustained damage and began to seek permission to unload its lethal cargo. She is currently seaworthy but unmoving some miles off the coast of Kent, to the east of London, and just outside UK territorial waters. Spurning the obvious solution of a return to Russia, where she loaded at Kandalaksha in late August, the damaged vessel embarked on an odyssey of attempted entry to European ports, beginning at the Norwegian anchorage of Tromsø, a naval base that she was ordered to leave on September 4. Ruby then sought permission to dock at Klaipėda in Lithuania, a critical NATO reinforcement facility in time of crisis and war. Lithuania refused because of the dangerous nature of the cargo. If 20,000 tons of ammonium nitrate were to detonate, it would obliterate the center of any port city — the blast would be equal to a third of the 1945 Hiroshima bomb. That would be a repeat of the devastating explosion of the same substance in Beirut in 2020, although Ruby is carrying seven times more ammonium nitrate. While Lithuanian authorities announced there was no evidence of malicious intent against the country’s national security, they noted that when dealing with Russia, or other unfriendly international actors, states should always be cautious. Alongside its war against Ukraine, the Kremlin has long pursued an aggressive hybrid strategy aimed at spreading chaos and destabilization through disinformation, interference in elections, and support for anti-Western political parties. But there has been a substantial uptick in recent months, including serious acts of sabotage. The shift in its strategy in the Baltic states from “classical” hybrid warfare to more “kinetic” approaches — not just propaganda and cyber-attacks, has now shifted to physical action on the ground. The physical sabotage includes acts such as a fire at an IKEA storage facility in Lithuania, which helped fuel false narratives about the safety and reliability of foreign investments, while cyber-attacks on power grids, water supply, and communication networks have also been used alongside GPS jamming to disrupt people’s everyday lives. The Baltic states are NATO members, meaning an outright military attack would likely trigger collective defense under Article 5; hybrid threats are designed to avoid direct confrontation that would result in a military response. Others have also been targeted. In August, German officials were reportedly concerned that Russia was responsible for incendiary devices on international air parcels. German trains have also been hit by sabotage attacks. In this atmosphere of heightened tension, should a ship carrying ammonium nitrate be interpreted as a hybrid threat? Potentially, yes, but it is important to walk between the dual traps of either neglecting emerging problems or labeling all incidents as deliberate. Get the Latest Sign up to receive regular emails and stay informed about CEPA's work. Email Ammonium nitrate is highly explosive, especially when exposed to fire or contamination, so strict safety protocols are followed, including controlled unloading in designated safe zones, continuous monitoring, and emergency response plans. The International Maritime Dangerous Goods (IMDG) Code contains strict guidelines for the substance, and compliance helps prevent accidents during transport and emergency repairs. Allowing Ruby to dock in Klaipėda would have created a significant security risk as the cargo would be a direct physical threat to a critical infrastructure hub, making it a potential trigger for destabilization if exploited by hostile actors. Klaipėda is vitally important to Lithuania and NATO in several strategic areas — military logistics, energy security, and regional power stability. It is a key hub for transporting military equipment and personnel and essential for NATO and the US’s reinforcement capabilities in the Baltic region. This would be particularly crucial in scenarios where the Suwałki Corridor, the narrow land strip connecting Poland and Lithuania, was under threat as the port would ensure NATO’s operational readiness in the region. The port also hosts the only large-scale LNG terminal in the Baltic states, which enables the import of LNG as an alternative to Russian gas and is a cornerstone of Lithuania’s energy security strategy. A security incident could disrupt supplies for the whole region. As if that wasn’t enough, Klaipėda plays a significant role in regional power connectivity through the NordBalt power cable, which links Lithuania with Sweden and is crucial for maintaining the stability of the Baltic power grid. Given these strategic roles, any threat to Klaipėda, whether from mismanagement of a dangerous cargo or a deliberate act, has far-reaching implications for regional security and energy stability. The Ruby episode underscores how hybrid threats can potentially evolve to include kinetic elements. The complexity of attribution, combined with Klaipėda’s strategic significance, makes it a potential flashpoint for regional security. To prevent such situations, robust intelligence-sharing, surveillance and maritime security protocols must be robust. Authorities should also be vigilant about the origins and intentions of vessels requesting access. Refusing or accepting such ships can have diplomatic repercussions, and denying entry might strain relations with the country of registration or cargo origin, especially if they are allies or significant trade partners. However, allowing such a vessel to dock could expose the host country to security and safety risks. Effective communication and adherence to international protocols are essential to navigate these diplomatic challenges, highlighting the need for a balanced approach to security, diplomatic and legal considerations. Eitvydas Bajarūnas is an ambassador in the Ministry of Foreign Affairs of the Republic of Lithuania, and currently a Center for Europe Policy Analysis (CEPA) Visiting Fellow. Assessments and views expressed in the article are those of the author and should not be treated as the official position of the MFA of the Republic of Lithuania. Europe’s Edge is CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America. All opinions are those of the author and do not necessarily represent the position or views of the institutions they represent or the Center for European Policy Analysis. 2024 CEPA Forum Leadership Awards Dinner Turning Leadership into Action. Learn More Europe's Edge CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America. Read More Related Articles Is Serbia the West’s Friend? Take a Fresh Look September 27, 2024 Civil Society Europe's Edge Regional Security Tsikhanouskaya: Western War Fatigue is a Luxury September 27, 2024 Authoritarian Threats Civil Society Europe's Edge Regional Security Boris Johnson: A Putin Victory “Will Make America Weak Again” September 27, 2024 Europe's Edge Regional Security Russia Related Issue Tags Baltic Sea Europe's Edge Hybrid Threats Regional Security Photo: The Stern of the MV Ruby, registered in Malta. The ship is carrying a 20,000 tons of highly explosive ammonia nitrate. Source: Times of Malta.",
    "commentLink": "https://news.ycombinator.com/item?id=41685917",
    "commentBody": "Floating megabomb heaves to near the English coast (cepa.org)187 points by itronitron 9 hours agohidepastfavorite199 comments chipdart 9 hours ago> While Lithuanian authorities announced there was no evidence of malicious intent against the country’s national security, they noted that when dealing with Russia, or other unfriendly international actors, states should always be cautious. This bears repeating. Russia has bee actively engaged in low-intensity warfare with the west for decades, and has single-handledly escalated their aggression towards the west in general but western Europe in particular for the last couple of years to the point they overtly and very publicly threaten the world with all sorts of attacks and global annihilation. Once Russia tries to casually float a massive bomb right into your doorstep, only a massive moron would not mitigate the risk presented by Russia, even if considered implausible. reply dtquad 8 hours agoparentRussia found out they had a faulty dangerous explosive ship under their control and instead of safely towing the ship to Russia and unload the Russian cargo they are instead using it to harass NATO countries as part of their hybrid warfare. The ship has been featured extensively in Danish and Norwegian media. First the Russians attempted to get the explosive ship close to a NATO base in Norway before the Norwegian coast guard chased them away. The Danish coast guard also had to confront them. The ship contains several times more Ammonium Nitrate than what caused the 2020 Beirut port explosion. reply samllmas 8 hours agorootparent7x Beirut or 1/3 power of Hiroshima according to the article (although would it cause as much damage as a nuke detonated in the air?) reply sigmoid10 8 hours agorootparentBeirut was 2750 tons. So it's slightly more than 7 times as much. Also, one ton of ammonium nitrate is roughly equivalent to 250kg of TNT. If this shipment actually were to explode all at once, the energy equivalent would be roughly 20x0.25=5 kilotons of TNT. That's one third of the Hiroshima bomb's 15 kilotons. But these are highly oversimplified number games. For example, it's highly doubtful someone could get this to explode all at once without dispersing most of it - even if they were actively trying to cause maximum damage. Nonetheless it's still a monumental safety risk and any port in their right mind would do well to shoo this piece of crap back to Russia. reply sixthDot 8 hours agorootparentprevNo, equal TNT power equivalent can have different effect depending on the nature of the explosive. The heat spreaded from an amonium nitrate blast, like in Beyrut, does not last as long, from [0], > However even on this basis, comparing the actual energy yields of a large nuclear device and an explosion of TNT can be slightly inaccurate. Small TNT explosions, especially in the open, don't tend to burn the carbon-particle and hydrocarbon products of the explosion. Gas-expansion and pressure-change effects tend to \"freeze\" the burn rapidly. A large open explosion of TNT may maintain fireball temperatures high enough so that some of those products do burn up with atmospheric oxygen [...] See also the \"Relative effectiveness factor\" paragraph [1] [0]: https://en.wikipedia.org/wiki/TNT_equivalent [1]: https://en.wikipedia.org/wiki/TNT_equivalent#Relative_effect... reply bruce511 8 hours agorootparentprevAt some point the comparison becomes moot. It's suffice to say that it's big enough to wreck the port, plus some significant percentage of the city around it. No, it likely wouldn't do as much damage as an airburst nuke. But it would be catastrophic nonetheless. reply chipdart 7 hours agorootparent> At some point the comparison becomes moot. That's a red herring. No one is looking at the decimal places. The comparison serves to provide a real-world benchmark of the expectable destructive power of the cargo held by this vessel, and a relative comparison of how big it would be. Arguing otherwise is idiotic. reply EasyMark 29 minutes agorootparentprevIt’s the same mentality of “it’d be really bad if something happened to that nuclear power plant due to an accident” that they approach the Ukraine invasion with the goal genociding their neighbor and taking their land/resources reply tgsovlerkhgsel 8 hours agoparentprevAt the same time, denying access due to the risk also shows that behavior has consequences: if Russia didn't behave like a dangerous, aggressive, untrustworthy bully, they would have an easier time getting their cargo offloaded reply AnonCoward42 8 hours agoparentprevnext [8 more] [flagged] rich_sasha 8 hours agorootparentI think the GPS jamming is fairly clearly a Russian operation. Not sure if this is a good source, but just eyeballing where the disruptions are, they centre around Kaliningrad region: https://rntfnd.org/2024/05/10/hobbyists-zero-in-on-kaliningr... Another one is hybrid warfare via artificial migration on Russia's Western borders. Poland, the Baltic states, and to a lesser extent also Finland, experience waves of aggressive migrants forcing these borders, often with clear help, or coercion, from Russian or Belarusian security forces. To be clear, I feel heavily for people escaping poverty and war, my point is they are being weaponised here. Protecting the borders saps resources from the militaries of these countries. Whether other specific attacks are Russian or not is hard to know, but it seems beyond doubt that Russia is engaging in low level hostility against the West. reply AnonCoward42 2 hours agorootparent> I think the GPS jamming is fairly clearly a Russian operation. Not sure if this is a good source, but just eyeballing where the disruptions are, they centre around Kaliningrad region: But you can admit that the IKEA fire example is laughable, right? But even the GPS jamming is questionable when it comes to the motivation. Do they have military reasons for it or is it to \"disrupt people’s everyday lives\"? > Another one is hybrid warfare via artificial migration on Russia's Western borders. Poland, the Baltic states, and to a lesser extent also Finland, experience waves of aggressive migrants forcing these borders, often with clear help, or coercion, from Russian or Belarusian security forces. To be clear, I feel heavily for people escaping poverty and war, my point is they are being weaponised here. This is actually a bit more nuanced than that. We are the ones that want (illegal) migration, it was only a problem when Belarus opened the borders and to be fair they have no obligation to keep them and they were upfront about it. It was a classic case of hypocrisy. That Russia did the same thing is new to me, but if Baltic states/Finland have proper border control there is no problem. It's a problem with our border control and creating unnecessary pull factors. > Whether other specific attacks are Russian or not is hard to know, but it seems beyond doubt that Russia is engaging in low level hostility against the West. I see the exact opposite and mostly retaliation to be honest, but even if you do not agree you can probably agree that the west is also hostile towards Russia. It's obvious that this opinion is not well received, but the west/US started all of it, starting at least with 2008 NATO summit and making it obvious in 2014 Ukraine coup d'état. I don't know what Russia did to the US to warrant this kind of provocation. reply mopsi 1 hour agorootparent> That Russia did the same thing is new to me, but if Baltic states/Finland have proper border control there is no problem. Finland has closed the entire land border with Russia in response to Russia ferrying migrants from the other side of the planet to Finnish border and forcing them to illegally cross it, to overwhelm Finnish social services and incite political instability. https://raja.fi/en/restrictions-at-the-border-crossing-point... > It's obvious that this opinion is not well received, but the west/US started all of it It is not well received because it is a hollow Russian talking point that has no substance behind it. Might as well bring up the international Jewish conspiracy and lizard people while you're at it. reply AnonCoward42 13 minutes agorootparent> It is not well received because it is a hollow Russian talking point that has no substance behind it. Might as well bring up the international Jewish conspiracy and lizard people while you're at it. Not sure why you are talking about lizards and jews. At least you're not telling anything of substance I could even take as an argument. You may tell me how it was Russia's fault the US/EU instigated the coup d'état in Ukraine for a change. reply ImPostingOnHN 4 minutes agorootparentUkraine's popular uprising against a russian-supported ruler is none of russia's business, as are most things that happen outside of russia. What you call a \"provocation\" is no excuse for russia's invasion and subsequent 3rd genocide of Ukrainians (the 1st being the russian genocide of the Crimean Tatars, the 2nd being the russian-perpetrated Holodomor). Had russia stayed within their borders and minded their own business, the current russian war of genocide against Ukraine would not exist. The hollow russian talking point in question is that russia being upset at something that happened in another country which has nothing to do with it, is somehow justification for russia perpetrating a war of genocide. chipdart 8 hours agorootparentprev> (...) we should still assume that most media are just propaganda (...) Is the ship filled with the same Beirute port explosion compound? Yes or no? Is the ship refusing to turn to Russian ports and instead is aimlessly trying to get into strategic EU/NATO ports? Even the captain failed to address any kind of repair while at Port. Only a moron does not consider this a threat worth mitigating. reply nkrisc 8 hours agorootparentprevWhen you have a Russian ship carrying this much ammonium nitrate, it’s prudent to assume the worst, even without evidence. Russia has made their bed, and now they must sleep in it. reply jojobas 8 hours agoparentprevnext [8 more] [flagged] spuz 8 hours agorootparentIn what way is this relevant, let alone an elephant in the room when talking about a ship of explosives. reply jojobas 8 hours agorootparentAs if an ammo warehouse didn't blow up in Czechia by two of these, an ammo factory didn't explode in Germany under mysterious circumstances. Not trusting a Russian ship is easy. How easy is trusting an ANFO-laden truck is not getting parked near a busy shopping mall right now? https://www.politico.eu/article/russia-berlin-fire-diehl-beh... https://en.wikipedia.org/wiki/2014_Vrb%C4%9Btice_ammunition_... reply giardini 2 hours agorootparentprevStanislov Petrov? The \"man who saved the world\"? Thank goodness for Stanislov Petrov! https://www.npr.org/sections/thetwo-way/2017/09/18/551792129... reply aaomidi 3 hours agorootparentprevBlatant xenophobia lol. Jesus Christ the state of this world. Immigrants go through a significantly higher barrier of entry and background checking than your average citizen. The average citizen who is probably reading rhetoric like yours and then going and mowing down migrants because the world told them they’re evil. reply giardini 2 hours agorootparentaaomidi says \"Immigrants go through a significantly higher barrier of entry and background checking than your average citizen. \" Nonsense. The vetting process can be as simple as wading across the Rio Grande and walking 20 miles (or a similar dry-land journey), whereupon the immigrant gains residency automatically. reply readthenotes1 2 hours agorootparentprevMaybe in your country. https://www.msn.com/en-us/news/us/ice-released-over-435-000-... reply piva00 4 hours agorootparentprevSource for hundreds of thousands naturalised? reply Terr_ 9 hours agoprev> Spurning the obvious solution of a return to Russia, where she loaded at Kandalaksha in late August, the damaged vessel embarked on an odyssey of attempted entry to European ports, beginning at the Norwegian anchorage of Tromsø This needs more explanation, does this mean the captain refused? Or Russian port authorities refused? Or they just... chose to limp in a particular direction? From another article [0]: > Not long after leaving the Russian port of Kandalaksha in late August, the general cargo vessel ran aground in a storm in Norwegian waters and a Port State inspection in Norway confirmed cracks in the hull and damage to the ship’s propeller and rudder. [0] https://theloadstar.com/baltic-ports-bar-damaged-ruby-now-in... reply derbOac 8 hours agoparentThat article fills in a lot of blanks for me: \"Over the weekend, MV Ruby was also denied access to the Strait of Denmark, the entrance to the Baltic which would have allowed it to offload its dangerous cargo at a Russian port. According to Danish news reports, on Friday a pilot was to be allocated the following day, but when the time came, authorities appeared to have changed tack. 'The ship is not going to have a pilot tonight, and the latest I’ve heard is that it’s in Norwegian waters,' DanPilot press officer Anne Heinze told DR Nyheder over the weekend. Instead, MV Ruby is apparently making its way toward the Channel, with Malta-flagged anchor handler Amber II maintaining a distance of around one kilometre... Though the vessel was able to limp some 1,600km around the Norwegian coast, it now faces a fraught voyage through the Channel, past Spain and the Strait of Gibraltar and onward to Malta through two of the world’s busiest shipping lanes. And there are few good choices ahead for the vessel’s crew: should MV Ruby sink, the cargo will likely cause enormous environmental damage, including algal blooms which choke swathes of ocean life, and could lead to a shipping exclusion zone to contain the spread of pollution.\" reply noselasd 8 hours agoparentprev> This needs more explanation, does this mean the captain refused? Or Russian port authorities refused? Or they just... chose to limp in a particular direction? The ship ran aground between Norway and Russia, seeked emergency shelter in Tromsø. The ship has damanges on it propellors and rudder. It anchored up near Tromsø for while until the port authorities and governments told the ship to leave due to security concern. Basically the ship stayed outside a small populated island, and it was determined the island would be blown flat if something happened. The Norwegian government are likely extra nerveous about this, just a small amount of the same stuff was used to blow up the government quarter in Oslo in the terrorist attack by Anders Brevik. Presumably the ship tried to get to another port elsehwhere, but got into more mechanical trouble. reply Arnt 8 hours agorootparentThe place \"near\" Tromsø where it anchored is in the middle of the city now. For this who don't know the place: the city is on an island, facing the mainland. There's a suburb on the mainland, connected to the city with a bridge and a tunnel. The ship anchored between the bridge and the tunnel. reply Arnt 8 hours agoparentprevIt was allowed entry to Tromsø and stayed there for a few days without repairs. reply alibarber 9 hours agoparentprevWould you want to be a captain of an EU registered ship stuck in Russia for an indeterminate amount of time with limited ability to pay for (sanctions) repairs of an uncertain nature? Of course I have no real info on why but it does seem plausible that returning would be unattractive. reply chipdart 8 hours agorootparent> Would you want to be a captain of an EU registered ship stuck in Russia for an indeterminate amount of time with limited ability to pay for (sanctions) repairs of an uncertain nature? Your hypothesis is quickly rejected/proven to be bullshit by the fact that the travel distance that the ship took after being rejected by Norway was greater than the distance it would need to take to get to a Russian port. And instead the ship planted itself where? Right in the middle of the English channel? We're talking about hitting ports from Norway, Lithuania, and now UK/France/Belgium? reply wood_spirit 5 hours agorootparentSo the ship is legitimately damaged in a grounding in a storm. The ship goes to nearest port for repairs. But when the nature of the cargo is understood, it is asked to leave. It chooses to head south to Russia via the Baltic instead of north into the artic. A reasonable safer course. Then Denmark denies it passage through the straights into the Baltic, so it now has to either head north again or carry on. It arranges to get to Malta, a place that makes its business in ship repairs. Seems reasonable actually. reply grues-dinner 1 hour agorootparentprevI assume the Murmansk ports told them they won't get back in (after all no other port will, why would they?) What do you think they should do, camp in international waters outside Murmansk in a dead-end of the Arctic, hoping a Russian port authority relents, until winter comes in full force and they're ultrafucked rather than just a bit fucked? Have you looked at a map? reply alibarber 4 hours agorootparentprevI'm not arguing against physical geography - I'm stating that it might in the current political climate be a lot easier to get a European flagged ship repaired somewhere in (political) Europe as opposed to Russia. reply londons_explore 9 hours agoprevNotably, ammonium nitrate is fertilizer. It is also effectively 'natural gas in solid form' - the main input to making ammonium nitrate is natural gas.The main cost is the cost of the natural gas, and there are huge worldwide markets for both natural gas and fertilizer. Therefore, from an economics perspective, natural gas and fertilizer are pretty much tied together. Same as electricity and aluminium. Natural gas is hard to ship - whereas fertilizer is easy to ship. Since Russia has bountiful supplies of natural gas, and sanctions prevent it selling that gas to europe via pipeline, producing fertilizer and selling that to the rest of the world is a workaround. reply odiroot 9 hours agoparentCH4 vs NH4NO3, where does the carbon go? Don't you need the carbon to recover the energy? reply kortex 8 hours agorootparentAmmonia is produced at scale by the Haber-Bosch process, N2 + 3H2 => 2NH3. Most H2 is currently produced by steam reformation of natural gas, CH4 + 2H2O => CO2 + 4H2. It's not really feasible to turn ammonium nitrate back to natural gas, moreso GP was insinuating it's a way to export (a proxy for) natural gas, eg to bypass sanctions. reply cromka 9 hours agoparentprevYou make it sound as if you can produce natural gas out of a fertilizer. reply MrVandemar 8 hours agorootparentThe parent does not imply anywhere that you can produce natural gas out of fertiliser. * They state that natural gas is an input to the fertiliser product * They state that with sanctions on natural gas from Russia, converting it to fertiliser evades the sanctions, albeit by transforming it into a different but saleable product. reply croes 8 hours agorootparentI think they mean because of that part >It is also effectively 'natural gas in solid form' reply squarefoot 8 hours agorootparentprevWould it be necessary if they could burn it in a controlled way that extracts an acceptable amount of energy? (Pure speculation of course, as I know nothing about the matter) reply M95D 8 hours agorootparentprevI think it's because gas wells can't just be turned off. Gas comes out of the ground and they have to do something with it. reply NewJazz 8 hours agorootparentprevYeah you just put it on grass then wait for cows to munch on the grass and burp. reply rich_sasha 9 hours agoprevI don't entirely follow the logic of the trip (but I know nothing about shipping). Tromso on the Norwegian Sea, then Klaipeda on the Baltic, now off the shore of Kent? That's very roundabout. It's easy to come up with explanations involving bad will. There must be some legit ones too. What are they trying to achieve? Did they buy some ammonium nitrate and are trying to offload it for a buyer, but successive ports are saying no? Surely whoever paid and loaded the cargo needed some idea of where and how they will offload it. reply greatgib 9 hours agoparentI agree also that news report are missing to report on what is the most interesting part to understand the problem: What was intended with this shipment in the first place? who is responsible for it? Regarding current international sanction, what was this ship doing loading or unloading in Russia and then going to any cost in Europe. Also, wouldn't it possible to unload it by smaller units with smaller boats why at the see? reply Arnt 9 hours agoparentprevThat ship is only 183m long. If it was in an emergency, there were plenty of ports near Tromsø that can handle that. Even Murmansk isn't far away. Marine Traffic says it's under way to Malta. reply krona 9 hours agoparentprev> That's very roundabout. Perhaps due to poor weather conditions in the past 14 days, especially given it has a cracked hull. reply rich_sasha 8 hours agorootparentAgain, I'm ignorant about seafaring, but isn't bad weather a reason to avoid long trips? reply tgsovlerkhgsel 7 hours agorootparentBad weather is a reason to avoid bad weather. On the scale of a long voyage, weather is \"local\" and can be avoided either by picking a different route, or a different time (potentially hiding in a man-made or natural harbor where the ship is less exposed to the waves and weather due to the surrounding terrain). reply timthorn 9 hours agoparentprevThe vessel is looking for a port to berth in but keeps being turned away. reply repelsteeltje 9 hours agoparentprevYeah I was thinking the same. Must have passed the Sont bridge (connecting Malmö to Kopenhagen) twice. Might have been a way of implying: whatever threats Ukraine may put on the Kerch bridge... well we obviously have means to retaliate \"the west\". reply willguest 9 hours agoprevI love the word 'megabomb' as much as the next guy, and I'm about all threat escalation, but isn't ammonium nitrate also fertiliser? Since this is one of the main (and historic) exports from Russia, I would imagine that one or two cargo ships have carried the stuff before. A little more info on how it is stored/transported and under which eventualities the cargo would become bomb-like would give me a sense of journalistic satisfaction as an accompaniment to my sense of impending doom. reply rnhmjoj 9 hours agoparentIt's probably a fertiliser shipment, but if it were to explode while unloading the intended use does not matter much. If you've seen some footage from the Beirut port explosion in 2020, calling something 7 times as large a 'megabomb' is not inappropriate. reply gmuslera 5 hours agorootparentThere are or were this kind of fertilizer shipments from other dates or countries that weren’t cataloged as megabombs? Maybe even bigger. A weapon is a weapon no matter who holds it. If coming from other sources, maybe in even bigger amounts, it is seen as something normal, then we are not talking about the ship. reply ErikBjare 8 hours agorootparentprevExperts have said in Swedish media that no such risk exists due to how it's packed/stored, unless someone intentionally mixes it with \"organics\" or stores it with fireworks (as in Beirut). reply tgsovlerkhgsel 8 hours agorootparentOrganics such as fuel oil, which the ship likely has on board and might also refuel. If it accidentally or \"accidentally\" leaks into the AN, you get ANFO, \"a widely used bulk industrial high explosive\". If Russia wants to nuke an European port city without using an actual nuke and while being able to at least leave some doubt whether it may have just been an accident, this certainly looks like a plausible way. reply sorokod 8 hours agorootparentprevLooks like some experts in Sweden disagreed, Ruby was denied entry to Gothenburg. reply neuroelectron 8 hours agorootparentprevAre you saying Beirut was intentional? reply petre 2 hours agorootparentWho cares, it's quite enough to reason to refuse a ship to dock in port. The Beirut ship also had a Russian owner. The AN was bound to Mozambique to be used for explosives. reply sorokod 9 hours agoparentprev> ... but isn't ammonium nitrate also fertiliser? That too, see the Beirut port explosion incident: https://en.wikipedia.org/wiki/2020_Beirut_explosion Going by the article, the ship carries an order of magnitude more ammonium nitrate then the amount that detonated in Beirut reply newsclues 8 hours agorootparenthttps://en.m.wikipedia.org/wiki/ANFO Simple to become a powerful explosive reply Arnt 9 hours agoparentprevhttps://www.thebarentsobserver.com/industry-and-energy/cargo... I guess the key is that after a few days in Tromsø, the authorities still didn't know what kind of repair was needed, and called bullshit. reply gizajob 8 hours agorootparentYeah it seems to be taking quite a tour for a faulty ship… reply spuz 8 hours agoparentprev> A little more info on how it is stored/transported and under which eventualities the cargo would become bomb-like would give me a sense of journalistic satisfaction as an accompaniment to my sense of impending doom. I agree. In fact the premise of the article - that this should be treated as a threat from Russia - hangs on the understanding that there is a legitimate reason a European port would accept a ship carrying this cargo. So how many such shipments are regularly made from Russia to Europe? What ports are designated to accept them? What safety measures do they have to handle the cargo? In what way is this particular ship different from those legitimate ones? Without this information, the article is incomplete. If there are no such legitimate shipments the article cannot claim there is any ambiguity about the threat posed by this ship. reply Arnt 4 hours agorootparentThere are many shipments of that cargo. What's unusual is to declare an emergency and then not order repairs quickly. reply dtquad 9 hours agoparentprevNo, Russia is deliberately using this ship to harass NATO countries. The ship was recently unusually close to a NATO base in Norway before the Norwegian coast guard chased them away. Here in Denmark the Danish coast guard also had to confront the ship. The ship has enough Ammonium Nitrate to cause an explosion several times the size of the 2020 Beirut port explosion. Basically any other country with a faulty ship full of dangerous explosive material would tow the ship back and fix their own mess. Russia is instead using it as hybrid warfare against geopolitical adversaries. reply rich_sasha 8 hours agorootparentThis is quite possible, equally though, what is stopping all these countries from simply refusing access to territorial waters for this ship. It seems to be travelling for thousands of miles just fine, so can't claim emergency shelter, and even then the danger to third parties seems to justify any refusals. The crew is likely tiny and easy to rescue if need be. I can imagine this being a simple ruse to annoy NATO countries and their navies too, that wouldn't be out if character, but beyond that... That would be a very petty hybrid risk. Or maybe Russia is just trying lots of things just to see what sticks..? From my side, while I think using a semi damaged ship as a hybrid threat would be within the Russian MO, it also seems like an easy one to protect against. reply chipdart 8 hours agorootparent> This is quite possible, equally though, what is stopping all these countries from simply refusing access to territorial waters for this ship. Note that for the ship to travel between Lithuania and Norway/UK, it needs to pass by Kaliningrad. For some reason the ship didn't stop there. The ship also didn't went from Lithuania to st Petersburg. Why was that? reply rich_sasha 8 hours agorootparentI get that, and it is odd. Though Russia can also wash its hands off of that ship. IIRC it is Maltese-flagged, owned by a Maltese company, and the crew is international. It \"just so happens\" that it contracts for Russian cargos. Russia may perhaps (?) be the ultimate beneficiary but it's also not strictly speaking Russian. Back to my question: can all these justifiably concerned countries not simply refuse access for this ship, end of story? reply grues-dinner 6 hours agorootparent> can all these justifiably concerned countries not simply refuse access for this ship, end of story Pretty much. Entire crews can be (and are) abandoned in international waters for years at a time if the company decides they don't want to deal with the ship any more. Which makes some sense as to why the crew would bring the ship down to the North Sea from the far northern Norwegian coast (weather this week: down to 2 degrees C, wind up to 40mph). If you think you might be abandoned in late September, and ports in Murmansk and Arkangelsk could also decide not to admit you, do you want to overwinter at sea in the Arctic, or go literally anywhere else? And that's if the company does forsake them, which is also a hypothetical. More likely, the company also would probably rather the ship is not at risk of being disabled in the Arctic considering they presumably couldn't get a guarantee readmittance to the port of origin and decided to at least get to relative safety down south with better weather and near countries that at least plausibly would lift a finger if the ship really was at risk. reply grues-dinner 6 hours agorootparentprevThe ship started in Murmansk. How would it have gotten to Lithuania (or Kaliningrad, St Petersburg or anywhere in the Baltic) if it's not allowed though the passage by Denmark? reply bborud 8 hours agorootparentprevFor those who downvote the above, yes it presents speculation as if verified fact, but what it puts forth is actually plausible when you see how Russian military efforts tend to make use of uncertainty. If you are going to dismiss it: dismiss it with facts and arguments. Don't just lazily downvote it. reply orbital-decay 8 hours agorootparentJust to be clear, you want HN users put effort into a rebuttal of the factless speculation presented as a fact? This isn't how discussions work, this is flamebait (just like the article itself) and has no place on HN. This doesn't contribute to the discussion, and should be downvoted and flagged. reply bborud 8 hours agorootparentThe two last statements of the post are indeed speculation. What was said up until that point can be verified. However, the speculation should be seen in light of recent history. Russia does have a history of shady maritime dealings covered by deniability. For instance you have probably heard of cables that have been mysteriously cut in the northern regions. As for you accusing me of posting flame-bait: that's not very nice. I presume you have some way of proving your speculation? reply orbital-decay 7 hours agorootparent>As for you accusing me of posting flame-bait Grandparent, not you. I'm not speculating about anything, please re-read my comment. reply protomolecule 9 hours agorootparentprevnext [6 more] [flagged] practice9 9 hours agorootparentThe interesting thing is that ship was damaged almost immediately after leaving the port, had a chance to stop in Russian ports along the way but instead is doing a tour near EU countries. The crew is either amazingly incompetent or malicious/complicit. You don’t put a ship that can blow up near: a. Gas&oil terminals, b. military air base reply protomolecule 8 hours agorootparentAnd it must be run be a suicide crew. These crazy Russians! reply op00to 5 hours agorootparentPerhaps the crew was not given a choice. reply protomolecule 5 hours agorootparentAnd they were like \"ok, we'll die for Mother Russia\" reply grues-dinner 4 hours agorootparent...said the Filipino deck hand to the Egyptian navigator, no less. (I don't know what nationalities the ship's crew has, but based on the ship's ownership, it would be pretty unlikely to be all Russian unless they've already disposed of and replaced the entire crew). So not only is there now a suicidal crew of mad Russians, but they also killed the old crew. They just keep getting more dastardly! They probably caused the bad weather too! Andøya is usually so lovely this time of year! Actually this rampant speculation thing is quite fun. I should sell this stuff to whoever is running the Tom Clancy estate. reply cromka 9 hours agorootparentprevYou don’t know that, this is pure speculation. reply xattt 9 hours agorootparentDidn’t they try to dock in two infrastructure-critical ports with a damaged vessel? How about the order of the docking? There must be some sort of remote outport where it can dock without the fear of obliterating critical infrastructure. Chances are it docks, it gets abandoned because there’s no money to fix it, and it stays conveniently parked until an “unfortunate” fire happens. Plausible deniability is the modus operandi of Russian operations. Borderline Personality Disorder-style scorched earth retaliation is more so. reply spookie 8 hours agorootparentprevThey've been wandering close to the Danish and Swedish coasts not that long ago with \"research ships\" that had armed personnel on board. I would be less inclined to believe if such strategies weren't as commonly employed. But, they are. reply bborud 8 hours agorootparentThis is a relatively constant factor along the Norwegian coast and has been for many years. In recent years the behavior has become a bit more aggressive with communication cables at sea going missing. This tends to not make international news as this activity isn't exceptional. It just varies in intensity and scope over time. reply noselasd 9 hours agorootparentprevSeems pretty accurate, no ? The ammonium nitrate stored in Beirut was 2,750 tonnes, this ships is carrying about 20,000 tonnes reply ErikBjare 8 hours agorootparentIt's not the same. Storage conditions matter. reply lb1lf 8 hours agorootparentThat is true, but given the current level of trust between Russian and 'Western' authorities, would it not be prudent to assume the vessel is indeed a threat and keep it away from infrastructure and the general population if at all possible? In the case of Arctic Norway, there are plenty of unpopulated, sheltered fjords. No need to dock it in a commercial port in an urban area. reply Lio 8 hours agorootparentprev> Storage conditions matter. …only if it hasn’t been deliberately sabotaged. It’s had opportunities to return to Russian ports and just sailed right by them. Why is it desperate to dock in a Western port? reply mulmen 42 minutes agorootparentI don’t know but it’s easy to imagine why an international crew would chose to be stranded in the west instead of Russia. reply grues-dinner 9 hours agorootparentprevIf this were a threat, how would the Russians coerce a ship full of sailors to not surrender or abandon the ship rather than choose between vaporisation or arrest or death by navy when trying to escape the aftermath (assuming they even have boats that can get away from the blast)? reply chipdart 8 hours agorootparent> (...) how would the Russians coerce a ship full of sailors to not surrender or abandon the ship rather than choose between vaporisation or arrest or death by (...) Have you paid any attention to Russia's meatwave tactics in Ukraine that so far already piled up half a million of Russian casualties? If you did, you wouldn't be considering this scenario implausible, because we see videos of said Russians needlessly marching towards their deaths on a daily basis. reply grues-dinner 8 hours agorootparentAre the sailors actually Russian military? Or are there suicidal commissars on board along with them to put a gun in their backs 1000km from home? I'm not saying it not possible, but the fact that there isn't a rather more concerted response involving, say, the SBS or an encounter with an Astute within the last several weeks while it's been tooling around the North Sea implies that the intelligence services don't consider it as much of an actual active threat as the media circus wants it to be. Certainly if there was even a breath of Russian military on the ship, I don't think \"hey sure, just drop anchor outside Margate and chill next to these other ships and right by the Thames and Channel shipping lanes\" would be the call they'd make. reply chipdart 7 hours agorootparent> Are the sailors actually Russian military? The people Russia is sending to their deaths in their meat wave tactics aren't exactly Russian military either. They are at best civilians under contract and moved to front lines weeks if not days after being hired. Then there are the civilians pressed into service such as unsuspecting immigrants and Ukrainians who found themselves in occupied territories. The key factor is complete disrespect for those under your control, and willingness to sacrifice themselves for the smallest reason. reply grues-dinner 7 hours agorootparentKind of seems like climbing onto or sending a message to the anchor hoy currently alongside and requesting asylum from the murderous Russians would be the obvious way out of that one. Margate may not be luxurious, but it's not a Ukrainian front line. The only evidence that it's anything other than a damaged ship in a shit situation (even shitter than your average Syrian/UAE cargo ship, which is probably saying something) with a very low chance of a very big explosion, trying to find somewhere to put in, is that the word \"megabomb\" makes good headlines and people want to have exciting things happen, even if \"it\" is blowing up a town, no matter how dreary, from 12 miles away with what would presumably be the biggest non-nuclear explosion in history. reply rainworld 7 hours agorootparentprev“The [Ukrainian] commanders estimated that 50 to 70 per cent of new infantry troops were killed or wounded within days of starting their first rotation.“ https://www.ft.com/content/b9396112-585a-4f7e-9628-13d500c99... http://archive.today/WKqxz reply sofixa 8 hours agorootparentprevThe same way Russia coerces soldiers to go into the meat grinder against Ukraine - money, assurances their families will be cared after (well it might be with a sack of potatoes, but the poor fools can't know that). reply croes 8 hours agorootparentprevMaybe they don't know they are used. reply amenhotep 8 hours agorootparentprevIf the plan was to deliberately detonate the ship rather than just be an annoyance that can't be ignored, then it seems like a very obvious option to rig it with a timer and have the crew escape during the night. Risk of arrest for sure but they'd have a chance, and the west has shown no shortage of willingness in the past to exchange assassins for hostages. People take on worse missions all the time. I'd far rather be crew on this ship than on HMS Campbeltown. reply grues-dinner 6 hours agorootparentAnd if that were remotely on the cards, even within a shadow if a doubt, there'd be an exclusion zone around the ship. And there isn't. There are ships going right past it, right now. reply wavefunction 8 hours agorootparentprevWhat if Russia cut the normal radio with a crew of dispensable third-worlders dummies like you suffer from a DEFICIT OF IMAGINATION reply grues-dinner 8 hours agorootparentHow would they have been turned away from ports, or even hope to get into a port, without a working radio (but still a working AIS)? There's a difference between a lack of imagination and a lack of credulity for any breathless headline. reply louthy 8 hours agoprevHere’s its current location: https://www.marinetraffic.com/en/ais/details/ships/shipid:16... reply qwery 8 hours agoprevI don't know much about CEPA (this is the first time I've come across them) but I don't think they're the best source for news. This article is extremely inflammatory, frames the entire story around Russia and seems to be extremely selective with which details were included. The article is stuffed with problems but I'll point out just a couple of examples: > Maltese-registered cargo ship This appears to be a deliberate attempt to cast doubt as to the \"true\" operator or entity controlling the vessel. The ship is \"Maltese-registered\" because it's owned by a Maltese company, 'Ruby Enterprise'. It's destination is Malta. > Spurning the obvious solution of a return to Russia, Is this obvious? As the article admits, the vessel is seaworthy. Why would a seaworthy ship carrying some exported product return to the origin port? I think this BBC article[0] offers a much more balanced take on the events. [0] https://www.bbc.com/news/articles/c62g95721leo reply loufe 8 hours agoparentThis is pretty much a non-point. In the age of off-shore, ownership-obfuscated, tax avoiding company proliferation, any country \"owning\" a vessel means very little. To give an example, technically most \"mining\" companies in the world are Canadian. What that means in practice is they rent a desk in one of a handful of office towers in Vancouver to set their legal/financial headquarters in the country to access services and the TSX. They are certainly not \"Canadian\" in the true sense. I see news articles sometimes mentioning X Canadian mining company operating in South America, Africa, or SE Asia. If the true owners are not Canadian, the operations are not Canadian, the office workers, leadership team, and financial flows never touch Canada, it's not Canadian. That said, I do agree it's inflammatory and probably not the best source. reply philipwhiuk 5 hours agorootparentIf Malta choses to give a ship a flag, they should bear some level of consequence for that action. reply tgsovlerkhgsel 8 hours agoparentprevThe article contains an interesting note at the end: \"Eitvydas Bajarūnas is an ambassador in the Ministry of Foreign Affairs of the Republic of Lithuania, and currently a Center for Europe Policy Analysis (CEPA) Visiting Fellow. Assessments and views expressed in the article are those of the author and should not be treated as the official position of the MFA of the Republic of Lithuania.\" That may suggest bias, but also an unusual level of insight (and there is the possibility that it is an official position pushed through a \"side channel\" to make it look less official). And according to the BBC article, it's destination isn't Malta, at least not until they figure out where else to unload the cargo, because Malta won't let them in with the cargo on board. That in itself is noteworthy. Especially since the \"it might leak\" claim sounds like it might just be an intentionally-transparent pretext. reply bryanrasmussen 8 hours agoparentprev> Why would a seaworthy ship carrying some exported product return to the origin port? Why would a seaworthy ship carrying some dangerous explosive material, that multiple ports have now refused entry, return to the origin port? I mean at this point - is there in fact a port it can go to that is not the port of origin that will accept them? It seems there isn't, so why travel around making moves towards other ports unless as a form of aggression. (no question mark) reply wewxjfq 8 hours agoparentprevAstonishing amount of critical thinkers here in this thread who have to highlight that the ship is Maltese because it's flying a Maltese flag as if this matters in international shipping. reply jojobas 8 hours agoparentprevYeah, cause Russians couldn't afford a front in Malta of all places, or play the crew blind. reply SideburnsOfDoom 8 hours agorootparentA Russian front in a small corruptible EU state in the Mediterranean (e.g. Malta, Cyprus) would not be a surprise at all. See many news articles e.g. https://www.eureporter.co/world/malta/2023/08/09/malta-has-a... https://www.icij.org/investigations/cyprus-confidential/cypr... reply jojobas 8 hours agorootparentThat is exactly my point. reply SideburnsOfDoom 7 hours agorootparentSure. I thought though that it might need spelling out to some of the audience here who are far removed from that part of the world. I myself didn't know it until I visited Malta and Cyprus. reply czottmann 4 hours agoprevCombine that story with the recent, substantial reports about hapless pseudo-mercenary \"disposable agents\" bought by Russian intelligence, and the whole thing feels even more icky. Have that ship dock somewhere, and some idiot assets who don't know what they got themselves into infiltrate it to start a fire or something, for a few hundred bucks. See this article from German newspaper ZEIT (auto-translated using Google Translate): https://www-zeit-de.translate.goog/2024/41/russische-sabotag... > The disposable agents > Russia is waging a war of sabotage against the West. Initially with graffiti, now with arson attacks. The perpetrators are young men who have no idea who they are serving. Original German-language article at https://www.zeit.de/2024/41/russische-sabotage-wegwerf-agent... Archived at https://archive.ph/20240926105720/https://www.zeit.de/2024/4... reply aftergibson 9 hours agoprevThe great sort of news you want to hear while drinking your morning coffee and living in Kent to the east of London. reply fanf2 2 hours agoparentHow far are you from the SS Richard Montgomery? https://en.wikipedia.org/wiki/SS_Richard_Montgomery reply lnxg33k1 9 hours agoparentprevBe careful, if the coffee is too hot.. :D reply samllmas 8 hours agoparentprevGrab some popcorn instead reply oswalk 9 hours agoprevIs it unfeasible to ship these kinds of things in smaller loads? Why would you put any kind of dangerous material that would \"obliterate the center of any port city\" in the same place without strong guarantees that nothing will go wrong? A boat does not seem like that kind of place. reply dist-epoch 7 hours agoparentThis fertilizer is very difficult to detonate accidentally. Quite a few things need to go wrong. It's also used in huge quantities. reply op00to 5 hours agorootparentIt is very easy to detonate on purpose though. Perhaps by contaminating it with fuel oil from the ship itself. “By accident”. reply lazide 9 hours agoparentprevHey, if you’re already packing ‘world destroying’ amounts of explosives and taking all the precautions, then why not make it 3x the amount? reply Tsiklon 2 hours agoprevIs there something to be said for “consumable” deep water off shore ports for contents that are “sensitive” like this? Diplomatically one can say “yes you can dock here and unload cargo, but we demand that it be off shore and away from otherwise sensitive infrastructure” This would allow such cargo to be offloaded safely in desperate circumstances while still maintaining the integrity of key infrastructure. reply giardini 2 hours agoprevOffload the cargo at sea to another boat? Barring that, flood it compartment by compartment and pump the fluid into other boats (to be later dried and re-packaged) or into the ocean (the ocean is big). Then bring the ship in to repair the hull or to salvage it.QED. This can all be done at sea. Of course, someone has to pay. reply Aeolun 9 hours agoprevJust leave it offshore then? I’m fairly certain ‘outside of territorial waters’ is equivalent to ‘more than 25km from shore’. It can safely explode there. If the crew want to get taken off their sinking ship they are more than welcome. reply lnxg33k1 9 hours agoparentExactly my point of view, detonate it far away and let the insurance pay reply agent327 9 hours agorootparentIs this your general view on all ships carrying fertiliser? Do you know how many people would starve to death if we stopped shipping fertiliser around the world? reply Aeolun 8 hours agorootparentOnly ships owned by countries we are more or less at war with and have a rich history of sabotage and assassinations. I think this is fairly self-evident. It’s quite similar to a trojan horse. reply Hamuko 7 hours agorootparentprevAre all ships carrying fertiliser damaged? reply lnxg33k1 8 hours agorootparentprevI'm no starving expert, but is all fertiliser explosive? reply fullspectrumdev 8 hours agorootparentA lot of the useful ones are nitrate based. So, “sometimes”. reply kevin_thibedeau 7 hours agoprevRussia sent a tugboat to Cuba. They can easily rescue the ship if they wanted. reply bborud 8 hours agoprevI'm assuming this is the ship? https://www.marinetraffic.com/en/ais/details/ships/shipid:16... Anyone have a Marine Traffic account and can tell us about its movements? reply sorokod 8 hours agoparentNo account required: https://www.vesselfinder.com/?imo=9626390 reply bborud 8 hours agorootparentThat just tells me where it is now. You need an account to see where it has been for the last N days. reply sorokod 8 hours agorootparentAh true, not exactly what you are looking for but according to this article [1] : Kandalaksha Tromsø Klaipeda Gothenburg [1] https://theloadstar.com/baltic-ports-bar-damaged-ruby-now-in... reply bartread 6 hours agoprevSorry, but this stinks to high heaven, and what it stinks of is bullshit. If the cargo is Russian and you legitimately want to dock for repairs, then why try Tromsø, Klaipėda, and then anchor the ship off the UK coast? If you legitimately need to dock for repairs why not dock at Kaliningrad? The cargo is after all Russian so let them deal with the problem. You have to literally sail past Kaliningrad to get to the English channel in any case, so it's hardly surprising that people port authorities are cautious if not outright suspicious. reply grues-dinner 4 hours agoparentBecause it was damaged in northern Norway, and requested permission to go to Klaipeda, in the Baltic. Lithuania said no, unless it unloads first. The Lithuanians said, two weeks ago, they'd found a port in Norway that agreed to unload, near where it was stopped. Presumably that fell though and thus the permission was withdrawn. Then Denmark refused access to the Baltic, and Gothenburg also then said no. The ship never entered the Baltic as far as I can tell. The implication is that the ship didn't want to go back to Murmansk. Possibly it was also denied entry, or doesn't want to get stuck there over winter if the Russians can't or won't repair the ship. It's not a Russian ship, it might not even be Russian-owned cargo any more, depending on the INCOTERMS, why would they make the effort if no one else will? https://www.lrt.lt/en/news-in-english/19/2358770/ship-with-r... reply malomalsky 8 hours agoprevThis is how I found out that Russia is burning down IKEA warehouses in Europe xD reply lolc 8 hours agoprevOne thing that's only lightly touched upon in the article: Is this journey unusual and where is the fertilizer usually unloaded? The way the article is written, the ship's operators may with plausible deniability be deliberately targeting ports where a blast would be most debilitating for NATO. But where are other ships with this fertilizer unloading? It must be a common operation in European ports. Are there special ports for this, and the captain is spurning them? Ostensibly because they want to dock for repairs? Now that I think about it, while it could be hard to sell that much fertilizer from a port where it wasn't ordered to, transfering it to another vessel not in need of repairs would solve the whole situation overnight wouldn't it? That's expensive but should be normal procedure I'd expect. So yeah what are the operators up to? reply qwertox 8 hours agoprevCan't it be dragged to the Kaliningrad port? That would be the perfect place to store the ammonium nitrate. reply Traubenfuchs 9 hours agoprevShips and their crews can‘t be cheap. Who paid to put the ammonium nirate on the ruby? Who paid for the ship to go somewhere? What was the original deal involving the ammonium nitrate? Did someone in another country originally plan to buy it but the deal was later cancelled? The ammonium nitrate cargo alone is worth several million us dollar. reply krona 9 hours agoparentIts a maltese ship headed to Malta. https://archive.ph/jFtD7#selection-1429.111-1429.116 > It is then expected to continue through the Channel with its destination listed as Marsaxlokk in Malta. The authorities in Malta said that they would only accept the vessel if it got rid of its cargo beforehand. reply ryanjshaw 8 hours agorootparentShips are registered in Malta as a matter of convenience. See: they don't want the cargo either. https://en.m.wikipedia.org/wiki/Flag_of_convenience reply jamil7 8 hours agorootparentThere’s a book capitalism and the sea that goes into more detail on this. It’s mostly a means for shipping companies to skirt regulations. reply illwrks 9 hours agoparentprevPerhaps it was someone trying to get around sanctions on Russian imports, was found out and refused entry/ abandoned? reply protomolecule 9 hours agorootparentThere are no sanctions on Russian fertilizers. Europe's fertilizer production is down due to high natural gas prices (I wonder what happened) and import from Russia is up. reply wewxjfq 8 hours agorootparentDo you want to provide sources for these claims? I see Germany's fertilizer exports are down by 10%, while its fertilizer imports from Russia fell by 80%. Fertilizer production seems to be up, but this metric is tracked by value only. reply protomolecule 6 hours agorootparent\"For some types of fertiliser, such as urea, imports have even increased since Moscow’s invasion of Ukraine in 2022. The cheap fertiliser has helped European farmers, but the region’s own fertiliser producers have been struggling to compete. “We are right now being flooded by fertilisers from Russia, which are significantly cheaper than our fertilisers, for the simple reason that they pay peanuts for natural gas in comparison to us European producers,” said Petr Cingr, chief executive of SKW Stickstoffwerke Piesteritz, Germany’s largest producer of ammonia. “If politicians will not act,” he warned, Europe’s production capacity “will disappear”. ... A third of EU imports of urea, the cheapest form of nitrogen-based fertiliser, come from Russia, with the amount imported in 2023 close to record levels, Eurostat data shows. Poland’s imports of Russian urea climbed to almost $120mn in 2023, up from just over $84mn in 2021, for example, according to customs data. ... Other big players are leaving the market. BASF, the world’s largest chemicals group, has shrunk its operations in Europe over the past few years, including its fertiliser business, and instead focused new investments in the US and China, where costs are lower.\" [0] [0] https://archive.is/20240630042149/https://www.ft.com/content... reply protomolecule 9 hours agoparentprevnext [7 more] [flagged] KronisLV 8 hours agorootparent> Lithuania refused to help to spite Russia. This was explained in the article: > Lithuania refused because of the dangerous nature of the cargo. If 20,000 tons of ammonium nitrate were to detonate, it would obliterate the center of any port city — the blast would be equal to a third of the 1945 Hiroshima bomb. That would be a repeat of the devastating explosion of the same substance in Beirut in 2020, although Ruby is carrying seven times more ammonium nitrate. That's hardly spite. reply protomolecule 6 hours agorootparentYou should've quoted the next paragraph too. There would be no need for it if the danger of fertilizer was enough to justify the refusal. \"While Lithuanian authorities announced there was no evidence of malicious intent against the country’s national security, they noted that when dealing with Russia, or other unfriendly international actors, states should always be cautious.\" And then the article goes on trying to justify that by saying that Russia has set on fire an IKEA warehouse (wat?) and is jamming GPS. Sure, this means that Russia is going to murder tens of thousands civilians by detonating its ship with fertilizer. reply KronisLV 4 hours agorootparentCaution feels like the right choice regardless: > On 4 August 2020, a large amount of ammonium nitrate stored at the Port of Beirut in the capital city of Lebanon exploded, causing at least 218 deaths, 7,000 injuries, and US$15 billion in property damage, as well as leaving an estimated 300,000 people homeless. A cargo of 2,750 tonnes of the substance (equivalent to around 1.1 kilotons of TNT) had been stored in a warehouse without proper safety measures for the previous six years after having been confiscated by Lebanese authorities from the abandoned ship MV Rhosus. This ship carries considerably more. You can critique the framing and language used if you want, but I doubt many officials would be happy to take that risk. reply protomolecule 3 hours agorootparentAnd what is the risk, exactly? \"Norway’s Maritime Authority told the BBC the vessel was inspected by DNV Group to ensure it met safety and environmental standards. The group found damage to its hull, propeller and rudder, but the Ruby was still deemed “seaworthy”. As a precaution, DNV Group, and the Maltese flag registry, insisted that a tug escort the vessel for the remainder of its journey. The ship was bound for Klaipeda, in Lithuania, according to ship tracking firm MarineTraffic. But despite being deemed seaworthy, the ship was denied entry to Klaipeda. Algis Latakas, the port authority's chief executive, told the BBC that this was \"because of its cargo\".\" [0] [0] https://www.bbc.com/news/articles/c62g95721leo reply pvaldes 8 hours agorootparentprevSeems a reasonable move having in mind the number of times that Russia said lately that they want Lithuania \"returned\" to them. And we all know what on Russia \"liberate\" means \"laminate\". Not helping the people that wants you dead is wise reply protomolecule 6 hours agorootparent>the number of times that Russia said lately that they want Lithuania \"returned\" to them Zero? reply rdtsc 9 hours agoprev> Ammonium nitrate is highly explosive, especially when exposed to fire Is that true? It seems, from a pedestrian perspective, if just fire could trigger it, they wouldn’t be transporting it in such amounts. reply albumen 9 hours agoparentFrom the Wikipedia article [1]: \"In the second case, the explosion results from a fire that spreads into the ammonium nitrate (AN) itself (Texas City, Brest, Tianjin, Beirut) or to a mixture of an ammonium nitrate with a combustible material during the fire. The fire must be confined at least to a degree for successful transition from a fire to an explosion (a phenomenon known as \"deflagration to detonation transition\", or DDT). Pure, compact AN is stable and very difficult to initiate. Ammonium nitrate decomposes in temperatures above 169 °C (336 °F). Pure AN is stable and will stop decomposing once the heat source is removed, but when catalysts are present, the reaction can become self-sustaining (known as self-sustaining decomposition, or SSD). This is a well-known hazard with some types of NPK fertilizers and is responsible for the loss of several cargo ships.\" [1]: https://en.m.wikipedia.org/wiki/List_of_ammonium_nitrate_inc... reply kpil 8 hours agoparentprevNo not really. You need an explosion or energetic impact to trigger it, and potentially a fire too. But it might become unstable by heat and more so if it's contaminated by oil. One early industrial disaster and the biggest explosion of it's time happened because the workers in a production plant in Germany regularly used Dynamite to clear out stuck ammonium nitrate in silos. The last time they tried, the plant was obliterated together with most of the nearby town. reply gus_massa 5 hours agorootparentI had to find more details. From https://en.m.wikipedia.org/wiki/Oppau_explosion > Indeed, nothing extraordinary had happened during an estimated 20,000 firings, until the fateful explosion on September 21 [1921]. reply adastra22 9 hours agoparentprevJust shaking it too much can trigger it, if stored improperly. reply rdtsc 8 hours agorootparentIf it gets wet or packed too tightly. Ah interesting. Yeah trusting Russian inspectors that they did their job is not a good idea. reply SideburnsOfDoom 9 hours agoparentprev> if it was so unsafe, they wouldn’t be transporting it in such amounts. You'd think so, but: https://en.wikipedia.org/wiki/2020_Beirut_explosion A classic example of how reasoning from logic alone is no match actual knowledge of reality. Or perhaps, in this specific case, the unsafeness is the point: it's intended to harass. reply rdtsc 8 hours agorootparentThey store it next to fireworks. And then proceed to weld near where the fireworks are stored. reply lazide 8 hours agorootparentprevSounds like a classic job for the CIA. Uh, I mean, ‘accident’. reply portaouflop 8 hours agoprevTIL you could wreck the whole international economy/market/political order with a few well placed shipwrecks reply westcort 1 hour agoprevLet it sink! reply yawpitch 8 hours agoprevFor the non-boaters, “heaves to” means “has stopped” in this context. reply londons_explore 9 hours agoprevammonium nitrate is safe till you accidentally mix it with something like fuel oil. It would be trivial for an inspector to go look and see if such mixing has occurred... and if it has not, let it into port to sell the cargo. reply gus_massa 6 hours agoparentIANAEE, but I think you are mixing potasium nitrare and ammonium nitrate. Looking in Wikipedia, in the danger warning square, in the yellow part potasium nitrare has a 0 and ammonium nitrate has a 3. Don't try this at home ... Potasium nitrate has a lot of oxygens but nothing to burn with it. So it's only explosive when mixed with some fuel. Ammonium nitrate has the oxygen and also the hidrogens that can be combined and release energy. It has also some spare oxygen, it is probably more dangerous mixed with fuel. reply aziaziazi 9 hours agoparentprevFuel oil… or any combustible basically. A famous combustible to mix with is sugar. Cheap and mis wert well with it, still stable if no heat source. I hardly imagine how an inspector can \"look\" if there’s any king of combustible hidden in the lower layers of the ship cargo. reply londons_explore 7 hours agorootparentA sampler on a stick is used, which can be poked down to the bottom to get a sample from the bottom - useful for contaminants which are heavy or liquids. reply adastra22 9 hours agoparentprevAmmonium nitrate is explosive by itself. It doesn’t need fuel or oxidizer. By adjusting its pH level the breakdown reaction can be prevented and the compound stabilized, but it decays over time or when improperly stored. reply aziaziazi 8 hours agorootparentIn my humble understanding among I’m nitrate is a oxidizer (or a precursor of it). Am I wrong ? How would it explode without a fuel ? reply adastra22 8 hours agorootparent2NH₄NO₃ (s) → 2N₂ (g) + O₂ (g) + 4H₂O (g) Only happens spontaneously at high temperature/pressure. But of course being an explosive reaction, once it starts in a little pocket of material, all the neighboring material experiences a lot of heat and pressure, and blows up. And then the next layer, and the next layer, etc. If improperly stored, pockets form with different pH values that cause it to spontaneously occur at lower temperatures. Or a spark, or a compressive event in an unstable patch, etc. reply tgsovlerkhgsel 8 hours agorootparentOr, if the ship is indeed being used as a weapon, a \"small\" hidden charge of military explosives that will be hard to find after a kiloton-scale explosion. reply tgsovlerkhgsel 8 hours agorootparentprevhttps://en.wikipedia.org/wiki/Oppau_explosion suggests that pure AN is also explosive. As far as I know, the explosion that leveled part of Beirut was mostly assumed to be caused by uncontaminated AN too. reply dist-epoch 7 hours agorootparentIt was stored in the same warehouse with fireworks, and in the videos you can see them explode shortly before the big explosion. reply senectus1 8 hours agoprevIts an interesting scenario. because if the ship suddenly decided to turn around and head for the closest, most densely populated costal city... what can they do about it? Blow it up? its ALREADY close enough to cause significant damage. Somehow sink it without detonating it? The environmental damage alone would be devistating to the econcomy... if this is a russian plot, it's already increadibly successfull. reply tgsovlerkhgsel 7 hours agoparentNukes aren't a perfect model for a ship full of explosive fertilizer, but a reasonable enough approximation/upper bound for which we can easily find formulas/calculators online. A 15 kiloton nuke has a 1 psi radius of about 3 km according to https://nuclearsecrecy.com/nukemap/# So a possible solution would indeed be stopping it by any means necessary somewhere between the 22 km mark (where it enters territorial waters) and the 3 km mark where it becomes a serious hazard. reply dist-epoch 7 hours agoparentprevYou just use tugboats to push it away, and protect the tugboats with coast guard vessels. The only environmental damage would be from the ship fuel. The fertilizer is not a problem, maybe it would cause a short term algae boom. reply lnxg33k1 9 hours agoprevI'd say, bring it as far as you can from any human being, and detonate the shit out of it, it has like 7 times more shit on it than the one in Beirut? And you want to dock it somewhere? Since what happened in Beirut, how do we allow to have so much explosive on a single ship? reply lazide 9 hours agoparentIt’s having the problems it’s having because no one allows a ship in with that much explosives on it anymore haha! reply lnxg33k1 9 hours agorootparentI mean, it's a great solution right now to detonate it away from humans, but I was more wondering to disallow loading that much explosive in the first place, because I think long term it's not great for sealife to detonate 20k tons of explosive every now and then :D reply protomolecule 9 hours agorootparentThen get ready for the raise of the prices on agricultural products in Europe. What's explosive for you is fertilizer for the farmers. reply kkfx 6 hours agoprevCuriously no one say who have bought the fertilizer... Ask yourself why, to ask yourself why the war in the first place. reply GaggiX 9 hours agoprevI hope they evacuate the crew and bomb it in the middle of the ocean so we can film the explosion in 4K. Unfortunately, I don't think that's going to happen. reply abricot 8 hours agoparentSadly true. It will likely be 720p vertical. reply JBiserkov 5 hours agorootparentAnd shaking horizontally, with a bit of rotational wobble. reply FollowingTheDao 8 hours agoprevThe Monsters Are Due on Maple Street. reply roenxi 9 hours agoprevThe hybrid war angle is wild conspiracy theorising. If the Russians wanted to blow up an English city they might as well drop bombs on it directly. I still wouldn't want to be near a fertiliser ship though so it'd be reasonable to tell it to go somewhere else. reply cromka 9 hours agoparentBlowing up a ship offers way more plausibility. It’s not hard to imagine it would leave NATO without response. Not so much with the actual bombs. reply tgsovlerkhgsel 8 hours agoparentprevDropping normal bombs on it is highly identifiable and attributable, and not very damaging. Also, a normal bomber or cruise missile might actually get shot down. There would be no doubt about Article 5 and the need for a military response. Dropping a nuke on it is equally or more damaging, but likewise highly identifiable and attributable, and would force an even bigger reaction, likely even by China. Also, again, might be shot down. An explosion of a cargo ship is just as damaging as a small nuke, but cannot be immediately identified as an attack - even if people suspect it, it's hard to conclusively prove that it wasn't an accident. This makes it hard to muster a unified and strong response. reply dctoedt 3 hours agorootparent> Dropping normal bombs on it is highly identifiable and attributable, and not very damaging. Also, a normal bomber or cruise missile might actually get shot down. Submariners would like a word. reply tgv 9 hours agoparentprevHow are they going to drop a bomb on it? Bomber? Rocket? If a ship explodes, Putin will deny everything, and grudgingly everyone will accept it, because you can't be certain, and we don't want war. But if a long-range bomber leaves Russia, flies to Liverpool and drops a bomb, it's an open declaration of war. reply wslh 9 hours agoparentprevThe world is full of complexities and often misunderstood events. Applying higher-order thinking, such as realpolitik and game theory, can provide a more nuanced understanding of global dynamics. After centuries of dismissing concerns as mere \"conspiracy theories\" it's important to recognize that this may not be a theory, but rather a potential warning. reply aAKagh 8 hours agoprev [–] The only Western asset that has been sabotaged was Nordstream, by either the U.S. or the Ukrainians (now the official story is that Zalushny ordered it). CEPA is a propaganda site: https://cepa.org/article/wake-up-nato-its-sabotage/ \"European energy security and the continent’s critical infrastructure are the core pillars of Transatlantic security. Safeguarding them is fundamental to ensuring democratic resilience and stability.\" In light of Nordstream, this is hypocritical and offensive to Western Europeans who suffer the economic consequences. Yes, the Russian invasion is bad, yes, they should get out of Ukraine, but repeatedly manufacturing additional stories is counterproductive. reply simion314 7 hours agoparent [–] What about Eastern Europe, some ammo depo sabotaged by Ruzzians? Sabotaging GPS that affected air traffice ? reply rhagsf 7 hours agorootparent [–] What about it? \"ammo depo sabotaged\" does not yield any meaningful search results. If it were confirmed, certainly The Telegraph and the New York Times would shout it from the rooftops. The GPS jamming is classified by the Finnish transport agency as a \"side effect of Russia's anti-drone activities\": https://www.politico.eu/article/gps-jamming-is-a-side-effect... \"Jamming GPS signals over the Baltic Sea is “most likely” a side effect of Russia's anti-drone activities, Traficom, the Finnish Transport and Communications Agency, said today. “The interference intensified when Ukraine's drone attacks on Russia's energy infrastructure began in January 2024,” Traficom said in a press release. Estonia also blames Russia for the signal jamming, but the Finnish agency doesn't agree with the Tallinn government in defining the interference as a hybrid attack.\" reply simion314 4 hours agorootparent [–] I am wasting my time to repsond for others that might read ehre, not sure hpow incompetent you must be not to find soemthign with Google or not to be aware by the sabotages that happened. But let me assume good faith and you are a poor Ruzzian kid with soviet mentality due to bad parents/grandaprents you can do a Google search like putting this text in the input box >ammo depo \"sabotage\" \"bulgaria\" \"russia\" https://www.novinite.com/articles/221906/First+Russian+Sabot... https://en.wikipedia.org/wiki/2014_Vrb%C4%9Btice_ammunition_... use Google and find more, though I am 100% sure you will balme CIA and Israel as a good soviet of fabricating the evidence. You have enough evidence with names and photos of Ruzzian agents and their movement. You have evidence from Russians that Putin tried to blow up apparments in Russia to achieve his goals and then you act surprised that Putin could do something bad in Europe, like his crimes are limited ot only Ruzzia and their exUSSR territories. Sinking a ship into a river to screw over a country is a typical soviet thing to do, same with abandoning a ship with explosives in a NATO port and blowing it up months later, you need to know the soviet mindset and then you will not be confused that they could think and act upon such terroristic plans. reply ajsdawzu 4 hours agorootparent [–] We have to keep these people out of the EU. It is getting tiresome. reply simion314 3 hours agorootparent [–] Yeah, and for HN, this accounts created a few seconds before they start defending a terrorist regime should be flagged, the IP should be blocked for a month. The guy might claim he does not want to lose karma for his support of terrorist regime but IMO if you support terrorists then you should be \"alpha\" enough so your ego can resist some karma hits. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The MV Ruby, a Maltese-registered ship carrying 20,000 tons of explosive ammonium nitrate, is damaged and seeking a port off the coast of Kent, UK, posing a significant security concern.",
      "The ship has been denied entry to several European ports, including Norway and Lithuania, due to the dangerous nature of its cargo, which could cause devastation comparable to a third of the Hiroshima bomb.",
      "The incident highlights Russia's hybrid warfare tactics and underscores the need for robust intelligence-sharing, surveillance, and maritime security protocols to manage such threats effectively."
    ],
    "commentSummary": [
      "A damaged ship carrying 20,000 tons of ammonium nitrate, a highly explosive material, is nearing the English coast, causing significant safety concerns.",
      "The ship has been denied entry to multiple European ports and is suspected of being used by Russia to harass NATO countries, raising geopolitical tensions.",
      "Authorities are on high alert due to the potential threat and Russia's history of low-level hostilities, questioning the ship's intentions as it travels from Norway to Lithuania and now near the UK."
    ],
    "points": 187,
    "commentCount": 199,
    "retryCount": 0,
    "time": 1727600343
  },
  {
    "id": 41687707,
    "title": "Some Go web dev notes",
    "originLink": "https://jvns.ca/blog/2024/09/27/some-go-web-dev-notes/",
    "originBody": "Some Go web dev notes I spent a lot of time in the past couple of weeks working on a website in Go that may or may not ever see the light of day, but I learned a couple of things along the way I wanted to write down. Here they are: go 1.22 now has better routing I’ve never felt motivated to learn any of the Go routing libraries (gorilla/mux, chi, etc), so I’ve been doing all my routing by hand, like this.// DELETE /records:case r.Method == \"DELETE\" && n == 1 && p[0] == \"records\": if !requireLogin(username, r.URL.Path, r, w) {return } deleteAllRecords(ctx, username, rs, w, r)// POST /records/case r.Method == \"POST\" && n == 2 && p[0] == \"records\" && len(p[1]) > 0: if !requireLogin(username, r.URL.Path, r, w) {return } updateRecord(ctx, username, p[1], rs, w, r) But apparently as of Go 1.22, Go now has better support for routing in the standard library, so that code can be rewritten something like this:mux.HandleFunc(\"DELETE /records/\", app.deleteAllRecords)mux.HandleFunc(\"POST /records/{record_id}\", app.updateRecord) Though it would also need a login middleware, so maybe something more like this, with a requireLogin middleware.mux.Handle(\"DELETE /records/\", requireLogin(http.HandlerFunc(app.deleteAllRecords))) a gotcha with the built-in router: redirects with trailing slashes One annoying gotcha I ran into was: if I make a route for /records/, then a request for /records will be redirected to /records/. I ran into an issue with this where sending a POST request to /records redirected to a GET request for /records/, which broke the POST request because it removed the request body. Thankfully Xe Iaso wrote a blog post about the exact same issue which made it easier to debug. I think the solution to this is just to use API endpoints like POST /records instead of POST /records/, which seems like a more normal design anyway. sqlc automatically generates code for my db queries I got a little bit tired of writing so much boilerplate for my SQL queries, but I didn’t really feel like learning an ORM, because I know what SQL queries I want to write, and I didn’t feel like learning the ORM’s conventions for translating things into SQL queries. But then I found sqlc, which will compile a query like this: -- name: GetVariant :one SELECT * FROM variants WHERE id = ?; into Go code like this: const getVariant = `-- name: GetVariant :one SELECT id, created_at, updated_at, disabled, product_name, variant_name FROM variants WHERE id = ? ` func (q *Queries) GetVariant(ctx context.Context, id int64) (Variant, error) {row := q.db.QueryRowContext(ctx, getVariant, id)var i Varianterr := row.Scan( &i.ID, &i.CreatedAt, &i.UpdatedAt, &i.Disabled, &i.ProductName, &i.VariantName,)return i, err } What I like about this is that if I’m ever unsure about what Go code to write for a given SQL query, I can just write the query I want, read the generated function and it’ll tell me exactly what to do to call it. It feels much easier to me than trying to dig through the ORM’s documentation to figure out how to construct the SQL query I want. Reading Brandur’s sqlc notes from 2024 also gave me some confidence that this is a workable path for my tiny programs. That post gives a really helpful example of how to conditionally update fields in a table using CASE statements (for example if you have a table with 20 columns and you only want to update 3 of them). sqlite tips Someone on Mastodon linked me to this post called Optimizing sqlite for servers. My projects are small and I’m not so concerned about performance, but my main takeaways were: have a dedicated object for writing to the database, and run db.SetMaxOpenConns(1) on it. I learned the hard way that if I don’t do this then I’ll get SQLITE_BUSY errors from two threads trying to write to the db at the same time. if I want to make reads faster, I could have 2 separate db objects, one for writing and one for reading There are a more tips in that post that seem useful (like “COUNT queries are slow” and “Use STRICT tables”), but I haven’t done those yet. Also sometimes if I have two tables where I know I’ll never need to do a JOIN beteween them, I’ll just put them in separate databases so that I can connect to them independently. Go 1.19 introduced a way to set a GC memory limit I run all of my Go projects in VMs with relatively little memory, like 256MB or 512MB. I ran into an issue where my application kept getting OOM killed and it was confusing – did I have a memory leak? What? After some Googling, I realized that maybe I didn’t have a memory leak, maybe I just needed to reconfigure the garbage collector! It turns out that by default (according to A Guide to the Go Garbage Collector), Go’s garbage collector will let the application allocate memory up to 2x the current heap size. Mess With DNS’s base heap size is around 170MB and the amount of memory free on the VM is around 160MB right now, so if its memory doubled, it’ll get OOM killed. In Go 1.19, they added a way to tell Go “hey, if the application starts using this much memory, run a GC”. So I set the GC memory limit to 250MB and it seems to have resulted in the application getting OOM killed less often: export GOMEMLIMIT=250MiB some reasons I like making websites in Go I’ve been making tiny websites (like the nginx playground) in Go on and off for the last 4 years or so and it’s really been working for me. I think I like it because: there’s just 1 static binary, all I need to do to deploy it is copy the binary. If there are static files I can just embed them in the binary with embed. there’s a built-in webserver that’s okay to use in production, so I don’t need to configure WSGI or whatever to get it to work Go’s toolchain is very easy to install, I can just do apt-get install golang-go or whatever and then a go build will build my project it feels like there’s very little to remember to start sending HTTP responses – basically all there is are functions like Serve(w http.ResponseWriter, r *http.Request) which read the request and send a response. If I need to remember some detail of how exactly that’s accomplished, I just have to read the function! also net/http is in the standard library, so you can start making websites without installing any libraries at all. I really appreciate this one. Go is a pretty systems-y language, so if I need to run an ioctl or something that’s easy to do In general everything about it feels like it makes projects easy to work on for 5 days, abandon for 2 years, and then get back into writing code without a lot of problems. For contrast, I’ve tried to learn Rails a couple of times and I really want to love Rails – I’ve made a couple of toy websites in Rails and it’s always felt like a really magical experience. But ultimately when I come back to those projects I can’t remember how anything works and I just end up giving up. It feels easier to me to come back to my Go projects that are full of a lot of repetitive boilerplate, because at least I can read the code and figure out how it works. it’s cool to see the new features Go has been adding Both of the Go features I mentioned in this post (GOMEMLIMIT and the routing) are new in the last couple of years and I didn’t notice when they came out. It makes me think I should pay closer attention to the release notes for new Go versions. Want a weekly digest of this blog? Subscribe Reasons I still love the fish shell",
    "commentLink": "https://news.ycombinator.com/item?id=41687707",
    "commentBody": "Some Go web dev notes (jvns.ca)159 points by tosh 4 hours agohidepastfavorite44 comments voigt 2 hours ago> In general everything about it feels like it makes projects easy to work on for 5 days, abandon for 2 years, and then get back into writing code without a lot of problems. To me this is one of the most underrated qualities of go code. Go is a language that I started learning years ago, but did't change dramatically. So my knowledge is still useful, even almost ten years later. reply tmpz22 2 hours agoparentI agree but those first 5 days are going to be a mixed bag as you pick through libraries for logging, database drivers, migrations, as well as project organization, dependency injection patterns for testing, organize your testing structure, and more. If you have a template to derive from or sufficient Go experience you'll be fine, but selecting from a grab bag of small libraries early on in a project can be a distraction that slows down feature development significantly. I love Go but for rapid project development, like working on a personal project with limited time, or at a startup with ambitious goals, Go certainly has its tradeoffs. reply mattgreenrocks 2 minutes agorootparentAbout 50% of the time learning a new language I find that the consensus framework/library choice is not quite to my taste. It isn’t that it’s bad, it just often feels like one thing went viral and then ends up boxed in by their success such that people double down/put up with it rather than evolve it further. Point being you’re probably going to spend those first five days evaluating the options. The “community” doesn’t know your taste or your needs. You have no idea what their goals are, or what the average skill level is. All of those things can make a big difference in selecting tech to build atop of. reply joshlemer 2 hours agorootparentprevI stumbled on this Go starter project that has enough batteries included to get you started I think. You might find it useful https://github.com/mikestefanello/pagoda reply tmpz22 1 hour agorootparentRight and mikestefanello/pagoda seems like a comprehensive framework combining the labstack/echo/v4 routing framework and entgo.io/ent \"ORM\" - among other things like HTMX and Bulma. That is a highly opinionated grouping of tools that gets you to a poor persons version of a full stack framework that many in the Go community would flat out reject. reply leetrout 1 hour agorootparentI really don't understand the hate for a framework in \"the community\". I had stayed away from Go for about 3 years and I posted on r/golang asking if anything had popped up like a django in go and got nothing but hate. I chock it up to people enjoy writing the same boiler plate stuff over and over in their paid jobs where they have the time to do it. To your point, I've got my own set of libraries that I think are The Best™ for all my reasons that at least keep me productive. Echo for the routing... sqlc for the db interface... I actually _love_ gomega and ginkgo for BDD but it makes people actually angry so I settle for testify and for logging we have slog now but I usually grab the logging lib from charm bracelet for nice colorized, leveled logging. reply onislandtime 44 minutes agorootparentHey, I checked your Reddit thread [1] and I see a good discussion with useful suggestions. I don't see \"anything but hate\" at all. There are pros and cons to using frameworks. True, many people seem to prefer to use smaller libraries. I personally don't like magic because sooner or later I lose track of what's going on and need to start guessing. With direct code I can understand faster without having to read docs and layers of source code. It's all about finding the right balance of abstractions. 1 - https://www.reddit.com/r/golang/comments/1anmoqg/what_go_lib... reply pepelotas 41 minutes agorootparentprevI liked gomega and ginkgo when I worked with it. But by virtue of running tests serially, the race detection becomes useless during testing, and I think it's a must have. Has it changed? reply cgg1 47 minutes agorootparentprevThe best thing I’ve found is beego: https://github.com/beego/beego Not affiliated in any way, but to me it’s better than most of the alternatives reply joshlemer 1 hour agorootparentprevAnd since it isn't a \"framework\" but rather just a wired up collection of libraries, it would be pretty simple and even a good learning process to change out the couple of libraries one doesn't like (say, in case they prefer not to use ent, and backlite). reply DarkCrusader2 1 hour agorootparentprevI had this exact same experience with Go. I picked up .Net (and Asp.Net for web stuff) on linux recently and found it to be much more easier to get started batteries included than Go. Don't need external libraries for any of the things you mentioned (ORM, logging, metrics, DI etc.). Razor pages are very interesting as well. I haven't used them enough to have a solid opinion yet but I really liked them for quick server rendered pages. reply aczerepinski 1 hour agoparentprevIt’s why I moved my personal site from Phoenix to Go and it has proven to he a great choice. I have zero dependencies so they never go out of date. reply ocdtrekkie 46 minutes agoparentprevThis used to be true of PHP as well, though them finally picking off the hairy bits of bad assumptions has eroded that a fair bit. For a long time you didn't usually need to concern yourself what version of PHP 4-5 or so what version you were running on. reply gwd 1 hour agoprev> I learned the hard way that if I don’t do this then I’ll get SQLITE_BUSY errors from two threads trying to write to the db at the same time. OK, here's a potentially controversial opinion from someone coming into the web + DB field from writing operating systems: 1. Database transactions are designed to fail Therefore 2. All database transactions should done in a transaction loop Basically something like this: https://gitlab.com/martyros/sqlutil/-/blob/master/txutil/txu... That loop function should really have a Context so it can be cancelled; that's future work. But the idea stands -- it should be considered normal for transactions to fail, so you should always have a retry loop around them. reply tedunangst 36 minutes agoparentYou'll just end up looping until your retry limit is reached. SQLite just isn't very good at upgrading read locks to write locks, so the appropriate fix really is to prevent that from happening. reply rad_gruchalski 49 minutes agoparentprevWouldn't you need two contexts? One for retry cancellation, one for underlying resources to be passed on to? reply returningfory2 1 hour agoparentprevI don't think this controversial. Retrying failed transactions is a common strategy. reply gwd 1 hour agorootparentYou're the first person I've heard say so. When I was learning DB stuff, there were loads of examples of things that looked at the error from a transaction. Not a single one of them then retried the transaction as a result. The OP's comment is a symptom of this -- they did some writes or some transactions and were getting failures, which means they weren't retrying their transactions. And then when they searched to solve the problem, the advice they received wasn't \"oh, you should be retrying your transactions\" -- rather, it was some complicated technical thing to avoid the problem by preventing concurrent writes. reply returningfory2 0 minutes agorootparentAh, interesting. Maybe my experience has been unusual then. I agree with you the retrying transactions is relatively simple and powerful. yegle 1 hour agoprevIt's sad https://pkg.go.dev/embed was not mentioned in a post about web development in Go :-) Having a true single binary bundling your static resources is so convenient. reply dullcrisp 9 minutes agoparentIt is mentioned now. reply okibry 1 hour agoparentprevWhich time golang read file, build time or run time ? reply nasretdinov 1 hour agorootparentembed package allows to embed assets directly into the binary, so the files are read once during build time and then you can access them as e.g. a byte slice, a string, or a special FS object that acts like an in-memory file system reply estebarb 1 hour agorootparentprevBuild time. It literally embeeds the file in the binary. reply catlifeonmars 1 hour agorootparentprevBuild time reply srameshc 2 hours agoprevGood to see author's mention about routing. I am mentally stuck with mux for a long time and didn't pay attention to the new release features. Happy that I always find things like these on HN. reply JodieBenitez 2 hours agoparentNice new feature, would actually make me want to use Go without Gin. reply leetrout 1 hour agorootparentI am over Gin and have been for years yet everyone keeps using it because it has inertia. The docs are garbage. Big fan of Echo and it has much better docs. https://echo.labstack.com/ reply JodieBenitez 9 minutes agorootparentThanks for the suggestion, will give it a try. I'm more familiar with Python than Go. I know my way around the Python ecosystem and can make informed decisions about which tool to use. Not so much with Go, so I appreciate your advice. reply xerox13ster 32 minutes agorootparentprevI had to move from Gin to echo for my personal site, the routing in Gin was refusing to serve static resources at the root path without some headache. reply imiric 1 hour agoprevThere are some good tips here. As for sqlc, I really wanted to like it, but it had some major limitations and minor annoyances last time I tried it a few months ago. You might want to go through its list of issues[1] before adopting it. Things like no support for dynamic queries[2], one-to-many relationships[3], embedded CTEs[4], composite types[5], etc. It might work fine if you only have simple needs, but if you ever want to do something slightly sophisticated, you'll have to fallback to the manual approach. It's partly understandable, though. It cannot realistically support every feature of every DBMS, and it's explicitly not an ORM. But I still decided to stick to the manual approach for everything, instead of wondering whether something is or isn't supported by sqlc. One tip/gotcha I recently ran into: if you run Go within containers, you should set GOMAXPROCS appropriately to avoid CPU throttling. Good explanation here[6], and solution here[7]. [1]: https://github.com/sqlc-dev/sqlc/issues/ [2]: https://github.com/sqlc-dev/sqlc/issues/3414 [3]: https://github.com/sqlc-dev/sqlc/issues/3394 [4]: https://github.com/sqlc-dev/sqlc/issues/3128 [5]: https://github.com/sqlc-dev/sqlc/issues/2760 [6]: https://kanishk.io/posts/cpu-throttling-in-containerized-go-... [7]: https://github.com/uber-go/automaxprocs reply physicles 2 hours agoprevGOMEMLIMIT has really cut down on the amount of time I’ve had to spend worrying about the GC. I’d recommend it. Plus, if you’re using kubernetes or docker, you can automatically set it to the orchestrator-managed memory limit using something like https://github.com/KimMachineGun/automemlimit — no need to add any manual config at all. reply nickzelei 15 minutes agoparentOh this is a good find. Thank you for sharing that link! reply codegeek 2 hours agoprev [–] What I love about Go is its simplicity and no framework dependency. Go is popular because it has no dominating framework. Nothing wrong with frameworks when it fits the use case but I feel that we have become over dependent on framework and Go brings that freshness about just using standard libraries to create something decent with some decent battle tested 3rd party libraries. I personally love \"library over framework\" mindset and I found Go to do that best. Also, whether you want to build a web app or cli tool, Go wins there (for me at least). And I work a lot with PHP and .NET as well and love all 3 overall. Not to mention how easy was it for someone like me who never wrote Go before to get up and running with it quickly. Oh did I mention that I personally love the explicit error handling which gets a lot of hate (Never understood why). I can do if err != nil all day. A big Go fan. reply jeffreyrogers 2 hours agoparent [–] I like Go for this reason as well. In Python I found the Flask framework to be suitably unobtrusive enough to be nice to use (never liked Django), but deploying python is a hassle. Go is much better in that area. The error handling never bothered me either. I think if Go shipped better support for auth/sessions in the standard library more people would use it. Having to write that code yourself (actually not very hard, but intimidating if you've never done it before) deters people and ironically the ease of creating Go packages makes it unclear which you should use if you're not going to implement it yourself. reply atomicnumber3 2 hours agorootparentMy main gripe about go is that it's decent for the middle and late stages and really really bad to start with. You'll spend way too much time rewriting stuff you literally get for free by running \"rails new\" or \"bundle add devise\" reply vasilzhigilei 2 hours agorootparentI love using Go for personal projects, but I keep finding myself recreating the same redis-based session storage logic, authentication, admin vs public routes, etc. Really does burn time in the beginning, even though it's fun to write the code. reply tizzy 1 hour agorootparentThere is definitely space for an opinionated set of libraries and boiler plate code for golang projects like this. Having said that, I’d bet that the go community consensus is that you build one out yourself and reuse it. So most times I end up copy and pasting the same logic rather than recreating. reply legorobot 59 minutes agorootparent100% this. I have a set of commonly-used code in a repository we use at work. AuthuthZ, code specific to our infrastructure/architecture, common http middlewares, error types, DB wrapper, API clients, OpenAPI Server generation, etc. However, my personal projects have a different set of code I reuse (more CLI- and tool-heavy focus), and I'm sure other environments would have an entirely different set of reused code. On the opinionated library side of things, I did follow LiveBud for a while, and Go-Micro but haven't really sat well with the experiences from those, given how they lock you in to different aspects of your stack. reply leetrout 1 hour agorootparentprevI am a Django apologist because I grew up with Django. So with that being said, I'm not out to convert you but I am genuinely curious what you don't like about it. Promise I won't refute anything I just like to try to understand where it turned off folks. I don't like flask because it seems just easy enough to be really productive in the beginning but you eventually need most of the things Django gives you. So I would rather pick up Django Rest Framework or Django Ninja than Flask or Fast API. In those cases I jump straight to Go and use it instead because the same library decisions on the Go side give me a lot more lift on the operations end (easy to deploy, predictable performance into thousands of requests per second if built correctly). reply jeffreyrogers 1 hour agorootparentIt's opinionated in a way I dislike. I don't actually have anything against opinionated software--tailwind is very opinionated about how you should write CSS but I like it because it matches up with how my mind works. But I find Django very jarring. I can't point to a specific thing about Django, it's more that if I were to design a framework from scratch it would look nothing like Django, so I experience a lot of friction trying to shape my ideas about how to build an application into Django's way of doing it. I have the same problem with Rails as well. I agree with you that Django provides most things that an application will eventually need, and if I were managing a team that was starting a project from scratch I think Django would be a reasonable choice, but aesthetically something about it irritates me. reply jpc0 1 hour agorootparentprevI have to learn an entite framework and if I want to stray away from what it wants the magic makes it hard. For one, I so migrations with raw SQL onto the server, I just don't trust it any other way and I dislike ORMs, I even dislike query builders. But for a big framework like Django you can't remove those batteries easily and you have already strayed away from the narrow paved road. If I'm spinning up an API endpoint for my existing stack, I'm picking flask ( well no I'm picking go because WSGI is a pain in the... to deploy ) purely because I don't need auth + rate limiting + an orm and all that. I need endpoints exposed to do what I need, literally the rest is already handled by my API gateway and it will be tied into our existing management dashboard. Django may be great to spin up a quick project but I found I needed to stary for the paved road pretty quickly so I rather picked a different tool... This doesn't apply to everybody either, for aome Django is the correct solution. reply kolja005 1 hour agorootparentprevI'm curious in what sense you find Python difficult to deploy? My company has tons of Python APIs internally and we never have much trouble with them. They are all pretty lightly used services so it it something about doing it on a larger scale? reply codegeek 1 hour agorootparentprev [–] Some great points about the downsides of Go. Btw I was a Flask junkie in early days. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Go 1.22 introduces improved routing support in the standard library, simplifying route handling and enhancing security with middleware.",
      "sqlc tool generates Go code from SQL queries, reducing boilerplate and streamlining database interactions.",
      "Setting a GC memory limit in Go 1.19 helps prevent out-of-memory (OOM) kills in low-memory environments, enhancing application stability."
    ],
    "commentSummary": [
      "Go's simplicity and stability are appreciated by developers, making it easy to resume projects after long breaks.",
      "Initial setup can be challenging due to the need to select various libraries for logging, database drivers, etc.",
      "The lack of a dominant framework in Go is seen as both a limitation and a benefit, offering flexibility with standard libraries."
    ],
    "points": 159,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1727620583
  },
  {
    "id": 41683815,
    "title": "Notes on the Crystal Language",
    "originLink": "https://wiki.alopex.li/CrystalNotes",
    "originBody": "Login / Get an account Logout view edit history discuss CrystalNotes First impressions Object stuff Type system stuff Stdlib stuff Other random bits Things to look at later Conclusions A friend talked me into trying out the Crystal programming language, and then another friend talked me into starting a little project that Crystal would be good for, so here’s the traditional rambling thoughts on it. Written in September 2024, using Crystal 1.13. Also note that I’ve used almost no statically-typed language besides Rust for like 8 years, so I am very Rust-brained these days. First impressions Language started in 2014 Overarching idea: Strongly-typed Ruby (with lots of type inference) This means Everything Is An Object, which always feels wrong to me these days, but like Ruby it’s a fairly good implementation of the idea. You can have standalone functions and whatever and it works fine. Programs are just compiled to native executables through LLVM. Compilation isn’t instant, but it’s Fast Enough for me so far. No repl that I’ve found, but also no main() function, writing bare statements in a toplevel file executes them from start to end. Sounds like a potential liability to me, with order of file imports changing side effects, but it sure is convenient to learn with. The tutorial also has editable and executable online code blocks, which is an excellent way to play around Has a good range of useful-but-less-common built-in types like sets, symbols/atoms, tuples and closures, so the creator is no fool Reasonably modern package/build manager: shards. Uses yaml for the file format unfortunately, but oh well. Decent project-blessed Debian packages and the usual (bad) curl ...sudo sh style install script, which I eyeballed and is not at this time a rootkit. Its .deb is hosted on opensuse.org, which feels weird; someday I should actually learn anything about SuSE besides “RPM based, I tried it in 2005 and it didn’t work well on my PC at the time” Tutorial is really minimal, be prepared to just read through the reference once you get through the bare essentials The reference is pretty good though Where the hell are for loops??? Oh they don’t exist, you use 10.each do |x| ... end like Ruby. Sure, why not. Reasonable ecosystem of libs, seemingly mostly decentralized like Go but shards has at least the framework for different package sources, so if someone makes a centralized Crystal package lib and it gets popular it can just be added as another option. Standard lib is more of the maximalist style, has a bunch of handy script-y things in it. Compiles to static-ish binaries with LLVM. So it’s not a scripting language per se, but… scripting-language-coded, I suppose. Was sold to me as having very good FFI and macro metaprogramming, which sounds useful. Object stuff It splits apart new to allocate memory and initialize to initialize it like Objective C does, which is always nice to see. Usually unnecessary, but nice to see. Class variables are all private, everything is done through accessors. There’s freely-available overloads for operators like =[] for x[y] = z, and more shortcuts (which turn out to be macros) for defining accessors. Does the Ruby annotation thing where foo is local var, @foo is instance var, @@foo is class var, which feels weird but after using it for a while I actually kinda like it. Oooooh all constants start with capital letters… and all types/classes start with capital letters… so all types are constants at runtime. Classy. …No, not that kind of class-y. Dammit that wasn’t supposed to be a pun! Go away! Structs are value-typed classes, like in C#. IMO this is a worse design than just having explicit references, but fine for 2014 when the language was created. There’s a feature called “splat assignment” which just seems like weaksauce pattern matching. Looks useful, but why not just have pattern matching? Splat assignment probably evolved out of Python’s * function argument swizzling operators. Has some nice shortcut syntax for designing your own collections types, so {1 => :foo, 2 => :bar} makes the builtin Hash type, but you can write MyType{1 => :foo, 2 => :bar} and it will desugar to MyType.new(); MyType[1] = :foo; MyType[2] = :bar; Feels a bit like C# there, nice option to have. Type system stuff You (almost) never need to add type annotations to vars and function args/returns to make the program typecheck, but you always have the option to add them so it typechecks the way you want,, which is good It looks like it does some form of global type inference, which sounds somewhat ad-hoc compared to OCaml-y HM but seems to work fine in practice (so far). The type inference allows unions of types like Typescript does, such as IntString. Variables are declared by being assigned to, which to me feels a little unnecessarily sloppy but usually works okay in practice. The @ sigils help a bit. Variables can be reassigned with a value of a different type, which is a little bold. So you can do a = 3; a = \"hi\" and it works. Not sure yet how hazardous this is in practice. I assume it types a as Int32String in that case? Yep; if you declare the type of a variable a : Int32 = 3; a = \"hi\" then it complains that the type of a is Int32 but you’re trying to use it as if it were Int32String. Writing a : Int32String = 3; a = \"hi\" works just fine. This is also how uninitialized variables work. Uninitialized vars have type Nil, which has only one value nil, which then interacts with other types like normal. So an uninitialized variable that is later set to a String has type NilString. So if you don’t want this to happen, you can always just give a variable a type. And if you don’t do that, but screw something up, it will get caught next time that variable is used with a function that has typed args. That feels very much like Typescript’s type system. Now, TS is a little infamously unsound, which means you can write contradictions in it; invalid programs can typecheck successfully. In practice this is seldom too much of a problem in TS, afaik, but definitely can fuck you up sometimes. I have no idea whether Crystal is unsound or not, since its logic around types and objects and stuff seems different from TS’s approach, which is shaped by needing to interoperate with the abject sadness that is JS. Would be interesting to learn more about it! In general subtyping (such as OO inheritance) and union types (like IntString) are places where type systems get Hard, and are areas of active research. So having Crystal wandering around this design space is pretty neat from a language creator’s point of view. There are also real generics, haven’t touched them much yet but they seem to do the job? There’s the usual zoo of OO features like private/protected methods, covariance and contravariance, virtual and abstract types, etc. I’m happy to ignore them when possible. Stdlib stuff Woohoo, batteries! Fun change from Rust. There’s hash functions in there! JSON parser/writer! A smol HTTP server! Bignums! Tempfiles! Oops, looks like its tempfile lib is written in library code in the style of mktemp(3), instead of calling the OS’s mkstemp(3) or equivalent. So it just finds a filename that doesn’t exist and then opens it separately, letting an attacker create a new file which they can read at that location between those two steps. Uh, have fun with your temporary files leading to exploitable race conditions guys. Digging through the Crystal issue tracker for this problem shows multiple attempts to try to make this better done at different times by different people, none of which seem to have been Good Enough. It’s a pretty good example of the downsides of a batteries-included library, tbh. Trying not to break shit is hard work. The stdlib’s OptionParser is hella better than a C/bash argparse-like API but it could be better still. I wish it were more declarative and a little more opinionated, like Rust’s clap or argh. Oh I take it back, there’s no way I can find to just tell OptionParser “this command line flag is necessary”. WTF? It’s basically “wire your own state machine” like Python’s lame-ass argparse. Maybe I should write a new command line parser lib. Oh, there’s already a bunch already written. A disadvantage of Crystal’s Go-style package management where everything is in its own repo, vs. Rust-style where there’s a blessed crates.io or equivalent: it’s hard to know where to go to find packages. There appears to be a decent (if commercial) curated list at https://crystal.libhunt.com/. commander and admiral seem close to what I want, though there’s plenty of others. Annoying as this is, I love that there’s a good language out there that makes decisions different from my habitual Rust/Python/Elixir ecosystem. Tradeoffs are worth exploring. Okay I hate writing this ’cause I’ve been having fun up until now, but the stdlib honestly needs some help. I had this code: testdir = Dir.new(testdir_path) LANGUAGES.each do |name, lang| Dir.cd(testdir_path) # Iterate through subdirs testdir.each_child do |subdir| puts \"Processing stuff in #{subdir}\" do_stuff(testdir_path / subdir) end end First off, Dir#each_child() returns a String, not a Path or a Dir or File object. Okay fine, paths are fucking cursed no matter what. But it turns out that the Dir object is an iterator, instead of what I expected, which was Dir#each_child creating an iterator. So for the first run of the outer loop it would iterate through the subdirectories of testdir_path, and do_stuff() in each one. Then for the next run of the outer loop it calls testdir.each_child() again… which is already at the end of the iterator, so it just bloody runs zero times. Want to iterate through the directory again? Gotta call testdir.rewind() first. Is this in the docs? Only if you look at the rewind() method and understand that this is a possibility; otherwise you just gotta figure it out the hard way like I did. Apparently this (like a lot of the rest of the Crystal stdlib) is inherited from Ruby, but that doesn’t mean it’s a good idea. THIS is why you need an immutable-first language with move semantics and borrowing, dammit! People ask me what Rust is good for if you are happy to have a GC? Shit like this, that’s what. Fine, Crystal isn’t that language, but still. But for as good as Crystal itself is, it deserves to have the stdlib that doesn’t result in me tripping across three separate footguns while writing what is, in the end, a 300-line “I didn’t want to write a shell script” program. That’s not great. Asking a good lang designer to also be a good stdlib designer is a pretty tall order, but fortunately lib improvements are the sort of work that can be done by a community more easily than core lang design. Someone with intimate knowledge of the Rust stdlib and all the horrible footguns its incredibly labyrinthine design tries to avoid, and the intestinal fortitude to rewrite major parts of a stdlib, please help Crystal out. Other random bits You can make functions with named args and call them like some_method 10, w: 1, y: 2, z: 3. Heh, more Objective C lineage – I don’t think Ruby does that? Oops it does; I think I last touched Ruby in like 2012. Either way, classy. Feels like how Elixir writes DSL’s out of functions, but in a good way. Probably not a coincidence, since they’re both Ruby-ish syntax. Yep, you can use the “splat operator” in function args and it’s exactly like Python’s arg swizzle operators. Always a nice feature for a dynamic-ish language, and one of the fun things that is just really fucking annoying to do sensibly in a For Realsies Static language like Rust. Even when it’s statically typed and compiled to native code, being able to have the language say “yeah we just use lots of dynamic dispatch and/or reflection here, it’s fine” is pretty convenient at times. Oh shit, there’s no sum types! Heck, no wonder this feels weird to write in. There’s enums, which is nice, but they are very explicitly limited to integers and intended for flags and stuff. If you really wanted Rust-style sum types you could fake them easily enough, but that always Feels Bad. No real pattern matching either, so you it’s more annoying to use the “tuple of symbol + value” style of sum types that’s ubiquitous in Elixir or Erlang. Modules are first-class values, huh. And have some relation to classes. Again I am reminded of one of my more mind-bending moments while learning Ruby, which was reading something along the lines of “the Module class of Module is a subclass of the Class class of Class.” Good times. The crystal binary comes with some handy tools built in, with the command crystal tool. There’s fairly mundane things like a formatter and a macro-expander, and also slightly more uncommon but interesting bits like something that prints out the full class tree for a program, or shows the implementations possible for an overloaded method call. The require file import statement is mostly file-based, vs Rust or Elixir’s more abstract module tree knowing where it expects to find files. There’s still some default search paths that result in a particular file layout in a multi-file project, but it seems to be more of a suggestion than a rule. Files also all share the same namespace by default, if you want nested namespaces you just make the file foo/bar.cr contain your code inside module Foo::Bar ... end . Feels a little oldschool compared to more abstract systems, like the concept is “C includes done properly”, but it seems to work fine. Meshes decently with the scripting-language vibe, you can just kinda throw files together if you want to. There’s some auto-casting of numerical types, but it’s very conservative compared to say C or Python 2. It only can occur in function args or class initialization as well, which is an interesting choice. Error handling is fairly mundane exceptions, so far. Crystal’s tools for dealing with Nil are kinda interesting. The type String? is a shortcut for StringNil. Nil is falsey, but has a little syntactic sugar to it: if you have a value x of type String? you can write if x do_stuff_with(x) end and the x inside the if block is of type String. It’s smart enough to do the opposite too; if you write if !x do_stuff(x) else do_other_stuff(x) end then inside the “if” part x is type Nil, and inside the “else” part x is type String. So I guess it’s a case/pattern match on the type, really, but a very handy one. Very alien to my brain used to Rust’s Option’s; Crystal once again does something that feels like how you’d write stuff in a dynamic language, but makes it type safe. The shortcuts for properties in class constructors are very convenient. Rust could learn some things there, tbh. Things to look at later Reflection FFI Error handling Macros Generics (in more depth) Can you magically return/break out of iterator functions like you can in Ruby? Threads/fibers? Conclusions I still think the world really needs a solid, immutable-first and functional-first scripting/glue language, and Crystal isn’t that. But it is a solid, well-considered OO language with a static type system that feels as low-friction as a dynamic one. So give Crystal a go next time you’re sick of writing your bajillion’th Python/Ruby/JS script. It steals lots of stuff from Ruby, but the stuff it adds is very solid so far. writing programming languages powered by gitit Site Front page All pages Categories Random page Recent activity Upload a file Help This page Raw page source Printable version Delete this page",
    "commentLink": "https://news.ycombinator.com/item?id=41683815",
    "commentBody": "Notes on the Crystal Language (alopex.li)149 points by todsacerdoti 18 hours agohidepastfavorite50 comments hi-v-rocknroll 6 minutes agoI've tried Crystal half a dozen times but always ran into some inconsistency or bug that became a show-stopper. Sigh. I hope maybe the next time it will be reliable and usable. reply giovannibonetti 7 hours agoprev> I still think the world really needs a solid, immutable-first and functional-first scripting/glue language, and Crystal isn’t that. The author might be interested in Roc [1] by Richard Feldman et al, which seems to check all the boxes, including scripting with type inference and glue with good FFI to other languages. It is still in early stage, though, since it is a very ambitious project. [1] https://www.roc-lang.org/ reply bandauo 5 hours agoparentIt seems that Clojure ticks all this boxes reply tomtheelder 5 hours agorootparentJVM is a hard dealbreaker for a scripting/glue language. reply lolinder 5 hours agorootparentprevThe JVM is a pretty heavy dependency for scripting/glue, if just for startup times. reply vfclists 4 hours agorootparentBabashka it when its done if it depends on libraries not in Babashka? reply rscho 3 hours agorootparentprev... or most Schemes/Racket reply compumike 4 hours agoprevWe use Crystal extensively at https://heiioncall.com/ for the high-performance stuff, and it’s terrific. :) As the author notes: the typing system is very pleasant. And the standard library is great! Generics work fine. The testing story is very good (almost as good as rspec). Have some experience with the Threads but won’t comment extensively as that’s about to get some big changes in the next minor release or two. Overall: highly productive for high-performance backend API servers and background task daemons. Way more fast and pleasant to write than Rust or Go (IMHO). reply steve_adams_86 12 hours agoprevI got to work on a crystal project years ago and loved it. I was exposed to a bunch of people who were really into crystal and it made me come to the completely incorrect conclusion that crystal was up and coming and I’d be able to find more work using it. I was wrong. I’ve never encountered it again. It was a great language, super productive. I helped some people develop a pet insurance service. So weird. I’d work with crystal again for sure. reply cogman10 7 hours agoparentI loved writing straight Ruby. It is by far my favorite scripting language. It makes me sad that Ruby on rails was the one big thing done in Ruby and that that gave it somewhat of a bad rap. reply michaelteter 5 hours agorootparentWere it not for Rails, most people wouldn't have heard of Ruby. It is unfortunate that Ruby doesn't get more general computing use, but Rails is really just the tip of the iceberg in a big project that uses Ruby. (You still get to do a lot of nice work that isn't Rails specific, at least if you structure your system well.) reply jaynetics 12 hours agoparentprevDid you have to work around some rough edges of the language in that job? To me it feels like it never quite reached maturity, although in a better world it would have gotten more support and conquered all territory that is now ruled by the Gophers. I guess to make a successful programming language, you either need corporate backing or extend an existing one nowadays, otherwise it's really hard to build a stdlib of modern proportions. reply bhaney 15 hours agoprev> Can you magically return/break out of iterator functions like you can in Ruby? Sure can. $ cat break.cr (1..).each do |x| break if x > 2 puts x end $ crystal break.cr 1 2 $ The answer to Crystal questions that end in \"like you can in Ruby\" is usually \"yes.\" The language really is just Ruby with static typing, warts and all. Most random snippets of Ruby will run just fine when compiled as Crystal. reply woodruffw 13 hours agoparentI agree this is weird, but I think it's largely an analogy issue: Ruby and Crystal both explicitly document blocks as not being closures, even when they can be converted into closures. They're their own weird thing. Crystal also documents that it will fail if the block contains return or break statements[1]. [1]: https://crystal-lang.org/reference/1.13/syntax_and_semantics... reply straight-shoota 9 hours agorootparentI'm a core developer of Crystal. Note that there are two different flavours of blocks in Crystal: inlined and captured ones. `return` and `break` are supported in inlined blocks. reply ljm 5 hours agoprevThe bit about iterating over a directory struck me as a bit of a misunderstanding and therefore the rant following it seemed a bit misplaced. The code example makes no sense at all, so you can’t really make sense of the argument being made. Without that, it just looks like the author has an insatiable love affair with rust and their arguments lose credibility. Of course if they’re trying to smash Rust semantics into any other language they’re going to be disappointed. reply hydrolox 14 hours agoprevnothing against the language but it's a bit suspicious that the top sponsors include \"buy Google reviews\" and \"buy Instagram followers\" (if you navigate to the actual Crystal language site) reply __jonas 8 hours agoparentI've come across some legitimate open source projects where all the listed sponsors are dodgy gambling sites, I doubt they actually use the tech, it's just a way to get relatively cheap backlinks from a legitimate website. Not sure what you're supposed to do as the project maintainer, might also be a bit strange to selectively only display some sponsors that you think are \"trustworthy\"? reply lolinder 5 hours agorootparentI know it's easy to say from the outside, but a project is under no obligation to accept a sketchy sponsor. If someone offered money to post a link to something obviously illegal, it would be illegal to accept that deal. If they offer money to post a link to something dubiously legal, it is likewise dubious to accept that deal. That they're starving open source developers doesn't remove the obligation to vet their sponsors before posting their links. reply Lerc 12 hours agoparentprevThat's a bit of an indictment on how poorly projects are supported. If those sponsors feel like the eyeballs they get from supporting this project is worth it, probably at least some of the owners of those eyeballs are getting enough value from the project to overbid. Is it an artifact of the Individual/Organisation split of OpenCollective? I see the top 10 individuals that have put in $1000 or more. reply bhaney 14 hours agoparentprevThat's an interesting form of guerrilla advertising. Find a project with decent website traffic that displays sponsors, and commit just enough to be displayed in the list of top contributors (which includes some delicious SEO-friendly backlinking juice too). $750/mo and it's already getting the companies mentioned in the currently-top comment of a thread on the front page of HN! reply mdasen 13 hours agorootparentI'm not sure there's a lot of SEO-friendly back linking juice. They're marked as rel=\"nofollow sponsored\" reply dunefox 8 hours agoparentprevIn my opinion, if it gets interesting projects funded I'm all for it. Otherwise, who knows if this language might get the support to thrive. reply graypegg 14 hours agoparentprevOh... and only for 750$ a month. The other sponsors pay more, but have to appear alongside those. reply Lerc 13 hours agoprevWhat's the performance like? The comment at the end OO language with a static type system that feels as low-friction as a dynamic one Sounds nice, but does the performance act like a dynamic language or is it super speedy? I'd be happy with half the speed of C. I'm still on the lookout for a language that feels as low-friction as a dynamic language but could do some form of iterable.map in parallel on all cores transparently. There's a blog post on paralellism in Crystal https://crystal-lang.org/2019/09/06/parallelism-in-crystal/ but that's a fair few years ago now. reply straight-shoota 9 hours agoparentI'm a core developer of Crystal. Crystal's dynamic nature is only in the source code. It generates highly optimized code thanks to LLVM codegen. So performance is generally comparable to other compiled languages like Go, Rust or C. Of course there are differences depending on specific use cases. A workload with lots of memory allocations means a high workload for GC which could be less efficient than an implementation that uses no garbage collection. But even that depends. reply viraptor 11 hours agoparentprev10x compared to Ruby for my use cases. reply diggan 9 hours agoparentprev> I'm still on the lookout for a language that feels as low-friction as a dynamic language but could do some form of iterable.map in parallel on all cores transparently. If you can get past the typical \"ew parenthesis instead of curly-brackets\" and prefix/Polish notation, Clojure is great for this. You'd normally do `(map a-func my-elements)` but if you want the map processing to be parallel, you'd change `map` to `pmap` without any other changes needed. reply samatman 1 hour agoparentprevIt's possible that the language you're looking for is Julia. https://docs.julialang.org/en/v1/manual/parallel-computing/ I know almost nothing about Crystal, so I can't make a fair comparison between them. Julia is used in scientific computing, where parallel clustered processing is essential. I don't like subthreads which hijack a Language A post to talk about Language B, so I'll resist making an elaborate pitch, but Julia does fit the bill for what you're on the lookout for. reply transfire 12 hours agoparentprevSuper speedy. It is in fact about half the speed of C. It has a GC so that’s probably the main slow down, but hey, no memory errors or raking your brain over a barrow checker. reply anotherhue 11 hours agorootparentThe GC in particular is excessively slow. It's not a production implementation. I don't need JVM level GC engineering everywhere but it really is painful. https://en.m.wikipedia.org/wiki/Boehm_garbage_collector reply viraptor 11 hours agorootparentWhat use cases do you see that in? And do you mean throughput or latency is slow? reply anotherhue 11 hours agorootparentWeb server with DB backend. Pause times can exceed 2000ms. No doubt some code changes could help but the fact remains the GC is not an optimised one. reply straight-shoota 9 hours agorootparentI'm a core developer of Crystal. Looks like something went very wrong there. The GC may not be super optimised, but it's still practical. I have never heard about such drastic performance issues. And I'm aware of quite a few companies who use Crystal in heavy production loads for exactly the web server + db use case without such issue reports. So I'd suggest the root cause might be something else then the GC implementation. reply cogman10 7 hours agorootparentWhat is roughly the gc algorithm? reply yxhuvud 6 hours agorootparentIt is using Boehm/libgc. Just a simple webserver should not have the described behavior. The GC is not incremental though, so having a big heap would trigger it. But that is typically not the case for the described use case. Likely the issue is with doing something that involves more allocations than necessary. There are works in libgc to allow incremental collection, but it is not yet ready for the needs of crystal (or at least it wasn't the last time I investigated). reply compumike 3 hours agorootparentprevConceptually, I think the correct time to do garbage collection is when your web server process is idle. My Crystal implementation of idle-time garbage collection is here: https://github.com/compumike/idle-gc though please note that its idle detection mechanism only works for single-threaded Crystal programs. An analogy is to imagine a single employee (thread) operating a convenience store. If there are customers waiting in the checkout line (latency-sensitive requests), the employee should priorities serving the customers ASAP! But once the line is empty (thread is idle), that might be a good time to start sweeping. Right now, with automatic garbage collection, the employee only decides to start sweeping the entire store while in the middle of serving a customer! (Because that's when mallocs are happening, which may trigger automatic GC.) Pretty ridiculous! With idle-time GC, the sweeping happens entirely or mostly while there are no customers waiting. This may not show latency improvements in an artificial benchmark where the system is running flat-out with a full request queue, but in the real world, it changes GC from something that happens 100% of the time in the middle of a request is being served (because that's when mallocs happen and trigger automatic GC), to something that only rarely or never happens while a request is being served. Even better would be to combine idle-time GC with incremental GC, so that the employee could put down the broom when a new customer arrives without finishing sweeping the entire store. :) See also \"Idle Time Garbage Collection Scheduling\" in Google Chrome (2016): PDF at https://static.googleusercontent.com/media/research.google.c... reply nobodywasishere 15 hours agoprevAs far as a REPL for Crystal goes, the interpreter is available via \"crystal i\" reply nobodywasishere 15 hours agoparentAlso for finding shards/libraries/documentation, I'd recommend checking out https://shards.info/, https://shardbox.org/, and https://crystaldoc.info/ reply bingo-bongo 12 hours agorootparentThe awesome crystal repo is also a good: https://github.com/veelenga/awesome-crystal reply sedatk 15 hours agoprev> Oops, looks like its tempfile lib is written in library code in the style of mktemp(3), instead of calling the OS’s mkstemp(3) or equivalent. So it just finds a filename that doesn’t exist and then opens it separately, letting an attacker create a new file which they can read at that location between those two steps. Uh, have fun with your temporary files leading to exploitable race conditions guys. Good catch. The API should be opening the tempfile atomically (the best option), or at least should use a CSPRNG for its random suffix. It doesn’t, currently. reply bhaney 14 hours agoparentI don't think that complaint is even true. A quick glance at the Crystal stdlib source[1] shows that the mktmp implementation uses the O_EXCL mode, which will cause the open call to error out if the file already exists, and the implementation here will handle that and try again with a different filename. I think the worst thing an attacker could do here if they could somehow predict the generated names before the file is created is DoS the mktmp call by racing ahead of it 100 times until it gives up. [1] https://github.com/crystal-lang/crystal/blob/release/1.13/sr... reply sedatk 14 hours agorootparentAlso, good catch! :) reply Trasmatta 15 hours agoprevCrystal is beautiful. I wish I had a use case for it. reply pmontra 12 hours agoparentSeconded. My use case might be running my own Ruby scripts faster, but they don't need to run any faster so it's not worth the trouble of setting up a development environment, especially one that requires a compilation step. It would be a totally different thing if it could run Rails, which is one of the things I do in my job. The speedup would probably justify using it, especially when running tests on my laptop. My customers are perfectly happy with the performance of Rails on their servers. Same with the ones using Python with Django. reply compumike 3 hours agorootparent> It would be a totally different thing if it could run Rails, which is one of the things I do in my job. At https://heiioncall.com/ we combine the two and use Rails for the human-facing parts, and Crystal for the machine-facing parts (inbound API server calls, and outbound HTTP probes). For us, the number of machine-facing requests per second is so many orders of magnitude higher than human-facing requests that Crystal's performance and lower footprint is valuable there. While on the other hand, the conveniences of Ruby on Rails are still great for a conventional human-facing web and mobile application. reply Trasmatta 2 hours agorootparentprevYeah,I've found that for the vast majority of Rails apps, the bottleneck is the database, not Ruby. Even a 100x speed up in the application code would have very little end user impact on performance in most cases. reply squarefoot 11 hours agoparentprevI would see plenty of use cases as a Micropython substitute if at least a subset of it was ported to microcontrollers. reply flats 14 hours agoprevI work with Ruby every day at work & have always been curious about Crystal. This was a very helpful dive into some overarching concepts & small details. Thanks for sharing! reply atemerev 8 hours agoprev [–] “Oh it’s nice but it’s not Rust, why everything can’t be just like Rust” The audacity of Rustaceans is so thick. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Crystal, a language started in 2014, aims to be a strongly-typed Ruby with type inference and compiles to native executables via LLVM.",
      "It features a decentralized ecosystem of libraries, optional type annotations, and a type system similar to TypeScript’s, supporting generics and other object-oriented features.",
      "Despite some issues with tempfile handling and directory iteration, Crystal offers many useful built-in functions and libraries, making it a solid choice for those looking for a dynamic-feeling static type system."
    ],
    "commentSummary": [
      "Crystal language is being discussed for its potential and current limitations, with users sharing mixed experiences regarding its reliability and maturity.",
      "Some users highlight Crystal's high performance and productivity for backend API servers and background tasks, while others point out issues like slow garbage collection (GC) and bugs.",
      "The conversation includes comparisons with other languages like Ruby, Clojure, and Rust, and mentions Crystal's use of LLVM for optimized code generation, making it comparable to Go, Rust, or C in performance."
    ],
    "points": 149,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1727568986
  },
  {
    "id": 41686722,
    "title": "Web components are okay",
    "originLink": "https://nolanlawson.com/2024/09/28/web-components-are-okay/",
    "originBody": "Read the Tea Leaves Software and other dark arts, by Nolan Lawson Home Apps Code Talks About « Improving rendering performance with CSS content-visibility 28 Sep Web components are okay Posted September 28, 2024 by Nolan Lawson in performance, Web, web components. Leave a Comment Every so often, the web development community gets into a tizzy about something, usually web components. I find these fights tiresome, but I also see them as a good opportunity to reach across “the great divide” and try to find common ground rather than another opportunity to dunk on each other. Ryan Carniato started the latest round with “Web Components Are Not the Future”. Cory LaViska followed up with “Web Components Are Not the Future — They’re the Present”. I’m not here to escalate, though – this is a peace mission. I’ve been an avid follower of Ryan Carniato’s work for years. This post and the steady climb of LWC on the js-framework-benchmark demonstrate that I’ve been paying attention to what he has to say, especially about performance and framework design. The guy has single-handedly done more to move the web framework ecosystem forward in the past 5 years than anyone else I can think of. That said, I also heavily work with web components, both on the framework side and as a component author. I’ve participated in the Web Components Community Group and Accessibility Object Model group, and I’ve written extensively on shadow DOM, custom elements, and web component accessibility in this blog. So obviously I’m going to be interested when I see a post from Ryan Carniato on web components. And it’s a thought-provoking post! But I also think he misses the mark on a few things. So let’s dive in: Performance [T]he fundamental problem with Web Components is that they are built on Custom Elements. […] [E]very interface needs to go through the DOM. And of course this has a performance overhead. This is completely true. If your goal is to build the absolute fastest framework you can, then you want to minimize DOM nodes wherever possible. This means that web components are off the table. I fully believe that Ryan knows how to build the fastest possible framework. Again, the results for Solid on the js-framework-benchmark are a testament to this. That said – and I might alienate some of my friends in the web performance community by saying this – performance isn’t everything. There are other tradeoffs in software development, such as maintainability, security, usability, and accessibility. Sometimes these things come into conflict. To make a silly example: I could make DOM rendering slightly faster by never rendering any aria-* attributes. But of course sometimes you have to render aria-* attributes to make your interface accessible, and nobody would argue that a couple milliseconds are worth excluding screen reader users. To make an even sillier example: you can improve performance by using for loops instead of .forEach(). Or using var instead of const/let. Typically, though, these kinds of micro-optimizations are just not worth it. When I see this kind of stuff, I’m reminded of speedrunners trying to shave milliseconds off a 5-minute run of Super Mario Bros using precise inputs and obscure glitches. If that’s your goal, then by all means: backwards long jump across the entire stage instead of just having Mario run forward. I’ll continue to be impressed by what you’re doing, but it’s just not for me. Minimizing the use of DOM nodes is a classic optimization – this is the main idea behind virtualization. That said, sometimes you can get away with simpler approaches, even if it’s not the absolute fastest option. I’d put “components as elements” in the same bucket – yes it’s sub-optimal, but optimal is not always the goal. Similarly, I’ve long argued that it’s fine for custom elements to use different frameworks. Sometimes you just need to gradually migrate from Framework A to Framework B. Or you have to compose some micro-frontends together. Nobody would argue that this is the fastest possible interface, but fine – sometimes tradeoffs have to be made. Having worked for a long time in the web performance space, I find that the lowest-hanging fruit for performance is usually something dumb like layout thrashing, network waterfalls, unnecessary re-renders, etc. Framework authors like myself love to play performance golf with things like the js-framework-benchmark, and it’s a great flex, but it just doesn’t usually matter in the real world. That said, if it does matter to you – if you’re building for resource-constrained environments where every millisecond counts: great! Ditch web components! I will geek out and cheer for every speedrunning record you break. The cost of standards More code to ship and more code to execute to check these edge cases. It’s a hidden tax that impacts everyone. Here’s where I completely get off the train from Ryan’s argument. As a framework author, I just don’t find that it’s that much effort to support web components. Detecting props versus attributes is a simple prop in element check. Outputting web components is indeed painful, but hey – nobody said you have to do it. Vue 2 got by with a standalone web component wrapper library, and Remount exists without any input from the React team. As a framework author, if you want to freeze your thinking in 2011 and code as if nothing new was added to the web platform since then, you absolutely can! And you can still write a great framework! This is the beauty of the web. jQuery v1 is still chugging away on plenty of websites, and in fact it gets faster and faster with every new browser release, since browser perf teams are often targeting whatever patterns web developers used ~5 year ago in an endless cat-and-mouse game. But assuming you don’t want to freeze your brain in amber, then yes: you do need to account for new stuff added to the web platform. But this is also true of things like Symbols, Proxys, Promises, etc. I just see it as part of the job, and I’m not particularly bothered, since I know that whatever I write will still work in 10 years, thanks to the web’s backwards compatibility guarantees. Furthermore, I get the impression that a wide swath of the web development community does not care about web components, does not want to support them, and you probably couldn’t convince them to. And that’s okay! The web is a big tent, and you can build entire UIs based on web components, or with a sprinkling of HTML web components, or with none at all. If you want to declare your framework a “no web components” zone, then you can do that and still get plenty of avid fans. That said, Ryan is right that, by blessing something as “the standard,” it inherently becomes a mental default that needs to be grappled with. Component authors must decide whether their s should work like native s. That’s true, but again, you could say this about a lot of new browser APIs. You have to decide whether IntersectionObserver oris worth it, or whether you’d rather write your own abstraction. That’s fine! At least we have a common point of reference, a shared vocabulary to compare and contrast things. And just because something is a web standard doesn’t mean you have to use it. For the longest time, the classic joke about JavaScript: The Good Parts was how small it is compared to JavaScript: The Definitive Guide. The web is littered with deprecated (but still supported) APIs like document.domain, with, and s. Take it or leave it! Conclusion [I]n a sense there are nothing wrong with Web Components as they are only able to be what they are. It’s the promise that they are something that they aren’t which is so dangerous. Here I totally agree with Ryan. As I’ve said before, web components are bad at a lot of things – Server-Side Rendering, accessibility, even interop in some cases. They’re good at plenty of things, but replacing all JavaScript frameworks is not one of them. Maybe we can check back in 10 years, but for now, there are still cases where React, Solid, Svelte, and friends shine and web components flounder. Ryan is making an eminently reasonable point here, as is the rest of the post, and on its own it’s a good contribution to the discourse. The title is a bit inflammatory, which leads people to wield it as a bludgeon against their perceived enemies on social media (likely without reading the piece), but this is something I blame on social media, not on Ryan. Again, I find these debates a bit tiresome. I think the fundamental issue, as I’ve previously said, is that people are talking past each other because they’re building different things with different constraints. It’s as if a salsa dancer criticized ballet for not being enough like salsa. There is more than one way to dance! From my own personal experience: at Salesforce, we build a client-rendered app, with its own marketplace of components, with strict backwards-compatibility guarantees, where the intended support is measured in years if not decades. Is this you? If not, then maybe you shouldn’t build your entire UI out of web components, with shadow DOM and the whole kit-n-kaboodle. (Or maybe you should! I can’t say!) What I find exciting about the web is the sheer number of people doing so many wild and bizarre things with it. It has everything from games to art projects to enterprise SaaS apps, built with WebGL and Wasm and Service Workers and all sorts of zany things. Every new capability added to the web platform isn’t a limitation on your creativity – it’s an opportunity to express your creativity in ways that nobody imagined before. Web components may not be the future for you – that’s great! I’m excited to see what you build, and I might steal some ideas for my own corner of the web. Related Leave a comment This site uses Akismet to reduce spam. Learn how your comment data is processed. Recent Posts Web components are okay Improving rendering performance with CSS content-visibility The continuing tragedy of emoji on the web Reliable JavaScript benchmarking with Tachometer Is it okay to make connectedCallback async? About Me Hi, I'm Nolan. I'm a web developer living in Seattle and working for Salesforce. Opinions expressed in this blog are mine and frequently wrong. Archives September 2024 (3) August 2024 (1) July 2024 (1) March 2024 (1) January 2024 (1) December 2023 (4) August 2023 (2) January 2023 (2) December 2022 (1) November 2022 (2) October 2022 (2) June 2022 (4) May 2022 (3) April 2022 (1) February 2022 (1) January 2022 (1) December 2021 (3) September 2021 (1) August 2021 (6) February 2021 (2) January 2021 (2) December 2020 (1) July 2020 (1) June 2020 (1) May 2020 (2) February 2020 (1) December 2019 (1) November 2019 (1) September 2019 (1) August 2019 (2) June 2019 (4) May 2019 (3) February 2019 (2) January 2019 (1) November 2018 (1) September 2018 (5) August 2018 (1) May 2018 (1) April 2018 (1) March 2018 (1) January 2018 (1) December 2017 (1) November 2017 (2) October 2017 (1) August 2017 (1) May 2017 (1) March 2017 (1) January 2017 (1) October 2016 (1) August 2016 (1) June 2016 (1) April 2016 (1) February 2016 (2) December 2015 (1) October 2015 (1) September 2015 (1) July 2015 (1) June 2015 (2) October 2014 (1) September 2014 (1) April 2014 (1) March 2014 (1) December 2013 (2) November 2013 (3) August 2013 (1) May 2013 (3) January 2013 (1) December 2012 (1) November 2012 (1) October 2012 (1) September 2012 (3) June 2012 (2) March 2012 (3) February 2012 (1) January 2012 (1) November 2011 (1) August 2011 (1) July 2011 (1) June 2011 (3) May 2011 (2) April 2011 (4) March 2011 (1) Tags accessibility alogcat android android market apple app tracker blobs boost bootstrap browsers bug reports catlog chord reader code contacts continuous integration copyright couch apps couchdb couchdroid developers development emoji grails html5 indexeddb information retrieval japanese name converter javascript jenkins keepscore listview localstorage logcat logviewer lucene nginx nlp node nodejs npm offline-first open source passwords performance pinafore pokedroid pouchdb pouchdroid query expansion relatedness calculator relatedness coefficient s3 safari satire sectioned listview security semver shadow dom social media socket.io software development solr spas supersaiyanscrollview synonyms twitter ui design ultimate crossword w3c webapp webapps web platform web sockets websql Links Mastodon GitHub npm Blog at WordPress.com.",
    "commentLink": "https://news.ycombinator.com/item?id=41686722",
    "commentBody": "Web components are okay (nolanlawson.com)147 points by keybits 7 hours agohidepastfavorite157 comments jeswin 5 hours agoI tried to understand the referenced article \"Web Components Are Not the Future\" - but found that there weren't many convincing arguments. The current state of Front-end frameworks is an absolute mess. Speaking for myself, I don't want to learn a complex framework. I don't want to learn magic that I don't understand without reading the documentation (useState, createSignal et al). Magic in frameworks is often a hack, unlike magic in libraries. The first library I used was Prototype. It felt like magic, and it truly was. And so was jQuery, and Backbone. I never had to guess what \"useState\" does behind the scenes. There are many things which don't carry over into Web Components from current JS frameworks. But if you start from Web Components (ignoring everything you know about frameworks), it suddenly becomes intuitive. And it brings in abilities which are missing otherwise, such as isolation via Shadow DOM. It grows on you. In my view the only thing we should retain from the React era is JSX (for many reasons, true type-safety, autocomplete etc). I wrote a library last week for using Web Components with JSX. No magic other than JSX. https://webjsx.org reply crabmusket 4 hours agoparent> I don't want to learn a complex framework. I don't want to learn magic that I don't understand without reading the documentation (useState, createSignal et al). I can't really parse this sentence. It seems to have a lot of ideas in it. Do you want to learn a framework at all, or have one that is so magical that it feels like it doesn't need to be learned? Do you want to read documentation or not? Do you think the problem with React is that its primitives are unsuited to the work you do in it? Or to the work anybody needs to do? I've spent most of my professional career in Vue, so I don't have a great perspective on the React ecosystem. But Vue feels like it must be included in your \"complex framework\" statement. I've definitely felt some pain from overuse of the framework, or poor understanding of various features, libraries, etc. The ecosystem around full-on SPAs is indeed complex. I'm just not sure what other systems would let me personally, and us broadly, manage a complex stateful client-side app. (This is entirely separate to overuse of SPAs for things that shouldn't be SPAs.) reply eddd-ddde 2 hours agorootparentI think the point is that frameworks ' magic isn't 100% there yet. You eventually HAVE to dive deep and understand things about the implementation to understand how to use it. reply szundi 3 hours agorootparentprevI think he was pretty clear that the \"magic\" in frameworks is not something you can easily understand, therefore have to guess how it really works. He doesn't like that. reply jsyang00 4 hours agoparentprevYou do not need to know how `useState` works to understand how to use it to write a React application, it is fairly intuitive to understand how to apply the pattern. If I look at your library, it seems to me like it requires a much more complex mental model to begin to use. Of course, it is better in theory for a developer to thoroughly understand the details of their framework, but empirically, React has been very successful in allowing people to build relatively sophisticated applications while understanding very little of the underlying model. reply InsideOutSanta 3 hours agorootparent\"You do not need to know how `useState` works\" I feel like you eventually do. The issue with React, at least in my experience, is that it's a type of abstraction that seems ill-suited for how the web works under the hood, so it's incredibly leaky. Everything seems to make sense initially, and you get along just fine, but then you run into an edge case, and there's an official workaround for the edge case, but then you run into edge cases for the workaround for the edge case, and suddenly, that's your whole life. Before you know it, you really do have to know how things actually work under the hood. reply djbusby 49 minutes agorootparentSeems like that happens with every frameworks I've ever used since 2000 (in Perl, PHP, Ruby, JS, etc). Every framework makes the easy things slightly easier, the boring stuff is included and you get to focus on the fun/hard part - and I think then, naturally, you bump into the edge. But! You get to that point faster. And then you have to know the guts to solve the issue the \"framework\" way or do some lower-level shit-hack. I feel like it's just a natural law of any general purpose framework. It made the first 80% of the job easy. Now you just have to finish the other 80%. reply recursive 1 hour agorootparentprevThis hasn't been my experience at all. The implementation details even leak into this crazy thing called \"the rules of hooks\". It looks like a function but it's actually this new thing called a hook. Which state will you get? That depends on whether the reconciler considers this invocation to be a mount or update. Getting the wrong one? Try restructuring your elements or adding or removing a \"key\" attribute. People tolerate this because they learned it but I don't think there is anything essentially simple about it. reply jeswin 2 hours agorootparentprev> If I look at your library, it seems to me like it requires a much more complex mental model to begin to use. How so? It has two functions: (1) createElement(jsx): Allows you to use JSX to write HTML markup. Returns Virtual Nodes. (2) applyDiff(parent, vNodes): Merges Virtual Nodes created with JSX into the real DOM efficiently. This is all you need to know. I can keep it simple because I am not doing much in the library. I felt that if I stayed close to the standards, I wouldn't need to do much. reply BoorishBears 1 hour agorootparentMaybe you have the luxury of users who want applications that have all the reactivity of a DMV form, but in my apps at some point I'll need the very simple priciple of \"do something complex when this value changes\" and reimplement useState/useEffect in an ad-hoc manner anyways. I'm more of a backend/embedded developer than a web developer and I still honestly don't get how people find useState/useEffect as intimidating as your comment makes them out to be. reply bakugo 3 hours agorootparentprevYou don't need to understand how useState works if you're writing a page with a button that increments a number when pressed, from a beginner's tutorial. As soon as you work on any remotely complex codebase, you will run into problems that require a decent mental model of the underlying \"magic\" to properly understand and solve. \"Building sophisticated applications while understanding very little of the underlying model\" is how you end up with gigantic piles of unmaintainable spaghetti code full of awful hacks, which seems to be the standard for React applications. reply lolinder 3 hours agorootparentIs this less true of Web Components? I've worked with a lot of different tech stacks over my career and every single one of them has required understanding the internals once you start using them seriously. I haven't found React to be substantially worse for that than any other tech stack I've used. reply peebeebee 2 hours agorootparentWith webcomponents you are pretty close to the “metal”. If you know how to write good vanilla JavaScript, you can take most of that knowledge into webcomponents. You only need to learn the custom components lifecycle, and shadowDOM, which is knowledge about web-standards. With other frameworks you need to learn template syntaxing, how state propagates, how the compiler works, etc etc. Lot of that knowledge might be obsolete in 10 years. Which isn’t to say it can’t be worth it. Learning multiple frameworks and libraries is also very helpful to skill up because you are learning about different concepts and implementations. reply Narhem 2 hours agorootparentAnother advantage of web components is the syntax is similar enough to Java (especially with JavaDocs) switching between coding a Java spring backend and a Web component based front end is doesn’t need as much of a mental context switch. reply rty32 4 hours agoparentprevOne aspect of this is how you think about UI. The underlying pattern of jQuery is fully side-effects -- you select an element and make some changes to it. Frameworks like React and Vue.js allows to create UI components whose states are completely determined by data, i.e. what the UI looks like is the value of a pure function, mathematically speaking. It also updates the UI with minimum DOM changes when the data changes. (Although you don't have to make them pure, and arguably you can achieve the same thing with jQuery.) Depending on where you are, it makes UI widgets much more readable and maintainable. These frameworks are innovative in terms of state management compared to \"old approaches\" (of course, with additional benefits like reusability etc) Bear in mind that today's websites and web based desktop applications are much, much more complicated than two decades ago, and has a much higher requirement for scalability and maintainability. If you just want to create simple UI, indeed they may not be your best choice. reply InsideOutSanta 4 hours agoparentprevI'm building my most recent project with web components + htmx, and it's mind-blowing how much better all of this feels to me than the typical React/Angular stack. I think there's a place for React and Angular and technologies like them, but 90% of the projects that currently use them would be better off with a much simpler stack. reply EMM_386 3 hours agoparentprev> The current state of Front-end frameworks is an absolute mess. Speaking for myself, I don't want to learn a complex framework. It's really not that hard. I was able to pick up Angular to a level where I could create complex sites with it, or submit acceptable PRs that involved in, in week or so. Granted, I am an experienced developer (C# since beta, HTML/JS/CSS from the start) but it seemed to just make sense quickly. So when I was asked by a company to replace their aging, complex portal to manage critical infrastructure, I chose Angular for the front end. That was smooth sailing. It was stable, performant, looked good and everyone was happy. People often avoid it because it has a \"steep learning curve\" but that mainly seems to come from developers who came into the industry knowing only JavaScript and maybe a little React. If you are more experienced, you can pick it up right away. And it helps, a lot, to use such frameworks on large complex sites. For various reasons. reply jeswin 2 hours agorootparentIt's a libraries vs frameworks thing. Libraries are relatively safer. Frameworks in C# are slightly better (compared to those on JS), because there are blessed Frameworks and most people are using them. In the JS world, you can see very popular frameworks (with millions of downloads) get abandoned. Not saying that all is well in the .Net world; desktop frameworks are an example. But overall it's a bit different because one company more or less controls it. reply jaredklewis 1 hour agoparentprev> I never had to guess what \"useState\" does behind the scenes. It's weird to me that React hooks are always dragged out in these arguments as some kind of bogeyman. If you understand the idea of a virtual DOM and a render loop, then it is only a tiny step from there to understand hooks. And you can understand all of these concepts in about 15 minutes: https://www.youtube.com/watch?v=1VVfMVQabx0 I just don't get all the hand wringing regarding frontend frameworks. I've been using React since 2014 and in 10 years, there has been exactly one big change to the framework: hooks. When they came out, I spent 15 minutes to understand them. It didn't kill me. And React has been undisputed king the frontend frameworks hill for at least 9 years, but people still act like it's some sort of ever-changing, confusing landscape of options. If you want boring, stable front-end development, choose a super popular, well documented tool like React. Or if you don't like frameworks, use vanilla JS. It's not a crisis. reply azangru 4 hours agoparentprev> In my view the only thing we should retain from the React era is JSX How do you deal with the non-existing difference between attributes and properties in JSX? Is every attribute a property and vice versa? Do properties reflect back as attributes? reply nsonha 2 hours agorootparentjsx is just a syntax to construct elements with attributes. You can still add properties like you do in a web component. In React you mostly never deal with instances (and properties) but that doesn't mean other ways to model components utilizing jsx cannot. reply azangru 1 hour agorootparentJsx uses properties, not attributes, while pretending that it uses attributes. Html attributes are strings, whereas jsx allows you to pass different data types to child components. Thus, properties. Which is also why is uses camel-cased names, or insists on className. Because these are the names of HTMLElement's properties. reply nsonha 41 minutes agorootparentthat's React's implementation, we are talking what it would be if not React. IMO the semantic is similar to attribute, example: let element =element.property = prop reply sandreas 3 hours agoparentprevWell, there is a project to convert react components to native ones[1]... this way you can write react and use it everywhere. I think this is the way to go, similar to svelte's approach. Write what you want but compile it to native standards. 1: https://github.com/bitovi/react-to-web-component reply coffeefirst 4 hours agoparentprevYeah. I know React quite well, there are legitimate use cases where it shines, but... What we've lost is the ability to say \"let's make a website today\" and just start making UI without build tools or crazy install trees or massive libraries that need maintenance and security updates, and drop it on a server somewhere. I keep thinking I can have that back... ES6 imports are fully supported now, modern CSS is amazing, all we really need is an SSR/a11y-friendly way to do some kind of nestable HTML macro/component, and we can party like it's 2007 (but with grid, and import statements, and all the other new shiny objects). reply lolinder 4 hours agorootparentAs I'm thinking about this, the main thing that is left before I could imagine a build-free website/webapp is TypeScript support in the browser. Even just esbuild-style stripping of types would be enough, but I can't imagine bringing myself to write even a small amount of JavaScript without types any more. Even without that, a tiny system that just depends on tsc should be within reach at this point. reply evilduck 3 hours agorootparentI wouldn’t personally make these tradeoffs but for the sake of argument if you're willing to write substantially more type info into JSDocs (AI tooling may alleviate this nowadays) you can retain most of the coverage and assurances without using anything Typescript adds to the syntax superset while still using it for type checking during development. Even without the type-heavy JSDocs you might be able to alter your coding style to lean into easing and increasing inference (more classes instead of types or interfaces) and get pretty far. Honestly though, I just never really run into use cases where I need to \"make a page in a day\" and where modern tooling gets in the way. I'm comfortable with create-react-app, NextJS, Gatsby, and a couple other things, I can definitely put a new static asset project from one of those on a VPS by shuffling files over scp in the timespan it takes to make a pot of coffee, and I would strongly prefer having those tools than trying to be \"pure\" for hand-wavy reasons and unproven benefit. reply 8n4vidtmkvmk 3 hours agoparentprevIn my admittedly little experience with shadow DOM, it doesn't isolate as much as it claims. CSS variables pierce the boundary, so if your styles are built around that, you can still run into trouble. I just haven't seen any benefit whatsoever once you have CSS modules. And CSS layers help too. reply peebeebee 2 hours agorootparentShadowDOM, and by extension web components are great for providing an extended set of HTML ‘native’ components. Let’s say your company has multiple frontend SPAs with different technologies (angular, react, svelte,…) they could all use the same set of company custom components, like a custom datepicker, or fancy selectbox. reply blovescoffee 3 hours agoparentprevHow does your library deal with state management and data flow? What primitives does your library offer for optimization? reply jrochkind1 4 hours agoparentprevYou implied but didn't say explicitly, are you doing your front-end development with web components now personally? reply jeswin 1 hour agorootparentYes. reply mock-possum 1 hour agoparentprevHave you tried the Lit library? Using lithtml to write web components based on Lit Component is DREAMY imo, if you’re into web components. It really reminds me of using jquery’s helper methods for ajax - like why wasn’t it just this way by default all along. reply Narhem 2 hours agoparentprevIf you use web components enough you realize why tools like useState exists then you have to bring in another library like alpine to offer the functionality. The whole point of web components is the ability to offer class encapsulation within the browser without anything other than a file server. JSX has much nicer syntax but I’d rather not have to deal with the overhead of launching a node server. Makes developing time quicker when working with smaller codebases. reply wslh 4 hours agoparentprev> I don't want to learn a complex framework. Completely agree. As a casual programmer, I just want something simple, inspired in VB6. reply apitman 4 hours agoprevI think part of the reason people talk past each other on this issue is because they're optimizing for different things. If you're working for a VC-backed startup with a central product that needs to move quickly and is going to require constant maintenance anyway, a framework might be a good fit for you. But I work in an academic lab. We don't have tons of money to maintain the apps that we've written. We need them to just keep working once funding has moved on to new projects. We're just finishing up a rewrite of an app from Vue to Web Components. It had dependency rotted to the point where we couldn't update anything because of dependency hell. Rather than spend hours trying to fix it, which we've done before and would have to do again until the end of time, I decided to experiment with Web Components. The experience was immediately so nice that we went all in. No regrets. We went from ~15 dependencies to ~1 (d3js). If you're curious to try the apps, old one[0] new one[1]. [0]: https://bam.iobio.io/ [1]: https://bam2.iobio.io/ reply jitl 4 hours agoparentIf you can rewrite to remove all dependencies except for d3js, why couldn’t you do the same thing, but also retain a dependency on Vue? What is it about Vue that requires the extra dependencies - is it built system things? (I’ve never used Vue) reply apitman 3 hours agorootparentVue itself must be updated. And if you throw out the router, Vuetify, state management, etc, what is it adding above Web Components anyway? reply Jcampuzano2 3 hours agoparentprevSometimes I don't understand this argument because theres nobody forcing you to always be on the latest version of a framework. You could have just stayed on the version of Vue you were using without issues. Unless theres some compelling reason you could use it into the end of time and be just fine. Thats not to say that maybe for your use case you could have not used it in the first place or that removing the dependency was a bad idea - just that if you do like Vue there doesn't seem to be anything forcing you to always be on the latest version. reply WD-42 3 hours agorootparentWhat happens when old versions stop receiving security updates? reply Jcampuzano2 3 hours agorootparentRarely do security issues come from directly as a result of your choice of frontend/client framework which should really only be in charge of displaying your data. Almost all issues should be handled by your backend. Most cases where it becomes an issue is when people drop security best practices falsely believing their frontend/client validation is a security layer. Anybody thinking updating your frontend solves your security issues has deeper problems. reply wavemode 57 minutes agorootparentDoesn't matter, a security update is a security update. So, especially when you work in a larger company, you end up having strict compliance requirements to keep things up to date. I'm as annoyed by it as the next guy. The supposed vulnerabilities are almost never actually relevant for frontend code, and rather assume that you are running Node as a web server. It's just one of those weird things that has resulted from how the JavaScript ecosystem has centralized around using node for everything (i.e. building frontend code as well as executing backend code - even though the two have kind of nothing to do with each other.) reply WD-42 3 hours agorootparentprev> Rarely do security issues come from directly as a result of your choice of frontend/client framework Front end client frameworks now span the backend. Nextjs is the prime example. It has plenty of CVEs already. reply Jcampuzano2 2 hours agorootparentWell next is not a frontend framework and doesn't claim to be. Its very clearly a full stack framework. Vue by itself isn't. reply MrThoughtful 5 hours agoprevI have been following the web components discussion for years now and just don't see what I can do with them that makes my life as a fullstack developer better. All the examples I have seen use them to template some data into html. I can do that with handlebars already. Am I missing someting? reply tomxor 4 hours agoparentFull native isolation. HTML, CSS, JS, the whole thing, no tricks, the browser isolates it for you. It's really nice to be able to make a web component, clearly define the JS, HTML and even CSS API in terms of variables, and then throw it into any environment without it breaking, or without creating a complex maze of CSS name spaces and framework dependencies. reply MrThoughtful 4 hours agorootparentIs there really ever a use case for that? When do you want part of your page to have different fonts, colors, everything from the rest of the page? reply rty32 3 hours agorootparentIt is not a choice in many situations. For a large company that has many different teams that own many different parts of a product, even though teams adhere to the same \"UI standards\", things get complicated quickly. For example, CSS classes that have name conflict can cause UI to break (which happens more often than you think, and strictly adhering to naming rules is just hard for humans). That's just one example. Custom elements with shadow DOM is a simple and straightforward solution to this, and it makes sense -- JavaScript code are scoped to modules and use imports/exports to define interfaces, and it is just natural to do that for UI instead of putting every class that other people don't care about in the global CSS space. reply skrebbel 2 hours agorootparentprevWe ran into this too, and ended up not using the Shadow DOM at all. We want our stuff to automatically use the page's fonts, sizes, colors etc. Also we want customers to be able to customize stuff with CSS without having to use JS hacks to inject CSS into the shadow DOM (this gets especially cumbersome when you're nesting web components). Personally I feel like the shadow DOM is the most oversold part of web components, in that it's so all-or-nothing that it often creates more problems than it solves. reply mock-possum 1 hour agorootparentWhich is another thing I love about web components - if you don’t want shadow dom, then don’t use it - you can build using just custom elements. reply eyelidlessness 3 hours agorootparentprevIn terms of style isolation, the answer is very much “it depends”. And it depends as much on the nature of what the component does, as the kind of isolation you want to achieve. - Namespace isolation. Example: you have different components in the same codebase or otherwise meant to work together; you may want assurance that a locally defined style attached to class “foo” doesn’t have unexpected effects on other components which happen to use the same class a different way. This is commonly achieved with build tooling, eg by mangling class names. - Cascade isolation. Example: you have an embeddable widget that you want to look consistent in any context, regardless of the styles of its parent DOM. This is achievable to some extent without custom elements, but they are a way to achieve it with confidence in a relatively straightforward way (at the expense of other limitations and complexity). reply pradn 3 hours agorootparentprevThe use-case for having isolated objects with parameters, much like classes in Java, is to be able to a) share code, b) hide internal details, and c) have object behavior be governed solely by a constrained set of inputs. So the point isn't to have your web component be different from the rest of the page. The point is that you can pass in parameters to make an off-the-shelf component look how you want. However, exactly how much freedom you want to give users is up to the component author. It is possible for there to be too little freedom, true. See here [1] for a concrete example of someone writing a reusable web component, and figuring out how to let users customize the styling. [1]: https://nolanlawson.com/2021/01/03/options-for-styling-web-c... reply gedy 3 hours agorootparentprevThis 100%. Web components get praised for this isolation - and it’s like the exact thing I do not want if I’m building an application. Like try to have a global CSS theme, or use bootstrap, etc. (Please don’t suggest I embed a link to global CSS in every component.) Like I get it if you’re sharing a component on different sites, like an embedded component or ad banner, etc. But it just gets in the way if you’re trying to do normal things that the majority of web apps need. reply HumanOstrich 3 hours agorootparentThere are ways to apply global styles to your components other than importing a global sheet. There's just not a standard way defined in the spec. Isolation by default is the correct path for them to take compared to the alternatives. That doesn't make it useless just because you don't know how to do it in a good way. See https://developer.mozilla.org/en-US/docs/Web/API/Web_compone... reply gedy 1 hour agorootparentMy main point is that gets in the way, unlike most other web frameworks when building normal applications. It's a headwind that always comes up and hurts adoption imho. reply traverseda 3 hours agoparentprevThere are two models of the \"web\", where HTML is a document and where HTML is the scenegraph of a more complicated app. If you're using HTML as a document you can use web-components to include fancier interactive real-time feature * A terminal emulator web component that attaches to a websocket * A date picker web component, add features like checking if a date is already taken * Custom form elements in general, a search-box that takes a URL for auto-completion suggestions * A map, but not a full mapping application * A data table, like the jquery plugin of old * Lightweight interactivity like tab widgets * Basically any of the custom components that jquery-ui provided Yes you can do all of these without webcomponents, but the HTML is a lot cleaner and a lot more document like if it's a custom component. Mixing the model and scenegraph views of the web is not my favorite. It sure would be nice if there was a consistent library of web components available. You can actually do pretty decent live-chat with something like HTMX and server-sent-events, I think. But it's sort of a progressive-enhancement view of HTML as a document model. reply skrebbel 4 hours agoparentprevWeb Components let you use a UI component made in a different framework than yours. That's it. For most other purposes they're pretty awful. Also they let you publish a UI component that works in every framework, without having to build 7 versions of it (or just exclude everyone who's not on React, or something like that) reply BostonFern 2 hours agorootparentThat’s also the conclusion I’ve drawn. This seems to be the reason Web Components exists. reply jhp123 5 hours agoparentprevthe examples probably avoid talking about the dynamic APIs because they are super ugly and very stateful. It's hard to say that Web Components are the future when your demo shows 200 lines of manual DOM reconciliation. reply j-krieger 5 hours agorootparentI‘ve come to the same conclusion while using them pretty extensively. The idea is nice, but they are not there yet. reply vinnymac 3 hours agorootparentThis could summarize every interaction I’ve had with Web Components since the beginning. Web Components are becoming the Nuclear Fusion of Web standards. reply microflash 4 hours agorootparentprevSure, there is some pain but after years of several Angular and a Vue migration, I'd say that pain is much less than the pain of framework migration. People often overlook the experience of a framework for a long term use. reply deergomoo 4 hours agoparentprevThey are very good for progressive enhancement, for example you could have a web component that wraps ato add fancy features like filtering or drag-and-drop reordering. If JS is disabled or fails to load, the user just gets a plain table, but they still get the content. When this stuff was new, that was much better for the user than what would happen with a front-end framework (they would get a white page), but now server-side rendering is widely available in those frameworks it’s less of a selling point. They are also good for style encapsulation, i.e. you could drop someone else’s component in your page and not worry about it affecting or being affected by your CSS. Anecdotally I feel like that is less of a common desire now than it was ~10 years ago, with the rise of both “headless” UI libraries (behaviour without dictating appearance) and the prevalence of scoped styles in front-end frameworks. What does annoy me about the standard is that to use slots you must opt into the shadow DOM, which means that if you’re trying to create reusable components for your own stuff, you can’t style them just by dropping a stylesheet into the page. I’m sure there’s a technical reason why this is the case, but annoying nonetheless. reply zupatol 3 hours agorootparentWithout the shadow dom, your component can still have children. If you need several slots, there's an example duplicating that functionality with javascript in the second comment of this blog post: https://frontendmasters.com/blog/light-dom-only/ reply mejutoco 4 hours agoparentprevIMO the slots that allow a component to have children are the difference. You can compose indepent components that way. Also the styles are scoped to the component by default, and you can only break the scope with custom vars (css vars) reply someothherguyy 5 hours agoparentprevAre you genuinely asking as a professional? Seems like a big ask for someone to go over all you are misunderstanding if you think they are equivalent to a template language. reply PaulHoule 5 hours agorootparentThe standard, like PWA, is designed for maximum feasible misunderstanding. To the average dev it seems like a random bunch of features that don’t hang together. Five developers could look at it and be like the blind men discussing the elephant —- hung up on individual parts and not seeing the whole, if there is a whole. There are a lot of candidates for “what’s wrong with modern web standards” but this fragmentation, which comes from a rather mathematical view of programming, is one of them. Thing is, a lot of web devs never studied computer science (even CS 101) and less than 5% live in San Francisco. reply Capricorn2481 4 hours agorootparent> and less than 5% live in San Francisco How will they ever understand web components. reply tome 5 hours agorootparentprevOn the other hand, if they're completely different from a template language it seems like it should be just a moments work to demonstrate why, and help a fellow professional understand what they're missing. reply EGreg 5 hours agorootparentWell um 1) You dont have to load an external library 2) Shadow DOM 3) Dynamic slots That’s about it, honestly LOL. I guess the main point of most browser APIs was to let apps use browser features. This one actually tried to make a standard way for apps to use other apps. But they already had their own libraries so nyeh, thank you very much! LOL reply mentalgear 6 hours agoprevOne of the things I really appreciate about Svelte is its support for generating Web Components through the Custom Elements API. Since Svelte compiles down to plain JS/HTML/CSS, creating reusable components that work across any framework or vanilla JS becomes seamless. https://svelte.dev/docs/custom-elements-api reply mmcnl 2 hours agoprevI don't really get this \"frameworks vs. web components\" discussion. They are both tools to solve different problems. Frameworks exist to render your view as function of state in a declarative way. They use web primitives to define the view layer. Web components can help there, but it doesn't solve the state management issue that frameworks aim to solve. That's a different problem that requires different solutions. In my opinion they can perfectly co-exist. reply lapcat 5 hours agoprevThe worst part about web components and the shadow DOM is how they can prevent browser extensions from working correctly, or working at all. And the browser vendors aren't in a hurry to remedy this situation. reply veggieroll 5 hours agoprevOne thing about web components that I've appreciated is that they can work without JS enabled (at least in theory). I've done this a few times for progressive enhancement. Broadly I agree with Nolan, though. Web components have enough rough edges that they're not going to take over the world in the current state. But, they are pretty nice for certain use cases. I'm not sure what he means by not playing well with server side rendering though. I've been doing that without issues. reply mariusor 4 hours agoparent> they can work without JS enabled (at least in theory). I wonder what makes you say that. All that I've seen seems to indicate[1] that Javascript is needed in order to register the template with a specific tag. [1] https://developer.mozilla.org/en-US/docs/Web/API/Web_compone... reply debugnik 4 hours agorootparentAllegedly, declarative shadow DOM lets you declare the template next to the prerendered slot, without JS. reply mariusor 37 minutes agorootparentWhere is this \"alleged\" though? From one of the paragraphs behind my link: > This won't appear in your page until you grab a reference to it with JavaScript and then append it to the DOM reply nsonha 21 minutes agorootparentprevthat's just wrong reply DonHopkins 4 hours agorootparentprevUsing HTML and CSS to make web interfaces without JavaScript is like using concrete to make garden gnomes without rebar, while the rest of the adult world is more concerned with using pre-stressed concrete with rebar to make skyscrapers and superhighways. Sure it's a marginal whimsical decorative use case, but not an important or interesting one. Most people who think turning off JavaScript is an important use case are only inflicting it upon themselves (and aggressively evangelizing that other people do it too) as performative luddites, to feed their martyr complex, so they have something to whine and complain about how the web is so unfair and out to get to them, and have exactly zero customers or products to support. reply mariusor 41 minutes agorootparentYou seem to be quite careless about whom you offend, but I'm not a fan. Please quit it, the only one whining right now seems to be you. reply nsonha 19 minutes agorootparentreally I feel the same as them reply charrondev 4 hours agoparentprevHow is this supposed to work? With reactJS I know I can server render a component or template and I’ll say JSX makes a pretty good tempting language. With web components as far as I understand there is no good templating language built in anyways (so you have to bring your own) I’m not aware of a standard mechanism in which I can take some chunk of JS for a component associated with a tag and have it render out HTML that does not require JS to run. reply nolanl 3 hours agoparentprevAuthor here. I cover this in another post [1], but basically the interop benefits you get on the client just aren't there (yet) on the server. My north star: > Maybe in the future, when you can render 3 different web component frameworks on the server, and they compose together and hydrate nicely, then I’ll consider this solved. [1]: https://nolanlawson.com/2023/08/23/use-web-components-for-wh... reply burcs 6 hours agoprevI love web components and am bullish on them breaking us out of the current frontend hellscape we have created for ourselves. I was recently able to give a short talk on the future of frontend, and it seemed like a lot of other people are hopeful for a way out as well. As far as performance we built out a data table for our DB GUI that can load in hundreds of thousands of rows and the scrolling through is still buttery smooth. We actually are getting ready to release our web component library, it's a bit early and rough around the edges but would love to get some more eyes on it! www.astra-ui.com reply candiddevmike 6 hours agoparentThe only way to get out of the current front end hell IMO is if we get client side import: https://github.com/whatwg/html/issues/2791 reply arcbyte 5 hours agorootparentI'm aghast at the comments in that thread. They are truly asleep at the wheel. No wonder the front end is such a disaster with those mindsets running the show. reply askonomm 5 hours agorootparentprevI meancan do ECMAScript module imports. reply meiraleal 5 hours agorootparentprevThat's a solved problem. You can create a custom element for that with some 5 lines of code. Or use one ready: https://github.com/justinfagnani/html-include-element reply PaulHoule 5 hours agorootparentAnd that’s exactly what some people don’t want! reply meiraleal 4 hours agorootparentSome people will never be happy reply jitl 3 hours agoparentprevI looked at your docs: - renders very weird on my iPhone iPhone 15 Pro Max in Safari 18.0. Consider responsive design for smaller screen sizes to restyle the sidebar and set a body max-width instead of a width. You might not expect your users to develop on phones, but you might have a hard time with adoption if the docs are mobile hostile. - the “explore components” button at the bottom of the home page seems to link to nowhere - site claims “Learn from well-structured, accessible component implementations” as an advantage but I didn’t find any links to the implementation from the docs - site claims “No dependencies to manage or update” but isn’t astra-ui a dependency? It has a changelog (https://www.astra-ui.com/changes/). Likewise “Full control over the code and styling” I don’t understand how I can both have full control but also be taking a dependency on implementations provided by a library. I’m curious why you’ve decided to release this library? I’ve come to view open-sourcing internal software as useful to the company for a few specific reasons but to generally be a time-sink without much return unless it’s accomplishing a goal. Component libraries need to fight for general ecosystem adoption or there’s no audience and you might as well not publish at all. reply burcs 42 minutes agorootparentReally appreciate the write up here! Maybe rough around the edges is an understatement haha, we are actively working to make the docs here better. So a few things, these are very primitive components that can easily be updated and restyled. There’s a given that there will be a dependency when using a library, right? The thing is with this you don’t even need to npm install if you don’t want to. Just plug and play. As far as why… there isn’t much out there in terms of a web component driven component library and I think we’ve done some great stuff with ours. That plus we have customers embedding our components into their platform and it’s always helpful to see the source code. I hear you on the docs quality though we will work on that. reply stavros 5 hours agoparentprevWhy aren't web components there/more popular yet? They seem like a fantastic solution reply kansface 56 minutes agorootparent> They seem like a fantastic solution for which problem? They don't replace the need for a framework nor do they make writing in one easier. They don't make dev ex better. What is the actual use case? If they were highly useful, they would be used. reply stavros 52 minutes agorootparentCreating self-contained components that don't rely on loading extra management code, in a standard way. Maybe they aren't useful because the modern trend of web development is to not care about speed or size as much. reply pfraze 2 hours agorootparentprevWeb Components have some nice features, some bad features, and no killer feature. Developers have mostly chosen to ignore them for other approaches (React, Vue) where there are better ergonomics and stronger network effects. reply meiraleal 24 minutes agorootparentShadowDOM should be a killer feature for people that wants to make web scrappers life a bit more difficult. reply nsonha 12 minutes agorootparentjust do a quick scan in this thread, many say it's the one thing that makes web components not work for them. It's the opposite of what a killer feature means reply burcs 5 hours agorootparentprevThe cynic in me wants to say it’s because they aren’t VC backed so there’s no main catalyst driving them. I don’t think a lot of people know about them, or if they do they have just heard about it in passing and have never actually used them. Whatever the reason is they have a marketing problem that’s for sure. reply stavros 4 hours agorootparentAh, well that's encouraging, if the tech itself is good, it means I can start using them more. reply j45 5 hours agorootparentprevNew developers follow social proof often instead of learning from first principles. Web Components are seriously cool and worth looking at. reply evilduck 3 hours agorootparentSocial proof does tend to follow employment opportunities. If you're a new dev you don't have the luxury to make principled choices in technology, you're more worried about housing and food security and maybe paying back student loans. Asking new developers to trend-set the industry would be deeply unfair. If we want them to learn from first principles then entry level jobs should have first principles opportunities available. reply j45 2 hours agorootparentI meant social proof like prejudice against technologies that employ but don’t seem popular and cool. Another confusion might be expecting an employer to educate you. That’s part of it but not the requirement. Self-directed learning is critical to go with any formal learning. First principles are needing to be taught where or before people are learning things like react. But they don’t, and get pulled into a world of complexity. reply stavros 4 hours agorootparentprevExcellent, thank you! reply tomjen3 5 hours agoparentprevWhy would I used them over something like a Vue component? reply burcs 5 hours agorootparentThey are framework-agnostic, meaning you're not locked into Vue, React, Angular, or any specific framework. They work natively in the browser, which makes them reusable everywhere, now and in the future. reply throw310822 4 hours agorootparent> They are framework-agnostic This is a selling point only if your job is producing component libraries. Otherwise, if you're an application developer, you'll be using a framework anyway. reply apotropaic 1 hour agorootparentNot entirely true. Making UI parts of your app using web components can future proof and prevent getting stuck on a framework. reply webdevladder 5 hours agoprevI think this minimizes the fact that interop - the main selling point to me as a user - comes at a performance cost where every component you use could have its own unnecessary runtime attached.[1] Using a framework like Lit with web components is the recommended way to use them. This cost will compound over time where new frameworks emerge, and components get stuck on older versions of their frameworks. I can't see this as anything but significant, and not to be minimized. Having multiple redundant libraries on a page is not the direction I would advise anyone to take, particularly not when baked into the accepted best practices. This bodes poorly in the long term. I've listened to the arguments from web component advocates in blog posts, social media, and videos for years now, and I should be in the target market. But on top of the interop tax, they're full of negatives that aren't present in the mainstream frameworks. Interop works great within each framework's ecosystem. The same dynamics that cause developers to seek interop cause them to huddle around a small number of mainstream frameworks. So we get a few vibrant ecosystems that push the state of the art together. Web components cannot keep up on the tech side of things, and introduce a ton of complexity to the web platform - ignorable to me as a dev, but not for browser implementers - in service of their early 2010s designs. [1] https://x.com/Rich_Harris/status/1840116730716119356 reply nolanl 3 hours agoparentI cover this in another post [1], but broadly: - Not every web app is perf-sensitive to every extra kB (eCommerce is, productivity tools typically aren't) - Plenty of frameworks have tiny runtimes, e.g. Svelte is 2.7kB [2] - I wouldn't advocate for 100 different frameworks on the page, but let's say 5-6 would be fine IMO No one is arguing that this is ideal, but sometimes this model can help, e.g. for gradual migrations or micro-frontends. BTW React 17 actually introduced a feature where you could do exactly this: have multiple versions of React on the same page [3]. [1]: https://nolanlawson.com/2021/08/01/why-its-okay-for-web-comp... [2]: https://bundlephobia.com/package/svelte@4.2.19 [3]: https://legacy.reactjs.org/blog/2020/10/20/react-v17.html reply afavour 5 hours agoparentprevWhile this is true I think the multiple libraries problem is a rounding error when you look at the majority of web apps created today. React and react-dom combined are over 100KB. Svelte and Lit are in the single digits. So you could embed a lot of frameworks before you get close to the bloat people use every single day without even thinking about it. reply webdevladder 5 hours agorootparentAs a Svelte user this argument rings hollow. You can't judge frontend by React and the way it's badly used. reply afavour 5 hours agorootparent> You can't judge frontend by React and the way it's badly used. IMO you can because it’s the vast majority of webapp usage today. I’m also a heavy Svelte user and I love it but front end web dev is practically a React monoculture so it makes sense to think about it when evaluating options. I’m not saying it isn’t a problem inherent in web components, it is. But using it as a reason to not adopt web components runs contrary to the logic the vast majority of the industry currently uses. Perfect as the enemy of good and all that. reply webdevladder 5 hours agorootparentReact is irrelevant for me and my users. This is not an argument in favor of web components over Svelte. Adopting web components would mean an objectively worse UX for my users - for example requiring them to enable JS. You won't get a Svelte to look past the flaws of web components by saying \"React is bad\". reply afavour 4 hours agorootparentYes, you’re talking about you and your users. I’m talking about the industry at large. Those two perspectives don’t have to line up. The article we’re discussing is titled “Web Components are okay”, not “Web Components are better than Svelte for webdevladder and their users”. reply webdevladder 4 hours agorootparentLook at the thread you've created here - I'm arguing that the article minimizes the antipattern cost they impose, and your response brings up React as if it somehow changes that. reply afavour 4 hours agorootparentYes, I previously mentioned the “perfect as the enemy of good” argument. Like I already said, I use and like Svelte. But the vast majority of the web dev ecosystem uses React. Web components would be better than everyone using React. Arguably everyone using Svelte could be better still but that’s a separate debate. > your response brings up React as if it somehow changes that. It does. Because the industry clearly has no problem with a large upfront cost, given that it imposes one today. Web components would be better than what we have today even if it isn’t the ideal. reply azemetre 5 hours agorootparentprevYou absolutely can judge tools by how they are used, especially if said tool encourages poor usage. reply webdevladder 5 hours agorootparentYou can judge React, but like I said, not frontend. You're responding to an argument I didn't make. reply hajile 4 hours agorootparentprevReact has one up-front size for rendering code whether you use 1 component or 10,000 components. Svelte and Lit rendering code size just keeps going up, and up, and up.... You can argue about which is better, but this kind of naive size comparison is disingenuous. reply afavour 4 hours agorootparentWhile it’s true that Svelte and Lit can grow in size dependent on project there’s no world in which even large projects get close to the base level of the React runtime. reply mdhb 4 hours agorootparentprevOnly if you are doing it wrong. https://lit.dev/docs/tools/publishing/ reply webdevladder 2 hours agoparentprevA more broad observation, I'm being pointed in the parent comment - web components need to win over framework authors. The signs are not trending well here from what I've seen consistently. That community is on X and web components are not addressing their problems and they're not used in optimal scenarios. I hope web components can win them over but they're mostly saying they've been a failure, arguably on balance bad for the web. reply skrebbel 5 hours agoparentprevI don't really understand this argument, to be frank. Most runtimes are pretty small, and there's not much of a performance overhead to both runtimes running at the same time. It's not like these are two realtime engines both purring along in the background or something like that. All modern web frameworks are reactive, and won't do anything unless something needs responding to. If one part of the page is built with React, another part is built with Lit, and a third part with Svelte, I don't see how that will have noticeably worse UX (or battery consumption) than a page made with just one framework, even when reactive triggers are frequently exchanged between them. The tweet you quote is about whether web components are \"useful primitives on which to build frameworks\". I doubt many web component fans (who actually really used them) would say that they are. They're a distribution mechanism, and the only alternative I've seen from these framework authors is \"just make the same library 7 times, once for React, once for Preact, once for Svelte, once for Solid, once for Vue, once for vanilla JS\". This is awful. reply webdevladder 4 hours agorootparentYou're ignoring page bloat as a performance cost. That's hugely impactful for UX on the web. reply skrebbel 4 hours agorootparentNot entirely, I said \"Most runtimes are pretty small\". I think people got trained by React into thinking that frameworks are big. SolidJS is 7kb, Lit is 5kb, Svelte is tiny and used to have no runtime at all, etc. Only React is big. And, well, if you're writing React components and publishing them as web components, it's usually quite feasible to build them with Preact instead, which is tiny as well. So on a page with like some hodgepodge of 5 frameworks purring along inside various web components, there's still going to be only 20-30 kb of extra overhead. You can compress one image slightly better and save more than that. reply webdevladder 4 hours agorootparentThe point being made is that web components can pay this cost per-component, and this problem will compound over time. This is an unprecendented cost to frontend framworks and it's the expected usage pattern. reply skrebbel 2 hours agorootparentI've yet to see this go wrong in practice. The kinds of components that are worth publishing as web components are often large, non-trivial components. Eg media libraries, emoji pickers (like the one made by this article's author), chatboxes, and so on. They are the kinds of things you only have a limited number of on your page. They're also the kinds of things where application code tends to be much bigger than the framework (except if the framework is React). On the other hand, if a component is small and focused in scope, it's likely either written in vanilla JS (like https://shoelace.style/), or made for a single framework (like the average React infinite scroll component). In other words, I don't think you're wrong, but I do think you're prematurely optimizing a problem that doesn't really exist in reality. And the cost is big: if you get your way, every component author needs to either lock themselves into a single framework's users, or make 7-8 different versions of their component. I'd argue that that's much more wasteful than a few kb extra framework JS. reply mhoad 4 hours agorootparentprevIt’s also just not actually true though. It’s not considered good practice to bundle your web components when publishing to npm for this exact reason. That’s something that should happen inside the final app itself where the components get used so you only have one instance of Lit for example if you are using that. reply dandrew5 26 minutes agoprevWeb Components are fun. I've played around with Lit, which some people have mentioned. Anybody tried Stencil? It looks similar from the outside but wondering how it plays out mid/late-term. reply gaganyaan 41 minutes agoprevI really dislike the Shadow DOM part of Web Components. Someone didn't learn any lessons from past mistakes and went and reinvented iframes. Trying to write tests or any automation for a web page that uses shadow dom is an exercise in misery, unnecessary at that. reply tannhaeuser 4 hours agoprevLet me explain the argument to you: > You can always add another layer of abstraction to solve a problem but removing one can be difficult. The argument being that there's no need to add anything to the browser stack and make it even more complex when it doesn't add any essential capability. There's already JS making everything possible; and yet, they keep on piling stuff. When with custom elements specifically, you also require JS anyway (to declare them). > Elements are not components. Idk maybe for \"web devs\" the concept is difficult to grasp that HTML isn't for them. It's for text authors, and as such a markup vocabulary where low-level elements are placed next to complex custom controls nilly-willy isn't really a useful evolutionary direction. reply thomassmith65 3 hours agoprevI use web components, but I often want to design classes as MVC. It isn't obvious how this should work (though I assume the Web Component spec authors discussed the topic at some point). The awkwardness is: (a) When you instantiate your View class (ie: 'web component') from JS, you probably want your Model and View to be 'owned' by properties of the Controller (eg: con.model and con.view). However... (b) when an HTML tag instantiates your View, the View has to create its Model and Controller. And now there's no obvious place to store a reference to the Controller. As a result, you have either to stick the Controller in a global variable somewhere, or - more likely - end up, not just with 'con.model' and 'con.view', but also with a new property: 'view.con' So... two paths to create everything (Controller-based, or View-based), and this ugly '.con' property stuck in the View. But, aside from this gripe, Web Components are okay. reply mattlondon 3 hours agoparentI don't think we components were intended as a complete \"framework\" for writing web apps, but more for the rendering of reusable UI components. So trying to do MVC with just web components feels a bit weird, at least to me. You'd need something extra I think reply thomassmith65 2 hours agorootparentThe problem is that the ShadowDOM is sort of the real View, and the CustomElement (judging it by its methods), is kind of a mix of a View and a Controller. Perhaps I should try making my controllers the HTMLElement subclasses, instead of my views. My gripe remains: the best approach is not obvious. reply addicted 3 hours agoprevWeb components are lacking some basic functionality that makes using them in something complex difficult. For example, one of the deal breakers we faced was the inability to unload and reload a web component. Once you load a web component you’re stuck with it until you refresh the browser. You cannot have an SPA with one page loading 1 version of the web component and another loading another version without some ugly namespace mangling. reply skrebbel 5 hours agoprevI'm bullish on web components as a distribution mechanism. In fact, we're currently hard at work betting our entire company (https://talkjs.com - a component library + API for chat) on it. I agree with Nolan here that the performance is fine. People keep comparing web components to React or Solid components, but the latter inherently have a tiny granularity whereas web components is primarily a way to distribute reuseable elements, not an application framework on its own. Don't make every tiny piece of your app its own little web component (or, at least, don't do it without a framework such as Lit to skip the pain). But web components are the way to build a component once and have it usable in all web frameworks (including none at all) out of the box. That's fantastic! And also unprecedented (on the web, that is). It bothers me that so much of the discussion is still about whether web components are good primitives to build frameworks on top of. No, not really, they're pretty awful for that! But for distribution, nothing else comes close. I'd love it for some alternative standard to emerge, without all the awful design choices of web components. And I agree with Rich (Svelte) and Ryan (Solid) that WCs being built into browsers are getting in the way of some other collective component interop design emerging. But until the framework authors stick their heads together and invent a fast, modular, non-shitty, property-only, functional-smelling standard for distributing components, I'm sticking with web components. For component authors, the only alternative is making a React version, a Preact version, a Lit version, a Svelte version, a Vue version, an Angular version, a Solid version and a vanilla JS version of the same UI component. That's awful! Web components are clunky but they're here, now! reply delusional 5 hours agoparent> With every programming language, you can do There are plenty of programming languages where you can't do that. If you really need that, can't you just register it as \"my-thing-1\" and then register the other one as \"my-thing-2\"? reply skrebbel 5 hours agorootparentSorry, I edited my post and took that out for being too detailed. > If you really need that, can't you just register it as \"my-thing-1\" and then register the other one as \"my-thing-2\"? Yes you can, but it means you gotta search-replace something, whereas in every modern programming language you just do an import or an alias or something like that. And you still can't solve hot-reloading a web component that way. reply PaulHoule 5 hours agoprevI did a project that used Shadow DOM and related tech to address the problem of embedding a widget into a partner’s web site without any risk of CSS interference. Worked great, but this was one medium-sized widget that did not interact with the rest of the page. reply tomrod 6 hours agoprevI like seeing accessibility respected. Good post. reply drawkbox 2 hours agoprevI dig WebComponents because I love building on standards which promote interoperability across frameworks and have long term lifelines. Standards reduce platform + dev lock-in and reduce framework balkanization and frankly chaos in many cases. You are a better developer if you understand the root standards and core systems, which WebComponents get you closer to. I also like the Lit Framework (https://lit.dev/) from Google which is rarely mentioned but it is quite nice for some of the simplifications and extras you might need when building them but it doesn't get in the way or try to take over your entire domain with dev-lockin. Whether going direct to WebComponents or a higher level simplification like Lit, they really are a freedom from dev lock-in that is nice to see. reply superkuh 5 hours agoprevWeb components are okay as long as you only use them to progressively wrap actual HTML elements. If you're using custom-elements by themselves like a JS frontend replacement and just making entire web pages full of blank grey boxes that do nothing without JS, you're doing a bad job. See: https://blog.jim-nielsen.com/2023/html-web-components/ reply claytongulick 5 hours agoparentOh? So anyone writing applications, PWAs, healthcare software, responsive mobile web apps, or a billion other business domains where the web makes sense as a UI is doing a bad job? Guess I've been doing a bad job for a long time now. reply superkuh 5 hours agorootparentYes, https://www.gov.uk/service-manual/technology/using-progressi... “All [UK] government services must follow progressive enhancement, even if part of the service or a parent service needs JavaScript” But more seriously, it's okay to do a bad job if you're being paid/forced to do it by a for-profit entity. That's what jobs are. Being paid to do things you wouldn't do otherwise (like making a webpage entirely inaccessible to people with screen readers because there's no text in the custom-elements pre-JS execution and not caring because the visually impaired don't contribute significantly to profit). Just don't chose to do a bad job for personal stuff. reply royal_ts 4 hours agorootparentWhile that link is great advice it's not 100% true that you need to have JS enabled to render anything in a web component - there's declarative shadow dom. Also while it's also true to depend on as little as possible JavaScript it's also required for some accessibility aspects. You can get far with only HTML and CSS but not always all the way. reply DecoySalamander 4 hours agorootparentprevScreen readers that can't do their job on dynamically generated pages are faulty and should not be relied upon by anyone, especially for browsing the web. There is absolutely no reason to be beholden to the incompetence of the developers of such software. reply superkuh 4 hours agorootparentYeah, those visually impaired people should be constantly changing their screen reader software so as to follow the eternally changing wave of web dev. That's totally a feasible and reasonable thing to ask. I'm sure the shadow dom is giving those dynamic screen readers zero problems. /s Please, please just consider putting actual text in the HTML. It helps a lot. reply newhotelowner 5 hours agoprevSafari is the only browser without the full support *Supports \"Autonomous custom elements\" but not \"Customized built-in elements\" reply claytongulick 4 hours agoprevI think one of the biggest \"mistakes\" with web components was coupling them in people's mind with shadow dom. For app dev (not library dev) web components are a super lightweight easy option when you stick with the light dom. You can continue to use bootstrap or tailwind or whatever css thing you like, but get great functional encapsulation with near zero cost, especially if you use lit-html or something similar as a renderer. My teams have generally found working with native web components refreshing. It takes a dev coming from the framework world about a week to adjust, and then they never want to go back. Just using simple class properties and a manual call to a render function on set() gives you all the benefits of reactivity without all the hassle of frameworks. The problem most people have with getting started with WCs is that there's not much out there showing how do to it in \"easy mode\". Most of the getting started things throw you right into shadow dom, css parts, and all these really painful technologies that were primarily intended for use by library authors, not app devs. I've been building apps with native WCs for a long time now, I should get off my keister and write a guide on how to make your life easier with WCs, something like \"The Good Parts\". reply nolanl 3 hours agoparentI use shadow DOM every day, but yes, it is often the part of WCs that baffles people – probably because they don't need it. Alternative approaches that may work for your use case: - \"HTML web components\" [1] - light DOM only, SSR-first, good as a replacement for \"jQuery sprinkles\" - \"Shadow gristle\" [2] - use as little shadow DOM as possible. If you need styling or composition, put it in the light DOM! [1]: https://adactio.com/journal/20618 [2]: https://glazkov.com/2023/03/02/shadow-gristle/ reply meiraleal 4 hours agoparentprevThat's exactly it. We are just missing slots for lightDOM reply renegat0x0 4 hours agoprevThis might be a stupid hot take, but I am surprised that so little of web UI exist outside of the browser. I mean why bootstrap or other frameworks are not managed by browser ecosystem? Why millions of people how to download same frameworks over and over? reply ramones13 3 hours agoparentThere’s a pretty thorough post covering this here - https://infrequently.org/2022/03/cache-and-prizes/ reply wellpast 1 hour agoprevWhat’s missing in his point and examples about “performance isn’t everything” (aria properties, forEach, …) is that these are cases where you could optimize later when and if needed. Using forEach is a fluid coding choice at the time but if for any reason you need to optimize to a for loop you can with minimal fanfare. But buying into web components is more of a one-way door and harder to iterate optimizations, and that’s the problem. reply mtn6747 4 hours agoprev [3 more] [flagged] toddmorey 3 hours agoparent [–] So just more AI comment spam, huh? It's unfortunately ruining my favorite communities. reply meiraleal 17 minutes agorootparent [–] it is only ruining if you decide to see the dead posts and still dislike that spam is being killed. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nolan Lawson addresses the debate on web components, sparked by Ryan Carniato's post \"Web Components Are Not the Future\" and Cory LaViska's counter \"Web Components Are Not the Future — They’re the Present.\"",
      "Lawson, experienced with web components, acknowledges their performance overhead but highlights trade-offs such as maintainability, security, usability, and accessibility.",
      "He concludes that web components, despite their limitations, offer unique creative opportunities and are one of many tools available in the diverse web development landscape."
    ],
    "commentSummary": [
      "The discussion centers around the complexity and usability of modern front-end frameworks versus web components, with some developers expressing frustration over the \"magic\" in frameworks like React.",
      "Web components are highlighted for their simplicity and closer alignment with web standards, offering features like Shadow DOM for isolation without the need for complex frameworks.",
      "A developer shared their positive experience transitioning from Vue to web components, significantly reducing dependencies and maintenance overhead, which is particularly beneficial for projects with limited resources."
    ],
    "points": 147,
    "commentCount": 157,
    "retryCount": 0,
    "time": 1727611020
  },
  {
    "id": 41683144,
    "title": "htmgo - build simple and scalable systems with golang + htmx",
    "originLink": "https://htmgo.dev",
    "originBody": "Hey all, I just wanted to share a project I&#x27;ve been working on for the past month.After years of heavy frameworks, I really like the idea of using htmx, but it’s a little too low level for me and needs a thin layer above it to facilitate things like components, better syntax with complex JS inside of an attribute, etcTo try and solve this problem with a very minimal stack (golang + htmx) that I&#x27;ve been really enjoying, I&#x27;m building this project to cater to my needs and was thinking it would be useful for other developers.",
    "commentLink": "https://news.ycombinator.com/item?id=41683144",
    "commentBody": "htmgo - build simple and scalable systems with golang + htmx (htmgo.dev)144 points by maddalax 16 hours agohidepastfavorite60 comments Hey all, I just wanted to share a project I've been working on for the past month. After years of heavy frameworks, I really like the idea of using htmx, but it’s a little too low level for me and needs a thin layer above it to facilitate things like components, better syntax with complex JS inside of an attribute, etc To try and solve this problem with a very minimal stack (golang + htmx) that I've been really enjoying, I'm building this project to cater to my needs and was thinking it would be useful for other developers. novoreorx 5 hours agoWelp, another fasthtml project. I still don't understand the idea of reinventing HTML in another language. It's too restrictive and will never be as compatible as JSX. Don't get me wrong, I love HTMX, I just don't want to write DSL to generate HTML. IMO a backend language should integrate HTMX similar to how https://hotwired.dev/ works. reply gwd 1 hour agoparent> I still don't understand the idea of reinventing HTML in another language. I switched from using golang templates with hand-crafted HTML to gomponents[1] a few months ago, and it's been amazing. It is so so so much easier to write re-usable components, so much easier to express complicated conditionals, so much nicer to have a type checker helping you not make mistakes. And of course I like gomponents for the same reason (I presume) JS-oriented people like NodeJS: It's just a lot nicer to have as much as possible written in the same language, be it JavaScript or Golang. [1] https://www.gomponents.com/ reply bilekas 1 hour agoparentprev> IMO a backend language should integrate HTMX similar to how https://hotwired.dev/ works. Turbo stimulus and Strada.. HTMX... Nothing. Just serve it however you feel. In the posts case, they decided to add some tight coupling with go, while not for everyone, is not really a framework. I appreciate go server for really lightweight banal sites or even light services and htmlx is quickly becoming my new favourite markup. I will say this project isn't for me, but casting it as just another 'fasthtml' project is a bit far off the mark. reply imacrayon 45 minutes agorootparentI actually created https://alpine-ajax.js.org for this reason. HTMX and Hotwire both have opinionated requirements around the content and status codes that your server returns. One of the goals with Alpine AJAX is you should be able to drop it into any basic CRUD app and have it working without changing any server code. HTMX for example requires that a successful form submission respond with a 200 status, but many applications (most?) will 302 redirect to a new page to prevent duplicate form request on refresh. reply maddalax 37 minutes agorootparentThis is very cool, I like the website too reply 2024user 7 hours agoprevWithout touching JavaScript but now you have to type return h.NewPage( h.Div( h.Class(\"flex gap-2\"), h.TextF(\"the current time is %s\", now.String()) ) ) To me that is horrible. reply maddalax 6 hours agoparentWell when you put it all on one line it doesn’t look great :) With it properly spaced out and nested, after a few days it started reading exactly like HTML to me, where I can quickly see the hiearchy reply snorremd 6 hours agorootparentAs a developer who has worked extensively with React and Reagent (a ClojureScript wrapper around React) I actually enjoy this kind of syntax. Better that then some custom HTML templating syntax I need to learn in addition to the language. It doesn't look too bad if one also break the code into multiple functions to make \"layouts\" and \"components\". I have had lots of fun building with Bun, ElysiaJS, and HTMX. Might test your go library out as well. Looks pretty neat. reply maddalax 5 hours agorootparentAwesome, yeah those are pretty nice technologies. Definitely let me know if you do / encounter any issues! reply j45 5 hours agoparentprevEverything doesn't have to be for everyone, and that doesn't make it bad. reply sitkack 4 hours agorootparentThis attitude would stop over 50% of disagreements. reply j45 1 hour agorootparentand.. piss off another group who get their validation externally by evangelically putting down the technological choices of others. Prejudice may not be in social areas but the same behaviour of prejudice is alive and well in justifying your own or denigrating someone else’s technology choices. Same folks aren’t willing to be open to what is new to them in a new framework is still a 20 year old thing. reply hadthischat 3 hours agoparentprevYou still type out code? My toolkit is endless generators and macros. I suppose bike shedding still matters to people who see themselves as Hemingway not an engineer reply bilekas 1 hour agorootparentThis is not right, there's nothing wrong with typing out code. Generators are fine, until they're not. > I suppose bike shedding still matters to people who see themselves as Hemingway not an engineer This is anything but bikeshedding. reply breadchris 5 hours agoprevI love this! I have been working on something similar recently [1] and it is exciting to think about the possibility of building full stack components for the web that are not going to break in the foreseeable future. Even if I need to swap languages/frameworks go is easy to parse and transpile! I dream of a library like ours to take on the likes of React, and to get there the devex needs to have some key features. Most notably, imo, is live reload. You could use air, but I find it still to be too slow to recompile the entire app. I have had some success so far with yaegi to interpret the go at runtime [2]. It isn't perfect, but the full language spec is implemented. My personal goal is to build the Go equivalent of rails/django. Live reloading is needed in addition to plugins that provide web app primitives (auth, storage, logging, metrics, etc). Additionally, I think the network effect of React is a powerful value driver, so some easy way to include React in an app is also important. Thankfully evanw has made this trivial with esbuild [3] [1] https://github.com/breadchris/share/blob/master/html2/html.g... [2] https://github.com/traefik/yaegi [3] https://github.com/breadchris/share/blob/master/graph/build.... reply maddalax 4 hours agoparentHaha we kind of have the same vision. That's eventually what I want to turn htmgo into, something like rails, but as minimal as it can be (essentially plugins, good defaults but you can opt out). > You could use air, but I find it still to be too slow to recompile the entire app. At the moment I'm using fsnotify to watch file changes and restart the process immediately, so far it hasn't been too bad for live reloading. I'm hoping as long as precautions are taken to lazy load things on startup, then it would stay fairly quick. reply hilti 4 hours agorootparent15 years ago I created a web framework for newLISP. It even ran fast on a Nokia N900 Maybe you want to have a look at the code and get some inspiration. https://github.com/taoeffect/dragonfly-newlisp reply maddalax 4 hours agoparentprevyaegi is very interesting... I'm going to see if I can get it working on htmgo for reloading the views. reply breadchris 2 hours agorootparentI would take a look at this demo [1]. Pay close attention to what is being interpreted vs bound as a symbol to compiled code. The `yaegi extract` command will not work on exported generics atm. If you want to collab more, shoot me an email: chris@breadchris.com [1] https://github.com/DCjanus/yaegi_demo reply anonzzzies 12 hours agoprevThese things are really nice and I enjoy using them very much, but we depend now so much on shadcn and ready made templates on top of that; almost all of those are react (and next). The world needs far more open source (fully, not those 'pay to a for all the useful components and templates'; not because I don't want to pay, but because of the licensing; we reuse all things internally, so 1-site license etc are just not options) html/tailwind, htmx, htmgo, clog etc templates with components. edit: typo reply 65 1 hour agoprevHas there ever been a widely used open source project for writing HTML as functions inside of another language? (JSX and PHP don't count - you're still writing the HTML markup). reply librasteve 1 hour agoparentI have been working on a raku module (HTML::Functional) to do this, as with the OP the main motivation is for me to be able to declutter my own projects, so not widely used, but yes OSS. Here is an \"Elm-like\" example from https://elmprogramming.com/building-a-simple-page-in-elm.htm... coded in raku. HTMX is a great lever to put the code on the server - thus Go, Raku, whatever. use HTML::Functional; my $body = body [ div( :class, [ h1(\"Welcome to Dunder Mifflin!\"), p \"Dunder Mifflin Inc. (stock symbol{strong 'DMI'})\" ~ q:to/END/; is a micro-cap regional paper and office supply distributor with an emphasis on servicing small-business clients. END ]), p :hx-get, \"Click Me\", ]; From the module synopsis which means some of the capabilities of the Raku Quoting Slang are in play ... https://raku.land/zef:librasteve/HTML::Functional. Raku functions only need parens for disambiguation btw. Named attrs can use the :name syntax which imo is the tidiest. reply gwd 1 hour agoparentprevI dunno how widely used it is, but I've found gomponents[1] a big improvement over golang templates with hand-crafted HTML. [1] https://www.gomponents.com/ reply pmdr 1 hour agoparentprevPhlex (https://phlex.fun), but I don't know about the 'widely' part. reply smallerfish 6 hours agoprevKotlin is a great fit for this - it has an html dsl library called Kotlinx.html, which works alongside HTMX fantastically. And, you can write a kotlinjs frontend chunk for anything additional you need that HTMX isn't a great fit for. I built a framework for my own use that has typesafe routing & SQL. It's a thing of beauty. reply andy800 47 minutes agoparentKotlin is indeed a great backend to pair with HTMX. However I find jte.gg templating superior to kotlinx.html's awkward syntax. You still benefit from working with native Kotljn objects inside the templates. Check it out! reply maddalax 4 hours agoparentprevthat looks nice, I've enjoyed Kotlin when I used it in the past reply tanduv 13 hours agoprevThe example TODO app doesn't seem to be doing so well https://todo-example.htmgo.dev/ reply maddalax 13 hours agoparentlol looks like I forgot to limit the user input length, clearing those now… reply maddalax 12 hours agorootparentsomeone decided to ddos it with profanity so I'm pushing an update now so its not global viewable anymore. reply lnxg33k1 11 hours agorootparentI would have paid extra for free profanity, consider to offer it as an addon reply DLA 15 hours agoprevThis is useful! Love the Go & HTMX combination and use it often. Good documentation too for an alpha release. Nice work. reply winrid 13 hours agoprevReminds me of https://j2html.com Which I have also been starting to use for one project, with quarkus, been a nice experience so far. reply jacques_chester 2 hours agoparentAlso Gomponents, a similar project for Go: https://www.gomponents.com reply mattgreenrocks 8 hours agoparentprevHave you tried Renarde and Qute? reply winrid 4 hours agorootparentYes. My concern is the template compilation will get really slow or the custom IDE integration will get out of date and break. reply thwg 9 hours agoparentprevj makes me shudder. But thanks for sharing. reply winrid 2 hours agorootparenthaha, to be fair my Java code is more like Go than typical Java. I should probably try Go someday. reply OccamsMirror 13 hours agoprevhtmx + Templ (https://templ.guide/) is something I'm really enjoying as a replacement for React in my personal projects. reply maddalax 13 hours agoparentI do also like the idea behind templ, only issue is when I tried to use it, the DX was pretty poor on Jetbrains IDE’s. I think the LSP is broken for it reply kosmozaut 10 hours agorootparentI'm kind of in the same boat (but with VSCode). In addition to that, I found that it didn't make things too much easier than something like MVC with built-in template/html. The context integration seems like a huge footgun, since it just panics if you access a value that doesn't exist. reply jonathrg 6 hours agorootparentprevThere is definitely a problem with the LSP. I've resorted to turning off the templ extension in VS Code, syntax highlighting and all. reply chabad360 13 hours agorootparentprevThat's actually something I've been slowly working on. There's a bug in the go parser tho that kinda slowed things down a lot. reply sublinear 13 hours agoprev\"Scalable\", but does it scale in terms of business requirements typical of web projects? reply TripleChecker 4 hours agoprevinteresting idea, can it be used with Gin or any other Go web framework - or is that not just the html templating library but a framework on its own? There were a few typos in the docs page: https://triplechecker.com/s/D32t6y/htmgo.dev?v=HrUfl reply maddalax 4 hours agoparentAh good call, I should have checked for typos. Will fix, ty. The routing uses the std lib + chi, it's fairly integrated into the html builder because the http request needs to be utilized to check specific htmx headers. I could imagine you could use your own web framework though, since you can wrap the std lib handlers. reply maddalax 4 hours agorootparentAlso depending on popularity, I may make other adapters for different go web frameworks reply bugsense 1 hour agoprevFresh air reply seumars 6 hours agoprevHow is htmx low level? reply maddalax 5 hours agoparentLow level in the sense that it doesn't have things you would traditionally need to build an application, such as re-usable components, conditional rendering, etc. To do that you have to wire it up with something else such as your backends templating system, alpine, etc. reply anonzzzies 12 hours agoprevI find, for a little extra productivity, that liveview [0] even adds a bit more effortless building personally. No plumbing endpoints is great with all written in Go. [0] https://github.com/canopyclimate/golive reply kitd 10 hours agoparentLooks nice. I've tried (a couple of times) to build something similar to this, and to OP's project, but it's never worked out. Golive looks the nearest to the ideal in my head. reply Terretta 4 hours agoprev“Letting a hundred flowers blossom and a hundred schools of thought contend is the policy for promoting progress in the arts and the sciences and a flourishing socialist culture in our land.” Hand-coding HTML is three decades in, like using computer languages from the 1970s in the 2000s. There are so many of these experiments the last few years, could any be what replaces HTML5? If not, why not? What would be enough better? Most likely not just another form of the same. reply ocean_moist 12 hours agoprevBackend devs rejoice as they can now build dashboards without leaving go. reply politician 5 hours agoprevTemplate functions are a better approach, IMO. [1] https://templ.guide/ reply jasonlotito 5 hours agoprevI remember the days when one of the complaints about PHP was people mixing PHP and HTML together. And no, it was mixing PHP and HTML together. That’s it. Don’t try to tack on anything else to the conversation. And we’ve been going back to it for some time now. This doesn’t even map to HTML naturally! I’m mean fine have fun with your libraries but the amount of excitement for something like this? Amazing. reply ilrwbwrkhv 14 hours agoprev [–] Beautiful! I don't use Go anymore (moved to Rust) but this looks pristine. reply sureglymop 12 hours agoparent [–] I love web dev using rust! I use sveltekit and proxy all requests to /api to a rust backend (though it works with any SSR framework). This is nicely configurable for the vite dev server. Then I basically have all the business logic on the rust side and all the presentation logic on the SSR side to get the best of both worlds. This gives me two things: 1. A development experience with instant visual feedback for the frontend. Even more so when using tailwind. 2. A stable, safe and performant backend. The downside is that a node process has to be running and doing the ssr, though that is an okay trade off for me because my project is mainly the api, having a reference implementation of the frontend is just a nice extra. I've also experimented with implementing the reverse proxy in rust itself and using a unix socket and other IPC mechanisms to push the data to the SSR layer. reply klabb3 9 hours agorootparent [–] > I love web dev using rust! I use sveltekit and proxy all requests to /api to a rust backend I think this most people would call this backend-, api- or service development. Especially if your api endpoint does not do anything web specific except http. Anyway, how do you share types between the backend and frontend? Are you rawdogging json? reply j45 5 hours agorootparent [–] Rust could probably generate the HTML. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A developer is working on a minimal stack combining Golang and htmx to enhance features like components and improve syntax for complex JavaScript.",
      "The project aims to provide a lighter alternative to heavy frameworks while addressing the low-level nature of htmx.",
      "This initiative could be beneficial for other developers seeking a streamlined and efficient development stack."
    ],
    "commentSummary": [
      "A developer introduced \"htmgo,\" a minimal stack combining Golang and HTMX, aimed at simplifying the creation of reusable components and improving syntax.",
      "The project has sparked discussions among developers about the merits of integrating backend languages with HTMX and the benefits of using Golang for lightweight web development.",
      "The community is comparing \"htmgo\" with other tools and frameworks like Hotwire, Gomponents, and various templating engines, highlighting a growing interest in efficient, server-side web development solutions."
    ],
    "points": 144,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1727559258
  },
  {
    "id": 41687739,
    "title": "Flexible RISC-V Processor: Could Cost Less Than a Dollar",
    "originLink": "https://spectrum.ieee.org/flexible-risc-v",
    "originBody": "SEMICONDUCTORS NEWS A Bendy RISC-V Processor The new 6-mW open-source plastic chip can run machine learning tasks and operate while bent around a pencil CHARLES Q. CHOI25 SEP 20243 MIN READ Charles Q. Choi is a Contributing Editor for IEEE Spectrum. A new RISC-V chip loses only about 4 percent of its performance when bent like this. PRAGMATIC SEMICONDUCTOR",
    "commentLink": "https://news.ycombinator.com/item?id=41687739",
    "commentBody": "Flexible RISC-V Processor: Could Cost Less Than a Dollar (ieee.org)131 points by rbanffy 4 hours agohidepastfavorite43 comments londons_explore 3 hours agoNearly any uses for flexible electronics would also be satisfied by sufficiently small electronics such that lack of flexibility doesn't matter. Eg. rather than having every pixel in your flexible screen be flexible, you make each pixel rigid and have the joints between pixels flexible. In this case, this design is based on SERV, which uses ~2100 gate equivalents, which in a recent tech node would be 40 um^2. That means you could fit a 10x10 grid of these in a single pixel on an iphone screen. I really can't think of a use case where a region 1/100th of an iphone screen pixel being rigid would be a problem. reply alted 1 hour agoparentIgnoring flexibility and cost/performance, this may be a sign that rapid chip fab turnaround times are possible. These were made by Pragmatic Semiconductor [1], who claim they can make chips within 48 hours and deliver within 4 weeks (likely due to their use of unconventional materials). Traditional silicon fabs, including trailing-edge foundries and TSMC, take 2-9 months. I do wish they'd emphasized this instead of flexibility. [1] https://www.pragmaticsemi.com/ reply IshKebab 1 hour agorootparentYeah but traditional silicon fabs aren't making 12k gate chips. reply Teever 45 minutes agorootparentWhat's the turn around time on 12k gate chips from a traditional fab? reply dragontamer 25 minutes agorootparentJust googling really quick: the Lattice Semiconductor LFE5U-12 is a 12k-LUT FPGA (and a LUT is way more flexible than a gate). So realistically, if you need fully custom digital logic, you'd buy LFE5U-12 instead and program that. So that's $16 FPGA from widely available distributors (like Digikey) who likely can afford 1 or 2 day shipping. ------------- Custom chip design for a flex-circuit is interesting, but only if you have substantial analog parts that cannot be easily implemented by an FPGA. reply addaon 2 hours agoparentprev40 um^2 might cover the logic (although I think your logic transistor count is a factor of three low; and something like this is most likely to be made on a 45 nm or bigger process), but doesn’t cover IO pads. If you’re willing to wire bond directly to a flex circuit you may be able to use pads on to order of 50 um x 50 um (each! Likely need 6 or 8 pads to be useful), but that’s a hell of a process, and you’d have to encapsulate afterwards, adding bulk. If you want to flip-chip mount it’s pretty hard to go under 1 mm x 1 mm for a useful microcontroller, although there’s some stuff out there at 600 um x 600 um or so from memory — but pad sizes under 300 um then bump up your resolution requirements for the flex circuit you’re bonding to. reply ChuckMcM 38 minutes agoparentprevSome questions you might consider which would help you to think of some use cases; 1) How would wiring to you processor work? 2) How many flexible compute applications are currently using just really small processors? 3) Given that Pragmatic has raised a lot of money, what was it in their use case that the investors thought would make a better product? 4) Besides flexibility, are there other requirements in this product space? 5) Given that you've just imagined a product with a flexible screen but solid pixels, does this exist on the market? Are there flexible screens on the market? How do those screens choose to implement flex versus the idea you have proposed? What factors might make their choices better (or worse) than the idea you proposed? I'm not being critical here, I think you start with an excellent starter question which is \"Would the requirements be satisfied by sufficiently small electronics such that [the] lack of flexibility [in the electronics] doesn't matter?\" The trick then is to see if you can see how other people who invested time and money in answering either that, or a closely adjacent, question answered it. When you do that you'll get to see what they thought the overall requirements were vs the technology they picked, and perhaps it might inform if the Pragmatic solution would be a better fit or the 'tiny electronics' solution would be a better fit. I'll be the first to admit that I'm 'weird' in that I really do enjoy going down these sort of engineering optimization rabbit holes to develop a better understanding of what problems various proposed solutions are trying to solve. reply kibwen 3 hours agoparentprevAt a certain threshold, miniaturization of electronics can become counterproductive for space applications. The amount of radiation received per unit of area remains constant but our transistor density keeps increasing, which means that every individual event threatens to wreak an increasing amount of havoc (e.g. more bits flipped in RAM per cosmic ray). Considering the increasing amount of error correction and redundancy needed to counter this, we may reach a practical floor on transistor density for such domains. reply synthos 2 hours agorootparentIt's also, if not more so, a factor of transistor voltage. 1.1V transistors are less prone to upset events than 0.7V. It's possible (assumption, here) that some 3+ volt circuits are still used for critical components of the system reply adrian_b 20 minutes agorootparentIt would be possible to use much higher supply voltages if silicon were replaced with a semiconductor material having a higher band gap. The main obstacle that has prevented this until now is that in all high-bandgap semiconductors it is easy to make only transistors of a single polarity, not transistors with both polarities, as required for CMOS logic. For high circuit densities it would be difficult to replace the CMOS logic, because all alternatives have higher idle power consumption. reply spwa4 3 hours agorootparentprev... which is a huge problem for solar panels ... but why would it matter for microprocessors? reply undersuit 1 hour agorootparentYou don't want transistors operating under the influence of outside forces. More than just having a bit flip in your data, what if one of the control lines in the CPU flips and the entire instruction stream gets corrupted... while you're trying to perform orbital maneuvers. reply mlyle 2 hours agoparentprevYou would need to connect wires to that little 40 um^2 mote to do anything, though, which in practice makes the rigid places needing strain relief a lot larger. reply zozbot234 2 hours agoparentprevLeading-edge fab nodes are way too costly for this kind of use. Specialty, low-volume chips are the domain of trailing-edge tech nodes, sometimes even at the μm level. Besides as some sibling comments mentioned, contact pads for off-chip wires would get so big as to ultimately take up most of the area, so there would be no real advantage to using the finer nodes. reply pclmulqdq 2 hours agorootparentMost microcontrollers today are using 40-90 nm processes. That's not the micron level at all. Chips that need current-handling capabilities or have weird needs will use bigger process nodes. This is a big part of why automotive electronics use old nodes. reply Brian_K_White 1 hour agoparentprevWhat are the fab requirements of the two techs? If the ffc version can be manufactured with as basic tech as ffc, then that is huge. Also bonding small rigid things to flexible things is never actually the same as a flexible thing, in several different ways. These are not equivalent even if you can manage to use either one for some use cases by accepting various compromises. reply wslh 3 hours agoparentprevSo, nothing particularly interesting here? When I first saw 'flexible' I immediately thought about balancing a chip's specifications, not its material flexibility! reply dragontamer 3 hours agorootparentFlexible circuits are interesting and worthy of discussion. Really, the whole process here is fascinating to me. There's been a lot of progress in flex circuits over this recent decade. None of it is electrically or computationally new. It's 1980s tech from a computation perspective. But mechanically?? Being able to weave circuits seamlessly into clothes, tapestry, and such is pretty cool. If only for the cosplay / costume designers but that's still a pretty / beautifully kind of display (especially with a few fiber optics to move lights around). One of the interesting electro-mechanical issues is that flex circuits are necessarily thin, making grounding / return currents exceptionally consistent. On the downside however, solid planes / ground fills are bad for flexibility, so you apparently need to make a ground-grid instead of ground-fill. Very interesting tech overall. Even if it's applications are quite small right now. reply grayhatter 2 hours agorootparentprevIt's funny, I thought the exact opposite. > Flexible... isn't that the point of any central processing unit, to be able to handle many differing types of work? Oh, pliable? that's cool, I wonder how that works? reply dragontamer 3 hours agoprev> Each Flex-RV microprocessor has a 17.5 square millimeter core and roughly 12,600 logic gates. The research team found Flex-RV could run as fast as 60 kilohertz while consuming less than 6 milliwatts of power. This is pretty bad from a power efficiency perspective. KHz speed silicon microcontrollers are closer to ~dozens of microwatts, about two decades of magnitude less power than this flex-circuit. Furthermore, small silicon dies can be placed into flexPCBs. I'm sure a flexchip has more flexibility than a solid silicon die on a flex board but there's a question of how much flex is actually needed in products? --------- Still, I recognize that a fully functional CPU on this process is a major achievement. I'm just trying to think of a commercial application, that's all. reply mystified5016 3 hours agoparentE-textiles, probably. There's a small, but real, niche trying to put circuitry onto/into fabrics. Traditional flex PCBs get you pretty close, but any large IC creates a limited bend radius and a stress point that will fail very quickly. Using lots and lots of tiny dice for this would technically work, but it's extremely impractical unless you're building your widget by the millions. But yes, the potential applications are quite limited. Flexible electronics just aren't as useful as people think. I guess it just sounds really cool, like transparent LCDs. reply dragontamer 3 hours agorootparentThe thin nature of flex circuits have interesting implications for capacitance / parasitic inductance. I've been told that flex circuits are far easier to pass EMC testing due to the physically closer ground/reference return path. Of course: with the caveat that solid planes of copper are not flexible and will crack. So ground-grid are the best you can do. But physically closer / physically thinner circuits have niche advantages. ------- But I'm talking about traditional silicon dies on a flexpcb. This article is about printing some kind of flexible chip to begin with. It's cool and relatively new, but silicon + flexpcb will be the main technique for e-textiles (and other flex applications) for the near future. Still, one more tool in the toolbox for electrical engineers. Niche as it is, it's still a tool with likely some good application somewhere. reply shadowpho 6 minutes agorootparent>I've been told that flex circuits are far easier to pass EMC testing That’s not correct. It really depends what application, industry and type of testing. I would say generally it’s the opposite due to worse shielding properties (and worse pi), but it’s a huge oversimplification that’s extremely dependent on application and testing type reply vpribish 48 minutes agorootparentprev\"a small, but real, niche\" - is it though? It's been an intriguing notion since the time of the dinosaurs, but what is an actual problem that it solves? I've never seen any textile electronics that delivered more than a novelty. reply dragontamer 33 minutes agorootparentA lot of video game characters, especially SciFi ones, have glowing clothes of some kind with mesmerizing patterns. The easiest way to create this effect is a combination of etextiles, LEDs and maybe some fiberoptics (which are also flexible enough to be woven into clothing). Recreating video game characters in real life is a niche. Cosplay. And there's also e-Fashion that is beyond just copying costumes from video games. You'll still need to hide the battery box somewhere, and likely also the LEDs are inflexible, but by making more of the circuit etextile / flexible, it allows you to hide the electronics in the clothing itself, woven into the clothes and properly integrated. ------------ An almost fully rigid design with a few flexible parts (ex: the hinge of the Motorola Fold) is also hot and fashionable right now. Motorola RAZR (the new foldable screen one) needs a hinge, and the electronics that are integrated into the hinge need to be as flexible as the hinge. Adding little bits of flexibility, especially to space constrained applications like Phones, does add new useful design features above and beyond \"novelty\" status, IMO anyway. reply kragen 2 hours agoprev60 kilohertz on 6 milliwatts sounds pretty bad (that's 100 milliwatts per megahertz and so 20 milliamps per megahertz if we assume 5 volts, while 0.06 milliamps per megahertz is common for low-power processors) but it's actually far, far worse than it sounds because serv is bit-serial, requiring, i think, 32 cycles per instruction. so you're looking at something like 5000 times the energy consumption of existing off-the-shelf microcontrollers the suggested price of a dollar is about 10x worse than something like the py32, ch32v003, or pmc150, which are also faster and more power-efficient that doesn't mean this is bad research! it just means it isn't yet developed to a state where there's likely to be a market for it. it's very helpful to know that serv occupies 12600 gates, for example, and that the flex-rv process provides 720 gates per square millimeter. it's very plausible you could design something useful with it that had 600 gates, was less than a square millimeter, used 300 microwatts at 60 kilohertz, and cost five cents, for example; that's a niche that silicon photolithography is struggling to fill because of high per-chip costs. you could fit a 6502 into twice that another potentially interesting niche is low power density; for implanting into your body you don't want hot spots that can burn your tissues (though you'd have to encapsulate the igzo behind something biocompatible) reply worik 1 minute agoprevVery cool. As Moore's Law runs out of steam it is time for the low end applications of computers to shine. Lots of comments here saying how [relatively] inefficient this is, that utterly miss the point. Putting cheap, good enough, CPUs into all sorts of places the \"efficient \" processors cannot go is going to revolutionise all sorts of applications This is not unique, but representative of its class reply eric__cartman 3 hours agoprev> Performance varied between a 4.3 percent slowdown to a 2.3 percent speedup depending on the way it was bent. I have practically zero knowledge on the physics behind semiconductors to try to think why this could occur but I find it fascinating nonetheless. reply dragontamer 3 hours agoparentMy expectation is that the core clock circuit has its capacitance and/or inductance change, this changing the timing of the clock. +/-5% is a region where everything in the digital domain probably still works. Your rise/fall time and dead-time / other critical timings need to be robust against some degree of variability. Transistors can have rather wide manufacturing variability after all (certainly wider than 5%). So everything still works but the core clock is changing. Which btw, happens in traditional silicon circuits as they heat up or cool down. A low precision RC oscillator changing by 5% or so between 20C and 100C is within expectations. I'm fact, a -50%/+100% change wouldn't surprise me. -------------- Old var-caps (variable capacitors) by twisting them tighter or looser. No joke. So that's where my expectation that they've changed the capacitance of some core element that controls an important clock. reply adrian_b 3 minutes agorootparentMany resistive materials, especially those that are semiconductors, have changes of resistivity caused by mechanical strain. This so-called piezoresistive effect is frequently used for measuring the deformations of various objects, by attaching piezoresistive wires to them, which can measure for instance the amount of bending of the object. Such a flexible integrated circuit might also have changes in the resistance of the transistor channels or of the interconnection traces, which will change the maximum permissible clock frequency. If an RC oscillator is used to generate a clock signal, its frequency will change with the bending of the circuit, more likely due to variations of the resistance than of the capacitance, because it is not likely for the bending to cause large variations in the thickness of the dielectric of the capacitors or in the area of the electrodes, even if that is also possible. The variable capacitors whose capacitance is changed by twisting have this behavior because their electrodes overlap only partially and the twisting changes the area of the overlapping region. No such thing happens when twisting or bending a normal capacitor. reply crest 1 hour agoparentprevNeither do I, but I can tell you if you manage to bend a normal CPU die the performance loss is 100% (because you broke it). reply gradschool 1 hour agoprevAny ideas on why they'd use NMOS [1] instead of CMOS if they're aiming for low power? Too many layers? My (amateur, outdated, and probably wrong) recollection is that CMOS dissipates very little power except when switching, but not so for NMOS. [1] https://www.pragmaticsemi.com/app/uploads/2023/07/Pragmatic-... reply dragontamer 59 minutes agoparentCMOS requires very tight tolerances for the PMOS + NMOS transistors to cancel each other out exactly. Otherwise it doesn't work at all. In particular, you need to ensure that the PMOS and NMOS turn on at the same voltage, otherwise you risk just shorting Vcc to Vss (aka: Power to Ground). NMOS was common in the 1970s before CMOS on silicon was figured out. I'm surprised to hear that this circuit is old-school NMOS, but I probably shouldn't be, as the CMOS step took a lot of research and effort back then.... If we're still at NMOS stage of production on this process, then its probably more relevant to think of analog-based designs. CMOS seems necessary if anyone is to achieve low-power modern-like designs. NMOS was still core to a lot of older chips though, so digital logic still can work on that. But the power consumption will be necessarily huge in comparison to CMOS. reply ddtaylor 48 minutes agoprevThe positioning of this product is strange to me. The features and specs of the product don't seem very impressive, as others have pointed out, and the overall tone of the writing suggests someone who found something and is looking for what drawer it goes in. reply vitiral 1 hour agoprevThis is super exciting, I love to see advances in low temperature semiconductor manufacturing. HOWEVER > The research team found Flex-RV could run as fast as 60 kilohertz while consuming less than 6 milliwatts of power. Those are TERRIBLE specs compared to silicon. Similar microcontroller specs are 1,000x faster at similar power consumption. reply EligibleDecoy 3 hours agoprevWhat’s interesting to me is that it loses 4% efficiency when bent. Like, I get why there’s some loss because of parasitic capacitance/inductance etc but 4% seems like… not very much? reply Someone 3 hours agoparentI guess it helps a lot that it’s running at 60kHz. https://en.wikipedia.org/wiki/Parasitic_capacitance#Effects: “At low frequencies parasitic capacitance can usually be ignored, but in high frequency circuits it can be a major problem.” reply Someone 3 hours agoprev> The research team found Flex-RV could run as fast as 60 kilohertz while consuming less than 6 milliwatts of power. They don’t give all details, but I think it’s safe to say there’s work to do w.r.t. performance/Watt, probably more so given that the CPU seems to be bit serial (https://github.com/olofk/serv), which I think means an addition takes 32 cycles. reply therealcamino 39 minutes agoparentFrom the linked Nature article: \"The 5.8 mW power consumption is predominantly static (99%) because of the resistive pull-up logic.\" reply ForestCritter 2 hours agoprevBecause wrapping it around a pencil is clearly a benefit(: reply Conscat 58 minutes agoparentFlexible PCBs are convenient to embed in fabric. reply yapyap 3 hours agoprev [–] Can’t wait to never hear about this again /s reply joelignaatius 3 hours agoparent [–] What's the smallest commercially available electronic and can it be inserted into the brain? Why am I having headaches? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A new 6-mW open-source plastic chip based on the RISC-V architecture can perform machine learning tasks while being flexible enough to bend around a pencil.",
      "The chip loses only about 4 percent of its performance when bent, showcasing its robustness and potential for flexible electronics applications.",
      "This development highlights significant advancements in the field of flexible semiconductors and open-source hardware."
    ],
    "commentSummary": [
      "A recent IEEE article highlights a flexible RISC-V processor that could cost less than a dollar, based on the SERV design.",
      "Pragmatic Semiconductor claims they can produce these chips within 48 hours, significantly faster than traditional silicon fabrication processes.",
      "Although the processor runs at 60 kHz and consumes 6 milliwatts of power, it could be valuable for niche applications such as e-textiles and flexible electronics."
    ],
    "points": 132,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1727620927
  },
  {
    "id": 41685326,
    "title": "NASA is selling a brand-new Moon rover: Never used, one previous owner",
    "originLink": "https://www.economist.com/science-and-technology/2024/09/25/nasa-is-selling-a-brand-new-moon-rover",
    "originBody": "Science & technologyVIPER NASA is selling a brand-new Moon rover Never used, one previous owner photograph: nasa Sep 25th 2024 Share N asa has big plans for the Moon. By the end of the decade, it wants to send humans back to the lunar surface. Before then, though, it intends to send probes to look for ice at its south pole. This ice carries enormous scientific value. It could shed light on how Earth acquired its liquid water; it is also ripe for conversion into rocket propellant. Science & technology September 28th 2024 Immune therapy shows promise for asthma, heart disease—and even ageing New technologies can spot pesky leaks in water pipelines NASA is selling a brand-new Moon rover The world’s oldest cheese sheds light on ancient Chinese culture Share Reuse this content the economist today Handpicked stories, in your inbox A daily newsletter with the best of our journalism Sign up Yes, I agree to receive exclusive content, offers and updates to products and services from The Economist Group. I can change these preferences at any time. More from Science & technology Immune therapy shows promise for asthma, heart disease—and even ageing Making treatment quick and affordable will be the challenge New technologies can spot pesky leaks in water pipelines Across Europe, nearly a quarter of water goes to waste The world’s oldest cheese sheds light on ancient Chinese culture What genetic analysis of a 3,500-year-old sour goat’s cheese from Xinjiang reveals China’s AI firms are cleverly innovating around chip bans Tweaks to software blunt the shortage of powerful hardware Most electric-car batteries could soon be made by recycling old ones Mining for raw materials may peak by the mid-2030s New battery designs could lead to gains in power and capacity Researchers are looking beyond the cathode",
    "commentLink": "https://news.ycombinator.com/item?id=41685326",
    "commentBody": "NASA is selling a brand-new Moon rover: Never used, one previous owner (economist.com)106 points by helsinkiandrew 12 hours agohidepastfavorite52 comments nimbius 5 minutes agoI'm gonna have to call in my NASA moon rover expert. Best I can do is $40. reply helsinkiandrew 12 hours agoprevhttps://archive.ph/2QINr reply bilekas 1 hour agoparentI just got a very hard block from this link from the `Ministero dell'Interno`... reply veggieWHITES 33 minutes agorootparentScary stuff... Condolences :/ Try TOR? reply bilekas 18 minutes agorootparentNo need, just a notice to others that would maybe prefer not to support such 'hosting' services. It was not trademark/copyright related I can say. reply tough 0 minutes agorootparenthttps://en.wikipedia.org/wiki/Archive.today amelius 6 hours agoprevHere are the keys. And by the way, we parked it on the Moon. reply woleium 5 hours agoparentA fully functioning rover on the moon would be worth significantly more than on earth, no? reply freedomben 4 hours agorootparentYes, but only if it also comes with all the communication equipment. If it's fully functional, but you can't talk to it, probably not worth anything. reply hshshshsvsv 1 hour agorootparentI want to know what kind of mental models you used to arrive at that conclusion. Curious. reply iambateman 4 hours agorootparentprevI think the collectible value of “only rover on the moon” would be extraordinary regardless of functionality. reply trothamel 2 hours agorootparentIn 1993, the price of a non-functional lunar rover was $68,500. That's how much Richard Garriott (son of astronaut Owen Garriott, creator of the Ultima game series, and after that, private astronaut that spent 12 days at the ISS) spent to purchase the rights to Lunokhod 2 and the Luna 21 lander. reply wongarsu 3 hours agorootparentprevIt would be the ninth. The honor of the first lunar rover goes to the Soviets. And in recent times China, India and Japan have all successfully deployed rovers on the moon. If it had been launched fast enough it could have become the first American (self-driving) rover on the moon. And still among the first ten rovers. That would be worth something to some collector reply metaphor 9 hours agoprevOutsider looking in, this article[1] published circa Jul 2022 appears to add some historical color to the status quo...it all seems related to CLPS[2] failures surrounding a few involved primes[3][4]. In any case, sure does look like a nasty Nunn-McCurdy breach that NASA has on their hands. [1] https://www.nasa.gov/solar-system/nasa-replans-clps-delivery... [2] https://en.wikipedia.org/wiki/Commercial_Lunar_Payload_Servi... [3] https://en.wikipedia.org/wiki/Astrobotic_Technology [4] https://en.wikipedia.org/wiki/Masten_Space_Systems reply philipwhiuk 6 hours agoparentThat's not the case. The rover itself, made by NASA, experienced cost growth. This is a longstanding problem in science missions and so, in an era of fiscal tightening, they chose not to add more money to VIPER. \"Nunn-McCurdy\" is weapons regulation. It doesn't apply here directly, but there are Congressional reporting requirements for it. reply 0xffff2 48 minutes agorootparentIt's absolutely the case. The rover was built in the middle of Covid. Given the challenges that created, the cost growth on the rover itself was quite reasonable. The problem right now is that NASA HQ has no confidence in the CLPS contractor building the lander, but it's not politically correct to throw a private company under the bus. reply Y_Y 11 hours agoprevHow many moons must a moon rover before you can call it a rover? reply cs02rm0 6 hours agoparentHow many moons must a moon rover rove over before you can call it a rover? Over. reply cookiengineer 4 hours agorootparentHow many moons must a moon rover rove over until a range rover calls the moon rover the rover of rovers that rovered over the moon? reply vasco 10 hours agoparentprevI think you're missing a rover, \"(...) must a moon rover rover before (...)\" reply echoangle 7 hours agorootparentWouldn’t it be \"(...) must a moon rover rove before (...)\"? Isn’t the verb to „rover“ „rove“? reply mgsouth 19 minutes agoparentprevWhile your comment would normally be considered \"humor\", and thus automatically subject to downvote, the Committee has noted that it seems, based on the numerous replies, to have tapped into an under-served concept in an upscale demographic segment. Even better, the segment appears to have dubious taste. It got legs, baby. Congratulations, and enjoy your upvote. We have taken the liberty to pass this along to a VC manager who is very interested in discussing future opportunities with you. Please be prepared to discuss specifics of the LLM we, ah, sort of assumed was involved. reply grues-dinner 11 hours agoparentprev> Just wait a sodding minute! You want a question that goes with the answer for 42? Well, how about \"What's six times seven?\" Or \"How many Vogons does it take to change a lightbulb?\" Here's one! \"How many roads must a man walk down?\" One more for the list! reply pxeger1 11 hours agoparentprevHow much moon could a moon rover rove if a moon cover could rove moon? reply interludead 9 hours agorootparentIf a moon rover could rove as much moon as a moon rover could, that moon rover would rove all the moon it could rove! reply ax0ar 8 hours agorootparentIf that moon rover roved all the moon it could rove, then the moon it roved would be the roved moon that no other moon rover could hope to rove. reply woleium 5 hours agorootparentit saddens me to see this site devolve into meaningless reddit like slop. Please do your part to help keep the signal to noise ratio up. reply jerkstate 3 hours agorootparentdownvote off-topic content and move on reply davidhunter 10 hours agoparentprevThe answer my friend, is rovin’ in the wind reply CarRamrod 10 hours agoparentprevMoon Rover Wider than a mile reply tripa 6 hours agorootparentWider than a mole? reply labster 9 hours agorootparentprevI’m launching you in style one day reply Cockbrand 8 hours agoparentprevSee also: Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo. https://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffal... reply rootsudo 6 hours agoparentprevYou mean moon pie isn’t made of moon? reply qingcharles 3 hours agorootparentNo, it's a cheesecake. reply stavros 9 hours agoparentprev\"How many moons must a moon rover rover before you can call a rover a moon rover?\" reply seydor 9 hours agoprevstill looks better than the cybertruck reply glitchc 6 hours agoparentThe OG EV truck. reply interludead 9 hours agoparentprevAnd the moon rover is designed to handle actual craters reply nolist_policy 6 hours agorootparentAt 0.166g thought. reply bmitc 1 hour agoprev\"No low balls. I know what I have.\" reply theflyingelvis 1 hour agoparentDoes the ac blow cold? reply highwayman47 6 hours agoprev\"For sale: baby shoes, never worn.\" reply hatsix 1 hour agoparentHeh, I mentioned this to my wife a while back, she said that we've had a pair of shoes since our first (of three) that had never been worn, and that shoes at our second hand store are often labeled that way. Turns out, baby shoes are aesthetic only, baby's feet aren't really foot-shaped yet so they're hard to put on, and if they're moving, they're crawling, and shoes make it impossible to use their feet while crawling. The shoes were either a gift, or something she bought before the baby was born... So that story made her think of the naivety of pre-parents and chuckle, I had to explain why people found it sad, and her response was \"those people have never tried to put baby shoes on a baby\". Which is to say, I think that her take makes this even more apt response... the people getting sad about this have never tried to put a rover on the moon. reply thfuran 1 hour agorootparentI tried, but I'm not tall enough. And the big ones are really heavy. reply blackoil 10 hours agoprevMeh. I have few Mars, Europa rover in case anyone is interested. reply hristov 5 hours agoprev [–] It is very suspicious that the companies bidding are NASA contractors. This may be a case of corruption. I.E., NASA sells the moon rover for 85 M and then pays 200 M for the moon rover to do something for them for future NASA missions. reply KyleBerezin 4 hours agoparent\"It's petty suspicious that the only companies trying to buy this mining equipment are other mining companies.\" Did you expect Walmart to make a bid on it? reply freedomben 4 hours agoparentprevIn general, I'm with you about being skeptical. However, in this case, I don't think there is anything weird going on, at least not with the information we have. I've never worked at one of these contractors who service NASA, but in the past I worked for a large defense contractor who in part provided some pretty high-tech stuff to the Air Force among others. One of the things I worked on specifically was the communications computer for the Predator drone. It was the piece of equipment that received all command and control from the ground station, and sent the video back from the drone camera. The actual plane itself was made by a separate company who was more specialized in that aspect. We were very proud to work on Predator, and we absolutely would have loved to have bid on something like that. Even though we made part of it, we didn't have a complete unit. Had we have won a bid to get one, it would have gone into a glass case in our visitor area, where we would proudly display it like a trophy. I would not be surprised in the least if that is what these bidders have in mind. Consider how much fun it would be if you are showing up for a job interview and you see in a glass case in the lobby an actual brand new moon Rover! I know that would be pretty cool for me. I do tend to love museums though, so maybe I'm not the best test case. reply II2II 3 hours agorootparentStipulations include performing the science mission and releasing the data. While there the cool factor would be orders of magnitude greater, there are also considerable commitments and risk involved. So the question is: what other benefits would be involved? I'm sure there would be many, particularly if you could prove that you could launch and operate such missions, but I doubt that having a museum piece would be one of them. (And you would only have that museum piece if there is a twin that remains on Earth, which seems to be common for NASA missions.) reply wongarsu 3 hours agoparentprevEveryone who has the capability to land this on the moon is a NASA contractor or a competing space agency. And I don't know how congress would feel about selling this to Roskosmos, the Chinese CNSA or Indian ISRO. Maybe ESA. Of course somebody else could buy it and pay somebody to put it on the moon. But that seems unlikely given the provision that findings have to be shared. For companies that sell moon landings it's good marketing, for anyone else there wouldn't be much upside reply BolexNOLA 5 hours agoparentprev [–] This is some pretty heavy speculation based on very little information. Saying \"maybe a case\" is really doing a lot of heavy lifting here. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NASA aims to return humans to the Moon by the end of the decade, starting with probes to the lunar south pole to search for ice, which holds scientific and practical importance.",
      "Recent advancements include immune therapies for asthma, heart disease, and aging, new tech for detecting water pipeline leaks, and the discovery of ancient cheese in China.",
      "Innovations in AI and electric-car battery recycling are also noteworthy, showcasing ongoing progress in various tech fields."
    ],
    "commentSummary": [
      "NASA is selling a new, unused Moon rover, sparking discussions about its value and historical context on a forum.",
      "Users debate its worth, share technical details, and humorously comment on the topic, while some express concerns about off-topic content.",
      "The conversation also highlights potential corruption in NASA's contractor bidding process and the challenges of building during COVID."
    ],
    "points": 106,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1727591414
  },
  {
    "id": 41685689,
    "title": "Feldera Incremental Compute Engine",
    "originLink": "https://github.com/feldera/feldera",
    "originBody": "Feldera is a fast query engine for incremental computation. Feldera has the unique ability to evaluate arbitrary SQL programs incrementally, making it more powerful, expressive and performant than existing alternatives like batch engines, warehouses, stream processors or streaming databases. 🔥 Incremental Computation Engine Our approach to incremental computation is simple. A Feldera pipeline is a set of SQL tables and views. Views can be deeply nested. Users start, stop or pause pipelines to manage and advance a computation. Pipelines continuously process changes, which are any number of inserts, updates or deletes to a set of tables. When the pipeline receives changes, Feldera incrementally updates all the views by only looking at the changes and it completely avoids recomputing over older data. While a pipeline is running, users can inspect the results of the views at any time. Our approach to incremental computation makes Feldera incredibly fast (millions of events per second on a laptop). It also enables unified offline and online compute over both live and historical data. Feldera users have built batch and real-time feature engineering pipelines, ETL pipelines, various forms of incremental and periodic analytical jobs over batch data, and more. 🎯 Our defining Features Full SQL support and more. Our engine is the only one in existence that can evaluate full SQL syntax and semantics completely incrementally. This includes joins and aggregates, group by, correlated subqueries, window functions, complex data types, time series operators, UDFs, and recursive queries. Pipelines can process deeply nested hierarchies of views. Fast out-of-the-box performance. Feldera users have reported getting complex use cases implemented in 30 minutes or less, and hitting millions of events per second in performance on a laptop without any tuning. Datasets larger than RAM. Feldera is designed to handle datasets that exceed the available RAM by spilling efficiently to disk, taking advantage of recent advances in NVMe storage. Strong guarantees on consistency and freshness. Feldera is strongly consistent. It also guarantees that the state of the views always corresponds to what you'd get if you ran the queries in a batch system for the same input. Connectors for your favorite data sources and destinations. Feldera connects to myriad batch and streaming data sources, like Kafka, HTTP, CDC streams, S3, Data Lakes, Warehouses and more. If you need a connector that we don't yet support, let us know. 💻 Architecture The following diagram shows Feldera's architecture ⚡ Quick start with Docker First, make sure you have Docker Compose installed. Next, run the following command to download a Docker Compose file, and use it to bring up a Feldera Platform deployment suitable for demos, development and testing: curl -L https://github.com/feldera/feldera/releases/latest/download/docker-compose.yml\\ docker compose -f - --profile demo up It can take some time for the container images to be downloaded. About ten seconds after that, the Feldera web console will become available. Visit http://localhost:8080 on your browser to bring it up. We suggest going through our tutorial next. Our Getting Started guide has more detailed instructions on running the demo. ⚙ Running Feldera from sources To run Feldera from sources, first install all the required dependencies. This includes the Rust toolchain (at least 1.75), Java (at least JDK 19), Maven and Typescript. After that, the first step is to build the SQL compiler: cd sql-to-dbsp-compiler ./build.sh Next, from the repository root, run the pipeline-manager: cargo run --bin=pipeline-manager --features pg-embed As with the Docker instructions above, you can now visit http://localhost:8080 on your browser to see the Feldera WebConsole. 📖 Documentation To learn more about Feldera Platform, we recommend going through the documentation. Getting started UI tour Tutorials Demo SQL reference API reference 🤖 Benchmarks Feldera is generally faster and uses less memory than systems like stream processors. Our Benchmarks are performed by our CI on every commit that goes in main. If you want to see all the results, please visit benchmarks.feldera.io. 👍 Contributing The software in this repository is governed by an open-source license. We welcome contributions. Here are some guidelines. 🎓 Theory Feldera Platform achieves its objectives by building on a solid mathematical foundation. The formal model that underpins our system, called DBSP, is described in the accompanying paper: Budiu, Chajed, McSherry, Ryzhyk, Tannen. DBSP: Automatic Incremental View Maintenance for Rich Query Languages, Conference on Very Large Databases, August 2023, Vancouver, Canada Here is a presentation about DBSP at the 2023 Apache Calcite Meetup. The model provides two things: Semantics. DBSP defines a formal language of streaming operators and queries built out of these operators, and precisely specifies how these queries must transform input streams to output streams. Algorithm. DBSP also gives an algorithm that takes an arbitrary query and generates an incremental dataflow program that implements this query correctly (in accordance with its formal semantics) and efficiently. Efficiency here means, in a nutshell, that the cost of processing a set of input events is proportional to the size of the input rather than the entire state of the database.",
    "commentLink": "https://news.ycombinator.com/item?id=41685689",
    "commentBody": "Feldera Incremental Compute Engine (github.com/feldera)104 points by gzel 10 hours agohidepastfavorite34 comments ZiliangXK 13 minutes agoTimeplus proton OSS https://github.com/timeplus-io/proton does similar thing but with powerful historical query processing as well. reply shuaiboi 8 minutes agoprevwould something like dbsp support spreadsheet style computations? Most of the financial world is stuck behind spreadsheets and the entire process of productioinizing spreadsheets is broken: * Engineers don't have time to understand the spreadsheet logic and translate everything into an incremental version for production. * Analysts don't understand the challenges with stream processing. * SQL is still too awkward of a language for finance. * Excel is a batch environment, which makes it hard to codify it as a streaming calculation. If I understand correctly, your paper implies as long as there is a way to describe spreadsheets as a Zset, some incremental version of the program can be derived? Spreadsheets are pretty close to a relational table, but it would be a ZSet algebra on cells, not rows, similar to functional reactive programming. So dbsp on cells would be incremental UDFs, not just UDAFs? thoughts?? reply rebanevapustus 1 hour agoprevBig fan of Feldera here. I would advise everybody to stay clear of anything that isn't Feldera or Materialize. Nobody aside from these guys have a IVM product that is grounded on proper theory. If you are interested in trying out the theory (DBSP) underneath Feldera, but in Python, then check this out: https://github.com/brurucy/pydbsp It works with pandas, polars...anything. reply jamesblonde 10 minutes agoparentIt's based on Z-Sets - a generalization of relational algebra. Many of the aggregations, projections, filters from SQL are associative and can be implemented in Z-Sets. Z-Sets supports incremental operations (adding one value to a set while computing the 'max' is just the max of the two arguments - rather than requiring recomputing the 'max' over the entire set. reply jacques_chester 2 hours agoprevI remember seeing a VMware-internal presentation on the DDlog work which led to Feldera and being absolutely blown away. They took a stream processing problem that had grown to an hours-deep backlog and reduced it to sub second processing times. Lalith & co are the real deal. reply lsuresh 1 hour agoparentThank you jacques_chester! Piping all that credit to my co-founders Mihai and Leonid, the key inventors. reply jitl 3 hours agoprevI’ve been following the Feldera/DBSP/Differential Datalog team for a while and am happy to see y’all stable-ish with your own venture and settling in a model more approachable than DDlog for most developers :) This seems much more adoptable to me in my org than DDlog was, even if I really liked DDlog much more than SQL :-( reply lsuresh 3 hours agoparentThanks for following our journey! There's still room for more language frontends if you'd like to contribute. :) reply arn3n 4 hours agoprevIf you don’t want to change your whole stack, ClickHouse’s Materialized Views do something extraordinarily similar, where computations are ran on inserts to the source table in an online/streaming manner. I’m curious how this solution compares in its set of features/gaurantees. reply atombender 7 minutes agoparentClickHouse's materialized views are wonderful, but they do require very careful design up front. In particular, aggregations need to be defined using the special AggregateFunction data types, which must be paired with the corresponding aggregation functions such as countMerge(). Joins are possible in CH views, but they operate in a specific way (against the insert batch) that you must know about; joins against other tables are generally a bad idea for performance, and you should use dictionaries as much as possible for fast in-memory lookup. Lastly, it's also hard to update MVs because their entire source query has to be modified as a whole. Adding a column requires declaring the whole MV, which introduces the possibility of making mistakes in your migrations. CH views are really more like triggers, and so they're a little misleadingly named. Very powerful, of course. In short, a lot more \"manual\" than this other system. reply lsuresh 4 hours agoparentprevFor incremental computation, Feldera is just way more powerful and general. It can evaluate arbitrarily sophisticated SQL programs incrementally (tables and deeply nested layers of views). For example, it can do rolling aggregates over joins, handle late and out-of-order arrivals, can compute over infinite streams with finite state (via automatic garbage collection), and it's strongly consistent. Clickhouse's materialized views are much simpler and restricted in comparison. That said, we are /not/ a replacement ever for Clickhouse or any other historical warehouse. In fact, we pair best with one of them. Have data flow through or teed into Feldera to maintain sophisticated standing queries -- maintain historical data in your warhehouse. reply qazxcvbnm 3 hours agoprevIncredible… I hadn’t even noticed, and people found the holy grail and open-sourced it! By the way, I was wondering about a related question. Do streaming engines typically store a copy of the data streamed to them? For instance, if I had a view to get the maximum value of a table, and the maximum value was removed, the streaming engine surely needs to get the next value from somewhere. It seems clear that the streaming engine needs at least its own snapshot of the data to have a consistent state of the computation, but duplicating the persisted data seems somewhat wasteful. reply lsuresh 3 hours agoparentThank you! The state Feldera maintains depends on the queries you write and the working set or windows you're computing over. Any time there are joins, distinct or non-linear aggregations, we need to maintain state as you've guessed. A cool feature in Feldera is that it can compute over infinite streams with finite state because we automate garbage collection. The user specifies lateness over data sources or even views, and with some static analysis, Feldera determines when it is safe to forget old state such that it won't affect the output of any views. reply bbminner 3 hours agoprevI wonder what guarantees can be made wrt resource consumption. I suppose that'd reasonable to assume that in most (all?) cases an update is cheaper then recompute in terms of cpu cycles, but what about ram? Intuitively it seems like there must be cases that would force you to store unbounded amount of data indefinitely in ram. reply ben_pfaff 3 hours agoparent(Feldera co-founder here.) There are some cases where Feldera needs to index data indefinitely, yes. For those cases, Feldera can put those indexes on storage rather than keeping them entirely in RAM. In a lot of cases where one might initially think that data needs to stay around indefinitely, people actually want the results from the last hour or day or month, etc. For those cases, Feldera supports a concept called \"lateness\" that allows it to drop older data: https://docs.feldera.com/sql/streaming/#lateness-expressions. reply lsuresh 3 hours agoparentprevYour intuition is correct. Incremental computation is fundamentally a time-space tradeoff. Depending on the views you write, you might end up maintaining large amounts of state. We've written about it here: https://www.feldera.com/blog/streaming-needs-storage That said, Feldera has several features to keep state bounded even when computing on infinite streams. For example, we do automatic garbage collection (GC) where with some static analysis, we can figure out when it is safe to forget inputs that will no longer affect the output of views. We recently ported a community member's warehouse workload to Feldera where with these features, we were evaluating As-Of joins and streaming aggregations with 1.2GB of RAM on a laptop with more than a million events/sec in perf. reply cube2222 8 hours agoprevThis looks extremely cool. This is basically incremental view maintenance in databases, a problem that almost everybody (I think) has when using SQL databases and wanting to do some derived views for more performant access patterns. Importantly, they seem to support a wide breath of SQL operators, support spilling computation state to disk, and it's open-source! Interestingly, it compiles queries to Rust, so an approach similar to Redshift (which compiles queries to C++ programs). There's already a bunch of tools in this area: 1. Materialize[0], which afaik is more big-data oriented, and doesn't pipe the results back to your database, instead storing results in S3 and serving them. 2. Epsio[1], which I've never used, seems to be very similar to this product, but is closed-source only. 3. When building OctoSQL[2], this capability was also important to me and it was designed from ground up to support it. Though in practice in a tool like OctoSQL it's pretty useless (was a fun problem to solve though). There's some things I'm curious about: - Does it handle queries that involve complex combinations of ordering with limits in subqueries? If due to a change in an underlying table a top-n row is added, resulting in moving other rows around (and removing the current n'th) will the subsequent query parts behave as though the order was maintained when computing it, or will it fall apart (imagine a select with limit from a select with bigger limit)? - Is it internally consistent[3]? They say it's \"strongly consistent\" and \"It also guarantees that the state of the views always corresponds to what you'd get if you ran the queries in a batch system for the same input.\" so I think the answer is yes, but this one's really important. Either way, will have to play with this, and dig into the paper (the link in the repo doesn't work, here's an arXiv link[4]). Wishing the creators good luck, this looks great! [0]: https://materialize.com [1]: https://www.epsio.io [2]: https://github.com/cube2222/octosql [3]: https://www.scattered-thoughts.net/writing/internal-consiste... [4]: https://arxiv.org/pdf/2203.16684 reply jonmoore 5 hours agoparentThe VLDB paper mentioned is https://www.vldb.org/pvldb/vol16/p1601-budiu.pdf. Abstract: \"Incremental view maintenance has been for a long time a central problem in database theory. Many solutions have been proposed for restricted classes of database languages, such as the relational algebra, or Datalog. These techniques do not naturally generalize to richer languages. In this paper we give a general solution to this problem in 3 steps: (1) we describe a simple but expressive language called DBSP for describing computations over data streams; (2) we give a general algorithm for solving the incremental view maintenance problem for arbitrary DBSP programs, and (3) we show how to model many rich database query languages (including the full relational queries, grouping and aggregation, monotonic and non-monotonic recursion, and streaming aggregation) using DBSP. As a consequence, we obtain efficient incremental view maintenance techniques for all these rich languages.\" reply lsuresh 4 hours agoparentprevThanks for the kind words! (Feldera's CEO here) - We evaluate top-k queries incrementally and the nesting shouldn't be a problem for the engine (or it'd be a bug). If you have an example of a query, we can try it out at our end. - Yes. It is internally consistent. We've verified with the experiment here: https://www.scattered-thoughts.net/writing/internal-consiste.... Our guarantee is that we always produce the same answer as if you'd ran the queries in a batch system. All views update together. You can see the computation model here: https://www.feldera.com/blog/synchronous-streaming/ And thanks for the catch about the broken paper link. This is the published version: https://www.vldb.org/pvldb/vol16/p1601-budiu.pdf reply cube2222 3 hours agorootparentThanks for the response and clarifications! I think this scenario would illustrate it. Make a table with one column, x, and insert into it rows with values 1-5, and then 8-20. Then query it using more or less `SELECT x FROM (SELECT x FROM xs LIMIT 15 ORDER BY x) LIMIT 10`, and then insert 6 into the table. Output should be 1-6, 8-11. Of course as long as the limits aren't merged together during optimisation, that would make the test-case moot. Good luck with your product! reply lsuresh 3 hours agorootparentThanks! Looks like that works. Here is the query I set up on try.feldera.com. CREATE TABLE foo (x INTEGER NOT NULL PRIMARY KEY) WITH ('materialized' = 'true') ; CREATE MATERIALIZED VIEW bar AS SELECT x FROM (SELECT x FROM foo ORDER BY x LIMIT 15) LIMIT 10; I then used our CLI tool fda to insert some rows and inspect the states after starting the pipeline: https://docs.feldera.com/reference/cli try.feldera.com/foo> select * from foo; +----+x+----+1| 2| 3| 4| 5| 8| 9| 10| 11| 12| 13| 14| 15| 16| 17| 18| 19| 20+----+ try.feldera.com/foo> insert into foo values (6); +-------+count+-------+1+-------+ try.feldera.com/foo> select * from bar; +----+x+----+1| 2| 3| 4| 5| 6| 8| 9| 10| 11+----+ reply cube2222 2 hours agorootparentAwesome, thanks for double-checking! reply tveita 5 hours agoparentprevI think Rama [1] (by Nathan Marz behind Apache Storm) is interesting as a \"NoSQL\" solution for a similar problem space, as I understand it. Impressive if this can support similar scale using only SQL. [1] https://redplanetlabs.com/ reply emmanueloga_ 5 hours agoparentprevAlso raising wave. —- https://risingwave.com/ reply seungwoolee518 9 hours agoprevWhen I saw the title first, I've thought that \"one of the os remove l\" introduces a new incremental conpute engine? Anyway, it was very impressive. reply lsuresh 4 hours agoparentThanks! reply Nelkins 6 hours agoprevI would love if something like this that exposed C bindings so that every language with an FFI could use the library. I’d love to be able to define pipelines and queries in .NET instead of having to use SQL. reply lsuresh 4 hours agoparentHi Nelkins. We do have a Rust crate you could consider using directly: https://docs.rs/dbsp/latest/dbsp/. Our SQL compiler puts together a pipeline by generating a Rust program that uses this crate. reply loxias 3 hours agoparentprevSecond the desire for C bindings! (or someone showing how to wrap and call the rust bindings?) reply lsuresh 2 hours agorootparentThe previous implementation we built at VMware went from datalog -> Rust, and we supported other language bindings using C bindings and FFI. The same ought to work here too. reply faangguyindia 1 hour agoprevWe just use bigquery and call it a day. Bigquery had figured this out long ago and built it in top of Big table. reply jonstewart 5 hours agoprev [–] How does it compare to Materialize/differential dataflow? reply lsuresh 4 hours agoparent [–] (Feldera's CEO here) We are based on DBSP (https://www.vldb.org/pvldb/vol16/p1601-budiu.pdf) which is an evolution of DD. DBSP gives us an algorithm to take arbitrarily complex queries and generate an incremental version of it. As a consequence, we evaluate everything incrementally. For example, we are the only engine that can perform rolling aggregates incrementally. In general, with DBSP, we can incrementalize \"the full relational algebra, queries over sets and multisets, arbitrarily nested relations, aggregation, flatmap (unnest), monotonic and non-monotonic recursion, streaming aggregation, and arbitrary compositions of all of these\". DBSP is a much simpler and cleaner foundation. As a product, both our enterprise and open-source (MIT licensed) offerings let you run it anywhere you want including your laptop. Positioning wise, we are a query engine with a unified way to compute over both bounded and unbounded data sources with perfect consistency, with an integrated storage layer. Materialize is going for building an operational warehouse. reply ZiliangXK 11 minutes agorootparent [–] There is always a tipping point for quite a few use cases where incremental evaluation degrades perf compared with full batch / historical query reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Feldera is a high-performance query engine designed for incremental computation, allowing continuous processing of changes without recomputing older data.",
      "It supports full SQL syntax and connects to various data sources, enabling users to manage pipelines and inspect results in real-time, even with datasets larger than RAM.",
      "Feldera can be started using Docker Compose or from source with dependencies like Rust, Java, Maven, and Typescript, and offers a web console for user interaction."
    ],
    "commentSummary": [
      "Feldera Incremental Compute Engine is an open-source tool designed for incremental computation, reducing stream processing times significantly.",
      "It is based on Z-Sets, a generalization of relational algebra, allowing many SQL operations to be implemented incrementally.",
      "Feldera supports a wide range of SQL operators, automatic garbage collection, and can index data on storage, making it suitable for sophisticated SQL programs and historical data warehouses."
    ],
    "points": 104,
    "commentCount": 34,
    "retryCount": 0,
    "time": 1727597025
  },
  {
    "id": 41685642,
    "title": "Text2CAD Generating Sequential CAD Designs from Text Prompts",
    "originLink": "https://sadilkhan.github.io/text2cad-project/",
    "originBody": "Table of Contents Contribution Data Annotation Text2CAD Transformer Results Quantitative Results Video Acknowledgement Citation More Research ▼ CAD-SIGNet Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts Mohammad Sadil Khan 1,2,3*† Google Scholar Email Website · Sankalp Sinha 1,2,3* Google Scholar Email Website · Talha Uddin Sheikh 1,2,3 Google Scholar Email Website Didier Stricker 1,2,3 Google Scholar Email Website · Sk Aziz Ali 1,4 Google Scholar Email Website · Muhammad Zeshan Afzal 1,2,3 Google Scholar Email Website * equal contributions · † corresponding author 1 German Research Center for AI (DFKI GmbH) · 2 RPTU · 3 MindGarage · 4 BITS Pilani, Hyderabad NeurIPS 2024 (Spotlight 🤩) Arxiv Code (Soon) 🤗 Dataset (Soon) Demo (Soon) Text2CAD: Designers can efficiently generate parametric CAD models from text prompts. The prompts can vary from abstract shape descriptions to detailed parametric instructions. Contribution We propose Text2CAD as the first AI framework for generating parametric CAD designs using multi-level textual descriptions . Our main contributions are: A Novel Data Annotation Pipeline that leverages open-source LLMs and VLMs to annotate DeepCAD dataset with text prompts containing varying level of complexities and parametric details. Text2CAD Transformer: An end-to-end Transformer based autoregressive architecture for generating CAD design history from input text prompts. Data Annotation Our data annotation pipeline generates multi-level text prompts describing the construction workflow of a CAD model with varying complexities. We use a two-stage method - Stage 1: Shape description generation using VLM (LlaVA-NeXT). Stage 2: Multi-Level textual annotation generation using LLM (Mixtral-50B). Text2CAD Transformer We developed Text2CAD Transformer to transform natural language descriptions into 3D CAD models by deducing all its intermediate design steps autoregres- sively. Our model takes as input a text prompt 𝑇 and a CAD subsequence 𝐶 1 : 𝑡 − 1 of length 𝑡 − 1 . The text embedding 𝑇 𝑎 𝑑 𝑎 𝑝 𝑡 is extracted from 𝑇 using a pretrained BeRT Encoder followed by a trainable Adaptive layer. The resulting embedding 𝑇 𝑎 𝑑 𝑎 𝑝 𝑡 and the CAD sequence embedding 𝐹 𝑡 − 1 0 is passed through 𝐿 decoder blocks to generate the full CAD sequence in auto-regressive way. Visual Results Visual examples of 3D CAD model generation using varied prompts. (1) Three different prompts yielding the same ring-like model, some without explicitly mentioning ’ring’. (2) Three diverse prompts resulting in same star-shaped model, each emphasizing different star characteristics. Qualitative results of the reconstructed CAD models of DeepCAD and Text2CAD on DeepCAD dataset. From top to bottom - Input Texts, Reconstructed CAD models using DeepCAD and Text2CAD respectively and GPT-4V Evaluation. Qualitative results of the reconstructed CAD models of DeepCAD and Text2CAD on DeepCAD dataset. From top to bottom - Input Texts, Reconstructed CAD models using DeepCAD and Text2CAD respectively and GPT-4V Evaluation. Visual examples of 3D CAD model generation using varied prompts. (1) Three different prompts yielding the same ring-like model, some without explicitly mentioning ’ring’. (2) Three diverse prompts resulting in same star-shaped model, each emphasizing different star characteristics. Qualitative results of the reconstructed CAD models of DeepCAD and Text2CAD on DeepCAD dataset. From top to bottom - Input Texts, Reconstructed CAD models using DeepCAD and Text2CAD respectively and GPT-4V Evaluation. ❮ ❯ Quantitative Results We evaluated the performance of Text2CAD using two strategies. CAD Sequence Evaluation: We assess the parametric correspondence between the generated CAD sequences with the input texts. This is done using the following metrics: F1 Scores of Line, Arc, Circle and Extrusion using the method proposed in CAD-SIGNet. Chamfer Distance (CD) measures geometric alignment between the ground truth and reconstructed CAD models of Text2CAD and DeepCAD. Invality Ratio (IR) Measures the invalidity of the reconstructed CAD models. Visual Inspection: We compare the performance of Text2CAD and DeepCAD with GPT-4 and Human evaluation. Click on the tab to visualize the bar chart. You can also hover on the bars to see the metrics. CAD Sequence Evaluation Visual Inspection F1 Scores CD and IR Video Coming Soon Acknowledgement This work was in parts supported by the EU Horizon Europe Framework under grant agreement 101135724 (LUMINOUS). Citation If you like our work, please cite. @misc{khan2024text2cadgeneratingsequentialcad, title={Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts}, author={Mohammad Sadil Khan and Sankalp Sinha and Talha Uddin Sheikh and Didier Stricker and Sk Aziz Ali and Muhammad Zeshan Afzal}, year={2024}, eprint={2409.17106}, archivePrefix={arXiv}, primaryClass={cs.CV}, url={https://arxiv.org/abs/2409.17106}, } 📋 © 2024 Mohammad Sadil Khan. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=41685642",
    "commentBody": "Text2CAD Generating Sequential CAD Designs from Text Prompts (sadilkhan.github.io)103 points by RafelMri 11 hours agohidepastfavorite59 comments mwill 1 hour agoI see multiple comments arguing that using a CAD package is only easier and faster if you already know how to use a CAD package, and this is a 'better' UI for people who don't have those skills....but in that scenario, are you not then just trading the fixed upfront time investment to learn the basics of CAD, for ongoing inefficiency and difficulty every time you want to model something? For a user of a UI like this, there comes a point where their time would have been better spent learning a CAD package. Another layer is if you are modelling something that has to be machined or built in real life, you have to be keeping an eye on how it will physically exist throughout the entire process, stock it will be machined from or materials it will be built with. Thinking in terms of CAD workflows help with this greatly in my experience. The operations shown in the demo are not only easier to perform in a CAD package than describe in English to an LLM, but also the easiest part of it (except maybe if you are designing strictly for 3D printing) reply dingnuts 14 minutes agoparent> For a user of a UI like this, there comes a point where their time would have been better spent learning a CAD package. for some users, they will think of few enough designs in a lifetime to make learning any specific software worthwhile. For these users, the LLM's inefficiencies are worth the trade-off. reply echoangle 7 hours agoprevAnyone who has ever done CAD knows that a picture is worth a thousand words. Describing a 3D object you want in words is much more effort to get right than drawing a simple sketch. Wouldn’t it be better to have image input for an application like this? reply godelski 1 hour agoparentThat's exactly what I was thinking. I can't describe what I want because I don't know it yet. It comes to life as I design. I was an engineer in a former life but still do a fair amount of printing. But when I design parts there's not even ways I __could__ know what I want before hand. As I build I realize I made wrong assumptions, but also not enough, that there are better ways to do things, that I can solve other problems, that I didn't think how things would interact together, that I could modify things to be better for the manufacturing process (this is such a big on in 3d printing and so many online files get this VERY wrong. But it is a hard skill to learn), and so many other things. In part this is because I've had more time to think, but there's more to it, when you see the thing \"coming alive\". This is much the same way I code, though I guess that's not common. I'm not sure if they'll address these problems, but I think anyone working in this space should make sure they also spend a lot of time in CAD themselves. It isn't clear to me that any of the authors do (looking at their websites. The main author mentions interest in AI-CAD but only has work from this year. Get this man a 3D printer). It's quite possible that they do, but they look like they've been computer scientists their whole career and that is probably not enough to understand the the intricacies of the problems they're trying to solve. There's a classic problem in CS where people get that you can learn a lot of things quickly but it is missed that getting the nuance and mastery takes time, that you should talk to experts. The first part is useful because it gives you the language to talk to experts, not because it makes you a replacement for one. reply throwgfgfd25 58 minutes agorootparent> In part this is because I've had more time to think, but there's more to it, when you see the thing \"coming alive\". Yep. I have two printed prototypes of different approaches to a mechanism on my desk that only exist because of months of staring at CAD in the evenings, learning new things, doing research. They are not radical (they may be slightly novel in places; I have never seen 3D printed mechanisms like them). I don't know if I could describe them in words at all, but if I could, it would only be because I worked through them in CAD in the first place. For anything other than a trivial object I just can't see how you'd even come up with the words without having worked through the design -- what, on paper in 2D in pencil? After doing the maths? That's CAD in reverse. reply godelski 50 minutes agorootparentYeah words and images (especially sketches) are fuzzy. I think we tend to think they are more precise than they are because we are so good at communicating, but often this is only after having a relationship with the other person. It is easy to ignore the frustration and frequency of miscommunication and blame it on other things, like your manager being dumb. When in fact, both might be true. There's definitely things I think I could describe in words, but without a doubt could be communicated faster by sketching. There more complicated things where I think it would just be faster to cad up the damn thing. It's like math (or code). The language(s) are precise and annoying because of that precision, but they're still the easiest way to do the things we want to do, which is why we use them. Natural language's flexibility is great for abstraction and big ideas but not so great when it comes to precision. Things get very wordy very fast when you get into the details. And I'm sure everyone knows the value of arguing with your friend or coworker over those tiny things, even if it doesn't seem important. If you don't, you probably need to work on teams more often or make more friends lol reply throwgfgfd25 37 minutes agorootparent> And I'm sure everyone knows the value of arguing with your friend or coworker over those tiny things, even if it doesn't seem important. Not to mention that in this case, this disagreement over the meaning of ultra-fine detail will be happening with an LLM, which does not really understand the words. reply godelski 14 minutes agorootparentI'm an ML researcher and I seriously do not understand how people are avoiding the stupid loops. Like where I tell the LLM all the conditions, what works and what doesn't work, and then it tells me to do the thing that I just said doesn't work (while at the beginning of the response it even acknowledges this!). So then I say \"x doesn't work, here's the output\" and then it says \"sorry for the confusion, you're right. Instead let'sthen do x\" where x is the same thing... I can't be the only one, right? I feel like I'm being gaslit lol reply jsheard 6 hours agoparentprevYeah but when all you have is an LLM hammer, everything looks like a text2text nail. reply CSMastermind 3 hours agorootparentLLMs are fundamentally one dimensional which works fine when you're generating next tokens for text which because that's a 1D problem. I do wonder how much progress we could make on a problem like this with a 3D transformer architecture. reply abotsis 3 hours agorootparentI’m not sure I follow this. Isn’t an LLMs dimensionality measured by how many parameters the model supports? Ie 10s of billions in some cases? If I understand it correctly, then, the model is already evaluating things in lots of dimensions and reducing it down to 1, as you say in the case of text, 2 dimensions in image generation, 3 should be pretty straightforward. reply btbuildem 2 hours agorootparentI think they're referring to the dimensionality of the input / output space, not the intermediate internal representation. reply btbuildem 2 hours agorootparentprevThe neat thing is, you can rasterize 1D space into 2D, 3D and so on. Trick as old as analog TV signal processing. reply throwgfgfd25 2 hours agorootparentIf I am understanding you right... I don't think this gets you anywhere useful. Even if you could do what you're suggesting with an LLM (I have my doubts) this result would be a mesh or 3D pixel grid or something, yes? This is terrible for interoperability and it's the opposite of what mainstream CAD packages do. reply DonnyV 4 hours agoparentprevYeah, a way to turn a flat sketch to a 3D model would be a better way to do this. reply jareklupinski 3 hours agoprev98% of the total time it takes me to design something, usually involves deleting entire designs because they get a point where something is unfeasible, invalid geometry, or against all manufacturers' guidelines (will this shape work with a draft angle? etc.) this is usually before i start adding intricacies such as shells, fillets, and other features, which do take a lot of effort, but making those by hand is more of the 'art' side of the process anyway anything that gets me through the first 98% is welcome :) reply JofArnold 1 hour agoparent> usually involves deleting entire designs Yes, for me that's usually around the point I've got a huge and complex assembly with all the motion wired up. Right-click -> Duplicate -> Rename \"MyProject V2\". I would save a huge amount of time also this way. reply throwgfgfd25 2 hours agoparentprev> anything that gets me through the first 98% is welcome :) Only if the result of the LLM is a good, well-architected parametric CAD model you can adjust, right? reply jareklupinski 1 hour agorootparentthat seems like a little much to expect from an LLM; the average CAD file in my experience has not been not well-architected :) as long as the output is something my manufacturer can understand (downloadable mesh: STL/STEP/etc (they dont take links)), the tool did its job for me i would probably start the final model from scratch no matter what the output was, so i can match my chosen manufacturer's tolerances/design rules/optimizations, and to give breathing room for my quirks/workflow (i like to design subtractively, some people design additively) reply btbuildem 2 hours agoprevI see a lot of comments here to the effect \"but it's easier to just do it in CAD in the first place\" -- those are experts speaking. Imagine being a newcomer to CAD, the learning curve is quite steep. Compared to mastering the complex UI and workflows of a CAD problem, a text-based approach seems much easier. I can see this being incorporated into existing software as an alternate workflow path. What caught my curiosity here is the \"sequential\" qualifier. One massive weakness of all the AI content generation schemes is the lack of editability -- you get what you get, and attempts to refine the initial results are middling at best. This seems like it allows the user to build a more complex scene from multiple prompts -- likely meaning you can go back and edit some of the prompts to tweak the building blocks, and edit the overall scene. Interesting! reply throwgfgfd25 2 hours agoparent> I see a lot of comments here to the effect \"but it's easier to just do it in CAD in the first place\" -- those are experts speaking. This is what I think, and yet I am the longest time away from being an expert. It's easier because CAD tools unlock CAD thinking and empower your brain to actually do design, as well as helping you see problems you didn't anticipate. This whole area -- LLM to CAD -- is one of the most misguided applications for generative AI (beyond \"generative design\" as it was understood in the pre-LLM/pre-GAN era, where it was usually used for FEM/topology optimisation) There are already enormous libraries of freely available basic CAD models for real-world objects; any beginner would be much better off simply learning how to merge them. And any tool aimed at beginners would be better off assisting that process (TinkerCad does, for example) And if a beginner has a truly novel object to make, an LLM is not going to have the training set data to make it. Nor is the beginner likely to have the CAD knowledge (words, expressions) to describe it. For this to be of use to a beginner you do have to imagine quite a niche kind of beginner: one who is expert in descriptive language and advanced geometry. Those people would be better off learning some sort of CAD environment; indeed they are the niche that is least likely to be driven insane by the limitations of OpenSCAD. reply q3k 9 hours agoprevDescribing what I want to design seems like more effort than actually just sketching things out in a decent CAD package. reply serf 8 hours agoparentonly if you're familiar with the CAD package. presumably a big benefit here is that all it really takes English and geometry knowledge. reply Palomides 4 hours agorootparentthinking in terms of composing 3d objects and their positions is 90% of doing CAD already, if you can do that, you can reproduce any of the objects in OP with 15 minutes of learning the tool seriously, I think people overestimate how hard basic CAD work is reply throwgfgfd25 3 hours agorootparent> seriously, I think people overestimate how hard basic CAD work is I think this is one of those things that programmers overestimate worse than non-programmers, too. To the point that they reject CAD UIs too early and get themselves stuck in often rather limiting code-CAD environments, because they never get to learn how parametric GUI CAD works. This belief that only code can be intuitively parametric is obviously not something that non-programmers suffer from. I think code-CAD has many benefits (though the idea of the various LLM-to-OpenSCAD tools out there makes me shudder; this is the worst possible combination of obscure knowledge-bases). But just a trivial amount of time learning even FreeCAD (the least-intuitive CAD package, pretty unambiguously) unlocks so much potential. reply iancmceachern 4 hours agorootparentprevYeah, if you architect your part right, which takes experience. For folks that don't belive us, check out \"speed modeling\" reply throwgfgfd25 2 hours agorootparentIt does take experience but mostly it takes a little analysis. I'm still really quite green at CAD; I've come to it late in life and I only make relatively simple things, perhaps; only simple mechanisms. But when I look at people getting stuck and asking for help in CAD groups it so often comes down to the knock-on effects of very early mistakes, like squandering the benefits of the base planes by choosing the wrong initial orientation, muddling through with primitives when an extrusion of a sketch would do the job, or making a series of complex circular pockets when a single revolve could have done it better. Basic familiarity with a few principles and their expression in CAD, and a little study of existing objects gets you a long way. It interests me that programmers are willing to learn the expressive nuances of individual languages or libraries or methodologies, but as soon as it comes to GUI CAD they dismiss the whole thing as too hard or too obscure. The excitement around LLM text-to-CAD seems emblematic of this; as if the wrong conclusions about GUI interfaces have been drawn from bad experiences of dev GUIs. reply iancmceachern 2 hours agorootparentTotally Asking me or folks that do what I do to create a hardware product that way would be like asking a sculptor to sit down and write NC code for a marble router to cut out the sculpture they see in their minds eye. When we're using these tools, Solidworks in my case, we're not just clicking with the mouse. We're typing complex commands, creating and using variables, creating scripts and macros, we often use gaming mice with many buttons mapped to complex hockey's, etc. The graphics interface is just part of it, the part where it shows us 3d geometry so we can put it into our minds eye, and a way to tell the computer what geometry we are talking about before we execute work using what I described above. Most people don't get it, if you do you do. You do. reply zppln 4 hours agorootparentprevSo then you're left with a CAD file for a CAD package you're not familiar with..? reply Aurornis 3 hours agoprevCool in theory, but I can’t imagine describing anything other than the most basic CAD designs verbally. Text is not a good medium for designs beyond the most basic shapes and modifications. reply CSMastermind 3 hours agoparentI work with software that displays 3D models of real products. If I could feed the manufacturers spec sheet along with maybe some pictures of the items and marketing copy then get a 3D model out it would save me a ton of money. reply l5870uoo9y 7 hours agoprevThat's something artificial intelligence is really good at: fitting data into a formalized format. I'm working on something similar[0], here the goal is not CAD design but charts. This is also something that has only become possible with later versions of AI, such as GPT-4. [0]: https://www.datavisualizer.ai/ reply faeyanpiraat 7 hours agoparentDo you have paying users? reply loughnane 6 hours agoprevThis would be most useful if it could generate objects that could then easily be tweaked, ideally parametrically. I think with a long preamble in the prompt (you are an expert at designing injection molded parts, and so on) you could get something pretty useful. reply qazxcvbnmlp 4 hours agoprevSo much negativity here. It’s interesting to see new technical possibilities. Congratulations to the team that made this. reply throwgfgfd25 1 hour agoparentIt's not negativity so much as informed dissent. reply maCDzP 2 hours agoprevLet’s see where this goes in 1-2 years. There is a ton of money in the CAD industry. reply avodonosov 7 hours agoprevWhat format for resulting CAD designs they use? And in general, what is (are) the best open CAD formats and applicatioms today? reply iancmceachern 4 hours agoparentThis is the rub reply isoprophlex 6 hours agoprevI wonder how effective a solution leveraging LLMs would be in producing NC code... maybe a numerically precise method is still a hard requirement there. reply iancmceachern 4 hours agoparentWe don't need LLM for that, and it would be very risky to trust not crashing a $250k machine tool with a $5k part in it that could kill the operator if something goes wrong reply therouwboat 21 minutes agorootparentThere is AI assistant for mastercam and other cam software, it promises to make 80% finished programs, but parts look really simple, like something you do on the first week of cnc training. reply timonoko 10 hours agoprevGemini clearly understands OpenScad primitives. \"Make this object hollow\", etc. But \"Make me a teapot\" seems to be aiming for teapot-looking object, which cannot hold tea. But this is not failure perse. reply timonoko 8 hours agoparentMaking functional teapot takes about 10 queries. You just have to make the pot and spout hollow and move the handle outside. Totally functional tea-pot production solution already. All you need to do is to automatize the display function and STL-production and any granny can print her own teapot without understanding nothing about computers and 3D-printers. reply jsheard 7 hours agorootparentRest in peace granny, taken from us by a cocktail of plastics, bacteria, mold and tea. Maybe stating the obvious but 3D printed parts usually aren't food safe unless you post-process them with an appropriate non-porous coating. reply andai 6 hours agorootparentWhat's your favorite non-porous teapot coating? reply timonoko 6 hours agorootparentNo coating needed. All you need is to re-flow the ABS. Feels like pottery after this simple operation: https://youtu.be/iLaGJwCCz-E?si=a1gccp8EI9sGzt-e reply echoangle 5 hours agorootparentDo you really want almost-boiling-water in ABS? I wouldn't do that. reply timonoko 4 hours agorootparentReflow happens at 200°C, out gassing any 3D-related harmful stuff. Equal to inject-molded ABS cutlery. reply echoangle 4 hours agorootparentMaybe I'm too careful but I wouldn't use plastic cutlery on hot food either. Also, the glass transition temperature of ABS is only 105 °C, so It's probably not too strong when filled with 100 °C water. reply timonoko 4 hours agorootparentI have already made all kinds of tests. Only restriction was that you cannot make open flame cooking pot, because it starts combusting too easily. reply echoangle 4 hours agorootparentHow did you test the water quality after storing it in an ABS container? How would you notice if something from the ABS dissolved in the water? reply waciki 7 hours agorootparentprevThose grannies are already making teapots, it's called pottery. reply throwgfgfd25 1 hour agorootparentMore than a thousand generations of grannies, at that. Additive manufacturing from 30,000 years ago! reply jaakl 4 hours agorootparentprevDoes it respond to http queries? reply kkfx 8 hours agoprevThe idea is very nice, but as all LLM-backed stuff I see results are poor, meaning we need more effort to use the LLM obtaining good results than doing the work with non-LLM-wrapped/backed tools. It's the same for copilot to code and so on. It's still an interesting applications that might have a better future concentrating toward simulations (Salomé MECA, CodeASTER etc) since for these systems it's more tedious designing the simulation by hand than just sketch a 3D part with a modern parametric CAD. reply magic_man 4 hours agoprevcan you import this into solid works or autocad? I think it would be super useful to have the basic model and then tweak it. reply throwgfgfd25 1 hour agoparentThis is one of those classic LLM scenarios that doesn't make sense. If you can tweak the model in a CAD package, you can quite possibly make it in CAD in the first place more quickly than you can manage several rounds of descriptions with an LLM. It's like the whole \"I'd like to get an LLM to write a song and then I'd adjust it\" thing. No musician needs this. If you can truly fine-tune a song, writing one is easy. And if you aren't a musician, you won't get good results fine-tuning a song. reply westurner 5 hours agoprev [–] From https://news.ycombinator.com/item?id=40131766 re: LLM minifigs and parametric CAD parts libraries: > Is there a blenderGPT-like tool trained on build123d Python models? > ai-game-development tools lists a few CAD LLM apps like blenderGPT and blender-GPT: https://github.com/Yuan-ManX/ai-game-development-tools#3d-mo... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Text2CAD is the first AI framework designed to generate parametric CAD (Computer-Aided Design) models from multi-level textual descriptions, making it a significant advancement in the field.",
      "The framework includes a novel data annotation pipeline using open-source LLMs (Large Language Models) and VLMs (Vision-Language Models) to annotate the DeepCAD dataset with varied text prompts.",
      "Text2CAD Transformer employs a pretrained BeRT Encoder and Adaptive layer to transform natural language descriptions into 3D CAD models, showcasing its capability through both qualitative and quantitative results."
    ],
    "commentSummary": [
      "Text2CAD is a tool that generates CAD (Computer-Aided Design) models from text prompts, aiming to simplify the design process for users unfamiliar with traditional CAD software.",
      "The tool is particularly beneficial for users who may not frequently design objects, as it reduces the need for extensive CAD training, though it may not be as efficient for complex designs.",
      "The discussion highlights the potential and limitations of using natural language to create precise 3D models, with some experts suggesting that traditional CAD workflows are still more effective for detailed and accurate designs."
    ],
    "points": 103,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1727596379
  }
]
