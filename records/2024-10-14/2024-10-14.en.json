[
  {
    "id": 41833902,
    "title": "Huly – Open-source project management platform",
    "originLink": "https://github.com/hcengineering/platform",
    "originBody": "Huly Platform ⭐ Your star shines on us. Star us on GitHub! About The Huly Platform is a robust framework designed to accelerate the development of business applications, such as CRM systems. This repository includes several applications, such as Chat, Project Management, CRM, HRM, and ATS. Various teams are building products on top of the Platform, including Huly and TraceX. Self-Hosting If you're primarily interested in self-hosting Huly without the intention to modify or contribute to its development, please use huly-selfhost. This project offers a convenient method to host Huly using docker, designed for ease of use and quick setup. Explore this option to effortlessly enjoy Huly on your own server. Activity Table of Content Huly Platform About Self-Hosting Activity Table of Content Pre-requisites Verification Installation Build and run Run in development mode Update project structure and database Troubleshooting Build & Watch Tests Unit tests UI tests Package publishing Additional testing Pre-requisites Before proceeding, ensure that your system meets the following requirements: Node.js (v20.11.0 is required) Docker Docker Compose Verification To verify the installation, perform the following checks in your terminal: Ensure that the docker commands are available: docker --version docker compose version Fast start sh ./scripts/fast-start.sh Installation You need Microsoft's rush to install application. Install Rush globally using the command: npm install -g @microsoft/rush Navigate to the repository root and run the following commands: rush install rush build Alternatively, you can just execute: sh ./scripts/presetup-rush.sh Build and run Development environment setup requires Docker to be installed on system. Support is available for both amd64 and arm64 containers on Linux and macOS. cd ./dev/ rush build # Will build all the required packages. # rush rebuild # could be used to omit build cache. rush bundle # Will prepare bundles. rush package # Will build all webpack packages. rush validate # Will validate all sources with typescript and generate d.ts files required for ts-node execution. rush svelte-check # Optional. svelte files validation using svelte-check. rush docker:build # Will build Docker containers for all applications in the local Docker environment. rush docker:up # Will set up all the containers Be aware rush docker:build will automatically execute all required phases like build, bundle, package. Alternatively, you can just execute: sh ./scripts/build.sh By default, Docker volumes named dev_db, dev_elastic, and dev_files will be created for the MongoDB, Elasticsearch, and MinIO instances. Before you can begin, you need to create a workspace and an account and associate it with the workspace. cd ./tool # dev/tool in the repository root rushx run-local create-workspace ws1 -w DevWorkspace # Create workspace rushx run-local create-account user1 -p 1234 -f John -l Appleseed # Create account rushx run-local configure ws1 --list --enable '*' # Enable all modules, even if they are not yet intended to be used by a wide audience. rushx run-local assign-workspace user1 ws1 # Assign workspace to user. rushx run-local confirm-email user1 # To allow the creation of additional test workspaces. Alternatively, you can just execute: sh ./scripts/create-workspace.sh Add the following line to your /etc/hosts file 127.0.0.1 host.docker.internal Accessing the URL http://host.docker.internal:8087 will lead you to the app in development mode. Limitations: Local installation does not support sending emails, thus disabling functionalities such as password recovery and email notifications. Run in development mode Development mode allows for live reloading and a smoother development process. cd dev/prod rush validate rushx dev-server Then go to http://localhost:8080 Click on \"Login with password\" link on the bottom of the right panel and use the following login credentials: Email: user1 Password: 1234 Workspace: ws1 Update project structure and database If the project's structure is updated, it may be necessary to relink and rebuild the projects. rush update rush build It may also be necessary to upgrade the running database. cd ./dev/tool rushx upgrade -f Troubleshooting If a build fails, but the code is correct, try to delete the build cache and retry. # from the project root rm -rf common/temp/build-cache Build & Watch For development purpose rush build:watch action could be used. It includes build and validate phases in watch mode. Tests Unit tests rush test # To execute all tests rushx test # For individual test execution inside a package directory UI tests cd ./tests rush build rush bundle rush docker:build ## creates test Docker containers and sets up test database ./prepare.sh ## runs UI tests rushx uitest To execute tests in the development environment, please follow these steps: cd ./tests ./create-local.sh ## use ./restore-local.sh if you only want to restore the workspace to a predefined initial state for sanity. cd ./sanity rushx dev-uitest # To execute all tests against the development environment. rushx dev-debug -g 'pattern' # To execute tests in debug mode with only the matching test pattern. Package publishing node ./common/scripts/bump.js -p projectName Additional testing This project is tested with BrowserStack. © 2024 Hardcore Engineering Inc.",
    "commentLink": "https://news.ycombinator.com/item?id=41833902",
    "commentBody": "Huly – Open-source project management platform (github.com/hcengineering)415 points by blacktechnology 15 hours agohidepastfavorite192 comments danpalmer 14 hours agoReading the deployment information, there's an interesting tension here with applications that target self-hosting. Deploying this requires running 5 different open source servers (databases, proxies, etc), and 5 different services that form part of this suite. If I were self-hosting this in a company I now need to be an expert in lots of different systems and potentially how to scale them, back them up, etc. The trade-offs to be made here are very different to when architecting a typical SaaS backend, where this sort of architecture might be fine. I've been going through this myself with a hobby project. I'm designing it for self-hosting, and it's a radically different way of working to what I'm used to (operating services just for my company). I've been using SQLite and local disk storage so that there's essentially just 2 components to operate and scale – application replicas, and shared disk storage (which is easy to backup too). I'd rather be using Postgres, I'd rather be using numerous other services, background queue processors, etc, but each of those components is something that my users would need to understand, and therefore something to be minimised far more strictly than if it were just me/one team. Huly looks like a great product, but I'm not sure I'd want to self-host. reply nine_k 12 hours agoparentCheap, easy, powerful: choose any two. - Cheap and easy: embed into one executable file SQLite, a KV store, a queue, and everything else. Trivial to self-host: download and run! But you're severely limited in the number of concurrent users, ways to back up the databases, visibility / monitoring. If a desktop-class solution is good for you, wonderful, but be aware of the limitations. - Cheap and powerful: All open-source, built from well-known parts, requires several containers to run, e.g. databases, queues, web servers / proxies, build tools, etc. You get all the power, can scale an tweak to your heart's content while self-hosting. If you're not afraid to tackle all this, wonderful, but be aware of the breadth of the technical chops you'll need. - Easy and powerful: the cloud. AWS / Azure / DO will manage things for you, providing redundancy, scaling, and very simple setup. You may even have some say in tuning specific components (that is, buying a more expensive tier for them). Beautiful, but it will cost you. If the cost is less than the value you get, wonderful. Be aware that you'll store your data on someone else's computers though. There's no known (to me) way to obtain all three qualities. reply nucleardog 4 hours agorootparent> Cheap, easy, powerful: choose any two. I don't think there's any reason the same codebase can't support different trade-offs here. Maybe I'm just looking at the past through rose-coloured glasses, but it seems to me that was the norm before we standardized on distributing apps as an entire stack through a docker-compose.yml file. Your app depends on redis for caching. If no redis instance is configured, go ahead and just instantiate a \"null\" caching implementation (and print a warning to the log if it makes you feel better) and carry on. You're using minio for object storage. Is there any reason you couldn't, I don't know, use a local folder on disk instead? Think of it as \"progressive enhancement\" for the ops stack. Let your app run simply in a small single node deploy, but support scaling up to something larger. reply itake 2 hours agorootparentIMHO, redis is either used as a key value store (which can easily be replicated in application code) or as a central storage to synchronize tasks (like counters). For the first case, dev should just build on SQLite or use application code. For the latter case, choose a single storage engine and use it for everything (Postgres?). reply prmoustache 8 hours agorootparentprev> - Easy and powerful: the cloud. AWS / Azure / DO will manage things for you, providing redundancy, scaling, and very simple setup. You may even have some say in tuning specific components (that is, buying a more expensive tier for them). Beautiful, but it will cost you. If the cost is less than the value you get, wonderful. Be aware that you'll store your data on someone else's computers though. Easy on the magic powder. Cloud vendors manage some stuff, they mostly abstract you the hardware and package management part, but that's about it. Hosting a postgresql DB on RDS instead of a VM somewhere or on bare metal doesn't change much. Sure redundancy and scaling is easyto setup. But you still have to stay up to date with the best practices, how to secure it through network, choose and set your backup policy, schedule when to upgrade, plan the potential downtimes, what is deprecated, what is new, when price will sky rocket up because AWS doesn't want many customers to still run that old version. Same applies to many individual tech sold as \"managed\" by cloud vendors. A whole lot of admin overhead is not removed by running some individual tech as a managed service. You only remove a significant part of the management when the whole stack of what comprises your user facing application is managed as a single entity but that comes with another problem. Those managed apps end up being very highly coveted targets by black hat hackers. All the customers over the world usually end up being pwnable at the same time thanks to the same bug/security hole being shared. It becomes a question of when, not if, your users accounts will become public data. reply moooo99 8 hours agorootparentprevSQLite is actually substantially more capable than many people think it is. I have served 20k MAUs from a reasonably sized single node server with some headroom to spare. Yes, it requires some thinking about efficiency and not necessarily going with nodejs + some ORM, but you can take SQLite quite far, even in a small to medium enterprise reply creshal 8 hours agorootparentSQLite works well with 2k DAUs on a single node, even with Django's not particularly efficient ORM. You just have to be careful about what you really need to write to DB and what's okay to either not save at all, or just throw into a log file for later offline analysis. reply imglorp 8 hours agorootparentI don't see how these guys can think about MAU/DAU to assess DB load and sizing without talking about the rest of the app/arch details. Wouldn't ops/time be more agnostic? reply alluro2 7 hours agorootparentAgreed, number of active users cannot make sense as a generic unit across systems... I have 2 systems where in the first (route optimization platform), 1 user would, as part of just a normal 10 minute session: - read ~100MB from the database - utilize 100% of 32-core machine CPU (and 64GB of RAM) - resulting in thousands of writes to the database - and side-effect processing (analytics, webhooks etc) Over a course of a day, it would likely be ~10x for that single user. In the other system - appointment scheduling - 1 user would, in 1 day, read ~1MB of data from the database, and make 2-3 writes from a single action, with maybe 1 email triggered. reply nine_k 8 hours agorootparentprevSQLite has excellent read performance. Insert / update performance is quite another story: https://stackoverflow.com/a/48480012 Even in WAL mode, one should remember to use BEGIN CONCURRENT and be ready to handle rollbacks and retries. reply ngrilly 10 hours agorootparentprevYou can scale quite far using SQLite. That's what Basecamp is doing with their new self-hosted chat app, named ONCE Campfire. It is designed to scale to hundreds or even thousands of concurrent users with the right hardware: https://once.com/campfire. reply benhurmarcel 7 hours agorootparentI wonder why it needs 2Gb of RAM even for a low number of users though. reply runako 4 hours agorootparentIt ships as a Docker container. Docker recommends a minimum of 2GB RAM to run the Linux version of the Docker Engine, before adding constraints imposed by running apps. reply ngrilly 6 hours agorootparentprevRuby on Rails is not known for being very RAM efficient, but this is only me speculating. reply day2punk 5 hours agorootparentprevawesome, thank you for the information. reply cyberax 1 hour agorootparentprev> But you're severely limited in the number of concurrent users You can easily handle 100-200 concurrent active users on a decent CPU with SQLite, if you don't do anything crazy. And if you need a project management solution that needs more than that, you probably are not too concerned about the price. reply supriyo-biswas 9 hours agorootparentprev> - Cheap and powerful: All open-source, built from well-known parts, requires several containers to run, e.g. databases, queues, web servers / proxies, build tools, etc. You get all the power, can scale an tweak to your heart's content while self-hosting. If you're not afraid to tackle all this, wonderful, but be aware of the breadth of the technical chops you'll need. What about lowering the number of dependencies your application uses, like only depending on a database? Running a database isn't that hard, and it also greatly simplifies the overhead of running 5 different services. reply SoftTalker 4 hours agorootparentThis works up to a point. Past a certain scale, running a database becomes hard(er), and you also start to need proxies, caches, load balancers, etc. to maintain performance. I would agree, though, that many software installations never need to scale to that point. Perhaps most. reply RussianCow 30 minutes agorootparentAt what point do you hit that scale with project management software, though? Maybe you can't get to the point where you're managing all projects across all of Walmart from the same instance, but certainly you can run pretty much anything of reasonable size. reply angra_mainyu 9 hours agorootparentprevsqlite can scale to thousands of concurrent users. Personally for me the issue with all these new project management platforms is that the target demographic is either: - they're so small they can't afford to self-host - they're big enough they can afford the pro plans of more established tools Small companies can get by perfectly with the free/cheap plans of other tools, like Trello+Google Workspace. Heck if you're a one-man team with occasional collaborators free Trello + Google Workspace (~$6/mo) is enough. A box to provision the Huly stack might come out at more per month... reply szundi 12 hours agorootparentprevHow big the organization has to be not to be able to deploy it on a big enough machine with SQLite? reply nine_k 11 hours agorootparentHow big is not the question. The question is how small: think self-hosting within a small non-profit or other such operation, on someone's aging ProLiant in a basement. A big organization likely would just buy their hosted solution. reply stephenr 11 hours agorootparentprevSize likely has nothing to do with it, while reliability is a much bigger concern. If your business uses said tool for all client work, and it's hosted on a single server (be it physical or a VM), that is a SPoF. Any downtime and your business grinds to a halt because none of your project or customer information is accessible to anyone. reply myaccountonhn 9 hours agorootparentDoes everything need 99.99% availability? It feels like you have to be a very big business for this to be a problem that is worth the extra engineering effort vs a single instance with an SQLite file that you backup externally with a cron job reply nine_k 8 hours agorootparentNot availability but predictability. Most stick trading systems and even many banking systems have availability like 40%, going offline outside business hours. But during these business hours they are 99.999999 available. Usually operation without trouble is operation with plenty of resources to spare, and in absence if critical bugs. reply notarobot123 7 hours agorootparentprevIt still astounds me how hard software distribution is. We've had so many generations of solutions and paradigms that attempt to solve this problem (e.g. C, Unix, Java, Docker, etc) but the best we've come up with is client-server applications and the web. Yet it's still not trivial to host a reasonably \"powerful\" web application. In theory, the components for a universal runtime are pretty apparent by now. Wouldn't it be wonderful if truly portable and end-user friendly cloud computing was a thing. reply lenkite 4 hours agorootparentThe WebAssembly Component Model is attempting to do this though it seems to be progressing rather slowly. reply amelius 6 hours agorootparentprevI suspect that a Docker container would in this case solve the issue. reply soulofmischief 9 hours agorootparentprevI think the point they're making is that it's not exactly cheap either, given the amount of upfront knowledge (and time investment to gain that knowledge) required, or the cost of vetting and paying people who do have that knowledge. So \"cheap and powerful\" just looks like \"powerful\", at which point you may as well make it easy, too, and go with a managed or hybrid solution. reply nine_k 6 hours agorootparentIt's \"cheap\" as in \"not paying $39/mo per user\", or whatever other subscription / licensing fees. reply whiplash451 8 hours agorootparentprevWhy is open-source \"cheap\"? It seems like you look at the cost of things only through the lens of licensing and not the cost of people to run/maintain them. I have nothing against OSS per se, but in my experience, the financial analysis of OSS vs paid software is much more subtle. reply zmmmmm 8 hours agorootparentthe cost of the people is represented by it not being \"easy\" reply wim 14 hours agoparentprev(Also building a product in the productivity space, with an option for users to self-host the backend) That's interesting, for us there was actually no trade-off in that sense. Having operated another SaaS with a lot of moving parts (separate DB, queueing, etc), we came to the conclusion rather early on that it would save us a lot of time, $ and hassle if we could just run a single binary on our servers instead. That also happens to be the experience (installation/deployment/maintenance) we would want our users to have if they choose to download our backend and self-host. Just download the binary, and run it. Another benefit is that it's also super helpful for local development, we can run the actual production server on our own laptop as well. We're simply using a Go backend with SQLite and local disk storage and it pretty much contains everything we need to scale, from websockets to queues. The only #ifdef cloud_or_self_hosted will probably be that we'll use some S3-like next to a local cache. reply danpalmer 13 hours agorootparentI think that's great if you prefer to operate a service like that. Operating for one customer vs many can often have different requirements, and that's where it can make sense to start splitting things out, but if the service can be built that way then that's the best of both worlds! reply djhn 11 hours agorootparentprevWhat about the user interface? I’m all in on Go + Sqlite, but the user facing parts need a UI. reply wim 10 hours agorootparentSure, this is just about the syncing backend. Our \"IDE\" frontend is written in vanilla JavaScript, which the Go backend can even serve directly by embedding files in the Go binary, using Go's embed package. Everything's just vanilla JS so there are no additional packages or build steps required. reply djhn 8 hours agorootparentAre you using something like Wails or Electron to wrap this into a desktop app? I’ll have to sign up for Thymer and check it out! I’ve been prototyping my app with a sveltekit user-facing frontend that could also eventually work inside Tauri or Electron, simply because that was a more familiar approach. I’ve enjoyed writing data acquisition and processing pipelines in Go so much more that a realistic way of building more of the application in Go sounds really appealing, as long as the stack doesn’t get too esoteric and hard to hire for. reply jcgl 6 hours agorootparentNot GP, but someone else who's also building with Go+SvelteKit. I'm embedding and hosting SvelteKit with my Go binary, and that seems to be working well so far for me. Took some figuring out to get Go embedding and hosting to play nicely with SvelteKit's adapter-static. But now that that's in place, it seems to be reliable. reply notpushkin 13 hours agorootparentprevYeah, I think keeping infra simple is the way to go too. You can micro-optimize a lot of things, but this doesn’t really beat the simplicity of just running SQLite, or Postgres, or maybe Postgres + one specialized DB (like ClickHouse if you need OLAP). S3 is pretty helpful though even on self-hosted instances (e.g. you can offload storage to a cheap R2/B2 that way, or put user uploads behind a CDN, or make it easier to move stuff from one cloud to another etc). Maybe consider an env variable instead of an #ifdef? reply stephenr 10 hours agorootparentprev> We're simply using a Go backend with SQLite and local disk storage and it pretty much contains everything we need to scale How do you make it highly available like this? Are you bundling an SQLite replication library with it as well? reply wim 10 hours agorootparentThis is probably where the real trade-off is, and for that it's helpful to look at what the actual failure modes and requirements are. Highly available is a range and a moving target of course, with every \"extra 9\" getting a lot more complicated. Simply swapping SQLite for another database is not going to guarantee all the nines of uptime for specific industry requirements, just like running everything on a single server might already provide all the uptime you need. In our experience a simple architecture like this almost never goes down and is good enough for the vast majority of apps, even when serving a lot of users. Certainly for almost all apps in this space. Servers are super reliable, upgrades are trivial, and for very catastrophical failures recovery is extremely easy: just copy the latest snapshot of your app directory over to a new server and done. For scaling, we can simply shard over N servers, but that will realistically never be needed for the self-hosted version with the number of users within one organization. In addition, our app is offline-first, so all clients can work fully offline and sync back any changes later. Offline-first moves some of the complexity from the ops layer to the app layer of course but it means that in practice any rare interruption will probably go unnoticed. reply hypeatei 7 hours agorootparent> just copy the latest snapshot of your app directory over to a new server and done. In practice, wouldn't you need a load balancer in front of your site for that to be somewhat feasible? I can't imagine you're doing manual DNS updates in that scenario because of propagation time. reply stephenr 4 hours agorootparentI don't know for sure but the explanation given sounds very much like they expect it to be a 100% manual process. reply stephenr 9 hours agorootparentprev> Servers are super reliable We have clearly worked in very different places. reply LorenDB 1 hour agoparentprevI am a firm believer that any self-hosted app should require, at most, a docker-compose.yml and possibly a .env file to get a basic service up and running. Requiring me to clone your repo or run some script from your site doesn't inspire a lot of confidence that it will be easy to maintain and keep up to date, whereas if you provide a prebuilt Docker image, I know that I can always just pull the latest image and be up-to-date. reply hiatus 57 minutes agorootparentThat doesn't preempt the parent's concerns. If your docker-compose has a mongo container now I have to either self-host mongo or use atlas. reply cheema33 13 hours agoparentprev> Deploying this requires running 5 different open source servers (databases, proxies, etc) That is the nature of the beast for most feature rich products these days. The alternative is to pay for cloud service and outsource the maintenance work. I don't mind a complex installation of such a service, as long as it is properly containerized and I can install and run it with a single docker-compose command. reply crabmusket 13 hours agoparentprevThis reminds me of Sentry. This podcast interview had an interesting discussion of self-hosting: https://www.flagsmith.com/podcast/sentry > In terms of how much thought and design you put into the self-hosted story, this is one of the things that we've been slowly realizing that every time the product gets more complex and the infrastructure required that run it gets more complex. As soon as you include a time series database, then that's adding another ratchet up of complexity if you're self-hosting it, but more outside of docker name. How much did you have that in your mind when you were designing the platform? > I would say that's changed a lot over time. Early on, Sentry’s goal was to adapt to infrastructure. We use Django. We’ve got support for different databases out of the box, SQLite, Postgres, MySQL. MySQL is going all this other stuff at some point too. We had that model early on. ... Our whole goal, and this is still the goal of the company, we want everybody to be able to use Sentry. That's why the open source thing is also critical for us. Adapting infrastructure is one way to do that. Now, we changed our mind on that because what that turned into is this mess of, we have to support all these weird edge cases, and nobody is informed about how to do things. We're like, “That's all dead. We only support Postgres.” Key value is still a little bit flexible. It's hard to mess up key values. We're like, “You can write an adapter. We only support Redis for this thing. We use a technology called Cortana. We only support ClickHouse for this thing.” We're over this era of, “Can we adapt it because it looks similar?” and it made our lives so much better. reply NetOpWibby 11 hours agorootparentVenture-backed open-source typically wants the software to run everywhere because some percentage of devs will have the power to get the enterprise they work for to shell out $$$ for the hosted service. Great for short/medium-term but unsustainable long-term. reply friendzis 12 hours agoparentprevSeemingly unpopular opinion, but coming from more ops related background, I always appreciate configurable deployments. If I want to test-deploy the thing on my own workstation I hope the defaults will work, but in a corporate environment I may not only want, but actually require flexibility. Infra, ops and dev intersect at different points in different orgs. Some may provide custom kubernetes operator and abstract the service away, some orgs may provide certain \"managed\" building blocks, e.g. postgres instance. Some will give you a VM and and iscsi volume. Some will allocate credits in cloud platform. Having the ability to plug preexisting service into the deployment is an advantage in my book. reply danpalmer 12 hours agorootparentIt's not an unpopular opinion, but as far as I can tell Huly is not a configurable deployment. It's a strict set of dependencies. If you can't run Mongo, Elastic, and a bunch of other bits, then you can't run it. The more pieces they add the more likely any one potential user can't run it. The options are either to minimise the dependencies (the approach I advocated for in my parent comment), or to maximise the flexibility of those dependencies, like requiring a generic-SQL database rather than Mongo, requiring an S3 compatible object store rather than whatever they picked. This is however far more work. reply d0gsg0w00f 8 hours agorootparentThis is clearly a case where Huly's primary focus is their complex SaaS option. The self-host option has to follow core or it bitrots. I'm fine with this trade-off personally. reply dotancohen 11 hours agoparentprev> there's an interesting tension here with applications that target self-hosting Being already set up in Docker simplifies this quite a bit for smaller installs. But I notice a send tension - the introduction of some new tool on every project. I'm reasonably proficient with Docker, been using it for over a decade. But until now I've never encountered \"rush\". And it did not surprise me to find some new tool - actually I probably would have been surprised to not find some new tool. Every project seems to foregoe established, known tools for something novel now. I mean I'm glad it's not \"make\", but the overhead for learning completely new tools to understand what I'm introducing into the company is attrition. reply paulnpace 6 hours agoparentprevIt seems like there are different categories of \"self-hosting\" that are something like \"corporate self-hosting\" and \"personal self-hosting\" plus some in-between, such as for the lone wolf admin contractor, etc. reply letters90 12 hours agoparentprevI don't really see where you are getting that https://github.com/hcengineering/huly-selfhost reply matly 11 hours agorootparentThat's actually supporting the posters' argument. Take a look at all the configs and moving parts checked in this very repo that are needed to run a self-hosted instance. Yes, it is somewhat nicely abstracted away, but that doesn't change the fact that in the kube directory alone [1] there are 10 subfolders with even more config files. 1: https://github.com/hcengineering/huly-selfhost/tree/main/kub... reply KronisLV 8 hours agorootparent> Yes, it is somewhat nicely abstracted away, but that doesn't change the fact that in the kube directory alone [1] there are 10 subfolders with even more config files. That's just what you get with Kubernetes, most of the time. Although powerful and widely utilized, it can be quite... verbose. For a simpler interpretation, you can look at https://github.com/hcengineering/huly-selfhost/blob/main/tem... There, you have: mongodb supporting service minio supporting service elastic supporting service account their service workspace their service front their service collaborator their service transactor their service rekoni their service I still would opt for something simpler than that and developing all of the above services would keep multiple teams busy, but the Compose format is actually nice when you want to easily understand what you're looking at. reply matly 5 hours agorootparentAs someone that develops native Kubernetes platforms: Providing the raw resources / manifests is almost the worst way of providing a user install. That works great as long as you never have a breaking change in your manifests or any kind of more complex upgrade. Which brings me back to the initial question: Is this complexity and the external dependencies really needed? For a decently decomposed, highly scalable microservice architecture, maybe. For an Open Source (likely) single tenant management platform? Unlikely. It highlights the problem of clashing requirements of different target user groups. reply wruza 7 hours agorootparentprevWe can also take a look at the linux kernel that powers the docker instances and faint in terror. These “moving parts” are implementation details which (iiuc) require no maintenance apart from backing up via some obvious solutions. Didn’t they make docker to stop worrying about exactly this? And you don’t need multiple roles, specialists or competences for that, it’s a one-time task for a single sysop who can google and read man. These management-spoiled ideas will hire one guy for every explicitly named thing. Tell them you’re using echo and printf and they rush to search for an output-ops team. reply matly 4 hours agorootparentThese moving parts require active understanding and maintenance, as they will change on each and every upgrade, which also requires manual upgrade steps and potential debugging on breaking changes. OCI images let you worry less about dependencies, but what they don't eliminate is debugging and/or upgrading k8s configuration manifests (which we are looking at here). > We can also take a look at the linux kernel that powers the docker instances and faint in terror. Sure, and computers are rocks powered by lightning - very, very frighting. That doesn't invalidate criticism about the usability and design of this very product my friend. reply wruza 2 hours agorootparentThese moving parts require active understanding and maintenance, as they will change on each and every upgrade, which also requires manual upgrade steps and potential debugging on breaking changes Maybe they won’t change or migrations will be backwards-compatible. We don’t know that in general. Pretty sure all the software installed on my PC uses numerous databases. But somehow I never upgraded them manually. I find the root position overdefensive at best. If it were a specific criticism, fine. But it uses lots of assumptions as far as I can tell, cause it references no mds, configs, migrations, etc. It only projects a general idea about issues someone had at their org in some situation. This whole “moving parts” idiom is management speak. You either see a specific problem with a specific setup, or have to look inside to see it. Everything else is fortune telling. reply nearportland 11 hours agoparentprevThanks so much for the analysis. I wish that people would simplify shit more. I think that self hosted has two meanings and not every person that self hosts want to use docker. reply KronisLV 11 hours agoparentprevThe most complex system that I've seen that you could self host is the Sentry APM solution, have a look at how many services there are: https://github.com/getsentry/self-hosted/blob/master/docker-... That's the main reason why I've gone why Apache Skywalking instead, even if it's a bit jank and has fewer features. It's kind of unfortunate, either you just have an RDBMS and use it for everything (key-value/document storage, caches, queues, search etc.), or you fan out and have Valkey, RabbitMQ and so on, increasing the complexity. That's also why at the moment I use either OpenProject (which is a bit on the slow side but has an okay feature set) or Kanboard (which is really fast, but slim on features) for my self-hosted project management stuff. Neither solution is perfect, but at least I can run them. reply rbut 10 hours agorootparentWe had to roll back to an earlier version of Sentry for this exact reason. It went from a few gb to using 18gb+ of RAM and a factor more number of containers. The older version had every feature we wanted, so there was no need to move forward. reply Summerbud 6 hours agoparentprevPersonal observation: Company use this strategy to redirect user into using their cloud platform and open-source is an go-to-market strategy. I think this pattern is not that harsh if they have a script to guarantee setting up a k8s cluster or some sort of that. reply atmosx 4 hours agoparentprevThat's kind solves, isn't it? Create interfaces for the components (DBs, Queues, etc) and let the users decide. reply rkagerer 13 hours agoparentprevWell, it gives you more projects with which you can use it to manage! reply theK 14 hours agoparentprevCan't such issues be solved by having something like a helm chart with meaningful scaling cofigs provider? Nexclozlud dies somthing like this and it makes scaling the cluster a breeze. reply johnny22 13 hours agoparentprevI'd like to see more of something like this https://github.com/electric-sql/pglite in combination with a redis/valkey compatible API and then you could still have it run out of the box, but allow folks to point to external servers too for both of those services if they need to scale. Although you do lack the simple on-disk db format that way. reply jstummbillig 8 hours agoparentprevIt always seems like Rails is ahead with understanding what is actually important for most people (before or if mosz people get around to understanding it). Looking at 8 in regards to this issue reinforces that once again. reply bastawhiz 14 hours agoparentprevMy philosophy is that's fine, as long as I get a terraform module that sets up the infra for me. Knowing how to glue the pieces together is often the vast majority of the effort. reply j45 9 hours agoparentprevIf docker is spinning all the services up it’s not as big of a deal. Unfortunately, JavaScript based apps can be quite convoluted to output HTML and JavaScript. reply al_borland 5 hours agorootparent>If docker is spinning all the services up it’s not as big of a deal. Until something goes wrong, or the business side of the house asks for some kind of customization. reply colordrops 14 hours agoparentprevSuper important point. I work for a very large famous company and deployed an open source project with a bit of customization which became one of the most used internal apps at the company. It was mainly front end code. It gained a lot of traction on GitHub, and the developer decided to create 2.0, which ended up having dependencies on things like supabase. I did all I could to try to deploy supabase internally but it was just too much of an impedence mismatch with our systems, so we ended up punting and going with another provider. If they just went with raw Postgres it would have been fine as we already have a Postgres provider internally, but I wasn't willing to commit to being the maintainer for a supabase and its many moving parts as a frontend engineer. reply danpalmer 13 hours agorootparentEvery decision for an external dependency that a self-hosted service makes is another chance for it to have that impedance mismatch you mentioned. Postgres is a relatively uncontroversial one, but I had the benefit of working for a company already operating a production postgres cluster where I could easily spin up a new database for a service. I went with SQLite/on disk storage because for most companies, providing a resilient block storage device, with backups, is likely trivial, regardless of which cloud they're on, being on bare metal, etc. reply nine_k 12 hours agorootparentSQLite is fine and dandy as long as you don't do a lot of updates. SQLite locks the entire database for a transaction. It may be fine for quite long, or you may face slowdowns with just a few parallel users, depending on your use case. reply emptiestplace 14 hours agoparentprevAre you against using containers? reply danpalmer 14 hours agorootparentNot at all, but they don't solve this problem. They help, but just because a database is in a container doesn't mean you don't need to know how it operates. Containerised databases don't necessarily come with maintenance processes automated, or may automate them in a way that isn't suitable for your needs. Postgres vacuuming comes to mind as an example. Pre-built docker images of it often just ignore the problem and leave it up to the defaults, but the defaults rarely work in production and need some thought. Similarly, you can tune Postgres for the type of storage it's running on, but a pre-built container is unlikely to come with that tuning process automated, or with the right tuning parameters for your underlying storage. Maybe you build these things yourself, but now you need to understand Postgres, and that's the key problem. Containers do mostly solve running the 5 built-in services, at least at small scale, but may still need tuning to make sure each pod has the right balance of resources, has the right number of replicas, etc. reply TomK32 12 hours agoparentprevYeah, for a software I'd use personally, if I don't see a docker-compose.yml I walk away from such a software. Painful enough to write those docker files for client projects that I work on. Huly has docker-compose files hidden and meant for dev? But a quick look into it show a lot of environment variables which is a great thing if you want to use your existing database once the software's use outgrows whatever specific limitations your docker host has. https://github.com/hcengineering/platform/blob/develop/dev/d... Their huly-selfhost project lets you run a setup to create that docker-compose file and it looks decent. reply eastbound 10 hours agorootparentSorry I’m not, but I thought customers would prefer a Kubernetes deployment than docker-compose? Isn’t docker-compose for the programmer’s machine, and isn’t K8s the big microservice organizer of large companies, requiring sysadmins to rewrite the file? Can K8s use docker-compose.yml files? reply matly 9 hours agorootparentKubernetes cannot ingest compose files as-is, no. From a users point of view: If I'm interested in a project, I usually try to run it locally for a test drive. If you make me jump through many complex hoops just to get the equivalent of a \"Hello World\" running, that sucks big time. From a customers point of view: Ideally you want both, local and cluster deployment options. Personally I prefer a compose file and a Helm chart. In this specific case I'd argue that if you're interested in running an OSS project management product, you're likely a small/medium business that doesn't want to shell out for Atlassian - so it's also likely you don't have k8s cluster infrastructure, or people that would know how to operate one. reply XorNot 9 hours agoparentprevAs a counterpoint though, the issue for me is \"environment pollution\" - not then number of products. My metric for this is something like Portainer, where it's installation instructions tend to be \"install this Helm chart on the K8s cluster you already have\" or \"run this script which will install 10 services by a bunch of bash (because it's basically some developers dev environment)\". Whereas what I've always done for my own stuff is use whatever suits, and then deploy via all-in-one fat container images using runit to host everything they need. That way the experience (at most scales I operate at) is just \"run exactly 1 container\". Which works for self-hosting. Then you just leave the hooks in to use the internal container services outside the service for anyone who wants to \"go pro\" about it, but don't make a bunch of opinions on how that should work. reply paulnpace 6 hours agorootparent> ...\"run exactly 1 container\". Which works for self-hosting. On Linux. The container everything trend that also has the effect of removing non-Linux POSIX-ish options from the table. reply eastbound 10 hours agoparentprev> I've been using SQLite and Postgres’ inability to be wrapped in Java (ie SQLite can be run as a Java jar, but PG need to be installed separately, because it’s in C) gives it a major, major drawback for shipping. If you ship installable software to customers, you’ll either have to make it a Docker or publish many guidelines, let alone customers will claim they can only install Oracle and then you’ll have to support 4 DBs. How have you found SQLite’s performance for large-scale deployments, like if you imagine using it for the backend of Jira or any webapp? reply epcoa 2 hours agorootparentSQLite is written in C. And the most commonly used SQLite driver interfaces to that compiled C code directly via JNI. The PostgreSQL client driver is written in pure Java on the other hand. Has nothing to do with language used. You can wrap anything in a jar (it’s just a zip file). You could certainly embed PostgreSQL in a jar and you can do something similar to this https://github.com/electric-sql/pglite I don’t think there’s that much interest, but it is doable. EDIT: https://github.com/zonkyio/embedded-postgres reply KronisLV 8 hours agorootparentprevIf you need a database that you can embed in Java, have a look at: H2: https://www.h2database.com/html/main.html HSQLDB: https://hsqldb.org/ Apache Derby: https://db.apache.org/derby/ Though those would certainly be a bit niche approaches, so you'll find that there are fewer examples of using either online. reply stephenr 14 hours agoparentprevWhen I see things like this where you need a package manager to install a different package manager to install the tool, and the only setup information assumes a bunch of stuff in Docker on a single machine, I just default to assuming it's deliberately over-engineered and under-documented specifically to dissuade self hosting. reply wg0 12 hours agorootparentI have seen open source products that pull 5 redis containers each per type of data/features alone making it all very complicated to operate. That's where the button for \"Cloud Pricing\" comes into play. reply otabdeveloper4 12 hours agorootparentprev> it's deliberately over-engineered and under-documented specifically to dissuade self hosting. This right here. Shitty architecture choices as a deliberate moat. reply olebedev 12 hours agoprevAs a person with russian background I am laughing on the name of the project. With all the respect to the effort, I can’t take it seriously. The «хули» (direct transliteration to huly) means “what a hell” or actually a bit spicier “what a f@ck”. This phrase is common for russian tradies who don’t bather to know anything but where is the nearest bottle shop and how much time left til the end of work shift. The name reminded me PizData project from the russian speakers. What. A. Joke. reply aleksi 10 hours agoparentHuly is being built by Andrey Platov, who was previously infamously known for Xored from Novosibirsk. It is clearly intentional. reply olebedev 7 hours agorootparentRight, then I am not surprised at all. I am looking at his github account now, his status is « твой софт — гавно» (direct translation: « your software — shit»). To me it's a clear message that the author doesn't respect anybody. Also, it seems applicable to potential projects people will build using that Huly tool? I guess my question would be -- how on earth it's possible people trust authors like this and commit into using product built by them? reply nigata 3 hours agorootparentA potential knave then. I know I won't use them. reply trenchgun 7 hours agorootparentprevIt is a fucking great name, now that I know that etymology reply UomoNero 2 minutes agorootparentYes! reply AlexSW 11 hours agoparentprevC.f. 'git', which you probably do use and etymologically is obviously a bit rude and humorous too. reply nine_k 4 hours agorootparentMerriam-Webster says: > as in lunatic a person who lacks good sense or judgment Not marked as rude or profane. reply akho 10 hours agoparentprevThis is pretty clearly built by Russians (look at the Github contributors). reply nilawafer 3 hours agoparentprevHooli? reply burgerrito 8 hours agoparentprevThis reminds me of something called Kontool from Germany (IIRC). Hahaha, I already laugh thinking about it. I think it's an accounting tool, but the name has an unfortunate meaning in Indonesian... it means \"dick\" I guess this kind of things are inevitable... Also, if you see their Twitter account, they clearly are aware of this naming clash and actually embracing it hahaha reply epolanski 8 hours agoparentprevI thought about Huli from Silicon Valley TV show, and couldn't but think \"Gentlemen, and lady, of the board\" reply jesterson 11 hours agoparentprevWhile it may have connotations in specific languages, it doesn't signify quality of the project. Hope we agree on it. reply tryuseless 11 hours agorootparentYes, cut them some Slack. reply olebedev 7 hours agorootparentprevNo, we are not. reply patrickaljord 15 minutes agorootparentwhy not? reply culebron21 8 hours agoparentprevI knew contributor @aplatoff personally, and project name is consistent with his rough and witty character. reply ketzo 14 hours agoprevThe general category of \"project management software\" is obviously a very crowded one. But it's a space where I'm always genuinely excited to see an even-slightly-new take; I think anybody who's worked in a modern workplace would agree that this is very much not a solved problem, and the returns on even small improvements are so huge. Best of luck to Huly, this seems pretty cool. I've never gone all-in on a fully-integrated stack like this (issue tracking + docs + chat + calls), but it seems like in an ideal world, that's what you would want? Huge integration with O365 seems like the one thing people do actually like about MS Teams, for example. Also, I'm a sucker for cool laser animations, so I'm saving the home + pricing pages to an inspiration folder for sure. reply rapht 5 hours agoparentIt's the reason why it can only work at small scale: it's all or nothing. It wants to be your only communication channel. But, surprise, as soon as you live in a larger organisation, there will already be communication channels that serve part of the same purpose. Then most of the functionality become clutter. reply mrbluecoat 14 hours agoparentprevlol, I too was fascinated with their clock animation at the bottom of the homepage. Not really a PM vibe, but cool nonetheless. reply qaq 14 hours agoprevInteresting naming decision it's actually a swear word in russian and given that top contributors are obviously familiar with the lang. that is not a coincidence. reply aakresearch 13 hours agoparentIndeed, I was going to point out that it may be an innocent mistake, like a decade old \"Fedora for Raspberry PI\" blunder. But now I've had a close look at the list of contributors, I cannot stop thinking it is an exquisite trolling! reply hexfish 11 hours agorootparentWhich blunder are you referring to? reply pronik 8 hours agorootparentProbably Pidora, which is also not an inviting name in Russian (connotation with \"fag\"). reply nine_k 12 hours agorootparentprev— You mean, we should make a replacement for every project management tool at once? —not? — OK, I've named the repo just that. reply aldanor 2 hours agoparentprevPerhaps it's to discourage bureaucratic Russian companies from using it :) reply dm33tri 8 hours agoparentprevTotally not a coincidence https://x.com/platoff/status/1737142050603086281 reply sssilver 13 hours agoparentprevInteresting username decision — “qaq” (քաք) is actually the vulgar word for “shit” in Armenian. reply ndndjdjdn 12 hours agorootparent(քաք) sure looks cute though reply yard2010 6 hours agorootparentprevTangibly related: car (kar) means dick in albanian. Imagine elementary english class: \"my father has a huge car, and my mother too\" reply homebrewer 7 hours agorootparentprevEnglish too: https://en.wiktionary.org/wiki/cack reply qaq 9 hours agorootparentprevGood to know reply aakresearch 13 hours agorootparentprevI'm sure GP is aware of this. This root has \"shitty\" connotations in many languages, Russian included. reply qaq 9 hours agorootparentthat def was not the intention :) как is how in russian reply dotty- 14 hours agoprevThe pricing is very interesting. The company I work for pays $20k for Jira & Confluence and $20k for Slack every year. And this platform claims I can replace both of them for $3600/year? and it's open source? The marketing looks great, so I hope the platform is actually a good competitor. I'd be so curious to see what their revenue is every year. reply danpalmer 14 hours agoparentBasecamp is also the same price. SaaS pricing is all made up. If you're a high-margin SaaS company the idea of spending $40k/yr for this seems... fine. If you're a small business, or you operate on retail margins, you'd laugh them out of the room, and rightly so as there are great tools at far better prices. The idea of every service charging $15-30 per user per month is a myth perpetuated by companies who themselves have that budget to spend out of their VC funding. reply imranhou 13 hours agorootparentPostman is one example - imagine spending 30 bucks a month on a tool that lets you call APIs. reply bearjaws 2 hours agorootparentEspecially when Bruno exists. The idea that people are hosting their entire API knowledge base in a third party server instead of their git repo... https://github.com/usebruno/bruno reply danpalmer 12 hours agorootparentprevNot only this, but it's worse for the fact that it's in a web browser, vs just being a native app that could be sold once, or at least with a yearly subscription for maintenance at 1/10th of the cost. The problem is that they realised they could make more money by trying to lock companies into a proprietary API definition platform – they want the design, testing, QA, documentation, etc, all to happen in Postman. reply rty32 8 hours agorootparentI mean, locking users into your platform is one of the most common ways companies make money and keep making money. And that works. If you want an obvious example, look at Apple. reply ndndjdjdn 12 hours agorootparentprevI am of the opinion that curl is better simply because you are already in the command line. You can use vim fzf or bash with it. Also curl will be the same on the day you die. reply rtpg 13 hours agorootparentprevOnly $15-$30 per user! What a deal! Somebody hasn't experienced Salesforce pricing reply colechristensen 12 hours agorootparentprevSaaS pricing is so weird because for so many things because the cost to run per user is almost zero, but then the company is spending tens or hundreds of millions of dollars developing the software. Evernote once had a valuation of nearly 2 billion, and like 400 employees. I replaced it with Obsidian which gives me more value and it was mostly just made by two people, now they list 9 employees, one of whom is the office cat. Each company for me was just syncing some text and maybe a few larger things like PDFs. The actual cost of that is pennies per year. reply prmoustache 7 hours agorootparentprevSaaS pricing is based on how captive the customers can be. I am not a fan of Atlassian products, but what retains them the most aren't the qualities of the products themselves nowadays, but the integration and plugin ecosystem + the difficulty of exporting the data. Nearly every tool has an integration for either jira, bitbucket, confluence, or all of them. And you would usually dismiss any tool that doesn't have them if you are an Atlassian customer already. Once you have set that up but decide you are paying too much for it, good luck good luck telling your users they will surely lose data/formatting/integrations when migrating to some other tool. This + having to train people to use another tool while companies usually take for granted that their users won't get lost in Jira (which really isn't true). Ultimately it becomes more of a tax than a price. reply gempir 12 hours agoprevMy thoughts just from reading the landing page, not having tested it. I think trying to replace all these Apps > serves as an all-in-one replacement of Linear, Jira, Slack, and Notion. is not a wise move. I can see Linear and Jira and maybe Notion, but fighting with Slack just is an uphill battle. There are so many Chat platforms out there and many open source too. Why would yours be the one to be at least on par with the likes of Slack? Which hasn't really happend for the others either. JetBrains tried this with JetBrains Space [1] it used to be a knowledge platform and chat platform all with a code hosting platform, CI platform and a little more. But even an experienced dev company like JetBrains gave that up and focused on the core. I think they should remove the chat part and stick to being a Jira + Notion replacement. [1] https://www.jetbrains.com/space/ reply beAbU 11 hours agoparentI don't think we should discount a competing product's existence just because it's a David and Goliath situation. If we all had your mindset we'd still be using MSN Chat on Windows XP or something. reply johannes1234321 7 hours agoparentprevThing is: You don't have to be on par with Slack. If that chat is \"usable enough\" but integrates well with the rest of the system, this can be a swelling point: Directly reference the tickets in a discussion, reassign, update, ... in a native integration. With such an \"Enterprise\" system the choice of the chat tool is a lot more a too down decision, than a chat in a social group. And it isn't like slack is perfect in all regards either ... reply zild3d 7 hours agorootparentThe concern wouldn't be if huly chat integrates well with the rest of huly project management, video calls, docs. It would be all the other services your company uses like pagerduty, salesforce, HR apps, etc where Slack has become the \"hub\" for everything to integrate with. reply Fuzzwah 33 minutes agorootparentIt's all just webhooks... reply Terretta 7 hours agoparentprev> I think trying to replace all these Apps (“serves as an all-in-one replacement of Linear, Jira, Slack, and Notion”) is not a wise move. As shown in the rendered billboard, they agree with you… \"Huly: the app for – anything – and nothing\" reply Aeolun 12 hours agoparentprevI think the only way they can capture some part of the market is by doing something the others are not. We don’t need another Jira + Notion clone I think. reply Maxion 10 hours agorootparentThere's a reason why Redmine is still in use in many places... reply tremarley 11 hours agoparentprevI think Huly would appeal to people who find peace of mind when using one companies tool, rather than 5 companies tools to do everything they need. Similar to how Notion became popular to people who wanted to use the same app for journaling, knowledge management and CRM, for home and work. Hopefully Huly pulls it off, having so many features that work well isn’t an easy task. reply crabbone 8 hours agoparentprevBefore JIRA became ubiquitous, before Slack even existed, I used to set up company's tools with MediaWiki, Jenkins, IRC, Redmine and GitWeb. The reason I'd choose these is because I knew more or less how to install them. It wasn't based on any sort of comparison of features etc. Looking back at those days, I'd still take IRC over Slack any time. Just for the self-hosting part, but also because of better integration, simpler interface, simpler way of extending it to fit company's needs. I'd also take GitWeb over Gitlab, Bitbucket or Gitea. None of the extras offered by these tools add any real value. The only reason I want any Web interface to Git at all is to be able to link to the code from Wiki / chat. But, Jenkins turned out to be a really bad pick. And so is Redmine. I've tried many popular CI tools, and they are all bad, so, who knows maybe this project will do it better?.. but they don't seem to tell much about how they see things working. I also haven't found a good bug-tracking tool yet. So, maybe this project will make something better? -- Let's hope. ---- Ideally, I'd prefer it if tools around project management standardized around some basic interfaces, so that no single company was tempted to create \"package deals\" where you choose to use crappy tools because they are packaged together with what you really want. But, I don't think it's clear to anyone what such interfaces might look like. So, this isn't happening probably in this decade... at least. reply ikeashark 14 hours agoprevI can't believe Gavin Belson is rejoining Hooli! reply dkga 14 hours agoparentConsider the bulldog reply anonymous8888 14 hours agoparentprevConsider the elephant reply tjpnz 13 hours agoparentprevThe bear is sticky with honey. reply penguin_booze 11 hours agoprevSurely, I'm not the only one thought of Hooli and Gavin Belson? reply tablet 11 hours agoparentMy first thought as well :) Not sure the naming is good. reply Brajeshwar 15 hours agoprevI’m kind of, by default, against meaningless animation, but your reveals and the fiery ones on the Pricing page are awesome. The plans are also generous and made for someone or a small team who needs the features but is not ready to start using all the resources, right away. Best of Luck. Looking good so far from the first browse and scroll-around. reply jonnycoder 14 hours agoparentI literally just stumbled upon the designer and he posted a tutorial on the fiery pricing bento boxes: https://x.com/alex_barashkov/status/1841493887359066421 I am blown away at all of his work. He has some graphics and animation that I want to mimic for a \"solar\" theme I am working on. reply namanyayg 14 hours agorootparentHe billed $90k for the website, design, and motion work. Crazy. reply sixhobbits 10 hours agoprevI've long wanted something similar to this. I currently use Linear as both an ATS and a CRM, and most project management can be reduced to People/Companies, Tasks/Deals, and Pipelines. Linear is not quite flexible enough for what I need as it is too strongly in the task management camp, so I can't define a proper candidate pipeline without hacking what the \"status\" of each \"issue\" means and remembering that. Most small companies don't need dedicated solutions for project management, ats and crm, so I'd love to combine them. But I'd be looking for something more lightweight than this, maybe even local without cloud, but at least single service with sqlite or similar. Would be amazing if it was very customizable to let people build or customize their own pipelines from some basic building blocks, still keeping the slick and fast UI from Linear. I agree going after Slack at the same time is too ambitious. reply zild3d 7 hours agopreveverywhere I look seems to mention a different product it's a replacement for Landing page: \" serves as an all-in-one replacement of Linear, Jira, Slack, and Notion.\" Github repo: \"alternative to Linear, Jira, Slack, Notion, Motion\" Github org: \"Alternative to Jira, Linear, Slack, Notion, Motion, and Roam by Huly Labs\" reply maverickdev69 10 hours agoprevWe’ve been using Plane CE and are really happy with it. For those who need a serious project management tool, I’d definitely recommend giving it a try. Huly looks interesting-might explore it in the future. I did try self-hosting, but the experience wasn’t great. https://github.com/makeplane/plane reply danielovichdk 6 hours agoprevAmazing. All my 25 year long professional programming career the shit around project management systems never fucking stops. Like ORMs, every programmer needs to write one. Pick one. Stick with it. reply farceSpherule 2 hours agoprevWhy do this when you can pay for any number of SaaS products out there? reply nearportland 11 hours agoprevIs there any option for self host that isnt attached to the boat-anchor that is 'docker'? I want to self host this on my public self hosted environment not my LAN side self hosted environment reply wg0 11 hours agoprevI am impressed by the laser border animations on the pricing page and that laser clock. Will check later how they are built. Amazing if CSS alone has advanced that far. reply jryan49 5 hours agoparentIf I disable JS it stops working so I imagine it's not CSS? Also there are no elements really attached to it? EDIT: Ahh it's a video, https://huly.io/videos/pages/pricing/plans/common.mp4 reply wg0 2 hours agorootparentInteresting. Probably won't scale for each screen size and they have few \"video sizes\" reply Havoc 10 hours agoprevKinda curious about the requirements. 4GB minimum. Isn’t a PM platform mostly text-like? Not criticising (gitlab manages same) just curious what’s driving that. reply mdaniel 3 hours agoparentIt's almost certainly their decision to use fucking Elastic for search:although I'm sure mongo isn't helping matters, eitherreply hu3 3 hours agorootparentI'm shopping for a better search engine. Any suggestions? reply mdaniel 3 hours agorootparentI don't believe there is just one answer to that, because it really depends on your needs, existing stack, and skillset. Disclaimer aside, I've heard very positive things about the search that ships with PostgreSQL, and similarly positive things for the few search extensions one can add (assuming extensions are available where you're running PG) https://github.com/quickwit-oss/tantivy#features seems to be a good starting place if you want to embed search, and its https://github.com/quickwit-oss/quickwit friend comes up a lot, but be sure to bear its AGPL license in mind Toshi is one of the ones which is striving for ES compatibility at the search level, making it a drop-in replacement https://github.com/toshi-search/Toshi#example-queries although last time I played with it, they were QUITE A WAYS away, depending on how deep one is in the ES query DSL And then just last weekwe were blessed with Nixiesearchwhich is a pretty specialized engine but will almost certainly be less resource intensive than Elastic (or it's FOSS friend OpenSearch) Browsing https://github.com/topics/search-engine I was reminded about a bunch that I either haven't tried or I tried so long ago I don't recall their pro/con lists https://github.com/meilisearch/meilisearch https://github.com/typesense/typesense https://github.com/qdrant/qdrant https://github.com/valeriansaliou/sonic https://github.com/manticoresoftware/manticoresearch reply mfld 7 hours agoprevWhen I read All-In-One PM and CRM platform I must think of bitrix24, which I think is still widely used. I personally didn't like it because feature creep made the UI quite confusing. reply avanttech 12 hours agoprevSite looks great and opensource moniker while replacing major products with self hosting got me really interested. Checked the github and understood svelte in frontend UI. All the best on your journey. btw, Is video & audio conferencing built from scratch or does it need MS Teams and Zoom or can integrate with 3rd party providers? reply platoff 6 hours agoparentVideo conferencing in Hulu does not need Zoom, etc and currently utilizes the awesome LiveKit (https://livekit.io), which is also open source reply nearportland 11 hours agoprevIs there any option for self host that doesn't get attached to the boat anchor that is 'docker'?? reply Separo 7 hours agoprevMy company uses Linear, Slack, Google Docs, Google Calendar, Monday, GitHub, Discord and more. This, if it works well, would be a godsend. reply lucifer153 10 hours agoprevInterestingly, Huly is also the sponsor of the Zig programming language[1]. [1]: https://ziglang.org/ reply platoff 6 hours agoparentThey are working on the next generation of Hulu in Zig. However, no final decision has been made since they are also sponsoring V (https://vlang.io) and Odin (https://odin-lang.org) :) reply Brajeshwar 14 hours agoprevAh! You guys were Huly.App and this is a relaunch. I had tracked your earlier progress a few months back but forgot about it. Nice, again, best of luck. reply whyowhy3484939 9 hours agoprevProject management strikes me as one of those fuzzy complicated looking problems that, for some reason, are always approached as a single problem that needs one UI. In my mind it is not a single problem. I'd try a more modular approach because IMO a substantial part of the problem is \"horses for courses\": PMs and developers have very different skills and requirements. Even inside those categories there is substantial variation. I see no reason why the UI for developers has to be same as for PMs and higher ups. My ideal PM solution would involve the CLI and the notion of committing changes and being able to organize information cleverly. Efficiency, bare-boned, no fluff, no pixels that add zero information. These would all be things I am interested in. My boss' ideal PM solution would probably involve some unholy marriage of Salesforce, Excel and CSVs without any organization whatsoever in a screen that explodes with fireworks and deliberately slows everything down and adds lag and loading screens so you feel you are doing important work. You can tell I am jaded, but my point is, fine. Let them have it. I see no reason to approach this problem with one, fixed, set of interaction patterns. It's a common theme these days for me. Why does everything has to be so monolithic? Why is everything so samey? reply keybored 4 hours agoparentQuite so. But bad managers have no qualms with making boss-problems and workflows something that their underlings have to deal with as well. reply johannes1234321 7 hours agoparentprevThat's why everybody has their own Jira dashboards showing different information in different structure. Which then leads to people talking about different things. There is some need of differentiation, but also need to make sure there is shared understanding on priorities and state. reply nubela 15 hours agoprevIs it just me that when someone sells something as \"everything\", I immediately feels like it does nothing well? reply platoff 6 hours agoparentHere is Huly's opinion on this topic: https://huly.blog/is-it-time-for-everything-apps reply hakanderyal 15 hours agoparentprevYour assumption is the worst case. Best case is it does the things it do \"good enough\". reply nikolayasdf123 14 hours agoprevthe webiste sure looks flashy reply jatins 14 hours agoparentthis did rounds on Twitter a while back. iirc they spent ~80k USD or similarly high amount for it found the tweet: > We charged $89,775 for this new @huly_io landing page - https://x.com/alex_barashkov/status/1801219973236342910 reply j45 7 hours agoprevHuly doesn’t seem to like to work on mobile. reply mib32 11 hours agoprevHuly tut tak malo? reply brainzap 8 hours agoprevwhere can I find the api docs reply lmc 12 hours agoprevIs anyone using this in a team? How is the perf? reply DoesntMatter22 14 hours agoprevidk if it's just me but if they don't' have a running demo of it I'm not even gonna spend any time unless I'm desperate reply byyoung3 11 hours agoprevgavin belson signature edition reply komali2 5 hours agoprevI really like that you can self host an entire project management stack these days. For my co-op we use OpenProject for Issues / Kanban but it seems it has things like time tracking, wiki, and many other features we don't use because we prefer alternatives. For wiki / notion we use Outline. For slack, Matrix. For CRM, Espo. For code repositories, forgejo, but we don't self host it, we use codeberg. I think this stack would probably cost us a couple thousand of dollars a month if we paid for SaaS since we have around a hundred members. Instead we pay something like 30$/month for a couple hetzner servers through elestio. When I work full time and I get to use all the bells and whistles SaaS products like linear, sometimes I think it's cool that the tool will do something like point out I'm about to create a duplicate ticket... But thousands of dollars a month cooler? Not sure, but not my money! reply zuck_vs_musk 11 hours agoprevI see 'Node.js' and I see something that's going to be unwieldy pretty soon. reply hajimuz 12 hours agoprevlooks pretty convincing! reply jacktheturtle 14 hours agoprevnice landing page, looks good. reply eclipxe 14 hours agoprev [–] This looks really great and love that it can be self hosted. Nice!!! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Huly Platform is a comprehensive framework designed to accelerate the development of business applications, including CRM, HRM, and ATS systems.",
      "The platform supports self-hosting using Docker and requires Node.js, Docker, and Docker Compose for setup, with Microsoft's Rush facilitating installation.",
      "It supports development on amd64 and arm64 architectures for Linux and macOS, and includes unit and UI tests, though local installations lack email functionalities."
    ],
    "commentSummary": [
      "Huly is an open-source project management platform designed to replace tools like Linear, Jira, Slack, and Notion, but requires running multiple servers and services for self-hosting.",
      "The platform's complexity and need for various system expertise may deter users, particularly smaller organizations or those lacking dedicated IT resources.",
      "Despite the challenges, Huly's open-source nature and potential cost savings compared to Software as a Service (SaaS) solutions make it an attractive option for some users."
    ],
    "points": 415,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1728875784
  },
  {
    "id": 41830717,
    "title": "CRLF is obsolete and should be abolished",
    "originLink": "https://fossil-scm.org/home/ext/crlf-harmful.md",
    "originBody": "Fossil CRLF Is Obsolete And Should Be Abolished Login ☰Home Timeline Docs Code Forum Download CRLF Is Obsolete And Should Be Abolished Update 2024-10-14 It seems that (1) there is still more software in circulation that depends on archaic CRLF line endings than I originally thought and (2) many people do not share my enthusiasm for creating a CRLF-free world. Alas. This makes me sad, but it is what it is. Thanks to everyone who was willing to give the idea a test run. It almost worked! I hereby withdraw the proposal and have reverted all my systems to generate CRLFs when required by spec. Bummer. One unexpected benefits of this experiment is that I found and fixed cases in Fossil and althttpd where those programs were requiring CRLF and would not allowing a bare NL as a substitute. The original document follows: Definitions Carriage-Return (CR) → Move the cursor to the left margin but keep it on the same row. LineFeed (LF) → Move the cursor down one row, causing all prior rows to scroll upwards, but keep the cursor on the same column. NewLine (NL) → Move the cursor down one row and to the left margin. Observations CR and NL are both useful control characters. NL is the most common operation - start a new line of text at the left margin. CR by itself is occasionally useful for when you want to overwrite a line of text you have just written. LF, on the other hand, is completely useless. Nobody ever wants to be in the middle of a line, then move down to the next line and continue writing in the next column from where you left off. No real-world program ever wants to do that. LF originated about 70 years ago in the age of mechanical teletype machines. Teletypes had no transistors. They were constructed purely of gears, cams, motors, relays, and servos. There were amazing, able to convert binary codes received over a twisted pair of copper wires into printed text on paper. Teletypes (technically \"teleprinters\" - \"teletype\" was just the most popular brand name) would print about 5 characters per second. The print head was a cylindrical or oval ball containing the letters to be printed. In between the ball and the paper was an cloth ribbon embedded with ink. To print one character, the ball would twist to the correct position for that letter and bang forward, causing ink from the ribbon to mark the paper in the shape of the desired letter. After each letter, the whole print-head mechanism (the ball and the ink ribbon and various control cams and gears) would shift to the right by one letter. This was happening five times per second. These machines made a lot of noise and shook noticeably when in operation. At the end of a line of text, the print head would have to traverse all the way back to the left margin. The print head moved fast, but moving all the way to the left still took time. There was no memory, and so the print head had to get all the way over the left before the next printing character arrived. To facilitate that, the NL operation was divided into two sub-operations: CR and LF. The CR would go first and start the print head in motion to the left. While it was still in flight, the LF would arrive and cause the paper cylinder to rotate up one row. That extra LF character gave the print head sufficient time to make it all the way over to the left margin before the next printing character arrived. Thus, the tradition of ending a line of text with CRLF goes back to the mechanical limitations of teleprinters from the the 1950s. It is a classic example of the implementation showing through into the interface. By the age of Multix and Unix in the late 1960s and early 1970s, most people recognized that using CRLF as a NL was silly, and so the task of sending separate CR and LF characters was relegated to the device drivers for teleprinters, since that is where work-arounds for hardware quirks belong. The computer sending the text would hold only a single NL character - adopting the same code for NL as the teleprinters used for LF, because a true LF is useless in every practical sense and so its numeric code was available for reuse as NL. Today, CR is represented by U+000d and both LF and NL are represented by U+000a. Almost all modern machines use U+000a to mean NL exclusively. That meaning is embedded in most programming languages as the backslash escape . Nevertheless, a minority of machines still insist on sending a CR together with their NLs, the official Unicode name for U+000a is still LF, and various protocols (HTTP, SMTP, CSV) still \"require\" CRLF at the end of each line. Almost all software these days will accept a single NL character without a preceding CR to mean end-of-line. You need to search really, really hard to find a device or application that actually interprets U+000a as a true linefeed. This tradition of sending useless CR characters before every NL, a tradition that dates back to the era of rotary-dial phones, and before the invention of integrated circuits, needs to end. There is no reason in our modern world to continue sending CRLF. The extra CR serves no useful purpose. It is just a needless complication, a vexation to programmers, and a waste of bandwidth. Call To Action Therefore, let everyone who seeks peace and simplicity and the flourishing of humanity join with me in opposing the use of CRLF and helping CRLF move swiftly towards its ultimate end as an historical curiosity, by agreeing as follows: Stop using \"linefeed\" as the name for the U+000a code point. Nearly all tech built within the past two decades, and a majority of tech from the past half century understands U+000a as a \"newline\", not \"linefeed\". \"Linefeed\" might be its historical name, but who cares. In near universal practice, it is used as a newline so call it \"newline\". Stop sending unnecessary CRs. Use CR only when you really do want to overwrite the current line with something new. CR before NL is a pointless waste of bandwidth. Use CR before NL only in the extreme case of having to communicate with obstinate systems over which you have no control and that insist on living in the 1950s. Even if an established protocol (HTTP, SMTP, CSV, FTP) technically requires CRLF as a line ending, do not comply. Send only NL. Almost all implementations of these protocols will accept a bare NL as an end-of-line mark, even if it is technically incorrect. Give no quarter to the tyranny of CRLF. Fix software that misbehaves or raises errors when it receives a NL without a preceding CR. All modern software should accept a bare U+000a character as a valid end-of-line mark. Systems may accept a CR before NL, for backwards compatibility. But software that requires a CR before NL is broken. Summary And Authorship The end of CRLF is long overdue. Let's work together to put this anachronism to rest. Let's make CRLF one less thing that your grandchildren need to know about or worry about. Written by D. Richard Hipp, creator of SQLite, Fossil, Althttpd, et cetera, in Charlotte, NC, USA on 2024-10-10 with minor edits thereafter. This page was generated in about 0.004s by Fossil 2.25 [521da5cd31] 2024-10-14 01:10:04",
    "commentLink": "https://news.ycombinator.com/item?id=41830717",
    "commentBody": "CRLF is obsolete and should be abolished (fossil-scm.org)398 points by km 23 hours agohidepastfavorite243 comments michaelmior 22 hours ago> various protocols (HTTP, SMTP, CSV) still \"require\" CRLF at the end of each line What would be the benefit to updating legacy protocols to just use NL? You save a handful of bits at the expense of a lot of potential bugs. HTTP/1(.1) is mostly replaced by HTTP/2 and later by now anyway. Sure, it makes sense not to require CRLF with any new protocols, but it doesn't seem worth updating legacy things. > Even if an established protocol (HTTP, SMTP, CSV, FTP) technically requires CRLF as a line ending, do not comply. I'm hoping this is satire. Why intentionally introduce potential bugs for the sake of making a point? reply FiloSottile 22 hours agoparentExactly. Please DO NOT mess with protocols, especially legacy critical protocols based on in-band signaling. HTTP/1.1 was regrettably but irreversibly designed with security-critical parser alignment requirements. If two implementations disagree on whether `A:BC:D` contains a value for C, you can build a request smuggling gadget, leading to significant attacks. We live in a post-Postel world, only ever generate and accept CRLF in protocols that specify it, however legacy and nonsensical it might be. (I am a massive, massive SQLite fan, but this is giving me pause about using other software by the same author, at least when networks are involved.) reply pdw 19 hours agorootparentHTTP is saved here because headers aren't allowed to contain control characters. A server that is strict enough to only recognize CRLF will hopefully also be strict enough to reject requests that contain invalid characters. The situation is different with SMTP, see https://www.postfix.org/smtp-smuggling.html reply kragen 16 hours agorootparentHopefully is not a good word to see in a argument that a software proposal is secure. Myself, I've written an HTTP server that is strict enough to only recognize CRLF, because recognizing bare CR or LF would require more code†, but it doesn't reject requests that contain invalid characters. It wouldn't open a request-header-smuggling hole in my case because it doesn't have any proxy functionality. One server is a small sample size, and I don't remember what the other HTTP servers I've written do in this case. ______ † http://canonical.org/~kragen/sw/dev3/httpdito-readme http://canonical.org/~kragen/sw/dev3/server.s reply tptacek 22 hours agorootparentprevThis would be more persuasive if HTTP servers didn't already widely accept bare 0ah line termination. What's the first major public web site you can find that doesn't? reply LegionMammal978 19 hours agorootparentGoing down a list of top websites, these URLs respond with HTTP 200 (possibly after redirections) when sent an ordinary HTTP/1.1 GET request with 0D0A line endings, but respond with HTTP 400 when sent the exact same request with 0A line endings: https://br.pinterest.com/ https://www.pinterest.co.uk/ https://apps.apple.com/ https://support.apple.com/ https://podcasts.apple.com/ https://music.apple.com/ https://geo.itunes.apple.com/ https://ncbi.nlm.nih.gov/ https://www.salesforce.com/ https://www.purdue.edu/ https://www.playstation.com/ https://llvm.org/ https://www.iana.org/ https://www.gnu.org/ https://epa.gov/ https://justice.gov/ https://www.brendangregg.com/ http://heise.de/ https://www.post.ch/ http://hhs.gov/ https://oreilly.com/ https://www.thinkgeek.com/ https://www.constantcontact.com/ https://sciencemag.org/ https://nps.gov/ https://www.cs.mun.ca/ https://www.wipo.int/ https://www.unicode.org/ https://economictimes.indiatimes.com/ https://science.org/ https://icann.org/ https://caniuse.com/ https://w3techs.com/ https://chrisharrison.net/ https://www.universal-music.co.jp/ https://digiland.libero.it/ https://webaim.org/ https://webmd.com/ This URL responds with HTTP 505 on an 0A request: https://ed.ted.com/ These URLs don't respond on an 0A request: https://quora.com/ https://www.nist.gov/ Most of these seem pretty major to me. There are other sites that are public but responded with an HTTP 403, probably because they didn't like the VPN or HTTP client I used for this test. (Also, www.apple.com is tolerant of 0A line endings, even though its other subdomains aren't, which is weird.) reply tptacek 19 hours agorootparentYou sure about this? www.pinterest.com, for instance, does not appear to care whether I 0d0a or just 0a. reply LegionMammal978 18 hours agorootparentMy apologies, I was using a client which kept the connection alive between the 0D0A and 0A requests, which has an effect on www.pinterest.com. Rerunning the test with separate connections for 0D0A and 0A requests, www.pinterest.com and phys.org are no longer affected (I've removed the two from the list), but all other URLs are still affected. reply tptacek 18 hours agorootparentI picked one at random --- hhs.gov --- and it too appears to work? For what it's worth: I'm testing by piping the bytes for a bare-newline HTTP request directly into netcat. reply LegionMammal978 17 hours agorootparentMake sure you're contacting hhs.gov and not www.hhs.gov, the www. subdomain reacts differently. $ printf 'GET / HTTP/1.1\\rHost: hhs.gov\\r\\r'nc hhs.gov 80 HTTP/1.1 302 Found Date: Mon, 14 Oct 2024 01:38:29 GMT Server: Apache Location: http://www.hhs.gov/web/508// Content-Length: 212 Content-Type: text/html; charset=iso-8859-1 302 FoundFound The document has moved here.^C $ printf 'GET / HTTP/1.1Host: hhs.gov'nc hhs.gov 80 HTTP/1.1 400 Bad Request Date: Mon, 14 Oct 2024 01:38:40 GMT Server: Apache Content-Length: 226 Connection: close Content-Type: text/html; charset=iso-8859-1 400 Bad RequestBad Request Your browser sent a request that this server could not understand. reply tptacek 16 hours agorootparentAhh, that was it, thanks. reply shadowgovt 5 hours agorootparentAnd this whole exercise is an example of why this is a non-starter proposal (at least the \"change existing implementations\" part). How much do we expect the domain owners to invest in changing an implementation that already works? Hint: it's a number smaller than epsilon. Google might, but their volume is so high they care about the cost of individual bytes on the wire. reply tptacek 3 hours agorootparentThis exercise was about demonstrating that our security can't rely on making sure there's a carriage return in HTTP line termination, because there is no such norm. See the root of the thread, where I asked the question. reply shadowgovt 2 hours agorootparentOh, I agree it's about that too, but my point is you've already volunteered more time and resources investigating the situation than most companies would be willing to spend. reply hifromwork 20 hours agorootparentprevAs the parent mentioned, it's security critical that every HTTP parser in the world - including every middleware, proxy, firewall, WAF - parses the headers in the same way. If you write a HTTP parser for a server application it's imperative you don't introduce random inconsistences with the standard (I can't believe I have to write this). On the other hand, as a client, it's OK to send malformed requests, as long as you're prepared that they may fail. But it's a weird flex, legacy protocols have many warts, why die on this particular hill. reply tptacek 20 hours agorootparentThat appears to be an argument in favor of accepting bare-0ah, since as a positive statement that is the situation on the Internet today. reply theamk 18 hours agorootparentWouldn't the safest thing, security-wise, to fail fast on bare 0ah? As a web server, you may not know which intermediate proxies did the request traverse before arriving to your port. Given that request smuggling is a thing, failing fast with no further parsing on any protocol deviations seems to be the most secure thing. reply tptacek 18 hours agorootparentI mean the safest thing would be to send an RST as soon as you see a SYN for 80/tcp. reply theamk 16 hours agorootparentThat would have a severe downside of not letting your customers access your website. Fast-abort on bare-0ah will still be compatible with all browsers and major http clients, thus providing extra mitigations practically for free. reply RedShift1 18 hours agorootparentprevWouldn't not replying at all be the safest? reply MobiusHorizons 15 hours agorootparentprevIf you expect to be behind a reverse proxy that manages internal headers for you (removes them on incoming requests, and adds them based on internal criteria) then accepting bare 0x0a newlines could be a security vulnerability, as a malicious request could sneak an internal header that would not be stripped by the reverse proxy. reply inopinatus 13 hours agorootparentprevThat was already motivated by Postel's Law. It's a step beyond to change what the strict form is; relying on the same to justify unilaterally transposing the form is asking too much of middlebox implementations of just about any line-oriented protocol, and possible violates Postel's Law itself by asserting the inverse. reply tptacek 11 hours agorootparentI don't believe in Postel's Law, but I also don't believe in reverential adherence to standards documents. Make good engineering decisions on their own merits. This article is right: CRLF is dumb. You know who agrees with me about that? The IETF, in their (very old) informational RFC about the origins of CRLF in their protocols. reply account42 9 hours agorootparentprev> As the parent mentioned, it's security critical that every HTTP parser in the world - including every middleware, proxy, firewall, WAF - parses the headers in the same way. If you write a HTTP parser for a server application it's imperative you don't introduce random inconsistences with the standard (I can't believe I have to write this). No it isn't, at least not critical to all those parsers. My HTTP server couln't care less if some middle boxes that people go through are less or more strict in their HTTP parsing. This only becomes a concern when you operate something like a reverse proxy AND implement security-relevant policies in that proxy. reply FiloSottile 21 hours agorootparentprevHrm, this is what I get for logging in to HN from my phone. It’s possible I am confusing this with one of the other exploitable HTTP/1.1 header parser alignment issues. Maybe this was so widespread that ~everything already handles it because non-malicious stuff breaks if you don’t. In that case, my bad, but I still would like to make a general plea as an implementer for sticking strictly to specified behavior in this sort of protocols. reply rtpg 19 hours agorootparentprevGunicorn expects `\\r` for lines (see gunicorn/http/message.py:read_line), though it's possible that every middleware that is in front of gunicorn in practice normalizes lines to avoid this issue. reply tptacek 18 hours agorootparentYep, tested it locally, you're right; gotta CRLF to gunicorn. reply michaelmior 22 hours agorootparentprevWe're talking about servers and clients here. The best way to ensure things work is to adhere to an established protocol. Aside from saving a few bytes, there doesn't seem to be any good reason to deviate. reply tptacek 21 hours agorootparentI'm saying the consistency that Filippo says our security depends on doesn't really seem to exist in the world, which hurts the persuasiveness of that particular argument in favor of consistency. reply dwattttt 21 hours agorootparentBut no one expects 0ah to be sufficient. Change that expectation, and now you have to wonder if your middleware and your backend agree on whether the middleware filtered out internal-only headers. reply tptacek 21 hours agorootparentYeah, I'm not certain that this is a real issue. It might be? Certainly, I'm read in to things like TECL desync. I get the concern, that any disagreement in parsing policies is problematic for HTTP because of middleboxes. But I think the ship may have sailed on 0ah, and that it may be the case that you simply have to build HTTP systems to be bare-0ah-tolerant if you want your system to be resilient. reply dwattttt 19 hours agorootparentBut what's bare-0ah-tolerant? Accepting _or_ ignoring bare 0ah's means you need to ensure all your moving parts agree, or you end up in the \"one bit thinks this is two headers, others think it's one header\". The only situation where you don't need to know two policies match is when one of the policies rejects one of the combinations outright. Probably. Maybe. EDIT: maybe it's better phrased as \"all parts need to be bare-0ah-strict\". But then it's fine if it's bare-0ah-reject; they just need to all be strict, one way or the other. reply immibis 10 hours agorootparentprevSecurity also doesn't exist as much as we'd like it to, which doesn't excuse making it exist even less. reply Aeolun 18 hours agorootparentprevWell, you can achieve the desired behavior in all situations by ignoring CR and treating any seen LF as NL. I just don’t see why you’d not want to do that as the implementer. If there’s some way to exploit that behavior I can’t see it. reply immibis 6 hours agorootparentThe exploit is that your request went through a proxy which followed the standard (but failed to reject the bare NL) and the client sent a header after a bare NL which you think came from the proxy but actually came from the client - such as the client's IP address in a fake X-Forwarded-For, which the proxy would have removed if it had parsed it as a header. This attack is even worse when applied to SMTP because the attacker can forge emails that pass SPF checking, by inserting the end of one message and start of another. This can also be done in HTTP if your reverse proxy uses a single multiplexed connection to your origin server, and the attacker can make their response go to the next user and desync all responses after that. reply Ekaros 21 hours agorootparentprevThere is very good reasons not to deviate as mismatch in various other things that can or are not on the path can affect things. Like reverse proxies, load balancers and so on. reply rtpg 19 hours agorootparentprevTook me a second to get what was going on here, but basically the idea is that you middleware might not see `C:D`, but then your application _does_ see `C:D`. And given your application might assume your middleware does some form of access control (for example, `X-ActualUserForReal` being treated as an internal-only header), you could get around some access control stuff. Not a bytes-alignment thing but a \"header values disagreement\" thing. This is an issue if one part of your stack parses headers differently than another in general though, not limited to newlines. reply Spooky23 19 hours agorootparentprevWhat a weird reaction. Microsoft’s use of CRLF is an archaic pain in the ass. Taking a position that it should be deprecated isn’t radical or irresponsible — Microsoft makes gratuitous changes to things all of the time, why not this one? Hipp is probably one of the better engineering leaders out there. His point of view carries weight because of who he is, but should be evaluated on its merits. If Microsoft got rid of this crap 30 years ago, when it was equally obsolete, we wouldn’t be having this conversation; if nobody does, our grandchildren will. reply theamk 18 hours agorootparentNo one is talking about Microsoft and whatever it does on its platform, the parent comment is about network protocols (HTTP, SMTP and so on..). I understand that it is tempting to blame Microsoft for \\r proliferation, but it does not seem to be the case - the \\r is comes from the era of teletypes and physical VT terminals. You can still see the original \"NL\" in action (move down only, do not go back to start of line) on any Unix system by typing \"(stty raw; ls)\" in a throw-away terminal. reply michaelmior 7 hours agorootparentprevI didn't say we shouldn't get rid of it. I'm saying we shouldn't intentionally break existing protocols. reply vrighter 5 hours agorootparentprevHe's not arguing for deprecating it. He's arguing for just not complying and hoping for the best. He explicitly says so right in the article. That is never the right approach. You intentionally introduce a problem you expect others to fix. All because he doesn't like 0x0d. The protocol is what it is. If you want to make more sane decisions when designing a new protocol (or an explicitly newer version of some existing one) then by all means, go for it. But intentionally breaking existing ones is not the way to go. reply naikrovek 16 hours agorootparentprevCRLF was the correct way to implement a new line the way we think of it now, because teletypes and typewriters considered the “return to the 0th column” and “go to the next line” to be different things that are each valid on their own. CRLF was the standardized way to implement “go down one line and return to column zero” and they’re the only ones who implemented new lines correctly at the outset. Blaming Microsoft now, because they like backwards compatibility above almost everything else, is misplaced and myopic. reply 0points 5 hours agorootparentAdditionally it is also dishonest to bring Microsoft into the discussion like that. The discussion revolved around _standardized_ network protocols, which is entirely unrelated to MS-DOS text formats. reply deanishe 2 hours agorootparentprev> but this is giving me pause about using other software by the same author Go read the article again. I think you'll be pleasantly surprised. reply mackal 21 hours agorootparentprev> massive SQLite fan, but this is giving me pause about using other software by the same author Even if I wanted to contribute code to SQLite, I can't. I acknowledge the fact God doesn't exist, so he doesn't want my contributions :P reply somat 19 hours agorootparentHe does not want your code anyway, sqlite is public domain. this has several implications. One of which is the author wants nothing from you. Note that public domain is fundamentally different than the usual method of releasing code, which is to issue a license to distribute a copyright protected work. Putting a thing into the public domain is to renounce any ownership over the thing. I think that the proper spirit of the thing is that if you have patches to sqlite is to just maintain them yourself. if you are especially benevolent you will put the patches in the public domain as well. and if they are any good perhaps the original author will want them. In fact the public domain is so weird, some countries have no legal understanding of it. originally the concept was just the stance of the US federal government that because the works of the government were for the people, these works were not protected by copyright, and could be thought of as collectively owned by the people, or in the public domain. Some countries don't recognize this. everything has to be owned by someone. and sqlite was legally unable to be distributed in these countries, it would default to copyright with no license. reply refulgentis 22 hours agorootparentprevI wouldn't be too worried and making personal judgements, he says the same thing you are (though I assume you disagree) reply amluto 22 hours agoparentprev> I'm hoping this is satire. Why intentionally introduce potential bugs for the sake of making a point? It’s worse than satire. Postel’s Law is definitively wrong, at least in the context of network protocols, and delimiters, especially, MUST be precise. See, for example: https://www.postfix.org/smtp-smuggling.html Send exactly what the spec requires, and parse exactly as the spec requires. Do not accept garbage. And LF, where CRLF is specified, is garbage. reply tptacek 22 hours agorootparentIf two systems agree, independent of any specification someone somewhere else wrote, to accept a bare NL where a CRLF is specified, that is not \"garbage\". Standards documents are not laws; the horse drags the cart. reply djbusby 21 hours agorootparentThat's just two systems that happen to agree on garbage. reply throwaway19972 6 hours agorootparentAt that point, what does garbage even mean? There's just functional software and non-functional software. reply DaiPlusPlus 22 hours agorootparentprev> Standards documents are not laws; the horse drags the cart. They can be: c.f. legally-enforced safety-regulations. reply tptacek 22 hours agorootparentThese aren't. reply Joker_vD 10 hours agorootparentprevThis is, by the way, exactly the stance the Microsoft used to have in the 90-s and 00-s on the standards (it probably still has). And MS caught a lot of flak for that, for a very good reason. reply perching_aix 22 hours agorootparentprevLaws are also just some ink on paper (and are routinely overruled, circumvented or unenforced in certain jurisdictions), so using this kind of logic in order to encourage standard violations is unsound. There is a method to this madness, and that's revising the standards. reply tptacek 21 hours agorootparentWhat's a \"standard violation\"? The original history of the IETF is a rejection of exactly this mode of thinking about the inviolability of standards, which was the ethos of the OSI. reply nsnshsuejeb 21 hours agorootparentElephant in the room is the trillions of actual servers and user agents that would need to be tested and patched if you retroactively change a standard. Luckily there are some digits after HTTP that allow the concept of new versions of the standard. reply perching_aix 21 hours agorootparentprevWhen an implementation is noncomformant to a standard in question. reply tptacek 21 hours agorootparentIETF standards are tools to help developers get stuff done on the Internet. They are not the only tool, and they don't carry any moral force. reply perching_aix 21 hours agorootparentApart from colloquially considering standards not-necessarily-normative being, in my opinion, nonsensical (see below), to the best of my knowledge at the very least the STD subseries of IETF standards documents are normative in nature: https://datatracker.ietf.org/doc/std > They are not the only tool, and they don't carry any moral force. Indeed there are countless other standards bodies in the world also producing normative definitions for many things, so I'm definitely a bit confused why the focus on IETF specifically. To be even more exact, I do not know of any standards bodies who would publish what they and the world consider as standards, that would be entirely, or at least primarily, informational rather than normative in nature. Like, do I know the word \"standard\" incorrectly? What even is a point of a standard, if it doesn't aim to control? reply tptacek 20 hours agorootparentOk, but just to be clear: the standards-track HTTP RFC says you can use a single LF. I don't think this issue is as clear as people seem to want it to be. reply vitus 19 hours agorootparentSure. HTTP/1.1 isn't the only network protocol, though, IETF standardization or otherwise. For SMTP (which this subthread started with): In addition, the appearance of \"bare\" \"CR\" or \"LF\" characters in text (i.e., either without the other) has a long history of causing problems in mail implementations and applications that use the mail system as a tool. SMTP client implementations MUST NOT transmit these characters except when they are intended as line terminators and then MUST, as indicated above, transmit them only as asequence. https://datatracker.ietf.org/doc/html/rfc5321#section-2.3.8 reply halter73 19 hours agorootparentprevCan you provide a citation for this? I’ve read older RFCs that \"recommend\" recipients allow single LFs to terminate headers for robustness. I’ve also read newer RFCs that weaken that recommendation and merely say the recipient \"MAY\" allow single LFs. I’ve never noticed an HTTP RFC say you can send headers without the full CRLF sequence, but maybe I missed something. https://datatracker.ietf.org/doc/html/rfc2616#section-19.3 https://datatracker.ietf.org/doc/html/rfc9112#section-2.2 reply perching_aix 20 hours agorootparentprevAh, this is a subthread about HTTP specifically - didn't notice. Explains why you focused on the IETF too. Nevertheless, my points I believe still all stand. As for HTTP or any other protocols' definitions go, I'd rather not join in on that back and forth. I'd imagine it's well defined what's expected. Skim reading RFC-2616 now certainly suggests so. reply convolvatron 18 hours agorootparentprevnone of this is as clear as anyone wants it to be. if standards _could_ be completely formally described, it would be an entirely different world. I did quite a bit of work implementing draft standards in the IETF, and and the end of the day the standard is the best we can make it, but for non-trivial things good luck actually implementing it without something to test against or a reference implementation. thats the context in which Postel's law make absolute sense. not that you should forgo any sanity checking, or attempt to interpret garbage or make up frame boundaries. but when there is a potential ambiguity, and you can safely tolerate it, then its really helpful for you to do so. reply sophacles 19 hours agorootparentprevI've implemented a lot of protocols. Most implementations I've come across for most protocols not strictly standards conformant, for many reasons. Big ones being: * The standards are often not detailed enough, or contain enough loose verbage that there are many ways to understand how to implement some part, yet those ways are not interoperable. * Many protocols allow vendor specifications in such a way that 2 implementations that are 100% compliant won't interoperate. * Many protocol implementations are interoperable quite well, converging on behavior that isn't specified in any standard (often to the surprise of people who haven't read the relevant standards) At least this is my experience for ietf rfc standards. reply perching_aix 17 hours agorootparentI'm aware of these factors, wasn't trying to suggest that the practice doesn't differ from the theory. What I was more going for was to highlight that the goal should be to primarily try and have these eventually converge, preferably sooner than later, not trying to strongarm the practice side and wait for the standards body in question to wake up one day and decide to amend the standard. That might give the impression of suddenness, but the core issue remains unsolved that way. Usually when there's a high disparity between the \"de jure\" and the \"de facto\", it's due to a discrepancy in the interests and the leverage, resulting in a breakdown in communication and cooperation. Laying into either then is a bandaid attempt, not a solution. It's how either standard sprawl starts, or how standards bodies lose relevance. reply halter73 21 hours agoparentprev> I'm hoping this is satire. Me too. It's one thing to accept single LFs in protocols that expect CRLF, but sending single LFs is a bridge to far in my opinion. I'm really surprised most of the other replies to your comment currently seem to unironically support not complying with well-established protocol specifications under the misguided notion that it will somehow make things \"simpler\" or \"easier\" for developers. I work on Kestrel which is an HTTP server for ASP.NET Core. Kestrel didn't support LF without a CR in HTTP/1.1 request headers until .NET 7 [1]. Thankfully, I'm unaware of any widely used HTTP client that even supports sending HTTP/1.1 requests without CRLF header endings, but we did eventually get reports of custom clients that used only LFs to terminate headers. I admit that we should have recognized a single LF as a line terminator instead of just CRLF from the beginning like the spec suggests, but people using just LF instead of CRLF in their custom clients certainly did not make things any simpler or easier for me as an HTTP server developer. Initially, we wanted to be as strict as possible when parsing request headers to avoid possible HTTP request smuggling attacks. I don't think allowing LF termination really allows for smuggling, but it is something we had to consider. I do not support even adding the option to terminate HTTP/1.1 request/response headers with single LFs in HttpClient/Kestrel. That's just asking for problems because it's so uncommon. There are clients and servers out there that will reject headers with single LFs while they all support CRLF. And if HTTP/1.1 is still being used in 2050 (which seems like a safe bet), I guarantee most clients and servers will still use CRLF header endings. Having multiple ways to represent the exact same thing does not make a protocol simpler or easier. [1]: https://github.com/dotnet/aspnetcore/pull/43202 reply jfengel 20 hours agorootparentLF only? Huh. In its original terms for printing terminals, carriage return might be ambiguous. It could means either \"just send the print head to column zero\" or \"print head to 0 and advance the line by one\". The latter is what typewriters do for the Return key. But LF always meant Line Feed, moving the paper but not the print head. These are of course wildly out of date concepts. But it still strikes me as odd to see a Line Feed as a context reset. reply romwell 19 hours agorootparent>The latter is what typewriters do for the Return key. Minor correction: mechanical typewriters do not have a Return key, but they have both operations (line feed, as well as carriage return). The carriage return lever is typically rigged to also do line feed at the same time, by a preset amount of lines (which can be set to 0), or you can push the carriage without engaging line feed. Technically, the lever would do LF, and pushing on it further would do CR (tensioning the carriage spring). It is, however, true that most of the time, the users would simply push the lever until it stops without thinking about it, producing CRLF operation — — and that CR without LF was comparatively rare. From a pure protocol UX perspective, it would make sense IMO to have a single command for (CR + LF) too, just like the typewriter effectively does it (push the lever here to do both at once). It seems weird that the protocol is more limited than the mechanical device that it drives, but then again, designers probably weren't involved in deciding on terminal protocol specs. reply Joker_vD 10 hours agorootparentNaked CR is an almost (baring legacy Mac OS) universally supported cross-platform way to print progress bars on CRT terminals. reply Izkata 15 hours agorootparentprevThey didn't say \"mechanical typewriters\", just \"typewriters\". Electric typewriters did have a Return key that did work the way they described. reply romwell 12 hours agorootparentIndeed, I was clarifying that: 1) \"Typewriters\" in parent's comment didn't refer to mechanical typewriters, but 2) Line feed/carriage return semantics, as well as the UX of combining them into one action to proceed to the next line of text, predate electric typewriters and were effectively the same on mechanical ones. As I wrote in the other comment, the subtle difference in semantics comes from teletypes, which couldn't advance the paper feed and return the carriage fast enough to print the next character in the timespan of one command. Not that it applied to all teletypes, but it was the case for a very popular unit. The makers of that machine deliberately didn't include a single command that would do CR/LF so that there'd be no way for the users to notice that. The ordering, CR then LF, differs from the one on mechanical typewriters, where LF always precedes CR when you use the big lever, allowing one to use the same lever to produce blank lines without moving the carriage (in effect, doing LF LF LF ... LF CR). On the teletypes though, CR LF ordering was, in any case, a lie, since in actuality, LF was happening somewhere in the middle of the carriage return, which took the time span of two commands. The CR command had to precede LF on the teletype because it took longer, but since the mechanisms were independent, they could be executed at the same time. This is the difference from mechanical typewriters. Typing mechanism was also independent of CR and LF, and running CR + [type character] at the same time was bad. But having fixed-time-per-command simplified everything, so instead of waiting (..which means buffering - with potential overflow issues - or a protocol to tell the sending party to wait, which is a lot more complex), hacks like this were put in place. My IBM selectric is not functional (got it as a repair project, didn't get to do it yet), so I can't verify, but I'd guess it doesn't need to do CR then LF, since it can simply not process input while the carriage is returning. It's OK for it to do CR and LF in any order, or simultaneously. If the operator presses and releases a button during this time, the machine can simply do nothing; the operator will re-type the character the next instant, using the buffer in their head where the text ultimately comes from. The teletypes didn't have that luxury, as the operator on the other end could be a computer, which was told it could send output at a certain rate, and by golly it did. Not processing a command would mean dropping data. All that is to say that CR and LF are present on both typewriters and teletypes, with the following differences: * mechanical typewriters always do LFCR due the mechanics of the carriage return lever, which was designed for a human operator; * teletypes do CRLF because that's how they cope with the typist being a machine that can't be told to wait a bit until the carriage returns; * and electric typewriters are somewhere in betwen and could do whatever, because the CR lever was replaced by the motor (like on a teletype), but the operator was still a human that could wait half a second without forgetting what it is that they wanted to type. IMO, it's worth keeping CRLF around simply because it's a part of computer and technology history that spans nearly two centuries, from typewriters to Google docs. reply fijiaarone 16 hours agorootparentprevOn manual typewriters there is a lever that turns the roller to accomplish a line feed (or two if set for double space.) This lever is usually located on the left side of the carriage to make it convenient to push it back to the right side in the same motion. reply romwell 16 hours agorootparentIsn't this what I said? >the lever would do LF, and pushing on it further would do CR (tensioning the carriage spring). In any case, carriage return is just as important function of the lever as line feed: - you can also directly do line feed by turning the roller - line feed, by itself, doesn't need a large lever - carriage return, by itself, doesn't need a large lever either - you can simply push the carriage - however, having a large lever is an ergonomic feature which allows you to: 1) return the carriage without moving your hands too far from the keyboard 2) do CRLF in one motion without it feeling like two things 3) If needs be, do a line feed by itself, since the force required for that is much smaller compared to the one to move the carriage (lever advantage!). The long lever makes it so that line feed happens before carriage return. If the lever were short, you'd be able to move the carriage until it stops, and only then would the paper move up. So I wondered why the control codes are doing the operations in the opposite order from the typewriter. Turns out, the reasons are mechanical[1]: >The separation of newline into two functions concealed the fact that the print head could not return from the far right to the beginning of the next line in time to print the next character. Any character printed after a CR would often print as a smudge in the middle of the page while the print head was still moving the carriage back to the first position. \"The solution was to make the newline two characters: CR to move the carriage to column one, and LF to move the paper up. Aha! Makes sense. In a way, this was creating a de-facto protocol by usage, in a similar spirit the the author is suggesting to get rid of it. As in: the existing standard wasn't really supported, but letting the commands go through nevertheless and allowing things to break incentivized people to collectively stick to the way of doing things that didn't result in misprints. ____ [1] https://en.wikipedia.org/wiki/Newline reply inopinatus 13 hours agoparentprevNot just potential bugs, there'll be definite security failures. Changing the line endings can invalidate signatures over plaintext content. So an email MTA, for example, could never do so. Nor most proxy implementations. Then there's the high latent potential for request smuggling, command injection, and privilege escalation, via careful crafting of ambiguous header lines or protocol commands that target less robust implementations. With some protocols, it may cause declared content sizes to be incorrect, leading to bizarre hangs, which is to say, another attack surface. In practice, retiring CRLF can't be safely performed unilaterally or by fiat, we'll need to devise a whole new handshake to affirm that both ends are on the same page re. newline semantics. reply jcul 10 hours agoparentprevNot disagreeing with you, but implementation diverges from spec a lot anyway. I've had to write decoders for things like HTTP, SMTP, SIP (VoIP), and there's so many edge cases and undocumented behavior from different implementations that you have to still support. I find that it affects text based protocols, a lot more than binary protocols. Like TLS, or RTP, to stick with the examples above, have much less divergence and are much less forgiving to broken (according to spec) implementations. reply michaelmior 7 hours agorootparentThat's fair, but I don't see that as an argument for intentionally deviating from the spec. reply mechanicalpulse 22 hours agoparentprev> Why intentionally introduce potential bugs for the sake of making a point? It seems spiteful, but it strikes me as an interesting illustration of how the robustness principle could be hacked to force change. It’s a descriptivist versus prescriptivist view of standards, which is not how we typically view standards. reply chasil 22 hours agoparentprevFYI, Sendmail accepts LF without CR, but Exchange doesn't. reply isThereClarity 10 hours agorootparentsendmail 8.18.1 includes patches to correct this behaviour (and options to turn it back on) due to its role in SMTP smuggling, CVE-2023-51765. See https://ftp.sendmail.org/RELEASE_NOTES sendmail is now stricter in following the RFCs and rejects some invalid input with respect to line endings and pipelining: ...snip... - Accept only CRLF . CRLF as end of an SMTP message as required by the RFCs, which can disabled by the new srv_features option 'O'. - Do not accept a CR or LF except in the combination CRLF (as required by the RFCs). These checks can be disabled by the new srv_features options 'U' and 'G', respectively. In this case it is suggested to use 'u2' and 'g2' instead so the server replaces offending bare CR or bare LF with a space. It is recommended to only turn these protections off for trusted networks due to the potential for abuse. reply 9dev 21 hours agorootparentprev…how very in character for each of them! reply cassepipe 19 hours agoparentprevIt seems to me the author is not suggesting to update the protocols themselves but rather to stop sending them CR even if the spec requires it. And to patch the corresponding software to it accepts simple newlines. reply nedt 20 hours agoparentprev> What would be the benefit Easy - being able to use a plain text protocol as a human being without having to worry if my terminal sends the right end of line terminator. Using netcat to debug SMTP issues is actually something I do often enough. reply tfehring 19 hours agoparentprevAt least for CSV, there's a divergence between usage in practice and the spec. The spec requires CRLF, but all of the commonly used tools I've encountered for reading and writing CSVs can read files with CR, LF, or CRLF line endings, and when writing CSVs they'll default to either LF or platform-specific line endings. (Even Excel for Mac doesn't default to CRLF!) I think this divergence is bad and should be fixed. But IMO the right resolution is to update the spec so that (1) readers MUST accept any of (CR, LF, CRLF), (2) writers MUST use one of (CR, LF, CRLF), and (3) writers SHOULD use LF. Removing compatibility from existing applications to break legacy code would be asinine. reply michaelmior 7 hours agorootparentFor CSV, \"breaking\" changes seem like less of a big deal to me. Partially because there is already so much variation in how CSV is implemented. reply phkahler 22 hours agoparentprev>> I'm hoping this is satire. Why intentionally introduce potential bugs for the sake of making a point? It's not satire and it's not just trying to make a point. It's trying to make things simpler. As he says, a lot of software will accept input without the CR already, even if it's supposed to be there. But we should change the standard over time so people in 2050 can stop writing code that's more complicated (by needing to eat CR) or inserts extra characters. And never mind the 2050 part, just do it today. reply michaelmior 22 hours agorootparentIgnoring established protocols doesn't make things simpler. It makes things vastly more complicated. Let's absolutely fix new protocols (or new versions of existing protocols). But intentionally breaking existing protocols doesn't simplify anything. reply nsnshsuejeb 21 hours agorootparentprevYes. We all know how to do this. You know that API version thingy. I agree to drop the carriage return when not needed but do it in future protocols. Obviously IPv6 shows you need to be patient. Your great grandkids may see a useless carriage return! Windows doesn't help here. reply perching_aix 21 hours agorootparentVersioning provides people with capability for change management, but won't perform it on their behalf. Who knew. reply javajosh 22 hours agoparentprev>What would be the benefit... It is interesting that you ignore the benefits the OP describes and instead present a vague and fearful characterization of the costs. Your reaction lies at the heart of cargo-culting, the maintenance of previous decisions out of sheer dread. One can do a cost-benefit analysis and decide what to do, or you can let your emotions decide. I suggest that the world is better off with the former approach. To wit, the OP notes for benefits \" The extra CR serves no useful purpose. It is just a needless complication, a vexation to programmers, and a waste of bandwidth.\" and a mitigation of the costs \"You need to search really, really hard to find a device or application that actually interprets U+000a as a true linefeed.\" You ignore both the benefits assertion and cost mitigating assertion entirely, which is strong evidence for your emotionality. reply YZF 22 hours agorootparentWhat's your estimate for the cost of changing legacy protocols that use CRLF vs. the work that will be done to support those? My intuition (not emotion) agrees with the parent that investing in changing legacy code that works, and doesn't see a lot of churn, is likely a lot more expensive than leaving it be and focusing on new protocols that over time end up replacing the old protocols anyways. OP does not really talk about the benefit, he just opines. How many programmers are vexed when implementing \"HTTP, SMTP, CSV, FTP\"? I'd argue not many programmers work on implementations of these protocols today. How much traffic is wasted by a few extra characters in these protocols? I'd argue almost nothing. Most of the bits are (binary, compressed) payload anyways. There is no analysis by OP of the cost of not complying with the standard which potentially results in breakage and the difficulty of being able to accurately estimate the breakage/blast radius of that lack of compliance. That just makes software less reliable and less predictable. reply michaelmior 22 hours agorootparentprevYou're right that I didn't mention the supposed benefits in my response. But let's incorporate those benefits into new protocols rather than break existing protocols. I just don't see the benefit in intentionally breaking existing protocols. reply LegionMammal978 22 hours agorootparentprevThe cost is, if people start transitioning to a world where senders only transmit LF in opposition to current standards for protocols like HTTP/1.1 or SMTP (especially aggressively, e.g., by creating popular HTTP libraries without a CRLF option), then it will create the mental and procedural overhead of tracking which receivers accept LF alone vs. which still require CRLF. Switching established protocols is never free, even when there are definite benefits: see the Python 2-to-3 fiasco, caused by newer programs being incompatible with most older libraries. reply bvrmn 12 hours agorootparent2-to-3 fiasco was solely caused by inadequate support to write py2 compatible code until python 3.4. It was literally \"you devs, stop write ugly py2, let's write godly py3\". reply perching_aix 22 hours agorootparentprev> you ignore the benefits the OP describes Funnily enough, the author doesn't actually describe any tangible benefits. It's all just (in my reading, semi-sarcastic) platonics: - peace - simplicity - the flourishing of humanity ... so instead of \"vague and fearful\", the author comes on with a \"vague and cheerful\". Yay? The whole shtick about saving bandwidth, lessening complications, and reducing programmer vexations are only ever implied by the author, and were explicitly considered by the person you were replying to: > You save a handful of bits at the expense of a lot of potential bugs. ... they just happened to be not super convinced. Is this the kind of HackerNews comment I'm supposed to feel impressed by? That demonstrates this forum being so much better than others? reply Ekaros 22 hours agoparentprevThinking about it. Using CR alone in protocols actually make infinitely more sense. As that would allow use of LF in records. Which would make many use cases much simpler. Just think about text protocols like HTTP, how much easier something like cookies would be to parse if you had CR as terminating character. And then each record separated by LF. reply mattmerr 22 hours agorootparentASCII already has designated bytes for unit, group, and record separators. That aside, a big drawback of using unprintable bytes like these is they're more difficult for humans to read in dumps or type on a keyboard than a newline (provided newline has a strict definition CRLF, LF, etc) reply fijiaarone 16 hours agorootparentThere is no reason those ascii characters need to stay unprintable. You could use other characters like an interpunct, silcrow, or down carat. reply eqvinox 10 hours agorootparentThere is in fact a reason those ASCII 'characters' should stay unprintable: the 0x00-0x1f (except Tab, CR, LF) range is explicitly excluded as invalid in a whole bunch of standards, e.g. XML. reply gpvos 22 hours agorootparentprevThat is so backwards incompatible that it is never, ever going to fly. reply SQLite 17 hours agoprevAuthor here: My title was imprecise and unclear. I didn't mean that you should raise errors if CRLF is used as a line terminator in (for example) HTTP, only that a bare NL should be allowed as an acceptable line terminator. RFC2616 recommends as much (section 19.3 paragraph 3) but doesn't require it. The text of my proposal does say that CRLF should continue to be accepted, for backwards compatibility, just not required and not generated by default. I failed to make that point clear. My initial experiments suggested that this idea would work fine and that few people would even notice. Initially, it appeared that when systems only generate NL instead of CRLF, everything would just keep working seamlessly and without problems. But, alas, there are more systems in circulation that are unable to deal with bare NLs than I knew. And I didn't sell my idea very well. So there was breakage and push-back. I have revised the document accordingly and reverted the various systems that I control to generate CRLFs again. The revolution is over. Our grandchildren will have to continue dealing with CRLFs, it seems. Bummer. Thanks to everyone who participated in my experiment. I'm sorry it didn't work out. reply AndyKelley 16 hours agoparentCopying my comment from lobste.rs in case you didn't see it: I really appreciate this attitude. As programmers, we love to complain and grumble to each other about how the state of things suck, or that things are over complicated, but then too often the response is the software engineering equivalent of “I paid my student loans, so you should have to, too”. A new person joins the project, and WTFs at something, and the traumatized veterans say, “haha oh boy welcome, yeah everything sucks! You’ll get used to it soon.” I hate that attitude. We are at the very, very beginning of software protocols that could potentially last for millennia. From that perspective, you would look back at this situation and think of Richard’s blog post as super obvious, the clear voice of reason, and the reaction of everyone here as myopic. Even if our software protocols for whatever reason don’t last that long, we need to be working on reducing global system complexity. Beauty and elegance aside, there is such a thing as complexity budget which is limited by the laws of information theory, the computer science equivalent of the laws of physics. People like Richard understand this intuitively, and actively work towards reconstructing our world to regain complexity currency so that it can be spent on more productive things. I would have backed you 100%. reply perching_aix 15 hours agorootparentYou remind me to the common wisdom regarding user feedback. That when your users complain about something, you should listen - not to their advice per se, but to their gripes. Because while their gripes may be legitimate, their advice is near guaranteed to be rubbish (they're not developers after all). Specifically, I'm referring to your new guy example here. The new guy usually very correctly identifies that things suck, what he lacks is perspective. This means that both his priorities will be off, as well as his approaches. Trust the gripe, not the advice. This is also I think what people in this thread are/were generally about here. Not because Richard would be some new unknown kid on the block mind you, but because our grandchildren having to deal with CRLF is approximately as harrowing as the eventual heat death of the universe, and because instead of standards revisions, he was calling for standards violations. reply inopinatus 13 hours agoparentprevThe problem with trying to legislate a specific case of Postel's Law is that everyone who might get on board because of it, is already on board because of it, and vice versa. reply Ygg2 13 hours agorootparentIt also goes a bit more than that, for optimal UTF8 search you want the ASCII separators. It's always easier to search for a single byte than two or more bytes of special pattern. That said, I do agree we should abolish CRLF. And replace it with LF. reply MatthiasPortzel 19 hours agoprevThey acted on these words, updating their HTTP server to serve just . => https://sqlite.org/althttpd/info/8d917cb10df3ad28 Send bare instead of \\r for all HTTP reply headers. While browser aren't effected, this broke compatibility with at least Zig's HTTP client. => https://github.com/ziglang/zig/issues/21674 zig fetch does not work with sqlite.org reply abhinavk 17 hours agoparentIt has been reverted. reply djha-skin 22 hours agoprev> Let's make CRLF one less thing that your grandchildren need to know about or worry about. The struggle is real, the problem is real. Parents, teach your kids to use .gitattribute files[1]. While you're at it, teach them to hate byte order marks[2]. 1: https://stackoverflow.com/questions/73086622/is-a-gitattribu... 2: https://blog.djhaskin.com/blog/byte-order-marks-must-diemd/ reply Kwpolska 20 hours agoparentNope. Git should not mess with line endings, the remote repository not matching the code in your local clone can bite you when you least expect it. On Windows, one should disable the autocrlf misfeature (git config --global core.autocrlf false) and configure their text editor to default to LF. reply zulu-inuoe 19 hours agorootparent3000% agree. I have been bitten endlessly by autocrlf. It is absolutely insane to me that anyone ever considered your having your SOURCE CONTROL tool get/set different content than what's in the repo reply layer8 17 hours agorootparentprevThis is impractical in many situations, because tools that process build-source files (for example XML files that control the build, or generated source files) inherently generate CRLF on Windows. These are many, many, many tools, not just one’s text editor. The correct solution is to use .gitattributes. reply dwattttt 17 hours agorootparentIf you're using tools that only support one particular line ending, the solution isn't to convert your source automatically in the repo, it's to know your source is always stored in one format, and convert it back/forth when a tool needs it to be different. How would you handle two different tools only supporting disjoint line endings? reply djha-skin 6 hours agorootparentprevSure, don't use autocrlf. But some _windows_ tools need crlf, like for powershell or batch build scripts. Defaulting to lf in the editor will not save you. Don't use `auto`, full marks, but the gitattributes file is indispensable as a safety net when explicit entries are used in it. I mean, the whole point of the file is not everyone who is working on the project has their editors set to lf. Furthermore, not every tool is okay with line endings that are not CRLF. When used properly (sure, ideally without auto), the git attributes file as a lifesaver. reply nsnshsuejeb 21 hours agoparentprevThe letters after the dot in my filename don't map 1 to 1 with the file format. reply perching_aix 22 hours agoprevWell, at least the title is honest. Straight up asking people to break standards out of sheer conviction is a new one for me personally, but it's definitely one of the attitudes of all time, so maybe it's just me being green. Can we ask for the typical *nix text editors to disobey the POSIX standard of a text file next, so that I don't need to use hex editing to get trailing newlines off the end of files? reply rkeene2 22 hours agoparentPeople don't seem to mind when Chrome does it [0]. The response \"standards aren't a death pact\" stands out in particular. [0] https://news.ycombinator.com/item?id=13860682 reply akira2501 18 hours agorootparentDeath pact? Jeez. Standards simply prevent people from having to waste time debugging dumb issues that rightfully could have been avoided. reply eviks 13 hours agorootparentThey also add to the time wasted by not removing needless complexity in due time reply akira2501 10 hours agorootparentThe complexity of CRLF? The balance here, of course, being backwards compatability. I'd sooner kill EBCDIC, bad ASCII and Code Pages than worry about CRLF if we didn't have to care about ancient systems. Programming languages still retain C's operator precedence hierarchy even though it was itself meant to be a backwards compatible compromise and leads to errors around logical operator expressions. Anyways, this article is about actively breaking systems like some kind of protocol terrorist in order to achieve an outcome at any cost, if it was merely along the lines of \"CRLF considered harmful in new protocols\" I'd have nothing to say. reply eviks 7 hours agorootparent> The complexity of CRLF? You didn't limit your general admiration of standards to CRLF, so no, not only that. > about actively breaking systems like some kind of protocol terrorist in order to achieve an outcome at any cost, That's simply false, he isn't > Almost all implementations of these protocols will accept a bare NL as an end-of-line mark, even if it is technically incorrect. reply LegionMammal978 6 hours agorootparent> Almost all implementations of these protocols will accept a bare NL as an end-of-line mark, even if it is technically incorrect. See https://news.ycombinator.com/item?id=41832555 as far as HTTP/1.1 goes, it's definitely common but far from universal. The big problem with \"it's 100% safe to make this change, since it doesn't break anything I know about\" is that there are always a lot of things you don't know about, not all of which can be boiled down to being negligible weirdos. reply perching_aix 22 hours agorootparentprevMight be just my personal impression, but I'm pretty sure Chrome is extremely notorious for abusing its market leader position, including in this way. So gonna have to disagree there, from my view people do mind Chrome and its implementation particularities quite a lot. reply dijit 21 hours agorootparentI think the parent is equally denigrating the situation. Leaders choose the standards, especially as they approach monopoly. Worse still: people will come out of the woodwork to actively defend the monopolist de facto standard producer. reply nsnshsuejeb 21 hours agorootparentNot defending the producer, just making pragmatic choices! reply dwattttt 17 hours agorootparentPragmatic choices is what Postel is known for now, and it makes for a pretty confused world when everyone makes different pragmatic choices. reply bityard 18 hours agoparentprevWhy would you want that? All Unix text processing tools assume that every line in a text file ends in a newline. Otherwise, it's not a text file. There's no such thing as a \"trailing newline,\" there is only a line-terminating newline. I've yet to hear a convincing argument why the last line should be an exception to that extremely long-standing and well understood convention. reply perching_aix 16 hours agorootparent> There's no such thing as a \"trailing newline,\" there is only a line-terminating newline. Is \"line-terminating newline\" a controlled / established term I'm unfamiliar with or am I right to hold deep contempt against you? Because \"trailing newline\", contrary to what you claim, is 100% established terminology (in programming anyways), so I'd most definitely consider it \"existing\", and I find it actively puzzling that someone wouldn't. reply eqvinox 10 hours agorootparentA trailing newline to me is \"\" at the end of a file, i.e. a superfluous empty line. That doesn't seem to be what the root comment is referring to, though? reply perching_aix 7 hours agorootparentI'm referring to files ending with a , and I do not see why this wouldn't be a trailing newline. It's a newline... at the end. reply oasisaimlessly 14 hours agorootparentprev\"Trailing newline\" isn't anymore of a special phrase than \"leading whitespace\" (or \"leftmost banana\"). reply perching_aix 12 hours agorootparentThat is also true, adding to the bafflement factor of it supposedly being \"non-existent\". reply 201984 22 hours agoparentprevWhat's wrong with trailing newlines? reply perching_aix 22 hours agorootparentOther than select software being pissy about it, not much. Just like how there's nothing wrong with CRLF, except for select software being pissy about that too. reply tryauuum 19 hours agorootparentI do like concatenating files with cat, and if a file has its final line not ending in newline symbol the result is ugly. I know it's just me but my worldview is that the world would be better if all editors had \"insert final newline\" behavior reply perching_aix 18 hours agorootparentMy problem is that what I input (and observe!) doesn't match what's persisted. Worse still, editors lie about it to me until I close the file and reopen it. And just to really turn the knife, various programs will then throw a fit that a character that I did not input and my editor lies about not being present, is present. I hope it's appreciable why I find this frustrating. I expect my editor to do what I say, not secretly(!) guess what I might have wanted, or will potentially want sometime in the future. Having to insert a newline while concatenating files is a chore, but a predictable annoyance. Having to hunt for mystery bytes, maybe less so. reply bityard 17 hours agorootparentI have been using and programming Unix systems for almost 30 years and have not run into anything like what you are describing. What Unix program \"throws a fit\" when encountering a perfectly normal newline in the last line in a file? reply perching_aix 17 hours agorootparent\"Unix programs\" I haven't ran into throwing a fit per se. That's why I didn't write that. What I ran into issues with was contemporary software that's shipped to Linux, such as Neo4j, which expects its license files to have no newline at the end of the file, and will actively refuse to start otherwise. I have a feeling I'll now experience the \"well that's that software's problem then\" part of this debate. Just like how software not being able to handle CRLF / CR-only / LF-only, is always the problem - instead of text files being a joke, and platforms assuming things about them being the problem. reply eviks 13 hours agorootparentprevWait, are they're no editors that don't lie to you? reply bmitc 21 hours agorootparentprevYep. Select software being Unix command line tools. reply norir 22 hours agorootparentprevIt makes writing parsers more complicated in certain cases because you can't tell without lookahead if a newline character should be treated as a newline or an eof. reply viraptor 21 hours agorootparentWhat? Which crazy non-binary format makes a distinction between CRLF(EOF) and just (EOF)? Apart from a plain text file, that is. reply nunobrito 20 hours agorootparentI won't mention telnet because you don't use it, but in CSV and similar data it is quite a trouble to normalize the data. So instead of 2 possibilities now we 3 to detect. reply viraptor 19 hours agorootparentI don't get the CSV part. You can emit a new row after a line ending and on EOF with non-empty buffer. What's the tricky part or third option here? The crlf is never a part of the data. reply nightpool 19 hours agorootparentprevI have never had any issues with this using a standards compliant CSV parser. reply bigstrat2003 21 hours agoparentprevYeah, I have no idea what the author is smoking. Deliberately breaking standards is simply not an acceptable solution to the problem, even if it were a serious problem (it's not). reply Ekaros 21 hours agorootparentIf there truly is a problem with existing protocols, propose and properly design new one that can replace it. Then if it is technically superior solution it should win in long run. reply nsnshsuejeb 21 hours agorootparentNo need. Just convince the king (e.g. Google for HTTP) to make a tweak in the next standard version. reply vitus 7 hours agorootparentGood news! Both HTTP/2 and HTTP/3 use a packed binary representation for headers, so CRLF is nowhere to be found in RFC 9113 / 9114. I don't see value in picking on Google or HTTP here, even if it is fashionable to do so. reply steeeeeve 47 minutes agoprevOnce in a long while, people start looking into things and wanting them to make sense. Like hey - why don't we start using the field separator and record separator characters when exporting/importing data. But then you end up realizing that even when you are right, the energy it would take to push a change like that is astounding. Those who successfully create an RFC and find a way push it through all the way to it becoming a standard are admirable people. reply moomin 22 hours agoprevCounterpoint: Unix deciding on a non-standard line ending was always a mistake. It has produced decades of random incompatibility for no particular benefit. CRLF isn’t a convention: it’s two different pieces of the base terminal API. You have no idea how many programs rely on CR and LF working correctly. reply fanf2 21 hours agoparentIt is a standard line ending. ANSI X3.4-1968 says: 10 LF (Line Feed). A format effector that advances the active position to the same character position on the next line. (Also applicable to display devices.) Where appropriate, this character may have the meaning “New Line” (NL), a format effector that advances the active position to the first character position on the next line. Use of the NL convention requires agreement between sender and recipient of data. ASCII 1968 - https://www.rfc-editor.org/info/rfc20 ASCII 1977 - https://nvlpubs.nist.gov/nistpubs/Legacy/FIPS/fipspub1-2-197... reply wongarsu 19 hours agorootparentThe first sentence is exactly what LF is in CRLF, and implies the necessity of CR. CR returns the cursor to the first character of the active line, LF moves it one line down without changing the horizontal position. The second sentence is the UNIX interpretation of LF doing the equivalent of CRLF. But calling it a standard line ending when it's an alternative meaning defined in the standard as \"requires agreement between sender and recipient of data\" is a bit of a stretch. It's permissible by the standard, but it's not the default as per the standard reply eqvinox 10 hours agoparentprevCounter-counterpoint: using 2 bytes to signal one relevant operation creates ambiguity out of thin air. If all you care about is \"where does the line end?\", having CRLF as a line ending creates edge cases for \"there is only CR\" and \"there is only LF\". Are those line endings or not? How do you deal with them? And what's LFCR? Personally speaking, I've always written my parsers to be permissive and accept either CR¹, LF, or CRLF as line endings. And it always meant keeping a little extra boolean for \"previous byte was CR\" to ignore the LF to not turn CRLF into 2 line endings. ¹ CR-only was used on some ancient (m68k era?) Macintosh computers I believe. P.S.: LFCR is 2 line endings in my parsers :D reply sebazzz 4 hours agorootparentDidn’t some version of an Apple operating system have CR as a line ending? reply matheusmoreira 21 hours agoparentprevYeah. It's weird how Unix picked LF given its love of terminals. CRLF is the semantically correct line ending considering terminal semantics. It's present in the terminal subsystem to this day, people just don't notice because they have OPOST output post processing enabled which automatically converts LF into CRLF. reply eqvinox 10 hours agorootparentI'd argue (but have no historical context) that it's a distinction between storage format and presentation interface, and IMHO that makes a lot of sense. A terminal has other operations too, backspaces and deletes being the most basic. Which coincidentally are one hell of a mess across different terminal types between ^H / 0x08 and DEL / 0x7f as well… (And these distinctions predate UNIX — if I were confronted with an inconsistent mess I'd go for simplicity too, and a 2-byte newline is definitely not simple just by merit of being 2 bytes. I personally wouldn't have cared whether it was CR or LF, but would have cared to make it a single byte.) reply globular-toast 11 hours agoparentprevBut, like the article says, LF is not useful. I could always interpret LF as NL and if you send CRs too it won't break anything. If you know I'm interpreting LF that way you can just stop sending the CRs. That's what happened in Unix. reply bmitc 20 hours agoparentprevI have always felt that somehow Linux and proponents of it default to every decision it made being right and everything else, namely Windows, being wrong. I honestly feel Linux is orders of magnitude more complex. It is much easier, in my experience to make software just work on Windows. (This is not to say Windows doesn't have bad decisions. It has many. All the major OSs are terrible.) reply ripe 17 hours agoprevHa, ha, ha! I love it. I believe the author is serious, and I think he's on to something. OP clearly says that most things in fact don't break if you just don't comply with the CRLF requirement in the standard and send only LF. (He calls LF \"newline\". OK, fine, his reasoning seems legit.) He is not advocating changing the language of the standard. To all those people complaining that this is a minor matter and the wrong hill to die on, I say this: most programmers today are blindly depending on third-party libraries that are full of these kinds of workarounds for ancient, weird vestigial crud, so they might think this is an inconsequential thing. But if you're from the school of pure, simple code like the SQLite/Fossil/TCL developers, then you're writing the whole stack from scratch, and these things become very, very important. Let me ask you instead: why do you care if somebody doesn't comply with the standard? The author's suggestion doesn't affect you in any way, since you'll just be using some third-party library and won't even know that anything is different. Oh bUT thE sTandArDs. reply abhinavk 16 hours agoparent> (He calls LF \"newline\". OK, fine, his reasoning seems legit.) He is not advocating changing the language of the standard. The Unicode standard does call it NL along with LF. 000A = LINE FEED (LF) = new line (NL) = end of line (EOL) Source: https://www.unicode.org/charts/PDF/U0000.pdf reply rgmerk 22 hours agoprevOf all the stupid and obsolete things in standards we use to interoperate, CRLF is one of the least consequential. reply fweimer 22 hours agoprevSMTPis pretty clear that the message termination sequence is CR LF . CR LF, not LF . LF, and disagreements in this spot are known to cause problems (include undesirable message injection). But then enough alternative implementations that recognize LF . LF as well are out there, so maybe the original SMTP rules do not matter anymore. reply mvdtnz 22 hours ago [flagged]parentnext [2 more] This is covered in the article you didn't bother to read before commenting on, > Even if an established protocol (HTTP, SMTP, CSV, FTP) technically requires CRLF as a line ending, do not comply. Send only NL. Almost all implementations of these protocols will accept a bare NL as an end-of-line mark, even if it is technically incorrect. Give no quarter to the tyranny of CRLF. reply dang 18 hours agorootparent\"Please don't comment on whether someone read an article. \"Did you even read the article? It mentions that\" can be shortened to \"The article mentions that.\"\" https://news.ycombinator.com/newsguidelines.html reply tedunangst 22 hours agoprevNo mention of what happened the last time we mixed and matched line endings? https://smtpsmuggling.com/ reply deltaknight 22 hours agoparentDoesn’t this show that ignoring CR and only processing LFs is a good idea? If I’m understanding right (probably wrong), this vuln relied on some servers using CRLF only as endings, and others supporting both CRLF and LF. If every server updated to line-end of LF, thereby supporting both types, this vuln wouldn’t happen? Of course if there’s is a mixed bag then I guess this is still possible, if your server only supports CRLF. At least in that scenario you have some control over the issue though. reply hifromwork 20 hours agorootparentYes, if every server/middleware implemented parsing in the same way this kind of vulnerability wouldn't happen. Same goes for HTTP smuggling and other smuggling attacks. Unfortunately, asking more people to ignore the currently estabilished standards makes the problem worse, not better. reply dwattttt 16 hours agorootparentprevAs I mentioned else-thread: it doesn't matter as much which option is chosen, so long as everyone agrees. If everyone agrees that LF on its own is enough (and we stop sending CR's to make sure it's not part of whatever comes before LF), that's fine. But it's just as fine for everyone to agree that CRLF is right, and reject plain LF. reply anonymousiam 21 hours agoprevThis article seems like it was written to troll people into a flame war. There is no such character as NL, and the article does not at all address that fact that the \"ENTER\" key on every keyboard sends a CR and not a LF. Things work fine the way they are. reply eviks 13 hours agoparent> There is no such character as NL, There is, copying from a helpful comment above: > The Unicode standard does call it NL along with LF. 000A = LINE FEED (LF) = new line (NL) = end of line (EOL) Source: https://www.unicode.org/charts/PDF/U0000.pdf And things don't work fine, there are many issues with this historical baggage reply anonymousiam 2 hours agorootparentI agree that there are issues. Making radical changes to legacy behavior will cause more. reply o11c 20 hours agoparentprevU+0085 is sometimes called NL (it is the standard in EBCDIC), but more often NEL in the ASCII world. reply TacticalCoder 19 hours agoparentprev> There is no such character as NL ... More specifically the Unicode control character U+000a is, in the Unicode standard, named both LF and NL (and that comes from ASCII but in ASCII I think 0x0a was only called LF). It literally has both names in Unicode: but LINEFEED is written in uppercase while newline is written in lowercase (not kidding you). You can all see for yourself that U+000a has both names (and eol too): https://www.unicode.org/charts/PDF/U0000.pdf > and the article does not at all address that fact that the \"ENTER\" key on every keyboard sends a CR and not a LF. what a key on a keyboard sends doesn't matter though. What matters is what gets written to files / what is sent over the wire. ... $ cat > /tmp/anonymousiam ... $ hexdump /tmp/anonymousiam 00000000 000a When I hit ENTER at my Linux terminal above, it's LINEFEED that gets written to the file. Under Windows I take it the same still gets CRLF written to the file as in the Microsoft OSes of yore (?). > Things work fine the way they are. I agree reply anonymousiam 13 hours agorootparentTry the cat example again with your tty in raw mode instead of cooked mode. (stty raw) Note that your job control characters will no longer function, so you will need to kill the cat command from a different terminal, then type: stty sane (or stty cooked) to restore your terminal to \"normal\" operation. You will then see the 0d hex carriage return characters in the /tmp/anonymousiam file, and no 0a hex linefeed characters present. reply eqvinox 10 hours agorootparentWhat bytes your terminal sends to communicate keys pressed and what is used in a text file to communicate the end of a line are not the same thing. \"\\eE\" (0x1b 0x45) can be a terminal newline too, after all. Or try pressing Alt+Enter. reply deltaknight 22 hours agoprevAs an implementation detail, I assume many programs simply ignore the CR character already? Whilst of course many windows programs (and protocols as mentioned) still require CRLF, surely the most efficient way to make something cross-platform if to simply act on the LF part of CRLF, that way it works for both CRLF and LF line ends. The fact that both CRLF and LF used the same control character in my eyes in a huge bonus for this type of action to actually work. Simply make everything cross platform and start ignoring CR completely. I’m surprised this isn’t mentioned explicitly as a course of action in the article, instead it focuses on making people change their understanding of LF in to NL which is as unnecessary complication that will cause inevitable bikeshedding around this idea. reply phkahler 22 hours agoparent>> instead it focuses on making people change their understanding of LF in to NL which is as unnecessary complication that will cause inevitable bikeshedding around this idea. Not really. In order to ignore CR you need to treat LF as NL. reply deltaknight 22 hours agorootparentFair point, although I’d suggest that many programs already treat LF as NL (e.g. unix text files), so this understanding of the meaning of LF already exists in the world. If you’re writing anything generic/cross-platform, you have to be able to treat LF as NL. So there isn’t really a change to be made here. reply zac23or 20 hours agoprev> Even if an established protocol (HTTP, SMTP, CSV, FTP) technically requires CRLF as a line ending, do not comply. Send only NL. Insane. First i think it was a April 1st joke, but is not. Let's break everything because YES. reply pathartl 55 minutes agoparentLet's all move to little-endian while we're at it. Don't accept anything else! reply Quekid5 20 hours agoparentprevIndeed. Very strange to hear a break-the-world suggestion from a person leading a company famous for never breaking the world. I'm kind of confused by this whole post. I do understand the desire for simplification (let's ignore the argument of whether this is one), but... reply sunk1st 21 hours agoprev> Nobody ever wants to be in the middle of a line, then move down to the next line and continue writing in the next column from where you left off. No real-world program ever wants to do that. Is this true? reply anamax 20 hours agoparentNo, it's not true. It was used for \"graphics\" on character-only terminals. reply numpad0 20 hours agoparentprevisn't CR without LF how CLI progress bars work? reply cowsandmilk 17 hours agorootparentHe says there are good usages of CR, he only argues for getting rid of LF. reply Ekaros 13 hours agoparentprevNope. reply ericyd 20 hours agoprevI'm not trying to be obtuse but I am actually confused how a modern machine correctly interprets CRLF based on the description in this post. If a modern machine interprets LF as a newline, and the cursor is moved to the left of the current row before the newline is issued, wouldn't that add a newline _before_ the current line, i.e. a newline before the left most character of the current line? Obviously this isn't how it works but I don't understand why not. reply chowells 19 hours agoparentLine feed is \"move the cursor down one line\". It's irrelevant what is currently on the line. These are printer/terminal control instructions, not text editing instructions. reply ericyd 39 minutes agorootparentOk, I conflated terminal instruction with text editing instruction. I thought the post made them sound like they behave the same but it sounds like I misunderstood, thank you. reply BlueTemplar 18 hours agoparentprevIf you are thinking of it being more like pressing \"Home\" then \"Enter\", it would seem that \"Enter\" actually works more like LFCR ? reply ericyd 41 minutes agorootparentYes this is a good description of my confusion reply layer8 17 hours agorootparentprevUnless your editor is in auto-indent mode. ;) reply srg0 8 hours agoprevI would also like to point out that English spelling is obsolete and should be abolished (/s). The text of the CRLF abolition proposal itself contains more digraphs, trigraphs, diphthongs, and silent letters than line-ending sequences. The last letter of the word \"obsolete\" is not necessary. \"Should\" can be written as only three letters in Shavian \"𐑖𐑫𐑛\". According to ChatGPT, the original proposal had: Number of sentences: 60 Number of diphthongs: 128 (pairs of vowels in the same syllable like \"ai\", \"ea\", etc.) Number of digraphs: 225 (pairs of letters representing a single sound, like \"th\", \"ch\", etc.) Number of trigraphs: 1 (three-letter combinations representing a single sound, like \"sch\") Number of silent letters: 15 (common silent letter patterns like \"kn\", \"mb\", etc.) For all intents and purposes, CRLF is just another digraph. reply ksp-atlas 8 hours agoparentI'm a big fan of English spelling reform and know Shavian and sometimes write in it, but I feel shavian is limited due to how heavily it uses letter rotation. Dyslexics already have trouble with b, d, p and q, having most letters have a rotated form would be challenging reply justin66 22 hours agoprevNice. I think that's the most energized I've seen Richard Hipp on a topic. reply zulu-inuoe 19 hours agoprevOf all the hills to die on. What an unbelivably silly one. CRLF sucks, suck it up. As many others have noted, there are millions of devices this idea puts in jeopardy for absolutely no reason. We should be reducing the exceptions, not creating them reply WillAdams 20 hours agoprevFWIW, I actually find CRLF handy in a database export I work in --- it exports cells with multiple lines by using LF for the linebreaks --- I open it in a text editor, replace all LFs w/ \\\\ (so as to get a single line for each data record and to cause the linebreaks to happen in LaTeX), and it's ready for further processing. reply Eduard 20 hours agoprev> Stop using \"linefeed\" as the name for the U+000a code point. stop reinventing terms. it's literally standardized with the name \"LF\" / \"line feed\" in Unicode. reply lifthrasiir 17 hours agoparentJust in case... Unicode doesn't define anything about C0 control characters. Everything you see from the code chart is from ISO/IEC 6429 and only shown there for information. Some parts of Unicode and related standards do assign a special meaning to U+000A, but often also to U+000D for the obvious reason. reply wongogue 18 hours agoparentprevHe is not reinventing anything. Unicode also defines 0a as LF, NL and EOL. In modern software, 0a is used as NL anyway. https://www.unicode.org/charts/PDF/U0000.pdf reply fracus 16 hours agoprevI read your article and am now fully indoctrinated to your noble cause. I propose an official chant. \"Death to LF!\" reply jftuga 20 hours agoprevI wrote a command line program to determine/detect the end-of-line format, tabs, bom, and nul characters https://github.com/jftuga/chars Stand-alone binaries are provided for all major platforms. reply pdonis 17 hours agoprevFor extra fun, the original Mac OS used CR by itself to mean newline. reply NelsonMinar 21 hours agoprevsqlite is a work of absolute genius. But every once in awhile something comes along to remind us how weird its software background is. Fossil. The build system. The TCL test harness. And now this, a quixotic attempt to break 50+ years of text formatting and network protocols. Yes CRLF is dumb. No, replacing it is not realistic. reply shadowgovt 22 hours agoprevDefine \"abolish.\" We could certainly try to write no new software that uses them. But last I checked, there are terabytes and terabytes of stored data in various formats (to say nothing of living protocols already deployed) and they aren't gonna stop using CRLF any time soon. reply eviks 13 hours agoparentIs defined in 4 points at the end reply theginger 22 hours agoprevRidiculous! We need to develop 1 universal standard that covers everyone's use cases. Yeah! reply webprofusion 16 hours agoprevNext you'll be telling us to use spaces instead of tab. reply fortran77 22 hours agoprevThe article had some major gaffes. Teletypes never had a ball. The stationary platen models had type boxes and cylinders, but never balls. reply refset 22 hours agoparentNot sure whether this changes anything about your critique, but note that the IBM 2741 terminal embedded a Selectric typewriter: > Selectric-based mechanisms were also widely used as terminals for computers, replacing both Teletypes and older typebar-based output devices. One popular example was the IBM 2741 terminal https://en.wikipedia.org/wiki/IBM_Selectric reply wrs 20 hours agorootparentWell, it says right there, the 2741 replaced Teletypes. It wasn't a Teletype. (Not sure I'd call this a \"major gaffe\", though!) reply refset 10 hours agorootparentNot a capital-T Teletype but it seems like it was widely used as a teleprinter and had similar mechanical constraints/requirements. The post does touch on this language ambiguity: > Teletypes (technically \"teleprinters\" - \"teletype\" was just the most popular brand name) reply nunobrito 20 hours agoprevXKCD has graphically replied to this topic: https://xkcd.com/927/ reply eviks 13 hours agoparentIt hasn't like it never does. In this case your mistake is that number of standards doesn't change reply bmitc 21 hours agoprevDoes anyone besides poorly designed Unix tools and Git actually get confused by any of this? I configure my editor to just use LF on whatever OS to appease Linux and configure Git to never mess with them. And in dealing with serial protocols, it's never an issue. reply lynx23 22 hours agoprevCan OP please tell me how to abolsih CR while in Raw Mode? Did he forget about it, or am I just unimaginative? reply samatman 21 hours agoparentRight, you don't need to search that hard for a device which interprets 0xA as a line feed, just set your terminal to raw mode, done. But given the very first sentence: > CR and NL are both useful control characters. I'm willing to conclude that he doesn't intend A Blaste Against The Useless Appendage of Carriage Return Upon a New Line, or Line Feed As Some Style It, to apply to emulators of the old devices which make actual use of the distinction. reply gfody 21 hours agoprevwe should leave it for backwards compatibility and adopt U+0085 as the standard next line codepoint. and utf8 libraries could unofficially support every combination of 0A 0D as escape sequences. reply fijiaarone 16 hours agoprevLine feed is exactly what you do when you are editing text. But nobody uses it. CR + LF was meant as an instruction for teletype printers, so it is outdated, and looks like he withdrew the proposal (which couldn’t have ever been serious) after some feedback. Fossil SCM, btw, was written by the creator of SQLite, so his opinion shouldn’t be discounted as some random nobody. reply truetraveller 17 hours agoprevI agree 100%. This is the cause of endless confusion, especially in crossplatform text files. Not to mention parsing programmatically. reply midnitewarrior 20 hours agoprevIf you'd like to break every system, and nearly every protocol, start abolishing arbitrary line endings that have been used for decades. That will make things better. reply A4ET8a8uTh0 21 hours agoprevI feel it necessary to have an obligatory 'Would someone think of banking?' before we 'abolish'(however we eventually arrive at defining it )anything. I mean it is all cool to have this idea, but real world implications, where half the stuff dangles on a text file, appear to be not considered here. For clarity's sake, I am not saying don't do it. I am saying: how will that work? edit: spaces, tabs and one crlf reply WesolyKubeczek 22 hours agoprev> Even if an established protocol (HTTP, SMTP, CSV, FTP) technically requires CRLF as a line ending, do not comply. Send only NL. Now just go pound sand. Seriously. And you owe me 5 minutes of my life wasted on reading the whole thing. My god, I would have thought all those “simplification” ideas die off once you have 3 years of experience or more. Some people won’t learn. P. S. Guess even the most brilliant people tend to have dumb ideas sometimes. reply elcritch 18 hours agoparentConversely, I'd argue most brilliant people tend to have more dumb ideas than others, usually on oddly specific topics which most people would find inconsequential. reply the_gorilla 17 hours agorootparentIt's true. Smart people tend to have a lot of novel ideas, most of which are going to be retarded. Most people just have no ideas. reply Animats 21 hours agoprevNow convince Microsoft. It's really the legacy of DOS that keeps this alive. reply nycdotnet 20 hours agoparentEven Notepad.exe supports LF only text files now. reply dankwizard 18 hours agoprev\"Call to action\" my god guy get a grip youre upset about some unicode reply M95D 11 hours agoprevBut adopting this new standard means we'll have to re-tool entire industries! /s reply forrestthewoods 22 hours agoprevI could not possibly disagree with this more strongly or violently. In short - shutup and deal with it. Is it an extremely mild and barely inconvenient nuisance to deal with different or mixed line endings? Yes. Is this actually a hard or difficult problem? No. Stop trying to force everyone to break their backs so your life is inconsequentially easier. Deal with it and move on. reply Avamander 21 hours agoparentWhy do we _have to_ keep bringing this legacy baggage with us for the next decades though? Allowing CRFL-less operation intentionally, especially in new implementations. Abusing protocol tolerance is (just a bit) to switch current ones. Should allow relatively gradual progress towards Less Legacy:tm: with basically no cost. Not every change is \"breaking your back\" especially if you should be updating your systems anyways to implement other, larger and more important changes. reply forrestthewoods 20 hours agorootparentBecause it’s literally fine and a non-issue. Only whiny Linux babies cry about it. It’s trivial for tools to support. Trivial. Like this is easiest, least harmful baggage in the history tech debt baggage. There will always be tech debt. Always and forever. Burn cycles on one that matters. reply Avamander 19 hours agorootparentSo what's the issue with getting rid of this debt slowly? It costs basically nothing, yet makes it cleaner for those in the future. Debts matter at a larger scale and the long run. reply wongogue 18 hours agorootparentThey carried the debt. Why shouldn’t everyone else? Regarding this issue…I don’t think the author is advocating for patching standards. Just consider CR as deprecated and use it only for backward compatibility. I do it similarly. I don’t convert line endings but any new project uses LF irrespective of the OS and configured as such in the editor. reply Ekaros 22 hours agoprev [–] I think I can offer most reasonable compromise here. Decide upon on new UTF-8 code point. Have the use mandated and ignore and ban all end-points that do not use this code-point instead of CRLF or just LF alone. reply bear8642 21 hours agoparent> Decide upon on new UTF-8 code point. Unicode have already done so - (NEL) https://www.compart.com/en/unicode/U+0085 reply phkahler 22 hours agoparentprevSo break everything. reply nycdotnet 20 hours agoparentprevWhich would need to be encoded in at least two bytes at which point, why not just use CRLF? reply kps 21 hours agoparentprevYou mean U+2028 LINE SEPARATOR? reply Ekaros 21 hours agorootparentPerfect. So now we just need to start filing bug reports to any tool that does not support it instead of CRLF or LF alone. reply bear8642 21 hours agorootparentprevOh, yet another option - first thought was U+0085 NEXT LINE as above reply whizzter 22 hours agoparentprev [–] https://xkcd.com/927/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "CRLF (Carriage Return Line Feed) line endings are considered outdated, originating from mechanical teletypes, and are seen as unnecessary in modern systems where a single NL (New Line, U+000a) is preferred.",
      "Although a proposal to eliminate CRLF was withdrawn, the initiative highlighted and resolved various software issues, emphasizing the need for systems to adapt to using only NL.",
      "The post advocates for the cessation of CRLF usage, encouraging developers to update software that still requires CR before NL and to adopt the term \"newline\" for U+000a."
    ],
    "commentSummary": [
      "CRLF (Carriage Return Line Feed) is considered outdated by some, but updating legacy protocols like HTTP, SMTP, and CSV to use only NL (New Line) could lead to bugs.- While newer protocols might avoid using CRLF, changing existing ones is not deemed advantageous due to potential compatibility issues.- The discussion underscores the tension between simplifying protocols and ensuring adherence to standards to prevent security vulnerabilities."
    ],
    "points": 398,
    "commentCount": 243,
    "retryCount": 0,
    "time": 1728847001
  },
  {
    "id": 41838337,
    "title": "Busy Status Bar from Flipper Devices",
    "originLink": "https://busy.bar/?hn",
    "originBody": "Busy Status Bar is a productivity multi-tool device with an LED pixel screen. Displays a personal busy message. Built-in Pomodoro timer and Apps. Fully customizable, open-source, and hacker-friendly. BUY Log in to Busy Cloud to control your device via API and MQTT Cloud Access Blog Downloads Shop Home Time management apps, custom busy message, Pomodoro focus timer Productivity tool Apps and integration Open HTTP API, open-source SDK, Python / Go / JavaScript libs, MQTT, no vendor lock-in Developer friendly App Library, connection to 3rd party software, integrations with calendar events and calls Productivity multi-tool Cloud-based Python/JavaScript/Go apps >_ Developers friendly > Open HTTP API Pomodoro timer > Bluetooth Low Energy > Free JavaScript apps SDK Time management technique based on short intervals of focused work broken by five-minute breaks. > Libs for Python/JavaScript/Go > USB Virtual LAN device Integration with hourly payment time trackers > Self-hosted cloud provisioning > Wi-Fi 2.4 GHz Configure your own focus intervals > Control via MQTT > Serial COM port over USB • > IoT integrations: IFTTT, HomeAssistant > No vendor lock-in > Offline API (no internet required) • Apps Built-in apps: clock, weather, social media metrics, currency chart, pixel art wallpapers, and more. Install JavaScript apps from community • • Busy Status Remote hosted Python/Javascript/Go apps via API Customizable busy status message to match your own workflow. Set any busy message, expiry timer and activation trigger Upload custom busy graphics or choose from gallery Activate manually from device or remotely from PC, Mobile App or via API Automatic activation by Zoom, Discord, Microsoft Teams, Google Calendar • • • • Live Busy status Busy Status Bar can integrate with desktop software and automatically activate when you’re on a call, live on stream, recording audio or when a certain program is active. Automatic “On Call” status Streaming mode When the microphone is activated on the computer, the device will automatically display an “on call” status. When you are streaming through any software like OBS (Open Broadcaster Software), Busy Status Bar will automatically turn on. Multi-platform support Supports Windows / macOS / Linux. Manual controls Physical buttons allow to control the device manually without connecting to PC or mobile app. The large buttons are designed for easy use without looking at the device. Start / Pause button Back button Start and stop your status. Also works as an OK button in menu Go back in menu and quit apps Scroll wheel 5-position selector Set timer in Busy and Pomodoro modes, navigate in menu, OK button Switch between modes Pomodoro Time management technique based on short intervals of focused work divided by 5-minute breaks Busy Active busy status message with custom design configurable for your own workflow Apps Clock, weather, social media stats (YouTube, Instagram, TikTok), and more. Supports 3rd-party user applications Settings Wi-Fi / Bluetooth connections, screen brightness, sound volume, power saving mode, etc. Eye-friendly back screen allows to control the device and see the status displayed on the main screen — even when it's turned away from you. Monochrome back screen Grayscale OLED display 1.54 inch, 160x80 px, adaptive brightness Designed by Flipper Devices Inc. © 2024. All rights reserved. 2803 Philadelphia Pike, Suite B #551 Claymont, DE 19703, USA D-U-N-S number: 11-765-8681 Shop Downloads Blog About Us Contacts Privacy Policy Privacy policy About us Conctacts Blog Downloads Shop Busy Cloud Log in to Busy Cloud to control your device via API and MQTT Home",
    "commentLink": "https://news.ycombinator.com/item?id=41838337",
    "commentBody": "Busy Status Bar from Flipper Devices (busy.bar)382 points by aleksi 3 hours agohidepastfavorite141 comments VoxPelli 1 hour agoIs there any message from the Flipper Zero people that this is actually their device? It’s not mentioned on https://www.flipperdevices.com/, neither on https://flipperzero.one/ or their Instagram? They have been plagued with peopling scamming people in their name before reply zhovner 1 hour agoparentHi, Pavel Zhovner here, Flipper Devices CEO. Yes it's our product, but it's not ready for announcement yet, so we keep it secret. Right now, we are working on implementing Matter smart home protocol and will slightly change the product concept. reply Y_Y 1 hour agorootparentHi Pavel Zhovner. I'm afraid you're not doing a very good job of keeping it secret. What are the odds of a kit version woth a lower pricetag and some assembly required? reply diggan 48 minutes agorootparent> What are the odds of a kit version woth a lower pricetag and some assembly required? Or even better, a version that ships with everything besides \"the brain\" and allows us to use our Flipper Zero as the brain :) Looking at the old blog articles about the project, it seems it got started with using Flipper Zero as the brain, so maybe it's not that far-fetched. reply dr_kiszonka 1 hour agorootparentprevIt looks gorgeous, especially the hardware. I think the typeface on the hardware and the retro busy text could be further refined, but it is very very cool overall. reply assusdan 1 hour agoparentprevIt is mentioned at their \"We're hiring\" page https://flipperdevices.com/jobs#!/tab/282752814-2 \"We are looking for a professional multidisciplinary designer to join our Busy Status Bar team and help bring the product to Kickstarter, generating excitement among future users.\" reply emilkaiumov 1 hour agoparentprevIt is (but in russian) Pavel Zhovner (a lead of flipper devices) wrote about Busy status bar 3 months ago in his Telegram channel (https://t.me/zhovner_hub/2073). At https://flipperzero.one/ you can find habr.com blog link. The first post in Flipper blog was made by Zhovner https://habr.com/ru/users/zhovner/ (who has a link to telegram channel zhovner_hub). reply bloopernova 1 hour agoparentprevI wonder how many people bought this item without checking that it's legitimate? reply tjohns 46 minutes agorootparentZero, because there's no checkout page yet. Just a mailing list for status updates. reply bloopernova 29 minutes agorootparentThat would put a crimp in any purchase plans, to be sure. reply diggan 47 minutes agorootparentprevI'm 97% sure 0 people bought this thing, seeing as it isn't available to buy yet. reply barrenko 1 hour agorootparentprevCaveat empor my dude. reply nmstoker 6 minutes agorootparentemptor :) reply kretaceous 1 hour agoparentprevCheck the footer. reply jstanley 1 hour agorootparentThat doesn't prove anything. reply blensor 1 hour agorootparentAnd interestingly none of the socials I could find are mentioning it. I am not saying it is a scam it's just very strange that all connections between busy.bar and flipper devices are one way. One would expect some two way mentions reply marliechiller 44 minutes agorootparentprevIt literally says: \"Flipper Devices Designed by Flipper Devices Inc. © 2024. All rights reserved.\" reply swores 34 minutes agorootparentEvery scam website ever made that pretends to be part of a known business copies that business's footer text, it's not remotely relevant in trying to judge whether a website is telling the truth or not about who owns it. (And in case anyone reads my comment without seeing that the founder of Flipper already commented confirming this is theirs, not a scam: that's the case.) reply mikestew 18 minutes agorootparentprevYeah, and those “PayPal” emails telling me to enter my creds must be legit because they say “PayPal © 2024” at the bottom, with a link to paypal.com. reply ThrowawayTestr 41 minutes agorootparentprevAnyone can put that there reply graypegg 3 minutes agoprevI'm a sucker for metal things with greebling. The price seems pretty fair for how niche this is; I totally expected Teenage Engineering prices. (Also in the field of greebled single use devices with knobs and the mass of a blunt-force-weapon) Will totally pick one up for the hardware's skookumosity and hackability poetential alone! reply schnable 2 hours agoprevPeople be so busy they need to buy a hacker-friendly device and build bespoke integrations with it. reply nixosbestos 1 hour agoparentTruly, it's so hard for me to not see this as just dressed-up techie-flavored consumerism. If you can't look at your phone to run a timer without getting distracted, I think there's a different problem to solve. (reminder that Android makes it trivial to not show notifications on the lock screen, or even in the top bar. I see notifications only when I want to.) reply Antipode 1 hour agorootparentThis is primarily to inform other people in the same building as you. reply drdaeman 24 minutes agorootparentprevFeels like a problem in search for a solution to me. Although I haven’t worked in an office for a while now, so it could be that I’m not understanding the importance in such setting (or whatever is this device’s target use environment) that can’t be replaced with a sticky note. reply blutack 1 hour agoprevIf you're looking for something with an addressable LED matrix in a clock style form factor, the Ulanzi TC001 [0] for ~$50 is worth having a look at. Doesn't quite have the same aesthetic but inside it's just an ESP32 (flashed via the USB-C port) and there's various mature open source firmware replacements. I use awtrix[1] on mine and it's very easy to tie in HomeAssistant for doorbell notifications and that sort of thing. I did also knock up a Pomodoro app for it. 0: https://www.ulanzi.com/products/ulanzi-pixel-smart-clock-288... 1: https://github.com/Blueforcer/awtrix3 reply CobrastanJorji 1 hour agoparentI was going to say that $200 seemed awfully expensive for a programmable kitchen timer. I've had a project idea for a while that would require a bit more juice. In short, I want to make a music practice timer for ADHD kids that avoid actually playing music during practice time. I want it to be beefy enough to run some simple ML for detecting instruments being played, and I only want the timer to count down while the instruments are playing. I picture it looking a lot like the clock above, but with something like a Raspberry Pi jammed inside so it's got enough power to reliably detect \"violin.\" Any ideas on hardware for that? reply r2_pilot 1 hour agorootparent\"Identifying Different Musical Instrument Sounds Using Fourier Analysis in LabVIEW\" Rather than \"ML\" du jour, I would say that a fast Fourier transform would get you sufficient data to determine if practicing or talking or silence. reply CobrastanJorji 32 minutes agorootparentDefinitely valid callout. I was also looking for an excuse to play with audio ML, but you're totally right that just examining a Fourier series could very likely do a great job of determining whether a given type of instrument is being played. reply bobnamob 1 hour agorootparentprevThe adversarial child would be playing recordings into the timer within minutes no? reply CobrastanJorji 35 minutes agorootparentI'm assuming the child is question is not so much adversarial so much as ADHD. They'll be actively looking to divert their attention to more stimulating activities than playing an instrument but not attempting to cheat the system. And I'm assuming a parent is present but not necessarily in full control of the child. Or it could work equally well for an adult in a similar situation. reply dr_kiszonka 1 hour agoparentprevNeat! This is very close to what I want. I am looking for a very affordable device like this to affix to my home office doors. I would like it to be programmable allowing me to set the status to Don't Enter when I am having a Zoom call, etc. reply purpleidea 1 hour agoparentprevNeat! Can't tell if it has a speaker at the back or not. Would like to play sounds or alarms... I'd love to attach this to a PoE to USB-C ethernet adapter to talk to it over API via hardwired. Still looking for something like that. The flipper busy bar seems to at least have some connectivity over USB. reply wildekek 13 minutes agorootparentIt has a small piezo buzzer, and you can use it to play RTTTL sounds. https://blueforcer.github.io/awtrix3/#/sounds I have to warn that it sounds like hot garbage though. The neat thing with ESP32 devices is that you can make it sound okay using its built in 8-bit DACs, or great using I²S. Speaking of hardware hacking; you can also get POE/LAN adaptors for the ESP32, if you have free hardware pins left for it. reply frereubu 2 hours agoprevThis reminds me of my first job in London looking after the network of a recruitment agency. The consultants got headsets for the first time and one got so annoyed about being interrupted when on a call - because you couldn't tell when people were wearing headsets the whole time - that she taped a big bit of card to the top of her headset saying \"ON A CALL\" that she could flip up and down depending on whether she was speaking to someone. reply kstrauser 1 hour agoparentI had a coworker who felt free to interrupt me at any time. Even if I were frowning and leaning in to read some code word for word, he’d stop by to talk about nothing. I started wearing headphones when I was in concentration mode and that didn’t help. Then I wrote “DO NOT DISTURB” on a post-it note, stuck it to my headphones, and dug in for some thought-intensive hacking. He came to my desk, pulled the note off the headphones I wore, and tapped me on the shoulder, laughing. “Hah, look what someone taped to your head!” We both learned something about the limits of my patience that day. reply semi-extrinsic 1 hour agoparentprevI can remember people using various USB \"busy lights\" since way back in the Skype for Business days. And one of our super old offices has an 80s style wired green/yellow/red light indicator outside of the door, that presumably used to connect to a switch on the desk. reply vel0city 1 hour agoparentprevOur old Plantronics phone headsets had a TRS jack which would connect to an optional status light. It would light up when the headset was on a call. https://www.headsetsdirect.com/product/poly-busy-light-strai... reply rufugee 13 minutes agoprevNice! For a home-rolled solution, I use a GE CYNC ST19 Edison Style bulb in a socket right outside my office door. I have it configured through Home Assistant (https://www.home-assistant.io/), and then use Hammerspoon (https://www.hammerspoon.org/) on my macbook to make an API call to Home Assistant when the camera state changes. If my camera turns on/off, so does the light bulb. Works really well for letting my family know I'm busy in meetings. reply supermatt 8 minutes agoprevI quite like the large format for a timer. I have some much lower tech alternative that works wonders for helping keep me focused on tasks: https://www.timetimer.com/ reply Buttons840 3 hours agoprevI might buy this to use as follows. I want a work-time tracker that lights a bright LED every 5 minutes or so, and as long as I'm there and working I smash a button and the light goes off for another 5 minutes. Some algorithm tracks the times I have hit the button and displays how long I have been working on said task. I'm picturing something fairly cheap, like a stop watch or 3 button kitchen timer. A LED, a few buttons, a LCD display, a AAA battery slot, and an internal timing circuit is all that's needed (and a case to hold it together). This would basically be a stop watch that stops on its own if neglected, and I can imagine a few uses for it. reply wepple 2 hours agoparentI’ve got this, just some simple JS that flashes bgcolor when the time is up, and I click to extend. I just keep a tiny thin browser on my laptop display I set it to 15 minutes or it’s too frequent. I’ve considered a hardware device (and have tried some) but I like to also track time in meetings, so I’d be lugging it around with me. reply ac_15 2 hours agoparentprevAdd an alarm to play VERY LOUD if the button is not pressed in a 5-7 minute window to keep you working. If you fail to do so the entire office/house has to hear your alarm going off reply Buttons840 1 hour agorootparentMaybe attach a small automatic glitter dispenser. If you stop working you can kiss your home--kiss your home covered in beautiful glitter. reply 0cf8612b2e1e 2 hours agoparentprevI assume lawyers have some mechanism like this already. Law firms can require staff to allocate every 6-8 minutes of their day. Which sounds terrible and likely to be wildly inaccurate as people cannot be bothered to invest that much overhead into their job. reply joshvm 2 hours agorootparentThis is how Swiss medical appointments are billed. I forget exactly how granular, but it's pretty small - 5-10 minutes. As a result, you tend to be quite efficient when going to the GP, because it’s a few Francs a minute If I retain a lawyer at $1k an hour, you bet I want 5 minute billing. reply mattkrause 46 minutes agorootparentSadly for you, I think 6 minute increments (i.e., 0.1 of an hour) might be more common. reply turblety 2 hours agorootparentprev> likely to be wildly inaccurate My gut reaction and prejudiced against all lawyers is it's probably in the law firms interest that these are inaccurate. reply 0cf8612b2e1e 2 hours agorootparentFor sure that seems the intention. Create an “audit trail” for billing while simultaneously making it so onerous that the employees have to fudge the numbers. reply hobs 2 hours agorootparentprevIn my experience it just means a lawyer marks each hour via charging you 10 increments, and that in some cases some forms of comms are generally charged at a sub-hourly charge. In most cases working with a lawyer is a fixed fee or going to be on a retainer basis where the hours pile up regardless, not so much about tracking every moment for every person. reply felideon 2 hours agoparentprevMake it a fidget toy and you're onto something. reply sgwizdak 1 hour agoprevThe mode where it sits on a monitor and displays a status (\"on call\") is very interesting. I think that could be simplified into a product unto itself -- but it would need to priced at \"office toy\" level -- so around $20-$40 USD. reply wildekek 6 minutes agoprevLots of features mentioned there, I wonder how many of those will be ready on launch day and what will be delivered later. reply tamimio 12 minutes agoprevA bit dystopian turning people into a taxi-like system where you need an indicator to tell if they are vacant or not. Regardless, I'm struggling to know the audience here. Is it an employee in the office? If that’s the case, it won’t solve any problem because most of the disturbances happen from your boss either calling about something or asking you to join another useless meeting. Your boss won’t care about your status simply because they won’t be collocated in the same office as you most of the time (not that they care about your online status anyway). For colleagues, after the first month or so, everyone will pretty much find the best way to approach others. If you still need a device for that, then there’s a problem in communication that you need a persistent device all the time. At home, you won’t need such a thing. So I don’t know who will find it useful; it looks gimmicky. What’s next, a hat that will turn a green light telling people you are approachable or in the chatting mode, and red when you are not?! reply refulgentis 10 minutes agoparentAfter reading the page, it seems clear it is akin to a recording studio busy signal, well-trodden territory predating computers, and marketed for video conferencing. Neither without target audience, nor a sigil of the fall of interhuman cooperation and communication :) reply turtlebits 3 hours agoprevLooks slick - the backside of the device does look a little \"busy\" and distracting if I had to stare at it on the top of my monitor. reply tivert 30 minutes agoprevIt looks very neat, and I love all the physical controls, but it seems like kind of a device from another time where everyone worked in-person all the time. I work a hybrid schedule, with a mostly distributed team, and hotdesk/hotel when I'm in the office, so I don't have the luxury of a physical device to indicate my status, nor much use for one. That said, I really want something designed like this that I can use. reply sureIy 3 hours agoprevDoes this really beat a printed BUSY clipart taped to my screen? It's far from the first product I see like this and the question is always the same. reply owlglass 2 hours agoparentThe 'Status' in the product name has two meanings, with the second being the standing conveyed by being able to shell out $189 for a pomodoro timer. reply dailykoder 2 hours agoparentprevFor some people, maybe. For most people not. To me it looks like a very slick, hacker gadget built from a very enthusiastic person. Good finish and highly over-engineered. For me, as a user, it'd be too expensive, but my hacker soul could imagine building something like that too. Nice product, but at that price point probably not for a big audience reply 0cf8612b2e1e 2 hours agorootparentI recall seeing little USB lights on Amazon that accomplished the same thing for $30. Turn red when your calendar/webcam is active, green when free. Of course, I would be suspicious of the software integration privacy, but different problem. reply michaelmior 2 hours agoparentprevYou can also have this update your status on Slack or whatever other relevant platforms support such updates. reply sureIy 2 hours agorootparentIf you're frequently on call I guess it's a cool product, but then again nothing a red ON AIR light can't do for a fraction of the price. reply Eric_WVGG 2 hours agoparentprevcan't things just be fun reply hyperhopper 17 minutes agorootparentNot for $189 reply loloquwowndueo 3 hours agoparentprevIt does cover people interrupting you to ask “ok but how long will you be busy?” :) unless you want to replace your taped clip art every minute or so. reply qmarchi 2 hours agorootparentYou can set your clipart to an end time rather than a count down. \"Busy until 16:00\" reply loloquwowndueo 2 hours agorootparentClever! Thanks you just saved me 200 bucks :) reply echoangle 2 hours agorootparentprevAt this price, you can get a second Monitor facing outward and display how long you’ll be busy on that. In fact, you can get 2 monitors and another computer and have some change left. This is a cool product, especially design-wise, but there are much cheaper solution for this very small problem. reply felideon 2 hours agorootparentGood point. I finally know what to do with the old iPads my kids don't use anymore. reply weinzierl 2 hours agoprevWhere does it draw power from? Does it have to be permanently connected or does it have a battery? I have a lilygo T-Display (which costs less than a 10th of the Busy Status Bar), but I intended to use it untethered and freely movable on the desk. Sadly the battery life is so bad that I basically have to leave it plugged in all the time. reply diggan 2 hours agoparent> Where does it draw power from? Does it have to be permanently connected or does it have a battery? Since it's not mentioned in text, extrapolating from the photos (sometimes it's connected with a cable, sometimes not) I'd have to assume it has a battery. reply weinzierl 53 minutes agorootparentThe natural follow up would be: How often do I have to plug it in? If I have to charge it daily it is probably too much of a hassle and I'll have to have it plugged-in all the time. reply noitpmeder 2 hours agorootparentprevStandard these days is chargeable, have to imagine that is the case here. reply thenoblesunfish 2 hours agoprevMessing with this thing sure seems like a great way to stay focused. reply INTPenis 1 hour agoprevThey need to make a miniature version that I can attach to my headphones because that is my busy indicator. If I'm at work and need to focus, noise cancelling headphones are a must. If they're off then I'm not busy. reply unixfg 3 hours agoprevWhy are the buttons are printed to be readable from the large sign side of the device and not the management side? reply DHPersonal 2 hours agoparentIf I'm in an open office and can set my status clock on top of a monitor, then I don't need the manual controls because I will be changing it via the computer. If I'm not using a computer and setting the device down on my desk in a cubicle, then the primary screen is going to be turned towards me and I will need to use the manual controls. For that specific set of use cases, I see the logic behind the manual control label positions. reply foz 2 hours agoparentprevyes this seems a strange choice. The operator is clearly controlling it from the side with the small screen. reply asoneth 1 hour agoprevI wouldn't have thought this kind of thing would be useful, but after trying a few pomodoro timers I ended up with one (TimeTimer Plus) that is so large that it had the unanticipated benefit of notifying others how long I'll be busy. However, I will say it depends a great deal on your coworkers/family as to whether they care that you're busy when they want to ask you something. reply riiii 54 minutes agoprevInteresting toy, but in my world none of my friends are going to pay $189 for that. Even when the the dollar sign is on the wrong side. reply tbeseda 1 hour agoprevRad device! Not here to gripe about the actual price - and I realize it's counter-intuitive since we say \"one hundred dollars\" out loud - but in the US, the dollar sign goes before the amount: $189 not 189$ reply jayd16 1 hour agoprevHmm shouldn't the button labels be reversed if you're supposed to face it away from you? reply danjl 1 hour agoprevBack when I worked in an office and had to do deep thinking without interruptions, I'd string up a bit of yellow police-like tape that I stole from the SGI offices that were closed during Shoreline concerts that said \"SILICON GRAPHICS\". Worked perfectly. reply leetbulb 2 hours agoprevOh my, this is something I've been wanting to create. Something simple like an illuminated on-air sign outside my office door. This is awesome, and awesomely over-engineered. reply burnte 2 hours agoparentCheck out BlyncLights from Embrava. Much simpler and cheaper. I've installed them in a few companies and have one at home so my wife knows when I'm in a meeting or free. reply simple10 2 hours agoprevThis is incredibly similar to a personal project I've been prototyping. I love that Flipper brought it to market and will buy one. A fully open source & open hardware timer like this would be awesome. Cheaper DIY kit with 3d printable case. Does anyone know if one exists? reply blutack 1 hour agoparentThe Ulanzi TC001 might fit the ticket, it's not open source but it's an ESP32 and a bunch of addressable LEDs you can flash through the USB port. There's an ecosystem of open source firmware for it already. reply slightwinder 2 hours agoprevThis looks retro-sleek. Really cool design. Does this work without cloud-connection? Does it work with the Flipper Zero? Considering it's from the same company, I would think there is some synergy available. And it seems to lack a speaker. For some reason, I would love to play radio on it, not sure why.. EDIT Ok, found the speaker. Nice. reply lwhsiao 2 hours agoprevI can't seem to tell: is this run off a battery? If so, any specs on the battery? Or is it powered via cable? reply anfractuosity 1 hour agoprevOut of interest is there anything similar to the Ulanzi TC001 but with a slightly higher resolution. reply robertlagrant 3 hours agoprevI'm a bit dumbfounded by the price tag of $189. Am I wrong? reply puzzlingcaptcha 3 hours agoparentSeems like quite a bit of hardware engineering went into the design. But if you are hacker and don't care too much about the aesthetics you could probably get 90% of the functionality with an ESP32, a GPIO extender, an LED array, an OLED display and a 3D printed case for like $30. reply zeroflow 3 hours agorootparentA few years ago, I built a simpler version of that device myself. As you said: A 90% solution is easy to hack together. I had mine displaying Skype for Business status so my colleagues would know if I was in a call or just listening to music. The harder part or much rather the time consuming part is getting a good status message from the installed apps. It looks like there is plenty of software and APIs available. reply echoangle 2 hours agorootparentprevCan confirm, here’s a small BOM: 8x 8x8 WS2812 Matrix $2 each = $16 ESP32 $3 1x some acrylic to laser-cut a case in a makerspace $5 So $24 total. The screen would be much larger than the Busy Bar version, which could be a pro or a con, depending on what you want. If you need the smaller back screen (I don’t see the use because I would control it from a computer anyways), that would add another $3 or so. The buttons are basically free but if we assume $3, that’s $30 like you said in total. reply tecleandor 3 hours agorootparentprevThe Ulanzi TC001 devices are kind of near (without the double screen and all the buttons and stuff) for around $50. IIRC they have an ESP32 and have at least 1 or 2 alternative opensource firmwares. reply whitehexagon 2 hours agorootparentprevor maybe a repurposed eWaste phone/tablet, or at this price probably a new phone. reply gffrd 45 minutes agoparentprevPrice is high … but the right price is the price people are willing to pay. … and people will pay a lot for anything that tickles their idea of self-identity, allows them to project an image they find favorable, but taps in to some core utility that allows you to provide cover for the prior. See: Apple devices, fitness, business conferences, this device. reply t-3 3 hours agoparentprevIt is a bit pricey, but probably not overpriced. This kind of niche product is not going to get good economies of scale, those custom molded plastic parts are going to get pretty expensive when not being produced by the million. reply Filligree 2 hours agorootparentThey do if you insist on molding them, but for small runs 3D printing ought to provide a baseline maximum cost. reply madeofpalk 2 hours agoparentprevThis seems like exactly the price I thought it would be. Maybe a bit cheaper to be honest. Those generic \"led pixel clock\" tend to be about $50-$80 ish, and this looks like a 'nicer' (in some aspects) fancier, more niche version of that. reply mannyv 1 hour agoparentprevMy guess was $150. Producing things costs a surprisingly large amount of money because moqs. reply Justin_K 2 hours agoparentprevGo build your own for cheaper and see if you can make a living. reply mplewis 3 hours agoparentprevHow much do you think it should cost? reply foz 2 hours agorootparentThis seems like an item that business would buy in bulk. $180 for single dev version, $90 each in packs of 10. Customized with your company branding maybe. reply enraged_camel 3 hours agoparentprevMaybe I’m not the target audience but I wouldn’t pay more than $20 for something like this, because I don’t have a burning need for it. reply jareklupinski 2 hours agoprevi thought someone had finally productized a clock i built for myself a long time ago, which, instead of showing you the time of day, counts down to your next meeting https://github.com/jareklupinski/count-down google and apple dont make it easy... reply darrelld 3 hours agoprevThis is cool, I've thought of building something like this for years now. The price is a bit high, but glad to see it in the real world. reply pavel_lishin 3 hours agoparentYeah - I feel like everyone who would want one of these would rather build one than pay $189 for it :/ reply karolist 1 hour agoprevLooks like lametric alternative? reply jeanlucas 2 hours agoprevSince 2014 I dream about a product very very similar to this! Happy to see it built!! reply LeafItAlone 3 hours agoprevI love this idea. If it was $100 instead of $189, I would order two (one for me, one for partner) as soon as they were available. reply QuinnyPig 2 hours agoprevFinally I can put my colleague on Verbal Probation. reply secondcoming 2 hours agoprevWhere has the practice of putting the $ behind the value come from? I see it happening to £ too. I'm irrationally annoyed by this. reply drchaos 1 hour agoparentIt's standard for Euro amounts and before that for many (most?) European currencies. reply encom 2 hours agoprevSo this is a cloud connected LED sign that tells people to ~~fuck off~~ leave me alone. For 189 USD. This is the most Hacker News thing I've seen in 2024. reply wannacboatmovie 1 hour agoparentIn a way it's the perfect product if your target market is those responsible for the atrocities of the modern web: like why I need a cloud-connected smartphone app that requests full permissions to set up a $10 camera. Juicero, where are you? reply jacknews 2 hours agoprevI hit the 'BUY' button while thinking 'how much is this worth, or would people be willing to pay' and settled on about $60-80. I'm obviously a cheapskate. Sure, some people will buy it even it was $2000, but I think most people will be put off by the ~$200 price. reply jeffbee 1 hour agoprevFinally, the productivity technique named after a $1 clockwork timer gets the fiddly software-and-cloud-based solution it deserves. reply Keyframe 3 hours agoprevtoo expensive to justify the purchase, otherwise cool and seems to be rather good build quality (at least from videos). reply Jayakumark 3 hours agoprevGood but expensive, also does not solve for people behind or side of you. reply emmanueloga_ 1 hour agoparentv2 should replace the matrix display with a Vegas Sphere [1] :-p -- 1: https://www.youtube.com/watch?v=Jjg6-xT6rJg reply euniceee3 3 hours agoprevWhy is everyone complaining on the price tag? It is a product that someone made for profit just like everyone else here is trying to do. Did Hacker News turn into Daily Deals? reply hyperhopper 8 minutes agoparentSo because everyone wants to make profit, nobody can complain about any prices regardless of how insane they are? What kind of logic is that? reply bradhe 3 hours agoparentprevIt's honestly not even that expensive considering all the functionality you get and the tech included (which is something HN should understand) reply hyperhopper 6 minutes agorootparentThe functionality is a small screen with a timer and a few API calls to set the timer for you sometimes. $189 for a timer is not a lot of functionality for more than 1% of the annual salary of a minimum wage worker. You can get a full android phone for that much which has 10000x the functionality. reply imglorp 2 hours agoprevAll these sad people working in offices that need to defend their focus. I will never do that again. reply jollyllama 1 hour agoparentI struggle to imagine the office where this is respected. reply Sohcahtoa82 2 hours agoparentprevSome people actually like being in an office. I wouldn't mind working hybrid and going to an office 2-3 days/week as long as the commute was under 20 minutes. reply tevon 2 hours agoparentprevI'm planning to use this at home to defend my focus from myself! That idea definitely goes both ways. reply timcobb 2 hours agoparentprevThe price of interacting with people in person reply MOARDONGZPLZ 2 hours agoparentprevI downvoted this because it is really pejorative to call people sad in this way for doing their jobs. Though I do agree that it stinks sometimes to be focused and have people walk by and cause context shifts. Regarding the original topic, I mostly work from home and even there like pomodoro timers because they help me focus. Set it for 25 minutes and focus until the time is up, take 5, then get back to it. Works great for me! reply rpgraham84 3 hours agoprev\"hey what's that flashing box on your monitor?\" \"that's my pomodoro timer, it's from a Russian company that specializes in devices that enable various forms of cybercrime. you may have heard of the widespread wave of fraud circa 2019\" \"oh neat, no I haven't heard of that\" \"hey what's the wifi password again?\" reply wepple 1 hour agoparent“Enable various forms of cybercrime” seems like a stretch. If flipper does, so does Nmap and metasploit and Linux and soldering irons. reply dingnuts 3 hours agoparentprevwhere do you see that they are Russian? they seem to have a bunch of US Patents, a Delaware postal HQ, and an office in the UK reply NicuCalcea 3 hours agorootparentMost of the staff looks to be Russian: https://www.linkedin.com/company/flipper-devices/people/ reply hiatus 3 hours agorootparentThe top \"Where they live\" is UK. reply rpgraham84 3 hours agorootparentwhew. that's a relief reply Nzen 2 hours agorootparentprevThe company makes Flipper Zero as well. When they launched that product, the same topic came up [0]. The strongest argument given seems to hinge on the former nationality/residence of many of the original team. Obviously, different people will weight that above or below the UK address / USA incorporation. [0] https://news.ycombinator.com/item?id=32168388 reply rpgraham84 3 hours agorootparentprevthe original team is Russian, but they downplay that a lot now (until you buy one and the promo stickers are in Russian). yes, they're registered in Delaware, almost every company that operates in the US is, including foreign companies. reply wannacboatmovie 2 hours agoprev [–] Very Les Nessman-ish. Whenever I see someone with a busy light in the office, I view it as an over-the-top, attention-grabbing, awkward human interaction and an explicit invitation to bother him or her. It's \"don't make me tap the sign\" in electronic form. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Busy Status Bar is a productivity tool featuring an LED pixel screen for displaying custom busy messages and includes a Pomodoro timer.- It is open-source and developer-friendly, supporting multiple programming languages like Python, JavaScript, and Go, and integrates with popular apps such as Zoom and Discord.- Designed by Flipper Devices Inc., it offers cloud control via API and MQTT, supports IoT integrations, and is compatible with Windows, macOS, and Linux."
    ],
    "commentSummary": [
      "Flipper Devices' Busy Status Bar is an upcoming product, confirmed by CEO Pavel Zhovner, currently in development and not yet officially announced.",
      "The device aims to indicate user status and may integrate with smart home protocols, sparking debates on its necessity and pricing.",
      "While some view it as a niche, hacker-friendly gadget, others appreciate its design and potential functionality, leading to discussions on its practicality and target audience."
    ],
    "points": 382,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1728919152
  },
  {
    "id": 41833200,
    "title": "Python client for the $20 Colmi R02 smart ring",
    "originLink": "https://tahnok.github.io/colmi_r02_client/colmi_r02_client.html",
    "originBody": "colmi_r02_client Open source python client to read your data from the Colmi R02 family of Smart Rings. 100% open source, 100% offline. What is the Colmi R02? It's a cheap (as in $20) \"smart ring\" / fitness wearable that includes the following sensors: Accelerometer step tracking sleep tracking gestures (maybe...?) Heart Rate (HR) Blood Oxygen (SPO2) I found out about the ring from atc1441 and his work on ATC_RF03 and the Hackaday coverage Got questions or ideas? Send me an email open an issue join the discord Are you hiring? Send me an email How to buy You can get it on here on AliExpress. If that link is dead try searching for \"COLMI R02\", I got mine from \"Colmi official store\". It cost me $CAD 22 shipped. Reverse engineering status Real time heart rate and SPO2 Step logs (still don't quite understand how the day is split up) Heart rate logs (aka periodic measurement) Set ring time Set HR log frequency SPO2 logs Sleep tracking \"Stress\" measurement Planned Feature add more CLI functionality pretty print HR and steps sync all data to a file or SQLite db simple web interface Getting started Using the command line If you don't know python that well, I highly recommend you install pipx. It's purpose built for managing python packages intended to be used as standalone programs and it will keep your computer safe from the pitfalls of python packaging. Once installed you can do pipx install git+https://github.com/tahnok/colmi_r02_client Once that is done you can look for nearby rings using colmi_r02_util scan Found device(s) NameAddress -------------------------------------------- R02_341C70:CB:0D:D0:34:1C Once you have your address you can use it to do things like get real time heart rate colmi_r02_client --address=70:CB:0D:D0:34:1C get-real-time-heart-rate Starting reading, please wait. [81, 81, 79, 79, 79, 79] The most up to date and comprehensive help for the command line can be found running colmi_r02_client --help Usage: colmi_r02_client [OPTIONS] COMMAND [ARGS]... Options: --debug / --no-debug --record / --no-record Write all received packets to a file --address TEXT Bluetooth address --name TEXT Bluetooth name of the device, slower but will work on macOS --help Show this message and exit. Commands: get-heart-rate-log Get heart rate for given date get-heart-rate-log-settings Get heart rate log settings get-real-time-heart-rate Get real time heart rate. info Get device info and battery level set-heart-rate-log-settings Get heart rate log settings set-time Set the time on the ring, required if you... With the library / SDK You can use the colmi_r02_client.client class as a library to do your own stuff in python. I've tried to write a lot of docstrings, which are visible on the docs site Communication Protocol Details I've kept a lab notebook style stream of consciousness notes on https://notes.tahnok.ca/, starting with 2024-07-07 Smart Ring Hacking and eventually getting put under one folder. That's the best source for all the raw stuff. At a high level though, you can talk to and read from the ring using BLE. There's no binding or security keys required to get started. (that's kind of bad, but the range on the ring is really tiny and I'm not too worried about someone getting my steps or heart rate information. Up to you). The ring has a BLE GATT service with the UUID 6E40FFF0-B5A3-F393-E0A9-E50E24DCCA9E. It has two important characteristics: RX: 6E400002-B5A3-F393-E0A9-E50E24DCCA9E, which you write to TX: 6E400003-B5A3-F393-E0A9-E50E24DCCA9E, which you can \"subscribe\" to and is where the ring responds to packets you have sent. This closely resembles the Nordic UART Service and UART/Serial communications in general. Packet structure The ring communicates in 16 byte packets for both sending and receiving. The first byte of the packet is always a command/tag/type. For example, the packet you send to ask for the battery level starts with 0x03 and the response packet also starts with 0x03. The last byte of the packet is always a checksum/crc. This value is calculated by summing up the other 15 bytes in the packet and taking the result modulo 255. See colmi_r02_client.packet.checksum The middle 14 bytes are the \"subdata\" or payload data. Some requests (like colmi_r02_client.set_time.set_time_packet) include additional data. Almost all responses use the subdata to return the data you asked for. Some requests result in multiple responses that you have to consider together to get the data. colmi_r02_client.steps.SportDetailParser is an example of this behaviour. If you want to know the actual packet structure for a given feature's request or response, take a look at the source code for that feature. I've tried to make it pretty easy to follow even if you don't know python very well. There are also some tests that you can refer to for validated request/response pairs and human readable interpretations of that data. Got questions or ideas? Send me an email or open an issue Other links https://github.com/Puxtril/colmi-docs gadgetbridge (open source android client for many smart devices) support PR",
    "commentLink": "https://news.ycombinator.com/item?id=41833200",
    "commentBody": "Python client for the $20 Colmi R02 smart ring (tahnok.github.io)292 points by tahnok 17 hours agohidepastfavorite100 comments z3ugma 9 minutes agoLots of good additional hacking at https://github.com/atc1441/ATC_RF03_Ring/issues/13 for what it's worth @tahnok I do this kind of (reverse) engineering of BLE for medical-grade devices for my day job, I'm keen to hack on this with y'all! reply vitorbaptistaa 21 minutes agoprevDoes anyone know if any of these rings' accelerometers are precise enough to detect falls? I am thinking of elderly patients who refuse to use smartwatches or any \"old-person-looking\" devices. reply TechDebtDevin 8 hours agoprevI'm so excited to play with this. I just ordered one. I've gone through two Oura rings (I do not reccomend). I'm not sure this will be reliable but it cost me $14.00 not $300 and doesn't charge me monthly to access a mediocre api. reply pards 6 hours agoparentIMHO companies should not be permitted to \"sell\" devices that require a subscription to function - that's a rental model - especially when there's only one service provider. Either sell the ring and include lifetime membership for free like Garmin [0], or _lease/rent_ the device on contract and charge a monthly fee. Don't do both The Oura starts at $469 CAD [1] plus $7.99 CAD per month [2]. [0]: https://connect.garmin.com/ [1]: https://ouraring.com/product/rings/oura-ring-4/silver [2]: https://support.ouraring.com/hc/en-us/articles/360052018753-... reply RunningDroid 4 hours agorootparent> Either sell the ring and include lifetime membership for free like Garmin [0], or _lease/rent_ the device on contract and charge a monthly fee. Don't do both An example of something similar is quip¹'s subscription, you buy the toothbrush and subscribing to the refill plan gets you a \"lifetime\"² warranty 1: getquip.com 2: lifetime of the subscription reply wjnc 4 hours agorootparentWhat are your thought on risk / reward (more precise: cashflow matching) with regards to physical products with a software component? I think buy (hardware) + fee (software) is the natural way of looking at things. Just as you pay separately for car maintenance. The buy-once, upgrade-years model puts too much risk on the developer. Which in turn results in lousy experiences for customers (dropped support for software, loss in value of hardware on the second hand market). I actually bought an iOS app twice because I found it crazy to be able to use the same €5-app as a baby monitor for over a decade. That is probably a single developer churning out features at a low pace, but continuously for a big part of a career. reply crusty 1 hour agorootparentBuying a car and paying for maintenance is not analogous. You buy the car - it works. Paying for maintenance is just meant to keep it working for longer. You could buy a car, not pay for maintenance and drive it until it breaks. That's very different than buying something that is completely non-functional without the subscription. Also, aside from some very specific and new instances, car maintenance has not been provided solely by the manufacturer or authorized dealers. reply TechDebtDevin 2 hours agorootparentprevAnd there's more than a 50/50 chance that if you forget to charge that $469 ring for a few days that it will brick. Also Oura isn't all that accurate. For anyone who is interested in the wearable space I HIGHLY reccomend The Quantified Scientist[0] on Youtube. He does his best to compare wearable accuracy with real medical devices or other proven devices. [0]: https://m.youtube.com/thequantifiedscientist reply renewiltord 1 hour agorootparentprevIMHO companies should not be allowed to sell anything unless they will provide open hardware and open software and an irrevocable license to use their tooling to construct more. reply kmlx 6 hours agorootparentprevoura ring does function without a subscription, but the data is obviously poorer. reply TechDebtDevin 2 hours agorootparentYeah I specifically referred to the API. Without the subscription their app is pretty whack and outside of that you can only download .csv from a link. reply pydry 8 hours agoparentprevOura rings do seem to have accurate tracking (unlike most smart watches). The data it collects and the subscription model look awful though. Im eagerly awaiting a ring sleep tracker like it which can be used offline with gadgetbridge or something. reply TechDebtDevin 1 hour agorootparentRings are not a mature form factor for these sensors/platforms.The $50.00 huawei band 8 is much more accurate than the $3-400 Oura ring. Check out the Quantified Scientist on YouTube[0]. [0]: https://m.youtube.com/@TheQuantifiedScientist While I still love the ring form factor. As tacky as it sounds, I still wear my bricked Oura rings sometimes just because I like the feel lol. However, I would never trust Oura ((or any other device outside of Apple(unfortunately)) to gauge you health off their data. While Oura is directionally correct (like most of them), it never once detected low oxygen levels in my sleep and I have some of the worst central sleep apnea my doctor has seen. reply bg0 37 minutes agorootparentThe comments referencing quantified scientists do so in a somewhat negative light. But it should be noted that in his research, he points out that the oura is one of the top trackers for sleep[0]. This is not the only video that he praises the oura for being pretty damn good based on other devices. [0]: https://www.youtube.com/watch?v=niLuR68YleI 2min41sec reply danielbln 6 hours agorootparentprevSupport for this ring (Colmi R02) was added to Gadgetbridge, so I suppose your wait is over: https://codeberg.org/Freeyourgadget/Gadgetbridge/pulls/3896 reply tahnok 4 hours agorootparentNice, I hadn't seen the gadgetbridge support PR before, will be good for a lot of people I think reply pydry 4 hours agorootparentprevThe sleep tracker seems to be quite poor - e.g. misrecognizing time spent in bed as time asleep. This was the same problem I had before with a xiaomi. It was so inaccurate on all fronts I just ditched the thing. I wasnt expecting the colmi to be accurate for this low price, but still. For gadgetbridge I dont think there are any good sleep trackers and the only two I know of that are genuinely accurate are the apple watch and oura (theres a guy who tests them all on youtube - this is what he found). Id happily pay extra for a decent non-apple local storage only fitness tracker which integrates with OSS and doesnt upload every heartbeat to the cloud but it does not seem to exist. reply runjake 3 hours agorootparentprev> Oura rings do seem to have accurate tracking (unlike most smart watches). Accurate tracking of what? And which smart watches? The Apple Watch seems to generally have the most accurate tracking according to most studies, which surprises me. When I was looking at buying an Oura and browsing user subreddits, it was full of complaints about inaccurate readings and the slow intervals between readings. reply rkwz 3 hours agoprevHow safe are these cheap devices? Should one be concerned about battery exploding? Found some threads about this happening to Oura rings: https://www.reddit.com/r/ouraring/comments/s1fave/ring_batte... reply tahnok 1 hour agoparentI'm not very concerned, the battery is extremely small and I think it's potted in resin so it's not likely to get damaged reply Galanwe 13 hours agoprevIs there a similar ring with NFC? I have no use for the smart health thingies, which really look like a data driven health gimmicks to me. NFC on the other hand I could find hundreds of applications, from payment to access and transport cards. reply edent 12 hours agoparentYes. I have the Z1 Ring. Getting secure tokens (like payment, door unlock, etc) is possible but can be complicated. The ring is a small target, so not always easy to find the received if you're using it with a phone. Oh, and the software is low level and finickity. I managed to accidentally set mine to read only mode permanently. Review at https://shkspr.mobi/blog/2024/02/giving-the-finger-to-mfa-a-... reply stavros 8 hours agorootparentI have a suspicion this is a whitelabeled NFC ring I got from AliExpress for $12. That one includes a T5577 chip and a Mifare tag. You can read and write the Mifare tag with your phone, as normal, and the T5577 with a Flipper Zero or a Proxmark (also from Ali, $40). The NFC tag is a small target, probably because of the size of the antenna, but the RFID one has pretty good range. I got five of those rings, very much recommended if you have stuff to auth to. reply edent 6 hours agorootparentI think your suspicions are wrong. Those $12 rings will allow you to serve NDEF messages or similar. They won't do U2F, payment, car unlock etc. reply stavros 5 hours agorootparentIt doesn't look like the Z1 does payment either, though. I don't know how they do U2F, but it looks like it comes with a custom reader, which is non-standard. I don't know how Tesla unlock works, so I can't say there. reply edent 3 hours agorootparentThere is no custom reader. It works with standard NFC readers on Linux and Android. reply stavros 3 hours agorootparentAhh interesting, thank you. reply franga2000 12 hours agoparentprevThe problem with that idea is that all secure implementations of RFID lock the user out, meaning you can't just buy an NFC ring/fob/implant and copy your bank card or transit card onto it. The only implementations where the user can do that are terribly insecure and, while still commonly used, are slowly getting phased out. So for anything other than systems you control or are good friends with the IT guy for, you're out of luck. reply Galanwe 12 hours agorootparentRight I agree with you on theory. But in practice, I already do clone most of my smart cards on small NFC stickers on the back of my phone case. The things is 99.9% of access cards (where I leave at least) are default-encrypted mifare classic, making cloning trivial. Transport cards are an other beast since they have their own backlog and proper encryption, but there are ways. So all in all, dumping the card is not the issue for me, it's the medium on which to put the clones that is still a question mark. The \"NFC sticker on the back of the phone\" is cool because it's almost as if your phone opens the door (stock android won't let me easily swap NFC SC ID), but NFC is fidgety when multiple chips are in close proximity, leading to frequent misses. I have found multi-chips NFC cards on Ali Express. These are basically a single antenna wired to an array of chips directed by a keypad. That seems viable on paper but you still get to carry the card and press the right switch. The ideal solution would be a smart ring with a reflashable NFC chip, along with a programmable MCU to implement the rolling logic between cards. reply stavros 8 hours agorootparentReflashing the NFC chip on the ring is a bit of a pain (it takes a second, but if I have to spend a second doing it every day, I might as well get my keys out). Since every phone has an NFC chip nowadays, though, can't we use that to emulate all our Mifare cards? reply Galanwe 6 hours agorootparent> can't we use that to emulate all our Mifare cards? Unfortunately, no. From my experience at least, most access cards are simple mifare classic cards, and they have no payload: the reader just got a list of allowed card IDs, maintained by the building IT. While you can freely rewrite mifare data from Android, it won't let you change your ID unless you root your phone. I guess this is similar to the old days where you weren't supposed to change your MAC addresses. reply wellthisisgreat 5 hours agorootparentprevSounds interesting, which sticker are you using? reply weinzierl 3 hours agoparentprevI have no use for the smart health thingies too, but instead of NFC I want to use it as a controller and display. Is there a ring with touch or physical buttons. A clicky wheel would even be better. As display I image multiple discreet RGB-leds, but other option could work as well. reply gorbypark 12 hours agoparentprevThey do exist, I believe. I don't have one but came across many for sale on AliExpress when looking for a writer to clone my RFID apartment door entry thingy. Seems like they even have some that are dual NFC/RFID that would work as regular NFC as well as for my apartment door (125khz). reply DaSHacka 11 hours agoparentprevDangerous Things (popular RFID/NFC implant makers) sell dual 125khz+13.56mhz clonable rings, but they're way overpriced ($130). I bought my \"V1\" back when they were still $60, and FWIW, if you know what you're doing, it does work. I've also seen some rings on Aliexpress that purport to support the same capabilites, but havent personally tried them out yet. reply stavros 8 hours agorootparentI've tried the Aliexpress ones, they work fine. I have like five of them. reply DaSHacka 1 hour agorootparentWhich vendor did you buy from? When aquiantances ask me for recommendations I always tell them to look into Aliexpress over Dangerous Things as they're significantly cheaper, but I've also heard really mixed things about the various offerings on the site. reply stavros 1 hour agorootparentThe only time I've been scammed was when I bought a 16 TB USB drive for $3, or a $10 mosquito bite thing that didn't work. Basically, if the thing sells for much cheaper than anywhere else, it's a scam, otherwise you're OK. I've bought from Ali hundreds of times, maybe thousands of items. The quality isn't always great (what can you expect for the price?), but it's very rarely scams. Stay away from microSD cards, though. reply m463 13 hours agoparentprevI think you're onto something. I would be ok with a watch too. reply hotfixguru 11 hours agorootparentA friend of a friend mods Casio watches[0] to have NFC, and sells them on his website. [0] https://delaveris.com/collections/nfc reply dsign 11 hours agoprevThe hardware is getting so cheap! But the software... I bought for $20 a bed lamp that comes with led lights, bluetooth receiver, clock and alarm clock, and wireless charging for my iphone. It has a microphone to stream all my conversations god knows where, though its purported purpose is to listen me sing and pulse the lights according to the pitch. It comes with a convenient app to set the clock and the lights. But due to a glitch in the software, the alarm goes off every night at 01:00 AM. I haven't been able to disable that via their official app; no real programmers were used making that thing. But there probably is a bug in their bluetooth stack that would allow me to become root of the lamp and fix it myself...if I had the time. I wish hardware makers for off-brand products would include a minimal hacking kit in their boxes. reply swiftcoder 59 minutes agoparent> its purported purpose is to listen me sing and pulse the lights according to the pitch I'm stunned there are enough customers with good enough pitch control to make that a viable market reply trojan13 7 hours agoparentprevYou could try to open it (carefully, you might damage your precious lamp. Also please plug it out beforhand). Often times smart devices like these have debugging ports left on the board you can easily access with some clamps. reply Yenrabbit 3 hours agorootparentOr failing that, desolder the offending speaker to keep the rest of the functionality intact. reply fulafel 6 hours agoprevSo you just scan for devices and then read? There's no authorization involved, these just publish the readings wirelessly for all interested? reply michaelt 5 hours agoparentThe basically-no-authorisation arrangement is somewhat common for modern bluetooth devices. It's problematic for things like keyboards used for entering passwords - but if my next door neighbour wants to snoop on my living room thermometer or someone wants to snoop on my heart rate strap as I jog past their house? It doesn't seem to be much of a problem, in practice. In the bad old days of bluetooth, loads of devices without screens would just hard code the pairing code to 000000 anyway. So it wasn't adding much security anyway. Unlike internet-connected devices, it's not exposed to a billion griefers from around the globe at any given moment. reply fulafel 4 hours agorootparentOngoing read of your neighbours, roommates, co-workers etc health data from a distance including recent history is getting your hands on sensitive personal data in addition to health data. You can tell what they are doing, getting drunk or having sex etc. reply swiftcoder 1 hour agorootparentprev... doesn't the app set an encryption key after they pair? The most similar device I've worked on is the various Oculus devices. Which will also accept bluetooth connections from absolutely everyone, but the first time you connect you store an encryption key that is used to secure all subsequent comms. reply wongarsu 26 minutes agorootparentIf it did that then losing your phone, deleting the app's storage or moving to a different phone without transferring the app's storage would brick the smart ring. Oculus decides are pretty big, I assume they have buttons that allow you to recover from that. This ring doesn't. reply wongarsu 5 hours agoparentprevThe ring has a very minimal interface. Apart from the sensors - an accelerometer to count steps and two LEDs with photodiode to get heart rate and blood oxygen - there is one status LED on the inside to indicating charging. That's it. The ring is a pure data collection device that basically can't be interacted with without the app. Maybe they could have required you to hit the ring on a surface to initiate pairing mode. But as it stands the ring will pair with any device that asks for it. I'm looking forward to someone making a custom firmware for these rings. There is some work in the linked ATC_RF03 project, but I'm not sure if anyone is still working on it reply tahnok 4 hours agorootparentI started looking at this last night [1] since there's an open SDK available (called SDK3) [2] but it seems like keil is involved in compiling it and I'm out of my depth when it comes to embedded stuff at the moment 1. https://notes.tahnok.ca/blog/Smart+Ring+Reversing/2024-10-13... 2. https://gitee.com/BXMicro/SDK3 reply Flux159 14 hours agoprevThis looks interesting - is there a comparable ring that also has a temperature sensor? It would be interesting to be able to determine if you're sick a day or two ahead like an Oura ring or Apple's new Vitals app for Apple Watch using an open source app. Alternatively, does anyone know if it's possible with the sensors just in this ring? reply karamanolev 12 hours agoparentFrom my experience, RHR, sleeping heart rate and HRV are good indicators of when I'm getting sick. reply JansjoFromIkea 2 hours agoparentprevwould also be keen to find one with a temperature sensor, looks like there's nothing remotely near this price point yet? reply anotheryou 6 hours agoprevIt doesn't support raw accelerometer data yet, right? That would be the only deliberate input method, which would be fun. reply blutack 7 hours agoprevFrom the GadgetBridge pull request[0] mentioned by dingensundso: There's a nice site with a lot of the BLE API documented (including commands) at https://colmi.puxtril.com/ 0: https://news.ycombinator.com/item?id=41834048 reply bhaney 14 hours agoprevCool. Just ordered one (from Temu, $18) even though I already wear an Apple Watch. Love the idea of having something I can interface with directly and pull realtime data from without having to install some middleman phone app. reply woadwarrior01 7 hours agoparentI just did the same. I'd love to try augmenting the sleep tracking data from my Apple Watch with the sleep tracking data from this ring. A couple of months ago, I learnt from this YT video[1] that sleep tracking gadgets are all quite inaccurate compared to a proper polysomnography study. But they're all inaccurate in different ways. [1]: https://www.youtube.com/watch?v=mjOYhxLJP90 reply cyberpunk 5 hours agorootparentRight but if it’s the same sensor you are wearing each night you can still learn something from the trends instead of relying on the raw numbers. E.g there’s a definite motivation kick to drink less when I see what it does to my hrv and sleep trends for days afterwards, while I don’t particularly care about the numbers being all that accurate. Edit: Oh and turning on afib history in your Apple Watch will make it record like 10x data points which also helps with that. Maybe reply wanderingmind 15 hours agoprevAmazing work. But, What would it take to port this work to Gadgetbridge to make the access easier reply dingensundso 15 hours agoparentLooks like gadgetbridge already supports it (in nightly): https://codeberg.org/Freeyourgadget/Gadgetbridge/pulls/3896 https://gadgetbridge.org/gadgets/wearables/colmi/ reply cdchn 14 hours agoparentprevWow I'm more excited to learn about Gadgetbridge than I am about this ring. reply dyeje 1 hour agoprevIs there an official client? reply navanchauhan 1 hour agoparentQRing reply heavyset_go 16 hours agoprevOne of these with a Java card and NFC would be cool. reply cdchn 14 hours agoparentWe've had those for 26 years https://www.ebay.com/itm/300495374337 reply hyperific 12 hours agorootparentOnly on HN could you find a gem like this. This is a bit of internet history. reply detaro 11 hours agorootparentprevI love eBay sellers: > JAVA RING: VERY RARE! > More than 10 available – 1,230 sold reply sgt 11 hours agorootparentAfter HN there won't be anything left. reply heavyset_go 7 hours agorootparentprevThank you for unlocking this core memory reply stavros 8 hours agoprevThis is great! I tried to do this because I wanted to add an indicator of my heart rate to Slack, so people would see if I'm pissed off, but I could never get the data from the ring. I'm very curious to see how the author does it. reply daghamm 6 hours agoparentThis has the unintentional effect of people knowing when you fall asleep in meetings. reply BarryMilo 5 hours agorootparentHope it stops updating after business hours! reply vosper 16 hours agoprevI couldn’t find it on the product page: any idea if this has a vibrating alarm? I’m in the market for something to wake me up without disturbing my partner reply yjftsjthsd-h 14 hours agoparentWouldn't a watch do that? Ex. the https://pine64.com/product/pinetime-smartwatch-sealed/ is dirt cheap and its alarms just vibrate the watch. reply vosper 10 hours agorootparentI would prefer something less bulky (I don’t wear a watch) but thank you for the link: that is indeed dirt cheap and probably worth a go. reply petemir 8 hours agorootparentprevI guess it depends. My partner still gets woken up by my (smart)watch at the lowest vibration setting. reply michaelt 4 hours agorootparentIf your partner gets woken by a watch vibration actuator, I doubt it's possible for you to sneak out of bed without waking them, as your body weighs about 10,000 times as much as that actuator. reply flax 16 hours agoparentprevit does not. reply 0xEF 37 minutes agorootparentWell, they missed a huge opportunity to break into the discrete sex toy market, then. reply IgorPartola 15 hours agorootparentprevIf it doesn’t vibrate that’s a real shame. Ideally I would want it to vibrate as well as be able to detect gestures. That would be such a killer combo for so many things from golf training to turning on the mood lighting with a swish of your hand. reply alchemist1e9 7 hours agoparentprevI used the smallest fitbit for that. Work very well for me. reply croes 14 hours agoprevHow accurate can the data of such a smart ring be or do other smart ring have so high margins? reply bhaney 14 hours agoparentFrom the little bit of research I just did before buying one, most people are reporting that compared to their more expensive trackers, the heart rate, accelerometer, and sleep tracking functionality are all pretty accurate (good sleep tracking being dependent on a high sampling rate, which decreases battery life), but the blood oxygen and \"stress\" reporting is uselessly inaccurate. reply OkGoDoIt 13 hours agorootparentThat has also been my experience with this model. I’ve been using it for about a month now. I originally planned on trying to use the accelerometer data over Bluetooth to build a custom control input for Frame smart glasses, but I got busy and never got around to that. But I’ve been wearing it as a health tracker and the heart rate and sleep tracking seem pretty accurate relative to my Apple Watch, and the blood oxygen measurement is generally a couple percentage lower than my Apple Watch. I have no idea what the stress thing is even supposed to measure, it’s just a random number that doesn’t seem to have any correlation with real life and there’s no units or explanation. I get about four days of battery life with all of the sensors turned up to maximum frequency, which is every 5 minutes at least for the heart rate. Surprisingly good for such a small lightweight device. I imagine it could go a lot longer if you turned down the sensors to a lower frequency. I found a good rhythm is to charge it when I take showers, that seems to be a good balance and it never comes close to dying. My Apple Watch on the other hand regularly dies before I go to bed, and I can’t wear it for sleep tracking because it can’t last that long. I will never understand people that pay a monthly subscription to access basic local sensor information like this. Yet I see people wearing subscription-based smart rings all the time. I don’t get it. reply updatedprocess 8 hours agorootparentSome reviews say it's a little bulky to wear. It's that your experience? reply stavros 8 hours agorootparentprevI tried blood oxygen and the readings were the same as my pulse oximeter (though it always shows 98%, so I haven't managed to test any other value), but my sleep reporting with the ring would regularly be three or four hours longer than I actually slept, making it useless. reply alwayslikethis 7 hours agorootparent> test any other value Try this: Hyperventilate for a minute or two. Then, make a full exhale and hold it. You should be able to hold your breath for longer than you normally can and during this time you should see the value drop a bit. Be sure to inhale before you start getting dizzy or faint. (Note: do not do this under water) reply HumblyTossed 5 hours agorootparent> (Note: do not do this under water) Or while operating heavy machinery. reply stavros 6 hours agorootparentprevOh interesting, thank you, I'll try that. reply ModernMech 3 hours agoprevHow is battery life with Python compared to C? reply Always42 15 hours agoprevAt a quick glance this looks cool! I just have a hard time justifying things like this when the apple watch + iphone work so well. But i'm sure at some point the apple experience will get worse and push people to other OS like windows is reply israrkhan 13 hours agoparentHere are few reasons that justify its existance. * Different form factor * Not tied to Apple Ecosystem. * Price * You can even use it independently (without phone). reply daghamm 12 hours agoparentprevI dont understand this attitude. If this is how you feel about technology why are you not on the verge instead of HACKER news? reply inanutshellus 2 hours agoparentprevEveryone I know that has a smart watch charges it overnight. How do you propose using it to track sleep? reply WesleyJohnson 1 hour agorootparentYour question implies the answer; charge it at different times and wear it to bed? reply inanutshellus 47 minutes agorootparentRemember the context of my quip is in reply to \"I don't see the value in the ring, just buy a $1200 watch and phone combo and make sure you charge your watch while you're out living your life, not when you're asleep.\" Still seems pretty clear as to why someone would find value in the ring. Another poster says he charges his ring while he showers. It's that quick. I'm not knocking smart-*, just reacting to the dismissive \"why would anyone want this\" attitude of GP. reply RamiAwar 14 hours agoparentprev20$ 1200$ I have an easier time justifying this reply TechDebtDevin 8 hours agoprevHell ya, thanks for this! reply ck2 3 hours agoprev [–] imagine showing a tiny ring with 200k of ram and half a meg of flash, bluetooth and all those sensors for $20 to someone just 10 years ago https://hackaday.com/2024/06/16/new-part-day-a-hackable-smar... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Colmi R02 Client is an open-source Python tool designed for accessing data from Colmi R02 Smart Rings, which are budget-friendly fitness wearables.",
      "The tool operates offline, enabling users to interact with the smart ring via Bluetooth for features like real-time heart rate monitoring and step logging.",
      "Users can install the client using pipx, a Python package manager, and utilize various commands for data retrieval and device settings through Bluetooth Low Energy (BLE) communication."
    ],
    "commentSummary": [
      "A Python client has been developed for the Colmi R02 smart ring, enabling users to access data without needing a subscription.",
      "The Colmi R02 is gaining attention on platforms like GitHub and Hacker News for its affordability and potential for hacking and reverse engineering, compared to pricier options like the Oura ring.",
      "Users express concerns about subscription models and device accuracy, with interest in alternatives that offer open-source compatibility and offline functionality."
    ],
    "points": 292,
    "commentCount": 100,
    "retryCount": 0,
    "time": 1728867997
  },
  {
    "id": 41832547,
    "title": "Zero-latency SQLite storage in every Durable Object",
    "originLink": "https://simonwillison.net/2024/Oct/13/zero-latency-sqlite-storage-in-every-durable-object/",
    "originBody": "Simon Willison’s Weblog Subscribe Zero-latency SQLite storage in every Durable Object (via) Kenton Varda introduces the next iteration of Cloudflare's Durable Object platform, which recently upgraded from a key/value store to a full relational system based on SQLite. For useful background on the first version of Durable Objects take a look at Cloudflare's durable multiplayer moat by Paul Butler, who digs into its popularity for building WebSocket-based realtime collaborative applications. The new SQLite-backed Durable Objects is a fascinating piece of distributed system design, which advocates for a really interesting way to architect a large scale application. The key idea behind Durable Objects is to colocate application logic with the data it operates on. A Durable Object comprises code that executes on the same physical host as the SQLite database that it uses, resulting in blazingly fast read and write performance. How could this work at scale? A single object is inherently limited in throughput since it runs on a single thread of a single machine. To handle more traffic, you create more objects. This is easiest when different objects can handle different logical units of state (like different documents, different users, or different \"shards\" of a database), where each unit of state has low enough traffic to be handled by a single object Kenton presents the example of a flight booking system, where each flight can map to a dedicated Durable Object with its own SQLite database - thousands of fresh databases per airline per day. Each DO has a unique name, and Cloudflare's network then handles routing requests to that object wherever it might live on their global network. The technical details are fascinating. Inspired by Litestream, each DO constantly streams a sequence of WAL entries to object storage - batched every 16MB or every ten seconds. This also enables point-in-time recovery for up to 30 days through replaying those logged transactions. To ensure durability within that ten second window, writes are also forwarded to five replicas in separate nearby data centers as soon as they commit, and the write is only acknowledged once three of them have confirmed it. The JavaScript API design is interesting too: it's blocking rather than async, because the whole point of the design is to provide fast single threaded persistence operations: let docs = sql.exec(` SELECT title, authorId FROM documents ORDER BY lastModified DESC LIMIT 100 `).toArray(); for (let doc of docs) { doc.authorName = sql.exec( \"SELECT name FROM users WHERE id = ?\", doc.authorId).one().name; } This one of their examples deliberately exhibits the N+1 query pattern, because that's something SQLite is uniquely well suited to handling. The system underlying Durable Objects is called Storage Relay Service, and it's been powering Cloudflare's existing-but-different D1 SQLite system for over a year. I was curious as to where the objects are created. According to this (via Hacker News): Durable Objects do not currently change locations after they are created. By default, a Durable Object is instantiated in a data center close to where the initial get() request is made. [...] To manually create Durable Objects in another location, provide an optional locationHint parameter to get(). And in a footnote: Dynamic relocation of existing Durable Objects is planned for the future. where.durableobjects.live is a neat site that tracks where in the Cloudflare network DOs are created - I just visited it and it said: This page tracks where new Durable Objects are created; for example, when you loaded this page from Half Moon Bay, a worker in San Jose, California, United States (SJC) created a durable object in San Jose, California, United States (SJC). Posted 13th October 2024 at 10:26 pm Recent articles OpenAI DevDay: Let’s build developer tools, not digital God - 2nd October 2024 OpenAI DevDay 2024 live blog - 1st October 2024 Weeknotes: Three podcasts, two trips and a new plugin system - 30th September 2024 scaling 132 sqlite 277 websockets 19 software-architecture 7 cloudflare 12 litestream 10 Colophon © 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024",
    "commentLink": "https://news.ycombinator.com/item?id=41832547",
    "commentBody": "Zero-latency SQLite storage in every Durable Object (simonwillison.net)270 points by ajhit406 19 hours agohidepastfavorite102 comments emadda 18 hours agoSome other interesting points: - The write api is sync, but it has a hidden async await: when you do your next output with a response, if the write fails the runtime will replace the response with a http failure. This allows the runtime to auto-batch writes and optimistically assume they will succeed, without the user explicitly handling the errors or awaits. - There are no read transactions, which would be useful to get a pointer to a snapshot at a point in time. - Each runtime instance is limited to 128mb RAM. - Websockets can hibernate and you do not have to pay for the time they are sleeping. This allows your clients to remain connected even when the DO is sleeping. - They have a kind of auto RPC ability where you can talk to other DOs or workers as if they are normal JS calls, but they can actually be calling another data center. The runtime handles the serialisation and parsing. reply crabmusket 17 hours agoparentThe RPC stuff is pretty interesting. More here: https://blog.cloudflare.com/javascript-native-rpc/ reply skybrian 13 hours agorootparentWithout a schema, I’m wondering about validation. I guess your server should use Zod or an equivalent library? reply ngrilly 10 hours agoparentprev> The write api is sync, but it has a hidden async await: when you do your next output with a response, if the write fails the runtime will replace the response with a http failure. This allows the runtime to auto-batch writes and optimistically assume they will succeed, without the user explicitly handling the errors or awaits. It reminds me of PostgreSQL's commit_delay, even thought it's not exactly the same principle: https://www.postgresql.org/docs/current/runtime-config-wal.h... Litestream, mentioned in the post, is also suggesting a similar technique. reply matharmin 11 hours agoparentprevJust wondering, do you have a specific use case for read transactions implemented on the database level here? In SQLite in general read transactions are useful since you can access the same database from multiple processes at a time. Here, only a single process can access the database. So you can get the same effect as read transactions either by doing all reads in one synchronous function, or implement your own process-level locking. reply emadda 8 hours agorootparentE.g. if you have many websocket connections and they each have a snapshot at a point in time (that spans over many different await function calls/ws messages). SQLite can have many readers and a single writer with WAL, so a many read transactions can exist whilst the writers move the db state forward. reply kentonv 5 hours agorootparentWe (Cloudflare) have considered adding an API to create multiple \"database connections\", especially to be able to stream a response from a long-running cursor while representing a consistent snapshot of the data. It's a bit tricky since if you hold open that old connection, the WAL could grow without bound and cannot be checkpointed back into the main database. What do we do when the WAL gets unreasonably large (e.g. bigger than the database)? Cancel old cursors so we can finally checkpoint? Will that be annoying for app developers to deal with, e.g. causing errors when traffic is high? SQLite itself calls an open database a \"connection\" even though there's no actual network involved. reply emadda 43 minutes agorootparentI did guess it might be harder to do than vanilla SQLite, as vanilla SQLite just has the WAL and main db on the same hard drive, so it has more space to grow the WAL and it is not an issue when the machine/instance reboots (as it just starts where it left off, even if the WAL is large and has not been check-pointed back to the main db). To be honest this is an edge case. But I often start a read transaction on a SQLite connection just so I know multiple queries are reading from the same state (and to ensure state has not been changed between queries). reply kentonv 53 minutes agorootparentprevUgh didn't notice until too late to edit, but apparently HN interpreted my asterisk as an instruction to italicize everything between it and the footnote it referred to. reply tmikaeld 12 hours agoprev> ..each DO constantly streams a sequence of WAL entries to object storage - batched every 16MB or every ten seconds. Which also means it may take 10 seconds before you can (reliably) read the write globally. I keep failing to see how this can replace regionally placed database clusters which can serve a continent in milliseconds. Edit: I know it uses streams, but those are only to 5 followers and CF have hundreds of datacenters. There is no physical way to guarantee reads in seconds unless all instances of the SQLite are always connected and even then, packet latency will cause issues. reply kentonv 40 minutes agoparentAs others have noted, you misunderstand how Durable Objects work. All traffic addressed to the same object is routed to a single machine where that object lives. That machine always has a consistent view of its SQLite database. You can have billions of objects, but each has its own separate database. There's no way to read from a database directly from a different machine than the one the DO is running on. reply firtoz 11 hours agoparentprevAFAIK the writes and reads are done only from the same process, so the long term storage will apply only if the current process is hibernated. When you write something and then read it, it's immediate, because the writes and reads are also updating the current process's state in memory. For another process (e.g. another DO or another worker) to access the data, they need to go through the DO which \"contains\" the data, so they'd be making a RPC or a HTTP request to the DO, and they'd get the latest information. + the hibernation happens after x seconds of inactivity, so it feels like the only time a data write to be unavailable as expected would be when the DO or worker crashes right after a write. reply tmikaeld 10 hours agorootparentYou're right that reads and writes are immediate in the same client connection, this is how it works with CF KV as well - but not across the entire network. On KV they expect up to 30 second latency before a write can be written everywhere, I expect similar here. reply ec109685 10 hours agorootparentCloudflare ensures all operations on a DO happen on _the_ single instance of that DO, worldwide. There’s no such thing as the read after wrote problem because only one host will ever do reads and writes (until that host dies). reply dumbo-octopus 10 hours agorootparentIndeed. The entire purpose of DO’s is essentially to provide the consistency guarantees that KV cannot. reply neamar 12 hours agoparentprevThe writes are streamed in near real time to five followers, acknowledging it near instantly. The cloudflare blog article mention this more in depth. So writes remain fast, while still having durability. reply memothon 12 hours agoparentprevThose WAL entries streamed to object storage I think are just for backups. Each DO is globally unique (there's one DO with a given id running anywhere) and runs sqlite on its own local storage in that datacenter. reply skrebbel 11 hours agoprevI really love the Durable Object design, particularly because it's easy to understand how it works on the inside. Unlike lots of other solutions designed for realtime data stuff, Durable Objects have a simplicity to them, much like Redis and Italian food. You can see all the ingredients. Given enough time and resources (and datacenters :) ), a competent programmer could read the DO docs and reimplement something similar. This makes it easy to judge the tradeoffs involved. I do worry that DOs are great for building fast, low-overhead, realtime experiences (eg five people editing a document in realtime), but make it very hard to make analyses and overviews (which groups of people have been which editing documents the last week?). Putting the data inside SQLite might make that even harder - you'd have to somehow query lots and lots of little SQLite instances and then merge the results together. I wonder if there's anything for this with DOs, because this is what keeps bringing me back to Postgres time and time again: it works for core app features and for overviews, BI, etc. reply bluehatbrit 4 hours agoprevThis is probably a really stupid question, but how would one handle schema migrations with this kind of setup? My understanding is it's aimed at having a database per-tenant (or even more broken down than that). Is there a sane way of handling schema migrations, or is the expectation that these databases are more short-lived and so you support multiple versions of the db (DO) until it's deleted? In my head, this would be a fun way to build a bookmark service with a DO per user. But as soon as you want to add a new field to an existing table, you meet a pretty tricky problem of getting that change to each individual DO. Perhaps that example is too long lived though, and this is designed for more ephemeral usage. If anyone has any experience with this, I'd be really interested to know what you're doing. reply simonw 3 hours agoparentYou'd need to roll your own migrations. I have a version of that for SQLite written in Python, but I'm not sure if you could run that in Durable Objects - maybe via WASM and PyOdide? Otherwise you'd have to port it to JavaScript. https://github.com/simonw/sqlite-migrate reply bluehatbrit 3 hours agorootparentAppreciate the response (and the blog post itself)! I probably worded my question poorly, but I'm more wondering about executing schema migrations against a large number of DO's as part of a deployment (such as 1 per customer). I suppose the answer is \"it's easier to have 1 central database/DO\", but it feels like this approach to data storage really shines when you can have a DO per tenant. reply simonw 1 hour agorootparentA pattern where you check for and then execute any necessary migrations on initialization of a Durable Object would actually work pretty well I think - presumably you can update the code for these things without erasing the existing database? reply bluehatbrit 1 hour agorootparentAh yes, that would work pretty well! You'd have to be able to guarantee any migrations can run within the timeouts, but at a per-tenant level that should be very doable for most cases. Not sure why I didn't think of that approach - great idea. I might have to try this out now. reply simonw 1 hour agorootparentI think those SQLite databases are capped at 1GB right now, so even complex migrations (that work by creating a new temporary table, copying old data to it and then atomically renaming it) should run in well under a second. reply simonw 19 hours agoprevOne thing I don't understand about Durable Objects yet is where they are physically located. Are they located in the region that hosted the API call that caused them to be created in the first place? If so, is there a mechanism by which a DO can be automatically migrated to another location if it turns out that e.g. they were created in North America but actually all of the subsequent read/write traffic to them comes from Australia? reply mhart 18 hours agoparentBy default in the region you created them in, but you can alternatively specify a locationHint. Use \"oc\" for Australia. https://developers.cloudflare.com/durable-objects/reference/... Note the \"Dynamic relocation of existing Durable Objects is planned for the future\" reply simonw 18 hours agorootparentThanks, added that to my post. reply dantiberian 18 hours agoparentprevhttps://where.durableobjects.live is a good website that shows you where they live. Only about 10-11% of Cloudflare PoPs host durable objects. Requests to another PoP to create a DO will get forward to one of the nearby PoPs which do host them. reply masterj 18 hours agoparentprev> Durable Objects do not currently change locations after they are created > Dynamic relocation of existing Durable Objects is planned for the future. https://developers.cloudflare.com/durable-objects/reference/.... IIRC Orleans (https://www.microsoft.com/en-us/research/wp-content/uploads/...) allows actors to be moved between machines, which should map well to DOs being moved between locations. reply pests 12 hours agorootparentAs actors in Orleans are virtual and persistent it can also be the case it is running nowhere. If it's stateless it could be running in multiple locations. I worry \"Dynamic relocation of DOs\" might be going a bit too granular, this should be something the runtime takes care of. reply ko_pivot 19 hours agoparentprevDurable Objects have long term storage. They get hydrated from that storage, so in that sense, they can move to any Cloudflare DS. However, there is no API call to move a Durable Object. It has to have no connections and then gets recreated in the DS nearest to the next/first connection. Memory gets dropped when that happens, storage survives. (This is slightly out of date as they have some nuanced hibernation stuff that is recent). reply crabmusket 18 hours agoparentprevNot an answer to your question, but shoutout to https://where.durableobjects.live/ reply jwblackwell 10 hours agoprevDoes anyone else struggle to wrap their head around a lot of this new cloud stuff? I have 15+ years experience of building for the web, using Laravel / Postgres / Redis stack and I read posts like this and just think, \"not for me\". reply djtango 10 hours agoparentFrom the article: > For useful background on the first version of Durable Objects take a look at Cloudflare's durable multiplayer moat by Paul Butler, who digs into its popularity for building WebSocket-based realtime collaborative applications. First apps that come to mind that have RT collaboration: - Google Docs/Sheets etc - Notion - Miro - Figma These are all global scale collaborative apps, I'm not sure a Laravel stack will support those use cases... Google had to in house everything and probably spearheaded the usage of CRDTs ( this is a guess!) but as the patterns emerge and the building blocks get SAASified, mass-RT collaboration no longer becomes a giant engineering problem and more and more interesting products get unlocked reply jlokier 9 hours agorootparent> Google had to in house everything and probably spearheaded the usage of CRDTs ( this is a guess!) Fwiw, Google Docs/Sheets etc don't use CRDTs, they use the more server-oriented Operational Transforms (OT). CRDTs were spearheaded by others. reply fastball 9 hours agorootparentprevGoogle actually uses OT for their collab. reply blixt 10 hours agoprevI'm constantly impressed by the design of DOs. I think it's easy to have a knee-jerk reaction that something is wrong with doing it this way, but in reality I think this is exactly how a lot of real products are implicitly structured: a lot of complex work done at very low scale per atomic thing (by which I mean, anything that needs to be transactionally consistent). In retrospect what we ended up building at Framer for projects with multiplayer support where edits are replicated at 60 FPS while being correctly ordered for all clients is a more applied version of what DOs are doing now. We also ended up with something like a WAL of JSON object edits so in case a project instance crashed its backup could pick up as if nothing had happened, even if committing the JSON patches into the (huge) project data object didn't have time to occur (on an every-N-updates/M-seconds basis just like described here). reply stavros 19 hours agoprevThis is a really interesting design, but these kinds of smart systems always inhabit an uncanny valley for me. You need them in exactly two cases: 1. You have a really high-load system that you need to figure out some clever ways to scale. 2. You're working on a toy project for fun. If #2, fine, use whatever you want, it's great. If this is production, or for Work(TM), you need something proven. If you don't know you need this, you don't need it, go with a boring Postgres database and a VM or something. If you do know you need this, then you're kind of in a bind: It's not really very mature yet, as it's pretty new, and you're probably going to hit a bunch of weird edge cases, which you probably don't really want to have to debug or live with. So, who are these systems for, in the end? They're so niche that they can't easily mature and be used by lots of serious players, and they're too complex with too many tradeoffs to be used by 99.9% of companies. The only people I know for sure are the target market for this sort of thing is the developers who see something shiny, build a company (or, worse, build someone else's company) on it, and then regret it pretty soon and move to something else (hopefully much more boring). Does anyone have more insight on this? I'd love to know. reply crabmusket 18 hours agoparentAs far as I can tell, multiplayer is the killer app for Durable Objects. If you want to build another Figma, Google Docs, etc, the programming model of Durable Objects is super handy. This article goes into it more: https://digest.browsertech.com/archive/browsertech-digest-cl... I think this old article is quite relevant too: http://ithare.com/scaling-stateful-objects/ Anyone who read the Figma multiplayer article and thought \"that's kind of what I need\" would be well served by Durable Objects, I think. https://www.figma.com/blog/rust-in-production-at-figma/ There are other approaches - I've worked in the past with CRDTs over WebRTC which felt absolutely space-age. But that's a much more complicated foundation compared to a websocket and a single class instance \"somewhere\" in the cloud. reply stavros 18 hours agorootparentThat's a very interesting use case. Given that your \"players\" aren't guaranteed to be local to the DO, doesn't using DOs only make sense in high-traffic situations again? Otherwise you might as well just serve the players from a conventional server, no? CRDTs really do sound amazing, though. reply crabmusket 17 hours agorootparentBest case, the players are co-located in a city or country, and they'll benefit from data center locality. Worst case, they're not co-located, and one participant has good latency, and the other doesn't. This is equivalent to the \"deploy the backend in a single server/datacenter\" approach. Aside from the data locality, I still find the programming model (a globally-unique and addressable single-threaded class instance) to be quite nice, and would want to emulate it even without the Cloudflare edge magic. reply paulgb 17 hours agorootparent> Aside from the data locality, I still find the programming model (a globally-unique and addressable single-threaded class instance) to be quite nice, and would want to emulate it even without the Cloudflare edge magic. You might be interested in Plane (https://plane.dev/ / https://github.com/jamsocket/plane), which we sometimes describe as a sort of Durable Object-like abstraction that can run anywhere containers can. (I'm also one of the articles you linked, thanks for the shoutout!) reply crabmusket 17 hours agorootparentI am interested, and I really enjoy your work on Browsertech! I haven't needed Plane above/over what Cloudflare is providing, but I've got it in the back of my mind as an option. I've long hoped other providers might jump on the Durable Objects bandwagon and provide competing functionality so we're not locked in. Plane/Jamsocket looks like one way to go about mitigating that risk to a certain extent. reply tlarkworthy 12 hours agorootparentprevIt's the actor model essentially. You can have a DO proxy each user connection, then they forward messages to the multipler document. The user proxy deals with ordering and buffering their connection message state in the presence of disconnects, and the document DO handles the shared state. reply crabmusket 12 hours agorootparentIt's actors plus a global routing system that means all messages addressed to a unique identifier will arrive in the actor instance. I haven't seen any other actor frameworks that provide that. reply tlarkworthy 7 hours agorootparentAkka and Erlang both support distributed routing to their actors, but this is planetary scale and fully-managed out of the box, which is very cool. reply skybrian 13 hours agorootparentprevSome games have regions and you only see players in the same region. For example, a “Europe” region. If you’re in the US and you connect to the Europe region, you know that you should expect some lag. And it seems like that would work just as well with durable objects. reply dumbo-octopus 17 hours agorootparentprevIn practice you’re most likely to be collaborating with other folks on your school project group, work team, close family, etc. Sure there are exceptions, but generally speaking picking a service location near your first group member ensures low latency for them (and they’re probably most engaged), and is likely to have lowish latency for everyone else. On the flip side, picking US-East-1 gives okayish latency to folks near that, and nobody else. reply crabmusket 17 hours agorootparentAnd the corollary to that is that often your collaborations have a naturally low scale. While your entire app/customerbase as a whole needs to handle thousands of requests per second or more, one document/shard may only need to handle a handful of people. reply klabb3 17 hours agoparentprevDatabases is an extremely slow-maturing area, similar to programming languages, but are all deviations from Postgres shiny and hipster? The idea of colocating data and behavior is really a quantifiable reduction in complexity. It removes latency and bandwidth concerns, which means both operational concerns and development concerns (famously the impact of the N+1 problem is greatly reduced). You can absolutely argue that networked Postgres is better for other reasons (and you may be right) but SQLite is about as boring and predictable as you can get, with known strong advantages. This is the reason it’s getting popular on the server. That said, I don’t like the idea of creating many small databases very much - as they suggest with Durable Objects. That gives noSQL nightmares - breaking all kinds of important invariants of relational dbs. I think it’s much preferable to use SQLite as a monolithic database like it’s done in their D1 product. reply crabmusket 17 hours agorootparent> That gives noSQL nightmares - breaking all kinds of important invariants of relational dbs IMO Durable Objects map well to use cases where there actually are documents. Think of Figma. There is a ton of data that lives inside the literal Figma document. It would be awful to have a relational table for like \"shapes\" with one row per rectangle across Figma's entire customer base. That's just not an appropriate use of a relational database. So let's say I built Figma on MongoDB, where each Figma document is a Mongo document. That corresponds fairly straightforwardly to each Figma document being a Durable Object instance, using either the built-in noSQL storage that Durable Objects already have, or a small Sqlite relational database which does have a \"shapes\" table, but only containing the shapes in this one document. reply jchanimal 15 hours agorootparentWe are wrestling with questions like this on the new document database we’re building. A database should correspond to some administrative domain object. Today in Fireproof a database is a unit of sharing, but we are working toward a broader model where a database corresponds to an individual application’s state. So one database is all the shared documents not just a single unit of sharing. These small changes early on can have big impact later. If you’re interested in these sort of design questions, the Fireproof Discord is where we are hashing out the v0.20 api. (I was an early contributor to Apache CouchDB. Damien Katz, creator of CouchDB, is helping with engineering and raised these questions recently, along with other team members.) reply klabb3 6 hours agorootparentprev> Durable Objects map well to use cases where there actually are documents Right. I wouldn’t dispute this. This is akin to a file format from software back in the day (like say photoshop but now with multiplayer). What this means is that you get different compatibility boundaries and you relinquish centralized control and ability to do transparent migrations and analysis. For all intents and purposes, the documents should be more or less opaque and self-contained. I personally like this, but I also recognize that most web engineers of our current generation are not used to think in this disciplined and defensive way upfront. reply 8n4vidtmkvmk 13 hours agorootparentprevN+1 problem is also reduced if you keep your one and only server next to your one and only database. This was actually the solution we came up with at a very big global company. Well, not 1 server, but 1 data center. If your write leaders are all in one place it apparently doesn't matter that everything else is global, for certain write requests at least. reply masterj 14 hours agorootparentprevIf you adopt a wide-column db like Cassandra or DynamoDB, don’t you have to pick a shard for your table? The idea behind Durable Objects seems similar reply simpsond 13 hours agorootparentYou have a row key, which gets consistently hashed to a shard / node on the ring. reply jmtulloss 19 hours agoparentprevIf you're in #1, you talk to CloudFlare. They need some great customer stories and they have some great engineers that are most likely willing to work with you on how this will work/help you with bugs in exchange for some success stories. If it gets proven out this turns into a service relationship, but early on it's a partnership. reply camgunz 10 hours agoparentprevFirst, this is very insightful--I think most people should go through this exact analysis before architecting a system. As others have said, the use is multiplayer, and that's because you need everyone to see your changes ASAP for the app to feel good. But more broadly, the storage industry has been trying to build something that's consistent, low latency, and multiuser for a long time. That's super hard, just from a physics point of view there's generally a tradeoff between consistency and latency. So I think people are trying different models to get there, and a lot of that experimentation (not all, cf Yugabyte or Cockroach) is happening with SQLite. reply danpalmer 18 hours agoparentprevI'd view the split here along the axes of debuggability/introspection. There are many services that just don't require performance tuning or deep introspection, things like internal tools. This is where I think serverless frameworks do well, because they avoid a lot of time spent on deployment. It's nice if these are fast, but that's rarely a key requirement. Usually the key requirement is that they are fast to build and low maintenance. It's possible that Cloudflare have got a good story for developer experience here that gets things working quickly, but that's not their pitch, and there are a lot of services competing to make this sort of development fast. However where I don't think these services work well is when you have high debuggability and introspection requirements. What metrics do I get out of this? What happens if some Durable Objects are just slow, do we have the information to understand why? Can we rectify it if they are? What's the logging story, and how much does it cost? I think these sorts of services may be a good idea for a startup on day 1 to build some clever distributed system in order to put off thinking about scaling, but I can't help but think that scale-up sized companies would be wanting to move off this onto something they can get into the details more with, and that transition would be a hard one. reply yen223 18 hours agoparentprevI almost have the opposite view: When starting out you can get away with using a simple Postgres database. Postgres is fine for low-traffic projects with minimal latency constraints, and you probably want to spend your innovation tokens elsewhere. But in very high-traffic Production cases with tight latency requirements, you will start to see all kinds of weird and wacky traffic patterns, that barebones Postgres won't be able to handle. It's usually in these cases where you'd need to start exploring alternatives to Postgres. It's also in these cases where you can afford to hire people to manage your special database needs. reply simonw 18 hours agorootparentHave you worked on any examples of projects that started on PostgreSQL and ended up needing to migrate to something specialized? reply yen223 17 hours agorootparentI did, twice. The second time, we had a reporting system that eventually stored billions of rows per day in a Postgres database. Processing times got so bad that we decided to migrate to Clickhouse, resulting in a substantial boost to query times. I maintain that we haven't exhausted all available optimisations for Postgres, but I cannot deny that the migration made sense in the long run - OLTP vs OLAP and all that. (The first time is a funny story that I'm not quite ready to share.) reply simonw 17 hours agorootparentThat makes a lot of sense to me. One of my strongest hints that a non-relational data store might be a good idea is \"grows by billions of rows a day\". reply adhamsalama 16 hours agorootparentIsn't Clickhouse relational? reply crabmusket 16 hours agorootparentIt does allow you to query with SQL, but it's meant for OLAP workloads, not OLTP. Its internal architecture and storage is different to what you'd usually think of as a relational database, like Postgres. See https://clickhouse.com/docs/en/concepts/why-clickhouse-is-so... The term \"relational\" is overloaded. Sometimes it means \"you can use SQL\" and sometimes it means \"OLTP with data stored in an AoS btree\". (And sometimes, a pet peeve of mine, it means \"data with relationships\" which is based on misunderstanding the term \"relation\". If someone asks you if \"your data is relational\" they are suffering from this confusion.) reply yen223 16 hours agorootparentprevClickhouse is a SQL database, so I guess it is? (Strictly speaking since a \"relation\" in the original Codd-paper sense is a table, anything with tables is relational. I don't know if that's what people mean by \"relational\", plus I don't know what counts as \"non-relational\" in that sense) reply simonw 16 hours agorootparentprevKind of? By \"relational\" there I meant \"traditional relational databases like MySQL and PostgreSQL that are optimized for transactions and aren't designed for large scale analytics\". reply xarope 16 hours agorootparentprevRight, OLTP vs OLAP are very different workloads (using the car analogy, that would be like using a ferrari to tow a trailer, and an F250 to... oh wait, an F250 can do anything!). But seriously though, even if you use postgres, as a former DBA (DB2 and Oracle) I would have tuned the OLTP database very differently to the OLAP database, and I don't mean just indexes, but even during ETL from OLTP->OLAP you might decide to de-normalize columns on the OLAP side simply to speed up queries (OLAP databases are the sort of database you were warned about, where indexes can be 10x the data size) reply adhamsalama 16 hours agorootparentprevWell, this isn't specific to Postgres, is it? If you were storing billions of rows per day in MySQL, SQL Server, or Oracle, it still wouldn't be able to handle it, would it? reply yen223 16 hours agorootparentThat's right. The key difference is using row-based vs column-based databases (i.e. OLTP vs OLAP). Any good database person should be cringing at the thought of using Postgres (or MySQL, Oracle, Sql Server, etc) for pulling reporting data. That said, no regrets using Postgres there. If we started with Clickhouse the project could have not launched as quickly as it did, and that would have given us more problems. reply gregwebs 18 hours agoparentprevThere are a lot of cases of low traffic applications that aren’t toys but instead are internal tools- this could be a great option for those. For higher traffic they are asking you to figure out how to shard your data and it’s compute. That’s really hard to do without hitting edge cases. reply stavros 18 hours agorootparentWhy would you use this for an internal, low-traffic tool over Postgres? reply alright2565 18 hours agorootparentIt's so low traffic that you don't want to pay the minimum $35/mo for a PostgreSQL instance on AWS maybe. Or you're required by policy to have a single-tenant architecture, but a full always-on database server would be overkill. reply fracus 18 hours agorootparentprevCould this be used to get a time edge in trading? I'm not an expert, just thinking out loud. I remember hearing about firms laying wire in a certain way because getting a microsecond jump on changing rates could be everything for them. reply crabmusket 17 hours agorootparentI'm also no expert, but from reading around the subject a little (Flash Boys by Michael Lewis was pretty cool, also Jane Street's podcast has some fantastic information)... no. I doubt you'd be on a public cloud if low-latency trading is what you're doing. reply aldonius 12 hours agorootparentAren't the HFT boxes usually stock exchange colocations? Each trader gets a rack (or multiple racks depending on size) in the exchange's datacenter, every rack has the same cable length to the switch, etc. reply MuffinFlavored 18 hours agoparentprev> If this is production, or for Work(TM), you need something proven. I feel like part of Cloudflare's business model is to try to convince businesses at scale to solve problems in a non-traditional way using technology they are cooking up, no matter the cost. reply segalord 12 hours agoprevNoticing CF pushing for devs to use DO for eveything over workers these days. Even websocket connections on workers get timed out after ~30s and the recommended way is to use DO for them reply rozenmd 11 hours agoparentDurable Objects have always been the recommended way to do websocket connections on Cloudflare Workers? (as far as I remember, anyway) The original chat demo dates back to 2020, using DOs + websockets: https://github.com/cloudflare/workers-chat-demo reply vlaaad 6 hours agoprevRe https://where.durableobjects.live/ — why the hell are they still operating in Russia? reply esnard 6 hours agoparentFrom https://blog.cloudflare.com/steps-taken-around-cloudflares-s... : > Since the invasion, providing any services in Russia is understandably fraught. Governments have been united in imposing a stream of new sanctions and there have even been some calls to disconnect Russia from the global Internet. As discussed by ICANN, the Internet Society, the Electronic Frontier Foundation, and Techdirt, among others, the consequences of such a shutdown would be profound. > [...] > Beyond this, we have received several calls to terminate all of Cloudflare's services inside Russia. We have carefully considered these requests and discussed them with government and civil society experts. Our conclusion, in consultation with those experts, is that Russia needs more Internet access, not less. reply myflash13 11 hours agoprevWhat I don’t understand is why, in the example of flight seat mapping provided, you create a DO per flight. So does a DO correspond to a “model” in MVC architecture? What if I used DOs in a per-tenant way, so one DO per user. And then how do I query or “join” across all DOs to find all full flights? I guess you would have to design your DOs such that joins are not required? reply ec109685 10 hours agoparentThey support “function” calling between DOs, so you are able to compose a response from more than one DO. reply avinassh 4 hours agoprevI'd love to know how they have hooked VFS with WAL to monitor changes. The SQLite's WAL layer deals with page numbers where as VFS deals with file and byte offsets. I am curious to understand how they mapped it, how they get new writes to the WAL and read from the WAL. reply kikimora 2 hours agoprevThis design does not handle hot partitions well and they are ubiquitous to so many domains. reply simonw 1 hour agoparentYour partition would have to be VERY hot for SQLite not to be able to handle it - anything up to several thousand writes per second would likely work fine. Since this is all running on Cloudflare you could scale reads with a 1 second cache TTL somewhere, which would drop your incoming read queries to around one per second no matter how much read traffic you had. reply kondro 19 hours agoprevDoes this mean SQLite for DO can lose up to 10 seconds of data in the event of a failing DO? reply stavros 19 hours agoparent> To ensure durability beyond that ten second window, writes are also forwarded to five replicas in separate nearby data centers as soon as they commit, and the write is only acknowledged once three of them have confirmed it. I think Simon meant \"within\", rather than \"beyond\", here. reply simonw 19 hours agorootparentThanks, I've updated that word. reply 9dev 9 hours agoprevI would love to work with Durable Objects and all the other cool stuff from Cloudflare, but I’m really hesitant to make a single cloud providers technology the backbone of my application. If CF decides to pull the plug, or charge a lot more, the only way to migrate elsewhere would be rebuilding the entire app. As long as there aren’t any comparable technologies, or abstraction layers on top of DOs, I’m not going to make the leap of faith. reply braden-lk 17 hours agoprevDurable objects seem so cool but the pricing always scares me. (Specifically, having to worry about getting hibernation right.) They’d be a great fit for our yjs document based strategy, but while everything in prod still works on plain ol redis and Postgres, it’s hard to justify an exploration. reply attilakun 16 hours agoparentDoes CloudFlare have proper spending caps? If they have, I'd be open to try DOs but if they don't, it's a non-starter for an indie dev as I can't risk bankruptcy due to a bad for loop. reply viraptor 13 hours agorootparentIt's not just the listed prices either. There was a story here not long ago where they essentially requested someone to migrate to an enterprise plan or get out. With AWS it's pretty common to get a refund for accidental abuse. From my contact so far and from stories here, I wouldn't expect anything close to that treatment from CF. reply ignoramous 16 hours agoparentprev> Specifically, having to worry about getting hibernation right. As long as the client doesn't exchange websocket messages with DO, it'll hibernate. From what I can tell, ping/pong frames don't count towards uptime, if you're worried about that. reply anentropic 9 hours agoparentprevWhat scares me is it is super specific to Cloudflare What is your option if you want to eject to another cloud? reply paulgb 1 hour agorootparentFor the specific example of a Yjs backend, I happen to be working on one that can be hosted either on Cloudflare or as a native process. We’ve had people running in production migrate from cloudflare to native just by swapping out the URL they connect to in their application config. https://github.com/jamsocket/y-sweet reply rcarmo 10 hours agoprevThe first thing I wondered was how this plays with data residency and privacy/regulatory requirements. reply CyberDildonics 5 hours agoprevWhat is the difference between a \"durable object\" and a file? reply simonw 3 hours agoparentYou can read the full article for an answer to that: https://blog.cloudflare.com/sqlite-in-durable-objects/ Short version: it's replicated to five data centers on every transaction, and backed up as a stream to object storage as well. reply CyberDildonics 29 minutes agorootparentSo it's a file that gets backed up like dropbox reply simonw 17 minutes agorootparentAt a very high level, yes. But the details matter here - you commit a transaction to the SQLite database and know that the commit has been pushed out to 3/5 replicas by the time the write API request returns - and that it will be logged to object storage (supporting 30 days of rollback) within ten seconds. AND it will live in a data center physically close to the user who caused it to be created. reply pajeets 15 hours agoprev [–] wonder how this works with Pocketbase reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cloudflare's Durable Object platform now incorporates a full relational system using SQLite, optimizing it for real-time collaborative applications by colocating application logic with data for enhanced performance.",
      "The platform operates each Durable Object on a single thread, with the ability to create more objects to manage increased traffic, exemplified by a flight booking system assigning each flight a dedicated Durable Object with its own SQLite database.",
      "A Storage Relay Service ensures durability by streaming Write-Ahead Logging (WAL) entries to object storage and replicating writes across data centers, with a JavaScript API designed for fast, single-threaded operations."
    ],
    "commentSummary": [
      "Zero-latency SQLite storage in Durable Objects offers efficient data handling with features like auto-batching writes and no read transactions, but is limited to 128MB RAM per runtime instance.",
      "Durable Objects are globally unique, ensuring consistency by operating on a single instance, making them suitable for multiplayer applications but potentially unsuitable for high-traffic or complex analysis needs.",
      "Key concerns include handling schema migrations and the reliance on a single cloud provider, with additional features like auto RPC for communication and hibernating Websockets without cost."
    ],
    "points": 270,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1728860823
  },
  {
    "id": 41831617,
    "title": "Counterintuitive Properties of High Dimensional Space (2018)",
    "originLink": "https://people.eecs.berkeley.edu/~jrs/highd/",
    "originBody": "Counterintuitive Properties of High Dimensional Space Marc Khoury Our geometric intuition developed in our three-dimensional world often fails us in higher dimensions. Many properties of even simple objects, such as higher dimensional analogs of cubes and spheres, are very counterintuitive. Below we discuss just a few of these properties in an attempt to convey some of the weirdness of high dimensional space. You may be used to using the word \"circle\" in two dimensions and \"sphere\" in three dimensions. However, in higher dimensions we generally just use the word sphere, or 𝑑 -sphere when the dimension of the sphere is not clear from context. With this terminology, a circle is also called a 1-sphere, for a 1-dimensional sphere. A standard sphere in three dimensions is called a 2-sphere, and so on. This sometimes causes confusion, because a 𝑑 -sphere is usually thought of as existing in ( 𝑑 + 1 ) -dimensional space. When we say 𝑑 -sphere, the value of 𝑑 refers to the dimension of the sphere locally on the object, not the dimension in which it lives. Similarly we'll often use the word cube for a square, a standard cube, and its higher dimensional analogues. Escaping Spheres Consider a square with side length 1. At each corner of the square place a circle of radius 1 / 2 , so that the circles cover the edges of the square. Then consider the circle centered at the center of the square that is just large enough to touch the circles at the corners of the square. In two dimensions it's clear that the inner circle is entirely contained in the square. Figure 1: At each corner of the square we place a circle of radius 1 / 2 . The inner circle is just large enough to touch the circles at the corners. We can do the same thing in three dimensions. At each corner of the unit cube place a sphere of radius 1 / 2 , again covering the edges of the cube. The sphere centered at the center of the cube and tangent to spheres at the corners of the cube is shown in red in Figure 2. Again we see that, in three dimensions, the inner sphere is entirely contained in the cube. Figure 2: In three dimensions we place a sphere at the each of the eight corners of a cube. To understand what happens in higher dimensions we need to compute the radius of the inner sphere in terms of the dimension. The radius of the inner sphere is equal to the length of the diagonal of the cube minus the radius of the spheres at the corners. See Figure 3. The latter value is always 1 / 2 , regardless of the dimension. We can compute the length of the diagonal as 𝑑 ( ( 1 2 , 1 2 , … , 1 2 ) , ( 1 , 1 , … , 1 ) ) = ∑ 𝑖 = 1 𝑑 ( 1 − 1 2 ) 2 = 𝑑 / 2 Thus the radius of the inner sphere is 𝑑 / 2 − 1 / 2 . Notice that the radius of the inner sphere is increasing with the dimension! Figure 3: The size of the radius of the inner sphere is growing as the dimension increases because the distance to the corner increases while the radius of the corner sphere remains constant. In dimensions two and three, the sphere is strictly inside the cube, as we've seen in the figures above. However in four dimensions something very interesting happens. The radius of the inner sphere is exactly 1 / 2 , which is just large enough for the inner sphere to touch the sides of the cube! In five dimensions, the radius of the inner sphere is 0.618034 , and the sphere starts poking outside of the cube! By ten dimensions, the radius is 1.08114 and the sphere is poking very far outside of the cube! Volume in High Dimensions The area of a circle 𝐴 ( 𝑟 ) = 𝜋 𝑟 2 , where 𝑟 is the radius. Given the equation for the area of a circle, we can compute the volume of a sphere by considering cross sections of the sphere. That is, we intersect the sphere with a plane at some height ℎ above the center of the sphere. Figure 4: Intersecting the sphere with a plane gives a circle. The intersection between a sphere and a plane is a circle. If we look at the sphere from a side view, as shown in Figure 5, we see that the radius can be computed using the Pythagorean theorem ( 𝑎 2 + 𝑏 2 = 𝑐 2 ). The radius of the circle is 𝑟 2 − ℎ 2 . Figure 5: A side view of Figure 4. The radius of the circle defined by the intersection can be found using the Pythagorean theorem. Summing up the area of each cross section from the bottom of the sphere to the top of the sphere gives the volume 𝑉 ( 𝑟 ) = ∫ − 𝑟 𝑟 𝐴 ( 𝑟 2 − ℎ 2 ) 𝑑 ℎ = ∫ − 𝑟 𝑟 𝜋 𝑟 2 − ℎ 2 2 𝑑 ℎ = 4 3 𝜋 𝑟 3 . Now that we know the volume of the 2 -sphere, we can compute the volume of the 3 -sphere in a similar way. The only difference is where before we used the equation for the area of a circle, we instead use the equation for the volume of the 2 -sphere. The general formula for the volume of a 𝑑 -sphere is approximately 𝜋 𝑑 / 2 ( 𝑑 / 2 + 1 ) ! 𝑟 𝑑 . (Approximately because the denominator should be the Gamma function, but that's not important for understanding the intuition.) Set 𝑟 = 1 and consider the volume of the unit 𝑑 -sphere as 𝑑 increases. The plot of the volume is shown in Figure 6. Figure 6: The volume of the unit 𝑑 -sphere goes to 0 as 𝑑 increases! The volume of the unit 𝑑 -sphere goes to 0 as 𝑑 grows! A high dimensional unit sphere encloses almost no volume! The volume increases from dimensions one to five, but begins decreasing rapidly toward 0 after dimension six. More Accurate Pictures Given the rather unexpected properties of high dimensional cubes and spheres, I hope that you'll agree that the following are somewhat more accurate pictorial representations. Figure 7: More accurate pictorial representations of high dimensional cubes (left) and spheres (right). Notice that the corners of the cube are much further away from the center than are the sides. The 𝑑 -sphere is drawn so that it contains almost no volume but still has radius 1. This image also suggests the next counterintuitive property of high dimensional spheres. Concentration of Measure Suppose that you wanted to place a band around the equator of the unit sphere so that, say, 99% of the surface area of the sphere falls within that band. See Figure 8. How large do you think that band would have to be? Figure 8: In two dimensions a the width of a band around the equator must be very large to contain 99% of the perimeter. In two dimensions the width of the band needs to be pretty large, indeed nearly 2, to capture 99% of the perimeter of the unit circle. However as the dimension increases the width of the band needed to capture 99% of the surface area gets smaller. In very high dimensional space nearly all of the surface area of the sphere lies a very small distance away from the equator! Figure 9: As the dimension increases the width of the band necessary to capture 99% of the surface area decreases rapidly. Nearly all of the surface area of a high dimensional sphere lies near the equator. To provide some intuition consider the situation in two dimensions, as shown in Figure 10. For a point on the circle to be close to the equator, its 𝑦 -coordinate must be small. Figure 10: Points near the equator have small y coordinate. What happens to the values of the coordinates as the dimensions increases? Figure 11 is a plot of 20000 random points sampled uniformly from a 𝑑 -sphere. As 𝑑 increases the values become more and more concentrated around 0. Figure 11: As the dimension increases the coordinates become increasingly concentrated around 0. Recall that every point on a 𝑑 -sphere must satisfy the equation 𝑥 1 2 + 𝑥 2 2 + … + 𝑥 𝑑 + 1 2 = 1 . Intuitively as 𝑑 increases the number of terms in the sum increases, and each coordinate gets a smaller share of the single unit, on the average. The really weird thing is that any choice of \"equator\" works! It must, since the sphere is, well, spherically symmetrical. We could have just as easily have chosen any of the options shown in Figure 12. Figure 12: Any choice of equator works equally well! Kissing Numbers Consider a unit circle in the plane, shown in Figure 13 in red. The blue circle is said to kiss the red circle if it just barely touches the red circle. (Leave it to mathematicians to think that barely touching is a desirable property of a kiss.) The kissing number is the maximum number of non-overlapping blue circles that can simultaneously kiss the red circle. Figure 13: The kissing number is six in two dimensions. In two dimensions it's easy to see that the kissing number is 6. The entire proof is shown in Figure 14. The proof is by contradiction. Assume that more than six non-overlapping blue circles can simultaneously kiss the red circle. We draw the edges from the center of the red circle to the centers of the blue circles, as shown in Figure 14. The angles between these edges must sum to exactly 360 ∘ . Since there are more than six angles, at least one must be less than 60 ∘ . The resulting triangle, shown in Figure 14, is an isosceles triangle. The side opposite the angle that is less than 60 ∘ must be strictly shorter than the other two sides, which are 2 𝑟 in length. Thus the centers of the two circles must be closer than 2 𝑟 and the circles must overlap, which is a contradiction. Figure 14: A proof that the kissing number is six in two dimensions. If more than six blue circles can kiss the red, then one of the angles must be less than 60 degrees. It follows that the two blue circles that form that angle must overlap, which is a contradiction. It is more difficult to see that in three dimensions the kissing number is 12. Indeed this was famously disputed between Isaac Newton, who correctly thought the kissing number was 12, and David Gregory, who thought it was 13. (Never bet against Newton.) Looking at the optimal configuration, it's easy to see why Gregory thought it might be possible to fit a 13th sphere in the space between the other 12. As the dimension increases there is suddenly even more space between neighboring spheres and the problem becomes even more difficult. Figure 15: The kissing number is 12 in three dimensions. In fact, there are very few dimensions where we know the kissing number exactly. In most dimensions we only have an upper and lower bound on the kissing number, and these bounds can vary by as much as several thousand spheres! Dimension Lower Bound Upper Bound 1 2 2 2 6 6 3 12 12 4 24 24 5 40 44 6 72 78 7 126 134 8 240 240 9 306 364 10 500 554 11 582 870 12 840 1357 13 1154 2069 14 1606 3183 15 2564 4866 16 4320 7355 17 5346 11072 18 7398 16572 19 10668 24812 20 17400 36764 21 27720 54584 22 49896 82340 23 93150 124416 24 196560 196560 As shown in the table, we only know the kissing number exactly in dimensions one through four, eight, and twenty-four. The eight and twenty-four dimensional cases follow from special lattice structures that are known to give optimal packings. In eight dimensions the kissing number is 240, given by the 𝐸 8 lattice. In twenty-four dimensions the kissing number is 196560, given by the Leech lattice. And not a single sphere more. This post accompanies a talk given to high school students through Berkeley Splash. Thus intuition is prioritized over mathematical rigor, language is abused, and details are laboriously spelled out. If you're interested in more rigorous treatments of the presented material, please feel free to contact me.",
    "commentLink": "https://news.ycombinator.com/item?id=41831617",
    "commentBody": "Counterintuitive Properties of High Dimensional Space (2018) (eecs.berkeley.edu)224 points by nabla9 21 hours agohidepastfavorite54 comments crazygringo 4 hours ago> The volume of the unit d-sphere goes to 0 as d grows! A high dimensional unit sphere encloses almost no volume! This feels misleading to me. Directly comparing volumes in different dimensions doesn't make any sense because the units are different. It doesn't make sense to say that a quantity in m^3 is larger or smaller than a quantity in m^4. Because it doesn't make any sense to compare the area of a circle with the volume of a sphere. > More accurate pictorial representations of high dimensional cubes (left) and spheres (right). The cube one is arguably accurate -- e.g. in 100 dimensions, if the distance from the center of a cube to the center of a face is 1, then the distance from the center of the cube to a corner is 10. But the sphere one, I don't know. Every point on a 100-dimensional sphere is still the same distance away from its center. The sphere is staying spherical in an intuitive way, it's just that the corners of the enclosing cube have gotten so much further away. So what is accurate to say is that the proportion of volume of a sphere relative to that of its bounding cube keeps decreasing. Which, rather than being supposedly \"counterintuitive\", makes perfect intuitive sense -- because every time you add a dimension, you can think of it as \"extruding\" the previous sphere into the new dimension and then shaving it round, the way a 2D circle can be extruded into a cylinder in 3D and then shaved down to make it into a sphere. Every time you add a dimension, you shave off more. The article suggests that a 3D sphere has greater volume than a 2D circle -- with a unit radius, the sphere is 4/3π while the circle is just π. But again, they're in different units, so it's a meaningless statement. It makes much more sense to say that a 2D circle takes up (1/4)π≈0.79 of its bounding square, a 3D sphere takes of (1/6)π≈0.52 of its bounding cube, a 4D sphere takes up (π/32)π≈=0.31, and so forth. So no, the volume doesn't go up and then down -- it just goes down every time when taken as a unitless proportion (and proportions are comparable). reply yatopifo 1 hour agoparentI think it all depends on how you define hypervolume. If you say it’s a positive real number constructed by means of integration, then you can certainly compare them across objects of various dimensions. When you say “units” I immediately think of stuff like bivectors and trivectors where you can’t reduce one to another without losing important geometric properties. But here we are talking about just the scalar part which is as “unitless” as can be. reply jvanderbot 2 hours agoparentprevYour image of extruding a cylinder in higher dimensions inside its bounding box then rounding it off was really insightful as a teaching tool. I've always struggled to visualize these \"counterintuitive\" results, which are only counterintuitive because they are harder to visualize or seem to \"change\" after D=3. But now they don't. Thanks! reply ricksunny 2 hours agorootparentHypercubist Math has the ambitious goal of imbuing an intuitive sense of 4-dimensions to people. Currently at Vol. 2 of a several-volume series, will be interssting whether they succeed or not if user feedback is anything to go by. https://m.youtube.com/watch?v=SwGbHsBAcZ0&t=509s&pp=ygUQaHlw... reply gcanyon 17 hours agoprevOne that isn't listed here, and which is critical to machine learning, is the idea of near-orthogonality. When you think of 2D or 3D space, you can only have 2 or 3 orthogonal directions, and allowing for near-orthogonality doesn't really gain you anything. But in higher dimensions, you can reasonably work with directions that are only somewhat orthogonal, and \"somewhat\" gets pretty silly large once you get to thousands of dimensions -- like 75 degrees is fine (I'm writing this from memory, don't quote me). And the number of orthogonal-enough dimensions you can have scales as maybe as much as 10^sqrt(dimension_count), meaning that yes, if your embeddings have 10,000 dimensions, you might be able to have literally 10^100 different orthogonal-enough dimensions. This is critical for turning embeddings + machine learning into LLMs. reply user070223 10 hours agoparentThat's what illustrated in the paper Toy Models of superposition https://arxiv.org/pdf/2209.10652 reply gcanyon 7 hours agorootparentThat's an awesome paper! reply phreeza 13 hours agoparentprevBy orthogonal-enough dimensions, do you mean vectors whose dot product is close to zero? reply gcanyon 7 hours agorootparentyes reply sigmoid10 10 hours agoparentprevThis is actually just another way to see the third example (concentration of measure). As you increase the number of dimensions, the contribution of each base vector component in the calculation of, say, the cosine angle (i.e. via the scalar product) becomes less important. So in three dimensions you'll have a pretty high angle if one vector component points along a different base vector. But in 10,000 dimensions, the angle will be tiny. reply westurner 16 hours agoparentprevDoes distance in feature space require orthogonality? With real space (x,y,z) we omit the redundant units from each feature when describing the distance in feature space. But distance is just a metric, and often the space or paths through it are curvilinear. By Taxicab distance, it's 3 cats, 4 dogs, and 5 glasses of water away. Python now has math.dist() for Euclidean distance, for example. reply epistasis 14 hours agorootparentNear-orthogonality allows fitting in more directions for distinct concepts than the dimension of the space. So even though the dimension of an LLM might beThis chapter has had another aspect. In it we have illustrated the use of a novel viewpoint and the application of a powerful field of mathematics in attacking a problem of communication theory. Equation 9.3 was arrived at by the by-no-means-obvious expedient of representing long electrical signals and the noises added to them by points in a multidimensional space. The square of the distance of a point from the origin was interpreted as the energy of the signal represented by a point. > Thus a problem in communication theory was made to correspond to a problem in geometry, and the desired result was arrived at by geometrical arguments. reply CoastalCoder 4 hours agoparentAnyone know if Pierce's book (dated 1961) is still a good intro to the topic? My background is in CS, and this would just be evening reading out of general interest. reply hotspot_one 1 hour agorootparentI would be willing to read a few chapters just on spec. There is real value in understanding how people used to think about a problem, and where the source ideas came from. reply remcob 14 hours agoprevThe distance between two uniform random points on an n-sphere clusters around the equator. The article shows a histogram of the distribution in fig. 11. While it looks Gaussian, it is more closely related to the Beta distribution. I derived it in my notes, as (surprisingly) I could not find it easily in literature: https://xn--2-umb.com/21/n-sphere reply zombot 12 hours agoparent> The distance between two uniform random points on an n-sphere clusters around the equator. This sentence makes no sense to me. reply p1esk 12 hours agorootparentHe means it clusters around the distance from a pole to the equator. reply remcob 12 hours agorootparentCorrect. I was too short in my comment. It's explained in the article: without loss of generality you can call one of the two points the 'north pole' and then the other one will be distributed close to the equator. reply isoprophlex 12 hours agorootparentprevPick an equator on an n-sphere. It is a hyperplane of dimensions (n-1) through the center, composed of all but one dimensions of your sphere. The xy plane for a unit sphere in xyz, for example. Uniformly distribute points on the sphere. For high n, all points will be very near the equator you chose. Obviously, in ofder for a point to be not close to this chosen equator, it projects close to 0 on all dimensions spanning the equatorial hyperplane, and not close to 0 on the dimension making up the pole-to-pole axis. reply oersted 11 hours agorootparentMy first thought is that it's rather obvious, but I'm probably wrong, can you help me understand? The analogy I have in mind is: if you throw n dice, for large n, the likelihood of one specific chosen dice being high value and the rest being low value is obviously rather small. I guess that the consequence is still interesting, that most random points in a high-dimensional n-sphere will be close to the equator. But they will be close to all arbitrary chosen equators, so it's not that meaningful. If the equator is defined as containing n-1 dimensions, then as n goes higher you'd expect it to \"take up\" more of the space of the sphere, hence most random points will be close to it. It is a surprising property of high-dimensional space, but I think it's mainly because we don't usually think about the general definition of an equator and how it scales to higher dimensions, once you understand that it's not very surprising. reply isoprophlex 11 hours agorootparent> The analogy I have in mind is: if you throw n dice, for large n, the likelihood of one specific chosen dice being high value and the rest being low value is obviously rather small. You're exactly right, this whole thing is indeed a bit of an obvious nothingburger. reply akdor1154 11 hours agorootparentprev\"clusters\" is acting as a verb here, not a noun. reply 7fYZ7mJh3RNKNaG 13 hours agoparentprevbeautiful visualizations, how did you make them? reply remcob 12 hours agorootparentThe first one IIRC with Geogebra, all the rest with Matplotlib. The design goal was to maximize on 'data-ink ratio'. reply FabHK 18 hours agoprevFor high-dimensional spheres, most of the volume is in the \"shell\", ie near the boundary [0]. This sort of makes sense to me, but I don't know how to square that with the observation in the article that most of the surface area is near the equator. (In particular, by symmetry, it's near any equator; so, one would think, in their intersection. That is near the centre, though, not the shell.) Anyway. Never buy a high-dimensional orange, it's mostly rind. [0] https://www.math.wustl.edu/~feres/highdim reply hansvm 17 hours agoparentIt's basically the same idea in both cases. Power laws warp anything \"slightly bigger\" into dominating everything else when the power is big enough. There's a bit more stuff near the outside than the inside, so with a high enough dimension the volume is in the rind. Similarly, the equator is a bit bigger than the other slices, so with enough dimensions its surface area dominates. reply WiSaGaN 13 hours agorootparentYes, this seems to be the result of the standard Euclidean metric rather than the high dimension itself. I guess most people assuming the metric to be Euclidean, so it's ok. reply youoy 11 hours agoparentprevIf you like ML, this is also related with the results of this paper [0], where they show that learning in high dimensions amounts to extrapolation, as opposed to interpolation. Intuitively I think of this as the fact that points in the sphere are convexly independent, and most of the volume of the ball is near the boundary. [0] https://arxiv.org/abs/2110.09485 reply mattxxx 18 hours agoprevYea - high dimensional spaces are weird and hard to reason about... and we're working very frequently in them, especially when dealing with ML. reply l33t7332273 17 hours agoparentLuckily if you do enough math it becomes much easier to reason about such spaces reply JBiserkov 16 hours agorootparent- How do you even visualize an 11-dimensional space? - oh that's easy - you just visualize an N-dimensional space and then set N equal to 11. reply rectang 15 hours agorootparentI think of high-dimensional spaces in terms of projection. Projecting a 3-dimensional space onto a 2-dimensional space loses information and the results depend on perspective. Same with an 11-dimensional space being projected onto a 10-dimensional space. I find that this metaphor works pretty well for visualizing how a vector-space search engine represents how two documents can be \"similar\" in N-dimensional term-space: look at them from the right angle and they appear close together. reply marcosdumay 15 hours agorootparentprevYeah, stopping that need to visualize everything is one of the mechanisms usually adopted for working in high-dimensional space. reply ljouhet 3 hours agoprevThank you! I love this article, but I couldn't find it. I always search \"Curse of dimensionality\" instead of \"Counterintuitive properties...\" reply brazzy 6 hours agoprev> The volume of the unit -sphere goes to 0 as grows! A high dimensional unit sphere encloses almost no volume! The volume increases from dimensions one to five, but begins decreasing rapidly toward 0 after dimension six. What the absolute fuck? That one caught me truly off guard. I don't think \"counterintuitive\" is a strong enough word. reply derbOac 18 hours agoprevI love this stuff because it's so counterintuitive until you've worked through some of it. There was an article linked to on HN a while back about high-dimensional Gaussian distributions that was similar in message, and probably mathematically related at some level. It has so many implications for much of the work in deep learning and large data, among other things. reply vqv 5 hours agoparentStatistician here. I agree that some of this stuff seems counterintuitive on the surface. Once you make the connection with high-dimensional Gaussians, it can become more \"obvious\": if Z is standard n-dimensional Gaussian random vector, i.e. one with iid N(0,1) coordinates, then normalizing Z by its norm, say W, gives a random vector U that is uniformly distributed on an n-Sphere. Moreover, U is independent of W --- this is related to the fact that the sample mean and variance are independent for a random sample from a Normal population --- and W^2 has Chi-squared distribution on n degrees of freedom. So for example a statement about concentration of volume of the n-Sphere about an equatorial slice is equivalent to a statement about the probability that the dot product between U and a fixed unit norm vector is close to 0, and that probability is easy to approximate using undergraduate-level probability theory. Circling back to data: it is very easy to be mislead when working with high-dimensional data, i.e. data with many, many features. reply bmitc 18 hours agoprevActually, the most counterintuitive is 4-dimensional space. It is rather mathematically unique, often exhibiting properties no other dimension does. reply dullcrisp 17 hours agoparentWell I’m sure 2- and 3- dimensional space are also mathematically unique and interesting by the same token, but they’re nearer to our experience and intuition. reply ngruhn 11 hours agorootparentI‘ve heard that knots only exist in 3 dimensions. In 2D you can’t entangle anything and in 4D+ you can always untangle everything. reply madcaptenor 4 hours agorootparentIt's been a while since I studied any topology, but if I'm remembering correctly you can knot an (n-2)-dimensional surface in n-dimensions. reply NL807 17 hours agoparentprev>often exhibiting properties no other dimension does. Isn't that true for some other dimensions as well? There is a whole much of mathematical concepts that is constrained for a specific dimension. For example the cross product only makes sense in 3D. The perpendicular dot product (a special case of the determinant) only makes sense in 2D. reply immibis 11 hours agorootparentApparently there's also a 7D cross product - and no others! reply elcritch 18 hours agoparentprevHow so? reply hansvm 17 hours agorootparentThe intuitive way to think about it is that with very few dimensions you have very few degrees of freedom, so it's easy to prove things possible or impossible. With lots of dimensions, you have enough wiggle room to prove most things possible. Somewhere in between, you have enough complexity to not trivialize the problems but not enough wiggle room to be able to easily circumvent the issue. Often in practice, that boundary is around 3-4 dimensions. See the poincaré conjecture, various sphere packing shenanigans, graph embeddings, .... reply bmitc 17 hours agorootparentprevThere's a section here about phenomena in 4 dimensions: https://en.wikipedia.org/wiki/4-manifold One of the most surprising is that all smooth manifolds of dimension not equal to four only have a finite number of unique smooth structures. For dimension four, there are countably infinite number of unique smooth structures. It's the only dimension with that property. reply elcritch 16 hours agorootparentFascinating that higher dimension manifolds are more restrictive! Though in a _very_ handwavy way it seems intuitive given properties like that in TFA where 4-d is the only dimension where the edges of the bounding cube and inner spheres match. Especially given that that property seems related to the possible neighborhoods of points in d-4 manifolds. Though I quickly get lost in the specifics of the maths on manifolds. :) > However in four dimensions something very interesting happens. The radius of the inner sphere is exactly 1/2, which is just large enough for the inner sphere to touch the sides of the cube! reply ashishb 16 hours agorootparentprev> One of the most surprising is that all smooth manifolds of dimension not equal to four only have a finite number of unique smooth structures. For dimension four, there are countably infinite number of unique smooth structures. It's the only dimension with that property. Can you give some intuition on smooth structure and manifold? I read Wikipedia articles a few times but still can't grasp them. reply aithrowawaycomm 14 hours agorootparentI am not sure the other comment was especially intuitive. Here is my understanding: Euclidean space is a vector space and therefore pretty easy to work with in computations (especially calculus) compared to something like the surface of a sphere, but the sphere doesn't simply abandon Euclidean vector structure. We can take halves of the sphere and \"flatten them out,\" so instead of working with the sphere we can work with two planes, keeping in mind that the flattening functions define the boundary of those planes we're allowed to work within. Then we can do computations on the plane and \"unflatten\" them to get the result of those computations on the sphere. Manifolds are a generalization of this idea: you have a complicated topological structure S, but also some open subsets of S, S_i, which partition S, and smooth, invertible functions f_i: S_i -> R^n that tell you how to treat elements of S locally as if they were vectors in Euclidean space (and since the functions are invertible, it tells you how to map the vectors back to S, which is what you want). The manifold is a pair, the space S and the smooth functions f_i. The smoothness is important because ultimately we are interested in doing calculus on S, so if the mapping functions have \"sharp edges\" then we're introducing sharp edges into S that are entirely a result of the mapping and not S's own geometry. reply bmitc 16 hours agorootparentprevApplying a smooth structure to a manifold to make it a smooth manifold is like a patching process that makes it look like a Eucliden space. Most of calculus and undergraduate math, engineering, and physics takes place in Euclidean space R^n. So all the curves and surfaces directly embed into R^n, usually where n = 2 or n = 3. However, there are more abstract spaces that one would like to study and those are manifolds. To do calculus on them, they need to be smooth manifolds. A smooth structure is a collection of \"patches\" (normally called charts) such that each patch (chart) is homeomorphic (topologically equivalent) to an open set in R^n. Such a manifold is called an n-dimensional manifold. The smoothness criterion is a technicality such that the coordinates and transformation coordinates are smooth, i.e., infinitely differentiable. Smooth manifolds is basically the extension of calculus to more general and abstract dimensions. For example, a circle is a 1-dimensional manifold since it locally looks like a line segment. A sphere (the shell of the sphere) is a 2-dimensional manifold because it locally looks like an open subset of R^2, i.e., it locally looks like a two dimensional plane. Take Earth for example. Locally, a Euclidean x-y coordinate system works well. reply nyc111 4 hours agoprev [–] I don't understand what is meant here by \"dimension.\" Is the definition of \"dimension\" consistent for 3-dimensional figures and n-dimensional figures? In other words, what is the importance of the orthogonality of the axes? The axes of dimensions beyond 3-d are not orthogonal, does this change the definition of \"dimension\". I cannot conceive a geometrical image of higher dimensions. Algebraically, yes, but not geometrically. reply travisjungroth 28 minutes agoparent [–] > The axes of dimensions beyond 3-d are not orthogonal, does this change the definition of \"dimension\". They are orthogonal. > I cannot conceive a geometrical image of higher dimensions. This is normal, and essential to the point of the article. If you could visualize 10-dimensional space, it wouldn’t be so counterintuitive. Try looking up images and videos of 4D objects projected into 3D and 2D. That might help. Hypercubes are maybe the easiest. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In higher dimensions, objects like cubes and spheres exhibit properties that defy our three-dimensional intuition, such as the inner sphere's radius extending beyond the cube.",
      "The volume of a unit 𝑑-sphere decreases with increasing dimensions, and most of the sphere's surface area is concentrated near the equator.",
      "The \"kissing number,\" or the maximum number of spheres that can touch another without overlapping, is precisely known in only a few dimensions, with solutions in eight and twenty-four dimensions using special lattice structures."
    ],
    "commentSummary": [
      "High-dimensional spaces exhibit counterintuitive properties, such as the decreasing volume of a unit sphere as dimensions increase, which challenges our understanding due to differing units across dimensions.",
      "In high dimensions, the volume of a sphere relative to its bounding cube decreases, which aligns with the concept of adding dimensions and is significant for understanding spatial relationships.",
      "High-dimensional spaces enable near-orthogonality, a critical concept in machine learning, allowing many directions to be sufficiently orthogonal, which is essential for algorithms and data analysis."
    ],
    "points": 224,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1728853780
  },
  {
    "id": 41832302,
    "title": "Why does FM sound better than AM?",
    "originLink": "https://www.johndcook.com/blog/2024/10/13/why-does-fm-sound-better-than-am/",
    "originBody": "Why does FM sound better than AM? Posted on 13 October 2024 by John The original form of radio broadcast was amplitude modulation (AM). With AM radio, the changes in the amplitude of the carrier wave carries the signal you want to broadcast. Frequency modulation (FM) came later. With FM radio, changes to the frequency of the carrier wave carry the signal. I go into the mathematical details of AM radio here and of FM radio here. Pinter [1] gives a clear explanation of why the inventor of FM radio, Edwin Howard Armstrong, correctly predicted that FM radio transmissions would be less affected by noise. Armstrong reasoned that the effect of random noise is primarily to amplitude-modulate the carrier without consistently producing frequency derivations. In other words, noise tends to be a an unwanted amplitude modulation, not a frequency modulation. FM radio was able to achieve levels of noise reduction that people steeped in AM radio thought would be impossible. As J. R. Carson eloquently but incorrectly concluded … as the essential nature of the problem is more clearly perceived, we are unavoidably forced to the conclusion that static, like the poor, will always be with us. But as Pinter observes The substantial reduction of noise in a FM receiver by use of a limiter was indeed a startling discovery, contrary to the behavior of AM systems, because experience with such systems had shown that the noise contribution to the modulation of the carrier could not be eliminated without partial elimination of the message. Related posts FM signal approximation Mathematics of radio [1] Philip F. Pinter. Modulation, Noise, and Spectral Analysis. McGraw-Hill 1965. Categories : Math Science Tags : Radio Bookmark the permalink",
    "commentLink": "https://news.ycombinator.com/item?id=41832302",
    "commentBody": "Why does FM sound better than AM? (johndcook.com)222 points by zdw 20 hours agohidepastfavorite234 comments pkolaczk 11 hours agoI don’t buy this explanation. The FM modulation uses a much higher bandwidth than AM. The distance between channels on FM radio is 200 kHz compared to only 9 kHz on AM. That’s more than 20x more bandwidth for FM. On AM, no matter how deeply you modulate the carrier, the bandwidth will not exceed twice the bandwidth of the input signal. On FM, the deeper you modulate it, the wider the output spectrum will be, and it can easily exceed the bandwidth of the input signal. In addition to that, the whole FM band is much higher frequency, while I guess quite a lot of noise, especially burst noise caused by eg thunderstorms is relatively low frequency. So it’s not picked up because it’s out of band. Any noise that falls inside the channel does get picked up by the receiver regardless of modulation. However because the available bandwidth is so much higher than the real bandwidth of the useful signal, there is actually way more information redundancy in FM encoding, so this allows to remove random noise as it will likely cancel out. If I encoded the same signal onto 20 separate AM channels and then averaged the output from all of them (or better - use median filter) that would cancel most of random noise just as well. Also another thing with modulation might be that if there is any narrow-band non-white noise happening to fall inside the channel (eg a distant sender on colliding frequency), on AM it will be translated as-is to the audible band and you’ll hear it as a single tone. On FM demodulation it will be spread across the whole output signal spectrum, so it will be perceived quieter and nicer by human ear, even if its total energy is the same. That’s why AM does those funny sounds when tuning, but FM does not. reply arghwhat 10 hours agoparentThe wider channels is the source of the available audio fidelity, but wider channels make you more exposed to noise, not less. A wider channel means listening to more noise sources, and having transmitter power stretched thinner for a much lower SNR. In other words, the noise rejection of FM is what enabled the use of wider channels and therefore better audio quality. An analog answer before digital error correction. In FM, the rejection is so strong that if you have two overlapping transmissions, you will only hear the stronger one assuming it is notably stronger. This in turn is why air traffic still use AM where you can hear both overlapping transmissions at once (possibly garbled if carrier wave was off), and react accordingly rather than being unaware that it happened. Technology moved on from both plain AM and plain FM a long time ago, and modern “digital” modulation schemes have different approach to interference rejection. reply pkolaczk 9 hours agorootparentShannon theorem disagrees with you. The wider the channel, the MORE noise you can tolerate when transmitting signal at a given data rate. In audio, the amount of information you need to transmit is naturally limited by the audio bandwidth (for FM truncated at about 15 kHz), so the useful signal bandwidth is fixed. Hence, if you transmit the same audio band over a broader channel of frequencies, you can tolerate more noise; or, for the same density of noise in the channel, you can get better SNR at the output. This is exactly what FM does. It uses the information multiplied in the most of that 200 kHz channel and projects it on 0-15 kHz band. While you are right that a wider channel captures more noise in total, noise does not add up the same way as useful signal, because it’s random. Doubling the channel width only increases the amplitude of noise by sqrt(2). There is no “magic noise rejection” coming from different ways of modulating the signal if all other things are the same. You can’t remove noise; you can’t magically increase SNR. If anything, FM makes the noise more pleasant to listen to and perceivably quieter by spreading non random, irregular noise over the whole band so it sounds more like white noise. But it also allows to use wider channels, and increase the fidelity of the signal, including increasing SNR. But that’s thanks to using significantly wider channels than audio. Also, it’s not like FM can use wider channels because of better SNR. FM can use wider channels because of how this modulation works - the spectrum of FM signal can be arbitrarily wide, depending on the depth of modulation. AM cannot do that. It only shifts the audio band up (and mirrors on both sides of the carrier). It can’t “spread it”. Btw: this is a very similar phenomenon as when you average multiple shots of the same thing in photography, eg when photographing at night. By adding more frames (or using very long exposures) you obviously capture more total noise, but the amount of useful signal grows much faster because signal is correlated in time, but noise is not. reply CHY872 7 hours agorootparentIt’s not immediately clear that Shannon’s theorem is a good point of comparison here, since it’s only recently that coding schemes have really approached the Shannon limits, and FM and AM do not use these. Even if one does assume a Shannon-perfect coding scheme, as the noise ratio gets greater the benefits of spreading a signal across a higher bandwidth fades. Furthermore, most coding schemes hit their maximum inefficiency as the signal to noise ratio decreases and messages start to be too garbled to be well decoded. I’d additionally note that folks get near the Shannon noise limit _through_ ‘magic noise rejection’ (aka turbo and ldpc codes). It’s therefore not obvious that FM isn’t gaining clarity due to a noise rejection mechanic. The ‘capture effect’ is well described as an interference reducing mechanism. Empirically, radio manufacturers who do produce sophisticated long range radio usually advertise a longer range when spreading available power across a narrower rather than wider bandwidth. reply some_ee_here 7 hours agorootparentprevYou are applying Shannon theorem incorrectly. Both AM and FM modulations are nowhere even remotely close to using their bandwidth with 100% efficiency, due to technology costs, and the difference in modulation is crucial. The article is correct and the mathematical models of AM and FM are well understood since decades. reply pkolaczk 4 hours agorootparentWhere did I say AM and FM are close to 100% efficiency? I was only replying to an obviously incorrect statement that by using more bandwidth you decrease SNR. If it were the case, Shannon theorem would not work. It doesn’t matter how close to the limit your encoding is, whether it is 20% or 99% the relationship between the bandwidth, noise floor and how much data you can send stays the same - by increasing bandwidth you can usually send considerably more information even if your encoding is poor. Which in translates to either a wider useful bandwidth or lower noise floor or any combination of both. A trivial thought experiment to illustrate this: For any analog encoding, if I double the transmission bandwidth by encoding the same signal over 2 channels instead of one, I can average the output signal coming out the receivers and get better SNR than using one channel and one receiver. That works regardless of AM, FM or whatever fancy encoding you could use. reply bobmcnamara 3 hours agorootparent> A trivial thought experiment.. That's not how this works. That's not how any of this works. Averaging a high SNR channel with a low SNR channel is likely to produce something less good than the high SNR channel. Could you get an improvement over the high SNR channel? Yes, and the limit of the improvement is related to the SNR of each and averaging the signals won't get you anywhere near that. reply pkolaczk 1 hour agorootparentAveraging two noisy signals increases SNR. That’s not even a thought experiment, that’s a reality. This is a technique used by probably all modern smartphone cameras to do night photos, as well as a common technique used by astrophotographers. Instead of taking one picture, you take a series of pictures and then align them and average. This improves SNR dramatically. A very long time ago we used this technique to get razor sharp, low noise pictures of the Moon at 3k x 3k resolution using… a cheap VGA internet camera: https://astronet.pl/wydarzenia/n2309/ Note that cameras at those times were barely capable of doing videoconferencing in artificial evening light - what you saw was mostly noise. Those sensors were really, really terrible. What you seem to be missing is the fact we’re talking here about transferring the same fixed bandwidth signal over a wider channel, not transferring a wider bandwidth signal over a wider channel. // edit: just noticed someone else gave another nice application of this phenomenon: GPS reply bobmcnamara 1 hour agorootparent> This is a technique used by probably all modern smartphone cameras to do night photos, as well as a common technique used by astrophotographers... I think this is a lot simpler because each of your pixels is assumed to have a single, correct DC value. This doesn't hold for a time varying signal like AM/FM. reply bobmcnamara 1 hour agorootparentprevLet's take it to the limit: Signal0: infinite SNR. Signal1: anything less. I just don't see how the output of averaging these would improve over Signal0. I don't think it can. reply bobmcnamara 1 hour agorootparentprevNo, that's one time varying signal. reply arghwhat 3 hours agorootparentprevWell, yes and no. It's a bit more complex than just taking the numbers from Shannon-Hartley, but I admit that my original description was at best lacking, so thank you for pointing that out. Shannon-Hartley describes that the theoretical information capacity of a signal given a bandwidth and an SNR. Doubling bandwidth halves your SNR (received noise increases, received signal does not), in turn reducing the bits gained per unit of bandwidth. At very high SNR, doubling bandwidth almost doubles capacity, but as SNR goes down, the benefit of additional bandwidth levels off until bandwidth no longer has any effect. However, this provides the number achievable by a perfect modulation scheme using all available bandwidth and signal strength. AM and FM are both incredibly inefficient, and more importantly have very different reactions to noise - something Shannon-Hartley does not concern itself with. With truly random noise, FM and AM noise both scale based on noise amplitude as you say. In AM, all noise overlapping with the band is played back verbatim, whereas in FM only the noise causing frequency variations in the carrier wave have any effect on the signal, and end up with a non-linear response to noise. However, we do not deal with purely white noise, and FM has far superior handling of non-random noise. In order to have any effect, it need to either induce frequency shifts to the carrier wave, or have enough power to cause the interference to be captured instead. There's also the far higher power efficiency, as FM puts all its power into the signal, whereas traditional AM puts most of it into a useless carrier and wastes half the remaining power on the redundant sideband (yes, SSB is a thing). These were certainly also factors in FMs demise. A simpler means to remove bandwidth from the equation would be to compare with a narrow-band FM transmission, or by multiplying the input waveform for an AM transmitter by some factor to fill the bandwidth. I believe FM should still handily beat it at least above its threshold. I don't see anyone giving exact numbers of this though, so I guess it could be a fun SDR project for someone wanting to prove either point. :) (Neither AM nor FM is of anything but historic value at this point - their only redeeming quality is discrete circuit simplicity if you need to MacGyver one out of shoelace and bubblegum, but that's it.) reply zsellera 5 hours agorootparentprevWhat you \"more bandwidth more noise\" people miss is the difference in randomness: the noise is random while the signal is not. In case of gaussian noise, double the bandwidth means 1.41x more noise. For signal, double the bandwidth double the signal. reply analogwzrd 5 hours agorootparentWhere are you getting 1.41x? What you'd really like to increase is the SNR. As you open up the bandwidth, the amount of energy you can collect in your band increases, but there's no way to collect the energy from only the signal and not collect the energy from noise. So as you increase your bandwidth, your SNR stays the same. Not all noise is gaussian. And the fact that the noise is random while the signal is not, is useful when you can average and drop your noise floor. But you need multiple measurements to do that. reply arghwhat 3 hours agorootparent1.41x is sqrt(2), which suggests that they meant noise amplitude rather than noise power. reply pkolaczk 1 hour agorootparentNoise power increases twice but signal power increases 4x. Noise amplitude increases sqrt(2) times, signal amplitude increases 2x. reply kabouseng 5 hours agorootparentprevNoise is not gaussian. reply kees99 9 hours agorootparentprev> (...) use AM where you can hear both overlapping transmissions at once Yes. Assuming signal strengths for both are comparable. Say, within 20 dB of each other. > (possibly garbled if carrier wave was off) Nah. If both stations have sufficient energy fall into receiver's bandwidth window (IF filter for analog receiver), no garbling. If one of stations has carrier sufficiently off to fall entirely outside IF, only other will be audible. You are probably thinking about SSB, where two stations with carrier offset indeed produce weird sounding interference. https://en.wikipedia.org/wiki/Single-sideband_modulation reply tomfanning 9 hours agorootparentIn SSB there is no carrier transmitted. Two SSB stations on top of each other sounds exactly like two microphones mixed. reply pkolaczk 1 hour agorootparentInteresting. However, if one of those stations runs on a slightly different frequency, I guess its output would be garbled, correct? Like I guess SSB receiver just shifts down the band by a constant? reply vel0city 34 minutes agorootparentIf it's kind of close it just sounds like someone talking in a slightly lower or higher pitch. It can still be pretty intelligible with the frequency slightly off. Eventually it gets very distorted though and you start losing a big part of the waveform entirely. Try listening in to some websdrs and you'll see what it's like. reply CamperBob2 3 hours agorootparentprevThe wider channels is the source of the available audio fidelity, but wider channels make you more exposed to noise, not less. From a signal:noise perspective, what matters is the ratio of bandwidth available in the transmission channel to the bandwidth of the content you are trying to send. Consider GPS, for instance, where the use of a 2 MHz channel to send 50 bps data provides an SNR advantage that would otherwise be achievable only through witchcraft. FM has strong noise immunity advantages -- notably AM rejection and the capture effect -- but they don't provide additional sound quality by themselves. That's where the bandwidth helps. An FM channel that is only as wide as an AM channel would sound pretty awful. reply arghwhat 3 hours agorootparent> FM has strong noise immunity advantages -- notably AM rejection and the capture effect -- but they don't provide additional sound quality by themselves. That's where the bandwidth helps. An FM channel that is only as wide as an AM channel would sound pretty awful. Comparing such low-modulation factor FM with traditional AM would be an interesting experiment. It certainly wouldn't sound good, but I'm not sure it would sound worse than traditional AM at the same SNR. The NFM use-cases I'm familiar with tend to cap audio bandwidth, so they're not fair comparisons. reply CamperBob2 1 hour agorootparentI'm mostly imagining what music would sound like via NBFM on a VHF amateur or public-safety radio channel. It's not an appealing thought... the words \"toll quality\" come to mind. But hey, no static at all... https://www.youtube.com/watch?v=HV3zWSawJiw reply zb 9 hours agorootparentprev> This in turn is why air traffic still use AM where you can hear both overlapping transmissions at once (possibly garbled if carrier wave was off), and react accordingly rather than being unaware that it happened. I’m not convinced this is the reason. The carrier wave is always off by a little. While you’re transmitting you hear nothing anyway. And when two parties are transmitting simultaneously, any third parties just hear very loud screeching. A 0.001% difference in carrier frequency would be more than enough to cause this effect in a VHF radio. Notably, this exact problem was a major contributing cause to the worst accident in aviation history. Using FM would have prevented it. https://archive.ph/2013.02.01-162840/http://www.salon.com/20... reply rlpb 4 hours agorootparentThat article makes out as if transmission blocking leads to a safety problem if a transmission gets lost. It doesn't. What that article misses is that aviation radio communications require readback and verification of the readback, in safety critical instructions such as \"cleared for take-off\". Not just for radio transmission blocking reasons, but also to detect mistakes in mishearing instructions. https://en.wikipedia.org/wiki/Tenerife_airport_disaster#Comm... tells a more accurate story: the root cause was that the captain assumed they were cleared for take-off without actually hearing their own callsign and the word \"cleared\". Since then, the word \"take-off\" is avoided in any other type of communication (eg. you might hear \"report ready for departure\" but never \"report ready for take-off\"), and every pilot knows never to assume that a clearance has been given unless they hear those exact words together with their callsign. reply p_l 7 hours agorootparentprevAM is used for two reasons - simplicity of transceivers AND the fact that two simultaneous transmissions result in buzz instead of locking onto stronger signal. We WANT to know that there's a collision in transmission so that we know we need to retransmit. What would be the expected effect if two FM transmission on same channel were sent? Fixing the \"glitch\" would result in way more problems than it solves. Interestingly, aviation authorities do not blame collission behaviour of AM radio for Tenerife, but instead corrected crew management procedures and pushed greater radio phraseology standardisation. reply BigTuna 4 hours agorootparent>We WANT to know that there's a collision in transmission so that we know we need to retransmit Digital trunked public safety systems solved this problem decades ago. If you key up when the frequency is in use you get a distinct rejected tone. I'd think prevention is far preferable to sorting it out once everyone's finished walking on each other. reply p_l 3 hours agorootparentIt also means you need to replace everyones radio at the same time because everyone needs to hear everyone on the channel. Where new additional technologies are possible, they have been applied (digital packet networks, like with CPLDC - Controller-Pilot Data Link Communications). Replacing A3E modulated VHF radio requires you replace it for literally everyone, because there are way more users at airport than you think. reply mindcrime 49 minutes agorootparent> It also means you need to replace everyones radio at the same time because everyone needs to hear everyone on the channel. In the public safety context it's not uncommon to phase in new systems (like digital trunked systems) incrementally. You accomplish that by simulcasting the dispatch audio over both systems, and monitoring incoming audio from both systems. A common pattern for how this plays out would be something like this: all the fire departments and ems agencies in a given jurisdiction are dispatched using two-tone (eg, motorola) paging over a VHF frequency. New digital radios are introduced, and all the fire/ems personnel keep their existing pagers, and (some|most|all) are given the new digital radios. People without the new radios can still talk to dispatch using VHF. And of course systems can be configured to mirror audio around so that if one person is transmitting on VHF they can be heard on the digital system (usually on a channel in the 800mhz or 900mhz band). It's basically a fancy version of a repeater. Dispatches are then given out over the same old VHF channel AND the new digital channel. In theory you can eventually replace all the old pagers and radios and quit with the simulcast deal, but IME, sometimes things stay in \"parallel\" mode more or less indefinitely for whatever reason[1]. That said, to your original point, you typically do want to get at least radios standardized as much as possible, even if you maintain the split for (paging|operational communications). To illustrate, two jurisdictions I'm familiar with: Orange County NC, and Brunswick County, NC. Both followed the path I talked about above: all VHF dispatch for fire/ems, then adopted the NC VIPER digital trunking system, but continue to page on VHF and simulcast the dispatch information over both channels. I'm not sure exactly when Orange County adopted VIPER but it's been quite some time and they're still doing both. FSM only knows if/when they'll ever completely abandon the old VHF system. [1]: and that reason is often as simple as \"money\". Plenty of volunteer fire departments in rural areas are skating by with barely enough money to keep their apparatus road-worthy. Replacing every hand-held and mobile radio they own in one fell swoop is often out of reach. [Source: was a firefighter and 911 dispatcher in a previous life] reply arghwhat 2 hours agorootparentprev> AM is used for two reasons - simplicity of transceivers That is not a factor anymore. Capable wideband transcievers like the ones in Baofengs and similar supporting multiple types of modulation cost cents. reply p_l 2 hours agorootparentThere's cost in simultaneous replacement for huge portion of the fleet. Don't devolve into simplism, consider that you need to replace the radio for everyone sharing the same space, and that there might be way more planes sharing that space than you think. reply nradov 1 hour agorootparentprevAnd who would pay for the Supplementary Type Certificate for every single aircraft model out there, including many that were built by manufacturers that no longer exist? I don't think you understand how this stuff actually works. reply akira2501 9 hours agoparentprevFM has 15kHz of bandwidth per stereo channel or an effective 30kHz sampling rate. The rest of the space is used for supplemental signals, including, the \"pilot carrier\" that is used to generate the \"stereo image.\" There is space for three more full bandwidth mono channels on the end of an FM broadcast. One of them is often used for RBDS. FM signals receive AM interference but heterodynes exclude them effectively. The cost is vulnerability to multipath reception in highly signal reflective environments and capture/wandering effects when two signals of similar strength are present. AM _can_ sound pretty good. Most AM transmitter sites are poorly maintained, combined with other stations into one antenna system (something you can do on AM with a phasor), and are typically just simulcasts of FM content or satellite delivered content. There's no real care put into it. On a well maintained, tuned, and properly programmed station, mono content on AM sounds quite pleasant. That's not even getting into \"cost saving\" measures that AM operators employ that completely compromise their signals. Or what Nielsen has convinced them to inject into their signals to register modern \"ratings points\" from the \"portable people meter\" system. Guess where I used to work. reply adrian_b 8 hours agorootparentFM has 15 kHz of bandwidth available for the audio signal, which is much higher than what had been previously standardized for the AM channels and which is an important reason for the perceived high fidelity. The modulated signal that is transmitted on the air has a much higher bandwidth. How much higher may differ between various broadcasting standards, but it can be e.g. 10 times or 20 times higher. The ratio between the bandwidth of the transmitted radio signal and the bandwidth of the audio signal is what is relevant for the noise rejection properties of FM broadcasting. When the bandwidth available for transmission is limited, FM is not an optimal kind of modulation from the point of view of resistance to noise, phase modulation (QPSK) is better (and optimum), so that is what is used for digital communications limited by noise. reply tboerstad 7 hours agorootparentprevThanks for the interesting info! My guess would be iHeartMedia reply xd1936 6 hours agoparentprevGoing back to first principles, modulating the frequency instead of the amplitude inherently makes the system less lossy. Imagine you were communicating with someone miles away on a hilltop, and they had a lot of data to convey. Would you find it easier to distinguish signal vs. noise if the light was increasing and decreasing rapidly in brightness (AM) or color (FM)? reply pkolaczk 1 hour agorootparentIf you AM modulate the carrier f0 by a single tone f1, you get a spectrum with only three tones: f0 - f1, f0, f0 + f1. If you FM modulate it, well the thing gets much more complex - depending on the depth of modulation you can get a much wider spectrum than from f0-f1 to f0+f1. So it is hard to compare. Your FM modulated signal may indeed be more resilient to noise but will require wider channel to be properly transmitted. I haven’t seen a convincing explanation if FM would be really that better than AM if both were given exactly the same channel width. reply Anotheroneagain 8 hours agoparentprevNeither is true. 9kHz, with two sidebands, means that the transmitted audio is limited to 4.5kHz, which is way too low to sound good. It was this, and not the noise, that made it sound much worse. reply adrian_b 8 hours agorootparentWhile one reason for limiting the audio bandwidth to 4.5 kHz was to allow a great enough number of channels in the long wave and medium wave bands, the second reason was to be able to reject the high frequency noise by low-pass filtering. So there were two reasons for the low audio fidelity of AM broadcasting, and noise was one of them, with the contention between multiple broadcasters for the narrow available bands being the other. reply giantrobot 1 hour agorootparent> with the contention between multiple broadcasters for the narrow available bands being the other. A non-obvious aspect of medium and long wave AM broadcast is depending on weather/atmospheric conditions a signal can propagate much further than its output power would suggest. This means a distant station on the same channel as a near station may end up in contention at certain times of day or random conditions. Solar flare? Suddenly stations a hundred miles away are overpowering local stations or just adding a lot of noise. Medium and long wave is also susceptible to local EM sources like switching power supplies and electric motors. So you can get the double whammy of local noice and distant stations adding additional interference to local stations. reply Johnythree 5 hours agorootparentprevThere is no reason that the channel spacing need limit the sideband bandwidth. The only downside to this is that listeners on adjacent stations hear a slight \"monkey chatter\" from the overlapping sidebands. This is one of many reasons why station frequencies are never allocated close to stations which are physically close. You only need glance at the waterfall display on a good SDR receiver to see that the actual audio bandwidth is often much wider than the channel spacing implies. reply fredgrott 7 hours agoparentprevfor fun, try using a square wave amplifier to shift the wave: -for AM you get sound effects such as chip monks -for FM what do you get? reply spease 3 hours agoprevI’m confused how this is even a question. With AM, anything that causes a variation in the intensity of the signal will introduce noise. With FM, anything that causes a variation in the timing of the signal will introduce noise. Unless you’re traveling at relativistic speeds, operating a time dilation device, or colocated with a black hole, you usually aren’t going to see the rate that time flows at vary. Thus if you can make the amplitude of your signal irrelevant past a certain threshold and embed all the information into the time domain, the only thing introducing interference should be other EM sources that happen to be on the same channel. reply aidenn0 2 hours agoparentThat is true for uncorrelated broad-band noise. Correlated noise (e.g. multipath interference) and narrow-band noise (e.g. another FM transmitter) can both affect FM pretty badly. reply polishdude20 2 hours agorootparentSpeaking of multipath interference, why is it that we almost never hear the effect of that? Like, aren't these waves almost constantly bouncing off of other things and being reflected? How are we not always hearing echos all the time? reply aidenn0 2 minutes agorootparentOther people answered your question, but if you ever saw shadowing artifacts on an analog UHF TV station, that was probably multipath. Note that lines on an NTSC TV are scanned at over 15kHz, so this is a very small time difference. reply vel0city 12 minutes agorootparentprevThe other poster is correct but I feel there's still a simpler answer when you see the units at play. You don't constantly hear reflections as echos mostly because of the speed of light and the inverse square law. Let's think about how far the echo has to come from to have even a half second delay. At the speed of light, that half second is 93,141mi. So it would have to reflect off something half that distance, ~46,500mi. Not a lot of good reflectors pointed at me 46,500mi away. So then think of the inverse-square law on that. How weak of a signal is that going to be travelling those 93,141mi? Are you set up to even notice that from the noise? It's 11 billion times weaker than the original signal, assuming your reflector perfectly reflects the source signal and you're in outer space. So obviously whatever \"echo\" we experience, it's not going to be something in the realm of humans directly detecting it. The shift that is possible to really mess with the signal at distance you'll actually receive reflections at are only going to shift the timing in a very small way, usually by being a slightly different phase. This means you'll get constructive and destructive interference from the same signal at slightly different phases, but not really a noticeable \"echo\". reply adrian_b 38 minutes agorootparentprevThe effect is easily noticeable only for high frequencies, where the wavelengths are no bigger than a few meters. For the lower frequencies used by AM broadcasting, where the wavelengths are up to hundreds of meters or kilometers, and you use small antennas for reception, it is unlikely to have problems caused by multipath propagation (because the waves will go around obstacles instead of being reflected; only for the higher frequencies of the shortwave range you can have multipath reception of signals reflected by the ionosphere, but the objects that are around the receiver still do not cause problems). When there is multipath propagation, you would not hear echos, because the time difference between the different paths is too small, due to the high speed of the radio waves. What you get is interference between the multiple signals, which can reduce too much the strength of the received signal. When the signal is reflected on some paths by mobile objects, or when the receiver itself is moving, the received combined signal will have an amplitude that varies in time, with intervals when the signal cannot be received (i.e. fading). reply taeric 3 hours agoparentprevI was surprised this wasn't leaned on more explicitly for the explanation. I think this is largely held in the assumptions that go into saying most noise will be amplitude modulation? Edit: Reminds me of the banal but vital insight that digital uses repeaters to gain distance, whereas analog uses amplifiers. Makes it very easy to consider why/how digital took over. reply nixass 2 hours agoparentprev> I’m confused how this is even a question. It sure is, why would everyone or anyone be aware of AM/FM differences? Even if one is tech savvy it doesn't mean this would be something trivial to understand at glance reply _fizz_buzz_ 2 hours agoparentprevFM usually has higher fidelity than AM even if no noise is introduced. reply MBCook 2 hours agorootparentRight. Isn’t FM just flat out higher bandwidth? So unless it’s wasting that somehow it’s just going to carry more information. And for audio, that means sounding better. reply cruffle_duffle 1 hour agorootparentThe use of FM doesn’t inherently imply higher bandwidth. For example, those consumer-grade FRS/GMRS radios you get from Costco use narrowband FM, which typically occupies about 12.5 kHz per channel. This is much narrower compared to the 200 kHz bandwidth used by FM broadcast radio. FM is simply a method of modulating the carrier signal by varying its frequency. The actual bandwidth depends on factors like frequency deviation and modulation, so FM can range from narrow to wide bandwidth depending on the application. reply mumer101 3 hours agoparentprevhttps://www.pbs.org/wgbh/aso/tryit/radio/radiorelayer.html reply matrix2003 18 hours agoprevSomeone gave me an analogy some time ago that made a lot of sense. If you shine a flashlight through a tree blowing in the wind and vary the brightness to convey information, the signal can get distorted pretty easily. However, if you have a constant brightness source and vary the color, it’s a lot easier to figure out what the source is trying to convey. reply userbinator 18 hours agoparentIt's not merely an analogy, just the same EM waves scaled up in frequency by a few orders of magnitude. reply mistercow 5 hours agorootparentExcept that color isn’t the same thing as wavelength when it comes to humans perceiving light, because our eyes only deal with the total energy within each of three overlapping bands. An FM receiver knows the difference between a single carrier varying in frequency, and two carriers of different frequencies varying in proportion. Our eyes don’t, hence the banner above appearing orange, even though it’s actually made of different proportions of red and green. reply idunnoman1222 40 minutes agorootparentRight, but let’s just consider the visual spectrum a single carrier/station reply beala 17 hours agoparentprevThis makes a lot of sense so long as your source of noise is something like a tree swaying in the wind, ie something that interferes with the amplitude. If instead the source of noise is uhhh a piece of stained glass swaying in the wind then blinking the flashlight is the better bet. I guess it just turns out radio interference is more like the tree. But why? reply arnarbi 17 hours agorootparentStained glass won’t (I think) shift any frequencies. It will attenuate different frequencies differently, but it won’t make up new ones. So when the signal frequency changes, you’ll still see that change, but the light might get brighter or dimmer at the same time due to the stained glass. But you don’t care about the brightness to begin with. reply carlmr 11 hours agorootparentIn the stained glass case, maybe you need to go digital where brightness and color don't matter, but only on-off state. reply ploynog 8 hours agorootparentYou'd be surprised by the amount of brightness and color produced if you are turning things on-off sufficiently fast. reply ykonstant 7 hours agorootparentRelated: lots of optical illusions. reply abnry 17 hours agorootparentprevIn this analogy, the AM and FM signals you receive aren't usually experiencing interference, they are experiencing multipath effects which includes things like path loss, attenuation, reflections, and so on. This is driven by geometry. You also have gaussian noise that the receiver has to deal with. You model this by taking your signal and convolving it with the channel vector. Usually the channel vector is a finite number of dirac deltas. Each delta is a different reflection. They are like echos. They can cause the signal to constructively and desconstructively interfere with itself. I haven't seen the math, but I am guessing this doesn't do as much to the frequency of the signal compared to the amplitude. reply a-dub 12 hours agorootparentpreva better analogy for frequency domain interference would be something like the spinning flashing lights on a fire engine or utility truck occasionally shining colored light on your detector. reply bee_rider 17 hours agorootparentprevThe stained glass would change the amplitude of some light selectively. But because the FM radio works at different distances, I wonder if it must have some way of adjusting for different amplitudes anyway? reply xeyownt 13 hours agorootparentYes, stained glass is like band filter, they let through a particular frequency range, while reducing those outside the range. Your FM receiver will still lock on the desired frequency as long as their is enough signal strength. It's kind of the same as listening to an emitter that is very far while being very close to another. Of course, it'll stop to work at some point depending on minimum signal-to-noise ratio. reply reader9274 18 hours agoparentprevI always shy away from analogies because more often than not they give the wrong \"feel\" for a concept. But this is one of those rare exceptions. reply Sesse__ 11 hours agorootparentIt _is_ the wrong feel for a concept. The analogy breaks down because the color changes are way too wide in frequency (and thus too robust to noise) compared to what happens in a radio broadcast. If you changed the color from RGB(127, 0, 0) to RGB(126.999999, 0.000001, 0), the movement of that tree would actually start to make your strategy difficult. Going from red to orange is about 50 THz. Typical FM radio modulation width is 100 kHz. reply Workaccount2 5 hours agorootparentThe analogy isn't wrong, it's just that it is incomplete as given. You are bringing the sensitivity of the receiver into the equation. But it doesn't really break down the analogy, because the frequency shift in color is calibrated for the human eye's sensitivity. Calibrate it for a FM receiver and that tiny color shift becomes easily discernible. The tree leaves have no impact on frequency, just amplitude. The reason the analogy is good is because it isn't even really an analogy, it is in fact a description of electromagnetic waves and a noise source. reply Filligree 18 hours agorootparentprevIt's not an analogy. This is precisely how it works. reply khazhoux 18 hours agorootparentUnless your car radio consists of a flashlight and a tree, this is an analogy. reply llm_trw 17 hours agorootparentThe flashlight is the radio tower, the tree is the tree, and the radio in the car is your eyes. There is no analogy here, it is literally the same EM waves shifted up to where our eyes can see them. It's like saying that the violins is merely an analogy for how a double base works. reply JumpCrisscross 14 hours agorootparent> it is literally the same EM waves shifted up to where our eyes can see them Rubber ducks aren't battleships because they both float. Visible light and radio attenutate in meaningfully-different ways. It's an analogy. reply wruza 7 hours agorootparentYou could make Bob Ross a new wig from all the hairs split in this subthread. reply digitalsushi 6 hours agorootparenta lot of people here have a lot of passions, but sometimes the passions overlap and we rub shoulders. if someone had made a pokemon playing card metaphor we might be in the same general condition - but i think we're better behaved showing each other how smart we must be with radio waves instead of greymon reply acje 13 hours agorootparentprevBoth are examples of communication by means of frequency modulated and amplitude modulated electromagnetic waves with distortion from a moving three. Also a good example that a large change in quantity is a change in kind. Probably a legit analogy imho. reply JumpCrisscross 1 hour agorootparent> Probably a legit analogy imho It’s a terrific analogy. OP is arguing that it isn’t an analogy but an identity. For what should be obvious reasons, it isn’t. And in this case, the difference between analogy and our best model of reality is material. reply dexwiz 13 hours agorootparentprevRubber ducks and battleships both displace water in the same way. reply JumpCrisscross 13 hours agorootparent> Rubber ducks and battleships both displace water in the same way Yes. Just like light and radio waves are both EM. A rubber duck remains an analogy for the buoyancy of a battleship. Not \"literally the same\" thing. reply aeonik 6 hours agorootparentBut if you say that a battleship floats on the water in a similar way to a rubber duck floating in the water... it's actually not similar... they are the same. It's the same water and the same physics. The \"only\" appreciable difference is scale. For me, the people saying they are the literal same thing are the same type of people that gave me that \"aha\" moment that really helped solidify my understanding of RF. It was pretty mind blowing when I Understood that AM is a change in brightness and FM was a change in color. We just can't see RF, but if we could, that's what it would be. reply aksss 13 hours agorootparentprevDucks and witches, on the other hand. . . reply treyd 13 hours agorootparentprevBut RC boats and battleships both have propellers and rudders. reply almostgotcaught 13 hours agorootparentprev> Visible light and radio attenutate in meaningfully different ways. It's an analogy. Lol news to me and my physics degree, Do tell because as far as I'm aware Maxwell's equations don't have an asterisk on them that say \"doesn't work below 1 GHz\". reply JumpCrisscross 1 hour agorootparent> as I'm aware Maxwell's equations don't have an asterisk on them that say \"doesn't work below 1 GHz\" You don’t see how one being able to attenuate around a hill while another needs line of sight isn’t material to the way we use light and radio waves? reply kuhsaft 12 hours agorootparentprev> Do tell because as far as I'm aware Maxwell's equations don't have an asterisk on them that say \"doesn't work below 1 GHz\". Did you really just pull out Maxwell's equations? EM interacts with matter in different ways. Glass hardly attenuates visible light, but wood does. 2.4 Ghz can pass through walls better than 5Ghz. There's the concept of permittivity wherein Maxwell's equations are defined in free space with vacuum permittivity. https://en.wikipedia.org/wiki/Vacuum_permittivity#Permittivi... To accurately model EM waves, you need more than just Maxwell's equations. You require material equations to model interactions of EM with media. If you want to get really advanced, whereas Maxwell's equations are classical physics, there's Quantum electrodynamics (QED) which can model interactions of EM and matter. https://en.wikipedia.org/wiki/Quantum_electrodynamics reply asdefghyk 11 hours agorootparentRE \"....Glass hardly attenuates visible light....\" Clear glass blocks about 5% visible light reply kuhsaft 11 hours agorootparentDepends on the frequency of EM. Fiber optic communications use specific frequencies to minimize attenuation in cables. https://en.wikipedia.org/wiki/Optical_fiber#Mechanisms_of_at... Same with communications over coax. Obviously visible light doesn't transmit well over copper, but a spectrum of radio waves do, some better than others. reply Sesse__ 11 hours agorootparentFiber optics also uses _exceptionally_ clear glass. If the ocean were as clear as your average long-distance fiber cable, you would see down to the bottom of the Mariana Trench (also in the range of visible light, AFAIK). reply kuhsaft 11 hours agorootparent> Fiber optics also uses _exceptionally_ clear glass. Clear in certain wavelengths. Depends on the composition of the glass. https://en.wikipedia.org/wiki/Optical_fiber#/media/File:Si_Z... Silica glass behaves differently from ZBLAN (fluorozirconate glass). Which goes to show how complicated EM interactions with media can be. It's generally easier to just empirically measure attenuation through some medium and use the empirical measurements as a model. reply Sesse__ 10 hours agorootparentIt's exceptionally clear compared to e.g. window glass even in the visible spectrum of light. You can shine a red light source into a 10 kilometer standard G.657 fiber (optimized for 1310/1550nm, i.e. deep infrared) and it will still be visible just fine on the other end. If you did that with regular glass, it would hardly go ten meters. reply schoen 5 hours agorootparentWhat are the relative contributions of the total internal reflection property of the fiber optic cable and the particular low-attenuation material it's made of? reply kuhsaft 10 hours agorootparentprevOh yeah. I'm not saying otherwise. Someone replied \"Clear glass blocks about 5% visible light\". I guess \"clear glass\" is pretty subjective. At what level of attenuation would someone consider glass not clear? xD reply almostgotcaught 3 hours agorootparentprev> There's the concept of permittivity > You require material equations to model interactions of EM with media > Quantum electrodynamics (QED) which can model interactions of EM and matter. It's amazing how condescending some people on here are; how could you possibly have missed literally in the first sentence of my response > ... my physics degree reply swores 13 hours agorootparentprevIt's not saying the violin IS \"merely an analogy for how a double base works\", just that a violin can be used as a simple analogy to somebody who understands how a violin works but doesn't know what a double bass is. Comparing similar things is literally what an analogy is, the fact that in these two cases (radio/light and string instruments) the things being compared are very similar it doesn't make them the same thing, nor does it make it not an analogy. reply mistercow 4 hours agorootparentprevIt is not literally the same. The colors you perceive on the screen in front of you demonstrate why. That banner above is not orange; it’s red and green. You don’t actually have the ability to distinguish a varying frequency between red-orange and yellow-orange, and two amplitude modulated “carriers” at red and green. That’s the hallmark of an analogy. It gives the general idea, but breaks down if we interrogate it in too much detail. reply kelnos 17 hours agorootparentprevEssentially that is actually the case. Human-visible light and AM/FM radio waves are just different wavelengths along the EM spectrum. A flashlight beams out waves that we can see; a radio transmitter beams out waves we can't. The brightness of the beam of light is related to its amplitude, just like the signal content in AM radio is related to its amplitude. And the color of the beam of light is related to its frequency, just like the signal content in FM radio is related to its frequency. reply khazhoux 13 hours agorootparentThe explanation asks us to imagine shining a flashlight through a tree, first changing the flashlight brightness and then changing its color. The flashlight is an analogy for a radio transmitter. We all get that they work on same principle but just on different wavelengths. But regardless I can't shine the flashlight in my kitchen drawer at my radio and pick up a signal. reply mordae 9 hours agorootparentRemove cover, locate LNA, modulate light correctly and voila... :-) reply viraptor 17 hours agorootparentprevWell... It kind of does. The source of the radio station is a kind of flashlight, just on a different frequency. The tree is still a tree (and all the other objects) reply cloudwalk9 17 hours agorootparentMore accurately a giant lightbulb, but emitting at 102.7 MHz (my favorite local radio station) rather than ~450 THz (my favorite color). Put visible light over a really long waveguide and modulate the colors, you invented fiber optic telecommunication. reply senorrib 17 hours agorootparentprevBoth concepts are based on frequency and amplitude of waves (radio vs light). reply khazhoux 13 hours agorootparentThat's what makes the analogy so clear. reply MrLeap 2 hours agoparentprevI read a similar explanation on slashdot a few decades ago that's stuck with me. reply squarefoot 9 hours agoparentprevGood analogy, however if you move back and forth the transmitter or the receiver at enough speed, frequency (color) will vary as well, and that analogy could be used to explain Doppler effect, and why civilian airplanes use AM. reply vel0city 4 hours agorootparentCivilian airplanes aren't using AM because of the Doppler effect. You're not accelerating that rapidly to make the Doppler effect that pronounced on the kind of radio being used in airplanes to the point they wouldn't be useful. Even if you're going hundreds of miles an hour the shift is going to be a few dozen Hz in drift. A cheap FM discriminator will be able to handle that without any problem. Doppler shift starts to matter when dealing with satellites, but not airplanes unless you're taking a SR-71 on a civilian stroll. Doing the math, if you're going 200mph away from a station transmitting at say 121MHz, the drift frequency would be ~36Hz. Not going to be a problem. And even then, your AM transmission still gets affected by Doppler shift as well. Airplanes use AM because when two SSB transmissions happen at the same time you can actually hear both at the same time. If you're using FM it's either an incoherent mess or one transmitter drowns out the other. reply ra 13 hours agoparentprevThat's not the real story. The RF environment is noisy, with naturally occuring static \"sparks\", but also with manmade RF noise. This static and RF noise is AM. It's impossible to filter it out from an AM signal, and so the background noise gets amplified with the signal. Encoding the signal in a modulated frequency (FM) means we don't need to amplify the detected AM signal and it's associated background noise. reply cbolton 12 hours agorootparentThat's exactly what the parent comment described in the beautiful example where the AM noise is due to moving tree leafs affecting the intensity of transmitted light, and you can fix it by varying color, which means varying the frequency spectrum of the light. reply ikekkdcjkfke 8 hours agorootparentHow does the radio follow the frequency modulations if the radio cannot \"see\" at a specific direction? reply cbolton 8 hours agorootparentIn the example, the amplitude of the flashlight signal is distorted by the movement of the trees. The signal is never completely hidden. Not sure if that answers your question... reply Sesse__ 11 hours agorootparentprevIt's not that simple, though. The only way you can detect frequency is by measuring the amplitude (and then differentiate; except of course in an analog circuit, you don't do that exactly, you have some mechanism that tries to track the carrier wave smoothly instead), so amplitude noise will necessarily also become frequency noise. But generally white AM noise will be pushed upwards in the spectrum after FM demodulation, away from the area where you care. (You can also add a hard limiter, which amplifies this effect; even more noise high up, even less noise further down.) reply tejohnso 17 hours agoparentprevThis seems great at first, but more so as an explanation of how AM and FM differ; one being by amplitude (brightness), and the other by frequency (color). What I don't see is how it explains why one would work better than the other. If the tree is blowing in the wind, and a leaf obstructs the entire signal, it doesn't matter whether it's a change in brightness, or a change in color. Either way, that information is lost by the blocked leaf. And if the entire signal is not lost, perhaps many leaves may have blocked the signal but some signal managed to get through, it doesn't matter whether the signal change was a change in brightness, or a change in color. Either way you're going to notice the change. So I don't see how this clarifies why FM is better. What am I missing? I see from the article that \"noise tends to be a an unwanted amplitude modulation, not a frequency modulation.\" In other words, the tree is providing an unwanted change in brightness. It never provides an unwanted change in color. I guess the tree is able to dim the signal so much that it appears to be a deliberate signal change? Couldn't this be dealt with if you know the details of the tree's dimming ability? reply evoke4908 17 hours agorootparentThe analogy is getting a bit tortured, so I'll try a more practical explanation. An AM receiver is a machine that senses the amplitude at a specific em frequency. In this situation, noise and interference become random additions or subtractions to that amplitude. Draw a sine wave, then go over the line with vertical ticks or scribbles. Now imagine taking a random sampling of points and reconstructing the original wave perfectly (without a computer). Most of the information is just gone and you end up with a noisy output wave. Now an FM receiver is one that measures frequency changes above and below a 'carrier' frequency. The amount of deviation away from center represents the amplitude of the sound signal being transmitted. In this setup, noise and interference are also random additions to the amplitude, but also at random frequencies. On average, interference happens evenly over the entire range of frequencies you're looking at. That means that the highest amplitude is still the same frequency away from center, it just has a slightly different amplitude. Go back to that sine wave. You can't see the original signal behind all the noise, but you can still see how far apart the peaks are. You can still easily extract its frequency content. FM uses the frequency dimension to transmit data because random noise can't really affect frequency. Noise mostly happens in the amplitude dimension across all frequencies at the same time. FM is more robust because it uses two dimensions to encode information vs AM's single dimension. That's also why FM is in stereo! reply bonzini 12 hours agorootparent> That's also why FM is in stereo! Stereo FM is essentially two waves transmitted at the same time (it's common and difference instead of left and right, but that's math). Stereo AM would be possible, it was never done because two different AM transmissions have to be spaced further away than FM. reply Johnythree 5 hours agorootparentThere were a number of successful AM stereo broadcasting methods proposed and trialed. These were completely compatible with conventional AM transmissions. The conceptually simplest of course whas where the LSB and USB are used as separate channels. Although most of the systems did work, they were not ultimately successful simply because insufficient stereo receivers reached the market. Go search in Wikipedia on \"AM Stereo\". reply bonzini 2 hours agorootparentOf the methods listed on Wikipedia only ISB is a true AM. All the others use phase modulation for the difference signal, as an easy way to achieve compatibility with mono AM receivers; and PM is basically the integral of FM. Wikipedia says that there was basically one station doing ISB stereo; which I guess is close enough to \"nobody did it\", but not quite \"it was never done\". reply LocalH 7 hours agorootparentprevAM stereo does exist, however. https://en.wikipedia.org/wiki/AM_stereo reply wkjagt 7 hours agorootparentprevCould you make AM stereo by somehow using the two sidebands (on each side of the carrier) for left and right? reply Johnythree 5 hours agorootparentYes, this is one of the proposed methods. It's known as \"Independent Sideband\". It works, but it is a fairly expensive method to implement. reply jmts 17 hours agorootparentprevFM works better because it is easier to detect the change in frequency independently of any change in the amplitude. I'm unsure of what the correct terminology would be, but (for my linear algebra brain) you could say something like, for FM the noise dimension is orthogonal to the signal dimension, while for AM the noise and signal dimensions are the same. Therefore for FM any change in amplitude in the noise dimension should be mostly isolated from the signal dimension, while it is essentially impossible to tell what is noise and what is signal for AM - you could probably do some radio equivalent of a differential pair in order to detect noise and remove it, but then why would you bother when FM has improved noise rejection anyway. reply arnarbi 17 hours agorootparentprev> What am I missing? The tree blowing in the wind will introduce its own amplitude (brightness) fluctuations. It will be hard for you to tell which amplitude changes are signal from the source and which are noise from the tree. Edit: Looks like you answered yourself while I typed that, where you added: > Couldn't this be dealt with if you know the details of the tree's dimming ability? If the tree is moving, and you’re far enough away to resolve individual leaves (which is not unreasonable) then its “dimming ability” is constantly changing. reply treis 17 hours agorootparentprevA leaf blocking some light doesn't change the color of the light that passes through. reply JumpCrisscross 14 hours agorootparent> leaf blocking some light doesn't change the color of the light that passes through Of course it does. Real-life objects aren't perfectly opaque or transparent. Similarly, radio waves aren't blocked or received: they're mangled and self-interacted in complex ways. reply kelnos 17 hours agorootparentprevI think the idea is that the leaves don't block the entire signal. They just partially obscure it sometimes. And even if leaves do sometimes block the entire signal, you're still going to do better with varying the color than the brightness. reply JumpCrisscross 14 hours agorootparentprevLet's switch the analogy to sound. Amplitude is loudness. Frequency is pitch. You are trying to discern two sources of sound. One is a constant pitch but variable volume. The other can always blast at max volume with variable pitch. reply therein 14 hours agorootparentAlso harder to discern and then quantify the loudness of a sound or brightness of a light as a human modem but we are better and more certain of the color. We have different names for the ranges and everything. reply JumpCrisscross 14 hours agorootparent> harder to discern and then quantify the loudness of a sound or brightness of a light as a human modem but we are better and more certain of the color Fair enough, this might be a sensory artefact. In this case, however, nature had a point. Energy scales proportionally with frequency but exponentially with amplitude. Increasing amplitude delivers more bang than increasing frequency. reply irjustin 17 hours agorootparentprev> Either way you're going to notice the change. For this, it's better to stick to many leaves - the analogy holds up well here because when is the brightness change due to the number of leaves being in the way vs the source changing its brightness? reply jareklupinski 17 hours agorootparentprevif the leaves are blowing back and forth between the transmitter and the receiver, they would introduce a doppler shift into the signal of course, you shouldnt be listening to radio during a tornado, but... reply spacemanspiff01 18 hours agoparentprevThis is the best explanation I have ever heard. reply crims0n 18 hours agoparentprevWow, that is pretty clever. reply pessimizer 18 hours agoparentprevI'm stealing this. reply kazinator 13 hours agoprevFM sounds better than AM partly because frequency is more durable than amplitude, but it's not the whole story. Frequency does not diminish with the inverse square law, as does the amplitude of a wave that is broadcast in all directions. This is because frequency is related to a count of events over time. Frequency from a source light years away is intact; we can look at frequency bands from a radiating celestial body and know which chemical elements there are, and also tell exactly how fast it is moving away from us from the red shift in that spectral pattern. Be all that as it may, AM should sound great when you are close to the radio tower, and have ideal reception with no multi-path reflections, and good signal/noise ratio. It still doesn't sound good, and that simply because of the bandwidth allocated to it is low. Furthermore, AM Stereo is a retrofit and crams two channels into one via phase modulation. AM stations are separated only by 10 kHz, as you can see on your AM tuner (which you likely have only in your car, if that). The bandwidth is directly related to the audio bandwidth because modulation produces side bands. For instance, if we modulate the amplitude of a 650 kHz carrier with a 1 kHz audio tone, we get side bands of 651 kHz and 649 kHz. You see where this is going? We can only go up to 5 kHz before we bump into the next station, which also needs +/- 5 kHz for its side bands. This 5 kHz limitation is why AM radio sounds like your speakers have a heavy woolen blanket over them. It's almost as bad as the bandwidth limitation as narrow band phone calls. Listening to AM music is almost as bad as listening to on-hold music over a narrow band codec like G.711. The kicker is that only one side band is needed to reconstruct the signal, so in theory AM stations could have 10 kHz bandwith. Unfortunately, SSB was not deployed for broadcast AM, even though it was already known at the dawn of radio. (https://en.wikipedia.org/wiki/Single-sideband_modulation has a note about why) reply Johnythree 5 hours agoparentThis is a myth. There is no reason that channel spacing need limit the modulation bandwidth. The only downside is that listeners to adjacent stations will hear a slight \"monkey chatter\" from the overlapping sidebands. In reality stations are never allocated adjacent frequencies within the same coverage area so this usually doesn't happen. reply kazinator 3 hours agorootparentBe that as it may, AM radio is obviously low-pass filtered. It might not be a brick wall at 5 kHz, but it sounds obviously muffled to someone who can't hear anywhere near up to 20 kHz. If I were to guess, based on years of experience of playing with EQs, I would say that it has next to no content beyond somewhere around 8 kHz. reply wkjagt 7 hours agoparentprevIt would also be harder to tune into a station that is SSB because there's no carrier to detect. If you're slightly too high or low, the audio will have a slightly higher or lower pitch. I'm just guessing but with modern radios that wouldn't be a problem, but when AM was still used a lot I think (analog) oscillators tended to drift a bit, and you would have to adjust your radio often to correct for the changing pitch. reply YZF 12 hours agoparentprevI think we had some fairly recent discussion on HN since I remember commenting. As you're saying, it's about bandwidth and signal to noise. Not something inherent to modulation. reply kazinator 12 hours agorootparentThe modulation is important. FM is more robust against external noise than AM. reply Johnythree 5 hours agorootparentOnly while signals are strong. On weak signals however, AM has a considerable benefit in intelligibility over FM. reply kazinator 3 hours agorootparentFM stays good as the signal weakens, and then kind of drops off a cliff almost. reply brcmthrowaway 12 hours agoparentprevCan we use this fact to enable faster than light communication? reply schoen 5 hours agorootparentEven though the frequency survives the long trip, any changes in that frequency are observed only after a delay corresponding to the speed of light. Someone once pointed out that shadows (which aren't objects with a mass and position) can move fast than light, at a sufficiently large distance from their origin. That is, the location of the border between the shadowed and unshadowed region can be changing faster than light speed. But that fact can't be used to communicate faster than light, because the changes in the location of the shadow's edge still take a comparatively enormous amount of time to propagate from their source to their destination. If you're creating the shadow, you can know that one galaxy will observe the shadow long before another galaxy does, but you can't use that knowledge to signal something to one galaxy or the other without waiting for the light (or lack of light) to travel all the way to that galaxy. reply cj 12 hours agorootparentprevNot if measuring by relative speed. reply myflash13 4 hours agoprevAs a non radio engineer, reading this thread on HN is so fascinating because there are so many heated conflicting explanations for a common phenomenon in a well-established technology. I thought this simple question would be settled already. If such disagreement is possible even in an established \"hard\" science like this, then no wonder some people think everything is subjective. reply _fizz_buzz_ 2 hours agoparentThis question is of course settled. However, it has more than one aspect and I am pretty sure there are also a lot of rather amateur people chiming in here ... I am an EE, but in power electronics and not an RF engineer so I am a little bit hesitant to comment too much on it, but my understanding is that it mostly breaks down to two aspects: 1) noise interferes more with amplitude 2) the fidelity of the modulating signal in FM is higher (more bandwidth) reply aidenn0 2 hours agoprevOne thing this seems to let out is that in FM, the signal is being broadcast with constant power. A 1MW FM station is always sending 1MW of signal; with AM the signal power varies; if you broadcast in AM powerful enough to mask the noise during periods of typical signal level, then you would still hear noise during quieter than typical periods. reply ryanmcbride 31 minutes agoprevThe way I had this explained to me when I was in highschool was something like: Imagine someone is shining a flashlight at you through some trees. It's a lot easier to tell what color it is, than how bright it is. reply fguerraz 9 hours agoprev> noise tends to be a an unwanted amplitude modulation, not a frequency modulation said someone who didn't understand anything about signal processing. Been debunked so many times: https://physics.stackexchange.com/questions/94198/why-does-n... reply Optimal_Persona 18 hours agoprevAlso the audio frequency bandwidth is narrower on AM, so fewer treble frequencies. TBH I think music from up to the late '60s (especially if originally released in mono) sounds really good, or at least more \"era-appropriate\" on AM radio. I remember my grandparents tuning in to easy-listening AM stations as I grew up in the '70s and '80s, to my ear Tennessee Ernie Ford's \"16 Tons\" or a classic Phil Spector \"Wall of Sound\" production sounds more \"right\" coming through the AM bands. And, in the age of cellphone speakers and compressed MP3/Bluetooth codecs - I'm not sure how much people actually care about audio quality. reply epcoa 17 hours agoparent> And, in the age of cellphone speakers and compressed MP3/Bluetooth codecs - I'm not sure how much people actually care about audio quality Bizarre thing to say after waxing nostalgic about incredibly lo-fi bandwidth limited AM. This is also the age of $9 per month unlimited lossless 24/96 streaming and $1000+ headphone amps. reply tacticus 14 hours agorootparentthey have to justify their non newtonian vibration dampeners (blutak) and custom AC power filter used to play noisy vinyls reply Johnythree 5 hours agoparentprevThis is yet another myth: The \"Woolyness\" of AM broadcast (at least in America) is due to the stations purposefully tailoring their audio processing to suit typical cheap AM receivers. And this in turn is because designers of cheap AM receivers fit narrow filters instead of using noise reduction techniques, eg a good outside antenna. There was a period (in the rest of the world) where high quality AM receivers had a narrow/wide switch to give better audio response to stronger signals. The good news is that modern SDR receivers usually have selectable bandwidth on AM so as to derive the full transmitted audio. And many of these have AM stereo decoders as well. If you listen to a good quality AM broadcast (eg Gov AM stations in Australia) you will hear audio which are very hard to tell from FM audio. Go back and read the many high-quality AM tuner articles in the electronic hobby magazines from the past. reply kragen 17 hours agoparentprevYou can use literally any bandwidth with literally any form of radio-wave modulation. reply trq01758 11 hours agoparentprevThose codecs got better with time. Also notebook and little portable speakers, while they are unable to physically reproduce low frequencies are getting better at emulating those. Somebody cares. And here's (dunno if true as they write in the description - probably the very first stereo) studio turntable from 1958 playing a record from 1988 through Youtube's compression. I did have a lousy vinyl deck with so so speakers when growing up and this impresses me a lot: https://youtu.be/PRty-_eBEpg?si=GsrctxRbkvT3xRAV reply kaoD 7 hours agorootparentWhat does \"emulating low frequencies\" mean? reply trq01758 6 hours agorootparentIt may be impossible for a little speaker to produce any sound at some low frequency, so manufacturers use \"virtual pitch\" psychoacoustic phenomenon by introducing harmonics above that frequency. There is no low bass, but there will be added harmonics that will be perceived by the listeners as low bass: https://sound.stackexchange.com/questions/37755/how-do-psych... Here's also a project and some info from Asahi devs on Macbook audio: https://github.com/AsahiLinux/asahi-audio reply Johnythree 5 hours agorootparentIs commonly known as \"Bass Boost\". As the OP has said, it cannot give louder bass, but simulates the bass harmonics. reply userbinator 8 hours agoparentprevTBH I think music from up to the late '60s (especially if originally released in mono) sounds really good, or at least more \"era-appropriate\" on AM radio. That music also sounds more era-appropriate coming from a vinyl record than a CD. reply duped 14 hours agoparentprevLook, I'm an audio snob and will talk shit about terrible design of BT headsets that halve bandwidth in duplex until the cows come home. But the reason that codecs have survived this long without substantial changes is because they're far and away good enough (*) for the vast majority of listeners. To the point where today, even trained listeners can't perceive a difference in audio quality between lossless and lossy encoded audio at high enough bit rates (which is 320kbps MP3, or comparable AAC which can be as low as 50% of that). (*) what we don't talk about is the latency of the codec itself, where regardless of available compute resources is still atrocious outside of proprietary codecs. While a listener cannot perceive noticeable differences in fidelity, they can perceive the delay, and this is a problem that doesn't have good solutions outside of specialized equipment today, although OPUS (as a descendant of CELT) is pretty darn good for the cases that consumers care about. Professionals still spend oodles of money on the proprietary gear that have codecs that not even ffmpeg supports. I would go so far as to say there is no practical benefit to uncompressed audio today at all. Lossy is fine for all consumers, and lossless encoding is faster to decode and playback (as well as encode and write) while using less disk/bandwidth than uncompressed for archival purposes. reply pseudosaid 13 hours agoparentprevits a big difference. The frequency range for AM radio is 540 to 1600 kHz vs 30hz-15khz Bass and fundamental frequencies really contribute to fidelity reply getnormality 5 hours agoprevDeeper explanations for those who aren't satisfied: https://physics.stackexchange.com/questions/94198/why-does-n... https://ham.stackexchange.com/questions/6312/why-are-fm-radi... reply fanf2 14 hours agoprevSome more about FM at http://www.theradiohistorian.org/fm/fm.html — https://news.ycombinator.com/item?id=41471355 « FM signals were much more immune to interference than AM due to its “capture effect” – an interfering signal needed to be more than 50% the strength of the desired signal to cause audible interference, compared to 5% or less with AM. This characteristic would considerably reduce the required separation between stations occupying the same channel and allow more channel re-use, which compensated for its greater occupied bandwidth. And most importantly, because all natural and man-made static is amplitude modulated, FM proved to be amazingly noise-free. Armstrong improved its resistance to noise still further by incorporating a new receiver component – a limiter that stripped off the amplitude variations in the received signal before it reached the detector. He had finally solved the problem of static interference that had confounded radio experts since the beginnings of the art. » reply Animats 16 hours agoprevIt's quite possible to have wideband AM radio. Some radio stations did it in the US before the FCC standardized bandwidth and started checking envelopes. Radio Caroline, the UK offshore pirate station (1964-1968), was wideband AM. Noise on AM can to some extent be overcome with power and a low modulation percentage. That's how analog broadcast TV worked. (Broadcast TV was AM video, FM audio.) The black level for the video signal was well above zero. A high black level allowed showing black areas without excessive noise. About 80% of the RF power went into the carrier because of that. Simple, but inefficient. The same trick can be done with AM audio radio, although it seems that's not done much. reply BoxOfRain 8 hours agoparentRadio Caroline would be such a good HN topic in its own right. Peter Chicago's name in particular should be up there in hacker lore for some of the things he did to keep Caroline on the air. reply ml_comms_eng 3 hours agoprevThere are many differences that explain why one can be better. All else being equal: - bandwidth of modulated signal: it is better to spread the signal over a large bandwidth => Nlog(1+snr) > log(1+Nsnr). the bandwidth used by the FM signal is larger - wasted energy on the DC signal: AM signal is A + s(t) where A > abs(s(t)) to make sure the sent signal is always positive. A (DC) does not carry information so the effective signal to noise ratio of a DC-less signal should be higher (phase/frequency modulation, signalling that can detect the negative part...) - filtering of baseband signal => if you filter too much the original signal, you lose information even before transmission. Voice is usually filtered and 4KHz, but music needs more. FM has more margin (more allocated bandwidth) so can have less stringent filters - tolerance to fading: the wireless channel is not AWGN, it is frequency dependent due to multipath. While radio signals are relatively narrow, signal modulated in frequency are more robust to fading (OFDM...) reply S_A_P 18 hours agoprevLightning is a great example of noise causing amplitude changes and not frequency changes. That’s why during a thunderstorm am radio plays each strike between the station and you. The is usually not any indication of lightning strikes on FM. reply drmpeg 12 hours agoprevHere's some SDR generated AM with 15 kHz audio bandwidth. Also shows why SSB isn't used for music broadcast. https://www.w6rz.net/am.mp4 reply Aloha 4 hours agoparentNeeded an emphasis curve applied to it. reply gpderetta 1 hour agoprevYet many (if not all?) digital wireless protocols use some form QAM. reply jdthedisciple 59 minutes agoparentPresumably because there's very little additive white noise inside copper wires reply tsurba 8 hours agoprevThe article kinda sucks as it does not really answer the question it poses. Why ”noise tends to be a an unwanted amplitude modulation, not a frequency modulation”? Is it due to naturally occurring background noise being low frequency high amplitude, showing up as AM? Could the situation change if humans keep generating more high-frequency noise? Or is it just that high frequencies do not travel as far so there will always be relatively little? reply davekeck 18 hours agoprevI always assumed it was because FM station bandwidths (200kHz) are much wider than AM (10kHz). AM's 10 kHz chops off a lot of human-hearable frequencies. reply ndndjdjdn 18 hours agoparentAM doesn't use the frequency for modulation though so it shouldn't matter. reply kragen 17 hours agorootparentWhen you amplitude-modulate a carrier wave with an audio signal, you spread it out into a bunch of sum and difference frequencies, as you can see if you use the trigonometric angle-sum formula to factor cos(85000·2πt) · (2 + cos(440·2πt)), a 440-hertz flute being transmitted on 85-kilohertz AM. These so-called \"sidebands\" mean that the bandwidth of AM does matter, and consequently, using a too-narrow bandpass filter on your AM radio station will result in low-pass filtering your demodulated audio signal. reply t-3 17 hours agorootparentprevAM does use the frequency, it just doesn't need as much and uses it differently than FM. If it was all at a single frequency, there just be a single tone getting louder and softer. reply ndndjdjdn 17 hours agorootparentThanks. I just learned that doing a rabbit hole about sidebands! Still getting my head around it. reply YZF 12 hours agorootparentOnce you change the amplitude of a sine wave (modulate it) it's no longer a side wave. It spreads in the frequency domain. Take the fourier transform of that and you can see the frequency components. reply KK7NIL 11 hours agorootparentprevOther comments gave a nice explanation of why AM does need a bandwidth, but here's the information theory explanation: https://en.m.wikipedia.org/wiki/Shannon%E2%80%93Hartley_theo... TL;DR: the information one can reliably send through a noisy channel (C) is proportional to the bandwidth of that channel. reply wruza 7 hours agoprevBecause noise is in line with AM and perpendicular to FM? Let’s read if that’s still so. Armstrong reasoned that the effect of random noise is primarily to amplitude-modulate the carrier without consistently producing frequency derivations. …It doesn’t talk much about the noise physics, but basically yes. reply massysett 18 hours agoprevWhat I’ve never understood is how the FM receiver can lock on to the signal if its frequency is always changing. Doesn’t the receiver need to lock on to something? If the answer is “it locks on to the amplitude, which doesn’t change,” well AM is bad because the amplitude is subject to interference, so wouldn’t FM have the same problem? reply jasonjayr 17 hours agoparentHaving recently purchased a RTL-SDR and watched and learned about FM -- there is \"pilot\" frequency that doesn't change and is fixed relative to the tuner frequency. See this chart here: https://en.wikipedia.org/wiki/FM_broadcasting#/media/File:RD... Each radio station has 100khz of bandwidth centered on it's tuner frequency. in the, there are channel spacing rules that give some gaps +/- another 100khz of that. (That's why in the US, radio stations are typically on 'odd' decimals, ie 92.3 mhz, 94.1 mhz, etc) That chart does not show HD radio frequencies, which due to those spacing rules, and more accurate transmitters, are on the +/- 100khz spaces along side the original analog 100khz. You can \"see\" the audio modulating the frequency on the spectrogram. But the OFDM digital signal on either side looks like a band of more intense noise. It's mind blowing to realize there's a signal in that! reply lrasinen 12 hours agorootparentThe pilot is there for stereo decoding, it has nothing to do with the ability to tune to an FM station. https://wiki.analog.com/university/courses/electronics/elect... has some of the analog approaches collected. reply jasonjayr 8 hours agorootparentYou're right -- after reading some of the peer responses, I realized that (I think...) my response is just how the Broadcast FM signal modulates the parts of the signal, and not how it actually 'locks on'. I'm still learning! reply lrasinen 8 hours agorootparentI got an RTL-SDR this summer and brushed up my DSP skills playing with FM signals. PLLs are marvellous beasts; you can do a slapdash job in \"designing\" one and it'll still probably lock on just fine. Might not be optimal but will still lock. Another fun one, when you have IQ samples, is the polar discriminator: calculate x[t] * x*[t-1] where x* is the complex conjugate, and take the angle with arctan. Feels a bit like magic (\"is that all?\") but is justified by the theory. reply analog31 18 hours agoparentprevOne possibility is a phase-locked loop. I don't know if there's anything better. It matches the frequency of a voltage controlled oscillator to the frequency of the incoming signal by detecting the phase mismatch. Then, the control voltage for the VCO becomes the audio signal. reply rnhmjoj 13 hours agorootparentI don't think radios use a PLL to demodulate the FM audio: the signal has a huge \"pilot\" tone at 19kHz that you can match to get the first part of the spectrum, mono audio (L+R channels), and at double that frequency you know you'll find the stereo part (L-R channels). Precise phase estimation is only necessary to decode the RDS digital data (station name, datetime, etc.). reply lrasinen 12 hours agorootparentThey do. First of all, the pilot is only required for decoding stereo and RDS. Mono FM does not use a pilot, so obviously there had to be a way to detect FM before stereo came along. I linked to a few of the approaches in a sibling (cousin?) comment. Second, the pilot is embedded in the decoded FM audio. You need to demodulate FM to get to it in the first place. If you look at the waterfall display in an SDR receiver, it might seem like the signal is already present in the original radio frequencies (especially during silent periods), but it's there only indirectly. If you have silence in an FM transmission (say 96.6 MHz), the only audio component present is the 19 kHz pilot signal, which causes the FM radio signal frequency to vary between 96.6 MHz ± k*19 kHz (not sure what's the value for k, but it's not 1). The sine likes to spend most of the time near the extreme values of its range; plot a histogram of a sine wave and you'll see peaks on either end. The waterfall is basically a histogram over frequencies so it gets those peaks as streaks on both sides of the main carrier frequency (plus smaller ones for other components in the signal). reply Johnythree 5 hours agorootparentprevMost cheap FM receivers definitely use a PLL to detect FM. Giving automatic tuning is just a side benifit. reply kmbfjr 6 hours agorootparentprevIt is not “huge”, it is no more than 10 percent and no less than 8 percent of the total modulation. reply kragen 17 hours agoparentprevDisclaimer: I don't really know any of this stuff, and I've never built a radio. I'm just repeating what I've read, or in some cases, simulated in software. The simplest answer is that you use a narrowband bandpass filter around the transmitting station's center frequency to eliminate the signals from other radio stations, just as you do for AM radio, and then you measure the frequency of the remaining signal instead of its amplitude. This works because the frequency deviations are small compared to the spacing between the frequencies on which different stations are transmitting. Downconverting to an intermediate frequency by mixing with a local oscillator, as CodeBeater correctly said most FM receivers do, doesn't really alter this fundamental principle, although it does alter the details. (Most current AM radios are also superheterodyne designs.) Most current FM radios use a phase-locked loop, as analog31 correctly said, which is sort of the same but sort of different; it gives better results. A PLL uses a much narrower bandpass filter which is centered on, not the nominal center frequency of the radio station, but the instantaneous, modulated frequency, which makes it much better at rejecting interference than the simpler approach. So the frequency band you're filtering down to gets swept back and forth in real time, thousands of times a second, to follow the FM signal. There's the question of how your PLL can initially achieve its lock if its passband is so narrow, of course. I don't know how mainstream FM radio does this, but it's not as hard a problem as you might think; because broadcast FM radio's frequency is always oscillating back and forth around its nominal center frequency, you can just wait for the audio signal to cross zero. Alternatively, you can sweep the PLL's local oscillator frequency over the band until you achieve a lock. I hope this is helpful! reply Johnythree 5 hours agoparentprevMost FM receivers can lock on the carrier because they have a \"Phase locked loop\" to cancel any tuning errors. Many good AM receivers do exactly the same thing, especially those receivers which have \"Synchronous Detectors\" for AM. It's just that the circuitry involved is simple for FM, but rather more complex for AM. reply jedimastert 17 hours agoparentprevI'm actually studying for my general ham radio license right now! Most FM receivers use something called a \"mixer\" to modulate the frequency to a known constant, then they use a circuit called a \"discriminator\" or \"quadrature\", both of which are \"detectors\". Typically they're not measuring the frequency or phase itself, but rather the change in frequency or phase. Edit: I should note that's only for analog circuits. DSP is also common. reply CodeBeater 17 hours agoparentprevMost FM receivers nowadays rely on creating a signal of a specific frequency that interferes with the desired on-dial frequency, this is called an intermediate frequency. Then the actual audio signal is analogous to the changes on that IF. This technique is known as superheterodyne, and Technology Connections has a wonderful video explaining it better than I can. reply rileymat2 9 hours agoparentprevIt locks into the range where the number on your dial is the center of the range, then listens over the whole range. The range does not change. reply thadk 13 hours agoprevThis short piece reminds me of a thread about the The Hedgehog and the Fox essay (1953) https://twitter.com/strangeattracto/status/13506001425970544... > The idea of code switching between multiple traditions doesn’t seem to occur to a person who is fixated on The One True Aesthetic. reply dumbo-octopus 17 hours agoprevBetter is in the ears of the beholder. Personally I prefer AM because I can hear multiple stations at once, and hear sources of wideband EM interference in my environment. reply bigfishrunning 5 hours agoparentI think this article is focussed on broadcast radio, where crosstalk and em interference are both considered negative properties (not that they're not useful in other applications) reply asdefghyk 14 hours agoprevbecause the FM system provides a wider audio bandwidth signal than the audio signal bandwidth provided by AM reply Johnythree 5 hours agoparentIt doesn't. In both it depends on what the stations engineer chooses to transmit. reply elahieh 17 hours agoprevIt's certainly perceived that way. \"Diff'rent Strokes\" \"Baseball Blues\", 1985... Willis does mention stereo is part of the appeal. - Now, Dad, you gotta picture me cruising along in my Mercedes. Head held high. Rocking to the FM stereo. Waving to the chicks. Hey there, mama, looking good. Catch you later, baby. (making engine noises) - You can do all of that in a $4,000 car. (imitating brakes squealing) - Dad, for $4,000 I'll have to slouch way down in my seat so no one can see me. And turn on my AM radio. Wave at the chicks. Hi there, mama, you're looking quite adequate. Chug, chug, chug. - That's just fine, son, chug chug chug means that you won't be spending any of your days in traffic court. - Or any of my nights at a drive-in movie. - Willis, you don't want to date a girl who only likes you for your car. - Sure I do. reply brudgers 13 hours agoprevAnd because FM broadcast radio caps audio at 15KHz, a CD “sounds better” than FM…yes, back in the day am SM57 was often good enough. reply tzs 6 hours agoparent…if you are young enough. By somewhere around 25 to 30 most people won’t be able to hear above 15 KHz. I’m a little surprised I’ve not seen audio equipment specifically for older people that just covers what they can hear. reply johndavid9991 18 hours agoprevI grew up listening to the radio and was always curious why FM indeed sounds cleaner than AM. My assumption before is that it's setup that way since FM is intended for music stations. reply dylan604 18 hours agoparentBefore FM, all music stations were on AM. reply timeon 18 hours agoparentprevI had AM associated with international broadcast while FM with local one. reply geocrasher 3 hours agoprevBandwidth. reply shsbdksn 17 hours agoprevI always thought about it as I can arbitrarily amplify and saturate the FM signal without changing it. reply twwwt 12 hours agoprevDefine \"sound better\", please. As we all know this is something subjective - mostly everyone has individual preferences. I would have found it better if the title was \"Why is frequency stable in spacetime and amplitude not (which can be verified so easily by listening to audio radio)\". reply analog31 6 hours agoparentThe most familiar definition, though not spelled out in the article, is audio fidelity which is the degree to which the output reproduces the input. It's fair to take this definition as a default, or implied by the article. In this specific case, frequency response and signal-to-noise are both fidelity measures. Also, some of the comments did a better job than the article of explaining things. reply ginko 4 hours agoprevKinda funny to see people argue AM vs FM when much of the world has already switched to DAB. reply josefritzishere 4 hours agoprevBack in 2005-ish a Clearchannel enginer, Littlejohn proposed narrowing bandwidth of Am stations to improve the signal to noise ratio. They implemented a 5 Khz bandwidth. Back in the 70s we were all blasting 12 kHz. While that's probably OK-ish for talk, it's dreadful for music. https://www.radioworld.com/columns-and-views/the-5-khz-am-re... reply Aloha 4 hours agoparent12 kHz AM on a good receiver sounds absolutely fantastic. I have a Royal 51/810 (one of each) that I use as a travel/bathroom radio, ironically, both have fantastic AM performance, and.. lacking FM - the IF/Audio bandwidth appears twice as wide on AM, and FM just sounds like crunchy - probably needs caps in the audio section, but its so tightly packed, and has a PCB with the heaviest plating I've ever seen - which means it needs work I cannot easily do. reply josefritzishere 3 hours agorootparentIs it packed too tight for a solder sucker to get in there? reply guidedlight 18 hours agoprevNo need to read the article. It’s literally in the name. AM = Amplitude Modulation FM = Frequency Modulation Obviously environmental factors can affect the amplitude of a radio signal. But environmental factors are less likely to affect the frequency. reply kelnos 17 hours agoparent> Obviously environmental factors can affect the amplitude of a radio signal. But environmental factors are less likely to affect the frequency. I don't think that's \"obvious\" to most people. reply zekica 6 hours agorootparentAnd it's not correct. Resulting frequency due to random noise is also changed, but in FM, noise is less perceivable. There is no such thing as \"affecting amplitude\" and \"affecting frequency\" - they are not separate concepts. reply chasil 18 hours agoparentprevFM spends bandwidth to reduce noise. reply dmitrygr 18 hours agoprevThis is 100% nonsense. Phase noise exists too, not just amplitude noise. The answer is actually rather simple. AM stations are limited to 10KHz band width. FM gets 200KHz. More bandwidth allows representing a higher fidelity signal… reply Stratoscope 18 hours agoparentYes, this is the right answer, although I would correct the numbers a bit. If we look only at the audio bandwidth, AM stations are limited to 5 kHz of audio spectrum. The 10 kHz figure comes from the fact that AM is double sideband modulation (as opposed to single sideband as used in ham radio and other radio services). So the broadcast signal uses twice the bandwidth of the audio. FM stations have 15 kHz of audio bandwidth, three times that of AM. They are able to do this because they transmit at a much higher frequency. The 200 kHz figure includes other things like stereo (two channels of audio), subcarriers for RDS data and such, and the \"Carson bandwidth rule\" that 'basementcat' mentioned. I am surprised that the article overlooked this simple and obvious explanation. reply nullc 11 hours agorootparentWFM in mono without RDS is still ~200kHz wide, the width isn't primarily a product of the extra signals, it's a product of the modulation index. reply basementcat 18 hours agoparentprevIt’s more than that. FM is several times less spectrum efficient than AM and needs more bandwidth to transmit the same information. https://en.m.wikipedia.org/wiki/Carson_bandwidth_rule reply IX-103 17 hours agorootparentYou provided a citation, but it doesn't prove your point. In general frequency modulation is more efficient than amplitude modulation (but requires more complicated receivers). For example GMSK in the 2G standard GSM replaced the less efficient 1G AMPS system which used amplitude modulation. reply crackalamoo 18 hours agoparentprevYes, phase noise exists, but I would think that in practice amplitude noise is greater. In physics, when a wave passes from one medium to another, its frequency is supposed to stay the same. Even if this isn't perfectly true in the real world, I would think amplitude is more likely to decrease due to obstacles, distance, and the medium absorbing some energy. reply 317070 14 hours agorootparentBut the two are the same thing. You took the fourier transform of white noise and find white noise, both real (amplitude noise) as complex (phase noise). You can think of it like this: the noise is not about the phase changing, it is about your ability to tell what the phase is. The noisier the signal gets, the harder time you will have to tell what the amplitude is, as well as what the phase is. reply IX-103 17 hours agorootparentprevIf the noise is white gaussian noise (AWGN) then the phase noise is essentially the same as the amplitude noise (by the properties of the Fourier Transform). Also, the information in AM is carried by the relative amplitude of the signal. Flat attenuation like you're describing doesn't really distort the AM signal. What does impact both AM and FM is frequency selectivity. Imagine light traveling through a prism and being split by frequency. If there are obstacles in the way, some colors won't pass through as well. The is can cause distortions in FM as the receiver loses lock on the signal. Am suffers from this too, but people are less likely to notice because they're used to these distortions -- these kind of effects happen with sound too. As other posters have mentioned, the reason FM sounds better is that it has more bandwidth for the signal. reply crackalamoo 17 hours agorootparentVery interesting, I'll have to look into AWGN and the Fourier transform. I guess in the trees blocking the flashlight example that's not at all AWGN. Although while we care about the relative amplitudes in AM, AWGN would make this harder to pick out if the signal is attenuated. Is the same idea true for frequencies? I don't see a direct parallel here. reply kragen 17 hours agorootparentYou do get some frequency deviation from AWGN. The sum of equal-amplitude 100Hz and 120Hz sine waves is a 110Hz sine wave that \"beats\", which is to say, is amplitude-modulated, at 10 Hz (or 20Hz from a certain point of view). So, if you have a 120Hz signal and you add a 100Hz signal to it, you should expect that to deviate the frequency of the detected signal downwards. AWGN will have varying, random amounts of all frequencies in it, which will cause varying, random amounts of frequency deviation as they add to your signal. It's definitely easier to understand in the Fourier domain. reply kragen 17 hours agoparentprevIt's not 100% nonsense, though it's true that phase noise does exist. FM radio can transmit silence, which gives it a better dynamic range, which is important for music. If your AM radio signal is 10dB stronger than the radio noise in the band, you'll get noise in the demodulated signal only 10dB quieter than the signal. Due to the so-called \"capture effect\" https://en.wikipedia.org/wiki/Capture_effect the effect on an FM-demodulated radio signal is potentially much less—though it's true that, with narrowband FM, it won't be. That's why commercial FM broadcasting uses a ±75kHz deviation even though it was originally only transmitting audio of ≤20kHz. Adding all this extra bandwidth to an AM station wouldn't actually help, because beyond ±20kHz, you're only improving your radio station's ability to reproduce ultrasound. But it does help FM; it greatly reduces the amplitude of demodulated noise, because, even without a PLL, the frequency deviation caused by additive white noise increases much more slowly with bandwidth than the frequency deviation you can use for your signal. With a PLL, I think the frequency deviation caused by additive white noise basically doesn't increase at all with bandwidth. (I guess I should simulate this; it should be pretty easy.) Unfortunately neither Cook's article nor the flashlight analogy explains any of this. reply bdjsiqoocwk 17 hours agoprevI guess the crux here is the claim that \"the effect of random noise is to amplitude modulate\". Does anyone here understand why? Ps I don't think analogies are helpful. reply jmts 17 hours agoparentAM reception is essentially the direct conversion of the strength (amplitude) of a given radio frequency into an audio signal. Any other noise present at the same frequency is added to the signal (superposition/interference) and therefore impacts the strength of that frequency at the receiver. Therefore it is impossible for the receiver to know whether the amplitude it received is just signal or is signal plus noise. The claim 'the effect of random noise is to amplitude modulate' is probably not 100% correct, because to my understanding it's not actually performing modulation (the modulation happens at the transmitter but the noise happens between the transmitter and receiver), but it is impacting the amplitude at a given frequency and to a receiver this is impossible to know whether said change in amplitude happened before modulation (signal) or after modulation (noise). reply raverbashing 12 hours agoprevThere's actually one important factor that's missing: AM radio is limited in bandwidth. The audio is cutting off around 10kHz or such (that's why it kinda sounds like a telephone) > To allow room for more stations on the mediumwave broadcast band in the United States, in June 1989 the FCC adopted a National Radio Systems Committee (NRSC) standard that limited maximum transmitted audio bandwidth to 10.2 kHz, limiting occupied bandwidth to 20.4 kHz (from Wikipedia) reply usr1106",
    "originSummary": [
      "FM radio is superior to AM radio in terms of sound quality because it is less susceptible to noise interference.- FM operates by varying frequency, whereas AM varies amplitude, making FM less affected by noise, which primarily impacts amplitude.- Edwin Howard Armstrong, the inventor of FM, anticipated that FM would reduce noise, a significant advantage over AM systems that struggle to eliminate noise without message loss."
    ],
    "commentSummary": [
      "FM radio offers superior audio fidelity compared to AM due to its higher bandwidth, with channels spaced 200 kHz apart versus AM's 9 kHz.",
      "FM is less prone to noise interference because it encodes information through frequency variations, making it more resistant to static and amplitude-based noise.",
      "The higher frequency band of FM avoids low-frequency noise, such as that from thunderstorms, resulting in clearer sound quality, particularly for music."
    ],
    "points": 222,
    "commentCount": 235,
    "retryCount": 0,
    "time": 1728858743
  },
  {
    "id": 41833198,
    "title": "A VSCode Extension to edit HTML visually in real-time",
    "originLink": "https://github.com/urin/vscode-web-visual-editor",
    "originBody": "Web Visual Editor Edit HTML files visually in real-time. ✨ Features 🖼 Visual Editing: Edit HTML elements visually within the WebView. ⏱ Real-Time Preview: See changes reflected instantly as you edit. 🧩 Integrated with Visual Studio Code: No additional processes and windows and well-integrated with VSCode theme. 📋 Functions 🖱 Element Selection: Select HTML elements with ease. Visual selections are synchronized with text selections on editor. 🔍 Zoom in and out: Zoom in and out the page. ↕ Move Elements: Drag elements to rearrange their position. ↹ Align Elements: Easy to align elements. ✂ Copy, Cut and Paste elements: Copy or cut elements, paste text into selected element. 🔒 Script and Link Management: Disable scripts and manage links for security. Alternatives This extension is similar to microsoft/vscode-livepreview and it differs in the following points: The ability to synchronize code selection with visual selection in the preview. Since Web Visual Editor has minimal functionality, the codebase is very small, making future expansions easy. It is designed to reflect changes made in the preview back to the code, so enhancing the editing capabilities within the preview may be beneficial in the future. For example, you can copy, cut, paste and delete elements within preview at this moment. 📜 License MIT License 💛 Sponsor Empower my motivation brewing and accelerate development by buying me a coffee!",
    "commentLink": "https://news.ycombinator.com/item?id=41833198",
    "commentBody": "A VSCode Extension to edit HTML visually in real-time (github.com/urin)200 points by urin 17 hours agohidepastfavorite111 comments jayflux 10 hours agoNice extension, it may be worth in the readme explaining how it’s different to https://github.com/microsoft/vscode-livepreview which has been around for a long time and maintained by Microsoft. reply anoncow 1 hour agoparentI thought of MS Frontpage for a very brief moment as I was clicking the link to Live Preview. reply urin 10 hours agoparentprevI have updated the README to address similar comments and issues. https://github.com/urin/vscode-web-visual-editor?tab=readme-... reply politelemon 8 hours agorootparentThanks, good work on this extension. reply braggerxyz 5 hours agoparentprevBecause of the debacle around VSCode extensions owned by Microsoft that recently surfaced here on HN, it's good to have an alternative. reply makestuff 5 hours agorootparentDo you have a link? Curious to know what the concerns were. reply ensignavenger 3 hours agorootparentMany of Microsoft's extensions are closed source. This one does not appear to be, but MS has been known to replace open source VS Code extensions with closed source ones in the past. reply qwertox 10 hours agoparentprevI think it's mainly the `No additional processes` point. Live Preview serves the page, likely by spawning another process to host the server. reply asdf000333 1 hour agoprevI like putting an auto-reloading browser window behind a 60% opacity Vim window. reply romulobribeiro 16 minutes agoparenthow do you set it up? reply asdf000333 12 minutes agorootparentI didn't go out of my way to make this work, so I don't know the general approach. The terminal is iTerm2, but the basic Mac terminal or common Linux ones can do opacity too. Auto-reload is a common feature in various web frameworks like create-react-app, which I'm guessing comes from some more barebones tooling you can use (watchify?) if you aren't using React. reply butz 3 hours agoprevI was expecting something more like WYSIWYG editor, that actually edits HTML visually in real-time. Something akin to old times of first webpage editors. reply gduplessy 2 hours agoparentHah yeah, I was picturing Dreamweaver before I clicked the link reply greybox 7 hours agoprevThis is great, A tighter feedback loop is always better for everyone. I'm also getting some serious Déjà vu for the web tools of the 2000's. History really does rhyme reply mg 13 hours agoprevI like to use standalone tools with no dependencies, so I made this open source html editor with instant preview as a single html page: https://github.com/no-gravity/html_editor It has a few convenience functions already. Open for pull requests. reply whoisthisguy 5 hours agoprevreminds me of good old Macromedia DreamWeaver times :) reply jdthedisciple 1 hour agoprevVery unfortunate naming if you understand some German... reply vivzkestrel 15 hours agoprevAre we trying to reinvent web development? Last few years have been wild. We abandoned HTML CSS and JS websites that used to work just fine and ran after frontend component frameworks and now the circle is getting completed by building tools and extensions we had 20 yrs ago reply stevage 12 hours agoparent>We abandoned HTML CSS and JS websites that used to work just fine Hmm. Have you actually done much web development in the last 10 years? Building websites with raw HTML, CSS and JS 10 years ago was very much not \"just fine\". There's a reason frameworks were invented. reply bugtodiffer 11 hours agorootparentOh I think it is very much \"just fine\", but people have requirements which make things too complicated. I find it way harder to work in a React app than a few .html and .js files. TypeScript's cool though. reply nicoburns 9 hours agorootparentMost people working professionally as web developers have limited ability to reduce the requirements and have to implement what their company ask for. At that point having something to manage the complexity is much better than not. reply pjmlp 4 hours agorootparentprevThe reason being CV driven development in most cases. For the large part of projects I work on, plain old server side rendering with sprinkles of vanila.js work just fine. At least folks now rediscovered SSG, but they seem to build rewriting bundlers in Rust as well. reply evilduck 4 hours agorootparent> sprinkles of vanila.js work just fine. Bullshit. jQuery as a library didn't inherently cause spaghetti code, it was predominantly just used as a cross-browser selector function and some standard library augmentation/fixes before JS itself caught up. Sprinkles of progressive enhancement jQuery were exactly the problem that caused frameworks to be created. Sprinkles of vanilla JS lead to the exact same outcome, minus a jQuery library load. reply pjmlp 3 hours agorootparentWhatever dude, we're doing ASP.NET MVC and Spring/Jakarta with vanilla.js just fine, go improve that CV. reply enraged_camel 2 hours agorootparentHow long have you guys been around? How large/old is the codebase? How many members are on your team? reply pjmlp 59 minutes agorootparentWe have been around since decades, being hired guns for Fortune 500 consulting. Codebases are as old, or as new, as customers require for their business cases. reply oneeyedpigeon 11 hours agorootparentprevWhat do you consider \"not fine\" about websites written in \"just\" html, CSS, and js? reply 0xFACEFEED 11 hours agorootparent1) Rats nest of non-declarative JavaScript. 2) Rats nest of JavaScript callbacks. 3) Overlapping stylesheets with !important everywhere. 4) Elements used for style not their semantic purpose (, ) 5) Subtle and not-so-subtle browser compatibility issues. reply bugtodiffer 11 hours agorootparent5) is the only valid reason, the rest has comparable alternative shitty things when using whatever framework reply 0xFACEFEED 11 hours agorootparentNo amount of discipline was going to make medium-large websites maintainable back then. Today it's actually possible if the creators know what they're doing. Tooling isn't going to prevent people from doing stupid things. reply netdevnet 10 hours agorootparentprevI agree with HTML+CSS+JS websites being not fine. But to be honest, js callbacks are more of a language thing than a framework thing. You don't need to use frameworks to write promises. reply netdevnet 10 hours agorootparentprevYou can't reuse pieces of UI functionality (a bundle of specific html, css and js) unless did copypasta which is obviously awful. Sharing business logic across different areas of an application becomes much harder and you can't non-trivially write and run tests across areas of your application because you are just using html,css and js. And the big monster: state. Sharing state safely across different areas of an application becomes much harder. You end up writing your own micro framework trying to make all the above work. At that point you might as well use as existing battle-tested one reply oneeyedpigeon 9 hours agorootparentSo, instead of \"Building websites...\", would it be fairer to say \"Building some types of web app...\"? reply stevage 5 hours agorootparentprevUsing them was fine. but developing them, no. It's way more work just managing event handlers for a start. reply rty32 8 hours agorootparentprevThis. A not so great analogy is you can always drop a single php file into your /var/www/ (or even do cgi) and get your \"dynamic\" website running like decades ago, but people don't do that any more for any website that is not a tiny one with just a few pages (barring famous exceptions like WordPress). People realize there are good reasons to use frameworks, and often, use other languages for website backend. reply netdevnet 10 hours agoparentprevLet's be honest. Those old HTML+CSS+JS didn't have the interaction levels of modern applications. And jQuery was great until you reached a level of complexity after which it became jquery Bolognese. There are 2 main challenges: state and reusing pieces of html. Both of these are much harder in modern applications due to their complexity. Try reusing a piece of HTML using HTML+CSS+JS alone (no Node or back-end tools allowed). Try keeping state synced across a modern application without using state management libraries. reply jeroenhd 7 hours agorootparentMost \"applications\" I visit in my browser have no business being an application. The \"clear search history\" button in my start menu has no business loading a React environment with three redirects either. Some web applications need a boatload of frontend stuff to make them usable, but I rarely encounter websites that warrant such overkill. A payslip/email subscription/car rental website with a profile page and maybe three forms I can possibly need to submit doesn't need to be a fully interactive application with loading bars and offline support, leave that stuff for the websites I visit more than once a month. At this point React/Vue/Svelte devs are probably cheaper to hire than basic JS devs, but technology wise the amount of Javascript my browser needs to load for the most basic interactions is mind-boggling. More than the \"this meeting could've been an email\" meetings, I run into \"this web application could've been a POST request\" web pages. reply worewood 5 hours agorootparentI have to second this, 100%. Not everybody is developing the next Canva or the next Google Docs. To me it sounds like people trying to justify that what they do has some higher value than what it really does. reply asdf000333 1 hour agoparentprevI'm not a frontend dev, but React (w/ JSX, and w/o Redux or whatever) is the only web thing I've ever used that made sense. Everything else like CSS, Angular, jquery, and even some HTML features made me go \"wtf\" as an uneducated user. reply phero_cnstrcts 13 hours agoparentprevTailwind is reviving the style attribute. reply 1propionyl 11 hours agorootparentI've taken the next step and written my own tool that lets me put all my Tailwind attributes in a separate file grouped by element selectors. :-) reply gavmor 3 hours agoparentprevNah, I went from jquery to Backbone, Angular, and React. I don't miss jquery, and I like the functional/declarative APIs of JSX. It's a lot like just writing HTML, and CSS, and I still write plenty of JS as pure functions or plain objects, and they're lovely to test. I don't really see the purpose of the OP when I have vite and subsecond rerenders. reply urin 14 hours agoparentprevThere are complex reasons behind my development of this. To be honest, I don’t think the editing functionality of this tool is particularly useful. I believe the real-time preview and element selection features are the ones that offer broader utility. I am considering making the editing feature disabled by default and allowing it to be enabled through settings in the future. reply pjerem 13 hours agorootparentI don’t think it was meant to criticize your work :) It’s just fun to see that we (here : you) are reinventing tools that everyone used 20 or 30 years ago. I remember making my first websites in Dreamweaver. I remember it being hated by \"pro\" developers but this plus an FTP client (which was integrated IIRC) was enough for teenager me to be live on the internet. reply a57721 13 hours agorootparentThe nostalgia hit me, I remember before Dreamweaver, there was Netscape Composer, W3C Amaya, and similar software. reply darreninthenet 12 hours agorootparentprevHow is Dreamweaver these days? reply captn3m0 11 hours agorootparentpart of creative cloud, $20/mo. Last update May 2024 https://helpx.adobe.com/dreamweaver/using/whats-new.html reply hashtag-til 10 hours agorootparentprevI came here to comment about Macromedia Dreamweaver (at the time I used it). It was an ok software for the time. Acceptable WYSIWYG. reply kak3a 1 hour agorootparentprevBring FrontPage back! ;) reply pjmlp 12 hours agoparentprevAnd what is more crazy, acting as if they are something new, instead of something that is 20 years old. reply robertlagrant 3 hours agorootparentNo one's doing this, or at least not in the way you're implying. reply urin 9 hours agoprevIt seems there have been many opinions questioning why a tool for editing pure HTML is being developed now. Here is my current view on this matter: These days, it's rare to directly handle HTML files on the frontend of web applications, and placing key elements using absolute or relative coordinates is also uncommon, so the use cases for this extension are currently quite limited. However, it could be somewhat useful in areas where web technologies are not yet widely adopted but need to be implemented simply. When creating individual components, such as with Vue.js, the real-time preview might become valuable. It could also be helpful for building non-application content like simple landing pages. reply ToucanLoucan 5 hours agoparentThere are so many websites downloading entire web frameworks, tens of megabytes, to display static web pages. Maybe a contact form, or a twitter embed or something. I absolutely loathe it and if these sorts of tools even slightly move the needle towards bringing back standard HTML sites, I'm so incredibly for them. The web is so flat and dull now. reply breadwinner 4 hours agoprevWould be much more valuable if you can live-preview Sass. It is easy to guess the impact of HTML edits I am making, but guessing impact of style edits is much harder and so live preview would be more valuable. reply gloosx 3 hours agoprevThe title was a little confusing for me. Don't you edit HTML visually in real-time all the time? reply whalesalad 16 hours agoprevwe've come full circle - macromedia dreamweaver had this in 2001 reply zeroq 16 hours agoparentWait till you hear about Typescript, you know adding types to ECMAScript, like Macromedia did some 20 years ago. :) Being in the industry for 20+ years and starting as a teenager making games in Flash it makes really hard for me to treat webdev seriously with all their revolutionary innovations. At work I often encounter a resistance to a tech or solution I propose, because \"there hasen't been any substational contribution to the repository in a week, seems dead to me\". To which I kindly respond with a question - how do you calculate hypotenuse, because it's been a long time since Pythagoras made the last commit. Meanwhile, some of my friends are still doing side jobs using CakePHP, 20 years later. :) reply Galanwe 13 hours agorootparent> how do you calculate hypotenuse, because it's been a long time since Pythagoras made the last commit. Also, Pythagoras should be rewritten in Rust for safety. reply wg0 12 hours agorootparentCareless bastard. If safety wasn't his concern he at least should have written it with style using NextJS with tRPC using React Server Side components hydrated on the fly with edge locations in mind utilizing streaming components backed by Drizzle ORM further cemented by AuthJS. I'm sure there would have been plenty of starter kits had he tried npm create. EDIT: RCS reply asdf000333 1 hour agorootparentprevI'm glad to have mostly avoided frontend dev, but we've also had some bonkers backend trends like SOAP. It was like closing your eyes and wishing for a full-stack impl to appear if you write enough XML. reply bugtodiffer 11 hours agorootparentprevToday I value web stuff for one thing and one thing only: they run in the best sandbox we have. I can run untrusted programs from hackernews folks without worrying! I wouldn't do that with native code of course, way too easy to hack me. But they won't waste a browser 0-day on random HN readers... Whatever can be done in the web, I usually like to do it there as no-body has to trust my code then. reply netdevnet 10 hours agorootparent> I can run untrusted programs from hackernews folks without worrying The assumption is that native code has virtually unrestricted access to your system while JS programs don't, which is true. But if the untrusted JS program is wrapped up in web extension, in 2024, it could do almost as much damage than native code especially since most non-techies don't have much of value in their machines. The value exists on walled sites reply stevage 11 hours agorootparentprev> Being in the industry for 20+ years and starting as a teenager making games in Flash it makes really hard for me to treat webdev seriously with all their revolutionary innovations. I think the framing here is unfair. It's not that the people innovating in JS or HTML think what they're doing is \"revolutionary\" or has never been done before. Generally they are applying ideas that have been developed elsewhere, but are currently lacking in whatever their specific area is. reply ww520 6 hours agorootparentprevUnless you are ready to maintain the product for the long term, proposing to use new tech is just resume development. reply pjmlp 4 hours agorootparentprevJavaScript 4, had it not been sabotaged. reply almostgotcaught 13 hours agorootparentprev> how do you calculate hypotenuse, because it's been a long time since Pythagoras made the last commit. Asinine - everything advances and needs maintenance over time, even geometry. I invite you to try building a game without using quaternions or projective (ie non-euclidean) geometry. Edit: does hn award points based on contrariness? Or is it just that people on hn think they're super clever with their contrary point? reply defrost 13 hours agorootparentquaternions - 1843, Hamilton projective geometry - 1420's but big in the 19th Century. These are things I used heavily programming earth mapping systems in the mid 1980s to mid 1990s. Principal reference text was from the 1920s. reply almostgotcaught 13 hours agorootparent... The guy I responded to is saying Pythagoras is good enough. Do you know what year Pythagoras died? reply defrost 12 hours agorootparentDoes that invalidate his theorem (that he cribbed from the Babylonians)? reply IAmGraydon 7 hours agorootparentNo one said it invalidated his theorem. They said it has been expanded upon. Also, comparing web technologies to something as fundamental as the pythagorean theorem is reductionist and overall pretty ridiculous. Web technologies need maintenance. Proven mathematical formulas don’t. reply defrost 5 hours agorootparentThey actually asked if I was aware what year he died. The eponymous triangle work is just as valid as it ever was in Euclidean geometries - lot of work there. That work is just as wrong as it ever was in non-Euclidean geometries - maths is timeless like that. > Also, comparing web technologies to something as fundamental as ... Take that up with whomever it was that did that. reply luismedel 12 hours agorootparentprevI understand what you want to say here but... Do you need these things to write Sokoban, Tetris or any other simple 2d game? reply IAmGraydon 7 hours agorootparentprev> does hn award points based on contrariness? Or is it just that people on hn think they're super clever with their contrary point? It’s both, and seems to be a theme here. HN generally despises the mainstream, so anything that goes against that is praised with little additional thought. A great example is the recent article about “founder mode” which is definitely one of the most idiotic contrarian things I’ve ever read, but receives heaps of upvotes every time it gets posted. reply block_dagger 15 hours agoparentprevCame in to post something similar. Dreamweaver was where my pro web life began. I want the WYSIWYG idea to work, but with the complexity of responsive design with modern css, I don’t see the model working well, at least in my workflow. reply dcreater 16 hours agoparentprevI was so excited when I first discovered Dreamweaver and was gonna make so many great websites. ironically my Engineering degree program had other thoughts reply Fire-Dragon-DoL 16 hours agoparentprevYes, but Dreamweaver had the render broken since about 2001 (I don't know the actual date, mine is a joke). Vs code being chromium means actual browser rendering reply JBiserkov 16 hours agorootparentWell, Visual Studio 6.0's Visual Interdev (1998) had actual browser rendering (via the Trident engine used in Internet Explorer I assume), including Java applets, which would run in the \"Quick view\" mode, but also amazingly in the Source [code] mode! reply the_mitsuhiko 14 hours agorootparentMozilla Composer also existed and is the root of a lot of WSISWYG editors today because of the legacy it and others left in the HTML spec (content editable). reply Popeyes 10 hours agoparentprevWe still use Dreamweaver just because you can drop well structured Word documents in and get a decent HTML document out of it. Still not found a better process really. reply boredemployee 16 hours agoparentprevthats exactly what I thought, I'm old enough to even remember Netscape Composer. I was 10 y/o when used it lol reply roywashere 15 minutes agorootparentHot Dog from Sausage Software reply zarmin 16 hours agoparentprevDon't forget Microsoft Frontpage reply RockRobotRock 15 hours agoparentprevWhen I was young, I learned HTML with Nvu, if anyone else remembers that. reply kmarc 13 hours agorootparentI do! Wow, what a flashback. I think it was formed from Mozilla's built in editor, and later on died quite quickly and was forked under a different name, which, in turn, died quickly. reply coding123 15 hours agoparentprevAnyone here remember homesite? reply BozeWolf 12 hours agorootparentAh yes! And HotDog html editor from “sausage software”. reply profsummergig 15 hours agoprevIs this a significant improvement from having a \"live preview\" on a browser? reply jenadine 14 hours agoparentYou don't need to save. And it has nice features like highlights selection reply braggerxyz 5 hours agorootparentYou know that every respectable editor nowadays has a auto-save feature on focus loss? So just alt+tab from your editor to your browser and refresh. reply jaxomlotus 16 hours agoprevNice. Will this work with React as well? reply fwouts 14 hours agoparentYou may want to check out previewjs.com (disclaimer I'm the author) although it's unfortunately not getting much love or attention lately, my kids are using all of that. reply MikeTheGreat 13 hours agorootparentWell, life takes us other places sometimes. Still, it's pretty cool that your kids are using previewjs.com! No, don't bother - I'll see myself out :) reply urin 14 hours agoparentprevThis tool only handles files that can be treated as static HTML. Therefore, it cannot currently be applied to React implemented with JSX. However, it may be applicable to Vue component files. reply rezaprima 15 hours agoparentprevOr vue ? reply 8mobile 13 hours agoprevThanks for sharing but I don't find big differences with the currently existing \"live preview\" and other plug-ins. Can you explain what are the features of your Web Visual Editor? Thanks reply urin 13 hours agoparentA notable feature is the ability to synchronize code selection with visual selection in the preview. Since this extension has minimal functionality, the codebase is very small, making future expansions easy. It is designed to reflect changes made in the preview back to the code, so enhancing the editing capabilities within the preview may be beneficial in the future. reply smusamashah 11 hours agorootparentThis is useful. I am occasionally day dreaming about moving my static site from Hugo to pure html which I write/edit myself. Do these features depend on complexity of the html or that doesn't matter? Does Javascript work in live preview? reply urin 11 hours agorootparentIt doesn't matter if it's complex. I believe this tool can be applied if it consists of a single HTML file and the resources linked to it. If you're using Web Components, there may be some issues. JavaScript is currently disabled because it's difficult to determine its impact, but enabling it is technically very simple. If there is enough demand in the future, I will add an option to control the functionality of JavaScript. reply netdevnet 10 hours agorootparentprevWhy do you fantasise about writing pure html manually for an entire website? Haven't you done it before? reply dxxvi 16 hours agoprevI like it. It saves me a Ctrl+s and some setup for a hot deployment. reply v3ss0n 8 hours agoprevYou missed the opportunity to name it Vscode-FrontPage. We Are So Back. reply luismedel 12 hours agoprevNice to see you again, HotDog. reply oliyoung 11 hours agoparentThere's a name I haven't heard in many years reply allanblair_ 16 hours agoprevDoes it handle js? I can't tell if this is only for static files from the documentation. reply urin 14 hours agoparentSince it does not handle JavaScript at the moment, I believe the applicable scope is quite limited. reply bryanrasmussen 13 hours agorootparentI'd think maybe in you could do inline JavaScript. Or inline CSS. Or JavaScript urls in the links. Gosh, there are so many possibilities, makes me feel good about the architectural decisions that led to this point. reply aloisdg 10 hours agoprevThank you for using a FOSS license! reply shipitnow 10 hours agoprevInteresting reply apiep 15 hours agoprevAh yes, bracket editor by adobe is back reply init 15 hours agoprev [–] This reminds me of Microsoft FrontPage more than 20 years ago. reply ok_dad 15 hours agoparent [–] Well now I have to try it. I used Frontpage for all of my web sites as a kid and I miss it a lot. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Web Visual Editor is a tool for real-time visual editing of HTML files, offering features like direct HTML element editing and instant preview of changes.",
      "It integrates seamlessly with Visual Studio Code, allowing synchronized selection of HTML elements and text, along with functionalities like zoom, element movement, alignment, and script management.",
      "The tool is similar to microsoft/vscode-livepreview but emphasizes synchronized code and visual selection, with minimal functionality for easy expansion, and is available under the MIT License."
    ],
    "commentSummary": [
      "A new Visual Studio Code (VSCode) extension offers real-time visual editing of HTML, prompting comparisons with Microsoft's existing Live Preview tool.",
      "The extension is noted for its real-time preview and element selection capabilities, which could enhance web development workflows.",
      "Discussions arise around the evolution of web development tools, with some users expressing nostalgia for older tools like Dreamweaver and FrontPage, while others debate the benefits of modern frameworks versus traditional HTML/CSS/JS."
    ],
    "points": 200,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1728867985
  },
  {
    "id": 41832215,
    "title": "Introducing Our New Name",
    "originLink": "https://blog.minetest.net/2024/10/13/Introducing-Our-New-Name/",
    "originBody": "“Is this a Minecraft clone? Is it like Minecraft Alpha?” If you’ve been a member of our community for some time, you are probably aware of how often these questions remind us of what people think of when they hear the name “Minetest”: a rip-off of a similar genre-defining game. Truth be told, that was celeron55’s initial plan. But things change, and Minetest evolved. Now, the time has come for Minetest to assume a new identity and prove it has moved beyond its original purpose. A Bit of History After seeing Minecraft’s alpha debut, celeron55 “took it as a challenge” to explore “the mystery of how a game world like this works under the hood”1. The name wasn’t very important; it was a test after all— an experiment to see what it could do differently. An experiment that began attracting more users and contributors throughout the years until Minetest eventually evolved from a game to what it is today: a game platform. Through the efforts of the community over the past decade, Minetest has developed a unique identity with an approachable API and easy scripting language, support for community-created games and mods, a central library to easily find community content, and more recently a shift to promoting community creations instead of the original Minetest Game. Despite these advancements, one anachronistic holdover has remained to remind us of the past: an idea that no longer describes the purpose of this project and community— its name. After more than a year of public and internal discussions, that era is over. “Minetest” is no more; the “Minecraft clone” is no more. With great thanks to the community for their input, we wave goodbye to Minetest and introduce a new era. Welcome 🥁 … Luanti! Luanwhat? “Luanti” is a wordplay on the Finnish word luonti (“creation”) and the programming language Minetest Luanti employs for games and mods, Lua. The goal was to avoid yet another plain English word (good luck finding something unique…) and highlight the core principles of the project. The fusion of celeron55’s Finnish nationality and the platform’s focus on content creation resulted in the birth of “Luanti”. We decided to avoid using “free” or “libre” in the name because we don’t think it does the project justice. Luanti will always be free software, but that core principle is not everything it has to offer. Projects like Blender, Krita, or Godot are awesome, and they don’t need to convince you about their libre nature by putting it in their names. They are libre, but they’re also much, much more! Luanti is a lot of things. Many of us are familiar with the voxel nature of the engine and the library of content it supports, and name suggestions related to that idea were certainly plentiful. But describing that in the new name would limit the platform in the same way as the original: users and developers would come to expect it to be an engine exclusive to cube games when it can be more than that. Luanti is a platform that is built to help you create. It’s a platform where anyone can make something. It’s a platform that will keep evolving to support your creations. Moving Forward With the new name, a few changes will be made in the engine and community. Obviously, all the repositories and community hubs will adopt the Luanti name in some form. You’ll be able to find the website at luanti.org and repositories at github.com/luanti-org (many old links will redirect). Our social platforms will change similarly. The logo will be staying, and you’ll probably still hear “Minetest” occasionally in reference to Minetest Game which will remain a testament to the project’s roots. Otherwise, Luanti now represents the future of the platform. For developers, the engine won’t actually change much. For those who aren’t aware, core is actually the real Lua namespace used internally, minetest is just an alias (which we will keep for compatibility). Rather than rename all the namespaces to luanti, core will be the official namespace to use. It’s shorter to type, easier to remember, and backwards-compatible. It’s also friendlier to forks and future name changes (which we don’t plan to do, promise!) We hope that, free from the ghost of its past, Luanti can bloom into something more and bring life to adventures and experiences for years to come. It can now live and breathe on its own, explore its nature and potential, and overcome its limits. At the very least, we can finally say to those who once asked “Is this a Minecraft clone?”: No, not anymore. It came from humble beginnings and has grown into a powerful game platform where you, and anyone else, can start creating. And with your help, it will continue to grow into something even better. What do you think about the new name? Let us know in the forum thread or on any of our community platforms! Sources: Open source game developer Perttu Ahola talks about Minetest with Wikinews ↩ Thanks to our post contributors this month: Zughy, GreenXenith, FreshReplicant. Cover image by Zughy.",
    "commentLink": "https://news.ycombinator.com/item?id=41832215",
    "commentBody": "Introducing Our New Name (minetest.net)196 points by luafox 20 hours agohidepastfavorite75 comments beeflet 20 hours agoThe new name isn't great (too many vowels in the same place, you couldn't spell it if you heard it) but at least it's original and doesn't sound like it's a knockoff test implementation of minecraft anymore. Minetest is kind of a unique experiment in how modular a voxel game can be with mods. It's pretty cool. You just visit another server and it downloads and sets up all of the server's mods. You have dependencies and stuff so not every mod has to reinvent the wheel. Much better experience than minecraft modding. Minetest should lean into this and make the core gamemode more different than minecraft. Change up the artstyle, and make the physics feel better. reply bovermyer 1 minute agoparent\"Luanti\" is pretty easy to pronounce/spell for me. I'm not sure what your native language is, though, maybe it's harder for you. reply xinayder 8 hours agoparentprev> The new name isn't great (too many vowels in the same place, you couldn't spell it if you heard it) That's only a problem for english. Finnish people (and I can say romance language speakers) would disagree. reply graemep 8 hours agorootparentI am an English speaker and disagree too. The spelling is fairly natural to me (probably how I would spell it if I heard it) and, in any case, English spelling is not exactly known for being obvious. reply KMnO4 4 hours agorootparentThe new name lacks context that the old one had. Imagine discussing it on a bad telephone connection: “There’s this game similar to Minecraft; it’s called Minetest. You know like, mining and testing” Vs “There’s this game similar to Minecraft; it’s called Luanti — uhhh, l-u-a-n-t-i” The new name isn’t hard, but it’s definitely not as easy. reply cortesoft 20 hours agoparentprev> You just visit another server and it downloads and sets up all of the server's mods. That's how mods work in Minecraft bedrock reply beeflet 20 hours agorootparentMinecraft Bedrock Edition is Microsoft's freemium children's game where you buy \"mods\" and \"skins\" using minecoins and you can visit a number of pre-approved pay-to-win servers or pay Microsoft to host a \"server\" for you and like 8 other people as long as you obey the microsoft guidelines and drink enough verification cans. You might be confusing it with a beloved viral indie PC game called Minecraft (2011) which is no longer for sale. reply r1chard007 19 hours agorootparentNeither of them is free and they're both still for sale https://www.minecraft.net/en-us/store/minecraft-deluxe-colle... reply jerbearito 19 hours agorootparentprevCorrection: Bedrock is not freemium. There's also nothing wrong with Bedrock. It allows for cross-platform play. The minecoins/purchases are available in the menus, but they're never pushed in-game. The experience is very similar to Java. Also, Java and Bedrock both have Realms (the managed \"server\" option you referred to). reply Twirrim 19 hours agorootparentprev> or pay Microsoft to host a \"server\" for you and like 8 other people as long as you obey the microsoft guidelines and drink enough verification cans. Or you can just run your own dedicated bedrock edition server, no need to pay anyone. https://www.minecraft.net/en-us/download/server/bedrock reply rkharsan64 19 hours agorootparentThere's a big catch here: creating mods for Bedrock is difficult. And, Mojang is taking steps that make it difficult for modders to create stuff for Bedrock. [1] There's no match for the modding capabilities that Java edition gives you. [1]: https://feedback.minecraft.net/hc/en-us/community/posts/2309... reply Twirrim 17 hours agorootparentNo disagreements there, but I was just correcting misinformation in the previous post reply Nullabillity 9 hours agorootparentprevNot if you want to connect from the console ports without very awkward hacks (and if you're on PC you wouldn't be running Bedrock in the first place). reply WheatMillington 19 hours agorootparentprevMinecraft Bedrock isn't free is it? Not when I looked at getting it for my kids it wasn't. reply zamalek 19 hours agorootparentprev> You might be confusing it I doubt it. Datapacks did originate in Bedrock, though Minecraft Java does have them now. Downloading Forge/Fabric mods automatically has never been supported as far as I know - good thing tool, it would be a security nightmare. reply cortesoft 18 hours agorootparentprevYou get the Java and bedrock version when you buy Minecraft for the PC. reply xp84 15 hours agorootparentprevYour dripping disdain for Bedrock seems pretty biased, and it seems like you have spent very little time with it. I’ve been playing it for a solid year because it’s what my kid can play (prefers touch controls) and the bedrock experience is light years away from a modern pay to win/in-game-currency focused game such as you’d find on a tablet. (To any reader: Skip the rest of this comment unless you are curious to hear the answer to “Isn’t Minecraft Bedrock a crappy in-game-purchase machine pretending to be a game like the crap on mobile app stores? Why would anybody ever choose it over Java?”) I know you said you only like the “old indie” version, but all my following comments apply to it as well since they’re about its huge omissions. Going back to Java with its archaic menu system and weird, drifty controls was jarring. (I played back in Alpha and for a couple years after, then stopped until using Bedrock last year). Bedrock supports simple LAN multiplayer! Java makes this possible only if you have a real computer (server) and know how. Any people playing Bedrock can play a LAN game with zero preparation, even 3 consoles, a PC, and an iPad. It contains a listing of 5 or 6 servers, yes, which is 5-6 more than Java includes helpful links to. You can also click below that and type in an IP. Yes, avatar costume items cost money. It’s because yes, 5-year-olds cannot use the Java skin editing mechanism of “just make a PNG file.” Of course, that’s all Java even has or had. And Bedrock has that as a free option too. Overall the marketplace is something trivially easy to ignore (btw the actual game costs $20 so it’s not “freemium”.) It’s just another option on the main menu. But my kid has “bought” all manner of both fun and educational stuff on that marketplace for completely free so I’m glad it’s there. There’s a bunch of free stuff on there. One really cool thing I liked was the special “15 year journey” map and modpacks they put up for the occasion of the game’s 15th anniversary. Again I know there are a ton of free mods for Java but that whole scene has become a nightmare for me with all these various weird third party programs I have to use to “apply” the mods. Again, not really a safe situation either to just have even a young teen on Google looking for downloads which may or may not be Minecraft mods. Or even non-tech-savvy adults, tbh. reply jawngee 13 hours agorootparent> Bedrock supports simple LAN multiplayer! Java makes this > possible only if you have a real computer (server) and know > how. Any people playing Bedrock can play a LAN game with > zero preparation, even 3 consoles, a PC, and an iPad. You can do this with Java. After you start a new world you select \"Open to LAN\" in the settings menu. > Again I know there are a ton of free mods for Java but that whole scene has > become a nightmare for me with all these various weird third party programs > I have to use to “apply” the mods. Again, not really a safe situation either to > just have even a young teen on Google looking for downloads which may or > may not be Minecraft mods. Or even non-tech-savvy adults, tbh. Nobody is downloading mods from Google. Modrinth, CurseForge and Prism are all very straightforward apps. You download the mods within those apps and they (mostly) handle dependencies. It's 1 click to launch Minecraft after that. My 6 and 9 year old use them easily and only one of them is a genius - but I won't say which one out of fear they might read these comments after I pass. They both prefer Java fwiw. And Essential mod gives you costume editing as well as making playing with friends even easier than it already is. https://essential.gg/ reply nullstyle 19 hours agorootparentprevWe all know Minecraft Bedrock edition, the children's game where I can actually play with my nieces and nephews confined to iPads and xboxes. It is also beloved by many, but i'm sure those folks count as subhuman to you. reply madeofpalk 18 hours agorootparentprevMore and more of Minecraft is moving into data packs, which is pretty neat. So many things that required .jar java mods are now first-class citizens for customisation, automatically ‘downloaded’ when you connect to a server. Pretty neat. reply Aeolun 20 hours agorootparentprevYou mean you are presented with fifteen purchase dialogs the moment you enter a server? reply JoeyBananas 19 hours agoparentprevThe barrier to having better physics is that better physics requires more complicated netcode. It is also a long-standing precedent in Minetest that the default game is just a minimal skeleton. \"Change the artstyle\" is a misguided suggestion because there are very few assets that are part of Minetest and not a 3rd party minetest mod. reply mschuster91 7 hours agoparentprev> You just visit another server and it downloads and sets up all of the server's mods. You have dependencies and stuff so not every mod has to reinvent the wheel. Much better experience than minecraft modding. Reminds me of Unreal Tournament 2004, that was pretty much the same experience. reply Workaccount2 5 hours agorootparentCounter-strike too reply freedomben 14 hours agoprevI absolutely adore minetest and have an enormous amount of love and respect for the people who have built it into the phenomenal platform that it is. But damn, they are not great at naming things. I have long wished they would rename from minetest to something else, because as silly as it is, one of the biggest barriers of adoption I have run into is the name. When people hear the name, it is confusing and they think it is stupid and a joke. Hell, I even joke about it sometimes too. Naming things is very difficult, so I do feel for them. I also will give this new name some time and see if it grows on me. I am a bit skeptical, but they have more than earned some trust. Regardless, this is a fantastic game and a fantastic platform, and I really don't understand why so many people play Minecraft when there is an open open source alternative that is this good. The code is genuinely very good, and is a pleasure to read. It is one of the things I love about a great open source project, where it was done for the love of the art, not just to grab a paycheck. The code is well thought out and well written, and dare I say even beautiful. Exactly my kind of project! reply thiht 7 hours agoparentLots of libre projects are terrible at naming things, I don't know why. Doing the \"use a word in some exotic language for some reason\" is lazy and rarely great. Another example of that is \"Forjego\", they forked Gitea and went with some Esperanto word because... reasons. reply trinix912 7 hours agorootparentIt's actually Forgejo not Forjego, with this example further proving what a convoluted name it is, with the added bonus that there are at least two points where the pronunciation can vary widely (is the J as in Jack or as in Spanish Juan? Is the G as in Google or George?). reply thiht 6 hours agorootparentOops my bad, I thought they went with it because it's in Go If it's \"Forgejo\" I thing I would pronounce it like in \"forget\", then \"jo\" like in jack, not sure if that's close reply taejo 4 hours agorootparentIt's G as in \"forge\" and J as in \"yo\". In Esperanto Ĝ represents that soft G sound and the word is spelled \"forĝejo\", which breaks into \"forĝi\" (to forge) plus \"ejo\" (a place), i.e. a place where one forges. reply yjftsjthsd-h 13 hours agoparentprevYeah, I've been on a minetest kick lately and it's a great game, and I can understand not wanting to call it \"minetest\", but minetest is 2 english words mashed together and one of them is extremely relevant/descriptive of the game in question. I personally even think that it's fine that it sounds like minecraft, because it... is basically minecraft but proper FOSS; that's approximately the reason I like it. This new name contains zero english words and frankly I'm having trouble getting my brain to hold it at all. Lua... something. And I only remember \"lua\" because I already knew about the programming language. I think I'm going to have to set up an alias or something on my machines so I can actually launch the thing now... reply tetris11 10 hours agorootparentIt's really weird to see it on HN as I've been diving into it hard this past week. Voxelibre is a fantastic standalone pack, and I'm trying out some of the others. I haven't ventured online but will at some point reply idle_zealot 6 hours agorootparentI highly recommend Nodecore. Try to see how far you can get without looking anything up. For certain kinds of brains it's a uniquely satisfying experience. reply VariousPrograms 18 hours agoprev6 months ago you’d have to tell your friends to join you on Mineclone2, a Minetest game, which was like telling people to switch to Doodle Chrome on Microsaft Wandows Beta. Any new name is so much better. reply cAtte_ 18 hours agoprev> We decided to avoid using “free” or “libre” in the name ... Projects like Blender, Krita, or Godot are awesome, and they don’t need to convince you about their libre nature by putting it in their names. so... we decided to add the name of the programming language we use instead? reply kragen 17 hours agoparentIt seems like a pretty reasonable choice when thinking about Luanti as a game engine instead of a game. If someone is choosing a game engine to write a game in, one of their most significant considerations is likely to be what programming languages are supported, so highlighting Lua in the name of the engine is not a bad idea. reply Dalewyn 17 hours agoparentprevI think it's very wise to market your product on something people might actually care about. Free/Libre is a fine philosophy, but as a selling point it has had a very disappointing history. reply froggerexpert 17 hours agoprevGreat project, which has sorely been in need of a better name. \"Luanti\" works. Unique, pronounceable, alludes to Lua ties. reply thaumasiotes 8 hours agoparentThe \"n\" obscures the notional reference to \"lua\". \"Lua\" is two syllables, but \"luan\" is just one. The name makes me think 乱, not an element you'd want to include in the name of most projects. reply yellow_lead 7 hours agorootparentFor non-chinese speakers 乱/亂 is pronounced luan4 in Chinese and means disordered. reply iand 4 hours agorootparentprevLu-anti seems like two syllables to me reply barrettondricka 19 hours agoprevGreat, but I wish they invested their nomenclature resources into design and ease of access. https://bloxd.io/ is currently reaping kids who can't afford official Minecraft. (Browser based, free, ad driven) But then again, MineTest is a bunch of volunteers playing around with a tool, so you can't exactly force anybody to do anything. reply singpolyma3 16 hours agoparentSo what exactly did you wish they did? Make a browser version? reply rdlw 13 hours agorootparentYeah, make a browser version with the time saved by not renaming the repository. reply notpushkin 12 hours agorootparentI think making a browser version would take a bit more time than that. The idea is nice though. reply owenpalmer 16 hours agoparentprevWow, Bloxd is really impressive. Works great on mobile. reply skybrian 20 hours agoprevThe main website lists lots of games that are built on Minetest / Luanti. [1] Does anyone have opinions on which of them are the most fun to play? [1] https://content.minetest.net/packages/?type=game reply beeflet 19 hours agoparentIDK a lot of the games feel really lame but there is this one CTF server that was fun. I might be too old for this stuff but I think it could be the next roblox if you could get it running inside of a webpage with WebGL. Just scrolling through the list I found some interesting ones that really think outside the box (no pun intended), like this one that generates 3D-printable models. https://content.minetest.net/packages/Warr1024/fdmcube/ reply barrettondricka 19 hours agoparentprevI haven't played much myself, but VoxeLibre (and Mineclonia) are pretty good Minecraft replicas. My only complaint is mobile controls. Desktop is decent but the mobile version (off F-droid) leaves much to be desired. reply thetoon 13 hours agorootparentVoxeLibre is trying to be less of a Minecraft replica, now. Mineclonia still is, though. reply rererereferred 4 hours agorootparentprevBut don't people playing Minecraft play it for the fun mods? And people playing Luanti play mods that replicate the original Minecraft? They've gone full circle in too little steps. reply detaro 4 hours agorootparent> But don't people playing Minecraft play it for the fun mods? Some subset of them does, many do not. > And people playing Luanti play mods that replicate the original Minecraft? Some subset of them does, many do not. reply runjake 20 hours agoprevName is awful but game itself looks awesome. Can any speak to how “good” it is, especially server play? reply jasonjayr 17 hours agoparentThere are a lot of creative mods + abilities. That the Lua programming language is core to the engine, means it is easy to do all sorts of supported creative things with the engine. But some of the mechanics and 'smoothness' of play that you can get in Minecraft just isn't there yet in Minetest, due to how the network protocol works. Give it a shot, you can play a local world with very little effort, and if you know lua, look at some of the 'world' definition code. reply o11c 14 hours agoparentprevThe thing that bugs me is how ... intrusive the object dependencies are. Outside of the most trivial mods, you absolutely must buy into one of the major ecosystems, and quite a few things can't be changed in an external mod, only in the ecosystem's core mods, because they're all registered in a single function that's not hookable. Changing the core mods themselves of course causes problems whenever you want to update them. That said, some of the ecosystems (frameworks?) themselves are decent as-is. The two mineclone forks (I don't pretend to know the difference) are probably the best place to start. Mapgen sucks if you want any kind of realism though. Even the mods that pretend to care about it (half of which are in lua and thus really slow) don't operate on a \"top-down\" level, so always end up with things like \"water flows uphill in a circle\". And the grid is very obvious, especially if you're obsessed with the dimensions of your base like I am. I also suspect poor RNG control in places. And there's definitely an idempotency option - if you quit (or crash) the game while mapgen is still running, you can end up with half-generated terrain. Even the builtin mapgens are slow to generate new terrain if you use the \"fast\" cheat. (this ended up being a bit more negative than I'd like; I don't intend to stop people from trying it) reply JoeyBananas 19 hours agoparentprevPretty much everything in Minetest is a 3rd party mod coded in Lua. It is viable, but you are limited by the netcode and the quality / integration of 3rd party mods. reply card_zero 12 hours agoprevHardcore fans shall be called \"luantics\". reply butz 3 hours agoprevAt least the didn't call it Unity or Proton. reply xanderlewis 18 hours agoprevI find it hard to take seriously much debate on naming things. Whatever name you choose is going to upset some people and please others; in the end, all you need is something fairly unique. You quickly forget any intrinsic meaning and it becomes transparent. ‘YouTube’ is a pretty amateurish sounding name and yet it stuck, and here we are now. When was the last time you even stopped and pondered its etymology? The name of any successful entity quickly becomes synonymous with that entity. It’s a fallacy to think you can imbue the entity with meaning by picking its name very carefully. If you think I’m underestimating the importance of a name, just imagine the reaction if you’d suggested naming a computer company ‘Apple’ in the 1970s. “…as in, the fruit?!” reply Affric 18 hours agoparentI agree but I always thought YouTube was a great name for what it was. It was me choosing what was on (no pesky programming) and us making videos. It’s very different now but “you”, as in me, was very central to my idea of what YouTube was. And the TV was a CRT. It was the tube. And as per GWB it was a series of tubes it came through (facetious). reply xanderlewis 16 hours agorootparentI agree, actually. But I do think it’s an odd name given what it’s grown into. And as far as I know there’s no movement to have it changed. reply pessimizer 18 hours agoparentprevApple is snappy and easy to remember, and they literally had to fight the Beatles for it. reply sixo 20 hours agoprev\"Luanti\"—a nice name! reply egorfine 6 hours agoprevfwiw in Russian language \"minetest\" is \"bj is available\". reply Averave 0 minutes agoparentReminds me of the Minecraft server software \"MiNET\" and the issue that followed: https://github.com/NiclasOlofsson/MiNET/issues/446 reply ksynwa 8 hours agoprevMinetest is not a good name but I felt it had become iconic as the game grew more solid. But I trust the maintainers to make the right decision here. reply opminion 12 hours agoprevName change solves a problem I was having just yesterday. And it is easy to use and spell in the tongue I was using it. reply h2odragon 19 hours agoprevWhen was this published? hard to keep up anymore > We decided to avoid using “free” or “libre” in the name ... Projects like ... Godot are awesome, they don’t need to convince you about their libre nature by putting it in their names. reply luafox 19 hours agoparentThis article was published today, October 13th, 2024. reply abraae 19 hours agoprevWhy would you choose a new name that you don't have the .com for? How about voxelmod.com or something else that is a) relevant and b) the .com domain is available. reply Timwi 9 hours agoparentFirst off, there are more TLDs than just .com. Secondly, the majority of people go to websites by googling them, not by typing a URL. reply andai 18 hours agoparentprevluanti.com — only $188.75/mo. for 36 months! reply excalibur 19 hours agoprev [–] Yeah, this name sucks. It will endlessly be misread as \"Luna-ti\" and assigned astrological connotations, it sounds like a pharmaceutical, and it tells you nothing about the platform. reply andai 18 hours agoparentLua does mean Luna, just in a slightly different language. reply itronitron 16 hours agoparentprevLuanti is easy to pronounce and distinct, but it's also vague enough that someone making a game using the Luanti platform will want to name their game something else. reply smohare 18 hours agoparentprev [–] Despite my familiarity with Lua, my mind originally went to the Yuan-ti. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Minetest has rebranded to \"Luanti,\" a name inspired by the Finnish word for \"creation\" and the Lua programming language, highlighting its focus on content creation.",
      "Luanti aims to differentiate itself from its origins as a Minecraft clone by offering an approachable API, easy scripting, and support for community-created games and mods.",
      "The rebranding involves changes to repositories and community hubs, while the core engine remains unchanged, positioning Luanti as a growing platform for creativity."
    ],
    "commentSummary": [
      "Minetest has been renamed to \"Luanti,\" eliciting mixed reactions due to its pronunciation and spelling, though some appreciate its originality.",
      "The community values Minetest/Luanti for its modularity and ease of modding, suggesting further differentiation from Minecraft through changes in art style and physics.",
      "Discussions include comparisons with Minecraft's Bedrock and Java editions, focusing on modding capabilities and multiplayer features, while Minetest/Luanti continues to be a popular open-source platform."
    ],
    "points": 196,
    "commentCount": 75,
    "retryCount": 0,
    "time": 1728858136
  },
  {
    "id": 41836748,
    "title": "Upgrading Uber's MySQL Fleet",
    "originLink": "https://www.uber.com/en-JO/blog/upgrading-ubers-mysql-fleet/",
    "originBody": "Uber Blog Sign up Engineering Engineering, Backend Upgrading Uber’s MySQL Fleet to version 8.0 August 8 / Global Introduction At Uber, our MySQL fleet is the backbone of our data infrastructure, supporting a vast array of operations critical to our platform. Starting 2023, we embarked on a significant journey to upgrade our MySQL fleet to the latest version (i.e., MySQL v8.0). In this blog post, we delve into the motivations, challenges, and solutions involved in this monumental upgrade process and how we completed this upgrade without impacting our Service Level Objectives (SLO). Motivation for the Upgrade Several compelling factors drove our decision to transition from MySQL v5.7 to v8.0: Addressing End-of-Life Concerns: As MySQL v5.7 reached its extended support end date, continuing to use it exposed us to potential security vulnerabilities and a lack of ongoing bug fixes. This posed a significant risk to the stability and integrity of our data. Boosting Performance and Concurrency: MySQL v8.0 offered a compelling proposition with its promise of substantial performance enhancements. Optimizations in indexing and resource utilization translated to faster query execution speeds and improved concurrency handling. This directly translates to a smoother user experience for our customers. Unlocking New Functionality: Beyond performance improvements, v8.0 introduced valuable features like support for window functions, enhanced JSON handling, and better spatial data capabilities. These features opened new avenues for data manipulation and analysis, empowering us to unlock new functionalities within our platform. Password Rotation: The introduction of “Dual passwords” in v8.0 allows for smoother password rotations during security incidents, minimizing service disruptions. Streamlining Operational Efficiency: Managing schema changes is an ongoing task. The Instant ADD Column feature in v8.0 significantly streamlined this process. This translates to reduced downtime during schema alterations, improving our overall operational efficiency. A Closer Look: Uber’s Massive MySQL Infrastructure Before delving into the details of our MySQL upgrade journey, it’s essential to grasp the scale and complexity of Uber’s MySQL infrastructure: Scale: Uber’s MySQL infrastructure comprises over 2,100 clusters, distributed across 19 production zones spanning three regions. With over 16,000 nodes, our infrastructure forms the backbone of Uber’s data storage and processing capabilities. Data Volume and Query Load: Supporting multiple Petabytes of data and serving approximately 3 million queries per second, our MySQL infrastructure handles a vast amount of data and traffic on a daily basis. Clustered Architecture: Each MySQL cluster consolidates multiple MySQL processes running on individual nodes. While each node within a cluster contains identical data, they are strategically distributed across different data centers to ensure data availability and support failover mechanisms. Primary-Secondary Replication: Within each cluster, a primary node manages all write traffic, while secondary nodes replicate data asynchronously. This architecture ensures redundancy and fault tolerance, allowing for seamless failover in the event of primary node failure. Upgrade Considerations: Notably, while MySQL v5.7 primary to MySQL v8.0 read replica replication is compatible, the reverse scenario—MySQL v8.0 primary to MySQL v5.7 read replica replication—is not supported. This distinction played a crucial role in our upgrade planning and execution strategy. Navigating Challenges in the MySQL Upgrade Journey The sheer scale of Uber’s MySQL infrastructure, with over 2,100 clusters and 16,000+ nodes spread across regions and zones, presented a significant challenge. Manual upgrades were simply not an option. To address this, we devised a comprehensive, multi-step upgrade strategy that could be executed efficiently across diverse environments, requiring meticulous coordination. Another key concern was minimizing downtime during the upgrade process. Maintaining Service Level Objectives (SLOs) and Service Level Agreements (SLAs) was paramount to ensure uninterrupted service for our users. Our solution involved meticulous planning and a focus on minimizing downtime throughout the upgrade process. Compatibility with existing applications and services was another hurdle. Ensuring seamless integration with our existing ecosystem necessitated extensive testing, including thorough validation and regression checks. To further enhance system reliability and minimize service disruptions, we implemented automated rollback mechanisms. These mechanisms could automatically revert upgrades in case of failures or compatibility issues. Finally, minimizing manual intervention during the upgrade process was crucial. To streamline operations and reduce the risk of human error, we developed robust automated workflows. These workflows automated repetitive tasks, enabling seamless upgrades across thousands of clusters and nodes. Overall, upgrading to v8.0 seemed like a huge win for everyone at Uber, as it promised a security boost, performance leap, and exciting new features. But manually tackling this across thousands of clusters? No, thanks! We needed a smarter solution–a solution that scaled. Enter our custom-built automation system, designed to guide each cluster meticulously through the multi-step upgrade process, all without a single human touch. Path to MySQL Upgrade @ Uber When we were considering an upgrade of our MySQL clusters from version 5.7 to 8.0, there were two possible approaches that we could have taken: Side-By-Side Upgrade In a side-by-side upgrade, the new version of MySQL (in this case, v8.0) is installed alongside the existing version (v5.7). This approach involves setting up a separate server where the new version is deployed and configured. Once the new server is ready, traffic is gradually redirected to the new version, allowing for a smooth transition. In Place Upgrade An in-place upgrade involves directly upgrading the existing MySQL installation to the new version (v8.0) without setting up a separate environment. This process typically requires stopping the MySQL service, performing the upgrade, and then restarting the service. In-place upgrades are simpler in terms of setup, but may involve longer downtime compared to side-by-side upgrades. Additionally, there is less room for rollback in case of unexpected issues during the upgrade process. Chosen Strategy After careful consideration and thorough evaluation of the advantages and disadvantages, we made the decision to opt for a side-by-side upgrade approach from v5.7 nodes to v8.0, rather than pursuing an in-place upgrade. This choice was made in anticipation of the following benefits: Minimal downtime: With a side-by-side upgrade, we can keep the old MySQL 5.7 nodes running while we set up the new MySQL 8.0 nodes. This means we can gradually migrate the applications to the new nodes without any significant downtime. Reduced risk: Since the old MySQL 5.7 nodes remain operational, we can roll back to it if there are any issues with the new MySQL 8.0 nodes. This reduces the risk of performance degradation, data loss (only until the maintenance phase in the upgrade process) or other issues that may arise during the upgrade process. Better testing: By running the new MySQL 8.0 nodes alongside the old MySQL 5.7 nodes, we can test the new nodes with production read-only application load before making the switch. This can help us identify any issues and ensure that everything works as expected before we complete the migration. Figure 1: Side-by-side upgrade of MySQL cluster. To address these challenges, we developed a system designed to completely automate the transition of a MySQL cluster from v5.7 to v8.0. Our automated alerts and monitoring system actively oversees the process to ensure a seamless transition and promptly alerts of any issues that may arise. A high-level overview of the upgrade process includes: Node Replication: For each MySQL v5.7 node in the cluster, a corresponding MySQL v8.0 replica node is added in the same region/zone, maintaining the distribution consistency between v5.7 and v8.0 nodes. Soak Period: A monitoring period of approximately one week allows us to observe the system’s performance and detect any degradation or SLA breaches caused by the newer version nodes. Traffic Diversion: Once the soak period concludes, MySQL v5.7 replica nodes are disabled to divert traffic away from them. Primary Node Promotion: A MySQL v8.0 node is promoted to primary status for the cluster. Removal of Old Nodes: Finally, all MySQL v5.7 nodes are removed, completing the upgrade to MySQL v8.0. The above process will be broken into 4 Stages: Pre-Maintenance: During this stage, the cluster is prepared for upgrade by adding MySQL v8.0 nodes as replicas, which operate alongside existing v5.7 nodes to serve real production traffic. Figure 2: Pre Maintenance Stage. System Monitoring: Newly added MySQL v8.0 nodes serve as replicas, allowing for real production traffic to be monitored. Any deviations from expected behavior are noted and addressed. Maintenance: Once the system monitoring stage is successfully completed, a MySQL v8.0 node is promoted to primary status, and system stability is monitored. Figure 3: Maintenance Stage. Post-Maintenance: In the final stage, non-replicating MySQL v5.7 nodes are deleted, resulting in a pure MySQL v8.0 cluster. Figure 4: Post Maintenance Stage. Rollback While there was a gradual rollout strategy, we still needed the ability to rollback at every step and we needed the observability to identify signals to indicate when a rollback was needed. We prioritized minimizing risks and ensuring data integrity throughout the upgrade process. Until the Maintenance Step, all actions are fully reversible without any risk of data loss. Should our customers encounter service degradation due to factors like high latency or CPU usage, we can seamlessly and instantly revert to MySQL v5.7 with absolutely no data loss. This means that by simply deleting or disabling the MySQL v8.0 replica nodes introduced during the pre-maintenance stage, we can swiftly return to the previous state. However, it’s essential to note that once a MySQL v8.0 node is promoted to primary status, replication to a MySQL v5.7 node ceases. This transition marks a point of no return in terms of compatibility with MySQL v5.7. Attempting to revert to a MySQL v5.7 primary after this stage would entail potential data loss, as any changes made on the MySQL v8.0 primary would not be replicated back to the MySQL v5.7 nodes. Therefore, careful consideration and thorough testing preceded the promotion of a MySQL v8.0 node to primary status, ensuring a smooth transition while safeguarding our data integrity. Stakeholder Communication We systematically advanced through each tier, commencing from tier 5 and descending to tier 0. At every tier, we organized the clusters into manageable batches, ensuring a systematic and controlled transition process. Before embarking on each stage of the version upgrade, we actively involved the on-call teams responsible for each cluster, fostering collaboration and ensuring comprehensive oversight. This deliberate and structured methodology allowed us to effectively navigate the complexities inherent in upgrading our MySQL fleet. By prioritizing coordination, communication, and teamwork, we successfully traversed through each tier, seamlessly transitioning to MySQL version 8.0. Issues Experienced Change of Query Execution Plan in v8.0 vs. 5.7 Upgrading to MySQL 8.0 brought not only new features, but also some unexpected tweaks in query execution plans for certain clusters. This resulted in increased latencies and resource consumption, potentially impacting user experience. This happened for the cluster which powers all the dashboards running at Uber. To address this issue, we collaborated with Percona, identified a patch fix, and successfully implemented it for the affected clusters. The resolution ensured the restoration of optimized query performance and resource efficiency in alignment with the upgraded MySQL version. Unsupported Queries & Configurations The transition from MySQL version 5.7 to version 8.0 introduced syntax changes for certain keywords, disrupting some queries in production. Additionally, a notable portion of our existing clusters did not have the “STRICT_TRANS_TABLES” SQL mode enabled, which is a default setting in MySQL 8.0. This absence resulted in errors for many customers during the upgrade procedure. Similarly, challenges emerged with the “ONLY_FULL_GROUP_BY” SQL mode, underscoring the necessity for meticulous configuration modifications to ensure compatibility with the specifications of the upgraded version. Previous Default Collation In MySQL 8.0, the default character set is utf8mb4, accompanied by the utf8mb4_0900_ai_ci collation. In contrast, the preceding MySQL 5.7 version employed the utf8mb4_unicode_520_ci collation, lacking support for the latest utf8mb4_0900_ai_ci. This transition introduced challenges in aligning collation settings across the upgraded system. Client Library Incompatibility Library Upgrade Requirement: Many existing client libraries were incompatible with MySQL v8.0. To address this, we had to upgrade these libraries, conduct thorough testing to ensure their proper functionality in a staging environment, and subsequently proceed with the primary upgrade. This step was crucial to guarantee a seamless transition without compromising client interactions. Improvements With the new version, we can harness the following performance improvements: Server-side Performance Improvements for MySQL v8.0 29% improvement in p99 latency for 1 million inserts at 1024 threads. Figure 5: MySQL v5.7 v/s 8.0 at 1M inserts 1024 Threads. 33% improvement in p99 latency for 1 million reads at 1024 threads. Figure 6: MySQL v5.7 v/s 8.0 at 1M Reads 1024 Threads. 47% improvement in p99 latency for 1 million updates at 1024 threads. Figure 7: MySQL v5.7 v/s 8.0 at 1M Updates 1024 Threads. Client-side Improvements due to MySQL Upgrade ~94% reduction in overall database lock time. Figure 8: Reduced locktime post upgrade. ~78% reduction in query time for some queries. Figure 9: Improved query time post upgrade. Learning and Takeaways Throughout the comprehensive upgrade journey, which spanned over a year, our dedicated team of engineers from the MySQL Team flawlessly navigated through a series of critical stages. The monumental task of transitioning our entire fleet to MySQL 8.0 encompassed not only staging clusters, but also production clusters supporting Uber and internal tool instances. This extensive upgrade underscores the indispensable role played by our observability platform, testing regimen, and robust rollback capabilities. Our meticulous testing procedures and phased rollout strategy proved invaluable, allowing us to unearth and address potential issues early on. By adopting this approach, we significantly mitigated the risk of encountering new failure modes during the primary upgrade phase. Conclusion The journey of upgrading our MySQL fleet at Uber to version 8.0 has been challenging but rewarding. By embracing the latest technology and leveraging automation, we’ve not only ensured the security and performance of our database infrastructure, but also demonstrated our commitment to innovation and excellence. The upgrade process, meticulously planned and executed by our dedicated team of engineers, underscores our unwavering dedication to maintaining the highest standards of reliability and efficiency. Through careful consideration of the benefits and challenges, we successfully navigated the transition, mitigating risks and minimizing disruptions to our services. As we reflect on this milestone achievement, we extend our gratitude to all those who contributed to the success of this endeavor. Together, we remain committed to pushing boundaries, driving innovation, and shaping the future of technology at Uber. Cover Photo Attribution: “North Lake CA” by Pacheco licensed as Attribution-NoDerivs. Siddharth Singh Siddharth Singh is a Senior Software Engineer at Uber, currently working on the MySQL Storage platform team. He played a pivotal role as the lead for the version upgrade project, guiding the team to successfully upgrade Uber's MySQL databases to version 8.0. Sriram Rao Udupi Sriram Rao Udupi is a Software Engineer II working on the Storage team at Uber. He has made critical contributions to many MySQL initiatives and played a crucial role in the MySQL fleet version upgrade. Raja Sriram Ganesan Raja Sriram Ganesan is a Staff Software Engineer on the Core Storage team at Uber. He is the tech lead for MySQL initiatives and has led critical reliability and modernization projects for MySQL at Uber. Debadarsini Nayak Debadarsini Nayak is a Senior Engineering Manager, providing leadership in the development and management of various storage technologies, based in India. Posted by Siddharth Singh, Sriram Rao Udupi, Raja Sriram Ganesan, Debadarsini Nayak Category: Engineering Backend Related articles Engineering, Backend Making Uber’s ExperimentEvaluation Engine 100x Faster October 3 / Global Engineering, Backend, Data / ML, Uber AI QueryGPT – Natural Language to SQL Using Generative AI September 19 / Global Engineering, Backend, Mobile, Web Transforming Executive Travel: Delegate Booking with Uber September 12 / Global Engineering, Backend Lucene: Uber’s Search Platform Version Upgrade September 5 / Global Engineering, Backend, Web Continuous deployment for large monorepos August 26 / Global Most popular TransitSeptember 12 / Global Using Uber: your guide to the Pace RAP Program TransitJuly 15 / Global Evolving partnerships: how Uber and Brightline rapidly innovate with flexible tech Engineering, Backend, Data / ML, Uber AISeptember 19 / Global QueryGPT – Natural Language to SQL Using Generative AI Engineering, BackendJuly 18 / Global Odin: Uber’s Stateful Platform View more stories Uber Visit Help Center Company About us Our offerings Newsroom Investors Blog Careers Uber AI Gift cards Products Ride Drive Deliver Eat Uber for Business Uber Freight Global citizenship Safety Diversity and Inclusion Sustainability Travel Reserve Airports Cities English Chicago © 2024 Uber Technologies Inc. Privacy Accessibility Terms",
    "commentLink": "https://news.ycombinator.com/item?id=41836748",
    "commentBody": "Upgrading Uber's MySQL Fleet (uber.com)190 points by benocodes 6 hours agohidepastfavorite173 comments remon 4 hours agoImpressive numbers at a glance but that boils down to ~140qps which is between one and two orders of magnitude below what you'd expect a normal MySQL node typically would serve. Obviously average execution time is mostly a function of the complexity of the query but based on Uber's business I can't really see what sort of non-normative queries they'd run at volume (e.g. for their customer facing apps). Uber's infra runs on Amazon AWS afaik and even taking some level of volume discount into account they're burning many millions of USD on some combination of overcapacity or suboptimal querying/caching strategies. reply aseipp 2 hours agoparentDividing the fleet QPS by the number of nodes is completely meaningless because it assumes that queries are distributed evenly across every part of the system and that every part of the system is uniform (e.g. it is unclear what the read/write patterns are, proportion of these nodes are read replicas or hot standbys, if their sizing and configuration are the same). That isn't realistic at all. I would guess it is extremely likely that hot subsets of these clusters, depending on the use case, see anywhere from 1 to 4 orders of magnitude higher QPS than your guess, probably on a near constant basis. Don't get me wrong, a lot of people have talked about Uber doing overengineering in weird ways, maybe they're even completely right. But being like \"Well, obviously x/y = z, and z is rather small, therefore it's not impressive, isn't this obvious?\" is the computer programming equivalent of the \"econ 101 student says supply and demand explain everything\" phenomenon. It's not an accurate characterization of the system at all and falls prey to the very thing you're alluding to (\"this is obvious.\") reply 0cf8612b2e1e 1 hour agorootparentSimple enough just to think about localities and time of day. New York during Tuesday rush hour could be more load than all of North Dakota sees in a month. Even busy cities probably drop down to nothing on a weekday at 3am. reply Twirrim 2 hours agoparentprevThey're not on AWS. They use on-prem and are migrating to Google and Oracle clouds. https://www.forbes.com/sites/danielnewman/2023/02/21/uber-go... reply Jgrubb 4 hours agoparentprevSee, the problem is that the people who care about cost performance and the people who care about UX performance are rarely the same people, and often neither side is empowered with the data or experience they need to bridge the gap. reply bushbaba 2 hours agorootparentHardware is cheap relative to salaries. It might take 1 engineer 1 quarter to optimize. Compare that to a few thousand per server. reply Jgrubb 59 minutes agorootparentOk but we're in a thread about Ubers cloud bills, which are probably well into the 9 figures annually. It definitely gets talked about in board meetings. Global public cloud spend is hundreds of billions of dollars a year. I wouldn't be surprised if it's AWS's marketing team that came up with the talking point about how much more expensive developer time is. Edit: put this another way- wherever you work, you might know what parts of the architecture need some performance work but do you know what parts of the architecture cost the most money? reply JackSlateur 33 minutes agorootparentprevA couple of years ago, I optimize some shit and reduced the annual billing of 150k€/y, for a 3 days of work I might say, \"hardware\" is expensive compared to (my) salary :) reply notyourwork 11 minutes agorootparentThere isn’t always low hanging fruit. And when there is, it likely requires engineering knowledge to know it exists. reply sgarland 2 hours agorootparentprevIt might take an engineer with no prior RDBMS knowledge a quarter to be able to optimize a DB for their use case, but then it’s effectively free. You found the optimal parameters to use for writer nodes? Great, roll that out to the fleet. reply nunez 3 hours agoparentprevDidn't realize their entire MySQL data layer runs in AWS. Given that they went with basically a blue-green update strategy, this was, essentially a \"witness our cloud spend\" kind of post. reply pocket_cheese 3 hours agorootparentThey're not. Almost all of their infra was on prem when I worked there 3 years ago. reply remon 3 hours agorootparentIt's neither. I remember them moving to the cloud but apparently they moved to Google/Oracle (the latter making this article particularly interesting btw). As per the relevant press release : \"It’s understood that Uber will close down its own on-premises data centers and move the entirety of its information technology workloads to Oracle and Google Cloud.\" reply remon 4 hours agoprevIt's sort of funny how can you immediately tell it's LLM sanitized/rewritten. reply cheema33 0 minutes agoparent> it's LLM sanitized/rewritten LLM is the new spellchecker. Soon we'll we will wonder why some people don't use it to sanity check blog posts or any other writing. And let's be honest, some writings would greatly benefit from a sanity check. reply 1f60c 1 hour agoparentprevI got that feeling as well. In addition, I suspect it was originally written for an internal audience and adapted for the 'blog because the references to SLOs and SLAs don't really make sense in the context of external Uber customers. reply jdbdndj 3 hours agoparentprevIt reads like any of those tech blogs, using big words where not strictly necessary but also not wrong Don't know about your LLM feeling reply est31 3 hours agorootparentIt contains the word \"delve\", a word that got way more popular in use since the introduction of LLMs. Also this paragraph sounds a lot like it has been written by LLMs, it's over-expressive: We systematically advanced through each tier, commencing from tier 5 and descending to tier 0. At every tier, we organized the clusters into manageable batches, ensuring a systematic and controlled transition process. Before embarking on each stage of the version upgrade, we actively involved the on-call teams responsible for each cluster, fostering collaboration and ensuring comprehensive oversight. The paragraph uses \"commencing from\" together with \"descending to\". People would probably write something like \"starting with\". It shows how the LLM has no spatial understanding: tier 0 is not below or above tier 5, especially as the text has not introduced any such spatial ordering previously. And it gets worse: there is no prior mention of the word \"tier\" in the blog post. The earlier text speaks of stages, and lists 5 steps (without giving them any name, but the standard term is more like \"step\" instead of \"tier\"). There is more signs like \"embark\", or that specific use of \"fostering collaboration\" which goes beyond corporate-speak, it also sounds a lot like what an LLM would say. Apparently \"safeguard\" is also a word LLMs write very often. reply wongarsu 3 hours agorootparentIt doesn't get much better if you translate that paragraph from corpo speak to normal language: \"We did the upgrade step by step. We did each step in batches. After we already decided how we were going to upgrade the clusters but before actually doing it we asked the teams responsible for keeping the clusters running for their opinion. This helped create an environment where we work together and helped monitoring the process\" I'm sure there are people who write like that. LLMs have to get it from somewhere. But that part especially is mostly empty phrases, and the meaning that is there isn't all that flattering reply zx76 3 hours agorootparentprevRelevant pg thread on twitter: https://x.com/paulg/status/1777030573220933716 reply maeil 3 hours agorootparentprevThis [1] is a good piece on it. Here's [2] anorher good one. We don't just carry out a MySQL upgrade, oh no. We embark on a significant journey. We don't have reasons, but compelling factors. And then, we use compelling again soon after when describing how \"MySQL v8.0 offered a compelling proposition with its promise of substantial performance enhancements\", just as any human meatbag would. [1] https://www.latimes.com/socal/daily-pilot/opinion/story/2024... [2] https://english.elpais.com/science-tech/2024-04-25/excessive... reply sroussey 22 minutes agorootparentIf the meatbag was a salesperson though… very believable! ;) reply remon 3 hours agorootparentprevNah this isn't a big word salad issue. The content is fine. It's just clearly a text written by humans and then rewritten by an LLM, potentially due to the original author(s) not being native speakers. If you feel it's natural English that's fine too ;) reply exe34 3 hours agorootparentprevI always thought 90% of what management wrote/said could be replaced by a RNN, and nowadays LLMs do even better! reply aprilthird2021 3 hours agoparentprevLet's delve into why you think that reply blackenedgem 0 minutes agorootparentI'm enjoying the replys to this not getting that it's a joke reply fs0c13ty00 3 hours agorootparentprevIt's simple. Human writing is short and to the point (either because they're lazy or want to save the reader's time), yet still manages to capture your attention. AI writing tends to be too elaborate and lacks a sense of \"self\". I feel like this article challenges my patience and attention too much, there is really no need to focus on the pros of upgrading here. We reader just want to know how they managed to upgrade at that large scale, challenges they faced and how the solved them. Not to mention any sane tech writers that value their time wouldn't write this much. reply wisemang 1 hour agorootparent> Human writing is short and to the point (either because they're lazy or want to save the reader's time) Good human writing is short and to the point. (Technical writing at least.) But this is not a result of laziness — it’s actually more difficult. “If I had more time, I would have written a shorter letter.” - Blaise Pascal, and probably others [0] In any case I find these LLM “gotcha” comments incredibly tedious. [0] https://quoteinvestigator.com/2012/04/28/shorter-letter/?amp... reply bityard 16 minutes agorootparentprevMy hypothesis is that long form content generated by LLMs tend to sound like blogspam and press releases because those are exactly the kinds of things they were trained on. Most content generated by humans for public consumption is ANYTHING but succinct. Their style is much more direct if you just ask them a question or to summarize something. (Although whether the answer is accurate or not is another matter.) reply peppermint_gum 2 hours agorootparentprev>It's simple. Human writing is short and to the point (either because they're lazy or want to save the reader's time), yet still manages to capture your attention. AI writing tends to be too elaborate and lacks a sense of \"self\". Corporate (and SEO) writing has always been overly verbose and tried to sound fancy. In fact, this probably is where LLMs learned that style. There's no reliable heuristic to tell human- and AI-writing apart. There's a lot of worry about people being fooled by AI fakes, but I'm also worried about false positives, people seeing \"AI\" everywhere. In fact, this is already happening in the art communities, with accusations flying left and right. People are too confident in their heuristics. \"You are using whole sentences? Bot!\" I fear this will make people simplify their writing style to avoid the accussations, which won't really accomplish anything, because AIs already can be prompted to avoid the default word-salad style. I miss the time before LLMs... reply vundercind 3 hours agorootparentprev> Not to mention any sane tech writers that value their time wouldn't write this much. This is a big part of why the tech is so damn corrosive, even in well-meaning use, let alone its lopsided benefits for bad actors. Even on the “small” and more-private side of life, it’s tempting to use it to e.g. spit out a polished narrative version of your bullet-point summary of your players’ last RPG session, but then do you go cut it back down to something reasonable? No, by that point it’s about as much work as just writing it yourself in the first place. So the somewhat-too-long version stands. The result is that the temptation to generate writing that wasn’t even worth someone’s time to write—which used to act as a fairly effective filter, even if it could be overcome by money—is enormous. So less and less writing is worth the reader’s time. As with free long distance calls, sometimes removing friction is mostly bad. reply remon 3 hours agorootparentprevThis. Thank you for verbalizing what I struggled to. reply Starlevel004 3 hours agorootparentprevevery section is just a list in disguise, and gpts LOVE listts reply msoad 3 hours agoparentprevYeah, I kinda stopped reading when I felt this. Not sure why? The substance is still interesting and worth learning from but knowing LLM wrote it made me feel icky a little bit reply greenavocado 3 hours agorootparentScroll to the bottom to see a list of those who claimed to have authored it reply l5870uoo9y 3 hours agoparentprevAI has a preference for dividing everything into sections, especially \"Introduction\" and \"Conclusion\" sections. reply whalesalad 6 hours agoprevSo satisfying to do a huge upgrade like this and then see the actual proof in the pudding with all the reduced latencies and query times. reply hu3 6 hours agoparentYeah some numbers caught my attention like ~94% reduction in overall database lock time. And to think they never have to worry about VACUUM. Ahh the peace. reply InsideOutSanta 5 hours agorootparentAs somebody who has always used MySQL, but always been told that I should be using Postgres, I'd love to understand what the issues with VACUUM are, and what I should be aware of when potentially switching databases? reply mjr00 4 hours agorootparentWorth reading up on Postgres' MVCC model for concurrency.[0] Short version is that VACUUM is needed to clean up dead tuples and reclaim disk space. For most cases with smaller amounts of data, auto-vacuum works totally fine. But I've had issues with tables with 100m+ rows that are frequently updated where auto-vacuum falls behind and stops working completely. These necessitated a full data dump + restore (because we didn't want to double our storage capacity to do a full vacuum). We fixed this by sharding the table and tweaking auto-vacuum to run more frequently, but this isn't stuff you have to worry about in MySQL. Honestly if you're a small shop without database/postgres experts and MySQL performance is adequate for you, I wouldn't switch. Newer versions of MySQL have fixed the egregious issues, like silent data truncation on INSERT by default, and it's easier to maintain, in my experience. [0] https://www.postgresql.org/docs/current/mvcc-intro.html reply williamdclt 3 hours agorootparentAs much as I have gripes with the autovac, I’m surprised at the idea of getting to such a broken state. 100M rows is not small but not huge, how frequent is “frequent updates”? How long ago was that (there’s been a lot of changes in autovac since v9)? “Stops working completely” should not be a thing, it could be vacuuming slower than the update frequency (although that’d be surprising) but I don’t know of any reason it’d just stop? That being said I’ve also had issues with autovac (on aurora to be fair, couldn’t say if it was aurora-specific) like it running constantly without vacuuming anything, like there was an old transaction idling (there wasn’t) reply sgarland 2 hours agorootparentOn decently-sized tables (100,000,000 is, as you say, not small but not huge), if you haven’t tuned cost limiting and/or various parameters for controlling autovacuum workers, it’s entirely possible for it to effectively do nothing, especially if you’re in the cloud with backing disks that have limited IOPS / throughput. It continues to baffle me why AWS picks some truly terrible defaults for parameter groups. I understand most of them come from the RDBMS defaults, but AWS has the luxury of knowing precisely how many CPUs and RAM any given instance has. On any decently-sized instance, it should allocate far more memory for maintenance_work_mem, for example. reply mjr00 2 hours agorootparentprevIt's been a while, but IIRC it was on pg12. \"Stopped working completely\" I'm basing on the vacuum statistics saying the last auto-vacuum started weeks ago for these tables and never actually finished. Frequent updates means regularly rewriting 10 million rows (at various places) throughout the table. I also should mention that there were 100+ materialized views built off this table which I'm sure had an impact. In any case, this got resolved but caused a huge operational headache, and isn't something that would have been a problem with MySQL. I feel like that's the main reason VACUUM gets hated on; all of the problems with it are solvable, but you only find those problems by running into them, and when you run into them on your production database it ends up somewhere between \"pain in the ass\" and \"total nightmare\" to resolve. reply InsideOutSanta 3 hours agorootparentprevThanks for that, that's valuable information. reply evanelias 2 hours agorootparentprevFor an in-depth read on the differences in MVCC implementations, this post is pure gold: https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postg... reply djbusby 5 hours agorootparentprevVACUUM and VACUUM FULL (and/or with ANALYZE) can lock tables for a very long time, especially when the table is large. Incantation may also require 2x the space for the table being operated on. In short: it's slow. reply sgarland 4 hours agorootparent`VACUUM` (with or without `ANALYZE`) on its own neither locks tables nor requires additional disk space. This is what the autovacuumdvaemon is doing. `VACUUM FULL` does both, as it's doing a tuple-by-tuple rewrite of the entire table. reply gomoboo 4 hours agorootparentprevpg_repack gets rid of the need to lock tables for the duration of the vacuum: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appen... It is an extension though so downside there is it not being included in most Postgres installs. I’ve used it at work and it felt like a superpower getting the benefits of a vacuum full without all the usual drama. reply take-five 3 hours agorootparentpg_repack can generate a lot of WAL, which can generate so much traffic that standby servers can fall behind too much and never recover. We've been using https://github.com/dataegret/pgcompacttable to clean up bloat without impacting stability/performance as much as pg_repack does. reply williamdclt 2 hours agorootparentprevOnly FULL takes a serious lock (normal vacuum only takes a weak lock preventing things like other vacuums or table alterations iirc). Aside: I wish Postgres forced to make explicit the lock taken. Make me write “TAKE LOCK ACCESS EXCLUSIVE VACUUM FULL my_table”, and fail if the lock I take is too weak. Implicit locks are such a massive footgun that have caused countless incidents across the world, it’s just bad design. reply luhn 2 hours agorootparent`TAKE LOCK ACCESS EXCLUSIVE VACUUM FULL` is just an incantation that will be blindly copy-pasted. I don't see how it would stop anyone from shooting themselves in the foot. reply immibis 56 minutes agorootparentImagine two footguns. One shoots your foot off when you open the window. The second requires you to point a gun at your foot and pull the trigger before the window unlocks. Far fewer people will suffer accidental foot injuries from the latter. reply cooljacob204 3 hours agorootparentprevThis is sorta mitigated by partitioning or sharding though right? Too bad it's sorta annoying to do on plain old pg. reply tomnipotent 3 hours agorootparentprevMySQL stores table data in a b+ tree where updates modify the data directly in place as transactions are committed, and overwritten data is moved to a secondary undo log to support consistent reads. MySQL indexes store primary keys and queries rely on tree traversal to find the row in the b+ tree, but it can also contain references to rows in the undo log. PostgreSQL tables are known as heaps, which consist of slotted pages where new data is written to the first page with sufficient free space. Since it's not a b-tree and you can't resolve a row with just a primary key without a table scan, Postgres uses the physical location of the row called a tuple ID (TID, or item pointer) that contains the page and position (slot) of the row within that page. So the TID (10, 3) tells Postgres the row is in block 10 slot 3 which can be fetched directly from the page buffer or disk without having to do a tree traversal. When PostgreSQL updates a row, it doesn’t modify the original data directly. Instead, it: 1) Writes a new version of the row to a new page 2) Marks the old row as outdated by updating its tuple header and relevant page metadata 3) Updates the visibility map to indicate that the page contains outdated rows 4) Adjusts indexes to point to the new TID of the updated row This means that indexes need to be updated even if the column value didn't change. Old rows continue to accumulate in the heap until the VACUUM process permanently deletes them, but this process can impact normal operations and cause issues. Overall this means Postgres does more disk I/O for the same work as MySQL. The upside is Postgres doesn't have to worry about page splits, so things like bulk inserts can be much more efficient. reply sgarland 2 hours agorootparent> The upside is Postgres doesn't have to worry about page splits, so things like bulk inserts can be much more efficient. Not in the heap, but if you have any index on the table (I know, don’t do that for bulk loads, but many don’t / it isn’t feasible sometimes) then you’re still dealing with a B+tree (probably). Also, MySQL still gets the nod for pure bulk load speed via MySQLShell’s Parallel Import Utility [0]. You can of course replicate this in Postgres by manually splitting the input file and running multiple \\COPY commands, but having a tool do it all in one is lovely. [0]: https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-uti... reply tomnipotent 1 hour agorootparent> then you’re still dealing with a B+tree Absolutely, though they're generally orders of magnitude smaller than the table file unless you're INCLUDE'ing lots of columns. There's pg_bulkload which supports parallel writers as well as deferred index updates until the loading process is complete. Not sure how it compares to what MySQL offers out of the box, but I definitely agree that the MySQL tooling ecosystem in general has a leg up. reply InsideOutSanta 3 hours agorootparentprevThat's a perfect explanation, thank you very much! reply anonzzzies 5 hours agorootparentprevYeah, until vacuum is gone, i'm not touching postgres. So many bad experiences with our use cases over the decades. I guess most people don't have our uses, but i'm thinking Uber does. reply RedShift1 5 hours agorootparentMaybe just vacuum much more aggressively? Also there have been a lot of changes to the vacuuming and auto vacuuming process these last few years, you can pretty much forget about it. reply anonzzzies 4 hours agorootparentNot in our experience; for our cases it is still a resource hog. We discussed it even less than a year ago with core devs and with a large postgres consultancy place; they said postgres doesn't fit our use case which was already our conclusion, no matter how much we want it to be. Mysql is smooth as butter. I have nothing to win from picking mysql just that it works; I rather use postgres as features / not oracle but... Edit; also, as can be seen here in responses, and elsewhere on the web when discussing this, the fans say it's no problem, but many less religious users feel it's a massive design flaw (perfectly logical at the time, not so logical now) that sometimes will stop users from using it, which is a shame reply yeswecatan 4 hours agorootparentWhat is your use case? reply anonzzzies 4 hours agorootparentWe have 100000s tables per database (1000s of those) (think sensor/iot data with some magic sauce that 0 of our competitors offer) that are heavy on the changes. And yes, maybe it's the wrong tool (is it though if it works without hickups?) for the job (but migrating would be severe so we would only attempt that if we are 100% sure it will work and if the endresult would be cheaper; remember; we are talking decades here, not a startup), but mysql has been taking this without any issues for decades with us (including the rapid growth of the past decade) now while far smaller setups with postgres have been really painful and all because of vacuum. We were postgres in 1999 when we ran many millions of records through it, but that was when we could do a full vacuum at night without anyone noticing. The internet grew a little bit, so that's not possible anymore. Vacuum improved too like everyone says here, and i'm not spreading the gospel or whatever; just fans (... what other word is there) blindly stating it can do loads 'now' they never considered is, well weird. reply dhoe 2 hours agorootparentI'd generally call this amount of tables an antipattern - doing this basically implies that there's information stored in the table names that should be in rows instead, like IDs etc. -- But I'll admit that sensor related use cases have a tendency to stress the system in unusual ways, which may have forced this design. reply anonzzzies 6 minutes agorootparentEspecially back when we started. Now we would've done it differently, but still think postgres wouldn't really work. Guess we will never now as even far smaller data sets do not work in the way we need them. leishman 5 hours agorootparentprevPostgres 17 tremendously improves vacuum performance reply mannyv 4 hours agorootparentVacuuming is a design decision that may have been valid back in the day, but is really a ball and chain today. In a low-resource environment deferring work makes sense. But even in low-resource environment the vacuum process would consume huge amounts of resources to do its job, especially given any kind of scale. And the longer it's deferred the longer the process will take. And if you actually are in a low-resource environment it'll be a challenge to have enough disk space to complete the vacuum (I'm looking at you, sunos4) - and don't even talk about downtime. I don't understand how large pgsql users handle vacuuming in production. Maybe they just don't do it and let the disk usage grow unbounded, because disk space is cheap compared to the aggravation of vacuuming? reply wongarsu 3 hours agorootparentYou run VACUUM often enough that you never need a VACUUM FULL. A normal VACUUM doesn't require any exclusive locks or a lot of disk space, so usually you can just run it in the background. Normally autovacuum does that for you, but at scale you transition to running it manually at low traffic times; or if you update rows a lot you throw more CPUs at the database server and run it frequently. Vacuuming indices is a bit more finicky with locks, but you can just periodically build a new index and drop the old one when it becomes an issue reply sgarland 2 hours agorootparentPeople not realizing you can tune autovacuum on a per-table basis is the big one. Autovacuum can get a lot done if you have enough workers and enough spare RAM to throw at them. For indices, as you mentioned, doing either a REINDEX CONCURRENTLY (requires >= PG12), or a INDEX CONCURRENTLY / DROP CONCURRENTLY (and a rename if you’d like) is the way to go. In general, there is a lot more manual maintenance needed to keep Postgres running well at scale compared to MySQL, which is why I’m forever upset that Postgres is touted as the default to people who haven’t the slightest clue nor the inclination to do DB maintenance. RDS doesn’t help you here, nor Aurora – maintenance is still on you. reply anonzzzies 4 minutes agorootparentWe make good money 'saving' people from Aurora; you can throw traffic at it and pay more. We often migrate companies who then end up with a fraction of the price. brightball 4 hours agorootparentprevThere are always tradeoffs. reply tomnipotent 3 hours agorootparentprevMySQL indexes can contain references to rows in the undo log and has a periodic VACUUM-like process to remove those references, though no where near as impactful. reply m4r1k 5 hours agoprevUber's collaboration with Percona is pretty neat. The fact that they've scaled their operations without relying on Oracle's support is a testament to the expertise and vision of their SRE and SWE teams. Respect! reply tiffanyh 4 hours agoparentAren't they using Persona in lieu of Oracle. So it's kind of the same difference, no? reply sandGorgon 4 hours agoprevso how does an architecture like \"2100 clusters\" work. so the write apis will go to a database that contains their data ? how is this done - like a user would have history, payments, etc. are all of them colocated in one cluster ? (which means the sharding is based on userid) ? is there then a database router service that routes the db query to the correct database ? reply ericbarrett 2 hours agoparentA query for a given item goes to a router*, as you said, that directs it to a given shard which holds the data. I don't know Uber's schema, but usually the data is \"denormalized\" and you are not doing too many JOINs etc. Probably a caching layer in front as well. If you think this sounds more like a job for a K/V store than a relational database, well, you'd be right; this is why e.g. Facebook moved to MyRocks. But MySQL/InnoDB does a decent job and gives you features like write guarantees, transactions, and solid replication, with low write latency and no RAFT or similar nondeterministic/geographically limited protocols. * You can also structure your data so that the shard is encoded in the lookup key so the \"routing\" is handled locally. Depends on your setup reply bob1029 4 hours agoparentprevI imagine it works just like any multi-tenant SaaS product wherein you have a database per customer (region/city) with a unified web portal. The primary difference being that this is B2C and the ratio of customers per database is much greater than 1. reply vivzkestrel 1 hour agoprevAnyone has any ideas why Uber doesn't use PostgreSQL? reply cyberax 1 hour agoparentThey switched from PG to MySQL because they need to update highly concurrent tables, and PG created tons of bloat as a result. MySQL uses locking instead of optimistic concurrency. reply hu3 1 hour agoparentprevhttps://eng.uber.com/postgres-to-mysql-migration/ reply candiddevmike 6 hours agoprevDoes Uber still use Docstore? I'd imagine having built an effectively custom DB on top of MySQL made this upgrade somewhat inconsequential for most apps. reply geitir 3 hours agoparentYes reply denysonique 4 hours agoprevWhy didn't they move to MariaDB instead? A faster than MySQL 8 drop-in replacement. reply evanelias 3 hours agoparentWhile it is indeed often faster, it isn't drop-in. MySQL and MariaDB have diverged over the years, and each has some interesting features that the other lacks. I wrote a summary of the DDL / table design differences between MySQL and MariaDB, and that topic alone is fairly long: https://www.skeema.io/blog/2023/05/10/mysql-vs-mariadb-schem... Another area with major differences is replication, especially when moving beyond basic async topologies. reply aorth 35 minutes agorootparentWow, I hadn't realized that MySQL and MariaDB diverged so much! In the last year I've started seeing some prominent applications like Apache Superset and Apache AirFlow claiming they don't support—or even test on—MariaDB at all. reply tiffanyh 6 hours agoprevWhy upgrade to v8.0 (old LTS) and not v8.4 (current LTS)? Especially given that end-of-support is only 18-months from now (April 2026) … when end-of-support of v5.7 is what drive them to upgrade in the first place. https://en.m.wikipedia.org/wiki/MySQL reply hu3 6 hours agoparentThe upgrade initiative started somewhere in 2023 according to the article. MySQL 8.4 was released in April 30, 2024. Their criteria for a \"battle tested\" MySQL version is probably much more rigorous than the average CRUD shop. reply paulryanrogers 5 hours agorootparentConsidering several versions of 8.0 had a crashing bug if you renamed a table, waiting is probably the right choice. reply blindriver 4 hours agorootparentYou’re not renaming tables when you’re at scale. reply abhorrence 3 hours agorootparentSure you do! It's how online schema changes tend to be done, e.g. https://docs.percona.com/percona-toolkit/pt-online-schema-ch... describes doing an atomic rename as the last step. reply yen223 1 hour agorootparentYou aren't renaming tables at scale because there are 27 downstream services that will break if you even think about fixing the name of the revnue_dolars table, and it's not in anyone's OKR to fix it reply johannes1234321 6 hours agoparentprevSince direct upgrade to 8.4 isn't supported. They got to go to 8.0 first. Also: 8.0 is old and most issues have been found. 8.4 probably has more unknowns. reply pizza234 6 hours agoparentprevI suppose they opted for a conservative upgrade policy, as v8.4 probably includes all the functional additions/changes of the previous v8.1+ versions, and moving to it would have been a very big step. MySQL is very unstable software - hopefully this will be past - and it's very reasonable to go for the smallest upgrade steps possible. reply hu3 1 hour agorootparent> MySQL is very unstable software I've worked on 20+ projects using MySQL in consulting career. Not once stability was a concern. Banking clients would even routinely shut down radom MySQL nodes in production to ensure things continued running smoothly. As I'm sure users like Uber and Youtube would agree. And these too: https://mysql.com/customers Unless you know something we don't and we're just lucky. reply PedroBatista 5 hours agoparentprevMySQL 8 and beyond has been riddled with bugs and performance regressions. It was a huge rewrite from 5.7. 8 has nice features and I think they evaluated it as stable enough to upgrade their whole fleet to it. I'm pretty sure from 8 to 8.4 the upgrades will be much simpler. reply cbartholomew 5 hours agoparentprevThey started in 2023. v8.0 was the current LTS when they started. reply tallanvor 6 hours agoparentprevAccording to the article they started the project in 2023. Given that 8.4 was released in April 2024, that wasn't even an option when they started. reply EVa5I7bHFq9mnYK 5 hours agoparentprevWith all the migration code already written and experience gained, I imagine upgrading 8->8.4 would take 1/10 of effort of 5.7->8.0. reply gostsamo 6 hours agoparentprev> Several compelling factors drove our decision to transition from MySQL v5.7 to v8.0: Edit: for the downvoters, the parent comment was initially a question. reply xyst 4 hours agoprevI wonder if an upgrade like this would be less painful if the db layer was containerized? The migration process they described would be less painful with k8s. Especially with 2100+ nodes/VMs reply remon 4 hours agoparentTheir entire setup seems somewhat suspect. I can't think of any technical justification for needing 21k instances for their type of business. reply meesles 2 hours agoparentprevA pipe dream. Having recently interacted with a modern k8s operator for Postgres, it lacked support for many features that had been around for a long time. I'd be surprised if MySQL's operators are that much better. Also consider the data layer, which is going to need to be solved regardless. Of course at Uber's scale they could write their own, I guess. At that point, if you're reaching in and scripting your pods to do what you want, you lose a lot of the benefits of convention and reusability that k8s promotes. reply __turbobrew__ 1 hour agoparentprevI can tell you that k8s starts to have issues once you get over 10k nodes in a single cluster. There has been some work in 1.31 to improve scalability but I would say past 5k nodes things no longer “just work”: https://kubernetes.io/blog/2024/08/15/consistent-read-from-c... The current bottleneck appears to be etcd, boltdb is just a crappy data store. I would really like to try replacing boltdb with something like sqlite or rocksdb as the data persistence layer in etcd but that is non-trivial. You also start seeing issues where certain k8s operators do not scale either, for example cilium cannot scale past 5k nodes currently. There are fundamental design issues where the cilium daemonset memory usage scales with the number of pods/endpoints in the cluster. In large clusters the cilium daemonset can be using multiple gigabytes of ram on every node in your cluster. https://docs.cilium.io/en/stable/operations/performance/scal... Anyways, the TL;DR is that at this scale (16k nodes) it is hard to run k8s. reply zemo 3 hours agoparentprevupgrade clients and testing the application logic, changes to the queries themselves as written, the process of detecting the regression and getting MySQL patched by percona, changes to default collation ... all of these things have nothing to do with whether the instances are in containers and whether the containers are managed by k8s or not. reply shakiXBT 3 hours agoparentprevrunning databases (or any stateful application, really) on k8s is a mess, especially at that scale reply edf13 6 hours agoprev3 million queries/second across 16k nodes seems pretty heavy on redundancy? reply sgarland 4 hours agoparentI was going to say, that's absolutely nothing. They state 2.1K clusters and 16K nodes; if you divide those, assuming even distribution, you get 7.6 instances/cluster. Round down because they probably rounded up for the article, so 1 primary and 6 replicas per cluster. That's still only ~1400 QPS / cluster, which isn't much at all. I'd be interested to hear if my assumptions were wrong, or if their schema and/or queries make this more intense than it seems. reply pgwhalen 4 hours agorootparent> assuming even distribution I don't work for Uber, but this is almost certainly the assumption that is wrong. I doubt there is just a single workload duplicated 2.1K times. Additionally, different regions likely have different load. reply withinboredom 6 hours agoparentprevThat's 200 qps per node, assuming perfect load balancing. reply 620gelato 4 hours agoparentprev2100 clusters, 16k nodes, and data is replicated across every node \"within a cluster\" with nodes placed in different data centers/regions. That doesn't sound unreasonable, on average. But I suspect the distribution is likely pretty uneven. reply donatj 4 hours agoprevInterestingly we just went through basically the same upgrade just a couple days ago for similar reasons. We run Amazon Aurora MySQL and Amazon is finally forcing us to upgrade to 8.0. We ended up spinning up a secondary fleet and bin log replicating from our 5.7 master to the to-be 8.0 master until everything made the switch over. I was frankly surprised it worked, but it did. It went really smoothly. reply takeda 4 hours agoparentAFAIK the 8.0 release is one where Oracle breaks compatibility. So anyone considering MariaDB needs to switch before going to 8.0, otherwise switching will be much more painful. reply John23832 5 hours agoprevAnyone else get a \"Not Acceptable\" response? reply internetter 3 hours agoparentI did but it worked on a private tab reply jauntywundrkind 5 hours agoprevHaving spent a couple months doing a corporate mandated password rotation on our services - a number of which weren't really designed for password rotation - happy to see the dual password thing mentioned. Being able to load in a new password while the current one is active is where it's at! Trying to coordinate a big bang where everyone flips over at the same time is misery, and I spent a bunch of time updating services to not have to do that! Great enhancement. I wonder what other datastores have dual (or more) password capabilities? reply johannes1234321 3 hours agoparentI can't answer with an overview on who got such a feature, but \"every\" system got a different way of doing that: rotating usernames as well. Create a new user with new password. This isn't 100% equal as ownership (thus permissions with DEFINER) in stored procedures etc. needs some thought, but bad access using outdated username is simpler to trace (as username can be logged etc. contrary to passwords; while MySQL allows for tracing using performance_schema logging incl. user defined connection attributes which may ease finding the \"bad\" application) reply gregoriol 6 hours agoprevWait until they find out they have to upgrade to 8.4 now reply gregoriol 6 hours agoparentAnd also all the passwords away from mysql_native_password reply johannes1234321 3 hours agorootparentWhich one should do anyways. mysql_native_password is considered broken for a out ten years. (Broken for people who can access the hashed form of the password on the server) reply sgarland 4 hours agorootparentprevThey've got until 9.0 for that, it just gives deprecation warnings in 8.4. reply evanelias 2 hours agorootparentMore specifically, mysql_native_password is disabled by default in 8.4, but can be re-enabled if needed: https://www.skeema.io/blog/2024/05/14/mysql84-surprises/#aut... reply gregoriol 2 hours agorootparentprevDeprecation warnings are in 8.0. It's disabled in 8.4. If you are up-to-date with all your libraries it all should go well, but if some project is stuck on some old code, mostly old mysql libraries, one might get surprises when doing the switch away. reply dweekly 4 hours agoprevAm I the only one who saw \"delve\" at the top of the article and immediately thought \"ah, an AI generated piece\"? Well, that and the over-structured components of the analysis with nearly uniform word count per point and high-complexity but low signal-to-noise vocabulary using phraseology not common to the domain being discussed. (The article doesn't scan as written by an SRE/DBA.) reply devbas 4 hours agoparentThe introduction seems to have AI sprinkled all over it: ..we embarked on a significant journey, ..in this monumental upgrade. reply rafram 6 hours agoprevDid they have ChatGPT (re)write this? The writing style is very easy to identify, and it’s grating. reply OsrsNeedsf2P 5 hours agoparent> The writing style is very easy to identify, Really? At n=1 the rate seems to be 0 reply paradite 5 hours agoprevI can tell from a mile away that this is written by ChatGPT / Claude, at least partially. \"This distinction played a crucial role in our upgrade planning and execution strategy.\" \"Navigating Challenges in the MySQL Upgrade Journey\" \"Finally, minimizing manual intervention during the upgrade process was crucial.\" reply traceroute66 5 hours agoparent> I can tell from a mile away that this is written by ChatGPT / Claude, at least partially. Whilst it may smell of ChatGPT/Claude, I think the answer is actually simpler. Look at the authors of the blog, search LinkedIn. They are all based in India, mostly Bangalore. It is therefore more likely to be Indian English. To be absolutely clear, for absolute avoidance of doubt: This is NOT intended a racist comment. Indians clearly speak English fluently. But the style and flow of English is different. Just like it is for US English, Australian English or any other English. I am not remotely saying one English is better than another ! If, like me, you have spent many hours on the phone to Bangalore call-centres, you will recognise many of the stylistic patterns present in the blog text. reply calmoo 5 hours agorootparentThere's nothing that sticks out to me as obviously Indian English in this blog post. It's almost certainly entirely run through an LLM though. reply antisthenes 4 hours agorootparentIf there are large amounts of Indian English in an LLM's training data, it stands to reason the LLM output will be very similar to Indian English, no? reply 620gelato 5 hours agorootparentprev(Speaking as an Indian engineer) Hate to generalize, but this has less to do with \"Indian style\" but rather adding a lot of fluff to make a problem appear more complex than it is, OR maybe someone set a template that you must write such and such sections, despite there not being relevant content. [ Half the sections from this article could be cut without losing anything ] In this case, the _former_ really shouldn't have been the case. I for one would love to read a whole lot more about rollback planning, traffic shifting, which query patterns saw most improvements, hardware cost optimizations, if any, etc. reply brk 5 hours agorootparentprevI agree (I've posted a similar comment in the past and collected a handful of downvotes). Much like ChatGPT, you tend to see a slight over use of more formal and obscure words and a tone that tends to feel like the topic being discussed is being given just a touch too much focus or dedication relative to the grand scheme of things. It is hard to fully describe, more of a \"you know it when you see it\". reply excitive 4 hours agorootparentprevCan you elaborate on the last part? What are some stylistic patterns that are different when something is written by a US author v/s Indian? reply albert_e 4 hours agorootparentI recently saw a tweet where someone pointed out that \"today morning\" was an Indian phrase. I had to really think hard why it is incorrect / not common elsewhere. Had to see comments to learn -- someone explained that a native English speaker would instead say \"this morning\" and not \"today morning\". As a Indian ESL speaker -- \"today morning\" sounded (and still sounds) perfectly fine to me -- since my brain grew up with indian languages where this literal phrase (equivalent of \"TODAY morning\") is not only very common, but also the normal/correct way to convey the idea, and if we instead try to say \"THIS morning\" it would feel pretty contrived. reply traceroute66 1 hour agorootparentprev> What are some stylistic patterns that are different when something is written by a US author v/s Indian? Largely as @brk above you already mentioned, tendency to use formal and obscure words alongside a specific tone. I'll also re-iterate what @brk said, hard to fully describe, more of a \"you know it when you see it\". If I had to pick some specific examples from the blog post, the following phrase is a good example: We systematically advanced through each tier, commencing from tier 5 and descending to tier 0. There are 101 ways you could write that in US English, but I reckon 99% of the US population would be unlikely to pick the above unless they were writing an academic paper or something. This one is also quite Indian English in many respects: Our automated alerts and monitoring system actively oversees the process to ensure a seamless transition and promptly alerts of any issues that may arise. Similarly, we have stylistic elements such as the over-breaking of paragraphs to the extent it becomes a series of statements. For example: Upgrading to MySQL 8.0 brought not only new features, but also some unexpected tweaks in query execution plans for certain clusters. This resulted in increased latencies and resource consumption, potentially impacting user experience. This happened for the cluster which powers all the dashboards running at Uber. To address this issue, we collaborated with Percona, identified a patch fix, and successfully implemented it for the affected clusters. The resolution ensured the restoration of optimized query performance and resource efficiency in alignment with the upgraded MySQL version. A relatively short paragraph, but five phrases. Your average US English writer would likely word it differently resulting in it being trimmed down to two or three phrases. As I said in my original post though, none of it is bad English, its just a different style. reply hodgesrm 4 hours agorootparentprevNot exactly a stylistic difference but there are real differences in the dialects. Here's example from many moons ago: \"Even I think that's a bad idea.\" That was an Indian colleague. It took me weeks to figure out that he was using \"even\" in place of \"also.\" In a like vein when Australians say \"goodeye\" they usually aren't talking about your vision. reply ssl-3 4 hours agorootparentPerhaps. Or perhaps it was meant to specify that they, themselves, might have been presumed to be an outlier who would think it was a good idea, but who has in fact come to think that is a bad idea. Examples of this kind of counter-presumptive use of the word \"even\": 1: On animals and the weather: \"It was so cold that even polar bears were suffering from frostbite and frozen digits.\" 2: On politics, where one's general stance is well-known and who who might be rationally presumed to be a supporter of a particular thing: \"Even I think that this issue is a total non-starter.\" Even if they may have meant something else, that doesn't mean that they didn't intend for the words to be taken non-literally. reply V-eHGsd_ 4 hours agorootparentprev> In a like vein when Australians say \"goodeye\" they usually aren't talking about your vision. They aren’t saying goodeye, they’re saying g’day (good day) reply brunocvcunha 5 hours agoparentprevI can tell just by the frequency of the word “delve” reply godshatter 4 hours agoparentprevThat sounds like regular old English to me. I could see myself saying all those things without thinking it's pushing any boundaries whatsoever. I'm starting to fear that LLMs are going to dumb down our language in the same way that people feared that calculators would remove our ability to calculate mentally. reply aster0id 4 hours agoparentprevBecause the authors are likely non native English speakers. I'm one myself and it is hard to write for a primarily native English speaking audience without linguistic artifacts that give you away, or worse, are ridiculed for. reply notinmykernel 5 hours agoparentprevAgree. Repetition (e.g., crucial) in ChatGPT is an issue. reply mannyv 2 hours agoparentprevOnce ChatGPT puts in \"we did the needful\" we're all doomed. reply greenchair 11 minutes agorootparentDear sir, we are having a P1 incident, Prashant please revert. reply rand_r 4 hours agoparentprevI know what you mean, and you’re probably right, but there’s a deeper problem, which is the overuse of adjectives and overall wordiness. It’s quite jarring because it reads like someone trying to impress rather than get an important message across. Frankly, ChatGPT could have written this better with a simple “improve the style of this text” directive. Example from the start: > MySQL v8.0 offered a compelling proposition with its promise of substantial performance enhancements. That could have just been “MySQL v8.0 promised substantial performance improvements.” reply kaeruct 5 hours agoparentprevChatGPT says \"While it's plausible that a human might write this content, the consistent tone, structure, and emphasis on fluency suggest it was either fully or partially generated by an LLM.\" reply gurchik 5 hours agorootparentHow would ChatGPT know? reply indulona 6 hours agoprevnext [10 more] [flagged] kavunr 5 hours agoparentI had a similar reaction when reading https://engineeringblog.yelp.com/2024/10/migrating-from-post... reply BarryMilo 5 hours agorootparentI get the urge to standardize infrastructure but... wow. After reading the whole thing, I get why they thought it was worth doing, but you'd think they'd just hire a Postgres guy or two. Especially when they looked at the missing features, this feels like a downgrade... reply kccqzy 5 hours agorootparentIn big companies they never just \"hire a guy or two\"; the bus factor would be atrocious in this case, not to mention vacations and such. The minimum unit of hiring is one team, about five people five or take. So the difference they are looking at is either hiring a team of Postgres people or forcing everyone on one existing team to learn Postgres deeply. From this perspective, standardizing on infrastructure makes more sense now. reply mardifoufs 5 hours agorootparentprevUber also famously migrated from postgres to MySQL, so they have used both! reply indulona 5 hours agorootparentpreveveryone is praising postgres and shitting on mysql, until performance matters. then, when all these big tech companies turn to mysql, the postgres fanboys cry in unison. reply sgarland 4 hours agorootparentTbf, either can be made to be fast, or slow. MySQL used to have a huge advantage for range queries due to its clustering index (assuming you have designed a schema to exploit that capability), but as time has gone on that gap has narrowed [0] (despite the title, it's not just about inserts). My own benchmarks for strictly read-only queries have also borne that out. The biggest difference, IMO, is if you _aren't_ aware of the clustering index, and so design your schema in a way that is suboptimal. For example, given a table with orders or something similar, with a PK of `(user_id, created_at)`, a query like `SELECT... FROM... WHERE user_id = ? ORDER BY created_at DESC LIMIT 1` can be quite fast in MySQL. With a monotonic integer as the PK, and a secondary index on those two columns, it can still be quite fast, depending on insert order. If however you invert the PK to `(created_at, user_id)`, while MySQL 8+ will still be able to use the index, it's not nearly as efficient – in my tests, I saw query speed go from 0.1 msec --> 10 msec. In contrast, while there is a small difference in Postgres with all of those differences, it's just not that big of a difference, since it stores tuples in a heap. Again, in my tests, query speed went from 0.1 msec --> 0.7 msec. This is a point query, of course; with range queries (`WHERE created_at < ...`) Postgres suffered more, jumping up to ~25 - 50 msec. [0]: http://smalldatum.blogspot.com/2024/09/mysql-and-postgres-vs... reply lenerdenator 5 hours agorootparentprevThere'd be less of that if there weren't a feeling that MySQL is the high-grade free hit that Oracle uses to get you hooked on their low-grade crap. reply mardifoufs 5 hours agorootparentIt's been 15 years since oracle acquired MySQL. I agree that you should always be prudent with Oracle but that's a long time... reply indulona 4 hours agorootparentprevuse mariadb instead of mysql. reply jeffbee 3 hours agoprevFile under \"things you will never need to do if you use cloud services\". reply martinsnow 3 hours agoparentNah random outages because the RDS instance you were on decided to faceplant itself, or the weird memory to bandwidth scaling AWS has chosen will make you pull your hair out on a high traffic day. It's just different problems. reply jeffbee 3 hours agorootparentThe company in the article is doing < 200qps per node. Unless they are returning a feature-length video file from every query, they are nowhere near any hardware resource limits. reply mannyv 2 hours agoparentprevThat's not true. The RDS 5.7 instances are EOL so you have to upgrade them at some point. At least in RDS, that will be a one-way upgrade ie: no rollback will be possible. That said, you can upgrade one instance at a time in your cluster for a no-downtime rollout. reply jeffbee 2 hours agorootparentHosted MySQL is not what I meant. That just means you're paying more to have all the same problems. The kind of cloud service I am alluding to is cloud spanner, cloud bigtable, dynamodb. reply paxys 3 hours agoparentprevAt Uber's scale they are a cloud service. reply greenie_beans 5 hours agoprevyall should prioritize your focus so you can do better at vetting drivers who don't almost kill me reply JamesSwift 4 hours agoparentI'm not sure how effective the database engineers are going to be at solving this, but I guess we can ask them to try... reply greenie_beans 4 hours agorootparentthanks for your help reply lenerdenator 5 hours agoparentprevTheir focus is prioritized according to what returns maximum value to their shareholders. reply greenie_beans 4 hours agorootparentbeep boop i'm a capitalist robot pretty sure safe travels is critical to maximum value to their shareholders (aka stfu or tell me how this blog post has anything to do with maximize shareholder value https://www.uber.com/en-JO/blog/upgrading-ubers-mysql-fleet/... ... shareholder value is a dumb ass thing to prioritize over human life) reply Kennnan 4 hours agorootparentHonest question, how do you (or amyone) propose to vet drivers? They require drivers license and car insurance registration, anything like a CDL would make being a driver prohibitively expensive. Their rating system already works as a good signal the few times Ive used uber. reply greenie_beans 4 hours agorootparenti don't know, i don't work there. i'm just somebody who almost died because one of their drivers was a terrible driver. that sounds like a problem they should figure out. dude didn't even know how to change a tire, so start with \"basic knowledge of car maintenance.\" and a basic ability to speak english would be a good bar to meet, too. they'll let anybody with a driver's license, car, and a heart beat drive on that app. there should be a higher barrier of entry. but idk, i don't work there. this is just my experience as consumer. also, the US should be wayyyyy stricter on who we issue drivers license to. so many terrible drivers on the road driving these death machines. reply robertlagrant 4 hours agorootparentIf you have one big company with 10 bad drivers, you'll get a much worse impression of it than 100 companies each with one bad driver. reply greenie_beans 4 hours agorootparentand your point is? this just makes no sense bc the drivers are on all of the different apps. rework your formula. reply croisillon 4 hours agorootparentprevmandatory retest every 5 years reply photochemsyn 4 hours agoparentprevIt's undeniable that the worst drivers on the road are those working for ride-hailing services like Uber. It's a big point in Waymo's favor that their automated vehicles behave predictably - Uber drivers are typically Crazy Ivan types doing random u-turns, staring at their electronic devices while driving, blocking pedestrian walkways and bike lanes, etc. reply menaerus 5 hours agoprev [–] Lately there's been a shitload of sponsored $$$ and anti-MySQL articles so it's kinda entertaining that their authors are being slapped in their face by Uber, completely unintended. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Uber upgraded its MySQL database from version 5.7 to 8.0, addressing end-of-life concerns and enhancing performance and features.",
      "The upgrade involved over 2,100 clusters and 16,000 nodes, using a side-by-side approach to minimize downtime and risk.",
      "The transition improved performance, reduced database lock time, and enhanced query efficiency, highlighting Uber's focus on innovation and reliability."
    ],
    "commentSummary": [
      "Uber's upgrade to MySQL version 8.0 has initiated discussions regarding their database strategy, particularly the efficiency of their setup with many nodes for low queries per second.",
      "The choice of MySQL over alternatives like PostgreSQL or MariaDB is debated, with some citing past performance issues with PostgreSQL's VACUUM process.",
      "Uber's collaboration with Percona and their strategic upgrade approach underscore their dedication to enhancing database performance."
    ],
    "points": 190,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1728907683
  },
  {
    "id": 41834662,
    "title": "Embedded Rust in Production?",
    "originLink": "https://blog.lohr.dev/embedded-rust",
    "originBody": "Embedded Rust in Production ..? A review after using Rust on embedded in production for over a year Michael Lohr ·Feb 4, 2024· 5 min read When I mention that we use Rust on the embedded ESP32 platform the most common reaction is a jaw-dropping \"This is possible?!\". Yes, it is indeed possible! - And we at STABL Energy have used it successfully for over a year now. And because so many people seem interested in why we use Rust and how it is going for us, I decided to write this blog post. \"Thanks to its direct access to both hardware and memory, Rust is well suited for embedded systems and bare-metal development.\" - GitHub It all started in 2022, with me getting annoyed by our C implementation of a small piece of software running on an ESP32 (a microcontroller with built-in internet connectivity). The purpose of the software was to read messages via UART (serial interface/protocol, often used to communicate between embedded devices) and send them to some cloud services via MQTT (messaging protocol, often used to communicate between IoT devices). Seems simple enough, right? Well, we had some additional requirements in terms of reliability, regarding the layout of the resulting JSON MQTT messages and concerning the content of the UART messages which is rather difficult to parse. To give you some more context: I work for a startup named STABL Energy where we build revolutionary energy storage systems, that are based on second-life batteries (batteries that were used in electric cars before). Instead of recycling them just now, we can use those perfectly fine batteries to (for example) back large PV farms and prolong their lives just a little bit more. The device I was talking about before is used to connect our battery storage systems to the cloud for monitoring and remote control. We also use it during development, to test new features in our system - so it really needs to be reliable, because we don't want to lose any data. Our C implementation was a small (very prototype) software running on the ESP32 platform. It had some serious runtime issues, preventing it from working reliably, that were hard to debug. And debugging on embedded is a lot more complicated than debugging software targeting desktop architectures. I have much respect for C (and even more for people programming in C), but I think its era is coming to an end. As I wrote in a previous blog post, Zig could be a quite good modern replacement in the future. But Zig is rather new and at the time we worked with the C implementation, I didn't even know that Zig existed. However, I did a lot with Rust in personal projects at that time. The developer experience in Rust is just on the next level and the software you write is reliable without giving reliability, memory allocation etc. too much thought in the first place. At STABL Energy, we didn't use any Rust before. We mainly used C for embedded and Python for anything else. But since I got to lead this project and had a great time with Rust, we ended up writing a prototype using ESP IDF, which even allowed us to use the Rust standard library. Long story short: Our Rust prototype ended up much more reliable than the C implementation. We spent a little bit more time writing the software (Rust takes longer to write than C) to achieve the same functionality but spent basically zero time debugging (since there weren't that many bugs) - so we stuck with it. At that time the Rust support from Espressif (the company behind the ESP32) was rather new and experimental (and it still is), but it kept improving and we noticed quite the investment from Espressif in terms of work spent working on Rust support for their platform. Fast forward to 2024: We now used the ESP32 with our custom software written in Rust for over a year in production, with great success. The devices transmit data 24/7 and we have no known bugs (I don't even remember the last bug we had). There is just one problem: Who maintains and further develops this project? While there are some pretty passionate Rust developers (& consultancies) out there (even in Germany) and even more that would be willing to learn Rust, it is not viable to hire one sole Rust developer for this (small) project. Since Rust, and especially embedded Rust (lots of FFI & unsafe), is quite hard to learn, it is not viable (for us) to retrain a C developer to Rust. Luckily we found a Rust developer who was willing to learn C as well. So what's the state of embedded Rust outside of our small project? Dion, from Tweedegolf, recently published a great article about the current state: He says that what works and does not work heavily depends on the specific use case and willingness to build the missing pieces yourself or rely on open-source software. There are still some rough edges, as visualised in his infographic, but overall Rust is a viable programming language choice for embedded projects. If, in the future, I were faced with a choice between C and Rust for embedded development again, I would most likely choose Rust because of how successfully we used it in the past. Let me know if you heard about some similar projects - I am always excited to hear about embedded Rust! RustembeddedESP32renewable-energyStartups Written by Michael Lohr Passionate about software development and architecture, web and cloud technologies, as well as game development. Passionate about software development and architecture, web and cloud technologies, as well as game development. Follow Share this",
    "commentLink": "https://news.ycombinator.com/item?id=41834662",
    "commentBody": "Embedded Rust in Production? (lohr.dev)184 points by michidk 12 hours agohidepastfavorite229 comments dazzawazza 11 hours agoAccess to competant Rust developers can be a challenge even for large companies. I recently finished a contract at a (very large game dev) company where some tools were written in Rust. The tools were a re-write of python scripts and added no new functionality but were slightly faster in Rust. The reality was that these tools were unmaintainable by the rest of the company. Only the author \"knew\" Rust and it was hard to justify a new hire Rust developer to maintain this small set of tools. The only reason these tools were written in Rust was because the dev wanted to learn Rust (a big but common mistake). I pointed out to the Technical Director that this was a big mistake and the teams had taken on a large amount of technical debt for no reason other than the ego of the wanna-be-rust-developer. Since I \"knew\" Rust he wanted me to maintain it. My advice was to go back to the Python scripts and I left. reply gwd 10 hours agoparentThis question of \"what tools / languages\" should we use was introduced to me (during an interview, actually) as \"technical strategy\". There is more to the choice of language or tooling than whether it's fast or slow or reliable at one instant in time -- you have to ask how you will grow and maintain things going forward. That said, obviously all languages were in that state at some point. Twenty-eight years ago you might have said the same thing about Java. Twenty-four years ago, Perl might have looked like a better choice than Python; now it's clearly the opposite. XenServer took a gamble and wrote their main control stack in OCaml in 2008; on the whole that has had some benefits, but the number of OCaml developers has not significantly grown, and it's not easy to hire people. That said, I think Rust is much more likely to follow Java's trajectory than OCaml's: My prediction is that it's only going to be easier and easier to find Rust developers. reply adamc 34 minutes agorootparentTwenty-four years ago, Python already looked better to me. I maintained a big Perl 5 app. Yuck. The problem wasn't that you couldn't write it, the problem was that you had to be able to read widely differing styles of Perl... and if you wanted to read library code, it was a huge pain. I quit maintaining that system in 2005, and it has barely changed since, from what I'm told. Viability of a language is certainly a consideration, but the characteristics of the language also matter. What you couldn't really predict about Java in, say, 2000, was how much the complexity of its ecosystem would grow. In 2000 (or 2005) it was fairly easy to move in and out of Java from project to project. That is not true today. My fear on the Rust front is that it's going to be another C++, where the complexity is considerable and requires more or less full-time expertise. reply acomjean 9 hours agorootparentprevI don’t love Perl, but we have 10+ year old Perl scripts at work that work fine. The python scripts of the same vintage have to be reworked because python versions and importantly supporting libraries have changed. This is mainly because Perl hasn’t changed, with the failure of perl6 to launch. But it’s an interesting comparison. I’ll agree Rust will be like like Java. reply adamc 30 minutes agorootparentI dunno. Java was pretty easy to learn for its first decade. Eventually, the complexity of Java and, especially, its toolchain ballooned. By then there were already a lot of Java developers, though. Rust is a different beast, much more complex from the outset, and not trivial to learn (as Java was). It will grow if that's where the best jobs are, but I don't think it is going to grow in the way Java did, because the difficulty and dynamics are different. There was a good stretch at the beginning where Java was both very helpful on your resume and really easy to learn. reply gwd 5 hours agorootparentprev> I don’t love Perl, but we have 10+ year old Perl scripts at work that work fine. I'm not talking primarily about Perl as a technology in and of itself, but as a long-term technology choice in terms of being able to find people to maintain and improve it. The Xen Project has a bunch of support stuff (automated testing and tooling around doing security work) written Perl. It was just about a reasonable decision when it started to be written 10-15 years ago; Golang was too young, Rust wasn't written yet, and Python had its downsides. But when the author of the code left the project 2-3 years ago, and there was 1) nobody with a similar level of expertise to maintain it, 2) nobody particularly wanted to gain that expertise, and 3) it wasn't easy to find someone else to pay to do maintenance. If you've managed to find people who can maintain those perl scripts, more power to you; but it unless perl5 can get some momentum back, it seems like it's going to be harder and harder to find replacements. reply pdimitar 7 hours agorootparentprevRE: scripts, I find Golang better and better for this nowadays. Uber-fast compilation, to the point of it being acceptable to just instead do `go run your_thing.go` even, and you have access to a very solid runtime and many libraries for most of what people usually need. I don't argue with the portability and longevity of Perl but it too has its problems. reply fredrikholm 5 hours agorootparentThe longevity of Go is also a thing. I have not encountered a single Go project that used to compile but now doesn't because it hadn't been touched. Go is in many ways leap years ahead of most AOT languages I've used in anger. Yes, sometimes you miss XYZ, but seldom is that an issue outside of personal preferences. What you do get though is amazing tooling and little-to-no downtime. Builds basically don't take any time, tests run past, pipelines are quick. go test ./... finishes faster than you can print Determining projects to restore... to the screen. It's a very liberating experience that is hard to go back from. reply pdimitar 5 hours agorootparentAgreed 100%. I have my very real pet peeves with Golang -- lack of sum types and thus no exhaustive pattern matching is the top one -- but I can't argue with results. Every time I wanted to whip up something quickly, Golang has gotten the job done and then some. reply fredrikholm 4 hours agorootparentI've gotten far with type switching on an interface that amounts to a single function that does nothing. Unfortunately it does nothing in terms of exhaustiveness, but it effectively gives you sum types which IME are so, so much easier to work with than state pattern or other inject-an-object-abstractions. Not having to design an API (that later leaks) is rewarding enough. It's strangely efficient as well. I've experimented with implementing sum types via tagged C-style unions and at every (ad hoc, micro) benchmark I've tried them against, type switching on an interface comes out on top. reply pdimitar 4 hours agorootparentCan you point me at an article that demonstrates Golang type switching? Does not ring bell at the moment for me so I'd love to see the code. reply assbuttbuttass 4 hours agorootparenthttps://go.dev/tour/methods/16 reply pdimitar 4 hours agorootparentThanks, for some reason I never stumbled upon this. Very valuable, I am bookmarking it. reply pjmlp 2 hours agorootparentprevStill leaves a lot to be desired versus Object Pascal from Apple/Borland days, or Delphi afterwards. reply tashmahalic 1 hour agorootparentWhat makes those better? reply pjmlp 1 hour agorootparentThe language features, designed for full stack systems programming, IDE tooling, the frameworks bundled with the compiler, first class support for binary libraries ecosystem, no culture against modern times... reply devsda 10 hours agorootparentprevI wish and I'm sure Rust will get there some day but is there a no-brainer usecase today where it's really important to use Rust, one important enough to overlook the initial learning curve, developer scarcity and evolving ecosystem? If there's a killer open product out there where the primary supported language is Rust(Linux kernel might as well be it someday), or if a big company launches a successful product in Rust then adoption may accelerate. For now its mostly limited to cryptocurrencies, performance critical paths or rewrite of hidden core components but nothing flashy. \"Nobody ever gets fired for buying IBM\". Unless teams can say the same about their choice of Rust, people are going to be risk averse and prefer using safest choice as long as its good enough. reply ttfkam 5 hours agorootparentAnother use case is when you need a systems language for a user-facing app (even if not directly connected to the internet) and would have reached for C++ previously. Memory corruption bugs are no joke. If you've got staff that already knows C++, their ramp up time for Rust will be much shorter compared to typical devs working only in Python, JS, etc. reply llm_trw 7 hours agorootparentprevnext [2 more] [flagged] pdimitar 7 hours agorootparentNobody is stealing anything, what a weird comment. And the problem with new kernels is how to reuse the huge trove of already-written drivers. Nobody is going to start rewriting everything in any language, be it Rust or any other -- does not matter. That's why the ABI and \"please commit to a standard\" points are so difficult and thorny in the kernel ecosystem; people want to reuse. reply pyrale 5 hours agorootparentprev> you have to ask how you will grow and maintain things going forward. The typical answer is \"The jobs market will provide\". The issue with that method is that you end up competing with everyone and, usually, your company is not the top employer. OTOH, some companies decide to use technology and invest in knowing the community, by hosting events or meetups, by frequently sending their devs to conferences on company time, etc. Usually, the people hired are above average, and are also able to train juniors if the market dries up. These companies typically are the safest in terms of ability to maintain their stack, but have to account for the fact that alienating their existing devs becomes a big risk. The real harm comes for companies that choose niche tooling but believe the market will provide. reply gwd 5 hours agorootparentRight -- you can choose a niche technology, as long as you're willing to commit to the additional costs of doing more training, being involved in the community, and so on. Those additional costs (and/or the risk of not doing so) need to be factored into the decision to use a technology. reply netdevnet 6 hours agorootparentprevThe kind of people that recklessly move from shiny language to the newest shiny language in town are the same kind of people that believe that you could kick out a dev writing systems in Java and stick a dev whose experience has only been Haskell and O'Caml and have the new dev hit the ground running reply stonemetal12 5 hours agorootparentprevIf a company chooses non standard tools then they are doing it with the knowledge that they will have to train new hires in it. Random employee using non standard tools without the company making the decision to pivot to embracing it, aka training existingew employees in that tool, is just making stuff that your company will have to throw away and redo. So XenServer embracing OCaml is nothing like Random Gamdev writing some scripts in Rust without the team deciding to embrace the change. reply sshine 9 hours agorootparentprev> Rust is much more likely to follow Java's trajectory than OCaml's I'd rather compare Rust to Haskell and Kubernetes. Haskell: - Dozens of handfuls of experts open to remote work. - Lots of aspiring juniors who see no way to enter the market. - Most employers are R&D-heavy academic consulting environments. Kubernetes: - Wildly hyped and cherished among people who don't have the complexity to warrant the purchase. - Eventually criticised for being overly complex and suitable only at a certain size and setup. > it's only going to be easier and easier to find Rust developers. I imagine it's never been easier to find Haskell developers and Kubernetes developers, either. Yet, one's wish to code Haskell professionally does not necessarily align with one's market value. It seems like there's a lot more open for Kubernetes, so Rust could go that way. Unlike Haskell, Rust seems to gain industry acceptance. reply pdimitar 7 hours agorootparentHaskell and OCaml have a lot of what Rust has (namely exhaustive pattern matching + sum types, typeclasses and the like) but Rust has stellar tooling. Had both of these languages' ecosystems and communities not dragged their feet and go full elitist on newcomers then Rust might not have ever been created. So sure, Haskell and OCaml are great but after I spent half an afternoon trying to bring in a dependency in a little-more-than-hello-world Haskell program and then spending the other half on trying to do the same in OCaml I just threw my hands in the air and said \"frak this, there has to be a better way\". Hence I landed on Rust. You and others can always say \"skill issue!\" but that's hugely missing the point; I want to use my skills on solving the actual problem, not on the logistics. We're not in the 1970s anymore and a weirdly huge number of people still haven't gotten that message. reply rixed 6 hours agorootparentI do have one ear for that argument that \"everything ought to be simpler\". But what I've observed over and over is that many systems tends to become more complex as the result of people wanting to make them more newbie friendly. That's certainly true of the last 10 years of Ocaml tooling evolution. reply pdimitar 5 hours agorootparentI guess you could argue both ways and it depends on your starting point. I did not mean to say \"make it newbie friendly\", I meant \"I want adding a dependency to my project to be a 10 seconds job, not a week-long endeavor\". If we both start from that point then I think we might find a common ground. reply rixed 21 minutes agorootparentYes it does very much depend on your starting point. For instance, coming from C Unix programming, it took me 2 hours to try OCaml 15 years ago or so, because Ocaml tooling, at that time, was the same as C. Basically, I made a generic rule for my makefiles to call ocamlopt instead of gcc and I was good to go. Installing a dependency was just the usual \"./configure && make install\" This was simple for me, but not for students with no Unix background. In that context \"opam install\" was simpler, although it's objectively more complex as it adds a few additional layers on top of the same process. reply pdimitar 13 minutes agorootparentYep, it's about your background. I moved away from makefiles long ago and I don't regret it, for a multitude of reasons that are well explained in many places. `cargo add ...` is great and I wish every language offered a tool like that. reply rixed 7 minutes agorootparentEven when i use cargo or go or node, make is still needed to build everything that's not just code. pdimitar 2 minutes agorootparentIf you say so. There are plenty of tools that can do more or less the same without having to remember weird bash-isms and pattern expansion rules. I use `just` for project tasks, but there are many others. AnimalMuppet 5 hours agorootparentprevBut 28 years ago with Java, it had a clear edge in a certain space. It came with a ton of libraries, so you didn't have to write a bunch of code. And it had garbage collection, so a bunch of problems just went away. For code that didn't have to be close to the metal, it was clearly superior. And it was pretty easy to learn for C++ developers. Rust may have an advantage in certain places (no segfaults is a definite win). But replacing working Python scripts is almost certainly not that place. Also, for a C++ developer, Rust isn't as easy to learn as Java. Rust may get there. But don't use Java's success to predict Rust's trajectory. reply Keyframe 3 hours agorootparentJava had a lot of things going on for it. Huge marketing push, whole set of everything both language and lib-wise, and killer domain which was SIM and mobile which if you wanted to do it was your only choice. Rust has no such things at the level Java had when it rose. It's more of an organic grassroots movement certain companies have started to pick up. reply tcmart14 2 hours agorootparentYea it did, and its important when making comparisons to not glaze over it. Java with the, write once and run anywhere mantra due to the JVM was a huge deal. Granted, in some ways it didn't pan out as well as advertised (embedded Java), but for an enterprise desktop application, it was definitely a huge win for the time. reply pjmlp 2 hours agorootparentApparently there was something to it, otherwise we wouldn't have every other day a WebAssembly startup being upvoted. reply geodel 3 hours agorootparentprev> I think Rust is much more likely to follow Java's trajectory than OCaml's: This looks like pipe dream of those Rust devs who usually claim that Rust borrow checker is easiest thing since heating HotPocket in microwave. reply psychoslave 9 hours agorootparentprevI don’t know about your later claim. To my shallow knowledge of Rust, it doesn’t try to compete on the same segment as Java. For the latter it’s still kinda of \"everybody can write some code that will run everywhere\". The former is more like \"you can have performance, consistency and correctness in a shallowly-C-like syntax\", which is more likely to tease the average HN reader, but probably not the average programmer who is in to earn some descent money or as a way to start before moving up in the businesses hierarchy. And you see there are some people which enthusiast to push Rust into the Linux kernel, while I doubt that in Java projects of similar size there is that much ardor for even introducing it in some part of it, let alone propose a full rewrite. reply Seattle3503 9 hours agorootparent> I don’t know about your later claim. To my shallow knowledge of Rust, it doesn’t try to compete on the same segment as Java. I don't think the origin lame was that it would compete for the same segment, but that it would reach the same level of ubiquity. It could do that by opening up a new non-existent segment, eg smart contracts on the block chain. Or it could take a little from multiple domains. reply pyrale 5 hours agorootparentprev> descent money When you want a decent paycheck, but instead get a descent into computing madness. reply psychoslave 5 hours agorootparenthaha, nice catch, thanks for the smile. :) reply mellosouls 6 hours agoparentprevThe only reason these tools were written in Rust was because the dev wanted to learn Rust (a big but common mistake). While they should get wider buy-in first then if the choice is technically justified within reason, its perfectly appropriate (and normal) for devs to pick up new languages in this way when existing expertise is not available on staff. No competent dev will accept their skills atrophying due to overly rigid political/tech choices. That's how skills are built, its always been thus in such environments, and thats ok. reply hu3 5 hours agorootparentSorry but employees are not entitled to get paid to learn whatever technology they want during work. And I say that as an employee. There's some flexibility to choose tooling but with autonomy comes responsibility. Replacing a bunch of working Python scripts with Rust is not just irresponsible, it's disrespectful and isolating towards coworkers. reply mellosouls 5 hours agorootparentSorry but employees are not entitled to get paid to learn whatever technology they want during work, in their own special ivory towers. rather different to my While they should get wider buy-in first then if the choice is technically justified within reason, its perfectly appropriate reply hu3 5 hours agorootparentMy point is about this: > No competent dev will accept their skills atrophying due to overly rigid political/tech choices. Competent dev to me is one that delivers value. I say that as a dev but I'm pretty sure stakeholders would agree. It's perfectly reasonable to hone your skills outside of paying hours if you chose to expand to new technology outside of your employer's stack. reply mellosouls 5 hours agorootparentFairer, but that's probably the point and tone you should have quoted with then. ;) I would probably concede that it depends on context - for devs paid at the top of the market to simply churn stuff out factory-style there is less justification for self-improvement on work time. For the majority though there is always give and take between responsible employees and employers, and building skills as discussed is normal. reply whatshisface 5 hours agorootparentYou're not likely to be paid top of the market at a firm whose biggest concern is that you might be more flexible and a faster learner than anyone else they were able to hire. reply nicoburns 10 hours agoparentprev> I recently finished a contract at a (very large game dev) company where some tools were written in Rust. The tools were a re-write of python scripts and added no new functionality but were slightly faster in Rust. > The reality was that these tools were unmaintainable by the rest of the company. Only the author \"knew\" Rust and it was hard to justify a new hire Rust developer to maintain this small set of tools. I can believe this, but it's funny because I work on a project where the main product is written in Rust, and it's the build tools written in Python that are the technical debt that nobody really wants to touch! In our case I suspect rewriting them in Rust will end up being the right thing to do (if/when we can justify the switching costs). reply bsnnkv 3 hours agorootparent> I can believe this, but it's funny because I work on a project where the main product is written in Rust, and it's the build tools written in Python that are the technical debt that nobody really wants to touch! Oh hi! You must be my teammate! I joined a team like this and just started a personal build/dev/ops tool repo in Rust for things that I needed but were not automated. Over time it has become an \"official\" repo and renamed to be blessed with an official \"org\" package prefix. When I started this project and people were interested, I was asked why I didn't just add to the Python repo; I said that others are free to rewrite them if they want to, but I can't justify spending days messing around with Python to achieve what I can in less than 30 minutes with Rust when I need to quickly automate a tedious task. Edit: A lot of downvotes on this, but in case it wasn't clear - the team is happy that someone took the time to scaffold a repo in Rust that everyone feels more confident in contributing to, since the overwhelming majority of the codebase is written in Rust and the Python tools repo is full of annoying runtime errors that could be trivially caught at compile time. The end result is more people feeling more empowered to automate repetitive and tedious tasks which can easily be fudged when executed manually instead of suffering with them because someone who isn't even here anymore decided to start a tools repo in Python for a team that almost exclusively writes code in Rust. reply Seattle3503 9 hours agorootparentprevThat makes sense, as the bulk of your developers are probably Rust devs. Homogeneity favors Rust in this case. Also Rusts existing build system is (unsurprisingly) built around Rust, so it makes sense to keep with it. reply cypressious 8 hours agorootparentI really enjoy projects where the project and the scripts around it use the same language. reply j-krieger 10 hours agoparentprev> Only the author \"knew\" Rust and it was hard to justify a new hire Rust developer to maintain this small set of tools. There are two dialects of Rust. One can be written immediately by beginners, the other is for experts. I make sure to write scripts in the first dialect. It uses `clone` all over the place, does not make use of any async runtime, and makes extensive use of \"anyhow\" for error creation and logging. I advise all my peers to do the same, if they find a need for Rust in tiny scripts or applications. reply sshine 10 hours agorootparent> There are two dialects of Rust. One can be written immediately by beginners, the other is for experts. I believe it's more like a spectrum. I'm 3 years into my Rust career. I started with .clone() everywhere. Then I moved on to write highly async code with tokio and std. Now I'm somewhere entirely unfamiliar, writing highly portable no-std Rust for bare-metal and wasm. It takes some time to know the difference between std and core. It takes some effort to write modular, allocation-free code (static allocations only). It takes some rediscovery of what crates will work for you. It's a steep curve, and I don't imagine everyone likes it. reply throwawaymaths 2 hours agorootparentprevStrong \"only use this subset of c++\" energy reply iknowstuff 3 minutes agorootparentexcept using a different set of rust is not gonna allow RCEs or leak your data to the internet reply serial_dev 27 minutes agoparentprevWhile I get most of your points, I believe some companies sometimes can or maybe even should experiment with new languages, and see what benefits it brings them. The important part is evaluating the experiment and having the courage to say “well that didn’t work out, let’s go back to the original version”. They should have evaluated what is “slightly faster”, how much money it saves and how much it will cost extra to maintain it. reply ram_rar 39 minutes agoparentprev> The reality was that these tools were unmaintainable by the rest of the company. Only the author \"knew\" Rust and it was hard to justify a new hire Rust developer to maintain this small set of tools. Only If I had a dollar for everytime this happens. Choosing a language for the company is a business decision. we have a similar issue with Elixir and now the entire team is spending a quarter just to get rid of it. For anyone building startup on LLMs , this is one killer application I would pay for. The generated code doesn't event have to 100% correct, just right enough for devs to tweek would go a long way. reply the8472 7 hours agoparentprevIf it's just a few tools that are essentially scripts and they don't even warrant a full-time dev then wouldn't a random senior dev do? I have had to touch things in languages I'm not familiar with and initially it's slow due to having to look things up, but plenty knowledge still does transfer. Opening a file is still opening a file, updating dependencies is still updating dependencies. Plus python devs should be used to changing tooling all the time ;P reply physicsguy 11 hours agoparentprevEmbedded developers that know Rust is an even smaller pool than Rust developers in general. It’s almost two non-intersecting groups of people since embedded in general is less well paid in many countries and so doesn’t attract people interested in the latest and greatest hyped up language. reply Seattle3503 9 hours agorootparentAs a Rust dev looking for a new job, this is my experience. I filter out the embedded jobs because knowing Rust only half the equation for those roles. reply cmatza 5 hours agoparentprev\"competent\" is a bit of a word there, there are very few shops right now that are willing to hire actually junior rust devs. The jobs are out there but they're all for mid level at a minimum roles in the Rust ecosystem specifically. Tons of people would jump ship to be able to use Rust, it has a lot of love in the community. \"Being totally unwilling to accept anyone junior, or who is new to the stack\" is a disease in this industry, and it's really apparent when some 200 person+ company is only hiring principal level rust devs. reply otabdeveloper4 9 hours agoparentprev> Access to competent developers can be a challenge for companies. Fixed it for you. You wouldn't believe the quality of the average applicant for a basic standard Python position if I told you. reply isoprophlex 8 hours agorootparentAt least you can pretend you've hired someone that's going to solve your python problens. And to mgmt, that's sometimes the only thing that matters. Greasing the wheels of the corporate meatgrinder with Rust is almost impossible, actual work quality notwithstanding. reply atoav 10 hours agoparentprevAs a Rust/Python dev I previously decided against Rust in a work context as I deemed it would make me the sole person who knows what is going on, while python feels much more like a lingua franca of programming nowadays. I would decide this on a case by case basis tho, Rust is different, but if e.g. what you wrote derives most of its business logic from its configuration, or the usecase is so generic changes aren't gonna be a thing for a while, why not. Rust is different, but unless you want a complete rewrite or new complex features any developer should be able to get into it if you give them a little time. And the strictness of Rust makes it unlikely that they break things in a bad way, which is good. reply dijksterhuis 8 hours agorootparent> but if e.g. what you wrote derives most of its business logic from its configuration, or the usecase is so generic changes aren't gonna be a thing for a while, why not there’s also the fairly easy cross compilation to bear in mind. i built a container entrypoint binary via python to stick in all our containers at last job. getting that to cross compile was going to be a bunch of pain i wasn’t willing to go down for a simple “download files from S3, run a sub process, upload files to S3” pre-execution wrapper. digital ocean infra + self hosted gitlab —> no readily available windows instances. so everyone had to use linux to dev these containers with wine+mono. being able to cross compile would have been brilliant here. i made the decision to not do this in rust for future maintenance reasons. but then people avoided using this thing because they couldn’t run on windows :/ (i know there’s that paid for package but the license fee is mind boggling from what i remember). reply hu3 5 hours agorootparentperhaps Go could have been a good solution for simple, cross-compiled code. reply dijksterhuis 3 hours agorootparentfrom what i looked at, go was a bit more complicated than rust for cross compilation. but it was still a lot less complicated than sorting it out for python. dunno. was at least two years since i looked at it, but i remember rust coming out on top in my mind. unfortunately the same maintenance issue applied -- it was a python / R shop so no-one else would have been able to change the code once i left. reply hu3 2 hours agorootparentAFAIK Go has one of, if not the easiest cross compilation stories. This is all it takes to build a linux arm64 binary: env GOOS=linux GOARCH=arm64 go build your_program You can even run that from Windows and it will just work. This is how you list all possible targets: go tool dist list If you want to generate binaries for many linux distros, you can even use a simple bash script: #!/usr/bin/bash archs=(amd64 arm64 ppc64le ppc64 s390x) for arch in ${archs[@]} do env GOOS=linux GOARCH=${arch} go build -o your_program_${arch} done reply dijksterhuis 1 hour agorootparentthats definitely not the commands the guide i looked at had lol looks on par with rust then. go is the next one for me to dive into when im doing fiddling with rust audio stuff. regardless, wouldn’t have worked at last job as no-one knew go either. would have been easier probably to get someone in, but i spent a year trying to get one new hire to no avail, so doubtful. reply marhee 7 hours agoparentprevDid you not offer to rewrite it in Python? I was a techical director at a company where we worked a lot with frontend contractors. Some loved typescript others were fans of vanilla js. When the balanced tipped there were rewrites from one to the other (ts to js to ts again), the first one two months full time, the second was interspersed with feature development. Of course the developers were very happy they could do it; it improved the solutions and afterward they both had 1) extreme product ownership 2) excellent company problem domain knowledge. So, a win-win for everyone. So I think, especially as it is a smaller part, than translating back in to Python would be warranted (provided you like it and would stay a while), not a big deal and a quite natural option. reply melodyogonna 3 hours agorootparentI don't think it needs rewriting if the original version was in Python. What you need to do is return the original Python version reply steelegbr 10 hours agoparentprevIndeed. The few times I've encountered Rust in the wild it's been for a project that didn't need it (web or IO bound applications) and someone's \"My First Rust Project\". It's difficult or even at times beyond the budget of smaller organisations to then hire a seasoned Rust dev to unpick whatever mess you got in to. Don't get me wrong, Rust has a niche where it's the right choice. But being a popular language of the day, it's getting used a lot in the wrong places. reply 6r17 10 hours agorootparentProject that does not need rust \"Web, or IO\" -> What would you actually choose to make an API then ? Python ? Ruby ? Did you compare benchmarks from rust server to python servers ? Did you actually feel the difference ? reply wmil 9 hours agorootparentMost web servers aren't doing anything computationally complex and there's a lot of tech to help you scale to multiple servers, so single server performance usually isn't really critical. Web stuff is about developer speed. So familiarity, libraries, and tooling. There are plenty of good options. Anything that needs to be performant can go in it's own service. reply smolder 5 hours agorootparentI will say that a rust service, even when doing relatively simple stuff, can scale well in the cloud due to small memory footprint, fast startup time when auto-scaling in containers, and no need for a JIT to \"warm up\" before it has high throughout and consistent low latency. Building something with these qualities on a framework like Rocket is pretty straightforward, IME. reply 6r17 4 hours agorootparentBuilding a web app with rocket is like using a fine BMW to go on highway. It just feels right- I love Guards and what not he added in his framework ; absolutely refreshing work ! reply 6r17 4 hours agorootparentprevHave you heard of something called climate change ? reply hu3 5 hours agorootparentprev> What would you actually choose to make an API then ? Python ? Ruby ? Python, Ruby, Go, PHP, C#, Java, TypeScript, Elixir. Performance benchmarks when writing APIs as 1st concern? Really? 99% of the cases this should be the last criteria. Monthly reminder that a good part of instagram still runs on Django/Python. reply tokinonagare 2 hours agoparentprev> some tools were written in Rust. The tools were a re-write Some memes just write themselves. reply meindnoch 11 hours agoparentprev>Only the author \"knew\" Rust [...] because the dev wanted to learn Rust Many such cases. Recipe for disaster. reply ahoka 10 hours agorootparentI think the rule of thumb should be that if you wouldn’t write aomething in C++, then you shouldn’t use Rust. reply j-pb 8 hours agorootparentThat's a horrible rule of thumb, because C++ adds a ton of complexity with little reward except for speed. Rust adds less complexity (still a lot ofc), but it also gives you awesome tooling and dependency management (much better than python for example), and and extemely powerful typesystem and functional programming features, that make writing correct code extremely easy. Rust is a complex but overall good language for writing solid software, C++ is making a deal with the devil in exchange for speed. reply ttfkam 5 hours agorootparentIf a garbage collected language can easily do the job, choose the garbage collected language. I like Rust, but it is NOT the fastest language to develop in. Typescript, Python, Go, Swift, and even Bash depending on the situation are all quicker to code in than Rust. If any of those languages are inadequate for the requirements whether they be memory-bound, CPU-bound, or sensitive to gc pauses, Rust is an excellent option that is far superior to C++ in 2024 and beyond. The notion of \"one true language\" has always been and will always remain a fool's errand. reply j-pb 1 hour agorootparentI write most of my stuff in a combination of Python, JS/TS and Rust these days with some form of Interop between them. I.e. mostly Python Marimo notebook with JS visualisations, and PyO3 Rust bindings. Tbh I don't find myself to be \"slow\" in rust. Sure for quick exploratory stuff the notebook-environment and introspection capabilities of a dynamic language are definitely nice (e.g. when taking apart some unknown JSON data format), but especially when it comes to complex logic and refactorings Rusts type system is really making a big positive impact on productivity. Sure TypeScripts type system is also powerful, but Rust is consistently better at infering types from closures and function calls, and the existing types and tooling story is miles ahead of TS. (and I've never encountered an easier to setup/use model checking language integration than Kani) For one-offs where correctness doesn't matter, sure throw $SCRIPTING_LANG at it. But once you want correct software, I'd still choose Rust in a heartbeat. reply cozzyd 1 hour agorootparentprevYou missed the point of the rule of thumb. Maybe rephrasing it as if 15 years ago you would have written it in C++ would help. reply j-pb 1 hour agorootparentNope. C++ has mostly downsides, Rust has significant upsides. A good rule of thumb would be: is correctness and code confidence more important than learning curve and compile times? If so Rust, otherwise JS or Python (with possibly parts in Rust). reply rob74 10 hours agorootparentpreva.k.a. \"resume-driven development\" reply makeitdouble 10 hours agorootparentTypically, devs polishing their resume instead of prioritising business metrics probably means the overall org is on the down slope. reply mytailorisrich 10 hours agorootparentPerfectly normal for people to want to develop their skills and to enhance their value. The thing is that this is not a developer's decision, this is a management decision. The developer might pitch for Rust or even start developing in Rust but if that is not right for the org then their manager should say 'no'. So ultimately this is a red flag about management. reply ndndjdjdn 9 hours agorootparentprevOr the dev wants more money reply FridgeSeal 8 hours agoparentprevGod I feel like I’m taking crazy pills when I read these threads. Can I hire 1000 Rust devs at the drop of a hat off the street? Well, no. Have I ever struggled to find competent Rust devs, or high level people who were happy to learn? Nope. I would absolutely not be afraid to use it because of “hiring concerns”. If your current devs can’t or won’t learn anything new, they’re not very good at their job. If you can’t or won’t hire because you can’t find a super-senior at the drop of a hat, well, your hiring process is broken and no language will really help there. reply jcgrillo 5 hours agorootparentThe underlying (absurd) assumption is that the sum total potential of a developer you hire to do a job is statically determined by their past experience at interview time. This is the problem with \"Human Resources\" thinking, it fails to account for all the, well, human stuff. Case in point from the article: > it is not viable (for us) to retrain a C developer to Rust What? Why the hell not? reply 6r17 10 hours agoparentprevI switched up from python to rust for some processing pipeline at work - rust has a lot of advantages over it specifically for typing and speed, the work itself it a little bit longer to develop. But the quality output is not even comparable, the code itself is way more readable and explicit than in python code. There is not a lot you can do to make your python code as good in terms of reliability or clarity of intent. I'm sorry to hear that you did not have a good experience with it, but frankly speaking, I cannot look at python code anymore because of the inherent \"hidden\" work that it creates, variables being passed trough without much care for their exact meaning, hidden \"bugs\" that make the overall job way more annoying to debug. Python is like that person that tells you everything is fine but is mostly wrong and won't even tell about that. Whereas Rust will just straight up tell you what's wrong in the draft. I prefer the honesty and the little additional overhead work to getting lost in debugs for weeks bc some person has inputed the wrong shape for some vals or whatnot. The peace of mind is saving me a ton on maintenance as well. (project is a 2years on with distributed python pipeline with a bunch of IA processing - switching up to rust was not the easiest thing to do considering some parts had to stay in python because of code ownership being someone's else - the stack is a rust/python stack now with some parts being left out in python depending on the actual needs of update) I understand very well that some people do not want to code in rust, specifically because they might not have the time or the will to do so. But objectively these people do not have to define the pipeline execution except for the actual order of execution, nor do they need to maintain every part of the code because it's just not their job. Now if you are to compare the exact benefits of rust vs python for a company, the server pricing will just speak itself and the choice will be made depending on the cost of production, the lifetime of the code, and the actual benefits. If I was to do some API today, I'd 50000% go for rust and I DO think of python as the `no-coder coder` thing. I initially learned C, switched up to Python for jobs, and the code quality of python is just downright bad. It does not push me in the right direction AT ALL. The fact that we used a scripting language with no typing for tools that need any kind of guarantee for years does not mean it's the best way to do it. Also to answer the problem concerning `rust` dev's being non-existant on the market, and no job being open is really simple : even tough rust has 10 years on the developer market on this is really young and need to learn. You need 3 years of practice to get 3 years of experience with rust. There is no way around that. And there is just not enough experienced people with this language yet to make it a shift. I'm not saying there is none, i'm saying it's not yet democratized. reply physicsguy 9 hours agorootparent> You need 3 years of practice to get 3 years of experience with rust. This is the major barrier. It's a difficult language to learn for people who've worked with a compiled, strictly typed language with manual memory management. That barrier is much higher for people who've only ever used a dynamic, interpreted language. I'm on-the-fence about orchestration of pipelines with Python since I've experienced a lot of the issues you're talking about, but you can just abstract the Python algorithm parts in to APIs that your pipelines call and separate out those two concerns. Then it's clear who has maintenance responsibility, it separates out the algorithms from data collection + calling, and it doesn't introduce a big barrier next time someone wants to implement something that depends on the latest and greatest algorithm written in Python, which writing in Rust inevitably does. To me though, I don't really understand the use of Rust in non-systems programming. For a lot of the use cases people talk about, Go seems like a better fit with a lot less of the pain since it's a much simpler language. When teaching people a language I'd much rather do that with Go than Rust, and that matters in an environment where developers who know either are not really that commonly available (at least here in the UK). reply ttfkam 5 hours agorootparent> This is the major barrier. It's a difficult language to learn for people who've worked with a compiled, strictly typed language with manual memory management. This was not what Google and others found when they studied it. https://www.theregister.com/AMP/2024/03/31/rust_google_c/ > More significant, Bergstrom said, is the comparison of rewrites of C++ code into Rust. > \"In every case we've seen a decrease by more than 2x in the amount of effort required to both build the services in Rust as well as maintain and update those services written in Rust,\" he said. reply 6r17 9 hours agorootparentprevI can 100% understand your take on `go` and will probably think of it more often ! reply FridgeSeal 7 hours agorootparentprev100% this. Well put. The Rust codebase I’ve built on run faster, don’t crash, are more correct, and take only marginally longer than the first python version. They’re easier to maintain, they’re easier to upgrade their dependencies, I’m more confident about asserting guarantees from the codebase, and it’s an easier time onboarding people and having them meaningfully contribute. There’s no more death-by-a-thousand-cuts that I experienced with Python codebases. I don’t have to worry about my Rust codebases blowing up at 2am because of some random exception. I am defs not going back. reply robertlagrant 8 hours agorootparentprev> The fact that we used a scripting language with no typing for tools that need any kind of guarantee for years does not mean it's the best way to do it. You can add typing tools now, though? CI pipeline runs mypy and that gets you a long way. reply realusername 10 hours agoparentprevWhat concerns me even more than the talent pool is that Rust is a language that isn't straightforward to learn. I can be confident to teach any average developer about Go without any prior experience relatively quickly, I'm not so confident I could do the same with Rust. reply ramon156 8 hours agorootparentThese comments make it seem like it's impossible for people to learn Rust. I have to admit that it takes a fair bit longer than other languages, but so is c/c++. Is there a bias towards not using Rust by other devs? Is it a scary language? reply ttfkam 5 hours agorootparentA garbage collector really takes away a huge amount of cognitive overhead. In doing away with it, Rust requires that you understand the borrow checker and lifetimes, even if minimally due to extensive use of .clone() in your early code. This ties into all of the different kinds of strings in Rust from str to string to vec[u8], etc. Unlike Go that only really requires experience in general programming to become rapidly productive, Rust basically requires that you read The Book in its entirety before you even think about applying that knowledge in production. There are just to many interdependent concepts to hand wave away the prep time. It all (mostly) makes sense once you've familiarized yourself with the basic concepts, but it's a training step you simply cannot skip without inflicting a fair amount of pain on yourself and others. reply oneshtein 2 hours agorootparentIt doesn't match my experience with Rust. How much code you wrote in Rust? reply realusername 8 hours agorootparentprevI'd put the same concerns for C and C++ to be fair. The learning curve just isn't the same as most other mainstream languages. reply ttfkam 5 hours agorootparentI'd put even more concerns on C++. All the same concerns plus all the concerns that arise from the compiler not helping you nearly as much. It's easy with C++ to be lulled into a false sense of security because it compiles, and your trivial happy path works. Under load or with unforeseen input, the chance for memory corruption is massive even for experts let alone beginners because it only takes one to bring down a whole process. C++ is better than it used to be, but it was truly atrocious in that regard for decades. It was simply the least worst option for those decades. I do not consider it the least worst option anymore. reply amelius 9 hours agorootparentprevGo is also a more productive language for many use cases. reply jcgrillo 5 hours agorootparentMy experience is the opposite. I spend a lot more time in a debugger when I work with golang than when I'm working with rust. Sure, there's a learning curve with rust's borrow checker, but once you figure out how to use it I find rust to be a much more \"flow state\" development experience, with less interruptions of the form \"what is this program actually doing and why?\" reply amelius 5 hours agorootparentYou forget that a lot of projects benefit greatly from generalized GC. reply jcgrillo 4 hours agorootparentNo. I didn't forget. It has not been my experience that not having a garbage collector in rust was a problem in practice. reply sunshowers 9 hours agorootparentprevOn day 1, yes, a newbie to Go would be able to be more productive. reply goodpoint 9 hours agoparentprev> Access to competant Rust developers can be a challenge even for large companies. Huh? There's tons of good developers looking for jobs right now, more so in Rust. reply culebron21 10 hours agoprevThe author complains there are few developers available to maintain Rust code. I see very few job postings, and almost all of them are either cryptocurrencies (I don't want to waste my life on this), or \"3 years professional Rust development in production\" (disqualifies self-learners). Given that nowadays most applications are not replied, it makes little sense to spend time even browsing the postings. reply rapsey 10 hours agoparentThere really is a strange dichotomy. Plenty of Rust developers have trouble finding jobs and apparently companies have trouble finding Rust developers. reply pytness 10 hours agorootparentFor being a relatively new language, there are almost no \"entry level\" positions. Just take a look at https://rustjobs.dev/. Most of them are well paid remote jobs, but they are asking for +3 years of \"professional experience\" with rust, \"with a proven track record of building and deploying production-quality code\", and more. Hell, iirc, i saw one asking for proof of contributions to the rust repo (eg, being a core maintainer). edit: to be fair, i saw one position a while ago asking to be willing to learn rust reply FridgeSeal 7 hours agorootparent> For being a relatively new language, there are almost no \"entry level\" positions. Isn’t this a fairly well-known phenomenon though? - new language makes waves. The people who picked it up early do some impressive stuff. - early early adopter companies either snap them, or internally make the choice to learn it too. In turn, they do some stuff with it. - gets a reputation for being the hot new thing. Other companies “want in on it”- they want to be able to do the fancy cool things the other places did, but they don’t have the patience, time or culture to grow it themselves so they aim to hire out seniors and everyone with lots of prior experience.3 years professional Rust development in production\" (disqualifies self-learners). It doesn't necessarily. Very few jobs postings that require \"N years of experience in language A\" actually require that. Most will accept N years of total experience and some smaller amount of experience (not necessarily professional) in language A. reply rty32 3 hours agorootparentChances are that recruiters just ignore your resume without even thinking about it. Especially if there are other candidates who do have that much experience in a specific language. Even if you are a better candidate overall (whatever that means), you need to pass the resume screening first. reply nicoburns 2 hours agorootparent> Chances are that recruiters just ignore your resume without even thinking about it. That's why should always try to avoid recruiters and apply direct if possible! > Especially if there are other candidates who do have that much experience in a specific language. True. But the context of this discussion is that there are not very many candidates with the (nominally) required experience (i.e. several years of professional Rust experience). And that's often the case as job specs often have unreasonable requirements. reply _proofs 1 hour agorootparentprevthis is the ideal but does not appear to really be the practice -- regardless of whether you're applying direct or not. reply DecoySalamander 9 hours agoparentprevSolvable by launching your own startup, using rust and running it for 3 years. reply myrmidon 10 hours agoprevA very important point that the article neglects is that for a lot of embedded platforms, you have to heavily rely on the hardware manufacturers libraries and tooling. All of that stuff is typically gonna be targeted at C. Without this, using even very simple hardware interfaces (like an SPI/I2C bus) is gonna be a huge pain, because you'll have to comb through reference manuals and register descriptions for your processor and piece everything together yourself instead of just calling a few API functions (this is also very error-prone and using Rust is not really gonna help one bit). The only chance to get even halfway decent rust integration is to pick one of the like 3 most popular hardware platforms among hobby enthusiasts (think ESP32, raspberry pico), which is simply not viable for a LOT of embedded applications. So I still think its probably a really bad idea for a typical embedded-shop to fully go for rust right now-- the downsides from lacking tooling/libraries, reduced developer pool and the need to train extant devs appear very hard to overcome to me. reply danhor 6 hours agoparentFor some complex peripherals (especially wireless) this may be the case, but in my experience it's often much easier to write small abstractions for what you need in the mode you need it in (for serial, timers, IO, DMA, ...) than relying on manufacturer SDKs, which are often so poorly documented that you need the reference manual anyways to understand the peripheral to then understand the abstraction, which is often much more complex to use than it needs to be for my use cases. With abstractions in Rust or, for something quickly thrown together, in uPython you're at least getting \"you're holding it wrong errors\". Interfacing with the peripheral registers themselves is also a bit simpler with Rust in my experience, as a proper .svd already contains bitfield setups with enums and R/RW/W1 information to at least set the bits you want instead of the Macro-Hell in C some manufacturers throw at you. reply leoedin 9 hours agoparentprev> A very important point that the article neglects is that for a lot of embedded platforms, you have to heavily rely on the hardware manufacturers libraries and tooling. All of that stuff is typically gonna be targeted at C. If you have a reference implementation in C it's not such a big job to set up something like an I2C or SPI peripheral. At it's core, you're making a sequence of writes to some memory locations. Most of the manufacturer libraries are quite low quality, and very easy to misuse. In my experience trying to do anything that pushes the hardware, you will end up combing through the reference manuals anyway. I've done a bit of embedded rust, and the huge benefit - just like on desktop - is that code which compiles tends to do what you intended. Obviously there's still scope for logic errors, but that takes away a huge amount of debugging time. reply vvanders 2 hours agoparentprevEven with the vendor libraries last time I had to poke at a CAN bus I ended up having to go to that same level because the C helper libraries omitted key features of the interface. There's a number of micros these days where the same libraries are provided using SVD[1] that will generate interfaces which is handy. [1] https://docs.rs/svd2rust/latest/svd2rust/ reply alex_suzuki 10 hours agoparentprevNot a Rust dev, but couldn’t you use FFI to call the C routines from Rust? Of course you‘ll have glue code which is seldom pretty, and depending on the amount of Rust actually involved at runtime it might be questionable to do in the first place. reply myrmidon 9 hours agorootparentAbsolutely! But this is a huge amount of complexity in build system/linker setup/debugger that you are gonna have to stay on top of. The gains from using Rust need to be overwhelming to justify a setup like that. Also consider that calling those FFI APIs from Rust is not gonna do anything for you by itself-- you are basically just calling C functions with extra steps... To actually get anything out of it, you'll then likely have to wrap the whole hardware interface in a \"rustified\" API (which, again, you'll probably have to write and maintain yourself...) reply acomjean 8 hours agorootparentMany years ago, our project had a library that would link our Ada code to the low level operating system calls that are in C (network, shared libraries etc). Once it was written the code was stable, but you bring back not so pleasant memories of building / testing. It might just be our make files were unnecessarily complex or we were building libraries not executables… reply wyager 1 hour agoparentprevRust solved this by autogenning code from mfgr published device xml descriptors. Eg https://embassy.dev/ Better than any C(++) embedded hal I've used reply stefan_ 6 hours agoparentprevThe irony in this article is that even the much lauded ESP32 integration is essentially all of the important stuff like WiFi continuing to run and live in the C world, while they have a little Rust frontend for all the hipsters to believe their great bugfree Rust code is making the world spin. reply RandomThoughts3 11 hours agoprevThe article is really light on actual details. Basically, this is a company who uses ESP32 to read serial data from batteries using UART and retransmits it in json over MQTT. They apparently had buggy C code to do that (for unspecified reasons) and successfully rewrote that in Rust. Conclusion, you can write ESP32 code in Rust. No information on what that actually entails sadly. reply whazor 9 hours agoparentSome more information on ESP32 on Rust. Espressif (the organisation behind ESP32) spent effort to properly support Rust on their chips, see their documentation: https://docs.esp-rs.org/book/ Another nice resource for Rust embedded is https://embassy.dev/ which also supports STM32, Nordic chips, and RP2040. IMO, the coolest feature about Rust embedded is that Async Rust works! This makes building a HTTP server for your embedded chip easy. reply qazxcvbnmlp 3 hours agorootparentMost embedded code is pretty bad at async - that could be a game changer. reply sgt 10 hours agoparentprevYes I wonder what was wrong with the C code. Was it fixable, was it just a single loop code that ran or could they have used something like FreeRTOS to handle multiple tasks with less chance of bugs? reply RandomThoughts3 10 hours agorootparentI would have liked to have more details because it's easy to have memory related issues when using a serial protocol in a memory constrained environment and I was wondering if somehow some feature of Rust helped them. I would guess that the more expressive type system is very nice but I don't expect memory safery features to be that useful in this context. Would like to hear from someone with real world experience on that. reply lsllc 1 hour agorootparentIf you're parsing a serial protocol on an embedded system where you're only getting a byte-at-a-time (from a register), or possibly up to 8 at a time, then a parser combinator library such as nom should make it very easy to create a bulletproof parser. Definitely much easier than in C, where I've resorted to using Ragel for safely parsing serial protocols (and also in Go!) since it generates a single small dependency free source file containing the state machine and your \"actions\", but nom is much more expressive. reply RandomThoughts3 47 minutes agorootparentDeeply doubt so. Parser combinators are notoriously poor performance and memory-wise. They are somewhat nice to write if you like the style and don’t mind the tax but we are talking about ESP32 here. Unless they are inexperienced, the issue is unlikely to be the state machine anyway and more likely to be in how they manage buffering of long message to avoid running out of RAM. reply usmanmehmood55 10 hours agoparentprevI was just about to point this out in my own comment but yours sums it up quite nicely. As an embedded software guy this article gives next to no specifics or details on what the bugs were and how they got solved with Rust. reply pixelfarmer 8 hours agoprevI remember looking into Rust for a personal project, on embedded, in 2016. After poking through all of it I decided against doing that because it was clear I'd be spending a lot of time getting Rust working at all instead of doing anything for the project itself. So C it was. The thing I have to say in the context of the article is this: There is no way to know whether a complete rewrite in C would have yielded similar results to Rust. The phrase \"C prototype\" made me squirm, even more so when reading that in the context of critical infrastructure. It is known by now (or should be) that such prototypes live on like zombies, so unless it is really some throwaway (from the point of architecture!), these things tend to live on for longer than most feel comfortable with. And, being so critical in function, maintainability is one of the primary concerns. Yes, Rust will, eventually, at some point, maybe? the go-to language we use in the embedded field, but we are talking not just about a language replacement, we are talking ecosystem replacement. That is not going to happen overnight. That said, as some mentioned Java, Perl, and such things: I revived a personal Perl 5 project not too long ago that was more than 20 years old by that point. Needed a small change because the latest installment of Perl 5 is a bit more restrictive with some borderline syntax things (good), but other than that it just worked. In the larger context of the project there is also some C code for binary file processing, also >20 years old. Needed a renaming of a POSIX function (arguments and functionality all the same, though), and then it worked, even compiled as native 64 bit code. Granted, there are not that many dependencies beside POSIX, and the code was even back then written to a level of quality that allowed it to run on all sorts of (POSIX) platforms already. Which is why \"C prototype\" sounds to me like \"we cobbled something together\", and all sorts of bugs are no surprise then. You can cut only so many corners before it becomes an issue, especially in software that is used all the time and in a critical place of a system. This needs to be done right, else you will waste a lot of time (and money!) afterwards. reply lnsru 7 hours agoparentImho Rust will be not much further in embedded world in 2026 than it was in 2016. I managed to get in the role where I have hiring decisions to make. From this perspective I need somebody to be able to work with existing projects in C from the 2006 instead of knowing cool new language. There is no single advantage for a company selling products to change the language used. Transition will only cost money. Regarding C prototype. I wrote it. 6000 lines of code, works nicely, 4200 lines of code were Xilinx driver calls to move data between the hardware blocks. So changing the language will not really bring any benefit. Maybe even opposite - one must study the register calls and read data sheets to create equivalent functions in other language. The code wasn’t beautiful, was created as “prototype” and was at the end the version shipped to a client. reply wyager 1 hour agorootparentI made this with rust in 2020 http://yager.io/vumeter/vu.html The embedded rust ecosystem has invanced a pretty insane degree since then. I have an ongoing embedded project and I have had to use C FFI calls a total of zero times in a ~100kloc codebase. There are native rust HAL libraries autogenerated from manufacturer published device specs that are insanely good, and take advantage of rust type system features to offer vastly superior APIs compared to mfgr provided C libs reply skwee357 10 hours agoprevAs someone who is using Rust in production for a year now [0], albeit in a different industry -- webdev, I really like the language. Sure, the first steps were rough, but eventually DX became decent, and the safety guarantees of Rust allow me to have a safe mind when developing and deploying (something I can't say about other popular dynamic languages). Having said that, I agree with one of the commenters in this thread: Rust is essentially a solution looking for a problem. It is a great language, but it fails to find its niche. Rust developers are nowhere to be found, companies are not hiring Rust developers (except if you want to work in crypto). [0]https://yieldcode.blog/post/one-year-of-rust-in-production/ reply kalaksi 9 hours agoparentI think it solves many problems regarding safety in lower level languages and with some great language features, so I can't really understand your take. Sure, C++ is more established with the benefits that entails, but that's not because of the language. reply skwee357 9 hours agorootparentI don't disagree with you. My comment was merely to agree with another commenter who said that there is a catch-22: Rust developers can't find jobs, while companies who are looking for Rust developers can't find candidates, because Rust can't really find its place in the industry outside the crypto world. reply kalaksi 9 hours agorootparentAh, right! I think rust will find more use but it takes time. Many existing technologies and languages are probably good enough for most suitable projects with historical baggage. Maybe crypto industry is just in a good position to try new, safer languages for new projects, who knows. Nowadays, Linux kernel also has some drivers written in rust so I'm hopeful. reply wanderingbit 9 hours agoparentprevIt has definitely found a niche in the crypto space, specifically with the node clients and the underlying new cryptography libraries they use. For instance, the more efficient Ethereum devs can make their node clients, the cheaper it is to run and the more people around the world can run it, which increases decentralization. Rust makes this possible without compromising on stability and maintainability. reply skwee357 9 hours agorootparentThe problem is that I still see all crypto as \"scam\", thus choosing Rust makes a non-viable choice for career progression. But I don't care about career progression anymore, so :shrug.png: reply physicsguy 6 hours agorootparentThere’s a guy who I work with who went to work for a crypto place that then exploded (as they all tend to do). He had quite a difficult time finding a new position, and was asked multiple times about working for a scammy company. So perhaps don’t underestimate the negative effect it can have career wise… reply pornel 8 hours agoparentprevIf you wouldn't write your program in C or C++, then it's not the problem that Rust is trying to solve. Rust has some nice high-level features and tools, so it gets used in other areas like web dev too, but in the end, it is a systems programming language. It is a low-level language, even though it may not feel like that a lot of the time. reply skwee357 8 hours agorootparentI disagree. Let's say I want to use a real type-safe language to write web applications. So rails/python/JavaScript/php is out of the window. I'm left with two big options: Java/Kotlin and C#. If I want to avoid Microsoft, I'm left with Java. And in fact, this is the industry standard for \"real\" web development: financial, enterprise, etc. But Java is cumbersome. It's very `FizBazBarFooAbstractInterface` type of cumbersome. Kotlin makes it nicer, but Kotlin didn't get much adoption in the web industry. C/C++ is too low level for web development. Rust is the perfect language, in my opinion of course, to fill this niche. Oh, there is also Go. Which is, by the way, also a system programming language. But nobody argues that Go shouldn't be used to write web services. reply creata 7 hours agorootparentBesides popularity (not denying that popularity is important!) is there a reason you'd prefer Rust over OCaml? reply skwee357 6 hours agorootparentNever considered. I grew up coding in C, so always wanted to come back to something similar. After being spoiled by PHP/JS, couldn't go back to C/C++. Rust offered me a modern, C-like language, so I just learned it and applied forcefully wherever I could. reply creata 6 hours agorootparentMakes sense, thanks. reply baq 7 hours agorootparentprevPlease excuse me for pointing out you don't disagree with the post you're saying you're disagreeing with. reply skwee357 6 hours agorootparentMy disagreement was referring to the statement that Ruts should be used only in-places where you'd consider C/C++. reply wyager 1 hour agoparentprevThe niche is anywhere C or C++ is used, which it excels at reply dextrous 6 hours agoprevI am a C/C++ dev learning Rust on my own, and enjoying it. I am finally starting to enjoy the jiu jitsu match with the compiler/borrow-checker and the warm “my code is safe” afterglow … but I have a question for the more experienced Rust devs out there, particularly in light of the OP’s observation about “lots of unsafe” in the Rust embedded realm (which makes sense). If your Rust project leans heavily on unsafe code and/or many libraries that use lots of unsafe, then aren’t you fooling yourself to some degree; i.e. trusting that the unsafe code you write or that written by the 10 other people who wrote the unsafe libs you’re using is ok? Seems like that tosses some cold water on the warm afterglow. reply danhau 6 hours agoparentYes, safe Rust is only as safe as the underlying unsafe code is. The power of unsafe is that it‘s opt-in, making the surface area of „dangerous“ code smaller, more visible and easier to reason about. As long as the unsafe parts are safe, you can rest assured that the safe parts will be safe too. reply throwawaymaths 2 hours agorootparent> As long as the unsafe parts are safe, you can rest assured that the safe parts will be safe too. That is not true. It is possible to have two pieces of validated unsafe code that are \"safe\" in isolation but when you use them in the same codebase, create something unsafe. This is especially true in embedded contexts, where you are often writing code that touches fixed memory offsets, and other shared globals like peripherals. reply iTokio 6 hours agorootparentprevAnother way to see the benefit of this approach is that if you have a memory violation, then you only have to look in the unsafe blocks. So, yes the less numerous they are, the more you gain from it. reply Ygg2 6 hours agoparentprev> If your Rust project leans heavily on unsafe code and/or many libraries that use lots of unsafe, then aren’t you fooling yourself to some degree That's why every unsafe block needs a SAFETY block. Is using vec.get_unchecked(6) safe? No. Is it safe for a vector that will under all circumstances (i.e. invariant) have exactly 64 element. Yes. As long as for all possible inputs in safe function your SAFETY block holds, that code is considered safe. reply blae 10 hours agoprevI hate how prevalent AI \"art\" has become on articles like these. reply augustk 9 hours agoparenthttps://www.reddit.com/r/Phobia/comments/webj9b/ai_generated... reply ndndjdjdn 9 hours agoparentprevIt is soo cheesy. The crab is even pulling a YT thumbnail face. reply baq 11 hours agoprevAs expected, the people problem is the biggest factor. Turns out getting C folks to learn Rust is a difficult proposition (hello, lkml) but the other way around it isn't too much of a problem. I wonder how much of it is low-level experienced developers only ever using C fail to see that C is not the universally best tool (or, 'if all you have is a hammer, everything looks like a nail' question). reply dunefox 11 hours agoparent> I wonder how much of it is low-level experienced developers only ever using C fail to see that C is not the universally best tool I'd say that's it. From my own experience with software developers, convincing some of them to learn something new is practically impossible. reply marcyb5st 10 hours agorootparentI generally speaking agree, but I would be more specific: If the person in question has a true passion for the craft, you can regardless of the age/seniority of the developer (at least in my experience). In fact, learning something like a new programing language is a big undertaking and if your work doesn't offer incentives/rewards the will has to come from the person him/herself and so that's why the passion bit I mentioned above. In my experience I also notice that more senior/older devs are more reluctant to learn new things, but I am unsure if that's due having their passion destroyed by many years of bullshit companies politics, pointless meetings/trainings, and adherence to the latest flavor of agile development every quarter or simply an age thing (I'm not there yet and so I can't tell first hand). reply wmil 8 hours agorootparentThe big problem with learning new programming languages is that you're going to suck at it for years until you reach the same level of familiarity with the new one. Suck here is more of an emotional thing. They can output high quality code fairly quickly. The issue is not knowing all of the quirks of the language and all development being slower and more difficult. Dropping down to simpler tasks while learning the language is a huge ego blow. reply baq 7 hours agorootparentAnd this is where LLMs help tremendously: you know exactly what you want to do, you don't know how to do it specifically like it should be done in the language you're learning, you query the latent space of the internet using plain english and you get an answer. It was a good argument literally a couple years ago less a few weeks before the chatgpt first release. Nowadays it's basically a moot point. reply dunefox 6 hours agorootparentI'm surprised at how useful the latest openai model is for me when it comes to either learn a python library or a new language, such as cl, for example. reply netdevnet 6 hours agorootparentprevWhen you learn a language, you don't just learn how to use the syntax of that language idiomatically. You also need to learn to use the different tools in that ecosystem reply Lanolderen 10 hours agorootparentprevWould this not also be partially connected to not wanting to throw away your 15 years experience with C for 1 year experience in Rust assuming the company actually ditches C? (or any other direct replacement language/tool scenario) Sounds like a way to replace yourself by 2 low pay students who also have 1 year of Rust experience. reply nsteel 10 hours agorootparentI'm genuinely surprised there are Rust developers out there that don't know C. Perhaps I'm showing my age, or my ignorance to how much CS education (even self-taught) has changed. reply Lanolderen 9 hours agorootparentIt's still thought but it's mostly a pointer course from my recent experience. It's a low credit subject where you play around with arrays and strings, maybe there will be an overflow calculation as well. Whereas something like Rust you'd do in a high credit course project where you have freedom over the tech stack and actually produce something with functionality. Edit: My point with the replacement is not that juniors don't/won't have C on their CV but that a manager would be more willing to replace an experienced dev with 1 year exp in the current tool with 2 worse devs also with 1 year exp in the current tool compared to replacing an experienced dev with say 10 years of experience in the current tool with 2 worse devs with 1 year experience in the current tool. reply nsteel 8 hours agorootparentI understood (and agree) with your original point. My comment about not having C experience/knowledge came from the article, where it really did sound like just that. reply jcgrillo 4 hours agorootparentprevI studied physics, not CS, so I can't really speak to the CS curriculum part. But I am someone who has written rust professionally for a few years so I'll describe how I got there. I think the most experience I've ever had with C was writing a fourth order Runge-Kutta routine and calling it from python for a college project. Maybe 20 lines of C? In industry for the first 5yr I wrote lots of python and java code for web APIs and \"big data\" systems. Simultaneously around 2015 I started getting interested in rust because it seemed interesting, and like it would probably play a big role in the next 20yr--memory safety without a garbage collector is inherently compelling if you've spent time trying to make java GC act right. Eventually I got a job which was a full time rust gig. After about 3 years of that I ended up in a golang shop. So I've written some tens of thousands of lines of rust and only a few lines of C. I read C, but it would take a while for me to get comfortable writing it. But I wouldn't, probably, because I can use rust instead. reply sgu999 8 hours agorootparentprevThat's really just being a Luddite, I understand the mindset but that's a very poor strategy if one cares about job security. A (good!) senior developer has a ton of value outside of the pure mastery of a language specs, not to mention that learning a language for 1 year with 15 years of prior knowledge really doesn't lead to the same level as a student who does the same. reply netdevnet 6 hours agorootparentThat kind of value only matters as long as you can find an ecosystem of companies that can be convinced to pay you what you think that value is worth. Many companies can't be convinced to do so and the companies that can are overflown by candidates smarter than you that have regular contributions in top rated github repos if they haven't made super popular frameworks and libraries reply marcyb5st 9 hours agorootparentprevI honestly don't see as throwing it away. The more you know the better software engineer you are with everything else being equal (IMHO). Also, if you need to gradually add rust to an existing codebase the C knowledge is extremely valuable. reply lawn 13 minutes agorootparentprevIt's surprising because I personally jump at an opportunity to try something new. Well, with some exceptions... reply netdevnet 6 hours agorootparentprevIt's a RoI. Are you just telling them to learn something new or are you explaining the benefits and costs of learning Rust when they could be learning X? reply ndiddy 8 hours agoparentprevThe article says that the author wanted to hire someone who knows both Rust and C to maintain his company's embedded projects, but was unwilling to hire a C developer and wait for them to learn Rust. I'm not sure how this supports your point. I would argue that it's more that most companies aren't willing to let their employees spend a significant amount of time learning new skills. reply whazor 9 hours agoparentprevGetting Rust developers to become Embedded Engineers is very interesting. Since it is easier to learn Rust than it is to learn C. reply wyager 1 hour agorootparentI think writing broken C is easier than writing correct Rust is easier than writing correct C. A lot of C(++) devs just like that they can mostly get away with writing broken code reply bboygravity 8 hours agoparentprevHow much of the embedded jobs are Rust? Maybe 1 percent? reply fulafel 10 hours agoparentprevThe complexity of Rust is on another level, it's a huge language. reply baq 8 hours agorootparentIt’s a tradeoff. The ownership rules are mostly the same as C. The difference is that Rust enforces them at compile time. reply fulafel 6 hours agorootparentHrm. These are the top level Rust ownership rules according to the book[1]: Each value in Rust has an owner. There can only be one owner at a time. When the owner goes out of scope, the value will be dropped. C has none of these. Or borrowing, etc. [1] https://doc.rust-lang.org/book/ch04-01-what-is-ownership.htm... reply baq 6 hours agorootparentTo get robust software out of C you don't have many options other than to adopt these rules. You can have useful software which breaks all of these, but you don't want to maintain it. reply throwawaymaths 2 hours agorootparentRobustness is relative. You can certainly write a cli that does everything in an arena; your GC is the OS and so going out of scope -- who cares. doing nothing and eliminating whole classes of errors from consideration (UAF e.g.) is incredibly maintainable. Or, as the old tale goes, your GC might be the software literally exploding (it's in an air to air missile) reply zifpanachr23 2 hours agorootparentprevIt's widespread practice to notate who owns what in the comments in C code. \"Ownership\" as a concept comes from well established C best practices and a good C developer is going to understand exactly what you mean if you say something like \"Caller owns the memory returned from this function\" etc. reply wyager 1 hour agorootparentprevUsing pointers correctly and safely in C basically requires tracking pointer rules substantially similar to the rust pointer rules, but in your head. Most people who don't do this just write incorrect code, although it might only rarely cause a serious problem. reply sshine 11 hours agoprevReposted: 2024-02-20 (3 comments): https://news.ycombinator.com/item?id=39446699 2024-02-04 (0 comments): https://news.ycombinator.com/item?id=39251131 reply cesaref 10 hours agoprevThe problem I have with articles like this is that if we were to substitute anything in for 'Rust', it would read the same. I imagine if they had re-written it in C it would also be better than before. If it was an advert for anything, it might be chucking away a dodgy prototype and starting again (which is surprisingly rare). Anyhow, on the other side of the coin, it's good to see newer languages getting a proper outing in real world situations. Proving stuff is 'up to it' can be a bit of a long haul, so every data point is useful. reply simon_void 10 hours agoparent> Rust takes longer to write than C > but spent basically zero time debugging that's the difference to rewriting it in C reply nicce 9 hours agorootparentOne could argue that when the program is finished without bugs, then it is maybe completed. So does it take actully longer to write with Rust? reply pornel 8 hours agorootparentIt depends how proficient you're in Rust. Once Rust itself is not a difficulty for you, there's a lot of productivity gained from having a modern language with many conveniences, and great tooling. Rust moves more bugs to compile time, so you will technically spend more time getting the code to compile, but in my experience in 99% of cases it's a time saving. And it lets you be more confident about a program correct by construction, rather than merely fuzzed and not observed to crash. The 1% of counter-examples is trying to be too clever with generic interfaces and hitting Rust's limits. reply Do123 10 hours agoprevDidn't they just have a shitty implementation written in C (could have been any other language...it's not the language!) and than learned from the past mistakes and written a new implementation in Rust(could have been any other language)? And now the author tries to attribute it's success to Rust? reply pornel 8 hours agoparentI've done many rewrites of C in C, and C in Rust, and there is a big difference that is directly attributable to Rust. The safety of references, no raw malloc, no null pointers, compiler-checked thread-safety of types, consistent and enforced error handling help a lot to make robust programs, and allow making bigger refactorings without fear of screwing something up. The Turing Tarpit means that theoretically everything you can write in Rust you could have written in C, but in practice Rust enables things that wouldn't be worth the risk/effort in C, even when doing a ground-up rewrite. reply alex_suzuki 9 hours agoparentprevMaybe. But them the dev wouldn’t have been able to add „Completed a migration of legacy C codebase to Rust with zero issues in production“ to their resume. Also might have been easier to get budget for „build something new to replace old thing“ than „fix pesky bugs in somewhat-working existing thing“. reply zifpanachr23 2 hours agorootparentGiven the difference in availability of jobs and the amount of code out there, unless you are working in startup world or on web dev, this would be a major red flag on a resume in a lot of cases. Even the use of the word \"legacy\" is a problem. Like, this isn't \"legacy\" you asshole, this is our companies highest revenue product with a decade of hard work behind it and we don't want somebody that is going to be constantly trying to shill rust when we hired you to help maintain an important C codebase that is part of the foundation of the business. We need you to get good at C, despite all its flaws and issues, not complain. This kind of attitude only works in an exceedingly small part of the software world that just happens to be disproportionately represented on sites like HN. Elsewhere, it's not a good luck to be using words like \"legacy\" on a resume without a lot of explanatory text about why exactly it really was legacy and deserved a full rewrite. reply diggan 7 hours agorootparentprevNot to mention it could also be more fun, something that sometimes can be more important than we think :) reply alex_suzuki 6 hours agorootparentFor the dev, absolutely:) reply Dowwie 5 hours agoprevIf you're going to try using rust for esp32 development, you'll use the wrapper libraries that Espressif maintains. When things don't work correctly, you'll be dealing with a larger problem space as you try to figure out whether the problem is your implementation / logic, the lower-level libraries, or the wrapper libraries. I don't know what benefits you're gaining using rust if you're not using a native rust (to the metal) stack of libraries. If only Oxide found a need for esp32 modules, perhaps they would be up for the task? reply jnordwick 7 hours agoprevTL;DR we had some buggy C code and fixed the bugs then rewrote it in Rust and wow we didn't have as many bugs... that we already fixed. Rewriting something is not the same as the first effort. Try green fielding see how long it can she develop it once you already had the first basic C code it's pretty trivial to convert it to rust most of the time especially just using other libraries. And imagine that. You fixed all the bugs in the prototype and the second rewrite didn't have as many bugs. That's his nothing about the second versions language it just says you fixed all the bugs in the prototype. reply marmaduke 11 hours agoprevI’m doing some C on esp32 currently, and wondered about switching to rust, and I understand that simple cases with Rust are solid. I’m definitely interested in trying it out. However we need to work with a lot of the hardware apis like twai, ble, lte, ota, etc. It seems like support is spotty or it’s DIY. It’s also worth keeping mind the remark about developer availability. I can generally answer questions about the C to someone who’s not experienced in C, while Rust might be another story. reply j-krieger 10 hours agoparent> It seems like support is spotty or it’s DIY I can somewhat attest to this! I have a pretty extensive prototype of using Rust on ESP32 in production. I wrote a reference implementation for ESP32 platforms deployed via BRSKI, a secure remote key bootstrapping protocol which builds upon attestation keys and public key infrastructure. I'm largely using `esp-idf-svc` for most things, which is a Rust-native wrapper around ESP-IDF code. For anything closer to the hardware, I'm using `esp-idf-sys` which is just a thin wrapper around the the `ESP-IDF` SDK. You can see the project here: https://github.com/hm-seclab/open-brski Hope this helps! I'm by no means an expert but I sometimes help contribute to the Rust ESP32 ecosystem, so ask away if you want :) reply marmaduke 4 hours agorootparentHi! Thanks for your reply. First time hearing about Brski, I’ll have a look I guess your takeaway is that despite spotty support, the benefits of rust are net positive? I guess learning to call C from Rust is gonna be part of it too right ? reply nsoonhui 9 hours agoprevI'm ignorant about Rust, but to me it's just static type language akin to C#. And C# has IOT library which seems to target Rust most usual use case, namely on embedded platform. C# also has memory safety just like Rust. So why do we need Rust at all? What's the use case for it? Anything that I'm missing? reply leoedin 9 hours agoparentRust compiles to native machine code. C# compiles to bytecode which runs in a runtime environment. That adds a huge amount of overhead, and means you don't have direct access to the hardware registers. The .net IoT framework is targeting computers running operating systems. When you compile rust for an embedded target it's running \"bare metal\" - there's no operating system, the microcontroller literally just starts running the instructions your compiler put at memory address 0. If you want anything an operating system offers - task scheduling, memory allocation, file system access, network access etc - you have to compile it into the binary that's loaded into the microcontroller. Only languages which compile directly to machine code are really suitable for that - C, C++, Rust (plus a long list of less common ones - this list of languages which can compile using LLVM is a good place to start https://github.com/learn-llvm/awesome-llvm?tab=readme-ov-fil...) reply neonsunset 3 hours agorootparent- https://nanoframework.net/ - https://www.wildernesslabs.co/device Here are examples where C# is successfully used as a language for an embedded target. In addition to that, compiling to bytecode is just one way to execute it out of many, and the statement does not correspond to reality. I'm not arguing C# is a good language for IoT. I'd personally use Rust for that in almost every situation, but the amount of false claims in this discussion is disheartening. reply 15155 9 hours agoparentprev> Anything that I'm missing? C# is garbage collected. This is a no-go in many/most embedded software applications. C# also grants you poor explicit control over heap/stack allocation: this is essential for embedded development. reply nlitened 9 hours agorootparentIs it really true though? I don't have much knowledge about embedded development, but as far as I know, Java has been used in many embedded systems, and was running on phones' SIM-cards. Please correct me if I am wrong. I think that most modern embedded systems are nowadays more powerful than my first desktop computer — is it really still worth for the majority of embedded projects to count every byte at the expense of developers' productivity (and overall project success, as a result)? reply leoedin 9 hours agorootparentSIM cards are a weird exception because they have a hardware computer designed to run a subset of Java. Normally Java compiles to a bytecode which is run by the Java VM - in SIM cards the VM is a hardware implementation of the Java VM. That's super uncommon - most processors in the world have a different instruction set, like ARM or RISC or x86. Java can't compile to instructions in those languages. Rust can. Yes, you can run a VM on one of those processors in which you run a language like C# or Java. Look at MicroPython as a successful example. But the code which runs that VM has to be written in something. Typically that has been C and C++ - but Rust can also do it. You're right though - a lot of what we call \"embedded computing\" could be done using a modern VM interpreted language. There are some languages out there - MicroPython and Squirrel come to mind - which can run on the memory and storage constrained environment of a microcontroller. The mainstream implementations of Java and C# use way to much memory - they've been optimised for desktop environments. Microcontrollers often have 64 - 1024 kB of RAM. You could ship products with application processors like the Raspberry Pi, running an OS, and write your application in whatever language you like. But that costs 1-2 orders of magnitude more money. A cheap microcontroller is $1. By the time you've added the RAM, flash and supporting power rails, a cheap application processor is $10+. Then you have to maintain an OS - that's a lot of engineering time. Sometimes it's worth it, sometimes it's not - the tradeoff depends on the product. reply psychoslave 9 hours agorootparentprevNot sure how well it fits reality, but it’s also to a large extend how dramatic can be the result of a fault of your system. If it’s embedded in a coffee machine, maybe all cost-effective taken into account it’s ok to have an over-bloated software stack maintained by the cheapest folk the manager could found. Now if you are working on embedded software for some vehicle like a critical part of a car, a train or a spaceship, considerations of safety for both ethic and legal reasons might lead to different tradeoffs and conclusions. reply neonsunset 3 hours agorootparentprevC# is the language with the best degree of control over allocation among all GC-based languages. You can write code that is completely allocation-free including abstractions. Most \"data processing\" APIs in the standard library do not allocate at all or allocate once for initializing e.g. lookup tables. The actual issue is existing selection of runtimes for embedded platforms is limited: https://nanoframework.net/ and https://www.wildernesslabs.co/device (to be fair, a friend of mine uses the second one for automating his lab for his microfluidics devices research project, so it is useful). reply 15155 15 minutes agorootparent> C# is the language with the best degree of control over allocation among all GC-based languages. It's the best, but if I can't say: \"never heap allocate under any circumstances,\" it's a problem. reply unnouinceput 4 hours agorootparentprevI would argue that using JSON in embedded, especially on ESP32, is another no-go. I'd wage that using a binary format and later on, after you're out of ESP32, convert it to JSON would be a bigger performance gain than the evangelic tone of this article vis-a-vis of Rust. reply lionkor 7 hours agoparentprevYou're missing that Rust has safety in terms of multithreading, which C# doesn't have. Writing a data race in C# is the default, writing thread safe code takes work. In Rust, the default is that it's safe, you have to jump through a lot of hoops to try to make it not thread safe. The same is true for async, which in C# is also a problem. In all C# codebases I've seen, you have threads and tasks, and you often run into multiple threads or tasks holding a mutable reference to the same data. That's not legal in Rust without synchronization/locking. If you don't believe me, just spin up a new main.rs file and write code that has a data race. reply throwawaymaths 2 hours agorootparentEasy. Decide to use an ecs system because of its lower memory footprint. Pass around integer indices. Use two threads. Data race. reply neonsunset 2 hours agorootparentprevThis was recently discussed: https://news.ycombinator.com/item?id=41801124 While it is true that Rust is a strictly superior option for highly concurrent systems code, it still leaves areas where you can make a mistake regarding lock management and other advanced forms of synchronization. In addition to that, .NET as platform is fairly tolerant to misuse and calling the code that is not thread-safe from multiple threads concurrently usually leads to logic bugs or \"stop modifying this collection concurrently, please\" exceptions but not to catastrophic memory safety issues like it happens in C/C++. You can read more on its low-level memory model here: https://github.com/dotnet/runtime/blob/main/docs/design/spec... > The same is true for async, which in C# is also a problem. Now, this one is strictly not true. Async primitives are thread-safe. In Rust, you must synchronize because at the very least you must deterministically deallocate memory used by shared state between the tasks. In C#, this complexity is handled for you by a GC (ironically, you get negative sentiment towards async from people having experienced Python's async or Rust's async complexity, assuming the same applies to C#). In some scenarios, it is also a throughput optimization since it reduces memory contention by not modifying the cachelines shared between the cores, lending itself into better performance on many-core systems - the memory is modified/reclaimed when it's no longer in use, while the actively shared data is placed elsewhere. reply fwip 2 hours agoparentprevI think the thing you're missing here is that \"Internet of Things\" usually means machines way beefier than \"embedded.\" IoT is roughly equivalent to a Raspberry Pi - the thing will usually have an operating system that you're running on top of, and most of your existing knowledge about computers will port over. Embedded is the chip in a happy meal toy, or your microwave in 1995. There is no \"operating system.\" Your code is the only code running on the machine. reply bpbp-mango 11 hours agoprevnice pop-up that scrolls you to the top of the article reply 6r17 11 hours agoparentI was using brave and did not see that popup reply goodpoint 9 hours agoprev> Since Rust, and especially embedded Rust (lots of FFI & unsafe), is quite hard to learn, it is not viable (for us) to retrain a C developer to Rust. Rust does not need a phd in quantum physics. Anybody can learn it with a bit of patience. reply priio 3 hours agoprevHas anyone tried Nim in embedded systems? I wonder how it went. reply n8henrie 5 hours agoprevESP32. ESP-IDF, not no_std. reply goodpoint 9 hours agoprev [–] Really? https://join.com/companies/stabl/12642327-initiative-applica... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Michael Lohr from STABL Energy discusses using Rust for embedded systems on the ESP32 platform, highlighting its reliability over C for connecting battery storage systems to the cloud.",
      "The transition to Rust began in 2022 due to reliability issues with C, and despite longer development times, Rust required minimal debugging and has been bug-free in production for over a year.",
      "A challenge remains in finding developers skilled in both Rust and C, but Rust is considered a viable choice for embedded projects, with Lohr favoring it over C."
    ],
    "commentSummary": [
      "A developer recounted their experience of transitioning tools from Python to Rust in a large game development company, resulting in faster but unmaintainable tools due to limited Rust expertise.",
      "The decision to adopt Rust was based on personal interest rather than business needs, leading to technical debt and highlighting the challenges of integrating new languages.",
      "Despite Rust's advantages in safety and performance, its adoption in production is often impeded by the scarcity of experienced developers and the language's complexity."
    ],
    "points": 184,
    "commentCount": 229,
    "retryCount": 0,
    "time": 1728885968
  },
  {
    "id": 41837204,
    "title": "X11 tool to share a screen area in any video meeting",
    "originLink": "https://github.com/splitbrain/clipscreen",
    "originBody": "clipscreen clipscreen is a simple application that creates a virtual monitor that mirrors a portion of your screen. A green rectangle highlights the specified area. Why's this useful? You can use any screen sharing tool (Google Meet, Microsoft Teams, Jitsi Meet, etc.) to share the virtual monitor instead of your entire screen. No need to share individual windows and having to switch between them, just move any window you want to share into the green border. Compile Ensure you have the following installed on your system: X11 development libraries Cairo graphics library A C++ compiler (e.g., g++) Then simply run the following command to compile the application: make Note: The application has only been tested on Linux and xorg. I doubt it will work on any other system. Usage Run the compiled executable with the following command: ./clipscreen : The width of the overlay and virtual monitor. : The height of the overlay and virtual monitor. : The x-coordinate of the top-left corner of the overlay and virtual monitor. : The y-coordinate of the top-left corner of the overlay and virtual monitor. For example: ./clipscreen 800 600 100 100 This command will create an 800x600 overlay window starting at position (100, 100) on your screen. Termination To terminate the application, press Ctrl+C in the terminal where the application is running. License Copyright 2024 Andreas Gohr andi@splitbrain.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "commentLink": "https://news.ycombinator.com/item?id=41837204",
    "commentBody": "X11 tool to share a screen area in any video meeting (github.com/splitbrain)175 points by splitbrain 5 hours agohidepastfavorite86 comments splitbrain 5 hours agoI have a big 49\" wide screen monitor and sharing my screen in Google Meet was cumbersome because you can only share a window or the whole screen, but not a screen region. So I wrote a small tool that uses the xrandr extension to mirror an area to a virtual monitor which then can be shared. See my blog post for some more details: https://www.splitbrain.org/blog/2024-10/11-introducing_clips... reply OsrsNeedsf2P 4 hours agoprevI love how simple this is- Barely 100 lines or C++ (ignoring comments). That's one thing that makes me prefer X11 over Wayland. reply asveikau 3 hours agoparentThe code is a little weird. There is no XLib event loop. It calls sleep(100) in a loop until it hits SIGINT. That will have high cpu usage for no reason. reply diath 3 hours agorootparentIt will not, even adding just a 1ms sleep in a loop will drop CPU usage to barely noticeable levels, 10 wakes a second is barely anything for any CPU from the past 3 decades. reply thwarted 1 hour agorootparentThis is what the pause(2) syscall was made for, waiting for a signal forever. reply Too 36 minutes agorootparentprevIt’s a good way to drain your battery on mobile devices, even if usage looks low. Not that this matters for this particular tool. reply erickj 4 minutes agorootparent> Not that this matters for this particular tool. Then the code is perfectly appropriate. reply asveikau 3 hours agorootparentprevNot my experience at all. Granted I haven't tried writing a loop like this in 20ish years, because once you spot that mistake you don't tend to make it again, and CPUs are better now. Another thing to note is when you call sleep with a low value it may decide not to sleep at all, so this loop just might be constantly doing syscalls in a tight loop. reply diath 3 hours agorootparent> Not my experience at all. Granted I haven't tried writing a loop like this in 20ish years, because once you spot that mistake you don't tend to make it again, and CPUs are better now. You can trivially verify it by running the following, I have personally been using \"sleep for 1ms in a loop to prevent CPU burn\" for years and never noticed it having any impact, it's not until I go into microseconds when I can start noticing my CPU doing more busy work. // g++ -std=c++20 -osleep sleep.cpp #include#includeint main(int, char **) { while (true) { std::this_thread::sleep_for(std::chrono::milliseconds {1}); } return 0; } > Another thing to note is when you call sleep with a low value it may decide not to sleep at all, so this loop just might be constantly doing syscalls in a tight loop. On what system? AFAIK, if your sleep time is low enough, it will round up to whatever is the OS clock resolution multiple, not skip the sleep call completely. On Linux, it will use nanosleep(2) and I cannot see any mention of the sleep not suspending the thread at all with low values. reply asveikau 1 hour agorootparentIf memory serves, Windows treats a sleep under the scheduler quantum length as a yield. It may take you off the cpu if there's something else to run but it may not. Meanwhile burning up cycles may prevent low power states. At any rate, back to the code at hand, there are many ways to block on SIGINT without polling. But it's also hugely odd that this code does not read events from the X11 socket while it does so. This is code smell, and a poorly behaved X client. reply tapoxi 3 hours agoparentprevIn Wayland you just start a capture with the xdg-desktop-portal API and it notifies the user and let them select the area to capture. reply gchamonlive 3 hours agorootparentYes, but I believe op was refering to how interacting with all things Wayland seems to be more involved than with x11. I'm not sure this is indeed like this, I have zero experience in developing for Wayland, but I think this is what op meant. reply yndoendo 1 hour agorootparentWayland is more focused on security. That onion layer right there will increase the complexity of usage. X11 doesn't have the extra abstractions to limit and prevent intrusive interactions with the desktop. Example of this would be where \"runas /user:smith application.exe\" is simple but does not work when a Windows Service is required to run an application as the user signed in. One must use Window's API to pull in the account's token and use more API to execute \"application.exe\". UltraVNC is a great source to see all the extras needed. reply tapoxi 3 hours agorootparentprevFrom a quick \"how do I implement this in Python\" with ChatGPT it seems to be about 30 lines, since most of the heavy lifting is done for you by the API. reply Zetaphor 2 hours agorootparentAs someone who uses LLM's regularly to assist in code creation, take that output with a huge grain of salt until you've actually tested it. Especially as it relates to Wayland, I've pulled my hair out trying to get an LLM to assist with very similar tasks to this. reply sim7c00 4 hours agoparentprevthere's very little code because there's very little error handling / sanity checking. not saying X11 isn't hackable and cool, but a lot of code gets bloated and complex (and robust!) by not assuming perfect usage. for example. run ./clipscreen 1 2 3 4 reply splitbrain 3 hours agorootparentTrue. If something goes wrong this will just crash. But to be fair, the only error handling I could think of would probably just exit with a vague error message... Pull requests to make it more robust welcome anyway! reply xrd 2 hours agorootparentTo the parent, splitbrain just got you to QA this for him. The true cost of software is the maintenance and QA, and he got you to do free work, and here I am doing free work writing about it. How hard we BOTH just got pwned!reply sim7c00 1 hour agorootparentwill work for food reply sim7c00 2 hours agorootparentprevhaha yeah, its ok for a tool its really cool honestly :p just commenting on the 'so little code' might be good to check if the x y etc. are within the screen / set resolution perhaps. reply jchw 3 hours agoparentprevThis certainly is an elegant X.org party trick that can't be done easily in almost any other windowing system: creating a virtual Xrandr display that overlaps with existing physical displays. It's slightly awkward since if it exits outside of sigint it will leave a virtual output and no overlay window but that's a pretty minor issue. (All of that having been said, I would strongly advise to not over-index on SLoC as a measure of quality or elegance.) This flat-out can't be done in Wayland. Though all is not lost, you might not need this at all in Wayland. The standard way to capture the screen from an unprivileged process in Wayland is through desktop portals, and at least KDE supports a wide variety of different capture options including capturing a rectangle of the screen. I haven't tried, but I suspect this is even true when running X.org applications, thanks to XWaylandVideoBridge. I am not really thrilled about D-Bus stuff everywhere, but it is nice that you can pretty much override any screen capture behavior you want by changing the org.freedesktop.impl.portal.ScreenCast implementation: I think that's actually a step in a better direction versus having every application implement its own functionality for selecting capture targets. reply rnhmjoj 55 minutes agorootparentTo me it's quite sad that for a lot of things, the \"standard\" way of doing something is not actually part of the standard (XDG portals, third party protocols, etc.). Yes, X.org is old, bloated, unmaintainable and whathever, but at least every desktop environment used the same X server implementation and the same tools worked everywhere. Besides the duplication of efforts in implementing the same stuff over and over, now someone developing somewhat non-trivial programs needs to be aware of the differences in supported features and non-standard extensions in all desktops, for example [1]. [1]: https://wayland.app/protocols/cursor-shape-v1#compositor-sup... reply teekert 3 hours agoparentprevIs it much more difficult under Wayland? reply ajross 4 hours agoparentprevYeah. I mean, not to deny the decades of arguments over its warts, but it's kind of amazing to me the extent to which X11 has emerged as, well, the simplest/best and most hackable desktop graphics environment available. You want to play a trick, it's right there. The ICCCM got a ton of hate back in the early 90's, but... no one else has an equivalent and people still innovate in the WM space even today. reply WD-42 4 hours agorootparentHackable is right. But not always in the positive sense of the word. reply l72 3 hours agorootparentI find it very interesting how much our threat model has changed in the last 10-15 years. We no longer trust even local software, as we have to assume everything is now malicious. Commercial software from \"reputable\" companies can't be trusted to not pull a ton of analytics and personal data off your computer. We now have to worry about every piece of software being a keylogger and spying on other windows/applications and reporting back. We've had to give up so much flexibility. Wayland certainly focuses on plugging this hole, but it means we've lost all these cool utilities like this one. There was just so much you could do with devilspie, xdotool, and others to make sure my operating system and window environment worked for me. I still really miss X11's Zaphod mode, where you had two independent X sessions (:0.0 and :0.1) on two different monitors, with different window managers and different windowing rules. I miss the days of being able to trust my computer and trust my software. reply singpolyma3 3 hours agorootparentIf you can't trust your locally installed software, everything is lost. I understand where this new threat model comes from for some people but I'd rather continue to avoid bad software sources than hamstring my OS in the hopes of avoiding malware I installed on purpose. reply l72 2 hours agorootparentI agree. But can you trust Zoom? What about Office or Photoshop? Can you trust Websites or your browser anymore? Even open source apps have analytics in them that may not be trustworthy anymore (firefox, audacity, ...). reply marcosdumay 2 hours agorootparentprev> If you can't trust your locally installed software, everything is lost. That's only true if you decide to trust it. You can deal perfectly well with software you distrust, and not have it harm your system. reply ajross 4 hours agorootparentprevFWIW, the threat model you're imagining is an attacker being able to run code to display directly to the desktop using the lowest level native API. A local[1] code exploit at the level of an interactive user is already a huge failure in the modern world. Is that a reasonable argument against using X11? Sure, for some use cases. Is it a good argument for wayland/windows/OSX/whatever to do your tiling WM experimentation? Not really, those environments kinda suck for playing around with. [1] Or \"local-ish\", your system or a trusted remote has to have been compromised already. Untrusted X11 protocol still exists but is deliberately disabled (and often blocked) everywhere. Even ssh won't forward it anymore unless you dig out the option and turn it on manually. reply boudin 4 hours agorootparentIsn't any app that can access read the x11 socket able to read any input? It's not just running an explicitly malicious app but also the risk of compromising an app which can read the x11 socket (e.g. Firefox) reply p_l 3 hours agorootparentIt's also why there existed more advanced security extensions for X11 (like security labels for windows), but also why even bare-bones X11 had methods to ensure that only one specific application was getting input, specifically to handle secure input like with passwords. reply ajross 3 hours agorootparentprevYes, exactly. I'm just saying that the response to a remote browser exploit in firefox is more likely to be \"YIKES ZERO DAY IN FIREFOX!!!!!\" and not \"well it's a good thing we're running it in windows so it can't screenshot other apps or inject key events\". It's not like it's not a valid argument, just that it's sort of a nitpick. Security is hard, and defense in depth is a thing, but this particular attack surface is way, way back in the \"depth\" stack for a modern app deployment. reply superkuh 2 hours agorootparentJavascript has managed to even ruin the linux desktop. Running every random JS application sent to your browser VM makes the browser insecure which means the entire computer can't be trusted. This is the reason things like the waylands enforce a smartphone like model of security where the user's applications aren't allowed to communicate or interact with other elements of the graphical desktop. Applications aren't trusted. So the user isn't trusted. A trade-off not worth it. reply themerone 3 hours agorootparentprevX11 is the opposite of simple and hackable. What you are thinking of as \"hackable\" is actually the result of it having a ton of legacy features that enable users to do neat tricks. Wayland breaks a lot of these tools because it is so much simpler than X. reply vidarh 3 hours agorootparentBy window manager started out as ~50 lines of Ruby copying an equivalent amount of C. You can say many things about Wayland, but it's \"simple\" from a point of view I for one really do not care about. Wayland may be \"simple\" in some respects, but it makes most of the things I care about doing unnecessarily complex. reply bee_rider 3 hours agorootparentWalyand probably would have been better if wlroots had been developed as a (whatever this means) first-party “built-in” library. reply ajross 3 hours agorootparentprevLacking features isn't the same thing as \"simpler\", Wayland is great, but is very much a subset of the features implemented on an X11 desktop. Wayland doesn't do selections or provide any IPC mechanism of its own, much less something like an ICCCM that allows you to identify/target other users of the desktop and interact with them in a flexible way. In fact as I understand it the linked tool is in fact impossible to write in Wayland. Again, this isn't the fault of \"Wayland\", which is just a compositor framework. The complaint is that the ecosystem of \"desktop\" software which evolved around Wayland is an ad hoc monstrosity that lacks the unified structure that its ancestor had way back in the X11R5 days. reply anthk 3 hours agorootparentprevThe most hackable would have been a Lisp based desktop. reply salviati 3 hours agoprevDo I understand correctly that you could to this with OBS on any platform, including Wayland? I'm reading many comments that make me think either many people don't know about OBS, or I'm overestimating it's abilities. reply splitbrain 3 hours agoparentYou probably can. I never used OBS, but it's probably a bit more than a 20kb binary though ;-) reply lopkeny12ko 2 hours agorootparentI don't understand, what is the significance of a 20kb binary? The only person using this would be someone who takes Zoom meetings on a company-issued computer and I can't imagine such machines are disk space-constrained. reply hamdouni 6 minutes agorootparentI'm not aware of company issued computer with x11. Is it really a thing ? reply Brajeshwar 4 hours agoprevAlso, I remember a friend showing me in Zoom that you can share not just one but multiple screens/windows—press the SHFT key while clicking the windows you want to share. reply HPsquared 4 hours agoparentHow do people discover these things? reply jdbdndj 3 hours agorootparentIsn't that the same of how you select multiple files in most file managers? Shift+Click: select from currently selected item to clicked item Ctrl+Click: add/remove clicked item to set of selected items reply hackernewds 1 hour agorootparentSure, but the idea you can share multiple windows this way. Can Google Meet (or hangout or w/e they call it now adays) do some of this? reply Brajeshwar 4 hours agorootparentprevThe same question I asked (that was me after using Zoom for 3+ years). reply 0cf8612b2e1e 1 hour agoprevCan someone explain why this is still an unmet need within the current video conference platforms? Giant monitors have become increasingly common-especially for the developers who might be working on these tools. reply simonmysun 57 minutes agoparentMaybe because a workaround with OBS isn't that difficult? reply z991 5 hours agoprevWow, this is fantastic! This exact use case, on Linux, is why our company selected Zoom instead of Meet. Awesome! reply z991 4 hours agoparentBuilt it and took a fullscreen screenshot with GIMP to figure out the width/height/x/y coordinates I wanted and tested with Google Meet. Working perfectly! reply machinestops 4 hours agorootparenthttps://github.com/naelstrof/slop Can also use a utility like this one, which lets you select an area of the screen and output it in a specified format. reply z991 4 hours agorootparentWow that is also very cool. For those wondering, this is what it looks like: $ sudo apt install slop $ slop1719x1403+1080+277 reply machinestops 3 hours agorootparentPutting the two together is easy too: $ clipscreen $(slop -F \"%x %y %w %h\") NB. The lack of quotes around $() enables wordsplitting to occur. reply Narishma 1 hour agorootparentI think you got the size and position switched. reply samwhiteUK 1 hour agorootparentprevOr $ clipscreen $(sloptr -s \"+x\" \" \") reply hackernewds 1 hour agorootparentprevthis is just cmd+shift+5 in a Mac OS reply yjftsjthsd-h 21 minutes agorootparentIs it? I thought that took a screenshot, not fed coordinates to a program (in this case a screen sharing program) reply hackernewds 1 hour agorootparentprevDid you have any issues implementing? reply attah_ 24 minutes agoprevI was just about to go looking for something like this! I'll look so pro on the meeting tomorrow :) reply tcsenpai 2 hours agoprevThis is surely useful right now. I wonder what will happens to all the nice X11 tools once Wayland (hopefully soon) will be the golden standard. There are options to enable X11 behaviors in Wayland but I guess that is just a fallback to the insecure implementation. reply alanjames00 2 hours agoprevI've looking for something like this for quite sometime. It's simple, clean and elegant. reply amelius 4 hours agoprevNice. This is the first time I read about creating a virtual monitor in X. reply IceDane 1 hour agoprevYou can literally do this with just xrandr. xrandr --setmonitor screenshare 2560/1x1440/1+0+0 none reply attah_ 23 minutes agoparentIn fairness; that and the overlay is what is happening, just from C++. Props for nice oneliner none the less. :) reply udev4096 3 hours agoprevThis is only helpful if you are using a desktop environment. What about window managers like i3? reply hamdouni 1 minute agoparentI'm not sure about i3 but you can have floating windows in DWM and move them to the targeted area with the mouse reply benjiweber 4 hours agoprevThis is brilliant. I've wanted this so many times and had to awkwardly switch between window being shared instead. reply fweimer 3 hours agoparentI wouldn't mind switching between windows if I could use the GNOME Activities overview for that. But maybe that is not possible because there is no way to communicate the change in stream size if the windows have different sizes? reply procparam 2 hours agoprevI've always wanted something like this, but for i3 workspaces. Something like \"share workspace 2.\" Anyone know how to accomplish this? reply shmerl 27 minutes agoprevI'm waiting for ffmpeg to implement pipewire screen grab so it could work on Wayland. reply snowe2010 4 hours agoprevDang. I need this for Mac. I’ve been wishing I had exactly this for years. reply _joel 3 hours agoparentWasn't the same thing posted for MacOS a few days back, can't recall the name? Looking at the time on the repo makes me think the author pushed after seeing people requesting something similar for Linux. edit: Here you go https://github.com/Stengo/DeskPad reply joombaga 3 hours agorootparentThat's not quite the same. With DeskPad you have to move the window to the virtual monitor. clipscreen allows you to select a portion of your screen without moving any windows. reply iknowstuff 59 minutes agoparentprevyou can just share multiple windows on the newest macOS and they will ne nicely arranged for viewers. You can even add the presenter thing to show your face next to them. reply thefreeman 3 hours agoparentprevI use \"Advanced Screen Share\" for this purpose. it has a one time purchase if you want to remove a small overlay but it gets the job done and is installable through the app store. reply yazzku 1 hour agoprevCan you not use std::condition_variable to avoid the active waiting of the signal? reply TacticalCoder 4 hours agoprevThat s very cool... Speaking of which: any easy way to allow two people, both on X, to both share and interact (keyboard and mouse) with a common X window? The app that we d like to share and both control is a browser (running on a machine on our LAN) so a browser extension would work too I guess. reply bee_rider 3 hours agoparentI think there was some way to do that with existing tools. I forget the details because I only threw it together as a bit of fun novelty. I think the terms to google are x2x and multiseat though, at least to start your search… reply patrakov 4 hours agoparentprevMy preferred solution for that would be a VNC server (so that it shares the whole screen) installed in a VM. reply ho_schi 3 hours agoprevNeat. Now I want for Wayland. Don’t use X11 for some years. reply singpolyma3 2 hours agoparentNever to late to upgrade to X11 :) reply TZubiri 5 hours agoprev [4 more] [flagged] ragebol 5 hours agoparentAs per the blog post, only Zoom allows to stream a selected area of the screen. What other proprietary SW can do this? With this tool, they should all be able to reply splitbrain 5 hours agoparentprevI'm not sure what you are referring to. What's the proprietary solution you're suggesting here? reply squilliam 5 hours agoparentprev [–] OBS has had the ability to do this for quite some time reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Clipscreen is an app that creates a virtual monitor to mirror a specific part of your screen, useful for sharing in video conferencing tools like Google Meet or Microsoft Teams.",
      "It requires X11 development libraries, the Cairo graphics library, and a C++ compiler to compile, and it operates on Linux with xorg.",
      "The app is licensed under a permissive free software license, allowing for broad usage and modification."
    ],
    "commentSummary": [
      "A developer has created a tool using the X11 xrandr extension to allow sharing of specific screen areas in video meetings, addressing limitations in platforms like Google Meet.",
      "The tool mirrors a selected screen region to a virtual monitor, enabling more precise sharing options, and is implemented in approximately 100 lines of C++ code, though it lacks error handling.",
      "Users appreciate the tool's simplicity and effectiveness, particularly for those with large monitors, but discuss concerns about potential high CPU usage and comparisons with Wayland's different screen-sharing approach."
    ],
    "points": 175,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1728911516
  },
  {
    "id": 41833833,
    "title": "Why pay for a search engine",
    "originLink": "https://help.kagi.com/kagi/why-kagi/why-pay-for-search.html",
    "originBody": "Why pay for search Search advertising is becoming increasingly aggressive and harder to distinguish from organic results. In 2022 alone, search advertising spending reached a staggering 185.35 billion U.S. dollars worldwide, and this is forecast to grow by six percent annually until 2028, hitting nearly 261 billion U.S. dollars. This explosion in spending has directly contributed to the cluttering of search results with intrusive ads, slowing down the experience and making it harder for users to find what they’re looking for. Beyond just the clutter, these ads are powered by invasive tracking technologies that follow users across the web, exploiting their data to maximize ad revenue. This is where Kagi comes in. By charging a nominal fee for searches, Kagi ensures that its search results are faster, more accurate, and completely respectful of the user's privacy: And when you pay for search, you’re supporting a product that doesn't need ad revenue or access to user data because it gets its support directly from its users. By aligning our incentives with those of our users, Kagi is committed to building a better, more ethical web. You can learn more in The Age of PageRank is Over post on our blog. Ad-supported search engines & the future of the web In the early days of Google, in 1998, its founders emphasized the importance of maintaining an ad-free search engine: \"The goals of the advertising business model do not always correspond to providing quality search to users. ... we expect that advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers.\" — The Anatomy of a Large-Scale Hypertextual Web Search Engine, Sergey Brin and Lawrence Page, 1998 Unfortunately, this is exactly how it played out, and over the last 20 years we proceeded to witness the great detoriation of web and search as a result. In many ways, Google made a pivot from \"organizing the world's information\" to \"organizing the world's ads\" and we believe that this leads to a sub-optimal experience for the end user. The numbers tell a tale Ad based search engines make almost $300 a year off their users. Google generated $76 billion in US ad revenue in 2023. Google had 274 million unique visitors in the US as of February 2023. To estimate the revenue per user, we can divide the 2023 US ad revenue by the 2023 number of users: $76 billion / 274 million = $277 revenue per user in the US or $23 USD per month, on average! That means there is someone, somewhere, a third party and a complete stranger, an advertiser, paying $23 per month for your searches. Choosing to subscribe to Kagi means that while you are now paying for your search you are getting a fair value for your money, you are getting more relevant results, are able to personalize your experience and take advantage of all the tools and features we built, all while protecting your and your family's privacy and data. Kagi offers a choice All search engines have search costs, development costs, and administrative costs. Most search engines cover this by advertising, tracking, and selling your data. And for 25 years we did not have any choice. Kagi brings a new model to the market - pay for your search with your wallet instead. For only $5/mo (Starter plan) or $10/mo (unlimited search plan) you can now search with a peace of mind, knowing the results are always shown with your best interest in mind. Pick a Kagi plan that is right for you We make it easy to pick the plan that is right for you, take a look at our Plan Types.",
    "commentLink": "https://news.ycombinator.com/item?id=41833833",
    "commentBody": "Why pay for a search engine (kagi.com)154 points by lr0 16 hours agohidepastfavorite192 comments depingus 12 hours agoI hope Kagi succeeds. But personally, I think the web is dead. And no search engine can save it. SEO spam has been strangling the web for years. Now, genAI SEO spam has escalated that onto inhuman levels. To make matters worse, no one wants to post to the open web anymore because their posts are just going to drown in that sea of spam and only genai's data stealing bots will read them. As the amount of spam posted to the web increases, the amount of worthwhile content posted decreases. Eventually, nothing of value will be posted. (like facebook?) You can lay the blame for the web's death squarely at Google's feet for allowing SEO to hijack search in the first place (or maybe the government is to blame for not breaking up Google's ad/search empire fast enough). Either way, the big companies all know the end is here and are gambling on genai to replace search. Already, places of knowledge are closing their borders and charging fees for genai to access. We have entered the internet's dark age. Fun aside: I think it's hilarious and fitting that Google's genai model sucks. And I hope they lose the genai wars (just out of spite, not because I think any other genai is worth a shit). reply dingaling 11 hours agoparent> Eventually, nothing of value will be posted. (like facebook?) I'm in a couple of dozen groups on Facebook and they produce interesting and thoughtful content every day. Of course I wish they were on the open web, but don't blame the network. reply levhawk 43 minutes agorootparentAfter your post I tried to find dotnet groups in facebook, but all I found is spam and almost no humans, which again reminded me about dead internet theory. Could you please recommend some groups? reply freetonik 8 hours agorootparentprevWould you mind sharing links to those groups? (unless they are local to your community/region/etc.) reply MichaelZuo 8 hours agorootparentprevThe open web as a concept doesn’t really make sense anymore, at least for written content. Since by definition it will need to be open to the majority of the world’s population, regardless of writing skill, but the bottom half of writers are already indistinguishable from cutting edge LLM output. And no one can install some sort of worldwide identity verification system, or it wouldn’t be ‘open’ anymore. reply carlosjobim 1 hour agorootparentAre you talking about the quality of the prose or about the content of writing? An LLM can only act on information that has been put into it by people, while a real person can create new and important information – even a person with low literal or oratory skills. reply knadh 12 hours agoparentprev> I hope Kagi succeeds. But personally, I think the web is dead. And no search engine can save it. I concur. Maybe now is the time to seriously think about alternate visions for \"search\". I have been toying with an idea[1] along those lines myself out of sheer annoyance at the state of WWW and web \"search\" in general. [1] https://nadh.in/blog/decentralised-open-indexes/ reply RavlaAlvar 12 hours agoparentprevLet say government nationalise google search or force to make it a non profit 15 years ago. How would that prevent SEO from happening? Isn’t SEO an inevitable outcome of website trying compete for attention? How would anyone prevent it from happening? reply bryanrasmussen 10 hours agorootparent>Isn’t SEO an inevitable outcome of website trying compete for attention? different Search engines with different rules and so forth would lessen the benefit of the O part, because it seems unlikely you could efficiently optimize for every particular algorithm and ruleset. Perhaps SEO is an inevitable outcome of one big dominant search engine and also made worse by that search engine not really giving a shit about making its search work that well for years and years but only about how many ads they could push at people and how much they could charge for those ads. reply RavlaAlvar 5 hours agorootparentI agree with your assessment that maybe this is an inevitable outcome of one big dominant search engine. But I would argue one big search engine is unavoidable since no one would want to use the second best search engine. Google search didn’t come the best because the other service like mail map and YouTube. So breaking up Google does nothing to stop google search from being the monopoly it is today. reply stvltvs 5 hours agorootparentIf different search engines optimized for different niches, there would be an user base for \"second best\" search engines. For example, nothing beats Bing for porn search. reply surgical_fire 9 hours agorootparentprevThat's an interesting idea. While I don't have the answer, what we might consider is the incentives that come with each model. In the current model, the incentives are clear. Google's incentive was to rent-seek all usefulness out of web search, privileging advertisement and their own profitability over usefulness. I am not sure if a search engine beholden to the government would be ideal. Governments do have their own sets of interests (legitimate or otherwise) that may at times go against users. Web search is in the end a piece of public infrastructure, used by billions across the world, very much subject to the Tragedy of the Commons. Perhaps it should be some sort of nonprofit, as other projects are (Linux Foundation comes to mind, being a successful one). reply RavlaAlvar 5 hours agorootparentI would guess just the incentive for any website to become top of the search results would likely create the outcome of today’s SEO landscape. reply surgical_fire 3 hours agorootparentExcept that Google is complicit and directly benefits of the current state of their search engine, no matter how awful it is to actually use it. reply throwup238 12 hours agorootparentprevThe same way people make adblockers happen. By making block lists of SEO garbage cruated by human beings. Nextdns and the RPi alternative do it. Kagi has all the infrastructure in place to make it happen at the search level, it just requires more manual work right now. reply RavlaAlvar 5 hours agorootparentHow would you define “SEO garbage”. Who has the power to decide what belongs in the list. reply openrisk 11 hours agoparentprev> I think the web is dead The web cannot 'die'. Everything and everyone moves online. Point one: A return to pre-internet days is not likely. Point two: Walled gardens had their peak moment. The dangers of everybody relying on them for our entire online existence are more than apparent to anybody with a firing neuron (and despite appearances, our species is not entirely inane). Ergo. The only path is forward, a more sane, less monopolized web. Build it and they will come. reply axegon_ 11 hours agorootparentThe web is very much dead as a matter of fact. I don't think a search engine has he ability to filter out all the LLM garbage that's flooding the internet. Just look at stackoverflow and github. Ever since chatgpt was released, the contributions skyrocketed and the quality dropped off the face of the earth and into a dark oblivion. reply bryanrasmussen 10 hours agorootparent>The web is very much dead as a matter of fact. I don't think a search engine has he ability to filter out all the LLM garbage that's flooding the internet. this presupposes the argument that for the web to have value then you must have a search engine to allow you to find things of worth on the web. Which argument you have not made but only taken as a given. reply nextaccountic 10 hours agorootparentprevWe are talking on a website on the web. Not everything needs to go through a search engine. reply openrisk 10 hours agorootparentprevwhat do you mean by \"the web\"? The web is all the people, companies, public sector etc. that are setting up web servers (whether self-hosted, cloud etc. it doesnt matter). To say that the web is dead means that nobody outside massive social media type sites will still run a server (and SO / github are social media type walled gardens at this point, thats why they get enshittified). But this development would be absurd as a whole. Mind you search engines as we have come to know them might be dead, but thats of their own making. People need to find / communicate useful, truthful information and sooner or later they will get it. reply whazor 10 hours agoparentprevWell, you could consider a 'search engine' to be a searchable curated website directory. You could manually curate this directory and only use scrapers to allow text search on these websites. This will always be a possible option and a way ensure that your search site is good. reply dazc 12 hours agoparentprevYou cite Facebook as an example of no meaningful content yet put all the blame upon Google? Maybe content creators are just incentivised into giving 90 percent of the public what they want. reply bryanrasmussen 8 hours agorootparentI figure if 90% of everything is crap, https://medium.com/luminasticity/90-crap-48e4c79419a9 then if the amount of available content has doubled in a decade, that is probably just too much crap to find the good stuff. reply ainiriand 11 hours agorootparentprevThe content added to Facebook was not what made the web what it was. The content indexed by Google, in turn, it was. The countless blogs or cooking recipes, fan sites, etc, were overriden with SEO filler slop over the years. OP example of what a content-devoid internet would look like is exactly what Facebook is now. A site that started as the place to connect and share with your friends and family now is just a place that is filled with AI slop and emptiness. reply anal_reactor 10 hours agoparentprevI think that the core of the issue isn't \"big corporations\" but rather the fact that the internet is more accessible than ever, which means that the ratio of users who want to create content for fun, to the users who want to just consume content or create it for monetary reasons, is completely different than years ago. reply n_ary 12 hours agoparentprevI do not blame Google for web’s current wasteland landscape, I blame ads and all the grifters who poison the landscape with SEO waste to try make some bucks with ads or other similar means. reply rkharsan64 11 hours agorootparentThere's several examples where Google's SEO has actively made things worse, even before you look at ads. And to be clear, I do agree that advertising has also done massive damage to the web. All the long, rambling stories you see before recipes? That's just there so the recipes can rank higher. I can't remember the source, but I also remember a website adding AI generated slop to cater to Google's wishes, and leaving a page to explain to normal users why they did so. It's also seen when you look at YouTube videos, where now it's basically necessary to have a clickbait thumbnail + title + reminders to like and subscribe. reply ainiriand 11 hours agorootparentprevIt really is Google's fault. Those blogs SEO goals are only targeting top Google positions. reply tourmalinetaco 12 hours agorootparentprevGoogle is an ad company that specifically lets SEO fill up its search results because those websites make them the most money per click. If Google continued to fight SEO abuse like they were literally founded to do then we wouldn’t be in this mess. reply indigo0086 9 hours agoparentprevPessimists live in a world built by optimists reply sshine 9 hours agoparentprev> the web is dead [posted 3 hours ago on the web] m-hm. reply tomjen3 9 hours agoparentprevHow do you square your idea that genai sucks with the fact that people are paying and using it, and not just for seo spam? reply tessierashpool9 11 hours agoparentprevyes, yes, yes and yes! reply thesuitonym 14 hours agoprevI'm almost exactly one year into my Kagi purchase, and I've got to say I'm loving it. Since this was just an experiment, I purchased the smallest level I could, which is now Starter, but back then it was a bit different. Some people want unlimited, and I understand that, but if you're on the fence, I'd suggest just getting Starter. Seeing how fantastic search can be is incredible. I can completely remove abusive domains (Fandom, Pinterest) from search results. I can get search results from only the small web. I just get better results overall. For those curious, in the past year I've only made ~1700 searches. That seems low, but that's what it says. I have made some changes to my search habits, though. For instance, when I'm looking for a result on Wikipedia, instead of just searching for it, I go to Wikipedia, same with IMDB, and similar sites. Sometimes, I search for something that I know will need a result from a disallowed domain, so I use DuckDuckGo for that. And I still use DDG for work searches, and some other miscellaneous searches. Again, if you're on the fence, just try it out. It is so, so, so much better than Google or DDG. reply theshrike79 12 hours agoparentI hit my year too just two weeks ago. I always think \"is it worth it\" when the payment hits my credit card, but every time I come to the conclusion that it is very much worth it. Just the universal summariser has saved me insane amounts of time. I can feed any rambling youtube video (with subtitles) or a long article to it and it'll give me the key points of it. Then I can decide whether it's worth spending an time on or not. Something like this is the future of \"AI\" in my opinion, you can \"teach\" the system what you're interested in and it can curate content just for you - locally, without an unicorn startup getting all your data. reply raybb 12 hours agoparentprevFyi you can search \"titanic movie Wikipedia !\" And when you use a bang it doesn't count against your searches. Or at least that's what it was like before I moved to the unlimited plan :) reply ivandenysov 11 hours agorootparentThank you! I think I’ll use quick bangs even more: https://help.kagi.com/kagi/features/bangs.html#quick-bangs reply paradox460 10 hours agorootparentprevYou can just use !w to search Wikipedia, no need for the \"I'm feeling lucky\" bang reply benhurmarcel 9 hours agoparentprevI've been doing the same but using the browser shortcut to select a search engine. If I start with \"k \" it searches with Kagi, with \"g \" it's Google, etc. I've been using Kagi only for non-trivial searches, so the starter plan has been enough. For very local searches (mainly about a local business or finding where to buy a product) I use Google. And most of my searches are just looking up the url to a website (like searching \"steam\"), so any search engine will do (I default to Duckduckgo for that). reply carlosjobim 5 hours agorootparentWhy waste that time and mental effort to save literal pennies? Isn't your limited time alive on this incredible earth worth more? This is like driving the whole afternoon around town to find the cheapest gas. reply benhurmarcel 5 hours agorootparentI agree, I started this way to test it out and just kept doing it. Although it saves 65€/year, not pennies. And I'm in Europe so I don't earn nearly as much as the average American engineer. I would still select the search engine for a number of queries though. I find Google better for local stuff, use WolframAlpha for computations, and Perplexity for LLM answers. reply carlosjobim 5 hours agorootparentGoogle Maps is the undisputed king for local results. Not even Apple has any chance of contending that throne, much less Kagi. My prediction is that maps will become the core of Google's search business quite soon. reply oefrha 13 hours agoprevA point I hardly ever see anyone bring up: I’m not a fan of the idea of doing all my searches while signed in, potentially creating a company-knows-me-better-than-myself situation. I do my searches in private windows mostly behind commercial VPNs so that it’s difficult enough to profile me that companies probably won’t bother. Public search engines have to get really bad before I move to a sign-in-required one. But given that this community which ostensibly touts privacy at every turn seems to overwhelmingly support feeding everything (not just searches) into OpenAI/Claude, I guess my aversion to having all my searches rounded up by a company (even if it’s not Google) is very fringe. Btw I’m by no means a privacy maximalist. reply freediver 8 hours agoparentWhile you can already sign to Kagi with disposable email and pay with crypto, we will also be bringing privacy pass (blind token) support soon. We already have a working proof of concept. More info here https://kagifeedback.org/d/653-completely-anonymous-searches... reply dannyw 8 hours agoparentprevA key difference is that you’re actually the customer here. I am much more comfortable telling my doctor everything about my health, for example; than Gmail with all my emails. It’s a personal choice at the end of the day; and I aspire for a world where there is genuine choice of companies. For the time being, I’m supporting competition by using Kagi (and I get a better search engine!) reply JumpCrisscross 13 hours agoparentprev> my aversion to having all my searches rounded up by a company (even if it’s not Google) is very fringe Kagi provides strong privacy guarantees [1]. They could be lying. But so could your VPN providers. [1] https://kagi.com/privacy reply whilenot-dev 13 hours agorootparentI'm calling marketing fluff here, given that its founder seems to hold a skewed model of kagis power in regard to collecting personal information altogether: \"personal information is what you can be identified with as an individual. no information you submit to kagi is personal information except if you use your real email address to register\"[0] [0]: https://d-shoot.net/img/kagi/weregood3.png reply JumpCrisscross 12 hours agorootparentThe image looks like it's from this post [1]. Long story short, this appears to be a case of a CEO needing to restrain themselves from saying (or typing) everything that comes to mind when faced with a combative user who clearly isn't trying to understand something or bring anything to the table. At the end of the day, what you care about when it comes to privacy in search are your search records. They say--in a way that generates liablity--that they don't store them. I see no reason for them to break that promise. Between a commercial VPN and Kagi, I trust Kagi more. [1] https://d-shoot.net/kagi.html reply eviks 10 hours agorootparentIt might appear like that from a corporate PR perspective, but from the perspective of a user that's just one of those rare cases where you get a glimpse of honesty, which is just (if not more) as valid as some undefined liability to be the ground for you assessment reply JumpCrisscross 5 hours agorootparent> from the perspective of a user that's just one of those rare cases where you get a glimpse of honesty User asked for data download. Company said there isn't any. User said that isn't GDPR compliant, which is nonsense. Company gave correct, snotty response. I get it. I've been pissed off at companies before, too, and basically engaged in a support conversation to get something ambiguous in writing that I could use to cost them time and money in New York, California, Texas or the EU. (Big regulatory organiations, some of which love fodder with which to justify their existence.) User was going down a rabbit hole. Kagi followed them there. They shouldn't have responded to that thread after it went into territory that on HN would have been flagged and in real life been settled with a glare. reply politelemon 11 hours agorootparentprevTangent to that, I hadn't realised their Orion browser was mac only, which is a flag of some colour to me. A company that takes privacy seriously ought to be taking Linux or cross platform seriously and if they do not I assume they do not. reply freediver 8 hours agorootparentOffering another perspective: A company that takes privacy seriously creates their web browser as a zero telemetry and with 'pay for your browser' business model so there is no incentive whatsoever to mine user data (Orion is both of these, and unique in the browser world as such). And a company that is 100% supported by user funding (which Kagi is) can only do so much with resources available, which is the reason we have to pick our battles (read more about Windows/Linux/Android versions for Orion https://orionfeedback.org/d/2321-orion-for-windows-android-l... ) People often criticize us for doing too much (eg link in the parent of parent comment) but we also at the same time do get critique that we are doing too little :) If Kagi is not doing something, believe me, it is not for the lack of will or ambition. (Kagi CEO here) reply JumpCrisscross 5 hours agorootparentprev> company that takes privacy seriously ought to be taking Linux or cross platform seriously Going out on a limb, but guessing that the chief hurdle a company like Kagi faces is willingness to pay. I'm going to guess the 'this is a great product, but I just can't bring myself to pay more than 20¢ per year for search' crowd is crowded in Linux. (I may be totally wrong on this!) reply whilenot-dev 12 hours agorootparentprevA user asking for the state of GDPR conformance is not by any means a \"combative\" user. They just want to know if their personal information a treated in their best interest and according to current laws. Privacy is a VPNs first business, for kagi that would be search. It feels like you mix your evangelism with a bit of whataboutism here... why do you bring up VPN providers when we talk about the privacy guarantees of kagi? reply timeon 9 hours agorootparentprev> faced with a combative user the user from your line: \"I really want to stress that I don't have anything against you or kagi :) just trying to be constructive.\" Is combative that he was explaining what GDPR was while while other side was insisting on confidentially incorrect view? reply surgical_fire 9 hours agorootparentprevI... Actually think that is an extremely poor answer from Kagi's founder, one that would give me pause before trusting them with personal data. The most charitable reading there is that they clearly don't understand what PII even is, why it is important, and therefore that they would handle it properly. reply oefrha 10 hours agorootparentprev> We will always respect your privacy. I don't trust \"always\" in tech, and take its usage as a negative signal -- if you have no problem promising something both of us know will have a 99.9% chance of being broken, I'll devalue other parts of the promise as well. (Incidentally that applies to basically any promise that involves \"always\", not just in tech.) Wording aside, I don't think these privacy policies have teeth. If they violate it, at worst they'll lose some users and have a harder time acquiring new users who care about this stuff, which may not be a lot of users. Therefore, I prefer not giving them easily correlated data in the first place. Sure, my VPN provider knows I'm going to google.com/bing.com/duckduckgo.com/etc., violate away, that's the necessary sacrifice of using the Internet without going full paranoid mode. Thanks to TLS they don't know the content. reply rjrdi38dbbdb 10 hours agoparentprevSeems like a good use-case for zero-knowledge cryptographic tokens. You could buy an allocation of tokens that would be difficult to link together when used through a large VPN and fingerprint-resistant browser. reply friendzis 12 hours agoparentprevWell being technology oriented, this community has disproportionate number of technology enthusiasts. Remember when everyone and their dog was cryptobro? There were multiple such spikes, coinciding with hype cycles of coins, nfts, etc. These days the most vocal are GPTmaxxing, tomorrow there will be a new shiny thing. reply yorick 8 hours agoprevTo provide some counterweight to all the overwhelmingly positive reviews: I've used kagi for 6 months and have over 7500 searches with them. It mostly works, but there are a few downsides compared to Google: - The latency is a lot higher than google, taking over a second to display any results. - The results are often not as relevant, I have to frequently retry my search in Google. - The results for anything local (I'm not in the US) are abysmal. Searching for anything in my city instead only gives me results for the city's history. Still, I persist in using Kagi, mainly because it's not Google and I want them to succeed. The results are frequently good enough for me to stay with them. reply __jonas 8 hours agoparentI mentioned my issue with the latency last time Kagi was posted, I would love it if they could bring it to be a bit closer to Google reply dannyw 8 hours agoparentprevYou can use multiple search engines. I use Kagi, Bing, and occasionally Yandex. reply RamiAwar 14 hours agoprevI would convert, but price is too high for me personally. I'd be willing to pay up to 3$ a month for my searches, but also per-use. If I make 0 searches, why do I need to pay? A replacement for Google that is to survive should really convince and be super cheap, it's so easy to ignore sponsored search results (for now). reply evoke4908 13 hours agoparentYou either pay a flat fee, or you have to deal with the added baggage of considering that each search costs you a very real half a cent or whatever. Would you use your search engine more if every search query were an implicit microtransaction? Would you use it more or less if you had to consider that your first search of the month cost $3, or if it's the last day of the month and you need to search for something but you have to wait to not incur a full month's fee. This is one of those arguments that sounds reasonable but isn't. Nothing but a flat fee structure makes sense for something you'll be doing hundreds if not thousands of times a month. And let's be real: if you're the kind of person who could go a full month with no web searches, you don't want or need what Kagi is offering. reply pzmarzly 11 hours agorootparentAlmost everyone is paying for their electricity based on usage, and yet people don't seem to think \"this will cost me a dollar\" when turning on the washing machine (unless really short on money). I think usage-based SaaS subscriptions could make sense from user's perspective, they are just too uncommon right now. reply eviks 10 hours agorootparentprev> or you have to deal with the added baggage of considering that each search costs you a very real half a cent or whatever. And one way to \"deal with\" that is get used to it and forget about it unless you get some surprise hit (which can be avoided with a cap). But you'll have a warm glow feel that it's \"fair\" It's not like this is some novel issue average people have never had exposure to (eg, utilities) reply JumpCrisscross 13 hours agoparentprev> replacement for Google that is to survive should really convince and be super cheap The market for most is met with ads. It's why streaming services are adding ad tiers and JCPenney doing \"away with constant sales and coupons, opting instead for everyday low prices\" failed [1]. That's most consumers. It's almost all non-premium consumers. That's good fodder for Google and whatever LLM garbage replaces them. Paraphrasing Scott Galloway, advertising is a tax on the stupid and the poor. I wish something like Kagi got public funding. But we have better priorities than taking ads out of search. So for the time being, you get one product for the wealthy and savvy and another, that's just good enough, for everyone else. [1] https://excelsiorcapital.substack.com/p/jc-penneys-lost-barg... reply ndndjdjdn 13 hours agoparentprevI think you could bundle online search and LLM, offline (personsal) search and LLM and it would make 10-20 bucks a month attractive. Why just do internet search. Be my search for everything! I think it should be free or cheaper for people who genuinely cant afford it to give the equity of access that Google does. reply andrewinardeer 12 hours agorootparentTop tier Kagi subscription allows you to tack a '?' onto the end of search and an LLM of your choosing will reply FYI. https://files.horizon.pics/dfcedf80-2b55-422e-9960-42d730532... reply wartijn_ 14 hours agoparentprev> If I make 0 searches, why do I need to pay? Do you ever have months in which you don’t use a search engine at all? If so you might just not be the target audience. reply PlattypusRex 13 hours agoparentprevnext [5 more] [flagged] ajkjk 13 hours agorootparentWell yes but it's kinda crappy that you do. Can easily imagine an alternate reality where laws are more pro-consumer such that it's illegal to charge someone for a service in a month that they don't use it. reply JumpCrisscross 13 hours agorootparent> Can easily imagine an alternate reality where laws are more pro-consumer such that it's illegal to charge someone for a service in a month that they don't use it Didn't use my vacation home this month, skipping the mortgage payments! reply Mawr 6 hours agorootparentThe comparison with a house does not work, it relies on a misapplication of the word \"use\". In the context of a house, \"use\" refers to ownership. You receive the benefits (use) of ownership regardless of your presence. You basically pay for the inability for others to live on the property. reply ajkjk 1 hour agorootparentprevThat's not at all the same. reply evoke4908 13 hours agoprevAnother Kagi user for a year or two. I've honestly never had a single negative experience. Since using Kagi, I've only had to use google a couple of very desperate times. I don't notice the subscription fee because I get excellent value from it. Kagi simply does what you ask and stays out of the way. Because you pay them, they don't need to monetize every pixel on the screen. No tracking or data mining. It's just software that does what it says it does and does what you tell it. It's tragic that \"thing that does one thing well and doesn't spy on you\" is a scary and alien concept these days. reply vachina 14 hours agoprevKagi is great because SEO cargo cult haven’t caught up yet. Once Kagi gains traction I guarantee result quality will nosedive. reply mjr00 13 hours agoparentMaybe, but one major problem with Google search is the perverse incentives. SEO garbage sites tend to be filled with Google advertisements, which means a Google search user who clicks through to a SEO site makes Google money. As long as the result is good enough, users still get what they need and the search is successful. And by good enough, I'm talking about sites like \"geeksforgeeks\", \"towarddatascience\" or \"realpython\" that just put additional text and ads around existing documentation; they do answer your search query, you just have to scroll and ignore the 20 ads on the page to get to it. It's to Google's benefit to offer one of these pages up over, say, python.org as the top result. Kagi, at least for now, is making its USP the fact that it surfaces more professional, curated results. Its algorithm is susceptible to manipulation, for sure, but unlike Google, it actually has an incentive to keep SEO garbage off the first page of results. reply bastawhiz 14 hours agoparentprevThe magic is in letting real humans curate what gets boosted and what doesn't. My results tend to be quite good because I've hidden tons of sites that I don't care about. It's the same reason uBlock works: filter lists can be shared. reply benhurmarcel 8 hours agoparentprevBeing paid, I don't think Kagi will ever \"gain traction\" in this way. Which is great for its users. reply pxtail 5 hours agorootparentWith being paid it's golden target for various \"influencers\" because it's users already did auto segmentation and assigned themselves to group of very wealthy individuals and ones eager to pay for internet services. reply EZ-E 13 hours agoparentprev> Kagi is great because SEO cargo cult haven’t caught up yet This seems like a hard problem to solve, the incentive to be top ranked is just so high. What could be the solution? Can AI even help? Do we need to go back to manual curation after all? I remember in the 90s there were manually curated lists of websites, something like a website directory. At this point I'd rather get recommended a list of websites from a reddit user than relying on Google's ranking. reply joe_the_user 13 hours agorootparentI don't think SEO actually beat Google. Rather, Google simply capitulated or was captured. I distinctly remember a 2019 update where things really went bad. Part of the situation is that a company that relies on ad revenue will get gradually feel the pull of the advertisers more and more. I'd be more worried about someone nefarious buying Kagi if it got big. Someone else would be willing to pay a whole lot of money for those eyeballs. reply dannyw 8 hours agorootparentSEO spam is correlated with ads. Google dominates web advertising. Google’s interests are aligned with SEO spammers, as long as it’s not so terrible you switch to another search engine or stop searching. reply interroboink 13 hours agorootparentprev> a hard problem to solve Indeed. And perhaps part of the issue is that there is not a single solution. Even manual curation is ultimately based on trust. If someone's trusted list of recommendations gets popular enough, what's to stop them from \"selling out,\" breaking that trust, to make money? Also, the good curated stuff is typically correspondingly small and focused. But lots of people want broad results in their searches, and it's hard to imagine a person or handful of people being able to cater to all of those varying needs equally well. Sometimes a person wants excellent narrow results (eg: academic looking for papers), other times they want broad shallow stuff, and at various other points want various other things in between. There's a whole field of expertise, sometimes called \"Library and Information Science\" about organizing and making information findable, since long before computers existed. Even for them it is not a solved problem. But the cat-and-mouse arms race that the online version has turned into makes libraries and asking a librarian for recommendations feel a lot more appealing (: reply hulitu 13 hours agorootparentprev> the incentive to be top ranked is just so high. What could be the solution? To not be top ranked ? /s reply p3rls 8 hours agoparentprevWhat? My niche is already dominated by the same SEO spammers as Google on Kagi and always has been. Kagi just takes google results... I swear some of you guys it's like we're not even using the same software. reply freediver 8 hours agorootparentCare enough to give an example or report to kagifeedback.org so we can check what is going on? reply p3rls 7 hours agorootparentSure, my niche is entertainment, so let's search anything in the international music scene and check out the rank orderings... Lo and behold it is exactly the same as Google pagerank. reply freediver 7 hours agorootparentHow about an exact example so that we are on the same page? Thanks. reply p3rls 6 hours agorootparentSure, I'll give you a recent example that I'm #1 in on both Google and Kagi: 2NE1 ages I can go through this list and see you are exactly the same, except you leave up more spam. Just one example of thousands I've looked at. reply freediver 6 hours agorootparentDid I misunderstand you when you said Kagi results are same as Google results and you really meant that just result #1 happens to match? For your query I can see there is a difference already at result #2, #3 etc.. Also if you believe this is wrong you should submit search quality feedback to kagifeedback.org We get a lot of feedback but it is mostly for technical queries that we usually address: https://kagifeedback.org/t/search-quality If you provide details what went wrong in kagi results for this query (and what sites should rank #1, #2... in your opinion) we can take a look. With search quality because it is such a broad space, what does not get reported, does not get looked at and addressed. reply p3rls 5 hours agorootparentI get that the scale of this problem is dazzling but think that fundamentally you do not have a solution if you are copying pagerank (even adding upvotes etc.) for queries that haven't been screened by your staff. I think you need to take a good hard look at what makes for shitty content and build some parameters off that. And if you had to go off pagerank (to begin with) I would be trying stuff like adding hidden penalties to popular CMSes, boosting reddit/HN content, and following SEO trends just to thwart them. I would categorize websites by expertise so queries related to korea do not rank pages from the hindustantimes. When you search for air filters, you should probably get that housefresh team and not forbes etc. The upvote system you have is moving in the right direction but even that will need to be fortified with anti-seoer measures. I would try to create real EEAT standards that cannot be gamed without massive investments. It's too late to undo the damage that the Danny Sullivans of the world have done but maybe can save something here. reply freediver 2 hours agorootparentAll we need is a search quality report as I indicated before and our team will look into it. The fact that there is no or little spam for other things Kagi users care about, is a testiment to our determination to deal with it. reply nurettin 13 hours agoparentprevIf kagi ranks according to pages that provide high value relevant information about the subject, how would SEO work around that? If they are willing to provide quality content, I guess they deserve to top the search? reply unstuck3958 13 hours agoprevWhy are there so many paying Kagi customers who feel the to write multiple paragraphs of testimonies? This is so unusual of HN. Reeks of astroturfing. reply slau 13 hours agoparentDisclaimer: I’m a paying customer of Kagi. It felt truly bizarre to subscribe to a search engine. To actually pay for access. There’s been a bit of drama with the CEO directly emailing people when they left poor reviews. Some people are not happy with Kagi investing in browser development instead of search results quality. I’m not surprised there’s a lot of people having thoughts and feelings about Kagi and expressing them. The fact that there’s a significant overlap between HN and Kagi’s user bases is hardly a surprise either. reply JumpCrisscross 5 hours agorootparent> Some people are not happy with Kagi investing in browser development instead of search results quality As someone who uses Orion as their daily driver, I'll admit I'm somewhat confused by why Kagi isn't staying mission focussed. That said, it may be the case that they're a premium company for a small, well-defined niche. In that case, broadening the service offering makes sense--it's what Apple did. reply Dayshine 11 hours agoparentprev> This is so unusual of HN Is it? I see paragraphs of testimony from HN users who love anything whether that's a programming language, web framework, etc. reply JTyQZSnP3cQGa8B 7 hours agoparentprevI can say that I’m a 10x dev since I use Kagi because it gives me good results most of the time at work. And when I accidentally switch back to other engines, I’m always disappointed. But the truth is that subscribers are happy because it’s the only decent alternative out there. Google/DDG/Bing all suck. SearX may be good and free but I haven’t tried it yet. reply JumpCrisscross 13 hours agoparentprevYou really can't distinguish enthusiasm for a product in a sea of crap from astroturfing? reply deely3 12 hours agorootparentIts hard to check is person geniune on internet. Also, too often we all see a lot of prise for not-so-good products. reply p3rls 8 hours agoparentprevIt's very well done-- really props to the Kagi marketing team, (you have a duckduckgo-style marketing book for sure to sell) but if you read a lot of hackernews you see the same stupid pattern over and over again in these Kagi threads with these testimonials like you said and becomes obvious. Especially if you have used kagi reply DarkNova6 7 hours agoparentprevThere are only few products which I believe are genuinely good and I am happy to be a paying customer. Next to Intellij, Kagi is one of these products. reply lompad 12 hours agoparentprevBecause a massive share of the kagi users are part of the hn-adjecent crowd. When you look at the most manually upranked domains, you'll probably get a clearer picture. https://imgur.com/a/1Ed23d6 The typical kagi user uses hn. In the past, hn was even further up, though I guess they're slowly getting \"normal\" people too. reply johannessjoberg 14 hours agoprevI can highly recommend switching to kagi. Happy paying customer here. reply ipaddr 14 hours agoprevTo be in the top 1% you would likely need to depend on search on a daily basis for your livelihood. As a reminder the Starter plan is USD $5/month with 300 searches included. 99% of people search less than 10 times a day with loading the next page counting as a search. That's interesting and hard to accept but might be true with many living in apps and wall gardens like facebook. I wonder what the mode number is for those 99%. 1 or 2 searches a day. reply johnnyanmac 14 hours agoparent>99% of people search less than 10 times a day with loading the next page counting as a search. that's pretty crazy to hear. Especially since on this day alone, a weekend, I seem to have 20 unique searches. I can easily hit triple digits a day when researching for a project or on the job. Search is invaluable to me. reply a57721 13 hours agorootparentI do 100+ searches a day, but that would easily drop to ~10 if I don't count searches where I know from the beginning that I am going to click on the link to Wikipedia / GitHub / some other familiar website. With the rise of AI-generated content and low-quality content farms, I am turning to the old habits of keeping bookmarks to reliable sources anyways. reply devjab 13 hours agorootparentprevWhat sort of job relies on internet searches? I’m not trying to be rude or anything like that at all, I’m genuinely curious. reply johnnyanmac 13 hours agorootparentI work as a dev like many here. Specially games. So lots of documentation lookup (or tutorials on what should be in documentation. Let's be real, games don't document a lot publicly to begin with, and public documentation is really poor for the tech industry), research on tooling for project, research to understand some new technical feature that rose up, spell checking for technical terms the built in dictionaries can't check, etc. I could go on for paragraphs, there's always something to learn, re-learn, or simply fact check. and of course: discussions among communities talking about all of the above. Be it benchmarks, landmines to look out for, bug reports, highly opinated design choices, etc. Definitely couldn't find all this restrained to a Discord server or Facebook page. And that's just all on the business end. Sometimes you just want to search up a reaction gif for a chat, or find news of the goings on (which is down on the weekend). reply carlosjobim 5 hours agorootparentprevAny kind of knowledge jobs. I mean, what job relies on having a computer with an office suite? None, because you can use paper and pencil? Let's say you're a plumber working at a job site where your company is digging up and re-doing lines. You come across a piece of material from the old contractor that you don't recognize, so you look up the name and code printed on the material... on a search engine. reply Veen 11 hours agorootparentprevI’m a technical writer. I use Kagi dozens of times a day for research. I particularly like custom lenses where I can limit search results to a client’s site, their existing documentation, related standards and regulations, etc. Plus, I can exclude competitor sites and other results I don’t want to see. https://help.kagi.com/kagi/features/lenses.html I do wish they’d increase the number of domains allowed in custom lenses and the number of lenses you can create. reply freediver 8 hours agorootparent> and the number of lenses you can create. I didn't know we had such limitation. Have you considered creating a feature request on kagifeedback.org? This sounds like an easy fix. reply daelon 13 hours agorootparentprevPro... gramming? I'm sorry, are you aware of what website you're on? reply devjab 13 hours agorootparentI’m a software developer, have been for two decades. I was suspecting it may be the case which is why I asked. Again, I’m not meaning to be rude or snide or anything, but what do you use search engines for? I almost never use them, I tend to head directly to the documentation when I need to look up the APIs for a library. This is mainly because “free” search engines suck at it these days, and I’m curious if Kagi doesn’t. reply Mashimo 12 hours agorootparentHow do you find the documentation in the first place? ;-) I search for Errors / StackTraces that I get. For me stackoverflow / reddit / forum answers are often more helpful. Or examples on how to implement something, the documentation can sometimes be a bit lacking on how to set things together. Give me some working code that I can fiddle with. High level comparison between two frameworks / libs that I'm not familiar with. reply supriyo-biswas 14 hours agoparentprevI'd assume searches for the majority might be very \"bursty\", and while they may indeed spend most of their time in Facebook, Tiktok etc. when planning a vacation, searching for stuff to purchase or looking up recipes to try and the like, they'd issue a number of queries to narrow down into their area of interest which would blow past your estimate of 10 queries/day. There are also a fair number of queries that are just \"Facebook\", \"\" etc. which would also probably count towards some of the quota; it'd be great if some sort of caching could be implemented for these. reply aniviacat 11 hours agoparentprevI assume these numbers are heavily skewed by the amount of people doing 0 searches a day. Lots of people hardly use their webbrowser, spending almost all their time within apps. YouTube and TikTok have become popular search engines, partly for this reason. If you only count people for whom paying a monthly subscription for search wouldn't be completely ridiculous, I'd guess these numbers would skyrocket. reply ipaddr 14 hours agoparentprevAnd Google is making 23 dollars on less than 300 searches which means Google makes 8c to 1 dollar per search. reply renegat0x0 10 hours agoprevPeople are sad over google demise, but we have more tools than before, and easily we can mitigate. - there are other search engines, like kagi - we have AI, chatgpt, which some people find use for. I use it to ask general questions about programming problem solving and it often helps me. I do not know every language, and when I needed to write browser extension it saved me a lot of time - bookmarking software. I wrote my own self-hosted software [1], with search ability. I do not have to 'research' everything I find interesting. Google will not bury inconvenient news anymore, or filter it I think we need is adapt. When Google entered, Yahoo was not able to change. IBM was not able to change. Old tech is replaced by new solutions. We need to reconsider how to find things online. [1] https://github.com/rumca-js/Django-link-archive reply andreagrandi 14 hours agoprevI’ve been an happy subscriber for nearly one year now. I even tried DuckDuckGo for some time but the quality just wasn’t the same. reply winwang 13 hours agoparentAgreed. Kagi even works well with Reddit. Great that I can just fall back to google easily too. reply freediver 8 hours agoparentprevThanks Andrea! reply dave_walko 5 hours agoprevI have signed up off and on. For me, the starter is just a tad to few searches per month. If I had 400 I would most likely just pay the $5 out of support for the team as I am also hoping to see Orion do better (bitwarden issue) I have some months where I search for stuff I already know. Like I goto url bar and just type imdb which then initiates a search. I know the dang url but am lazy lol. I wish the team tons of luck, I monitor the pricing page monthly usually, just hoping to see a small uptick in starter limits as unlimited is just not my use case. $8.00 for unlimited and again, I would sign up just to support them. reply lowleveldesign 10 hours agoprevApart from search customizations, I also use the bang searches (a few mine and many from https://github.com/kagisearch/bangs). I also recently switched to ultimate and created a few assistants with system prompts for my various needs (coding, learning chemistry, etc.) reply Toutouxc 13 hours agoprevKagi is easily in the top tier of my subscriptions (along with JetBrains and my cloud backup provider), where if it were a local business, I'd go there to pay in person, and smile while doing it. I feel respected as a customer and I feel like I'm getting great value from the service. A LLM-fueled storm might be brewing on the web, but I'm definitely riding into it with Kagi. reply JumpCrisscross 13 hours agoparent> Kagi is easily in the top tier of my subscriptions Funny, in terms of (non-niche) brand loyalty and evangelism, I'd say it's up there for me with Apple and Delta. reply slau 13 hours agorootparentI’d put it in the “I’m paying for this but I’m not sure the CEO will never make me regret that fact” category. There’s been some… ego-fuelled decision making happening in Kagi’s communication. reply jaysonelliot 14 hours agoprevThe idea of paying for services online that most people expect to get for free is great, actually. There was a time when you simply expected to pay for anything that had value. Whether that was a newspaper, a magazine, a movie, music, or even an online service like AOL or CompuServe, you paid for it and you expected a certain level of quality in return. In the early days of the Web, it wasn't clear at all that sites could pay their bills with advertising. Then in the mid90s, Ethan Zuckerman invented the pop-up ad (he's apologized since) and things progressed - or regressed, if you prefer - and we slid down the long slope to companies selling your data, hyper-targeting ads, and worse. So many of society's ills right now can be traced to the ad-driven model. It's why clickbait is lucrative, why it's more profitable to run a populist site filled with misinformation than a trustworthy news org, it's how scammers and spammers are incentivized to flood social media sites with slop. I'd love to see Kagi succeed, and others to follow their lead. I'd much rather spend an extra $20, $30, even $50 a month or more to subscribe to a bunch of ad-free sites that I can trust than to get it all for \"free\" at the cost of ads, data mining, and scammy clickbait. reply Sajarin 14 hours agoparentI’m curious if you (or anyone else) know of any other services that are paid-only in a traditionally free/freemium product space. Perhaps for news, or video content, or music, or something else. What else do you use today for free that often feels like a Faustian bargain? As a random aside, If Google released a paid version of their search engine, would you switch back? reply evoke4908 13 hours agorootparentJetbrains. Well, up until recently. Now I'm paying hundreds of dollars for a cheap copy of VSCode and I'm really not sure why I shouldn't just use the free version. reply avh02 12 hours agorootparentBecause of the new ui? Seriously it's terrible, but the classic ui is still benevolently available as a plugin. Don't know for how long. reply tjpnz 13 hours agorootparentprev>As a random aside, If Google released a paid version of their search engine, would you switch back? Not if Google continue to make the bulk of their money from ads. reply nox101 13 hours agoparentprevinterestingly you paid for a newspaper or a magazine and it was full of ads even if you paid or subscribed. And most people liked it that way. Computer Shopper was way more ads than content and was immensely popular reply jaysonelliot 6 hours agorootparentThat speaks to the relative intrusiveness of those ads, and the quality of the ads as well. Newspaper advertising was generally well distributed so that it didn't interfere with reading, and its black and white on paper look wasn't jarring. Magazine ads, at least in specialized pubs like computer magazines, were actually useful. As a kid, I subscribed to Dragon Magazine because I played D&D, and the ads were half the fun for me. You'd think that with the hyper-targeting of online ads, that we'd be happy with them, too. But the actual products behind them are usually low quality spam. And we've lost a lot of discoverability from all this targeting. Sometimes it's good to see things that aren't aimed directly at your immediate demographic. reply taspeotis 13 hours agoprevI use Kagi, it’s pretty good. I pay for it and would recommend everybody at least evaluate. The worst bits, which aren’t even that bad: The maps are a work in progress. No shopping search. If I want something like shopping search I can use Google. Not sure if it’s because I’m in Australia but sometimes it takes a while for the page to load. Subsequent searches are faster. reply slau 12 hours agoparentI don’t believe I’ve ever used shopping search. I remember seeing it a decade ago or something, but I never understood the point. What is it for? reply dagw 6 hours agorootparentI find it super useful for listing all the places in my country where I can buy X, orders by price. Doing a more generic search for a product tends to give results heavily dominated by sites in the US. Also really useful when combined with image search. I can take a picture of a cool lamp and quickly find all the places where I can buy a similar lamp. reply Mashimo 12 hours agorootparentprevTo find where a products is being sold for the cheapest price. For electronics I know 3rd party services that compare prices for different shops. But in cases like \"Where can I by this specific dental floss\" I sometimes use google shopping search. reply smoovb 13 hours agoprevI would pay for Chrome Premium, as I pay for Youtube Premium. Prefer the Brave/YT Premium model where creators and sites get some share of your payment. The Kagi model, unless I missed it, seems to be \"just pay us\" with nothing going to creators. reply evoke4908 13 hours agoparentKagi is just a search engine. You're paying to access their index. There is no advertisement of any kind and Kagi has no relation to any site in their index. This is like being miffed that Yellowpages doesn't pay businesses to list them in the phone book. reply freediver 8 hours agoparentprevKagi's mission is to humanize the web and it is boosting creators (small, personal blogs and websites) in search results: https://blog.kagi.com/small-web How would you design a system where creators are paid in a search engine? We have always had an idea of profit share for showing up in results but we would need to reach about 10M members for this to be more than few cents a month. (Kagi CEO here) reply ricardo81 13 hours agoprevThe interesting thing about their calculation of Google's $23/m revenue per user, is how much of that is simply by matching a user's query and location to ads? i.e. Is all the additional data collection and abandonment of privacy entirely necessary to reach anywhere near that number? Also it's not clear if the numbers used in the article omits publisher ads from Adsense. It would be great if G's advertisers were opened up to competitors, I think a CPA model would work out well since combatting click fraud involves a lot of profiling. reply youoy 13 hours agoprevQuick questions por people that have used it: is it good for technical searches? Like math/programming? At some point I tried another search engine but I ended up going back to Google for those. For what type of topics do you find yourself going back to Google/other search engine? reply rckclmbr 13 hours agoparentI’ve been a subscriber for about a year. It’s best at technical searches. I would say other topics, particularly niche questions I have about like sports or something, it has a more difficult time on. Absolutely do not regret subscribing though reply CleverLikeAnOx 13 hours agoparentprevI use it for programming and math. When I started using kagi almost 2 years ago, I had to go back to Google occasionally. Now I basically never go back to Google search. reply moonlion_eth 14 hours agoprevPaying customer here. Kagi all day every day reply mholubowski 13 hours agoprevVery serious question: How is this better than using Google with an ad blocker? —- That’s my current solutions, why should I switch to paying for Kagi? Ty! reply freediver 8 hours agoparentMy best answer is try your 100 free trial searches and compare the search experience. Kagi has every incentive to create a superior search experience or you do not pay. For Kagi, every customer matters. reply tanduv 13 hours agoparentprevJust tried that example screenshot of 'postgresql query analysis' and got the same results on Kagi vs Google with uBlock. What exactly is novel here? reply commandersaki 10 hours agoparentprevAdblockers do not eliminate geekforgeeks in search results. reply JumpCrisscross 13 hours agoparentprev> How is this better than using Google with an ad blocker? Rubber duck to a battleship. The number of times I've found something in seconds that a co-worker was digging around in pursuit of for minutes has by this point escaped me. Were you around for Alta Vista vs. Google? This feels the same. The only difference is it's paywalled, which for the consumer, is generally good--it means the benefits won't be generalised and the product will remain an elite minority offering that doesn't gain traction with SEO bots. reply byzantinegene 11 hours agoparentprevit's not, there's clearly astroturfing going on, there's two articles by kagi on the front page of hackernews. reply bobek 14 hours agoprevI am on Family plan for over a year. Very happy z including czech sites. reply n8cpdx 13 hours agoprevNever going back to FASS, Kagi is great. So much better than Google, and getting better every day now that Google is sticking made up nonsense into the results. I like that I get to choose when to use GPT. If you’re on iOS, the Orion browser is great, too - tldr chrome extensions on iOS. reply pinkmuffinere 13 hours agoprevI’ve considered using kagi before, but I think this blog post finally convinced me not too: https://d-shoot.net/kagi.html The quick summary is that they aren’t really privacy focused at all, don’t comply with GDPR, and generally seem ok misleading their customers. The lack-of-privacy doesn’t bother me itself, but misleading customers really troubles me. Why would I trust them with X when I know they’ve lied with Y? reply JumpCrisscross 13 hours agoparentSkimmed. Not seeing how Kagi are lying about anything. To the degree I can fault Vlad, it's in going down irrelevant rabbit holes with these folks. reply pinkmuffinere 11 hours agorootparentHere’s an easy one: Vlad claims they are GDPR compliant. However, they do not provide a way to download stored personal info, as required by GDPR. This is a contradiction reply freediver 8 hours agorootparentWe do, just email support@kagi.com. Please do not spread disinformation. reply pinkmuffinere 7 hours agorootparentI’m glad to hear you have updated your policy. reply freediver 7 hours agorootparentThat was always our policy. reply pinkmuffinere 7 hours agorootparentThe linked article has screenshots showing that it was not reply freediver 6 hours agorootparentI would beg to disagree. The screenshots show that I think there is very little information to be downloaded to begin with because Kagi does not collect it, which is true. That does not mean that our policy is to ignore GDPR requests, that is a ridiculous inference to make. The article you point to is a perception of one person, unfortunately sharing screenshots out of context to create a negative narrative and exploiting a fact that we run a 100% transparent business where you can ask the CEO literally anything directly. Our policies have always and will belong in kagi.com/privacy and not on random websites. And it is hard enough to do what Kagi does even without misinformation shared in bad faith, so I'd ask you to please not do that going forward. Here is why Kagi exists: https://dkb.blog/p/kagi-interview reply jasonpeacock 14 hours agoprevBecause: > If you are not paying for it, you’re not the customer; you’re the product being sold. -- Andrew Lewis reply asddubs 14 hours agoparentI don't really like that quote. Many services you do pay for still treat you like an asset to make money off. And many services that are free, like the internet archive for example, are not. reply santoshalper 14 hours agorootparentI'd put it this way... if you're paying a company, you might still also be the product, but if you're not paying for something that a company is spending money to make, you're definitely the product. reply SansGuidon 13 hours agorootparentI service people for free because I can afford it despite I'm a company. It's part of the philosophy of sharing value for free. There are many services and products I use for free and I then make a donation to them because I love what they do. So clearly it's not true, maybe just true for the companies that do not care much about doing something good for people with only optional contribution in return. reply nox101 13 hours agorootparentAgree. Also, plently of people at Google, Meta, etc feel they are doing good by providing free ads based services. I suspect people with low income are way better off with free search, free maps, free docs than if each was $3 a month. It doesn't sound like much but their were definitely times in my life where $3 a month per service felt like too much. And yet, those services arguably provide extraordinary value for their users. reply asddubs 14 hours agorootparentprevAgain, not true. There's many services like the internet archive that do not operate to make a profit. Lots of open source also fits this bill. The absolutism of the quote is just overly cynical. On the other hand, if the company is VC funded I would say this is generally true but it also dismisses basically all of non-commercial open source. How are you the product when you use debian? reply jsemrau 14 hours agorootparentprevI think social data tracking and categorization reached a point of saturation leading to diminishing returns. As a result, data companies that relied on this to target advertising audience are rolling us premium SaaS plans to de-risk their revenue streams from this problem. reply iml7 14 hours agorootparentprevAre you looking for windows? reply EZ-E 14 hours agoparentprevIn some cases you pay and you're still the product. I paid for a subscription for an online news subscription and they are still showing me some ads (the economist) - likely sharing my data too. reply iml7 14 hours agoparentprevAre you looking for windows? reply dr__mario 14 hours agoprevI didn't have much success with Kagi for Spanish/local searches. Has this improved? reply benhurmarcel 48 minutes agoparentFor local searches (meaning in your city or even more local) I find Google better. For national searches, I find Kagi good at long as you specify the country. That’s one of my favorite features actually, you can leave it international by default, and add “!es” to search in Spain. reply Freedom5093 11 hours agoprevThe only time I think about using or paying for Kagi is when I see these posts on HN and get FOMO. I think that's because I actually don't have that SEO garbage problem anymore. AI apps have made search, and learning in particular, a lot easier. reply Veen 11 hours agoparentAI apps like Perplixity and Phind index and rank web content too. They have the same problem. reply pptr 11 hours agoprevWhen I do a Google search for the example query \"postgresql query analysis\" on mobile chrome (no ad block), I get 0 ads. Same thing if I select the \"Example\" filter as shown in the demo image. reply inquisitor27552 13 hours agoprevi liked the idea but here in SEA the latency is just nuts compared to google. reply maxehmookau 8 hours agoprevI love my Kagi account, and will continue to pay. It is too US-centric, something I've been asked to report in HN comments (I have), and something that continues to be a problem. But as with all of these things, I'm paying to no longer be the product. That's the value for me, and so \"it not working exactly as I expect 100% of the time\" is actually a small price worth paying. Generally speaking, I find the quality of results usually on a par with Google. reply nbenitezl 10 hours agoprevAnother happy Kagi user here, I also love the fact they also give FastGPT as a bonus. reply Peteragain 12 hours agoprevAs a bit of a socialist I guess I should at least suggest that in the information age search is infrastructure. IP addresses are the commons. Capitalism will, of course, argue it's right to make money where it can but .. And I am sure it is not in the national interest to have another country in a position to turn off your infrastructure. reply iml7 14 hours agoprev[removed] reply thesuitonym 14 hours agoparentAnd someone else can take up the mantle. But perhaps, just perhaps, a business can just exist and turn a modest profit, without trying to scorch the earth raising revenue infinitely. reply zorked 13 hours agorootparentI would pay extra for services from a company that promise not to try to grow indefinitely. reply tjpnz 14 hours agoparentprevIf they did that they would lose the bulk of their paying subscribers. reply blindriver 14 hours agoprev [–] I would rather pay $20/month for ChatGPT and ask it questions directly. I think search engines are a dead technology pretty quickly and the entire ecosystem will die in the next 2-3 years. reply a57721 13 hours agoparentThere are lots of use cases when you want references to reliable sources written by real people instead of AI slop. Science, law, technical documentation, etc. If you ask an LLM for the sources, it is happy to generate bogus citations for false claims, and the only way to verify the answer is by using the good old web search. I hope real search engines never die, only those that turn to AI slop like Google. reply JumpCrisscross 13 hours agoparentprev> would rather pay $20/month for ChatGPT and ask it questions directly Kagi integrates GPT 4 and other LLMs, as well as its own Quick Answer product. The Quick Answer product is 9 times out of 10 superior to any of the pre-trained LLMs. Mostly because it's accessing live information. Put another way, I'd love to go head to head with a competitor who relies on ChatGPT for their queries. reply seattle_spring 13 hours agoparentprev [–] ChatGPT answers range from completely correct to deranged God-awful wrong, which means I have to use a regular search engine to verify the answers for anything remotely complex. Relying entirely on generative models for information is asking for trouble. Especially because the wrong answers often \"look\" correct/plausible. reply gandalfgreybeer 8 hours agorootparent [–] If you’re using chatGPT, you can add a prompt (I’ve set it in my rules) to “fact check from other websites” when I’m asking it things I’m not an expert in. It then provides some links which I then open up. I’ve found that to be a lot more efficient than searching from google straight up especially with very specific questions I sometimes query. Half the websites it shows are those I wouldn’t have found on google and are relatively high signal for what I’m looking for (including very niche blogs from experts from the field). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Search advertising is increasingly aggressive, making it difficult to differentiate from organic results, with spending projected to grow significantly from $185.35 billion in 2022 to $261 billion by 2028.",
      "Kagi presents an alternative search engine model by charging users a fee, offering faster, more accurate, and privacy-focused search results without ads or invasive tracking.",
      "Unlike ad-supported search engines like Google, which earns approximately $277 per user annually from ads, Kagi's subscription model aligns its incentives with user privacy and experience, starting at $5 per month."
    ],
    "commentSummary": [
      "Kagi.com is a paid search engine favored by some users for its ability to filter out SEO spam and deliver more relevant search results compared to Google.",
      "The search engine is appreciated for its privacy features and customization options, though concerns about its cost and sign-in requirement persist.",
      "The ongoing debate questions the value of paying for a search engine amidst the prevalence of SEO and AI-generated content on the web."
    ],
    "points": 154,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1728874851
  },
  {
    "id": 41832579,
    "title": "Faster convergence for diffusion models",
    "originLink": "https://sihyun.me/REPA/",
    "originBody": "Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think Sihyun Yu1, Sangkyung Kwak1, Huiwon Jang1, Jongheon Jeong2, Jonathan Huang3, Jinwoo Shin1*, Saining Xie4* 1KAIST 2Korea University 3Scaled Foundations 4New York University *Equal Advising. Preprint Paper Code News event [Oct 2024] Our project page is released. Overview Generative models based on denoising, such as diffusion models and flow-based models, have been a scalable approach in generating high-dimensional visual data. Recent works have started exploring diffusion models as representation learners; the idea is that the hidden states of these models can capture meaningful, discriminative features. We identify that the main challenge in training diffusion models stems from the need to learn a high-quality internal representation. In particular, we show: The performance of generative diffusion models can be improved dramatically when they are supported by an external high-quality representation from another model, such as a self-supervised visual encoder. Specifically, we introduce REPresentation Alignment (REPA), a simple regularization technique built on recent diffusion transformer architectures. In essence, REPA distills the pretrained self-supervised visual representation of a clean image into the diffusion transformer representation of a noisy input. This regularization better aligns the diffusion model representations with the target self-supervised representations. Notably, model training becomes significantly more efficient and effective, and achieves >17.5x faster convergence than the vanilla model. In terms of final generation quality, our approach achieves state-of-the-art results of FID=1.42 using classifier-free guidance with the guidance interval. Observations Alignment behavior for a pretrained SiT model We empirically investigate the feature alignment between DINOv2-g and the original SiT-XL/2 checkpoint trained for 7M iterations. Similar to prior studies, we first observe that pretrained diffusion models do indeed learn meaningful discriminative representations. However, these representations are significantly inferior to those produced by DINOv2. Next, we find that the alignment between the representations learned by the diffusion model and those of DINOv2 is still considered weak, which we study by measuring their representation alignment. Finally, we observe this alignment between diffusion models and DINOv2 improves consistently with longer training and larger models. Bridging the representation gap REPA reduces the semantic gap in the representation and better aligns it with the target self-supervised representations. Interestingly, with REPA, we observe that sufficient representation alignment can be achieved by aligning only the first few transformer blocks. This, in turn, allows the later layers of the diffusion transformers to focus on capturing high-frequency details based on the aligned representations, further improving generation performance. Results REPA improves visual scaling We first compare the images generated by two SiT-XL/2 models during the first 400K iterations, with REPA applied to one of the models. Both models share the same noise, sampler, and number of sampling steps, and neither uses classifier-free guidance. The model trained with REPA shows much better progression. REPA shows great scalability in various perspectives We also examine the scalability of REPA by varying pretrained encoders and diffusion transformer model sizes, showing that aligning with better visual representations leads to improved generation and linear probing results. REPA also provides more significant speedups in larger models, achieving faster FID-50K improvements compared to vanilla models. Additionally, increasing model size yields faster gains in both generation and linear evaluation. REPA significantly improves training efficiency and generation quality Finally, we compare the FID values between vanilla DiT or SiT models and those trained with REPA. Without classifier-free guidance, REPA achieves FID=7.9 at 400K iterations, outperforming the vanilla model's performance at 7M iterations. Moreover, using classifier-free guidance, SiT-XL/2 with REPA outperforms recent diffusion models with 7× fewer epochs, and achieves state-of-the-art FID=1.42 with additional guidance scheduling. Citation @article{yu2024repa, title={Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think}, author={Sihyun Yu and Sangkyung Kwak and Huiwon Jang and Jongheon Jeong and Jonathan Huang and Jinwoo Shin and Saining Xie}, year={2024}, journal={arXiv preprint arXiv:2410.06940}, }",
    "commentLink": "https://news.ycombinator.com/item?id=41832579",
    "commentBody": "Faster convergence for diffusion models (sihyun.me)137 points by vsroy 19 hours agohidepastfavorite18 comments fxtentacle 11 hours agoThe title is not wrong, but it also doesn't feel correct either. What they do here is they use a pre-trained model to guide the training of a 2nd model. Of course, that massively speeds up training of the 2nd model. But it's not like you can now train a diffusion model from scratch 20x faster. Instead, this is a technique for transplanting an existing model onto a different architecture so that you don't have to start training from 0. reply pedrovhb 7 hours agoparentIt does feel right to me, because it's not distilling the second model, and in fact the second model is not an image generation model at all, but a visual encoder. That is, it's a more \"general purpose\" model which specializes in extracting semantic information from images. In hindsight it makes total sense - generative image models don't automatically start out with an idea of semantic meaning or the world, and so they have to implicitly learn one during training. That's a hard task by itself, and it's not specifically trained for this task, but rather learns it on the go at the same time as the network learns to create images. The idea of the paper then is to provide the diffusion model with a preexisting concept of the world by nudging its internal representations to be similar to the visual encoders'. As I understand DINO isn't even used during inference after the model is ready, it's just about representations. I wouldn't at all describe it as \"a technique for transplanting an existing model onto a different architecture\". It's different from distillation because again, DINO isn't an image generation model at all. It's more like (very roughly simplifying for the sake of analogy) instead of teaching someone to cook from scratch, we're starting with a chef who already knows all about ingredients, flavors, and cooking techniques, but hasn't yet learned to create dishes. This chef would likely learn to create new recipes much faster and more effectively than someone starting from zero knowledge about food. It's different from telling them to just copy another chef's recipes. reply psb217 4 hours agorootparentThe technique in this paper would still be rightly described as distillation. In this case it's distillation of \"internal\" representations rather than the final prediction. This a reasonably common form of distillation. The interesting observation in this paper is that including an auxiliary distillation loss based on features from a non-generative model can be beneficial when training a generative model. This observation leads to interesting questions like, eg, which parts of the overall task of generating images (diffusionly) are being learned faster/better due to this auxiliary distillation loss. reply byyoung3 11 hours agoparentprevYes, now it seems obvious, but before this it wasn't clear that that would be something that could speed things up, due to the fact that the pretrained model was trained on a separate objective. It's a brilliant idea that works amazingly. reply psb217 4 hours agorootparentIt's a classic \"Will it work? IDK, maybe. Let's try it and find out...\" paper. reply fxtentacle 4 hours agorootparentprevTo me, it seemed that the technique presented here was just a logical continuation of methods that OpenAI used when they trained the Dota agents: https://arxiv.org/pdf/1912.06719v1 And, arguably, Facebook's unsupervised pre-training for their multi-modal speech-to-text models is kind of the same idea as unsupervised pre-training for a multi-modal text-to-image diffuser. https://ai.meta.com/research/publications/wav2vec-2.0-a-fram... reply zaptrem 11 hours agoparentprevYeah, I wonder whether this still saves compute if you include the compute used to train DINOV2/whatever representation model you'd like to use? reply cubefox 7 hours agorootparentThat's the question. More precisely, how does the new method compare to the classical one in terms of training compute and inference compute? reply viktour19 5 hours agoprevDiffusion models are already being evaluated using pretrained SSL models à la CLIP Score [1]. So it makes sense that one would incorporate that directly into training the model from scratch. [1] https://huggingface.co/docs/diffusers/en/conceptual/evaluati... reply gdiamos 11 hours agoprevStill waiting for a competitive diffusion llm reply kleiba 11 hours agoparentWhy? reply WithinReason 10 hours agorootparentDiffusion works significantly better for images than sequential pixel generation, there is a good chance it would work better for language as well. Sequential generation used to be state of the art in 2016 and it's basically how current LLMs work: https://arxiv.org/abs/1601.06759 reply kleiba 9 hours agorootparentNeural LMs used to be based on recurrent architectures until the Transformer came along. That architecture is not recursive. I am not sure that a diffusion approach is all that suitable for generating language. Word are much more discrete than pixels. reply WithinReason 9 hours agorootparentI meant sequential generation, I didn't mean using an RNN. Diffusion doesn't work on pixels directly either, it works on a latent representation. reply kleiba 8 hours agorootparentAll NNs work on latent representations. reply barrkel 8 hours agorootparentThe contrast here is real: there are pixel space diffusion models and latent space diffusion models. Pixel space diffusion is slower because there's more redundant information. reply magicalhippo 7 hours agorootparentprevI had similar thoughts to you. However diffusion models suck at details, like how many fingers on a hand, and with language words and characters matter, both which ones and where they are. So while I'm sure diffusion could produce walls of text that look convincingly like a blog post at a glance say, I'm not sure it would hold up to anyone actually reading. reply GaggiX 8 hours agoprev [–] I wonder how well this technique works if the distribution of the training dataset between the diffusion model and the image encoder is quite different, for example if you use DinoV2 as the encoder but train the diffusion model on anime. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Generative models, particularly diffusion models, are effective for creating complex visual data, but training them is challenging due to the need for high-quality internal representations.- The study introduces REPresentation Alignment (REPA), a regularization technique that aligns diffusion model representations with high-quality external representations, improving training efficiency and generation quality.- REPA enhances performance by reducing the semantic gap in representations, allowing diffusion transformers to focus on high-frequency details, and demonstrates scalability and efficiency, outperforming traditional models in speed and quality."
    ],
    "commentSummary": [
      "The technique discussed involves using a pre-trained model to guide the training of a second model, specifically a visual encoder, to adapt to a new architecture.",
      "This method focuses on aligning internal representations rather than direct distillation, distinguishing it from other pre-training strategies.",
      "The approach raises questions about its efficiency and applicability across various datasets, highlighting its potential benefits and limitations."
    ],
    "points": 137,
    "commentCount": 18,
    "retryCount": 0,
    "time": 1728861203
  },
  {
    "id": 41835217,
    "title": "Blocking the \"Sign in with Google\" Prompt (2023)",
    "originLink": "https://superuser.com/questions/1773208/how-can-i-block-the-sign-in-with-google-prompt-on-websites",
    "originBody": "Join Super User By clicking “Sign up”, you agree to our terms of service and acknowledge you have read our privacy policy. Sign up with Google OR Email Password Sign up Already have an account? Log in X Skip to main content Stack Exchange Network Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange Loading… Tour Start here for a quick overview of the site Help Center Detailed answers to any questions you might have Meta Discuss the workings and policies of this site About Us Learn more about Stack Overflow the company, and our products current community Super User help chat Meta Super User your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions Tags Users Jobs Companies Unanswered Teams Now available on Stack Overflow for Teams! AI features where you work: search, IDE, and chat. Learn more Explore Teams Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Explore Teams Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams How can I block the “Sign in with Google” prompt on websites? [duplicate] Ask Question Asked 1 year, 7 months ago Modified 1 month ago Viewed 49k times This question shows research effort; it is useful and clear 82 Save this question. Show activity on this post. This question already has answers here: How to disable Google One Tap sign-up prompts? (9 answers) Closed last year. The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved On many websites that require login, those annoying Google login prompts appear: There are several tutorials on the Internet on how to avoid this, for example, this one on How-To Geek, which suggest disabling an option in the Google account. However, this doesn't work, since mine is not enabled and never was: Note, that this only happens with Firefox (110.0.1 (64-bit), AdBlocker ultimate v 3.7.21 installed); if I use the Brave browser (version 1.49.120 Chromium: 111.0.5563.64 (Official Build) (64-bit)), which is known to block ads by default, they are not displayed. I'm on Ubuntu 22.04.2 LTS (Jammy Jellyfish) with Linux kernel 5.19.0-35-generic x86_64. firefox browser login prompt adblock Share Improve this question Follow Follow this question to receive notifications edited Mar 15, 2023 at 6:12 Peter Mortensen 12.2k2323 gold badges7272 silver badges9090 bronze badges asked Mar 11, 2023 at 11:04 jay.sfjay.sf 95111 gold badge66 silver badges1212 bronze badges 2 11 Note that the \"disabling an option in the Google account\" is not a possibility if you use firstparty-isolate or any other privacy features that prevent embeds like this from seeing your Google session cookie. This is another motivation to want a way to block it browser-side. – R.. GitHub STOP HELPING ICE Commented Mar 11, 2023 at 21:18 7 Does this answer your question? How to disable Google One Tap sign-up prompts? – Jan Doggen Commented Mar 13, 2023 at 11:01 Add a comment1 Answer Sorted by: Reset to default Highest score (default) Date modified (newest first) Date created (oldest first) This answer is useful 109 Save this answer. Show activity on this post. uBlock Origin worked better for the poster, with this added to the filters section: accounts.google.com/gsi/* Click on the three gears in uBlock Origin, then go over to \"Options\" and then \"My Filters\" and paste the above line into the page below and then click \"Apply Changes\". Share Improve this answer Follow Follow this answer to receive notifications edited Sep 6 at 18:21 tirenweb 1,38122 gold badges1414 silver badges2323 bronze badges answered Mar 11, 2023 at 12:12 harrymcharrymc 1 6 13 Thank you so much for this answer - many of the answers to this problem start by saying \"well, first, you sign in to your google account...\" :sigh: This seems to work for me. – artfulrobot Commented Mar 23, 2023 at 11:09 13 For those new to this, click on the three gears in uBlock Origin, then go over to \"My Filters\" and paste the above line into the page below and then click \"Apply Chnages\" – Nate Commented May 14, 2023 at 20:02 3 This answer makes the actual internet as a whole better. What a gem. – suchislife Commented Oct 28, 2023 at 17:37 2 If you don't (or don't want to) have uBlock or any other 3rd party extension, and would like to accomplish using built-in OS tools, and are willing to go extreme on this, you can add 0.0.0.0 accounts.google.com to your hosts file, it's /etc/hosts on a Mac and C:\\Windows\\System32\\drivers\\etc\\hosts on Windows. And if you ever need to actually change something on your Google account, you can temporarily unblock it. – ᴍᴇʜᴏᴠ Commented Apr 4 at 9:06 If you want to block them only on a specific domain, e.g. subdomains of stackexchange.com, put this in the dynamic rules pane: stackexchange.com accounts.google.com * block – virchau13 Commented Aug 19 at 17:12Show 1 more comment Not the answer you're looking for? Browse other questions tagged firefox browser login prompt adblock . The Overflow Blog Is this the real life? Training autonomous cars with simulations Featured on Meta Preventing unauthorized automated access to the network Upcoming initiatives on Stack Overflow and across the Stack Exchange network... Linked 154 How to disable Google One Tap sign-up prompts? 26 Disable Login with Google 20 Disable chrome \"sign in as\" popup 15 What risks are you taking when \"signing in with Google\"? 17 How to permanently block 'Sign in with Google' suggestions from websites? Related 6 Block an ad on an excepted site with AdBlock? 1 How to block google logo image in Firefox 11 How do I block ads on startpage.com? 0 How to block ad popups in web browser? 81 How to block Hot Network Questions in the sidebar of Stack Exchange network? 0 Can Firefox's password manager sign in automatically to websites? Hot Network Questions In what Disney film did a gelatinous cube appear? Stick lodging into front wheel - is it preventable? Why does Jupiter spin so fast but not the Sun? Roll a die in 3D Numerically stable half-angle identities Is grounding an outlet only to its box enough? USBc rail filtering with ferrite bead for voltage regulators Does \"people who own cars\" mean \"people who own cars in general\" (so 1+ cars) or \"people who own 2+ cars\"? What type of firearm is ideal in zero gravity infantry asteroid combat? Nexus hub - why is the sprocket being dragged round by a dust cap? SSL certificate working ok on Firefox but not for Chrome I've been hunting for a new job. Should I adjust my job title for each application? Mining metals with microbes Is observation the only way to indicate that God is real? How to check dies temperatures on a modern RISC mac? What was Adam Smith's position on the American Revolution? Could one hypothetically parallelize LaTeX compilation using \\include statements? How can patients afford expensive surgeries but not lawsuits in the U.S. medical system in \"Dr. Death\"? What Expressions/Kind of verbs are used for the adding of ingredients (solid, fluid,powdery) into a container moslty used while Cooking \"Almost true\": non-trivial claims that have exactly one counterexample Is it true that there are real numbers that cannot be expressed? does fetching values into local variables allow greater optimization in C/C++? Is this ring isomorphic to a quotient of a group algebra? Are there infinitely many possible thoughts? more hot questions Super User Tour Help Chat Contact Feedback Company Stack Overflow Teams Advertising Talent About Press Legal Privacy Policy Terms of Service Cookie Settings Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2024.10.11.16802",
    "commentLink": "https://news.ycombinator.com/item?id=41835217",
    "commentBody": "Blocking the \"Sign in with Google\" Prompt (2023) (superuser.com)120 points by Qision 11 hours agohidepastfavorite49 comments archargelod 10 hours ago> accounts.google.com/gsi/* This filter might break functionality on some sites, so it's better to use more specified version: ||accounts.google.com/gsi/*$xhr,3p Explanation of the relevant syntax: `[no prefix]`: Blocks resources that have this text string anywhere in its URL. `||`: Blocks resources that have a specific domain or subdomain. `$3p`: Ensures that resources from a domain are only blocked if you're not visiting the domain itself. `$xhr`: Prevents such resources from being downloaded through the titular JavaScript APIs. More Ad-filtering syntax explained: https://github.com/DandelionSprout/adfilt/blob/master/Wiki/S... reply red_admiral 9 hours agoparentThanks. Added that besides ||google.*/complete/search$xmlhttprequest,important which is not for everyone, but turns off the autocomplete for me. Needs an \"important\" to override the override in on of the default filter lists. And then of course: - google is an ok search engine with the udm 14 trick. - bing is an ok search engine if you use it through duckduckgo. reply dogtierstatus 6 hours agoparentprevIs there anyway to do this on Android mobile? reply McGuffin 4 hours agorootparentYes, switch to a firefox based browser for android. reply boesboes 10 hours agoprevI wonder how anyone can think 'you know what, my website, that you don't even need to sign in to for 99% of the use cases, needs a big popup from google!' Aside from the security/privacy considerations, why the fuck would you do that to a website? SSO from a login page? sure, whatever. a f'ing popup on every page for a SINGLE provider? That is just brain-rot. Do they pay you to do this? reply Sayrus 10 hours agoparentUsually it's because users will login or miss click on it. This will give their email address and personal information so that they can be sold or spammed. On another note, it boosts new accounts/sign-in metrics. It does suck for the user. reply zwog 10 hours agoparentprev> Do they pay you to do this? I don't sites get payed (with money) but it probably improves the ranking in the search results (or at least some SEO guide claims that, so everybody does it) reply whstl 10 hours agorootparentI worked in some companies that had this popup, and the most common goal was to harvest email addresses for newsletters. Setting this up has become an automatic request from marketing people, almost as common as asking us to setup Google Analytics and such. This is almost the equivalent to them to \"have a CI/CD\" for us devs: not having such things for them is strange, almost wrong. Of course the end goal is totally different. reply zwog 9 hours agorootparent> I worked in some companies that had this popup, and the most common goal was to harvest email addresses for newsletters. Ooh, I've never looked into it, but I would have thought that with this feature the website explicitly does NOT get my email address. Silly me, still believing some features are meant for the user. reply whstl 8 hours agorootparentFor fairness, I just disabled my Ad Blocker to check, and the popup seems to have changed, but the previous popups were quite explicit about sharing your email with the website: https://superuser.com/questions/1414410/how-to-disable-googl... I can't confirm whether the email is still shared. It used to be the case from late 2010s up to a few years ago. reply bilekas 9 hours agorootparentprevWhile I don't consider myself an apple fanboy by any means they really did do a good job with their apple sign in, I don't know the full process but they seem to use an email from a pool of apple IDs for emails that prevent the app/service ever getting your real email. It would be easy to assume that other oath providers are doing the same but absolutely not. reply whstl 8 hours agorootparentYep, it uses an auto-generated @icloud.com for \"Hide my Email\" (useable in any website, or even if you want to give to someone in person) and @privaterelay.appleid.com when you use \"Sign In With Apple\". This is quite visible in User Accounts where I work... while they do cause some issues from time to time (when the user disables the relay address for an active account), it guarantees privacy. But I don't know if other popular single-sign-on provider do this. reply cjpearson 9 hours agoparentprevIt's an easy way to increase the user count and claim growth. Since the link is to StackExchange, it may be relevant that they are now dealing with a huge spike in users who do not actively participate and probably unintentionally created an account. https://meta.stackexchange.com/questions/402813/user-activat... reply CalRobert 9 hours agoparentprevI think we’ll see more of this to stop bots and llm scraping. It will likely not show up for chrome users eventually, further cementing Google’s dominance reply fmajid 9 hours agoparentprevIt’s a useful canary for “watch out, this site does not care one whit about your privacy” reply pantulis 9 hours agoparentprev> Do they pay you to do this? Apart from Google sponsoring this in some way or the other (by boosting up SEO ranking in sites that display this) I believe that this is a consequence of the third party cookiegeddon and I guess that once your users allow this login their activity is tracked as first party in your website, which would simplify things a lot for, well, tracking user behaviour. Of course Google benefits more. reply michaelt 9 hours agoparentprevI'm pretty sure 95% of business types and developers visit their own websites with a load of cookies already set, so they never actually see the first-time-customer experience. If someone has searched for gloves on Google, and clicked through to my glove selling website, they're clearly ready to buy some gloves. Why the hell would I put a full screen cookie consent popover in their way? Or a join-our-mailing-list popover? Or require them to complete a captcha to create an account before they can check out? This person wants to give me money, why would I put barriers up in their way? And yet quite a few sites do precisely those sort of things. But if everyone dogfooding the site arrives with cookies that hide the popovers, and an account already created - I could believe they just don't realise how bad their website is. reply photonthug 9 hours agorootparentMore likely that many (most?) employees don’t care about directly harming the company they work for if they can score points for themselves or their departments in the corporate version of game of thrones. Similar to how in a two party system, politicians will often prefer to lose elections to the other party, rather than lose control inside their own party. It only looks self-destructive from the outside.. inside a sufficiently large bureaucracy me/us/them all get muddled reply mythz 10 hours agoprevIt's a dark pattern to trick users into handing over their email. Accidentally clicked on one these instead of the close button and then started immediately receiving incessant marketing spam from that website. Of course I wasn't able to unsubscribe from the mailing list without first creating an account with them and accepting their terms so ended up resorting to blocking their email. reply homebrewer 10 hours agoprevJust go into ublock origin settings -> Filter lists -> enable \"Social widges\" and \"Annoyances\" (you can experiment with only some of them, but I enabled everything years ago and never had major problems). It takes care of a lot of this stuff, including cookie banners and all sorts of popups. Buy a beer for list maintainers (some of them accept donations) since Raymond doesn't, and their work is equally valuable. reply seszett 9 hours agoparentMore specifically, this Google popup is blocked by the \"EasyList – Other Annoyances\" filter list. reply qwertox 10 hours agoparentprevThank you for pointing this out. Those popups weren't achieving anything else but annoying me. reply Qision 10 hours agoparentprevThese lists are marked as obsoletes in my version of ublock (v1.60.0). reply lexicality 10 hours agorootparentDo you need to do a list update perhaps? They're fine in mine (same version) reply Qision 9 hours agorootparentIt works now, thanks for the trick! reply hapticmonkey 10 hours agoprevThe new “Hide Distracting Items” feature in iOS18 Safari has been a godsend for me. Just tap on the offending overlay/prompt and watch it disappear into the digital ether. Even with ad blockers, these sign in prompts are becoming increasingly common and annoying. Blocking Google and Reddit sign in popups especially have restored some of my sanity. reply bongobingo1 10 hours agoparentCurious how that behaves on https://how-i-experience-web-today.com/. I assume its blocking by origin, not behaviour? Or does that entire website just \"\"\"break\"\"\"? reply pcl 9 hours agorootparentMy uneducated assumption based on their docs is that it drops DOM elements or something, rather than network requests. The UI seems to be that you select things you want to be rid of, and the browser makes it so. They state that frequently-changing parts of the page, including ads, don’t get filtered, presumably because whatever they filter on is statically defined structure. reply yunohn 5 hours agorootparentprev> https://how-i-experience-web-today.com/ This is so incredibly accurate - I’m laughing and crying. reply rlpb 9 hours agoparentprev1990s Google would then have used \"distracting item\" stats to adjust website ranks downwards had they done the same thing in Chrome (and had Chrome existed). Ironically, this article describes Google as now being the source of such a distracting item. I liked 1990s Google. reply ktosobcy 10 hours agoprev> There are several tutorials on the Internet on how to avoid this, for example, this one on How-To Geek, which suggest disabling an option in the Google account. However, this doesn't work, since mine is not enabled and never was: I don't have google account (or better yet - I'm not logged in to it in any reasonable manner) yet the promp shows constantly :| f* google reply kemotep 9 hours agoparentThat suggestion for a fix never made sense because you get it on every device and browser. How would that work if you aren’t signed into Google in the first place? reply stvltvs 5 hours agorootparentI have a different Firefox profile to sign into Google with. For normal, everday browsing, I use another profile where I never sign in. reply pixelesque 10 hours agoprevWith a nice example demo of how annoying it is from superuser.stackoverflow! reply butz 3 hours agoparentWho ever thought that half covering Sign up button with this monstrosity was a good UX? reply j16sdiz 10 hours agoprevFrom the comment: > Note that the \"disabling an option in the Google account\" is not a possibility if you use firstparty-isolate or any other privacy features that prevent embeds like this from seeing your Google session cookie. This is another motivation to want a way to block it browser-side. I literally can't remember all sort of site isolation, cross site request or whatnot privacy feature and exceptions. If we can throw away all backward compatibility, can we have something simpler? Or is this just unsolvable because how complex the problem is? reply pjc50 9 hours agoparent> If we can throw away all backward compatibility, can we have something simpler? Maybe, but how do you stop people gradually building it up again because they need/want it for something? reply nottorp 9 hours agoparentprevIt's not unsolvable but it would shrink the \"marketing industry\" by a factor of 100 if the spyware friendly features were dropped out of browsers. reply Semaphor 10 hours agoparentprevWhat do you want to throw away? This is literally what those features are supposed to do. reply jzellis 10 hours agoprevIronically, when I clicked on it I got one to sign into StackExchange. reply whywhywhywhy 9 hours agoprevThe fact this prompt seems to block the first click of input on the actual site usually is indefensible. Not including an easy to find and easy to understand option in Chrome to just disable it outright with a 100% success rate just adds to the evidence that giving Google any power on the internet was a mistake. reply jsnell 6 hours agoparentYou understand that this isn't a browser feature, right? Chrome isn't creating the login prompts and doesn't have any kind of special support for them. It's just rendering the HTML / running the JavaScript on the page. reply zo1 10 hours agoprevHow is this \"feature\" not a privacy/security issue? Why do I get the sense that the whole push towards single-sign-on, OAuth, etc was just to push for a single, ad-controlled login? reply arkh 10 hours agoparent> How is this \"feature\" not a privacy/security issue? Like every third party script this feature has been a privacy issue from day-1. Same as the \"like / share on whatever social networks\" buttons. Same as the google analytics scripts you use, the Google Tag Manager scripts. \"Webmasters\" decided that selling their users data for free service was worth it. For more than 2 decades it's been business as usual. A whole generation and now even less people will bat an eye about doing it, they'll even defend it because \"there is no other way to keep the lights on\". Maybe the lights should be off on most of the websites depending on this kind of practices. reply AStonesThrow 8 hours agorootparentWell, guess what, there is a simple fix to this that we could've implemented when Eternal September began. Don't use any free web services. Don't access anything for free on the Internet. Especially don't patronize an ad-supported company. Don't sign up for free email accounts. Don't visit websites that display ads. I mean, don't try to block the ads, just never go there in the first place! For God's sake, stop stealing audio and video streams, scholarly papers, and other objects of piracy. You're a net drain on the economy... literally. Stop using free (as in beer) software, or at least make donations for it. Stop complaining that you only get a license and not ownership. Rent your software and give the developers their due. All of you, especially those who cheat and block ads, you're all freeloaders who are responsible for the growth of ad-supported services on the Internet, and long before the Internet was a thing, you watched TV, you listened to the radio, you read newspapers and magazines, you've built expectations to get something for nothing, and ultimately you were influenced and manipulated by those ads enough to make them profitable. We've nobody to blame but ourselves for this proliferation of Google, Facebook and the rest. We are the ones who could've stopped it, but we built this Internet the way it is. reply thephyber 10 hours agoparentprevGoogle, Facebook, and Twitter certainly wanted to (1) be the central source of identity and (2) hook into many/most 3rd party site logins. But SSO/OAuth in general has far more tradeoffs. It outsources the difficult task of managing passwords (including hashing and storing), 2FA, password resets, etc. SSo allows the end-user to trust a few mega companies that have comparative advantage around security, and also benefit from having to maintain fewer credentials. reply red_admiral 9 hours agorootparentThe \"central source of identity\" idea is not inherently bad, and for the majority of non-techie people, might actually be a net plus. I also trust google more to not have an SQL injection vulnerability on the login page than some random little shop. I just wish it didn't come bundled with tracking. And then there's the risk that if google's algorithms thinks you did something naughty, you get locked out of everything. reply j16sdiz 10 hours agoparentprevThis depends on who your user are. If you are in corporate environment office, your user would literally expect every internal website seamlessly integrated with each other. reply beretguy 6 hours agoprev [–] Also can probably use a custom DNS with De-Google filter. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Users can block the \"Sign in with Google\" prompt using ad-filtering syntax, such as `||accounts.google.com/gsi/*$xhr,3p`, to avoid functionality issues on certain websites.",
      "The discussion emphasizes privacy concerns and the widespread use of popups to collect emails for marketing, prompting users to consider ad blockers like uBlock Origin or alternative browsers like Firefox on Android.",
      "This highlights the ongoing debate over privacy and the push by major tech companies for single-sign-on systems, which streamline login processes but may raise privacy issues."
    ],
    "points": 120,
    "commentCount": 49,
    "retryCount": 0,
    "time": 1728892127
  }
]
