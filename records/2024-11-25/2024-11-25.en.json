[
  {
    "id": 42232040,
    "title": "RFC 35140: HTTP Do-Not-Stab (2023)",
    "originLink": "https://www.5snb.club/posts/2023/do-not-stab/",
    "originBody": "Subject: RFC 35140: The Do-Not-Stab flag in the HTTP Header Date: Fri, 17 Nov 2023 Message-Id: https://www.5snb.club/posts/2023/do-not-stab/ Tags: #rant(3) Date: March 7, 2111 Abstract This document defines the syntax and semantics of the Do-Not-Stab header, a proposed HTTP header that allows users to indicate to a website their preferences about being stabbed. It also provides a standard for how services should comply with such user preferences, if they wish to. Authors [REDACTED] (Google) [REDACTED] (Google) [REDACTED] (Google) [REDACTED] (Google) Introduction Over the last 50 years, advancements in peripherals have allowed websites to stab users. A number of industries have popped up to provide SaaS (Stabbings as a Service). Some users have expressed discomfort when a knife is plunged into their chest, and this header allows those users to express their personal preferences. A user preference can, of course, be ignored by bad actors. However, most stabbings are not done by malicious actors, they are simply law-abiding companies which will gladly stop stabbing you if you ask. This standard provides a method for a user to easily opt-out of all stabbings, except those mandated by law, and ones that the company wants to do anyways. Syntax The header has only one form, Do-Not-Stab: 1. This is because the lack of a header indicates a clear preference that the user wants to be stabbed. Defaults A user-agent MUST NOT adopt Do-Not-Stab: 1 as the default preference. If a user-agent were to do this, web services SHOULD ignore the preference and stab the user anyways. This is because user-agents are in no position to determine if a user wants to be stabbed or not, this must be an explicit choice that the user makes. Enforcement Microsoft has committed to supporting the Do-Not-Stab header inside the EEA (European Economic Area). Outside of the EEA, support for the header is still in-progress, and you may get stabbed, even with the header set. If you are in a country that leaves the EEA, you may get stabbed. Exceptions Exceptions to the Do-Not-Stab header are accepted when commercial interests outweigh safety concerns. These include, but are not limited to Stabbing users who have consented to being stabbed (even if they don’t know they consented) Stabbings requested by a government. Websites SHOULD NOT try to challenge the legality of any stabbings requested, the user probably deserved it. Stabbings that are probably not going to kill the user. Shareholders wanted it Editor Comments (REMOVE BEFORE PUBLISHING) seriously, what the fuck is with companies nowadays demanding that they be told to not do the things they know they shouldn’t be doing anyways? why is microsoft respecting the user’s choice only in the EEA? because they only have to there. extremely funny how they were also the ones to set Do-Not-Track by default in IE, thereby getting everyone to ignore it for IE. because companies are god damn children and must be told no explicitly by every person individually. it’s a fucking wonder that DNT even got in as a general option and wasn’t mandated to be set per-origin, making it even more fucking useless than it is. https://blogs.windows.com/windows-insider/2023/11/16/previewing-changes-in-windows-to-comply-with-the-digital-markets-act-in-the-european-economic-area/ it’s fucking depressing when even the fucking bare minimum form of regulation is followed to the letter and no more, because every company out there fucking hates you and would sell you out to make a bit more money if they legally could. and even if they couldn’t, who’s going to stop them? “We and our 756 partners process personal data[…]” wow big polycule this website is in, there’s no fucking way they actually need to work with that many fucking companies, what the shit? adtech is a scourge on humanity and serves zero fucking purpose.",
    "commentLink": "https://news.ycombinator.com/item?id=42232040",
    "commentBody": "RFC 35140: HTTP Do-Not-Stab (2023) (5snb.club)738 points by zkldi 18 hours agohidepastfavorite185 comments jeroenhd 15 hours agoIt's important to note that the Do-Not-Stab header has been deprecated because one browser engine switched it on by default and requiring users to opt into stabbing hurt the bottom line of the stabbing industry, so it's no longer respected. Luckily someone came up with General Assault Control, a non-standard alternative, which also only has one value, so you can set Sec-GAC to 1 to request websites not to assault you. By design, this header cannot be extended, so it cannot be used to distinguish brutal stabbings from a comedic pie to the face in the future. Because of legal requirements, the General Assault Control header may not be enabled by default, as American states like Colorado require explicit opt-out (rather than explicit opt-in). This protects Colorado's thriving stabbing and shooting industry as most users will never want to opt into being stabbed. Despite the feature being forced to be disabled by default, the organisation behind the spec is pushing hard for customers to download fringe browsers that implement the feature (though you may need about:config to enable it). Because of the small user base, the request not to be assaulted can be used by websites not willing to follow the standard to make their stabbings and shootings more precise. End users can request a JSON file from the web server containing the supposed support for the GAC header, but requesting this URL may be used to kick the user in the teeth by non compliant servers. reply boomlinde 7 hours agoparentIt's now customary, in order to comply with European regulations, to present users with a list of possible violent crimes against their person that they can opt out of before using a website. This ensures that non-consent to stabbing is always an active choice, so that users who want to be stabbed or otherwise maimed won't accidentally miss out on the opportunity. reply rakoo 7 hours agorootparentWe value your body integrity. We and our 1492 partners would like to stab you. reply avhception 6 hours agorootparentPlease use this outlandishly convoluted form to opt out of every single one individually. You might also want to read our ToS in order to stay informed about the multiple ways, some of them illegal under EU law, you still will get stabbed. (Approximate reading time: 4h53m, assuming a law degree and multiple years of experience in data protection law practice) reply avhception 6 hours agorootparentWe also have a monthly paid plan that allows you to avoid some of the stabbing automatically (but not all of it). Estimated cost for paying every random website you stumble upon: one bazillion dollar / month (imitates Dr. Evil face) reply SlightlyLeftPad 2 hours agorootparentprevIs this part of a long term plan for opt-in suicide booths in New New York City? reply skriticos2 6 hours agoparentprevWhy is it a binary value? What about masochists, or people who lost a bet and want to be stabbed just a little? Or strangled? reply jnordwick 6 hours agorootparentYou can put a window that covers the bottom half of the content the defaults to all assaults being allowed also has a way to customize which assaults you would like. It shouldn't be possible to uncheck necessary assaults for the website might not work. reply FridgeSeal 6 hours agorootparentAnd “by not work” we mean “will work exactly as it should, but little Timmy in marketing will get a frowny face and won’t go out for drinks on Friday, so you have to tick it”. reply foundry27 16 hours agoprevIt’s great satire, but it really does mirror a larger societal shift where the burden of safeguarding personal autonomy has shifted from institutions/regulators to individual users. Do-Not-Stab, Do-Not-Track, whatever it might be, any sort of “voluntary compliance” is a non-starter in the face of financial pressures IMO we need to start normalizing being militant about this stuff again, to aggressively and adversarially defend the freedom to use your computer the way you choose to use it reply pims 7 hours agoparentIt's amusing to see this message heavily upvoted on HN when most mentions of Firefox here are welcomed with an avalanche of perfect solution fallacies. I'm dubious about people becoming militant about this when the software engineering industry gave Chrome a red carpet by using it and installing it on their relatives' computers while knowing very well it's adware and when switching to the alternative is incredibly cheap. reply imglorp 4 hours agorootparentI think we shouldn't minimize the harm Chrome does by calling it adware. It monitors all your activity for Google to tie it to your identity, who then publish your demographics, preferences, history, and mental state on the global markets. Let's call it what it is: a brain tap. reply latexr 28 minutes agorootparentprev> It's amusing to see this message heavily upvoted on HN when most mentions of Firefox here are welcomed with an avalanche of perfect solution fallacies. HN is not a hive mind. There are people here who love Firefox, people who despite it, and everyone in between. It’s tiring to always be reading your type of comment, as if everyone is a hypocrite. Maybe, just maybe, the people making those contradictory comments are not the same individuals. And it’s not like Mozilla is free from controversies, including several of betraying user trust. If every major browser maker is going to break your trust and sell your data, I can see why people choose their poison based on other factors. I use neither Firefox nor Chrome. Is Safari any better? Or Brave? In some areas yes, in others no. I don’t think there’s a single browser vendor which gets it unambiguously right. reply account42 3 hours agorootparentprevMozilla would be the first to request permission to stab you so that they can then analyze the blood of the knife in order to make future product decisions. reply mschuster91 7 hours agorootparentprevChrome had the advantage for a long term because their dev tools were just so much better than Firebug in both features and performance. Even today, I can't pinpoint it to specific things because it's (relatively) little and subtle differences, but Chrome's dev tools feel way more polished than Firefox's. It's almost as if Steve Ballmer and the legendary \"developers developers developers\" speech still rings true today - the key to getting people to use your software is to make life as easy for the power users as possible, let them spread the word. And it's ironic how Microsoft lost its ways there... a lot of people I know have gone from Windows to Mac and convinced their close relationships (aka those whose computers they fix) to do the same. It's just so much more relaxing to boot into an OS that doesn't try to shove advertising down your throat at every turn. reply svrtknst 6 hours agorootparentPersonally I disagree. IMO, devtools were better when competing with firebug, but I haven't experienced much of a difference in the past... 8? years. Something like that. reply pims 4 hours agorootparentprev> Chrome had the advantage for a long term because their dev tools were just so much better than Firebug in both features and performance. Even today, I can't pinpoint it to specific things because it's (relatively) little and subtle differences, but Chrome's dev tools feel way more polished than Firefox's. My point exactly! You're talking about which browser to use for web development. That's not relevant for engineers not touching html/js/css, and for all non tech savvy family members whose computers we set up. reply myfonj 3 hours agorootparentInteresting, in my murky memory Chrome's developer tools were at most \"quite decent\" but for a long period of time could hardly compete with Firefox's, maybe even with mere Firebug. It it true that in total \"feature count\" Chrome most probably leads now, and especially recently they seem to adapt features that used to be Firefox exclusive in remarkably increasing rate. But I really do not remember being blown away by Chrome's devtools, like, ever, actually. Even today I pretty much prefer Firefox Developer Tools over Chrome's, because they mostly has more features I actually need and also feel way less cluttered. Most of the times I need to do anything with Chrome's devtools it takes me just a little moment to stumble upon some missing detail I am used to (for example overflow/layout/event listeners badges directly in the DOM inspector tree) or to be mildly offended by unfamiliar (or missing) keybinding, or confusing layout. There are quite a few features In Chrome that I'd like to see in Firefox (command palette for example), but still prefer \"living\" in Fx albeit without them. Yes, al subjective, biased and anecdotal, but wanted to leave one real (yet still virtual) vote in favour of Firefox's Developer Tools here. reply klabb3 9 hours agoparentprev> IMO we need to start normalizing being militant about this stuff again, to aggressively and adversarially defend the freedom to use your computer the way you choose to use it Yes. As a millennial the times of civil disobedience was better. Not only did we get a better internet for consumers, but better companies were rewarded and won. Rose tinted glasses? Possibly, but there’s another reason for disobedience: the other side does it, and they do it just for money. Concretely, is there something like Adblock that can be done for cookies? I don’t think blocking is as effective as poisoned data though. They ask for data, they should get it. If you don’t get consent, poisoned data is merely malicious compliance. It could even be standardized as an extension to DNT: “if asking for consent after a DNT header, a UA MAY generate arbitrary synthetic data”. reply rakoo 7 hours agorootparentUse ublock origin with the \"Cookie notices\" custom lists. Not explicitely accepting cookies is legally the same as refusing them (now, whether websites actually respect that is the opening keynote of the Naiveté conference) reply cjs_ac 8 hours agorootparentprev> Concretely, is there something like Adblock that can be done for cookies? I use a combination of two browser extensions: Cookie AutoDelete[0] and I don't care about cookies[1]. The second hides any GDPR 'compliance' popup; the first deletes any cookies set by a website when you close the last tab with it open. Both extensions have whitelist functionality. [0] https://github.com/Cookie-AutoDelete/Cookie-AutoDelete [1] https://www.i-dont-care-about-cookies.eu/ reply worble 8 hours agorootparentublock origin now has specific filters for cookie popups, you just need to turn them on in the filter lists. I'd say this is probably preferential to downloading another addon (that already had a scare with being sold off) reply lucumo 6 hours agorootparentprev> I don't care about cookies[1]. The second hides any GDPR 'compliance' popup > [1] https://www.i-dont-care-about-cookies.eu/ I like to use Consent-o-Matic[1] for this. IDCAC accepts tracking when ignoring the request doesn't work. CoM rejects all tracking on those popups. I like the slight Fuck Off that that sends. [1] https://consentomatic.au.dk/ reply mpalmer 16 hours agoparentprevTo be extremely pedantic, it's great satire precisely because it mirrors that shift. Owes a lot to the OG, A Modest Proposal. reply photonthug 12 hours agoparentprev> aggressively and adversarially defend the freedom to use your computer the way you choose to use it Sadly even if you’re inclined to do this, it’s always a war of attrition, and corporations seem to realize they can just up the cost of your resistance in terms of time/frustration, and that’s enough for them to win in the long term. The history and trajectory of platforms, from browsers to AppStore’s to SaaS-all-the-things, is just tragic, with the amount of user control on a downward slide at each stage. The big question now is whether / how / to what extent AI is going to be corporate or democratized, but it’s hard to be optimistic. Or, you know, if Clicking do-not-stab for 60 more years sounds like it sucks, you can try to become a shepherd or something. Works great for ~10 years, and then you can’t use cars, dishwashers or light switches without clicking do-not-stab, at which point they finally win and you say, you know what? I should be grateful they asked before they stabbed me, I practically owe it to them anyway, and I can’t wait to see all the love/cash rolling in after I’m a big shot shepherd influencer. Like and subscribe y’all and as always, hail corporate reply mcdeltat 12 hours agorootparentWorth noting the times where you have the choice to engage or not with a company with bad practices. Make it unprofitable for them to provide horrible service. Particularly applicable to tech, because most of it is useless rubbish we don't really need anyway! reply fsflover 5 hours agorootparentReminds me of Graphene OS, which forces you to directly give money to Google to buy a Pixel, if you care about privacy and security. reply travisgriggs 12 hours agorootparentprevIs this a case where monopoly actually benefits the cause? The last great uprising in the public interest, imo, was Microsoft against the open source movements at the turn of the century. It was a heady time to be involved in software. I miss it frankly. But perhaps it really only succeeded, because that Microsoft was like the Boeing of today, a company where Pournelles second type (the institutionalists) had taken over and was just riding out the momentum, allowing the upstart unfunded open source hippies to actually have success. reply aaronbrethorst 13 hours agoparentprevBest time to do that would've been 19 days ago, but here we are. Buckle up. reply thrtythreeforty 16 hours agoparentprevI'm registering my elderly relatives for dmachoice.org, to prevent them from getting junk mail. These clowns create the problem and then have the audacity to charge you to be added to the opt out list. I was really skeptical about the GDPR when it was passed and I am now fully on board for an American version. reply shadowgovt 16 hours agorootparentI'm still extremely skeptical of it because in practice it basically added a cookie banner to every every website I visit infrequently with no particular benefit to me. I'm just going to click \"yes,\" stop asking. reply Aeolun 15 hours agorootparentThe cookie banner is only there because the website in question uses non-functional cookies (e.g. targeted advertising) reply Aloisius 14 hours agorootparentIt's gotten entirely out of hand. Most EU national government websites have cookie banners. Even the European Commission website has a cookie banner! This should have been implemented at the browser level. Let the browser generate a nice consistent UI to nag EU users when visiting websites about accepting cookies and let the rest of us opt out. reply almostnormal 12 hours agorootparentThe standard for cookies should be updated with a way to include or retrieve a description of each cookie separately. Then, require sites to provide that description, and let users choose per cookie in the browser. reply Sander_Marechal 10 hours agorootparentThat's nonsense. It's not about the cookies, it's about the data collection. You can use cookies without having to use a cookie banner by simply not gathering data you don't need. And if you do gather that data without using cookies you still need to ask for consent. reply dcow 8 hours agorootparentI can tell you, with absolute certainty, that nobody knows how to implement the law or what it even means, legislators, lawyers, engineers alike. There was a good somewhere and now we're in hell. reply Macha 8 hours agorootparentNah, companies don't want to implement it as it's bad for their business model so they feign ignorance. I still remember being at an all hands at a former employer where the team presenting the revised cookie banners promoted as a benefit that it had opt in rates that would make an authoritarian dictator embarrassed to claim as uninfluenced reply account42 3 hours agorootparentprevYou're right in the sense that it tends to be hard to understand things when your salary depends on you not understanding them. This seems to describe most web developers from the number of non-compliant consent popups in the wild. reply shadowgovt 2 hours agorootparentCan you give an example? If your claim is that sites that use cookie banners don't understand the law, I don't know how we square that claim with the European Commission site's cookie banner. Certainly, the government itself can interpret the law successfully, right? reply GoblinSlayer 2 hours agorootparentprevThey already provide description: \"improve user experience\", lol. reply Arch-TK 10 hours agorootparentprevThat would be horrendous and would play right into the advertiser's hands which want you to \"just click accept\". Cookies should be categorised as essential and non-essential and the website should specify which laws it is considering when it categorises them as such. The GDPR definition of \"legitimate interest\" (which is a bit vague but it's not that hard to understand it) should be explicitly clarified so that companies can't claim that a whole swathe of shit they opted you into automatically is \"legitimate interest\" if they also give you the option to opt out. At this point they can still attach descriptions to each cookie (hopefully using some standardised interface so you don't have to literally send these with every cookie, localized) and then your browser can still present you with the idiotic: \"here's what we would like you to use\" interface, but streamline the process with the ability to just opt out of anything which won't outright break the website. Although this still opens it up for abuse by companies putting things like: \"your preference for us not popping up an annoying full-page message every time you visit a new page\" into a \"non-essential\" cookie to incentivise you to just accept them all. Honestly I think we should just have Joe \"Sensible Person\" judge company's websites for whether they're being actively malicious in any way and force the closure of any company which is considered actively malicious along with the destruction of all company IP and liquidation of non-IP assets. All the company owners should also be banned from owning/running any other company for 10 years. (only half kidding) reply devjab 11 hours agorootparentprevAs someone who has worked on the Danish public sector I have a slightly different take on the public websites. They should never have been using things like 3rd party analytics to begin with. I understand it’s was media and communication departments do, and that it’s natural that the people working within them would want to do so regardless of where they work. It’s their trade after all, unfortunately they bring the exact same “user engagement” mindset with them into the public sector. Well, at least in my anecdotal experience with a handful of these departments in 7-8 different cities around here. You can of course make good points on user metrics on a public website, but they should frankly work very different than they would on most web sites. On a public website it should be the goal to get to user to leave the site as quickly as possible, because the longer they hang around the more time they are spending finding what they need. That’s not what happens with these metrics in my experience, however, instead they are used to do what you might do on a news site. That’s just one side of it, however, because the privacy concerns are their own issue. If you absolutely want metrics on a public website at least have the courtesy to build your own. It should be illegal for public web sites to use 3rd party tracking. I know why they use it, it’s for the same reason they spend a ridiculous amount of money on custom designs systems build on top of what is usually SharePoint or Umbraco. They refuse to hire the Django (insert any other extremely low maintenance system) expertise because it’s expensive on the “long term budget”, even though it would be much cheaper than 3rd party tools and consultants on the actual long term budget. Anyway, that is another point. But it really pisses me off when public websites need you to allow 3rd party tracking because they aren’t using it in any way which serves the public. Worst of all is that cookie banners are explicitly a private industry way of dealing with their refusal to respect “do-not-stab”. Public websites could simply put their bullshit into their privacy page. Of course nobody would go there and turn on 3rd party cookies, but why should the public care? reply KennyBlanken 14 hours agorootparentprevThe cookie banner is there to punish people who have cookies turned off or set to be deleted upon browser/tab close - and generally annoy everyone else. Think about how obsessive companies are about \"UX\" and how disruptive the banner is. Bitch-slapping people for fighting against tracking is more important to them than the user being able to access or use the site at all. reply TeMPOraL 11 hours agorootparentObviously, because in our digital economy, users are cattle. Companies are obsessive about UX so the users shut up and eat grass and allow themselves to be milked or sheared. Refusing to participate? A cow that eats grass but doesn't let itself be milked gets shot, so in some sense maybe we should be grateful for the bitch-slapping... reply brookst 14 hours agorootparentprevOr if the legal department is concerned that someone could claim a cookie is non-functional, so to save the uncertainty and expense they advise always showing the banner. Especially since everyone else does. It seems like there should be a parallel to “tragedy of the commons” that talks about how a good idea coupled with extreme penalties can lead to a bad outcome by making any risk calculation result in “jesus we just can’t take any chances here”. reply mola 12 hours agorootparentprevNo,.all the companies running the sites chose to add a cookie banner. And you choose to keep going there reply shadowgovt 8 hours agorootparentYes, and my life world be more convenient if this banner would go away or I could declare a universal preference. I miss the old Internet where nobody cared about their privacy. reply williamdclt 7 hours agorootparentnobody cared about their privacy because there was no widespread systematic effort to invade it. I don't care about my privacy in the street despite it being public because there's no-one following my every step taking note of where I go, how fast, what music I'm listening to, what I'm looking at... (although the astute reader will argue that this is less and less true, there's more and more tech tracking our activity in real life too) reply samtheprogram 14 hours agorootparentprevI click no to all of them, but it would be really nice if the Do-Not-Track header essentially let you pick in advance — for you (0) or for me (1) reply rurban 7 hours agorootparentNot just \"really nice\". It must be mandatory to respect it. reply d3VwsX 6 hours agorootparentprevThe only hope I still have is for some kind of fully local LLM-driven \"agent\" browser that does the browsing for me, navigating search engines, cookie banners and showing me what it found, nothing else. Unfortunately entire businesses are built around preventing people from using bots, for obvious reasons, so the only obvious way forward to make browsing the web a better experience will also mean ending up on the wrong side of that battle. reply blooalien 15 hours agorootparentprev> ... \"it basically added a cookie banner to every every website I visit\" ... Yeah, no. Hostile advertising companies added that cookie banner as a form of \"malicious compliance\" with the law purely to annoy everyone like a buncha spoil't little brats who didn't get their way, so now they're gonna make everyone suffer... If we get a similar law in the USA, you can expect to see annoyances just like it (and probably worse) on sites hosted here, too. reply chrismorgan 14 hours agorootparentThe worst part is that it wasn’t even malicious compliance: the cookie banners they added seldom even satisfied law, in ways completely obvious if you just read the law (which is pretty easy reading, only a few thousand words for the relevant parts). I don’t understand why relevant commissions didn’t make more noise about that, because it was obvious that major players were deliberately poisoning public perception. reply shadowgovt 2 hours agorootparentprevThat heavily incentivizes me to advocate against any such law. reply brookst 14 hours agorootparentprevCan you source your claim? Because it seems like it would create a competitive advantage for a non-hostile advertising company. Websites aren’t any happier about cookie banners than users are. If it’s just an emotional, spiteful reaction, the grownups should be able to make a fortune. reply blooalien 14 hours agorootparentYou'd think there'd be some \"competitive advantage\" to be had, but when their entire industry is built upon tracking and profiling everyone they possibly can, they'll do anything they can, fighting tooth-and-nail to the very end against any legislation that somehow interferes with their tracking, even if it means resorting to childish and petty temper tantrums that further enshittify the web. What little \"competition\" exists in that industry all fully believe that building massive profiles on everyone is the only way to make any money at advertising. They've been allowed to get away with it for so long that they can't even remember there was a time when tracking everyone all the time everywhere wasn't even a thing (and yet advertisers still managed to advertise back then, somehow)... reply wahnfrieden 13 hours agorootparentOther replier believes that competition is a system that works toward consumer needs and betterments. Advertising is extractive reply bombis 4 hours agorootparentCompetition _is_ a system that works toward consumer needs and betterments. In advertising though, you are not the consumer. reply thfuran 15 hours agorootparentprevNot if we ban third-party ads. reply shadowgovt 15 hours agorootparentprevAnd if the regulators didn't predict such compliance they should be replaced with competent actors in their jobs. That was the obvious outcome. What did people predict: site owners leaving money on the table? Who pays for operating the sites then? reply schmidtleonard 15 hours agorootparentWhen GDPR was first going through the public circuit I remember reading the proposed laws and being pleasantly surprised to find that they specifically called out and forbade the likely workarounds, including the obnoxious banners we now see everywhere. I would love to know what happened. Did the laws get \"revised\" to re-open the loophole? Was superseding legislation passed? Did the courts reject it? Are there enforcement issues? reply roenxi 14 hours agorootparentThat sounds like a legal minefield - I would point out that GDPR-style legislation exists because the legislators don't trust the industry to assess what is reasonable. So the industry would be in a position where: 1) They aren't trusted to be reasonable about user consent. 2) They are only to take action when they judge it is reasonable to check user consent. It'd probably be a very rocky process to nail down what those words like \"loophole\" and \"workaround\" mean as the advertisers start abusing prescribed no-banner situations. reply p_l 9 hours agorootparentprevTL;DR the enforcement simply lacks manpower, and the most egregious cases go to court which also takes time. reply Aeolun 15 hours agorootparentprevAll the sites that need advertising like that can just die off and leave the internet a better place. reply shadowgovt 8 hours agorootparentDid we ever think that would be the end result of all this? reply account42 3 hours agorootparentprevGood job rewarding those companies for adding the nag screen. I'm sure that will get them to stop. reply shadowgovt 2 hours agorootparentIf by 'companies' you mean https://commission.europa.eu/ then sure. reply badgersnake 10 hours agorootparentprevCookie banners are malicious compliance and the failure to do anything about them is indicative as to how much the EU cares about privacy vs how much they want to be seen to be caring about privacy. reply pjc50 8 hours agorootparentprevThe problem is GDPR isn't prescriptive enough. That makes it ripe for \"technically correct but really annoying\" solutions. It also failed to actually ban ad tracking. reply adra 15 hours agorootparentprevClearly you don't have a browser plugin that simply opts out of all cookie banners. Ultimately, the webs ites have a financial interest in malicious compliance, so you either work within the system as given or throw your hands in the air and let every and all sites rape your data. reply shadowgovt 15 hours agorootparentYes, the second one. I don't really care; it's not \"my\" data. It's data about me. When I walk down the street and sometime sees me go by, those aren't my photons they caught. By analogy, same with my browsing history. reply Zak 14 hours agorootparentIt is, however worth at least considering restrictions on continuously following a person in public places and reporting all their observed activities to a third party. Of course there are practical limitations on that kind of physical surveillance. It's expensive, tends to attract attention, and even nation states can only do it to a few people at a time. Information technology allows it to scale to almost everyone, almost all the time, for a small fraction of a corporate budget. Perhaps it's worth at least considering restrictions on that. reply dylan604 14 hours agorootparent> It is, however worth at least considering restrictions on continuously following a person in public places and reporting all their observed activities to a third party. I don’t see any difference between online “tracking” and real world stalking. If some one was following you every where you went taking notes on everything you did, interrupting you and preventing you from actually doing what your were actually wanting to do, you’d be able to have the police intercede in your behalf. Only now we think it is different because “on a computer”.??? reply lmm 14 hours agorootparent> interrupting you and preventing you from actually doing what your were actually wanting to do This is the part that would get the police involved, and no-one online is doing anything like this. Doris the curtain-twitcher compiles a dossier on everyone, maybe shares it in her gossip circles. No-one cares. reply rockskon 15 hours agorootparentprevYou are the culmination of your life's experiences. Going by your definition, one could infer an individual has zero intrinsic ownership of any non-health data. Which I categorically object to. reply Aloisius 12 hours agorootparentYou have ownership over your own memories and records. Other people also own their own memories and records - some of which may be about you. At least, this is how it was for most of human history. Now some people think they should be able to demand everyone destroy records about them. If it was possible, no doubt they'd also demand people destroy any memories about them as well. reply rockskon 12 hours agorootparentThat's not how it's been for the bulk of modern history. What absolute absurdity. It's an ancap mentality taken to the notion of privacy. reply moritonal 8 hours agorootparentprevKey to note that the cookie banner fiasco wasn't GDPR, it was a separate policy that should be changed. reply dcsommer 15 hours agorootparentprevePD in 2002 mandated cookie banners well before GDPR in 2018. But yes, point taken that well intentioned regulation can be poorly implemented and have negative repercussions. reply lolc 15 hours agorootparentI know of no regulation that mandated cookie banners. I just know a lot of sites who chose to use banners because the operators are somewhere between weasely and malicous. reply IgorPartola 13 hours agoparentprevI wonder if there is some way to DoS the tracking services by basically accepting third party cookies but then immediately discarding them so every page load generates a new cookie and presumably state stored on the other end to match it. Or are these tracking cookies typically self-contained so that no state is stored server-side? reply tliltocatl 12 hours agorootparentGiven that web industry uses no-server-state for *authentication* (with all the issues it implies), i would expect tracking also be no-server-state. reply rixed 12 hours agorootparentprevIsn't that the reason cookies were invented in the first place? To keep servers stateless? reply afiori 11 hours agorootparentIf the server can recognize you then it is not stateless, cookies make http stateless reply wkat4242 13 hours agoparentprevYeah and the fuss about it being enabled by default is not really relevant. In the EU tracking must be opt-in anyway. So this is expected behaviour. However the EU dropped the ball by not making it mandatory to respect this flag. If they had we wouldn't have had the huge cookiewall mess we have now. reply Deukhoofd 9 hours agorootparentThe annoying thing is that they have regulations in trilogue that would actually make the DNT header obligatory to follow, the ePrivacy Regulation. That was supposed to drop alongside GDPR, but has instead been delayed for 6 years now. It's apparently supposed to be finally finalized somewhere in 2024, so I hope to see it sometime soon. reply wkat4242 8 hours agorootparentOh that's good news, that would be great, then I can just set that flag and will never have to bother with cookie banners againlarger societal shift where the burden of safeguarding personal autonomy has shifted from institutions/regulators to individual users. If anything the shift is going the other way, with some of the more busy-body jurisdictions trying to take things that are properly enforced by the user's user-agent and instead making them officially the responsibility of the other party. reply shadowgovt 16 hours agoparentprevOn the internet, it started as the user's responsibility. For netizens, the idea that the use should be able to opt out of logs about their interaction with the service the operator owns is novel (because they always had the option of not using the service if they found the pattern distasteful). reply blooalien 15 hours agorootparentThere's a bit of a difference between normal logging of access to services to protect your devices / network (and to understand your users' access to your services), and using every nasty trick in the book to build extensive detailed profiles of everyone's browsing footprint across the entire web, often without their knowledge or consent (hence the laws, because it's the only way to convince some folks to not do bad things). The first should be expected behavior, whereas the second should be considered unacceptable and abusive, but has somehow been \"normalized\" in modern society. reply shadowgovt 15 hours agorootparentIt's a difference of degree, not kind, which is how it became normalized. reply hedora 15 hours agorootparentThe internet started with decentralized protocols like NNTP, so you could just choose a different news server if the one you were using started tracking + selling your download logs. Centralizing the serving of third party (or even first party) content is already way outside the original norms of the internet. Heck, back in the day, HTTP caching would be enough to block tracking. (No javascript, and only the ISP sees which users pulled the document from cache.) reply Aloisius 13 hours agorootparentThe internet/arpanet started largely with centralized protocols like various file transfer protocols, telnet, finger, various networked filesystem protocols, network printer protocols, network graphics protocols, echo, QOTD, etc. reply actionfromafar 17 hours agoprevThis is such transparent EU Bureaucracy shilling. No wonder Europe doesn't have any large SaaS companies with their stabbing unfriendly business climate. reply phoronixrly 16 hours agoparentYeah, why can't the EU just leave the stabtech industry stab in peace?... reply rurban 7 hours agorootparentThe stabtech industry will just change to Stab-Into-The-Back technology, because every user hates to be stabbed in the chest, but doesn't care if it's not seen. reply nyanpasu64 16 hours agoparentprevI downvoted before I read the end of the comment and realized this was satire. reply MBCook 16 hours agoparentprevGood to know HN will be the same in 100 years. /s reply bue7jclotemp 16 hours agoparentprevI think you are factually wrong: Skype, Spotify, Revolut, Zendesk, Transferwise... There are quite many European unicorns too (less though than US and Chinese companies) which are operating as SaaS. Some of them got acquired or re-based to other countries though reply hmottestad 11 hours agorootparentDidn’t Zendesk stab a pentester recently? https://news.ycombinator.com/item?id=41818459 reply notpushkin 13 hours agorootparentprevCan confirm, got stabbed by a spammer on Skype yesterday. reply wkat4242 13 hours agorootparentSkype is fully American these days though. reply averageRoyalty 9 hours agoprevThis website appears to be part of a webring (how delightful!) made up of MtF trans people, furries, self-identified robots (some of which exclusively use third person pronouns) and sometimes a mixture of these. All appear to be some form of sysadmin or programmer. This isn't my tribe, but I'm incredibly pleased to see a beautiful reflection of the old internet within this webring. reply cuuupid 17 hours agoprevFor the low price of $20/1000 clicks, I will provide you with a stabbing consent banner, fully compliant with upcoming EU and CA regulations on web-based stabbing. reply jsheard 16 hours agoparentI'm sold, the distinctions between \"necessary\", \"targeting\", \"performance\" and \"functional\" stabbings are such a minefield. Not to mention how I'm supposed to properly disclose the 846 different stabbing brokers I work with. How's a man supposed to make a living stabbing people with all of this red tape in the way? reply makapuf 6 hours agorootparentAt least people will be able to differentiate between legitimate interest to stab you and consent to be stabbed for 247 of those 846 partners. reply Macha 8 hours agoparentprevBy the way, studies show users only opt in to stabbing with our competitors banner 95% of the time, but they opt in with ours 98% of the time, thanks to our banner taking 50% longer to properly opt out of, so you should really go with us. reply layer8 6 hours agorootparentI raise you 5000% longer, which gets you to four nines. reply andyzei 14 hours agoprevThe Do Not Track header was originally proposed in 2009 by researchers Christopher Soghoian and Sid Stamm.[2] Mozilla Firefox became the first browser to implement the feature. https://en.wikipedia.org/wiki/Do_Not_Track#:~:text=The%20Do%.... reply shdon 12 hours agoparentI wonder how many web developers actually honour Do Not Track. I do, in all the websites I've made for my employer too, but I think I'm only getting away with it because my employer doesn't know. I've even made it so that browsing with Do-Not-Track enabled also skips the cookie consent banner and just assume the user wants no cookies other than the strictly necessary ones (like their session/login cookie), and doesn't include Google Analytics, instead just upping a single view counter on the page, with no PII in there. reply kelnos 11 hours agorootparentA better option would be to just make tracking illegal, and heavily fine companies that are found to be doing it. And make it strict liability, so intent doesn't matter. I can dream... reply hifromwork 5 hours agorootparentI know we all have our pitchforks out, and I hate tracking as much as everyone else here, but \"tracking\" is a very broad term, and is not always malicious. Unless you want to outlaw access logs, for example. reply latexr 15 minutes agorootparent> but \"tracking\" is a very broad term Which is why it should be defined in the law. The GDPR and the ePrivacy directive define what counts as tracking and what is acceptable. See for example: https://commission.europa.eu/resources-partners/europa-web-g... I don’t think GP is suggesting we just make a law that says “u track, u pay fine”. reply shadowgovt 8 hours agorootparentprevThis sounds like a recipe to reduce the internet to a handful of heavily-financed publishers who can afford legal protection against strict liability. reply psd1 7 hours agorootparentThat's reasonable. Could also decimate the adtech industry and cut them down to just serving ads based on keyword searches and location, like they did 20 years ago reply shadowgovt 7 hours agorootparentI mean... I'm not categorically against the internet becoming the exclusive playground of FAANG companies, but I perceive many don't agree. reply quectophoton 5 hours agorootparentprev> A better option would be to just make tracking illegal, and heavily fine companies that are found to be doing it. And make it strict liability, so intent doesn't matter. I don't think it's that easy though. The \"just\" is doing a lot of work in there. Consider: Some websites have login with third-party credentials. It doesn't matter that you choose to use these for convenience, because intent doesn't matter, and it is a fact that both the Service Provider and the Identity Provider are tracking you. IdP knows which sites you are logging in to, and SP knows and stores your third-party identity (they might say they need it to know which account you're logging in to, but like I said, intent doesn't matter). Hacker News is currently tracking me. They might say the cookie is needed for session stuff to work, but intent doesn't matter, and it is a fact that the cookie uniquely identifies me. My web browser is tracking my mouse position. Mozilla might say they need it for styling stuff to work, but intent doesn't matter, and it is a fact that Mozilla's software is tracking my mouse position in real time (let's not even talk about browser history). Your browser cache might have two HN posts where my comments appear. If that's the case, then it would be a fact that you are tracking which posts I am commenting on. Intent doesn't matter, so hopefully you're not a company (tracking is fine if you're an individual though (based on the quoted text)). /s Hopefully this ride down the slippery slope illustrates some subtleties, at least without a very precise definition of \"tracking\". But then again, if the definition is too precise, there's gonna be loopholes in the letter of the law; in that case we might say that we should also consider the spirit of the law, but \"intent\" is part of that. reply jeroenhd 9 hours agorootparentprevYou're taking exactly the right approach in my book. Thank you! I don't know if they still do it, but last time I browsed Medium I found that it claimed to respect DNT, which is quite nice. Lots of self-hosted analytics software also respects DNT out of the box and I don't think site administrators often bother to turn that off. Still, the vast majority of websites probably ignores the header, especially since it's been deprecated as a standard. If you care about such things, maybe also consider looking into Sec-GPC, its intended replacement. reply killerstorm 7 hours agoparentprevThere was a much more elaborate standard called P3P recommend by w3c in 2002. It apparently defined a description of how business can use personal data. But apparently it was considered too complex and \"lacking enforcement\". Now maybe if it survived till GDPR it could have it's enforcement, but Mozilla yanked support before that... reply dare944 15 hours agoprev> because every company out there fucking hates you They don't actually hate you. Rather, they love your money and they have a depraved indifference for you. reply khafra 12 hours agoparentThey don't hate you, but they're Out To Get You (https://www.lesswrong.com/posts/ENBzEkoyvdakz4w5d/out-to-get...) reply dylan604 14 hours agoparentprevNo, they love the money they can make about you. I don’t know anybody giving their money to these people. It is other shady companies buying the data about for, shady companies that have collected. All of this is offered to you free of charge. reply notpushkin 13 hours agorootparentMind you, some companies will take your money and still track the shit out of you, show you ads, and sell your data to the highest bidder. reply almostnormal 12 hours agorootparent> and sell your data to the highest bidder. Do they provide a guaratee to only sell once, instead of selling to everyone? reply maufl 10 hours agoparentprevThat reminds me of the second half of this sketch https://www.youtube.com/watch?v=uQjUh4nWwaM reply forty 10 hours agoparentprevlooks like someone just discovered that capitalism is bad for people ^^ who would have thought it... reply jaza 16 hours agoprevRelax, folks, entities have plenty of other options, there still won't be support for Do-Not-Shoot, Do-Not-Rape, Do-Not-Stone, fun for the whole family. reply grahamj 16 hours agoparentDon't forget robots.txt reply charles_f 3 hours agoprevDon't care too much about do-not-stab since I deployed a pi-bulldog on my network that catches all the back alley NSRs (network stab requests). I was thinking about using SDoH (self-defense over https) or AoT (AR15 over TLS) to be protected outside my network as well, but honestly the little stabbings here and there cause sufficiently little blood to be drew that its not worth the hassle. reply sillysaurusx 17 hours agoprevI’ve always wondered, since an RFC is a request for comment, how does one leave a comment? And who? reply staplung 17 hours agoparentA bit of lore that I learned in my networking class in college was that the RFC name was chosen as tongue in cheek in that by the time a proposal gets to the RFC stage, comments are very much not appreciated. You're supposed to comment well before that point. No idea if that bit of lore is true but it is certainly the case that RFCs are usually the final word on the relevant standard. In fact, once they get their ID, RFCs cannot be modified or rescinded; only superseded by another RFC. reply dogleash 2 hours agorootparentThat's apocryphal, the name just lasted beyond the original workflow of a now 55 year old publishing system. The idea that a published RFC is a final word is a newer idea too. Yeah, you can't modify an RFC, you have to publish a newer one, but that was a pretty good way of doing distributed change control in 1969. reply jaza 16 hours agorootparentprevFinally I understand why RFCs are served with the Do-Not-Comment header! reply SilasX 17 hours agorootparentprevThen they should be renamed CFCs (closed for comments). reply telgareith 16 hours agorootparentBut CFCs are banned! reply jowea 15 hours agoparentprev> The early RFCs were, in fact, requests for comments on ideas and proposals; the goal was to start conversations rather than to create an archival record of a standard or best practice. This goal changed over time, as the formality of the publication process evolved and the community consuming the material grew. Today, over 8500 RFCs have been published, ranging across best practice guidance, experimental protocols, informational material, and, of course, Internet standards. > https://www.rfc-editor.org/rfc/rfc8700.html Nowadays you're supposed to comment before it gets to \"Internet standard\" reply vandyswa 17 hours agoparentprevRFC's operate under the IETF. RFC's are developed under some specific group, and you can join that group, the business is generally conducted on email. There are (well, were back when I participated) in-person meetings, but attendance there was not mandatory. reply teddyh 6 hours agorootparentRFC:s are published by the RFC Editor . While it’s true that most RFC:s are written and published through the IETF, this is not an actual rule. reply layer8 6 hours agoparentprevYou can submit errata. Maybe it should be renamed to RFE. reply riffic 15 hours agoparentprev\"request for compliance\" is the alternative interpretation. reply iddan 9 hours agoprevExcellent satire. Really drives the point home. I think it's hard sometimes to understand just how much forces of bad use paper trail to push their agenda. This outlines this really well reply nojs 16 hours agoprevWouldn’t this header just be another bit of entropy used by companies that are going to stab you anyway? reply wkat4242 13 hours agoparentWithout legal backing, yes. If it had that it would have been a very different story. reply ipnon 10 hours agoprevAdtech is kind of like the fungal domain of the web, in that it allows life to technically exist where it shouldn’t, because death is actively in progress. It recycles deathly content back to the top of the food chain to Big N, wherein it is reconstituted into cushy salaries for the people that ultimately create the infrastructure that allows endless slop to permeate the web. reply dingosity 4 hours agoprevThem: What's your LinkedIn Account? Me: Don't have one. Them: Twitter? Me: Nope. Them: InstaGram or TicToc? Me: Nope. Them: Do you use the web at all? Me: Only through Lynx. I see a lot fewer ads. Them: No JavaScript! How do you use YouTube? Me: I don't, really. Them: You have no social media? Me: Well... I *did* order a pizza from Dominos online once... Yeah... I don't use the web much as you would expect for someone who's livelihood depends on it. I just wish USENET was still USEFUL. I have a rant in me about ad-tech and crap-ware on the web. I'm just enjoying my life without the web too much to write it. And clearly, HN is my web-tech achilles heel. reply thih9 3 hours agoprevI find it funny that the authors are from Google, of Google Analytics, where the recommended way to opt out of tracking is to install a \"do not track\" browser plugin (not available on mobile). > Google has also released a browser plug-in that turns off data about a page visit being sent to Google, however, this browser extension is not available for mobile browsers. source: https://en.wikipedia.org/wiki/Google_Analytics#Privacy reply tonetegeatinst 13 hours agoprevThis is going to wipe out the saas market (Sutures As A Service) which is a additional somewhat often used service once Stabbing As A Service has occurred. reply tsujamin 15 hours agoprevA big shoutout to those reading the comments who are the direct subjects of this satire. reply hamdrew 4 hours agoprevI'm personally more worried about being clamped, but this is a step in the right direction. reply b0rbb 13 hours agoprevFor some reason, I'm reminded of a particular comic strip from Achewood - https://achewood.com/2007/01/11/title.html. \"Fools! I have invented a usb device which can collect votes from the Internet and drive a knife through your heart!\" reply tbrownaw 13 hours agoprevI see someone needs to teach their user-agent how to say \"no\". Maybe they could get advice on the best way to do that from these people?: https://news.ycombinator.com/item?id=42169027 reply atoav 9 hours agoprevIf Monty Python made an RFC it would look very much like this one, just with more fruit. On a more serious note: yeah wtf. I hope we in the EU draw the conclusion of companies even being unable (unwilling?) to gain informed consent and just start treating these privacy breaches as an outright crime. reply tdeck 17 hours agoprevFor those who only skim things, it might be worth scrolling down to read the \"Editor Comments\" section which is the actual article. reply MathMonkeyMan 16 hours agoparentI feel like that section ruins the joke. reply SilasX 16 hours agorootparentMaybe it’s just me, but I fundamentally disagree with the mentality that we should prioritize the “feeling of being special” among those who already get the joke (and corresponding point) at the expense of those who have yet to appreciate the message. You can still laugh at the joke with the section there, you’ll just have fewer confused people to correct, and be in one less elite club. reply GuB-42 8 hours agorootparentThe thing is, the last part does not just explain the joke, it is a very angry rant, and it ruins it for me because of the change of tone. Imagine in real life, someone starts making a joke, and then suddenly starts cursing and yelling. I wouldn't be comfortable with what feels like a lack of self-control and I will try to move away before things get violent. Either do the \"joke\" style or the \"angry rant\" style, not both. The joke can be explained calmly if there is a need to. reply dullcrisp 15 hours agorootparentprevSure, but the point of critical thinking club isn’t really its exclusivity. In this case if you don’t know which specific header this is parodying that’s completely understandable. But if you really think this is about computers stabbing people and can’t laugh at yourself about it when you find out that it isn’t then I don’t think we will be able to engage on this topic in a mutually rewarding manner. reply SilasX 14 hours agorootparentI don’t think it’s about computers stabbing people, but that’s not relevant. The issue is your willingness to keep people in the dark so you can feel good that you got a reference without it being explained. reply dullcrisp 7 hours agorootparentI wasn’t accusing you of not getting the joke, I was speaking in general. But thank you for demonstrating how it’s difficult to have a conversation with someone who takes everything literally. reply Timwi 7 hours agoparentprevI feel the need to comment on one sentence in it: “companies are god damn children and must be told no explicitly by every person individually.” While it's true that children will often go out of their ways to test boundaries, I have no trouble giving them the benefit of the doubt and saying that children are innocently experimenting. Companies, meanwhile, are doing this with fully deliberate malicious intent. They do this because capitalism rewards it. We need to say this, and keep saying it, until everyone gets it. Companies cannot be reared like children. Companies do not “mature” to become well-behaving, ethical citizens. With the profit motive in effect, companies have every incentive to work around every legislation and regulation and screw us at every opportunity they get. The profit motive must go. reply grahamj 16 hours agoparentprevI bailed before that so thanks for pointing it out. I couldn't agree more, both with the point implied by the RFC and with that directly stated below. reply benreesman 12 hours agoprevSounds like handlers of the “UPGRADE” verb SHOULD have taken the “WOCK” to Poland. reply m0rissette 15 hours agoprevRight. This was just too on point. Thank you for making my night! reply yieldcrv 9 hours agoprev> “We and our 756 partners process personal data[…]” wow big polycule this website is in This gets more and more unhinged, I love it reply indus 15 hours agoprevWhy a header? Do a sidedoor as a /do-not-stab.txt Do-Not-Stab: 1 reply SilasX 16 hours agoprevI couldn’t tell if it was intended to be a note-for-note parody of an RFC about the do-not-track header, but I couldn’t find one that would qualify. The closest would be this[1], but it doesn’t cleanly match up (in part because [1] is more verbose and its points scattered). Another satire RFC in the same spirit is the one about the evil bit[2] (designate one bit in packets to indicate whether it’s intended for evil), with the same subtext as the linked post: no, you can’t trust malicious entities to change their behavior to make it easier to stop. [1] https://www.w3.org/TR/2019/NOTE-tracking-dnt-20190117/ [2] https://datatracker.ietf.org/doc/html/rfc3514 reply zatkin 12 hours agoprevWell that's one way to take a stab at this problem. reply scotty79 14 hours agoprevI'd love for Please-Do-Stab header to exist so I can just set it and with it opt out of any stabbing-anti-stabbing wars and politics. I fully understand that it's absence wouldn't meant that people won't get stabbed, but it would save time and mental space of all people like me who really don't care about being stabbed or not. Honestly if anything, I'd like to be stabbed more. By analogy to current situation about tracking ... Ad companies know too much about me? I think they know too little. For example for half a year they still haven't figured out that I know barely any words in German and are serving me German advertisements all the time just because I happen to be living in Germany currently. reply PeeMcGee 16 hours agoprev> it’s fucking depressing when even the fucking bare minimum form of regulation is followed to the letter and no more For Microsoft this also rings true from the opposite direction. Any specification that Microsoft technically abides is implemented in an egregiously dark way (at least for anything consumable at an enterprise level). They go to great lengths to exercise every bit of leeway permitted by the spec, even when it doesn't make economical sense, because what are you gonna do about it? Vote with your wallet? Against the vendor that runs all your workstations and manages your directories and databases and deployments and authentication and authorization and business intelligence and and and? No, you're gonna accommodate their absurd counter-requirements because what other choice do you have? The decision then becomes: 1. branch your code to shit with `vendor == microsoft` clauses 2. branch your project/architecture to shit and effectively maintain a Microsoft version alongside the \"normal\" core version 3. use Microsoft's bespoke library that solves the problem they created A project that selects option 3 will face the least resistance integrating with Microsoft products, but will also become beholden to arbitrary rules that complicate integration with every other vendor who benevolently implements the standard. reply anakaiti 13 hours agoprevnext [2 more] [flagged] Timwi 7 hours agoparentThe whole website is a treasure trove. There's a page with two C# puzzles and one with an HTML/JavaScript puzzle that I found very interesting. I'm still stuck on the second C# one! reply TacticalCoder 16 hours agoprev> it’s fucking depressing when even the fucking bare minimum form of regulation is followed to the letter and no more, because every company out there fucking hates you and would sell you out to make a bit more money if they legally could. and even if they couldn’t, who’s going to stop them? Certainly not any government. If you think the EU's regulation are of any help to the consumer you are gravely mistaken. The EU is quickly becoming a fucking nightmare to live in. \"The more corrupt the state, the more numerous the laws\". The meme that goes around atm is that while Elon Musk created Tesla, SpaceX and Starlink the EU managed to get everybody to now have plastic bottles who do not close properly anymore: due to some regulation that mandates that bottle caps must hold to the bottle, weird only partially-functional mechanism have been created and it's a PITA to either drink from a plastic bottle or, worse, try to lay it horizontally in a fridge. That's what the EU is: probably that some politicians or bureaucrats with enough brain cells to recognize a bottle cap on the ground thought \"I've got an idea to make the EU better, let's mandate every bottle to have a cap that cannot be separated from the bottle\". As a result you lay horizontally a plastic bottle of sugary drink in your fridge (because you've been used to do that for decades) and now all your fridge is sticky due to the bottle leaking. It's all that is wrong with the EU bureaucrats in one example. Also hailing the EU as the savior vs Microsoft when our lives becames miserable with EU consent cookie popups virtually everywhere is a bit thick. reply orbat 16 hours agoparentSo the EU is bad because you can't learn to screw on a bottle cap that's different than before? reply SirHumphrey 12 hours agorootparentI am not joining the whole “EU is bad argument”, however the new caps are very annoying, especially the limited benefits they provide. reply kawsper 9 hours agorootparentThe non-profit Plastic Deposit Organisation, responsible for managing Denmark's container deposit system, estimates that this change alone will enable them to collect and reuse approximately 70 million additional bottle caps annually. This equates to 140 tonnes of plastic each year. https://www.emballagefokus.dk/goer-noget-uden-at-goere-noget... reply account42 2 hours agorootparentThis assumes a 90% cap return rate before (which seems low) and a 100% return rate afterwards (not in Denmark myself but I can't be the only one to have returned zero of the new caps vs almost 100% before). The whole thing smells like a made up issue concocted by some company wanting to sell their bottle cap solution. reply lmm 13 hours agorootparentprevHonestly yeah. The EU is run entirely by PMC people who don't understand or care about the effect on lower-class and frankly less intelligent people's lives. reply rakoo 5 hours agoparentprev> while Elon Musk created Tesla, SpaceX and Starlink the EU [created] some regulation that mandates that bottle caps must hold to the bottle At least the EU made something useful reply CRConrad 12 hours agoparentprev> The meme that goes around atm is that while Elon Musk created Tesla, SpaceX and Starlink the EU managed to get everybody to now have plastic bottles who do not close properly anymore: due to some regulation that mandates that bottle caps must hold to the bottle, weird only partially-functional mechanism have been created and it's a PITA to either drink from a plastic bottle or, worse, try to lay it horizontally in a fridge. I haven't encountered that meme, but if it exists, it's like most memes seem to be: Wrong. The bottle caps work just fine. reply WD-42 16 hours agoparentprevnext [3 more] [flagged] CRConrad 12 hours agorootparentNo, he needs to learn how to screw on a bottle cap. We keep soda bottles horizontal in our fridge, and they don't leak. reply account42 2 hours agorootparentDismissing people's real concerns is how you get them to vote for parties you don't like. Fact is that the new caps do make it easier to end up without a good seal. reply bagels 16 hours agoprev [–] The authors are [redacted] Google. Are they actually Google? They seem to unironically complain about what Microsoft is doing, but Google is guilty of the same. reply teractiveodular 12 hours agoparentI think the author's entire point is that self-regulation by the big boys is not working very well. reply Mathnerd314 14 hours agoparentprevThe actual author is one person, user '5225225' reply averageRoyalty 9 hours agorootparentApparently they identify as a robot, not a person. reply bhaney 16 hours agoparentprev [–] Dude come on reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "RFC 35140 humorously critiques the deprecation of the \"Do-Not-Stab\" HTTP header, which was abandoned after a browser's default setting negatively impacted the fictional stabbing industry.",
      "The introduction of a \"General Assault Control\" header, requiring explicit opt-out, satirizes user consent mechanisms and the shift of responsibility from institutions to individuals.",
      "The satire addresses broader societal issues, including privacy, data tracking, and the difficulties of enforcing regulations against corporate interests."
    ],
    "points": 738,
    "commentCount": 185,
    "retryCount": 0,
    "time": 1732495383
  },
  {
    "id": 42230103,
    "title": "Starlink Direct to Cell",
    "originLink": "https://www.starlink.com/business/direct-to-cell",
    "originBody": "STARLINK DIRECT TO CELL Seamless access to text, voice, and data for LTE phones across the globe. The Starlink Direct to Cell launch campaign is underway. LEARN MORE UBIQUITOUS COVERAGE Starlink satellites with Direct to Cell capabilities enable ubiquitous access to texting, calling, and browsing wherever you may be on land, lakes, or coastal waters. Direct to Cell will also connect IoT devices with common LTE standards. TEXT Starting 2024 VOICE & DATA Starting 2025 IOT Starting 2025 STAY CONNECTED Direct to Cell works with existing LTE phones wherever you can see the sky. No changes to hardware, firmware, or special apps are required, providing seamless access to text, voice, and data. Careers Satellite Operators Authorized Reseller Privacy & Legal Gear Store Starlink © 2024 Starlink is a division of SpaceX. Visit us at spacex.com Interested in staying up to date with Starlink? Email SIGN UP chevron_right By clicking Sign Up, you agree to our Privacy Policy",
    "commentLink": "https://news.ycombinator.com/item?id=42230103",
    "commentBody": "Starlink Direct to Cell (starlink.com)649 points by tosh 22 hours agohidepastfavorite714 comments mmaunder 17 hours agoVertical integration by Starlink of the cheapest launch capability in the world (by far) is the reason there are no competitors, and there will be no competitors. The pace of innovation at SpaceX is not THE reason - it’s an additional reason that no one has a snowballs chance in hell of ever catching Starlink. I’ve seen talk of competitor satellite networks or a possible competitor emerging. Folks it’s game set and match, the trophy has been handed over and the crowd has gone home. SpaceX and Starlink have the same owner, both are private companies, with SpaceX launching 80% of the global space payload last year and rising, and Starlink has a constellation two orders of magnitude bigger than any competitor. It’s over. And IMO it’s awesome. reply modeless 17 hours agoparentI disagree. Starlink is indeed awesome and SpaceX deserves every bit of their success. But there will be competitors eventually, if for no other reason than foreign militaries sponsoring them. There's no inherent reason for this to be a winner takes all market. We can only hope the competitors are half as responsible as SpaceX has been about space debris risk and ensuring the satellites are not visible to the naked eye and don't disrupt astronomy. So far the proposals I've seen have been much worse than Starlink in these areas. reply nordsieck 15 hours agorootparentIMO, one of the central problems is the cost of launching stuff into space. Today, SpaceX offers world leading low prices to launch satellites: $4 m / tonne[1]. But Starlink has access to launch at cost, which is $0.86 m / tonne[2]. Which is a huge advantage when launching an enormous number of satellites. One thing to keep in mind, especially for these LEO constellations: the lifetime of these satellites is 5-10 years. Which means the operators can never stop launching. It's an ongoing operational cost. For smaller operators like OneWeb, they don't have to launch that often, but for a serious competitor like Kuiper, they'll be constantly launching some satellite every year. IMO, launch cost will be a problem even for China. The cost of an LEO constellation is so high that even if it's partially subsidized by the military it'll be a serious cost for the country. That could change pretty soon, though - various companies and organizations in China are aggressively working on getting reusable rockets working. --- 1. $70 m / 17.5 tonnes == $4 m / tonne 2. $15 m[3] / 17.5 tonnes == $0.86 / tonne 3. The $15 m number is not public info, but it is widely believed that it is in the correct ballpark. reply nrmitchi 15 hours agorootparentIn the past this at-cost dealing would have been considered monopolistic enough to force divestment (ie, almost exactly the same as Boeing and United Airlines divestment due to the Air Mail Act). > Air Mail Act of 1934: > This legislation prohibited the common ownership of airlines and aircraft manufacturers to prevent conflicts of interest and promote fair competition in the aviation industry. reply nordsieck 14 hours agorootparent> In the past this at-cost dealing would have been considered monopolistic enough to force divestment I guess we'll see what happens. As with most things monopoly related, the critical fight is over how to appropriately define the market. Presumably SpaceX would argue that Starlink is an ISP and that it just happens to use satellites to deliver its service. And if that doesn't work, then it's a satellite internet provider, but competes with both LEO and GEO services. If it ever goes to court, it'll be interesting to see how such an argument holds up. reply ryandrake 14 hours agorootparentFor obvious reasons I think it's pretty safe to say we can count on at least the next four years of zero regulation or government scrutiny of any company Musk is involved in, monopoly-related or otherwise. reply starspangled 13 hours agorootparentYou believe the FAA, FCC, OHSA, EPA, FDA, etc., will cease to regulate SpaceX, Tesla, Nuralink operations? That seems pretty outlandish. reply michaelt 7 hours agorootparentThey won't cease to regulate, no. But you may have noticed companies like Boeing getting white-glove treatment from regulators. You know, deciding that their competitor's cheaper aircraft should be subject to a 300% tariff. Not burdening them with too much scrutiny about whether that modified aircraft should keep the same type rating. Taking their word for it when they say every aircraft has 100% of the door bolts installed. If they have broken some regulations, maybe giving a $150 billion company a $250 million fine. Not ceasing to regulate - just regulators with broad discretionary power exercising that discretion in line with the will of the politicians who appoint them. reply vbezhenar 10 hours agorootparentprevStarlink is the most important military weapon in the world right now. Those civilian organizations have no say when state security is at hand. It's like disarming nuclear rockets because some green guys care about birds. Will not happen. reply starspangled 8 hours agorootparent\"National security\" obviously gets significant concessions from regulators. That doesn't mean military and adjacent industries or significant industries and works are above the regulators, it just means the necessity of the activity and input from military and other interested parties would be duly taken into account by regulators. That's not unique to SpaceX and I don't think that's wrong as such, although people argue that military interests in general get too much leeway. reply hhh 9 hours agorootparentprevStarshield != Starlink reply bbarnett 9 hours agorootparentParent should have said \"SpaceX\", Starlink is just a subsidiary. SpaceX has more military applications than Starshield alone. For example, SpaceX's assembly line will be pumping out (eventually) a rocket a day. That's the plan. From a military perspective, Starship is supposed to be able to send 100+ people on long space trips. If that is instead to deliver troops to other parts of the planet, I'm sure hundreds could be packed in. Imagine a fast deploy with parachute capability for personnel and cargo, just as with planes, but with immense range and deploy speed. You may wonder why, but aircraft carriers and their fleets are considered less usable as deploy platforms, due to increased vulnerability. If the US continues to withdraw from the world stage, its ability to deploy could be affected by a reduction in 'friendly' regional countries and thus leased bases. I don't see any issue with this now, but once a large conflict breaks out, who knows... and this could vastly enhance Starship or equiv as a deploy platform. I'm sure some reading this will balk at \"large war\" and \"never happen\" and so on, but Starshield is an example of a platform for such a large conflict. So considering the use of Starship itself as a lightning speed, emergency deploy platform is important. There are all sorts of gotchas, such as being shot down, but of course those same issues exist with planes or ships. Frankly, with the state of AI, the close-to-real Android + military robots, along with drones, Starship would be best served by mass fly-over and deploy of 100k small drones, or hundreds of military robot platforms, or.. well, lots of things. This really isn't about Starship of course. It's just that we've gotten to the point where this sort of platform is very usable. I can't imagine sending in a large-cost asset like this for general troop deploy, but I can for special ops, weapons platforms in low-risk flyovers, and a variety of other use cases. And in times of war, things get nationalized too. Interesting thoughts on the logistics side. reply btilly 13 hours agorootparentprevElon Musk was just appointed by Donald Trump as being in charge of firing half of the government. He won't likely do that. But any regulator who gets in his way? Yeah, not many will volunteer for \"the firing line.\" reply starspangled 12 hours agorootparentI really don't know what Musk has been appointed to do and it's a laughably blatant conflict of interest, but conflicts of interest seem to be what the entire government is built on. Politicians involved with energy and military companies are involved in decisions to go to war, generals get lucrative consultancy jobs at military firms, congress makes billions of dollars insider trading, foreign aid somehow finds its way funneled through \"charities\" owned by the ruling class, politicians cosy with medical companies block real healthcare reform, etc. Musk isn't anything new or different here. The idea that he'll just be above the law is fearmongering hyperbole though. Sure he'll get favorable treatment and be able to push his agenda to degrees well out of reach of us commoners. No more than if he'd just stayed in the shadows and bought his politicians and judges and bureaucrats and generals like a normal billionaire. reply hsuduebc2 11 hours agorootparentI follow the same reasoning as you. This is actually nothing really \"new\". Patronage from politicics is something that is publicly criticized but is quite common among politicians and business. reply smolder 10 hours agorootparentIt's too bad no one in government will ever step up to undo the citizens united ruling. At least we didn't have legal-but-opaque bribery, prior. The difference is substantial when people can't report on where campaign financing comes from without someone first talking too loud about it in a public setting. reply _heimdall 6 hours agorootparentThe good news, at least, is that Citizens United was only a legal ruling and can be overturned by another ruling. Laws are much harder to undue, with rulings we don't need anyone in the government to step up (other than judges trying the case). reply einichi 8 hours agorootparentprevHow can you determine a conflict of interest if you don’t know what he’s been appointed to do? reply starspangled 8 hours agorootparentBecause I heard he was going to have some advisory or executive capacity on government operation. There's a significant conflict of interest there if he's running and owning these companies at the same time. reply _heimdall 6 hours agorootparentIts hard to determine a conflict of interest when the role isn't clear though, and the problem there is that everyone can really go off of what they heard through the grape vine. If the role truly is advisory I wouldn't personally see that as a conflict of interest. Regulators are often asking for advise from those they are meant to regulate without it getting flagged as a conflict of interest (for better or worse). reply starspangled 4 hours agorootparentI don't think it's that hard to determine. He has big companies involved in significant regulatory actions and oversight, he would stand to gain a lot by influencing things slightly in his favor. Sure, taken to absurdity everybody in government has a conflict of interest because they are alive on the same planet and have heir own views on things, but for the case of someone like Musk it's pretty clear. Politicians and bureaucrats can and should consult with the people they govern of course. The \"proper\" way to do that would be via reasonably open and transparent process that is open to interested parties so competitors, customers, unions, scientists could have their say. Again I'm fully aware this isn't how things actually work, so I'm not saying Musk is really doing anything outside the norm in American politics by buying a seat at the table. He's just being slightly more open about it than most of them. reply _heimdall 3 hours agorootparentI wouldn't be opposed to going after such situations as corruption or conflict of interest issues, but that's going to be a big can of worms. From the FAA and Boeing to multiple health agencies and pharmaceutical companies, there are a ton of advisory type roles that involve industry leaders \"recommending\" policy. I'd be surprised if Musk ended up at the top of the list when sorted by impact, counted either by financial impact or number of rules and regulations impacted by industry. reply mschuster91 10 hours agorootparentprev> The idea that he'll just be above the law is fearmongering hyperbole though Is it? If there is anything the 45th and the aftermath has shown is that there are people clearly above the law. And even without the 45th, Musk himself has escaped justice many many times - especially the SEC whose explicit orders he openly defied multiple times. reply starspangled 8 hours agorootparentYes I think it is, and I think the rhetoric around Trump is hyperbole and fearmongering too. Not that you can't criticize them, I just don't see exaggeration being interesting or helpful there. Also I think caring about certain corruption or conflicts of interest when it happens to politicians one disagrees with is fairly easy to be seen as being divisive or politically motivated even if it's not. I thought that wheeling out the architects of the Iraq war to denounce Trump's corruption/incompetence/bad foreign policy/etc was particularly ironic and sad, for example, even if they might have been technically correct. Musk isn't going to be immune to federal regulators. I'm sure he'll get the kinds of favors that come with buying politicians as all the rest of them get though. reply mschuster91 7 hours agorootparent> Yes I think it is, and I think the rhetoric around Trump is hyperbole and fearmongering too. Well just reading through Project 2025 is very sobering. It's not like old times where what they wanted had to be read through the lines any more, it's right out in the open what they want to do - and even getting a quarter of their plans actually passed through is a very, very troubling perspective. > I thought that wheeling out the architects of the Iraq war to denounce Trump's corruption/incompetence/bad foreign policy/etc was particularly ironic and sad, for example, even if they might have been technically correct. A sad consequence of people no longer debating policy on a shared common ground based on facts, but on tribalism, lies and propaganda instead. reply starspangled 4 hours agorootparentI shouldn't have brought up Trump, the subject never goes anywhere useful in an online debate. That was just my opinion, and other opinions and fears are not invalid. > > I thought that wheeling out the architects of the Iraq war to denounce Trump's corruption/incompetence/bad foreign policy/etc was particularly ironic and sad, for example, even if they might have been technically correct. > A sad consequence of people no longer debating policy on a shared common ground based on facts, but on tribalism, lies and propaganda instead. Yep. When they do that it does make you wonder who shares common ground with whom, and who spreads lies and propaganda about what. reply mullingitover 12 hours agorootparentprevSafe to say? You sure about that? I’d say it’s just as likely that six months from now there will be a falling out, Musk will be called a pathetic loser, government agencies will be turned against him, etc. If past behavior is any kind of indicator, it’s more likely than not. I would not be surprised if we see Musk doing a perp walk within 12 months. reply perihelions 8 hours agorootparentFor those who forgot, Musk joined Trump v1.0's advisory council in December 2016 [a], and resigned from it in June 2017 [b]. All of this played out once before. [a] https://news.ycombinator.com/item?id=13175928 (\"Trump Names Elon Musk, Uber CEO to Advisory Team – TheHill (thehill.com)\", 92 comments) [b] https://news.ycombinator.com/item?id=14465667 (\"Elon Musk quits Trump advisory councils, saying, 'Climate change is real' (latimes.com)\", 4 comments) reply TheOtherHobbes 8 hours agorootparentprevTrump is likely to have an entirely unexpected terminal medical event before his term is over. The nation will mourn his heroic patriotism. Then business will carry on as usual, only more so, with a more compliant leader. reply griomnib 12 hours agorootparentprevThere can only be one Main Character, and Trump doesn’t share the spotlight with anybody. Elon will fuck up and his money won’t save him from what comes after that. reply squilliam 11 hours agorootparentGreat fanfic material reply flyinglizard 10 hours agorootparentprevElon knows well enough to act as a supporting character. He can't run for presidency anyway given he's not a native, and no other political post would be interesting enough. There'll be no falling out. reply mullingitover 1 hour agorootparentThe recent U.S. Supreme Court ruling that addressed Section 3 of the 14th Amendment and declared that they're only enforceable by Congress really opens a can of worms. It sounds to me like the 22nd Amendment and the Article II natural-born citizenship requirement are also only enforceable by Congress. If you're making your plans based on a theory that Congress is able to do the right thing, or that the Supreme Court is not a hyper-partisan institution, I would have a strong C because plans A and B are pretty questionable. reply dotancohen 5 hours agorootparentprevTrump is not a native either, his family is German and Scottish (just checked). So far as I know a native has never held the presidency in the US. reply southernplaces7 4 hours agorootparentWhat silly political posturing. Native-born is the specific reference, and a perfectly valid one. By your logic, if the current descendants of people who have been here for many centuries by now aren't natives, than vast parts of the world's population are also not natives of the places where their families have lived for centuries. Why not go further and say that the \"natives\" also aren't natives since they also migrated to the Americas over the Bering land bridge? reply griomnib 1 hour agorootparentPeople were here, and Europeans showed up and killed nearly all of them, claimed all the land as their “manifest destiny”, and proceeded to subject the few original inhabitants they didn’t kill to lives of desperation. Call that whatever you want. reply dotancohen 1 hour agorootparentprev> By your logic, if the current descendants of people who have been here for many centuries by now aren't native. It's not my logic. The term Native American has an agreed, standard meaning. Trump's family does not meet that meaning. My comment was not an attack on your political views. Are you suggesting that being born in a place makes one native? I'll accept that definition. Now go convince the rest of the world to update their definition of Native American. reply robotresearcher 29 minutes agorootparentprevParent didn’t say Trump is a Native American, just a native (of America, from context). That’s a perfectly normal use of the word ‘native’, and you don’t win consciousness points by pretending otherwise. reply zo1 12 hours agorootparentprevAnd this is why we can't have nice, cheap things. Instead we usually get that \"cost\" pressure solved by giving it on a silver platter to worker-rights-leading China. There has to be a better way to prevent abuses in the market without crippling it. But following from that, at what point did we assume this kind of (monopolistic) abuse would happen automatically anyways? I haven't seen it yet, so let's maybe hold off till it happens? Maybe one day X will host all sorts of government-unapproved content on satellites that are free from US jurisdiction and control? @Elon, do this now, they'll come for you eventually. reply s1artibartfast 12 hours agorootparentit is a fascinating outcome when a vertically integrated monopoly is the cheapest option, and best consumer value. The challenge is figuring out if the firm is really providing the best value, or just a local minimum. reply modeless 11 hours agorootparentMy understanding is Standard Oil provided good service for low prices in most cases. It's not always the case that monopolies provide super expensive or bad service. reply DanielHB 9 hours agorootparentprev> vertically integrated monopoly is the cheapest option I would like to remind you that you can use google, gmail, google maps, google drive and a bunch of other services for free (and the best consumer value even if accounting for their data gathering). reply ulfw 13 hours agorootparentprevNow that Starlink owner Musk effectively runs the US government from Trump's ear no divestment of any kind will happen that negatively impacts Mr. Musk reply BurningFrog 3 hours agorootparentprev> But Starlink has access to launch at cost, which is $0.86 m / tonne[2]. Which is a huge advantage when launching an enormous number of satellites. Starlink is a division of SpaceX. So what price it charges/pays itself is only an internal bookkeeping artifact. reply punnerud 10 hours agorootparentprevIf China where to compete they also need LEO satellites that is just over China for a couple of minutes, that have to take a long round trip around the word to give a couple of minutes access again. That’s why you need a huge constellation. It’s either selling to the whole world or nothing. If you don’t want to go for slow GEO stationary. reply hkdobrev 10 hours agorootparentprevWhen Starship starts launching customer satellites, it's possible that even the price for customers would be cheap enough to launch and maintain a LEO constellation. But competing requires massive innovation in cheap and fast production of satellites which are very energy efficient and highly capable. Especially, the technology for starshield protecting against cyber warfare in space and the direct to cell capability. This would be the main reason for not emerging a viable competitor for some time. SpaceX has innovation advantage in the satellites, manufacturing, dishes, base stations, software apart from the launch capability. reply est31 11 hours agorootparentprevIs it really required to be an LEO constellation? It would certainly be good, so that eventually the satellites deorbit and contribute less to Kesseler syndrome risk. But some nation state might chose to not care about that and deploy at higher and more stable orbits. reply Sander_Marechal 10 hours agorootparentHigher orbits also mean more latency and slower speeds. reply martyvis 10 hours agorootparentprevLEO means less RF power and lower latency. reply Cthulhu_ 7 hours agorootparentprevYeah in theory China is the biggest potential competitor, having both a space program, a state deeply involved in business, etc. But their space tech is archaic in comparison, using really nasty fuels to blast stuff into space. The reusability of SpaceX's rockets is a feat that is years ahead of the competition - it's been nearly ten years since the first recovered Falcon 9 booster in a commercial launch if my quick fact check is accurate, and no other competitor, private or governmental, has managed it yet. And in a few years they will have a reusable vessel capable of launching 100 tonnes into LEO, at a fraction of the development and launch cost of e.g. the Space Shuttle. Unless of course Musk's political fuckery ends up dismantling SpaceX. But, Musk didn't do the engineering on these feats, so the knowledge and patents will continue on if he doesn't. reply maxglute 4 hours agorootparentPRC didn't take reusables seriously until a few years ago, really when strategic value of starlink became obvious. They're already making relatively quick progress, as in the expected faster than original catchup mode progress. Ultimately the issue with simping for SpaceX is that it's still an American company working at American scale. People are conflating SpaceX doing cheap payload advantage at modest scale for actual scale. There's likeThe increase in value of a F9 booster after use is more than the near-negligible per-launch maintenance cost. Do we have anything proving this besides the self-serving word of a privately owned company? I'm not saying it's false, I have no idea either. But there's a lot of highly specific speculation going on here, based on no reliable source. reply adastra22 1 hour agorootparentYes, insurance rates for satellites launching on reused boosters go down the more flight tested the booster is. reply michaelt 6 hours agorootparentprev\"Depreciation\" and \"capital cost\" reflect the fact the vehicle has a maximum life, even given maintenance. Imagine if I buy a $200,000 Lamborghini which, with regular servicing, will survive 100,000 miles. That means for every mile I drive, not only am I paying for fuel, and insurance, and tyres, and servicing - I'm also paying, on average, $2/mile in depreciation. And sure, the \"true\" value chart might not be linear. Maybe there'll be a sharp drop when the car ceases to be brand new, or a bump in value when it becomes a classic. But so long as it's worth $200k at 0 miles and $0 at 100k miles, the average cost of a mile must be $2. reply adastra22 4 hours agorootparentThe statistics here are inverted. The main marginal cost of a launch is the risk of loss of payload which the customer must insure against. The risk of loss of payload actually goes DOWN with more launches, making costs cheaper the more a booster is reused. It’s as if your car gained value with every mile driven. reply nordsieck 3 hours agorootparent> The risk of loss of payload actually goes DOWN with more launches, making costs cheaper the more a booster is reused. I don't think that's true. All of the F9 failures[1] have been due to the 2nd stage. And that's new every time. --- 1. CRS-7, AMOS-6, and Starlink 9-3 reply sudosysgen 3 hours agorootparentprevThe fact that customers launching exceptionally expensive payloads (the US space force, for one) tend to demand new boosters is not consistent with this. But even then, it doesn't change that the booster has a maximum lifespan and/or eventually increasing repair and therefore depreciation - we are working on an amortized basis. reply schiffern 16 hours agorootparentprev>We can only hope competitors are half as responsible as SpaceX... about space debris.. and satellite [visibility] Thank you. For those unaware, one of the SpaceX engineers gave a talk to professional astronomers on this topic. https://youtu.be/MNc5yCYth5E?t=1717 reply greenavocado 13 hours agorootparentprevWe civilians aren't going to get anything useful from foreign militaries launching payloads reply bigfatkitten 13 hours agorootparentUnless you're in Brazil https://www.wired.com/2009/04/fleetcom/ reply Nevermark 12 hours agorootparentprev> There's no inherent reason for this to be a winner takes all market. Economics? Competitors would have to match SpaceX's vertical integration: Satellite design, reusable launches at cost, its exiting armada of satellites, and its moving target of customer penetration. The latter is huge. Starlink is clearly not satisfied leaving any satellite demand on the table. There is no military on Earth that has demand for satellite bandwidth approaching anything like SpaceX's, which is basically being designed to meet the needs of the whole planet. Note that militaries (US, China, Russia, Europe, ...) have their custom means of communicating on planet, for unique reasons, but the vast majority of their communication is over commercial cell phones. This is no different. If anyone was going to have a chance, it was Bezos. But neither his launch capabilities, or big satellite constellation plans, have amounted to much. China will feel the need to try. But they won't have SpaceX's customer base to support a fraction of a comparable effort. (And I say that as someone who has tremendous respect for the multi-decade cadence of their space capability march.) reply modeless 12 hours agorootparent\"SpaceX is really good and it's hard to compete with them\" is not an economic reason for it to be winner takes all. Economic reasons would be, for example, regulations that either explicitly or implicitly prohibit others from competing, as are present in many terrestrial ISP markets. Some way for SpaceX to corner the market for some essential resource like spectrum or orbits and exclude competitors that way. reply cjblomqvist 8 hours agorootparentVertical integration is definitely one. It's such a big factor it can cause regulators to break up a company. See Google/Chrome as an example from last week. reply modeless 7 hours agorootparent\"SpaceX is vertically integrated\" is also not an economic reason for the space ISP market to be winner takes all. Vertical integration doesn't cause breakups. Anticompetitive behavior causes breakups, with or without vertical integration. And vertical integration is not some kind of cheat code to suppress competition. It can be a business advantage but it can also easily be a disadvantage. reply michaelt 5 hours agorootparentprevI'm no economics expert, but I gather certain industries are known as 'natural monopolies' https://en.wikipedia.org/wiki/Natural_monopoly I don't know what the precise defining lines are, but I can certainly see how you'd make more money running an electricity cable to a home with no electricity, than running a second cable to a home that already had an electricity supply in place. And Wikipedia says \"frequently occurs in industries where capital costs predominate [...] examples include public utilities such as water services, electricity, telecommunications, mail, etc\" - starlink does sound like capital-intensive telecommunications. Of course, even if nobody cares to take on Starlink in the broadband satellite internet market, there are a bunch of incumbent cable and cell phone companies. So it's not like starlink are on course to an internet access monopoly. reply mmaunder 16 hours agorootparentprevGame that out for us. How government innovation competes with a private sector launch company whose main differentiator is lower cost. reply modeless 16 hours agorootparentChina is going to do it for sure. It doesn't have to be as efficient as SpaceX if it is massively subsidized for defense purposes. And China is pretty good at building things cheap. On the commercial side Blue Origin has been slow in starting but they are almost ready and will have relatively cheap launches. There are other up and coming private launch competitors too. reply ethbr1 15 hours agorootparentThe issue is that space launch has some huge economies of scale. And {world space launch demand} is >> {one country's space launch demand} The argument for China overcoming SpaceX would be: - China needs to get within functional (not cost) technological parity with SpaceX ASAP (i.e. which means reusability, albeit for cadence/capacity reasons) - After that, they need to incentivize global demand to launch on Chinese rockets (likely heavily subsidizing prices to attract demand) - After that, they need to continue to out-innovate SpaceX on technological and economic fronts Of those, convincing a substantial portion of global launch demand to use Chinese rockets seems the trickiest bit, give the CCP's relationship with the rule of law. reply MaxPock 10 hours agorootparent\"convincing a substantial portion of global launch demand to use Chinese rockets seems the trickiest bit, give the CCP's relationship with the rule of law.\" Expound more on this please assuming I'm a potential Brazilian South African ,Saudi or Thai client . reply ethbr1 5 hours agorootparentFor countries that aren't on the US' shit list (e.g. Brazil, South Africa, Saudi Arabia, or Thailand), why would I take a chance on Chinese legal agreements instead of American ones? The American private company might be prohibited from launching military assets for you, but once a launch contract is otherwise signed, you know it's going to happen. In contrast, a Chinese legal agreement is worth what, if the central government decides to get involved? reply maxglute 4 hours agorootparentAmerican Gov is far, far more fickle and likely to \"get involved\" / abuse export controls / fuck over friendlies due to domestic politics. Space is ITAR heavy, there's less guarantee that private American company can honor agreement than CCP verbal contract. This is 2024, JP steel just happened, US \"rule of law\" means nothing when strategic interests involved, never have. Can't say the same about PRC, granted they're to high end capabilities export. Ultimately, going with PRC likely will get you ITAR tier tech access bundled with cheaper launch, see state of military drones sales. reply wmf 12 hours agorootparentprevI don't think China needs any third-party payloads. Even if they only launch Qianfan it should be enough to bring costs down. reply ethbr1 5 hours agorootparentThe issue is that SpaceX, unlike any space company since some never-realized 1960s hypotheticals, is a flywheel company built around scaling. They create demand so they can scale manufacturing that they can use to decrease prices that creates more demand... etc. etc. You can't beat a company doing that by just getting \"big enough\" unless the scaling company (a) runs out of increased demand or (b) cannot convert increased volume into cheaper economics per unit. Neither of those seem very plausible. reply nordsieck 15 hours agorootparentprev> On the commercial side Blue Origin has been slow in starting but they are almost ready and will have relatively cheap launches. [citation needed] Sure, New Glenn is designed to be a partially reusable rocket. But it's far from clear that they'll even successfully launch on their debut, not to mention recover the booster. And even when they've sorted all that out, word on the street is that the rocket was not designed to be inexpensively manufactured. It's not clear to me just now low reuse can help drive down their launch price. reply jimmydoe 16 hours agorootparentprevNothing is impossible but it takes time. Based on current disclosed plan, they will have same number of LEOs as SpaceX have today by ~2030; and SpaceX is not slowing down either. reply jaimex2 14 hours agorootparentprevChina is very good at copying things but this is one they'll have trouble with given the strict employment requirements. reply ANewFormation 12 hours agorootparentprevAnd adding onto this it's not just cost, they also have the fastest turn around and the highest reliability. It's vaguely analogous to the early automobile market where Ford was dominating by every single objective metric so competitors were left to compete on subjective metrics like styles. Incidentally this era is where planned obsolescence really took off. Unfortunately for competitors I'm not sure coating a rocket in a chrome finish and running a sleek ad campaign is going to beat out price+speed+reliability. reply freeone3000 16 hours agorootparentprevblink By spending more money in absolute terms to achieve objectives, without a necessitative need of immediate profit? reply 01100011 13 hours agorootparentprevTesla fanatics espouse the same sort of thinking. Tesla will figure out FSD and will capture the entire automotive market leaving competitors to close up shop and give up. I don't get it. Otherwise intelligent people have told me some version of this with a straight face. It's like they've somehow blocked how the economy functions out of their minds in an effort to further exalt Tesla. reply wmf 12 hours agorootparentIt's not the same because there are plenty of companies that can manufacture cars at scale but only one company that can launch satellites cheaply. Arguably Waymo is ahead of Tesla FSD and they have access to the mature Hyundai and Zeekr supply chains. reply robotresearcher 13 minutes agorootparentWaymo could be much better at driving but without a low cost sensor strategy they can’t make money in a market that will immediately become commodity priced. Reaching huge scale needs the right market strategy as well as good supply chain. SpaceX has a clever strategy of exploiting their first mover advantage in cheap launch to create the first cheap satcom system. They will suck up so much of the available revenue from that market that the next movers will have trouble getting sufficient investment. reply 01100011 10 hours agorootparentprevIt is the same. In both cases people are doubting the ability of the free market(and non-free markets) to detect and respond to an opportunity. How long do you think it will be before a, say, Chinese SpaceX catches up while being unfettered by environmental restrictions and backed by government subsidies? Space is quite important and as the world deglobalizes there will be intense pressure to compete. SpaceX is breaking new ground and giving other competitors plenty to copy. reply adastra22 13 hours agorootparentprevWith respect, I’m not sure you understand the scale of what we are talking about. No other organization — including national space agencies and military contractors — has the life capacity to compete with Starlink at ANY cost. Even if money were no object, the other contenders literally don’t have the launch capacity and can’t reasonably scale up. It’s as if Intel released the Pentium Pro back in the 50’s when everyone else was working with vacuum tubes. Yes, in theory there is room for competition. But the gulf is so large in practice. reply la64710 12 hours agorootparentprevThis is already available in iPhone with their text based coverage: https://support.apple.com/en-us/120930 Probably they are using GSAT satellites. reply modeless 12 hours agorootparentApple's feature is not comparable. It is extremely low bandwidth and requires special hardware and holding the phone pointing in a certain direction. Starlink acts as a regular (albeit low bandwidth) 4G tower in space. reply quailfarmer 10 hours agorootparentStarlink DTC is also very low bandwidth in this generation, it’s is a fundamentally similar RF link budget reply modeless 7 hours agorootparentStarlink DTC bandwidth is orders of magnitude higher than Apple's. reply everfrustrated 6 hours agorootparentprevStarlink allows calling (Apple's can't) which requires a higher bandwidth by definition. Obviously it will never have the bandwidth of a local cell site, but doesn't need to to still be useful. reply meta_x_ai 12 hours agorootparentprevYou have no idea the margins at which Elon Musk operates. If you read his biography he is obsessive about cost cutting like no else in the history of mankind. There are plenty of examples where Musk brings down the cost of a component by 90%. No other leader takes risks like Musk and hence he will always push frontiers. His companies never get lazy or bloated even if it reaches $10T market cap. Musk methods can't be replicated because it is the anti-thesis of every management practice. reply throwing_away 16 hours agorootparentprevI disagree too, but because it will no longer require military budget to start a SpaceX competitor. Pretty soon AI agents could reasonably take a crack at it. reply mmaunder 16 hours agorootparentI’m sure LangGraph has Elon quaking in his boots. reply nikkwong 16 hours agoparentprevMy family had starlink installed at a remote house we own for internet access. While we could get it up and running, the connection wasn't reliable and we encountered many issues. When we tried to contact Starlink for help, support was non-existent; sent us to multiple dead ends, and often wasted our times with repairs promised weeks into the future, over and over, which never surfaced. After 8 months of pain, we ended up getting rid of it and moving back to our 6mbps. Starlink is like Elon's other companies. Engineering marvels—where the customer's are merely an annoyance and the means to an end. They are basically hostile to the customer every step of the way; and from what I've seen from Elon—I think this attitude comes right from the top. reply hcurtiss 16 hours agorootparentWhere was this? Members of my family have three different remote cabins surrounded by trees in Montana, Idaho, and Oregon, and all work perfectly. The early days were a little more glitchy, but with the constellation they have today, you don’t even need to aim. reply nikkwong 16 hours agorootparent2023 in the Pacific Northwest. We were given the argument that tree cover was a problem quite early on in our attempted troubleshooting. The house is a waterfront property, with a clear view of sky to the east. Anyways, the suspected issue continued to evolve, and we were not able to get to the bottom of it with the support we received. Certainly, our experience could be an anomalous. But I certainly hear this happening all the time with Tesla, with the manufacturer trying to void warranties and evade liability for vehicle defects. I just.. wouldn't be bullish on any of Elon's companies in a crowded market; which I suspect will define more his companies in the future. His politically obtuse behavior and lack of respect for authority is enough to turn off ethically minded consumers; and that's before the general crummy experience of being his customer. My best friend has a Honda EV that broke down twice, one time being potentially out of warranty-and the dealer repaired it, no questions asked reply quailfarmer 10 hours agorootparentIt can be counterintuitive because the user terminal is shaped like the kind of satellite dish we’re mentally prepared to understand, the kind we’ve had for the last 50 years, but it’s fundamentally different. The “clear view of the sky to the east” is the source of your problems. Starlink satellites move quickly across a the sky, and the dish needs a comparatively massive 100+ degree view angle to ensure continuous contact. If you look around online you can see comical configurations with Starlink mounted on enormous poles to get them above the tree line. This issue is the #1 cause of problems we see with new installs. reply dboreham 14 hours agorootparentprevRealistically Starlink is not going to diagnose RF issues at your site. Microwave either works, or gets expensive fast (because you need an expensive person with expensive test equipment to properly investigate). A wild guess based on the available information is that reflections off the water surface are the cause. reply hattmall 13 hours agorootparentYeah I'm not really sure what issues you could reasonably expect a satellite internet provider to be troubleshooting at all. It's very much a 0 or 1 situation. reply nikkwong 12 hours agorootparentThen tell the customer that, rather than string them along for 8 months promising fixes (software or hardware), that never come in reply inemesitaffia 12 hours agorootparentIf they don't put people on the ground they don't have the insights required. It's like trying to diagnose WiFi next to a radar station remotely when you don't know the user is next to one reply nikkwong 12 hours agorootparentAgain... the logistical structure of the company is not something that the customer should have to be privy to when trying to figure out if the product is going to workout for them, or not. If the product is not going to be working, the company should not be charging the customer $100 a month for 8 months promising a fix that will never come in. reply inemesitaffia 11 hours agorootparentI don't disagree. Just pointing out that there's things you can't diagnose without being physically present. And these kinds of issues aren't only existent in Telecoms or SATCOM in particular. The user should ask for a credit/refund. The product was almost certainly working. But not meeting expectations. If not it wouldn't have been on for 8 months. Can't tell me you ran 0 bytes over it reply whywhywhywhy 6 hours agorootparentprevDid you try a different wifi hotspot, convinced the one they ship with it sucks from my experience with it. Couldn't handle a connection maybe 8 meters away and one floor up, no walls. reply mensetmanusman 15 hours agorootparentprevWould be interesting to measure the amount of Ku-band ghz noise near your property. reply shkkmo 14 hours agorootparentprevGenerally, sky to north is what matters. I've done a fair bit of boondocking with starlink and found it to be very sensitive to tree cover in the wrong part of the sky. I don't think that starlink's support or documentation is particularly great, but it still seems better than my experiences will cell phone and internet service providers. reply infobot 16 hours agorootparentprevYou…wouldn’t be bullish on the most successful businessman in the history of the world? Sometimes I come here for a good laugh reply ethbr1 15 hours agorootparent> most successful businessman in the history of the world You're ranking Musk above Jobs, Ford, Rockefeller, Carnegie, Disney, Toyoda, Walton, and Buffett? reply ANewFormation 12 hours agorootparentIMO it depends on what you see as the point of business and entrepreneurship. I don't see money as the goal, but rather on creating great things. So Buffet wouldn't even rank for me, while you would have omitted Musk's closest competitor - Thomas Edison. Put another way, if in 30 years Musk has 10 trillion in wealth would seem, to me, to be much less relevant than if he succeeds in making humanity a permanently multi-planetary species. Advancing humanity in so many different revolutionary fields all at once is something that had not been achieved in a very long time. reply ethbr1 5 hours agorootparentI get what you're saying, but I also think you're being reductive in devaluing wealth creation. Why is a company worth more today than it was five years ago? Because it's generating more revenue, has more assets... is better at doing whatever {company thing} is. One can argue that (a) {company thing} isn't good for humanity at all and/or (b) a company which generates more money isn't really more successful, but merely a side effect of capitalist valuing. And maybe... But I'd say there's a pretty strong argument that Buffett is worth what he is because BH made multiple companies very much better at doing what they do. In the same way that Ford or Walton made their money by building companies that did what they did better. And I'd add in the perspective that science and discovery without engineering into mass application is... a hobby with limited impact. The real litmus test is \"Can you use this to improve many people's lives?\" And when you do that in a capitalist society, you usually have a chance to make a lot of money. reply taeric 15 hours agorootparentprevMany people don't have any real understanding of how wealthy people have been in the past. The Walton family is a fun case. Split the fortune among the family and there are still billionaires in the mix. Edit: should add that Elon is still valued at a good percentage of the US gdp. So, not unreasonable to say that is incomprehensible, as well. By that measure, is similar to Rockefeller, I think. reply lotsofpulp 12 hours agorootparentI wouldn’t use the Waltons in this example, considering Walmart is eclipsed by a few companies, and even by 50% by one business that Musk has a significant share of. reply taeric 12 hours agorootparentSilly comparison, all told. Walmart is the single largest private employer. 1.6 million in the US. Literally 10x what Tesla and SpaceX have. Such that it is clear valuation is tough. Look, Elon is worth a lot. Walton family is worth as much, as well. Just split among several people. None of which should be scoffed at. None are made more impressive by pretending the others are less. reply tgma 15 hours agorootparentprevThis characterization isn't entirely unreasonable. Isn't Musk objectively the richest businessperson ever in nominal dollars? Inflation-adjusted, I think only Rockefeller or Carnegie may come close, but the variety of businesses Musk has is impressive, and it appears he is just getting started with a long way to go. reply highwaylights 14 hours agorootparentInflation-adjusted I believe Rockefeller was worth more than $400b at the peak of his wealth. The Walton estate now is worth over $350b, but it’s not a fair comparison as it’s had much longer to compound. The other thing is that while SpaceX is incredibly successful, the other companies he’s started aren’t. Tesla (despite its massive growth) is in a market of rapidly growing competitors, and he’s on record saying the company lives or dies on tech his own engineers have suggested in court isn’t coming (FSD). reply tgma 14 hours agorootparentGoogle Search says Elon is at 334.3 gigadollars so not that far off and he's not dead yet. reply latentcall 14 hours agorootparentprevElon is successful yes but why do other men feel the need to stroke him off online all the time? Strange behavior. Are you expecting a kickback? reply valval 58 minutes agorootparentI find your view even more perplexing. I get that it’s entirely motivated by anger and contempt, but it’s still weird that someone would get upset over the respect someone else is getting online. I suppose it’s some deep personality trait difference that makes us right wingers appreciate his work and what makes leftists hate his guts. reply scotty79 13 hours agorootparentprevI think this is a psychological thing. Humans during evolution were highly rewarded for seeking and keeping powerful allies. So by imagining that Elon is my friend (because I'm his friend) and Elon is really intrinsically powerful (instead of just a lucky, well positioned grifter that can fall from grace at any moment) I can feel better about my own safety. I can feel more powerful by extension and the indirection somehow muddles that fact that it's all made up. The same mechanism works in religious people. reply openrisk 11 hours agorootparentYou might be onto something but we need a proper \"evolutionary theory of bootlicking\" before we get carried away. Its pretty clear that the all-too-common in space and time hierarchies, oligarchies, command-and-control pyramids etc. rely on trickle-down privilege to sustain. But the feeligs of disgust and disbelief at how a person can diminish themselves in the hope of some crumbs falling their way must also have strong evolutionary basis? reply refurb 8 hours agorootparentI’m not sure I understand your viewpoint. The OP said “the most successful businessman in the world”. Sure one can argue about how OP came to that conclusion, by what measure, etc, but the man produced a highly successful car company, in a field nobody has really been able to do it, under terms where everyone was counting down the days until it went bankrupt. That alone is an amazing feat. Then he went on to create a rocket company that broke barriers of space travel no one has been able to do. Then he started a satellite company that pushed the boundaries of communication for the average person. I’d say all those feats are worthy of praise and make him a person who stands out significantly from any other businessman in recent history. So saying he’s the “most successful businessman” doesn’t seem like an absurd or overly hyperbolic statement. And how you got “stroking off” or the even more absurd “bootlicking” from that statement is just bizarre. I saw zero evidence of either. I’d say your comments are the odd ones here and say more about you than the OP. reply openrisk 2 hours agorootparentsorry, the burden is on you to distinguish genuine business accomplishment from what others might suspect, less charitably, is excellence in crony capitalism [1],[2]. The Economist made a feeble effort to rank countries in this respect [3] but it does not even include the tech sector in the \"crony-prone\" sectors (eyes rolling). [1] \"situation in which businesses profit from a close relationship with state power, either through an anti-competitive regulatory environment, direct government largesse, and/or corruption. Examples given for crony capitalism include obtainment of permits, government grants, tax breaks, or other undue influence from businesses over the state's deployment of public goods, for example, mining concessions for primary commodities or contracts for public works\" etc. [2] Crony Capitalism, American Style: What Are We Talking About Here? https://www.hbs.edu/ris/Publication%20Files/15-025_c6fbbbf7-... [3] https://en.wikipedia.org/wiki/Crony-capitalism_index reply TheAlchemist 15 hours agorootparentprevThat depends on how you define successful businessman. If we look at valuations, then yeah. If we look at how much money all of his ventures make ? The picture is very different. SpaceX - may or may not be profitable in the last year - it's hard to know. Until recently definitely no profitable Tesla - really profitable since 2021, with great 2022 / 2023. Trending in the wrong direction recently Twitter, xAI, boring, neuralink - all are money furnaces. reply nordsieck 15 hours agorootparent> SpaceX - may or may not be profitable in the last year - it's hard to know. Until recently definitely no profitable SpaceX is very much in the same position as early Amazon. If they wanted to, they could be profitable today. But they are investing heavily in the future. IMO, that's a good sign for SpaceX. Many large companies have run out of ideas of what to do with money, so they accumulate it in bank accounts, or do dividends/stock buybacks. reply ulfw 12 hours agorootparentprevAh yes. This coming from another one of Elon's bot accounts. With a Karma of 2 no less. reply loandbehold 12 hours agorootparentprevYour experience is not typical. Starlink has been working flawlessly for me for the last few years. It revolutionized Internet access in my remote area. HughesNet was the only game in town with speeds under 3Mbps and 10GB monthly data cap. Now everyone has Starlink with over 100 Mbps speeds. Never heard of issues. reply nikkwong 12 hours agorootparentI stated in a neighboring comment that our experiences could be anomalous. Based on how frustrating it was talking to them on multiple occasions with multiple different service reps I assumed it was endemic to their culture; a la Comcast. At the very least, Telsa seems to be trailing tens of thousands of angry customers online who are struggling with defective vehicles. reply loandbehold 12 hours agorootparentTesla has some of the highest customer satisfaction scores among car brands. I'm not sure what you are referring about \"tens of thousands of angry customers\", you need to look at percentages and not absolute numbers. Tesla has had quality issues and problem with services but overall people are very happy as far as car brands go. And you have to be reasonable with your expectation for customer service of an internet service provider. There's only so much you can do to help an individual customer. Maybe it doesn't work in your area for some specific reason, you can't expect their engineers to spend time investigating that single case. If it was a broader issue i'm sure they would look. Did you try getting new Starlink receiver? reply NoPicklez 15 hours agorootparentprevI appreciate you have had a bad experience, but to then think that's the overall experience is myopic. There are many highly remote areas where people can't speak more highly of Starlink. reply Nursie 14 hours agorootparentAnd not that remote. Internet provision not all that far out of major Australian cities can be abysmal. I'm only 30 minutes drive from the centre of Perth and my options are currently 5G (operating at about 4Mbit), Wireless Broadband (performance promise - the download speed will reach 25Mbit at least once in any given 24 hour period!) or Starlink, at a pretty stable 120/20. I'd love to not have to pay for it, to use what local/national companies can provide, but so far nothing comes close. I am informed that the wireless system is due to be upgraded to support much higher speeds, but that was supposed to happen this year and there's not a lot of this year left. reply hattmall 12 hours agorootparentI would think 5G could really improve that situation. In the states we have the 600 MHz spectrum on T-Mobile and can pull down decent speeds 30-150mb through trees 15 miles from the tower. Upload is not great. reply Nursie 12 hours agorootparentIt could, if there was decent signal here. At least in part that's been delayed because of someone in the area raising a band of nutters and giving the council hell about 5G killing her grandchildren. Sigh. Might happen before too much longer - she managed to get the project to build the new antenna on private land killed (I'm sure much to the annoyance of the landowner, who was going to pocket a nice chunk of ground-rent). But now the local authority have given the go-ahead for one to be built on their land, and they're going to get the rent. She is apoplectic, which brings me great joy. reply NoPicklez 14 hours agorootparentprevAbsolutely, I've had 5G modems within the metro area of an Aussie city and it was horrible. reply immibis 8 hours agorootparentprevIt may or may not be relevant to your case, but every time a story like this comes up I will remind people in general that fiber-optic cable is 50 cents per meter (probably $1 per meter Australian), wireless links cost equipment and a regulatory approval fee and are easier in less densely populated areas, and there are tons and tons of stories of people dissatisfied with their ISP creating a better competitor, your neighbours are likely as frustrated as you if they use the Internet, and there is no minimum size to an ISP. reply matwood 8 hours agorootparentprevI use Starlink in Italy and it's been flawless. To be honest it's like magic with how easy it was to setup and use. One my colleagues tried Starlink at his cabin in the PNW and he had to return it. He just couldn't get a clear and wide enough line of sight through the tree cover. I wonder if that was your issue? reply TheOtherHobbes 7 hours agorootparentprevI think this is quite perceptive. Musk is a narcissist, and the driving motivators of narcissists are a bottomless need for praise and attention and contempt for others. Musk is famous for being contemptuous of his employees, and he's starting to show more and more contempt for Rest of World. Cybertruck and X both reek of it. Everyone here is assuming Musk is rational and SpaceX and Starlink will continue to develop rationally. I don't think they will. He appears to be becoming more and more unhinged, and that's going to have negative effects on his fledgling empire. reply misiti3780 4 hours agorootparenthow is cybertruck contemptuous lol? reply GJim 7 hours agorootparentprev> moving back to our 6mbps * Mbps reply jonplackett 10 hours agoparentprevYou think it’s awesome that there’s a monopoly? And it’s owned by a single, politically derelict insane man? I agree the pace of change is amazing. I marvel at everything spacex does. The starship catch was ridiculous. But no competition always leads somewhere really bad eventually reply rm445 9 hours agorootparentA (temporary) monopoly is not as bad in something that wouldn't otherwise exist. If Elon Musk concentrated only on cars, or SpaceX had had another couple of launch failures and gone bust, this functionality might be 40 years away. Not to say you're wrong, we all benefit from competition in the long run. We get it from a level playing field and preventing natural monopolists from locking the gate behind them. reply jonplackett 8 hours agorootparentI agree a (temporary) monopoly is totally OK. Normal in fact. But the parent comment was specifically celebrating a long term, unassailable monopoly. reply nwienert 8 hours agorootparentIf you read it uncharitably. If you read it charitably, the “it’s awesome” can be referring to how quickly they made something work that otherwise wouldn’t for many more years. reply jonplackett 1 hour agorootparent> Starlink has a constellation two orders of magnitude bigger than any competitor. It’s over. And IMO it’s awesome I feel like you are being overly charitable. The ‘it’s awesome’ comes directly after the ‘it’s over’ But TBH I’m pretty cyclical at the best of times. reply LightBug1 8 hours agoparentprevOdd. You seem to be overjoyed at the possible birth of a monopoly situation? I think your emotions and tribal instinct would be better served towards something more benign, like football or baseball ... Lest your voting intentions become equally malignant. reply michaelt 8 hours agorootparentPerhaps they merely mean it's awesome to have one global satellite broadband service, and one semi-affordable launch option, instead of zero which is what we had before? reply rplnt 6 hours agorootparentThis part could have been phrased better in that case. > It’s over. And IMO it’s awesome. reply leovingi 6 hours agorootparentprevA more charitable interpretation would obviously be that the OP is very happy with the products and services that these companies build and provide and if the alternative is between this never happening and the companies becoming monopolies, at least in the short-term, they are OK with it. reply swat535 4 hours agorootparentprevMore to it, monopolies eventually get broken up by regulations. EU will step in eventually and regulate if it becomes too great of a concern, right now it's quiet because it hasn't reached critical mass yet. Musk's empire is already being dismantled and the trend will continue, either by direct competition of laws. reply u2sweetie 8 hours agorootparentprevYou seem to have a lot of creativity in your judgements as none of this follows from his comment. reply palata 7 hours agorootparentCan you read this sentence and tell me how none of this follows from it? > SpaceX and Starlink have the same owner, both are private companies, with SpaceX launching 80% of the global space payload last year and rising, and Starlink has a constellation two orders of magnitude bigger than any competitor. It’s over. And IMO it’s awesome. It says: \"It's a private monopoly, and IMO it's awesome\" reply mylastattempt 8 hours agorootparentprevIt's litterally the last sentence: ...any competitor. It’s over. And IMO it’s awesome. reply WinstonSmith84 10 hours agoparentprev> there will be no competitors Define the time frame. 1 year? Quite likely. 10 years? nothing is less sure ... But in 50 years, I bet SpaceX doesn't even exist anymore. Companies rises and falls and it's always been like this (and the same applies to Empires, Countries or .. Species). It's always a matter of timeframe reply rock_artist 10 hours agorootparentIt'll be interesting for sure. similar to requesting Chrome to become separate from Google, there might some law enforcement scenarios where they'll have to split things. reply ponector 9 hours agorootparentprevThere will be several competitors in 5-10 years. Due to immense military capability of this technology. Same thing happens with GPS. reply CodeArtisan 15 hours agoparentprevThe European Union wants its own satellite network to counter Starlink. It will be build by SpaceRISE, a consortium that include Airbus, Thales, Deutsche Telekom... https://en.wikipedia.org/wiki/IRIS%C2%B2 https://www.spacerise.eu/ https://defence-industry-space.ec.europa.eu/eu-space/iris2-s... reply perlgeek 8 hours agorootparentAny consortium that includes Deutsche Telekom is doomed to failure. We've seen that when Germany introduced the Autobahn toll, it was a complete disaster. If I had to guess who's going to have a Starlink competitor up next, I'd point to China. reply rdm_blackhole 12 hours agorootparentprevThat's not going to happen. Remember when the EU wanted to build it's own internet browser? Or it's own search engine? Or it's own sovereign cloud? None of these initiatives panned out. This is just political posturing when they have literally zero plans on how to achieve that. reply palotasb 11 hours agorootparentBut https://en.wikipedia.org/wiki/Galileo_(satellite_navigation) panned out and that's a closer analogue. reply rdm_blackhole 10 hours agorootparentIt took roughly 20 years for the EU to deploy 30 satellites. How long do you think it's going to take to deploy 300 or so of them when the Ariane 6 had only one launch (with a partial failure) in the last 14 years? If you want to build a constellation, you need the means to send payloads in space at a relatively low cost. The EU can't do that so it will be an expensive and slow endeavor and by the time those 300 satellites are up there, Space X will have deployed 10s of thousands of them. You can say, that the EU does not want to compete with Space X or that their goals are not the same but either way, it's just too little too late IMHO. reply rplnt 6 hours agorootparentI agree with your overall point, but that's a super deceptive metric to use. First Ariane 6 was scheduled for 2020 and only the first one ever launched. reply verzali 11 hours agorootparentprevOr when they built their own GPS system and it ended up being far more accurate than any other system in use? Or when they built their own Earth observation system and it was also better than anyone elses? Or when they built their own weather monitoring constellation and forecast model and it ended up superior to all others? Or when they built the world's most powerful particle collider and discovered the Higgs boson? The world's largest passenger aircraft? The first mRNA Covid-19 vaccine? The weight loss drugs keeping American celebrities thin? reply Salmonfisher11 8 hours agorootparent> Or when they built their own GPS system and it ended up being far more accurate than any other system in use? It actually is. But yes - that project was a shitshow for a long time. Galileo HAS now offers 30cm accuracy with less than 100s convergence time not needing additional correction servers/stations. Also spoofing resistant thanks to cryptographic signing (Galileo Open Service Navigation Message Authentication). Both free for use. Forever. Classic GPS doesn't offer this. reply spacemanspiff01 7 hours agorootparentMy impression is that the US system does, but the higher accuracy is still reserved for military use? reply rdm_blackhole 9 hours agorootparentprev> Or when they built their own GPS system and it ended up being far more accurate than any other system in use? It took 20 years to deploy 30 satellites. You can call that a success I guess. > The world's largest passenger aircraft That is an Airbus project which is not an EU project. Airbus is the result of a merger between multiple companies and was not initiated by the EU. > The weight loss drugs keeping American celebrities thin? This drug is manufactured in Denmark by a Danish company. It has nothing to do with the EU. > The first mRNA Covid-19 vaccine? You mean the Pfizer vaccine? That's a German company, not an initiative from the EU. > Or when they built the world's most powerful particle collider and discovered the Higgs boson? They did build the CERN ... in 1954. Which we can agree was a long time ago. Since then the ability of the EU to deliver big projects such as for example Ariane 6 has gone down rather quickly. Also you ll notice that when the CERN was created, the EU as we know it today did not exist. > Or when they built their own Earth observation system and it was also better than anyone elses? Or when they built their own weather monitoring constellation and forecast model and it ended up superior to all others? Ok and so what? Does that invalidate my arguments? A few successes amongst a ton of failures. That does not inspire any confidence. That is why I am skeptical but I am prepared to eat my own words if the EU has a complete up and running constellation of 300 satellites in orbit by 2035. The EU has some great companies for sure but these companies did not get there because the EU helped them or because the EU decreed that such companies have to exists. reply inemesitaffia 12 hours agorootparentprevExpect it to be worse than OneWeb for more money reply mschuster91 10 hours agorootparentprevWhich is precisely why it will not be built. Too many cooks in the kitchen and too many known grifters with their own vested interests. SpaceX, as much as there is to dislike about its founder, has the advantage of being one company with a founder at the top who has made it very clear that only his vision matters and intra-company political bullshit just Does Not Fly. reply panick21_ 14 hours agorootparentprevThat constellation doesn't even play in the same league as Starlink. It makes some sense for Europe, but it will likely be more for government use and a few large European commercial uses. This has no chance what so ever in the larger global consumer market. And the claim that it will exist by 2027 is utterly hilarious. But even this small constellation is way beyond what European industry can currently do, they need to basically mobilize every European space company to do this, and all of them working together to get this working. Lets see them pull this off first. reply bpodgursky 15 hours agorootparentprevI'm sorry but if you think this has even a snowball's chance in hell of succeeding you need to learn more about the launch and satellite comms industries. This is political posturing, not a plan. I don't want to spend hours typing on this so let's just say this; Arianespace is on the \"team\", so it's going to launch on Ariane 6, a rocket that was obsolete before it launched (and it was not a successful launch). The idea that you can launch mass on Ariane6 to challenge Starlink is like saying you can win NASCAR on a horse and buggy. I'm not even exaggerating, that is literally the price differential between Starship and the rest. This initiative is a joke. reply varjag 11 hours agorootparentA6 maiden launch wasn't completely successful but that hardly matters in a debate involving SpaceX. reply flanked-evergl 11 hours agorootparentprevThe EU's one skill is to turn my tax money into shit ever better than my socialist government. If any private company was as reckless with its customer's money as European governments, they would be fraudulent. reply nickfromseattle 13 hours agoparentprevYes, being able to manufacturer and deploy your satellite services at cost is an insurmountable competitive advantage. There is one other player in this space, Rocket Lab. They are 5-10 years behind SpaceX, but are the #2 launched rocket in the USA and 2/3rds of their revenue is from satellite manufacturing. I think something like 25-50% of the non-SpaceX satellites in-operation have a Rocket Lab logo somewhere on the craft. The next step in their vertical integration plan is to launch their own constellation and provide some sort of space-based service. Although it's several years away and pending the scale-up of their medium launch vehicle test flying next year. Their CEO has come to the same conclusion as you. The major space companies of the future have to be vertically integrated if they want to compete. The founder has a pretty cool story. From New Zealand. Built a rocket bike and a rocket pack, but didn't go to college. Being a foreign national without traditional education meant he couldn't work in the space sector due ITAR. So he started Rocket Lab in 2006. Their small lift vehicle (300kg) was the fastest vehicle from first orbit to 50 orbital launches, and tracking to be the fastest to hit 100 orbital launches. Their medium lift vehicle (13,000kg), if it makes orbit next year, will become the most capital efficient ($300m spent) MLV developed, and the fastest MLV to go from announcement to orbit (5ish years). After Rocket Lab and SpaceX, the competition is pretty thin. Blue Origin is launching their HLV (40,000kg) New Glenn for the first time in early 2025 and there are a couple of startup and traditional defense contractor projects, but all unproven. SpaceX is so insanely far ahead of everyone else. They will hit 100+ launches in 2024, Rocket Lab is at 15ish with their 300kg vehicle, and planning to scale their 13,000kg vehicle to 3 launches in 2026, 5 in 2027 and 7 in 2028. New Glenn will be on a similar ramp. reply cmdli 15 hours agoparentprevIf you are right and Starlink will have no competition, then why would it not be regulated? Generally speaking, monopolies are regulated to prevent price gouging, including natural monopolies. And if its not a monopoly, then clearly the game is not over. reply hattmall 12 hours agorootparentStarlink mostly does have competition but they are seeking out specifically underserved customers which is an ever decreasing market. 5 or so years ago I signed up for the waiting list because there was no reasonable internet, 6mb DSL. Before I got the invite there was 4G for $50 a month. Now there's two 5G service providers and Fiber is suppose to come very soon. reply mikea1 14 hours agorootparentprevIn the market for internet service, Starlink is a disruptor to existing ISPs. Especially for those servicing rural areas. I don't understand a reflexive reach to encumber a nascent business model with additional regulations. What problem are you trying to solve? reply kaliqt 15 hours agorootparentprevBecause it is not abusing its position. Monopolies are not an inherent bad, they just tend to start abusing their position, and when they do then they get handled. This is more common with public companies than private companies though. Founders have their own life, honor, ethics, desires, etc. which usually help strongly keep the company on a positive track. e.g. Valve Corporation. reply theptip 14 hours agorootparentThis is the American model of anti-trust, very much not the European model (which explicitly targets competition for its own sake even when consumers are not harmed by the monopolistic behavior). reply teamonkey 9 hours agorootparentprevJust because you like a company (and as a consumer, I like Steam) doesn’t mean it’s not acting monopolistically. Valve is certainly abusing its position. It charges extremely high rents for the services it offers because of its dominance as a marketplace. It does provide a host of services and does them well, but whether they are value for the platform fee is another question. Using those services creates lock-in and friction to port to other platforms. By providing them as part of the package, Steam has extinguished companies that used to provide those services, meaning that it’s even harder to provide the same functionality elsewhere. reply cmdli 15 hours agorootparentprevCompanies always abuse their position. Its basic capitalism; markets only thrive and are fair when both buyers and sellers have multiple options, and it would be odd to assume this time is the exception. reply 8n4vidtmkvmk 11 hours agorootparentSo start drafting up the policies if they need time, but don't enact them yet. I'm not a fan of the owner, but if the product is good and the price is fair, leave it be until it becomes a problem. Let's not punish innovation. reply immibis 9 hours agorootparentprevBecause it's owned by the second most powerful man on the planet, who has power over all of the would-be regulators. Politics matters. reply panick21_ 14 hours agorootparentprevWhat people sometimes don't understand about monopolies, specially of a new product, is that the competition, in additions to all the competition that already exists for internet, is simply not having it. SpaceX can just asked for an absurdly high price, because if they want to sell into the broader consumer market, people aren't going to pay 1000s of $ a month to watch Netflix. reply cmdli 13 hours agorootparentThat is called the monopoly price: https://en.wikipedia.org/wiki/Monopoly_price reply nehal3m 17 hours agoparentprevAre you Elon? Also monopolies are never awesome. reply mmaunder 16 hours agorootparentPerhaps you’re not aware that SpaceX sued the US government to break ULAs monopoly on national security launches and brought down costs. And perhaps you’re unaware just how many national telcos world wide have a national monopoly and for the first time ever may have to compete with Starlink? Perhaps you’re also unaware of the grip that Russian rocket engine manufacturers had with the RD180 engine on the US launch sector until recently and the positive impace SpaceX has had on that. reply nehal3m 16 hours agorootparentOn the one hand you’re arguing that SpaceX is awesome for breaking monopolies. On the other you’re saying it’s awesome that “it’s over” and they own the market now. Perhaps you missed the irony. reply inemesitaffia 12 hours agorootparentThere's no real non cost barrier here reply piyh 17 hours agorootparentprevHonest question because it's something I've internally debated over. Would we have had Bell Labs without the AT&T monopoly? reply mensetmanusman 15 hours agorootparentNo, organizational slack and a willingness to spend on r&d is required for labs to exist. Monopolies can afford expensive r&d. reply Zambyte 15 hours agorootparentprev> Would we have had Bell Labs without the AT&T monopoly? The implication here is that Bell Labs was a good thing. While I find it hard to say I wouldn't have loved to have been a part of something like that, I think we may have been better off without it, considering what it squashed. reply treyd 14 hours agorootparentA research environment like Bell Labs freed from the behemoth of AT&T would have been a great boon to society had it stayed around in a similar form to today. reply lmm 13 hours agorootparentprevWould we have had a single lab that became famous for so many things? No. Would we have got thousands of smaller labs that added up to more innovation? Maybe. reply vajrabum 15 hours agorootparentprevAT&T was heavily regulated (common carrier) through much of it's history and was a big part of the reason that BellLabs was so influential. Not true of SpaceX and Starlink. reply ssl-3 16 hours agorootparentprevMust a monopoly always be bad? For example: Mitutoyo seems to have a monopoly on producing accurate digital calipers that have battery life measured in years (using one dainty little LR44 alkaline cell). They use approximately fuck-all for power whether switched on or off. Certainly, the market is open for others to produce an actually-competitive product with similar performance. All it takes is for the competition figure out how to do it and put them into production, since any necessary patents expired long ago. But they simply have not done so. So here we are today, wherein: The free market has decided that Mitutoyo has a defacto monopoly on tools of this capability. Is that... is that implicitly a problem, somehow? reply sgnelson 15 hours agorootparentMitutoyo isn't a monopoly, not even close. Just because a company offers a product that is arguably just slightly better in one aspect than others does not make it a monopoly. (I say this with a 10 year old pair of harbor freight calipers on my desk that easily have a 2 year battery life with regular usage. Also, Dial Calipers.) But to answer your question, must they? No. Do they tend to be bad? Yes. Does their behavior get worse over time? Typically. reply serf 16 hours agorootparentprev>For example: Mitutoyo seems to have a monopoly on producing accurate digital calipers that have battery life measured in years (using one dainty little LR44 alkaline cell). They use approximately fuck-all for power whether switched on or off. metrology is vast. I am a fan of Mitutoyo too, but this is a poor example of a monopoly. I have literally 3 different brands , including Mitutoyo, on my desk, and the Mitutoyo unit offers the worst value-to-dollar ratio and it's the hardest to read at a glance; it's only there because it's the coolant-proof unit I have on hand at the moment. i'd gladly give up a bit of battery life for a backlight and some bigger character display; thankfully the market responded by offering this from about numerous other manufacturers.. >So here we are today, wherein: The free market has decided that Mitutoyo has a defacto monopoly on tools of this capability. well, no. Mitutoyo is great, but American shops, especially any DoD affiliated ones, push American made Starett like crazy. All of my less-discerning maker friends use Amazon/Harbor Freight/Chicago no-name Alibaba glass scale calipers and they're perfectly happy with them. My German friends often use Vogel/Hoffman/Mahr. But anyway, whatever. I love my Mitus, and I even have a pair of their very first electronic scale calipers in a drawer somewhere ; the battery life was great even then. reply ssl-3 15 hours agorootparentAll of my less-discerning maker friends use Amazon/Harbor Freight/whatever calipers and complain about the battery life. Hence, the source for articles like this: https://hackaday.com/2021/10/30/cheap-caliper-hack-keeps-em-... reply nehal3m 16 hours agorootparentprevYeah I should think so. edit: I don’t use this category of tools so for the sake of argument I will assume your assertion on Mitutoyo’s monopoly is accurate. Without serious competitors, Mitutoyo has little reason to push the boundaries of performance or reduce costs further. Monopolies can result in complacency, where companies become gatekeepers rather than innovators. In this case Mitutoyo may have a fine product but the monopoly introduces a systemic risk of lack of innovation or price gouging. You’re assuming the market has chosen rationally but economic conditions, patent legacies, and lack of competition might simply be symptoms of market failure rather than optimal outcomes. reply golemotron 16 hours agorootparentprevThiel and Masters make the case eloquently in Zero to One. reply Taek 17 hours agorootparentprevif you don't want monopolies then you need to create regulations that make it easy for new startups to compete reply nehal3m 17 hours agorootparentI agree, but given Elons current position there is basically no chance that’s going to happen in the next four years. reply coliveira 16 hours agorootparentThe future of the US: 90% of cars will be Tesla (other carmakers will go bankrupt), internet access and space exploration will be monopolized as well. reply yencabulator 2 hours agorootparentAttempting to make Ford disappear would be a political suicide. reply kumarvvr 15 hours agorootparentprevThere are dozens of satellite launch systems around the world. Its hardly a monopoly. reply GeekyBear 15 hours agorootparentprevThere is a difference between having a monopoly and having a lower cost per unit of mass put into orbit. reply fragmede 17 hours agorootparentprevFor the monopolist they are! reply flanked-evergl 11 hours agorootparentHistorically they have been even better for consumers than monopolists. reply montagg 17 hours agorootparentprevThey are when you can regulate the crap out of them to benefit everyone after they’ve benefited from government contracts, FCC governance, an educated population, etc. reply stouset 17 hours agorootparentI can’t think of anything less likely to happen in the coming years. reply simon_acca 7 hours agoparentprevSpaceX has no qualms launching competitors constellations, it has done so with Kupier already. Sure the prices might not be quite as good as what Starlink gets but definitely comparable in big-O notation (especially compared to other launch providers). reply GuB-42 15 hours agoparentprevI would even go to say that the reason Starlink exists is to use up SpaceX excessive launch capacity. With its idea of building assembly lines and reusable rockets, can launch more stuff than there is market for. So they create their own market. Starlink launches are almost free besides the fuel, as they have rockets lying around that are already paid for. A state-funded competitor could come up though. China for instance may want their own satellite internet for strategic reasons, and fund that. I am sure Russia would be interested too. This in turn, will pay for development of a reusable rocket program. reply panick21_ 14 hours agorootparentLets cool down a bit. Falcon 9 launches cost much more then 'just the fuel'. Estimated launch price is still 10-20 million $. The Upper stage is an expensive thing to build. Operations cost are also not that low. Fuel cost are only like a couple 100k$. China is deftly building something. Russia doesn't have a snowball chance in hell of building something like Starlink. reply JumpCrisscross 16 hours agoparentprev> It’s over. And IMO it’s awesome It’s not over precisely because it’s vertically integrated. Buyers want to maintain leverage. SpaceX wants to avoid forced divestiture. Hence the airlines inking deals with AST Mobile, and SpaceX lofting their birds. reply the_duke 11 hours agoparentprev> SpaceX and Starlink have the same owner To be precise: Starlink is a division of the SpaceX corporation, it's not a separate entity. reply mirekrusin 10 hours agoparentprevEven if you like Elon and his companies monopolies are still bad. He is not going to live forever, somebody else will be in charge sooner or later and that person/group may not adhere to same principles. reply tirant 9 hours agorootparentMonopolies due to the State granting permissions to only one company, or gaining advantages due to coercion or lobbying are indeed terrible. But monopolies due to excellence in the development of the product, like Starlink, are not bad at all. In any case these are extremely rare and tend to last very little time. reply hsuduebc2 10 hours agoparentprevMusk is similar to Henry Ford in that he currently has an advantage due to the innovative nature of his business. However, over time, his ideas will likely be replicated by other businesses or even governments. I'm not entirely convinced that becoming a strong political figure by aligning with one side is a wise long-term strategy. This election was a loss for the opposition, not just because of their poor communication of achievements but also due to the ordinary cycles of politics. People often place blame on those in power for any problems during their tenure. The pendulum of trust will eventually swing back to the other side. Musk's political aspirations also pose a risk for him, as they could jeopardize his relationships with allies within the currently dominant party. What I’m suggesting is that monopolies like this often collapse when they become too politically entrenched, threatening the very power structures that initially enabled their rise and powet accumulation. reply matco11 11 hours agoparentprevNo. They have already allowed Starlink competitors to launch on Space X rockets. There are multiple players working on constellations of low-orbit satellites competing with Starlink reply irjustin 10 hours agorootparentWhile you're technically correct, the parent is more correct. Competitors have to pay normal launch rates. The competitive service needs to include those costs to end users. Starlink \"pays\" for launches at cost. While we don't know what SpaceX's cost margins are, they are not trivial. To setup a low orbit constellation is extremely expensive and competitors lose millions per launch that Starlink gets to reinvest. There's been 136 launches of Falcon 9 for Starlink. ~US$62m per launch? If their margins are 20% that's that's $1.6b in savings. And I bet F9's margins are closer to 50% - supporting Starship and more. reply the_duke 11 hours agorootparentprevSure, but Starlink launches are at-cost, which is much, much cheaper than the cost for external customers. Starlink also has launch priority. Good luck with getting 50 launches a year as a customer... reply esaym 16 hours agoparentprev>I’ve seen talk of competitor satellite networks Swansat anyone? https://web.archive.org/web/20080119080404/http://swansat.co... reply RobotToaster 11 hours agoparentprevSpaceX bought up competitors like Swarm Technologies to kill them. It's a monopoly engaging in anti-competitive practices, and should be broken up. reply lutorm 10 hours agorootparentSwarm wasn't a competitor to SpaceX at the time, Swarm and Starlink wasn't aiming at the same market at all. And they didn't exactly kill Swarm. They launched Swarm satellites for a while and there was talk of integrating Swarm transceivers on Starlink satellites. I think once direct-to-cell became a reality, the idea of Swarm was subsumed into that project since it should do everything Swarm did but better. It's worth noting that the Swarm founders are now working on the direct-to-cell project. reply financetechbro 2 hours agoparentprevThere is nothing “awesome” about monopolies reply griomnib 12 hours agoparentprevI’m sure they have the official MAGATEL licenses ready to go for the FCC as well. reply fspeech 12 hours agoparentprevYou don't need LEOs to have text direct to cell. You can cover with a lot fewer satellites in higher otbits. China had this since last year, though through special protocols, not LTE, so you need new hardware. But the hardware fits into a regular cell phone. reply 127 8 hours agoparentprevI would not count China out. reply torlok 15 hours agoparentprevUS tax dollars at work. reply godelski 13 hours agoparentprevYou have it reversed. It’s fair, it’s hard to tell if you haven’t worked in the launch industry. But drive out to Mojave and go talk to the dozens of companies out there. Many of them have reusable designs. But also if you look at the financials, I think many would laugh at the funding many of these companies get when you compare to Silicon Valley. Clear vaporware frequently gets bigger investing. The problem with launch companies is that you have nothing to launch. It’s a vicious coupled system, because it also means you can’t bring prices down to increase the number of launches. You need scale to bring prices down. You can’t implement the Silicon Valley model of run all your competitors (ULA) without dumping 10x down the drain compared to your Uber or Netflix. So the reason it works is because SpaceX is its own customer. You are bootstrapping. The satellite internet idea isn’t even new. I was pitching this to a company I worked for in the early 2010’s (inspired by the brand new planet labs), but what helped was I even found white papers by Qualcomm and others that clearly had the exact same idea. My boss dismissed it because the failures of Celestri, Teledesic, Iridium, and Globealstar. I’m sure this is why I was able to find those white papers too, and very clearly so did SpaceX. The difference here is that SpaceX is a launch company AND has the funding of a billionaire that is willing to take the risk [0]. Imo, the real question is who pitched Kuiper and did they do it before Starlink? It’s a good and obvious idea, so I’d put money down that someone did. I’m pretty sure they’re fucked now as there’s legitimate reasons you want LEO satellite mega constellation to be handled by a monopoly. You just can’t have a dozen of those companies running around. [0] side rant: why the fuck are more billionaires not willing to take big risks. Especially those with at least a billion liquidated from their stock. What’s the point of that money? You’re so wealthy it’s effectively impossible to go broke. The real exception is if your wealth is mostly paper and you’re defrauding people. At 10 billion it basically will not happen even then. If you can stash (not even) 50 million, you never have to work ever again to live in high luxury. reply EGreg 6 hours agoparentprevAngela Merkel is upset that Elon owns 60% of all satellites in space now: https://amp.theguardian.com/world/2024/nov/22/angela-merkel-... reply badpun 7 hours agoparentprevThe conpetition is there already. In Europe you can get satellite Internet for around $40 a month. It’s slower than Starlink (transfer is decent, but the latency is in the hundreds), but much cheaper. reply scotty79 13 hours agoparentprev> The pace of innovation at SpaceX is not THE reason - it’s an additional reason that no one has a snowballs chance in hell of ever catching Starlink. Don't forget over $15bln of tax money they got for doing barely anything so far. reply inemesitaffia 12 hours agorootparentBarely nothing? Are you out of your mind? pLEO, Starshield, SDA, NSSL, Commercial Crew, Commercial Cargo????? Only HLS is in view. And it's less than 5 billion. Everything listed above is delivered and has more expensive alternatives. reply matwood 7 hours agorootparentprevI think it's important to recognize the irony in how much SpaceX and Tesla benefit from government programs and funds that he now wants to turn off as part of DOGE, but you can't say SpaceX has barely done anything. reply 7e 14 hours agoparentprevIt's none of that, it's the willingness of Starlink to run at a massive loss. reply doctorpangloss 15 hours agoparentprevYeah but if they were like, \"Lemme tell you how to provide Internet for boats and Iranians in the most expensive way possible,\" it doesn't sound like that exciting of a business anymore now does it? reply dyauspitr 16 hours agoparentprevIt’s awesome but also worrying. Elon is a political timebomb. I wouldn’t put it past him to selectively deny people usage based on political alignment, sex etc. At least for now there are much worse geosynchronous competitors, but some future state where one doesn’t exist is worrying. reply lmm 13 hours agorootparentMusk is at least a named individual, somewhat accountable for his decisions. Yes him having the ability to cut people off is worrying, but I'm less worried about him doing it than e.g. the Internet Watch Foundation, or whoever cut off Kiwi Farms (where we still don't really know who's actually responsible). reply 71bw 11 hours agorootparent>(where we still don't really know who's actually responsible) Keffals and Fong-Jones reply lmm 10 hours agorootparentAllegedly. Even assuming they were the people who wanted that to happen, we don't know how/why they have the authority and who to vote out if we don't like their decision, whereas Musk is expected to be appointed by the duly elected president who made it clear to the electorate that this was his plan. reply 71bw 10 hours agorootparent>we don't know how/why they have the authority Oh we know damn well. The good old \"scream so loud the issue cannot be ignored anymore\" issue. Especially with Fong-Jones' background in tech with access to a lot of vocal influencer figures in the field. Not to mention the big amount of brain-melted teens who immediately assume anything said about anyone who dares to express negative opinions about what the aforementioned teens believe as true and create a supposedly warranted lynch mob against them. reply hcurtiss 16 hours agorootparentprevWouldn’t put it past him? Can you offer even a single example? reply sd8f9iu 15 hours agorootparentThere are countless examples of Musk selectively banning people on Twitter based on political belief, such as this one [1]. And of course, he banned the @elonjet account, even after specifically saying he would not [2]. More specifically to StarLink, he banned Ukrainian forces from using them around Crimea [3]. [1] https://variety.com/2022/digital/news/twitter-suspends-journ... [2] https://x.com/elonmusk/status/1589414958508691456 [3] https://archive.is/jfdy4 reply omeid2 14 hours agorootparentnext [4 more] [flagged] sd8f9iu 14 hours agorootparentI don't want private businessmen making decisions like that. reply inemesitaffia 12 hours agorootparentHe agrees with you. Believe it or not. You're also arguing SpaceX should have waited for a Pentagon contract to deliver to Ukraine reply ahmetrcagil 13 hours agorootparentprevYes, it is unelected corrupt officials' job after all. reply dyauspitr 15 hours agorootparentprev2022, cut out crimea. reply inemesitaffia 12 hours agorootparentNot true and still off today. I've not seen anyone claim they used to be able to use equipment in Crimea at some point in the past and now it doesn't work. reply throwaway290 7 hours agorootparentprevI believe by the time Starlink arrived in Ukraine Crimea was already occupied and post \"referendum\" and providing service there would be like providing service to Russia, no? reply aguaviva 5 hours agorootparentNo, because the \"referendum\" was meaningless and had no effect on the peninsula's sovereignty. Which since 1991 has been and remains Ukrainian. reply cprayingmantis 19 hours agoprevIf anyone from Starlink or SpaceX is reading these comments here’s what you want to do: Sell your own branded trail cam with solar charging and LTE from orbit. You can charge $25-$40 a month for unlimited pictures sent from the cam. This would open up hunters, nature enthusiasts, and researchers to be able to place their hardware anywhere in the field without worrying about connectivity. Here in SWVA we have deep hollows that can’t get LTE without dense tower coverage that we don’t have the population to justify, but you can grab a satellite connection. After writing this out I’m beginning to doubt the market would be big enough but I know at least 20 people with 2 or more LTE cams for deer season. reply teruakohatu 19 hours agoparentI work with researchers that deploy all sorts of solar powered sensor equipment in remote parts of New Zealand. Realistically Starlink would need to support NB-IoT and LTE-M which is what these kinds of devices are moving towards (if they need cellular connectivity). These are low power variants of 4G and 5G. Even if you have solar and a fixed platform, you usually want to deploy as little solar as possible. Especially if you need to carry the gear on foot. So minimising power consumption is really important. reply djsnoopy 16 hours agorootparentRidiculously niche comments from experts like this is why HN is so special. Thank you. reply teruakohatu 13 hours agorootparentNo problem. It’s also why I love HN. reply pandemic_region 11 hours agoparentprev> This would open up hunters, Christ what more do you guys need to shoot a rabbit. reply aniviacat 5 hours agorootparentHunters observe wildlife. They don't just shoot wildlife whenever they feel like it. reply rpmisms 13 hours agoparentprevMy in-laws live in your county, and Starlink is the only Internet that actually works. Thankfully the TN side runs fiber on the power poles. Additionally, Starlink was a complete lifesaver during Helene. reply user3939382 17 hours agoparentprevIsn’t tree cover a problem for propagation of wavelengths used in satellite comms? reply piyh 16 hours agorootparent>Direct to Cell works with existing LTE phones wherever you can see the sky. No new antennas implies we're in the 1-6 GHz region. Should be fine? reply hughesjj 9 hours agorootparentprevLte antennas of almost arbitrary length exist reply dyauspitr 16 hours agorootparentprevHaving had starlink before, yes. I needed a direct line of sight to the sky to receive service. reply MobiusHorizons 13 hours agorootparentThis service uses a different radio link using LTE. That’s why you don’t need the dish. They had to launch new satellites with the extra radio gear. So your past experience is not necessarily representative. reply scellus 10 hours agoparentprevIn Finland, i get 5Mbps LTE uplink for EUR 4 per month, for a trailcam, with unlimited use (at least in principle). So $20 per month sounds expensive, but obviously there are places where one has no earthly LTE and then it could be justified. In general, having low-bandwidth Starlink IoT connections globally accessible would be just great, I can see lots of usage. reply gspr 10 hours agorootparentFinland is fairly flat and has _excellent_ LTE coverage. Being in Norway myself, which isn't flat, but still has fantastic LTE coverage for political reasons, I do often find myself thinking like you, and need to be reminded of how abysmal coverage is in rural North America (and even in for example rural Germany). reply lm28469 7 hours agorootparentprevCurrent US mobile coverage and prices are like europe in 2002 reply geepytee 19 hours agoparentprevInteresting idea. I can build this and open source it. I imagine there is equivalent hardware over LTE already? reply _hark 19 hours agoparentprevThis could also be a hardware startup. If only there were some entrepreneur types around... Presumably there's a market for this in other niches, e.g. w",
    "originSummary": [
      "Starlink Direct to Cell is a new service by SpaceX offering global text, voice, and data access for LTE phones, ensuring connectivity on land, lakes, and coastal waters.",
      "The service will begin with text services in 2024, followed by voice, data, and IoT (Internet of Things) support in 2025, without needing hardware changes or special apps.",
      "This development highlights SpaceX's expansion into telecommunications, providing seamless connectivity without additional equipment."
    ],
    "commentSummary": [
      "Starlink's vertical integration and cost-effective launches position it as a leading force in the satellite internet industry, facing minimal competition.",
      "While some view Starlink's dominance as monopolistic, others believe innovation and foreign military support might foster future competition.",
      "The high cost of satellite launches is a major hurdle, but advancements in reusable rocket technology could alter the competitive landscape."
    ],
    "points": 649,
    "commentCount": 714,
    "retryCount": 0,
    "time": 1732478914
  },
  {
    "id": 42230392,
    "title": "This website is hosted on Bluesky",
    "originLink": "https://danielmangum.com/posts/this-website-is-hosted-on-bluesky/",
    "originBody": "This Website is Hosted on Bluesky November 24, 2024 14-minute read Well, not this one. But this one is! How? Let’s take a closer look at Bluesky and the AT Protocol that underpins it. Note: I communicated with the Bluesky team prior to the publishing of this post. While the functionality described is not the intended use of the application, it is known behavior and does not constitue a vulnerability disclosure process. My main motivation for reaching out to them was because I like the folks and don’t want to make their lives harder. Being able to host a website on Bluesky really has very little to do with Bluesky itself. I happen to use Bluesky for hosting my Personal Data Server (PDS), but all of the APIs leveraged in uploading the site contents are defined at the AT Protocol level and implemented by a PDS. Bluesky offers access to my PDS via their PDS entryway, which allows for the many (have you heard that they are growing by a million users per day?) PDS instances they run to be exposed via the bsky.social domain. That being said, individual PDS instances can be accessed directly, and if you clicked the link at the top of this post to access the Bluesky hosted website, then you have already visited mine at porcini.us-east.host.bsky.network. Most social applications, and many applications in general for that matter, broadly have two primary types of content: records and blobs. Records are the core entity types that users create. They generally have some defined structure and metadata, and they may reference other records or content. Blobs are typically larger unstructured data, such as media assets, that may be uploaded by a user, but are exposed via a record referencing them. For example, on Bluesky a user may upload an image, then create a post that references it. From an end-user perspective, these two operations appear to be one action, but they are typically decoupled at the API level. This decoupling is described in detail in the AT Protocol blob specification. Blob files are uploaded and distributed separately from records. Blobs are authoritatively stored by the account’s PDS instance, but views are commonly served by CDNs associated with individual applications (“AppViews”), to reduce traffic on the PDS. CDNs may serve transformed (resized, transcoded, etc) versions of the original blob. Later on, the specification details how blob lifecylce is to be managed. Blobs must be uploaded to the PDS before a record can be created referencing that blob. Note that the server does not know the intended Lexicon when receiving an upload, so can only apply generic blob limits and restrictions at initial upload time, and then enforce Lexicon-defined limits later when the record is created. Reading this section is what initially got my wheels turning. While Bluesky has a limited set of media asset types that can be referenced by posts, posts are just one record type that is defined by the Bluesky lexicon (app.bsky.*). Records, on the other hand, are defined in the AT Protocol lexicon (com.atproto.*) and are designed to accommodate creating any type of record defined by any lexicon. Because different types of blobs may be relevant for other lexicons, the specification highlights that restrictions cannot be enforced at time of upload. Instead blobs are not made available until they are referenced, at which point the validation can be performed based on the lexicon of the record type. After a successful upload, blobs are placed in temporary storage. They are not accessible for download or distribution while in this state. Servers should “garbage collect” (delete) un-referenced temporary blobs after an appropriate time span (see implementation guidelines below). Blobs which are in temporary storage should not be included in the listBlobs output. The upload blob can now be referenced from records by including the returned blob metadata in a record. When processing record creation, the server extracts the set of all referenced blobs, and checks that they are either already referenced, or are in temporary storage. Once the record creation succeeds, the server makes the blob publicly accessible. However, applying validation does not mean that Bluesky’s restrictions will necessarily be applied. A record that references a blob could very well be of a type defined by a different lexicon, or, as we’ll see later on, part of a sub-schema enabled by an open union in the Bluesky lexicon. Let’s see how this works in practice. In order to perform data creation operations against a PDS, an access token must be acquired for authentication. The com.atproto.server.createSession XRPC method can be used to exchange user credentials for a token. In the following curl command, I used danielmangum.com as $BSKY_HANDLE and my password as $BSKY_PWD. curl -X POST 'https://bsky.social/xrpc/com.atproto.server.createSession' \\ -H 'Content-Type: application/json' \\ -d '{\"identifier\": \"'\"$BSKY_HANDLE\"'\", \"password\": \"'\"$BSKY_PWD\"'\"}' The response includes an accessJWT field, which will be used as $ACCESS_JWT in subsequent operations. As described in the blob specification, a blob must be uploaded prior to it being referenced. I wanted to verify that the blob was not present in the com.atproto.sync.listBlobs output, or accessible via the com.atproto.sync.getBlob methods immediately after upload, so I checked how many blobs were currently being returned. curl -s 'https://bsky.social/xrpc/com.atproto.sync.listBlobs?did='\"$DID\"'' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"''jq -r '.cidslength' The decentralized identifier ($DID) used above can be obtained from the createSession output as well. It is the underlying identifier for an account. Every Bluesky handle resolves to a DID. 391 The com.atproto.repo.uploadBlob method is used to upload a blob to a repository. The content of the website is a simple index.html file. This Website is Hosted on BlueskyThis website is just a blob uploaded to Bluesky via the API. Curious about how this works? Check out the write-up on danielmangum.com.To upload it, I used the following command. curl -X POST 'https://bsky.social/xrpc/com.atproto.repo.uploadBlob' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"'' \\ -H 'Content-Type: text/html' \\ --data-binary '@index.html' { \"blob\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq\" }, \"mimeType\": \"text/html\", \"size\": 268 } } The returned $link can be used as the Content Identifier (cid) when fetching the blob via the getBlob method. However, according to the specification, because this blob has to be referenced, it shouldn’t be visible. I checked to see if I could access it with the following command. curl -L 'https://bsky.social/xrpc/com.atproto.sync.getBlob?did='\"$DID\"'&cid='\"$LINK\"'' { \"error\": \"InternalServerError\", \"message\": \"Internal Server Error\" } Not the error I was expecting, but it looks like I indeed cannot access it. I was also able to determine that it had not beed added to the listBlobs output. curl -s 'https://bsky.social/xrpc/com.atproto.sync.listBlobs?did='\"$DID\"'' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"''jq -r '.cidslength' 391 Blobs can be referenced in app.bsky.feed.post records on Bluesky by including an embedded image. However, the app.bsky.embed.image schema retricts the MIME type to those prefixed with image/*. We can see this validation in action if we try to create a post with an embedded image. curl -X POST 'https://bsky.social/xrpc/com.atproto.repo.createRecord' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"'' \\ -H 'Content-Type: application/json' \\ -d '{ \"repo\": \"danielmangum.com\", \"collection\": \"app.bsky.feed.post\", \"record\": { \"$type\": \"app.bsky.feed.post\", \"text\": \"testing123\", \"createdAt\": \"2024-11-23T05:49:35.422015Z\", \"embed\": { \"$type\": \"app.bsky.embed.images\", \"images\": [ { \"alt\": \"that is not an image that is a website!\", \"image\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreidphtuvbzublyzacxukmmk2ikiur5ahme75fegokbhh26o4wfzvry\" }, \"mimeType\": \"text/html\", \"size\": 21 } } ] } } }' { \"error\": \"InvalidMimeType\", \"message\": \"Wrong type of file. It is text/html but it must match image/*.\" } For completeness, I also tried specifying the mimeType as image/jpeg and verified that the PDS also validates that the blob reference MIME type matches the blob. { \"error\": \"InvalidMimeType\", \"message\": \"Referenced Mimetype does not match stored blob. Expected: text/html, Got: image/jpeg\" } However, the blob $type is part of the AT Protocol data model and not specific to Bluesky. Because Bluesky’s PDS implementation is open source, we can see exactly how a BlobRef is defined. export class BlobRef { public original: JsonBlobRef constructor( public ref: CID, public mimeType: string, public size: number, original?: JsonBlobRef, ) { this.original = original ?? { $type: 'blob', ref, mimeType, size, } } We can also see exactly how the PDS identifies blobs in a record. export const findBlobRefs = ( val: LexValue, path: string[] = [], layer = 0, ): FoundBlobRef[] => { if (layer > 32) { return [] } // walk arrays if (Array.isArray(val)) { return val.flatMap((item) => findBlobRefs(item, path, layer + 1)) } // objects if (val && typeof val === 'object') { // convert blobs, leaving the original encoding so that we don't change CIDs on re-encode if (val instanceof BlobRef) { return [ { ref: val, path, }, ] } // retain cids & bytes if (CID.asCID(val) || val instanceof Uint8Array) { return [] } return Object.entries(val).flatMap(([key, item]) => findBlobRefs(item, [...path, key], layer + 1), ) } // pass through return [] } The important thing to notice is that identifying blob references does require the presence of a lexicon schema. findBlobRefs recursively navigates a LexValue and looks for $type: blob. In order to support new lexicons over time, the PDS needs to be able to handle lexicons that it doesn’t know about. Because blobs are a fundamental component of so many applications, these new lexicons also need to be able to leverage them. To put this into action, I attempted to create a record of type com.danielmangum.hack.website, which included a reference to the uploaded HTML blob. curl -X POST 'https://bsky.social/xrpc/com.atproto.repo.createRecord' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"'' \\ -H 'Content-Type: application/json' \\ -d '{ \"repo\": \"danielmangum.com\", \"collection\": \"com.danielmangum.hack.website\", \"record\": { \"$type\": \"com.danielmangum.hack.website\", \"website\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq\" }, \"mimeType\": \"text/html\", \"size\": 268 } } }' { \"uri\": \"at://did:plc:j22nebhg6aek3kt2mex5ng7e/com.danielmangum.hack.website/3lbnguuzckm2u\", \"cid\": \"bafyreicjcptshc7lmgb7abxlvcb5fmqqjdj6neie23szyum7rcaowmm5qm\", \"commit\": { \"cid\": \"bafyreid6apjjy56xoyenxmg5xv356twh22n3hayecoxlf6mflpltlzpuwu\", \"rev\": \"3lbnguuzmd42u\" }, \"validationStatus\": \"unknown\" } It worked! We can see in the response that the PDS was unable to validate the record (validationStatus: unknown) because it does not know about the com.danielmangum.hack.* lexicon. Nevertheless, it will agree to persist the record. The next step was to check whether the referenced blob had been persisted. curl -s 'https://bsky.social/xrpc/com.atproto.sync.listBlobs?did='\"$DID\"'' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"''jq -r '.cidslength' 392 It looked like it had as the count had increased by 1. Fetching the blob directly would tell us for sure. Importantly, getBlob does not require passing the $ACCESS_JWT because unauthenticated parties need to be able to fetch blobs to process alongside records that reference them. curl 'https://bsky.social/xrpc/com.atproto.sync.getBlob?did='\"$DID\"'&cid=bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq' { \"error\": \"Redirecting\", \"message\": \"Redirecting to new blob location\" } Adding -L to the command enables following redirects. curl -L 'https://bsky.social/xrpc/com.atproto.sync.getBlob?did='\"$DID\"'&cid=bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq' This Website is Hosted on BlueskyThis website is just a blob uploaded to Bluesky via the API. Curious about how this works? Check out the write-up on danielmangum.com.Examining the redirect response, we can see that we are being directed directly to my PDS. < HTTP/2 302 < date: Sun, 24 Nov 2024 13:58:21 GMT < content-type: application/json; charset=utf-8 < content-length: 68 < location: https://porcini.us-east.host.bsky.network/xrpc/com.atproto.sync.getBlob?did=did:plc:j22nebhg6aek3kt2mex5ng7e&cid=bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq < x-powered-by: Express < access-control-allow-origin: * < ratelimit-limit: 3000 < ratelimit-remaining: 2997 < ratelimit-reset: 1732456898 < ratelimit-policy: 3000;w=300 < etag: W/\"44-1je7JKzDJZFd5iRtOI+IS+zlOOE\" < vary: Accept-Encoding Opening the location URL in the browser presents the website as expected, And just like that, we have a website hosted on Bluesky! While this is not really the intended use of blobs on Bluesky specifically, it could be a legitimate use case in the future. Records that reference website content, code, or other binary artifacts are a possibility on the AT Protocol. That being said, if a service like Bluesky is running PDS instances on behalf of users, this effectively equates to free (albiet unreliable) arbiratry file hosting, which has implications beyond just racking up large storage and egress data fees. Returning back to the blobs specification, there is an additional section on Security Considerations. Serving arbitrary user-uploaded files from a web server raises many content security issues. For example, cross-site scripting (XSS) of scripts or SVG content form the same “origin” as other web pages. It is effectively mandatory to enable a Content Security Policy (LINK: https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP) for the getBlob endpoint. It is effectively not supported to dynamically serve assets directly out of blob storage (the getBlob endpoint) directly to browsers and web applications. Applications must proxy blobs, files, and assets through an independent CDN, proxy, or other web service before serving to browsers and web agents, and such services are expected to implement security precautions. Bluesky does apply recommended CSP headers to the endpoint in the handler, which guards against some of the issues described. res.setHeader('x-content-type-options', 'nosniff') res.setHeader('content-security-policy', `default-src 'none'; sandbox`) There is also a default size limit on blob of 5 MB. blobUploadLimit: env.blobUploadLimit ?? 5 * 1024 * 1024, // 5mb Images, the most common blob type on the Bluesky application, are expectedly not served directly from PDS instances, but from the Bluesky CDN. For example, the following URL points to the feed thumbnail version of an image I recently uploaded as part of a post. https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:j22nebhg6aek3kt2mex5ng7e/bafkreie5ci75iujpv34slnh3o4b7xcuxklpcguzed6qqmi4eaagn6cg4ve@jpeg A different URL provides the full size version. https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:j22nebhg6aek3kt2mex5ng7e/bafkreie5ci75iujpv34slnh3o4b7xcuxklpcguzed6qqmi4eaagn6cg4ve@jpeg However, the post that references the image just includes the cid. The application itself needs to be aware of how images are served from the CDN. { \"$type\": \"app.bsky.feed.post\", \"createdAt\": \"2024-11-12T14:18:44.263Z\", \"embed\": { \"$type\": \"app.bsky.embed.images\", \"images\": [ { \"alt\": \"Title image for blog post \\\"USB On-The-Go on the ESP32-S3\\\" on danielmangum.com.\", \"aspectRatio\": { \"height\": 1080, \"width\": 1920 }, \"image\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreie5ci75iujpv34slnh3o4b7xcuxklpcguzed6qqmi4eaagn6cg4ve\" }, \"mimeType\": \"image/jpeg\", \"size\": 869901 } } ] }, \"facets\": [ { \"features\": [ { \"$type\": \"app.bsky.richtext.facet#link\", \"uri\": \"https://danielmangum.com/posts/usb-otg-esp32s3/\" } ], \"index\": { \"byteEnd\": 261, \"byteStart\": 229 } } ], \"langs\": [ \"en\" ], \"text\": \"ICYMI: This weekend I wrote about USB On-The-Go on the ESP32-S3. OTG allows devices to also act as USB hosts. I dive into how the USB PHY is configured, and demonstrate connecting two ESP32-S3's, as well as a Raspberry Pi Pico.danielmangum.com/posts/usb-ot...\" } The logic is present in the ImageUriBuilder, which will use a CDN if one is configured. const imgUriBuilder = new ImageUriBuilder( config.cdnUrl || `${config.publicUrl}/img`, ) So why does Bluesky provide direct unauthenticated access to the PDS getBlobs endpoint? Once again illustrating the beauty of open source, there is an issue describing the original motivation. In it, image labeling and user content export, as well as additional future use cases, are enumerated. There is also a mention of the possibility of users hotlinking content and Bluesky for free hosting, so these issues are clearly top-of-mind. The original implementation did not include the proper security headers, but they were subsequently added. Traditional social platforms can place more restrictions on blobs at time of upload because there is a limited set of valid content. The extensibility of Bluesky and the AT Protocol, which is what differentiates it from traditional networks, also necessitates more complexity. However, I, and clearly the awesome folks building Bluesky, think it’s clearly worth it. Bonus Content Link to heading I mentioned sub-schemas and open unions earlier in this post. The app.bsky.feed.post type includes a union for valid embeds. Per the AT Protocol lexicon specification, unions are open unless explicitly marked as closed. By default unions are “open”, meaning that future revisions of the schema could add more types to the list of refs (though can not remove types). This means that implementations should be permissive when validating, in case they do not have the most recent version of the Lexicon. The closed flag (boolean) can indicate that the set of types is fixed and can not be extended in the future. The embed union is not marked as closed. \"embed\": { \"type\": \"union\", \"refs\": [ \"app.bsky.embed.images\", \"app.bsky.embed.video\", \"app.bsky.embed.external\", \"app.bsky.embed.record\", \"app.bsky.embed.recordWithMedia\" ] }, Therefore, posts can be created with an embed $type that is not enumerated. For example, I could also persist the website HTML via making a post on Bluesky with a custom embed. curl -X POST 'https://bsky.social/xrpc/com.atproto.repo.createRecord' \\ -H 'Authorization: Bearer '\"$ACCESS_JWT\"'' \\ -H 'Content-Type: application/json' \\ -d '{ \"repo\": \"danielmangum.com\", \"collection\": \"app.bsky.feed.post\", \"record\": { \"$type\": \"app.bsky.feed.post\", \"text\": \"This post embeds a website.\", \"createdAt\": \"2024-11-23T05:49:35.422015Z\", \"embed\": { \"$type\": \"com.danielmangum.hack.sites\", \"sites\": [ { \"site\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq\" }, \"mimeType\": \"text/html\", \"size\": 268 } } ] } } }' { \"uri\": \"at://did:plc:j22nebhg6aek3kt2mex5ng7e/app.bsky.feed.post/3lbpfxwnjoq23\", \"cid\": \"bafyreidnlyhcvlzl5hc3btih6ly5anjld6ss4bgocyichnm72cpnjuzsvu\", \"commit\": { \"cid\": \"bafyreibv77m3bdyywmotn7ncbbrqv6pv7irzmw27bzklt4tppgsoodarma\", \"rev\": \"3lbpfxwo57q23\" }, \"validationStatus\": \"valid\" } In the Bluesky application, the embed is silently ignored. However, the content is persisted and the reference is included in the post record, so a different application could choose to start rendering the embed. { \"$type\": \"app.bsky.feed.post\", \"createdAt\": \"2024-11-23T05:49:35.422015Z\", \"embed\": { \"$type\": \"com.danielmangum.hack.sites\", \"sites\": [ { \"site\": { \"$type\": \"blob\", \"ref\": { \"$link\": \"bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq\" }, \"mimeType\": \"text/html\", \"size\": 268 } } ] }, \"text\": \"This post embeds a website.\" } In my opinion, this is one of the most interesting features of lexicons because it allows for “micro-extensions” that build on existing use cases (e.g. “microblogging”). For example, I for one would love a world in which small code snippets could be embedded in my posts and run in a WebAssembly sandbox by other users. But that’s a post for another day.",
    "commentLink": "https://news.ycombinator.com/item?id=42230392",
    "commentBody": "This website is hosted on Bluesky (danielmangum.com)636 points by hasheddan 22 hours agohidepastfavorite147 comments pfraze 21 hours agoAppreciated Daniel reaching out to the team about this! Hosting blobs is one of those things that will inevitably go through iterations as we understand the abuse vectors more and more, but for now it's really fun to see this kind of usage in action. The PDS is meant to be a database host in the same sense that a webserver is a website host. reply sebmellen 18 hours agoparentAre you ever going to bring back Beaker Browser? Used to love playing around with that! Didn't realize you'd gone on to Bluesky, very neat. reply pfraze 3 hours agorootparentThanks! Probably won’t revive it, but it was a great experience. Wrote some notes on it here: https://github.com/beakerbrowser/beaker/blob/master/archive-... reply nileshtrivedi 14 hours agoparentprevDoesn't the potential for abuse reduce when content is linked through user's own domain rather than a particular appview like bsky? Bsky already supports a user's domain ALIASed to redirect.bsky.com: https://bsky.app/profile/jacob.gold/post/3kh6rnpdzmp2v reply philipwhiuk 5 hours agorootparentIf people use BlueSky as a magnet link for illegal content it will quickly become a problem. reply philipwhiuk 5 hours agoparentprevYou're walking headfirst into the copyright, CSAM, pornography hole of content moderation here. reply thesuitonym 4 hours agorootparentHow is this any different than the regular hole of content moderation they're already in? reply chefandy 3 hours agorootparentI don’t have a well-considered answer, but a) I imagine being able to host a phishing site on an official domain from them using their SSL cert is problematic, and b) my gut says that as soon as you start hosting arbitrary files— e.g. zip files— and browser executable JavaScript with your domain in there, that’s a different level of possible content. I guess the question is whether or not the disposition of a social media network makes that more problematic than it does with, say, Google drive. reply preciousoo 2 hours agorootparentIt’s not possible for me, a non Google employee to create a file that’s hosted on Google.com, or any Google domain and have it read in the browser as text/html, bypassing many a firewall, for example reply nutanc 4 hours agorootparentprevAgreed. I assume this will open up Bluesky to a lot of potential legal problems. But will it be any different from accesing the content using the app as the content is anyway hosted. That said, just the other day I was thinking, is the reverse possible. I have a web site/blog. Use RSS and then the RSS updates are posted to a handle on Bluesky. I would assume that's a lot more useful? reply diggan 3 hours agorootparent> That said, just the other day I was thinking, is the reverse possible. I have a web site/blog. Use RSS and then the RSS updates are posted to a handle on Bluesky. I would assume that's a lot more useful? This is trivial, I'm currently doing this for https://bsky.app/profile/aemet-bot.bsky.social which reads a bunch of RSS feeds from AEMET (Spain's national weather service basically) and posts warnings to the feed if there is any warning above Yellow. The code for managing this is about ~200 lines of Rust code. reply skiman10 1 hour agorootparentDo you have that code posted somewhere by chance? I would be interested in browsing through it! reply diggan 1 hour agorootparentNot right now, no. It's fairly simple (login to Bluesky, read RSS, save item IDs to a text file, post if there are any new feed items, close program then systemd timers run this every N minutes) + pretty specific to AEMET and their formats. If there is interest I guess I could spend some hours to make it a bit more generic and publish the source. reply pfraze 3 hours agorootparentprevAs opposed to running a social network? What else is new reply moritonal 18 hours agoparentprevCongrats on finding a role at Bluesky. Beaker was such an amazing project to follow, that experience must be so useful. reply simonw 21 hours agoprevI was curious as to the security context this runs in: curl -i 'https://porcini.us-east.host.bsky.network/xrpc/com.atproto.sync.getBlob?did=did:plc:j22nebhg6aek3kt2mex5ng7e&cid=bafkreic5fmelmhqoqxfjz2siw5ey43ixwlzg5gvv2pkkz7o25ikepv4zeq' Here are the headers I got back: x-powered-by: Express access-control-allow-origin: * cache-control: private vary: Authorization, Accept-Encoding ratelimit-limit: 3000 ratelimit-remaining: 2998 ratelimit-reset: 1732482126 ratelimit-policy: 3000;w=300 content-length: 268 x-content-type-options: nosniff content-security-policy: default-src 'none'; sandbox content-type: text/html; charset=utf-8 date: Sun, 24 Nov 2024 20:57:24 GMT strict-transport-security: max-age=63072000 Presumably that ratelimit is against your IP? \"access-control-allow-origin: *\" is interesting - it means you can access content hosted in this way using fetch() from JavaScript on any web page on any other domain. \"content-security-policy: default-src 'none'; sandbox\" is very restrictive (which is good) - content hosted here won't be able to load additional scripts or images, and the sandbox tag means it can't run JavaScript either: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Co... reply benatkin 20 hours agoparentBlocking/allowlisting all JavaScript is the only way [1] to have a CSP fully contain an app (no exfiltration) [2] and with prefetch that might not be enough. The author is correct at the end to suggest using WebAssembly. (Also, it still has the issue of clicking links, which can be limited to certain domains or even data: by wrapping the untrusted code in an iframe and using child-src on the parent of the iframe) 1: https://github.com/w3c/webappsec/issues/656#issuecomment-246... 2: https://www.w3.org/TR/CSP3/#exfiltration reply EE84M3i 9 hours agorootparentI didn't realize you could use CSP for preventing exhilaration now! How did they close the WebRTC loopholes? reply benatkin 2 hours agorootparentThey haven't. That in the spec stops short of actually saying that it will stop all exfiltration. What it will do is make it harder because you'd have to put the data in a subdomain or in a username/password. It also could make it hard to deny that an attempt to exfiltrate was deliberate. reply kmeisthax 15 hours agorootparentprevWhy would WebAssembly provide more protection against exfiltration than JavaScript in this case? reply benatkin 14 hours agorootparentBy default WebAssembly doesn't have access to the DOM or JavaScript globals. You have full control of how it can access these things. reply nightpool 20 hours agoparentprevis the default-src necessary if you're using sandbox or is it redundant? reply johncolanduoni 19 hours agorootparent`sandbox` doesn’t affect making requests via HTML (images, stylesheets, etc.). reply nightpool 2 hours agorootparentRight, but what would be the security impact of that compared to just plain HTML? I guess it allows for some form of view counting or IP exfiltration, but other than that anything you can do with an external request you could do with an embedded data URI. reply brewmarche 55 minutes agorootparentAs far as I understand CSP, since it’s set to `none`, no URIs are allowed, not even `data`. Inline scripts and stylesheets are not allowed either, since `unsafe-inline` (or nonces/hashes) is missing. reply the-chitmonger 5 hours agoprevI wasn't around for this specific era, but the way users of BlueSky are able to dive deep into technological waters reminds me of how people talk about learning HTML for the first time while using MySpace. Social media is a more saturated market now than before, but I wonder if we'll see a new generation of programmers sprout from BlueSky. reply crowcroft 3 hours agoparentMySpace and old forums walked you up a ladder of abstraction from, I'm adding some text into a box and it shows up on the webpage -> I'm adding some images as well -> I'm adding some BBCode/Markup and now things look really custom -> I'm writing HTML and CSS -> I'm writing complete scripts. Bluesky does the first step and then it's a great big leap from there imo. reply rsynnott 8 hours agoprevThere should really be a name for this phenomenon; put basically anything on the internet, and sooner or later people will try to host arbitrary files on it. reply Suppafly 17 minutes agoparent>and sooner or later people will try to host arbitrary files on it. I'm pretty sure that's a key reason that google accounts are limited to 15gb now until you pay for more storage. When it was unlimited there were all these opensource projects coming up with ideas to backup your filesystem to gmail and such which got even worse when Drive came about. These free services need to foresee that that will be an issue and put in some basic limits. reply Jerrrry 3 minutes agoparentprevInner Platform effect https://en.wikipedia.org/wiki/Inner-platform_effect reply superzamp 8 hours agoparentprevThere's already \"parasitic computation\" so we could probably go for \"parasitic data storage\" reply miningape 8 hours agoparentprevJohnson's Law: The more attention something receives, the bigger it's area of impact becomes. reply sequoia 1 hour agorootparentIs this comment intended to have a bawdy subtext or am I just reading to much into it? reply marcosscriven 6 hours agorootparentprevI thought that was the Streisand effect? reply kingofheroes 3 hours agorootparentThe Streisand is \"the more you try to hide something, the bigger its area of impact becomes\". reply SAHChandler 19 hours agoprevI'm very hopeful for the possibility of using bluesky for blob data. A friend and I had considered looking into storing DOOM WADs on bluesky so that \"map packs\" could be shared in the same way posts are. Follow an account, a list, or a starter pack, and you could theoretically modify GZDoom or some other client to know how to search and view any WADs posted by those accounts. Like how the Steam Workshop works, except it's via bluesky. :D reply Rick76 5 hours agoparentThis is a cool idea, are you thinking of self-hosting this or on their servers? Have they mentioned anything about any guidelines for what their blob storage can be used for? I know doom is small and that's a great idea, a workshop is a perfect example of how this can be used. I'm just wondering if this can be abused to outsource large server space. reply verdverm 4 hours agorootparentLook into Lexicon on https://atproto.com You can define custom records for basically anything A PDS would be a point in the network that decides if abuse is happening, also a place where competition can occur reply dev0p 8 hours agoparentprevSo, basically using Bluesky as an RSS feed for arbitrary data? Kind of? reply hiop 2 hours agoprevThe recent API changes in Strava reminded me of how limited our access is to the data stored on their platform. As a dominant player in the fitness space, they could gradually lock features behind a subscription wall. While this might raise privacy or safety concerns, could the AT Protocol be a suitable platform for storing GPX or FIT files? reply d-lo 1 hour agoparentI’d love a federated Strava replacement. Unfortunately I don’t believe that the AT Protocol supports private or limited visibility posts yet, which I think is a pretty key feature for Strava’s use case. reply willscott 11 hours agoprevOne of the points that is made is that since the PDS that's being interacted with here is part of a 'Personal Data Server' rather than the Bluesky product, it ends up able to offer infinite free data storage. This seems like one of the things that might be part of the references the bluesky team has made at time to introducing a subscription service - providing more space / bandwidth / higher quality video on your PDS seems like the type of hosting that could be offered at a premium tier. reply hk1337 2 hours agoparent> 'Personal Data Server' rather than the Bluesky product If I understood correctly, the PDS was hosted on Bluesky. I assume it could be hosted somewhere else, so yeah it could be interacted with more than Bluesky. reply edavis 21 hours agoprevIf this sort of thing interests you, check out atfile: https://github.com/electricduck/atfile reply h4x0rr 21 hours agoprevAnyone else feels like this will be abused for phishing and/or malware distribution? reply kuschku 8 hours agoparentIt will be. We had the same issue with Matrix attachments. reply Arathorn 10 minutes agorootparentgot fixed by https://github.com/matrix-org/matrix-spec-proposals/blob/mai... fwiw reply lazystar 20 hours agoparentprevis there any hosting site that isn't? feels like a computing law at this point; if you build a hosting site, someone will try to use it for malicious purposes. reply EGreg 20 hours agorootparentCan’t you just make the hosting site features only be for real purposes? Like a link shortener which only forwards to a domain that matches the subdomain? Or only for watching videos and collecting metrics etc. reply internetter 17 hours agorootparentAny file upload can be used for unintended purposes, eg encoding files into static to upload to youtube and all other sorts of tomfoolery: https://github.com/boehs/awesome-cloud-storage-abuse reply bigfatkitten 14 hours agoparentprevIt'll take about 5 mins for that to happen and then for *.bsky.network to start getting blocked by Google Safe Browsing, Palo Alto, Bluecoat etc. reply remram 20 hours agoparentprevI don't see how. This is a direct link to the author's bluesky server (PDS) so of course it is controlled by them. reply nicky0 5 hours agorootparentThe link in question (linked from the the sumbitted link) is `porcini.us-east.host.bsky.network`. That's hosted by bsky, isn't it? reply ndjdjddjsjj 16 hours agorootparentprevPhish could be this: $inane_marketing_trope ... Click here to Unsubscribe from Bluesky https://porcini.us-east.host.bsky.network/xrpc/com.atproto.s... ... Redirects to bad site. reply remram 15 hours agorootparentAs long as content is authored by the administrator of the server, I don't see where there is a security issue. It's like if you point to your own Apache server in your own domain where you host a scam page and say there's a security issue with Apache because you could do that. Or are you saying that you can make this person's server serve third-party content? reply ndjdjddjsjj 11 hours agorootparent> Or are you saying that you can make this person's server serve third-party content? Http: yes see OP Email: not sure. Hopefully not. But spoofing happens. reply benatkin 20 hours agorootparentprevLack of moderation combined with an offical-sounding domain name. This would have to get the user to follow a link or call a phone number or something though. These are plausible. It's too bad the content-security-policy can't prevent following links. reply extraduder_ire 19 hours agorootparentBluesky seems to use a lot of totally different domain names for each part of their infrastructure, maybe for this reason. e.g. this one is bsky.network While they're nowhere close on volume, they're certainly beating microsoft in terms of the rate they're adding similar looking official URLs. reply whywhywhywhy 7 hours agorootparent> bsky.network Shortening your brand to 4 letters when your chosen TLD is the same length as your full brand name is such a weird choice. reply wise_young_man 3 hours agorootparentI guess bsky.net and bluesky.net were taken. What’s weird is why ICANN allowed .network TLD at all when .net already existed, was shorter, and meant for that. reply tomrod 4 hours agorootparentprevThis is why you and I aren't in charge of marketing I reckon. reply anon7000 17 hours agorootparentprevI mean, the way AT Proto is designed, moderation primarily happens on the app layer, not the protocol layer. So on an app like Bluesky, you can have a lot of moderation. But the protocol itself allows hosting arbitrary content in a distributed/decentralized way. reply ineedaj0b 19 hours agoparentprevhehehe. I pinned it to the top research ideas. I'll get back to you on this reply hi_hi 19 hours agoprevCould some awesome person possibly summarise any limitations or use cases where this might not work well? The example provided is quite basic static text, so I'm wondering if there's a reason for that? reply hk1337 2 hours agoprevhttps://atproto.com/guides/glossary How exactly is the personal data server used? Examples and such? The link gives a nice high level explanation but I still am not sure of its purpose. reply Retr0id 21 hours agoprevThe CSP headers didn't used to be there, which I used to pop an alert(), way back. (at the time there was also a MIME whitelist, but that whitelist included image/svg+xml, which allows script execution) reply steveklabnik 21 hours agoprevAh this is super cool! I’ve been thinking about doing this with my website, but was going to leverage the whtwind lexicon, since my site is mostly a blog. But for the front page, and anything else, I may have wanted something else. This is more of an unstructured approach, which is cool because it needs less specialized tooling. It has the disadvantage of being… well, just a blob. No semantic information there. reply srg0 4 hours agoprevMy first reaction was like -- wow, a site that runs on a reverb pedal. reply code_for_monkey 2 hours agoparentthis website has the toan reply alpb 1 hour agoprevRight now it's the only page under site:bsky.network if you search for that. Hilarious and awesome! https://www.google.com/search?q=site%3Absky.network Daniel is a great hacker. reply skybrian 20 hours agoprevI'm wondering whether a third-party PDS implementation should support other protocols as well. Would a combined git/PDS repo make any sense at all? (That is, it's a PDS, but it also implements enough of git to do read-only access via git commands.) What other protocols would make sense? reply genem9 8 hours agoprev“Hosting websites” has been possible on nostr for some time already with npub.pro … reply rpastuszak 2 hours agoprevJust a (very unserious) reminder that you can host +7kb of data in a single tweet using data URIs + gzip. Here's Pong (HTML + JS) and the Epic of Gilgamesh: https://x.com/rafalpast/status/1316836397903474688 (brought to you by the ad tracking pixel parameters ignoring the tweet length limit) More links + the \"Twitter CDN\" editor™: https://sonnet.io/projects#:~:text=Laconic!%20(a%20Twitter%2... reply bbor 21 hours agoprevPretty awesome! Convenience link to the fascinating github issue linked at the bottom, featuring Bluesky celebrity pfrazee: https://github.com/bluesky-social/atproto/issues/523 I have a lot of hope for AT. I'm sure there's lots of smart people on HN that have done great things with the Fediverse, but this whole paradigm just seems more sustainable + realistic. Basically it gives us centralization by default, but with real decentralized support when you need it / for power users. reply jazzyjackson 21 hours agoparentAs far as sustainability goes I'm hoping for a better business model than \"accept funds from Blockchain Capital\" [0], some return on investment in mirroring the firehouse. I can muse, a Discord alternative where some users pay to host longer videos (current limit is 60sec [1]) or Patreon where a relay takes a cut in exchange for managing access/decryption keys, or Bandcamp or some other kind of social marketplace - as it is theres no reason I couldn't do this, it is an open platform after all. [0] https://www.blockchaincapital.com/blog/bluesky-13m-users-and... [1] https://bsky.social/about/blog/09-11-2024-video reply pm90 16 hours agorootparentIm hoping that most of the infra costs get amortized by people bringing on their PDS’s, while some of the core stuff (app layer, iOS app etc.) is maintained by a small team funded by donations/subscriptions. reply bbor 21 hours agorootparentprevYeah I’m also worried about profitability, tho not particularly concerned about that particular investor, personally; all VCs are inherently amoral profit generators. They are a “benefit corporation” like anthropic, which gives them some leeway to deny shareholder requests in the name of public good. Which is nice! In general I feel like social media is in the perfect spot for a huge shakeup as display ads breathe their last breath. Even if Google wins/draws out its Display Ads antitrust case and successfully implements some new interest-tagging system, I think anyone with a calculator and a newspaper subscription can read the leaves at this point; people are concerned about their data, and the money it generates is peanuts compared to more traditional advertising schemes. All of this is of course not even mentioning what I think intuitive algorithms will do (cynical or no, there’s lots of credentialed scientists saying that AGI (!!) is within reach in the coming decade, if not the coming few year). All that to say: I feel like they can find a way to make it work. Revenue doesn’t need to be as high anyway if you a) don’t have 1000 devs optimizing Display Ad A/B tests all day, and b) have the support of the open source community. reply yokem55 20 hours agorootparentIf they can get ~100k subs to a $10/mo premium service similar to discord nitro, they are probably close to breaking even at the current scale and ops methodology. Which seems feasible. reply anacrolix 20 hours agoprevhttps://github.com/anacrolix/btlink reply erlend_sh 19 hours agoparentI guess pkdns is a newer, actively maintained version of the same thing? https://github.com/pubky/pkdns reply neuroelectron 18 hours agoprevWhat's the license for the Bluesky data btw? Is it something free to mirror and train LLMs on? reply anon7000 17 hours agoparentSo the ToS explicitly says Bluesky does NOT own your data. However, data on AT Proto is fully public and it’d be trivial for someone to extract the data for AI to train. For example, this app shows you entries hosted on the protocol: https://atproto-browser.vercel.app/at/nytimes.com reply phs318u 18 hours agoparentprevBased on https://bsky.social/about/support/tos#user-content , I would answer yes. While it's not expressly called out (permitted or forbidden), my reading of the above would indicate that it's not forbidden per se, and probably permitted (\"Modify or otherwise utilize User Content in any media. This includes reproducing, preparing derivative works, distributing, performing, and displaying your User Content.\"). I believe training an LLM falls under \"utilize\" and \"preparing derivative works\". reply jamilton 13 hours agorootparentThat's about your user content, not others'. reply slowhadoken 19 hours agoprevWhenever I hear about Bluesky I think about Jack Dorsey quitting their board and asked people to stay on Twittet/X. https://amp.theguardian.com/technology/article/2024/may/07/j... reply crabmusket 18 hours agoparentWhat do you think about it? What I remember about that whole affair is that I'd really respected Jack for starting Bluesky, allowing it to be independent of Twitter (and Jay deserves a heaping of credit for pushing that!), and then losing that respect when he seemed to totally misunderstand what Bluesky had gone on to achieve. https://www.techdirt.com/2024/05/13/bluesky-is-building-the-... Jack was pushing Nostr at the time which... seems ok if you're into that. But his arguments in his interview with Mike Solana really didn't make sense to me. reply strogonoff 17 hours agorootparentBluesky’s attitude seems logical and their reasoning aligns with my thoughts exactly. If techdirt’s article is to be believed, Dorsey’s departure has to do with going from an extreme to an extreme—from a traditional social monolith to a pure protocol—whereas Bluesky chose to pursue not only the protocol, but also “the app” as the face of that protocol for the ordinary user, and let’s face it: the ordinary user does not really care about protocols. My speculation about him suggesting people “stay on Twitter” is that Nostr (which he apparently is invested in now) and Twitter are orthogonal, so there is no conflict there, but Bluesky competes with both. Not a Bluesky user (the invite-only period has put me off for a while), but if they do not compromise on the protocol part (and there are no shenanigans unfolding, who knows, maybe Dorsey found something) their attitude seems to me to be the most reasonable for a mainstream social platform. reply apitman 10 hours agorootparentWhat's your issue with invite-only periods? Is there a better way to throttle signups while you scale a system early on? reply wesleytodd 4 hours agorootparentBut if you use web scale tech you can scale to infinity on day one right? :eye-roll: reply irusensei 9 hours agorootparentprevThe invite-only system established the main Bluesky instance as a big circlejerk. It worked with Orkut back in the day where the internet was new and untainted by culture wars. Bluesky is lefty twitter now and I want no business with that platform. reply tomrod 3 hours agorootparent> Bluesky is lefty twitter now and I want no business with that platform. I love hearing people say this, because in reality Bluesky covers most of the political dimensions one wants to subdivide a population by except the most toxic of participants. Also, most of the academics have moved to Bluesky because Twitter became toxic / suppressed speech dramatically and at the whims of one Mr. Musk. As per usual, where the \"lefties\" are the \"righties\" follow (to use the parlance of the prior comment) be is social media, good policy, you name it. Plenty of conservatives are there, such as Lincoln project folks, right libertarians, and even National Review & Reason IIRC. But I guess these folks don't count these days as conservative (despite definitionally being so, just not aligned with modern US Republican policy planks)? Not sure. Anyhow, I'm enjoying Bluesky for what it is -- a new social media platform that isn't fully encumbered by bots and nonsense for a bit. reply natoliniak 2 hours agorootparent> Twitter became toxic / suppressed speech dramatically But what kind of speech is supressed nowadays on X? what about Bluesky? does Bluesky not supress any speech? reply BryantD 56 minutes agorootparentSure. CSAM. Meanwhile Twitter is now openly suppressing links off-site. For financial reasons rather than ideological ones (although the latter may also be occurring). reply rsynnott 8 hours agoparentprevI mean, honestly, losing Dorsey was probably a big part of its success. reply la64710 21 hours agoprevI think the AT protocol is versatile in that users can acces each others data once authenticated without any centralized service (granted the aggregators and some other things may still be centralized). reply jazzyjackson 21 hours agoparentIs there any auth necessary to pull data from a PDS? I know the main relay is a public firehouse so I would be surprised, but maybe the PDS can put relay servers on an allowlist? reply anon7000 17 hours agorootparentAs far as I can tell, all content on ATProto is fully public without auth reply unshavedyak 16 hours agorootparentDoes it federate or anything? Wonder what up to date summaries exist of it’s capabilities reply jazzyjackson 15 hours agorootparentIf by federate you mean \"is stored on content addressed, signed merkle trees that can be mirrored and served from more than one domain\" then yes Also it's uh, atproto.com reply irusensei 9 hours agoparentprevSo the recent push to artists to move there to protect their rights against AI training is not only false but a trap since anyone can point their cannons to train data on Bluesky. reply tr1ll10nb1ll 22 hours agoprevunrelated probably, but it made me realize how I don't really see Hugo/Jekyll type websites anymore. reply hipadev23 21 hours agoparentHow do you even know? Don't those both just generate static html? reply tr1ll10nb1ll 21 hours agorootparentFooter. also Jekyll/Hugo sites use generator so you can mostly find it in the meta generator tag. Next.js sites are also a super easy find like this. reply veqq 21 hours agorootparentYou can trivially remove it e.g. `disableHugoGeneratorInject = true` in `config.toml`. reply thesdev 21 hours agorootparentprevIt says \"Powered by Hugo\" at the bottom of the page. reply Zambyte 21 hours agorootparentDepending on the theme. reply rahkiin 21 hours agorootparentI build my own themes and don’t include that either reply mikae1 21 hours agorootparentSame here reply teitoklien 21 hours agoparentprevI build my own with Jinja2 templates my custom python script + mistune library to parse markdown to html, and a YAML file in similar format to Hugo (the previous generator i used to use) I found building my own custom one with python3, much more freeing in all sorts of interesting ways, I also exposed the static site generator with a FastAPI based API to auto build my website from my notes, my cooking recipes, database records, financials, git commits, etc to build me a private protected website (via nginx auth) from anywhere, whether via sending a text message to my telegram bot, or running a Shortcuts command on my iPad, or just directly running a command from my terminal. It took barely a day to setup, and allows me to run interesting custom extensions in all sorts of interesting ways, and builds me a personal website curated to my interest, where the primary viewer is supposed to be me. and it exposes a public barebones website with barely any content for everyone else. One of these days I think i’ll expose more of it to the world. reply zahlman 21 hours agoparentprevI see plenty of blogs generated from Markdown with tools like that. Has something overtaken Hugo and Jekyll in that space? reply aryonoco 16 hours agorootparentIf you like JS/TS, then Astro. I maintain a blog on Hugo but also host a couple of Astro ones. I think Hugo is great but to my eyes at least Astro has more active development behind it, and I also enjoy it more (probably because I know Typescript more than golang) reply dangerlibrary 21 hours agoparentprevI just use mkdocs for everything. reply dv35z 19 hours agorootparentHave you found a decent bare bones starter theme? I've been using MkDocs Material, and I find the theme too complicated (HTML etc) - hoping to find a super simple one that looks decent - plain - and is a good base for theming / styling. Thanks & take care. reply dangerlibrary 14 hours agorootparentI use the readthedocs theme: https://www.mkdocs.org/user-guide/choosing-your-theme/#readt... Not sure if that fits the bill for you, but I like it. reply leoc 21 hours agoprevhttps://bsky.app/profile/leocomerford.bsky.social/post/3l7v6... To help the hard of clicking, this time I have pasted it all for you: Leo R. Comerford ‪@leocomerford.bsky.social‬ Why was it decided not to build on any existing content-addressable networking system (IPFS or whatever)? November 1, 2024 at 12:39 PM ‪Leo R. Comerford‬ ‪@leocomerford.bsky.social‬ · 23d (Not implying that this was the wrong decision, it’s a genuine question.) ‪dan‬ ‪@danabra.mov‬ · 23d actually not sure i can answer this well. paging @bnewbold.net or maybe @why.bsky.team (who worked on IPFS btw) ‪dan‬ ‪@danabra.mov‬ · 23d my guess is that we’d want data hosting to be under direct control of the user (same as web hosting) rather than peer-to-peer, want instant deletion/edits at the source, need ability to move to a different host or take content down, need grouping into collections. not sure how much IPFS could adapt ‪dan‬ ‪@danabra.mov‬ · 23d we do use some pieces from IPFS through (aside from the actual peer to peer mechanism) ‪bryan newbold‬ ‪@bnewbold.net‬ · 4mo you can basically ignore it, we don't use \"IPFS\" proper anywhere. there are strong social connections, and we borrow some tech components like CIDs (flexible hash/digest syntax) and DAG-CBOR (more-deterministic subset of CBOR, good for signing+hashing) ‪ Bumblefudge‬ ‪@bumblefudge.com‬ · 1d yeah this is all accurate. bluesky remixed a lot of IPFS components and patterns in interesting ways, but the monolithic global IPFS network (with chatty DHT distribution) wouldn't make sense here, BS made an infinitely more efficient/performant distribution of bytes tailored to its use case. ‪ Bumblefudge‬ ‪@bumblefudge.com‬ · 1d FWIW the IPFS foundation is working on making IPFS more modular and easily remixed for future BlueSkies, but it's a big task decomposing the monolith and reorienting the documentation and ergonomics... [a second reply to the first skeet:] ‪Uai‬ ‪@why.bsky.team‬ · 23d As far as im concerned (and i led ipfs development for a number of years) we are using ipfs, just a specific streamlined implementation of it. All your repo data can be imported into an ipfs node and addressed via cid ‪ Uai‬ ‪@why.bsky.team‬ · 23d We dont use libp2p because for a consumer mobile app we didnt want to futz with nat traversal and connectivity and the like, but its definitely possible to build a p2p version of bluesky reply echelon 19 hours agoparent\"skeet\" is such a terrible term for this. It's like mastodon \"toot\"s. Using bodily functions as core infra terminology is off-putting and feels like a bit like a juvenile boy's club. I get that some people find it funny, but it alienates people. We should just call these \"posts\". Same thing with names like CockroachDB and GIMP. reply xeeeeeeeeeeenu 19 hours agorootparentThe official Bluesky FAQ says this: >What is a post on Bluesky called? >The official term is “post.” https://bsky.social/about/blog/5-19-2023-user-faq reply singpolyma3 17 hours agorootparentprevEevn better: call them tweets. That's what they are. reply leoc 19 hours agorootparentprevSure, whatever: I had certainly given it approximately no thought in this case, and my personal investment in 'sk**t' is zero. I'd edit my post but I seem to have hit the timeout. I will also say that I don't think this is the most interesting or on-topic thread to pull on from my comment. reply mjmsmith 3 hours agorootparentprevHuh, I thought it was a reference to shooting: fling your hot take into the sky in front of an audience ready to blow it to smithereens. reply bbor 18 hours agorootparentprevHard agree -- this one is especially bad because it's gendered. We'll see what happens, but I'd put my money on \"post\" winning out. There's some people on Bluesky who feel absurdly strong about this because of the history (the CEO asked them not to use it so they used it more often as a joke), but they're simply outnumbered already. Such is exponential growth... reply bargainbot3k 21 hours agoprevnext [10 more] [flagged] steveklabnik 21 hours agoparentIn what sense? reply bargainbot3k 18 hours agorootparentnext [9 more] [flagged] noirbot 17 hours agorootparentWhat is there to respond to? \"This thing may happen at some point in the future\" isn't insight or commentary. I can formulate a response, but it's already required more thought and effort than you seemed to have put into your comment. Engagement farming and bait isn't what HN is generally for. reply bargainbot3k 16 hours agorootparentnext [4 more] [flagged] noirbot 15 hours agorootparentI just cannot imagine being this upset about someone else doing something they enjoyed that hurt no one. This is pure gatekeeping at its finest. It's a cool use of technology! Maybe this is Bobby's first API. Why the need to tell Bobby that you're too cool to appreciate it? As the opening of the OP points out, this has very little to do with ${new_propaganda_platform} as you so dismissively put it. They're self-hosting their site on a protocol not intended to exactly do that! That's cool even if you've been able to do that since whenever you discovered you could do that. They don't seem to be doing any of the things you're throwing at them as negatives. They're not saying this is the future of the internet or something everyone should do or forcing all their friends onto it. It's just an interesting demonstration of the underlying tech of a protocol and what you can do with it. If you seem to think people talking online about their joy about technology and the things they can do about it is \"shit spewing\" onto your beloved \"WWW\" then I'm not sure why you're here. You definitely don't seem like you actually read any part of the OP you're \"shit spewing\" all over. reply bargainbot3k 14 hours agorootparentnext [3 more] [flagged] blackqueeriroh 12 hours agorootparentThis is a pretty pitiful comment. It fails (again) to actually make any salient points (what “propaganda platform” are you talking about? How did you reach that conclusion? Based on what?) and instead just does the “anti-interest negativity dance” that so many edgelords are into these days. reply naught0 4 hours agorootparentIt sounds like they don't even understand Bluesky or the OP. OP is certainly not recommending hosting serious websites from Bluesky's arbitrary blob storage, as though it's the \"hot newness.\" This was a fun blog post exploring something that resembles a hole in Bluesky's defenses if anything. reply ziddoap 18 hours agorootparentprev>Not sure why my parent comment was flagged. I guess when you can’t formulate a response, you flag and downvote? Is that the HN way? It was a vague and negative one-liner, with no indication of what you were insinuating or why you think that way, from a brand new account. If you spent 30 more seconds to expand on what history you were referring to and why you think history is repeating, it would not have been flagged. reply bargainbot3k 18 hours agorootparentAre you a mod/admin here? reply ziddoap 18 hours agorootparentNo, just someone who spends too much time here and am familiar with the trends. reply dgfitz 16 hours agorootparentprevI’d have at least said something like “it reminds me of app.net, but with a lot more traction” or something to poke at a conversation. reply paulvnickerson 4 hours agoprevnext [17 more] [flagged] nerdjon 4 hours agoparentI would be very curious how exactly this is being said and if it is just simply stating an \"opinion\" or if it is being used as a way to attack people and purposefully start a fight. If it is the later 2, than them being \"eager\" is a good thing since that just feeds to toxicity and is a major reason that people have been pushing to move away from Twitter in the first place. Even the first one I can understand since I really struggle to figure out why you would feel the need to repeat this if it was not an attempt to stir up an argument. > I would be very reluctant to store anything important there. Regardless of the reason, you should always be reluctant to store anything important on a platform you don't own. Focusing on this particular topic as the reason however is really just trying to start an argument that does not need to happen. reply aniforprez 4 hours agorootparentObvious trolling attempt aside, on the topic of uploading files to third party platforms, people should have really learned their lesson when uploading files to Discord and using that as a CDN and Discord completely killing that and hundreds of thousands of links by adding timeouts to the files hosted on their servers. It's really annoying because there are a bunch of mod servers that refuse to put their files anywhere else and so many links were completely lost to the ether. Now you need to join so many servers just to get files and it gets very annoying very fast. Please just use a file hosting solution or make a website. reply nerdjon 4 hours agorootparentI actually did not know about what happened with Discord. I mean I think its still a cool concept but no reason to rely on it. Especially when its so easy and cheap to store something in S3 and stick a domain in front of it for example. reply aniforprez 4 hours agorootparentThey said in their official statement[1] that it was to \"block malware\" but clearly they did not want to serve file traffic off-site. And yes I am very much in favour of using S3 or at least some file hosting service to dump the files where it's their job to do so. I am not sure why they were all using a chat application's file hosting as a CDN with gleeful abandon. [1] https://www.bleepingcomputer.com/news/security/discord-will-... reply beanjuiceII 4 hours agorootparentprevwhats wrong with an argument? reply coldpie 4 hours agorootparentSome people want to live their lives without having to justify their existence to strangers every time they appear in a public space. It's exhausting. There are plenty of spaces where you can have those arguments. It's OK to have spaces where those kinds of arguments are not welcome, too. reply aniforprez 4 hours agorootparentprevThis is not an argument or a discussion. That would require two parties willingly engaging. This is someone trolling and simply being hurtful/aggressive for kicks. I don't know if the BlueSky moderators are banning such accounts but it's an insta-block from me. reply nerdjon 4 hours agorootparentprevThere is nothing wrong with an argument, but as the other person said this is not really being posted just for the sake of having an argument. On topics like this neither side cares what the other has to say because they have made up their mind. This isn't like saying \"Mexican is the best food\". Which sure may get a bit heated but at the end of the day is a personal opinion argument. Attempting to \"argue\" about someone else's life, who's existence doesn't impact you in the slightest, isn't an argument that deserves to happen. At the very least not in a public space and not without expecting the repercussions of it happening. reply diggan 4 hours agoparentprev> Bluesky has demonstrated a strong eagerness to censor content based on political ideology Can you demonstrate where/when this has happened? I've been on Bluesky since 2023 and yet to see any concrete examples of people getting banned for saying anything like that. I've seen plenty of examples of users getting a ton of pushback from others when saying something like that, and ending up on block lists that others can (optionally) subscribe to, but never seen anyone permanently banned over it. reply enterpriss 4 hours agoparentprevWould be curious if you have any sources or publications to backup this claim? reply code_for_monkey 4 hours agoparentprevthats because thats a dogwhistle that people post to start fights. Its the posting equivalent of an 11 year old saying 'im not touching you!' and its good to ban it. its annoying. reply altcognito 4 hours agoparentprevBluesky is decentralized and has no central algorithm, so I'm not sure where you're getting this misinformation from. I'm happy to be shown otherwise. reply davexunit 3 hours agorootparentWhile I definitely don't agree with the GP here, Bluesky is not decentralized in any meaningful way, but they aspire to having a \"credible exit\" if Bluesky the company falls into the wrong hands. https://bsky.app/profile/dustyweb.bsky.social/post/3lbkecsk3... reply wyager 17 minutes agorootparentprevBluesky is not decentralized; they have tons of centralized infrastructure, including all the identity management stuff. reply verdverm 4 hours agorootparentprevA PDS can refuse to host someone's data, an App View can refuse to serve content or specific users. But, being decentralized, they cannot \"remove them from the platform\" depending on how we define this phrase Being removed by Bluesky can certainly happen, in the sense that most people who are unaware ATProto is different from what came before, think about these things. I too would like to see such claims backed up. Too many flags being planted to stake out ideological territory... reply TheHypnotist 4 hours agoparentprevIf what you are saying is even true (a quick google showed it's not), this seems like it's likely a specific case of moderation and not censorship. reply layer8 5 hours agoprev [–] Someone implementing a file hosting service on top of Bluesky would explain a steep growth in user accounts. ;) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The AT Protocol, used by Bluesky, supports hosting via Personal Data Servers (PDS), showcasing its flexibility beyond intended uses.- Content on Bluesky is organized into records and blobs, with blobs being larger data like media, which must be uploaded before being referenced in records.- The protocol's extensibility allows for creative applications, such as hosting websites, potentially leading to new use cases in the future."
    ],
    "commentSummary": [
      "The website hosted on Bluesky has initiated discussions about its potential uses, including hosting RSS feeds and storing data like DOOM WADs, as well as concerns about content moderation and legal issues.",
      "Comparisons are being made to past platforms like MySpace, highlighting the AT Protocol's public nature and its potential for decentralized data storage.",
      "Users are divided, with some skeptical about Bluesky's moderation capabilities, while others view it as a promising new platform."
    ],
    "points": 636,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1732481013
  },
  {
    "id": 42233524,
    "title": "How I configure my Git identities",
    "originLink": "https://www.benji.dog/articles/git-config/",
    "originBody": "How I configure my Git identities Note: I've had this post drafted for 3 YEARS!!! It's finally time to publish it. I like to mess with my dotfiles and every so often, I find out about a new way to do things and I spend more time than I should learning how to use it. A few years ago I learned about includeIf for including specific files if some condition was met for git. The example that I first saw was doing: [includeIf \"gitdir:~/code/**\"] path = ~/.config/git/personal [includeIf \"gitdir:~/work/**\"] path = ~/.config/git/work So that ~/.config/git/personal is only included for git directories under ~/code and ~/.config/git/work is only included for directories under ~/work. The contents of those included files varies but usually it contains your git identity, signing keys, etc. Here's an example of what that could look like: [user] name = benji email = benji@work.com signingkey = ~/.ssh/work.id_ed25519.pub That works pretty well but I usually organize all my code in ~/workspace regardless of whether its personal, work-1, work-2, etc. I wanted to be able to configure git depending on where that repo actually lives instead of where the directory is in my machine. Then I found out about hasconfig:remote.*.url:! This makes it so that I can configure git conditionally if the given remote URL exists for that directory I'm currently working in. A few examples of what I do is: [includeIf \"hasconfig:remote.*.url:git@github.com:orgname/**\"] path = ~/.config/git/config-gh-org [includeIf \"hasconfig:remote.*.url:git@github.com:*/**\"] path = ~/.config/git/config-gh [includeIf \"hasconfig:remote.*.url:git@gitlab.com:*/**\"] path = ~/.config/git/config-gl [includeIf \"hasconfig:remote.*.url:git@git.sr.ht:*/**\"] path = ~/.config/git/config-srht Now if I'm in a directory where the remote matches github.com:orgname/** it would use ~/.config/git/config-gh-org, otherwise it uses the general config file for any other GitHub repo. While that handles git identities, I still need to configure SSH keys separately to be able to pull and push to remotes. The simple version of my ~/.ssh/config looks like this: Host gitlab.com Hostname gitlab.com User git IdentityFile ~/.ssh/gitlab.id_ed25519 Host github.com Hostname github.com User git IdentityFile ~/.ssh/github.id_ed25519 The only problem with this is that in order to use a different IdentityFile for the same Hostname so that I could use a different key for repos under github.com/orgname, I'd have to use a different value for Host. So in my case I would add the following to my ~/.ssh/config: Host gh-work Hostname github.com User git IdentityFile ~/.ssh/work.id_ed25519 Finally, to use that Host when I'm looking for a repo in github.com/orgname, I would add the following to my git config: [url \"gh-work:orgname\"] insteadOf = git@github.com:orgname So when I clone, pull, or push a repo that's under my work's org account I can do: git clone git@github.com:orgname/project and insteadOf would replace github.com:orgname with gh-work:orgname so that it uses the right info from my SSH config. It's a neat trick which I saw referenced in this article. Are there any issues with this approach? Is there a better way to do this? I'm not sure so please let me know as I'd love to learn and I'll update this post accordingly. References https://fundor333.com/post/2021/advance-git-config-and-ssh-config/ https://www.kenmuse.com/blog/ssh-and-multiple-git-credentials/#git https://garrit.xyz/posts/2023-10-13-organizing-multiple-git-identities https://stevenharman.net/configure-ssh-keys-for-multiple-github-accounts Posted in on Nov 22, 2024 bnj.pw/b5_90 dev dotfiles git Interactions ❤ To reply to this post, send a Webmention or contact me.",
    "commentLink": "https://news.ycombinator.com/item?id=42233524",
    "commentBody": "How I configure my Git identities (benji.dog)387 points by 8organicbits 13 hours agohidepastfavorite91 comments powersnail 11 hours agoI do something similar, but instead of `insteadOf`, I just clone the repo with `gh-work:org/repo`, and in the git config: [includeIf \"hasconfig:remote.*.url:gh-work:**/**\"] path = ~/.gitconfig.d/gh-work.inc So, any git repo cloned with the ssh identity defined under `gh-work` will take on the config of `gh-work.inc`, which includes the git identity, and also the same signing key as in the ssh config. Essentially, the name `gh-work` becomes the distinguishing element in both my ssh identity and my git identity, and I find this easier to think about. reply TeMPOraL 6 hours agoparentThank you. The article left me uneasy, in OCD sense, about the solution having more degrees of freedom than it needs. I was wondering how to trim it down to one runtime parameter, and yours is an elegant way to do it. reply montroser 7 hours agoprevI used to work at a startup with a character who would set his identity to be random fairytale-sounding nonsense, changing every day. So his commits on Monday would be attributed to Mr. Bunnymann, and Tuesday would be Doctor Funtime, etc. It was super unhelpful when trying to do version control forensics. But if I'm being generous, I think maybe he was trying to remind everyone that anyone can put anything in their identity config, and we shouldn't trust whatever is in there for all that much. reply necovek 6 hours agoparentIf yours was a \"blameless culture\", when you did \"version control forensics\", you didn't really care about who did it, but when it happened and around what other changes (to understand the broader context)? Right? (Though obviously, it helps to know who did something so you can ask them directly if they remember more details, or so you know what to expect when it comes to style and expertise :) Anyway, if you simply[1] require commits to be signed with GPG, and enlist what GPG identities are acceptable, you are pretty much set (and you can instead rely on the signature instead of the author/committer metadata to identify the actual author). [1] \"Simply\" and GPG signing don't always go hand-in-hand, I admit. reply Ferret7446 6 hours agoparentprevYou should trust it as much as you trust any document written/signed by your employees. Which is to say, if you can't trust your employees to not properly identify their commits, you should fire them. reply helloooooooo 6 hours agorootparentNo, the previous commenter is saying that you cannot trust the identity provided in commits period. This has nothing to do with trusting employees, rather placing trust in the identity in commit. reply theamk 5 hours agorootparentThis is true in general internet, but workplaces are normally more high-trust. If one needs to guard themselves against hacking by their co-worker, they have less time and energy to do actual work. So a fiction character is maaybe OK, as long as it is clearly fictional name and no one else in the company does that; but other stuff, like actually impersonating other co-workers would be very bad, and should eventually leave to firing. reply spacemanspiff01 7 hours agoparentprevDid he use the same signing key? (If we are being generous) reply kevindamm 6 hours agorootparentI don't think you can -- the key's identity needs to match the name/comment/email it was generated with. You would have to regenerate after every name change to have them all verified (and keep them all in file with the got server afterwards, too). reply tecleandor 6 hours agorootparentI'd say that in general it verifies it with the email, but it depends. I just did a test with four commits with a signature matching both on user and email, only on email, only on user, and in none of them and: From GitHub, it validates signatures with the email registered in the commit: If the signature matches the key registered for the GitHub user with that email address, it says \"Verified\" in a green box. If it doesn't , it says \"Unverified\" in a yellow box. So GitHub \"Verified\" two commits: the one that matches all the fields and the one that only matches the email. From git CLI, it depends on your configuration. If you do a `git log --show-signature` at first it will complain with `error: gpg.ssh.allowedSignersFile needs to be configured and exist for ssh signature verification`. You need to set up a file with your trusted ssh signatures. Once you set that up, it will verify ALL correctly signed commits, even if they don't match the commit email address. Seems like the signature and the commit can have different emails, so to speak: \"commited by fake@email.com and signed by real@email.com. The signature is valid by real@email.com\". Example I did, changing the email addresses: git show --show-signature 11906e1 commit 11906e14155ae08b7e7e23f26aa9c04913ade5dd Good \"git\" signature for good@email.com with ED25519 key SHA256:9uU6+7pNNzwVEKTecpJE4Bmm2WXaqZXMZRLe9rJZ0ZY Author: fake nameDate: Mon Nov 25 13:36:28 2024 +0100 reply TeMPOraL 6 hours agorootparentprev> needs to match the name/comment/email Is that \"/\" an \"and\", or an \"or\"? I'd expect only e-mail has to match, leaving you free to change the user name. reply edejong 7 hours agoparentprevPeople paid him for such nonsense? reply 7bit 7 hours agorootparentThe service came at no additional cost reply est 6 hours agoparentprevgit has built in support to separate author and committer I believe he/she is just changing the author property. reply er453r 9 hours agoprevOne even-better approach IMHO Just keep a .gitconfig in your HOME with aliases for your identities. Then just after initializing/cloning the repo do git config-company or git config-personal er453r@r7:~$ cat ~/.gitconfig [user] useConfigOnly = true [alias] config-personal = !echo CONFIG-PERSONAL && \\ git config --local user.email 'personal@email.com' && \\ git config --local user.name 'personal' && \\ git config --local core.sshCommand 'ssh -i ~/.ssh/id_rsa_personal' config-company = !echo OLD CONFIG-COMPANY && \\ git config --local user.email 'official@comapny.io' && \\ git config --local user.name 'Name Surname' && \\ git config --local core.sshCommand 'ssh -i ~/.ssh/id_rsa_company' reply flumpcakes 7 hours agoparentHow would you do the initial clone without the correct ssh config to begin with? I think the benefit of the article's method is that any clone from their org will just work. reply er453r 5 hours agorootparentYou are right - that first clone has to be manually preceded by GIT_SSH_COMMAND=\"ssh -i ~/.ssh/id_rsa_personal\" - but after this you just configure the repo and forget about it. I just like this workflow better since it is totally directory/remote agnostic (compared to the article). Just use whatever suits you best :) reply nixosbestos 1 hour agorootparentThe same exact config you'd have to replicate for the OP's solution is what you'd have to replicate as well. It also means your config is semi-copied into every repo instead of being centrally managed. This is like the worst of all options, idgi. I'm sorry, I don't want to be mean but this has got to be the worst way Ive seen someone try to solve this. I want to cry skimming it. Why would anyone do this and think it's simpler? Wew, gotta just leave this one alone. reply kreetx 6 hours agorootparentprevI have something like the parent suggests and yes, the article's idea is better because you don't need to do anything manual nor remember to run your own command at all. reply metabeard 2 hours agoprevI prefer to split work and personal repos into ~/dev for work and ~/src for personal. # file ~/.gitconfig [includeIf \"gitdir:~/src/\"] path = /Users/metabeard/.config/git/.gitconfig-personal [includeIf \"gitdir:~/dev/\"] path = /Users/metabeard/.config/git/.gitconfig-work and # file .config/git/.gitconfig-personal and .config/git/.gitconfig-work # both are very similar with different email and signingkey [user] name = Meta Beard email = email@metabeard.me signingkey = ssh-rsa xxx== [gpg] format = ssh [gpg \"ssh\"] program = \"/Applications/1Password.app/Contents/MacOS/op-ssh-sign\" [commit] gpgsign = true reply est 12 hours agoprevyou don't have to mess with ~/.ssh/config Just put this in your ~/.gitconfig (or ~/.config/git/personal as in the article) [core] sshCommand = /usr/bin/ssh -o IdentitiesOnly=yes -i ~/.ssh/IdentityFile2 -a This makes submodules easy without the `insteadOf` reply duskwuff 11 hours agoparentAnd if you have more than one SSH identity? reply est 11 hours agorootparentYou can also put that in your includeIf confs. I updated the parent comment reply dgfitz 11 hours agorootparentprevSounds like a different problem. reply lijok 7 hours agoprevI always strongly advise consultants to use a separate machine for work, or at the very least a separate OS user. You’re risking putting yourself in a whole lot of trouble by using a personal machine for work. reply necovek 6 hours agoparentUsing a \"personal machine for work\" is a very wide gamut of situations (eg. at one remote-first company, we were expected to provide our own laptops, and got extra money every 2-3 years to buy a new one, but they were always our \"personal\" laptops even if the company contributed to paying them off; or what if you are a temporary contractor; or...). Care to elaborate in what circumstances is it a problem and why? Edit: I mostly asked the parent poster to provide more context and avoid general assertions like \"a whole lot of trouble\". Risks are indeed tangible, but if we are unable to enumerate them, we are mostly spreading FUD instead of educating. reply lijok 6 hours agorootparentPersonal machine as in a machine that you use for anything other than work for that particular client. The same goes for putting anything personal on a company issued device, such as signing into your private email. It is a problem in all circumstances. The problems may not always manifest, but if they do, you’ll be in deep trouble. Problems range from the mild; company has mandatory tooling that takes control of your machine. To the extreme; offices get raided and equipment seized indiscriminately. General assertions are fine. The exercise of whether to follow them up with research is left as an exercise to the reader. reply Sardtok 6 hours agorootparentprevMixing personal and work data in the same directories on disk can be an issue. Requires extra work to cleanly separate private stuff and confidential work stuff. reply necovek 6 hours agorootparentThis is still very general, and in opposition to the previous advice. A solution to this seems to be \"use separate directories\", not \"use separate machines\". reply sshine 5 hours agorootparentUsing separate directories does not guarantee proper deletion. reply necovek 5 hours agorootparentUsing separate laptops does not guarantee proper deletion. Not sure what your point is? (Contractual terms between an employee/contractor and employer/company is what ensures there is no abuse for the most part) reply sshine 5 hours agorootparentI should say: Using separate directories makes improper deletion likely. Using separate computers with full-disk encryption and shredding procedures makes proper deletion a happy path. It's not that you cannot properly isolate environments on a single computer. It's that a single computer is, unless you're a Qubes/BSD/Hypervisor fanatic, not very isolated at all. So if/when your personal computer gets compromised because of a browser zero-day, your work's intellectual property is potentially compromised. When you combine that with likely not deleting files properly (or at all), the window of opportunity for IP theft is much bigger. When you further add the complete unlikeliness that former employees/contractors will report that their personal computers were compromised after having neglected to properly purge your intellectual property, the case for buying your employees/contractors dedicated machinery becomes a no-brainer. Simply from a corporate risk perspective. It's not a practical problem, but a principal + legal problem. reply necovek 5 hours agorootparentI fully agree it's a legal problem, which is what my point was from the beginning — depending on the circumstances, it might apply to you or not. Companies both have to have a set of \"processes\" in place for legal/compliance reasons, and an employee is liable if they do something that's outside the recommended practice (like using a personal device when forbidden by such policies). Still, the focus should be on liability and ensuring compliance with legal terms, and an employee needs to make sure they do that. In some cases, that's easier done with a separate computer. In others (when there is no direct spelled-out requirement), downsides of using a separate device outweight the benefits of making compliance with legal terms easier. As a side note, a browser zero-day is probably even more likely to target work computers, so that example is pretty bad — company data remaining on personal devices by accident is where the problem really is. reply sshine 6 hours agorootparentprev> Care to elaborate in what circumstances is using a \"personal machine for work\" a problem and why? When you stop working for an employer/customer and you are legally required to purge all files. Having everything work-related on a dedicated machine makes purging all files very easy. Not having everything work-related on a dedicated machine makes purging all files questionable. reply necovek 5 hours agorootparentOk, so one circumstance is when there is a \"legal requirement to purge all files\". That's certainly not \"always\" and not always as hard: one of my jobs was at an open source company, and there are plenty of those to go around these days; as a consultant, you may start with some base work to build off of that you keep the rights to as well... This also assumes you never-ever used a personal device to access any of them either (they might be in caches or Trash/Recycle Bin) — and I agree that to satisfy such a legal requirement, you probably don't want to be using a personal device to access them at all. Keeping things separate has some upsides, but also some downsides (multiple devices to lug around) — depending on their situation, everybody should choose their own compromise (granted, some engagement contracts will make that choice for you). reply sshine 5 hours agorootparentI've personally come to be very happy with hardware isolation as a method of mental compartmentalization. E.g. choice of computer dictates choice of activity, I won't accidentally work on something when I'm not supposed to. I've had paid-for open source gigs, and I have a bunch of open source work spread out on a bunch of machines. Downsides are: - The bag gets heavy when I have multiple events for separate customers/events on the same day - For stuff that is shared between computers (e.g. open source projects), I can forget to git push I've tried to put my machines on the same VPN for some convenience wrt. file sync. Fortunately, the most locked off machines never need for other computers to connect to them. And yes, this came as a customer requirement, but I've decided to grow with the choice. I don't trust process isolation on a single computer very much. reply kroltan 6 hours agorootparentprev- Endpoint monitoring software may compromise more than it strictly needs to; - If you're a contractor, risk of leaking other clients' assets (running `tree` in the wrong folder while screensharing or more subtle variations); - Shredder policy, done with the work = destroy hardware (though I don't think companies with shredder policy would incentivise personal laptops, you never know) reply necovek 6 hours agorootparentIf it's a personal laptop, I would assume there is no \"endpoint monitoring software\" installed. When it comes to \"assets\", companies make a big fuss about leaking them, but in reality, it's totally irrelevant. I.e. witness Windows OS source code being leaked: Microsoft wasn't affected at all. Leaking short/mid-term plans would probably have a bigger effect (abuse on the stock market, beating a competitor to the market on their big bet...). reply kroltan 3 hours agorootparentYou would assume wrong, many (asshat) employers require them, so much that I actually have to screen that kind of sillyness when interviewing. Works a treat to filter out toxic workplaces, but exists nontheless. As for leaking assets, maybe it does not affect the company at large, but that literally does not matter for this discussion. It will definitely affect your relationship, most often negatively. And in any case, my usage of assets was clearly general, substitute the example for \"clicking on the wrong stored tab while screensharing\" can just as well lead you to leaking a plan. reply lijok 6 hours agorootparentprev> When it comes to \"assets\", companies make a big fuss about leaking them, but in reality, it's totally irrelevant There’s no milder way to put this; you’re delusional. reply necovek 5 hours agorootparentThere are certainly \"milder ways\" to put it, but the tone one uses is certainly on the author. For example, please let me know of any one's company leaked source code and how someone has used that to their advantage and become amazingly successful in the same market? reply lijok 5 hours agorootparentWhat does this have to do with work device management? Are you seriously suggesting using a personal device for work, despite the asset leakage risk, and relying on \"it doesn't matter\" as recourse if that risk were to materialize? reply bobek 10 hours agoprevI've been using `includeIf` with directory for ages (https://www.bobek.cz/til/git-identities/), the `hasconfig:remote` is really neat. And it also works when cloning the repository. reply guthriej 9 hours agoprevThank you for this! I have exactly the same problem and was waiting for the solution to present itself, which it now has. Aside: I use NixOS with home-manager (on linux and mac), which makes this trivial [1]. Added the following lines to my home-manager config: programs.git = { enable = true; ... includes = [ { condition = \"hasconfig:remote.*.url:git@github.com:/**\"; contents = { user.email = \"\"; }; } ]; } [1]: https://nix-community.github.io/home-manager/options.xhtml#o... reply SpaceNugget 7 hours agoparentThat certainly looks less trivial than writing it directly in your .gitconfig file. It's the same condition and setting as what's in the article, but now with a build/templating stage and a new programming language to learn with unusual syntax. reply necovek 6 hours agorootparentWhile I don't use NixOS or home-manager, I would imagine this provides some extra value: i.e. config is versioned or easy to move between machines. Curiosity got the better of me so I looked it up at https://nix-community.github.io/home-manager/ and it indeed does purport to provide benefits I guessed at and then some. Whether that's better than just manually managing things yourself is altogether a different matter. reply elric 11 hours agoprevThe includeIf stuff is pretty neat. I currently keep the SSH complexity in ~/.ssh, where I have several includes, one for each customer|project|identity. Things without unique hostnames, like github, get an alias assigned: Host customer-github Hostname github.com IdentityFile ~/.ssh/customer_rsa User git All I have to do is use the alias in any git clone command and I'm done. reply dolmen 10 hours agoparentI have created a tool 12 years ago (still actively maintained) to manage multiple GitHub SSH identities: https://github.com/dolmen/github-keygen reply bilalq 11 hours agoprevSo glad I clicked on this link. I was already doing the `includeIf: \"gitdir\"` thing to separate work and personal stuff, but `hasconfig:remote` is a total game-changer. reply meitham 11 hours agoparentabsoluelty! I can't believe this treasure was hidden as a draft for three years! reply cquintana92 11 hours agoprevShameless plug for a tool I developed in order to easily switch git identities based on projects: https://github.com/cquintana92/git-switch-user After configuring the identities you just need to run $ git su Personal $ git su Work And all the identity configuration (email, name, SSH key and optionally PGP key) will be set up into the repo's .git/config file. Saved me a ton of time. reply dolmen 10 hours agoparentShameless plug for a tool I developed in order to easily manage GitHub identities for Git access via SSH: https://github.com/dolmen/github-keygen 12 years old, but still actively maintained. reply stared 9 hours agoprev> Note: I've had this post drafted for 3 YEARS!!! It's finally time to publish it. I suddenly felt a deep connection with the author. It is not only me. I promise you, my dear drafts, that one day, I will set you free to see the world! reply computerfriend 10 hours agoprevThis is a nice trick. But if you: * use a dedicated work machine and * also want to version control your dotfiles (including ~/.config/git/) and * don't want to leak your work repository organisation via your dotfiles, you can instead add something like [include] path = work.gitconfig which will override any settings above it and also fail gracefully/silently if work.gitconfig does not exist. reply redak 6 hours agoparentWhat would work.gitconfig include in this case? reply zelphirkalt 4 hours agoprevSomewhat annoying, that the configuration is spread out across 2 config files of 2 separate programs (git and ssh) and that the `insteadOf` `url` must match the `Host` in `.ssh/config`, which leaves a lot of room for mistakes and is fiddly, but at least this method works well! Edit: Hmm it seems to ask me over and over again for my password for a key at every pull or push. Maybe this method somehow disables memorizing the SSH identity? reply cimnine 8 hours agoprevI've written a short blogpost about how to link SSH Keys to Git identities: https://brainfood.xyz/post/20241030-use-a-specific-ssh-key-i... reply zelphirkalt 3 hours agoprevWhy does the page redirect me periodically to https://www.benji.dog/%F0%9F%8D%AA/ and hide its content? reply pestaa 11 hours agoprevIs there a risk with not using different keys for work and personal? The private bits are all in the same place: if one is compromised, so are the rest. reply tonyedgecombe 9 hours agoparentThere is also a risk using the same machine for work and personal. I’d address that first. reply heywire 6 hours agorootparentRight? I can’t believe how many people seemingly use the same machine for both. reply dolmen 10 hours agoparentprevAbout signing keys, it would make sense stopping using a signing key (marking it as such and deleting it) once you stop a job. Your signing key for personal projects probably has a different temporality. reply notpushkin 9 hours agorootparent> About signing keys, it would make sense stopping using a signing key (marking it as such and deleting it) once you stop a job. What does this achieve exactly? reply necovek 6 hours agorootparentNobody can steal it and sign it with your key for a commit to appear as if it was signed by a regular committer to a work project that would pass the verification if there is any on the repo or CI/CD side (if that's not restricting keys by the time period). The scenario is certainly a bit far-fetched and contorted, but it is possible. reply x3n0ph3n3 11 hours agoparentprevYour key cannot be tied to more than one identity, and if you use GitHub Enterprise, your work identity may be restricted from contributing to repos outside of the Enterprise. This is to prevent cloning private code into public spaces. For this reason, you need to have separate keys. reply pestaa 10 hours agorootparentInteresting! Curious though that the compliance rules are strict enough it warrants distinct keypairs, but not that strict for the devs to use dedicated hardware. reply dns_snek 11 hours agoparentprevIf both of your keys are on the same computer they would most likely be compromised simultaneously, or not at all. However if you're worried about this then you should probably be using a hardware token anyway - something that supports SSH authentication via FIDO2, GPG, or smart card interface. reply andrei-akopian 8 hours agoprev> Note: I've had this post drafted for 3 YEARS!!! It's finally time to publish it. Did you say that just so we could imagine the world where you published it earlier? Thanks anyway, and nice site! reply codazoda 8 hours agoprevI love that Rek drew the image on your about page. I knew I recognized their work as soon as I saw it. Based on that and your 1.44MB Club, you might find Neat CSS interesting. :P https://neat.joeldare.com My Neat CSS websites will almost always fit on a floppy and I have a case of old floppies right here in my closet. The Neat CSS home page is only about 12k. Things get bigger when you start adding images, of course. reply ab71e5 6 hours agoprevGreat tips, did not know about the `hashconfig:remote` option. Currently dealing with a difficult setup where we have subrepos (so just using an `~/.ssh/config` alias for github.com:org does not work), some dependencies downloaded with CMake CPM, and working in a vscode devcontainer. reply bentinata 11 hours agoprevI use `insteadOf` instead of ssh alias because my workplace use GitLab orgs. So instead of typing the full URL like: git clone gitlab.com/acme-corp/project-name I could use: git clone work:project-name But this kinda broke `includeIf` since it store the `insteadOf` remote url directly. I then had to convert existing repositories to use the `insteadOf` url. I wrote a little bit about it here: https://bentinata.com/log/git-insteadof-includeif reply asadjb 9 hours agoprevI hated configuring multiple Hosts/aliases in my ~/.ssh/config for Github/Bitbucket when dealing with different keys for different clients. I ended up creating a \"SSH environment\" manager 4 years ago to help with this: https://github.com/theonejb/sshenv It's worked wonderfully for me since then, and it's something I use almost daily. reply ku1ik 11 hours agoprevThis post is a great reference of what’s possible with git config wrt includes/remotes, and I’m sure I’ll be getting back to it. One thing though: what’s the point of using separate keys for work/personal/github/gitlab? I fail to see a practical and security advantage over using one key (per workstation). reply gloflo 10 hours agoparentPrivacy for sure. It's no ones business to know how certain accounts are related. reply ku1ik 10 hours agorootparentAh, right. E.g. using separate GH accounts for personal and work. Forgot about that! reply ku1ik 10 hours agoparentprevTo add to my other replies to replies in this thread… These days I prefer to use local VMs to compartmentalize different areas of work (personal, consulting, etc) so my git config is plain and simple. Lately I’ve been doing mostly consulting work around open-source so I’ve been using my primary GH account for the most part, but separate VMs allow me to use a different key (account) without advanced git config incantations. reply carbonboarder 10 hours agoparentprevGitHub does not allow you to share a key with another GitHub account anymore reply ku1ik 10 hours agorootparentOf course! I’ve been using separate GH accounts for work and personal stuff in the past myself. It’s been years since then and I completely forgot. In fact, I was one of not too many who used separate account for work, and people didn’t understand it, wondering why the hassle. reply computerfriend 10 hours agorootparentprevThey never did. The account is identified by the key, so it's impossible. reply layer8 6 hours agoprevBe careful what client you use, though. JGit unfortunately still doesn’t support includeIf. reply jmb99 10 hours agoprevAs cool as this is, how many peoples' employers allow them to do either personal work from the work computers, or work work from their personal computers? My company is quite strict on both. reply TeMPOraL 6 hours agoparentThere's a third use case: multiple identities at work. In my case, company I worked for got acquired by a larger corp. Things happening as they usually do, I ended up having two different e-mails/identities/SSO credentials - me@old.company and me@new.corp. Most of the code I worked on was stuck on old company's infra, but new repos were developed on the acquiring corp's infra, so for years, I had to maintain two different SSH / Git identities too, and use appropriate one for a given repo. reply that_guy_iain 10 hours agoparentprevI've not had a single employer care. For many of the companies that I've worked at, the laptops were taken home to be used as personal computers at the end of the day and this was a well-known thing and I was often looked at weird when I said I had another laptop. One time I took the wrong laptop in and had to work on my personal laptop in the office. It wasn't so much fun that day. reply dmos62 9 hours agoprevWhy have multiple git identities in the same machine? I use a single different key with each machine and that's it. reply buro9 9 hours agoparentI use a unique account with every distinct git org / github org that I interact with. Even if I'm in my work profile and I need to do something in an org called `acmecorp`, I will create @acmecorp-identifier to do that. This is just a very long experience... * Security policies for work things have a blast radius of just that employer * OSS things have a lifetime beyond the life of an employment / contract * Source control elsewhere (GitHub / GitLab / Bitbucket / Gitea / Forgejo / etc) all has a local blast radius, and if a provider / org forces changes (roll your keys!) then the impact is limited to just that provider * When something changes ownership (i.e. an org), the impact to me is low It seems much more sane. I think of a single git identity across multiple orgs as a bit of a smell. reply nicholassmith 9 hours agoparentprevI use different accounts for my work GitHub and my personal GitHub, so this approach would be great if I shared a machine for both of them to keep separation. reply wink 6 hours agorootparentI find the premise to be potentially wrong already. Is a `dotfiles` repo personal? I don't usually push to my own repos from my work machines, but I do want to pull and push config updates while not disclosing my work email there or rewrite commits all the time (it's not secret, I just don't want it there). reply vishnugupta 12 hours agoprevI really liked the website, the layout, typography, icons etc. Really well done! reply ndjdjddjsjj 11 hours agoparentEspecially the TLD reply phito 11 hours agorootparentThe whole domain name for me, my childhood dog was named Benji :) ... time to go change my security questions reply cabirum 10 hours agoprev [–] user.useconfigonly=true can also help reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post discusses configuring Git identities using `includeIf` for conditional configurations, allowing different settings based on directory paths or remote URLs.",
      "The author shares a method to manage multiple Git identities and SSH keys by using different `Host` values in `~/.ssh/config` and adjusting Git configurations with `insteadOf`.",
      "The post highlights a new approach using `hasconfig:remote.*.url:!` for conditional Git configurations based on remote URLs, enhancing flexibility in managing Git identities."
    ],
    "commentSummary": [
      "The `includeIf` directive in Git config allows automatic application of different settings based on the repository's URL, streamlining identity management.",
      "This method enables users to set specific user details and SSH keys for work-related repositories, facilitating seamless switching between personal and work projects.",
      "Maintaining security and privacy can be further enhanced by using separate machines or user accounts for work and personal projects."
    ],
    "points": 387,
    "commentCount": 91,
    "retryCount": 0,
    "time": 1732512753
  },
  {
    "id": 42232000,
    "title": "SQLiteStudio: Create, edit, browse SQLite databases",
    "originLink": "https://sqlitestudio.pl/",
    "originBody": "SQLiteStudio Home About Donate Contact News Gallery Features Download GitHub Discussions Wiki Bugs & Ideas ChangeLog SQLiteStudio Create, edit, browse SQLite databases. Download Donate 3.4.6 released! It's a hotfix release to address urgent problem of \"black SQL code line\" that appeared in 3.4.5. It also gets two more issues resolved. Read More → Posted on 23 November 2024 More news → Feature rich Powerful, yet light and fast. Learn more Open Source It's released under GPL license and is free to use for any purpose. Cross-platform Runs on Windows, Linux and MacOS X. Portable No need to install or uninstall. Just download, decompress and run. Copyright © sqlitestudio.pl 2020",
    "commentLink": "https://news.ycombinator.com/item?id=42232000",
    "commentBody": "SQLiteStudio: Create, edit, browse SQLite databases (sqlitestudio.pl)316 points by thunderbong 18 hours agohidepastfavorite71 comments googie 10 hours agoAuthor here. I'm surprised and honored to have my pet project here ;) As mentioned in another comment, I'm currently in the process of bugfixing/polishing 3.4.x branch. Then I will focus more on 3.5.0, which will bring many big features. One of them being ERD (read & write). reply tolai 8 hours agoparentSQLiteStudio is fantastic, I've been using it on and off for a few years already and it's saved my ass so many times. Once, we were doing many many meetings discussing a potential implementation for a sales incentive scheme and it was very difficult to get everyone onboard. Fed up with this I built a demo database in sqlite using a portable SQLiteStudio instance and prepared a bunch of queries. This \"reference implementation\" made it possible to get everyone aligned in record time !! This would not have been possible at all with the \"frictions\" of a convential RDBMS. Also, analyzing and cleaning up client data during project UATs is so damn convenient in SQLiteStudio. Thanks !!!! reply forinti 7 hours agoparentprevIt's a great tool. My use-case is a bit unusual: I decommissioned an Oracle Portal instance and decided to keep a copy of the tables in SQLite so that I can recover files people may later remember they need. It's much easier than maintaining an Oracle instance. It's a nice feature of SQLiteStudio that you can click on a blob and see the image, if it's an image file. reply macmac 1 hour agorootparentHow did you get the tables from Oracle into SQLite? reply forinti 1 hour agorootparentWith a little Perl: https://github.com/glgraca/ora2sqlite reply shigawire 3 hours agoparentprevThanks for your work on this. It was super helpful as a student learning SQL. Having the visual feedback to check the statements made or queries ran on my test data was invaluable. reply pie_flavor 2 hours agoparentprevI learned about it just a week ago, and the thing I wanted to do with it worked flawlessly the first time on terribly formatted data. Thank you for your hard work! reply bmacho 1 hour agoparentprevIt says portable, and > No need to install or uninstall. Just download, decompress and run. but the main download button is an installer for windows. reply TheRealPomax 49 minutes agorootparentThat's why you click on \"downloads\" which takes you to https://github.com/pawelsalawa/sqlitestudio/releases because a homepage button offers people \"the most likely installer their OS/Browser combo suggests they probably want\", so you click through the full list of downloads to explicitly pick the version you want. Just like you'd do if you wanted to download the Linux and Mac installers even though you're currently on Windows. reply muhehe 8 hours agoparentprevThank you! This is great software. I don't use it much (and recently almost not at all), but I still love. It's fast, it's easy to use. I just checked your website and it looks there are tons of features I didn't know about :). Thanks again. reply confiq 3 hours agoparentprevWhere have you been all my life? :) Seriously, I needed this 10 years ago. reply bpiroman 7 hours agoparentprevlove it! thank you so much!! reply simonw 15 hours agoprevScreenshots here: https://sqlitestudio.pl/gallery/ It's built in C++ and Qt, is GPL licensed, looks like it's been in development for just under ten years. https://github.com/pawelsalawa/sqlitestudio reply googie 10 hours agoparentActually the project is much older. It started in 2007. More details on this can be found at https://sqlitestudio.pl/about/ reply SonOfLilit 9 hours agoprevThis week I needed to quickly have a peek at what was saved in a testing database, and I wondered \"does VisiData support this?\" and sure enough vd test.sqlite3 gave me a list of tables, right there in the terminal, and choosing a table with arrows and Return showed me the table data in a grid view with all of vd's filtering and sorting commands right there. reply hysan 16 hours agoprevHow does this compare with https://sqlitebrowser.org/ ? reply hochmartinez 10 hours agoparentI've used both. Sqlitestudio is far more powerful, intuitive and easy to use. Fast and efficient. Flies even in old PCs. In Linux you won't find It in the repositories. You have to download and run a handy installer. reply pmarreck 1 hour agorootparentFYI to anyone on Nix/NixOS, sqlitestudio is available on unstable branch of nixpkgs: https://search.nixos.org/packages?channel=unstable&show=sqli... reply dotancohen 3 hours agorootparentprevIt's GPL, so why no Debian packaging, if it is popular? reply 0points 9 hours agorootparentprevIt's in AUR reply knighthack 13 hours agoparentprevThat's my Swiss knife. Super handy in a lot of scenarios, and I use it side-by-side with Jetbrains' DataGrip. reply PeterStuer 10 hours agoparentprevI have been using sqlitebrowser as well. Fairly satisfied, except for the poor 'export to csv' that seems to fail on respecting csv separations in some cases. Does SQLiteStudio handle this correctly? reply justinclift 7 hours agorootparentDo you have the specifics of the failure cases? We (sqlitebrowser.org devs) tend to fix bugs like that when we have a reproducer. reply PeterStuer 3 hours agorootparentThx for replying here. My issue had to do with exporting text fields that have multi-line content and then importing that data into Microsoft Excel. I have quickly looked more deeply into this as for now I used a workaround by exporting to JSON. Upon investigation it does not seem like sqlitebrowser is doing anything explicitly wrong. It quotes texts correctly when necessary, in my case specifically strings that contain 'LF', and does not do it when it is not needed. The fault lies with the Excel importer that in this case does not correctly derive that it should use QuoteStyle=QuoteStyle.Csv (it uses QuoteStyle=QuoteStyle.None even when you instructed it to base its derivation on the entire dataset. I do not know if any accommodations on the exporting application can (or should) be made to compensate for Excel's import heuristics failures. P.S. for those running into the same issue (there seem to be many and I have not seen a solution from a quick Goolge that worked), in Excel when doing the import from CSV, select \"Transfrom Data\", open up the \"Advanced Query Editor\" and in the first line you will see something like let Source = Csv.Document(File.Contents(\"the path to your CSV file\"),[Delimiter=\"#(tab)\", Columns=13, Encoding=65001, QuoteStyle=QuoteStyle.None]), ... Just replace the QuoteStyle.None with QuoteStyle.Csv and you should be good to go. My apologies to the sqlitebrowser devteam for my initial misconception. reply thechao 1 hour agorootparentprevHey! Thanks! Y'all do great work! Your tool is critical to my ability to keep sane. reply jksmith 15 hours agoparentprevMy goto as well. reply hu3 11 hours agoprevI've been using this client lately: https://dbgate.org Anyone else? reply thinker5555 1 hour agoparentI just tried it out, but for some reason it's complaining about missing a pivot_vtab module when I try to open an existing database. (MacOS ARM/Ventura) reply Oxodao 10 hours agoparentprevJust tried it, it might replace DBeaver for me! Vim mode without plugin is amazing. Need a few days to fully try it out reply hochmartinez 10 hours agoprevI've been using It for several years, in Windows and now in Linux. Fast, slick and very powerful. Flies on my humble Atom laptop. By far the best free sqlite manager. Thanks Paweł Salawa for this great piece of software! reply xenodium 7 hours agoprevThis looks great. For Emacs users, v29 introduced sqlite-mode. I've experimented with some convenience extensions which can be handy for quick sqlite views and edits https://lmno.lol/alvaro/sqlite-mode-goodies reply DecoPerson 13 hours agoprevBe very careful using this over Samba, even with WAL mode enabled. I corrupted an important testing DB this way. Thankfully .recover came to the rescue and only a small amount of data was lost (but the test team had to wait a couple hours for me to bring the test environment back online). reply CaliforniaKarl 12 hours agoparentThe WAL journal mode does not work over Samba. See the first disadvantage from https://www.sqlite.org/wal.html: > All processes using a database must be on the same host computer; WAL does not work over a network filesystem. This is because WAL requires all processes to share a small amount of memory and processes on separate host machines obviously cannot share memory with each other. The presence of the `-shm` file is one of the signs that the database is currently operating in WAL mode, and must only be accessed from the machine hosting the database file. Looking at the list of journal modes supported (https://www.sqlite.org/pragma.html#pragma_journal_mode), you should see if the problem happens with the default `DELETE` journal mode. Also, see https://www.sqlite.org/atomiccommit.html#_broken_locking_imp... for warnings about the SQLite that ships with macOS. reply chasil 2 hours agorootparentThat is not the only limitation of WAL mode. “It is not possible to change the page size after entering WAL mode.” “In addition, WAL mode comes with the added complexity of checkpoint operations and additional files to store the WAL and the WAL index.” https://www.vldb.org/pvldb/vol15/p3535-gaffney.pdf “SQLite does not guarantee ACID consistency with ATTACH DATABASE in WAL mode. “Transactions involving multiple attached databases are atomic, assuming that the main database is not \":memory:\" and the journal_mode is not WAL. If the main database is \":memory:\" or if the journal_mode is WAL, then transactions continue to be atomic within each individual database file. But if the host computer crashes in the middle of a COMMIT where two or more database files are updated, some of those files might get the changes where others might not.” https://www.sqlite.org/lang_attach.html reply JaggerFoo 11 hours agoprevExcellent product that behaves as expected and adheres to Sqlite's unique requirements when updating schema objects. reply dkjaudyeqooe 3 hours agoprevThis behaves very strangely on macOS 10.14.6: the installer downloaded from the website immediately logs you out without warning. reply googie 1 hour agoparentWeird behavior indeed. I don't observe it myself on MacOS 10.11 and I had feedback from couple of other Mac users, where it worked fine - even on older MacOS than yours. I really cannot imagine what could cause your MacOS to log out. Sorry. reply pjturpeau 8 hours agoprevVery nice \"pet\" project! I was about to ask what would make it more interesting than HeidiSQL or DB Browser for SQLite and then I remembered those two are crashing on few of my .sqlite files while SQLiteStudio does not! reply skc 13 hours agoprevSolid tool. But on Windows it has a tendency to freeze and remain unresponsive if you leave it open without using it for an extended period eg overnight. It's a minor annoyance reply googie 10 hours agoparentAuthor here. This was never reported. I haven't noticed it for myself either. Feel free to get in touch through the official email (mentioned on the homepage) or through GitHub issues. I'm in the process of polishing 3.4.x branch, eliminating as many bugs as possible, before focusing on 3.5.0. reply thunderbong 7 hours agoparentprevI've used it for many years. Never faced this problem. reply cess11 11 hours agoparentprevReally? To me that's a major annoyance, an obvious defect in the software. It's like a car going unresponsive from standing still at a red light and needing me to turn it off and waiting for five seconds before I start it again before I can drive away, or having to turn it off when stopping and then starting again when the light changes. reply Temporary_31337 9 hours agorootparentThen report it via the appropriate channels with as much detail as possible and steps to reproduce. It looks like you are complaining without having even used the software. reply cess11 8 hours agorootparentNo, I'm just not going to use the software if I encounter this. reply gchamonlive 6 hours agorootparentYou'll have to stick to pen and paper, although pens stop working if you don't use it for an extended period of time, so I guess it's an obvious defect with the product and you shouldn't use it. reply cess11 5 hours agorootparentNo, I spend something like ten to sixteen hours a day in front of software that doesn't freeze up just because I don't cuddle it. I've got some devices behind a NAT I'm lazy with, I reboot them maybe once a year or so. reply Alifatisk 8 hours agoprevIs there a tool that allows multiple people to work in the same sql workspace? I thinking an application like mysql workbench but for collaboration where everyone shares the same editor, terminal and everything else. That would accelerate the brainstorming a lot when working in a team remotely. reply djsnoopy 16 hours agoprevWhat does this have that the SQLite command line program doesn’t? Because every time I try one of these I go back to the cli. reply owobeid 13 hours agoparentHere's one use case: while I don't use this particular GUI, it really does help when you have some columns containing RTL text such as Arabic and you want to browse through a table. RTL handling in most terminal emulators I've used is really lacking, though I can't blame them. reply bilekas 10 hours agorootparentThat's actually a really interesting case I had never considered. I actually just took it for granted that RTL in the console was a solved problem reply owobeid 8 hours agorootparentNot just in consoles. While RTL is solved for most cases, I generally avoid writing Arabic in code for example (hard-coded strings, regex, etc) and just use Unicode escape sequences. Some issues include ASCII punctuation appearing (visually) in the wrong order and very awkward text selection reply dotancohen 2 hours agorootparentprevOne day I set out to resolve this, though I can not find in my notes' files what the solution was (for MySQL). It might have been to simply use MyCLI instead of the standard MySQL CLI. Have you tried it? https://github.com/dbcli/mycli reply hochmartinez 9 hours agoparentprevLots of things! It gives you sqlite superpowers. It makes you more productive and saves you lots if time. You can edit several databases at the same time. And editing them is far easier. For example, it generates and executes the sql code to add new columns for you. You can edit the data of several rows directly on a query response, as if It was a spreadsheet, just by clicking on a column value (or you can use a column value editor). Super handy. You can view and edit blobs. The sql editor has autocompletition and you can execute a statement just by having the cursor on this statement, so you can quickly test multiple independent queries in a single editor window. It shows the execution times, so you can easely compare the speed of several query strategies. You can view the query optimizer info by clicking a button. It supports several scripting lenguajes, and the list goes on and on. Check the features here: https://sqlitestudio.pl/features/ reply dagw 9 hours agoparentprevAllows people who are not versed in SQL to interact with and edit sqlite files as if it was a spreadsheet (for better or worse) reply TheRealPomax 53 minutes agoparentprevAll the benefits of a normal GUI-based DB manager. So \"too many things to list, have a look at the website, it should be pretty self-explanatory\" =D reply kyawzazaw 14 hours agoparentprevUI is quite useful to me reply googie 10 hours agoparentprevFor example it has context-aware syntax autocompletion, easy D&D for tables between databases, and many more - you can see longer list at https://sqlitestudio.pl/features/ reply rmbyrro 9 hours agoparentprevA good alternative to the sqlite cli is litecli [1]. I've been a happy user for quite some time. [1] https://litecli.com reply dayeye2006 16 hours agoparentprevMaybe UI reply emptiestplace 14 hours agoparentprevAgreed, rip the band-aid off folks. You will be so glad you did. reply nbevans 3 hours agoprevI've been using this tool pretty much every day for almost a decade. It has a few quirks but it is still the best desktop tool for interacting with SQLite databases. reply DonnyV 3 hours agoprevJust tried it out. It seems to freeze on Windows with large sqlite views. I have a 89GB sqlite file and it doesn't like it. sqlite file I used https://btrfs.openfreemap.com/areas/monaco/20241022_231001_p... reply googie 1 hour agoparentThe file you linked is around 388kB in size. Are you sure it's the one you intended to link? I've checked it anyway and I see no problem for SQLite to open and query views from that db file. reply killingtime74 13 hours agoprevI just use Datagrip. Works with SQLite and many more dbs reply turblety 11 hours agoparentDatagrip is a paid, proprietary and closed source commercial product. reply coldcode 4 hours agoprev [–] MacOS refused to run the installer on Sequoia. Signing it is not all that hard. reply JaggerFoo 1 hour agoparentI use it all the time on Sonoma OS with no problems. I have yet to upgrade to Sequoia due to the numerous reported problems on Reddit. reply googie 4 hours agoparentprev [–] You can right-click and run from the context menu, in which case it should start. Contributions are welcomed. reply jbverschoor 1 hour agorootparentNot on Sequoia / Lockdown Mode. Signing is not that hard indeed reply TheRealPomax 51 minutes agorootparentMuch like all previous versions of MacOS: settings -> privacy and security -> click \"open anyway\". No need for open source to give in to Apple's signing demands. reply nolito 2 hours agorootparentprev [–] Same problem here. Also on Seqouia reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SQLiteStudio has released version 3.4.6, addressing the \"black SQL code line\" issue from the previous version 3.4.5 and resolving two additional issues.",
      "This software is open-source, cross-platform, and portable, available for free under the GPL license, and compatible with Windows, Linux, and MacOS X.",
      "Notably, SQLiteStudio requires no installation, making it convenient for users to create, edit, and browse SQLite databases."
    ],
    "commentSummary": [
      "SQLiteStudio is a user-friendly tool designed for creating, editing, and browsing SQLite databases, praised for its portability and powerful features.",
      "It includes support for Entity-Relationship Diagrams (ERD), which aids in handling complex database tasks and offers visual feedback, benefiting both professionals and students.",
      "While some users have encountered platform-specific issues, SQLiteStudio is generally regarded as a reliable and efficient SQLite management tool."
    ],
    "points": 316,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1732495006
  },
  {
    "id": 42231489,
    "title": "The two factions of C++",
    "originLink": "https://herecomesthemoon.net/2024/11/two-factions-of-cpp/",
    "originBody": "The two factions of C++ The dream of a single dialect-free C++ has probably been dead for many years, anyway. Written by Mond Zero Ranger. Toggle original/dithered image There seems to be a lot of fighting and arguing over the future of C++. On Reddit and a certain orange website, definitely, but also surely at the official C++ standard committee meetings. You don’t need to look very far. EDIT (25-11-2024): Typos and phrasing. Mentioned on HN, r/cpp, lobste.rs. The Absolute State (of C++) It looks like we’re in the following situation: C++’s Evolution Working Group (EWG) just achieved consensus on adopting P3466 R0 - (Re)affirm design principles for future C++ evolution: This means no ABI breaks, retain link compatibility with C and previous C++. It also means no ‘viral annotations’ (no lifetime annotations, for example).1 It doubles down on a set of incompatible goals, ie. no ABI break and the zero-overhead-principle.2 Whether this is good or bad, it is a (literal) doubling down on the current trajectory of the C++ language. In the meantime: The US government wants people to stop using C++: The CISA The NSA The White House, apparently. No, really. Various branches of the US government have released papers, reports, recommendation to warn the industry against usage of memory-unsafe languages. All sorts of big tech players are adopting Rust: Microsoft is apparently rewriting core-libraries in Rust. Google seems to be committing to Rust, and in fact started working on a bidirectional C++/Rust interop tool. AWS is using Rust. etc. Speaking of big tech, did you notice that Herb Sutter is leaving Microsoft, and that it seems like MSVC is slow to implement C++23 features, and asking the community for prioritization. The infamous Prague ABI-vote happened (tl;dr: “C++23 will not break ABI, it’s unclear if it ever will.”), Google supposedly significantly lowered its participation in the C++ development process, and instead started to work on their own C++ successor language. They even have a summary outlining all of the issues they had trying to improve C++.3 Stories of people trying their best to participate in the C++-standard committee process across multiple years, only to be chewed up and spit out are widely known and shared throughout the community. (A feature landing in C first doesn’t help either.) Modules are still not implemented. Are we modules yet? ‘Safety Profiles’ are still in a weird state with no existing implementation, trying to retrofit some amount of safety onto existing C++ code while minimizing changes to existing code. Sean Baxter himself took a stance against profiles, and described C++ as “underspecified”. I don’t know about you, but if I were to look at all of this as an outsider, it sure would look as if C++ is basically falling apart, and as if a vast amount of people lost faith in the ability of C++’s committee to somehow stay on top of this.4 Two Cultures People seem to be looking for other solutions. Say, Google. Google evidently lost faith in ’the process’ ever since the ABI-vote. This isn’t a loss of faith in the language itself, Google has one of the largest C++ codebases in the world, and it has served them incredibly well. It’s a loss of faith in the language’s ability to evolve as pressure mounts from different angles (potential government regulations, competing languages, a desire for better performance and safety guarantees from key players, etc.). So what’s the problem? Why doesn’t C++ just…change? Well, figuring that out is easy. Just look at what Herb Sutter said in his paper on profiles: “We must minimize the need to change existing code. For adoption in existing code, decades of experience has consistently shown that most customers with large code bases cannot and will not change even 1% of their lines of code in order to satisfy strictness rules, not even for safety reasons unless regulatory requirements compel them to do so.” – Herb Sutter Cool. Is anyone surprised by this? I don’t think so. Now, let’s contrast this with Chandler Carruth’s biography on the WG21 member page: I led the design of C++ tooling and automated refactoring systems built on top of Clang and now part of the Clang project. […] Within Google, I led the effort to scale the automated Clang-based refactoring tools up to our entire codebase, over 100 million lines of C++ code. We can analyze and apply refactorings across the entire codebase in 20 minutes. Oh. Do you see it? (Yes you do, I highlighted it.) It’s “automated tooling”. Except it’s not just that, automated migration tooling is just the peak, the single brightly glowing example. We’re basically seeing a conflict between two starkly different camps of C++-users: Relatively modern, capable tech corporations that understand that their code is an asset. (This isn’t strictly big tech. Any sane greenfield C++ startup will also fall into this category.) Everyone else. Every ancient corporation where people are still fighting over how to indent their code, and some young engineer is begging management to allow him to set up a linter. One of these groups will be capable of handling a migration somewhat gracefully, and it’s the group that is capable of building their C++ stack from versioned source, not the group that still uses ancient pre-built libraries from 1998. This ability, to build the entire entire dependency stack from versioned source (preferably with automated tests) is probably the most critical dividing line between the two camps. In practice, of course, this is a gradient. I can only imagine how much sweat, tears, bills and blood must’ve flown to turn big tech codebases from terrifying balls of mud into semi-manageable, buildable, linted, properly versioned, slightly-less-terrifying balls of mud. With the bias of hindsight, it’s easy to think of all of this as inevitable: There was a clear disconnect between the needs of corporations such as Google (who use relatively modern C++, have automated tooling and testing, and modern infrastructure), and the (very strong) desire for backwards compatibility. To go out on a limb, the notion of a single, dialect-free and unified C++ seems like it’s been dead for years.5 We have, at the very least, two major flavors of C++: Any remotely modern C++. Everything can be built from versioned source using some sort of dedicated, clean and unified build process that’s at least slightly more sophisticated than raw CMake, and sort of looks like it just works if you squint a little. Some sort of static analyzers, formatter, linter. Any sort of agreement that keeping a codebase clean and modern is worthwhile. Probably at least C++17, with uniqe_ptr, constexpr, lambdas, optional, but that’s not the point. What matters is the tooling. Legacy C++. Anything that’s not that. Any C++ that’s been sitting in ancient, dusted-up servers of a medium-sized bank. Any C++ that relies on some utterly ancient chunk of compiled code, whose source has been lost, and whose original authors are unreachable. Any C++ that sits deployed on pet-type servers, to the point that spinning it up anywhere else would take an engineer a full month just to figure out all of the implicit dependencies, configs, and environment variables. Any codebase which is primarily classified as a cost-center. Any code where building any used binary from source requires more than a few button presses, or is straight-up impossible. You’ll notice that the main difference isn’t about C++ itself at all. The difference is tooling and the ability to build from versioned source in any clean, well-defined manner. Ideally, even the ability to deploy without needing to remember that one flag or environment variable the previous guy usually set to keep everything from imploding. How much of eg. Google’s codebase is following ‘modern’ C++ idioms is pretty much secondary to whether the tooling is good, and whether it can be built from source. A lot of people will tell you that tooling isn’t the responsibility of the C++ standard committee, and they are right. Tooling isn’t the responsibility of the C++ standard committee, because the C++ standard committee abdicates any responsibility for it (it focuses on specifications for the C++ language, not on concrete implementations)6. This is by design, and it’s hard to blame them considering the legacy baggage. C++ is a standard unifying different implementations. That said, if there’s one thing which Go got right, it’s that tooling matters. C++, in comparison, is from a prehistoric age before linters were invented. C++ has no unified build system, it has nothing even close to a unified package management system, it is incredibly hard to parse and analyze (this is terrible for tooling), and is fighting a horrifying uphill battle against Hyrum’s Law for every change that needs to be made. There’s a massive, growing rift between those two factions (good tooling, can effortlessly build from source vs. poor tooling, can’t build from source), and I honestly don’t see it closing anytime soon. The C++ committee seems pretty committed (committeed, if you will) to maintaining backwards compatibility, no matter the cost. I don’t necessary disagree with this, by the way! Backwards compatibility is a huge deal for a lot of people, for very good reasons. Other people don’t care nearly as much. It doesn’t matter which group is “right”: It’s just that these are incompatible views. Consequences This is why profiles are the way they are: Safety Profiles are not intended to solve the problems of modern, tech-savvy C++ corporations. They’re intended to bring improvements without requiring any changes to old code. Likewise, modules. You’re intended to be able to “just” import a header file as a module, and there should not be any sort of backwards compatibility issues. Of course, everyone loves features which can just be dropped-in and bring improvements without requiring any changes to old code. But it’s pretty clear that these features are designed (first and foremost) with the goal of ’legacy C++’ in mind. Any feature that would require a migration from legacy C++ is a non-starter for the C++ committee since, as Herb Sutter said, you essentially cannot expect people to migrate. (Again, building features with ’legacy C++’ in mind is not bad. It’s a completely sensible decision. ) This is something which I try to keep in mind when I look at C++ papers: There’s two large audiences here. One is that of modern C++, the other is that of legacy C++. These two camps disagree fiercely, and many papers are written with the needs of one specific group in mind. This, obviously, leads to a lot of people talking past each other: Despite what people think, Safety Profiles and Safe C++ are trying to solve completely different problems, for different audiences, not the same ones. The C++-committee is trying to keep this rift from widening. That’s, presumably, why anything in the direction of Safe C++ by Sean Baxter is a non-starter for them. This is a radical, sweeping change that could create a fundamentally new way of writing C++. Of course, there’s also the question of whether specific C++ standard committee members are just being very, very stubborn, and grasping at straws to prevent an evolution which they personally aesthetically disagree with. Far be it from me to accuse anyone, but it wouldn’t be the first time I heard that the C++ committee applied double standards such as: “We expect a full, working implementation across several working compilers from you if you’d like to see this proposal approved, but we’re still happy to commit to certain vast projects (eg. modules, profiles) that have no functioning proof of concept implementation.” If this were the case (I genuinely cannot say) then I really wouldn’t know for how much longer C++ could continue going down that road without a much more dramatic split. And all of that that is not even getting into the massive can of worms and problems that’d be caused by breaking ABI compatibility. If you want to be cynical, you can interpret this as an explicit “Nuh-uh” towards Rust’s lifetime annotations, and Sean Baxter’s ‘Safe C++’ proposal. If you want to be less cynical, it’s at least a bitter awareness of the fact that the industry doesn’t care to refactor existing code. ↩︎ “You don’t pay for what you don’t use.” Essentially, an existing C++ feature can only ever impact your runtime performance if you actively use it. This is not quite compatible with a stable ABI since a stable ABI (understood as a feature of C++) precludes certain performance improvements. ↩︎ I think Carbon is a lot more interesting than most people give it credit for. Ask me about my opinion sometime. I might write a post on it. ↩︎ Is it falling apart? Eh. Depends on what you mean. All that C++ code is not going to go anywhere. So in that sense, no. C++ code will continue to exist, at the very least. ↩︎ Whether it was ever alive, with all sorts of different compilers, and their own compiler extensions is a different question. ↩︎ This is slightly unfair. There’s a study group dedicated to tooling, SG15. For example, see this post. Of course, the entire process is still focused on writing papers, not on eg. shipping a canonical package manager. ↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=42231489",
    "commentBody": "The two factions of C++ (herecomesthemoon.net)314 points by cyclopeanutopia 19 hours agohidepastfavorite361 comments saurik 17 hours agoI compile a lot of C++ code from a lot of places, and the only time I run into code that somehow simply doesn't work on newer versions of C++ and where the developers aren't even sure if they will accept any patches to fix the issue as they claim it \"isn't supported\" to use a newer version of C++--even for the public headers of a library--is, you guessed it: code from Google. Meanwhile, most of the C++ code from Google seems to be written in some mishmash of different ideas, always at some halfway point along a migration between something ancient and something passable... but never anything I would ever dare to call \"modern\", and thereby tends to be riddled with state machines and manual weak pointers that lead to memory corruption. So... I really am not sure I buy the entire premise of this article? Honestly, I am extremely glad that Google is finally leaving the ecosystem, as I generally do not enjoy it when Google engineers try to force their ridiculous use cases down peoples' throats, as they seem to believe they simply know better than everyone else how to develop software. Like... I honestly feel bad for the Rust people, as I do not think the increasing attention they are going to get from Google is going to be at all positive for that ecosystem, any more than I think the massive pressure Google has exerted on the web has been positive or any more than the pressure Google even exerted on Python was positive (not that Python caved to much of it, but the pressure was on and the fact that Python refused to play ball with Google was in no small part what caused Go to exist at all). (FWIW, I do miss Microsoft's being in the space, but they honestly left years ago -- Herb's existence until recent being kind of a token consideration -- as they have been trying to figure out a tactical exit to C++ ever since Visual J++ and, arguably, Visual Basic, having largely managed to pivot to C# and TypeScript for SDKs long ago. That said... Sun kicking Microsoft out of Java might have been really smart, despite the ramifications?) reply DanielHB 7 hours agoparent> code from Google. I spilled my coffee, I was just talking the other day to some coworkers how I don't trust google open source. Sure they open their code but they don't give a damn about contributions or making it easy for you to use the projects. I feel a lot of this sentiment extends to GCP as well. So many google projects are better than your average community one, but they never gain traction outside of google because it is just too damn hard to use them outside of google infra. The only Google project that seems to evade this rule that I know of is Go. reply kccqzy 1 hour agorootparent> but they don't give a damn about contributions Here is a concrete reason why Google open source sucks when it comes to contributions and I don't think it can be improved unless Google changes things drastically: (1) an external contributor makes a nice change and a PR on GitHub; (2) the change breaks internal use cases and their tests; (3) the team is unwilling to fix the PR or port the internal test (which may be a test several layers down the dependency tree) to open source. > making it easy for you to use the projects Google internally use Blaze, a version of Bazel. It's so ridiculously easy for one team to use another team's project that even just thinking about what the rest of us needs to do to use another project is unloved dreadful work. So people don't make that effort. I do not see either of these two points changing. Sure there are individuals at Google that really care about open source community, but most don't, and so their project is forever a cathedral not a bazaar. reply DanielHB 1 hour agorootparentIt is not only that, but often when google uses an open source project not owned by them they either try to take ownership of the project or fork it instead of trying to contribute to the original. reply rahkiin 47 minutes agorootparentprevOne could ask whether Google works ‘open source’ or more ‘source available’; the source is there but you cannot contribute, if you can build it at all reply kccqzy 22 minutes agorootparentNo, \"open source\" doesn't imply open contribution. The standard terminology is cathedral vs bazaar. reply humanrebar 5 hours agorootparentprevGoogletest is the most widely used test library for C++. Googlemock is the only mocking library available that's reasonably feature complete. reply bluGill 4 hours agorootparentI you are using googletest, you owe it to yourself to check out catch2 which I find much better and uses modern C++. There are a few other test frameworks in C++ that look better than google test as well, but catch2 is the one I settled on (and seems to be the best supported): feel free to check them out. I've given up on mock frameworks. They make it too easy to make an interface for everything and then test that you are calling functions with the expected parameters instead of the program works as you want. A slight change to how I call some function results in 1000 failed tests and yet I'm confident that I didn't break anything the user could notice (sometimes I'm wrong in this confidence - but none of the failing tests give me any clue that I'm wrong!) reply Maxatar 3 hours agorootparentcatch2 has become fairly bloated. doctest takes all of the best parts of catch2 without all the bloat and the end result is a test framework that is literally over 10x faster than catch2. It's also like 90% compatible with catch2 so porting your tests to it is pretty easy. Especially if you have a build process that always runs your unit tests, it's nice to have a very fast test/compile/debug loop. https://github.com/doctest/doctest reply Suppafly 15 minutes agorootparent>catch2 has become fairly bloated. doctest takes all of the best parts of catch2 without all the bloat and the end result is a test framework that is literally over 10x faster than catch2. It's also like 90% compatible with catch2 so porting your tests to it is pretty easy. I feel like you could make a madlib where you could plug in any two project names and this sentence would make sense. reply gary_0 3 hours agorootparentprevI was just about to suggest doctest, you beat me to it! I'm all about faster compile times, and it was mostly a drop-in replacement for catch2 in my case. Also, IMO, both doctest and catch2 are far superior to Google Test. reply amalcon 2 hours agorootparentprevI've found exactly three places where I really want to have a mock available: 1) Databases and other persistent storage. Though in this case, the best mock for a database is generally another (smaller, easily snapshottable) database, not something like googlemock. 2) Network and other places where the hardware really matters. Sometimes, I really want to drop a particular message, to exercise some property of the sender. This is often possible to code around in greenfield projects, but in existing code it can be much simpler to just mock the network out. 3) Cases where I am calling out to some external black-box. Sometimes it's impractical to replicate the entire black-box in my test. This could be e.g. because it is a piece of specialized hardware, or it's non-deterministic in a way that I'd prefer my test not to be. I don't want to actually call out to an external black-box (hygiene), so some kind of a mock is more or less necessary. reply eddautomates 2 hours agorootparentFor 1 have you looked at test containers? reply amalcon 44 minutes agorootparentBriefly, but frankly: copying small SQLite files around works so well in almost all cases that I don't feel the need for a new abstraction. reply ehoh 4 hours agorootparentprevSounds like the mocks are overused or used inappropriately in your experience (whether by a colleague or yourself). Mocks have their place. A prototypical example is at user-visible endpoints (eg: a mock client). reply bluGill 3 hours agorootparentI have found in my world it is easy to setup a test database (we use sqlite!) and the file system is fast enough (I have code to force using a different directory for files). I have been playing with starting a dbus server on a different port in my tests and then starting the real server to test against (with mixed results - I need a better way to know when dbus is running). I have had great success by writing a fake for one service that is painful - the fake tracks the information I really care about and so lets me query on things that matter not what the function signature was. I'm not arguing that mocks don't have their place. However I have found that by declaring I won't use them at all I overall come up with better solutions and thus better tests. reply gpderetta 4 hours agorootparentprevGoogle test and mock are quite powerful but are a big hit at both compile time and runtime, which matters for quick edit-compile-fix loops. I still go back and forth on whether google test and mock are worth it. Google benchmark is also nice. reply jimmaswell 1 hour agorootparentDoes it not support only running some or no tests? I only run the full test suite rarely, close to releases. reply physicsguy 2 hours agorootparentprevI used to really like Google Test, and then Google decided in it's infinite wisdom to make the OSS version depend on their C++ shared library replacement Abseil, and not just that but the live at head version. That makes sense internally for Google because they have their massive monorepo, but it sure as hell makes it a pain in the ass to adopt for everyone else. reply jeffbee 1 hour agorootparentI don't think you're reading those docs correctly. Googletest recommends living at head, but there's no reason you can't pin a release, either a git commit hash or a release label, of which there have been several. Googletest does not depend on the HEAD of abseil-cpp, it actually declares a direct dependency on an older LTS release of absl, but since you are building it from source any later release or commit of absl would work. Google open source libraries are often a mess when you try to include more than one of them in the same project, but googletest isn't an example of the mess. It's actually pretty straightforward. reply james_promoted 27 minutes agorootparent> Google open source libraries are often a mess when you try to include more than one of them in the same project Completely agree. In isolation all of their libs are great, but inevitably I end up having to build Abseil from source, to then build Protobuf off of that, to then build gRPC off of that. If I can include the sanitizers under Google then that also becomes painful because Abseil (at least) will have ABI issues if it isn't built appropriately. Thinking about it I'd really just like a flat_hash_map replacement so I can drop Abseil. reply __MatrixMan__ 1 hour agorootparentprevI blame monorepo culture. If it doesn't grow up in a context where it's expected to stand on its own, it crashes and burns when you kick it out of the nest. reply badpun 6 hours agorootparentprevTensorflow is/was decent. It looked like they made a lot of effort for it to be accessible for outsiders. reply th2oi34234234 6 hours agorootparentHave you tried building the damn thing ? Nix build is still stuck in the one from 3-4 y back because bazel doesn't play well. Debian too has some issues building the thing... reply jimmaswell 1 hour agorootparentAs an industry we need to stop treating breaking changes as an acceptable thing. The rate of bit rot has accelerated to an absurd pace. I can't remember the package but I had to spend considerable time fixing a build because a package.. changed names.. for NO REASON. They just liked the new name better. This should be career death. You're wasting your fellow humans' time and energy on your vanity when you make a breaking change that is at all avoidable. I should be able to run a build script made 20 years ago and it should just work. No renamed package hunting, no WARNING WARNING DEPRECATED REWRITE ALL YOUR CODE FOR LEFTPAD 10.3 IMMEDIATELY in the console, no code changes, no fuss, we should expect it to just work. This state of affairs is a stain on our industry. reply knome 56 minutes agorootparentthis is why you build to a specific version of a library. drop your build script into a container with the versions of software it expects and it should do fine. containerization is the admittance that versioning environments is needed for most software. I expect the nix/guix crowds to win in the end. reply p_l 1 hour agorootparentprevHaving tried on other platforms, it's not Bazwl, it's not even just Google. It's python packaging and the way the only really supported binary distribution method of Tensorflow for many many years was to use Pip and hope it doesn't crash. And it's reflected in how the TF build scripts only support building python lib as artefact, everything else at the very least involved dissecting bazel intermediate targets reply fpoling 2 hours agoparentprevI second the observation of the state of Google C++. Just look at Chromium. There are a lot of unfinished refactoring there, as if people lost interest the moment the clean refactoring hit a roadblock requiring efforts to communicate with other teams. Only by a sort of direct order from the management things can be completed. reply pjmlp 10 hours agoparentprevThe issue with Microsoft until recently, has been the power of WinDev, which are the ones responsible for anything C++ on Microsoft dungeons. Hence the failure of Longhorn, or any attempt coming out from Microsoft Research. Ironically, given your Sun remark, Microsoft is back into the Java game, having their own distribution of OpenJDK, and Java is usually the only ecosystem that has day one parity with anything Azure puts out as .NET SDK. reply memsom 1 hour agorootparentI use the Microsoft JDK daily - to develop in Maui for Android. Other than that, I'm not too sure what anyone would use it for over the actual OpenJDK versions. I'm pretty sure the MS OpenJDK is mostly there to support pushing people to Azure (hence your observation) and Android. I don't think it is there for much else outside of that, but I'm happy to stand corrected if anyone has another use cas for it. reply pjmlp 1 hour agorootparentIt was thanks to Microsoft that you get to enjoy the JVM on ARM for example, or better escape analysis. https://github.com/microsoft/openjdk-aarch64 https://www.infoq.com/news/2023/02/microsoft-openjdk-feature... reply quietbritishjim 9 hours agorootparentprevWhat is \"WinDev\"? A quick search didn't turn up much except a French Wikipedia article. reply pjmlp 9 hours agorootparentWindows Development, per opposition to DevDiv, Developer Division. Two quite common names in the Microsoft ecosystem. reply asveikau 1 hour agorootparentAs a former MS employee some time ago I don't think I ever heard \"windev\". It was always referred to as \"Windows\". Though there were a lot of different groups within that, so sometimes you'd hear an initialism for a specific team. For example during some of my time there was a big organizational split between \"core\" and more UI oriented teams. reply pjmlp 1 hour agorootparentHere is an example in the press, with an email from Somasegar, leader of developer division in the past. https://www.zdnet.com/article/microsoft-splits-up-its-xaml-t... reply asveikau 1 hour agorootparentI was an employee in Windows on the date of that email. I left a few months later. Note that the email itself doesn't say \"windev\". It says \"Windows\" a bunch of times. If I'm stretching this \"windev\" thing, the domain for a lot of employee accounts (including mine) was NTDEV, that had a longer history afaik, nobody called an org that.. reply pjmlp 29 minutes agorootparentThe journalist writes it though, as do many other folks. I didn't come up with this definition myself. If I am not mistaken, I can probably even dig some Sinosfky references using it. reply loup-vaillant 8 hours agorootparentprevFor a moment there I thought you were referring to this trademark: https://pcsoft.fr/windev/index.html Which was known at a time for having young women in light clothing in their marketing material. reply jcelerier 5 hours agorootparentaha, that's the windev that comes to mind too. I didn't know they were actually a french company, wild that they're still around... their ads were plastered everywere in the 2000s. Apparently they have a programming language for which you can \"one-click-switch\" between english and french for the keywords??? https://pcsoft.fr/windev/ebook/56/ reply voidfunc 5 hours agorootparentThat's actually kind of neat, also I love how the brochure uses the American flag for English... reply xbar 4 hours agorootparentYes. I would have preferred that they had used Canadian flags for both. reply vinkelhake 15 hours agoparentprev> Honestly, I am extremely glad that Google is finally leaving the ecosystem, as I generally do not enjoy it when Google engineers try to force their ridiculous use cases down peoples' throats, as they seem to believe they simply know better than everyone else how to develop software. Well, you may be celebrating a bit prematurely then. Google still has a ton of C++ and they haven't stopped writing it. It's going to take ~forever until Google has left the C++ ecosystem. What did happen was that Google majorly scaled down their efforts in the committee. When it comes to the current schism on how to improve the safety of C++ there are largely two factions: * The Bjarne/Herb [1] side that focuses on minimal changes to the code. The idea here is to add different profiles to the language and then [draw the rest of the fucking owl]. The big issue here is that it's entirely unclear on how they will achieve temporal and spatial memory safety. * The other side is represented by Sean Baxter and his work on Safe C++. This is basically a whole-sale adoption of Rust's semantics. The big issue here is that it's effectively introducing a new language that isn't C++. Google decided to pursue Carbon and isn't a major playing in either of the above efforts. Last time I checked, that language is not not meant to be memory safe. [1] https://github.com/BjarneStroustrup/profiles [2] https://safecpp.org/draft.html reply pjmlp 5 hours agorootparentPeople like to always talk about Carbon like that, yet the team is the first to point out anyone that can use something else, should. Carbon is an experiment, that they aren't sure how it is going to work out in first place. > \"If you can use Rust, ignore Carbon\" https://github.com/carbon-language/carbon-lang/blob/e09bf82d... > \"We want to better understand whether we can build a language that meets our successor language criteria, and whether the resulting language can gather a critical mass of interest within the larger C++ industry and communit\" https://github.com/carbon-language/carbon-lang/blob/e09bf82d... reply josh11b 1 hour agorootparentprev(Carbon lang dev here.) Carbon is intended to be memory safe! (Not sure whether you intended to write a double negative there.) There are a few reasons that might not be clear: * Carbon has relatively few people working on it. We currently are prioritizing work on the compiler at the moment, and don't yet have the bandwidth to also work on the safety design. * As part of our migration-from-C++ story, where we expect code to transition C++ -> unsafe Carbon -> safe Carbon, we plan on supporting unsafe Carbon code with reasonable ergonomics. * Carbon's original focus was on evolvability, and didn't focus on safety specifically. Since then it has become clear that memory safety is a requirement for Carbon's success, and will be our first test of those evolvability goals. Talks like https://www.youtube.com/watch?v=1ZTJ9omXOQ0 better reflect more recent plans around this topic. reply Conscat 1 hour agorootparentprevCarbon isn't currently memory safe, but Chandler Carruth has made it clear that every security expert he talked to says the same thing: memory safety is a requirement for security. He at least claims that Carbon will have memory safety features such as borrow checking down the line. I guess we'll see. reply IAmLiterallyAB 4 hours agorootparentprev> Herb side that proposes minimal changes Herb is developing a whole second syntax, I wouldn't call that minimal changes. And probably the only way to evolve the language at this point, because like you said Sean is introducing a different language entirely, so its not C++ at that point. I really like some of Herb's ideas,but it seems less and less likely they'll ever be added to C++ reply darknavi 4 hours agorootparentHave you seen some of his recent talks? Lots of underpinnings of cppfront have been added or are in committy. He compares it to the JS/TS relationship. reply nox101 3 hours agorootparentIt's not really a valid comparison though. cppfront is a different language that just happens to be compatible with C++. ts/js is were ts is just js with types. You can comment out the types and it just runs. cppfront's language you'll actually have to re-write the code to get it to compile in C++ typescript function add(a: number, b: number): number { return a + b }; javascript function add(a/*: number*/, b/*: number*/)/*: number*/ { return a + b }; cppfront add: (a: float, b: float): float = { a + b; } cpp float add(float a, float b) { return a + b; } reply EE84M3i 1 hour agorootparent> ts/js is were ts is just js with types. You can comment out the types and it just runs. Is this true in the general case? I thought there were typescript features that didn't have direct JavaScript alternatives, for example enums. reply paulddraper 55 minutes agorootparentEnums and namespaces are the only runtime features of TypeScript. So, yes, you can't just strip types, but it's close. reply EE84M3i 24 minutes agorootparentIs there a comprehensive list of such incompatibilities documented somewhere? reply HelloNurse 3 hours agorootparentprevDo you realize that the Typescript example contains strictly more information than the Javascript one (namely, declarations for the type of three things) and is therefore more complex to compile, while the two C++ examples are semantically identical (the last expression in the function is returned implicitly without having to write \"return\") and the new syntax is easier to parse? reply Conscat 1 hour agorootparentThere are several semantic differences between Cpp1 and Cpp2. Cpp2 moves from last use, which is the biggest one. In a contrived example, that could result in a \"hello world\" changing to \"goodbye world\" or any other arbitrary behavior change you want to demonstrate. Cpp2 also doesn't require you to order functions and types or declare prototypes, which means partial template specializations and function overloads can produce similar changes when migrating from Cpp1 to Cpp2. reply pjmlp 3 hours agorootparentprevNope, that is mostly sales pitch, the only thing added thus far has been the spaceship operator. He also sells the language differently from any other language that also compiles to native via C++, like Eiffel and Nim among others, due to conflict of interest to have WG21 chair propose yet another take on C++. reply throwaway2037 17 hours agoparentprev> riddled with state machines Why is this bad? Normally, state machines are easy to reason about. reply majormajor 17 hours agorootparentThe set of developers who say \"I want to implement this logic as a state machine\" is MUCH larger than the set of developers who say \"I should make sure I fully understand every possible state and edge case ahead of time before making a state machine!\" reply jimmaswell 1 hour agorootparent> \"I should make sure I fully understand every possible state and edge case ahead of time before making a state machine!\" Attempting to understand every state and edge case before writing code is a fool's errand because it would amount to writing the entire program anyway. State machines are a clear, concise, elegant pattern to encapsulate logic. They're dead simple to read and reason about. And, get this, writing one FORCES YOU to fully understand every possible state and edge case of the problem you're solving. You either have an explicit state machine, or an implicit one. In my entire career I have never regretted writing one the instant I even smell ambiguity coming on. They're an indefatigable sword to cut through spaghetti that's had poorly interacting logic sprinkled into it by ten devs over ten years, bring it into the light, and make the question and answer of how to fix it instantly articulable and solvable. I truly don't understand what grudge you could have against the state machine. Of all the patterns in software development I'd go as far as to hold it in the highest regard above all others. If our job is to make computers do what we want them to do in an unambiguous and maintainable manner then our job is to write state machines. reply freeone3000 4 hours agorootparentprevImplement as a state machine? But. Your program exists as a set of transforms upon memory. Your program is a state machine! You just need to define the proper morpisms to map your problem domain to the computer domain. reply marcosdumay 3 hours agorootparentTransformations are separable by principle, it's a fundamental property of them that state machines have as an afterthought that is even hard to represent. It doesn't matter if they have equivalent power. One of those representations fundamentally allows your software to have an architecture, the other doesn't. reply freeone3000 2 hours agorootparentHow much of software architecture is required because of the architecture? If your program has types that are the possible states, and functions to transform between those states, what architecture is needed beyond that? A grouping of related types, perhaps? reply marcosdumay 26 minutes agorootparentYeah, just one layer of functions is enough for everybody. Let's look next at that \"compiler\" thing and high-level languages. The hardware-native one suffices, no need for all that bloat. reply throwaway2037 16 hours agorootparentprevCouldn't this be said about any alternative solution? I fail to see how this is specific to state machines. What do you suggest instead of a state machine? reply bvrmn 8 hours agorootparentLike properly model a domain in domain terms? reply nottorp 7 hours agorootparentAnd that won't be a state machine with the states having more fancy names? reply InDubioProRubio 6 hours agorootparentIt will be, but the idea of having an overview over the states is gone then. There is just modules-> objects with the transitions being method calls. Nobody will have to know all the things about all the state transitions, resulting in another problem (dys)solved by architecture obscurity. If needs be the state-machine can be reconstructed on a whiteboard by a team of five. reply kayo_20211030 4 hours agorootparentprevI have a coding problem. I'll use a state machine! Now, I have two problems :-( reply risenshinetech 17 hours agorootparentprevPlease describe \"normally\". State machines can turn into nightmares, just like any design pattern used poorly. reply nurettin 13 hours agorootparentprevState machines don't have syntax for \"transition here when event is encountered no matter what state you are in\" so the whole diagram becomes a spaghetti mess if you have a lot of those escape hatches. reply lelanthran 6 hours agorootparent> State machines don't have syntax for \"transition here when event is encountered no matter what state you are in\" so the whole diagram becomes a spaghetti mess if you have a lot of those escape hatches. I place a note at the top of my diagrams stating what the default state would be on receipt of an unexpected event. There is no such thing as \"event silently gets swallowed because no transition exists\", because, in implementation, the state machine `switch` statement always has a `default` clause which triggers all the alarm bells. Works very well in practice; I used to write hard real-time munitions control software for blowing shit up. Never had a problem. reply rramadass 5 hours agorootparent> hard real-time munitions control software for blowing shit up. Never had a problem. Ha, Ha, Ha! The juxtaposition of these two phrases is really funny. I would like to apply for a position on the Testing team :-) reply quietbritishjim 9 hours agorootparentprevState machines don't have a native syntax in C++ at all, so you can structure them however you want. It's easy to structure a state machine, if needed, so that all (or some) states can handle the same event in the same way. reply dgfitz 3 hours agorootparentI always thought this framework was neat: https://doc.qt.io/qt-5/statemachine-api.html Downside of course is now you have a dependency on qt. reply alexvitkov 1 hour agorootparentThe downside is that you're now heap allocating at least one object for every state, and I'm willing to bet that each QState has an associated std::vector-style list of actions, and that each action is also its own object on the heap. If you can afford to do things like this you can most likely use something other than C++ and save yourself a lot of headaches. reply dgfitz 1 hour agorootparent> If you can afford to do things like this you can most likely use something other than C++ and save yourself a lot of headaches. Surely you can understand that, despite the recent c++ hate, my job doesn't give a fuck and we aren't migrating our massive codebase from c++ to... anything. reply liontwist 6 hours agorootparentprevgoto is exactly this feature. reply a_t48 12 hours agorootparentprevI believe HSMs can model this, but don't quote me. :) reply nurettin 11 hours agorootparentYes, of course in theory nested state machines should be able to model this. I feel like adding more complexity and bending the rules is a bit of a concession. reply jeffreygoesto 8 hours agorootparentBack in the days we implemented HSM helper classes in about 500 LoC and generated them from Enterprise Architect. No need to write a GUI yourself, but better to have a visual for documentation and review. Worked very well until we replaced EA with docs-as-code, now I miss that there is no nice simulator and Modeler for that workflow. reply AnimalMuppet 17 hours agorootparentprevThey can be. Or they can be... less easy. Imagine you have an informally-specified, undocumented, at-least-somewhat-incomplete state machine. Imagine that it interacts with several other similar state machines. Still easy to reason about? Now add multithreading. Still easy? Now add locking. Still easy? Cleanly-done state machines can be the cleanest way to describe a problem, and the simplest way to implement it. But badly-done state machines can be a total mess. Alas, I think that the last time I waded in such waters, what I left behind was pretty much on the \"mess\" side of the scale. It worked, it worked mostly solidly, and it did so for more than a decade. But it was still rather messy. reply lelanthran 12 hours agorootparent> Imagine you have an informally-specified, undocumented, at-least-somewhat-incomplete state machine. Imagine that it interacts with several other similar state machines. Still easy to reason about? You think that developers that wrote an informally-specified, undocumented, at-least-somewhat-incomplete state-machine would have written that logic as a non-state-machine in a formally-specified, documented and at-least-somewhat-complete codebase? State-machines are exceptionally easy to reason about because you can at least reverse-engineer a state-diagram from the state-machine code. Almost-a-state-machine-but-not-quite are exceptionally difficult to reason about because you can not easily reverse-engineer the state-diagram from the state-machine code. reply gpderetta 4 hours agorootparentIn fact state machines are great for documentation even if the code is not explicitly written as a state machine! reply _huayra_ 3 hours agorootparentYes, and it's much better than having a dozen or more `bool` values that indicate some event occurred and put it into some \"mode\" (e.g. \"unhealthy\", \"input exhausted\", etc) and you have to infer what the \"hidden state machine is\" based on all of those bool values. Want to add another \"bool state\"? Hello exponential growth... reply rramadass 12 hours agorootparentprevBut that is just true of any problem-solving/programming technique. In general, state/event machine transition table and decision table techniques of structuring code are easier to comprehend than adhoc and even worse, poorly understood pattern-based techniques are. reply andai 4 hours agoparentprevI am out of the loop, what kind of pressure were they putting on Python? reply j-krieger 2 hours agoparentprev> Like... I honestly feel bad for the Rust people, as I do not think the increasing attention they are going to get from Google is going to be at all positive for that ecosystem We are just now feeling this. Some original contributors left the field, and lately the language has went in directions I don't agree with. reply Conscat 1 hour agorootparentAs an outsider, I'm curious what directions those are. Are you referring to effects or keyword generics or something else? reply nicce 1 hour agorootparentprevBut Google is not even the first. Amazon has had their eyes in Rust for quite some time already. reply protomolecule 5 hours agoparentprev> riddled with state machines What's wrong with state machines? Beats the tangled mess of nested ifs and fors. reply bluGill 4 hours agorootparentThat depends on your problem. I've seen useful state machines. I've seen someone implement a simple decoder as a complex any-to-any state machine that couldn't be understood - a single switch statement would have been better. Nothing about state machines, but some people have a hammer and are determined to prove it can drive any screw - it works but isn't how you should do it. reply jimmaswell 1 hour agorootparentI've adopted a rule of thumb to have a very low bar to skip straight to writing a state machine. I've never once regretted it, personally. I'm sure they can be misused but I haven't came across that. reply taneq 3 hours agoparentprev> I compile a lot of C++ code from a lot of places, and the only time I run into code that somehow simply doesn't work on newer versions of C++ I'm impressed that you even get as far as finding out whether that much C++ from disparate sources works on a newer version of C++. The myriad, often highly customized and correspondingly poorly documented build systems invented for each project, the maze of dependencies, the weird and conflicting source tree layouts and preprocessor tricks that many projects use... it's usually a pain in the neck to get a new library to even attempt to build, let alone integrate it successfully. Don't get me wrong, we use C++ and ship a product using it, and I occasionally have to integrate new libraries, but it's very much not something I look forward to. reply cmrdporcupine 1 hour agoparentprevThe C++ from Google that people in the outside world are seeing is not the C++ the article is talking about. Chromium and open sourced libraries from Google are not the same as C++ in Google3. I worked on both back in the day and ... There's slightly different style guides (not hugely different), but most importantly the tooling is not the same. The kind of mass refactorings / cleanups / static analysis talked about in this article are done on a much more serious and large scale on C++ inside the Google3 monorepo than they are in Chromium. Different build systems, different code review tools, different development culture. reply deltaburnt 47 minutes agorootparentGoing from g3 to AOSP has been downright painful. It was like suddenly working in a different company the contrast was so stark. reply cmrdporcupine 14 minutes agorootparentInteresting. I never worked in Android, but did in Chromium & Chromecast code bases. Biggest difference with Google3 was honestly in the tooling. Style guide was fairly close, maybe a bit more conservative. Also the lack of the core libs that eventually became Abseil. I work full-time in Rust these days and everytime I go back to working in C++ it's a bit of a cringe. If I look long enough, I almost always find a use-after-free, even from extremely competent developers. Footgun language. reply shadowgovt 3 hours agoparentprevThis phenomenon is mostly because, as the article notes, Google has one of the largest C++ deployments in the world. And since much of the C++ code needs to be extremely platform-agnostic (any given library might be running in a web service, a piece of Chromium or Android, and an embedded smart home device), they tend to be very conservative about new features because their code always has to compile to the lowest-common-denominator (and, more importantly, they're very, very sensitive to performance regressions; the devil you know is always preferred to risking that the devil you don't know is slower, even if it could be faster). Google can embrace modern processes, but the language itself had better be compilable on whatever ancient version of gcc works on the one mission-critical architecture they can't upgrade yet... reply returningfory2 14 hours agoparentprevI think the article is pretty interesting. There are so many more interesting takes than just another boring Hacker News moan about Google. reply pif 9 hours agoparentprevGoogle has such proficient programmers that they had to invent a language for dummies (Go) for them not to get lost. The farther they step from languages for professionals, the better! reply guappa 6 hours agorootparentAnd then they were so unproficient that they made a terrible language that has the same amount of safeguards as C (ok a bit more, but not much more). reply pif 7 hours agorootparentprevnext [4 more] [flagged] zozbot234 7 hours agorootparentGolang is a great programming language if your alternative is Java, C# or scripting languages like Python/Ruby/etc. Not everything needs to be written in C++ or Rust from the outset. It's also reasonably possible to rewrite small codebases from Golang to, e.g. Rust for better performance. reply guappa 6 hours agorootparentIt really isn't, no. It joins an awkward syntax with bad API design and terrible safeguards. reply otabdeveloper4 5 hours agorootparentDon't be so mean, it's definitely a step up from PHP. reply trmantrl 5 hours agoparentprevThe technical pressure exerted on Python (which was resisted) is one thing. The social pressure incubated the most radical culture warriors the Internet has ever seen and its proponents have ruined the Python organization, driven away many people and have established a totalitarian and oppressive regime. Interestingly, Google has fired the Python team this year. The revolution eats its own? Anyway, Rust should take note and be extremely careful. reply bagxrvxpepzn 18 hours agoprevTo the people who work on C++ standards: I approve of the current C++ trajectory and please ignore all of the online noise about \"the future of C++.\" To anyone that disagrees severely with the C++ trajectory as stated, please just consider another language, e.g. Rust. I don't want static lifetime checking in C++ and if you want static lifetime checking, please use Rust. I am not a government contractor, if you are a government contractor who must meet bureaucratic risk-averse government requirements, please use Rust. I have an existing development process that works for me and my customers, I have no significant demand for lifetime checking. If your development process is shiny and new and necessitates lifetime checking, then please use Rust. To Rust advocates, you can have the US government and big tech. You can even have Linux. Just leave my existing C++ process alone. It works and the trade offs we have chosen efficiently accomplish our goals. reply aiono 5 minutes agoparentYou frame it like \"Rust advocates\" try to infiltrate into C++ language decision making and inject safety features into it. That's not the case at all. For years C++ committee simply ignored the need for safety and they didn't take Rust and lifetime analysis seriously. But now they themselves want it. reply natemcintosh 2 hours agoparentprevAnd what about, for example, those government contractors who are in the same position as you: they have a large C++ codebase that currently works, and is too big to re-write in rust? Now they're being asked to make it safer. How will they do that with the \"existing C++ process\"? reply pizlonator 3 minutes agorootparentThey can use Fil-C++ and then they get memory safety without any rewrites. reply jart 1 hour agorootparentprevDidn't Project Zero publish a blog post a few months ago, saying that old code isn't your security problem? They said it's new code you have to worry about. Zero also had copious amounts of data to demonstrate their point. In any case, if you really want to rewrite C++ in Rust, LLMs are fantastic at doing that. They're not really good yet at writing a new giant codebase from first principles. But if you give them something that already exists and ask them to translate it into a different language, oftentimes the result works for me on the first try. Even if it's hundreds of lines long. reply jesse__ 42 minutes agorootparentYeah I remember reading that post about bugs over time. IIRC 5 years was the time it takes for most bugs to get ferreted out. reply moregrist 2 hours agorootparentprevThe funny thing about government funding is that it may be easier to secure capital for a Rust rewrite than for ongoing maintenance to add static lifetimes and other safety features to an existing C++ codebase. Legislatures seem a lot more able to allocate large pots of money for major discrete projects than to guarantee an ongoing stream of revenue to a continuing project. reply AlotOfReading 18 hours agoparentprevC++ has lifetime rules just like Rust. They're simply implicit in the code and not enforced by the compiler. Do you prefer the uncertainty of silent miscompilations and undefined behavior to upfront compiler errors? You're already using a language with a strong type system, so it's confusing to me why you would choose to draw the line here. reply bagxrvxpepzn 17 hours agorootparent> Do you prefer the uncertainty of silent miscompilations and undefined behavior to upfront compiler errors? Yes because then I don't have to spend hours writing esoteric spaghetti code to prove something to the compiler that is trivially known to be true. Your error is assuming static lifetime checking is free. As an engineer, I use judgement to make context-dependent trade offs. If you like playing the compiler olympics, or your employer forces you to, please use Rust. reply roland35 17 hours agorootparentI've found that often when I am writing esoteric spaghetti rust code... I need to start thinking about what I am trying too do! Most of the time it's a bad idea :) reply HelloNurse 3 hours agorootparentIf one needs to \"prove something to the compiler\" it is usually something both complex and against the grain; on the other hand lifetime annotations are usually just \"promise something to the compiler\" to allow it to make a better job. reply wiseowise 1 hour agorootparentprev> Yes because then I don't have to spend hours writing esoteric spaghetti code to prove something to the compiler that is trivially known to be true. And that’s exactly the reason why we need more safety in C++. I’m terrified at amount of code in real world written with this mindset. reply rramadass 13 hours agorootparentprev> As an engineer, I use judgement to make context-dependent trade offs. Well said. This is why i am firmly in the Stroustrup camp of backward compatibility/zero overhead/better-C/etc. goodness of \"old C++\". I need to extend/maintain/rewrite tons of them and that needs to be as painless as possible. The current standards trajectory needs to be maintained. The OP article is a rather poor one with no insights but mere hoopla over nothing. reply th2oi34234234 6 hours agorootparentprevLOL; someone has definitely played with type-systems here. reply lelanthran 5 hours agorootparentprev> C++ has lifetime rules just like Rust. They're simply implicit in the code and not enforced by the compiler. The problem is that the rules enforced by Rust is not restricted to lifetime rules, it's a much much larger superset that includes quite a lot of safe, legitimate and valid code. reply AlotOfReading 4 hours agorootparentSure, but that's not a design philosophy C++ adheres to. Look at the modern C++ guidelines or profiles. The entire point is to rule out large swathes of safe, legitimate, and valid code in an optional and interoperable way. C++ isn't beholden to Rust's trade-offs either. There's a whole spectrum of possibilities that don't require broken backwards compatibility. Hence: \"Why draw the line specifically at lifetime annotations?\" reply PittleyDunkin 5 hours agorootparentprevThat's what the unsafe keyword is for. reply guappa 6 hours agorootparentprev> You're already using a language with a strong type system I'll have you know I made a variable void* just yesterday, to make my compiler shut up about the incorrect type :D reply bluGill 4 hours agoparentprevC++ is on the trajectory to create a future with more safety. Should we do profiles or static lifetime checking (or something else??) is still an open question (and both may be valid). However I'm glad c++ is thinking about that. We have real problems around safety in the real world and people are writing unsafe code even when modern safe code would be easier to write. Of course it remains to be seen how this all plays out. Static lifetimes can be done good or bad. Profiles can be good or bad. Even if whatever we come up with is done well that doesn't mean people will (I know rust programmers who just put unsafe everywhere). reply zozbot234 4 hours agorootparentProfiles are vaporware. The C++ folks are pushing a fantasy of \"full memory safety with no changes to existing code, not even annotations to enable sound static analysis.\" That's just a non-starter, there is no way to get to full memory safety from there unless you count very silly things like making \"delete\" and \"free()\" a no-op - and also running everything in a single thread for \"concurrency safety\". reply bluGill 3 hours agorootparentThe only way to get anywhere is provide a path forward. I have a lot of C++98 code that has been working just find for 14+years (that is since before C++11). It isn't worth changing that unless we discover a bug in the code (after 14+ years unlikely) or we need to add new features (if we haven't in 14+ years we probably won't need a new feature there anytime soon). Code I write today is the latest C++. What I really want is a way to say don't write the bad things today, but still allow that old code to work. That is what profiles promises to me. Sure we will never to get full memory safety that way, but that isn't my goal, I just want to make my new code better, and when I come back to old code improve that too. reply zozbot234 2 hours agorootparentThe case for \"100% Safe C++\" is that you might be able to annotate that old C++98 code in ways that don't otherwise alter its semantics, but still ensure safety. That would be a one-time cost that might be well-worth paying if the cost is low enough - Where \"cost\" depends on developer experience as opposed to mere volume of annotations. A \"viral\" compiler feature that auto-surfaces all the places that will need annotation for a given level of safety has the potential to be quite easy to learn and use effectively. It's not clear why the C++ folks are rejecting that approach, seemingly out-of-hand. reply bluGill 46 minutes agorootparentI have > 10 million lines of C++ that is not annotated. There are many projects much larger than mine. If you cannot automatically annotate the code there is no point in trying as you can't do it manually. If you can automate it why not just build that into the compiler and skip the syntax? reply GrantMoyer 15 hours agoparentprevWhile programming in Rust, I've never thought to myself, \"man, this would be so much easier to express in C++\". I've plenty of times thought the reverse while programming in C++ though. Edit: except when interfacing with C APIs. reply bowsamic 8 hours agorootparentThen you must be avoiding situations that traditionally use OOP reply zozbot234 7 hours agorootparentMost kinds of OOP can be expressed idiomatically in Rust. The big exception is implementation inheritance, which is highly discouraged in modern code anyway due to its complex and unintuitive semantics. (Specifically, its reliance on \"open recursion\", and the related \"fragile base class\" problem) reply galangalalgol 4 hours agorootparentPeople often say that modern c++ doesn't have the problems needing a solution like rust. Ironically that means people who write modern c++ haven't had any aramp up time needed when joining our rust projects. They were already doing things the right way. At least mostly. But now they don't have to worry about that one person who seems to be trying to trick the static analysis tools on purpose. reply kkert 13 hours agorootparentprevThis is interesting because i'm writing quite a bit of embedded Rust, and i always run into limitations of very barebones const generics. I always wish they'd have half the expressiveness of C++ constexpr and templates. Win some, lose some though, as the overall development workflow is lightyears ahead of C++, mostly due to tooling reply badmintonbaseba 9 hours agorootparentThe expressiveness of const generics (NTTPs) in C++ wouldn't go away if it adopted lifetime annotations and \"safe\" scopes. It's entirely orthogonal. Rust decided to have more restrictive generic programming, with the benefit of early diagnostic of mistakes in generic code. C++ defers that detection to instantiation, which allows the generics to be more expressive, but it's a tradeoff. But this is an entirely different design decision to lifetime tracking. reply zozbot234 7 hours agorootparentprevRust generics are not intended as a one-to-one replacement for C++ templates. Most complex cases of template-level programming would be addressed with macros (possibly proc macros) in Rust. reply galangalalgol 5 hours agorootparentConst generic expressions are still being worked. They are what is blocking portable simd. They are also a much cleaner way to implement things like matrix operations or really anything where a function with two or more arguments of one or more types returns things that have types that are a combination or modification of the input types. reply zozbot234 4 hours agorootparentThe problem AIUI is that \"const generic expressions\" in full generality are as powerful as dependent types. It's not clear to me that the Rust folks will want to open that particular can of worms. reply galangalalgol 4 hours agorootparentI thought dependent types were types that depended on a value? What they are proposing are types that depend on types or compile time constants. reply zozbot234 3 hours agorootparentThe problem is combining the \"const generic\" and \"expression\" part. If your \"compile time constants\" can actually be complex expressions, you arguably end up with the same kind of generality as dependent types. This is true even for expressions that are only evaluated in a compile-time context, since dependently-typed languages do \"everything\" at compile time anyway, they don't have a phase distinction where you can talk about \"runtime\" being separate. reply galangalalgol 3 hours agorootparentAh, yeah! I get it now. So c++ is a dependently typed language. That is hilarious. I want lisp syntax in c++29. That said, too many features are blocked on const generic expressions, so I think they are going to have to bite that off. There is already talk about migrating proceduralacros to be something more like normal rust, this moght fit in with that. reply Rusky 1 hour agorootparentC++ is not a dependently typed language, for the same reason that templates do not emit errors until after they are instantiated. All non-type template parameters get fully evaluated at instantiation time so they can be checked concretely. A truly dependently typed language performs these checks before instantiation time, by evaluating those expressions abstractly. Code that is polymorphic over values is checked for all possible instantiations, and thus its types can actually depend on values that will not be known until runtime. The classic example is a dynamic array whose type includes its size- you can write something like `concat(vector, vector) -> vector` and call this on e.g. arrays you have read from a file or over the network. The compiler doesn't care what N and M are, exactly- it only cares that `concat` always produces a result with the length `N + M`. reply galangalalgol 54 minutes agorootparentIn c++ it does care what N and M are at compile time, at least the optimizer does for autovectorization and unrolling. Would that not be the case with const generic expressions? reply afdbcreid 11 hours agorootparentprevThat's actually quite interesting because this is not an inherent limitation of Rust, and it is definitely planned to be improved. And AFAIK, today (as opposed to last years) it is even being actively worked on! reply sumanthvepa 8 hours agoparentprevThank you for this. C++ should NOT try to be Rust. I find modern C++ really nice to program in, for the work I'm doing - 3D graphics. The combination of very powerful abstractions and excellent performance is what I'm looking for. I'm more than willing to endure percived lack of safety in the language. reply tsimionescu 2 hours agorootparentThe lack of safety is perceived because it is there. There is no proof that anyone can write a C++ program larger than, say, 100k lines of code that doesn't have memory safety issues. reply logicchains 54 minutes agorootparentAnd that memory safety is completely not an issue if you're writing something like a game, trading system, simulation, internal application or science calculation where there's no potentially hostile users who could do real harm by hacking your code. It's just a class of bug that in modern C++ is generally far outnumbered by logic bugs. reply lubesGordi 33 minutes agoparentprevI don't know enough about what it would take to implement static lifetime checking. Is that fundamentally impossible to do in a backwards compatible way? reply aiono 2 minutes agorootparentIf you want alias tracking and lifetime checking, yes they are backwards incompatible. They need \"viral annotations\" if we speak with the C++ committee terminology. reply steveklabnik 11 minutes agorootparentprevIt depends on what you mean by \"backwards compatible,\" and what you mean by \"static lifetime checking\" :) The profiles proposal suggests adding static lifetime checking, \"without viral annotations.\" I use quotations because I don't really agree with this framing, but whatever. The paper is here if you'd like to read it yourself: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p30... The core idea here is that you add annotations to opt in or out of certain checks. And opting in may be a compiler flag, requiring no changes to source code. So that would be \"backwards compatibility\" in that sense. Of course, code may fail these checks, so you'll have to add annotations to opt out, or re-write the code. We will see in practice how much change is required once implementations exist and are tried out. But the other part is, these profiles do not attempt to cover all valid cases. And what I mean by that is, there are some lifetime issues that this proposal does not attempt to analyze. And, where the analysis is similar, they offer a subset of what other proposals do. These decisions were made because the authors believe that they'll reduce a significant number of issues, and are easier to adopt. And that's worth it instead of going for more checks. The competing proposal, Safe C++, has you opt into safety checks on a file-per-file basis. So in that sense, it is also backwards compatible: all existing code compiles as-is. When you opt in to those checks, it adds new syntax, similar to Rust, to do the safety analysis checks. So you gain this benefit for only new code, but it also you get much more power. This syntax is necessary to communicate programmer intent to the checks, but is the \"viral annotations\" that the proponents of profiles don't like. So, basically, that's the thing: both are backwards compatible, but offer very different tradeoffs in the design space. reply feelamee 16 hours agoparentprevOk. Please, just use your current C++ standard. But we will go to use the new one with all features we want to use. reply Attrecomet 9 hours agoparentprevWhat I don't understand is why you demand that C++ evolution be halted in a clearly suboptimal position so you don't need to change your processes. Just use the version of C++ that meets your needs, you clearly don't want nor need new developments. You are fine with being locked into bad designs for hash maps and unique ptr due to the (newly invented, in 2011/13) ABI stability being made inviolable, you clearly need no new developments in usability and security. So why not be honest and just use C++01, or 11, or whatever it is that works for you, and let the rest of the ecosystem actually evolve and keep the language we invested so much effort into as a viable alternative? There's zero benefit, except to MS who want to sell this year's Visual Studio to all the companies with 80's-era C++... reply bagxrvxpepzn 1 minute agorootparent> What I don't understand is why you demand that C++ evolution be halted in a clearly suboptimal position so you don't need to change your processes. I don't demand that C++ evolution be halted. I support the current trajectory of not adding viral annotations for the sake of implementing static lifetime checking. I want C++ to evolve into a better version of itself, I don't want it to become something it's not. If you want static lifetime checking, please use Rust. It already exists and it's great for people who need static lifetime checking. reply liontwist 6 hours agorootparentprev> evolution be halted in a clearly suboptimal position It’s clear it’s imperfect. But not clear there is an obvious path to a nearby local maxima. Design choices have tradeoffs. And even if that were true, who would take advantage of that “better” language in a purely abstract sense? New language standards primarily exist to benefit existing C++ code bases, and the cohort of engineers who work on them. You have to consider that social reality. reply diath 18 hours agoparentprevOn the contrary, why would I not want these things in C++ if I'm developing every project with -fsanitize=address,undefined to catch these types of errors anyway? reply chlorion 6 hours agoparentprevImagine an engineer in any other field acting like this. \"I don't want to install air bags and these shiny safety gadgets into my cars. We have been shipping cars without them for years and it works for us and our customers.\" The problem is that it doesn't actually work as well as you think, and you are putting people at risk without realizing it. reply andrewflnr 2 hours agorootparentYou're trying to install airbags on a motorcycle, though. The design of the vehicle/language is incompatible with airbags/lifetimes. So if you want airbags... don't use C++. (Yes, I know about airbag vests. Let's analogize those with external static checkers.) reply downut 4 hours agorootparentprevYou are making a general statement about the distribution of general consumers of computer languages, complete with a long tail, and the commenter is explaining that he is an expert car driver, way out there on the long tail. This tyranny of the less capable mode is really grating, especially on a site named \"Hacker News\". As usual, the answer is quite simple: \"please use rust\". We promise to never mention when we break out nasm. Driver anecdote: I have antilock brakes on my Tundra, but they are annoyingly counterproductive in 4WD descending 6\" or larger sandy rocky steps. Do antilock brakes work overall best for the less capable mode? Of course! Do they work best for me? No. reply ModernMech 4 hours agorootparentWe learned a long time ago as an industry that the expert car drivers are not immune to causing pile ups, which makes it all our problem to solve. Safety by default with escape hatches when absolutely necessary is the better way to go for all, even if it means some power users have to change their ways. reply mempko 30 minutes agoparentprevThis! The hardest part of making software is making something that works for people. What I love about C++ is multi-paradigm programming. I can express my ideas directly using the appropriate paradigms. Regarding safety, with modern C++ programming, it's not hard to write software that's correct. Safety is often never the first thing I worry about. If having strict safety means I can't express my mental models in code, I don't want it. It will slow me down. It will make it harder to write software that's useful. Remember people, we are here to make things that are useful to people. If safety gets in the way of that, then it's not worth it. reply 616c 18 hours agoparentprevnext [3 more] [flagged] umanwizard 12 hours agorootparentPlease don't shame people for using pseudonyms on here, regardless of whether you disagree with their concrete point. It's nice to have a place where people don't have to think about how their friends, family or colleagues will react before posting something. reply AnimalMuppet 17 hours agorootparentprev> But why say so under a pseudonym That's a rather odd complaint, coming from a pseudonym. reply jandrewrogers 16 hours agoparentprevThe parts of the government that think everything should be written in a memory-safe language (like Rust) are the same parts that already write everything in Java. Most of the high-end systems work is in C++, and that is the type of software where lifetimes and ownership are frequently unknowable at compile-time, obviating Rust's main selling point. reply AlotOfReading 16 hours agorootparentIt's not a hard dichotomy. Almost all of the rules Rust imposes are also present in C++, enforcement is simply left up to the fallible human programmer. Frankly though, is it that big a deal whether we call it unique_ptr/shared_ptr or Box/Arc if a lifetime is truly unknowable? Rust shines in the other 95% of code. I spend some time every morning cleaning up the sorts of issues Rust prevents that my coworkers have managed to commit despite tooling safeguards. I try for 3 a day, the list is growing, and I don't have to dig deep to find them. My coworkers aren't stupid people, they're intelligent people making simple mistakes because they aren't computers. It won't matter how often I tell them \"you made X mistake on Y line, which violates Z rule\" because the issue is not their knowledge, it's the inherent inability of humans to follow onerous technical rules without mistakes. reply galangalalgol 3 hours agorootparentYeah, I don't end up fighting rust very often, and when I do, it is right. And when I run into a case that it isnt, I have unsafe and the rustonimicon to help me. You can do anything in rust you can do in c++, it is just that rust defaults to safe instead of unsafe, and there is no single keyword to let you know the c++ you are looking at is safe. reply fefe23 5 hours agoprevOh no! Herb Sutter is leaving Microsoft?! That does not bode well for Microsoft. At least from the outside perspective it looks like he was the adult in the room, the driving force behind standards adoption and even trying to steer C++-the-language towards a better vision of the future. If he is gone, MSVC will again be the unloved bastard child it has long been before Herb's efforts started to pay off. This is very disheartening news. I'm happy he held out for this long even though he was being stonewalled every step of the way, like when Microsoft proposed std::span and it was adopted but minus the range checking (which was the whole point of std::span). Now he has been pushing for a C++ preprocessor. Consider how desperate you have to be to even consider that as a potential solution for naysayers blocking your every move. reply tux3 3 hours agoparentThe rumor that has been widely circulating is that the MSVC backend is being reused as a code generator for the Rust compiler (because nobody really understands PDBs anymore, not even Microsoft, and especially LLVM doesn't. So rustc could be a MSVC frontend instead to reuse all the existing arcane logic.) MSVC will continue to be used for many years, and especially the backend might see renewed effort. But I don't know about the C++ frontend specifically, I've seen complaints about more and more bugs on the cpp subreddit. It's possible MS will be investing a little less in C++. reply pjmlp 3 hours agorootparentDisregarding the rumor, it is quite public information that on Azure side, C and C++ are now only allowed for existing code bases, or scenarios where nothing else is available. Meanwhile on Windows side, it was made officially at Ignite that a similar decision is now to be followed upon Windows as well. Here the official stuff, so whatever happens to MSVC is secondary, https://azure.microsoft.com/fr-fr/blog/microsoft-azure-secur... https://blogs.windows.com/windowsexperience/2024/11/19/windo... reply _huayra_ 2 hours agorootparent> in alignment with the Secure Future Initiative, we are adopting safer programming languages, gradually moving functionality from C++ implementation to Rust. This seems like one hell of an initiative for the Windows OS. That is millions of lines of C++ code, often with parts from waaay back. A friend who works on one of the OS teams told me that his team got a boomerang hire that worked on Windows back in the 90s and he was still finding parts of his code in there! I hope this corporate interest bodes well for Rust though. It seems like for C++ it really caused a schism over the ABI break issue where Chandler et al were basically rebuffed finding some timeline to break it, and then Google dropped all their support on the committee in favor of Carbon, Rust, etc. reply pjmlp 1 hour agorootparentApple and Google focusing on their own stuff, is one of the reasons why clang lost velocity in ISO C++ adoption, most of the C++ compiler vendors that fork clang don't contribute frontend stuff only LLVM, and with them out, it took some time until new folks jumped in to replace their contributions. Likewise you will noticed MSVC is no longer riding the wave in regards to C++23, after being the first to fully support C++20. Then there are all those other compilers out there, lost somewhere between C++14 and C++17, and most likely never moving beyond that. reply bluGill 4 hours agoparentprev> Now he has been pushing for a C++ preprocessor. He has been showing it, but not pushing it. the difference is subtle but important. He is showing a lot of \"what ifs\" trying them, and pushing the useful ones back into the language. Reflection is on track for C++26 in large part because he inspired a lot of people with his metaclasses talk (a long time ago, but doing things right takes time) reply chrsig 4 hours agoparentprevIt looks like he's staying on the committee and what not, just changing his day job. That's actually one of the benefits of having a committee & iso standardization process -- things aren't so reliant on a single engineer staying employed at a single company. I'm sure it's never as clean a situation as anyone would like, but hey, world is a rough place sometimes. reply adambatkin 18 hours agoprevSomething that Rust got _really_ right: Editions. And not just that they exist, but that they are specified per module, and you can mix and match modules with different Editions within a bigger project. This lets a language make backwards incompatible changes, and projects can adopt the new features piecemeal. If such a thing came to C++, there would obviously be limitations around module boundaries, when different modules used a different Edition. But perhaps this could be a way forward that could allow both camps to have their cake and eat it too. Imagine a world where the main difference between Python 2 and 3 was the frontend syntax parser, and each module could specifically which syntax (\"Edition\") it used... reply CrendKing 18 hours agoparentBut Edition can exist only because Rust intrinsically has the concept of package, which naturally defines the boundary. C++ has nothing. How do you denote a.cpp be of cpp_2017 edition which b.cpp be cpp_2026? Some per-file comment line at top of each file? C++ is a mess in that it has too much historic baggage while trying to adapt to a fiercely changing landscape. Like the article says, it has to make drastic changes to keep up, but such changes will probably kill 80% of its target audiences. I think putting C++ in maintenance mode and keep it as a \"legacy\" language is the way to go. It is time to either switch to Rust, or pick one of its successor languages and put effort into it. reply umanwizard 12 hours agorootparentRust doesn't have the concept of package. (Cargo does, but Cargo is a different thing from Rust, and it's entirely possible to use Rust without Cargo). Rust has the concept of _crate_, which is very close to the concept of compilation unit in C++. You build a crate by invoking `rustc` with a particular set of arguments, just as you build a compilation unit by invoking `g++` or `clang++` with a particular set of arguments. One of these arguments defines the edition, for Rust, just like it could for C++. reply ynik 7 hours agorootparentThat only works for C++ code using C++20 modules (i.e. for approximately nothing). With textual includes, you need to be able to switch back and forth the edition within a single compilation unit. reply bluGill 3 hours agorootparentModules are starting to come out. They have some growing pains, but they are now ready for early adopters and are looking like they will be good. I'm still in wait and see mode (I'm not an early adopter), but so far everything just looks like growing pains that will be solved and then they will take off. reply epage 5 hours agorootparentprevMixing editions in a file happens in Rust with the macro system. You write a macro to generate code in your edition and the generation happens in the callers crate, no matter what edition it is. reply hypeatei 18 hours agorootparentprev> I think putting C++ in maintenance mode and keep it as a \"legacy\" language is the way to go I agree but also understand this is absolutely wishful thinking. There is so much inertia and natural resistance to change that C++ will be around for the next century barring nuclear armageddon. reply actionfromafar 17 hours agorootparentI don't think even that would suffice. :) reply adgjlsfhk1 17 hours agorootparentprevCobol's still around. Just because a language exists doesn't mean that we have to keep releasing updated specifications and compiler versions rather than moving all those resources to better languages. reply AnimalMuppet 17 hours agorootparentCOBOL's most recent standard was released in 2023, which rather ruins your point. reply bluGill 4 hours agorootparentprev> I think putting C++ in maintenance mode and keep it as a \"legacy\" language is the way to go That is not possible. The the following function in C++ std::vector doSomething(std::string); Simple enough, memory safe (at least the interface, who knows what happens inside), performant, but how do you call that function from anything else? If you want to use anything else with C++ it needs to speak C++ and the means vector and string needs to interoperate. reply zozbot234 4 hours agorootparentYou can interoperate via C ABI and just not use the C++ standard types across modules - which is the sane thing to do. Every other language that supports FFI via C linkage does this, only C++ insists on this craziness. reply galangalalgol 3 hours agorootparentAlso I wouldn't start by rewriting the thing that calls do_something, I'd start by rewriting do_something. Calling into rust from c++ using something like zngur lets you define rust types in c++ and then call idiomatic rust. You can't do it in the opposite direction because you cannot safely represent all c++ types in rust, because some of them aren't safe. reply bluGill 3 hours agorootparentI have millions of lines of C++. do_something exists and is used but a lot of those lines and works well. I have a new feature that needs to call do_something. I'm not rewriting any code. My current code base was a rewrite of previous code into C++ started before rust existed), and it costs a nearly a billion dollars! I cannot go to my bosses and say that expensive rewrite that is only now starting to pay off because of how much better our code is needs to be scrapped. Maybe in 20 years we can ask for another billion (adjust for inflation) to rewrite again, but today either I write C++, or I interoperate with existing C++ with minimal effort. I'm working on interoperation with existing C++. It is a hard problem and so far every answer I've found means all of our new features still needs to be written in C++ but now I'm putting in a framework where that code could be used by non-C++. I hope in 5 years that framework is in place by enough that early adopters can write something other than C++ - only time will tell though. reply galangalalgol 2 hours agorootparentYeah that use case is harder, but I'm involved in a similar one. Our approach is to split off new work as a separate process when possible and do it entirely in rust. You can call into c++ from rust, it just means more unsafe code in rust wrapping the c++ that has to change when you or your great grandchild finally do get around to writing do_something in rust. I am super aware of how daunting it is, especially if your customer base isn't advocating for the switch. Which most don't care until they get pwned and then they come with lawyers. Autocxx has proven a painful way to go. The chrome team has had some input to stuff and seem to be making it better. reply bluGill 3 hours agorootparentprevSure I can do that - but my example C++ function is fully memory safe (other than don't go off the end of the vector which static rules can enforce by banning []). If I make a C wrapper I just lost all the memory safety and now I'm at higher risk. Plus the effort to build that wrapper is not zero (though there are some generators that help) reply tsimionescu 2 hours agorootparentHow about going off the end of the vector with an iterator, or modifying the vector while iterating it, or adding to the vector from two different threads or reading from one thread while another is modifying it or [...]. There is nothing memory safe whatsoever about std::vector and std::string. Sure, they give you access to their allocated length, so they're better than something[] and char* (which often also know the size of their allocations, but refuse to tell you). reply bluGill 48 minutes agorootparent> going off the end of the vector with an iterator, The point of an iterator is to make it hard to do that. You can, but it is easy to not do that. > modifying the vector while iterating it Annoying, but in practice I've not found it hard to avoid. > adding to the vector from two different threads or reading from one thread while another is modifying it Rust doesn't help here - they stop you from doing this, but if threads are your answer rust will just say no (or force you into unsafe). Threads are hard, generally it is best to avoid this in the first place, but in the places where you need to modify data from threads Rust won't help. reply pjmlp 3 hours agorootparentprevOnly if using a hardened runtime with bounds checking enabled, without any calls to c_str(). reply SkiFire13 8 hours agoparentprev> And not just that they exist, but that they are specified per module Nitpick: editions are specified per crate, not per module. --- Also note that editions allow to make mostly syntactic changes (add/remove syntax or change the meaning of existing ones), however it is greatly limited in what can be changed in the standard library because ultimately that is a crate dependency shared by all other crates. reply wink 6 hours agoparentprevMy C++ knowledge is pretty weak in this regard but couldn't you link different compilation units together just like you link shared libraries? I mean it sounds like a nightmare from a layout-my-code perspective, but dumb analogy: foo/a/* is compiled as C++11 code and foo/b/ is compiled as C++20 code and foo/bin/ uses both? (Not fun to use.. but possible?) Is that an ABI thing? I thought all versions up to and including C++23 were ABI compatible. reply zozbot234 5 hours agorootparentHow does foo/bin use both when foo/a/* and foo/b/ use ABI-incompatible versions of stdlib types, perhaps in their public interfaces? This can easily lead to breakage in interop across foo/a/* and foo/b/ . reply bluGill 4 hours agorootparentprevWhat is the point? C++ is mostly ABI compatible (std::string broke between C++98 and C++11 in GNU - but we can ignore something from 13 years ago). The is very little valid C++11 code that won't build as C++23 without changes (I can't think of anything, but if something exists it is probably something really bad where in C++11 you shouldn't have done that). Now there is the possibility that someone could come up with a new breaking syntax and want a C++26 marker. However nobody really wants that. In part because C++98 code rebuilt as C++11 often saw a significant runtime improvement. Even today C code built as C++23 probably runs faster than when compiled as C (the exceptions are rare - generally either the code doesn't compile as C++, or it compiles but runs wrong) reply Maxatar 2 hours agorootparentThere are plenty of things between C++11 and C++23 that have been removed and hence won't compile: Implicit capture of this in lambdas by copy. std::iterator removed. std::uncaught_exception() removed. throw () exception specification removed. std::strstream, std::istrstream, and std::ostrstream removed. std::random_shuffle removed. std::mem_fun and std::mem_fun_ref, std::bind1st and std::bind2nd removed. There are numerous other things as well, but this is just off the top of my head. reply bluGill 52 minutes agorootparentNone of those things I've never used. Many of those are in bad practice for C++11. reply wink 3 hours agorootparentprevThere is no inherent point, I was just wondering, if it's possible, why people don't use such a homegrown module layout like Rust editions in C++. I only ever worked in a couple of codebases where we had one standard for everything that was compiled and I suppose that's what 90% of people do, or link static libs, or shared libs, so externalize at an earlier step. So purely a thought experiment. reply humanrebar 5 hours agoparentprevThe C++ profiles proposal is something like an \"editions lite\". It could evolve into more fully featured editions some day, though not without some significant tooling work to support prevention of severe memory and type safety issues across different projects linked into the same program. reply steveklabnik 17 hours agoparentprevThere was a similar proposal for C++, using rust’s original names: epochs. It stalled out. reply ykonstant 8 hours agorootparentThey should call them 'eras'. Then they can explain that epochs did not lead to a new era in the language, but eras will mark the next epoch of C++. reply kccqzy 1 hour agoparentprevThat's irrelevant. Look, the C++ committee has decided yet again not to break ABI. That is to say, they have affirmed that they DO NOT want backwards incompatible changes. So suggesting a way to make backwards incompatible changes is of no interest to the C++ committee. They don't want it and they have said so more than once. reply pornel 6 hours agoprevThere will be eventually only one faction left using C++ — the legacy too-big-to-refactor one. The other faction that has lost faith in WG21, and wants newer, safer, nimble language with powerful tooling is already heading for the exits. Herb has even directly said that adding lifetime annotations to C++ would create \"an off-ramp from C++\"[1] to the other languages — and he's right, painful C++ interop is the primary thing slowing down adoption of Rust for new code in mixed codebases. [1]: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p34... reply jmull 5 hours agoparent> newer, safer, nimble \"newer\" is hopefully a non-goal. Unfortunately, an option that is both safer and nimble doesn't appear to exist. I'm still hopeful, but at the moment it looks like rust is our future. A fate only marginally better than C++. reply marcosdumay 2 hours agorootparentEverything out there is nimbler than C++. So you only have to select for safer to get those, and anything with managed memory and Rust are safer. (Not an exclusive set, but you'll need to actually evaluate other options.) reply omoikane 2 hours agoprev> Stories of people trying their best to participate in the C++-standard committee process across multiple years This links to: https://thephd.dev/finally-embed-in-c23 It was a fascinating story, particularly about how people finally coming to terms with accepting that a seemly ugly way of doing things really is the best way (you just can't \"parse better\"). The feature itself is interesting too. https://gcc.godbolt.org/z/jGajc6xd5 reply munificent 34 minutes agoprevI really really like this article. I think the two camps the author describes very much reflect my experience over the past couple of decades at a dotcom startup, then a game developer, and now at Google However, I think the author is a little off on the root cause. They emphasize tooling: the ability to build reliably and cleanly from source. That's a piece of it, but a relatively small piece. I think the real distinguishing factor between the two camps is automated testing. The author mentions testing a couple of times, but I want to emphasize how critical that is. If you don't have a comprehensive set of test suites that you are willing to rely on when making code changes, then your source code is a black box. It doesn't matter if you have the world's greatest automated refactoring tools that output the most beautiful looking code changes. If you don't have automated tests to validate that the change doesn't break an app and cost the company money, you won't be able to land it. Working on a \"legacy C++ app\" (like, for example, Madden NFL back when I was at EA) was like working on a giant black box. You could fairly confidently add new features and new code onto the side. But if you wanted to touch existing code, you needed a very compelling reason to do so in order to outweigh the risk of breaking something unexpectedly. Without automated tests, there was simply no reliable way to determine if a change caused a regression. And, because C++ is C++, even entirely harmless seeming code changes can cause regressions. Once you've got things like reinterpret_cast, damn near any change can break damn near anything else. So people working in these codebases behave sort of like surgeons with a \"do no harm\" philosophy. They touch as little as possible, as non-invasively as possible. Otherwise, the risk of harming the patient is too high. It's a miserable way to program long-term. But it's really hard to get out of that mess once you're in it. It takes a monumental amount of political capital from engineering leadership to build a strong testing culture, re-architect a codebase to be testable, and write all the tests. A lot of C++ committee changes aimed at legacy C++ developers are about \"how can we help these people that are already in a mess survive?\" That's a very different problem than asking, \"Given a healthy, tested codebase, how can we make developers working in it go faster?\" reply shultays 9 hours agoprev“We must minimize the need to change existing code. For adoption in existing code, decades of experience has consistently shown that most customers with large code bases cannot and will not change even 1% of their lines of code in order to satisfy strictness rules, not even for safety reasons unless regulatory requirements compel them to do so.” – Herb Sutter with large code bases cannot and will not change even 1% of their lines of code in order to satisfy strictness rules Do people really say this? Voice this in committee? I have been in a few companies, and one fairly large one, and all are happy to and looking forward to upgrade newer standards and already spend a lot of time updating their build systems. Changing 1% of code on top of that is probably not really that much compared reply loup-vaillant 7 hours agoparent> Changing 1% of code on top of that is probably not really that much compared Quite a few companies have millions and millions of lines of code. Changing 1% of it would mean changing more than 10K lines of code, perhaps even more than 100K. In much bigger code bases, where changing anything has a risk of breaking something — not just because you might make a mistake, but because your program is full of Undefined Behaviour, and changing anything might manifest latent bugs. Given that, I'm not surprised people say that Sutter quote with a straight face. reply bregma 7 hours agoparentprevMany of my customers are in an industry with a huge C++ code base and it's all under active development. Safety certification requirements are onerous and lead-times for development are long: many are now experimenting with C++17 and C++20 is on the long-term horizon but not yet a requirement. Because of the safety certification requirements and the fact that the expected lifecycle of the software is the order of decades after their products have been released, changing any lines of their code for any reason is always risky. Lives can be at stake. But this is a multi-billion-dollar industry. If you're working on scripting a little browser \"app\" for a phone things may be different. reply titanomachy 2 hours agorootparent“Little browser apps for phones” are a trillion-dollar industry reply nicce 4 hours agorootparentprevIs there a lot of manual work for getting the new certificate? E.g. is human rewiewing the code? If not, someone should build CI pipeline for the certification process. reply bluGill 3 hours agorootparentHundreds of hours of manual testing. I don't have to do safety certificates, but my code gets 500 hours of manual testing (I'm not allowed to give real numbers, these numbers are close enough) - they find enough critical can't ship issues where the fix is risky enough to start all over that we typically are doing 2500 hours of manual testing. on every release. We have a large automated test suite that runs on every build and takes hours. The problem with automated tests is they only verify situations you thought of work the way you think they should, while human testers find slight variations of setup that you wouldn't think matter until they do. Human tests also find cases where the way you expect things to work don't make sense in the real world. reply rwmj 7 hours agoparentprevPeople just don't make mass changes to existing working code. Mostly they cannot. Even if the tooling was available, which it's not, it's also about reeducating their developers, who don't want to or can't change. Plus it'd have to be recertified. It's all cost with no benefit. Except, allegedly, at Google. But is there any evidence they actually do this, eg. in public code bases? Or is it just hype? reply Someone 9 hours agoparentprevCould be selection bias. Companies (or departments within companies) who are still actively developing their C++ code probably tend to hire more developers and consultants than companies who are doing minimal maintenance on their code base, and that might correlate well with the “two factions of C++” discussed here. “Our code is an asset” ⇒ code kept up-to-date “Our code is a burden, but we need it” ⇒ change averse reply otabdeveloper4 5 hours agoparentprev> Changing 1% of code on top of that is probably not really that much compared Changing 1% across all modules is a nightmare. Changing one module which is 1% of the code is nothing. reply Hilift 9 hours agoparentprevAre you referring to his book written 20 years ago or 25 years ago? \"customers with large [C++] code bases\" there aren't that many of these. Vendors, government. With code bases that have stewards, not programmers. reply torginus 5 hours agoprevI have been saying this for a more than a decade, but the number one thing that killed C++ as an attractive modern language is (the lack of) modules - the ability to include C++ code and libraries from others (perhaps with transitive dependencies), would allow an actual community of devs and companies spring up around the language. Instead we have greybeards and lone warriors, and million-line legacy codebases, half of which have their own idea on what a string or a thread is. reply fsloth 5 hours agoparent” killed C++ as an attractive modern language” I’m not sure were you got this perception that it’s dead. C++ remains the only game in town in many domains. That said, _unless you work in those domains_ there is no good reason to use C++ IMHO. Apart from the legacy codebases, there’s lots of C++ greenfield development. ” the ability to include C++ code and libraries from others ” Libraries in vcpkg - a large number - are compatible enough to be used in this sense. It’s possible your specific domain is lacking contributions or you’ve been looking from the wrong places? reply MichaelZuo 4 hours agorootparentYeah, a ‘module’ based system of various language is so much less efficient that it seems absurd to compare them for anything that actually requires that performance. reply torginus 4 hours agorootparentHonestly not sure what you mean by that - in C#, for example it doesn't matter to the compiler where the code comes from, it can be JITed/inlined just the same even if its coming from a different dll. I haven't seen any perf impact of splitting stuff between files/js modules in typescript either. What I'm guessing is that you mean that static compilers, like that of C++, need to be able to 'see' large amounts of code to make clever inlining optimizations. Which shouldn't be the case if the code is well designed, and/or the compiler can prove invariants necessary for optimization without having to look at the body of the code. reply pjmlp 5 hours agoparentprevModules could be better, the problem are some greybeards and lone warriors (thankfully not all), that insist using C++ as it was plain old C. Basically, it is no different than renaming .js to .ts to take advantage of some stuff in Visual Studio Code, while keep writing plain old JavaScript. reply eej71 5 hours agorootparentI think the struggle with modules has much more to do with the complexity of the problem at hand. I think the solution looks very easy should one be willing to dispense with large parts of the ecosystem. But if your goal is to keep the ecosystem together and not break the world (ala python 2/3 or perl5/6) and solve the problem at hand (waves vaguely at modules) - then its a really hard problem. I wish I could say modules don't work, but I have yet to understand them. Which is probably a big part of its problem. reply pjmlp 4 hours agorootparentAll my hobby coding in C++ makes use of modules. Visual C++ and clang, alongside MSBuild and CMake/ninja. As for ecosystem fragmentation, it has been the same old story since WG14 and WG21 exist, each compiler and platform is their own snowflake of what they actually support. reply _huayra_ 2 hours agorootparent> All my hobby coding in C++ makes use of modules. Do you have an example (of yours or others) that you could link? I've been trying to get this up and running myself, but can't seem to whisper the right CMake prayers. reply pjmlp 1 hour agorootparentSure, https://github.com/pjmlp/RaytracingWeekend-CPP reply imtringued 4 hours agorootparentprevStop using python 3 as an example. It is really tiring to hear about an extreme case of gross incompetence over and over again, while over in say the Grails/Spring ecosystem I don't even bother upgrading Grails 3 or 4 Plugins to Grails 6, because they still work as intended. When you upgrade a plugin from one version to the next, you're just swapping out build.gradle, gradle wrapper and a bunch of ancillary properties files. The build system changes, but everything else stays the same with only a tiny tiny minority of plugins being affected and even then the things that broke are absolute nonissues that can be fixed relatively quickly. It is kind of interesting how the python community hasn't learned a thing from python 2/3. The problem isn't breaking backwards compatiblity. Probably the biggest mistake you can do is act like breaking backwards compatiblity is a big deal, therefore you should pile up as many breaking changes as possible and release them all at once so as to maximize pushback and upgrade friction. It is in fact the exact opposite. If you break 10 libraries out of a million, you as the language developer can step in and upgrade them on behalf of the original maintainer. The users increment a library version when they increment the language version and done. reply bluGill 3 hours agorootparentPython3 is a great example. They looked at what others had done. They carefully thought about the problem. They build tools to migrate. They announced plans. They really thought they had found a better answer that would work out because they had planned for everything. Of course we are now looking at things in hindsight and see what didn't work. reply earthboundkid 2 hours agorootparentIt's really important to be clear about the lessons to be learned from Python 3. 1. Forward compatibility is more important than backward compatibility. 2. Automated refactoring tools don't help with 1. The problem wasn't that they broke a lot in Python 3. It was that you couldn't write your Python 2 in such a way as to be compatible with it until well into the transition process as the six package got popular and the devs fixed needlessly broken things in Python 2. reply VyseofArcadia 4 hours agorootparentprevI have seen a lot of C++ code that has a lot of \"this is clearly just C\" in it. None of it is because of \"greybeards and lone warriors\". All of it was because it started as a C codebase, and sometime in the mid to late 90s when object-oriented fever swept the world they started just adding C++ on top of the existing C codebase. Given that the general industry approach to technical debt is \"yes, more please\", it is unsurprising to me that any sufficiently old C++ project still has lots and lots of plain C inside it. reply pjmlp 3 hours agorootparentExcept the complaint equally applies to green field projects. reply mgaunard 9 hours agoprevIf you're comparing Herb Sutter and the Google people at the standard committee, there is one thing that was clear: Herb was good at getting people to agree on compromises that served everybody, while Google was mostly claiming they knew better than everybody else and pushing their own agenda. reply danpalmer 18 hours agoprevPython similarly has 2-3 factions in my experience: teams doing engineering in Python and using all the modern tooling, linting, packaging, types, testing, etc; teams doing data science and using modern but different tooling (i.e. Anaconda); and teams that don't get onboard in any of the language health initiatives and are on unsupported language versions with no packaging, tooling, linting, etc. Javascript/Node/Typescript has even more identifiable factions. I think developing factions around these things is unfortunately normal as languages grow up and get used in different ways. Rust has arguably tried to stay away from this, but the flip side is a higher learning curve because it just doesn't let certain factions exist. Go is probably the best attempt to prevent factions and gain wide adoption, but even then the generics crowd forced the language to adopt them. reply dehrmann 16 hours agoparentWhen you put it this way, personas might be a better term than factions. reply danpalmer 15 hours agorootparentYeah I think that's a much friendlier term. I do think language ecosystems have a hard time, because on the one hand they should be aiming to be as useful as possible, which means doing more, on the other hand they have to acknowledge that any given user will likely not use all the language and that the rest of it may hinder them, which means doing less. C++ does a lot, but has a big disengaged crowd, for many reasons, and that crowd will suffer from the push forward. Python and Node are similar. reply AlotOfReading 18 hours agoprevProfiles aren't a mess because they're intended for legacy codebases instead of big tech monorepos. They're a mess because they're not a serious effort. There's no actual vision of what problems they're trying to solve or what the use cases are, or even what kind of guarantee profiles are going to make. reply seanhunter 8 hours agoprevPorts of massive legacy codebases are possible and they happen. They can be extremely difficult, they take will and effort but they can get done. The idea that you have to slow down the development of the language standard for people who won't port to the new version is weird- Those people won't be updating compilers anyway. How do I know this? I migrated a codebase of about 20m lines of C++ at a major investment bank from pre-ansi compilers to ansi conformance across 3 platforms (Linux, Solaris and Windows). Not all the code ran on all 3 platforms (I'm looking at you, Solaris) but the vast majority did. Some of it was 20 years old before I touched it - we're talking pre-STL not even just pre ansi. The team was me + one other dude for Linux and Solaris and me + one other different dude for windows, and to give you an idea the target for gcc went from gcc 2.7[1] to gcc 4[2], so a pretty massive change. The build tooling was all CMake + a bunch of special custom shell we had developed to set env vars etc and a CI/CD pipeline that was all custom (and years ahead of its time). Version control was CVS. So, single central code repo and if there was a version conflict an expert (of which I was one but it gives me cold sweats) had to go in, edit the RCS files by hand and if they screwed up all version control for everyone was totally hosed until someone restored from backup and redid the fix successfully. While we were doing the port to make things harder there was a community of 667 developers[3] actively developing features on this codebase and it had to get pushed out come hell or high water every 2 weeks. Also, this being the securities division of a major investment bank, if anything screwed up real money would be lost. It was a lot of work, but it got done. I did all my work using vim and quickfix lists (not any fancy pants tooling) including on windows but my windows colleague used visual C++ for his work.[4] [1] Released in 1995 [2] Released in 2005 [3] yes. The CTO once memorably described it to me as \"The number of the beast plus Kirat\". Referring to one particularly prolific developer who is somewhat of a legend on Wall Street. [4] This was in the era of \"debugging the error novel\" so you're talking 70 pages of ascii sometimes for a single error message wit",
    "originSummary": [
      "The C++ community is split between modern tech companies seeking advanced features and legacy users reliant on outdated systems, creating a tension in the language's evolution.- The C++ Evolution Working Group's focus on backward compatibility conflicts with the demand for modern features and safety, leading to dissatisfaction among some major tech players.- In response to these challenges, the US government and companies like Google are exploring or developing alternative languages, such as Rust, which prioritize safety and modern capabilities over backward compatibility."
    ],
    "commentSummary": [
      "The C++ community is divided between maintaining legacy codebases and adopting modern, safer language features, with a focus on the challenges of refactoring without automated testing.",
      "The article highlights Google's significant influence in the C++ standards committee and the difficulty of evolving the language without disrupting existing code.",
      "Similar factional divides and complexities in language evolution are noted in other programming languages like Python and Rust."
    ],
    "points": 314,
    "commentCount": 361,
    "retryCount": 0,
    "time": 1732490496
  },
  {
    "id": 42231148,
    "title": "Bluesky is on the verge of overtaking Threads in all the ways that matter",
    "originLink": "https://mashable.com/article/bluesky-gaining-ground-on-competitor-meta-threads",
    "originBody": "Bluesky, the formerly Jack Dorsey-affiliated, decentralized answer to Elon Musk's X is closing the gap with Threads at breakneck speed. The browser version of Bluesky surpassed Threads in total usage weeks ago, but now the Bluesky app has exploded to 3.5 million daily active users, putting it just 1.5 times behind Meta’s Threads — an impressive feat considering the Threads app had 5x Bluesky's active users at the start of the month. SEE ALSO: People are importing their lame tweets to Bluesky The momentum shift has been nothing short of seismic, especially in the wake of the November 5 election. According to Similarweb data reported by the Financial Times, Bluesky’s user base has ballooned by 300 percent since Election Day. Journalists, academics, and companies are fleeing Elon Musk’s chaotic X (formerly Twitter) in droves, and Bluesky is quickly becoming their platform of choice. Why Bluesky over Threads? Meta CEO Mark Zuckerberg’s decision to downplay political content on Threads appears to have turned off many users seeking vibrant public discourse. Critics see it as an attempt to stay in President-elect Donald Trump’s good graces, effectively neutering the platform’s potential as a forum for political and cultural debate. Mashable Light Speed Want more out-of-this world tech, space and science stories? Sign up for Mashable's weekly Light Speed newsletter. Sign Me Up By signing up you agree to our Terms of Use and Privacy Policy. Bluesky has quickly become the go-to platform for what commentator Max Read has called the \"Politically Engaged Email Job Blob\" — the same cohort that helped transform early Twitter into the cultural juggernaut it once was. That said, Bluesky is still very much a work in progress. Its rapid growth has brought its share of headaches, including outages, glitches, and scammers. As more users flock to this latest \"Twitter replacement,\" expect some inevitable growing pains along the way. Topics Social Media Meta",
    "commentLink": "https://news.ycombinator.com/item?id=42231148",
    "commentBody": "Bluesky is on the verge of overtaking Threads in all the ways that matter (mashable.com)280 points by gnabgib 20 hours agohidepastfavorite322 comments thekevan 17 hours agoI still feel that an enormous amount of why threads shows up in data analytics is because Instagram just added it on and made an account for everyone. It wasn't adopted, it was falsely created. I'd go even further to say that it isn't a social network, it's an add-on to another social network. reply hughesjj 17 hours agoparentIt reminds me of google plus. Technically better than the existing top dog, but the forced migration and trying to bootstrap with a huge but only semi involved userbase let it fizzle soon after the start. Has there ever been a successful case of bootstrapping a new social media product with an existing userbase? Like not just added features or merging two together. reply citizenkeen 16 hours agorootparentGoogle+ was wildly successful in certain circles. Tabletop RPG design still hasn’t entirely recovered from its loss. Google+ was successful from any real metric but it didn’t replace Facebook so it was axed. reply hughesjj 13 hours agorootparentI definitely preferred it to Facebook, even before the feed became 100% inflammatory political stuff or ads and 0% my friends reply plufz 6 hours agorootparentprevBy which metrics was Google+ successful? I don’t doubt you, I just never heard that before. reply blntechie 5 hours agorootparentI can't say user metrics but Google Photos came out of Google+ and it is a massively successful product. Hangouts (now Meet?) was also a product out of Google+ but considering GChat (the xmpp version) existed before, it was kind of a step backwards. I think Google Local Guide also has some parts of Google+, not sure. reply Fluorescence 4 hours agorootparentIMHO Google Photos was also just brand/infra-churn because it replaced Picasa Web Albums. reply AlchemistCamp 16 hours agorootparentprevYes. WeChat bootstrapped off of QQ accounts, which were basically like Yahoo or MSN messenger + pages for desktop users. reply wink 5 hours agorootparentprevNot sure how you define \"technically better\" but in any way I'd add \"citation needed\". G+ was kinda horrible with a couple good ideas and I think the lack of widespread adoption spoke for that. reply wolpoli 15 hours agorootparentprevIt's not exactly new social media product, but Facebook did add messaging to their then Facebook app, build up usage of messaging itself (network effect within the user's friend list), and then split it off into its own Messenger app. They are sharing the same Facebook login through. reply protocolture 12 hours agorootparentprevWell Facebook bootstrapped using the MySpace userbase. reply crossroadsguy 11 hours agorootparentWhen MySpace essentially died. There was no such void to fill for Google+. reply crossroadsguy 11 hours agorootparentprevI never used and would never use Threads for the same reason I never even considered Google+. It was DoA and I guess everyone could see it, even the people who were trying it. Such is the case with Threads. I mean that morning when Zuck woke up and decided that a Threads a/c would need an Instagram a/c he must have seen on his daily astronomy calendar \"Day of self-sabotage\". reply result2vino 8 hours agoparentprevNo they don’t. That’s untrue. The fact that so many replies are speaking as if it’s true is quite telling. Instagram continually pesters me to create a Threads account, but doesn’t just “make one for me”. Threads’ user growth would look very very different if this were true. It’s another app. Instagram won’t even let you expand one of the stupid Threads posts it shows you until you install the app. reply dgeiser13 15 hours agoparentprevFor the most part the types of people who find Instagram interesting (and would have a Threads account created automatically) are simply not the audience for a tool like Bluesky (or Twitter). reply result2vino 8 hours agorootparentThis is dripping with personal bias. Bluesky gets the stamp of being a “tool”. It can be just as much of a mind-numbing fuckaround as Threads. Most replies in this thread are just starting from “Bluesky is where my people are” and trying to turn it into something self-righteous. Why are HN users so afraid of admitting that they’re dumb humans like everyone else? Christ. reply plufz 6 hours agorootparentAbsolutely. But I still think there is a difference with Bluesky and the other big social medias with full customization of how the feed(s) works, third party servers, custom labelers, etc. To me it seems plausible that they actually want to create more of an empowering tool that the users can control. That will of course not stop users from using ”dumb” feeds. But the users doesn’t have the incitament of Facebook to always produce higher engagement and show more ads. It is of course also troublesome that we do not know how Bluesky will act down the road to get their ROI. reply jjaksic 13 hours agorootparentprevYes, this! I wanted to join Threads as an alternative to Twitter, but I changed my mind when it tried to force me to create an Instagram account. I don't want an Instagram account because I think posting or looking at people's pictures is idiotic. So as long as Threads requires me to touch Instagram in any way, it's a hard pass. reply rcpt 15 hours agoparentprevThreads is so confusing. I have no idea who's replying to who when I click into a discussion. reply tylerchilds 12 hours agoparentprev100%. i wouldn’t say falsely created, but i would say “padded statistics” threads is beholden to KPIs unlike every other activity pub implementation their team obviously wants to be successful to continue developing against activity pub their metrics are akin to a company bragging about how much software they’ve written with the assistance of AI threads was able to approximate how many instagram users wished they had twitter in the same way intellisense is able to provide auto complete for dot notation; as a magician, i spot the misdirection for investors reply Yizahi 7 hours agoparentprevThat's false. I've tried their app once and they certainly did not made an account automatically. reply crossroadsguy 12 hours agoparentprevI agree. But then a big premise of Bluesky (hence AT Proto) is that it is not centralised however when we say BlueSky we just mean Bluesky i.e https://bsky.app and that is, frankly, very concerning. It might not sustain. While Threads is just forced Instagram users, bsky is a decentralised social network which is not decentralised. Comparing bsky with Threads is anything but a compliment. reply xyzabcrst 17 hours agoparentprevSame thing happened to TikTok and Lemon8 recently, though the move had to do more with US banning. reply bloomingkales 17 hours agoparentprevYou know, they stopped Amazon from buying iRobot because of I guess unfair robot vacuum competition (why does that sound hilarious?). It's almost luck that Threads isn't that successful, because then they'd have to deal with monopoly concerns. At least now they can just say it's a shitty twitter knock off, don't bother us. reply TiredOfLife 11 hours agoparentprev> Instagram just added it on and made an account for everyone. They didn't. reply paxys 18 hours agoprev> but now the Bluesky app has exploded to 3.5 million daily active users, putting it just 1.5 times behind Meta’s Threads Are they implying that Threads has just ~5 million daily active users? Adam Mosseri shared in the beginning of November that they have 275 million monthly active users. Bluesky meanwhile has 20 million total users. Considering the author hasn't shared a single source for their claim, I find it hard to believe. Realistically he is off by at least an order of magnitude. Mashable used to be one of my go-to blogs, but I haven't been there in a while. Has it really fallen this far? reply sockaddr 17 hours agoparentI’d bet Meta is counting all the random Instagram users that accidentally interact with the forced threads clickbait posts in their feed. reply EasyMark 21 minutes agorootparentI click on it randomly to see if anything is going on and usually close it pretty rapidly, so that is almost a false positive. I find bsky much more of of a time sink reply jazzyjackson 15 hours agorootparentprevIt's so transparent too, the way every single threads post shown in the Instagram widget ends halfway through with \"...\" I've managed to never go there because I'm only on Instagram for the pretty pictures reply rightbyte 10 hours agorootparentAha I see clearly now. So that is my Reddit make you reload a comment thread when you click the 'expand thread' sometimes. To get more add views? I just thought it was inline with all their other crappy ux choises. In this case they want to increase some KPI instead. reply result2vino 8 hours agorootparentChrist. Some people are willing to believe anything when it affirms their baseless beliefs. You’ve taken some reply that was about another situation entirely and let it convince you. I can think of multiple more likely explanations. Enough for this to at least be in the “who knows?” bucket. reply rightbyte 4 hours agorootparentYe I had a revelation about something totally unrelated, when reading about one KPI hack, that the Reddit load new page upon clicking expand comment, also most likely is one. What would be a good reason for that, that is not KPI hacking? The extra text is bogger all bandwidth wise. reply blitzar 4 hours agorootparentSocial networks hook users in with the one little trick ... click here to find out why you should be using it too. reply Yizahi 7 hours agorootparentprevYou can't interact with that without creating a Threads account (manually) and without having Threads app installed at the moment of click on the Instagram embed. And if you did that, you are a proper user of Threads, so no double count happens. reply subarctic 16 hours agorootparentprevBut that doesn't really matter right? They got tricked into using it but they're still using it reply afavour 16 hours agorootparentIt does. If all you do is tap on a post then immediately hit back you’re not really engaging with the platform. But I’m sure they’ll still count you as an active user. The meaningful stats would be number of posts seen, engaged with, and number of posts the user made themselves. reply drivingmenuts 15 hours agorootparentDoes Google do that for advertising? I always wonder if my little game of hitting SKIP ASAP shows up as a valid engagement or a user-bailed or something. And the ads, I can't skip, I hate those MFers. reply nitwit005 15 hours agorootparentThey have a general metric for it: > An ad is counted as viewable if at least 50% of its area is visible for at least 1 second for display ads, or at least 2 seconds for video ads. https://support.google.com/google-ads/answer/7029393?hl=en reply prisenco 16 hours agorootparentprevIt certainly matters as a bellwether for future traction. reply ElCapitanMarkla 17 hours agorootparentprevBe interesting to see if they count people with the app or not. As far as I’m aware you need the app to view threads in their entirety. I tried it but uninstalled shortly after reply 101008 16 hours agorootparentTreads is accesible via the browser now too reply jacoblambda 17 hours agoparentprevThis seems to be where they are getting the data from (as they get their data from FinancialTimes who get it from SimilarWeb) https://www.similarweb.com/blog/insights/social-media-news/b... reply AznHisoka 13 hours agoparentprevI wonder how many of those 20 million BlueSky users are squatters that are registering every popular brand name, in the hope it becomes a lot more valuable in a year reply NoahKAndrews 13 hours agorootparentYou can use your domain as a handle, so apple.bsky.social is likely to be a fake, as the real Apple would have the account apple.com. Certainly you could fool some users, but it's not like Apple would want apple.bsky.social to use as their actual account. reply paxys 13 hours agorootparentSure but if you are Jim you'd want to register jim.bsky.social, regardless of whether you intend to use the service or not. reply n1c 10 hours agorootparentThere's an interesting dynamic because of the domains, I originally registered with `n1c.bsky.social` because like you say whether I intended to use the service or not it's nice to lock in the name. But then the next level is that it's actually more valuable or makes more sense for me to use it as `n1c.dev` as it's more closely tied to \"me\". I am kinda sad that now someone else who isn't me is n1c.bsky but so be it. reply pbronez 40 minutes agorootparentI think this is a meaningful security problem. Most users won't know that the domain name matters. They'll learn eventually, but lots of opportunity for mischief in the medium term. If you have `n1c.bsky` and then migrate to `n1c.dev`, Bluesky should set `n1c.bsky` as a redirect to your destination domain by default. If you ever choose to terminate that redirect, `n1c.bsky` can go back in rotation... but it should have an immutable record that you registered the name originally, migrated to `n1c.dev`, maintained a redirect, and released the redirect on . reply tylerchilds 12 hours agorootparentprevthat would defeat the purpose of a decentralized network if only one person was jim, jim. reply frithsun 19 hours agoprevIt's inevitable that social media will split up into separate and distinct networks of people who can no longer stand or even undertand the other sociopolitical tribes. All of us sharing a singular global network was an exceptional and ephemeral circumstance. reply cosmic_cheese 18 hours agoparentI don’t think it’s inevitable at all. In fact I believe that the present day situation boils down to one thing only: the prioritization of engagement at the cost of all else. That’s what set us down this road. It incentivizes inflammatory posting that eschews nuance and context and twists and exaggerates the subject matter in order to provoke emotional responses — whether they be angry replies, “dunk” quote-posts, reposts, or even spending a couple extra seconds with the post on screen. Anything to steal away more of your attention and mindshare. Over time, this has polarized people to ever further extremes and normalized disrespect and bickering (as opposed to discussion). It would be an interesting experiment to see the effects of effectively the polar opposite of twitter, where ragebait and other attention-seeking behaviors are actively punished, with the content that’s most readily surfaced instead being that which is thoughtful, candid, and not emotionally charged. reply anon7000 17 hours agorootparentAdded to that is user choice over moderation and algorithms. That’s what’s truly interesting about BlueSky. It allows for side A and B to both exist, with people who want to be more isolated in a safe space (so to speak) to do so. That’s a really great property. If I want to engage with content I severely disagree with, I can put it in a feed I check infrequently so that it doesn’t impact my life. Humans aren’t good at coping with a constant barrage of disagreeable (for one’s personal definition of disagreeable) or inflammatory content. reply cosmic_cheese 17 hours agorootparentI like that aspect about Bluesky too. On “safe spaces”, as you hint at I think many of us don’t want to be shielded entirely from opposing or otherwise differing lines of thought. Speaking personally, I welcome it if there’s actual discussion to be had. Good faith discussions and exchange of perspectives is great, but I have no patience for trolls, circular logic, insults, “debate” that wouldn’t even pass for high school level, etc. reply EasyMark 18 minutes agorootparentI would love to see a respectful debate starter pack on bluesy get started. Maybe controled by a bot that looks for words that are insults like “troll” “don’t melt snowflake”, etc and will boot you if you get caught. I like political debate, sharing of trustable sources, etc. I don’t like someone telling me I’m just a melting snowflake or cuck, when I bring in a link from a scientific journal to cite as part of my argument reply raxxorraxor 11 hours agorootparentprevThen you need to choose the safe space option. Under no circumstances should you opt to advertise removing content for others. Because your justification with \"circular logic\" could mean anything. This is the safe space option. That more free platforms employ spam protection is no excuse. reply cosmic_cheese 4 hours agorootparentI think circular logic is fairly well defined (from Wikipedia, “Circular reasoning is a logical fallacy in which the reasoner begins with what they are trying to end with. Circular reasoning is not a formal logical fallacy, but a pragmatic defect in an argument whereby the premises are just as much in need of proof or evidence as the conclusion.”) That said, yes it’s not grounds for a ban. I wouldn’t block over it either unless the person in question is being obnoxious and e.g. following me around between threads and trying to stir up argument about the subject of contention or resorts to personal insults or something like that. reply raxxorraxor 2 hours agorootparentYou will never have an agreement on it. Some see statements as axioms and others do not. Without premises, every form of reasoning can be regarded as circular. You can have an authority on it that determines something as circular or not. But then you will inevitably end up with dogmatism. Someone once said that circular reasoning works if the circle is large enough. Knowing the fallacy might help you detect faulty reasoning in your own thoughts. It doesn't allow for much more practical applications. reply cosmic_cheese 23 minutes agorootparentMaybe, though that suggests that there can be no such thing as a ground truth, which seems kinda shakey to me since it can be used to justify practically any viewpoint imaginable, regardless of how divorced from reality or lacking in verifiable proof it may be. reply lone_onion 16 hours agorootparentprevI've just started using Bluesky. How does it compare to Reddit? There are dedicated subreddits for the conservatives and the liberals, and every subreddit has moderation rules. I use the right and left-focused subreddits to keep track of what's going on in different universes. However, I must mention that you won't find a reasonable discussion of left vs right ideologies on the main sub-reddits, as Reddit users are predominantly left-leaning. But at least there are smaller forums where these two groups meet and interact, and there is some debate. reply vohk 12 hours agorootparentBluesky is a lot more like old, early algorithm twitter. Reddit is a cluster of independently operated communities that occasionally get signal blasted onto the main feed. The top moderator of a subreddit owns it and sets any standard they like. With Bluesky there are no defined communities outside of collective engagement with particular topics or hashtags or networks of follows. There is also a \"Show me [more/less] of this\" button every post, and so far it seems like the platform is pretty solid at respecting your preferences. They also seem to be actively moderating the really open bad behaviour off the platform. I don't think Bluesky is as good as a well-moderated subreddit for long form discussion, but if you spend a little time curating your feed I think you might enjoy it. reply lone_onion 2 hours agorootparentThanks. I'll invest some time in curating my feed. I'm not finding a ton of interesting starter-lists yet. I suppose it will get better over time. reply gwervc 16 hours agorootparentprevnext [4 more] [flagged] cosmic_cheese 16 hours agorootparentThe move to Bluesky encompasses much more than leftists and came as a result of increasing numbers of trolls and bots and decreasing quality of interaction, both of which hit an inflection point following the election. You don’t have to belong to a particular political leaning to get tired of those things. As an example, a lot of artists moved because they wanted to post their work and talk with other artists in peace, which had become increasingly difficult on X. reply citizenkeen 16 hours agorootparentprevnext [2 more] [flagged] valval 10 hours agorootparentI think your logic is a bit silly in the sense that bringing up dissatisfaction over any subject can be brushed off as “screaming that they’re being oppressed”. Sometimes people are being oppressed. Sometimes it’s people you don’t like, and would like to see oppressed. reply bargainbot3k 16 hours agorootparentprevI think it’s also that some of them take pride in the harsh conditions. But this is a petulant stance and not really conducive to a healthy society. The adage goes “right wingers don’t have safe spaces” and it implies, for better or worse, that there is nowhere you can really hide. reply raxxorraxor 11 hours agorootparentprevTheir advertising model certainly is a problem. But it isn't the only one, there are more and more users that demand other users be removed because of their opinion. When social networks started to listen to a few of them, they made themselves hostages to more demands. Platforms like Twitter or reddit certainly suffered from this. reply EasyMark 13 minutes agorootparentYou can say just about whatever you want on bsky as long as you’re civil. I think you will probably get kicked if you start hate-ons for issues like trans, LGBTQ, women, etc that are uncivil. It’s one thing to debate gender, it’s another to say “quit crying qu*r”. That’s likely get you reported and banned or on some blacklists. I think you would probably have to be civil in discussions on groups that are likely protected under say the civil rights act, and modern take on that as to which groups should have been added but haven’t like LGBTQ. Just my take, it’s not the law of the land :). It seems like dems/magas/libertarians aren’t considered protected groups on there and I’ve seen some heated”discussions” that didn’t seem to get cut. reply drw85 5 hours agorootparentprevI agree that ads are basically controlling most of the internet and public discourse now. Like you can't even use normal words in youtube videos anymore, because your video will be less visible/removed. On the other hand, there are way too many people/accounts/bots out there that don't actually want to talk or discuss something, but spread false information and incite rage and anger. Those need to be moderated even harder than they already are, i think. reply cosmic_cheese 4 hours agorootparentOvert support or advocacy for known hate/supremacist groups should fall under the scope of “needs moderation” as well. That sort of content has seen a sharp uptick on X which is one of the reasons why people are now jumping ship. reply lmm 18 hours agorootparentprev> It would be an interesting experiment to see the effects of effectively the polar opposite of twitter, where ragebait and other attention-seeking behaviors are actively punished, with the content that’s most readily surfaced instead being that which is thoughtful, candid, and not emotionally charged. Who would read it? The same people who already avoid twitter - not journalists, and therefore not celebs/politicians. reply PittleyDunkin 17 hours agorootparent> Who would read it? Presumably, normal people who want to interact with people they already know? interaction with journalists and politicians is valuable in an entirely different manner. reply bfrog 15 hours agorootparentprevIt wasn’t like this as little as 10 years ago reply _DeadFred_ 14 hours agorootparentYou didn't really have people posting from their prepaid phones 10 years ago. Old internet users were a select group. reply shiroiushi 18 hours agoparentprevIt shouldn't be any surprise: it's not like the internet's userbase of 1990 represented a broad cross-section of American society, let alone western or global societies. It was mainly a bunch of academics and college students and government users. It's just gotten more and more fragmented as more people have been added. reply user3939382 18 hours agorootparentAnd even then we were segregated by usenet, mailing lists, etc. reply ipaddr 18 hours agorootparentprevAnd social media didn't exist reply orbat 18 hours agorootparentUsenet, BBSs, mailing lists etc. are social media reply lolinder 18 hours agorootparentIn most ways they were far more social than modern social media, in that they were about socializing. The distinguishing characteristic that sets modern social media apart from the old school stuff is the performative aspect of it—where everyone is now encouraged to behave as a content producer optimizing for engagement—which is hardly social. reply mingus88 18 hours agorootparentprevNot in the modern sense. Those mediums do not have algorithms, feeds, followers, profiles, influencers, likes, or any features that many people point to as the toxic aspects of pretty much every commercial social media site of the last decade. I’d say livejournal was the tipping point where the internet became very self-centered and your value in the platform was measured by how much engagement you were able to get. Up until that point, in a world before blogs, social sites were mostly centered around shared interests and communities would aggressively police off topic content reply arethuza 9 hours agorootparentI wonder if Arthur T. Murray would count as an influencer? reply otteromkram 17 hours agorootparentprev> Not in the modern sense. Yes, no one was making that comparison. reply jjav 11 hours agorootparentprev> Usenet, BBSs, mailing lists etc. are social media In a generic sense, yes. People did socialize. But \"social media\" today really means: a proprietary platform controlled by a single corporation, where all the user interaction is ultimately just a ploy to keep the participation metrics up so the corporation can profile you better and sell more advertising. So in that sense, the absolute opposite. reply ipaddr 18 hours agorootparentprevThose are very social places but I would classify them as not social media because real names / identities weren't attached. reply ajmurmann 11 hours agorootparentNot everyone on Twitter uses their real name. Meanwhile I knew the real names of about half the top 20 most active users on a retro gaming phpbb board in the early 00s and had meet many in person and knew we everyone lived, what other hobbies they had and what they did for work or school. reply orbat 17 hours agorootparentprevReal names were absolutely used on Usenet especially in the early days, ditto for mailing lists (and still are for that matter), even though technically they are pseudonymous. In any case pseudonymity doesn't seem like it's relevant for whether something is a social medium or not – many social media are pseudonymous (or even anonymous, like the chans). HN is pseudonymous. Reddit. Tumblr. The various Fediverse services. reply llm_trw 18 hours agorootparentprevThey are social networks not social media, social media is when you scream in a void and the void screams back. The latrinalia of our age if you will. reply antod 16 hours agorootparentI wouldn't call the old stuff social networks. What made social networks a new thing was the social graph of connections becoming the information architecture of the content rather than topics. You found stuff (or it found you) by person rather than subject. Usenet was topic based (eg reddit seems closest these days), mail lists were usually topic based, forums were organised around topics etc. reply EasyMark 20 minutes agoparentprevI use both X and bsky. I would say the behavior on bsky and the hate language is dialed down by a factor of 10. reply spamizbad 18 hours agoparentprevI disagree somewhat. Social media apps are powered by feed algorithms that fall into two camps: The first camp biases toward sprinkling provocative, highly engaged content in your feed even if it falls outside your network of follows or areas of interest. A sort of “forced discovery”. Elon’s Twitter and YouTube during the 2010s follow this model. The second camp does the same thing but requires recommended content to track closer to its perception of your interests. TikTok does this exceptionally well, to the point where people often say they feel like their feed is “reading their mind”. Bluesky seems to follow this pattern as well. The latter is more scalable than the former, but to your point it is an open question how big it scales, and maybe there’s just too many people for either approach to work. reply rescbr 16 hours agorootparentAs far as I understand it, Bluesky's default feed is chronologically sorted posts from who you follow. It is as a dumb pipe as it gets. reply Pufferbo 16 hours agorootparentThere’s multiple feeds, which is one of its main features. There’s user created feeds, which are just aggregates of tags and keywords. These are alright, but prone to issues with cross domain terminology. ie, say you want a football/soccer feed and use the word “spurs”, you’ll end up having it filled with basketball and rodeo posts. The two default feeds are your followed accounts in chronological order, the other is an algorithmic feed. The algorithmic feed is pretty good to be honest. I “disliked” around 20 political posts the first day, and it has seemed to responded fairly quick to that feedback. reply empthought 14 hours agorootparentNo matter how many times I choose \"Show less like this\" on furry manga art in the algorithmic feed, I still see it show up. :( reply Onavo 18 hours agorootparentprevThe second camp is just artificially creating echo chambers, a virtual \"separate and distinct network\" for the parts that matter. reply the_snooze 18 hours agorootparentThe \"echo chamber\" argument really doesn't speak to me because all I want is a place where I can get timely updates about: people in my research field, pictures of cute dogs, and municipal government activities. The more a website stays laser-focused on my interests, the better. reply cosmic_cheese 17 hours agorootparentI think those things you’ve mentioned are what most people came to social media for originally, but it’s gotten lost in all the noise. The original point of social networks was to be social and connect with people in your industry or who share your interests or share a locality in common, and X especially has drifted far from that ideal — lots of users now log onto it to find something/somebody to be angry at and to argue/troll. reply mingus88 17 hours agorootparentprevI’m still using an RSS reader for that very purpose. I want my trusted content displayed chronologically; miss me with the algorithm and the recommended influencers. I’ve been on the internet long enough to know what I want and how to find it. reply AlienRobot 16 hours agorootparentprevI share the sentiment. It seems some people got on the internet to argue and never learned to enjoy anything. I'm a bit sorry for them, to be honest. reply hooverd 12 hours agorootparentIt's kind of alarming, not that I'm not guilty of it, but you do see people whose entire online presence is just stuffing their face with negative interactions. reply hooverd 12 hours agorootparentprevHackerNews is an echo chamber. You're not even allowed to call people f*ggots or speculate about the Jews here! reply derbOac 17 hours agorootparentprevThat makes a lot of assumptions about the nature of the content provided by the recommendation algorithms, as well as human nature. A good recommendation engine, for example, would recognize when someone either likes a broad range of sources politically speaking, or likes a neutral region. Conversely, it's unclear that a recommendation engine would be able to predict what would be best at \"disrupting an echo chamber\", and more importantly, when that is desirable, and what \"desirable\" even means. It's also unclear that the first model is successful at all in disrupting echo chambers, as opposed to exacerbating or amplifying existing positions. I think there's good reasons to think that provocative can be less effective if anything. reply spamizbad 18 hours agorootparentprevI disagree with this: if the only thing you allow to pierce the veil is selected based on engagement metrics you just walk away with a shallow view of your opposition. If anything this may entrench your existing views and give you a false sense of intellectual and/or moral superiority. You need to “meet people where they are” and the first type of algorithm just doesn’t do that. It just says “conservatives/liberals really like this, so you’re going to be forced to see this too because you show interest in politics” To give an example: let’s say I’m a small business owner who voted Trump but has some lingering concerns around how tariffs might impact my business. Am I going to be better informed reading some engagement-bait post from liberals talking about how I’m going to get “deservedly” crushed by tariffs or a post from a conservative economist laying out the cold hard facts (both good and bad)? reply Onavo 18 hours agorootparentYour argument is in support of mine. Separate networks are an interesting legal and software engineering detail, but from the POV of the user, as long as they see what they want to see, they will stay with the network. reply spamizbad 18 hours agorootparentAh you’re right. reply beeflet 17 hours agoparentprevIs it inevitable? I am not sure either way. I think that if you look at real-life Friend-to-Friend groups, this is what you find: clusters of people with similar values. So it it makes sense that the same applies to F2F groups over the internet. But most social media is not F2F groups. Most (advertiser-driven) social media (including this site) is based on the idea of what I call \"implicit ranking\": The idea that a user can influence what another user sees (through \"likes\", \"votes\", \"reports\", \"bumps\", etc.) without having an explicit consensual relationship with them (such as a \"subscription\", \"following\", or \"sharing\" or \"direct message channel\"). This \"implicit ranking\" model is pretty successful because it is better at finding engaging content is and probably the dominant form of social media. In contrast to F2F, implicit ranking networks tend to promote controversial content from outgroups because angry users are engaged. We all love to flamewar sometimes, I'll admit it. reply jowea 18 hours agoparentprevI don't know, the entire point of the \"algorithmic bubble\" was to keep the tribes separate but happy, no? And the value of the network still increases with more people on it. Maybe some future social media will figure out how to keep everyone happy at the same time. For example, I think everyone but a couple of hardcore FOSS advocates and the far-right are still using Youtube. reply ks2048 18 hours agoparentprevIt does seem natural to happen. But there are loads of \"neutral\" accounts: gov agencies, businesses, etc that use social media for announcements and simple broadcast communication. Most are on Twitter now. I think I big question is will they add bluesky, or move (probably not, because of inertia), or something else. reply PittleyDunkin 17 hours agoparentprev> All of us sharing a singular global network was an exceptional and ephemeral circumstance. Did this happen at all? Social networks have always been balkanized by culture. reply dehrmann 16 hours agoparentprevIf the algorithm doesn't make the filter bubble, people will make it on their own. reply CaptainFever 15 hours agorootparentSee the Fediverse for example, which prides itself on not having algorithms, and is yet the most echo-chambery and radical place I know of. People automatically filter themselves into different servers, and defederate with each other with frequency. (Whether or not this is good or bad depends on your moral views. But I think it is obvious that \"algorithms\" are not really to blame.) reply _DeadFred_ 14 hours agorootparentDidn't it spring up in response to those blameless \"algorithms\"? reply dehrmann 13 hours agorootparentIt's more a product of cheaper and easier content distribution. When TV is expensive to produce, there are only three channels, and it's heavily regulated, you target your content to be broadly appealing and inoffensive. The rise of cable TV, revocation of the fairness doctrine, rise of the internet, and fall of the USSR all led to more exposure to broader views. Like GP said, whether this is good or bad depends on your view. reply CaptainFever 11 hours agorootparentThis is another good point. I didn't actually intend to make this point, but I wanted to thank you for pointing this out. I am not a sociologist, just a layman. But I feel that there seems to be two axis of communication. Mass (you don't know who you're talking to) vs targeted (you do know who you're talking to, like friends). Then, professional (you try to be unoffensive) vs casual (you have no such obligation). Before the Internet, generally communication happened either mass-professional (e.g. TVs, newspapers, magazines) or targeted-casual (e.g. chatting with friends and family). This reduced offense, since mass channels were largely unoffensive as you said, while targeted channels knew how to avoid offense (i.e. you knew how to not offend your friends and family). However, the Internet enabled a lot of mass-casual communication. And this created a lot of offense, because you didn't know who would read your messages (i.e. Twitter posts), while you didn't have the professional obligation to make sure it was unoffensive and easy to understand. This created a lot of misunderstandings, offense, etc., which leads to cancellations, hate mobs, etc. Do note that once again I am not a sociologist, and there seems to be holes in this view. What about large group gatherings? Trashy magazines? Clubs? They seem to be examples of mass-casual communication too. reply CaptainFever 11 hours agorootparentprevYou are correct, but my point was that it seems to me, that even though engagement algorithms aren't really a thing in the Fediverse, such filter bubbles still appear via self-sorting and de-federation. So yes, perhaps algorithms are to blame for filter bubbles in centralized social media, but removing algorithms doesn't remove filter bubbles, because people create it by themselves anyway. TL;DR: Blaming the algorithm (correct or not) doesn't actually matter in the end, because filter bubbles happen with or without them. reply nitwit005 14 hours agoparentprevThe press coverage is a bit misleading. Everyone is leaving Twitter. Liberals are just leaving faster. Keep in mind that a lot of Twitter users never wanted political content. They were there for sports, art, science discussions, etc. Some of those communities are clearly migrating. reply EasyMark 8 minutes agorootparentI think I’ve even noticed a huge decrease in hate bots lately in my feed, certainly doesn’t seem to up date as often (aka takes longer for my usual “followees”to go off the firehouse, as they have some precedence in the feed make up reply fooker 15 hours agoparentprevThere's one single that prevents this: sharing screenshots, and the impossibly difficult task of blocking those in practice. reply prisenco 16 hours agoparentprevI'm not convinced everyone sharing a singular global network was ever a good idea in the first place. reply protocolture 17 hours agoparentprevNot really. The issue is that social media sites produce feeds and content matching, forcing alternative views in your face. Its like, they have decided to push metcalfes law as far as possible, to see when the breaking point is. Like a giant social experiment. But if everyone is in one place thats still the most desirable network to be on. Just dont push Joe Blo's dumbest political opinions in my face as sponsored content. reply alsetmusic 18 hours agoparentprevnext [16 more] [flagged] lolinder 18 hours agorootparentPoe's law strikes again: I'm genuinely unsure if you're intentionally being ironic in perfectly illustrating OP's point, or if you legitimately think that \"the Right\" is single-handedly responsible for creating the sociopolitical tribes that can't stand or even understand one another. If you're being ironic there's not much to add, so on the assumption that you meant what you said: Trump's ascendancy is evidence of what OP is saying, not the cause. The coastal elite has been completely incapable of understanding Trump's voters for decades, long before they were Trump voters. Trump hijacked the Republican party and won the presidency (twice now!) because he managed to make these long-neglected voters finally feel understood. We're not going to solve the problem of Trumpism by doubling down on treating these voters like idiots, because that's what got us here in the first place. reply dandellion 18 hours agorootparentprev>> It's inevitable… > Yes and no. Yes and yes. The right and the left don't even speak the same language. I'm not a native English speaker and half the time I don't even understand what the left are even saying. Examples: > regress into an id-dominated state of hyper-reality > what can be, unburdened by what has been What does that even mean? People keep calling the right stupid, but at least everybody can understand what they're talking about. reply blharr 18 hours agorootparent>What does that even mean? \"id-dominated state\" refers to the psychological \"id\" basically being primal. \"A person who is dominated by their id might be narcissistic and impulsive\" I don't blame you for not getting this part, but it is a common psychological theory. >What can be unburdened by what has been Well, yea. If you take a fragment of a sentence out, it is going to be confusing. The full quote is on the lines of \"My mother raised me to see what could be, unburdened by what has been\" i.e. to look at accomplishing at the highest possibilities without the baggage of traditional limitations Reading it now and in context, its a normal impactful thought. But the right took a cut off the middle... like if I quoted you and said \"a native English speaker and half the time\" a missing phrase will obviously make it confusing reply dandellion 16 hours agorootparentEven with the context, rephrasing it like this: > i.e. to look at accomplishing at the highest possibilities without the baggage of traditional limitations Is much easier to understand. The other one I might have guessed correctly, but yours is quite clear to understand. reply jrflowers 18 hours agorootparentprevI think one example of hyperreality(1) would be a person seeing a phrase that they don’t immediately understand and deciding “this is how ‘the left’, a real and cohesive/consistent group, talks” 1 https://en.m.wikipedia.org/wiki/Hyperreality reply llm_trw 18 hours agorootparentnext [7 more] [flagged] athrun 17 hours agorootparentThe real world is a complicated place. You want simple answers when reality is complicated and nuanced. The fact is that there are—and have always been—people for which these things are not the same. You might want to wish it away, but that doesn't change reality. reply llm_trw 17 hours agorootparent>>I've just committed a hate crime and possibly called for genocide. >You might want to wish it away, but that doesn't change reality. My post was 4 sentences long and you skipped 2. Why even bother replying? reply jrflowers 17 hours agorootparentprevWhile “the left” in the US is incredibly nebulous, largely composed of groups and people that rarely agree on nearly anything at all, let alone a literary style, this recent article(1) about Bluesky has an eloquent description of “the right” when it comes to online spaces. > Liberals and the left do not need the right to be online in the way that the right needs liberals and the left. The nature of reactionary politics demands constant confrontations—literal reactions—to the left. People like Rufo would have a substantially harder time trying to influence opinions on a platform without liberals. “Triggering the libs” sounds like a joke, but it is often essential for segments of the right. The assumption that strangers on the internet are interested in or obligated to engage with “debate me bro”-style theatrics any time a person feels like summoning them to is very much a specific example of hyperreality that is particularly endemic amongst “the right” > I'm going to go ahead and stick my dick in the hornets nest You can put your dick somewhere else. It is not interesting here. 1 https://www.theatlantic.com/technology/archive/2024/11/twitt... reply llm_trw 15 hours agorootparent>Liberals and the left do not need the right to be online in the way that the right needs liberals and the left This is quite ironic considering that the last 8 years 'Liberals on the left' have done nothing but react to whatever Trump was doing that day. >The assumption that strangers on the internet are interested in or obligated to engage with “debate me bro”-style theatrics any time a person feels like summoning them to is very much a specific example of hyperreality that is particularly endemic amongst “the right” If you don't want to have an online debate don't post in places that have comments. reply protocolture 12 hours agorootparent>This is quite ironic considering that the last 8 years 'Liberals on the left' have done nothing but react to whatever Trump was doing that day. No thats literally his point? Trump doesn't provide good interesting politics. Trump makes liberals angry, thats the product. Most of his policy positions are there to generate liberals talking about how his policies are bullshit. If he was suddenly unable to engage with liberals he wouldnt be able to hold right wing interest at all. The one shot copmala had was to run the most crazy batshit circus of a campaign possible. Free Ponies, Killer clowns, whatever. Keep trump out of the news, and you would break the cycle. reply magicalist 17 hours agorootparentprevExcept this is yet another example of who's actually doing the navel gazing. I think it's clear your objection here isn't the navel gazing, so let's speak plainly. reply staplers 17 hours agorootparentprevPeople keep calling the right stupid, but at least everybody can understand what they're talking about. This isn't the enlightened take you think it is. Lack of education led us here. Fuming at intellectuals when they attempt to address complex issues reminds me of our evolutionary ancestors fuming at the creation of civilization. reply dandellion 16 hours agorootparentIt's not an enlightened take, it's a pretty basic observation. I've had the fortune of working with many people a lot smarter than me, and one thing all the smartest ones can do is explain complex topics to people outside their field in a way they can understand. Using intellectual language to address a non-intellectual audience like voters, or a forum with many non-native speakers, that they won't understand seems a dumb thing for an \"intellectual\" to do. It's not about intellect, enlightenment or education, it's about using language to communicate instead of using it for... something else, not sure what. reply lordfrito 17 hours agorootparentprev> Lack of education led us here. There are a lot of intelligent people that just happen to be \"uneducated\". Meanwhile I've met plenty of \"educated\" people that hold a wide variety of contradictory beliefs and lack the ability to critically think. \"Not educated\" is just another convenient (and lazy) strawman outgroup. Liberty for me but not for thee, etc. reply lolinder 17 hours agorootparentprev> Lack of education led us here. No. Belittling people for their lack of education led us here. People don't follow those who consistently treat them as barely-human tally marks that we (their betters) tolerate as long as they vote the right way. Eventually they get sick of being treated as less-than, and eventually someone comes along that makes those people feel important. There are only really two reasonable ways out of Trump's populism at this point: learn from him and recognize the importance of the less-educated, or reduce the franchise and prevent people from voting unless they pass a certain educational bar (which not is not actually an option for so many reasons). Any other approach will either take generations or is doomed to failure. reply janalsncm 19 hours agoprevIs it all the ways that matter? The author mentions one way, DAU. Sure, that is important but I can think of other things that matter. The number of “creator” accounts matters just as much as the number of lurkers. From my experience Bluesky is way better and has respect for the user’s choice front and center. Lists of users to follow is a first-class citizen feature. Their algorithm is a chronological feed, not boosting engagement bait. reply paxys 18 hours agoparentHere's one metric that matters – revenue per user. Bluesky's is, I assume, zero, and soon that will have to change. Threads meanwhile has the largest social media ads and monetization platform in the world behind it ready to make the dollars flow at the push of a button. reply EasyMark 3 minutes agorootparentRight, I’m sure they’ll have to bring in ads, but I believe we’ve seen this play before. I’m cool with ads, I’m not cool with promoting hate speech because it “improves engagement” reply afavour 16 hours agorootparentprevIf the revenue per user is enough to cover costs, does it matter? Will it have to change? We’ve all had “hockey stick growth!” shouted at us so many times that we’ve internalised it but Bluesky is a team is 20 odd people. They don’t have the kind of footprint Meta has and right now they don’t need it. I hope they stay small and chart a different path to success. reply hellcow 15 hours agorootparentThey just raised $15M. Surely their investors expect a large return. reply afavour 15 hours agorootparentThey’d be dumb to: > Bluesky Social is a benefit corporation; as such, it is allowed to use its profits for the public good, and is not obligated to maximize shareholder value or return profits to its shareholders as dividends. I have no idea but I suspect the investors see monetary value in an open social network not owned and operated by today’s tech giants. There’s a difference between users making money via the social network and the social network making money via the users. But both involve making money. reply dhosek 15 hours agorootparent[Public] Benefit Corporations¹ are this weird sort of in-between between a non-profit and a regular corporation. My first encounter with this was the benefit corp that was set up for This American Life and Serial (although the latter is now owned by the New York Times) and after reading a whole bunch, it’s still not entirely clear to me what it means. Everything I’ve seen talks about transitioning from a non-benefit corp to a benefit corp, I don’t know if the concept is old enough for the reverse to have ever happened. ⸻ 1. Whether it’s called a “benefit corporation” or “public benefit corporation” apparently depends on the state, and not all states have laws to allow them to be established. reply ndiddy 14 hours agorootparentprevThe only protection that the \"public benefit corporation\" status provides is that investors can't sue the company for failing to maximize shareholder value. There's lots of other avenues they can take to make the company do what they want (assuming sufficient share ownership) such as pressuring the board, voting in directors, or converting the company to a regular corporation (it's not like a 501(c)(3) where this isn't possible in most cases). reply llm_trw 15 hours agorootparentprevRemember when open ai was a not for profit? reply dhosek 15 hours agorootparentIt still is. reply jazzyjackson 15 hours agorootparentprevYea good point, kind of a commodotize your complement kind of thing , Blockchain Capital needs a new landscape of marks to scam. reply madeofpalk 18 hours agorootparentprev> largest social media ads and monetization platform in the world behind it ready to make the dollars flow at the push of a button At the direct cost of making a worse product for users. I remain hopeful that Bluesky is able to monetise/fund development without succumbing to working against its users. reply llm_trw 17 hours agorootparentHoping that the people who made twitter what it is will somehow create a different outcome when doing the same thing is ... something. reply madeofpalk 17 hours agorootparentWell, they’re not doing the same thing aren’t they? I’m cautiously optimistic that the open/decentralised nature of these sites can act as a powerful forcing function to keep them in check, keeping their incentives more inline with their users compared to traditional commercial social media sites. Mastodon’s financial (and so far technical) structure seems more inline with this compared to taking on investment, so we’ll see how it goes. I just want a network that’s not going to juice engagement to optimise for page views for ad revenue. I want a reverse chronological feed. I want third party clients that might have different UX ideas It’s free to hope :) reply willsmith72 19 hours agoparentprevwouldn't things like creator-lurker ratio be captured within DAU? as in, poor ratio leads to poor DAU? reply luplex 18 hours agorootparentNot necessarily. There could be different types of content that requires different types of creators, like imagine professional video producers vs your friends posting about their day. There could also be a different algorithm/network that allows for a few creators to feed a large number of consumers. reply dylan604 19 hours agoparentprev> Their algorithm is a chronological feed Why does a chronological feed get considered and algo? Do we consider SQL queries with WHERE and ORDER BY clauses an algo now? reply rty32 4 hours agorootparenthttps://en.m.wikipedia.org/wiki/Algorithm > In mathematics and computer science, an algorithm is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Looks good to me. And did you just question \"WHERE\" and \"ORDER BY\" in SQL? I wouldn't do that. There are probably a ton of algorithms and optimizations done there. In my very naive understanding, quick sort is at least worth something. reply samatman 19 hours agorootparentprevWhat else could it possibly be? reply morkalork 19 hours agorootparentprevIt absolutely is. Sure it's the default, but it's the default to measure against and beat. It's like comparing ML algos against the average prediction, or forecasts against the previous known value. reply paxys 18 hours agorootparentprevfun sum(x, y) { return x + y } Congratulations, you have yourself an algorithm. reply aetimmes 14 hours agorootparentprevI mean, it's all just quicksort under the hood, right? By extension... reply aetimmes 14 hours agorootparentprevI mean, it's all just quicksort under the hood, right? By extension... reply Zigurd 18 hours agoprevI made a Bluesky account long ago and started cross-posting my tiktoks, often on the popular and titillating topic of project management. For a long time it was sleepy as I would have expected. I got a sudden uptick recently, which prompted me to figure out how to port my follows from X, which I did with \"sky follower bridge.\" Bluesky has been a lively, friendly place. Sky follower bridge was able to scrape my X blocklist, but could not turn it into a Bluesky block list. No troll problems yet so that's OK for now. I still have to host my videos on titok because some are too long for Bluesky. My tiktok \"for you page\" has turned to sludge and my followers are not getting my posts without setting notification options. I wonder if the magical algorithm was sequestered in China to hide it from inquiries. Hopefully a Bluesky presence helps. reply pythonguython 19 hours agoprevLow quality article aside, Threads also had a major spike in usage that quickly dropped off. I could be wrong, but I’m going to guess Bluesky will be the same. They don’t seem to offer anything new/different other than moderation, which I’m not convinced is enough to shift momentum from x to bluesky reply bertil 19 hours agoparentThe difference in moderation is night and day. Soon after Musk took over, I started having accounts wishing me violent deaths, repeatedly commenting on everything I said with graphic details (broken bones, poisoning, dragging my body over the pavement, etc.). That happened occasionally before, but they typically got banned. After the takeover, those were gone (and my account got blocked a couple of times for quoting them). That hasn’t happened after a year on BlueSky and Threads. Scams were rampant on large accounts and people looking at cryptocurrencies: more than three-quarters of comments were obvious patterns that I had flagged dozens of times. I noticed those earlier today on Threads; let’s see if they reappear and make up most of the discourse there. reply rcpt 15 hours agorootparentRight. After the pay-to-play change that boosted Blue Checks to the top of everything it became unusable. No better than going into the local news comment section or Craigslist discussion forums. reply lupusreal 18 hours agorootparentprevMan, I wish I could be even a hundredth as effective at pissing people off online. I only piss off boring people I guess. reply moomin 18 hours agorootparentA lot of the hate you get depends not on what you say, but what you are. reply lupusreal 8 hours agorootparentOn the internet, I'm a dog. reply Aeglaecia 15 hours agorootparentprevthe impact of existence on perception is mediated by group attitudes, which are lessened in influence by anonymity ... my personal maxim is that hatred does vary on what is said and more so by where it is said reply ipaddr 18 hours agorootparentprevnext [11 more] [flagged] kevincrane 18 hours agorootparentWhat problem do you think they’re causing that would warrant death threats? reply ipaddr 18 hours agorootparentWhat do I think someone could say over different platforms over a long time period of time that would get multiple death threats? I have no idea but would love for original poster to share more details. reply mulmen 18 hours agorootparentprev> Never had or seen a death threat. Ever wonder if you might be drawing all of that negative attention yourself. It's hard to admit that you might be the problem. This is victim blaming. It’s wrong and it has no place here or anywhere. reply ipaddr 18 hours agorootparentFirst you need to identify a victim before you can come to their rescue. Is the parent poster a victim? Are the people he taunts into death threats his victims? Am I a victim of your verbal attack. Are you a victim because you read something and reacted? reply mulmen 18 hours agorootparentYou don’t know what the parent posted. I didn’t attack you. You shared your own irrelevant experience which undermines the experience of being threatened. You then used that irrelevant experience to assume with no information that these threats were deserved. You could have instead asked what was posted and then offered your advice if it was warranted. But what post or posts justify graphic death threats? reply ipaddr 17 hours agorootparentIf I felt you attack me doesn't that make me a victim based on your worldview. You tell me that my opinion is irrelevant because someone who you labelled a victim could be undermined then you do the same thing. You can't have it both ways. You can be a hero saving a victim by creating more victims. What posts justify graphic death threats? In a vacuum none. With context I could think of many examples including: Maybe he is posting death threats himself or perhaps committed a crime to a person in an identity we consider more of a victim. Someone who punches somebody and when they hit them back that person is suddenly the victim? I'm not sure I see the world as black and white as that. reply mulmen 17 hours agorootparent> If I felt you attack me doesn't that make me a victim based on your worldview. No. > You tell me that my opinion is irrelevant because someone who you labelled a victim could be undermined then you do the same thing. I didn’t say your opinion is irrelevant. I said your experience of not receiving death threats is irrelevant to someone else’s experience of receiving death threats. > You can't have it both ways. You can be a hero saving a victim by creating more victims. I’m not a hero and I’m not saving anyone. > Maybe he is posting death threats himself or perhaps committed a crime to a person in an identity we consider more of a victim. There’s literally no justification for graphic death threats. You have no reason to believe either of those hypotheticals are real. > Someone who punches somebody and when they hit them back that person is suddenly the victim? I'm not sure I see the world as black and white as that. You are arguing with your own straw man. reply StanislavPetrov 18 hours agorootparentprevThe idea that you cannot possibly be at all responsible in any way for any of the bad things that happen to you is one of the most ridiculous assertions I come across on a regular basis. Are there cases where you bear 0% of the blame for what misfortune occurs? Of course! If someone shoots a gun up in the air from a mile away and the bullet comes screaming through the window and hits you, you bear no responsibility at all for being the \"victim\". But if you ride choose to ride the subway back and forth across the Bronx at 3 am every night with big gold chains visibly dangling around your neck, you absolutely deserve some of the blame for being the \"victim\" when you get mugged! It is incumbent upon every one of us to understand that when you engage with the environment and/or other people, that your words and actions have an influence and an effect. Responsibility is not a zero sum game. Just because the guy who mugs you bears 100% responsibility for being a violent criminal does not mean you are completely absolved from all responsibility after having exercise truly terrible judgement (or no judgement at all). I am not familiar with the original OP, but anyone who goes around having interactions in a confrontational style should expect to be confronted, along with all of the other things that come along with confrontations. Pretending that none of us have any agency in any of the bad things that happen to us because we are \"victims\" is a silly trope that is far too common. reply mulmen 18 hours agorootparentOf course we can be responsible for bad things that happen to us. We might also not be responsible. Without knowledge of what was posted we can’t determine what is true in this case. But making the assumption that it is deserved is unreasonable. > But if you ride choose to ride the subway back and forth across the Bronx at 3 am every night with big gold chains visibly dangling around your neck, you absolutely deserve some of the blame for being the \"victim\" when you get mugged! Actually no, wearing gold chains and riding the subway are not crimes. This is just more victim blaming. A better example would be the mugger is responsible for their subsequent arrest and imprisonment after mugging someone. > I am not familiar with the original OP, but anyone who goes around having interactions in a confrontational style should expect to be confronted, along with all of the other things that come along with confrontations. Right, you don’t know, so you’re just assuming that’s relevant here. You have no reason to believe graphic death threats were warranted. Personally I can’t imagine a post that would justify such death threats. > Pretending that none of us have any agency in any of the bad things that happen to us because we are \"victims\" is a silly trope that is far too common. Who is pretending this? You have fabricated this position. reply jazzyjackson 15 hours agorootparentprevCome on ya'll now, let's be real Some jokers got a rough time keepin' it concealed I wonder what it mean, it's probably self-esteem They fiendin to be seen, get hemmed like Gabardines Cats think it can't happen until the gats start clappin They comin' down the wire spittin fire like a dragon Cause while the goods glisten, certain eyes take position To observe your trickin', then catch that ass slippin' Like, come on now ock, what you expect? Got a month's paycheck danglin' off your neck And while you Cristal sippin', they rubbin' up they mittens With heat in mint condition to start the getti-gettin' reply transcriptase 18 hours agorootparentprevWhat the hell are you doing or saying to warrant that kind of negative attention? reply mulmen 18 hours agorootparentThat kind of attention is never warranted. reply rsynnott 11 hours agorootparentprevI got some of this years back, by offending Milo Yiannopoulis (who apparently used to search his own name for stuff to point his followers at), back when he was still a far-right darling. Took about a day of mass-block-lists to weed the enraged Nazi teenagers out of my at-mentions. That was just a single incident, being noticed by far-right weirdos thankfully not being a regular thing for me. But I can imagine it would get old quickly if you were the sort of person who was. Bluesky’s far superior self-moderation is absolutely very useful here. reply xena 18 hours agorootparentprevIt's pretty easy to get that kind of vitriol if you say that you want people like you to continue existing. reply ipaddr 18 hours agorootparentAnd you say this to people you label not like you. You probably have more in common than you think. You both agree to label the other and you decided to fight a proxy battle from the agreed among identities. Do you want the other side not to exist as well? If yes let them know. reply virgildotcodes 17 hours agorootparentPeople defending themselves from bigotry, and bigots themselves, are not equivalent. Black people not wanting racists to exist, and racists not wanting black people to exist, do you see a distinction? There has been such a consistent attempt at ramming square pegs into round holes online in trying to “both sides” a bunch of these issues. One trait is immutable and the other is not. One trait is entirely internally focused and is not defined by a rejection of anyone external to the subject, the other's trait is entirely defined by such an external focus on the rejection of another person's immutable identity. reply ipaddr 15 hours agorootparentYou guess racist? I had a different first guess. Then I had a better second guess. I then had a three and fourth guess. Then I wasn't sure at all. None of them were racism. This becomes a personality test that speaks about who you are and what battles you always see. reply virgildotcodes 15 hours agorootparentSubstitute homosexuality, being transgender, or whatever you'd like. reply ipaddr 14 hours agorootparentTry words you may not like too like right wing or Trump supporter. Still work? reply virgildotcodes 14 hours agorootparentBeing a right wing trump supporter is an immutable characteristic like being black or gay? reply ipaddr 11 hours agorootparentI support the concept of gender fluidity. Yes not everyone is hardwired as gay or straight or bisexual. Being black.. is that referring to skin tone because people can slightly change their color and many products exist to lighten and darken skin tone. Or identifying from black culture in this case you can be white or black or something else and still identify. People can't change height either. Why you jumped to race tells us what your focus is. Why not Palestine / Jewish? It equally describes both depending on what your point of view is. reply virgildotcodes 3 hours agorootparentThis seems like word salad, are you sure you’re continuing to argue all this in good faith? You’re now saying that medical procedures can change your skin pigmentation, so race is no longer immutable? You genuinely hold this position? Is everything mutable then? Since with the right surgical and drug interventions you can theoretically change anything about a person’s mind or body, which trivially includes their height. Wow, truly this is deep. If there are short/tall people who are being targeted for harassment/oppression then yes they too are in the right to wish that heightists/heightism didn’t exist and their harassers are in the wrong. What are we even talking about here? reply ipaddr 3 hours agorootparentEverything is mutable. reply madeofpalk 17 hours agorootparentprevLet’s not pretend the disagreement is about fiscal policy. reply ipaddr 15 hours agorootparentLets pretend we know what the disagreement is about. What's your guess? reply kevincrane 17 hours agorootparentprevlol I don’t want the bigots and people sending death threats to exist, I’ll stand on a soapbox and say that reply ipaddr 15 hours agorootparentYour guess is bigots. Care to provide more details. Racism or a broader bigot definition? reply kevincrane 13 hours agorootparentI’ll be honest, I have better things to do with my time then help you narrow down your personal definition of bigot. Sorry. reply ipaddr 11 hours agorootparentI haven't heard that word since the 70s. It's outdate like 'to the moon Alice'. What were you trying to convey with that word? reply madeofpalk 18 hours agoparentprev> They don’t seem to offer anything new Bluesky actually does offer some neat features. Starter Packs is such a brilliant feature for onboarding people into specific niches - it's a wonder why it took so long for someone to do this. 'Labellers' is a neat approach to moderation - you can subscribe to a labeller, and it marks accounts according to whatever criteria and then you can chose how you want that to shape your experience - block those posts/accounts outright, hide them behind a disclaimer, or just put a little badge on them. I subscribed to one which marks public figures with which private school they went to which is funny. Custom algorithms is also another really neat improvement to the overall experience. On my homepage I pinned a \"Quiet Posters\" feed that surfaces posts from lower-volume people I follow that I might have otherwise missed. This is necessarily a feature of the AT Protocol's open network that really needs the firehose to function. But the biggest 'new feature' (for now) is that it's non-commercial so Bluesky's incentives are not directly opposed to it's users. Even pre-Musk, Twitter's business goals worked against it's users, driving engagement at all costs to pump up ad views and revenue. A company that doesn't make money from page views, and which is based on an open network, will have more going for it to creative a positive environment for all. It remains to be seen how sustainable this is, which Bluesky taking investment, and whether at open AT Protocol can be an escape valve for Bluesky making the product worse. reply shigawire 19 hours agoparentprevThere is more momentum against Musk now than when threads launched. Not sure it is enough to overcome the network effect - but there is a lot of illwill towards his projects. I can see how something like SpaceX is overall a net good, but I don't see that upside for X. reply unnamed76ri 18 hours agorootparentFree speech is the upside of X. People leaving to join the echo chambers of Bluesky or Threads, only serves to turn X into the echo chamber they claim it is. reply madeofpalk 18 hours agorootparentI know I'm falling for the bait, but saying X is some last bastion of free speech is baffling, considering it's actual actions. Why do the remaining posters keep self-censoring \"Blues*y\"? reply unnamed76ri 17 hours agorootparentI don’t know what you are referring to. I’ve never seen someone self-censor Bluesky. I see people talking about it on X all the time. Mainly to highlight some of the worst content they find there but that’s another subject… I tried checking out Bluesky the other day. The feed was mainly unhinged political rants of a very particular flavor. reply threecheese 17 hours agorootparentA feature of Bluesky is the ability to change your feed algorithm (or code your own - yes I wrote ‘code’). You can easily filter all political (labeled) content. To say that BS is an echo chamber is untrue, though I do not disbelieve that you observed that algorithmic choice when you first tried the app. There are many echo chambers for sure, but the protocol is designed to permit you to exclude or join them. Unlike competitor systems (which I also use, and dislike more and more due to the lack of ability to choose what I see - despite trying). reply glenstein 16 hours agorootparentRight, and what's more the charge of echo chamber has always been intellectually lazy. You can have a fruitful exchanges of ideas and information and debates on a foundation of similar values in a way that amounts to more than just repeating ideas back and forth. Using the term as a catch-all for a shared desire for conversations to have certain ground rules or certain community values, or subjects that spark your intellectual curiosity, calling those echo chambers is shallow and is not going to inform you about the real cultural dynamics that drive those kinds of communities. It's just a lazy way to try absence of critical thought by looking for the wrong thing. If people labeling things as echo chambers cared about the things they said they cared about, they would look at entirely different criteria, such as epistemic closure, the quality of relationships, propensity for trolling, and so on. reply tensor 15 hours agorootparent> more than just repeating ideas back and forth. Yes, people on X seem very upset that they can be blocked on bluesky. But if I've heard what you have to say and don't want to hear the same thing 1000x, that's not an echo chamber. That's me hearing you, disagreeing, and you having nothing more of value to add. Discussion requires communication, not simply repeating propaganda over and over and over, which is 99% of the time all that anyone crying \"echo chamber\" tends to do. reply mlboss 17 hours agorootparentprevnext [7 more] [flagged] sapphicsnail 12 hours agorootparentYou literally can't say cis on X anymore without your engagement getting nuked. Are they going to punish people for saying straight next? reply insane_dreamer 11 hours agorootparentprevthat's completely untrue reply Fnoord 16 hours agorootparentprevCause it is trolling, pure hatred. Hermaphroditism exists, simple scientifically backed up fact. reply jazzyjackson 14 hours agorootparentHermaphroditism is an \"exception proves the rule\" kind of thing - they are not a third sex, and I don't think the \"two genders\" crowd hates intersex people or even men who claim to be women, but they do probably hate people who claim that it's bigotry to say sex is a binary. reply glenstein 16 hours agorootparentprevRight, this is one of the games that trolls play which is kind of to search for normalizing language, create a provocation, and then relish in the attention derived from the provocation. reply rsynnott 11 hours agorootparentprevI mean, you’ll pretty swiftly end up on transphobia blocklists, but what of it? Like, unless you want to force people who don’t want to hear your shit to hear your shit (note that this is not what ‘free speech’ means), what harm is that doing you? reply pengowray 6 hours agorootparentprevThere is no \"free speech\" on X. Musk has banned journalists. Banned users he didn't like. Arbitrarily banned random words. Banned links to Mastodon. Banned links to linktree. Encouraged harassment of users and news organizations until they left the platform. Banned links to articles about political candidates. No unpaid user's reply can appear in the replies to one of Musk's tweets in any practical sense. X is not a free speech platform. Musk is a liar. He is lying to you. You are being lied to. If you think X has anything resembling \"free speech\" I have bridge made of solar powered tiles to sell you. (That was another scam of Musk's if you missed it). The lively debate you crave does not and cannot happen on X. reply mcphage 16 hours agorootparentprev> Free speech is the upside of X. You can’t possibly believe that, can you? Have you not noticed the vast gulf between what Musk says and what Musk does? reply unnamed76ri 15 hours agorootparentI don’t care much for Musk one way or the other. What I do know is that old Twitter actively censored ideas that didn’t align with their world view and new Twitter stopped that fascistic approach. Musk fired 6,000 Twitter employees and the site not only continues to work fine but has rolled out many new features. What were those 6,000 people even doing? Just how big was the censorship team? reply mcphage 14 hours agorootparentBut it does censor idea that don’t align with their world view. They do it even more now than they did before; the only difference is now they claim they don’t. And it continues to run, but not well. The nice thing about the kind of site it is, is that if you don’t see a particular message, you can’t tell it’s missing. reply trustinmenowpls 13 hours agorootparentidk, I specifically go to twitter for my political fix and when I go to the for you section I see a ton of liberal stuff and a ton of conservative stuff, many posts are unhinged in either direction. Others are more moderate, in general I don't really follow any political accounts, and yet I see a many posts that give me a great view of the zeitgeist for each side. reply hooverd 12 hours agorootparentEh, post Musk I see may more straight-up StormFront shit from \"verified\" posters. reply Jensson 8 hours agorootparentThe question was what he censored, not what was allowed. Allowing something is not a case of censorship. reply insane_dreamer 11 hours agorootparentprev> Free speech is the upside of X lol, you seriously believe that a network fully controlled by the world's richest man, accountable to no one, is a bastion of free speech? I presume you have a bridge to sell me as well? reply afavour 16 hours agoparentprevIMO the biggest difference is that they aren’t paying users based on engagement. That’s the #1 worst decision Musk made after buying Twitter, it incentivizes people to post incendiary content, to troll and to outright lie in the aim of going viral. You see it all the time on Twitter these days and Bluesky is vastly better not having that motive. reply dkrich 19 hours agoparentprevAs someone (who likes to think) is pretty unbiased politically, I can say I’ll go wherever the people I’m interested post. I have been somewhat surprised that pretty non political accounts have moved to Bluesky which I have interpreted as both political and motivated by the loads of political bs that are posted on x that normal people simply get tired of. I think Bluesky will gain more traction than threads but will end up being a more successful mastodon. A place where people with massive followings who simply don’t like x will post and there will be two competing apps. reply jsheard 19 hours agorootparentIt's not just that X/Twitter shows you politics whether you want it or not, it's that it's flavor of politics is increasingly resembling that of 4chan. I just skimmed though the auto-play videos on my account and the algorithm decided to show me this for some reason: https://x.com/AlaskanTom/status/1860339990992925170 That's far from the worst I've seen on there either, evidently you can just post about how Hitler was right and it won't affect your visibility at all now, nevermind get you banned. reply jghn 18 hours agorootparent> It's not just that X/Twitter shows you politics whether you want it or not But this is not true. I always use my \"following\" feed and not my \"for you\" feed. Other than sponsored ads the only thing I see are posts from people I follow. I don't understand why people persist with the narrative that Twitter forces people into \"the algorithm\". I've been splitting time between Twitter & Bluesky for the last year or so. The only real difference i notice is the set of people I follow as until recently most of my Twitter follows weren't on Bluesky reply jsheard 18 hours agorootparentI also only use the following feed, but a fairly recent change to the video player means it now immediately cuts to the next video in the auto-play queue (or an ad) when it finishes, and that's always algorithmically driven regardless of which feed you were using. reply jghn 18 hours agorootparentFair. I almost always refuse to click on videos in twitter-like sites, so wouldn't have noticed this. I (usually) hate video content, especially the massive shift towards video content in our media sources. reply thekevan 17 hours agoparentprev>but I’m going to guess Bluesky will be the same I disagree. Bluesky will grow further and then be like a \"Coke or Pepsi\" to Twitter. (Albeit, it will stay smaller than Twitter.) I have 2 threads accounts and never created a single one. That's because I had 2 Instagram accounts. The difference is people chose to go to Bluesky, Threads accounts were just added on to your Insta account by Meta. reply tapoxi 18 hours agoparentprevBluesky's custom labels, algorithm choice, client choice, and starter packs seem like legitimately cool features. reply raxxorraxor 9 hours agoparentprevI think overzealous moderation was what drove some people off Twitter in the first place. Another social media site asking for my phone number, no thank you. I read the occasional Twitter/X and probably now Bluesky post, but this offers nothing that would attract me. Twitter/X/Bluesky/Insta/Threads is for people that like celebrities with some interesting stuff in between. But overall that isn't worth it. reply grbrr 19 hours agoparentprevFor social media, moderation makes the product reply JansjoFromIkea 17 hours agoparentprevI'm not sure Threads ever had that much of a spike in usage beyond the first day of new accounts. Got the impression a huge number of people curious about it signed up due to the very easy onboarding if you already had an instagram, looked around a little and then never went back. Outside of the tiny number of Threads users who didn't have an Instagram account beforehand, the act of registering to BlueSky is a far more engaged move than Threads ever had imo. reply kalupa 19 hours agoparentprevI’m going to guess you don’t use the service much… You’d likely have a very different opinion otherwise reply ianbicking 18 hours agoparentprevI have given Threads a good try, and recently when Bluesky activity started up I restarted using Bluesky (it didn't stick for me the first time). The technology doesn't really matter that much, as long as it's basically competent. It's only the social network itself. I'm not sure there's anything in any of the products that makes one better than the other (except Mastodon is actively obtuse). It's just a matter of who joins and how they interact. People on Bluesky act like people on Twitter used to, but maybe (hopefully) without as much rage-baiting. Though seeing some classic Twitter personalities translating their snarky and meta commentary to Bluesky, I'm finding it doesn't really work... the medium is exactly the same, but the vibe isn't. Threads feels like a text Instagram, because so many of its users came from there. It can be entertaining, but it feels ephemeral, and the algorithm promotes a kind of low-brow broad content that doesn't make me feel good after consuming it. Somehow it feels like trying to make a social network out of someone else's comment thread... like it's never really meant for us. X feels pretty shitty, not like Twitter. It's a lot of self-promotion bullshit, and doubling down on rage bait. Using it is also an expression of fealty to someone who in his vanity is actively hurting this nation. Threads isn't an expression of fealty to Zuckerberg... it's all filtered through the capitalistic process that mostly removes direct ideology. It might suck or be great, but it's not a person. X is a person. There's no way to separate the two. Bluesky feels like what we make of it. There's not a lot of algorithm putting its thumb on the scale. reply that_guy_iain 18 hours agoparentprev> Low quality article aside, Threads also had a major spike in usage that quickly dropped off. I could be wrong, but I’m going to guess Bluesky will be the same. Threads had a lot of users sign up when it first launched. Bluesky launched over 18 months ago. > They don’t seem to offer anything new/different other than moderation, which I’m not convinced is enough to shift momentum from x to bluesky There are tons of differences. For example, if there are replies in a thread and one of the users blocks the other. Those replies are blocked out for everyone. If you quote post a user you've blocked. That post is blocked out for everyone. There are starter kits that are creating tons of growth in accounts for lots of people so you're not posting to nothing. The engagement is higher, seriously people are posting the same stuff on Twitter and Bluesky and with 10x more on Twitter there getting 2x better engagement on Bluesky. If someone quote posts you and you don't like it, you can remove the post from the quote. You can hide replies in your threads. It has a threaded UI that looks like reddit comment threads. I think everyone has been waiting for a replacement to emerge and Bluesky has spent a lot of time slowly growing and slowly adding features that it does everything people want from Twitter with more control. reply add-sub-mul-div 19 hours agoparentprevIt would be the worst thing for Bluesky if the eternal September came over from Twitter. I think that population is too passive to make the move and will put up with any level of advertising etc. reply jauntywundrkind 19 hours agoparentprev> They don’t seem to offer anything new/different other than moderation Pretty wildly obviously critically incorrect statement right there! It's still early days, but BlueSky is \"protocols not platforms.\" So there's lots of extensibility baked in. There's already a variety of custom feeds available. Which in short lets us opt in to whatever algorithms we would like. I love my Quiet Posters feed, which emphasizes folks who aren't super active, who I would otherwise miss. The default view is a timeline, which is so much better than the disgusting engagement farming shallow or demented shit that floods Threads and X. So the default view is much better, much less polluted with awful garbage, and I have the ability to control what I see, what algorithms I would want to opt in to. There's a variety of different clients available, which is a nice option for power users and those trying to organize the many flows and feeds they want to keep tabs on. Everyone else is making links harder to engage with or algorithmically de-prioritizng them. BlueSky claims they \"love the open web\" and don't do any of that gross entrapping. The \"protocols not platforms\" ethos here allows new stuff to get built around and on top of Bluesky. Early days, but there's a bunch of projects listed on for example https://github.com/fishttp/awesome-bluesky . Everything else is run top down by awful sterile controlling corporate interests, but BlueSky has that emerging new possibilities potentiation going strong, by appealing to developers, asking them to build stuff. Here's their latest call for projects... You just don't see that sort of stuff anywhere except BlueSky anymore. https://github.com/bluesky-social/atproto/discussions/3049 reply epistasis 14 hours agoparentprevIt's not just checkbox features that matter, it's also the entire algorithm and who is allowed to have their posts gain organic traction. X actively penalizes high quality information, and pushes misinformation in an attempt to become an echo chamber. If you want to find your colleauges' posts, if you want to find high quality information, if you want good links to long articles, X is no longer the place to be. If you want to have click-bait and rage-bait or lots of right-wing politics, X will cater to your needs. But it won't cater to somebody that's trying to get to highly-curated high-signal information networks that Twitter allowed in the past. That's all been actively destroyed, with great intention. reply ineedaj0b 19 hours agoparentprevX is pretty great now. Once the politics dies down a little it'll be the best place to be for the next 4+ years reply akira2501 19 hours agoprev> overtaking Threads So the lowest bar possibly imaginable? reply ks2048 18 hours agoparentI've fallen for the Threads-links shown in Instagram. Obviously the instagram connection is what gave them a great start at a user-base. But, everytime I try to use Threads, something seems off (mainly see lame, boring, engagement-bait). Bluesky seems different and better. Also a much better story in-terms of open data, open protocol, etc. reply enjaydee 18 hours agoparentprevI don't think it's that low of a bar. Threads benefited from easy account creation and promotion from Instagram (2b MAU?) Bluesky started from word of mouth invite only reply glenstein 15 hours agorootparentYeah, getting anywhere near what the major tech companies are capable of should be understood as a triumph. Does anyone remember now Spoutible? Substack Notes? How about Spill, Hive, or Post? Being even with in anything approximating striking distance of Threads would have been a triumph for any of them. reply jrs235 18 hours agoparentprevI can think of a \"Truthier\" \"social network/platform\" that is lower than Threads... reply peanuty1 14 hours agorootparentTrumpet (AKA Truth Social)? reply johnchristopher 19 hours agoparentprevReally ? Right in front of my lemmy username ? reply tmaly 19 hours agoparentprevI downloaded threads when it came out, but I only used it once. reply wnevets 16 hours agoprevThe head of instagram/threads (Mosseri) appears to have no idea how the algorithm on these platforms work. He is shocked to see how many people are talking about threads in his feed. It may explain how threads has managed to waste such a large captured audience. reply dgudkov 13 hours agoprevAn extension to port your following from Twitter to Bluesky: Chrome: https://chromewebstore.google.com/detail/sky-follower-bridge... Firefox: https://addons.mozilla.org/en-CA/firefox/addon/sky-follower-... Disclaimer: I'm not affiliated in any way. I just tried it and it worked well. reply ogou 7 hours agoprevThreads attracted a lot of people that I left behind on Facebook. It also gets a lot of people that cross-post to every platform. I can't think of a single post that I saw and still remember. Bluesky lets you block reposts and that has been the killer feature for me. Original content from people I choose is the best recipe for my tastes. Also, I spend a lot of time on niche creative feeds and really enjoy the things I see. I also like the idea of seeing regional and local feeds. That was an interesting part of early Twitter that was obliterated by national political emphasis. No more political hot takes, where is a good Korean BBQ spot? reply phb01 18 hours agoprevI think the factor which will determine which networks survive is the ability to handle bots driven by modern AI agents. I’m not sure how even the best moderation features can detect and mitigate these. reply wmf 18 hours agoparentAI doesn't matter. Moderation should apply to humans and AIs equally. reply glenstein 15 hours agorootparentIt does matter because AI can be more effectively leveraged and scaled to support \"coordinated inauthentic activity\" campaigns. reply prisenco 16 hours agorootparentprevAI has the ability to overwhelm systems of moderation at a much greater scale than humans. That's the issue. reply Der_Einzige 14 hours agorootparentGood. reply devnullbrain 14 hours agorootparentCare to share your IP address? reply prisenco 14 hours agorootparentprevCan you explain how that's a good thing? reply mcphage 16 hours agorootparentprev> Moderation should apply to humans and AIs equally. Unless you’re trying to create a social network to promote human voices and not bots. reply joshdavham 17 hours agoparentprevIt’s gonna be incredibly interesting to see what happens concerning this. I suspect that bots will probably thrive in feeds where ‘the algorithm’ is responsible for recommending most content. However, bots probably won’t do as well with vanilla follower feeds. reply senojsitruc 19 hours agoprevFor all the ways that matter, find a more meaningful bar. reply kivle 17 hours agoprevFor me it's a very easy choice to go with Bluesky over Threads. With Threads you can already see that Facebook/Instagram is in it's DNA. There's no pure \"following\" feed. It's instead an algorithmic feed that mixes people you follow with people Threads decides to push. So it's going down the enshittification path from day one. With Bluesky there's at least some hope that it will not end up as the algorithmic time sinks all other social media has slowly become. I'm all for discoverability, but allow me to decide when and how I discover new people to follow. Never touch my \"following\" feed, and I'll be happy. reply elisharobinson 3 hours agoprevthey are afloat using VC math . I dont think modern web is a place for a social media company. the AD revenue / AWS bill does not make sense. Unless they become a data broker like Meta. Or become the microphone for a group or individual. reply cynicalpeace 16 hours agoprevI predict Bluesky will go the way of Threads and Mastodon. reply jaimex2 14 hours agoparentProbably worse. Mastedon runs on self hosting, Threads has a parent company with deep pockets and is a Instgram mod at best. Twitter burned cash for years and it could because it was new, innovative and growing quickly. Once BlueSky burns through its initial money whats the plan and why would anyone invest in it? reply taspeotis 19 hours agoprev> Meta-owned Threads started November with 5 times the daily app users of Bluesky. That number is now down to just 1.5. Is this because Threads is fading into obscurity and has fewer daily app users than their peak, and Bluesky has a bit more than they had before in November? Today are either within an order of magnitude of X? reply dylan604 19 hours agoparentBlusky started at 0. Threads started with existing meta users. That seems like a big difference to me. reply willsmith72 19 hours agoparentprev> Is this because Threads is fading into obscurity and has fewer daily app users than their peak, and Bluesky has a bit more than they had before in November? Looks like no, threads is pretty flat and bluesky is hockey stick-ing from this graph: https://bsky.app/profile/jburnmurdoch.bsky.social/post/3lbmp... not sure what x data looks like reply threeseed 19 hours agoparentprev> Is this because Threads is fading into obscurity Threads has ~300m MAU and will be on track to being larger than X in a year. In fact X is struggling so much they now provide the option to hide engagement metrics: https://www.newsweek.com/elon-musk-hides-x-engagement-figure... reply Numerlor 17 hours agoprevGotta ask, am I missing something with how bluesky is supposed to be used? Every time I open something from there it takes over 30 seconds to load on my phone reply elicash 15 hours agoparentYou're experiencing a bug. reply damnloveless 4 hours agoprevlive bluesky user counter: https://bcounter.nat.vg/ reply PittleyDunkin 17 hours agoprevDid thread have significant traffic to begin with? The last four to six times I logged on it was a ghost town. reply peanuty1 10 hours agoparentThey claim to have about 300 million MAUs but it feels empty compared to X. reply elphinstone 13 hours agoprevWhere's Google's Twitter clone? It can have AI nobody wants, a bland name nobody will remember, and be quietly sunsetted when nobody uses it. reply rsynnott 11 hours agoparenthttps://en.wikipedia.org/wiki/Google_Buzz It was actually okay. Half-surprised they didn’t bring it back when Twitter self-immolated. reply slater 12 hours agoparentprevCan't help you on the first item there, but everything else: https://en.wikipedia.org/wiki/Jaiku reply mhh__ 19 hours agoprevThreads has a massive problem in that it recruits its users from Instagram (there are others but primarily its still a branch of Instagram) which is the domain of AI generated slop and people I actually know in real life. The whole point of the twitter style firehose is to be not be either of those things. Bluesky honestly probably has a decent shot but I think its still attracting some hyper-orthodox, censorious, thinkers. Musk has gone too far with X[0] but I don't think his vision in the abstract is wrong. [0] Every accusation is a confession - X is now near-directly attached to the US Gov! reply cosmic_cheese 18 hours agoparentI think the Bluesky crowd will probably chill out with time, but right now if you don’t readily use the block feature there you’re going to have your feed and notifications peppered with the same trolls that are currently making X inhospitable. The majority of users getting blocked aren’t interested in actual discourse, they’re just there to get a rise out of people. It’s difficult to envision any social network staying healthy in the long term without either decent moderation or robust tools to help users manage harassment and the like. There’s just too many bad actors who will take advantage of low-control environments. reply skybrian 18 hours agorootparent> inevitable I don't get any trolls on either platform. I guess I'm too boring :) reply cosmic_cheese 17 hours agorootparentI don’t get much trouble myself personally either, but it shows up in the replies to the posts in my feed which isn’t great and why a good block feature is necessary. reply skybrian 16 hours agorootparentYes, but the root cause is that Twitter doesn't stop rendering posts when there are no replies left to display. Instead it fills the silence with posts that aren't replies. BlueSky just stops, like a normal program. When there's nothing more to show, silence is okay. So I don't need a blocklist there. reply threeseed 19 hours agoprevPeople keep missing the point of Threads. It isn't designed to be a pure Twitter clone and doesn't want to become the public square for news, politics etc. It wants to be a text-centric network that helps release Instagram to be more video-centric to compete with TikTok. And so it wants content that is fun, interesting and light. And of course easily monetisable. So I know people like having a fight but I see the two sites as being complimentary and both needing to thrive in order to relegate X to the dust bin. reply jazzyjackson 14 hours agoparentInstagram was the only social network that kept me around because it was mostly art and nice photos. Recently i caught myself scrolling past endless videos and thought, shit, I've been tiktokked. Back to scrolling through hacker news comments to rot my brain instead. reply danielbln 11 hours agorootparentI had to disable my YouTube watch history recently because I got trapped into shorts frequently and the only way to disable those is to kill the watch history. One might think it's only Gen Z/Alpha that is susceptible to the Tiktok dopamine squeeze, but no, works just as well on us old geezers and it's pretty nefarious how well it works. reply vanjajaja1 18 hours agoprevthreads federates with mastodon, what stops threads getting on the AT protocol? is it just their assumed desire to not share data? they could be a mastodon / AT bridge reply rsynnott 11 hours agoparentThere are a couple. They’re… shaky, but they exist. reply sakesun 17 hours agoprevI find it's interesting that React which Bluesky was built on, was originally license with BSD + patents, which disallow building Facebook competing products. reply jazzyjackson 14 hours agoparentI agree there's some irony to",
    "originSummary": [
      "Bluesky, a decentralized platform initially associated with Jack Dorsey, is gaining traction and now has 3.5 million daily active users, closing in on Meta's Threads.",
      "The platform experienced a 300% user increase since the November 5 election, as journalists and academics migrate from Elon Musk's X, seeking more open public discourse.",
      "Bluesky's growth is challenged by issues such as outages and scams, but its appeal is strengthened by Meta CEO Mark Zuckerberg's decision to limit political content on Threads."
    ],
    "commentSummary": [
      "Bluesky is attracting users with features such as custom labels, algorithm choice, and a chronological feed, offering a more user-controlled experience compared to Threads.",
      "It is viewed as a potential alternative to X (formerly Twitter) due to its focus on user choice and reduced algorithmic interference.",
      "Despite its growing popularity, concerns about Bluesky's sustainability and monetization persist, as it is still in its early development stages compared to more established platforms."
    ],
    "points": 280,
    "commentCount": 322,
    "retryCount": 0,
    "time": 1732486994
  },
  {
    "id": 42230355,
    "title": "Pushing AMD's Infinity Fabric to Its Limit",
    "originLink": "https://chipsandcheese.com/p/pushing-amds-infinity-fabric-to-its",
    "originBody": "Share this post Chips and Cheese Pushing AMD’s Infinity Fabric to its Limits Copy link Facebook Email Notes More Pushing AMD’s Infinity Fabric to its Limits Chester Lam Nov 24, 2024 27 Share this post Chips and Cheese Pushing AMD’s Infinity Fabric to its Limits Copy link Facebook Email Notes More 6 Share I recently wrote code to test memory latency under load, seeking to reproduce data in various presentations with bandwidth on the X axis and latency on the Y axis. Ampere pretty much described how that was done during their Hot Chips 2024 presentation. To achieve the same results in a semi-automated fashion, I run a latency test thread while also running a variable number of threads that generate bandwidth load. We run a single latency sensitive application and gradually add bandwidth hungry applications. Matthew Erler, during the AmpereOne presentation at Hot Chips 2024 Getting good data from the test required more care than I anticipated. Some AMD chips were particularly sensitive to thread placement. Certain core affinity choices would result in dramatic latency spikes, while others showed latency being very well controlled even with similar or higher achieved bandwidth. I worked around this issue when I wrote the Broadwell article. But now, it’s time for a more detailed dig into AMD’s system topology and the various bottlenecks it may present. Loaded latency graph during Ampere’s presentation at Hot Chips 2024 AMD chips since Zen have used multiple levels of interconnects to create a modular system, letting AMD hit high core counts quickly and cheaply. Several Zen cores share a L3 cache within a cluster, called a Core Complex (CCX). CCX-es access the rest of the system through AMD’s Infinity Fabric, a flexible interconnect that lets AMD adapt system topology to their needs. Since Zen 2, that meant putting CPU cores on Core Complex Dies (CCDs). CCDs connect to a separate IO die, which talks to system memory and slower components like PCIe, SATA, and USB. That creates a hub and spoke model, and let AMD push core counts higher than Intel. IFOP link from AMD’s Zen 2 platform (Matisse/Rome), from an ISSCC 2020 paper CCDs connect to the IO die using an Infinity Fabric On-Package (IFOP) interface. A CCD’s IFOP link provides 32 bytes per cycle of read bandwidth and 16 bytes per cycle of write bandwidth, at the Infinity Fabric clock (FCLK). FCLK is typically far lower than L3 and core clocks. In later Zen systems with faster DDR5, one IFOP may not have enough bandwidth to saturate DDR5 bandwidth. Past that potential bandwidth limit, DDR memory has not been able to provide enough bandwidth to handle what all cores can demand in a high core count system. Of course, there can be other points of contention too. On Zen 2, multiple CCX-es can contend for one IFOP interface. Here, I’ll look at how pushing bandwidth limits at multiple points affects a latency sensitive thread contending for the same shared resource. Instead of presenting data with latency on one axis and bandwidth on another, I’m going to plot latency and bandwidth as two separate series to show how latency is affected by core count. Zen 4: AMD Ryzen 9 7950X3D Zen 4 is AMD’s outgoing CPU generation, and makes for a convenient testing platform because it’s my daily driver desktop. As a recent member of the Zen line, it has one octa-core CCX per CCD. A single Zen 4 core can read from a 3 GB array at about 50 GB/s, so it can guzzle an incredible amount of memory bandwidth compared to prior Zen generations. That should make any bottlenecks easy to see. I’m using a typical DDR5 configuration with moderately spec-ed DDR5-5600. Under minimal load, my system has 82-83 ns of DRAM latency. A latency test thread quickly sees worse latency as bandwidth demand from other cores starts filling up queues throughout the memory subsystem. Just a couple bandwidth test threads are enough to push the CCD’s memory subsystem to its limits. Up to 7 bandwidth test threads and the latency test thread, all pinned to the non-VCache CCD Increasing thread count makes latency skyrocket, probably as more cores cause more contention for queue capacity. Latency shoots past 400 ns when fighting with five bandwidth threads. Shoving the bandwidth load to the other CCD dramatically improves latency. I see a weird latency spike when CCD0 has one core demanding bandwidth, and CCD1 is running the latency test. Loading more cores on CCD0 curiously brings latency down, even as achieved bandwidth inches up. I wonder if AMD is detecting active core count, and starts reserving queue entries or otherwise throttles per-core bandwidth consumption if enough cores require high bandwidth. Bandwidth improves alongside latency. In fact, the CCD running eight bandwidth test threads achieves nearly 64 GB/s. AMD seems to get excellent bandwidth efficiency out of the IFOP interface when the bandwidth test threads aren’t fighting with the latency thread. Taken together, those two observations suggest AMD’s dual CCD setup can act as a QoS mechanism of sorts. Containing bandwidth hungry code within one CCD can let latency sensitive code on the other CCD to proceed with minimal impact. To test the whole system, I switched up core loading order to alternate between CCDs when adding bandwidth test threads. That lets me use both IFOP links, hopefully maximizing memory bandwidth. Achieved bandwidth of course is higher, and latency remains well under control with a couple of bandwidth test threads in play. I also achieve maximum bandwidth with one bandwidth test thread running on each CCD. But the situation rapidly gets out of control as I spawn more bandwidth test threads. We’re probably looking at contention at both the CCD and memory controller level. Latency delays at both layers seems to be additive, and the latency test thread really gets the worst of it when it has to fight with more than 10 bandwidth hungry threads. At this point, the system also started behaving strangely. For example, bringing up the “Details” tab in Task manager took an agonizingly long time, even though my test only loaded up one thread per physical core. Thankfully, I think it’s a rather extreme and non-typical workload. Hardware Performance Monitoring Observing latency from software is simple, but I can get more information by asking the hardware what’s going on. Zen 4’s L3 cache has performance monitoring facilities. One of its capabilities is randomly sampling L3 misses and tracking their latency. Event documented in AMD’s Zen 4 Processor Programming Reference (PPR) While this performance monitoring event provides an idea of average latency just as my C and assembly code does, they don’t measure exactly the same thing. Software can only observe load-to-use latency. That includes latency all the way from address generation within the core to getting the data from somewhere in the memory hierarchy. AMD uses the mnemonic “XiSampledLatency” to describe their event. “Xi” is a component in Zen’s L3 cache complex that interfaces with the rest of the system. Likely, it stands for “eXternal Interface”. It probably has a set of queues to track outstanding requests. Sampling latency would be as simple as noting how long a queue entry remained allocated. Figure from AMD’s ISSCC paper on Zen 1, showing the L3 cache complex. Xi is likely eXternal Interface. DP might be Datapath, STM = State Macros, LRU = least recently used metadata Because this event is likely implemented in the Xi, it only measures latency after a L3 miss. DRAM latency as seen from software will include latency introduced at many other layers. That includes address generation, and checking each cache layer before a L3 miss is discovered. Therefore, latency seen by the Xi should be lower than latency seen by software. Still, this event is useful for seeing how the memory subsystem behaves after a L3 miss. Data from the Xi roughly correlates with software observations at the start of my full system bandwidth test, when CC1 runs a latency test and CCD0 runs a single thread generating bandwidth load. Software sees 190 ns of latency, while L3 performance monitoring on CCD1 sees 166 ns. X axis = elapsed time during test run. Latency test thread on CCCD1. I alternate between CCDs when adding bandwidth test threads Interestingly, performance monitoring data from the other CCD suggests Zen 4 prioritized the bandwidth hungry thread at the expense of the latency sensitive one. As a sanity check, L3 miss bandwidth from the CCD hosting the bandwidth test thread is 59 GB/s, almost exactly matching what I calculated from software. Once I spawn more bandwidth test threads, performance monitoring data suggests average latency rises to around 200 ns. However, software observations from the latency test thread sees latency go beyond 700 ns. Requests from the latency test thread account for a small minority of traffic passing through the memory subsystem, so it makes sense that the average latency as seen by the Xi doesn’t reflect my measurements. Zen 5 with Fast DDR5 Zen 5 is the latest and greatest member of AMD’s Zen line. It uses the same IO die as Zen 4, but the CCDs have changed. Cheese (George) has set the system up with very fast DDR5, and is running Infinity Fabric at a slightly higher clock to boot. I wouldn’t call this a typical setup. DDR5-8000 kits are expensive. AMD’s reviewer guide recommends 6000 MT/s as a sweet spot. Yet this configuration provides a look into how Infinity Fabric performs with a ton of memory bandwidth available. I shouldn’t come anywhere close to DRAM bandwidth limits from within a single CCD. And indeed, latency is much better as I push to the IFOP’s bandwidth limits. Latency also starts off lower under high load, probably thanks to the very fast DRAM configuration. Contention within a single CCX still increases latency, but not to the same extent as with Zen 4. Zen 5 cores can also individually gobble down tons of bandwidth just like its predecessor. Perhaps CCX-level changes play a role. At Hot Chips 2024, AMD showed a slide suggesting each Zen 5 CCX has a pair of XIs. The two XIs together likely have more queue entries available than on Zen 4, which the slide also hints at. That probably decreases the chance of bandwidth hungry threads monopolizing all queue entries and starving out a latency sensitive one. Moreover, IFOP bandwidth covers just 55% of DDR5 bandwidth in this setup, compared to 71.4% on my Zen 4 system. Lower load on the memory controller gives it more room to manage DRAM inefficiencies like bus turnarounds, refreshes, or bank conflicts. I suspect Zen 5’s better behavior comes down to a combination of both factors. As with Zen 4, CCD boundaries can insulate a latency sensitive thread from bandwidth hungry code. On this Zen 5 system. faster memory and faster Infinity Fabric clocks make everything better overall. More significantly, the latency spike observed on Zen 4 with one bandwidth thread is gone. On Zen 4, that spike must have been caused by something within Infinity Fabric. After all, the latency and bandwidth test threads can’t fight for the same XI or IFOP if they’re on different CCDs. Even though Zen 5 uses the same IO die, AMD may have tweaked their traffic management policies to more fairly service cores with varying memory access patterns. The Ryzen 9 9950X and its fast memory setup continues to impress as I load both CCDs. Even as memory bandwidth passes 100 GB/s, latency remains well under control. Those DDR5-8000 memory sticks appear to cost $250 for a 48 GB kit. For that much money, you better get top-notch performance. Again, I suspect AMD tweaked something to improve latency under load. Crazy 700 ns measurements from Zen 4 are gone. I’m not pushing as close to DDR5 bandwidth limits on Zen 4, but Zen 4’s performance monitoring data suggests latency shouldn’t have been too far above 200 ns. Zen 2: Two Clusters Per CCD/IFOP Zen 2 may be a bit dated, but it did debut AMD’s modern chiplet setup. More interestingly, it has two quad core CCX-es per CCD. That lets me look at CCX-level and CCD-level bottlenecks separately. Unlike Zen 4 and Zen 5, I’m running Zen 2 with matched FCLK and DRAM speeds. Thus one CCD’s IFOP bandwidth matches DRAM bandwidth. Zen 2 achieves about 84.4% of theoretical DRAM bandwidth from a single CCX. That’s a larger percentage than Zen 4 (71.4%) or Zen 5 (55%). Of course both later generations achieve better absolute bandwidth. Latency starts at 71.7 ns, and increases to 142.77 ns when three bandwidth hungry threads share the same CCX. But the latency test thread running on one CCX is reasonably well insulated from bandwidth load on another CCX, even if both CCX-es are on the same CCD. That leads me to think the CCX’s XI may be a more significant bottleneck than the IFOP link downstream. Creating bandwidth demand across both CCX-es within a CCD drives latency up. That’s no surprise because there’s now contention at both the CCX’s XI, and at the IFOP. Still, Zen 2 doesn’t do too badly. 285 ns of latency isn’t great, but it’s better than Zen 4’s 400 ns from a single CCD. Zen 5 is better than both at ~151 ns for a comparable CCD-level contention test. I suspect Zen 2 does better than Zen 4 because Zen 2 cores individually can’t consume as much bandwidth. DRAM latency is high, which means you need a lot of in-flight requests queued up to sustain high DRAM bandwidth. A Zen 2 core can only sustain enough in-flight requests to achieve 24-25 GB/s of DRAM bandwidth. That’s well short of Infinity Fabric or DRAM bandwidth limits, so the latency test thread has a good chance of finding free queue entries for its own requests. Zen 2 can benefit from CCD-level isolation too, just like Zen 4 and Zen 5. Like Zen 5, Zen 2 doesn’t see a latency spike with a single bandwidth hungry thread. However, I doubt there’s any sophisticated traffic management going on here. Again, a single thread isn’t able to sustain enough L3 misses to monopolize downstream queues. Stepping back, Zen 2’s DDR4 controller is doing an excellent job of scheduling memory requests under high load. Despite being pushed closer to its bandwidth limits, the Ryzen 9 3950X is able to keep latency under control. In the bandwidth on CCD1, latency tested from CCD0 scenario, the 3950X maintains better latency than the 7950X3D. Loading both CCDs does increase latency, but it’s better than drawing all DRAM bandwidth through one CCD’s IFOP. Even though one IFOP interface has enough bandwidth to saturate the DDR4 controller, using both IFOP interfaces together provides better latency. That’s likely because I’m only pushing DDR4 bandwidth limits at this point, rather than pushing both DDR4 and a single IFOP to its limits. Those observations suggest contention within a CCX is most problematic, though contention over an IFOP interface can slightly increase latency too. Zen 2 also has a pair of XI performance monitoring events for tracking average L3 miss latency. However, Zen 2 does a more straightforward measurement in cycles, rather than randomly sampling requests. The PPR tells you to divide the latency event by request count to get latency in cycles. Basically, it’s telling you to solve Little’s Law. Working backwards, the latency event is incrementing with the XI’s queue occupancy per cycle. From AMD’s Zen 2 PPR. There’s a corresponding event that you can divide by to get L3 miss latency in cycles. latency = queue occupancy / request count. So the latency event tracks queue occupancy Looking at the queue occupancy figure on its own shows average queue occupancy around 59-61, which is suspiciously close to 64. Unfortunately AMD’s L3 performance counters don’t support count masking, but the average figure could mean each CCX’s XI has 64 queue entries. If so, two CCX-es together would have 128 XI queue entries. At Hot Chips 33, AMD presented a slide indicating the XI for Zen 3’s merged, octa-core CCX has 192 queue entries. AMD’s slide from Hot Chips 33 showing 192 pending misses from the CCX to memory With Zen 5, AMD may have 320 XI queue entries per CCX, likely 160 entries in each of the CCD’s two XI blocks. Unfortunately, I haven’t found any information on Zen 4’s XI queue capacity. Perhaps Zen 4 increased the number of queue entries, but not by enough to accommodate Zen 4’s massive jump in memory level parallelism capabilities. Both the L2 and the L3 received larger miss queues to support more outstanding requests Kai Troester, at AMD’s Hot Chips 2023 presentation on Zen 4 If so, that would explain some of the weird behavior I see on Zen 4. Queue entries of course aren’t free, and larger queues cost both area and power. AMD could have made a sensible tradeoff on Zen 4 if users rarely run into those limitations. AMD likely evaluated many programs and decided on a sensible tradeoff. I don’t have the time or resources to do what a full time employee can, but I can go through a few examples. Latency and Bandwidth in Practice Here, I’m running Cyberpunk 2077’s built-in benchmark at 1080P. I ran the benchmark twice with the game pinned to different CCDs, which should make performance monitoring data easier to interpret. On the non-VCache CCD, the game sees 10-15 GB/s of L3 miss traffic. It’s not a lot of bandwidth over a 1 second interval, but bandwidth usage may not be constant over that sampling interval. Short spikes in bandwidth demand may be smoothed out by queues throughout the memory subsystem, but longer spikes (still on the nanosecond scale) can fill those queues and increase access latency. Some of that may be happening in Cyberpunk 2077, as performance monitoring data indicates L3 miss latency is often above the 90 ns mark. Pinning Cyberpunk 2077 to the VCache die significantly reduces L3 miss traffic, showing the value of having three times as much L3 capacity on hand. L3 misses are serviced with lower latency too. Less memory traffic reduces queuing delays, throughout the memory subsystem. Thus VCache has a secondary benefit of reducing average DRAM latency. It’s a potent combination, and one that’s reflected by the benchmark’s output. Cyberpunk 2077’s benchmark averaged 122.34 FPS when pinned to the non-VCache die, and 153.98 FPS when pinned to the VCache die. Despite clocking lower, the VCache die delivered 25.8% better performance. Stepping back, neither scenario sees the game push against bandwidth limits anywhere in the memory subsystem. Latency in both cases is well under control, and baseline latency has more of an impact on performance than latency incurred from approaching bandwidth limits. GHPC is a tank game, and presents another example. Patterns are similar, though with lower bandwidth demands. Again VCache shows its worth by servicing more memory requests on-die. And again, reducing load on the memory subsystem past L3 reduces average L3 miss latency. Baldur’s Gate 3 is a role playing game where you can roll dice and throw things. Bandwidth demands vary wildly from second to second, but sampled memory latency remains well under control. We don’t get anywhere close to the 200 ns that would suggest a bandwidth bottleneck. Again, Zen 4’s memory subsystem isn’t under significant pressure. VCache continues to do an excellent job, bringing L3 hitrate from 31.65% to 79.46%. But even without VCache, there’s plenty of spare Infinity Fabric and DDR5 bandwidth to go around. RawTherapee is a free and open source raw file conversion program. Enthusiast cameras can record raw 12 or 14-bit sensor data instead of processed JPEGs. Raw files give photographers much more editing headroom to make exposure and white balance adjustments. They also let the editor make conscious tradeoffs between preserving detail and reducing noise. However, image processing can be computationally intensive. Here, I’m converting a few 45.7 megapixel D850 raw files to JPEGs, with exposure and noise reduction applied. I didn’t pin RawTherapee to a CCD because image processing is a parallel task that benefits from high core counts (unlike most games). Instead, I’m logging data for both CCDs simultaneously. RawTherapee has spiky bandwidth demand – enough to fill queues, but often not long enough to run for longer than my 1 second sampling interval. That’s where the sampled latency figure gives valuable insight. Latency spikes to over 200 ns, indicating the memory subsystem is pushed to its limits. Not all multithreaded programs stress the memory subsystem though. I played Baldur’s Gate 3 while running video encoding jobs in the background. L3 miss traffic is significant but not overwhelming. Latency remained under control, and the game held 60 FPS most of the time. Video encoding can demand a lot of bandwidth, but the Ryzen 9 7950X3D’s L3 cache contains enough of it to avoid contention at the XI, Infinity Fabric, or DRAM controller levels. Off-core traffic exceed 85 GB/s over some sampling intervals, so a hypothetical Zen 4 setup with no L3 cache would suffer heavily from DRAM and Infinity Fabric bottlenecks. For perspective, here’s a bandwidth plot with L3 hit bandwidth included. Long ago, chips like AMD’s Llano or Excavator only had 1 MB L2 caches and no L3. A large L3 cache takes significant die area and adds complexity, so I understand why AMD omitted it on certain products. But I can only imagine how hard even a fast DDR5 setup would be pushed by a hypothetical desktop chip with 16 cores, 1 MB of L2 per core, and no L3. Any interconnect sitting between the cores and memory would be heavily loaded too. Of course, such a setup doesn’t exist for good reason. Final Words AMD’s successful Zen line stands on top of a scalable system architecture with multiple interconnect levels. But designing a scalable architecture is hard. Several blocks at one level may have to be fed through a choke point in the next level. If many cores are asking for as much bandwidth as they can get their hands on, queues can start filling and cause delays. That risks a “noisy neighbor” problem where latency sensitive code is penalized by bandwidth heavy code running elsewhere on the system. Delays at level in the memory subsystem are additive. A request held up for a dozen cycles waiting for an XI queue entry will be dozens of cycles late to the party when fighting for IFOP cycles. Any additional delays at the IFOP will mean the request goes through various Infinity Fabric components later, and so on. Zen 4 appears to be most severely affected by compounding delays, probably because AMD let individual cores consume way more bandwidth than before. But as performance counters and observations on Zen 2 show, AMD’s Infinity Fabric and memory controller do a good job of maintaining reasonable latency under load. CCX-level contention seems to cause the worst of the loaded latency spikes I saw. For the most part, these limitations aren’t seen in typical client applications. Games can be latency sensitive, but the ones I tested don’t create enough bandwidth demand to stress parts of the memory subsystem. Even well threaded productivity workloads may not push bandwidth limits, as AMD’s large L3 cache can contain a lot of memory accesses. Some workloads, like RawTherapee, are both difficult to cache and well threaded. I wouldn’t advise running such a workload alongside a game or another latency sensitive program. Still, Zen 5 shows AMD is paying some attention to ensuring a good baseline level of performance for latency sensitive tasks, even when the memory subsystem is very busy. If time permits, I intend to test some Intel chips too. Many Intel chips basically have a single level interconnect, with a mesh or ring stop connecting cores to L3, DRAM, an iGPU, and possibly other blocks too. My first impression is that Intel’s Comet Lake behaves much like AMD’s Zen 2, though without the CCX and CCD-level contention points. Loading all cores brings latency up to 233.8 ns, worse than Zen 2 with all cores loaded, but better than Zen 2 with all bandwidth load and the latency test stuck on a single CCD. Eventually, I plan to play with some cloud server instances too. If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our Patreon or our PayPal if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our Discord. Subscribe to Chips and Cheese Launched a year ago The Devil is in the Details! Deep dives into computer hardware and software and the wider industry... Subscribe Error 27 Share this post Chips and Cheese Pushing AMD’s Infinity Fabric to its Limits Copy link Facebook Email Notes More 6 Share PreviousNext",
    "commentLink": "https://news.ycombinator.com/item?id=42230355",
    "commentBody": "Pushing AMD's Infinity Fabric to Its Limit (chipsandcheese.com)210 points by klelatti 22 hours agohidepastfavorite22 comments majke 6 hours agoThis has puzzled me for a while. The cited system has 2x89.6 GB/s bandwidth. But a single CCD can do at most 64GB/s of sequential reads. Are claims like \"Apple Silicon having 400GB/s\" meaningless? I understand a typical single logical CPU can't do more than 50-70GB/s, and it seems like a group of CPU's typically shares a mem controller which is similarly limited. To rephrase: is it possible to cause 100% mem bandwith utilization with only or 1 or 2 CPU's doing the work per CCD? reply ryao 4 hours agoparentOn Zen 3, I am able to use nearly the full 51.2GB/sec from a single CPU core. I have not tried using two as I got so close to 51.2GB/sec that I had assumed that going higher was not possible. Off the top of my head, I got 49-50GB/sec, but I last measured a couple years ago. By the way, if the cores were able to load things at full speed, they would be able to use 640GB/sec each. That is 2 AVX-512 loads per cycle at 5GHz. Of course, they never are able to do this due to memory bottlenecks. Maybe Intel’s Xeon Max series with HBM can, but I would not be surprised to see an unadvertised internal bottleneck there too. That said, it is so expensive and rare that few people will ever run code on one. reply buildbot 2 hours agorootparentPeople have studied the Xeon Max! Spoiler - yes, it's limited to ~23GB/s per core. It can't achieve anywhere close to the theoretical bandwidth of the HBM even, with all cores active. It's a pretty bad design in my opinion. https://www.ixpug.org/images/docs/ISC23/McCalpin_SPR_BW_limi... reply KeplerBoy 6 hours agoparentprevAren't those 400 GB/s a figure which only apply when the GPU with its much wider interface is accessing the memory? reply bobmcnamara 3 hours agorootparentThat figure is at the memory controller. It applies as a maximum speed limit all the time, but it's unlikely that a CPU would cause the memory controller to reach it. Why it's important is that it causes increased latency whenever other bus controllers are competing for bandwidth, but I don't think Apple has documented their internal bus architecture or performance counters necessary to see how. reply doctorpangloss 2 hours agorootparentprevAnother POV is that maybe the max memory bandwidth figure is too vague to guide people optimizing libraries. It would be nice if Apple Silicon was as fast as \"400GB/s\" sounds. Grounded closer to reality, the parts are 65W. reply jeffbee 3 hours agoparentprevThere are large differences in load/store performance across implementations. On Apple Silicon for example the M1 Max a single core can stream about 100GB/s all by itself. This is a significant advantage over competing designs that are built to hit that kind of memory bandwidth only with all-cores workloads. For example five generations of Intel Xeon processors, from Sandybridge through Skylake, were built to achieve about 20GB/s streams from a single core. That is one reason why the M1 was so exceptional at the time it was released. The 1T memory performance is much better than what you get from everyone else. As far as claims of the M1 Max having > 400GB/s of memory bandwidth, this isn't achievable from CPUs alone. You need all CPUs and GPUs running full tilt to hit that limit. In practice you can hit maybe 250GB/s from CPUs if you bring them all to bear, including the efficiency cores. This is still extremely good performance. reply majke 2 hours agorootparentI don't think single M1 cpu can do 100GB/s. This source says 68GB/s peak: https://www.anandtech.com/show/16252/mac-mini-apple-m1-teste... reply wizzard0 2 hours agorootparentbtw what's about as important is that in practice you don't need to write super clever code to do that, these 68GB/s are easy to reach with textbook code without any cleverness reply jeffbee 2 hours agorootparentprevThat's the plain M1. The Max can do a bit more. Same site since you favor it: https://www.anandtech.com/show/17024/apple-m1-max-performanc... reply Agingcoder 12 hours agoprevProper thread placement and numa handling does have a massive impact on modern amd cpus - significantly more so than on Xeon systems. This might be anecdotal, but I’ve seen performance improve by 50% on some real world workloads. reply bob1029 3 hours agoparentNUMA feels like a really big deal on AMD now. I recently refactored an evolutionary algorithm from Parallel.ForEach over one gigantic population to an isolated population+simulation per thread. The difference is so dramatic (100x+) that loss of large scale population dynamics seems to be more than offset by the # of iterations you can achieve per unit time. Communicating information between threads of execution should be assumed to be growing more expensive (in terms of latency) as we head further in this direction. More threads is usually not the answer for most applications. Instead, we need to back up and review just how fast one thread can be when the dependent data is in the right place at the right time. reply Agingcoder 45 minutes agorootparentYes - I almost view the server as a small cluster in a box, and an internal network with the associated performance impact when you start going out of box reply bobmcnamara 3 hours agorootparentprevIs cross thread latency more expensive in time, or more expensive relative to things like local core throughput? reply bob1029 2 hours agorootparentTime and throughput are inseparable quantities. I would interpret \"local core throughput\" as being the subclass of timing concerns wherein everything happens in a smaller physical space. I think a different way to restate the question would be: What are the categories of problems for which the time it takes to communicate cross-thread more than compensates for the loss of cache locality? How often does it make sense to run each thread ~100x slower so that we can leverage some aggregate state? The only headline use cases I can come up with for using more thanof threads is hosting VMs in the cloud and running simulations/rendering in an embarrassingly parallel manner. I don't think gaming benefits much beyond a certain point - humans have their own timing issues. Hosting a web app and ferrying the user's state between 10 different physical cores under an async call stack is likely not the most ideal use of the computational resources, and this scenario will further worsen as inter-thread latency increases. reply hobs 5 hours agoparentprevWhen I was caring more about hardware configuration on databases in big virtual machine hosts not configuring NUMA was an absolute performance killer, more than 50% performance on almost any hardware because as soon as you left the socket the interconnect suuuuucked. reply cebert 19 hours agoprevGeorge’s detailed analysis always impresses me. I’m amazed with his attention to detail. reply geerlingguy 17 hours agoparentIt's like Anandtech of old, though the articles usually lag product launches a little further. Probably due to lack of resources (in comparison to Anandtech at its height). I feel like I've learned a bit after every deep dive. reply ip26 2 hours agorootparentHe goes far deeper than I remember Anandtech going. reply AbuAssar 14 hours agoprev [–] Great deep dive into AMD's Infinity Fabric! The balance between bandwidth, latency, and clock speeds shows both clever engineering and limits under pressure. Makes me wonder how these trade-offs will evolve in future designs. Thoughts? reply Cumpiler69 8 hours agoparent [–] IMHO these internal and external high speed interconnects will be more and more important in the future, as More's law is dying, GHz aren't increasing, and newer FAB nodes are becoming monstrously expensive, so connecting cheaper made dies together is the only way to scale compute performance for consumer applications where cost matters. Apple did the same on the high end M chips. The only challenge is SW also needs to be rewritten to use these new architectures efficiently otherwise we see performance decreases instand of increases. reply sylware 6 hours agorootparent [–] You would need fine-grained hardware configuration from the software based on that very software semantics and task. If ever possible in a shared hardware environment. Video game consoles with shared GPU(for 3D) and CPU had to chose: favor the GPU with high bandwidth and high latency, or the CPU with low lantency with lower bandwidth. Since a video game console is mostly GPU, they went for the GDDR, namely high bandwidth with high latency. On linux, you have the alsa-lib which does handle sharing the audio device among the various applications. They had to choose a reasonable default hardware configuration for all: it is currently stereo 48kHz, and it is moving to the 'maximum number of channels' at a maximum of 48kHz with left and right channels. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AMD's Infinity Fabric, part of the Zen architecture, connects CPU cores and manages memory latency, with Zen 5 showing improved bandwidth handling due to faster DDR5 and better traffic management.",
      "Zen 2 provides insights into Core Complex (CCX) and Core Complex Die (CCD) bottlenecks, though it's an older architecture.",
      "While typical applications like games don't stress bandwidth, demanding workloads like RawTherapee can reveal latency management strengths and limitations, particularly in Zen 4 under heavy load."
    ],
    "commentSummary": [
      "The discussion centers on AMD's Infinity Fabric and the constraints of memory bandwidth, with comparisons to Apple's Silicon capabilities.",
      "Users debate the feasibility of claims like Apple's M1 Max achieving 400GB/s bandwidth, noting differences in core utilization between AMD's Zen 3 and Apple's architecture.",
      "The conversation also highlights the significance of Non-Uniform Memory Access (NUMA) configuration and the complexities of optimizing software for emerging CPU architectures."
    ],
    "points": 210,
    "commentCount": 22,
    "retryCount": 0,
    "time": 1732480741
  },
  {
    "id": 42230384,
    "title": "SQLite: Outlandish Recursive Query Examples",
    "originLink": "https://www.sqlite.org/lang_with.html#outlandish_recursive_query_examples",
    "originBody": "Small. Fast. Reliable. Choose any three. Home Menu About Documentation Download License Support Purchase Search About Documentation Download Support Purchase Search Documentation Search Changelog The WITH Clause Table Of Contents 1. Overview with-clause: hide WITH RECURSIVE cte-table-name AS NOT MATERIALIZED ( select-stmt ) MATERIALIZED , cte-table-name: show select-stmt: show Common Table Expressions or CTEs act like temporary views that exist only for the duration of a single SQL statement. There are two kinds of common table expressions: \"ordinary\" and \"recursive\". Ordinary common table expressions are helpful for making queries easier to understand by factoring subqueries out of the main SQL statement. Recursive common table expressions provide the ability to do hierarchical or recursive queries of trees and graphs, a capability that is not otherwise available in the SQL language. All common table expressions (ordinary and recursive) are created by prepending a WITH clause in front of a SELECT, INSERT, DELETE, or UPDATE statement. A single WITH clause can specify one or more common table expressions, some of which are ordinary and some of which are recursive. 2. Ordinary Common Table Expressions An ordinary common table expression works as if it were a view that exists for the duration of a single statement. Ordinary common table expressions are useful for factoring out subqueries and making the overall SQL statement easier to read and understand. A WITH clause can contain ordinary common table expressions even if it includes the RECURSIVE keyword. The use of RECURSIVE does not force common table expressions to be recursive. 3. Recursive Common Table Expressions A recursive common table expression can be used to write a query that walks a tree or graph. A recursive common table expression has the same basic syntax as an ordinary common table expression, but with the following additional attributes: The \"select-stmt\" must be a compound select. That is to say, the CTE body must be two or more individual SELECT statements separated by compound operators like UNION, UNION ALL, INTERSECT, or EXCEPT. One or more of the individual SELECT statements that make up the compound must be \"recursive\". A SELECT statement is recursive if its FROM clause contains exactly one reference to the CTE table (the table named on the left-hand side of the AS clause). One or more of the SELECT statements in the compound must be non-recursive. All non-recursive SELECT statements must occur before any recursive SELECT statements. The recursive SELECT statements must be separated from the non-recursive SELECT statements and from each other by the UNION or UNION ALL operators. If there are two or more recursive SELECT statements, they all must be separated from each other using the same operator that separates the first recursive SELECT from the last non-recursive SELECT statement. Recursive SELECT statements may not use aggregate functions or window functions. To put it another way, a recursive common table expression must look something like the following: recursive-cte: hide cte-table-name AS ( initial-select UNION ALL recursive-select ) UNION cte-table-name: show In the diagram above, initial-select means one or more non-recursive SELECT statements and recursive-select means one or more recursive SELECT statements. The most common case is for there to be exactly one initial-select and exactly one recursive-select but more than one of each is allowed. Call the table named by the cte-table-name in a recursive common table expression the \"recursive table\". In the recursive-cte bubble diagram above, the recursive table must appear exactly once in the FROM clause of each top-level SELECT statement in the recursive-select and must not appear anywhere else in either the initial-select or the recursive-select, including subqueries. The initial-select may be a compound select, but it may not include an ORDER BY, LIMIT, or OFFSET. The recursive-select may also be a compound select with the restriction that all elements of that compound must be separated by the same UNION or UNION ALL operator that separates initial-select from recursive-select. The recursive-select is allowed to include an ORDER BY, LIMIT, and/or OFFSET but may not use aggregate functions or window functions. The ability for the recursive-select to be a compound was added in version 3.34.0 (2020-12-01). In earlier versions of SQLite, the recursive-select could only be a single simple SELECT statement. The basic algorithm for computing the content of the recursive table is as follows: Run the initial-select and add the results to a queue. While the queue is not empty: Extract a single row from the queue. Insert that single row into the recursive table Pretend that the single row just extracted is the only row in the recursive table and run the recursive-select, adding all results to the queue. The basic procedure above may modified by the following additional rules: If a UNION operator connects the initial-select with the recursive-select, then only add rows to the queue if no identical row has been previously added to the queue. Repeated rows are discarded before being added to the queue even if the repeated rows have already been extracted from the queue by the recursion step. If the operator is UNION ALL, then all rows generated by both the initial-select and the recursive-select are always added to the queue even if they are repeats. When determining if a row is repeated, NULL values compare equal to one another and not equal to any other value. The LIMIT clause, if present, determines the maximum number of rows that will ever be added to the recursive table in step 2b. Once the limit is reached, the recursion stops. A limit of zero means that no rows are ever added to the recursive table, and a negative limit means an unlimited number of rows may be added to the recursive table. The OFFSET clause, if it is present and has a positive value N, prevents the first N rows from being added to the recursive table. The first N rows are still processed by the recursive-select — they just are not added to the recursive table. Rows are not counted toward fulfilling the LIMIT until all OFFSET rows have been skipped. If an ORDER BY clause is present, it determines the order in which rows are extracted from the queue in step 2a. If there is no ORDER BY clause, then the order in which rows are extracted is undefined. (In the current implementation, the queue becomes a FIFO if the ORDER BY clause is omitted, but applications should not depend on that fact since it might change.) 3.1. Recursive Query Examples The following query returns all integers between 1 and 1000000: WITH RECURSIVE cnt(x) AS (VALUES(1) UNION ALL SELECT x+1 FROM cnt WHERE x0 AND NOT EXISTS ( SELECT 1 FROM digits AS lp WHERE z.z = substr(s, ((ind-1)/9)*9 + lp, 1) OR z.z = substr(s, ((ind-1)%9) + (lp-1)*9 + 1, 1) OR z.z = substr(s, (((ind-1)/3) % 3) * 3 + ((ind-1)/27) * 27 + lp + ((lp-1) / 3) * 6, 1) ) ) SELECT s FROM x WHERE ind=0; The \"input\" CTE defines the input puzzle. The \"digits\" CTE defines a table that holds all digits between 1 and 9. The work of solving the puzzle is undertaken by the \"x\" CTE. An entry in x(s,ind) means that the 81-character string \"s\" is a valid sudoku puzzle (it has no conflicts) and that the first unknown character is at position \"ind\", or ind==0 if all character positions are filled in. The goal, then, is to compute entries for \"x\" with an \"ind\" of 0. The solver works by adding new entries to the \"x\" recursive table. Given prior entries, the recursive-select tries to fill in a single new position with all values between 1 and 9 that actually work in that position. The complicated \"NOT EXISTS\" subquery is the magic that figures out whether or not each candidate \"s\" string is a valid sudoku puzzle or not. The final answer is found by looking for a string with ind==0. If the original sudoku problem did not have a unique solution, then the query will return all possible solutions. If the original problem was unsolvable, then no rows will be returned. In this case, the unique answer is: 534678912672195348198342567859761423426853791713924856961537284287419635345286179 The solution was computed in less than 300 milliseconds on a modern workstation. 4. Materialization Hints The \"AS MATERIALIZED\" and \"AS NOT MATERIALIZED\" forms of a common table expression are non-standard SQL syntax copied from PostgreSQL. Using MATERIALIZED or NOT MATERIALIZED after the AS keyword provides non-binding hints to the query planner about how the CTE should be implemented. If the MATERIALIZED phrase is used, then select-stmt will be materialized into an ephemeral table that is held in memory or in a temporary disk file. That ephemeral table will then be used in place of the CTE table name whenever the CTE table name appears in the subsequent SQL. Because the select-stmt is evaluated immediately, the opportunity to apply optimizations such as query flattening or the push-down optimization, is lost. This loss of optimization is a feature, not a bug. Developers are able to use the MATERIALIZED keyword as an \"optimization fence\" to more tightly control the behavior of the SQLite query planner. SQLite copied the idea of using MATERIALIZED as an optimization fence from PostgreSQL. If the NOT MATERIALIZED phrase is used, then select-stmt is substituted as a subquery in place of every occurrence of the CTE table name. Optimizations such as flattening and push-down are then applied to the subquery as if the subquery had by used in directly. In spite of its name, the NOT MATERIALIZED phrase does not prohibit the use of materialization. The query planner is still free to implement the subquery using materialization if it feels that is the best solution. The true meaning of NOT MATERIALIZED is closer to \"TREAT LIKE ANY ORDINARY VIEW OR SUBQUERY\". If neither hint is present, then SQLite is free to choose whatever implementation strategy it thinks will work best. This is the recommended approach. Do not use the MATERIALIZED or NOT MATERIALIZED keywords on a common table expression unless you have a compelling reason to do so. The MATERIALIZED and NOT MATERIALIZED hints are only available in SQLite version 3.35.0 (2021-03-12) and later. 5. Limitations And Caveats The WITH clause cannot be used within a CREATE TRIGGER. The WITH clause must appear at the beginning of a top-level SELECT statement or at the beginning of a subquery. The WITH clause cannot be prepended to the second or subsequent SELECT statement of a compound select. The SQL:1999 spec requires that the RECURSIVE keyword follow WITH in any WITH clause that includes a recursive common table expression. However, for compatibility with SqlServer and Oracle, SQLite does not enforce this rule. This page last modified on 2024-01-29 11:00:27 UTC",
    "commentLink": "https://news.ycombinator.com/item?id=42230384",
    "commentBody": "SQLite: Outlandish Recursive Query Examples (sqlite.org)193 points by Rendello 22 hours agohidepastfavorite51 comments jitl 19 hours agoNo matter how much time I spend contemplating recursive CTE examples, I just cannot “get it” enough to write my own without a lot of trial and error and head-scratching. I would love to take a 2 hour class on “thinking in SQL for hackers” or something, but I haven’t really found anything to improve my mental model from “broken” to “working” so far. reply CGamesPlay 18 hours agoparentA prerequisite to understanding is knowing the CTE syntax (\"WITH\"). That's just a group of SQL queries that can refer to one another. It's extremely useful for making modular SQL queries and has nothing to do with recursion. Then when you use \"WITH RECURSIVE\", the queries can now refer back to themselves. This is just a for loop over a queue of SQL results, conceptually. The part before the UNION ALL fills the queue to start, and the part after the UNION ALL runs once for each result in the queue, adding all results back into the queue. If you understand this, then you can understand the Sudoku or Mandelbrot examples (definitely don't start with trying to understand these two though). For example, the Sudoku example contains one recursive query, \"x(s, ind)\". As explained on the page, \"s\" is the puzzle (unsolved spaces shown as \".\") and \"ind\" is the index of the first unsolved space (or 0 for a solved puzzle). It creates an unsolved puzzle in the initial setup. The for loop body finds all valid values for the first unsolved space, and the next index to solve; then puts all these results into the queue. The final (non-recursive) SELECT in the CTE looks over all results in the queue, and returns the one where the index is 0 (the solved puzzles). reply cryptonector 14 hours agoparentprevSQL recursive queries are just loops. The CTE is a UNION or UNION ALL query (well, never use UNION ALL unless you really want to loop infinitely!) where one side is the query that seeds the CTE and the other is executed and its outputs added to the CTE, and the last part is repeated until the CTE stops growing. There's just one more detail: the \"recursive\" side of the UNION query needs to do a JOIN to the CTE itself (thus the \"recursion\"), but this doesn't change the loop nature of the thing. That's it. It's just a simple loop. (Yes, recursion is looping. But in this case it's very clear that a stack is not needed, that the recursion is \"tail recursion\" if know what that is.) The hard part lies in getting the JOIN in the \"recursive\" side of the UNION query right. Here's a transitive closure query: WITH RECURSIVE closure AS ( SELECT parent, child FROM relationships UNION SELECT c.parent AS ancestor, r.child AS descendant FROM closure c JOIN relationships r ON c.child = r.parent ) SELECT * FROM closure; Here `SELECT parent, child FROM relationships` is the seed, and the rest (`SELECT c.parent, r.child ...`) is the recursive part of the query that gets repeated until the whole set of results from the seed and all the repetitions of the recursive part stops growing. The recursive part simply says to add to the `closure` all the children of children of tuples in the closure, but with the parents from the closure as the parents. So if this were human parent/child relationships then initially you might have your parents' relationships to you, and also yours to your children, and this will find that your parents are ancestors to your children. reply CGamesPlay 14 hours agorootparent> However, if the example had used UNION instead of UNION ALL, then SQLite would have had to keep around all previously generated content in order to check for duplicates. For this reason, programmers should strive to use UNION ALL instead of UNION when feasible. reply cryptonector 13 hours agorootparentOf course, if you have loop detection in your business logic when writing to the database, then you can safely use UNION ALL always. EDIT: Removed a bunch of stuff that was partly based on a faulty memory of how UNION works vs UNION ALL. Indeed, UNION ALL means the RDBMS does not need to keep around the whole result set. reply CGamesPlay 12 hours agorootparentJust to be clear, the reason I mentioned this in response to your original post is that UNION ALL doesn't have anything to do with the query recursing infinitely: it just allows the database engine to not keep previous results around. If you have a query that recurses infinitely, with UNION it will definitely exhaust the memory of the database engine, and with UNION ALL it will never stop returning results, which may exhaust the memory of the database client (unless it discards the results). reply remram 18 hours agoparentprevAn crucial point for me was realizing that \"recursive CTEs\" are not really recursive but better understood as iterative, in other words a loop. The results of each iteration are fed into the next iteration, until no new result is produced. reply eru 13 hours agorootparentYes, iteration is a special case of recursion. reply cryptonector 12 hours agorootparentAll recursion is iteration. Sometimes you have a stack to help you, and other times you get tail recursion optimization, but it's always a loop. reply eru 11 hours agorootparentWhat makes you think so? Please have a look at the formal definition of regular expressions at https://en.wikipedia.org/wiki/Regular_expression#Formal_defi... on Wikipedia, and let me know where the stack and the iterations are. I can't find them. https://en.wikipedia.org/wiki/Recursive_definition#Well_form... is also a good example. Regular expressions are a particularly interesting example because you brought up 'loops', so I'm assuming you are interested in how you can implement some of these recursive definitions on a computer. So for regular expressions a common technique is to compile them to a finite state machine. You can model that in your computer as one block of eg assembly instruction per machine state. To move to a different state, you just 'jmp' to the corresponding code's address. That's pretty fun to work out, but I still don't see anything I would describe as a 'loop' here; but the recursive analysis still makes perfect sense. Yes, some programming languages have special purpose looping constructs. But they are of limited usefulness, and not particularly fundamental: they usually get compiled away. reply vincnetas 8 hours agorootparentprevall iterations are recursion but not the other way around. reply cryptonector 2 hours agorootparentWhen you add an explicit stack to help you keep state then you can have recursion be the same as iteration. Normally the stack you get in recursion is implicit rather than explicit. reply fifilura 13 hours agorootparentprevIsn't recursion exactly that? A loop that feeds into the next iteration. reply Shraal 8 hours agorootparentIt's important to differentiate between tail-recursive functions and non-tail-recursive functions. Compilers will often convert tail-recursive functions into their iterative counterparts. See: https://en.wikipedia.org/wiki/Tail_call In contrast, non-tail-recursive functions will make the call stack grow with each call. reply cryptonector 12 hours agoparentprevI highly recommend the O'Reilly SQL Pocket Guide (https://www.oreilly.com/library/view/sql-pocket-guide/978149...). Its explanation of CTEs is fantastic, and it does a great job on many other parts of SQL, and it's a short and sweet book you could read in a few hours. And it will server as a reference long after you first absorb it. reply danielheath 18 hours agoparentprev“Thinking in sql” is hard because it’s an awkward syntax for the (much simpler) relational algebra. Learn to think in terms of the relational algebra, and how to translate that to/from SQL, and it starts making sense. reply jitl 15 hours agorootparentI can express my ideas well enough in various Datalog/Prolog variants w/ the horn syntax. But when it comes to translating that from several discrete simple propositions into one massive CTE-stack SQL query I get very puzzled. I wrote a toy Datalog-to-SQLite compiler (https://percival.jake.tl) but I struggle to grasp the translation skill myself reply refset 6 hours agorootparentIt doesn't help that SQL's recursive CTE model is a bit odd - Frank McSherry proposed a much nicer alternative (which Materialize has implemented): https://materialize.com/blog/recursion-in-materialize/ reply cryptonector 12 hours agorootparentprevI don't find that the syntax gets in the way of thinking in relational algebra, but I did learn SQL first. reply pawelduda 18 hours agoparentprevIt's unusual and not a commonly needed tool in SQL. I always need a quick refresher on how to write these after a longer break reply DemocracyFTW2 9 hours agorootparentNot commonly needed presumably only because we've grown up to understand that SQL is not a language where you can easily express rescursively hierarchical relationships, such as the in the go-to example where you have a table of employees with a 'reports-to' field. In classical SQL there was no way to write a simple query that will resolve 'who is reporting to who' recursively with an arbitrary depth. Recursive CTEs can do that. reply tlarkworthy 13 hours agoparentprevSome things that helped me Every query response in SQL is a rectangular matrix [1]. JOINs add columns sideways. UNIONs add rows vertically[2]. [1] Which is why tree shaped data is awkward to query in SQL in one round-trip. [2] From this you realize why the column names have to match to apply a UNION, and why recursion is something to do with a UNION. reply fifilura 11 hours agorootparentAnd if you get stuck, since it is all about rows and columns, just sketch it out in Excel. Not using formulas in Excel but just using it as a rows/columns editor. This makes it visually clearer. reply hansvm 17 hours agoparentprevFor \"ordinary\" working programmers (some denominator of reasonably common knowledge across the industry without any specific skills that help with CTEs in particular), there are a couple mental models I find helpful: 1. Recursion and iteration are duals of each other. Anywhere a \"recursive\" CTE is a good tool for the job, there exists a natural for-loop or while-loop you would write in an ordinary programming language to solve the same job. Figure out what that looks like, and then you can translate it to SQL. Optimizing further often isn't necessary. The general form isn't terrible (ellipses hide the extra columns you'd have to manually include in most SQL dialects): WITH RECURSIVE t(n, ...) AS ( SELECT 1 as n, * from base_case UNION ALL SELECT n+1, f(...) FROM t WHERE not_terminated(n, ...) ) SELECT something_interesting(...) FROM t 1 (continued). You can explicitly encode for-loops and while-loops, doing all the normal sorts of things an ordinary programming language allows. SQL is just a different language representing all the things you already know how to do; don't make it complicated until performance becomes a problem. 2. There exists a concept of \"equality saturation\" that's exceptionally powerful in a number of domains. Everything in (1) is familiar to an ordinary working programmer, but the database's mental model of a recursive CTE is while (not_done(working_set)) { working_set.extend(process(working_set)); } 2 (continued 0). One model of solving a sudoku puzzle is an iterative/recursive branch-and-bound algorithm (try a reasonable thing, expand all the easily learnable knowledge, exit if impossible or if done (recursing at each level), go to the next reasonable thing). One \"equality saturation\" version of that solution is (plus a stopping condition somewhere): 2a. For each partial potential solution 2b. For all the ways in which the potential solution is viable 2c. Expand into all those new potentialities 2 (continued 1). That ability to describe a monotonically increasing set of things which finitely approaches a boundary is powerful in math, powerful in search, powerful in optimization (the Rust EGG crate (e-graphs good) has reasonable documentation for one particular concrete way in which that idea could manifest, if such concreteness helps you learn -- whether you know/like Rust or not), and so on. Gradient descent is just expanding your information till you don't have much more to learn. Optimizing a program is just expanding the set of optimization-based re-writes till you don't have any more re-writes (and pick the best one). Parsing a document is just adding to the things you know about it till no parsing rules can glean any more information. Since that thinking modality is how the database treats your query, you'll usually have better optimized queries if you can naturally formulate your problem in that language (as opposed to the naive iterative solution I proposed in (1)). Not all problems can be thus phrased, but if you're doing a lot of work in your database with recursive CTEs, it's a good idea to spend a week or three hammering home. 3. Combining (1) and (2) a bit, your database will usually have a cost somewhere around O(all_the_rows_you_produce) when evaluating recursive CTEs. These tasks only get hard when performance is a problem and you have to figure out how to take the naive ideas from (1) and transform them into the expected model of (2) in a way that actually reduces unnecessary work. For the sudoku example, you can do that by adding a bit more internal state to transform the breadth-first-search I described into a depth-first-search (making the solution _more_ iterative, interestingly; the \"natural\" solution is very slow comparatively), but in general you might have to get very creative or might not actually have a reasonable solution available. reply daelon 19 hours agoparentprevI would also love to take that class! reply nbbaier 19 hours agoparentprevSign me up for this class too! reply hobs 18 hours agoparentprevIt's just going to be practice, recursion in general is annoying to think about. Start simple, have a loop you want to write instead of a recursive thing, write it step by step instead of trying to do it all at once. I was implementing newton raphson a few years ago in SQL (so as not to implement it as a straight loop) and iterating over the problem several times really helped. Get a query. Now think of the next step in the iteration, and you're basically writing a query that connects to that. And now, it runs again and again based on the previous criteria. If you can isolate each part of the query for each logical step you're going to have a much simpler problem to mentally solve. reply gzel 47 minutes agoprevI really like the way of how feldera implemented recursion in SQL: https://docs.feldera.com/sql/recursion All you have to do is to add a forward declaration of the view and then you can reference it in a recursive query. Makes the syntax part much easier. reply hans_castorp 7 hours agoprevWith Postgres you can also generate fireworks http://explainextended.com/2009/12/31/happy-new-year/ or snowflakes: http://explainextended.com/2011/12/31/happy-new-year-3/ Or you can solve a Sudoku riddle in Oracle https://technology.amis.nl/2009/10/13/oracle-rdbms-11gr2-sol... reply mike_hearn 6 hours agoparentIntriguing. The Sudoku puzzle in your last Oracle link from 2009 is exactly the same puzzle used in the SQLite example, doing the same thing. reply magicalhippo 19 hours agoprevI've mostly kept the usage to \"sane\" stuff like turning delimiter-separated text into rows, or walking a graph. As much as I enjoy the Mandelbrot set, I bought the Fractint book as a kid, anyone done any outlandish but useful recursive queries? PS: awesome explanation of how exactly the recursive query works. Wish I had read it when I first needed it in some other DB which help did not have such a clear explanation. Tore out a lot of hair before I got it working right. reply airstrike 17 hours agoparent12 years ago I wrote a recursive CTE which aggregated a bunch of accounting journal entries from pretty big SAP extracts with intermediate account also needing to be calculated in a way that rolled up to company-level values, with some tagging/indexing in the process. I remember only being able to finish the query after some kind anon helped me in an IRC channel at 4am on a weeknight... to this day I'm immensely grateful to them I made it into a neat little Django portal with configurable permissions, interactive charts for the data, filtering, etc. It became a ~10-min async celery task running in the background from what previously used to take the company weeks to create that report in an error prone way with macros written by someone long gone / in another department. I'm still pretty proud of that app even though it never got implemented. I got promoted, moved to a different department and don't think it ever saw the light of day, but I do have the code laying around somewhere reply JaggerFoo 16 hours agoparentprevYears ago I came across a Knapsack problem solution written in Oracle SQL, that I adapted to Daily Fantasy Golf. Here's the source: https://aprogrammerwrites.eu/?p=878 Cheers reply hobs 18 hours agoparentprevLast time it was useful I re-implemented XIRR(https://support.microsoft.com/en-us/office/xirr-function-de1...) using Excel's approach in pure SQL so it would be able to make the finance bros happy, it was something like 50,000x faster than the user defined function/loop approach. reply dspillett 18 hours agoprevThe Mandelbrot example had been around in various forms for quite some time, IIRC I first saw it in ~2006 for SQL Server which gained recursive CTE support in its 2005 release. Another example from around that time was using recursive CTEs to define dragon curves using spatial types that would then be drawn using SSMS's support for displaying data in those types. reply rkwz 18 hours agoprevNot SQLite, but recently used Postgres Recursive CTEs for graph retrieval - https://www.sheshbabu.com/posts/graph-retrieval-using-postgr... reply simonw 13 hours agoprevI thought this might be a relatively new example - I remember having seen the fractal one but I didn't recall the Sudoku one. Turns out both of those examples have been in that documentation for over a decade now! https://web.archive.org/web/20140331191105/http://sqlite.org... reply jschrf 17 hours agoprevCTEs are extremely useful mechanisms for writing modular and easily maintainable queries, particularly around anything to do with ETL, graphs, and timeseries data. Highly recommend. reply firer 12 hours agoprevI love this stuff. If anybody wants another outlandish example here is an emulator I built: https://github.com/DanielFi/sqlite-vm/blob/main/emulator.sql reply owlninja 15 hours agoprevI often have to generate ad-hoc recursive queries for bills of materials. Any one have good ideas to make something more self serve for end users? I guess just some sort of app where the user supplies the top level part works, but I wonder if it should be pre-exploded? Often I am given a list of many parts to explode. reply cryptonector 13 hours agoparent\"Something more self-serve\" is essentially what graph databases provide. If you don't have the time to use one of those or build your own (and you probably shouldn't) sort of thing on top of SQL, then you can instead define a bunch of VIEWs using recursive queries and GROUP BY and aggregation functions to provide something simple for your users to query. If you do want to build something more general purpose... If you begin by modeling your schema in something other than SQL DDLs (like with an AST) and then model FKs as bi-directional relationships (because they are), and if you add a way to group those relationships, and further provide a way to define a subset of like columns from all the tables in a graph defined by a group of those relationships, then suddenly you can also come up with a simple(ish) language for expressing [sub-]graphs that you want to fetch. And there's your ad-hoc query language for dealing with recursive graphs in your relational data. reply clumsysmurf 19 hours agoprevJust curios: can CTE's be used to make time series range queries easier / more performant? Sqlite is the default option on Android and it's pretty common to have time series sensor data that needs to be captured, stored, and analyzed... But sqlite isn't really meant for a time series workload. There is also duckdb but I'm not sure about the status of the Android bindings. reply dspillett 18 hours agoparent> can CTE's be used to make time series range queries easier / more performant? On their own, I'd guess likely not a lot. If a view would help, a CTE will help similarly without needing the external structure, if a correlated subquery would help, then yes similarly, especially if the pattern is repeated in the overall query. In conjunction with other things (good indexing, materialised sequences (\"numbers\" tables), etc.), is guess yes. Though you need to be much more specific about your data and the queries in question before I can do better than these vague guesses. reply remram 18 hours agoparentprevNo. They are a query syntax, they don't change the storage or retrieval performance. reply jitl 19 hours agoparentprevnothing really helps with potato slow Android device / storage media. CTE is not magic sauce that will make sqlite go faster. Depending on the recursion pattern and the overhead of your sqlite driver, it can be faster to do many ID lookups then try to cram it all into one mega CTE query. https://www.sqlite.org/np1queryprob.html source: we have the CTE for loading page data in the notion Android app, and the network regularly beats disk on lower end Android devices using whichever query we pick. reply westurner 19 hours agoprevFirefox bookmarks have nested folders in an arbitrary depth tree, so a recursive CTE might be faster; https://www.google.com/search?q=Firefox+bookmarks+%22CTE%22 (Edit) \"Bug 1452376 - Replace GetDescendantFolders with a recursive subquery\" https://hg.mozilla.org/integration/autoland/rev/827cc04dacce \"Recursive Queries Using Common Table Expressions\" https://gist.github.com/jbrown123/b65004fd4e8327748b650c7738... reply leeoniya 17 hours agoparentstoring the tree as an MPTT/NestedSet would massively simplify this, without any subquery shenanigans. https://en.m.wikipedia.org/wiki/Nested_set_model https://imrannazar.com/articles/modified-preorder-tree-trave... reply jitl 15 hours agorootparentWell the read query has simpler syntax with MPTT but implementing the whole structure is more complicated and any re-organization like moving a folder around requires rewriting a lot of rows. Although it doesn’t apply to the Firefox use-case, I’ve never understood how this technique can be applied to anything but the most trivially sized, roughly immutable trees. What do you do in a production system when two people move two different node in the tree? It seems to need all kinds of complicated locks. reply westurner 2 hours agorootparentprevThere are at least five ways to store a tree in PostgreSQL, for example: adjacency list, nested sets like MPTT Modified Preorder Tree Traversal, nested intervals, Materialized Paths, ltree, JSON E.g. django-mptt : https://github.com/django-mptt/django-mptt/blob/main/mptt/mo... : indexed_attrs = (mptt_meta.tree_id_attr,) field_names = ( mptt_meta.left_attr, mptt_meta.right_attr, mptt_meta.tree_id_attr, mptt_meta.level_attr, ) Nested set model: https://en.wikipedia.org/wiki/Nested_set_model : > The nested interval model stores the position of the nodes as rational numbers expressed as quotients (n/d). reply otteromkram 17 hours agoprev [–] The SQL formatting on this website is atrocious. I can't find a good reason not to left-align everything vs trying to right-align keywords and keep everything else on one line until the next keyword. reply thissuchness 12 hours agoparent [–] Can you give an example of a query you find offensive, and how you'd format it better? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Common Table Expressions (CTEs) in SQL serve as temporary views for a single statement, with two types: ordinary and recursive, simplifying complex queries and handling hierarchical data, respectively.",
      "CTEs are created using a WITH clause and can include multiple CTEs in a single statement, with recursive CTEs requiring specific rules like using UNION or UNION ALL operators.",
      "Materialization hints, available in SQLite version 3.35.0 and later, guide the query planner on CTE implementation, with limitations such as the inability to use WITH in CREATE TRIGGER."
    ],
    "commentSummary": [
      "SQLite's recursive Common Table Expressions (CTEs) function like loops, allowing queries to reference themselves, which is useful for complex tasks such as solving Sudoku puzzles or calculating transitive closures.",
      "Mastery of the syntax, particularly \"WITH\" and \"WITH RECURSIVE,\" is essential for effectively utilizing recursive CTEs, which operate by seeding a query and executing recursively until no new results are generated.",
      "For those finding recursive CTEs challenging, resources like the O'Reilly SQL Pocket Guide and a solid understanding of relational algebra can be beneficial in simplifying complex SQL queries."
    ],
    "points": 193,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1732480962
  },
  {
    "id": 42236841,
    "title": "Hey, wait – is employee performance Gaussian distributed?",
    "originLink": "https://timdellinger.substack.com/p/hey-wait-is-employee-performance",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"timdellinger.substack.com\",cType: 'non-interactive',cRay: '8e83e4936b4d10d1',cH: 'ADm5.DDhhoY_9e.pX29RaygcVx2bHlNRZThDhJNz_rQ-1732561344-1.2.1.1-NkAuU57trYCqGMVpmxeDowOAGHA5fT0KLi1X2baulGNAWWzFsmQLrsMAYpoDxAUY',cUPMDTk: \"\\/p\\/hey-wait-is-employee-performance?__cf_chl_tk=8aRV7T0A8XZ7I6fbXtUanTyuXms448HHkZZP3O0P1Hk-1732561344-1.0.1.1-UdSq7R4hhexu92vSAtuOdfHu9ZrfKnQkAB8N8M6pznk\",cFPWv: 'g',cITimeS: '1732561344',cTTimeMs: '1000',cMTimeMs: '120000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/hey-wait-is-employee-performance?__cf_chl_f_tk=8aRV7T0A8XZ7I6fbXtUanTyuXms448HHkZZP3O0P1Hk-1732561344-1.0.1.1-UdSq7R4hhexu92vSAtuOdfHu9ZrfKnQkAB8N8M6pznk\",md: \"uGInMUJtKWVDHdlRrezSUZ1PTUoH_fmzG9EFu4AILKU-1732561344-1.2.1.1-q4QyXy_GnWCIkkqRogo1ITRRS2fH8wrr81o9gS5mBPGELVfIQh3B5c42B96KgWVIes34MVRRkIFaNZaHXDFr1ilJ0afbzaso3JYmWlCKas2v.lcnfQbH9QVdN7ZSJBKVDrRjAwvCtYriLKhT79QwDCBIb0xqgiPSRi9furFJhv3o.ECIaNyaF6KgrVg1uHGoUFBFQOOkg4nPurgDbMAX4iZh7kULstN0yGVT0Nz21KC9eB.qybLOZLsh3sOfwtpCzww7fogLLoji3v7diNMT4MujewXgfhWqlwUvgAIH93oEIYAVSy6A6MyFCPOehcutK7Cfwp8S6FfSk9B3SC_BGuMzWOZK8p2JGe0kaxqTtsc_oqUlaVKUig6Z256F0tw1evhFXnWPjvKDEwUV7cZDXPGjlGQ3i.9O.WfV0aQ1zX2wk48DfDe.XcNrjaHkbfFgNSAtx6Sk0lMvQ3P54TDvtXgVmmMnoczpxHVFt79SVZZVuJjw97diFNCRlLhfkkFj._E95XWkKFwEAdJVUyJA5rdfh5rJcyFnGNGp8AMpS1n1CTluPw5IjA6DtSnvcrhcugy7cGp3R4qDBjIaKmNO9jd8d.Q1F3ylkAUSbeuMFquqV73a4JS6jOLOM00Lu5ftWZH_ECNlPTJVCi5NwsU8F1A3GPuQTzTOYKGEf_dg.TgNaeA_f9_N5KZBNR95kQmbOCa10HRC7jcpS.NPpy7d_WPPE5SaJejbdulFRYqP16CgqjarKOsnFBTFFY0NsQl_3E4inWopp_z1Fedq.bALwuWde_PHyY4im2C97_G.3795zwduFmsLZjD73lbP2ro4iybsPM6Eik7kkoL9NqKwFAELQmIvJXZnNUN5w1zgwpPxN7zgJwr_ScsY5mGQ8e10GEwQniAqcQNw1E3S1Z3NVk6d__LsVGGqhPbV1JbqrFlkc7lhLJpoBG8.gMpYs19UT9UN_bRW18rn5.BGDnheBLkY3XKTit3p74D1MOfvtDZ5_.Vk2ncFyIblcPyZsyt03eVdvwWUtnDuUTtzhGIfCwOzpO7JlwIXNOpc4ZxjcPdCUpEo_0ap0dTJZ7XxxMQwZLvy_7g.yKHBiSMs.Le8BJv94VUvhNmcA3V3UL.W2IXeh83XdCcCtwOxxid_AYa8DmX5fu__BXp2Xbx8JgkHXhPwyIxG8Jx3VVd0lxxVFiAU0j2v12KSnp1mfxfQAFU7UgToEO3wzJTXvGVLvockstodjO5nVU7vPZE2ftnX932yAgz_PMcccsEBk9ekPytrXJ93SDRvOJPw4xO63HepOVsuy_.AEB0J.kTfp3_WkyZM0wrzz27WPnlBNI2fQRNZbW1YVjGT3p5TYmnEInkmRbdjNWa.g02c_8NkMBl8.ByQTw4X2IM9Gzz1VQjfCspL1tPAYMLH9hkTje.QRI92xrohEuEAkh91XxerjRhnZbNSc2ib5ooFo8bPYXa_1YLeNDogSfR8URSiBPvSmWGhTAHG7_1DyXLZHEXkHtBd4KA6WzgY1ffP6ePUvvnEFbB0ErX7z72daA0Ob6L.QqF8tzrcTjVl4XdSyrPf8M.cXsPgqkgiJz_fvokNFEBEbbEZimGtJ7kF5PDRi11gzhYKeFpx0oIZE4Tue0EwEEFjqzMTC1utz2XADJleWnJDtTUo43ONb7kRQcT9Pt0HmBtTpeJNpjpoHu0pB9HpO4lD17ODkOJ_SlbcBQn6xoLUbLq8jiwiIXuHizx6gPMyKNbo_EvQN0di44Imz8Y5nS4.IhU7D5FrNAd85rbAxg_NKijfII4Cn.qn.04uYjJGx6MUv8bQlvXh7Kxj_5vdOkiPqvIkL0n69Qo.T_wHI2mIHERb7Z31e4IjF5dHKqVHnbL4U0aapDhDTy1WQgHvAfF9CYrNv_naXXYr1_nLvpgmnqoW\",mdrd: \"kiZsDOMJB5aoP43wqo.JT1PFMGJxXTbox9m1wOpk3w4-1732561344-1.2.1.1-wuuBKIk_TEI8PkkjfEYdHZze.p9bnNl6YLwLc.oUaE57zNm6rOoY_P.2SyEreeGVp2R52Zt50_D6mQWLx_JAvNQ7Jn6QfmC9v49jpRqTIpdvG69NCeKlI4H7qSZHzfVVQZXHBsoQOBECSyVPkBPHBMyM3GhH8PHnYpkaXiCvNwSilH1uoYJACiZOo3U9SOsqxxk1WHqUhvWLg4jGO738MBT0qCl50FkyWSIB2RarvY7aeSd7pCOAFE.N3DtlduTEtnswfV0RTKvHfifc1zphuA6vnfqKpQ5miMHDkdU4pVp5hiB42PTrbP838KU31qC731jO0kUSEPPhcNE.s6hgKO.bMStRk6YylLdfxGQYfqC8UmbLUqzLx3EaYiWUMfsiGaoa0TlZrmhixcFb7xQl.zxlMpwI_ZTDmaIhwTfUCiTyNla16RirXeLjlLd.tiboIBlI9Scivf_jujrXYftu3_F.KbOJq2ub9p_5DciKIetOTn6QAC3yaV7GZO7ftoSNXVq6nCrhvBGiAiOwYOKiEv85cwyFq.jWreyU7mDp6GCYwSz2Jq4vVKYyKYCHM98.TJpu23YVEN6jby48JHnDctqyH5kUpG_RzOCmyGkWKv_CqfXmI2lX8RgcMRohcd0A2bed0_JgzQpjPIQUKeVutQxXAxMB0nzEWTo140sc0XbmV90yLAR9YC49GJEXmVlc53TJZXmy_5deET0UMbKqPM_GtxnG23MiVRggVNzoXHtXo3VlYMEM5BEi7x5mnL8iD3WTrm8M_0NTapHEzGx1mL.FjW4vVzjgC.kSiDOhRvJ.z5w89fUyurY3FgKdM9nqM5z1LQ2veBunY9vU5XyObN4ZJvI35FmwKeq.bhlocPi4rQgiPiNguGCzZllwpDW0JXFFoc9hpU3yaIeCuAT5WHLNEEL3Gpcp1R4rXU9cZ.6TLU3tHLAV2qMWq4iJvD9wqHAFCBZ_wT0_vBSKeH4ysvEJFEjDzpUb1Ny.S31031emA_LnQ7F0gHprq8yFeVbT8gH0fXX24zXOBPk_5g.0Cf2e_EefhJRIDH5dwYtFm582_B3n89SMs_k12r_gqm1wJ6FigzumcghbUSq.8c4QQxLfcyoOq64mTG_gQCf_9I6HBRQIvNvuxQ.dkEclayXDkvEI4C9loZHOvP.QGb70t2F0pvcF.MGBqBwCf1UeuuQQZpRnEQtYsaLSYVKEmgjVXnyNhxxdWNPqRnWm6Ke9f6nzzw5Qg3wGnSWRLIn0myAoE61qjMZEUr771.xRrqa1NH0Dbke184fdG173ihJ7prUyDelkBALYg6GxeW9PulI_rE13hPp8QIHflN9frin.EjATqTTPkufJxHrguHqMzjk32BhC32eXzqkJCAz07M_D1js82rp2Zk8l7jMUZcJ0.ySU5WqEH6Sv5verAFojv8OLoaaQCeG6CXFTombgulOqr1SauffmEv0s4_eeGEatpPq53wPBzuoKUhdXiKnwJDYzOT4Na.L4O5GBc6_FdaaP5XNjTbCTGYfTcP0GfLCjYAsHYCQVibZu6Tp_rvpQcwl3lyl8D6pzhLgisOEoCNQu2kw5VDlQWYhfRsrlsxeL01M99e8HKCOwj_RCDciAXpSFtfnE1O_q23axGFOlSMqGSJu_20c8sSVoOAW.8QQwEUeDGzJzrwImBntUOjmRvvkVqSFuu6CM5e3XsTI0.NsFt39LNxjT6TFgBIbuvM7c.KSE8dCLKs593YhOy9EQQ.3fupW7e37cY2JOOhzEwgBkYcuImD6SaDfXi.XlRZQeqE3uNuM_IZxpM_cgb2XcIiIMs7_4I3V9McCvjQHY.D5Q0DCsASkxukJxz5evisIw2wyHcW.EkSGZ830suZ.1_MRBQW_lXIlQNWseR.E9Zof7wOFKcnDGIsMHzkrlYGUd7RkX1lznWilJRwU_DOfmH69WQC2JSBRpvOlxVm5lbXdwVn8aTAt1hDP7oPIe2C_wQy9B1J_qgf0jxCJ6.sde0XeNA6l8RXKlpPuw3GHYAix.omAbPKyYIMYssKZXt88ydWZJcRMvV0lhg5jXqJF9zIJU5j0wJbxk8tsNmUqTIBmwu840n183kfESaNCXVeOOq1ve.9B8haJXM3.giQFtWi5MtIeSgryQEOixHy7XLxlC4Fog7Pbs994GjlSftQtd4OaUdhWp2wPKKr.1L2TbPlgW_xwNg3H5qDa9VEZsoq0XV18miwDJuQDlCL1NhW8vNkM6mZk327jluwcGFavriQ0ADOr1OYvIu7z8e8G5I5uoffD.5YwrT7M6N9AletdqxSXz5e38NM0EchV2g4KFcFTN56RrLic6lVauROgOpINREDV9nPWjCd.2JxXjw.HEytyxvajMXu8xg3SvD.M068j_f0e.zPDNG5uamYcm65BWmigZl9.dMlS_.s.lUS7y\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8e83e4936b4d10d1';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/hey-wait-is-employee-performance?__cf_chl_rt_tk=8aRV7T0A8XZ7I6fbXtUanTyuXms448HHkZZP3O0P1Hk-1732561344-1.0.1.1-UdSq7R4hhexu92vSAtuOdfHu9ZrfKnQkAB8N8M6pznk\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42236841",
    "commentBody": "Hey, wait – is employee performance Gaussian distributed? (timdellinger.substack.com)180 points by timdellinger 3 hours agohidepastfavorite156 comments sangnoir 1 hour ago> Performance management, as practiced in many large corporations in 2024, is an outdated technology that is in need of an update Author made a couple of fundamental mistakes: the first is they assume employees are (or should be) paid according to how much they \"individually\" earned the company. Employers strive to pay employees the minimum they can bear, on employers terms. Those terms are information asymmetry and a Gaussian distribution. Fairness is the last thing one should expect from employers, but being honest about this is not good for morale, so instead, they rely on keeping employees uninformed, while the employers collude to gather everyone's remuneration history via the Work Number. The second mistake they made is assume that companies would prioritize being lean and trimming the mediocre & bottom 5%. There are other considerations, combined productivity is more important than having individual superstars working on the shiniest features. How much revenue do you think a janitor or café staffer generates? Close to zero. The same goes for engineering. Someone has to do the unglamorous staff, or you end up with a dysfunctional company, with amazing talent (on paper). Edit: there's an infamous graph that shows when aggregate worker productivity and average income. The two tracked closely, rising in tandem until the 1970s, where they got decoupled. With income becoming much flatter, and productivity continuing to rise. That's how the world has been for the past 50 years on the macro and the micro reply thrwaway1985882 23 minutes agoparent> The second mistake they made is assume that companies would prioritize being lean and trimming the mediocre & bottom 5%. There are other considerations, combined productivity is more important than having individual superstars working on the shiniest features. I'll add a perverse incentive too that I've talked about elsewhere – hiring is a goddamn mess right now. If I trim the bottom 5% of my org (in my case, 2-3 engineers), I may not get a backfill for them. Or I'll have to drop their level from L5->L4 to make finance happy, or hire overseas or convert a FTE to a contractor. I also have to be ready for the potential of RIFs happening, which means having an instantly identifiable bottom 5% puts me at the advantage of being ready when my boss says \"give me your names\". So the time value of a staffed engineer is way higher right now than it might be in a few months. It'll never be zero, because proactively managing people out makes all of our managers happy. But for now, I definitely need my low performers. reply nilkn 0 minutes agorootparentI think the value of low performers becomes much more obvious when you separate out the concept of a toxic employee. Toxic employees hurt the team or organization whether low performing or high performing, and with rare exceptions it’s almost always worth getting rid of them. Toxic employees are the people getting into arguments and conflicts all the time, dragging others down constantly. Or they’re the managers who cause attrition or can’t retain their team or lie to their peers and own leadership until it catches up to them, often dramatically. However, low performers are not always toxic. Often, low performers are just kind of lazy, or they take longer than they should to finish their work, or they take too long to reply to emails or messages, or their work needs extra review and checks and balances, or they are only capable of delivering on a relatively small set of fairly simple tasks, or they just want to work on the same part of the same product forever and can’t emotionally handle change, or … Non-toxic low performers can be great because they’ll often do the unglamorous work for you for relatively low pay, and all you have to do is not bother them too much. The worst thing you can do with non-toxic low performers is try to force them into high performers. It won’t work, because they’re either not capable or they just don’t care. For some people, their work just isn’t that important to them, and there’s nothing you can do to change their perception of the relative importance of their job to the other aspects of their life. What might look like low performance in a corporate environment can just be someone setting boundaries and refusing to let work infringe too much on their personal life. reply efitz 4 minutes agoparentprevI have a crazy idea. If a corporation lays off any people in a particular job category/title, that corporation should not be allocated ANY H1B visas for that job category/title for the next year. If a corporation institutes any policy that requires decimation (or any other statistic-based termination program) of employees with a particular job category or title, or if IN EFFECT they perform this (because they will just hide it otherwise), then they will not be allocated any H1B visas for that job category or title, for the next year following any such act. In essence, the point here is that if a corporation decides it can live without X% of their workforce, then they don't get to go bring in foreign workers. The H1B program is to help find workers for positions that can't be filled; if you're laying off or mass firing people then obviously you CAN find people to fill those jobs. reply polishdude20 1 minute agorootparentThe play devil's advocate, presumably they're fired because they didn't meet standards (in whatever vague way they can justify) and they want foreign workers because local workers didn't meet those standards. reply abeppu 13 minutes agoparentprevIt's also just embarrassing that this is supposed to be a data science blog about employee performance and the only non-simulated data directly presented or discussed is the US wage distribution, where the author has just cavalierly marked the x-axis as \"Performance\". There's all this spew, and the author makes claims about what good data scientists do ... and there's no data in this discussion that's directly relevant to their rambling claims. reply ec109685 56 minutes agoparentprevEmployers want to pay the minimum, clearly, but until a person’s salary exceeds the value they bring to a firm, there will be other firms willing to pay more and attract that talent. So provides some upward pressure on wages, which the author addresses: > Economists will teach you something called the Marginal Productivity Theory of Wages, the idea being that the amount of money that a company is willing to spend on an employee is essentially the value that the company expects to get out of their work. This strikes me as mostly true, most of the time, and likely to be the case in the corporate world that we’re considering here. reply bluGill 33 minutes agorootparent> but until a person’s salary exceeds the value they bring to a firm, there will be other firms willing to pay more and attract that talent This is false. Supply and demand is a factor. I could clean the toilets at the office, if janitors were in short supply my boss might setup a rotation schedule - nobody wants to but it must be done and so he would pay me. However because janitors are cheaper than me he doesn't. This isn't just theoretical - McDonald's mostly has the crew clean the floors - janitors make more money than McDonalds crew. reply PittleyDunkin 16 minutes agorootparentprev> there will be other firms willing to pay more and attract that talent. ...marginally more. Still nowhere near the actual value their labor brings in. We simply don't have a competitive enough employer market to provide the upward wage pressure that would be sufficient to pay people fairly. reply shkkmo 28 minutes agorootparentprev\"provides upward pressure on wages\" is true, but you simply can't get from there to actually demonstrating the \"marginal producivity theory of wages\". It is pretty clear that the employment market suffers from severe inefficiency and information asymmetry. It takes a pretty bad economist to look at a market like that and think that its pricing is accurate. Employees often don't know how much value they bring and thus are severly limited as counter party and other companies have a hard time predicting how much value you'll be able to add for the. These (plus many other factors) mean that you should expect significant mismatches between pay and performance. Edit: None of this is evidence against performance being a paretor distribution (which makes sense to me), but we're gonna need more than just pay data to determine that. reply hemloc_io 51 minutes agoparentprevWhen I first heard of the Work Number, I thought there's no way they stay in business given the Real Page suit. reply diggan 1 hour agoparentprev> the first is they assume employees are (or should be) paid according to how much they earned the company From the perspective of a employee and/or human, that does seem like the most fair way of distributing what the company earns, sans the money that gets reinvested straight back into the business itself. But I'd guess that'd be more of a co-operative, and less like the typical for-profit company most companies are today. reply stoperaticless 1 hour agorootparentThere is no way to unambiguosly decide who is responsible for which earnings. Hipothetical two people cooperative that produces simple hammers. One specializes on wooden part, the other on metal part. How much each of them earned to the company? (Or producing and selling; or one spending his lifesavings to buy pricey hammer-making-equipment while other presses buttons on said equipment) reply no_wizard 47 minutes agorootparentprevEven with sales based around commission, the most objective sort of salary determination, businesses still find ways to undercut payouts if they don’t think it’ll hurt the bottom line or employers won’t notice reply nkrisc 1 hour agorootparentprevHopefully you don’t get assigned to fixing bugs, because then you may not earn any money. reply dingnuts 1 hour agorootparentprevDid you even finish reading the comment you're replying to? It explicitly explains why employees who do not generate revenue are still valuable. What you're describing, that money would go to whoever brings in revenue directly, is the myopic viewpoint of Sales with an emphasis on closing deals with nothing else. If it wasn't for the rest of the work, there'd be nothing to sell! reply deepnet 1 hour agoparentprevMy takeaway ( and an indication of who actually needs a performance review [ e.g. the manager ]) “ It’s my opinion that the biggest factor in an employee's performance – perhaps bigger than the employee’s abilities and level of effort – is whether their manager set them up for success “ reply kozikow 54 minutes agorootparentOr other way around - in bigcorp (or in startup) choosing what to work on have much bigger impact than the work you do. On very low level it's up to your manager. As time goes, even as IC you have a lot of agency. It's not just company selection, team selection, but also which part of the project you are working on and how you are approaching solving it. Of course \"if everyone does this, who will fix the bugs\". However, the quickest promoted people I've seen are the people who were excellent at politics-izing (and sometimes foresight) the best work assigned to them. reply groby_b 33 minutes agorootparentprevIt's not so much that managers need a performance review per se, but they need training and useful feedback. If you've ever worked in tech management, your experience likely was \"IDK, you're senior, you vaguely have an idea what we should do, here, go manage a few folks\". No training, or minimal training. Often with an expectation that of course you can still be a strong technical contributor, because how much time could managing folks possibly take. And then mostly being evaluated based on how your reports delivered. As long as we follow that approach, we'll struggle with managers doing the right thing, because they neither have learned it, nor have they seen it modelled. Sure, that expresses in bad manager performance, but often nobody can really see it or tell people what they should do better. Performance review is too late to fix that. (This is, btw, mostly true for employees as well - if you only talk about performance 1-4 times a year, people are being set up to fail) reply ianbicking 1 hour agoprev\"IQ is Gaussian\" – it was pointed out somewhere, and only then became obvious to me, that IQ is not Gaussian. The distribution is manufactured. If you have 1000 possible IQ questions, you can ask a bunch of people those questions, and then pick out 100 questions that form a Gaussian distribution. This is how IQ tests are created. This is not unreasonable... if you picked out 100 super easy questions you wouldn't get much information, everyone would be in the \"knows quite a lot\" category. But you could try to create a uniform distribution, for instance, and still have a test that is usefully sensitive. But if you worry about the accuracy of the test then a Gaussian distribution is kind of convenient... there's this expectation that 50th percentile is not that different than 55th percentile, and people mostly care about that 5% difference only with 90th vs 95th. (But I don't think people care much about the difference between 10th percentile and 5th... which might imply an actual Pareto distribution, though I think it probably reflects more on societal attention) Anyway, kind of an aside, but also similar to what the article itself is talking about reply FredPret 1 hour agoparentThis is a subtle aspect of intelligence measurement that not many people think about. To go from an IQ of 100 to 130 might require an increase in brainpower of x, and from 130 to 170 might require 3x for example, and from 170-171 might be 9x compared to 100. We have to have a relative scale and contrive a Gaussian from the scores because we don’t have an absolute measure of intelligence. It would be a monumental achievement if computer science ever advances to the point where we have a mathematical way of determining the minimum absolute intelligence required to solve a given problem. reply silvestrov 54 minutes agorootparentI wonder how a graph looks for \"how many seconds does it take people to run 100 meters\". Might be a mix because quite a number of older or overweight people runs very slowly and some can't at all. reply groby_b 29 minutes agorootparentprev> It would be a monumental achievement if computer science ever advances to the point where we have a mathematical way of determining the minimum absolute intelligence required to solve a given problem. While that would be nice, it's likely a pipe dream :( There's a good chance \"intelligence\" is really a multi-dimensional thing influenced by a lot of different factors. We like pretending it's one-dimensional so we can sort folks (and money reinforces that one-dimensional thinking), but that means setting ourselves up for failure. It doesn't help that the tests we currently have (e.g. IQ) are deeply flawed and taint any thinking about the space. (Not least because folks who took a test and scored well are deeply invested in that test being right ;) reply logicchains 1 hour agorootparentprev>It would be a monumental achievement if computer science ever advances to the point where we have a mathematical way of determining the minimum absolute intelligence required to solve a given problem For a huge number of problems (including many on IQ tests) computer science does in fact have a mathematical way of determining the minimum absolute amount of compute necessary to solve the problem. That's what complexity theory is. Then it's just a matter of estimating someone's \"compute\" from how fast they solve a given class of problems relative to some reference computer. reply shkkmo 25 minutes agorootparent> Then it's just a matter of estimating someone's \"compute\" from how fast they solve a given class of problems relative to some reference computer. Heh... \"just\"... Good luck with that. reply jppope 1 hour agoparentprevCorrect. IQ isn't an effective measurement of intelligence as is typically stated. It is (at best) a measurement of learning disabilities. reply liontwist 1 hour agorootparentIt’s a pretty good measurement of your ability to play logic games and fast pattern match. I’m sure we agree that doesn’t constitute “intelligence”, but it’s more than disability. reply mjburgess 20 minutes agorootparentIndividual test-retest variability is high. It's only a valid measure of anything much below 100. Consider a test of walking speed which each time you take it gives results of (2, 3, 6, 2, 3, 5, 7, 3) etc. -- does this measure some innate property of walking speed? No. Yet, if it wereand then pick out 100 questions that form a Gaussian distribution. This is how IQ tests are created. You missed an extremely important final step. People's scores on those 100 questions still aren't going to form a Gaussion distribution. You have to rank-order everyone's scores, then you assign the final IQ scores based on each person's ranking, not their raw score. reply fwip 5 minutes agorootparentIt would form a gaussian distribution if you pick the questions carefully enough. If you rank-order scores and fit to the distribution after the fact, the questions are nearly irrelevant, as long as you have a mix of easy, medium and hard questions. reply bhouston 2 hours agoprevI would feel better if this was derived from empirical data rather than just rhetoric. This seems super testable, no? There is probably a ton of data already in different industries with regards to productivity. Even if human talent have a Pareto distribution (which is not clear), the people employed by a company are a selected sub-set of that population, which would likely have a different distribution depending on how they are selected and the task at hand. I think that any of these simplified distributions are likely not generalizable across companies and industries (e.g. productivity of AWS or Google employees are likely not distributed like employees of MacDonalds or Wal*Mart because of the difference in hiring procedures and the nature of the tasks.) Get hard data within the companies and industry you are in and then you can make some arguments. Otherwise, I feel it is too easy to just be talking up a sand castle that has no solid footing. reply Miraltar 2 hours agoparentTo me it says that our system is built on a reasonable but untested assumption (performance is a gaussian) and by replacing it with an equally reasonable assumption (performance is a pareto), suddenly our system looks stupid. It isn't really offering a solution but a new perspective reply pama 1 hour agoparentprevI thought that Bonus Content #1 and the references down the article were reasonably convincing. It would be great if large companies disclosed such details but it is unlikely. reply wavemode 1 hour agoparentprev> I would feel better if this was derived from empirical data rather than just rhetoric. This exact statement applies to the practice of Gaussian performance ranking. It is pure corporate politics, it isn't founded in sound statistics. The present author at least provides multiple sources of statistical evidence for their beliefs, if you read the footnotes. reply KK7NIL 2 hours agoparentprevThe problem is that intellectual productivity is generally not possible to measure directly, so you instead end up with indirect measurements that assume a Gaussian distribution. IQ is famously Gaussian distributed... mainly because it's defined that way, not because human \"intelligence\" (good luck defining that) is Gaussian. If you look at board game Elo ratings (poor test for intelligence but we'll ignore that), they do not follow a Gaussian distribution, even though Elo assumes a Gaussian distribution for game outcomes (but not the population). So that's good evidence that aptitude/skill in intellectual subjects isn't Gaussian (but it's also not Pareto iirc). reply EnergyAmy 1 hour agorootparentDo you have a reference for Elo ratings not being Gaussian? A casual search shows lots of graphs and discussions saying it is. reply KK7NIL 1 hour agorootparentLook at my reply to bhouston. Elo ratings for active players are close to Gaussian, but not quite, they show a very clear asymmetry, especially for OTB old school Elo (compared to online Glicko-2). The active players restriction is a big one and one I didn't assume I in my original statement. reply bhouston 2 hours agorootparentprev> so you instead end up with indirect measurements that assume a Gaussian distribution. 100%. I was going to write something similar. > If you look at board game Elo ratings (poor test for intelligence but we'll ignore that), they do not follow a Gaussian distribution, even though Elo assumes a Gaussian distribution for game outcomes (but not the population). So that's good evidence that aptitude/skill in intellectual subjects isn't Gaussian (but it's also not Pareto iirc). Interesting, yeah, Elo is quite interesting. And one can view hiring in a company as something like selecting people for Elo above a certain score, but with some type of error distribution on top of that, probably Gaussian error. So what does a one sided Elo distribution look like with gaussian error in picking people above that Elo limit? reply KK7NIL 2 hours agorootparentLichess has public population data (they use a modified version of Glicko-2 which is basically an updated version of Elo's system): https://lichess.org/stat/rating/distribution/blitz It's basically a Gaussian with a very long right tail. Big caveat here is that these are the ratings of weekly active players. If we instead include casual players, I suspect we'd have something resembling a pareto distribution. reply JackFr 1 hour agorootparentGood question - do the bad players play less because they are bad, or are they bad because they play less? reply bhouston 1 hour agorootparent> Good question - do the bad players play less because they are bad, or are they bad because they play less? Both for sure. If you don't practice you will never rise much about bad. But if you are bad and not progressing you won't play much because it isn't rewarding to lose. One needs to almost figure out those with low ELO ratings, what is their history compared to the number of games played and see if they were following an expected ELO progression. I wonder if you can estimate with any accuracy where a player will eventually plateau given just a small-ish sampling of their first games. Basically estimate the trajectory based on how they start and progress. This would be interesting. Given how studied Chess is, I expect this is already done to some extent somewhere. reply jlawson 2 hours agorootparentprevAll polygenic traits would be Gaussian by default under the simplest assumptions. E.g. if there are N loci, and each locus has X alleles, and some of those alleles increase the trait more than others, the trait will ultimately present in a Gaussian distribution. i.e. if there are lots of genes that affect IQ, IQ will be a Gaussian curve across population. reply KK7NIL 1 hour agorootparentVery interested point, this is a close corollary to the central limit theorem, no? Doesn't this assume a linear relationship between relevant alleles and the given trait though? reply boothby 42 minutes agorootparentThe missing assumptions are that the number of genes is large, independently distributed (i.e. no correlations among different genes), and identically distributed. And the whopper: that nurture has no impact. You can weaken some of those assumptions, but there are strong correlations amongst various genes, and between genes and nurture. And, one \"nurture\" variable is overwhelmingly correlated to many others: wealth. Unpacking wealth a little, for the sake of a counterexample: one can consider it to be the sum of a huge number of random variables. If the central limit theorem applied to any sum of random variables, it should be Gaussian, right? Nope, it's much closer to a Pareto distribution. In summary: the conclusion of the central limit theorem is very appealing to apply everywhere. But like any theorem, you need to pay close attention to the preconditions before you make that leap. reply Bootvis 1 hour agorootparentprevIt does. A lognormal distribution would model that better which gives a nice right tail so maybe it is a useful toy model. reply drcwpl 2 hours agoparentprevAgree with you - although, rhetorically speaking, I have come across many instances which the author refers to \"of low performers are 3x as common as high performers.\" This is unfortunate as I always think do your best, and as Tyler Cowen states - Average is Over. So agree it would have been way better to use empirical data to back up this claim especially. reply groby_b 19 minutes agoparentprev> There is probably a ton of data already in different industries with regards to productivity. Uh. Not really. Our industry is notoriously bad at measuring productivity. And the bigger problem is that when we try to measure it - \"performance review\" - we like grading on a gaussian curve. We'll never know if that's correct because we put our thumb on the scale. An even bigger problem is that productivity is strongly influenced by completely non-technical factors. How enthusiastic are folks about what they are doing[1], how much variety do their tasks have [2], what are their peers like, etc. (Of course, that whole field of study has issues rooted in the inability to measure precisely as well) Ultimately, it's a squishy judgment applied by humans. [1] https://www.semanticscholar.org/paper/What-Predicts-Software... [2] https://research.google/pubs/what-predicts-software-develope... reply jedberg 1 hour agoprevOne of the things I loved about working at Netflix was that the base assumption was that everyone was a top performer. If you weren't a top performer, you were given a severance check. The analogy we used was a sports team. Pro sports teams have really good players and great players. Some people are superstars, but unless you're at least really really good you're not on the team. Performance and compensation were completely separate, which was also nice. Performance evals were 360 peer reviews, and compensation was determined mostly by HR based on what it was costing to bring in new hires, and then bumping everyone up to that level. So at least at Netflix 10 years ago, performance wasn't really distributed at all. Everyone was top 10% industrywide. reply brabel 1 hour agoparentIt's really difficult for me to believe that they really got 10% top performers. For one, knowing the cut-throat nature of employment there, I would expect only a minority of developers would be willing to try working there, despite the awesome rewards. Another reason I really don't trust that to be true is that I've never seen a good way to measure who is a top performer and who is not. I don't think there's one, people are good in different things, even within the same job... for one assignment, Joe may be the best, but for another, Mary is the winner (but again, to measure this reliably and objectively is nearly impossible IMHO for anything related to knowledge work - and I've read lots of research in this area!). Finally, just as a cheap shot at Netflix, sorry I can't resist as a customer: they absolutely suck at the most basic stuff in their business, which is to produce good content in the first place, and very importantly, NOT FREAKING CANCEL the best content! I won't even mention how horrible their latest big live stream was... oh well, I just did :D. reply kube-system 1 hour agorootparent> the most basic stuff in their business, which is to produce good content in the first place, and very importantly, NOT FREAKING CANCEL the best content! It isn't that simple. Making money from content is not 1-to-1 related with the quality of the content. There are many examples of great content that doesn't make money, and many examples of content that makes a lot of money that isn't great. Also there are many differing opinions on what 'great content' even is. reply echelon 1 hour agorootparentIt's an increasingly bad business to be in. Netflix burns customers when they cancel beloved shows, and they constantly have to experiment. They now have a bazillion competitors who are ramping up comparable businesses. There's no moat or secret sauce competitive advantage. Customers are free to switch at no cost. Bigger tech companies are using media content as simply a fringe benefit or commodity to enhance their platform offerings. YouTube, on the other hand, is already starting to eclipse the entire Netflix business model. YouTube is a monster with a huge and enviable moat, and it's only going to continue growing. It's a much stronger business model and they have a sticky and growing user base. reply jedberg 15 minutes agorootparentprev> It's really difficult for me to believe that they really got 10% top performers. Of course there is no hard data on it, but I can say anecdotally the people I know who went on elsewhere were consistently rated at the top of whatever organization they landed at. And also, there wasn't a single person there that I would not want to work with again and would jump at that chance. > For one, knowing the cut-throat nature of employment there, I would expect only a minority of developers would be willing to try working there, despite the awesome rewards. On the flip side, a lot of people wanted to work there because of that culture. But you're right, some really great people wouldn't even apply, won't deny that. > Finally, just as a cheap shot at Netflix, sorry I can't resist as a customer: they absolutely suck at the most basic stuff in their business, which is to produce good content in the first place, and very importantly, NOT FREAKING CANCEL the best content! Actually, objectively, it's not the best content, which is why it gets cut. The way that decision is made is every piece of content is charted on a cost vs minutes watched. Then that chart is looked at by actual humans. Some content, like reruns from the 1950s, is super efficient. It's not watched a lot but it also costs very little, so it stays. Some content, like the latest Marvel movie (before Disney had their own streaming service) was very inefficient, but it was kept because it was a big marketing draw. But some content didn't quite make it over the line because it was expensive but niche. It was popular amongst a small set of die hard fans. I think your complaint it more about the industry in general though -- it's not just Netflix that doesn't give a show room to grow. Even the old school TV networks cut shows much quicker now than they did before. > I won't even mention how horrible their latest big live stream was... oh well, I just did :D. Netflix knows it didn't go well. Streaming in general used to break just as much. But the nice thing was that they gave us the resources to hire the right people and the autonomy to fix it. And so we did things like create Chaos Engineering and OpenConnect. I suspect the same will happen with live streaming. reply lolinder 35 minutes agorootparentprev> I would expect only a minority of developers would be willing to try working there, despite the awesome rewards. So much this. OP's description of the work environment is stressing me out and I don't even work there. At best a strategy like the one described above will get you the top 10% of people who are willing to put up with that kind of work environment, which means you might get the top 10% of single, childless 20–35-year-olds—people who are motivated first and foremost by ego and pay and don't value stability and work-life balance. But in the process you're more or less explicitly saying that you're not interested in people who are further along in their lives and value stability and reliability more than ego and raw paycheck size. This means that you're missing out on the top 10% of 35–65-year-old engineers who are now parents with responsibilities outside of their career, even though the top 10% of that bracket would typically be \"better\" by most metrics than the top 10% of the younger bracket you're pre-filtering down to. In a startup environment this might be a perfectly rational tradeoff—you want to filter for people who don't have much else to do and can give you a huge amount of unpaid overtime in exchange for you stroking their ego—but past a certain size and market share you need the stability offered by mature, experienced professionals. If Netflix failed to get over that hump, it's not so surprising after all that they fell so hard in the last 10 years. reply jedberg 13 minutes agorootparentMost of the people I worked with were 30-50 years old with families and kids. The work life balance was great. I was the rare outlier who was married without kids. We had senior engineers who would work hard and get things done and then go and be parents and partners. reply creer 1 hour agorootparentprev> difficult for me to believe that they really got 10% top performers It's difficult to achieve, but it's not an unreasonable objective to have. After that there is a question of measurement. How do you measure that? Did they? What was their score? - and yes, until the evidence is released, they probably didn't. (But I would also cut slack on the measurement - it IS difficult to measure so a decent attempt - a top 10% attempt? - will do.) Where the \"top performers\" meme obviously fails is when every new business and their sister claims the same thing. We are all winners here and all that. reply FuriouslyAdrift 36 minutes agorootparentprevNetflix has a reputation for the highest salaries in tech. That tends to attract top talent. https://medium.com/dice-insights/netflix-ceo-explains-why-he... reply exe34 1 hour agorootparentprevI think it's safe to assume gp has drunk the koolaid. I spoke to somebody from the army once, and they too had the top 10% and it's difficult to imagine that every employer employs the top 10%. it's a cultural meme really, like everybody tells themselves they are good people really. reply jajko 51 minutes agorootparentAt some point, people invest into their work/employment so heavily and tie it to their identity tad too much, they internally need to feel this is the right and best choice, which for many top talents may mean working with \"top 10%\", whatever that means. So otherwise smart folks will start parroting official company policies and become a 'good boy'. Suffice to say I don't look kindly on this, but it highly depends on the business. I've heard similar claims many times before, albeit mostly not from places paying so much. Ie at university, there was promotion seminar from Accenture branch in our country, the guy was some higher manager and stated the same, how they want only the best of the best and work hard getting and maintaining this. Then maybe 10 years later I had 20 of them as contractors and reality was not that rosy, huge variation from good to terrible. reply exe34 39 minutes agorootparentI love my job, but I'm careful not to give the impression at work. Best to keep them on their toes. I'm also good at weaving the corpospeak into conversations, but very few can hear the sarcasm. reply Eikon 1 hour agoparentprevHow are 'top performers' and 'low performers' being defined in this context? In my experience, these labels in corporate environments often correlate more with social dynamics and political acumen than actual work output. People who are less socially connected or don't engage in office politics may find themselves labeled as 'low performers' regardless of their actual contributions, while those who excel at workplace networking might be deemed 'top performers'. The interview process of these kind of companies also often falls into a problematic pattern where interviewers pose esoteric questions they've recently researched or that happen to align with their narrow specialization from years in the same role. This turns technical interviews into more of a game of matching specific knowledge rather than evaluating problem-solving abilities, broader engineering competence or any notion of 'performance'. Let's be honest: how many people can truly separate personal feelings from performance evaluation? Even with structured review processes in place, would most evaluators give high marks to someone they personally dislike, even if that person consistently delivers excellent work? reply efitz 1 hour agorootparent> problematic pattern where interviewers pose esoteric questions they've recently researched The days of the “brain teaser” interview question are gone, at least from the “magnificent 7” and similar big tech companies. Nowadays it’s coding, behavioral, and design, at least for engineers. I concur with the sentiment that performance ranking has a very significant social component. If you have a bad relationship with your manager, watch out. But also, if your manager has a bad relationship with THEIR manager, or are not adept at representing their employees, you can get screwed too. reply lifeisstillgood 21 minutes agoparentprevLogically no-one else will try this - because if every company competed for the top talent, wages would rise to consume all profit. I think this is probably how labour and capital should compete - I expect we need to equalise tax treatment so that becomes more possible reply yreg 1 hour agoparentprevA bit offtopic, but I've been curious about this. Could you please describe how the unlimited vacation policy worked? How did people feel about it and whether they were anxious regarding using it (afraid that it will reflect on them badly when they take \"too much\" time off)? reply jedberg 11 minutes agorootparentI loved the unlimited vacation policy. I took more vacation at Netflix than anywhere else. No one was anxious about using it. It helped that senior leadership set a good example. The CEO took a few weeks off every year and made sure everyone knew that it was ok to do that. He also made sure all his directs took a few weeks every year at a minimum. There was a culture of management encouraging you to take advantage of the program. reply dangus 1 hour agoparentprevIn summary, Netflix told all their employees that they are so amazing at their job, they are the top 10% of the whole world, they are like NFL athletes. If they don't perform to top tier levels, they'll be shown the door. Here's a thought experiment: pretend that Netflix is lying and that their employees are not actually made up of the top 10% of talent industrywide. Let's for this thought experiment assume the realit is that they have slightly above average talent because Netflix pays slightly above industry average. But now they've convinced those employees that they're not just slightly above average, they are like elite NFL players. And that means they have to work like elite NFL players. Netflix convinces their employees to work XX% harder with longer hours than the rest of the industry because they think they are elite. \"Only amazing pro athlete geniuses can work here\" is way more motivating than \"You have to work yourself to death with extra hours to make quota or you're fired!\" because it's a manipulation of the ego. I think this thought experiment is closer to reality than Netflix or their kool-aid-drunk employees will admit, and that Netflix's \"pro athlete\" culture is worker-harming psychological manipulation. reply vineyardlabs 1 hour agorootparentThe interesting thing about this thought experiment is that you assume Netflix would have slightly above average employees if they have slightly above average compensation. Now what happens to the experiment if Netflix has ridiculously above average, end of the bell curve compensation (as they do)? Serious question, I do not and have not worked for Netflix. reply dangus 28 minutes agorootparentI was really giving them the benefit of the doubt. I don’t think Netflix had anything special above and beyond any other Silicon Valley software company. They just pushed this narrative and nobody questioned them. Netflix as a business isn’t even way ahead of competition anymore. It’s not better than Hulu or Max or anything else. Netflix’s platform crumbled handling live streaming a boxing match, while Amazon and the rest of the legacy media companies have no issues streaming NFL games every weekend, and I’m supposed to believe that Netflix engineers are better than the ones at Paramount+ who never made me wait for a buffer to watch Premier League or NFL on CBS. reply jonas21 1 hour agorootparentprevMost Netflix employees have worked at other places and can make the comparison for themselves. They don't have to take Netflix' word for it. Also, since when is telling people they're good at what they do \"worker-harming psychological manipulation?\" reply MilanTodorovic 1 hour agorootparentMy guess would be that it nurtures the imposter sydrome once the \"top performer\" starts struggeling with something they shouldn't if they truely were a top performer. reply dangus 37 minutes agorootparentprevThe employees are making that judgment in an environment that has been tainted by the psychological manipulation itself. How many people have brains that are going to seriously put up a fight for objective truth when other people talk them up like that? If you tell me my team is full of excellent talent I’m not going to self-sabotage my ego and question it. It’s negative psychological manipulation when it’s being used as an excuse to fire and replace reasonably productive people. The employment contract is highly lopsided. An employee is harmed far more when they are fired than a business, and Netflix exploits that advantage with this organizational culture. reply thifhi 1 hour agoparentprev> Performance and compensation were completely separate, which was also nice. Huh? How is that nice? Does performance and compensation not correlate in your ideal world, or am I misunderstanding it? reply jedberg 8 minutes agorootparentIn my ideal world, no they do not. Pay equals what it would cost to rehire me today. Performance should always be great for what you are expected to do. Where the two correlate is that if you're hiring a mid-level person they get mid-level pay, and if they are top performing mid-level, they get promoted to senior and get commensurate pay. So performance leads to promotions which leads to better pay. But pay is not directly correlated with performance. I expect everyone in the same level to have equal performance (over the long term, of course there will be short term variations). reply haolez 1 hour agoparentprevHow can 360 peer performance reviews ever work? The incentives are against a fair evaluation: the reviewers have the incentive to overly criticize others so that they can stand out more. I'm not saying that everyone on a 360 review process does that. But the incentive is there and it's working against fair reviews. reply jedberg 6 minutes agorootparentIf performance is not tied to pay, why would you have an incentive to do that? If anything the incentive is problematic in the other direction. People tend to be nice because they don't want to say mean things that they know the manager will see. reply stonemetal12 46 minutes agorootparentprev>The incentives are against a fair evaluation: the reviewers have the incentive to overly criticize others so that they can stand out more. Wouldn't that(how you view and fit in with your team) be part of your review? If I was Bob's manager and all reviews he gave of his teammates were \"Teammate M is a dumbass and the only reason they are productive is because I do 80% of their job for them\", wouldn't leave me thinking Bob is great. It would leave me thinking Bob is a jerk who doesn't work well with others. reply hemloc_io 2 hours agoprevCool data/idea, and anecdotally lines up with my experiance at BigCos from a coworker perspective. But in my experiance employee perf evals are more political than data based. At the end of the day a lot of mgmt at BigCo, esp these days, wants that 10% quota for firing as a weapon/soft layoff and the \"data\" is a fig leaf to make that happen. More generously it's considered a forcing function for managers to actually find underperformers in their orgs, even if they don't exist. Either way it's not really based on anything other than their own confirmation bias. IME the scrutiny of perf evaluation is basically tied to the trajectory of the company and labor market conditions. Even companies with harder perf expectations during the good times of ~2021 relaxed their requirements. reply riazrizvi 2 hours agoprevThis is a well constructed empty argument because it glosses over the central concern, ‘employee performance’. Without defining that we have no idea what the graph represents. reply bhickey 2 hours agoparentFor analyses like this it just doesn't matter. Pick a metric and measure it over your workforce. Across the universe of salient metrics of interest you won't see a gaussian across your workforce. In a previous job I modelled this and concluded that due to measurement error and year-over-yead enrichment, Welchian rank-and-yank results in firing people at random. reply pembrook 2 hours agorootparentAll of Jack Welch’s management tactics should be considered suspect now. His performance at GE was 100% fueled by financial leveraging that blew up in 2009, basically killing the company. Nobody should be taking management lessons from this guy. reply lotsofpulp 1 hour agorootparent> Nobody should be taking management lessons from this guy. Rank and yank is simply about lowering labor costs, once the business has achieved a significant moat and no longer needs to focus solely on growing revenues. A negotiating tool for the labor buyer, due to the continuous threat of termination. reply bhouston 2 hours agorootparentprevStack ranking will tell you when something isn't working, but the solution isn't always to fire, but rather use that data to fix things in a more general solution. I found that team composition and role assignment matters a lot, at least if you hire people who are at least above a certain bar. Match a brilliant non-assertive coder with someone who is outgoing and good at getting along and at least decent coder, and the results from the two outperform generally either of them individually. You can bring out the best of your employees or you can set them up against each other. This either brings everyone up or brings everyone down. reply dataflow 2 hours agorootparentWholeheartedly agree with you on team composition mattering a ton, but how often do you have such an abundance of engineers and tasks that you can match them up the right way? reply bhouston 2 hours agorootparentI think if you get to know your engineers, you can figure out the right pairings to bring out the best. But this requires intimate knowledge and probably subjective based on how good the manager is at managing coders. So I guess from up high, stack ranking-based firing is easier. But I think it is also cheaper to make great teams rather than just doing brutal firings all the time. But it may be a micro-optimization? reply Cheer2171 2 hours agorootparentprevSo you're saying that if you don't think about construct validity and just pick any given metric that can spit out a comparable number across all your different positions and teams, that these metrics have weird distributions? Hmm, I wonder why. reply munk-a 1 hour agorootparentI think it's more charitable to interpret their statement as \"for all metrics\" rather than \"run this experiment once and arbitrarily just chose a single metric\". Their statement is a lot more actionable because as much as we've tried to over decades finding an accurate metric to represents performance seems to be an impossible task. A researcher friend at a previous job once mentioned that in grad school he and several other students were assisting a professor on an experiment and each grad student was given a specific molecule to evaluate in depth for fitness for a need (I forget what at this point) and one of the students had a molecule that was a good fit while the others did not - that student was credited on a major research paper and had an instant advantage in seeking employment as a researcher while the other students did not. That friend of mine was an excellent science communicator and so fell into a hybrid role of being a highly technical salesperson but tell me - what metrics of this scenario would best evaluate the researchers' relative performance? The outcome has a clear cut answer but that was entirely luck based (in a perfect world) - a lot of highly technical fields can have very smart people be stuck on very hard low margin problems while other people luck into a low difficulty problem solution that earns a company millions. reply withinboredom 1 hour agorootparentMost of the world is ruled by luck. Where you are born, who your parents, how rich they are, who you know, whether or not someone “better” than you applies for the same position, etc. etc. Ignoring luck or trying to control for it would be a mistake. reply timdellinger 2 hours agoparentprevOh, the answer to that is apparent enough, but frustratingly circular: Performance is \"visibly doing the things that the company rewards during the performance review process\". Theoretically, each role at a company should have a set of articulated accomplishments that are expected. (This is sadly often not the case.) But you're right that the subjective nature of \"performance\", and the lack of a clear numerical scale, are a difficulty of the entire process! reply chambers 27 minutes agoparentprevOn a meta note, you're right to note that unclear terms undermine our collective reasoning, despite a proper chain of propositions. I've found Term Logic[1] to be useful for figuring out why certain discussions confuse me. I've also used to avoid unnecessary arguments by seeing if the participants are starting with clear concepts (signaled by terms). [1] https://en.wikipedia.org/wiki/Term_logic#Basics also this explainer https://adoroergosum.blogspot.com/2015/05/the-three-acts-of-... reply alphazard 2 hours agoparentprevYou could replace \"employee performance\" with \"value to the company\" and the same argument would hold. Performance is difficult to measure, but we get a good estimate of value to the company any time someone receives a competing offer and drags their manager to the negotiating table. The amount of money the manager is willing to match is the perceived value to the company. This is how the company actually behaves (we know for sure whether they match the offer or not) and that behavior implies a value to the company, regardless of what anyone says in performance review season. reply dataflow 1 hour agorootparent> The amount of money the manager is willing to match is the perceived value to the company. This assumes the manager is irrelevant here. But we all know that different managers (or non-managers) can communicate value differently for the same employee. So this metric can't be solely measuring the value of the employee. reply alphazard 1 hour agorootparentYou are talking about value as some intrinsic quality. I'm talking about value as a belief that is subjectively assigned, and that we can infer from actions. We can all agree on the actions, and we can agree on the possible beliefs that an action can imply. The action to not match an offer implies that the company believes the employee adds less value than their new offer. If the company believed the employee was adding more value than their new offer, they would match the offer to keep the employee. A company isn't a single rational agent. It's made up of people performing different functions. But behaving irrationally is a categorically bad thing for the company to do, and the leadership has a fiduciary duty to prevent the company from acting irrationally or otherwise not in its own self interest. The manager may matter here, but the leadership is supposed to be creating a management structure such that the company acts rationally to make progress towards set goals. reply mitthrowaway2 2 hours agoparentprevThe article does briefly caution about measuring difficulties. But given that the main conclusion is an argument against stack-ranking-and-firing, the question of \"what is performance\" passes forward to whatever metric the stack-ranking manager was going to use when they were planning to fire the \"bottom\" 10% of their payroll. reply michaelmior 2 hours agoparentprevI'm not sure this is the argument the author is making, but you could claim that the rest of the argument is true for any (or most) reasonable measure of employee performance that a company actually cares about. reply nradov 2 hours agorootparentYou could claim anything, but is there hard quantitative data to support such a claim? Or are we just guessing? reply michaelmior 45 minutes agorootparentThe author presents some data in the article. Also, the absence of hard quantitative data doesn't necessarily make it a complete guess. (At least not any more than starting with the assumption of a Gaussian distribution.) reply BiteCode_dev 1 hour agoparentprevYes, is performance Pareto, or perception of performance Pareto? reply SideburnsOfDoom 2 hours agoparentprevIt also assumes that \"productivity\" is something that is meaningful at all at the level of individuals, not teams or larger. IMHO, it is not. reply crazygringo 1 hour agoprevThis is very unconvincing. The author already admits one reason why: > But there are low-performing employees at large corporations; we’ve all seen them. My perspective is that they’re hiring errors. Yes, hiring errors should be addressed, but it’s not clear that there’s an obvious specific percentage of the workforce that is the result of hiring errors. I think it is clear that we expect a certain percentage of hiring \"errors\". And that they are not binary but rather a continuum. And that there are lots of other factors like employees who were great when they were hired but stopped caring and are \"coasting\" or just burnt out, who got promoted or transferred when they shouldn't have been and are bad at their new level/role, and so forth. The Pareto distribution isn't particularly relevant here, because a hiring process isn't trying to get a whole slice of the overall labor market with clear cutoffs. For any position, it's trying to maximize the performance it can get at a given salary, and we have no reason to expect the errors it makes in under- and over-estimating performance to be anything but relatively symmetric. So a Gaussian distribution is a far more reasonable assumption than a slice of the Pareto distribution, when you look at the multiplicity of factors involved. reply wavemode 1 hour agoparent> So a Gaussian distribution is a far more reasonable assumption than a slice of the Pareto distribution It's not an assumption. See the evidence referenced in the footnotes. reply dheera 1 hour agoparentprevPersonally I think manager/report mismatches are far greater than hiring errors. When A doesn't like B it doesn't mean A or B are necessarily unfit to work at the company, but it generally results in the subordinate being framed as underperforming or not being given the resources to perform. reply wavemode 54 minutes agoprevThis concept is not new - see [0]. There's ample research that Welchian stack ranking, and assuming a Gaussian distribution of employee performance, is not well-founded. Even its original pioneers (General Electric) have abandoned the practice (see [1]). Not sure why there are so many commenters here defending the Gaussian model. Most researchers at this point agree that a pareto distribution is more realistic. [0]: https://hbr.org/2022/01/we-need-to-let-go-of-the-bell-curve [1]: https://qz.com/428813/ge-performance-review-strategy-shift reply iambateman 2 hours agoprevAs employees, our expectations for performance management come from the system of giving grades in school. What's interesting is that school grades often doesn't follow a normal distribution, especially for easier classes. I suspect that getting an \"A\" was possible for 95%+ of students in my gym class and only 5-10% of the students in my organic chemistry class. In the same way, some jobs are much easier to do well than others. So we should expect that virtually all administrative positions will have \"exceptional\" performance, which is to say that they were successful at doing all of the tasks they were asked to do. But for people who's responsibility-set is more consequential, even slightly-above average performance could be 10x more meaningful to the company. reply atoav 2 hours agoparentOne thing where this analogy stops to work, is that more so than in school your performance in a company can be highly dependent on how well and/or timely others do their job. Your managers performance metric may or may not catch that. E.g. imagine you are assigned a project where you have to interact a lot with department X and now department X is running at/over capacity, so you are performing worse, because their part isn't done in time and each back and forth takes half a week. Now you spend half your time not being productive with no fault of your own and the others are 110% productive while setting the whole shop on fire. Based on that metric they should fire you and hire more people for department X, when in fact they should probably just hire more for them (or reorganize the department). Another example where this analogy stops working is that in school the students usually get the same/comparable assignments, that is somewhat the point of those. As the goto hard-problem-person at my current workplace I am pretty sure that it is absolutely impossible to compare my work to the work of my collegue who just deals with the bread and butter problems, it isn't even the same sport. How would you even start doing a productivity comparison here, especially if you understand 0 about the problem space reply iambateman 54 minutes agorootparentGreat perspective and I agree. This is the basic reason that performance management in an organization is so difficult and fraught. A significant percentage of people in an organization create the problems they solve. reply nightski 2 hours agoparentprevHaving a shifted mean doesn't mean they aren't a normal distribution. Not saying they are necessarily, but the anecdote you are providing isn't convincing. reply kurthr 2 hours agorootparentPerhaps, but due to the sampling of the distribution you would likely never know. If 95% of your samples fit in the top 3 bins, you can’t say much at all with certainty. Poisson, Gaussian, binomial, Boltzmann, gamma… reply marian_ivanco 2 hours agorootparentprevThat is not IMHO what he is trying to say, you don't shift the distribution, you measure if somebody passed a test. I the test is \"passable\" then one side of \"distribution\" is at least cut off. E.g. it's normal (and sometimes expected) that the whole class will pass without issues. reply dowager_dan99 2 hours agorootparentprevif your scale doesn't have the atomic values at the top end to differentiate the data it's not a normal, it's Pareto or Zipf or some other power law. reply sokoloff 2 hours agoparentprevWould “doing all of the tasks they were asked to do” really be “exceptional”? What could be exceptional about that? I would think it would be “meets expectations” at most. reply iambateman 55 minutes agorootparentI have an issue with this thinking, but I don't mean to pick on you...it's common within organizational politics. Managers suggest that an employee must \"go above and beyond\" their ordinary duties to get an exceptional rating. But that just means that \"going above and beyond\" is, in fact, a duty. The problem is it's an ill-defined duty which is even more susceptible to the whims of what the manager thinks counts as \"above and beyond.\" Good managers give clear rubrics of performance. To me, \"meets expectations\" says that the employee's error rate was at acceptable levels and \"exceptional\" means they had almost no errors whatsoever. reply dowager_dan99 2 hours agorootparentprevYou don't really need a distribution to measure tasks that are binary in nature though, why bother with a Likert scale when you can just use a yes/no checklist? I suspect there's also a high correlation between the jobs/roles and the likelihood of being displaced by machine or otherwise, as measuring success is a key problem to be solved when \"dehumaning\" these jobs. reply dogleash 2 hours agoprevTo me the biggest insight here is that no matter what data science you're trying to do on a group of employees, the people you already have decided should be fired or promoted from that group are outliers and should be removed from the sample. There are certainly times that you would want them included, but those can be classified under \"budgeting,\" not gaining insight on a workforce. reply ses1984 2 hours agoparentDoesn’t the inclusion or exclusion of these people heavily depend on what type of insight you’re trying to get out of the data? reply doctorpangloss 2 hours agoprevThis article: \"Wouldn't it be cool if when you measure employee performance, it turned out to fit a Pareto distribution better than a Gaussian?\" Would that be cool? We could posit the implications of all sorts of improbabilities. But I feel more strongly about how cool it would be that P = NP. All this aside, being laid off sucks - being pushed out, even when you're a high performer, sucks even more. The truth is that \"data science\" does not help you process grief the way reading Dostoevsky does, so maybe getting an A in your liberal arts education is valuable even when you are working as a software developer. reply igorkraw 26 minutes agoprevThe author looks at \"observables\" of performance without considering whether there might be confounders such as those discussed in great nuance here https://onlinelibrary.wiley.com/doi/full/10.1111/joes.12328 . He cites similar work by William Shockley who taught both electrical engineering and scientific racism at Stanford https://en.wikipedia.org/wiki/William_Shockley (no swipe at the author, just pointing at the biased motiviations of some of the researchers foundational to the idea of \"high performers\"). In general, when you see pareto structures or power laws, you should think of compound or cascade effects, which in human structures generally means some form of social mediation. Affinity for a desireable skill might be gaussian, but the selection process means that the people who _get_ to do that skill might become pareto shaped because if you aren't much better than the next guy, you wouldn't stably stay at the top. Similar logic can hold for other expressions. In general, I wish more people would read https://blackwells.co.uk/bookshop/product/Causality-by-Judea... or at least the more accessible https://mixtape.scunning.com/ before starting to conjecture from data about social systems - the math will tell you what you can and cannot speculate on. (fun exercise: draw the causal models of IQ in https://dagitty.net/ and ponder the results) reply drc500free 13 minutes agoprevI've recently been working with a lot of service center productivity data. Staff productivity (customers/hour) is pretty close to a gaussian, with some skew towards many slight underperformers and few overperformers. However, any single customer interaction is exponential or weibull distributed. reply jampa 2 hours agoprevGoing through some performance reviews as a manager, I always try to push back a bit against the bell curve. It kinda reminds me of the \"stack ranking.\". There are also some factors to be considered: If you are in a hiring freeze or not promoting, most of the curve should shift right, assuming you are hiring great people. They will probably perform better quarter after quarter. Some might counter-argue that if everyone performs better, this should be the \"new expectation,\" but I disagree: the market sets expectations. If you have someone at a senior level with expectations of staff, for example, they won't be in the company for long. I hired many great engineers who later said they only looked for a new job because they were never promoted despite being overperformers. reply _vaporwave_ 40 minutes agoprev> a helpful order of magnitude estimate is that the hiring process all told costs the company approximately a year’s salary It feels weird to gloss over this since transaction costs this high have a huge impact on how the system should be designed. reply seiferteric 1 hour agoprevA lot of focus on employee performance, but relatively little on management performance. I always wonder how a once great company can slowly decline into irrelevance. Take yahoo for example, it could only be due to management failure over several decades right? How can companies optimize for management performance? reply bornfreddy 1 hour agoparentFiring 10% each year would be a great start in many companies. ;) reply TrainedMonkey 1 hour agoprevEmployee performance MEASUREMENT appears to be Gaussian distributed. To my first simple, and let's be real probably somewhat wrong, approximation there are roughly 3 things that go into it. 1. There is a certain skill in communicating all the important things you've done, we shall lump likability + politicking into this one for convenience. 2. There is a premium that is placed on shiny new features and saving the day heroics. A lot less priority is placed on refactoring and solving the problems before they require heroics. 3. Finally there are individual's technical and self-management skills. I.E. it's important to work on important things and be good at it. reply throwaway48476 2 hours agoprevSetting aside the issue of defining a function for 'employee performance', this glosses over the invisible interactions. An employee in a dysfunctional organization will perform worse than if they were in a well functioning one because they don't have to waste time dealing with people and processes that are a hindrance. reply wing-_-nuts 2 hours agoprevOne reason I'd never work for a company with a 'bottom 10% gets PIP'd' mentality is that it directly conflicts with my goal of self development. Of course I want to be on a great team where everyone performs better than I do. That's how I hone my craft! It just seems really wasteful to have to cull the bottom 10% of every team, even if that team is performing well. I wish there was a list of companies that subscribed to that mentality, so I could avoid them. reply warrentr 2 hours agoprevIn the work rules book about google, Bock claims (apparently using a lot of real data from google) that employee performance follows a power law distribution. reply philipov 1 hour agoprev> How much revenue do you think a janitor or café staffer generates? Close to zero. The same goes for engineering. Someone has to do the unglamorous staff, or you end up with a dysfunctional company, with amazing talent (on paper). If the company would be dysfunctional without that janitor or software engineer, and not bring in as much revenue as a result, it sounds like the model that attributes close to zero revenue to them is already dysfunctional. If the company can't function without the janitor, then a significant portion of the revenue of the company should be attributed to them. reply sangnoir 1 hour agoparentSound like you're expecting employers to strive for fairness. Instead, they are striving for profits for the capital class. The labor class gets the minimum possible amount to reach the shareholders primary goal. reply philipov 1 hour agorootparentIt sounds like you're confusing what they do currently and what the system should be set up to encourage instead. That things are broken right now is not a valid argument in favor of the status quo. The point you make only proves why it is so important that unions should have as much economic power as corporations do, so that the buy and sell sides of the labor market have negotiation parity. reply sangnoir 1 hour agorootparentI'm being descriptive, bot prescriptive: I'm stating what the priorities are under a capitalist system without the rose-colored glasses offered by the Just-world fallacy. reply philipov 1 hour agorootparentIn a well-functioning capitalistic system, the sell side of the labor market has equal power with the buy side. When the buy and sell sides of a market have a huge power imbalance, this leads to market failure, which is contrary to the goals of a capitalist system, as it results in inefficient allocation of capital. reply sangnoir 50 minutes agorootparentWhere can one find examples of such a well-functioning capitalistic system? Or is it a thought-experiment reply xmly 1 hour agoprevWell, managers are trying to make it Gaussian, but underlying is actually power law. reply dmurray 2 hours agoprev> For what it’s worth, human height is also Gaussian, and that’s correlated with workplace success. Height is generally not considered to be Gaussian and this is exactly the kind of statistics mistake the author seems to be accusing employers of. Adult height is somewhere between Gaussian and bimodal. reply timdellinger 2 hours agoparentFair enough. Perhaps better stated as \"adult human height is approximately Gaussian for a given biological sex\", with an asterisk that environmental factors stretch the distribution. I love the anecdote that people born in the American colonies came back to England to visit family, and were remarkably taller compared to their cousins due to environmental factors. reply irrational 1 hour agoprevIs it Q4 at a lot of companies? How many companies align their fiscal calendar with the yearly calendar? Our Q4 is March-May. reply spyckie2 1 hour agoprevSo… 1) treat poor performers as bad hires and ignore them in your dataset 2) treat 10x performers as needing to be promoted and also ignore them in your data 3) treat everyone else as relatively equal …and use “Pareto distribution” and “no one has mentioned this before” to write a blog post? Is the point of the article to get people who disagree with 10% corporate culling a pseudo intellectual economic buzzword argument to stroke their hatred of an inefficient hr practice? If so: 1) 10% culling in performance review is a mechanism to cull “bad hires”. I find it difficult to understand how the author can argue it’s a bad practice and then state that you cull bad hires from your dataset without thinking that they are the same thing or at least largely overlapping. 2) If the author is proposing to separate performance review, culling bad hires, and promotions, into 3 separate systems and assume no overlap, he should think through the structural issues more. While it’s possible to design a management structure where the organization is at a constant state of no bad hires, all 10xers promoted, that is putting a lot of responsibility on individual managers to run review, culling and promotion by themselves at a very high level. It’s brittle - a few bad managers not running the system can easily leave your organization bloated with bad hires and no fallback (fallback = performance review process). 3) The system of performance review is equally about risk management to the business as it is about rewarding your employees. IMO, the author’s framing simplifies the problem too much and pushes the complexity out for other people to deal with. It’s the kind of thinking that is damaging to organizations… I wonder if there is a process to cull this kind of thinking from your org… wait what time of year is it?? reply nonameiguess 2 hours agoprevIt's worth hammering on this point as much as possible hoping a few people listen, but there is at least one other important point about employee performance. If you're allocating bonuses, a single year's performance is probably a good way to do that, assuming you can accurately measure it. When you're talking retention and promotion, though, you're making a prediction of future performance, possibly at a variety of different jobs. That is even harder to do and more poorly reflected in the last year's results. You have some analogies to sports performance in this article, and you see this kind of thing all the time there. Guy does great in a single year, gets a huge, possibly long-term contract, then tanks. On the other hand, one of the better dynasties of the past decade was accomplished by the Golden State Warriors in the US NBA thanks to underpaying one of the all-time great players in NBA history because he suffered a series of ankle injuries early in his career and scared off other suitors. Single-year performance isn't necessarily reflective of a person's true mean abilities, and their place in the Pareto distribution won't be the same at all levels of advancement and responsiblity, either. The problem, from a company's perspective, is you probably need to retain everyone at least five years, and actually give them a wide variety of assignments in that time, to really get any usable data about their long-term prospects. reply stego-tech 2 hours agoparentLiterally this. I’ve been banging on about this my entire career, not that corporate leaders tend to listen to the riff-raff. Especially in tech companies, they tend to only evaluate promotions and raises based on the past half-year of work, rather than a repeated pattern of successes across a diverse array of tasks and backgrounds over a significant period of time (years); even then, you only get the promotion if you’re on the right team, doing the right work, at the right time, and for the right leader. This leads to otherwise stellar performers going elsewhere, because the janitors, maintainers, and firefighters in an organization never get properly rewarded, respected, or recognized by leaders. Said leaders pass this off as “bad performers”, failing to realize the importance of superb talent working on less-than-stellar projects that keep the company running efficiently. The only people who benefit from performance reviews are shareholders whose price pops when layoffs happen, and those who game the system for their own political ends. Top talent never really thrives in these, because they’re too busy doing actually meaningful and important work. reply hermanradtke 2 hours agoparentprev> On the other hand, one of the better dynasties of the past decade was accomplished by the Golden State Warriors in the US NBA thanks to underpaying one of the all-time great players in NBA history because he suffered a series of ankle injuries early in his career and scared off other suitors. In case people want to read more about this: https://www.essentiallysports.com/nba-active-basketball-news... reply timdellinger 2 hours agoparentprevInterestingly enough, sports salaries are Pareto-distributed, which says something about how valuable (as assessed by the marketplace) each player is https://marginalrevolution.com/marginalrevolution/2024/08/go... reply datadrivenangel 2 hours agoprevIf you assume that people are promoted to their level of incompetence -- terminal responsibility level, then you would expect that level adjusted performance should approach a Gaussian? reply riehwvfbk 2 hours agoparentNo, because there simply aren't enough high-level employees at the top in any given company for a meaningful sample. You'd have to compare across companies; I guess the stock market does that indirectly. reply Joel_Mckay 2 hours agoprev\"Hey wait - is [arbitrary metrics] Gaussian distributed?\" =3 reply riazrizvi 6 minutes agoparentThis whole thread smh. It feels like a military power convinced it can win a war by flying around in airplanes at 30,000’ and they are here vigorously discussing their insane tactics. It’s time for me to leave Silicon Valley. reply bparsons 2 hours agoprevUnless you are measuring the output of people on simple assembly lines, it is very difficult to define \"performance\". In a properly functioning team, people perform different, discrete roles which are probably not entirely understood by other team members or management. reply uoaei 45 minutes agoprevI suspect you can dig into any metric here and find that they are explicitly determined in terms of an assumption of underlying normality. reply AtlasBarfed 1 hour agoprev1) performance reviews are never aligned with employee value, because companies are strongly invested to take excess production from employees and transfer it to management, secondarily shareholders 2) the are also not aligned with the replacement cost of employees because the religion of management is that labor is effortlessly replaceable and low value 3) employee retention is not aligned with corporate performance in Machiavellian middle management, it is aligned with manager promotion for things like loyalty and maintaining fiefdom power, budgetary size, headcount, etc 4) there are no absolute or ever directly derived metrics in software development that have ever worked, to say nothing of other positions Those are off the top of my head. reply 29athrowaway 1 hour agoprevI guess developers should have a pay structure similar to sales when you make part of your money from bonuses tied to results. But those results are hard to evaluate because shipping something fast can have bugs found after the reward date. reply morkalork 2 hours agoprevIf you ever look at tranditional human-driven sales data, you'll often see a small percentage of top performers absolutely dominating the total sales volume. So yes, employee performance is not Gaussian at all. reply xphilter 3 hours agoprev [–] Yeah good luck. I don’t think any hr decisions have ever been about data; it’s about following norms. If you can get the rand corp or heritage foundation to adopt this policy then maybe corporations would look into it. reply timdellinger 2 hours agoparentInterestingly enough, I remember in my younger days being inspired by Rand Corp's 1950's era game theory work on e.g. mutually assured destruction. It later occurred to me that I don't need to be employed by a think tank to write think pieces! That being said, I like to think that startups growing into large corporations have an opportunity to be better when it comes to things like performance management. reply hobs 2 hours agorootparentAs soon as the market actually incentivizes it, which it almost never does, it will get better. Most of the big companies just throw endless interviews, high pressure firings, and a lot of money at the problem and make the people below them solve the rest of the problems. They see how much they are paying for the mess, but any medium term effort is torpedoed because of all the other things the business focuses on (lack of resources for the process and training), and other powerful individuals who want to put their own brand on hiring and firing who have significantly more ego than sense. reply thrance 2 hours agoparentprev [–] The Heritage Foundation would probably fire every competent employees and replace them with partisan sycophants, like they plan to do with America in Project 2025. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The article challenges the assumption that employee performance follows a Gaussian (normal) distribution, suggesting that this view may lead to outdated performance management practices in corporations.",
      "It critiques the practice of trimming the bottom 5% of employees, advocating for a focus on combined productivity rather than individual performance, and proposes that performance might follow a Pareto distribution, where a few employees contribute significantly more to output.",
      "The discussion encompasses various perspectives on performance evaluation, hiring practices, and the role of management in influencing employee success."
    ],
    "points": 180,
    "commentCount": 156,
    "retryCount": 0,
    "time": 1732547019
  },
  {
    "id": 42233565,
    "title": "A Day in the Life: The Global BGP Table",
    "originLink": "https://articles.foletta.org/post/2024-01-08-a-day-in-the-life-the-bgp-table/",
    "originBody": "A Day in the Life: The Global BGP Table Nov 12, 2024 Categories: C BGP Networking 22 minutes read Much has been written and a lot of analysis performed on the global BGP table over the years, a significant portion by the inimitable Geoff Huston. However this often focuses on is long term trends, like the growth of the routing table or the adoption of IPv6 , dealing with time frames of of months or years. I was more interested in what was happening in the short term: what does it look like on the front line for those poor routers connected to the churning, foamy chaos of the interenet, trying their best to adhere to Postel’s Law? What we’ll look at in this article is “a day in the life of the global BGP table”, exploring the intra-day shenanigans with an eye to finding some of the ridiculous things that go on out. We’ll focus in on three key areas: General behaviour over the course of the day Outlier path attributes Flappy paths As you’ll see, we end up with more questions than answers, but I think that’s the hallmark of good exploratory work. Let’s dive in. Let the Yak Shaving Begin The first step, as always, is to get some data to work with. Parsing the debug outputs from various routers seemed like a recipe for disaster, so instead I did a little yak-shaving. I went back to a half-finished project BGP daemon I’d started writing years ago and got it into a working state. The result is bgpsee, a multi-threaded BGP peering tool for the CLI. Once peered with another router, all the BGP messages - OPENs, KEEPALIVES, and most importantly UPDATEs - are parsed and output as JSON. For example, heres one of the BGP updates from the dataset we’re working with in this article: { \"recv_time\": 1704483075, \"id\": 12349, \"type\": \"UPDATE\", \"nlri\": [ \"38.43.124.0/23\" ], \"withdrawn_routes\": [], \"path_attributes\": [ { \"type\": \"ORIGIN\", \"type_code\": 1, \"origin\": \"IGP\" }, { \"type\": \"AS_PATH\", \"type_code\": 2, \"n_as_segments\": 1, \"path_segments\": [ { \"type\": \"AS_SEQUENCE\", \"n_as\": 6, \"asns\": [ 45270, 4764, 2914, 12956, 27951, 23456 ] } ] }, { \"type\": \"NEXT_HOP\", \"type_code\": 3, \"next_hop\": \"61.245.147.114\" }, { \"type\": \"AS4_PATH\", \"type_code\": 17, \"n_as_segments\": 1, \"path_segments\": [ { \"type\": \"AS_SEQUENCE\", \"n_as\": 6, \"asns\": [ 45270,4764, 2914, 12956, 27951, 273013 ] } ] } ] } Collected between 6/1/2024 and 7/1/2024, the full dataset consists of 464,673 BGP UPDATE messages received from a peer (many thanks to Andrew Vinton) with a full BGP table. Let’s take a look at how this full table behaves over the course of the day. Initial Send, Number of v4 and v6 Paths When you first bring up a BGP peering with a router you get a big dump of of UPDATEs, what I’ll call the ‘first tranche’. It consists of all paths and associated network layer reachability information (NLRI, or more simply ‘routes’) in the router’s BGP table. After this first tranche the peering only receives UPDATEs for paths that have changed, or withdrawn routes which no longer have any paths. There’s no structural difference between the first tranche and the subsequent UPDATEs, except for the fact you received the first batch in the first 5 or so seconds of the peering coming up. Here’s a breakdown of the number of distinct paths received in that first tranche, separated by IP version: It’s important to highlight that this is a count of BGP paths, not routes. Each path is a unique combination of path attributes with associated NLRI information attached, sent in a distinct BGP UPDATE message. There could be one, or one-thousand routes associated with each path. In this first tranche the total number of routes across all of these paths is 949483. A Garden Hose or a Fire Hose? That’s all we’ll look at in the first tranche, we’ll focus our attention from this point on to the rest of the updates received across the day. The updates aren’t sent as a real-time stream, but in bunches based on the Route Advertisement Interval timer, which for this peering was 30 seconds. Here’s a time-series view of the number of updates received during the course of the day: For IPv4 paths you’re looking on average at around 50 path updates every 30 seconds. For IPv6 it’s slightly lower, at around 47 path updates. While the averages are close, the variance is quite different, a standard deviation of 64.3 and 43 for v4 and v6 respectively. Instead of looking at the total count of udpates, we can instead look at the total aggregate IP address change. We do this by adding up the total amount of IP addresses across all updates for every 30 second interval, then take the log2() of the sum. So for example: a /22, a /23 and a /24 would be \\(log_2(2^{32-22} + 2^{32-23} + 2^{32-24})\\) Below is the log2() IPv4 address space, viewed as a time series and as a density plot. It shows that on average, every 30 seconds, around 2^16 IP addresses (i.e a /16) change paths in the global routing table, with 95% of time time the change in IP address space is between \\(2^{20.75}\\) (approx. a /11) and \\(2^{13.85}\\) (approx. a /18). What is apparent in both the path and IP space changes over time is that there is some sort of cyclic behaviour in the IPv4 updates. To determine the period of this cycle we can use an ACF or autocorrelation plot. We calculate the correlation between the number of paths received at time \\(y_t\\) versus the number received at \\(y_{t-{1,t-2,…,t-n}}\\) lags. I’ve grouped the updates together into 1 minute intervals, so 1 lag = 1 minute. There is a strong correlation in the first 7 or so lags, which intuitively makes sense to me as path changes can create other path changes as they propagate around the world. But there also appears to be strong correlation at lags 40 and 41, indicating some cyclic behaviour every forty minutes. This gives us the first question which I’ll leave unanswered: What is causing the global IPv4 BGP table have a 40 minute cycle?. Prepending Madness If you’re a network admin, there’s a couple of different ways you can influence how traffic enters your ASN. You can use longer network prefixes, but this doesn’t scale well and you’re not being a polite BGP citizen. You can use the MED attribute, but it’s non-transitive so it doesn’t work if you’re peered to multiple AS. The usual go-to is to modify the AS path length by prepending your own AS one or more times to certain peers, making that path less preferable. In chaos of the global routing table, some people take this prepending too far. This has in the past caused large, global problems. Let’s take a look at the top 50 AS path lengths for IPv4 and IPv6 updates respectively: What stands out is the difference between IPv4 and IPv6. The largest IPv4 path length is 105, which is still pretty ridiculous given the fact that the largest non-prepended path in this dataset has a length of 14. But compared to the IPv6 paths it’s outright sensible: top of the table for IPv6 comes in at a whopping 599 ASes! An AS path is actually made up of one or more AS sets or AS sequences, each of which have a maximum length of 255. So it’s taken three AS sequences to announce those routes. Here’s the longest IPv4 path in all it’s glory with its 105 ASNs. It originated from AS149381 “Dinas Komunikasi dan Informatika Kabupaten Tulungagung” in Indonesia. [1] \"45270 4764 9002 136106 45305 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381 149381\" We see that around 6 hours and 50 minutes later they realise the error in their ways and announce a path with only four ASes, rather than 105: recv_time time_difference id as_path_length type nlri 2024-01-06 06:31:18 NA 66121 105 UPDATE 103.179.250.0/24 2024-01-06 13:21:35 6.84 280028 4 UPDATE 103.179.250.0/24 Here’s the largest IPv6 path, with its mammoth 599 prefixes; I’ll let you enjoy scrolling to the right on this one: [1] \"45270 4764 2914 29632 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 8772 200579 200579 203868\" Interestingly it’s not the originator that’s prepending, but as8772 ‘NetAssist LLC’, an ISP out of Ukraine prepending to make paths to asn203868 (Rifqi Arief Pamungkas, again out of Indonesia) less preferable. Why is there such a difference between the largest IPv4 and IPv6 path lengths? I had a couple of different theories, but then looked at the total number of ASNs in all positions for those top 50 longest paths, and it became apparent what was happening: Looks like they let the junior network admin at NetAssist on to the tools too early! Path Attributes Each BGP update consist of network layer reachability information (routes) and path attributes. For example AS_PATH, NEXT_HOP, etc. There are four kinds of attributes: Well-known mandatory Well-known discretionary Optional transitive Optional non-transitive Section 5 of RFC4271 has a good description of all of these. What we can do is take a look at the number of attributes we’ve seen across all of our IPv4 paths, placing this on on a log scale to make it easier to view: The well-known mandatory attributes, ORIGIN, NEXT_HOP, and AS_PATH, are present in all updates, and have the same counts. There’s a few other common attributes (e.g. AGGREGATOR), and some less common ones (AS_PATHLIMIT and ATTR_SET). However some ASes have attached attribute 255 - the reserved for development attribute - to their updates. At the time of receiving the updates my bgpsee daemon didn’t save value of these esoteric path attributes. But using routeviews.org we can see that some ASes are still announcing paths with this attribute, and we can observe the raw bytes of its value: - AS265999 attrib. 255 value: 0000 07DB 0000 0001 0001 000A FF08 0000 0000 0C49 75B3 - AS10429 attrib. 255 value: 0000 07DB 0000 0001 0001 000A FF08 0000 0003 43DC 75C3 - AS52564 attrib. 255 valuue: 0000 07DB 0000 0001 0001 0012 FF10 0000 0000 0C49 75B3 0000 0000 4003 F1C9 Three different ISPs, all announcing paths with this strange path attribute, and raw bytes of the attribute having a similar structure. This leads us to the second question which I’ll leave here unanswered: what vendor is deciding it’s a good idea to use this reserved for development attribute, and what are they using it for?. Flippy-Flappy: Who’s Having a Bad Time? Finally, let’s see who’s having a bad time: what are the top routes that are shifting paths or being withdrawn completely during the day. Here’s the top 10 active NLRIs with the number of times the route was included in an UPDATE: nlri update_count 140.99.244.0/23 2596 107.154.97.0/24 2583 45.172.92.0/22 2494 151.236.111.0/24 2312 205.164.85.0/24 2189 41.209.0.0/18 2069 143.255.204.0/22 2048 176.124.58.0/24 1584 187.1.11.0/24 1582 187.1.13.0/24 1580 Looks like anyone on 140.99.244.0/23 was having a bad time during this day. This space is owned by a company called EpicUp… more like EpicDown! *groan*. Graphing the updates and complete withdraws over the course of the day paints a bad picture The top graph looks like a straight line, but that’s because this route is present in almost every single 30 second block of updates. There are 2,879 30-second blocks and it’s present as either a different path or a withdrawn route in 2,637 of them, or 92.8%! We know the routes is flapping, but how is it flapping, and who is to blame? The best way to visualise this is a graph, with the ASNs in all paths to that network as nodes and edges showing the pairs of ASNs in the paths. I’ve colourised the edges by how many updates were seen with each pair of ASes, binned into groups of 300: What a mess! You can make out the primary path down the centre through NTT (2914) and Lumen/Level3 (3356), but for whatever reason (bad link? power outages? router crashing?) the path is moving between these tier 1 ISPS and others, including Arelion (1299) and PCCW (3419). While it’s almost impossible to identify the exact reason for the route flapping using this data only, what it does show is the amazing peering diversity of modern global networks, and the the resiliency of a 33 year old routing protocol. Just The Beginning There’s a big problem with a data set like this: there’s just too much to look at. I needed to keep a lid on it so this article didn’t balloon out to 30,000 words, but there’s another five rabbit holes I could have gone down. That’s not including the the questions I’ve left unanswered. With the global BGP table, you’ve got a summary of an entire world encapsulated in a few packets. Your BGP updates could could be political unrest, natural phenomena like earthquakes or fires, or simply a network admin’s fat finger. You’ve got the economics of internet peering, and you’ve got the human element of different administrators with different capabilities coming together to bring up connectivity. And somehow it manages to work, well, most of the time. There’s something both bizarre and beautiful about seeing all of that humanity encapsulated and streamed as small little updates into your laptop.",
    "commentLink": "https://news.ycombinator.com/item?id=42233565",
    "commentBody": "A Day in the Life: The Global BGP Table (foletta.org)158 points by gjf 13 hours agohidepastfavorite11 comments kortilla 5 hours agoNice article. That flapping from EpicUp 140.99.244.0/23 prefix should have been subject to route dampening. This is per peer or per prefix rate limiting typically enforced on all peers by ISPs to prevent this exact issue of a single prefix making up a significant portion of the global BGP churn. I’m unconvinced of the correlation between the updates that the author attributed to knock on effects. It would be pretty janky to have your advertisements be based on the path to other autonomous systems’ prefixes, especially unstable ones. I don’t think there is a 40 minute periodicity either (at least there wasn’t 8 years ago when I was deep in the BGP world). Smells like what this dataset happened to show either by luck or because of the network the author was getting the BGP feed from. If you dig into the data and look at which AS’s and prefixes are experiencing changes, you’ll find it’s all over the place and there isn’t really any bigger pattern. On any given day there are usually a few noisy ISPs because of bad circuits or misconfigurations. Then there are new prefixes flapping in and out as a new thing is brought online for the first time, etc. Then sprinkle in path changes for regular draining maintenance, etc. It’s simultaneously both fascinating and a little horrifying how a little ISP in Kansas experiencing a fiber consuming backhoe shows up on routers in Perth. Yet the frequency of updates is kept to <10hz globally through tons of hand tuned policies. reply benjojo12 1 hour agoparentRoute dampening has mostly fallen out of fashion with networks these days. Most setups were horribly misconfigured and (most) routers are no longer extremely CPU starved as they once were, That doesn't mean that it does not still exist of course, when I did bgp battleships ( https://blog.benjojo.co.uk/post/bgp-battleships ) I found that 3356 (at the time) was doing route dampening, so play had to be paused for a while. reply benjojo12 59 minutes agoprevBased on some quick sleuthing, I would assume that the 0xff reserved BGP attribute is likely a huawei quirk. Almost all of the 0xff's visible to bgp.tools (hi) follow the same format as the one in the post, and some of those networks with them seem to be running huawei kit. reply chriscjcj 2 hours agoprev25 years ago, I worked for a small ISP (back when there was such a thing.) When I started there, we had one upstream ISP. I was charged with getting us multihomed. I found some tutorials written by Avi Freedman (1). I don't know what I would have done without him. He made an intimidating topic approachable. Thanks to him, I got us a /20 from ARIN and advertised our routes to two different peers. It was fascinating to learn how it all worked. And the more I learned about it, the more amazed I was that it worked at all. (1) http://avi.freedman.net/ Avi reply nickstinemates 2 hours agoparentI used to work for Avi at Kentik. He is a smart, nice person and remembered writing these articles fondly to help people out! reply throw0101a 6 hours agoprevIf anyone wants to learn about BGP (especially day-to-day stuff for peering scenarios), the Network Startup Resource Center out of U.Oregon has a good series of videos going through things: * https://learn.nsrc.org/bgp reply CJefferson 11 hours agoprevI learnt quite a few things I didn’t know about BGP from this article, probably most interesting how chaotic it is! I’d definitely be interested to read some follow-ups, diving into more details. reply zokier 2 hours agoprevWhat is the easiest way for average joe to get hands on BGP data? If I wanted to try do similar analysis and don't happen to have a friend at ISP. reply throw0101a 2 hours agoparent* http://archive.routeviews.org * https://www.ripe.net/analyse/internet-measurements/routing-i... * https://lukasz.bromirski.net/post/bgp-w-labie-3/ reply mike_d 16 minutes agoparentprevI have had a project on the back burner for about a year now to offer a BGP feed via a websocket to facilitate people playing around and doing research without allowing them to accidently spew crap into the DFZ. Shoot me an email if you are interested and I'll try to get it spun up this week. reply nhggfu 3 hours agoprev [–] /me thinks to himself : real nice font on that page reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article delves into the daily fluctuations of the global BGP (Border Gateway Protocol) table, focusing on short-term behaviors such as unusual path attributes and flapping paths.",
      "Using a tool called bgpsee, the author analyzes BGP messages to uncover insights into path updates, cyclic behaviors, and extreme AS (Autonomous System) path lengths.",
      "The exploration highlights the complexity and resilience of the BGP system, emphasizing the intricate dynamics of global internet routing despite raising more questions than answers."
    ],
    "commentSummary": [
      "The article addresses the global Border Gateway Protocol (BGP) table, focusing on issues such as route flapping and the practice of route dampening to mitigate excessive BGP churn.",
      "A user highlights the flapping of the EpicUp 140.99.244.0/23 prefix, suggesting it should be dampened, while another notes that route dampening is less common now due to past misconfigurations and enhanced router capabilities.",
      "The discussion includes BGP quirks, historical insights from Internet Service Providers (ISPs), and resources for those interested in analyzing BGP data, with suggestions for potential projects."
    ],
    "points": 158,
    "commentCount": 11,
    "retryCount": 0,
    "time": 1732513305
  },
  {
    "id": 42232289,
    "title": "Wildlife monitoring technologies used to intimidate and spy on women",
    "originLink": "https://www.cam.ac.uk/research/news/wildlife-monitoring-technologies-used-to-intimidate-and-spy-on-women-study-finds",
    "originBody": "Your cookie choices Cookies are little files that we save on your device to remember your preferences. We use necessary cookies to make our site work. We use site usage measurement cookies to analyse anonymised usage patterns, to make our websites better for you. You may choose to opt-in to use optional cookies for personalisation and to remember your social marketing preferences. Give me more information Personalisation settings — these cookies allow you to tailor your experience Social marketing preferences — these cookies do things like measure how you view media content on our website using third-party services and websites Save my choices Accept all cookies Decline optional cookies View menu Study at Cambridge About the University Research at Cambridge Quick links For Cambridge students For staff For alumni For our researchers Business and enterprise Colleges and Departments Give to Cambridge Libraries Museums and collections Search Search Search Study at Cambridge Undergraduate Courses Applying Events and open days Fees and finance Postgraduate Postgraduate courses How to apply Fees and funding Postgraduate events International students Continuing education Executive and professional education Courses in education Close About the University How the University and Colleges work Term dates History Map Visiting the University Annual reports Equality and diversity News A global university Events Public engagement Jobs Give to Cambridge Close Research at Cambridge Close For Cambridge students For staff For alumni For our researchers Business and enterprise Colleges and Departments Give to Cambridge Libraries Museums and collections Home Research News Wildlife monitoring technologies used to intimidate and spy on women, study finds Research Menu Research home News Our people Spotlights About research Back to section home About research About research overview Animal research About research Animal research Animal research overview Overseeing animal research Animal research Overseeing animal research Overseeing animal research overview The Animal Welfare and Ethical Review Body Animal welfare and ethics Report on the allegations and matters raised in the BUAV report What types of animal do we use? Animal research What types of animal do we use? What types of animal do we use? overview Chickens Guinea pigs Equine species Mice Naked mole-rats Non-human primates (marmosets) Other birds Rats Sheep Xenopus Zebrafish Non-technical summaries Animal Welfare Policy Alternatives to animal use FAQs Further information Strategic Initiatives & Networks Interdisciplinary Research Centres Research culture Nobel Prize Open access Horizons magazine Research integrity Energy sector partnerships Business and enterprise Our impact Wildlife monitoring technologies used to intimidate and spy on women, study finds Camera traps and drones deployed by government authorities to monitor a forest in India are infringing on the privacy and rights of local women. Nobody could have realised that camera traps put in the Indian forest to monitor mammals actually have a profoundly negative impact on the mental health of local women who use these spaces. Trishant Simlai Remotely operated camera traps, sound recorders and drones are increasingly being used in conservation science to monitor wildlife and natural habitats, and to keep watch on protected natural areas. But Cambridge researchers studying a forest in northern India have found that the technologies are being deliberately misused by local government and male villagers to keep watch on women without their consent. Cambridge researcher Dr Trishant Simlai spent 14 months interviewing 270 locals living around the Corbett Tiger Reserve, a national park in northern India, including many women from nearby villages. His report, published today in the journal Environment and Planning F, reveals how forest rangers in the national park deliberately fly drones over local women to frighten them out of the forest, and stop them collecting natural resources despite it being their legal right to do so. The women, who previously found sanctuary in the forest away from their male-dominated villages, told Simlai they feel watched and inhibited by camera traps, so talk and sing much more quietly. This increases the chance of surprise encounters with potentially dangerous wildlife like elephants and tigers. One woman he interviewed has since been killed in a tiger attack. The study reveals a worst-case scenario of deliberate human monitoring and intimidation. But the researchers say people are being unintentionally recorded by wildlife monitoring devices without their knowledge in many other places - even national parks in the UK. “Nobody could have realised that camera traps put in the Indian forest to monitor mammals actually have a profoundly negative impact on the mental health of local women who use these spaces,” said Dr Trishant Simlai, a researcher in the University of Cambridge’s Department of Sociology and lead author of the report. “These findings have caused quite a stir amongst the conservation community. It’s very common for projects to use these technologies to monitor wildlife, but this highlights that we really need to be sure they’re not causing unintended harm,” said Professor Chris Sandbrook, Director of the University of Cambridge’s Masters in Conservation Leadership programme, who was also involved in the report. He added: “Surveillance technologies that are supposed to be tracking animals can easily be used to watch people instead – invading their privacy and altering the way they behave.” Many areas of conservation importance overlap with areas of human use. The researchers call for conservationists to think carefully about the social implications of using remote monitoring technologies – and whether less invasive methods like surveys could provide the information they need instead. Intimidation and deliberate humiliation The women living near India’s Corbett Tiger Reserve use the forest daily in ways that are central to their lives: from gathering firewood and herbs to sharing life’s difficulties through traditional songs. Domestic violence and alcoholism are widespread problems in this rural region and many women spend long hours in forest spaces to escape difficult home situations. The women told Simlai that new technologies, deployed under the guise of wildlife monitoring projects, are being used to intimidate and exert power over them - by monitoring them too. “A photograph of a woman going to the toilet in the forest – captured on a camera trap supposedly for wildlife monitoring - was circulated on local Facebook and WhatsApp groups as a means of deliberate harassment,” said Simlai. He added: “I discovered that local women form strong bonds while working together in the forest, and they sing while collecting firewood to deter attacks by elephants and tigers. When they see camera traps they feel inhibited because they don’t know who’s watching or listening to them – and as a result they behave differently - often being much quieter, which puts them in danger.” In places like northern India, the identity of local women is closely linked to their daily activities and social roles within the forest. The researchers say that understanding the various ways local women use forests is vital for effective forest management strategies. Reference: Simlai, T. et al: ‘The Gendered Forest: Digital Surveillance Technologies for Conservation and Gender-Environment relationships.’ November 2024. DOI:10.17863/CAM.111664 The text in this work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Images, including our videos, are Copyright ©University of Cambridge and licensors/contributors as identified. All rights reserved. We make our image and video content available in a number of ways – on our main website under its Terms and conditions, and on a range of channels including social media that permit your use and sharing of our content under their respective Terms. Read this next New long-term collaboration with Suzano begins with a £10 million donation to support conservation and sustainability education and research Cambridge is forging a future for our planet Public invited to chat to museum animals in novel AI experiment Cambridge conservation and sustainable business leaders prepare for COP16 Media enquiries Jacqueline Garget External Affairs and Communications Share reddit Published 25 Nov 2024 Search research Keyword search Go Sign up to receive our weekly research email Our selection of the week's biggest Cambridge research news sent directly to your inbox. Enter your email address, confirm you're happy to receive our emails and then select 'Subscribe'. Email I wish to receive a weekly Cambridge research news summary by email. The University of Cambridge will use your email address to send you our weekly research news email. We are committed to protecting your personal information and being transparent about what information we hold. Please read our email privacy notice for details. Subjects Biodiversity conservation digital technology sociology People Chris Sandbrook Trishant Simlai Places Department of Geography Department of Sociology University of Cambridge Conservation Research Institute (UCCRI) School of the Physical Sciences School of the Humanities and Social Sciences Connect with us Facebook Instagram LinkedIn X YouTube © 2024 University of Cambridge Contact the University Accessibility statement Freedom of information Privacy policy and cookies Statement on Modern Slavery Terms and conditions University A-Z Study at Cambridge Undergraduate Postgraduate Continuing education Executive and professional education Courses in education About the University How the University and Colleges work Give to Cambridge Jobs Maps Visiting the University Cambridge University Press & Assessment Research at Cambridge Research news About research at Cambridge Public engagement Spotlight on...",
    "commentLink": "https://news.ycombinator.com/item?id=42232289",
    "commentBody": "[flagged] Wildlife monitoring technologies used to intimidate and spy on women (cam.ac.uk)142 points by gnabgib 17 hours agohidepastfavorite78 comments dghlsakjg 16 hours ago> Nobody could have realised that camera traps put in the Indian forest to monitor mammals actually have a profoundly negative impact on the mental health of local women who use these spaces. Most women could have predicted that spycams in a park, run by a government in a country with known issues around women’s rights, would lead to issues. Even governments with incredibly strict rules and indelible audit trails struggle with men in government using their access to data to stalk women. India is not a country known for these things. reply ChrisMarshallNY 16 hours agoparentHere in NY, we had a [very short-term] governor, who used to be the Attorney General, get hoist by his own petard. While AG, he put in place, a monitoring regimen, that caught him, as Guv, using state funds to buy hookers and whatnot. For all I know, he might have gotten away with it, if he hadn’t been using state funds. It kinda ripped the lid off a bunch of fairly misogynistic attitudes, though. He didn’t last long, after that. reply Spooky23 14 hours agorootparentNah. A compliance officer at his bank filed a SAR because he was structuring wire transfers to bypass his reporting requirement. He wasn’t using state funds. The Feds started poking around, and voilà. The Southern District of NY US Attorney was a big game hunter for politicians, so his goose was cooked. Ironically, the lieutenant governor who replaced him came out swinging, disclosing that he did inhale, regularly had sex outside of his marriage, did cocaine and various other things. Lol. reply Semaphor 12 hours agorootparent> Ironically, the lieutenant governor who replaced him came out swinging, disclosing that he did inhale, regularly had sex outside of his marriage, did cocaine and various other things. Lol. Hah, how did he do? reply fsckboy 12 hours agorootparenthttps://en.wikipedia.org/wiki/Eliot_Spitzer_prostitution_sca... succeeded as governor by David Paterson, a blind man... nothing says a blind governor can't embezzle funds to spend on prostitutes, but perhaps it's less common? wikip: Paterson launched a campaign for a full term as governor in the 2010 New York gubernatorial election, but he announced on February 26, 2010, that he would bow out of the race. During the final year of his administration, Paterson faced allegations of soliciting improper gifts and making false statements; he was eventually fined in excess of $62,000 for accepting free New York Yankees tickets. He was not charged with perjury. He was succeeded as governor by https://en.wikipedia.org/wiki/Andrew_Cuomo_sexual_harassment... reply yieldcrv 14 hours agorootparentprevConsuming sex work isn’t misogynistic, by definition as it doesnt involve contempt or hate of women, sex workers have a voice too and don’t want to be marginalized by that assumption or dilution of that word Just a view I see lacking and underrepresented in tech spaces But if there are other things you’re referring to with that governor then definitely mention those, separately reply ChrisMarshallNY 6 hours agorootparentI don’t think it had that much to do with the hookers. I think a bunch of other behavior came to light, during the ensuing brouhaha. reply BadHumans 4 hours agorootparentprevBuying sex doesn't make you a misogynist but misogynist can and often do buy sex. reply binary132 4 hours agorootparentprevactually I see this opinion every time I read comments on any article even remotely touching on the subject in a tech forum. reply yieldcrv 2 hours agorootparentgreat, representation matters reply automatic6131 8 hours agorootparentprev>Consuming sex work isn’t misogynistic Something very much up for debate amongst leading scholars. I - personally - think buying sex is bad, and degrading to both parties. reply Cumpiler69 7 hours agorootparent>Something very much up for debate amongst leading scholars Who are those \"leading scholars\" and what gives them authority to be the judge what consenting adults do with their body for a living or for entertainment? reply mensetmanusman 7 hours agorootparentWhat gives anyone authority either way to say whether something is degrading? It comes down to consensus in practice. reply Cumpiler69 6 hours agorootparentExactly. Random people should stop trying to play \"morality police\" on consenting adults engaging in legal activities in their own private spaces in their private time. It's none of your concern what other people do. reply mensetmanusman 1 hour agorootparentPeople tend to not consent to all the laws imposed upon them at the moment of birth, so consent isn’t everything. reply cess11 5 hours agorootparentprevWhat do you mean, \"consenting adults\" and \"private spaces\"? It's transactional and commercial, someone is using money to get access to another's body, at least as exploitative as work generally is. It's something that wouldn't happen without the money, hence it obviously exerts some power in the relation. reply Cumpiler69 4 hours agorootparent>It's something that wouldn't happen without the money People never have sex, hook up or send nude pics of themselves without exchanging money? reply cess11 4 hours agorootparentYou're conflating what sex workers do with what people who feel lust and excitement and decide to get intimate do. You should spend some time with sex workers. Pretty much the first lesson in this line of work is that you act well and submit to the whims and wishes of your clients, and the second lesson is to put some hard limits on what you'll do or you'll be abused. It's generally an act, one person faking attraction or friendship or whatever and another person paying for it. Sometimes sex workers get to know clients personally, but outside porn where the 'client', i.e. the producer or whoever is paying, isn't the one you're fucking I've never heard about a sex worker initiating a non-paying relationship with a client. To answer your actual question, no, this is not a common type of behaviour. reply Cumpiler69 4 hours agorootparentYou're conflating sex workers with sex slaves. Nobody's forcing you to be a sex worker for them if the job is done within the confines of the law between consenting adults. Unemployment is low in the developed west, there are tens of thousands of other legal careers you can choose if you want to support yourself. There's no manufactured imbalance of power here since nobody's forcing you into sex work. You choosing to strip to gooners online for money is your voluntary choice as an adult so take responsibility for it and don't outsource it by blaming those paying for your life choices. reply vjk800 5 hours agorootparentprevBy stating that people's private business shouldn't concern others, you are also imposing a moral system on others. Throughout most of the history, and to many people even now, morality extends beyond what's observable to outsiders. See e.g. what most of the religions have to say on issues such as homosexuality or eating certain foods. I'm not saying I have the right answer to all of this either, I'm just pointing out that your \"morally neutral\" stance isn't as neutral as you'd like to think. reply HeatrayEnjoyer 5 hours agorootparentYour religion example isn't helping. reply Cumpiler69 5 hours agorootparentprev>By stating that people's private business shouldn't concern others, you are also imposing a moral system on others Only in mental gymnastics. Staying out of other people's private lives is not a question of my own morality but also the law in most western democracies. I am free to do whatever I want as long as my freedom doesn't negatively affect anyone else. If you're not affected by what I'm doing in private, why are you trying to involve yourself in it and act as a judge? reply Gud 2 hours agorootparentThat is just not the case. Try doing some illegal drug or something. reply ben_w 4 hours agorootparentprevYou're literally telling other people to stop doing stuff that you don't want them doing, specifically the act of telling others what to do. You're allowed to do that, and we're allowed to point out that this doesn't work in practice and that the failure in practice is itself why we're not surprised or even upset about the hypocrisy. reply Cumpiler69 4 hours agorootparent>You're literally telling other people to stop doing stuff that you don't want them doing Telling people to respect the privacy you're awarded by law is nto telling them what to do. reply ben_w 4 hours agorootparentYeah it is. It literally is. The laws themselves were written to tell people what to do. That's why they come with actual punishments if you break them, not merely arguements like on the internet. And some of those laws do actually ban various acts associated with prostitution, though the stated reasons for such laws are also often out of sync with the consequences given what is easiest to prosecute. reply wizzwizz4 5 hours agorootparentprev> See e.g. what most of the religions have to say on issues such as homosexuality or eating certain foods. Can you name a specific religion? I can't think of any, but maybe that's because I misunderstand the religions. reply ben_w 4 hours agorootparentAny that takes Leviticus seriously will have issues with both food and male homosexuality, though I'd point out that not all denominations of Christianity do so about homosexuality and most Christians expressly reject the bits about food. People can be weirdly selective about such things, which is why I've not seen any suggestion by current christians that sacrificing a bird and dipping another bird in it's blood and then then shaking the blood soaked bird on the patient is a valid cure for leprosy. (Chapter 14:1-7) Just realised that the text in Leveticus if taken literally says women are not allowed to have straight sex, only gay sex: \"\"\"You shall not lie with a male as with a woman; it is an abomination\"\"\" - Leviticus 18:22 That said, translations are more of an art than a science, that's why there are so many of them. It might instead be interpreted as a statement against being bisexual like me, where either gay or straight is fine but doing both is what the writer (from the Watsonian perspective, god) doesn't like. reply hnlmorg 6 hours agorootparentprevI actually know people who have worked in various different professions in the sex industry and it really depends on an individual to individual basis just how “degrading” it is. There are obviously people who are exploited. So those instances should be treated with the full severity of the law. However there are genuinely others who enjoy the work and find it more empowering than degrading. So it’s not just an industry full of stereotypical sleaze bags exploiting vulnerable women. I’m not making an argument for nor against sex work here by the way. Just saying that you cannot treat this kind of topic with Boolean arguments like you have done. It’s a hell of a lot more complex than that. In my opinion what we really should be doing is spending more time making this industry safer for those that choose it, rather than pretending it can be eradicated and thus pushing it into dark corners where vulnerable individuals cannot be kept safe. reply ChrisMarshallNY 6 hours agorootparentAgreed. Also know a number of ex-sex workers. Some have truly horrific stories, like being gang-raped at age 12, and forced into a lifetime of prostitution. Others, actually chose the work, and did well. Then, there’s trafficking, which is often a nightmare situation. Not all the victims (or volunteers) are women, either. I think that the fact the profession is often illegal, makes things considerably worse, all around. It pretty much guarantees that bad guys/gals will be running things, and there will be no oversight. reply voidfunc 4 hours agorootparentAlso have known a number of sex workers. Some were just part time dominatrixes, some full time anything goes girls. Most enjoyed the work. I think all were voluntary? Few last in it long-term. The ones that do often legitimize into doing fetish content videos and VIP escort services as they get older or they keep a small set of good clients. All of them also acknowledged it is a dangerous trade with plenty of horror stories. reply yieldcrv 2 hours agorootparentprevInterestingly, none of that fits the definition of misogynistic reply raxxorraxor 4 hours agoparentprevThese are just accepted casualties of those pushing for video surveillance. We also know about the chilling effects of surveillance. Nobody seems to care. reply johnisgood 6 hours agoparentprevWhy is it limited to women in general? It affects everyone. And I wonder in what cases it is an issue for those, because we have cameras everywhere and people are fine with it. > Camera traps and drones deployed by government authorities to monitor a forest in India are infringing on the privacy and rights of local women. Why women specifically? Would it not affect me?! > The women, who previously found sanctuary in the forest away from their male-dominated villages, told Simlai they feel watched and inhibited by camera traps, so talk and sing much more quietly. This does not explain it. Men and women both do this. My Indian friend just went to visit a \"retreat place\" or whatever it is called for a week, there are both men an women. I would not want to be recorded in the forest either, nor anywhere else, but it is a \"fact of life\" I cannot do against. :| reply sabbaticaldev 6 hours agorootparent> Why is it limited to women in general? It affects everyone John, you should ask this to men, why do men get obsessed over women and stalk them much more often? > Why women specifically? Would it not affect me?! do you have a history of being stalked by women? I don’t believe reply johnisgood 2 hours agorootparentI actually do have a history of being stalked by women, e.g. my ex, a female, twice my age and \"only\" another female. So... in my entire life I have been stalked by women only, 2 women in total (as far I can recall). The whole thing is not limited to stalking anyways. reply washadjeffmad 5 hours agorootparentprevIt's certainly not limited to women, in theory, but I don't think you understand rural village life. For women who aren't free to voice opinions in the home, who don't have privacy, who might be abused or treated like servants, there are few spaces to escape and freely share information. If you've never seen this, they do work very hard to keep it a secret, but mostly it's because they don't have technology. Presumably, women are not putting up the spy cameras, weren't asked their opinions beforehand, weren't informed whether audio, video, or both were being captured, and don't have access to the footage to verify. If your company started putting trail cams in the break rooms or your neighbor installed one pointing at your back porch, you probably wouldn't think \"this is fair for everyone, I trust they won't check it without telling me unless there's a good reason or share this with anyone I wouldn't want them to, like my bosses or my abusive spouse\". reply johnisgood 2 hours agorootparentI know about how females are being treated in e.g. Iraq. Awful. reply belorn 6 hours agorootparentprevThe article do explains the cause of why women in this specific situation are more likely observed than men: forest rangers in the national park deliberately fly drones over local women to frighten them out of the forest, and stop them collecting natural resources despite it being their legal right to do so. later on it says: The women living near India’s Corbett Tiger Reserve use the forest daily in ways that are central to their lives: from gathering firewood and herbs to sharing life’s difficulties through traditional songs. For unspecified reasons, women are responsible for collecting those natural resources. If I put down a guess, that the wood is used for cooking and cleaning (with the men doing the typical gender role activities that India apply towards men). We could create a similar article saying that men are more affected by road cameras than women, since men are more likely than women to be driving (especially truck drivers). reply dhfbshfbu4u3 6 hours agorootparentprevSure, it effects everyone’s privacy but women are 99.99% more likely to be raped than men so perhaps they have a bit more to worry about. reply DennisP 5 hours agorootparentSo just under 100% more likely, i.e. twice as likely? That's an underestimate. Only 9% of rape victims are men. https://www.humboldt.edu/supporting-survivors/educational-re... reply binary132 4 hours agorootparentprevgenerally speaking women are predated on by men more than men are by women. reply mrweasel 5 hours agoprevAt this point, this shouldn't really be a massive surprise to anyone. The surprising part comes from the continued inability to predict these scenarios with anything less than 100% accuracy. Does it have a camera, microphone, GPS, lidar or any type of wireless communication, if yes it can and it will be used to monitor, oppress and intimidate. reply JadeNB 4 hours agoparent> The surprising part comes from the continued inability to predict these scenarios with anything less than 100% accuracy. I don't think Hanlon's razor applies here. If there's no penalty to the people who establish a system for its foreseeable abuses, then their not foreseeing those abuses isn't inability, it's strategy. reply nomilk 14 hours agoprevSeems a lot of modern tech is (ab)used for the purpose of perving. I recently visited a gym which seemed very social media oriented (not dissimilar to most gyms tbh), but as days went by I gathered the impression something weird was going on. I ended up suspecting (but having absolutely no evidence) that the owner or staff was using the cameras to spy on members. Further oddities exist in the reviews for the place, which includes staff walking into the change rooms (of the opposite sex) with naked people there. That's a really long/specific way of saying: wildlife cameras spying on Indian women is an instance of a more general problem. I feel like plausible deniability (e.g. security/monitoring) is so easy that discovering and alleging wrong-doing would be met with little more than shrugging of shoulders. reply fsckboy 12 hours agoparent>I feel like plausible deniability...is so easy that discovering and alleging wrong-doing would be met with little more than shrugging of shoulders. it was not met with shrugs FTA: Young men appointed as temporary forest workers shared the photo on local Whatsapp and Facebook groups to \"shame the woman,\" Simlai said. \"We broke and set fire to every camera trap we could find after the daughter of our village was humiliated in such a brazen way,\" one local told the researchers. reply nomilk 12 hours agorootparent> it was not met with shrugs That's good news in this instance but not in the case of cameras in gyms and many other cases, unfortunately. reply averageRoyalty 10 hours agoparentprevWhat solution do you propose for private businesses? Having cameras is sensible, if not a must. People are abusive, burglars break in, staff steal, etc. reply raxxorraxor 4 hours agorootparentYou can install cameras in a way that you only film the parts relevant for potential break ins. In my country this is demanded by law. So not directing cameras on public streets or other properties. Aside from that, camera necessity isn't real, affordable cameras for mass deployment are perhaps not recent, but there certainly were other ways in the past to handle crime. reply nomilk 9 hours agorootparentprevI don't have a solution (and would be mindful any 'solution' could be unreasonably burdensome, unenforceable, or have unintended consequences). I just point out that the past couple of decades have seen a dramatic change how easy it is for people to be spied on, often in sensitive environments and unbeknown to them. reply gadders 8 hours agoparentprev>>Further oddities exist in the reviews for the place, which includes staff walking into the change rooms (of the opposite sex) with naked people there. Unless it was a one-off error, that is the reddest of red flags. reply akudha 4 hours agoparentprevI remember reading that camera phones sold in Japan are required by law to make shutter sound while taking photos. There was another report from South Korea on hidden cameras in women’s restrooms. This whole thing is beyond disgusting, I say this as a male. This seems like a problem in many countries. I don’t think this problem can be fixed with stricter laws. Not that we shouldn’t try, but I wonder how effective it would be. We should raise boys to be better men. Across the world, right wingers are coming to power, this is not good for women. Then there are shitheads like Andrew Tate who have a big following among boys and young men. This whole thing is just depressing. reply keithnz 16 hours agoprevanother article with some other details https://www.enca.com/opinion/wildlife-monitoring-tech-used-h... seems like they developed a set of principles a while back https://wildlabs.net/sites/default/files/principles_for_the_... But my guess is without strict enforcement of the rules with consequences this will carry on. reply gnabgib 15 hours agoparentThat article references this University of Cambridge study. reply fsckboy 12 hours agoprevthey should put the women in charge of the cameras and wildlife monitoring reply bilbo0s 8 hours agoparentNot as simple as that. Sadly, in addition to men, there are also a lot of women, who abuse women. (And even children.) reply akudha 4 hours agorootparentYes, but it is likely to be a bit better with women in charge than men. But yeah, there isn’t any easy solution to this reply nonrandomstring 6 hours agoprevFly tipping is a reason that some UK councils hide cameras in woodlands [0]. That's what we semi-confirmed (the council \"declined to deny it\" in a coded response) in this episode \"It is not closed, it is not a circuit, and it is not even television!\" For US readers \"fly tipping\" is illegal dumping of household waste, not giving money to insects. [0] https://cybershow.uk/episodes.php?id=26 reply lifestyleguru 10 hours agoprevUnfortunately I think that access to all kind of IP cameras is too easy. Normal people mostly don't care to install, don't bother to deal with setting up the recording infrastructure. Creeps, psychos, delusional people go wild with them, including pointing camera at neighbour doors, windows, garages in residential areas. Yes, you can tell them to turn the camera away but they are delusional so discussion rarely makes sense. Some people draw this sick perverted satisfaction in recording their neighbour and sometimes only violence works as an argument. reply pvaldes 10 hours agoprevThis excuse has been also used in Swedden to forbid trail cameras in public areas unless the government emit a permit. People has been sued because a woman toke a dump in front of the camera. Is unclear to me if this was deliberated or not. Is a \"think on the children\", but with women. The fact is that people in public areas can and should expect to be filmed or appear in the background of a selfie. First because is legal, and second because is unavoidable. Without the current \"male panic\", women shouldn't have a problem with appearing in the background of a low quality photo (that in most cases will show a blurred face). Men don't care about it either, and people don't wander around naked in forests typically. Cameras can have benefits for women also. Will detect presence of wild animals in the area that could be dangerous to women; or criminal activity, like poachers, arsonists or violators. I assume that this is the real problem with the presence of cameras here. That poachers are being filmed They aren't neither bad or good. Is just a tool. The huge majority of zoologists are normal responsible people that would delete any photo with sensitive personal information and never would filter it to internet. The fix is to put banners on the area, but then the cameras will be stolen. Or we could also stop to study nature and let everything go to hell. reply x3ro 7 hours agoparent> The fact is that people in public areas can and should expect to be filmed Says who? I certainly don't agree with this. It's a societal decision whether or not we want or need video surveillance, which is very different from some random dude filming me with his smartphone. Evidence on whether or not video surveillance is _effective_ is also, at the very least, inconclusive [1] and highly depends on location. So no, I don't think people should expect to be filmed by their government or its contractors at all, _especially_ not in public places :) [1]: https://journalistsresource.org/politics-and-government/surv... reply qup 5 hours agorootparentWhat does that link tell us about the effectiveness of monitoring mammals with cameras? reply hansvm 4 hours agorootparentprev> which is very different from some random dude filming me with his smartphone Not that I disagree, but to fix it you need to make it different in a way that you can write down in a law -- something better than \"I know it when I see it\" -- and you need to keep the negative externalities limited [0]. A law like that seems like it basically wants to codify the level of privacy a typical citizen in 1910 (or 1850 or even 1970) might have enjoyed. Before we had our current level of networking, storage, and computing power, we didn't have to worry about things like \"some random dude filmed me with his smartphone\" (almost always not a problem) transforming into \"every video is automatically uploaded to an AI surveillance tool\" (a potential problem -- even if the video itself is \"legal\", an aggregation of those videos paints a picture of whether you're pregnant, your food preferences, whether you should be afraid of being seal-team-sixed by God-Emperor Trump, ...). The ability to take more invasive measurements throws another wrench in things. Laws regulating videos and security feeds haven't kept up with the technology improving to capture more sensitive data than before. It's fine if my security cameras accidentally capture some of your house and activities 24/7. Assume I'm not automatically uploading those to a central service *cough* ring doorbell *cough* .... It's not great if I intentionally aim more cameras at you (often legal). It's worse if I make them public (often legal). Is thermal imaging to get an idea of which rooms you're in okay (often legal, less so if you're the police)? What about using wifi for imaging [1] to get a fuzzy view of you in a bath (similarly, often legal)? Can I hover a drone outside all your windows at an angle to try to peek through gaps in the blinds (mostly illegal, though the police still try -- FAA isn't the only governing entity here even though their rules mostly allow things like that)? What if I'm not violating your airspace and use an ultra-zoom lens (mostly legal)? [0] Anti-recording laws tend to make it harder to record things you ought to be able to. That can be direct (police using their power to physically block you from recording their abuse, using the existence of anti-recording laws as enough of an excuse that qualified immunity will protect them regardless of how badly those laws are interpreted), indirect (your phone physically not letting you record debt collectors breaking the law in CA, even with consent from the collector, just because your phone knows that CA is 2-party consent), chilling (especially if the law is a bit vague, it gives well-funded actors yet another way to bankrupt you when they're caught breaking the law by your recording -- first trying to sue you for the illegal video), .... [1] I've seen better articles and better performance, but this seems fine: https://www.tomshardware.com/news/wi-fi-routers-used-to-dete... reply em-bee 8 hours agoparentprevThe fact is that people in public areas can and should expect to be filmed in germany i can expect the opposite because surveillance cameras in public spaces are illegal. this is not a \"think of the women\" argument, but \"think of the people\". reply x3ro 7 hours agorootparentTo be very clear, this only applies to private individuals setting up cameras. The government is very much able to surveil the population to its hearts content [1] (link German). There are plenty of \"security\" cameras around Berlin, at least. [1]: https://www.bundestag.de/resource/blob/507980/bf8a67c2440522... reply pvaldes 6 hours agorootparentprevIn most countries, people can legally spend all morning taking photos in a park if they want. But the real problem in this particular case can be spotted from a mile. Crime against nature was so rampant, that the India government must spend money and use cameras, drones and anything to stop it in the protected area. This is really \"think of the criminals\". The alleged psychological damage done to women because a natural protected area is being surveilled, is clearly an excuse from poachers, unable now to continue their previous activity freely. I will not try to pretend that I know the role of women on Indian culture and how much fragile mentally they are, but I assume that people can understand that scientific work is necessary; and that behind each camera there is not necessarily a rapist (Cambridge has also women doing science also). If this women are so stressed, the most probable reason is that they are poachers also. Either you protect it, or you lose it. My sympathy for the \"victims\" of protecting nature is low and decreasing. reply Miraltar 5 hours agorootparent>If this women are so stressed, the most probable reason is that they are poachers also. I would be stressed too if a drone was following me in my daily activities reply truculent 5 hours agoparentprev> First because is legal, and second because is unavoidable. That it is legal can obviously be changed, and it being \"unavoidable\" is a matter of culture. You could view stealing as \"unavoidable\" (ultimately, someone much bigger/stronger/with a weapon/etc _could_ just take your stuff on the street, right?). It's primarily through culture and cultural instruments that we reduce its prevalence. Whether we choose to prioritise a given issue or not is, of course, up for debate, but we should acknowledge that it is, in fact, a choice. reply itishappy 4 hours agoparentprev> Men don't care about it either. Speak for yourself brother, I care quite a lot. reply yieldcrv 14 hours agoprevnext [2 more] [flagged] hackernewds 11 hours agoparentthey are not just escaping from the men at home. they're actively having illicit affairs away from their men at home, in the privacy of the forest.. reply _giorgio_ 10 hours agoprevI suppose that this is not the right thread to ask about what devices would you use outdoor, but I'll try anyway... Requisites: - battery operated - IP protection - fast shutter (example: moving objects) - wifi? - night mode not important (using it in optimal conditions) Thanks reply batch12 6 hours agoparentThe phrase for your search is \"trail camera\" reply _giorgio_ 2 hours agorootparentthanks, I had no idea that it was called that way I need them to count cars more than animals anyway reply thaumasiotes 17 hours agoprevPerhaps there's an inherent conflict between using the forest as a source of resources for the nearby village, and using it as a storage space for tigers. reply nine_k 16 hours agoparentThat same forest without the cameras didn't exhibit that particular kind of conflict. I suppose the problem is in behavior of particular humans here, not of tigers, the forest, or even the cameras. reply notRobot 16 hours agoparentprevThe forest is for all to use and not exploit reply RobotToaster 11 hours agoprev [–] > they feel watched and inhibited by camera traps, so talk and sing much more quietly. Why would you stop singing loudly because of cameras? Even if their singing is bad, they're just inflicting it on someone who they don't like? reply blitzar 9 hours agoparent [–] If only people would not sing and dance when the tiktok camera is on. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cambridge researchers discovered that wildlife monitoring technologies, such as camera traps and drones, are being misused in India to spy on women, impacting their mental health and safety.- These technologies, originally intended for conservation purposes, are reportedly used by local authorities to intimidate women, infringing on their rights.- The study emphasizes the need for careful consideration of the social impacts of deploying such technologies."
    ],
    "commentSummary": [
      "Wildlife monitoring technologies, such as camera traps, are being misused in Indian forests to intimidate and spy on women, raising significant privacy and mental health concerns.- This misuse underscores broader global issues of surveillance and privacy, particularly in regions with existing women's rights challenges, and is not confined to India alone.- Addressing these issues requires complex solutions, including the implementation of stricter laws and cultural shifts to safeguard privacy and ensure safety for all individuals."
    ],
    "points": 142,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1732497881
  }
]
