[
  {
    "id": 41775463,
    "title": "Nobel Prize in Physics awarded to John Hopfield and Geoffrey Hinton [pdf]",
    "originLink": "https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf",
    "originBody": "Attention Required!Cloudflare . nobelprize.orgCloudflare 8cf862227c000ca7 • 4.227.115.140 •",
    "commentLink": "https://news.ycombinator.com/item?id=41775463",
    "commentBody": "Nobel Prize in Physics awarded to John Hopfield and Geoffrey Hinton [pdf] (nobelprize.org)632 points by drpossum 9 hours agohidepastfavorite586 comments chriskanan 5 hours agoHere is the reasoning: https://www.nobelprize.org/uploads/2024/09/advanced-physicsp... I'm surprised Terry Sejnowski isn't included, considering it seems to be for Hopfield Nets and Boltzmann machines, where Terry played a large role in the latter. reply dang 1 hour agoparentI guess it makes sense to use that link above since it goes into much more detail. Changed from https://www.nobelprize.org/prizes/physics/2024/summary/. Thanks! reply whizzter 4 hours agoparentprevHe was probably considered since he is mentioned in the reasoning paper, still it could be one of those unfortunate omissions in the nobel history since those deciding the prize might have a hard time to measure impact. reply gtirloni 42 minutes agorootparentThen they shouldn't be trusted to give awards in an area they are not experts in. reply hxnamer 14 minutes agoparentprevIs this a widely accepted version of neural network history? I recognize Rosenblatt, Perceptron, etc., but I have never heard that Hopfield nets or Bolzmann machines were given any major weight in the history. The descriptions I have read were all mathematical, focusing on the computational graph with the magical backpropagation (which frankly is just memoizing intermediate computations). The descriptions also went out of their way to discourage terms like \"synapses\" and rather use \"units\". reply mistercheph 1 hour agoparentprevWhether or not these fields are meaningfully distinct is a matter of taste, despite the fashion being to imagine a plurality of interconnected but autonomous domains. reply KingFelix 2 hours agoparentprevYeah, Terry is a rockstar, and pumping out tons of papers. Maybe they google scholared, list by citations? reply nextos 3 hours agoprevI find the prize a bit odd this time since it focused on Hopfield networks and Boltzmann machines. Picking those two architectures in particular seems a bit arbitrary. Besides, Parisi got the prize last year (edit: actually 2021, time flies) for spin glasses. Hopfield networks are quite related. They could have included Hopfield & Hinton too, and it would have looked more coherent. It is also concerning that lately the Nobel Committee seems to be ignoring fundamental broad theoretical contributions. In this case, backpropagation, where Seppo Linnainmaa could have been one of the awardees. It is a bit sad he and others who have already passed away get little credit for something so fundamental. reply whatshisface 2 hours agoparentThe Nobel in Physics only goes with experimental discoveries, Peter Higgs didn't get his (deserved since the 70s) until the LHC directly observed the particle. I agree that Hopfield networks and Boltzmann machines are a surprisingly arbitrary choices. It is like they wanted to give a prize to someone for neural networks, but had to pick people from inside their own field to represent the development, which limited the range of options. There is also the aspect of the physics community wanting to give somebody that they liked a Nobel, and then trying to fit them in. (The prize isn't handed out by a shadowy committee of Swedes, there's an involved and highly bureaucratic process for nomination that requires your colleagues to take up your case.) reply nextos 2 hours agorootparentBut, as you said, Higgs got his prize once theories were tested. Hence, theoretical contributors (still alive as per prize rules) could have been included here as well. reply dawnofdusk 2 hours agorootparentprevGiorgio Parisi's prize proves the committee gives prizes for theoretical discoveries nowadays. This year's prize is more proof. reply pfortuny 2 hours agorootparentprevMmmmhhhhh… What about Penrose? Honest question. reply wing_rets 2 hours agoparentprevParisi won in 2021, not last year. His work was more about establishing spin glasses as a way to study complex systems. Hopfield definitely built on that, showing how those ideas could be applied to neural networks and info storage in state-space machines. As for focusing on Hopfield networks and Boltzmann machines, I get where you're coming from. They’re just a couple of architectures among many, but they’re pretty foundational. They’re deeply rooted in statistical mechanics and have had a huge impact, finding applications across a range of fields beyond just machine learning. reply nextos 1 hour agorootparentThanks, that's right, 2021 not 2023. Corrected. reply an_cap 3 hours agoprevAn excellent career retrospective by John Hopfield - https://pni.princeton.edu/sites/g/files/toruqf321/files/docu... \"As an Academy member I could publish such a paper without any review (this is no longer true, a sad commentary on aspects of science publishing and the promotion of originality).\" reply kkylin 1 hour agoparentNational Academy members still get to pick the reviewers (if they choose to go that route rather than regular submisssion), and the review is not blind. The reviews themselves are not public, but the identities of the reviewers are made public once the paper is out. So members can't just say whatever sh*t they want (and you can imagine some do), but still a highly unusual process. reply DrillShopper 2 hours agoparentprevYeah, fuck peer review!/s reply ajkjk 1 hour agorootparentEveryone's first thought when they read something is whatever the social norms say you're supposed to think (peer review = good, publishing without peer review = not science somehow?), but shouldn't you stop and wonder why the esteemed scientist wrote that line instead of just dismissing it? Otherwise you are only chiming in to enforce a norm that everyone already knows about, which is pointless. One of the really refreshing things about reading older research is how there used to be all these papers which are just stray thoughts that this or that scientist had, sometimes just a few paragraphs of response to some other paper, or a random mathematical observation that might mean nothing. It feels very healthy. Of course there were far fewer scientists then; if this was allowed today it might be just too crowded to be useful; back then everyone mostly knew about everyone else and it was more based on reputation. But dang it must have been in a nice to have such an unrestricted flow of ideas. Today the notion of a paper is that it is at least ostensibly \"correct\" and able to be used as a source of truth: cited in other papers, maybe referred to in policy or legal settings, etc. But it seems like this wasn't always the case, at least in physics and math which are the fields I've spent a lot of time on. From reading old papers you get the impression that they really used to be more about just sharing ideas, and that people wouldn't publish a bad paper because it would be embarrassing to do so, rather than because it was double- and triple-checked by reviewers. reply tikhonj 52 minutes agorootparentWe still have lots of stray thoughts, responses and observations, now they just happen on blog posts, on social media and in other non-peer-reviewed venues. The Internet has driven the cost of publishing to 0, and peer review is the only thing left that makes academic publishing qualitatively different. If anything, publishing your thoughts online is better than publishing a traditional paper in every single way except for peer review. reply erinnh 1 hour agorootparentprevIm not a scientist and do not know how these things work out, but wouldn't it be possible for scientist to simply publish their papers online without peer review if that is what they want? What's stopping them from doing so? reply naasking 1 minute agorootparentThe only for work to have an impact is if it gets exposure. Publishing in journals got you an audience, but that audience is gatekept by peer review, which has its problems. So sure, you could publish but the chance of having an impact was low. Thankfully that's changed a bit with arxiv. auggierose 6 minutes agorootparentprevTheir survival instinct. reply ars 1 hour agorootparentprevThat still exists, they just call them pre-prints and put them on the arxiv. reply naasking 8 minutes agorootparentprevYes, but non-sarcastically. reply physicsguy 7 hours agoprevThis is totally bizarre, no precedent for it really. The reality of the prize means that less and less are the winners names every physicist has heard of, but even today they're still big names in each subfield. For e.g. Kosterlitz, Thouless and Haldane weren't exactly household names but they really deserved the prize in 2016. In this case, there's a good argument that Hopfield had conducted strong work as a physicist and in physics, but Geoffrey Hinton has never worked as a Physicist, at best adopting some existing things from physics into cognitive science use cases. In any case, what they've been given the prize for is work where they've not contributed to the understanding of the world of physics - it's not even really an arguable case where this is work that crosses over between Physics and another field either. It'd be like if Black or Scholes had been given the Physics prize rather than Economics because their famous equation can be re-written in Schrodinger equation form. reply ecosystem 3 hours agoprevHopfield made substantial contributions (Nobel-contention work) in multiple fields, which is truly astonishing: Kinetic proofreading (biochemistry/biophysics), HopNets (ML), long distance electron transfer (physics), and much more. Welcome news that he finally got there. reply tempusalaria 8 hours agoprevWhat bizarre choice. Hinton’s work has nothing to do with physics. Nobel prize jumping on the bandwagon, just like they did for mRNA after covid. At least that was related to medicine. The first 2 paragraphs of the linked pdf read like a joke. Like it’s a parody announcement. reply jampekka 8 hours agoparentHinton did introduce the Boltzmann machine networks that kind of resemble thermodynamics if you squint really hard. And those didn't really pan out. Of course the price is really for MLP backpropagation (or how it found applications) but I guess it's not physics enough. Hopfield networks never really found use either, but they are sort of related to Ising models and NNs, so I guess it's physics then. reply kgwgk 8 hours agorootparentAt least they already recognized actual spin-glasses research in physics in 2021. That makes this award for this by-product more puzzling though. reply adastra22 8 hours agoparentprevOr Obama’s peace prize. reply karmasimida 8 hours agoparentprevBoltzmann machine does quote physics as its inspiration, they didn't award him for his work in BP and stuff. But I agree, this feels like a stretch. reply Ma8ee 8 hours agoprevI think this is the Royal Academy of Sciences way to admit that Physics as a research subject has ground to a halt. String theory suffocated theoretical high energy physics for nearly half a century with nothing to show for it, and a lot of other areas of fundamental physics are kind of done. reply eigenket 8 hours agoparentI think this is (very) inaccurate. It feels more like them trying to jump on a \"hot topic\" bandwagon (machine learning/AI hype is huge). Physics as a discipline hasn't really stalled at all. Fundamental physics arguably has, because no one really has any idea how to get close to making experimental tests that would distinguish the competing ideas. But even in fundamental physics there are cool developments like the stuff from Jonathan Oppenheim and collaborators in the last couple of years. That said \"physics\" != \"fundamental physics\" and physics of composite systems ranging from correlated electron systems, and condensed matter through to galaxies and cosmology is very far from dead. reply 620gelato 8 hours agorootparent> trying to jump on a \"hot topic\" bandwagon I don't know exactly what they hope to gain by jumping on that bandwagon though; neither the physicists nor the computer scientists are going to value this at all. And dare I say, the general populace associated with the two fields isn't going to either - case in point, this hn post. If there weren't any noble-worthy nominations for physics, maybe skip it? (Although that hasn't happened since 1972 across any field) reply klwant 8 hours agorootparentOne possibility is that they think this will access hype funding. Put \"AI\" in a physics paper and watch the grants roll in. reply eigenket 2 hours agorootparentI kinda doubt it. The kind of people who end up nominating people for Nobels or even making the decisions on these aren't really struggling for grant funding. reply mppm 8 hours agoparentprevIt really has not, though. There is more to physics than high-energy and cosmology, and there is no shortage of deserving contributions of smaller scope. It really is bizarre that deep learning would make it to the top of the list. reply Ma8ee 8 hours agorootparentCould you give me some examples of areas of fundamental physics that are vital and have done some significant discoveries lately? I genuinely would like to know, because I really can't think of any. reply mppm 7 hours agorootparentI'm probably not the right person to ask, but off the top of my head: superconductivity of high-pressure hydrides; various quantum stuff like quantum computing, quantum cryptography, quantum photonics, quantum thermodynamics; topological phases; rare decays (double beta, etc.); new discoveries in cosmic rays, etc. My point was that physics is a big and active field, stagnation at the smallest and largest scales notwithstanding. Note also that the Nobel committee is not in any way limited to \"newsworthy\" stuff and has in many cases awarded prizes decades after the fact. reply eigenket 8 hours agorootparentprev\"Vital\" is completely subjective but I'd throw stuff around quantum information into the ring. Maybe you'd consider the loop-hole free Bell tests performed in 2015 and awarded the 2022 Nobel prize to count? reply Ma8ee 7 hours agorootparentI think the prize in 2022 was a nice prize, but it could still be considering just tidying the corners. In the end it just proved that things really work as most of us has thought it worked for decades. reply amai 7 hours agoparentprev> Physics as a research subject has ground to a halt Max Planck was told by his professor to not go into Physics because \"almost everything is already discovered\". Planck said he didn't want to discover anything, just learn the fundamentals. reply Ma8ee 3 hours agorootparentFirst, I didn't say that I thought everything already was discovered, but that the fundamental physics community doesn’t discover new things. That is due to how physics research is practiced today and has nothing to do with how much that is left to discover. Second, even if it obviously wasn't true when Planck was told that almost everything is discovered, it doesn't say anything about the state today. reply killerstorm 6 hours agoparentprevWhat if the next breakthrough is complex and not directly accessible from our current state of math/physics thought? I see no reasons to expect steady progress. Nobody knows how long it would take to prove Riemann hypothesis, for example. reply noobermin 8 hours agoparentprevString theory and the foundations are not the only area of physics. It would be nice for theorists to remember that. reply api 8 hours agoparentprevMy sense is that we might have reached the limits of what we can do in high-energy or fundamental physics without accessing energy levels or other extreme states that we currently can't access as they are beyond our capacity to generate. From what I've read (not a professional physicist) string theory is not testable unless we can either examine a black hole or create particle accelerators the size of the Moon's orbit (at least). Many other proposed theories are similar. There is some speculation that the hypothetical planet nine -- a 1-5 Earth mass planet predicted in the far outer solar system on the basis of the orbits of comets and Kuiper Belt / TNO objects -- could be a primordial black hole captured by the solar system. A black hole of that mass would be about the size of a marble to a golf ball, but would have 1-5g gravity at the distance of Earth's radius. If such an object did exist it would be within space probe range, which would mean we could examine a black hole. That might get us un-stuck. If we can't do something like that, maybe we should instead focus on other areas of physics that we can access and that have immense practical applications: superconductivity, condensed matter physics, plasmas / fusion, etc. reply slashdave 49 minutes agorootparentAlthough rare, there are cosmic rays that do span very high energies. You can access these from, for example, atmospheric showers. reply alwinaugustin 8 hours agoparentprevEven Sheldon Cooper stopped researching string theory at one point. reply ChrisArchitect 4 hours agoprevWas just listening to a live radio interview with Hinton finding him in a small hotel room in California somewhere quite flabbergasted at the news. Interviewer all happy for him etc, but when delving more into what it was for he started to go off on AI concerns etc and the interview didn't last much longer. Acceptance speech might be something. reply scarmig 3 hours agoparentHoping he speaks a lot of truth to power. reply dr_dshiv 5 hours agoprevDid Hinton win for the restricted Boltzmann machine? I believe Paul Smolensky has some priority with the Harmonium, but Hinton certainly deserves it. But worth reading Smolensky’s paper, it is a classic!! https://stanford.edu/~jlmcc/papers/PDP/Volume%201/Chap6_PDP8... reply everybodyknows 4 hours agoparentI don't see a date in the PDF. When was it written? reply ilya_m 3 hours agorootparentIt's a chapter from here: Rumelhart, D. E., McClelland, J. L., & the PDP research group. (1986). Parallel distributed processing: Explorations in the microstructure of cognition. Volume I. Cambridge, MA: MIT Press. reply gen220 3 hours agorootparentThe whole book is quite good, btw! And it looks cool on a bookshelf. reply dcuthbertson 3 hours agorootparentprevAnother version of that paper [0] is dated Feb. 1986. [0]: https://apps.dtic.mil/sti/tr/pdf/ADA620727.pdf reply openrisk 8 hours agoprevThis does indeed smell of desperation. Which is really, really sad. Advances in _real_ physics are central to the absolutely needed sustainability transition. In a sane society that values its self-preservation you would not need to grasp at second-order straws to justify the need for all sorts of both fundamental and applied physics research. We need to think seriously whether our collective hallucinations (pun) have got us to some sort of tipping point, undermining our very ability to act according to our best long-term interests. ps. not to imply anything negative about the worthiness of the awardees in general reply mishaevtikhiev 7 hours agoprevMy perspective as a PhD in theoretical physics, who's been doing deep learning in the last 4 years: 1. The prize itself makes zero sense as a prize in _physics_. Even the official announcement by the Nobel Prize Committee, taken at a face value, reads as a huge stretch in trying to link neural networks to physics. When one starts asking questions about the real impact on physics and whether the most important works of Hinton and Hopfield were really informed by physics (which is a dubious link to the Nobel prize anyway), the argument stops holding water at all. 2. Some of the comments mention that giving prize for works in AI may make sense, because physics is currently stalled. This is wrong for several reasons: 2.1. While one can argue that string theory (which is, anyway, only a part of high-energy theoretical physics) is having its \"AI winter\" moment, there are many other areas of physics which develop really fast and bring exciting results. 2.2. The Nobel Prize is often awarded with quite some delay, so there are many very impactful works from 80s which haven't been awarded with a Nobel prize (atomic force microscopy is a nice example). 2.3. It is wrong to look at the recent results in some sub-field and say \"okay, there was nothing of value in this field\". For example, even if one completely discards string theory as bogus, there were many important results in theoretical physics such as creation of conformal field theory, which was never recognized with a Nobel Prize (which is OK if Nobel Prize is given to other important physical works, but is quite strange in the light of today's announcement). To finish on a lighter mood, I'll quote a joke from my friend, who stayed in physics: \"Apparently the committee has looked at all the physicists who left academia and decided that anything they do is fair game. We should maybe expect they will give a prize for crypto or high-frequency trading some time later\". reply muratgozel 5 hours agoprevJust watched the nobel prize live stream, surprised by the topic, looks very engineering to me rather than physics, do algorithms make physics subsidiary? reply aDyslecticCrow 3 hours agoparentThe physics prize has historically taken the role of both \"innovation/engineering\" topics and \"mathematics\". It's more broad than simply physics. The most important factor tends to be the positive impact on society, as that's one of the price's core tenets. reply andrepd 3 hours agorootparent>The most important factor tends to be the positive impact on society Making it even more baffling that this won then reply aDyslecticCrow 1 hour agorootparentI can understand the sentiment against the current \"AI\" crace with chatbots. But are you dismissing neural networks as a whole as non-impactful? What about; - Improved weather forecasts - Protein folding - Medical imaging and diagnostics - Text-to-speech and voice recognition - Language Translation - Finance fraud detection - Supply chain and logistics optimization - Natural disaster prediction reply choilive 2 hours agorootparentprevIf you don't think machine learning and neural networks have made massive positive contributions to humanity then you are naive. reply DangitBobby 2 hours agorootparent\"Massive\" seems overstated. Also doubt that it's net positive. reply aDyslecticCrow 1 hour agorootparentYou're probably only thinking about the modern chatbots when you say that. reply jhbadger 2 hours agoparentprevWell in 1912, the physics prize went to a guy who designed a better light for light houses and buoys to prevent shipwrecks! Actually, most early Nobels went to practical things. https://en.wikipedia.org/wiki/Gustaf_Dal%C3%A9n reply Anon84 5 hours agoparentprevBoth Hopefield Networks and Boltzmann machines trace their origins and motivations to Statistical Mechanics and Spin Glasses. Coincidently, Giorgio Parisi got the 2021 Nobel prize for his work on spin glasses reply viraj_shah 3 hours agoparentprevI am really surprised. I would have guessed that a Nobel Prize would be awarded to advancements in the field itself. Not for inspirations from it or to tools that led to advancements. Although as I write this I'm sure there have been several prizes awarded to scientists / engineers who have developed tools to advance physics. Like radio astronomy? Still surprised though. reply parodysbird 3 hours agorootparentSome other recent cases of the prize being given to an engineering contribution: - 2018 was for chirped pulse amplification, which is most commonly used in medicine (LASIK surgery for example) - 2014 was for basically for LED lights - 2010 was for a method for producing graphene - 2009 was for both charge-coupled device, which is a component for digital imaging (including regular consumer digital cameras), and fibre-optic cables reply ladams 2 hours agorootparentCPA is very very widely used in experimental physics, so I don’t really think it belongs on this list. reply parodysbird 2 hours agorootparentWell yeah, so are neural nets. I just meant that these are engineering accomplishments, not scientific per se. Of course experimental science will often take advantage of cutting edge technology, including from computer science. reply adamnemecek 4 hours agoparentprevIt’s closely related to statistical mechanics. reply stainablesteel 3 hours agoparentprevi reason it from the perspective that its because they've found a way to make a machine out of bits that no one's ever made before, they're physical objects reply andrepd 3 hours agoparentprevEh. \"\"\"AI\"\"\" is all the rage so I guess even the nobel in physics has to have something to do with this. Not a fan reply T-A 8 hours agoprevFor what it's worth, the \"Advanced information\" PDF does a somewhat better job of trying to explain the rationale than the linked press release: https://www.nobelprize.org/uploads/2024/09/advanced-physicsp... reply amai 7 hours agoparentInteresting. LeCun, Bengio, Schmidhuber and Hochreiter are (amongst others) also mentioned in this article. reply karmakurtisaani 7 hours agorootparentEagerly waiting for Schmidhuber's comment on the prize. reply seydor 4 hours agoprevIt will certainly be an interesting acceptance speech by Hinton reply noobermin 8 hours agoprevMay be I should know better, but is there no Nobel category for computer science or mathematics? This isn't physics, this is absolutely embarrassing. May be all those bitter elder physicists who didn't get a prize can feel a little justified in their derision of the institution. reply drpossum 8 hours agoparentThere no Nobel category for computer science or mathematics. Related reading https://hsm.stackexchange.com/questions/24/why-isnt-there-a-... reply amai 8 hours agoparentprevHow about a \"Nobel Memorial Prize in Computer Sciences\" similar to the https://en.m.wikipedia.org/wiki/Nobel_Memorial_Prize_in_Econ... reply etiam 1 hour agorootparentPerhaps not a bad idea in that specific instance, but they're so embarrassed today about getting bought for the economics one that doing something similar again has become effectively out of the question (and on a balance I think that's for the best). reply eigenket 8 hours agoparentprevComputer science has the Turing award and mathematics the Fields medal. Neither is exactly equivalent to the Nobel but they're similar levels of prestige. The Nobel prize fields and criteria are a bit random, they're essentially just whatever Alfred Nobel wrote in his will. reply dagw 6 hours agorootparentthey're similar levels of prestige Within their respective fields, not in general. What makes the Nobel so unique and desirable is that everybody knows what it is and is impressed by it. Mentioning that you've won a Nobel prize will impress people and open doors in virtually any circumstance. Saying you have a Turing award will mostly lead to blank stares from anybody outside the field. reply hintymad 1 hour agoprevHas NN led to any fundamental breakthrough in physics research? I understand the impact from NN to scientific research, but I'm not aware of any big results in fundamental physics research because of NN. reply colmmacc 1 hour agoparentIt's not the Nobel Prize in Fundamental Physics though, and maybe this is correcting a bias that has been present for too long. Just because something isn't quantum or astronomical doesn't mean it's not physics. Physics is the study of the physical world, and learning, imagination, creativity, are all phenomena that we observe in the physical world but have only a primitive understanding of. It's a staggering advancement that we can now simulate key aspects of each. reply etiam 59 minutes agoparentprevIt seems like part of the motivation here is that it's possible to run many contemporary and planned very-big-science projects at all, since nobody's going to be sitting around analyzing centuries' worth of unvetted sensor data, but there are plenty of people prepared to spend a few years of their lives checking and massaging the regions of interest marked by a computer cluster. The simplest cases will have been long enabled by simpler regressions and such, of course, but the more complex pattern recognition appears to be appreciated. reply pvitz 8 hours agoprevNext year, the creators of Excel will get the prize, because it is an implementation of the mathematical universe. reply passwordoops 8 hours agoparentYou know what, I can support this for its predecessor, Lotus123. If ANNs are worthy of the prize in physics, then so is this reply jhbadger 54 minutes agorootparentVisiCalc, surely. Lotus 123, much like Excel, was just following in the footsteps of the original spreadsheet. https://en.wikipedia.org/wiki/VisiCalc reply sega_sai 8 hours agoprevPhysicist here. I'm sure Hinton deserves some sort of prize, but in Physics is really bizarre. reply jampekka 8 hours agoparentHe did get the Turing award already in 2018. reply jmakov 1 hour agoprevWonder when Anna will get her share since she's making all this possible by making the articles and books available (Anna's archive). reply huijzer 8 hours agoprevIn some sense it makes sense to award AI researchers on behalf of the physics community because I know many physics PhD’s who thank their job to AI; they work as data scientist now. Jokes aside, physics is a bit stuck because it’s hard to do experiments at the boundaries of what we know, as far as I understand. So then it makes sense I guess to award people who made useful tools for physics. reply openrisk 8 hours agoparent> it’s hard to do experiments at the boundaries of what we know this applies primarily to fundamental physics. There are many areas of applied physics (materials, fusion, biophysics, atmospheric physics, etc. etc.) where the main constrain is understanding complex systems. These areas are quite crucial for society. reply hoseja 7 hours agorootparentAs evidenced by the search for room temperature low pressure superconductors. reply drpossum 8 hours agoprevI don't know if this is a travesty that they awarded the prize to work on non-physical systems to jump on a bandwagon or that there was nothing else obvious enough to the board in actual physics to give this to. If I was the awardee I'd consider declining just out of respect to the field. reply jgrahamc 8 hours agoparentThe linked document connects their work to physics as follows: \"The Hopfeld network utilises physics that describes a material’s characteristics due to its atomic spin – a property that makes each atom a tiny magnet. The network as a whole is described in a manner equivalent to the energy in the spin system found in physics, and is trained by fnding values for the connections between the nodes so that the saved images have low energy\" \"Hinton used tools from statistical physics, the science of systems built from many similar components.\" reply drpossum 8 hours agorootparentThen it should be awarded for the result. Given the line of reasoning this has now opened up Alan Turing should be awarded one posthumously in every field. reply eigenket 8 hours agorootparentHe unironically should reply volkadav 8 hours agorootparent100% agreed as I can't think of any one individual since(1) who has done as much for all of science and engineering as he ultimately did; alas, they are not awarded posthumously. (1) Newton would be a strong contender on a \"for all time\" basis, but even he would've probably needed to share it with Leibniz, which would have driven him absolutely ~b o n k e r s~, like wet hornet in a hot outhouse mad, LOL. reply eigenket 1 hour agorootparentvon Neumann probably reply jampekka 8 hours agorootparentprevNeither of these models were never really influential though beyond some theoretical niches. reply drpossum 8 hours agorootparentYup. This prize is indistinguishable from \"we saw AI in all the headlines, let's see what's the most plausible reasons we could hand it out for that\" reply wslh 7 hours agorootparentprevIt seems like a hallucination generated from a ChatGPT prompt... reply alwinaugustin 8 hours agoprevIt’s time to consider adding computer science as a category for the Nobel Prize. They have already been awarded prizes for economic sciences and peace, so why not computer science? It's not the same as physics, and its impact on modern life is undeniable reply amai 8 hours agoparentHow about a \"Nobel Memorial Prize in Computer Sciences\" similar to the https://en.m.wikipedia.org/wiki/Nobel_Memorial_Prize_in_Econ... reply kgwgk 7 hours agoparentprev> They have already been awarded prizes for [..] peace Since 1901. reply ginko 7 hours agoparentprevWhy though? The Turing award exists. reply og_kalu 2 hours agorootparentPeople often say that the Turing award is the Nobel Prize of computing but that's not really true. The Turing award is the most prestigious award in computing yes but that's not enough for Noble like recognition/pedigree. What makes the Nobel prize unique is that almost anyone, even the general public or pioneers in other fields etc can here you received one and be very impressed. You'll generally be met with blank stares if you told anyone not in computing or an enthusiast you'd won a Turing. Even if you then said, \"It's the most prestigious award in computing!\", it wouldn't hit the same. Awards like these are basically only really worth their social recognition, so it's no surprise people would still want a Nobel in Computing/Mathematics etc even with Turing/Field etc existing. reply matsemann 8 hours agoparentprevIs that even \"possible\"? As in, they have to follow the rules of the organization, which have some criteria laid out. Not sure who could stop them from changing, though. Like, I think the original intent was to have done the most the preceding year, but now it's more of a lifetime award. So perhaps they can change or add different categories if wanted. reply Separo 7 hours agoprevWell maybe in time ML will help break through the high energy physics roadblocks. reply moelf 7 hours agoparentit already had, bottom-quark tagging has improved O(10)x in efficiency in the last decade without any new \"physics\" understanding, just from training with more low-level data and better ML arch (now using Transformers) but we haven't found new physics with or without ML, making this prize a little weird. reply telotortium 4 hours agorootparentMaybe it's a prize for hope and change that physics will be revolutionized by neural networks? Similar to how Obama got a Nobel Peace Prize in order to repudiate Bush's legacy in Iraq and Afghanistan. While Bush's legacy absolutely deserved to be repudiated, I don't think awarding a new president the Peace Prize was the best way to do it, especially because in the foreign policy realm, he ended up not so different from Bush. reply slashdave 44 minutes agorootparentprevHow about a prize for the Monte Carlo simulation methods needed as input to these models? reply seanhunter 6 hours agorootparentprevI sort of agree in principle but in practise they've always taken a broad view. Kissinger was one of the most prominent disrupters of world peace in the postwar era but that didn't stop him winning the peace prize. Churchill won the literature prize for defeating Hitler. The blue led guys a few years back didn't do much except make a thing that would go on every single consumer gadget and disrupt my sleep but they won the physics prize. Even when they get it right they often get it wrong. For example I believe Einstein supposedly won for \"especially his work on the photoelectric effect\" rather than relativity. reply DoughnutHole 5 hours agorootparentEinstein’s work on the photoelectric effect was incredibly important, and incredibly influential on other research at the time. He proposed that light was quantised - essentially the foundation of quantum mechanics. It’s no exaggeration that Einstein’s work on the photoelectric effect was as important as special or general relativity, and it had the advantage of strong experimental verification by 1921. The main reason that prize is remarkable is that Einstein himself hated quantum mechanics - but that doesn’t dispute the work’s importance. reply topaz0 3 hours agorootparentI would add to this that it had the advantage of something like 40 years of history as a field that was the basis for some of the biggest advances in instrumentation of that era. reply moelf 6 hours agorootparentprev>Einstein supposedly won for \"especially his work on the photoelectric effect\" rather than relativity. just adding to this, this is because relativity wasn't experimentally verified (i.e. not sure if it's reality) at the time. reply mr_mitm 5 hours agorootparentAlso, the prize is about the greatest benefit to humankind according to Alfred Nobel, not the most impressive research. Arguably, the photoelectric effect fits that notion better than GR or any other of Einstein's research. Besides that, Einstein received the prize in 1921, whereas the Eddington experiment in 1919 generally counts as the first experimental verification of GR. reply littlestymaar 4 hours agorootparent> Arguably, the photoelectric effect fits that notion better than GR or any other of Einstein's research Today we could argue about it due to the importance of solar panels, but that was hard to forecast in 1921. Also, without GR there would be no GPS so it's not like it doesn't bring benefits to humanity. reply mr_mitm 1 hour agorootparentEinstein laid the foundation of quantum mechanics with his description of the photoelectric effect, so you could add transistors, lasers, LEDs, CCD sensors and more to the list. Although I agree that it's doubtful that most of this could have been foreseen then. reply zellyn 53 minutes agorootparentprevSurely they would have just noticed a discrepancy in timing and added a few circles-upon-circles to effectively fix it up? Is deeply grokking relativity necessary for GPS to work? On the other hand, it would be impossible to make those adjustments without someone coming up with GR :-) reply topaz0 3 hours agorootparentprevMore to the point, photoemission spectroscopy has been a workhorse tool for understanding the electronic properties of materials for quite a long time now (though perhaps not yet in 1921). reply zitterbewegung 5 hours agorootparentprevNobel prizes are generally awarded for verifiable observations but, also require real world applications. Einstein won the physics prize on the photoelectric effect due to having real world applications and observable and if GPS actually existed while he was arrived (yes I know this is a stretch) he would have gotten it for relativity. Blue LEDs allows you to access more of the color spectrum for LEDs in general and they were not easy to make. For this year it does feel like a very large leaning into practical applications instead of physics though. Did we run out of interesting physics in the last year? reply ilya_m 2 hours agorootparentprevI would add to this list Bernard Russel who won the Nobel in literature for being a public intellectual. reply nickpeterson 2 hours agorootparentI should take up being a public intellectual, instead of a public nuisance. reply BurningFrog 3 hours agorootparentprevThe Nobel peace prize was a mistake. Peace is not a science, and you can't objectively measure how much anyone has helped peace, especially not before a few decades has passed. So I agree that the peace prize committee has made some bad choices, but they do have an impossible job. reply jonstewart 5 hours agorootparentprevNot supposedly. \"for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect\" https://www.nobelprize.org/prizes/lists/all-nobel-prizes-in-... reply datavirtue 5 hours agorootparentprevOh come on, blue LEDs were a feat of physics and chemistry mastery. reply seanhunter 5 hours agorootparentI'm sure they are but they drive me nuts. If I ever become filthy rich and in doing so sell my soul and become a bad person, one of my priorities will doubtless be to have the blue led inventors hunted down remorselessly.[1] [1] Note to future law-enforcement: I am honestly kidding. I wouldn't hurt a fly, officer. reply mozball 4 hours agorootparentA black sharpie over the offending led indicators will fix that. Now you can enjoy your sleep uninterrupted by dreams of manhunts and mephistophelian bargains. reply slashdave 45 minutes agoparentprevIf I may be so bold, a breakthrough will require new experimental techniques, and we aren't likely to get those from ML. reply ww520 5 hours agoparentprevML absolutely has helped astrophysics in sorting the massive amount of observation data to make new discovery. reply Yizahi 3 hours agorootparentSo if someone will invent say a new keyboard layout which will improve median data input rate by 10% and will be used by astrophysicists then it will be worthy of the astrophysics prize? Or better yet - in your example the main driver for the ML is Nvidia, should be award Jensen a prize in astrophysics? Or in any other field where ML is deployed? In my opinion we should separate efforts of people making tools, from the efforts of people doing research using said tools. reply OneDonOne 2 hours agorootparentprevSo do telescopes. Has anyone every won a Nobel for a telescope? reply hildolfr 2 hours agorootparentPeople have won it over new microscope designs and techniques.. possibly telescopes, too.. but I'm less familiar with that and not somewhere where it's convenient to look it up. reply bnegreve 5 hours agorootparentprevMost disciplines in CS have done that one way or another. reply elashri 7 hours agoparentprevOne of the very early successful applications of ML was using neural network and other models in particle identification systems in particle physics experiments. reply andrenth 3 hours agoprevI guess if it's not metaphysics then it's physics. reply AlbertCory 3 minutes agoprevConsider the Nobel in economics: https://en.wikipedia.org/wiki/Nobel_Memorial_Prize_in_Econom... It was not one of the original five, but it was endowed by a bank. SO: you tech billionaires, why don't you endow a Prize in Computer Science? That would end the dispute about whether ML is \"really\" physics? reply chronolitus 7 hours agoprevMoreso genuine curiosity than as a gotcha: A lot of comments are saying this was the wrong choice. I'd find it really interesting to hear who the nomination should have gone to instead, in your opinions. reply kleiba 8 hours agoprevThis must piss Schmidhuber off like nothing else. reply karmakurtisaani 7 hours agoparentA very long and detailed blog post incoming. Spoiler alert: the Nobel prize should have been awarded to Gödel/Hilbert (and Schmidhuber). reply raverbashing 8 hours agoparentprevTo the point of nuclear fusion even. reply barrenko 7 hours agoprevWell, the easiest way to enter the ML field is to pivot from theoretical physics. reply VHRanger 6 hours agoparentGeoffrey Hinton wins the Nobel prize in physics for giving physics postdocs more reasonable job market options reply scarmig 4 hours agorootparentThis prize is more of a settler colonialist land grab by physicists. ML is just a subfield of physics (like every other field), so let's make sure that everyone knows that it's in our domain. Speaking as a onetime physicist now in ML... reply dekhn 3 hours agorootparentmachine learning is math, not physics. physics uses math, not the other way around. ML can be used in any field of science, not vice versa. reply wing_rets 2 hours agorootparentThe actual process of computation, sure, but machine learning was born from physics-based methods and applications to understand complexity and disorder. reply theGnuMe 1 hour agorootparentprevI would agree.. But it took Computer Scientists to put neural networks on the map by getting them to scale. Basically by asking the question what happens if we turn it up to 11. Statisticians would never have done that due to parsimony and something something Bayesian. Engineers would never have done it, nor mathematicians either. It took Computer Scientists because it is computation. reply Der_Einzige 3 hours agorootparentprevMath, Logic, Epistemology, et al are not \"subfields of physics\" - The other way around is more likely. reply frotaur 1 hour agorootparentI also had this view, but thinking a bit more about it, what we consider 'reasonable axioms' in math, all come more or less from our logical intuition. Which was built from our evolution, which respects the laws of physics. This has changed my point of view to where math is kinda derived from physics, as the axioms (but even the derivation rules, like modus ponens) are chosen because they respect what feels intuitively 'logical'. But this intuition cannot be disentangled from physics, as it was a product of physics. reply CamperBob2 3 hours agorootparentprevEh, I doubt Hinton would have won if he hadn't turned to alarmism in his dotage. The prizes are as political these days as they are scientific. reply fnands 5 hours agorootparentprevAnd as an ML engineer with a PhD in physics I can tell you that I am deeply grateful that I didn't have to go the postdoc route. I know we are joking around here, but damn, just for that alone I'm happy that he got it. For whether it is actually physics? That I'll leave for another discussion. reply ahdhdixud 1 hour agorootparentprevOk, now I understand why this is a notable achievement in physics reply EXHades 6 hours agorootparentprevlol,All for employment reply alsodumb 6 hours agorootparentprevLol I almost choked laughing at this lmaoo reply holmesworcester 6 hours agorootparent...than finance reply auntienomen 4 hours agorootparentIt's been a generation since it was easy to go into finance from physics. reply WhitneyLand 1 hour agoprev“In 1985 Hinton published a paper ‘How I Intend to Screw Over Physicists by Winning Their Nobel Prize’” As expected iconoclast Sabine Hossenfelder is quick out of the gate with sarcasm and commentary on this one. https://youtu.be/dR1ncz-Lozc?si=7kpntqwCzp0HLi02 reply bijant 1 hour agoparentthank you for wasting 2 minutes of my time as I obviously looked for the paper in parallel to listening to the video XD reply mikaeluman 28 minutes agoprevI think this says more about the state of modern physics than anything else. Sad. reply timonoko 3 hours agoprevWhy is that? I have video of Teuvo Kohonen explaining neural networks in 1985. \"You can stack them\" and \"when a network has learned a skill, you can sell it as separate entity\". What more you want? https://youtu.be/Qy3h7kT3P5I?si=3Klgib0TaTbiG6dC&t=2477 reply ecosystem 3 hours agoparentHopfield associate NNs was several years prior to 1985. reply elashri 8 hours agoprevAs a physicist, my reaction to this is how bizarre is that. Maybe he deserves a nobel prize but in physics? Also arguing that NN is used in physics so we can argue nobel prize is okay is like asking for Stephan Wolfram to be awarded Nobel prize for Mathematica which is much more used in physics as a tool. And he is a physicist and had contributions to the field of numerical relativity (The reason he created Mathematica in the first place). The royal science academy fucked up so much with this choice. reply lr1970 8 hours agoparentBy this definition Claude Shannon (the father of Information Theory) clearly deserves a Nobel in Physics. The central concept in Information Theory is Entropy which is defined literally the same way as in Physics. And Shannon's Information Theory clearly revolutionized our life (tele-communications) much more than Hopfield network or Hinton's Boltzmann machine. reply drpossum 7 hours agorootparentFun historical fact: Claude Shannon did win the Noble prize https://en.wikipedia.org/wiki/Alfred_Noble_Prize#Recipients reply lr1970 7 hours agorootparentIn 1939 Claude Shannon won the \"wrong\" Nobel prize -- The Alfred Noble Prize award presented by the American Society of Civil Engineers [0]. It causes a lot of confusion. Claude Shannon never won a \"real Nobel\". [0] https://en.wikipedia.org/wiki/Alfred_Noble_Prize EDIT: typos reply elashri 7 hours agorootparentprevThat's different local prize by the American society of civil engineers. https://en.wikipedia.org/wiki/Alfred_Noble_Prize reply drpossum 7 hours agorootparentYes. That's the joke. reply hnfong 4 hours agorootparent[party pooping] It would have been better delivery if you said \"a Nobel prize\" instead of \"the\". reply thw09j9m 3 hours agorootparentNoble != Nobel reply hnfong 3 hours agorootparentAh my bad. reply amelius 8 hours agoparentprevIt feels a bit like the field of physics claiming the invention of AI, where we all know that mathematics and/or CS deserve the honor. reply cubefox 7 hours agorootparentSomeone changed the Wikipedia article today to call Hopfield a \"physicist\". Previously the article called him simply a scientist, because his main work wasn't limited to physics. I changed it back now, let's see if it holds up. reply oefrha 7 hours agorootparentprevThe Nobel Committee doesn’t represent the field of physics. I talked to a few former colleagues (theoretical physicists) just now and every one of them found this bizarre. reply alkonaut 8 hours agorootparentprevI think the Nobel prize doesn't want any scientific advance to fall outside the range of awards entirely. reply meindnoch 7 hours agorootparentprev>where we all know that mathematics and/or CS deserve the honor Or semiconductor manufacturers. All the math and CS needed for AI can fit on a napkin, and had been known for 200+ years. It's the extreme scaling enabled by semiconductor science that really makes the difference. reply cubefox 7 hours agorootparentThat's absurd. The computer science needed for AI has not been known for 200 years. For example, transformers were only invented in 2017, diffusion models in 2015. (When the required math was invented is a different question, but I doubt all of it was known 200 years ago.) reply jampekka 7 hours agorootparentprevTBF backpropagation was introduced only in the 1970's, although in hindsight it's a quite trivial application of the chain rule. There were also plenty of \"hacks\" involved to make the networks scale such as dropout regularization, batch normalization, semi-linear activation functions (e.g. ReLU) and adaptive stochastic gradient descent methods. The maths for basic NNs is really simple but the practice of them is really messy. reply miven 7 hours agorootparentResidual connections are also worth mentioning as an extremely ubiquitous adaptation, one will be hard-pressed to find a modern architecture that doesn't use those at least to some extent, to the point where the original Resnet paper sits at over 200k citations according to google scholar[1]. [1] https://scholar.google.com/citations?view_op=view_citation&h... reply programjames 7 hours agorootparentprev> All the math and CS needed for AI can fit on a napkin, and had been known for 200+ years. This isn't really true. If you read a physics textbook from the early 1900s, they didn't really have multivariate calculus and linear algebra expressed as concisely as we do now. It would take several napkins. Plus, statistical mechanics was quite rudimentary, which is important for probability theory. reply zmgsabst 7 hours agorootparentprevI don’t think calculus existed at sufficient rigor 200 years ago. Computer science wasn’t even a thing 100 years ago. reply KeplerBoy 7 hours agorootparentCalculus has been around for quite some time. If Newton had the machinery to fit large models to data, he would have done so. No doubt. reply zmgsabst 6 hours agorootparentCauchy’s main work was under 200 years ago; and there’s been quite a lot of work since. Again, I’m unsure that calculus existed at sufficient level 200 years ago — it didn’t appear in modern form from either Leibniz or Newton. reply rramadass 7 hours agoparentprevRight; the Nobel Committee has officially \"jumped the shark\". Reminds me of the old classic Physics and Politics by Walter Bagehot. reply yreg 7 hours agoparentprev> Maybe he deserves a nobel prize but in physics? Which category fits better? reply nabla9 8 hours agoprevMost commenters here don't know that Boltzmann machines and associative memories existed in condensed matter physics long before they were used in cognitive science or AI. The Sherrington–Kirkpatrick model of spin glass is a Hopfield network with random initialization. Boltzmann machine is Sherrington–Kirkpatrick model with external field. This is price in physics given to novel use of stochastic spin-glass modelling. Unexpected, but saying this is not physics is not correct. reply dawnofdusk 2 hours agoparentAgree completely, being in this field. However, it is weird for the committee to give a prize for theoretical physics without an experiment. It is doubly weird when they already made this \"mistake\" in 2021 with Parisi, who was the odd one out among the geophysicists, and are giving another prize in spin glass/stat phys... why? reply nabla9 1 hour agorootparentIn summary, it's definitely related to physics, but kind of weird choice. Why David Sherrington and Scott Kirkpatrick did not share the price for the Sherrington–Kirkpatrick model? Hopfield is referencing their work? Multiple theoretical physicists working with black holes (Hawkin's and others) didn't get Nobel, because black holes were not confirmed or theory could not be tested. reply twic 7 hours agoparentprevSo if they used a genetic algorithm, they could have got the prize for biology? reply dawnofdusk 1 hour agorootparentThere is no nobel prize for biology reply xqcgrek2 7 hours agoparentprevThe methods may be inspired by physics, but they have made no contribution to understanding physical laws or phenomena. It's mathematical/CS work. The connection to actual physical laws or phenomena is even more tenuous than the prize for exoplanets a few years ago. The Nobel prize physics committee has made itself a joke, and probably destroyed the credibility of the prize. reply parodysbird 6 hours agorootparent> but they have made no contribution to understanding physical laws or phenomena. Neural networks are used in tons of data pipelines for physics experiments, most notably with particle accelerators. The Nobel Prize is also occasionally awarded to engineers who develop tools that are important parts of experiments. 2018 for example was awarded for chirped pulse amplification, which is probably best known for being used in LASIK eye surgery, but it is also used in experimental pipelines. reply hnfong 5 hours agorootparent> Neural networks are used in tons of data pipelines for physics experiments With this argument you could even say Bill Gates should get an award for inventing Windows and popularized the desktop computer... Or at least Linus Torvalds since those pipelines are probably running Linux... reply parodysbird 5 hours agorootparentNo you couldn't. Windows doesn't have any bearing on outcomes, whereas machine learning methods directly impact the data and probability inference. reply slashdave 40 minutes agorootparentprevYeah, well, those pipelines are running on HPCs that are using linux. Particle physicists kind of hate Windows. reply empiko 5 hours agorootparentprevThe techniques highlighted in this prize are not really that useful for deep learning. reply etiam 3 hours agorootparentYou mean besides bringing it into existence at all? reply sudosysgen 1 hour agorootparentThey did not bring it into existence. The MLP is older than the Hopfield network. The invention that made it practical was back propagation, which wasn't used here at all. reply selimthegrim 7 hours agoparentprevAlso double descent was discovered already by physicists in 80s-90s reply archmutant 6 hours agorootparentIn curious what's the context for this? reply amai 4 hours agoprevNobody predicted that: https://www.reddit.com/r/Physics/comments/1f94660/2024_nobel... https://www.reddit.com/r/Physics/comments/1fydwg3/prediction... reply cwiz 3 hours agoprevIt seems physics is natural continuation for those who want understand what's behind the curtains after all. Thanks physicists for providing support for AI scientists. Next phase for joint research is quantum AI where one would need expertise in both physics and ML. reply T-A 1 hour agoparentOld news: https://www.nature.com/articles/nature23474 reply ghrqan 8 hours agoprevWhat an odd rationale. Please do not devalue the Physics Nobel Prize to the status of the Nobel Peace Prize. This is overtly driven by expediency or business interests and ignores all societal problems. Be happy that you get your billions for CERN and keep a low profile. reply napa3uT 7 hours agoparentthis is a painfully accurate description of how we feel we are treated(CERN physicists that is) are you an ex colleague or something :) reply gyre007 7 hours agoprevThis reminded me of my Hopfield networks implementation in Go [1]. The algorithm is rather simple but fascinating nevertheless and works surprisingly well for reconstructing noisy images. I actually blogged about it as well [2]. But as many are discussing here Deep Memory networks based on Boltzmann networks are more powerful yet they don't seem to have found much use case either [1] https://github.com/milosgajdos/gopfield [2] https://cybernetist.com/2017/03/12/hopfield-networks-in-go/ reply protoman3000 8 hours agoprevThis is not physics. Does that mean there was no Nobel Price worthy research happening in the field of physics? reply jeanlucas 8 hours agoprevAwesome. > They trained artificial neural networks using physics Here's from Nobel Prize official website: https://www.nobelprize.org/prizes/physics/2024/press-release... reply avip3d 3 hours agoprevWhy does it fall under physics and not under mathematics? reply lucasban 2 hours agoparentThere isn’t a Nobel prize for mathematics. There is the Fields medal but it is different, and not handled by the same organization. reply gweinberg 1 hour agorootparentTrue, but that's not a very good reason for giving a Nobel Prize in Physics to something that isn't physics. I think the standard way of giving a Nobel Prize to mathematicians is to call it economics. reply AceJohnny2 2 hours agoparentprevthe Nobel Prize doesn't do mathematics. reply uoaei 2 hours agoparentprevThere is no Nobel Prize in Mathematics. reply snitty 8 hours agoprevChemists everywhere are wondering where this furor has been for the forty years or so. reply nullhole 7 hours agoparentPhysicists stole the chemistry prize, now computer scientists are stealing the physics prize, I guess reply hillsboroughman 5 hours agoprevI wonder if they ever gave a Physics Nobel to a person who held a patent! People like Graham Bell never got recognized by the Nobel people. I get the impression that Physics Nobel prizes were more or less given only to University professors. They didnt seem to particularly care for people with grease on their hands reply tombert 4 hours agoparentI don't really know what I'm talking about, but weren't there like 9 Nobel prizes awarded to Bell Labs engineers for physics? One of which (I think) being the invention of the transistor, which presumably had a patent. reply dotnet00 3 hours agoparentprevA post from yesterday, complaining about Musk not receiving a prize despite (according to the author of that post) deserving it, has had me thinking about that too. Folks like Bell, Musk, Bezos etc are in many ways similar to Alfred Nobel, highly successful and very controversial businessmen, where their contributions to the world have had great positives and great negatives. Putting aside the fact that it's also entirely reasonable to say that Musk, Bezos etc, while having changed the world, have not really personally made breakthroughs in fundamental science of the level as to deserve a Nobel prize; I wonder if the Nobel Foundation avoids figures like that because of the parallels. reply anonyfox 3 hours agorootparentCurrently I'd flat out refuse to give any sort of prize to musk, that could be a tipping point for his mental \"stability\" completely breaking down. The last few years really had a toll on him. Fallen from idol to conspiracy rightwing idiot crashing his companies more and more. reply T-A 1 hour agoparentprev\"Nakamura holds 208 US utility patents as of 5 May 2020\" [1] He's also a professor though, so maybe that doesn't meet your criteria. [1] https://en.wikipedia.org/wiki/Shuji_Nakamura reply kspacewalk2 4 hours agoprevI suppose LeCun and Bengio are way too young for a Nobel prize these days[0] [0] https://www.ageing.ox.ac.uk/images/fig01.jpeg reply Chabsff 4 hours agoparentNo, these are the proper laureates (for that topic anyways, whether the topic is appropriate in the first place is another matter). LeCun and Bengio's works are undoubtedly immensely impactful, but there's no denying that they are standing on shoulders of giants. reply scarmig 4 hours agorootparentSchmidhuber enters the room and has lots of things to say. reply mindcrime 4 hours agorootparentWell to be fair, everything important in AI is based on Jurgen's ideas! J/K'ing. That said, Jurgen has done a lot of important work, and may well be a bit under-appreciated. reply scarmig 4 hours agorootparentHe does get a reference in the Nobel announcement, so he can console himself with that at least. reply mindcrime 3 hours agorootparentGood point. I suppose if one is going to not win the Nobel Prize, a decent \"consolation prize\" is at least being referenced in the prize announcement for whoever did win. reply queuebert 4 hours agoparentprevThat is a really strange plot. It looks like they are fitting a really high order polynomial to what is more or less a linear or maybe quadratic trend. And the overfitting exaggerates the recent trend. reply divyaranjan1905 4 hours agoprevHinton has no published books on physics, and his bibliography of papers, to the extent I've examined, lacks any serious contributions to physics. There are underrepresented physicists who never will come close to winning a Nobel. Not to speak of the women in Physics, and the fact that we still have Edward Witten who still isn't worthy of winning a Nobel. As someone who has seen friends and others give up on physics due to being denied for funding and other institutional issues, I am infuriated at this gesture by the Nobel Committee. When was the last time we gave someone a Nobel physics who hasn't bothered writing a book? We have professors dying without a tint of recognition for their work. The whole ordeal is terrible, it's like giving Einstein a Nobel in medicine because his research on photoelectric effect has opened a new domain in biotechnology and because that's the new cool thing in the market, we'll go with that. A lot of the outsiders think \"physics is dead\", but dare they look into the research inside it. It is not at all dead. And arguing that failing to have definitive answers to the Big questions means being 'dead' is a terrible way to look at the field. Math still doesn't have a definite way to look at primes, for centuries we didn't have the definite way to look at algebraic equations of higher degrees and general solutions to them. That didn't make math die, that's what keeps it alive. I am fine with Hoppfield for once maybe, but seriously why Hinton? reply sharadov 2 hours agoprevWouldn't ML and NN fall under the field of mathematics than physics? reply ak_111 8 hours agoprevThe contrast in discoveries made in 'core' physics in the first 25 years of the last centuries compared to this century is quite insane, it was never going to be sustainable. If it did sustain we would be colonising a new galaxy by now. Consider that in 1900 the atom wasn't discovered yet, within around 25 years the basic principles of quantum physics were established, to say nothing about discoveries in cosmology (GR + big bang). reply pyb 7 hours agoprevMaybe the story here isn't so much whether Hinton is a physicist or not, but rather a lack of groundbreaking progress in physics to give the Nobel to. reply xcodevn 2 hours agoprevLooking forward to Hinton receiving a Fields Medal for inventing backpropagation. reply aithrowawaycomm 2 hours agoparentThis is sarcastic, right? https://en.wikipedia.org/wiki/Seppo_Linnainmaa reply xanderlewis 54 minutes agoparentprevIs this a joke? reply hsuz 7 hours agoprevI'd rather they withhold the prize this year, if there isn't really anything interesting happening in physics. reply Izikiel43 2 hours agoprevWeird, this is what the Turing award is for reply sidcool 1 hour agoprevCan someone ELI5 what they did? reply krishnasangeeth 8 hours agoprevTuring award and now Nobel prize in physics, something which he would have never expected. What an amazing career! reply DiogenesKynikos 8 hours agoprevThere's a long backlog of major achievements in physics that haven't gotten a Nobel Prize in Physics. Giving the prize to something that has essentially nothing to do with physics is just a slap in the face to the physics community. reply Kon-Peki 6 hours agoparent> a slap in the face to the physics community The physics community could use a few more slaps in the face, according to many physicists. reply underlines 6 hours agorootparentHere's a resounding 'slap' delivered by one physicist to his peers: https://www.youtube.com/watch?v=cBIvSGLkwJY reply datavirtue 2 hours agorootparentThis is like that sidebar you have with someone after you have joined a series of meetings and listened intently and have all these nagging suspicions and you are in denial about people who you think could not possibly be talking this much nonsense because they clearly should know more than you. A few seconds into the sidebar the person tells you that everyone is full of shit, and you find relief in that you were actually understanding everything you were hearing and yes, you were drawing the right conclusions. reply mhh__ 6 hours agorootparentprevThe response of the physicists they say should get a slap is, in programming terms, basically shut up and show me the code. It's a fairly one sided debate that we're blessed with seeing in literally every thread anywhere about it reply tombert 4 hours agoparentprevIt still kind of baffles me that there isn't a Nobel Prize in Mathematics and/or computer science. The latter makes a bit more sense, computer science wasn't really a thing when Alfred Nobel was around, but mathematics certainly was! It seems like it would be perfectly reasonable to add a category for math, and I think Neural Nets would fit in there considerably better. reply aDyslecticCrow 3 hours agorootparentThe Swedish central bank later added the price in economics (although controversial). So other things can be amended. However, I suspect we won't see any more amendments to the noble price. A different institution can step up and make a price on its own, though I'm not sure what institution would have that amount of prestige without weaponizing it for commercial purposes. I prefer a nicer price for mathematics that includes a bit of computer science than a price for computer science. I don't think there is much room for a \"society-changing innovation\" within CS that isn't either an engineering feat (Linux, Docker, FFmpeg) or an algorithm that could fit under a mathematics price (FFT, Navier Stokes). reply Findecanor 2 hours agorootparentIf a new prize is added, it would need its own funding. The five original Nobel Prizes are funded by interest from the fortune that Alfred Nobel left behind. The economics prize is funded by the Swedish central bank, and is therefore officially their prize \"in memory of Alfred Nobel\", not a \"Nobel Prize\" as such. reply tombert 1 hour agorootparentprev> I don't think there is much room for a \"society-changing innovation\" within CS that isn't either an engineering feat (Linux, Docker, FFmpeg) or an algorithm that could fit under a mathematics price (FFT, Navier Stokes). I'm not sure I agree with that. There's plenty of theoretical computer science that isn't really \"engineering\" and would fall into a pretty different category than stuff like FFT or Navier Stokes. If you look at something like Concurrency Theory, for example, and work with stuff like Pi Calculus or CSP or Petri Nets, those aren't \"engineering feats\", but also kind of fall into a different category than the rest of math, or at least pretty different than Navier Stokes. I think you could make a pretty strong argument that CSP has been a pretty big innovation in regards the academic state of the art while not simply being engineering. reply aDyslecticCrow 1 hour agorootparentLet me add RSA, Elliptic curves, Runge–Kutta, Finite element analysis, and Hamming codes to the list. I would still consider CSP, Petri Nets, and Pi-Calculus mathematical enough to be wrapped under a mathematics price if they're influential enough. The first true computer scientists were mathematicians, and I still feel that much of the theoretical work in the field is closer to \"mathematics useful for computers\" than its separate field. In the spirit of the nobel price, \"mathematics with the greatest humanitarian impact\" leaves plenty of room for the inclusion of influential pieces from theoretical computer science, especially as those prices within mathematics that do exist already include loads of mathematics that require computers to prove or solve. reply tombert 47 minutes agorootparent> I would still consider CSP, Petri Nets, and Pi-Calculus mathematical enough to be wrapped under a mathematics price if they're influential enough. I guess, but they certainly feel categorically different than something like Runge-Kutta. They're more about the study of algorithms, which is generally where I've drawn the line of \"computer science vs math\". reply lukasga 3 hours agorootparentprevThe story is that it is because Alfred Nobel was cheated on by a mathematician (hilarious, but unconfirmed) http://nobelprizes.com/nobel/why_no_math.html#story reply shombaboor 3 hours agorootparentprevthe fields medal fills that gap reply tombert 1 hour agorootparentYeah, and the Turing Award for CS, and there's probably a bunch more that I'm forgetting. Still kind of weird that the prestigious award that everyone has heard of doesn't have a mathematics category. reply shombaboor 1 hour agorootparentthe nobel prize has the best branding and name brand recognition pop culture wise. I'm sure winning all these others means nearly as much to those communities. reply drpgq 3 hours agorootparentprevI'm surprised someone hasn't done it similar to the economics award that came later. reply canjobear 2 hours agoparentprevI understand the frustration, but a lot of Geoff Hinton's foundational work was based on physics principles. For example https://proceedings.neurips.cc/paper/1993/file/9e3cfc48eccf8... reply DiogenesKynikos 34 minutes agorootparentInformation theory, which is foundational to computing, has some mathematical similarities to statistical mechanics. That doesn't make it physics. reply gandalfgreybeer 2 hours agoparentprevMy adviser's PhD dissertation (PhD Physics) has Hopkins as one of her major references. This is grounded in Physics. reply hcks 6 hours agoparentprevCould you please list say the top 5 Nobel worthy achievements of this backlog reply cosmic_quanta 7 hours agoparentprevI can only think of major achievements in my (narrow) field of study. What do you think could have reasonably been awarded? reply nodfyr 6 hours agorootparentThe computation of the cosmic microwave background fluctuations hasn't received a nobel prize yet. It's had a deep impact on how we understand the Universe. Some people still alive who made important contributions to this are Rees and Sunyaev. reply DiogenesKynikos 7 hours agorootparentprevThree off the top of my head: The measurement of the Hubble constant using delay times between multiple images of lensed supernovae. The first transit spectrum of an exoplanet atmosphere. The first directly imaged exoplanet. (They could hand out Nobel Prizes in the field of exoplanets like candy.) reply Workaccount2 4 hours agorootparentAlfred Nobel's stated standard for a prize is: \"conferred the greatest benefit to humankind\" So while those things are cool and groundbreaking, I'd say they have yet to cross the threshold into \"greatest benefit to humankind\" reply DiogenesKynikos 30 minutes agorootparentIf you define \"benefit to humankind\" narrowly, and don't view gaining pure knowledge about the workings of the universe as beneficial to humanity, then most physics Nobel Prizes over the last few decades fail the test. Detecting gravitational radiation from the merger of two black holes was an incredible step forward for our understanding of the universe. It will not practically change your life in any way. reply xqcgrek2 7 hours agorootparentprevExoplanet science is not physics, it's chemistry or planetary science. By your logic prizes to teams who send probes to the outer solar system planets could also be given prizes. reply YeGoblynQueenne 6 hours agorootparentWhat's \"exoplanet science\"? The above are applications of knowledge of physics to astrophysics, as far as I understand it. Certainly they sound more relevant to physics than neural networks. reply cosmic_quanta 6 hours agorootparentprevI would argue that the first measurements of exoplanets' existence is definitely physics. This was a leap in our understanding of the makeup of the universe. reply bfmalky 6 hours agorootparentprevOk, so under what logic does ML become physics? reply topaz0 3 hours agorootparentprevSomething for nonequilibrium statistical mechanics reply amusedcyclist 4 hours agoparentprevYeah this is absolutely disgusting tbh, revising my opinion of all previous nobels way down now reply bogtog 8 hours agoprevI wonder if this'll help physics PhDs get industry jobs (I hear Myron Scholes is up for the 2025 prize) reply hellectronic 8 hours agoparentYou mean like the ones working on Wall Street? reply vasco 8 hours agorootparentIf you google who Myron Scholes is you'll see the person you replied to made the same assertion already. reply eleveriven 7 hours agoprevA profound moment where physics, neuroscience and artificial intelligence intersect. reply seydor 7 hours agoparentvery little to do with neuroscience reply whymauri 2 hours agorootparentIt's funny because I learned about Hopfield multiple times in neuroscience classes, but never once in an EECS/ML course. reply dboreham 4 hours agorootparentprevAt the very least neuroscience provides an \"existence proof\". Somehow this stuff must be possible using some sort of trained machine comprising a large number of simple components... reply Separo 7 hours agorootparentprevExcept that the development of deep neural networks took direct inspiration biological neuroscience with neurons and synapses. Neural is even in the name. https://en.wikipedia.org/wiki/Deep_learning reply raincole 7 hours agorootparentstill, very little to do with neuroscience reply seydor 5 hours agorootparentprevActually iirc the first deep architectures that Hinton trained were restricted boltzmann machines reply Insanity 5 hours agorootparentprevI’m actually not sure why this is being downvoted? Is it actually incorrect and if so, where did it take inspiration from? reply Maxatar 3 hours agorootparentThe downvotes are very unusual to say the least. All the historical material on the subject unambiguously points to neural networks emerging from work done to formalize actual brain neurons. That formalism turns out not to be a great way to explain biological brains but the abstraction it provided proved highly effective for tasks like pattern recognition, classification, and decision making. So much about computer science has been inspired from other fields such as biology. Polymorphism and object oriented programming, reification, neural networks and in particular convolutional neural networks, genetic algorithms... If anything, it teaches the value in learning a topic and then applying it directly within computer science. The strength of computer science lies in its ability to adapt and incorporate ideas from other domains to push the boundaries of technology. reply littlestymaar 6 hours agorootparentprevIt was a source loose of inspiration for sure, but it still have nothing to do with neurosciences. “Neural” network are as close to actual nervous system as the “Democratic” Republic of Korea is to democracy. reply elcomet 6 hours agorootparentYou're mistaken. The perceptron was invented by Rosenblatt, a psychologist. This field has deep roots in neuroscience. reply scarmig 5 hours agorootparentMcCulloch and Rumelhart were psychologists as well. reply almostgotcaught 4 hours agorootparentprevPeople always repeat these stupid things like they're lore. Ok let's suppose this is true. What else is true is that neurology itself was inspired by phrenology and the practice of exorcisms. Should we now start recognizing and exalting those connections given how divorced modern (useful!) neurology is? reply scarmig 4 hours agorootparentHinton's most recent paper on forward-forward acknowledges Peter Dayan explicitly for his feedback on the paper, and cites a paper they cowrote together back in the 90s. Dayan being the author of the canonical textbook on theoretical neuroscience. reply SkyBelow 4 hours agorootparentprevMajor distinction given those practices have been abandoned as pseudo science or even worse, so they aren't fields of science continued to be developed which further useful connections might be found. In psychiatry, there is a certain amount that we continue to study social standards of normalcy in other (including historic) societies to determine what should count as a mental disorder, but more to make sure we aren't doing a 21st century equivalent of labeling something as a demon possession because it contrasts with our current deeply held social norms. reply SkyBelow 4 hours agorootparentprev>nothing to do with So what is the meaning of to do with and nothing to do with? Inspiration seems to be a relationship. Consider a different relationship between cellular biology and the Cells at Work anime. Clearly any relationship is unidirectional. Any cellular biology learns nothing from the anime, but the anime wouldn't exist without cellular biology. Do we say the show has nothing to do with cellular biology? That doesn't seem right to me, given it depends upon it despite taking an amazing degree of artistic freedom. reply FrustratedMonky 6 hours agorootparentprevWell, come on, not that far apart. When I see someone trying this hard to be smart I just hear \"REEEEEEEEE\" or \"Well actually......\" reply comment423 6 hours agorootparentprevMore to do with neuroscience than you think. Fukushima took direct inspiration from Hubel & Wiesel's nobel prize in the 1960s when developing the neocognitron, which turned into convolutional neural networks. Hopfield networks are a model for associative memory. And, well, then there is the perceptron. There was always a link and mutual inspiration. Recommended reading: Lindsay, G. W. (2021). Convolutional neural networks as a model of the visual system: Past, present, and future. Journal of cognitive neuroscience, 33(10), 2017-2031. https://direct.mit.edu/jocn/article-abstract/33/10/2017/9740... reply aDyslecticCrow 3 hours agorootparentAs inspiration, yes. However, a neural network neuron and a biological neuron are, to modern understanding, entirely unrelated. reply canjobear 2 hours agorootparentThey're not identical but they are related. There's a series of approximations and simplifications you can go through to get from biological neurons to neural nets. Essentially the weights in the neural net end up corresponding to steady-state firing rates of populations of spiking neurons. See for example Chapter 7 of Dayan & Abbott's Theoretical Neuroscience. reply NotYourLawyer 7 hours agorootparentprevVery little to do with physics. reply splintfrog89 7 hours agoprevReal physics and its resulting breakthrough technologies have been hidden from society for a very long time. And so they simply need somebody they can give that price to. reply sva_ 8 hours agoprevHas anyone else won a Turing award as well as the Nobel prize in physics? reply isaacfrond 8 hours agoprevPhysics Nobel prize now also covers computer science, I guess. reply programjames 8 hours agoparentMeh, neuroscience. reply molli 4 hours agoprevHinton: Studied psychology, became cognitive scientist. Schmidhuber: Studied cs and math, developed algorithmic theory of the computable universe. Hinton wins Nobel price in physics. reply meindnoch 7 hours agoprevBaffling. If this isn't a sign of a major crisis in physics, then I don't know what is. reply kdavis 1 hour agoprevAs someone who has done lots of work in both fields, this is some BS. reply amai 7 hours agoprevPeak AI Hype! Winter is coming! reply chx 18 minutes agoprevI posted https://hachyderm.io/@chx/113272153511607297 > So they gave the Nobel Physics prize to AI bros before honoring another woman. Five women were ever honored so and 221 men. > This is your regular reminder Wikipedia refused an attempt to create a page for Donna Strickland with \"This submission’s references do not show that the subject qualifies for a Wikipedia article\" not half a year before she became a Nobel laureate. Katalin Kariko's page was not created until April 27, 2020. #EverydaySexism #SystemicMisogyny It got a decent amount of favs and retoots - and no angry responses. Now, when I posted this here, it got flagged. That tells a hell lot about the people who visit the site. It's a great opportunity to check your own biases. That's why I am reposting it with this note. reply dev1ycan 2 hours agoprevYou can't take this back, this literally just discredited the only nobel that actually mattered, great job discrediting the nobel. reply gandalfgreybeer 2 hours agoparentTwo of my research advisers whose dissertations in PhD Physics had Hopfield as their primary reference. I'm also a PhD candidate working on one right now (no longer my primary reference because of all the developments) but I can trace several of my main references back to them. reply uoaei 2 hours agoparentprevThis is an appropriate application of this prize considering the adage that there are now three pillars to science, the third being simulation (after theory and experiment). Also, many of the underlying theories in machine learning display deep analogy with physical laws we are already familiar with, e.g., thermodynamics. Machine learning is much bigger than chatbots. reply OneDonOne 2 hours agorootparentWhat Nobel-worthy physical, chemical, or biological process has been solved/discovered in silico? reply moralestapia 2 hours agorootparentprevHey! >the adage that there are now three pillars to science, the third being simulation (after theory and experiment) Any specific place I could learn more about this? (aside from Google obv.) I do simulation for a living, so that is mega-interesting to me. reply uoaei 42 minutes agorootparentI heard it from a professor who was a researcher in magnetohydrodynamics, studying flows on and under the surface of the sun. I don't know where to read more unfortunately, I'm not sure where it'sbeen fleshed out as an ideology. reply throw_m239339 6 hours agoprevCongrats to the laureates! Maybe a Computing prize should be created though, like Nobel did not create the \"nobel prize of economy\".Though you could argue that Computing is Math? What are computer scientists usually awarded with? edit: s/rewarded/awarded reply jvanderbot 6 hours agoparentI think there's some backlash against a google-able answer here. However, from memory the list of biggest awards for CS/Math are: Fields medal Abel prize Turing award Godel award reply seanhunter 5 hours agorootparentI don't think Geoff Hinton is in the running for a Fields medal[1] any more, unless they did what they did for Andrew Wiles and give him a \"quantized\" Fields medal. [1] You have to be under 40. https://www.fields.utoronto.ca/aboutus/jcfields/fields_medal... reply amarcheschi 6 hours agorootparentprevKanellakis award too for theoretical cs https://en.m.wikipedia.org/wiki/Paris_Kanellakis_Award reply astura 6 hours agoparentprev>What are computer scientists usually rewarded with? The Turing Award is considered by most to be the highest award in computer science. reply jprete 6 hours agorootparentHinton already won a Turing award, so this Nobel just seems doubly absurd. I hope he turns it down, but it's a monetary prize too and it takes a lot of dedication to science to turn it down. reply FredPret 5 hours agorootparentIsn’t he a socialist? reply Vecr 2 hours agorootparentDoesn't matter. He wants to work on AI risk, right? reply FredPret 2 hours agorootparentUnsure of your point - I meant he doesn’t believe in provate property, so the prize money shouldn’t be a factor. If he truly believes what he says he believes. reply Vecr 1 hour agorootparentBecause you can use money to do things? Even if you don't want private property after AGI, you need it now. reply FredPret 1 hour agorootparentBelieving that you can do a better job of allocating your Nobel prize money than a central authority is free-market thinking. If he’s a socialist, he should donate all his property to the government, including the entire prize money. reply throw_m239339 5 hours agorootparentprevOh yeah! I forgot about this one! Extremely prestigious in CS but less known by the public unfortunately. reply jwilk 8 hours agoprevSee also https://news.ycombinator.com/item?id=41775449 (> 40 comments). reply lr1970 8 hours agoprevHonestly, I am stunned by today's Nobel committee announcement. Hinton's Boltzmann machine is a clever construct that nobody, repeat nobody, in the AI and ML is using anymore in actual practice. EDIT: add minor clarification. reply FrustratedMonky 4 hours agoprevWhat if I were to tell you that Physics included more than Theoretical Particles? Are experimental Physicist just Engineers? Are String Theorists just Mathematicians? Is John von Neumann not a Physicist because he also worked with Computers? Awful lot of nit-picking in this thread. reply blululu 2 hours agoparentPhysics is pretty old and it has always been about understanding the fundamental structure of reality. If it doesn’t tell you how it all goes round then it is not physics: plain and simple. reply FrustratedMonky 1 hour agorootparentDo physicists know the fundamental structure? They have some mathematical approximations that work for some measurements. They can make some predictions in some areas, but the same approximations break down in other areas. So the fundamentals aren't 'known'. Some think measurements is engineering. So are the physicist that focus on building an apparatus to measure a theory, they are engineers? So only the theoretical people doing math are physicist? Even thought at that point they are only doing math? Is Information Theory and Entropy a Computer Science subject or a Physics subject? reply slashdave 34 minutes agoparentprev> Are String Theorists just Mathematicians? Umm... well reply rramadass 3 hours agoparentprevNo; The Nobel Committee has done a complete error in judgement with this. These are Mathematics/CS techniques and nothing whatever to do with core Theoretical/Experimental Physics notwithstanding that they may have been inspired from Physics. There are plenty of Physics Researchers toiling away at real hard problems of the Physical World and instead of recognizing them the Committee has gone with \"market fads\" which themselves were only realizable due to Hardware advances at scale over the past decade. With this award they have disheartened and demotivated all true Physics Researchers which is a huge disservice to the Hard Science Community. This is not to say that AI/ML researchers/community are not worthy of recognition. But they should not be folded under Physics rather a new category should have been created and they then awarded under it. reply FrustratedMonky 1 hour agorootparentI think there has now been enough crossover between Information Theory and Quantum Mechanics, that we can stop splitting hairs between \"it's an algorithm on a computer, that isn't physics\". reply RandomLensman 8 hours agoprevMaybe just scrap the categories and have set or prizes for whatever sort of advanced humanity the most? reply kwar13 7 hours agoprevIn physics...? reply logicchains 8 hours agoprevImagine how Schmidhuber's feeling right now. reply throwaway2562 8 hours agoparentAlas, poor Jurgen! I knew him, Horatio. A fellow of infinite jest, of most excellent fancy… reply cubefox 7 hours agoparentprevI'm sure he writes an article pointing all the errors in the official justification for the prize. reply versteegen 7 hours agoparentprevThat was my almost immediate reaction to the headline! Rarely credited but rarely forgotten. reply beautifulfreak 8 hours agoparentprevreference: https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber#Credit... reply bobosha 8 hours agoparentprevhaha! reply jeffwass 8 hours agoprevAs a former physicist (PhD in Experimental condensed matter physics), I have to ask WTF? I get the importance of AI development, but Physics? reply tmelm 8 hours agoparentI'm equally as confused; huge WTF moment. Seems like a paradigm breakthrough, in that Nobel Prizes can be given for discoveries in tangential fields. Or perhaps it's due to Dr. Hopfields physicist status, that all his discoveries are considered physics related? Or that NNs are considered a part of physics / nature? reply Alifatisk 8 hours agoparentprevYeah I was wondering the same, I get that this was fundamental work, but how was this strongly tied to physics? reply aborsy 7 hours agoprevTerrible. Hopfield networks nobody cares about, and few heard of? reply karavelov 8 hours agoprevWaiting for Sabine's comment: \"Told you so, physics is dead\" reply noobermin 8 hours agoparent\" And the 2024 Nobel Prize in Physics does not go to physics... \" https://x.com/skdh/status/1843592351736050053 reply varjag 8 hours agoparentprevNaturally she's not happy https://x.com/skdh/status/1843592351736050053 reply lucaslucasluke 5 hours agorootparentCould you copy and paste her post in here? I'm brazilian and our STF overlords have decided that we shall not access twitter anymore reply hnfong 4 hours agorootparentThe other comment (sibling of the one you replied to) already quoted the entire tweet. (Yes it's short and snarky.) reply ngcc_hk 5 hours agoprevNot really related to physics per sec, but to let physicist to get out of research in physics. The most self-denial award ever. But machine learning deserve a prize. Just this … anyway congratulations reply pknerd 1 hour agopreveh..is it some kind of hallucination by \"NobelGPT\"? reply deepnet 8 hours agoprevAs a former Alumni of Hinton’s MOOC I can attest to his humble, kind nature and clarity, & erudition as a teacher. Modelling learning as entropy, and heat in his Boltzmann machines was genius as was the 1980s backdrop paper. Geoff tirelessly evangelised neural nets and machine learning right from his 1970s phd days at Edinburgh. Despite being in the academic wilderness during the many decades of symbolic AI. Moore’s law ( & parallel processing via GPUs ) finally caught up with Geoff’s vision and proved him right. Well deserved ! reply chubot 1 hour agoprevI definitely think their work is deserving of awards, but I kinda agree with other commenters in that this says more about the Nobel committee than anything i.e. Hinton has already won a Turing Award in 2018, and there is no Nobel for computer science And this work was already recognized to have impact ~12 years ago, when he auctioned his company of 2 grad students to Google/Microsoft/Baidu/Facebook, for over $40M, ultimately going with Google [1] --- i.e. IMO it feels a little late / weird / irrelevant to be giving this award in physics to machine learning research – it doesn’t feel like that would have happened without the news cycle At least IMO the scientific awards are more interesting when they're leading indicators, not trailing ones -- when they are given by peers, acknowledging impact that may happen in the future. Because it often takes decades to have impact, and it may occur after the researcher has passed away --- [1] https://www.amazon.com/Genius-Makers-Mavericks-Brought-Faceb... - good book if you’re interested in how technology transfer happened in the last 10-15 years reply whatshisface 1 hour agoparent>IMO it feels a little late / weird / irrelevant >scientific awards are more interesting when leading indicators Peter Higgs waited 50 years, the Nobel is not a \"leading indicator.\" If it was, it would be given out on the basis of the \"hype cycle,\" which would not be very helpful to anybody. reply chubot 58 minutes agorootparentWell, it's possible to wait 50 years, and still NOT have realized the full impact of your work in society Sometimes science/engineering turns out like that e.g. I think Claude Shannon is like that -- his impact continues to rise, and he's viewed as more important after he died He apparently never won a Turing Award or Nobel Prize, probably because there was and is no Nobel in computer science https://en.wikipedia.org/wiki/Claude_Shannon#Awards_and_hono... So I guess I mean \"drawing attention to something that would have not otherwise had attention\", and based on the consensus of people working in the field reply meepmorp 57 minutes agorootparentprevThe Higgs boson was first detected in 2012 and he won the Nobel the following year. Saying he waited 50 years for the prize is a bit disingenuous. reply martopix 45 minutes agorootparentNot the poster, but I don't understand the downvotes: this is exactly right. Higgs was awarded the Nobel after the mechanism he theorized was experimentally confirmed, and that is 100% the reason it took so long. reply meepmorp 36 minutes agorootparentRight! Einstein didn't get the Nobel because the theory of relativity is awesome, he got it after Eddington observed gravitational lensing during an eclipse, confirming a key prediction. Brilliant theorizing can be both brilliant and wrong. reply kragen 35 minutes agorootparentEinstein got the Nobel Prize for his work on quantum physics, not relativity. reply kibwen 51 minutes agorootparentprevIt's not disingenuous, the Higgs mechanism was theorized in the 60s: https://en.wikipedia.org/wiki/Search_for_the_Higgs_boson reply DiogenesKynikos 8 hours agoprev\"The Nobel Prize for Stuff We Think is Cool.\" reply anonymousDan 8 hours agoprevWhat a bunch of BS, yet another field trying to steal the thunder of CS. How often have I had to listen to physicists sneer at CS as not a proper science! reply napa3uT 7 hours agoparentthanks the feeling is mutual since comp scientists sneer at physicists too, just for other reasons reply anonymousDan 5 hours agorootparentReally? Why would comp scientists sneer at physicists? reply cfcf14 8 hours agoprevSo uh, things are not looking so good for actual physics these days, I gather? reply oefrha 7 hours agoparentFormer high energy theorist here: things are not looking so good for high energy physics (both theoretical and experimental) which loosely speaking accounted for maybe 1/3-1/2 of Nobel Prizes in the 20th century. That’s part of the reason I got out. I’m inclined to say astrophysics and cosmology, another pillar of the fundamental understanding of the universe, isn’t doing that well either, probably in the okayish but not as exciting as it used to be territory. I’m not qualified to talk about other fields. reply dotnet00 7 hours agorootparentI think saying they're not looking good might be a bit of an exaggeration. Technological developments in both high energy physics and astrophysics stuff are in-between generations of technology right now, which is why things are a bit slower than usual. With astrophysics, we're probably going to need the more sensitive gravitational wave detectors that are in development to become operational for new big breakthroughs. With high energy physics, many particle colliders and synchrotron light sources seem to be undergoing major upgrades these days. While particle colliders tend to get the spotlight in the public eye and are in a weird spot regarding the expected research outcomes, light sources are still doing pretty well afaik. This Nobel I think is mainly because AI has overwhelmingly dominated the public's perception of scientific/technological progress this year. reply T-A 1 hour agorootparent> With high energy physics, many particle colliders and synchrotron light sources seem to be undergoing major upgrades these days. AFAIK synchrotron light sources are tools for materials science and other applied fields, not high energy physics. Did I miss something? I am also puzzled by the \"many particle colliders\". There is currently only one capable of operating at the high energy frontier. It's getting a luminosity upgrade [1] which will increase the number of events, but those will still be the 14 TeV proton-proton collisions it's been producing for years. There is some hope that collecting more statistics will reveal something currently hidden in the background noise, but I wouldn't bet on it. [1] https://home.cern/science/accelerators/high-luminosity-lhc reply juanjmanfredi 3 hours agorootparentprevWhat are you considering \"high energy physics\"? \"1/3-1/2 of Nobel Prizes in the 20th century\" is a significant overestimation unless you are including topics not traditionally included in high energy physics. For example, there were many Nobel prizes in nuclear physics, which shares various parallels with high energy physics in terms of historical origins, experimental techniques, and theoretical foundations. But nuclear physics is in a very exciting era of experimental and theoretical developments, so your \"not looking so good\" description does not apply. reply oefrha 2 hours agorootparentMuch of nuclear physics was effectively “high energy physics” (or more appropriately named elementary particle physics) back in the day. They ceased to be elementary or high energy at some point. My very loose categorization is everything on the microscopic path towards the fundamental theories; and there’s another macroscopic path, cosmology. Edit: Expanded a few times. reply nullindividual 5 hours agorootparentprevAs a layman, the visualization of black holes, the superstructure above and below the Milky Way, JWST’s distant galaxy discoveries, gravitational wave detectors as mentioned, and some of the Kuiper Belt observations all seem to be interesting and exciting. Oh and the death of string theory! reply sva_ 8 hours agoparentprevInteresting thought. I hear some voices saying theoretical physics is stuck with string theory, but am not really qualified to make a judgement. reply rty32 8 hours agorootparentNobel prize was awarded to theoretical work in 2021: https://www.nobelprize.org/prizes/physics/2021/popular-infor... \"theoretical physics\" is such a big and ambiguous concept that physicists tend not to use the word in discussions. Thereotical work often involves a lot of numerical simulation on super computers these days which are kind of their own \"experiments\". And it is usually more productive to just mention the specific field, e.g. astronomy, condensed matter, AMO etc, and you can be sure there is always a lot of discoveries in each area. reply drpossum 8 hours agorootparentprevPhysics is not stuck in string theory as physics is not just high energy theoretical particle physics. There's also more going on in high energy theoretical particle physics than just \"string theory\". reply Animats 7 hours agorootparentMuch of the experimental action in recent decades has been in low energy theoretical particle physics. Down near absolute zero, where quantum effects dominate and many of the stranger predictions of quantum mechanics can be",
    "originSummary": [],
    "commentSummary": [
      "The Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton for their contributions to neural networks and machine learning, which has sparked surprise and debate.",
      "Critics argue that their work does not fit traditional physics, suggesting either a scarcity of groundbreaking physics discoveries or an attempt to leverage AI's current popularity.",
      "This decision has prompted discussions about the relevance of existing Nobel categories and the potential need for a separate prize dedicated to computer science."
    ],
    "points": 632,
    "commentCount": 586,
    "retryCount": 0,
    "time": 1728381166
  },
  {
    "id": 41776324,
    "title": "Differential Transformer",
    "originLink": "https://arxiv.org/abs/2410.05258",
    "originBody": "Computer Science > Computation and Language arXiv:2410.05258 (cs) [Submitted on 7 Oct 2024] Title:Differential Transformer Authors:Tianzhu Ye, Li Dong, Yuqing Xia, Yutao Sun, Yi Zhu, Gao Huang, Furu Wei View PDF HTML (experimental) Abstract:Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, Diff Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models. Subjects: Computation and Language (cs.CL); Machine Learning (cs.LG) Cite as: arXiv:2410.05258 [cs.CL](or arXiv:2410.05258v1 [cs.CL] for this version)https://doi.org/10.48550/arXiv.2410.05258 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Li Dong [view email] [v1] Mon, 7 Oct 2024 17:57:38 UTC (429 KB) Full-text links: Access Paper: View PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.CLnewrecent2024-10 Change to browse by: cs cs.LG References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=41776324",
    "commentBody": "Differential Transformer (arxiv.org)332 points by weirdcat 7 hours agohidepastfavorite127 comments islewis 2 hours ago> Differential attention takes the difference between two softmax attention functions to eliminate attention noise If I understand correctly, this architecture trades twice as much attention memory in exchange for either a higher quality model, or less parameters at a similar quality. > According to the fitted curves, 6.8B-size DIFF Transformer achieves a validation loss comparable to 11B-size Transformer, requiring only 62.2% of parameters This raises a few questions for me: - Would having only 60% of the parameters negate the double space for attention, leaving a similar memory profile as a traditional transformer? - Does that tradeoff change noticeably between training and inference? reply _hl_ 1 hour agoparentMy understanding was that the extra parameters required for the second attention mechanism are included in those 6.8B parameters (i.e. those are the total parameters of the model, not some made-up metric of would-be parameter count in a standard transformer). This makes the result doubly impressive! Here's the bit from the paper: > We set the number of heads h = dmodel/2d, where d is equal to the head dimension of Transformer. So we can align the parameter counts and computational complexity. In other words, they make up for it by having only half as many attention heads per layer. reply chessgecko 58 minutes agoparentprevI think they mitigated the extra memory/compute from this by using half the number of overall heads and doubling V and O. Without actually checking the math I think it should be equivalent in flops, not counting the extra (cheap) multiply by const and subtract. reply Kubuxu 56 minutes agoparentprevIt would double the size of the KV cache, which can be significant (multi-GB) at larger context sizes. reply entropicdrifter 2 hours agoparentprevI think it would negate the RAM savings, but it would also reduce the amount of storage needed at rest and possibly reduce initial start up times depending on storage speed and model size. So, possibly good for low-end models on consumer devices? reply aDyslecticCrow 3 hours agoprevVery clever. I like this kind of nitty-gritty detail work, and the change is small enough to be adapted easily by others. Bravo! I'm a little concerned about the last sentence of the section introduction of \"2 Differential Transformer\". It mentions using improvements from previous papers, but in the grammatical context, it's unclear if this improvement is added to both the normal transformer and their diff transformer. This would otherwise sully the comparisons. It's the \"main difference\" wording in the previous sentence that raised a flag for me. Of course, a good-faith researcher would know this and may not feel the need to clarify. But you can never be too careful about some published research in this field. reply Chirono 3 hours agoparentThe two other changes they mention have been widely adopted, and are included in at least some of the models they benchmark against. It seems they list them for completeness as changes to the original transformer architecture. reply aDyslecticCrow 1 hour agorootparentNicely spotted! Then, I really look forward to seeing this method tested by others! Epic stuff. reply Imnimo 1 hour agoprevI feel like I'm missing a key insight here. I understand the problem that regular softmax attention struggles to approach assigning zero attention to irrelevant stuff. And I get that having this subtraction formula makes it possible to assign exactly (or near) zero attention weight without having crazy outlier activations. But it seems like it also makes it very easy to have negative attention weight (which is equivalent to having positive attention weight on the negation of your value vectors). Intuitively, it just feels like a difficult balancing act to keep all the stuff you don't care about so close to zero. But Figure 1 clearly shows that it works, so I don't doubt that it is in fact possible. I'm just struggling to build a picture of how exactly the network accomplishes this. reply watsonmusic 1 hour agoparentnegative values can enhance the expressibility reply Jerrrrrrry 24 minutes agorootparentdoubt is the seed of reason reply msoad 5 hours agoprevLike most things in this new world of Machine Learning, I'm really confused why this works? The analogy to noise-cancelling headphones is helpful but in that case we clearly know which is signal and which is noise. Here, if we knew why would we even bother to the noise-cancelling work? reply chessgecko 2 minutes agoparentMy hypothesis for why this works that it mitigates the downsides of rope to eli5: rope is the modern strategy used to give information to the model about how far a query and a key are apart when doing attention. It's the best strategy we have now, but has a major downside, where it makes some connections between tokens that are far apart much stronger than you would like them to be. Xpos (https://arxiv.org/pdf/2212.10554) is another paper by microsoft tackling issues with rope and you can see figure 1 on page 4 to get a visual interpretation of the sinusoidal attention strength (you would like it to be smooth). I think a big reason differential transformers is working so well, especially on long sequence stuff, because when both q1 and q2 don't match a token, the rope relative strength will still have the same value and the noise will cancel out. Leaving intended matches, but at the cost of somewhat dampening the original value rope brought. Just a hypothesis though. It would be easy to test by running this experiment against a baseline where both use alibi attention (https://arxiv.org/pdf/2108.12409) which has a different set of tradeoffs this wouldn't mitigate, but still a really interesting result. reply blackbear_ 4 hours agoparentprevWith a single softmax you cannot predict exactly 0, but only very small numbers. When you have a large number of values to add up, this \"poisons\" the output with a lot of irrelevant stuff (the noise mentioned in the paper). To make things worse, low attention values will have very low gradient, thus needing a lot of weight updates to undo that kind of mistakes. On the other hand, subtracting the output of two softmax allows the model to predict a weight of exactly zero for some of the values, while keeping a reasonable gradient flowing through. So the model already knows what is noise, but a single softmax makes it harder to exclude it. Moreover, with a single softmax the output of all heads is forced to stay in the convex hull of the value vectors, whereas with this variant each head can choose its own lambda, thus shifting the \"range\" of the outputs outside the convex hull pre-determined by the values. This makes the model as a whole more expressive. reply nyrikki 2 hours agorootparentWhile I don't discount the value of this, can you expand on the meaning of your claim that it makes the model 'more expressive' Everything I am seeing in this paper is related to reduced size and noise, which implies a reduction in expressiveness. The improvement in needle and a haystack, benchmarks on multi-hop questions of in corpus data and multishot in-context learning points to this. This is a wonderful thing if robustness is more important than generality, but it doesn't address trimming away activations that may be spurious in the general use case but may improve an individual domain specificity. Context would dramatically impact what tradeoffs and more desireble, and noise is probably never desirable. But the ability of this paper to enable bit size for inference points to a reduction in expressiveness. Perhaps I am too focused on generalization? reply freeqaz 4 hours agorootparentprevI'm able to follow most of what you're saying. It's unclear to me what \"convex hull\" means though. Also, where is each softmax happening here? For each attention head? reply Majromax 4 hours agorootparent> It's unclear to me what \"convex hull\" means though. The convex hull (https://en.wikipedia.org/wiki/Convex_hull) of a set is the smallest convex shape that includes that set. Geometrically, it's what you'd get if you \"shrink wrapped\" the thing you're looking at: edges still protrude, but any indentations get smoothed over. In this context, the grandparent comment is pointing out that with a traditional transformer block, the resulting computed value for a token can never \"stick out\" past some weighted average of the values of attended-to tokens, but this differential attention formalism allows that result. reply blackbear_ 4 hours agorootparentprevThe convex hull of a set of points is the region \"between\" those points. So the convex hull of three points (that do not lie on the same line) is a triangle with those three points as vertices. If you add a fourth point inside the triangle, the convex hull remains the same, but if you add it outside then the convex hull becomes the four-sided region with those points as vertices. In the context of standard transformer attention, each output lies in the convex hull (\"somewhere between\") the input values. With the modification of this paper, the input values can be scaled a little so that the output of different heads can be in different \"regions\" and thus do not interfere with each other (so yes to your third question, the two softmaxes are performed separately for each head). reply robertsdionne 1 hour agorootparentprevIt means one of these things: https://en.wikipedia.org/wiki/Simplex#Standard_simplex reply pizza 4 hours agorootparentprevO_i = softmax(...) * V_i and softmax is between 0 and 1, so O_i = alpha * V_i for some alpha between 0 and 1 so that makes it convex, and it makes the O_i just a shrunken version of V_i. Whereas if you have the diff of softmaxes, you get O_i = (alpha - beta) * V_i, which can range from -V_i to +V_i, so its output could rescale /or/ flip V_i. And yes this is happening in every head in parallel, then they get summed. reply x1000 1 hour agorootparentprevCould you help explain how we would achieve an attention score of exactly 0, in practice? Here’s my take: If we’re subtracting one attention matrix from another, we’d end up with attention scores between -1 and 1, with a probability of effectively 0 for any single entry to exactly equal 0. What’s more, the learnable parameter \\lambda allows for negative values. This would allow the model to learn to actually add the attention scores, making a score of exactly 0 impossible. reply jszymborski 30 minutes agorootparentYour comment brings up two interesting variants that could be interesting if your goal is to increase the sparsity of the attention: - Rectify the difference of the softmaxes. (min(0, s(A1) - lambda s(A2))) - Apply the Heaviside function to the second softmax. (softmax(A1) - lambda H(s(A1) - lambda s(A2)) The second one being a bit more drastic and maybe harder to train. reply espadrine 1 hour agorootparentprevIt is a neat approach, but one that comes with a tradeoff, IIUC: doubling the key heads. I wonder if a different approach without that issue exists. For instance, using max(0, exp(x)-1) instead of exp(x) in the softmax attention formula. That way when the query is orthogonal to the key (or worse), it does not contribute. reply dartos 4 hours agorootparentprev> predict a weight of exactly zero for some of the values Wouldn’t this be pretty unlikely, though? reply schopra909 3 hours agorootparentQuite the opposite — if you have a long sequence only a smattering of the words will influence the meaning of the current word. Everything else is “noise”. Attention is really good at finding this smattering of words (ie assign most weight there). But it struggles to put exactly 0 on the other words. reply dartos 1 hour agorootparentI mean wouldn’t it be unlikely that SoftmaxA[n] - SoftmaxB[n] is exactly 0? Even if 2 attention layers learn two different things, I would imagine the corresponding weights in each layer wouldn’t exactly cancel each other out. reply absoflutely 2 hours agorootparentprevwhy say lot word when few word do reply dartos 1 hour agorootparentFew word no do tho reply 1024core 27 minutes agorootparentPhew! reply WithinReason 3 hours agoparentprevDon't look for an analogy, this just adds a new mathematical capability. It enables \"negative attention\", the network can say \"I want to subtract the contribution of this token\" in the attention calculation. Previously it could only reduce how much it adds. The simple way of doing this would be to just remove the softmax or use a sigmoid instead, but in practice a softmax works better it seems. reply phire 4 hours agoparentprevNoise cancelling headphones are probably the wrong analogy here. The better example is the differential signalling used in professional audio and many digital signaling protocols like Ethernet, HDMI and USB. Instead of using one wire, referencing to ground, they send the signal as the difference between both wires. Both wires end up carrying the same signal with inverted polarity. Because both wires are running next to each-other any external noice will be applied to both equally. The voltage will change, but the difference in voltage between both wires is untouched. And when you subtract the two voltages at the receiver end, any noise simply gets subtracted out. reply seamossfet 3 hours agorootparentI think when they bring up differential amplifiers they're referring more to the DSP technique of how headphone noise cancelling works but the actual electrical properties of how a differential amplifier does that muddies the message a bit. It sort of feels closer to heterodyning and \"demodulating\" the signal encoded in the softmax. Those tiny little errors we're trying to denoise with this technique are almost closer to carrier waves (when encoded to softmax) than noise imo. This wouldn't get rid of noise in the training data or noise in the dimensionality of the key / value space. It's really only removing noise introduced by the process itself. reply _hl_ 5 hours agoparentprevSome of the \"prior art\" here is ladder networks and to some handwavy extent residual nets, both of which can be interpreted as training the model on reducing the error to its previous predictions as opposed to predicting the final result directly. I think some intuition for why it works has to do with changing the gradient descent landscape to be a bit friendlier towards learning in small baby steps, as you are now explicitly designing the network around the idea that it will start off making lots of errors in its predictions and then get better over time. reply seamossfet 4 hours agoparentprevIt sounds like they're just splitting the query / key space down the middle. We don't know which dimensions are encoded in each matrix, but they're assuming the \"noise\" introduced in one query / key space is equivalent to noise introduced in the other space. If that is the case, then the \"signal\" in this case would be the softmax that encodes the dimensions captured by the query / key space. Since the noise ideally is the same in both softmax encodings, subtracting them should \"cancel out\" the noise. reply HarHarVeryFunny 5 hours agoparentprevI don't understand either. It seems the general idea is that they calculate attention twice, which due to random initialization might be expected to give two slightly different results. I'd have thought that what these two attention maps would have in common would be the signal, and where they would differ would be noise, so rather than subtracting them (resulting in all noise?!) what you really want is to add (so the common signal gets reinforced) and normalize. reply kelseyfrog 3 hours agorootparentThe values between the groups are also going to diverge during training due to the structure of the DiffAttn equation. The analogy I can think of is when you're paying attention to a variety of things and you actively avoid concentrating on something because it will distract you. You don't give it zero attention, you give it negative attention. reply Carlseymanh 4 hours agorootparentprevI think there might be some communalities with system engineering, where you subtract the output from the input in order to get a control signal that steers the plant to the target values. I too fail to see how that would be supposed to work in practice. reply mistercheph 41 minutes agoparentprevI think common mode filtering in balanced audio cables is a much better analogy than noise canceling headphones (and where this paper gets its name from I assume), you don't know what the noise is ahead of time, but if you take two samples with one positive and one negative, noise displaces both absolutely, which you can take advantage of to denoise the signal (find the differential mode). For example, if you are trying to send a +1V signal on one wire, and a -1V signal on the other and a +0.5V noise exists, one wire will have +1.5V and the other will have -0.5V, Take the difference and divide by 2: (+1.5V - -0.5V) / 2 = +1V or, if your setup is different (-0.5V - +1.5V) / 2 = -1V reply watsonmusic 5 hours agoparentprevthe model is supposed to learn this reply WithinReason 3 hours agoprevWe empirically find that the setting λᵢₙᵢₜ = 0.8 − 0.6 × exp(−0.3 · (l − 1)) works well in practice I wonder about the story behind that formula... reply Kubuxu 2 hours agoparentHmm, 0.8 works well, but let's try setting lower layers to lower initial value. Let's say 0.2. Ok, I need a formula that will go between 0.2 and 0.8, slowly approaching 0.8. Starts fiddling with numbers for 20min, I guess this can work. reply chessgecko 1 hour agoprevI wonder how much of the value here is from canceling out the positional noise rope produces. I would love to see a table comparing an alibi version of this to an alibi baseline in addition to the rope models here. Crazy gains though congrats to the researchers reply iandanforth 4 hours agoprevThe key bit I didn't understand at first was what happens if the two groups of attention learn the same thing; because their attention masks are subtracted from one another if they both output similar values the attention across the board will drop to zero and this will lead to high loss. So the only way to reduce loss is if they learn to attend to different things. One of the simplest strategies they could learn (and this paper claims that they do) is for one group to focus on relevant context and the other to focus on irrelevant context. Thus one group learns the noise and the other the signal (it's not this cut and dry but is a useful simplification for understanding IMO). reply patcon 44 minutes agoparent> what happens if the two groups of attention learn the same thing I wonder if there's a metaphor here for our own experience and utility in \"surprise\". Like if one attention head is surprised by what another learns, up-weight it. But if they both find the same, assume it's not very surprising and down-weight it. Admittedly, \"surprise\" is something that has a big section of my knowledgebase[1][2][3] (both as a subjective feeling and adaptive function of our minds, one of the most complex adaptive system we know of) [1] https://plus.maths.org/content/information-surprise [2] https://blakeelias.name/papers/Multi-Agent-Cooperation-Intri... [3] https://complexity.simplecast.com/episodes/81/transcript reply magicalhippo 3 hours agoparentprevAn interesting aspect is that they don't do a plain subtraction, but rather subtract a portion of the second softmax. This makes sense, if one considers that the two copies are identical then the softmax outputs would be identical and the difference is zero everywhere. However, by subtracting a scaled copy, the normalization of the difference seems to really boost the signal value(s) over the \"noise\", making the signal stand out compared to pre-normalization. reply testdfkjahdfh 46 minutes agorootparentif two attentions A, B are identical, would (A - lambda * B) be just (1-lambda) * A, how does it \"boost the signal value(s) over the \"noise\"\"? reply dartos 4 hours agoparentprevThere’s probably a small chance that they could both learn the same thing, but it’s probably not likely enough to be a major issue. reply nextaccountic 3 hours agoparentprevMaybe the loss function could penalize them learning the same thing? reply machinelearning 1 hour agoprevThis is a good problem to solve but the approach is wrong imo. It has to be done in a hierarchical way to know what you attended to + full context. If the differential vector is being computed with the same input as the attention vector how do you know how to modify the attention vector correctly reply quantadev 1 hour agoparentDoesn't everything just get tweaked in whatever direction the back-propagation derivative says and proportionally to that \"slope\"? In other words, simply by having back-propagation system in effect there's never any question about which way to adjust the weights, right? reply patcon 5 hours agoprevI wonder what is lost here. Surely there's a trade-off... I'm wondering if there's any effect of \"creativity\", or ability to interpolate between concepts. Hallucination and creativity feel very related to me. I understand hallucinating as simply being misaligned with the space humans feel appropriate to interpolate between reply dartos 4 hours agoparent> Hallucination and creativity feel very related to me. Why? I see them as just sampling errors. Sure a mistake can spark inspiration sometimes, but creativity is much more than mistakes. > I understand hallucinating as simply being misaligned with the space humans feel appropriate to interpolate between These language models are next-token predictors. The way the next token is predicted is by sampling a probability space outputted by the model. That sampling process can be non deterministic. Hallucinations are when that sampling results in tokens that come together to create a false or otherwise unintended statement. You can just as well think of everything a model outputs as a hallucination, but we train the model to output a space what we want them to hallucinate is more likely. Otherwise it just outputs meaningless noise. “Hallucinate” is really an awful word for what it’s trying to describe. reply slashdave 1 hour agorootparent> You can just as well think of everything a model outputs as a hallucination Exactly. Don't forget that an important factor in the success of GPT3 was RLHF, which is essentially training the model to produce \"hallucinations\" that are more acceptable on average to human trainers. reply nextaccountic 3 hours agorootparentprev> Sure a mistake can spark inspiration sometimes, but creativity is much more than mistakes. It looks like creativity has many steps but being able to come with novel, unprompted stuff is important, as long as you are able to discard the bullshit earlier. \"Hallucination\" is only a problem if later layers (or additional networks) can't detect and remove it reply dartos 3 hours agorootparent> \"Hallucination\" is only a problem if later layers (or additional networks) can't detect and remove it Yeah I mean sure. Anything is only a problem if it goes undetected. The issue is that if you rely on statistical model, you’ll always have hallucinations, so you can’t filter statistical output with another statistical model if you need real guarantees. Many products don’t need those guarantees though. reply skybrian 2 hours agorootparentprevLLM’s are too unpredictable for many practical uses so I’d guess better predictability is better. Hopefully the change the paper proposes will help! But here’s a case for the other side: sure, most mistakes are just errors, but evolution happens via “mistakes.” Also, LLM’s often deliberately add add randomness at inference time. reply dartos 1 hour agorootparent> evolution happens via “mistakes.” That’s a nice slogan, but it’s a gross oversimplification. In the natural world, you can say that mistakes in DNA replication leads to evolution, but that’s discounting the entire process of natural selection. Same with creativity. Look at Picasso. His was a technically brilliant realistic painter at 15, but his work later in life evolved to be more abstract and weird. I don’t think that was the result of mistakes, but rather intentionally breaking patterns he learned in his youth. reply skybrian 1 hour agorootparentTo oversimplify, evolution is a generate-and-test process and the evaluation step is critical. Something needs to decide which variations are better. Often, with generative AI, it’s people who judge the results. Still, generating interesting examples (the brainstorming phase) plays some role in that. I don’t know a whole lot about Picasso’s art, but I imagine the way he evaluated his own work played an important role, in being able to see that sometimes creative accidents are interesting. reply thomastjeffery 2 hours agorootparentprevHallucinate is an awful word because of what it is trying to describe. Hallucination describes the same feature you just called \"non deterministic sampling\", but exclusively the cases that we don't like. It would be really convenient if we could actually draw that line, but we can't. If non-determinism is a core feature, then that feature will be present in every case; including the ones we find desirable, and the ones we find undesirable. reply magicalhippo 4 hours agoparentprev> Surely there's a trade-off... For one, speed and memory. They have twice as many Q and K weights in the attention blocks, leading to a ~10% reduction in throughput on their H100 (table 7 in appendix A). reply lennxa 3 hours agorootparentthey mention similar performance to vanilla transformer with significantly reduced param count though reply karmasimida 2 hours agorootparentprevI mean it doesn’t necessarily needs 2x QK to match that performance, in terms of accuracy, of a regular transformer right? reply watsonmusic 5 hours agoparentprevnot all hallucinations are creativity Imaginate that for a RAG application, the model is supposed to follow the given documents reply vsroy 4 hours agoprevIs the thing that's going on here that softmax can't push a value to 0, but by subtracting 2 softmax maps we can output 0s? reply pkoird 3 hours agoparentOr negatives reply slashdave 1 hour agoprevI don't get it. Arbitrary linear combinations are already accommodated via feed forward. What am I missing? reply miven 2 hours agoprevIs there an intuitive reason why this ends up working this well compared to, say, applying some kind of thresholding to attention activations that are below average for a given head to filter that same attention noise out? reply nmacias 4 hours agoprevAdderaLLM was right there reply singularity2001 4 hours agoprevAnyone remember siamese networks? reply pxdm 4 hours agoprevWhat's the comparison with conventional attention using a more aggressive (lower temperature) softmax? I can imagine that for the multi-needle retrieval test this may also give a performance boost, although at some cost other more creative tasks. reply pizza 4 hours agoprevWas just going to mention that it seems that it should be possible to make a Flash Attention version of this algorithm and was pleasantly surprised to see they already included an implementation of one :) reply WithinReason 3 hours agoprevHmmm, this could be expressed as 2 consecutive attentions in a residual branch: Simplified differential T. looks like: (softmax(Q₁K₁) − λ softmax(Q₂K₂)) V You can factor this into: x = softmax(Q₁K₁)V x += -λ softmax(Q₂K₂)V which is like 2 subsequent regular attentions added that are sharing V reply kelseyfrog 2 hours agoparentYou could also extrapolate this into more than two terms by squinting your eyes and saying that λ ∈ {1, -1} is close enough to λi ∈R^d ∣ ∥λi ∥=1. No idea if it would result in better performance, but that's research babyyyy! reply dartos 4 hours agoprev> By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization I’m very interested in this claim. I was under the impression that hallucination is unavoidable in these kinds of models. IIRC proof for that was trending on HN a couple weeks ago. reply pshc 1 hour agoparentMore broadly I think hallucination is inevitable in pure text models. We need model architectures incorporating a stream of real-world ground truth such as a live video feed or embodiment. reply ErikBjare 4 hours agoparentprevMitigate, not completely fix. reply moffkalast 4 hours agoparentprevIt's not possible to get rid of it entirely, but if you can get the model to bullshit only 0.1% of the time instead of 5% of the time it's a massive improvement. Most of it should be happening when there's no data to draw conclusions from. E.g. STT models make up words in silence, vision models find things in lens cap noise, LLMs make up explanations when they have no data to pull from. The real solution would be more along the lines of training models to specifically ignore these cases, or in the case of LLMs to just know when to say \"I don't know\". reply lucidrains 3 hours agoprevdoes this not mean we should explore usage of talking heads (Shazeer et al) a bit more? https://arxiv.org/abs/2003.02436 reply digdugdirk 5 hours agoprevIs there any way to replicate this with existing models, or are we going to need to wait for models to be trained in this style? I'm imagining a smaller model examining the output tokens of a larger model and metaphorically slapping it on the wrist with a ruler if the output tokens start drifting off topic. Not quite the same, but an entertaining thought nonetheless. reply bionhoward 4 hours agoparentYes, I believe this is possible, you could clone weights of one or more existing models and fine tune them in groups with different random seeds for noise/drop to produce reasonable outputs under a differential transformer decoding scheme whereby tokens with disagreement receive more attention (surprisal analysis) reply causal 5 hours agoparentprevIt's a different attention mechanism with a different map setup, so fundamentally a different type of model reply om8 5 hours agorootparentLooks like it is a drop in replacement for attention, but models will need to be retrained for this one, yes. reply aDyslecticCrow 3 hours agorootparentIt may not need to be entirely retrained. The value spans and input are the same, and no extra weights are needed. You may be able to tune an existing model with this attention mechanism and get some of the benefits. But overall... it's mainly a training change, so training is needed to make a difference. reply watsonmusic 5 hours agoprevThe modification is simple and beautiful. And the improvements are quite significant. reply x49asvk 3 hours agoprevThis concept is really interesting to me, I am very very new to transformers but would love to learn more about normal transformers and differential too. Can anyone suggest any resources? reply pikseladam 6 hours agoprevDid this mean they solved the hallucination problem of transformers? edit: not fully but it gives promising results. quiet an improvement actually. reply HarHarVeryFunny 4 hours agoparentI don't think there's any narrow definition of what \"hallucination\" means. It generally refers to the model giving non-factual answers in contexts that are meant to be factual, but not all causes of this are going to be fixable without very major changes. The fundamental issue is that most of the time LLMs are going to be combining statistics derived from many training samples when generating a single continuation, and there is just no guarantee that this will result in a semantically coherent response. Of course the model's depth of parsing and semantic analysis usually means that each generated word is highly plausible, but this isn't the same as being factually correct, especially so in these cases where the model is drawing on multiple sources to create a mashup response, which is the normal mode of operation. reply lafreb 6 hours agoparentprevThe paper says that they've improved hallucination mitigation, but not really \"solved\" the issue. reply Rhapso 5 hours agorootparent\"Hallucination\" isn't really a problem that can be \"fixed\". Its just model error. The root problem is simply that the model doesn't capture reality, just an approximation. What we are incorrectly calling \"hallucination\" is just the best the model has to offer. reply spencerchubb 5 hours agorootparentit's not \"just\" model error during pre-training, there is never an incentive for the model to say \"I don't know\" because it would be penalized. the model is incentivized to make an educated guess large transformer models are really good at approximating their dataset. there is no data on the internet about what LLMs know. and even if there were such data, it would probably become obsolete soon that being said, maybe a big shift in the architecture could solve this. I hope! reply singularity2001 4 hours agorootparentin another paper which popped up recently they approximated uncertainty with Entropy and inserted \"wait!\" tokens whenever Entropy was high, simulating chain of thought within the system. reply happypumpkin 5 hours agorootparentprev> it would probably become obsolete soon Suppose there are many times more posts about something one generation of LLMs can't do (arithmetic, tic-tac-toe, whatever), than posts about how the next generation of models can do that task successfully. I think this is probably the case. While I doubt it will happen, it would be somewhat funny if training on that text caused a future model to claim it can't do something that it \"should\" be able to because it internalized that it was an LLM and \"LLMs can't do X.\" reply spencerchubb 4 hours agorootparentalso presumes that the LLM knows it is an LLM reply Vecr 2 hours agorootparentThey're generally fine tuned not to. I'm not sure how long that will hold though. reply adwn 3 hours agorootparentprevSystem prompts sometimes contain the information that \"it\" is an LLM. Maybe in the future, those prompts will include motivational phrases, like \"You can do it!\" or \"Believe in yourself, then you can achieve anything.\" reply spywaregorilla 4 hours agorootparentprev> during pre-training, there is never an incentive for the model to say \"I don't know\" because it would be penalized. the model is incentivized to make an educated guess The guess can be \"I don't know\". The base LLM would generally only say I don't know if it \"knew\" that it didn't know, which is not going to be very common. The tuned LLM would be the level responsible for trying to equate a lack of understanding to saying \"I don't know\" reply dilap 5 hours agorootparentprevit can be fixed in theory if the model knows-what-it-knows, to avoid saying things its uncertain about (this is what (some) humans do to reduce the frequency w which they say untrue things). theres some promising research using this idea, tho i dont have it at hand. reply hoosieree 5 hours agorootparentLLMs can't hallucinate. They generate the next most likely token in a sequence. Whether that sequence matches any kind of objective truth is orthogonal to how models work. I suppose depending on your point of view, LLMs either can't hallucinate, or that's all they can do. reply ToValueFunfetti 5 hours agorootparent>Whether that sequence matches any kind of objective truth is orthogonal to how models work. Empirically, this cannot be true. If it were, it would be statistically shocking how often models coincidentally say true things. The training does not perfectly align the model with truth, but 'orthogonal' is off by a minimum of 45 degrees. reply viraptor 5 hours agorootparentIt matches the training data. Whether the training data matches truth (and whether it's correctly understood - sarcasm included) is a completely separate thing. > The training does not perfectly align the model with truth, but 'orthogonal' Nitpicky, but the more dimensions you have, the easier it is for almost everything to be orthogonal. (https://softwaredoug.com/blog/2022/12/26/surpries-at-hi-dime...) That's why averaging embeddings works. reply ToValueFunfetti 4 hours agorootparentI went to school to learn about the world and the overwhelming majority of that learning was from professors and textbooks. Whether the professors' beliefs and the textbooks' contents reflected the true properties of the world was a completely separate thing, entirely outside of my control. But I did come away with a better understanding of the world and few would say that education is orthogonal to that goal. If you add two vectors that don't have a truth component (ie. are orthogonal to the truth), the resulting vector should be no closer to the truth. If you start with random weights and perform some operation on them such that the new weights have a higher likelihood of producing true statements, the operation must not have been orthogonal to the truth. Am I wrong there? reply viraptor 3 hours agorootparent> But I did come away with a better understanding of the world and few would say that education is orthogonal to that goal. That's due to the reward function / environment. But even outside extremes like North Korea, lots of education environments value conformity over independent analysis. reply ToValueFunfetti 2 hours agorootparentCertainly an AI trained on North Korean data would emerge with some very suspect beliefs regarding Kim Jong-Un. My point is just that aligning something with training data is aligning it with truth, to the degree that the training data is true and regardless of why it is true. educate(me, truth) can hardly be called orthogonal to the truth, even if the 'educate' and 'me' terms do nothing to prevent educate(me, falsehood). reply timcobb 4 hours agorootparentprevIsn't this the same thing that happens when you train a human on truths vs falsehoods? reply CooCooCaCha 5 hours agorootparentprevWhenever someone takes issue with using the word “hallucinate” with LLMs I get the impression they’re trying to convince me that hallucination is good. Why do you care so much about this particular issue? And why can’t hallucination be something we can aim to improve? reply visarga 5 hours agorootparentprevThis reminds me it's easy to train similarity models, hard to train identity/equivalence prediction. Two strings can be similar in many ways, like \"Address Line 1\" and \"Address Line 2\" or \"Position_X\" and \"Position_Y\", yet distinct in meaning. That one character makes all the difference. On the other hand \"Vendor Name\" is equivalent with \"Seller Company\" even though they are pretty different lexically. The dot product, which is at the core of attention, is good for similarity not identity. I think this is why models hallucinate - how can they tell the distinction between \"I have trained on this fact\" and \"Looks like something I trained on\". reply atrus 5 hours agorootparentprevI don't think that fixes it, even in theory, since there's always some uncertainty. reply AnimalMuppet 5 hours agorootparentprevI'm pretty sure there's something I don't understand, but: Doesn't an LLM pick the \"most probable next symbol\" (or, depending on temperature, one of the most probable next symbols)? To do that, doesn't it have to have some idea of what the probability is? Couldn't it then, if the probability falls below some threshold, say \"I don't know\" instead of giving what it knows is a low-probability answer? reply darkPotato 5 hours agorootparentMy understanding is that the hallucination is, out of all the possibilities, the most probable one (ignoring temperature). So the hallucination is the most probable sequence of tokens at that point. The model may be able to predict an \"I don't have that information\" given the right context. But ensuring that in general is an open question. reply dTal 5 hours agorootparentprevIt doesn't really work like that. 1) The model outputs a ranked list of all tokens; the probability always sums to 1. Sometimes there is a clear \"#1 candidate\", very often there are a number of plausible candidates. This is just how language works - there are multiple ways to phrase things, and you can't have the model give up every time there is a choice of synonyms. 2) Probability of a token is not the same as probability of a fact. Consider a language model that knows the approximate population of Paris (2 million) but is not confident about the exact figure. Feed such a model the string \"The exact population of Paris is\" and it will begin with \"2\" but halfway through the number it will have a more or less arbitrary choice of 10 digits. \"2.1I don't know\" is neither a desirable answer, nor a plausible one from the model's perspective. reply viraptor 5 hours agorootparentprev> Doesn't an LLM pick the \"most probable next symbol\" Yes, but that very rarely matters. (Almost never when it's brought up in discussions) > Couldn't it then, if the probability falls below some threshold, say \"I don't know\" instead of giving what it knows is a low-probability answer? A low probability doesn't necessarily mean something's incorrect. Responding to your question in French would also have very low probability, even if it's correct. There's also some nuance around what's classified as a hallucination... Maybe something in the training data did suggest that answer as correct. There are ideas similar to this one though. It's just a bit more complex than pure probabilities going down. https://arxiv.org/abs/2405.19648 reply anon291 5 hours agorootparentprevYou need to separate out the LLM, which only produces a set of probabilities, from the system, which includes the LLM and the sampling methodology. Sampling is currently not very intelligent at all. The next bit of confusion is that the 'probability' isn't 'real'. It's not an actual probability but a weight that sums up to one, which is close enough to how probability works that we call it that. However, sometimes there are several good answers and so all the good answers get a lower probability because there are 5 of them. A fixed threshold is not a good idea in this case. Instead, smarter sampling methods are necessary. One possibility is that if we do have seeming confusion, to put a 'confusion marker' into the text and predict the next output and train models to refine the answer as they go along. Not sure if any work has been done here, but this seems to go along with what you're interested in reply viraptor 5 hours agorootparent> However, sometimes there are several good answers and so all the good answers get a lower probability because there are 5 of them. That's the result after softmax. If you want to act on the raw results, you can still do that. reply ithkuil 5 hours agorootparentprevThis may work when the next token is a key concept but when it's a filler word or a part of one of many sequences of words that can convey the same meaning but in different ways (synonyms but not only at the word also at the sentence levels) then it's harder to know whether the probability is low because the word is absolutely unlikely or because it's likelihood is spread/shared among other truthful statements reply skydhash 5 hours agorootparentprevYou would need some kind of referential facts that you hold as true, then some introspection method to align sentences to those. if it can’t be done, the output may be “I don’t know”. But even for programming languages (simplest useful languages), it would be hard to do. reply PaulHoule 5 hours agorootparentprevMy guess is the problem is words with high probabilities that happen to be part of a wrong answer. For one thing the probability of a word occurring is just a probability of the word occurring in a certain sample, it's not an indicator of truth. (e.g. the most problematic concept in philosophy in that just introducing it undermines the truth, see \"9/11 truther\") It's also not sufficient to pick a \"true\" word or always pick a \"true\" word but rather the truthfulness of a statement needs to be evaluated based on the statement as a whole. A word might have a low probability because it competes with a large number of alternatives that are equally likely which is not a reason to stop generation. reply tucnak 5 hours agorootparentprevI'm led to believe this is mostly because \"known unknowns\" are not well-represented in the training datasets... I think, instead of bothering with refusals and enforcing a particular \"voice\" with excessive RL, they ought to focus more on identifying \"gaps\" in the datasets and feeding them back, perhaps they're already doing this with synthetic data / distillation. reply watsonmusic 6 hours agoparentprevthat would be huge! reply nowayno583 4 hours agoprevDoes anyone understand why they are taking the difference between transformers instead of the sum? It seems to me that in a noise reducing solution we would be more interested in the sum, as random noise would cancel out and signal would be constructive. Of course, even if I'm right proper training would account to that by inverting signs where appropriate. Still, it seems weird to present it as the difference, especially seeing as they compare this directly to noise cancelling headphones, where we sum both microphones inputs. reply thegeomaster 4 hours agoparentI suspect that plus vs minus is arbitrary in this case (as you said, due to being able to learn a simple negation during training), but they are presenting it in this way because it is more intuitive. Indeed, adding two sources that are noisy in the same way just doubles the noise, whereas subtracting cancels it out. It's how balanced audio cables work, for example. But with noise cancelling headphones, we don't sum anything directly---we emit an inverted sound, and to the human ear, this sounds like a subtraction of the two signals. (Audio from the audio source, and noise from the microphone.) reply nowayno583 3 hours agorootparentOh! It's been a good while since I've worked in noise cancelling. I didn't know current tech was at the point where we could do direct reproduction of the outside noise, instead of just using mic arrays! That's very cool, it used to be considered totally sci fi to do it fast enough in a small headset. reply aDyslecticCrow 4 hours agoparentprevThe noise isn't truly random; it's just a matrix of small values that shouldn't be taken into account. Subtracting them cancels them out. As pointed out by a different comment, it's actually the attention we are interested in that is cancelled out *if they are both equal*. This is what the paper mentions in its abstract; > promoting the emergence of sparse attention patterns In theory, it is quite clever, and their results seem to back it up. reply magicalhippo 6 hours agoprevThe visualization reveals that Transformer tends to allocate only a small proportion of attention scores to the correct answer, while disproportionately focusing on irrelevant context. [...] Specifically, we partition the query and key vectors into two groups and compute two separate softmax attention maps. Then the result of subtracting these two maps is regarded as attention scores. [...] The approach is analogous to noise-canceling headphones and differential amplifiers in electrical engineering, where the difference between two signals cancels out common-mode noise. Simple change, with seemingly decent improvements across the board. reply campers 5 hours agoprevThe tl;dr on high level performance improvements \"The scaling curves indicate that Diff Transformer requires only about 65% of model size or training tokens needed by Transformer to achieve comparable language modeling performance.\" \"Diff Transformer retains high performance even at reduced bit-widths, ranging from 16 bits to 6 bits. In comparison, Transformer’s accuracy significantly drops with 6-bit quantization. The 4-bit Diff Transformer achieves comparable accuracy as the 6-bit Transformer, and outperforms the 4-bit Transformer by about 25% in accuracy.\" reply ExxKA 6 hours agoprev [–] Very interesting. Currently working on timeseries with Transformers. Let me know if anyone else out there is also reading it from that context. reply d3m0t3p 5 hours agoparent [–] Really cool, I'm a CS majoring in AI, but I'm also interested in that domain, would you have any recommendation to get started ? reply ExxKA 36 minutes agorootparent [–] Get a lot of data, and just dig in :) No better way to learn. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Differential Transformer introduces a novel attention mechanism that enhances focus on relevant context while minimizing noise, using a differential attention approach that subtracts two softmax attention maps to encourage sparse attention patterns.",
      "Experimental results indicate that the Diff Transformer surpasses traditional Transformers in language modeling, particularly excelling in long-context modeling, key information retrieval, and reducing hallucinations, thereby improving accuracy and robustness in in-context learning.",
      "This development positions the Diff Transformer as a promising architecture for advancing large language models, with potential applications in computation and language, as well as machine learning."
    ],
    "commentSummary": [
      "Differential Transformer introduces an innovative architecture using differential attention, which reduces noise by subtracting two softmax attention functions, allowing for a smaller model size with performance comparable to larger transformers.- The 6.8 billion parameter DIFF Transformer achieves similar validation loss to an 11 billion parameter Transformer, using only 62.2% of the parameters, by employing half the number of attention heads per layer.- This architecture shows potential in reducing hallucinations in tasks such as question answering and text summarization, though it necessitates retraining models to adopt the new attention mechanism."
    ],
    "points": 332,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1728388470
  },
  {
    "id": 41770921,
    "title": "uBlock Origin CNAME uncloaking now supports filtering by IP address",
    "originLink": "https://github.com/gorhill/uBlock/commit/6acf97bf51",
    "originBody": "gorhill / uBlock Public Notifications Fork 3.1k Star 46.4k Code Issues 12 Pull requests 2 Actions Projects Wiki Security Insights Commit Permalink Rewrite cname uncloaking code to account for new ipaddress= option Browse files This commit makes the DNS resolution code better suited for both filtering on cname and ip address. The change allows early availability of ip address so that `ipaddress=` option can be matched at onBeforeRequest time. As a result, it is now possible to block root document using `ipaddress=` option -- so long as an ip address can be extracted before first onBeforeRequest() call. Related issue: uBlockOrigin/uBlock-issues#2792 Caveat ------ the ip address used is the first one among the list of ip addresses returned by dns.resolve() method. There is no way for uBO to know which exact ip address will be used by the browser when sending the request, so this is at most a best guess. The exact IP address used by the browser is available at onHeadersReceived time, and uBO will also filter according to this value, but by then the network request has already been sent to the remote server. Possibly a future improvement would make available the whole list of ip addresses to the filtering engine, but even then it's impossible to know with certainty which ip address will ultimately be used by the browser -- it is entirely possible that the ip address used by the browser might not be in the list received through dns.resolve(). Loading branch information gorhill committed 1 parent 44b6519 commit 6acf97b Showing 4 changed files with 153 additions and 96 deletions. Whitespace Ignore whitespace Split Unified platform chromium manifest.json firefox vapi-background-ext.js opera manifest.json src/js background.js 2 changes: 1 addition & 1 deletion 2 platform/chromium/manifest.json Original file line number Diff line number Diff line change@@ -89,7 +89,7 @@ }, \"incognito\": \"split\", \"manifest_version\": 2, \"minimum_chrome_version\": \"73.0\", \"minimum_chrome_version\": \"80.0\", \"name\": \"uBlock Origin\", \"options_ui\": { \"page\": \"dashboard.html\", 244 changes: 151 additions & 93 deletions 244 platform/firefox/vapi-background-ext.js Original file line number Diff line number Diff line change@@ -26,8 +26,10 @@ import {/******************************************************************************/// Canonical name-uncloaking feature. let cnameUncloakEnabled = browser.dns instanceof Object; const dnsAPI = browser.dns;const isPromise = o => o instanceof Promise; const reIPv4 = /^\\d+\\.\\d+\\.\\d+\\.\\d+$/// Related issues: // - https://github.com/gorhill/uBlock/issues/1327@@ -40,21 +42,24 @@ vAPI.Net = class extends vAPI.Net { constructor() { super(); this.pendingRequests = []; this.canUncloakCnames = browser.dns instanceof Object; this.cnames = new Map([ [ '', null ] ]); this.dnsList = []; // ring buffer this.dnsWritePtr = 0; // next write pointer in ring buffer this.dnsMaxCount = 256; // max size of ring buffer this.dnsDict = new Map(); // hn to index in ring buffer this.dnsEntryTTL = 60000; // delay after which an entry is obsolete this.canUncloakCnames = true; this.cnameUncloakEnabled = true; this.cnameIgnoreList = null; this.cnameIgnore1stParty = true; this.cnameIgnoreExceptions = true; this.cnameIgnoreRootDocument = true; this.cnameMaxTTL = 120; this.cnameReplayFullURL = false; this.cnameFlushTime = Date.now() + this.cnameMaxTTL * 60000; }setOptions(options) { super.setOptions(options); if ( 'cnameUncloakEnabled' in options ) { cnameUncloakEnabled = this.canUncloakCnames && this.cnameUncloakEnabled = options.cnameUncloakEnabled !== false; } if ( 'cnameIgnoreList' in options ) {@@ -73,15 +78,13 @@ vAPI.Net = class extends vAPI.Net { this.cnameIgnoreRootDocument = options.cnameIgnoreRootDocument !== false; } if ( 'cnameMaxTTL' in options ) { this.cnameMaxTTL = options.cnameMaxTTL || 120; } if ( 'cnameReplayFullURL' in options ) { this.cnameReplayFullURL = options.cnameReplayFullURL === true; } this.cnames.clear(); this.cnames.set('', null); this.cnameFlushTime = Date.now() + this.cnameMaxTTL * 60000; this.dnsList.fill(null); this.dnsDict.clear(); }normalizeDetails(details) { const type = details.type; @@ -104,6 +107,7 @@ vAPI.Net = class extends vAPI.Net { } } }denormalizeTypes(types) { if ( types.length === 0 ) { return Array.from(this.validTypes);@@ -122,75 +126,19 @@ vAPI.Net = class extends vAPI.Net { } return Array.from(out); }canonicalNameFromHostname(hn) { const cnRecord = this.cnames.get(hn); if ( cnRecord !== undefined && cnRecord !== null ) { return cnRecord.cname; } } processCanonicalName(hn, cnRecord, details) { if ( cnRecord === null ) { return; } if ( cnRecord.isRootDocument ) { return; } const hnBeg = details.url.indexOf(hn); if ( hnBeg === -1 ) { return; } const oldURL = details.url; let newURL = oldURL.slice(0, hnBeg) + cnRecord.cname; const hnEnd = hnBeg + hn.length; if ( this.cnameReplayFullURL ) { newURL += oldURL.slice(hnEnd); } else { const pathBeg = oldURL.indexOf('/', hnEnd); if ( pathBeg !== -1 ) { newURL += oldURL.slice(hnEnd, pathBeg + 1); } } details.url = newURL; details.aliasURL = oldURL; return super.onBeforeSuspendableRequest(details); } recordCanonicalName(hn, record, isRootDocument) { if ( (this.cnames.size & 0b111111) === 0 ) { const now = Date.now(); if ( now >= this.cnameFlushTime ) { this.cnames.clear(); this.cnames.set('', null); this.cnameFlushTime = now + this.cnameMaxTTL * 60000; } } let cname = typeof record.canonicalName === 'string' && record.canonicalName !== hn ? record.canonicalName : ''; if ( cname !== '' && this.cnameIgnore1stParty && domainFromHostname(cname) === domainFromHostname(hn) ) { cname = ''; } if ( cname !== '' && this.cnameIgnoreList !== null && this.cnameIgnoreList.test(cname) ) { cname = ''; } const cnRecord = cname !== '' ? { cname, isRootDocument } : null; this.cnames.set(hn, cnRecord); return cnRecord; if ( hn === '' ) { return; } const dnsEntry = this.dnsFromCache(hn); if ( isPromise(dnsEntry) ) { return; } return dnsEntry?.cname; }regexFromStrList(list) { if ( typeof list !== 'string' || list.length === 0 || list === 'unset' || browser.dns instanceof Object === false ) { if ( typeof list !== 'string' || list.length === 0 || list === 'unset' ) { return null; } if ( list === '*' ) { return /^./; } if ( list === '*' ) { return /^./; } return new RegExp( '(?:^|\\\\.)(?:' + list.trim()@@ -200,9 +148,14 @@ vAPI.Net = class extends vAPI.Net { ')$' ); }onBeforeSuspendableRequest(details) { const hn = hostnameFromNetworkURL(details.url); const dnsEntry = this.dnsFromCache(hn); if ( dnsEntry?.ip ) { details.ip = dnsEntry.ip; } const r = super.onBeforeSuspendableRequest(details); if ( cnameUncloakEnabled === false ) { return r; } if ( r !== undefined ) { if ( r.cancel === true ||@@ -212,25 +165,128 @@ vAPI.Net = class extends vAPI.Net { return r; } } const hn = hostnameFromNetworkURL(details.url); const cnRecord = this.cnames.get(hn); if ( cnRecord !== undefined ) { return this.processCanonicalName(hn, cnRecord, details); if ( dnsEntry !== undefined ) { if ( isPromise(dnsEntry) === false ) { return this.onAfterDNSResolution(hn, details, dnsEntry); } } if ( details.proxyInfo && details.proxyInfo.proxyDNS ) { return; } const documentUrl = details.documentUrl || details.url; const isRootDocument = this.cnameIgnoreRootDocument && hn === hostnameFromNetworkURL(documentUrl); return browser.dns.resolve(hn, [ 'canonical_name' ]).then( rec => { const cnRecord = this.recordCanonicalName(hn, rec, isRootDocument); return this.processCanonicalName(hn, cnRecord, details); }, ( ) => { this.cnames.set(hn, null); if ( this.dnsShouldResolve(hn) === false ) { return; } if ( details.proxyInfo?.proxyDNS ) { return; } const promise = dnsEntry || this.dnsResolve(hn, details); return promise.then(( ) => this.onAfterDNSResolution(hn, details)); }onAfterDNSResolution(hn, details, dnsEntry) { if ( dnsEntry === undefined ) { dnsEntry = this.dnsFromCache(hn); if ( dnsEntry === undefined || isPromise(dnsEntry) ) { return; } } let proceed = false; if ( dnsEntry.cname && this.cnameUncloakEnabled ) { const newURL = this.uncloakURL(hn, dnsEntry, details); if ( newURL ) { details.aliasURL = details.url; details.url = newURL; proceed = true; } } if ( dnsEntry.ip && details.ip !== dnsEntry.ip ) { details.ip = dnsEntry.ip proceed = true; } if ( proceed === false ) { return; } // Must call method on base class return super.onBeforeSuspendableRequest(details); }dnsToCache(hn, record, details) { const i = this.dnsDict.get(hn); if ( i === undefined ) { return; } const dnsEntry = { hn, until: Date.now() + this.dnsEntryTTL, }; if ( record ) { const cname = this.cnameFromRecord(hn, record, details); if ( cname ) { dnsEntry.cname = cname; } const ip = this.ipFromRecord(record); if ( ip ) { dnsEntry.ip = ip; } } this.dnsList[i] = dnsEntry; return dnsEntry; }dnsFromCache(hn) { const i = this.dnsDict.get(hn); if ( i === undefined ) { return; } const dnsEntry = this.dnsList[i]; if ( dnsEntry === null ) { return; } if ( isPromise(dnsEntry) ) { return dnsEntry; } if ( dnsEntry.hn !== hn ) { return; } if ( dnsEntry.until >= Date.now() ) { return dnsEntry; } this.dnsList[i] = null; this.dnsDict.delete(hn) }dnsShouldResolve(hn) { if ( hn === '' ) { return false; } const c0 = hn.charCodeAt(0); if ( c0 === 0x5B /* [ */ ) { return false; } if ( c0 > 0x39 /* 9 */ ) { return true; } return reIPv4.test(hn) === false; }dnsResolve(hn, details) { const i = this.dnsWritePtr++; this.dnsWritePtr %= this.dnsMaxCount; this.dnsDict.set(hn, i); const promise = dnsAPI.resolve(hn, [ 'canonical_name' ]).then( rec => this.dnsToCache(hn, rec, details), ( ) => this.dnsToCache(hn) ); return (this.dnsList[i] = promise); }cnameFromRecord(hn, record, details) { const cn = record.canonicalName; if ( cn === undefined ) { return; } if ( cn === hn ) { return; } if ( this.cnameIgnore1stParty ) { if ( domainFromHostname(cn) === domainFromHostname(hn) ) { return; } } if ( this.cnameIgnoreList !== null ) { if ( this.cnameIgnoreList.test(cn) === false ) { return; } } if ( this.cnameIgnoreRootDocument ) { const origin = hostnameFromNetworkURL(details.documentUrl || details.url); if ( hn === origin ) { return; } } return cn; }uncloakURL(hn, dnsEntry, details) { const hnBeg = details.url.indexOf(hn); if ( hnBeg === -1 ) { return; } const oldURL = details.url; const newURL = oldURL.slice(0, hnBeg) + dnsEntry.cname; const hnEnd = hnBeg + hn.length; if ( this.cnameReplayFullURL ) { return newURL + oldURL.slice(hnEnd); } const pathBeg = oldURL.indexOf('/', hnEnd); if ( pathBeg !== -1 ) { return newURL + oldURL.slice(hnEnd, pathBeg + 1); } return newURL; }ipFromRecord(record) { const { addresses } = record; if ( Array.isArray(addresses) === false ) { return; } if ( addresses.length === 0 ) { return; } return addresses[0]; }suspendOneRequest(details) { const pending = { details: Object.assign({}, details),@@ -243,6 +299,7 @@ vAPI.Net = class extends vAPI.Net { this.pendingRequests.push(pending); return pending.promise; }unsuspendAllRequests(discard = false) { const pendingRequests = this.pendingRequests; this.pendingRequests = [];@@ -254,6 +311,7 @@ vAPI.Net = class extends vAPI.Net { ); } }static canSuspend() { return true; } 2 changes: 1 addition & 1 deletion 2 platform/opera/manifest.json Original file line number Diff line number Diff line change@@ -88,7 +88,7 @@ }, \"incognito\": \"split\", \"manifest_version\": 2, \"minimum_opera_version\": \"60.0\", \"minimum_opera_version\": \"67.0\", \"name\": \"uBlock Origin\", \"options_page\": \"dashboard.html\", \"permissions\": [ 1 change: 0 additions & 1 deletion 1 src/js/background.js Original file line number Diff line number Diff line change@@ -59,7 +59,6 @@ const hiddenSettingsDefault = { cnameIgnore1stParty: true, cnameIgnoreExceptions: true, cnameIgnoreRootDocument: true, cnameMaxTTL: 120, cnameReplayFullURL: false, consoleLogLevel: 'unset', debugAssetsJson: false, 0 comments on commit 6acf97b Please sign in to comment.",
    "commentLink": "https://news.ycombinator.com/item?id=41770921",
    "commentBody": "uBlock Origin CNAME uncloaking now supports filtering by IP address (github.com/gorhill)272 points by gslin 22 hours agohidepastfavorite122 comments vifon 20 hours agoThe title seems to be wrong, uBlock Origin supported it for many years at this point (only on Firefox). This seems to be a refactor of that code, not a whole new feature. reply wild_pointer 20 hours agoparentWell, it does support it now. It supported it before, too :P reply normanthreep 19 hours agorootparenti used to use ublock origin. i still do, but i used to, too reply readyplayernull 19 hours agorootparentThere must have been some Monty Python... ah you get it. reply LinuxBender 19 hours agorootparentI believe that is a reference to Mitch Hedberg R.I.P. [1] [1] - https://www.youtube.com/watch?v=VqHA5CIL0fg [video][10 seconds] reply benterix 11 hours agorootparentThank you for providing the video length, it is the factor that made me click. reply rowinofwin 19 hours agorootparentprevAnd there are at least 3 fish reply thayne 13 hours agoparentprevIt sounds to me like more than just a refactor, it now allows blocking based on ip earlier, before the request is actually made. Although, that isn't perfect because it doesn't know which ip address the browser will choose if there are multiple ips for a single domain. reply dang 18 hours agoparentprevOk, I've reverted the title to that of the page. Submitted title was \"uBlock Origin supports filtering CNAME cloaking sites on Firefox now\". If someone wants to suggest a more accurate and neutral title, we can change it again. Github commits without additional context don't usually make for great HN threads though... reply vifon 4 hours agorootparentSomething akin to \"uBlock Origin CNAME uncloaking now supports filtering by IP address\" should be fine. reply dang 49 minutes agorootparentOk, I've switched to that - thanks! reply jeanlucas 20 hours agoprevIt did not hit me yet, but I'm already rewriting my extensions to firefox to switch if Chrome really axes uBO reply TheGlav 20 hours agoparentIt's not if. It's when. It has been 'when' since 2020. It is coming. It is not going to not come. It will be here in mere releases. Get ready. reply chrisfosterelli 19 hours agorootparentYou're probably right, but FWIW it's not unheard of for google to announce, continually delay, and eventually completely backtrack on things like this, like third party cookie deprecation. reply zarzavat 19 hours agorootparentThis time it affects their bottom line in a profound way so wishful thinking is probably not going to work unfortunately. reply Terretta 19 hours agorootparent> affects their bottom line in a profound way Something around 8% of total digital ad spend. reply sebastialonso 18 hours agorootparentTo be fair, that's tremendous reply timbowhite 16 hours agorootparentprevSource? reply jeanlucas 20 hours agorootparentprevYeah, hence why I started already migrating, slowly. I have a simple tab organizer extension and some greasemonkey scripts that should work perfectly fine on Firefox without any changes. reply godzillabrennus 20 hours agoparentprevI am switching family over to Brave. They don’t even notice the difference and I’m more confident the browser will continue to support user centric content filtering. reply capitainenemo 19 hours agorootparentWhich is fine so long as what they have built into the browser is all you need (and so long as Google does not sabotage those efforts). If ever you might need more such as what uBO offers, though, Brave is also subject to whatever changes Google makes (such as Manifest V3). reply WD-42 19 hours agorootparentprevIs that going to help? Brave is still blink. They might have some filtering baked in but I’m not sure if it’s as powerful (or can be) as UBO. reply smallerize 19 hours agorootparentBrave will keep Manifest V2 compatibility as long as they can, specifically focusing on \"AdGuard AdBlocker, NoScript, uBlock Origin, and uMatrix\". https://brave.com/blog/brave-shields-manifest-v3/ reply WD-42 19 hours agorootparentI guess I'm curious what \"as long as they can\" actually means. If it means they can't pull upstream Blink without losing v2 support, that's bad. I think Firefox is the only viable solution to continue using UBO at this point. reply EasyMark 5 hours agorootparentI seem to recall they said as long as it was technically AND economically feasible. It depends on how much google attempts to spread the cancer of mv3 throughout their code base. Eventually brave won’t have the manpower to hack v2 in is the likely result without going bankrupt if google really wants to go down that path. reply xelamonster 18 hours agorootparentprevI don't think the new manifest rules are because of any actual restriction or the engine, maybe I'm wrong but it was my impression that the change is mostly just Google wanting to control what users can do with their browsers even more (and always in ways that make them profit of course). So they should be able to keep V2 support if they're willing to be on the hook for keeping it maintained themselves. reply capitainenemo 18 hours agorootparentAnd if the removal of manifest v2 allows google to abandon/remove/refactor code exposed through it (and google could even be inclined to do so deliberately)? At some point Brave would end up having to maintain its own fork, which they probably don't have the resources to do. reply sureIy 4 hours agoparentprev> I'm already rewriting my extensions to firefox What does that mean? Firefox uses the same API. At most you have to change `background.service_worker` to `background.scripts` (literally just rename the key) reply c2h5oh 20 hours agoparentprevIt's already axed in canary release reply jeanlucas 20 hours agorootparentI'm still at the \"This extension may soon no longer be supported\" warning reply Technetium 1 hour agorootparent2 days ago: \"Chrome Canary just killed uBlock Origin and other Manifest V2 extensions\" https://news.ycombinator.com/item?id=41757178 reply altdataseller 20 hours agoparentprevFor those unaware, what is uBO and how would it affect most extensions? reply OkGoDoIt 19 hours agorootparentuBO (uBlock Origin) is a popular open source ad blocker. There is a change coming to the way Google Chrome and some other browsers host extensions called manifest v3, which for (stated) security and privacy purposes limits a lot of the functionality that makes ad blockers work the way they do. There are workarounds but they are suboptimal. This has been an ongoing fight for years and there are plenty of accusations that Google is doing this because they want to cripple ad blockers since they make so much money from advertising. Firefox has explicitly stated they will not force these changes on extension developers, and thus a lot of people have been threatening to move to Firefox whenever Google finally makes this change for real. reply testfrequency 19 hours agorootparentprevMaybe it’s a telling sign of the new wave of HN users, but I’m genuinely surprised to read that you don’t know what uBlock is.. reply jeanlucas 14 hours agorootparentI'm happy youngsters still use this ol' forum reply EasyMark 5 hours agorootparentIt’s good that we are still getting Youngbloods who see the superiority of text in communications rather than one sided talking head videos. reply cholmon 19 hours agorootparentprev\"uBO\" is an abbreviation of \"uBlock Origin\". reply itohihiyt 20 hours agoprevuBlock Origin is what makes Firefox even greater and definitely one big reason I use Firefox over Chrome etc. It make the Internet browsable. reply ants_everywhere 19 hours agoparentThat may change since Mozilla is becoming an ad company reply EasyMark 5 hours agorootparentThey are not, but they are adding in support for more anonymous ads as they see it as a “compromise”, I don’t but I also don’t think they are as malevolent as a lot of people on HN and Reddit like to make them out to be. reply EasyMark 5 hours agoparentprevHonestly I’ve used brave and Firefox and don’t see a huge difference. I still prefer Firefox though because of its philosophy and status as coming from a nonprofit. Brave is a quality project too though, and is my back up, although sometimes I throw Vivaldi in the mix because of its windows splitting and much superior tab management. reply jajko 20 hours agoparentprevI moved many years ago to this combo, and never saw a single reason to switch away. Same for android phone, the only usable mobile web experience I've seen. Those few sites over a decade that had some display issues had issues also under chrome. Plus I personally consider ads a cancer of modern society. White and not so white lies, manipulation... nothing respectable regardless (or because ) of tremendous money circulating in it. reply xelamonster 19 hours agorootparentI really wish I could agree but sadly this has not been my experience with Firefox, and I have so many issues I've started to switch away recently. Wasting way too much time fighting with websites that turn out to work perfectly fine on Chrome, and the captchas I get on Firefox are becoming genuinely impossible for me to solve. I'm with you on the ads though, and glad it's working out for someone at least! reply OkayPhysicist 18 hours agorootparentTry Firefox serving Chrome's UserAgent. You'll be shocked how many issues disappear. reply EasyMark 5 hours agorootparentCan you recommend an extension for that? I use “User agent switcher and manager” but it seems overly complicated and aimed at web devs. I just want a simple interface and easy switching between OS and browser combinations reply jholman 17 hours agorootparentprevI have very few issues with Firefox. The two that I suspect are: 1) Google-owned sites seem to just chew CPU on Firefox. In particular I'm thinking of GMail and Youtube, both of which I'm a heavy user of, and also Maps. But no non-google sites seem to have this problem. 2) I'm constantly getting websites saying \"This is your first time using this device, are you sure you're you?\", and I haven't tried whether it's better on Chrome, but it's pretty crazy because I've literally never used your stupid site with any other device, and I used it with THIS device just last month you idiots. I'm just blind guessing that this is some kind of problem as a result of Firefox privacy choices, like maybe the site doesn't know how to use cookies in a way that doesn't trigger anti-tracking. For example banks. But Firefox can keep thousands of tabs open at once (thousands. plural. not kidding, not exaggerating.), it has working uBO, and the frequency of \"just because we wanted to\" UX changes is much lower. It's just a better choice all around. reply beeflet 20 hours agorootparentprevI mean there are appropriate applications for advertising (like classifieds in a newspaper), but there is no reason why advertising should be so pervasive that it requires a massive surveillance apparatus like it does today. Advertisements are the reason why everyone switched from TV to Netflix, and that's back when cable TV was a paid service. secushare[1] makes the case that this is because the internet lacks a secure micropayments layer, so the funding model for everything has to be advertising-based instead of patronage-based. Paypal and the like are exploited as cash cows because of their centralized nature. Cryptocurrencies were later tried but have technical limitations that broadly prohibit this use case (even with payment channels/LN). [0] https://secushare.org/broken-internet reply warkdarrior 19 hours agorootparentUgh, micropayments again! I have no desire to pay for content or software -- torrents and OSS are all anyone needs. reply RockRobotRock 21 hours agoprevCNAME cloaking? Does this mean an ad site may use a randomly generated subdomain pointing to a wildcard record? reply nodja 20 hours agoparentThat's part of it. Normally when you visit contentsite.com which serves ads from adsite.com. Adblocker rules can just block adsite.com and the ads won't be shown. CNAME cloaking would have the main site have a subdomain like adsite.contentsite.com point to adsite.com, now the adblockers have the impossible task of blocking millions of subdomains that seemingly belong to legit sites, this also allows the legit sites to keep changing the subdomain since the adblocker will have no idea which subdomains serve legit content vs ads. As a bonus since the content is being served from the same domain, they can bypass certain cookie browser policies and track users even better. This update allows you to set rules so that you can filter by resolved ip. reply Pxtl 19 hours agorootparenti hope that this results in sites that host malicious ads and use wildcard session-cookies get hacked to all hell by their ads. reply shiroiushi 14 hours agorootparentI would hope that this results in websites hosting malicious ads which harm users, which then results in a big lawsuit against these websites with a huge payout for the harmed users. After all, if the malware ad is being effectively hosted by the site, then the site should be legally responsible. reply synergy20 20 hours agorootparentprevthis reminds me of domainfronting, who was a super smart way to get around of ads and other sites blockers, not sure if it's all 'fixed' now. reply ceejayoz 20 hours agoparentprevYes. Ads and analytics providers have started doing this to get around third-party cookie protections. reply sidewndr46 20 hours agorootparentI always find this development curious. About a decade ago I worked in this space. When someone brought up ad blockers I just said \"put the analytics on our main domain. No one is going to block the entire website\". The answer I got was \"no one would ever do that because of the implications of serving advertising from your main domain\". Yet, here we are. reply alerighi 20 hours agorootparentThey use a third party domain just because that way they can track the user actions with cookies, for example Google can track your navigation across multiple websites, and thus propose to you more relevant ads. Also using a different domain was simpler and cheaper, since you don't have to host the AD content and metadata, just include the JS from the AD provider somewhere in your HTML. Now that thanks to EU laws and browser imposing restrictions about third-party cookies it's more difficult, the whole \"serve ads from other domain\" may not be that relevant anyway. If you use a random wildcard subdomain... just serve them from the main website, what is the difference? On the other side with a proxy just route the AD requests to another server if it needs to be, of course you have to find a way to distinguish which requests are for AD and which are not, something you can do with some sort of signature in the filename, so that only the server can know which requests shall be handled locally and which one forwarded to the AD provider server. reply bluGill 20 hours agorootparentprevNews payers used to all serve their own ads including in house sales and design. Frankly with how key advertising is I don't understand why anyone would out source it. reply 627467 20 hours agorootparentThis. Everyone and their grandma decided it's cool for Google and others to decide what should display on your website next to your content because of \"magic online advertising\". How much of the efficiency of online advertising comes from the actual \"art\" of tracking users and their preferences to display \"personalized\" ads vs the \"efficiencies\" from firing/outsourcing your marketing, ad sales and creative workforce. reply grogenaut 19 hours agorootparentprevAdvertisers trust other advertisers not to lie but not the content providers. well except Google they trust Google. So you have to use these hella shady and networks that are fly by night and security and privacy nightmares across many domains. Instead of many walled gardens of ads like you're saying. reply pas 20 hours agorootparentprevcost and effectiveness. selling ad space was always a lot of work. algorithms do it cheaper and in general better. next step is just to run a GoogleAds lib/proxy... reply bluGill 17 hours agorootparentUntil the algorith associates you with an ad for something negative to your audience. Scams for example are common for algorithms to allow while a human can validate some legitimentch reply Groxx 20 hours agorootparentprevParticularly with the reams of evidence that fraud is rampant, both in advertising content and in claimed click/view rates. reply thayne 13 hours agorootparentprevWell, it's just a question of priorities. What do you care about more, security on your site, or getting your ads past ad-blockers? I'm not surprised there are people who prioritize the latter, especially for small sites where they may not have someone who fully understands the risks. reply hypeatei 20 hours agorootparentprevWhat are the implications? reply dpifke 20 hours agorootparentIf third party ad servers get access to your main domain's cookies, they can impersonate your signed-in users and steal their data. reply _fool 19 hours agorootparent...Unless you're savvy. Thank goodness for the availability of https://publicsuffix.org/ (as long as you only use your main domain and don't need to share cookies with your own subdomains), and the includeSubDomains directive to HSTS! But - if you already set this up, you probably are savvy enough to avoid the problems created (or your provider is) reply aaronmdjones 18 hours agorootparentHSTS won't prevent this at all; the advertiser merely needs to also set up TLS by getting a certificate for that subdomain, which they can already do precisely because it goes to their web server -- not yours. This also lets them steal cookies marked secure (sent over HTTPS only). Edit: A combination of DNS CAA with an account identifier restriction in the record would prevent this. Then the advertiser would complain, and any ads served would have to be over plaintext, which would cause browser warnings about mixed content and allow MITM injection of (more) malicious content. reply debit-freak 20 hours agorootparentprevPresumably that adblockers (or rather their users) would object to blocking domains that folks might actually want to load content from. I can’t imagine “domain” is the only signal one could use to identify ads, though. To truly befuddle them you’d make advertisements truly indistinguishable from content. This is not trivial. reply sidewndr46 20 hours agorootparentNot entirely true. If you lower the quality of your content enough the advertisements are in fact indistinguishable. I often enjoy reading the \"chumbox\" at the bottom of the news article more than the reporting itself reply grotorea 18 hours agorootparentprevI think what we're asking is what are the implications for the advertisement company. And yeah, I can trivially block stuff in uBO by using CSS rules for example, so that's still on the table. reply debit-freak 2 hours agorootparent> I think what we're asking is what are the implications for the advertisement company. Higher impressions? Higher integration cost? I guess I'm not sure what the confusion might be. Advertisers obviously want to ram their bullshit down as many eyesockets as they can find. reply sidewndr46 20 hours agorootparentprevIt more or less boiled down to \"we would be labeled an advertiser and not a destination for information on the internet\". Like being an advertiser stopped people from using Google search or something reply Groxx 15 hours agorootparentOr newspapers, both before and after it. They've always been vast advertising platforms, but don't have anywhere near the same stigma that online advertisers have acquired (for extremely good reasons imo - they're as invasive as possible, while printed media has rather tight limits) They could have become the dominant advertisers online too, and then no doubt they'd be just as nasty. But they lost that war multiple times, first to doubleclick-likes and then to social media. reply belorn 19 hours agorootparentprevRandomly generated domains are a major red flag for abuse and malware detection, and seems to have become a rather large part of how the domain industry manage abuse. Domain \"credit score\" is also something that is used in the email industry to score links and thus spam values. A large part of providing score values is behind security companies that offer their service as a paid services, but as with a lot of this stuff there are a lot of movement to offer it for free similar to spam block lists. It will be interesting when this kind of technology moves down to browser add-ons. reply 404mm 20 hours agorootparentprevThis is such an intrusion of privacy. I wish I could just disable cookies entirely but the usability of many webpages just goes down. I should not be punished for not wanting 3rd party trackers. reply quesera 19 hours agorootparentI run all the time with first-party cookies disabled. Most of the web works. Anything that does not, and I care about, gets blessed. The only content I allow by default, even in low-security browser profiles, and even from first-party domains, are HTML, CSS, and images. I consider the occasional broken page to be a successful test of my configuration. If I care, I adjust permissions. reply Sophira 17 hours agorootparentWhat do you use to enforce this? Is it something that's going to break with Manifest V3? reply quesera 11 hours agorootparentI use uMatrix. On Firefox, so no current concerns about MV3. reply jrockway 20 hours agorootparentprevBefore I get too alarmed someone would have to tell me how an adsite.com cookie is being sent to adsite.example.com. This workaround seems to let adsite.com profile me as well as example.com already can, but it loses the ability to correlate my activity across example2.com and example.com with a single cookie. (I guess ad providers have gotten good enough to not need cookies? Like they know my browser window size, installed fonts, GPU vendor and model, IP address, geolocation, header order, etc. so they don't even need cookies anymore to track my activity across the web? I suppose it was only a matter of time.) reply lancesells 19 hours agorootparentThe correlation is happening through an API connection between adsite.com and example.com and not through cookies. So even if you block all third party cookies and scripts your activities are being tracked through the first party. reply pas 19 hours agorootparentprevcookie is for each site, but that's enough... sure, maybe no retargeting ads, but those were creepy anyways (and likely not more effective) reply bongodongobob 20 hours agorootparentprevBrowser profiling has been a thing for at least a decade if I'm not mistaken. reply jrockway 20 hours agorootparentMakes sense. \"I am session abcdef12345\" always seemed significantly guaranteed to me, but in a world with ad blockers and third-party cookie restrictions, using heuristics is the only way forward. It's somewhat scary how much information our browsers leak to unknown parties. (I don't really take sides on this. I use an ad blocker and am very anti-ad, but am impressed when ad companies come up with tech to thwart them. The cat-and-mouse game is entertaining to read about.) reply pas 19 hours agorootparentit's more than enough. especially that the competition is also only using the same tech reply A4ET8a8uTh0 20 hours agorootparentprevThere is a part of me that, at a high level, appreciates the back and forth between the user and the ad industry. On a personal level, I am slowly getting to the point, where I am less.. uhh.. understanding. That said, the average person's conception of what acceptable needs to change. I did briefly think that they need suffer through more ad-infestation first, but I realized that the answer is more in line with what my wife seemed to have gone through. The low exposure to ads made her less willing to deal with them. This might be the way forward. It is hard for a person used to existing ecosystem to even imagine, there could be something better. reply labster 18 hours agorootparentCertainly, streaming services have ruined broadcast television for me. I don’t know how I used to spend over $100 a month on cable TV to be advertised to. Spending four and a half days a year (44 minutes out of every two hours) watching ads is not for me. reply tyingq 19 hours agoprevThis a good example of why manifest v3 sucks. By definition, it can't do anything like this...no live code hueristics are possible. It's a war of escalation with advertisers. Google is the arms dealer to both sides. They won't give you what you would need to win. reply madeofpalk 18 hours agoparentThere's no reason why a declarative manifest v3 API couldn't offer this. If I'm reading the commit details correctly, it could work even better by being better integrated into the request flow to block the request on the actual IP address used before anything is sent to the servers. Of course, this all relies on browser vendor (Google) wanting to add this API. Doing this imperatively with \"live code\" allows for innovations in userland before browser makers add built in support for it. reply tyingq 17 hours agorootparentIt could. Google won't do that for chrome. Had they not taken away onBeforeRequest with manifest V3, plugins could implement it themselves. Which is the thing you're suggesting...before the request goes. reply madeofpalk 17 hours agorootparentThe commit message details the caveat of using onBeforeRequest, and how it's not perfect because it's called at the wrong time in the request lifecycle with incomplete info. reply tyingq 16 hours agorootparentThis commit is using onBeforeRequest: >The change allows early availability of ip address so that `ipaddress=` option can be matched at onBeforeRequest time. It is using some other functionality, on Firefox only, to get that early availability. But I'm saying Chrome is a non-starter since onBeforeRequest is hobbled there. So the \"early availability of ip address\" doesn't help. You need both. reply gruez 19 hours agoparentprev>This a good example of why manifest v3 sucks. By definition, it can't do anything like this... Technically manifest v3 has nothing to do with APIs that the browser makes available to extensions. On firefox manifest v3 is supported with blocking web request[1], which is the filtering api prior to \"manifest v3\". Therefore the statement that it certain functionality \"by definition\" is false. [1] https://blog.mozilla.org/addons/2022/05/18/manifest-v3-in-fi... reply tyingq 16 hours agorootparent> Therefore the statement that it certain functionality \"by definition\" is false. Here's the design document. The hobbling is noted there as part of the spec. \"API Changes WebRequest: Restrict the blocking capabilities of the webRequest API.\" https://docs.google.com/document/d/1nPu6Wy4LWR66EFLeYInl3Nzz... That firefox chose to skip that portion of the design and still call it 'v3' doesn't change history. A true-to-spec implementation kills live heuristics. reply fallingsquirrel 18 hours agorootparentprevExactly this. There's some good stuff in MV3, but Google decided to take the opportunity to smuggle in some self-serving changes, similar to how Congress likes to sneak controversial laws under the radar as part of unrelated bills*. * https://en.wikipedia.org/wiki/Rider_(legislation) reply WD-42 18 hours agorootparentprevOK so Google's near monopoly implementation of V3 sucks. Technically a difference, but practically not so much. reply takeda 18 hours agorootparentprevI'm confused, isn't the Manifest V3 essentially just API spec? reply tyingq 18 hours agorootparentThey trojan horsed hobbling webRequest.onBeforeRequest into their manifest v3 design doc and rollout. Which is part of what would give you request time cloak detection. reply nine_k 18 hours agorootparentprevYes. The point is which APIs Google exposes through it. reply codetrotter 19 hours agoparentprevAbandon Chrome, embrace Firefox. reply Exuma 20 hours agoprevIs chrome going to block uBO im never up to date on the latest. I do know theyre allowing 3rd party cookies now... so maybe theres a chance reply TheGlav 20 hours agoparentThey're not blocking uBO, they're removing the features in the browser that allowed uBO to work by releasing new plugin APIs, \"Manifest v3\". They're eliminating the key APIs needed for uBO to identify things that it shouldn't load, and then not load them. Google claims this was for \"performance\" or \"security\" reasons. Of course, the only major 'performance' or 'security' affected is the ability to identify, intercept, and stop harmful or ad related downloads before they start. reply altdataseller 19 hours agorootparentDoes this affect extensions that know every website you visit even if it doesnt need to know, and has nothing to do with the extension’s functionality? (ie the ones that Similarweb buys) reply blacksmith_tb 19 hours agoparentprevNot updating your browser is also hazardous - much better to switch to FF, and have a browser that gets updates and also fully supports uBO. reply anderskaseorg 20 hours agoparentprevThey’re doing a slow phase-out over a long time to try to avert a wave of bad publicity that threatens their browser monopoly, but that timeline has already started as of June. https://developer.chrome.com/docs/extensions/develop/migrate... https://www.bleepingcomputer.com/news/google/google-chrome-w... reply Dwedit 18 hours agoparentprevFor right now, uBlock Origin is still on the Chrome Web Store for Chromium browsers which support Manifest V2. If you use a Manifest V3 only version of Chromium, it is hidden. reply o11c 20 hours agoparentprevHonestly, it probably is going to depend on whether the US continues to have an administration that's willing to take blatant monopolists to court. reply tbrownaw 19 hours agoprevDon't some DNS servers implement something that acts like a server-resolved CNAME, where the admin puts in a record that points to some other DNS name but the client just sees an A (out AAAA) record? reply nikeee 19 hours agoparentI think you are referring to ALIAS records reply _fool 19 hours agorootparentYup. some implementations provide similar ANAME, and Cloudflare has flattened CNAME which is probably the best implementation I came across in years of supporting folks trying to use these kinds of records on a large CDN. https://developers.cloudflare.com/dns/cname-flattening/ reply taftster 16 hours agoprevuBO has had this feature for awhile, since 1.34.0 (or 1.25.0 in advanced settings). https://github.com/gorhill/uBlock/wiki/Dashboard:-Settings#u... I think that's around 2021 time frame. FYI. reply lelandbatey 20 hours agoprevAs an example of what CNAME cloaking is, let's say that a SAAS provider A wants to provide you, company Q, with fancy ad tracking software. In the olden days, they'd tell you to embed a script at e.g. https://A-ads-tracking.example into your website at address https://q-company.example To block those ads, blocklists that uBlock Origin use have rules then that say \"block requests being made to the domain name A-ads-tracking.example\", which blocks the ads. CNAME cloaking is where SAAS provider A sets up their ad-tracking services not on domain A-ads-tracking.example, but instead at a specific IP address of e.g. 29.1.2.3; then (and here's the important part) SAAS A tells you Company Q that you need to set up a subdomain of q-company.example which has a CNAME record pointing to 23.1.2.3, a subdomain with an innocuous name like media.q-company.example; once you've set up that CNAME, you at Company Q add a script tag to your website for `media.q-company.example` and now SAAS A is able to track all the users on your site. This indirection allows for effectively infinite cat-and-mouse on the part of you the owner of the Q Company vs the blocklists that the public assemble. To get around this CNAME cloaking problem, the software powering extensions like uBlock Origin need to be able to see not only the destination domain of requests by browsers, but the underlying IP addresses of those domains as well. This commit makes that behavior possible, or at least is related to making that code work better. reply ndriscoll 19 hours agoparentThat's not quite right; as the name suggests, it uses CNAMEs (which point to other records), not A records (which point to IPs). So you would have something like `media.q-company.example` as a CNAME to `q-company.ads-tracking.example` which then has an A record to give an IP. Browsers might not offer intermediate DNS names to extensions (I don't know), so something like uBlock might need to rely on IP lists, but DNS-based filtering like pihole should just block it by a rule against `ads-tracking.example`. In any case, it's good to use both browser based and DNS based malware blockers. reply lelandbatey 18 hours agorootparentGah, it's all right there! Amazing what you can forget/mistake due to what you've been working on lately. reply biglyburrito 20 hours agoparentprevThank you for the breakdown! reply itohihiyt 20 hours agoparentprevAnd this is a good reason to block all JavaScript in unlock advanced and slowly whitelist the scripts you see until the site works properly. Slow and error prone but once you get used to it it's a breeze. And you're completely immune to this sort of shittery. reply jftuga 19 hours agorootparentIs there a public list of known legit, whitelisted scripts? reply itohihiyt 11 hours agorootparentNone that I'm aware of but I've not looked either. reply marcell 20 hours agoprev [–] What is the uBI status on Brave, Edge and Opera? reply homebrewer 20 hours agoparent [–] I don't care about the two proprietary browsers you've mentioned, but Brave is going to (partially) support manifest v2 and maintain uBO compatibility for as long as they're able to: https://brave.com/blog/brave-shields-manifest-v3/ Not that you really need it as Brave has its own very capable built-in ad blocker with -- last time I checked -- higher performance than uBO (since it's compiled into native code) and full support for same ad lists. reply zamadatix 19 hours agorootparentBrave is open source instead of proprietary now? I knew they were Chromium based (like the others) but I hadn't realized they switched over on all of the customizations on top. reply mossTechnician 18 hours agorootparentBrave is like Firefox: it's open source, But it connects to some closed source servers to serve up contentious features (IMO this is a bigger problem on Brave than Firefox, since many of them cannot be fully hidden). reply attentive 10 hours agorootparentprev [–] and brave/shield supports CNAME uncloaking reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The update enhances uBlock's DNS resolution code, improving its ability to filter by CNAME (Canonical Name) and IP address.",
      "A new feature allows the `ipaddress=` option to block root documents if the IP is extracted before the first request, though it uses the first IP from the DNS list, which may differ from the browser's choice.",
      "The commit involves changes across multiple files, with 153 lines added and 96 lines removed, indicating a significant code update."
    ],
    "commentSummary": [
      "uBlock Origin has updated its CNAME uncloaking feature to include IP address filtering, which was previously exclusive to Firefox.",
      "This update enhances existing functionality by allowing IP-based blocking before requests are made, though it may face challenges with domains having multiple IPs.",
      "Ongoing discussions focus on browser support for uBlock Origin, particularly with Chrome's Manifest V3 changes, prompting users to explore alternatives like Firefox and Brave for better ad-blocking capabilities."
    ],
    "points": 272,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1728334328
  },
  {
    "id": 41776878,
    "title": "Kotlin Money",
    "originLink": "https://blog.eriksen.com.br/en/introducing-kotlin-money",
    "originBody": "Introducing Kotlin Moneybody{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}/** * Reset some basic elements */ body, h1, h2, h3, h4, h5, h6, p, blockquote, pre, hr, dl, dd, ol, ul, figure { margin: 0; padding: 0; } /** * Basic styling */ body { font-family: Helvetica, Arial, sans-serif; font-size: 16px; line-height: 1.5; font-weight: 300; color: #111; background-color: #fdfdfd; -webkit-text-size-adjust: 100%; } /** * Set `margin-bottom` to maintain vertical rhythm */ h1, h2, h3, h4, h5, h6, p, blockquote, pre, ul, ol, dl, figure, .highlight { margin-bottom: 15px; } /** * Images */ img { max-width: 100%; vertical-align: middle; } /** * Figures */ figure > img { display: block; } figcaption { font-size: 14px; } /** * Lists */ ul, ol { margin-left: 30px; } li > ul, li > ol { margin-bottom: 0; } /** * Headings */ h1, h2, h3, h4, h5, h6 { font-weight: 300; } /** * Links */ a { color: #2a7ae2; text-decoration: none; } a:visited { color: #1756a9; } a:hover, a.active { color: #111; text-decoration: underline; } /** * Blockquotes */ blockquote { color: #828282; border-left: 4px solid #e8e8e8; padding-left: 15px; font-size: 18px; letter-spacing: -1px; font-style: italic; } blockquote > :last-child { margin-bottom: 0; } /** * Code formatting */ pre, code { font-size: 15px; border: 1px solid #e8e8e8; border-radius: 3px; background-color: #eef; } code { padding: 1px 5px; } pre { padding: 8px 12px; overflow-x: scroll; } pre > code { border: 0; padding-right: 0; padding-left: 0; } /** * Wrapper */ .wrapper { max-width: -webkit-calc(900px - (30px * 2)); max-width: calc(900px - (30px * 2)); margin-right: auto; margin-left: auto; padding-right: 30px; padding-left: 30px; } @media screen and (max-width: 800px) { .wrapper { max-width: -webkit-calc(900px - (30px)); max-width: calc(900px - (30px)); padding-right: 15px; padding-left: 15px; } } /** * Clearfix */ .wrapper:after, .footer-col-wrapper:after, .content-col-wrapper:after, .book .book-meta:after { content: \"\"; display: table; clear: both; } /** * Site header */ .site-header { border-top: 5px solid #424242; border-bottom: 1px solid #e8e8e8; min-height: 56px; position: relative; } .site-title { font-size: 26px; line-height: 56px; letter-spacing: -1px; margin-bottom: 0; } .site-title, .site-title:visited { color: #424242; } .site-tagline { display: block; color: #828282; font-size: 13px; margin-top: -10px; } .site-nav { float: right; line-height: 56px; } .site-nav .menu-icon { display: none; } .site-nav .page-link { color: #111; line-height: 1.5; } .site-nav .page-link:not(:first-child) { margin-left: 20px; } @media screen and (max-width: 600px) { .site-nav { position: absolute; top: 9px; right: 30px; background-color: #fdfdfd; border: 1px solid #e8e8e8; border-radius: 5px; text-align: right; } .site-nav .menu-icon { display: block; float: right; width: 36px; height: 26px; line-height: 0; padding-top: 10px; text-align: center; } .site-nav .menu-icon > svg { width: 18px; height: 15px; } .site-nav .menu-icon > svg path { fill: #424242; } .site-nav .trigger { clear: both; display: none; } .site-nav:hover .trigger { display: block; padding-bottom: 5px; } .site-nav .page-link { display: block; padding: 5px 10px; } } /** * Site footer */ .site-footer { border-top: 1px solid #e8e8e8; padding: 30px 0; } .footer-heading { font-size: 18px; margin-bottom: 15px; } .contact-list, .social-media-list { list-style: none; margin-left: 0; } .footer-col-wrapper { font-size: 15px; color: #828282; margin-left: -15px; } .footer-col { float: left; margin-bottom: 15px; padding-left: 15px; } .footer-col-1 { width: -webkit-calc(35% - (30px / 2)); width: calc(35% - (30px / 2)); } .footer-col-2 { width: -webkit-calc(20% - (30px / 2)); width: calc(20% - (30px / 2)); } .footer-col-3 { width: -webkit-calc(45% - (30px / 2)); width: calc(45% - (30px / 2)); } @media screen and (max-width: 800px) { .footer-col-1, .footer-col-2 { width: -webkit-calc(50% - (30px / 2)); width: calc(50% - (30px / 2)); } .footer-col-3 { width: -webkit-calc(100% - (30px / 2)); width: calc(100% - (30px / 2)); } } @media screen and (max-width: 600px) { .footer-col { float: none; width: -webkit-calc(100% - (30px / 2)); width: calc(100% - (30px / 2)); } } .license { font-size: 15px; color: #828282; } /** * Page content */ .page-content { padding: 30px 0; } .page-heading { font-size: 20px; } .post-list { margin-left: 0; list-style: none; } .post-list > li { margin-bottom: 30px; } .post-meta { font-size: 14px; color: #828282; } .post-link { display: block; font-size: 24px; } .content-col { float: left; margin-bottom: 15px; padding-left: 30px; } .content-col-1 { width: -webkit-calc(73%); width: calc(73%); padding-left: 0; } .content-col-2 { width: -webkit-calc(27% - (30px)); width: calc(27% - (30px)); } @media screen and (max-width: 800px) { .content-col-1, .content-col-2 { width: -webkit-calc(100% - (30px / 2)); width: calc(100% - (30px / 2)); padding-left: 0; } } @media screen and (max-width: 600px) { .content-col { float: none; width: -webkit-calc(100% - (30px / 2)); width: calc(100% - (30px / 2)); padding-left: 0; } } .sidebar .social-media-list li { float: left; padding-right: 5px; } .site-author p { font-size: 15px; color: #828282; padding-top: 15px; } @media screen and (max-width: 800px) { .site-author img { float: left; margin-right: 15px; } .site-author p { padding-top: 0; } } @media screen and (max-width: 600px) { .site-author img { float: left; margin-right: 15px; } .site-author p { padding-top: 0; } } @media screen and (max-width: 400px) { .site-author img { float: none; } .site-author p { padding-top: 15px; } } /** * Posts */ .post-header { margin-bottom: 30px; } .post-title { font-size: 42px; letter-spacing: -1px; line-height: 1; } @media screen and (max-width: 800px) { .post-title { font-size: 36px; } } .post-content { margin-bottom: 30px; } .post-content h2 { font-size: 32px; } @media screen and (max-width: 800px) { .post-content h2 { font-size: 28px; } } .post-content h3 { font-size: 26px; } @media screen and (max-width: 800px) { .post-content h3 { font-size: 22px; } } .post-content h4 { font-size: 20px; } @media screen and (max-width: 800px) { .post-content h4 { font-size: 18px; } } table { table-layout: fixed; width: 100%; margin-bottom: 15px; border-collapse: collapse; } table, table th, table td { border: 1px solid #AAA; } table th, table td { padding: 15px; } table tr:nth-of-type(2n) { background: #EEE; } .mapping-domain-knowledge table th:nth-child(1), .mapping-domain-knowledge table th:nth-child(3) { width: 43%; } .mapping-domain-knowledge table th:nth-child(2) { width: 14%; } .mapping-domain-knowledge table td:nth-of-type(2) { text-align: center; } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { .mapping-domain-knowledge table td:nth-of-type(2) { text-align: left; } } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { .mapping-domain-knowledge table td:nth-of-type(1):before { content: \"If your project\"; } .mapping-domain-knowledge table td:nth-of-type(2):before { content: \"Score\"; } .mapping-domain-knowledge table td:nth-of-type(3):before { content: \"Supporting thoughts\"; } } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { /* Force table to not be like tables anymore */ table, thead, tbody, th, td, tr { display: block; } table { /* Hide table headers (but not display: none;, for accessibility) */ } table thead tr { position: absolute; top: -9999px; left: -9999px; } table tr { border: 1px solid #AAA; } table td { /* Behave like a \"row\" */ border: none; border-bottom: 1px solid #CCC; position: relative; padding-top: 35px; } table td:before { /* Now like a table header */ position: absolute; /* Top/left values mimic padding */ top: 6px; left: 6px; padding-right: 10px; white-space: nowrap; font-weight: bold; } } /** * Custom styles for this website. */ hr { height: 1px; margin-bottom: 15px; background-color: #eee; border: 0 none; } dt { font-weight: bold; } dt::after { content: \":\"; } dd { margin: 0 0 5px 15px; } .cover-image { width: 100%; height: 250px; background-position: center center; background-repeat: no-repeat; background-size: cover; } @media only screen and (min-width: 620px) { .cover-image { height: 450px; } } @media only screen and (min-width: 1800px) { .cover-image { height: 800px; } } .cover-image-description { text-align: center; } .post h2, .post h3, .post h4, .post h5, .post h6 { margin-top: 20px; margin-bottom: 20px; line-height: 1.2; } .post amp-img, .post noscript img { margin-top: 15px; } .post noscript + p, .post .centered + p { margin-top: 5px; margin-bottom: 20px; text-align: center; color: #333; } .post .centered { display: flex; justify-content: center; } /** * Icons */ .icon > svg { display: inline-block; width: 16px; height: 16px; vertical-align: middle; } .icon > svg path { fill: #828282; opacity: 1; } amp-img { cursor: pointer; } .site-author amp-img { cursor: default; } .sidebox { background-color: #EEE; margin-bottom: 20px; padding: 20px; } .sidebox *:first-child { margin: 0; padding-top: 0px; padding-bottom: 15px; } .sidebox *:last-child { margin-bottom: 0; } .site-branding { float: left; } .site-translation { float: right; display: block; height: 12px; margin-top: 40px; } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { .site-translation { margin-top: 75px; } } .site-translation img { width: 17px; height: 12px; } .site-menu { float: right; height: 12px; margin-right: 30px; margin-top: 45px; line-height: 12px; } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { .site-menu { float: left; margin-right: 0; margin-top: 0; padding-bottom: 15px; } } .site-menu ul { margin-left: 0; } .site-menu ul li { float: left; display: inline-block; margin-left: 15px; } @media only screen and (max-width: 760px), (min-device-width: 768px) and (max-device-width: 1024px) { .site-menu ul li { margin-left: 10px; } } .site-menu ul li:first-child { margin-left: 0; } .books .post-list { margin-top: 30px; } .books .post-list h2 { margin-bottom: 0; } .book .book-meta { /** * Rules taken from the affiliate link inline styles. */ } .book .book-meta dl { padding-top: 10px; } .book .book-meta .amazon-link { display: block; width: 180px; } @media only screen and (min-width: 620px) { .book .book-meta dl { float: left; width: calc(100% - 180px); padding-top: 0px; } .book .book-meta .amazon-link { float: right; } .book .book-meta .amazon-link:hover { text-decoration: none; } } .book .book-meta .amazon-tracking { border: none; width: 0; height: 0; margin: 0; } .talks .post-list { margin-top: 30px; } .talk .overview { margin-top: 15px; } .talk .quotes li { margin-bottom: 15px; } /** * Syntax highlighting styles */ .highlight { background: #fff; } .highlight .c { color: #998; font-style: italic; } .highlight .err { color: #a61717; background-color: #e3d2d2; } .highlight .k { font-weight: bold; } .highlight .o { font-weight: bold; } .highlight .cm { color: #998; font-style: italic; } .highlight .cp { color: #999; font-weight: bold; } .highlight .c1 { color: #998; font-style: italic; } .highlight .cs { color: #999; font-weight: bold; font-style: italic; } .highlight .gd { color: #000; background-color: #fdd; } .highlight .gd .x { color: #000; background-color: #faa; } .highlight .ge { font-style: italic; } .highlight .gr { color: #a00; } .highlight .gh { color: #999; } .highlight .gi { color: #000; background-color: #dfd; } .highlight .gi .x { color: #000; background-color: #afa; } .highlight .go { color: #888; } .highlight .gp { color: #555; } .highlight .gs { font-weight: bold; } .highlight .gu { color: #aaa; } .highlight .gt { color: #a00; } .highlight .kc { font-weight: bold; } .highlight .kd { font-weight: bold; } .highlight .kp { font-weight: bold; } .highlight .kr { font-weight: bold; } .highlight .kt { color: #458; font-weight: bold; } .highlight .m { color: #099; } .highlight .s { color: #d14; } .highlight .na { color: #008080; } .highlight .nb { color: #0086B3; } .highlight .nc { color: #458; font-weight: bold; } .highlight .no { color: #008080; } .highlight .ni { color: #800080; } .highlight .ne { color: #900; font-weight: bold; } .highlight .nf { color: #900; font-weight: bold; } .highlight .nn { color: #555; } .highlight .nt { color: #000080; } .highlight .nv { color: #008080; } .highlight .ow { font-weight: bold; } .highlight .w { color: #bbb; } .highlight .mf { color: #099; } .highlight .mh { color: #099; } .highlight .mi { color: #099; } .highlight .mo { color: #099; } .highlight .sb { color: #d14; } .highlight .sc { color: #d14; } .highlight .sd { color: #d14; } .highlight .s2 { color: #d14; } .highlight .se { color: #d14; } .highlight .sh { color: #d14; } .highlight .si { color: #d14; } .highlight .sx { color: #d14; } .highlight .sr { color: #009926; } .highlight .s1 { color: #d14; } .highlight .ss { color: #990073; } .highlight .bp { color: #999; } .highlight .vc { color: #008080; } .highlight .vg { color: #008080; } .highlight .vi { color: #008080; } .highlight .il { color: #099; } Eriksen Costa On software development and deliveryHome Playbooks Talks Books reviewsDollar bills and Bitcoins. Photo by David McBee. Introducing Kotlin Money Oct 8, 2024 Manipulating monetary amounts is a common computing chore. However, no mainstream language has a first-class data type for representing money, it’s up to programmers to code abstractions for it. This isn’t an issue per se until dealing with rounding issues from operations like installment payments (e.g., buy now, pay later), foreign exchange, or even simple things like fee processing and tax collection. Inspired by my days at N26 dealing with these challenges, I introduce Money: a Kotlin library that makes monetary calculations and allocations easy: val price = 100 money \"USD\" // USD 100.00 val shipping = 5 money \"USD\" // USD 5.00 val subtotal = price + shipping // USD 105.00 val discount = 10.percent() // 10% val total = subtotal decreaseBy discount // USD 94.50 val ratios = listOf(60.percent(), 40.percent()) // [60%, 40%] total allocate 2 // [USD 47.25, USD 47.25] total allocate ratios // [USD 56.70, USD 37.80]The library supports mathematical operations with monetary amounts, calculations with percentages, and allocation, making it simple to model use cases like those mentioned. Cryptocurrencies are also fully supported out of the box: val price = 0.01607580 money \"BTC\" // BTC 0.01607580 val transactionFee = 1.25.percent() // 1.25% val total = price increaseBy transactionFee // BTC 0.01627675 val installments = total allocate 3 // [BTC 0.00542559, BTC 0.00542558, BTC 0.00542558] val rate = 62_555.60 money \"USD\" // USD 62555.60 val totalInUsd = total exchange rate // USD 1005.63Allocation One of the nicest features of the library is its allocation capability. Allocation allows the distribution of a monetary amount into parts while guaranteeing that the sum of the parts equals the original value. For example, a retailer may accept purchases by credit card installments or by buy now, pay later (BNPL). What happens when a customer makes a purchase totaling USD 100.00 to be paid in three installments? val price = 100 money \"USD\" val number = 3 val installment = price / number val installments = List(number) { installment } // [USD 33.33, USD 33.33, USD 33.33] val total = installments.sum() // USD 99.99As you noticed, there is a loss of USD 0.01. A penny here and there may seem a slight loss, but it may be costly over time. But there are other complications as well, such as overcharging a customer (which can be an infringement of consumer rights in several countries) due to rounding issues. The library provides a handy allocate() method that guarantees the result won’t differ from the original amount: val price = 100 money \"USD\" val installments = price allocate 3 // [USD 33.34, USD 33.33, USD 33.33] val total = installments.allocations().sum() // USD 100.00To allocate in proportional parts, pass a list of Percentage values to the method: val amount = 2345.89 money \"USD\" val result = dueAmount allocate listOf(50.percent(), 30.percent(), 20.percent()) val allocations = result.allocations() // [USD 1172.94, USD 703.77, USD 469.18] val total = allocations.sum() // USD 2345.89As you can see in the previous examples, both results totaled up to the original monetary amount. No cent was lost or gained. By default, the library automatically allocates the difference. But you can tweak how the difference is allocated in the allocations list. For example, suppose your company requires the difference to be always allocated to the last item. You can do it by creating the allocator object directly with the desired allocation strategy: val price = 100 money \"USD\" val allocator = EvenAllocator(OnLast) val installments = allocator.allocate(price, 3) // [USD 33.33, USD 33.33, USD 33.34] val total = installments.allocations().sum() // USD 100.00Wrapping up This post is just a glimpse of the library’s capabilities. I intend to keep the library’s API concise and to expand its capabilities gradually, including supporting Android development and out of the box persistence and serialization. Nevertheless, I hope it’s useful in its current version for people manipulating monetary amounts in Kotlin projects. Refer to the usage guide on how to work with Money. The library has built-in support for 306 circulating currencies and 2283 cryptocurrencies. The installation procedures are explained in the project’s README. Give it a shot!ReferencesPlatform engineering at N26: how we planned and launched itMoney: Project repositorySlate. Lav Varshney, 2019. The Deadly Consequences of Rounding ErrorsMoney: Usage guideMoney: Circulating currenciesMoney: CryptocurrenciesMoney: Installation proceduresWant to discuss this post? Reach me at Twitter! Software developer and open source specialist. Helps organizations to deliver better software, continuously. This blog content is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License. { \"vars\" : { \"gtag_id\": \"G-ZJXJ730P64\", \"config\" : { \"G-ZJXJ730P64\": { \"groups\": \"default\" } } } } { \"@context\": \"http://schema.org\", \"@type\": \"Article\", \"name\": \"Introducing Kotlin Money\", \"headline\": \"Manipulating monetary amounts is a common computing chore. However, no mainstream language has a first...\", \"url\": \"https://blog.eriksen.com.br/en/introducing-kotlin-money\", \"mainEntityOfPage\": \"https://blog.eriksen.com.br/en/introducing-kotlin-money\", \"image\": \"https://blog.eriksen.com.br/assets/images/headshot-2017.jpg\", \"datePublished\": \"2024-10-08\", \"dateModified\": \"2024-10-08\", \"articleBody\": \"Manipulating monetary amounts is a common computing chore. However, no mainstream language has a first-class data type for representing money, it’s up to programmers to code abstractions for it. This isn’t an issue per se until dealing with rounding issues from operations like installment payments (e.g., buy now, pay later), foreign exchange, or even simple things like fee processing and tax collection.Inspired by my days at N26 dealing with these challenges, I introduce Money: a Kotlin library that makes monetary calculations and allocations easy:val price = 100 money \\\"USD\\\" // USD 100.00val shipping = 5 money \\\"USD\\\" // USD 5.00val subtotal = price + shipping // USD 105.00val discount = 10.percent() // 10%val total = subtotal decreaseBy discount // USD 94.50val ratios = listOf(60.percent(), 40.percent()) // [60%, 40%]total allocate 2 // [USD 47.25, USD 47.25]total allocate ratios // [USD 56.70, USD 37.80]The library supports mathematical operations with monetary amounts, calculations with percentages, and allocation, making it simple to model use cases like those mentioned. Cryptocurrencies are also fully supported out of the box:val price = 0.01607580 money \\\"BTC\\\" // BTC 0.01607580val transactionFee = 1.25.percent() // 1.25%val total = price increaseBy transactionFee // BTC 0.01627675val installments = total allocate 3 // [BTC 0.00542559, BTC 0.00542558, BTC 0.00542558]val rate = 62_555.60 money \\\"USD\\\" // USD 62555.60val totalInUsd = total exchange rate // USD 1005.63AllocationOne of the nicest features of the library is its allocation capability. Allocation allows the distribution of a monetary amount into parts while guaranteeing that the sum of the parts equals the original value. For example, a retailer may accept purchases by credit card installments or by buy now, pay later (BNPL). What happens when a customer makes a purchase totaling USD 100.00 to be paid in three installments?val price = 100 money \\\"USD\\\"val number = 3val installment = price / numberval installments = List(number) { installment } // [USD 33.33, USD 33.33, USD 33.33]val total = installments.sum() // USD 99.99As you noticed, there is a loss of USD 0.01. A penny here and there may seem a slight loss, but it may be costly over time. But there are other complications as well, such as overcharging a customer (which can be an infringement of consumer rights in several countries) due to rounding issues. The library provides a handy allocate() method that guarantees the result won’t differ from the original amount:val price = 100 money \\\"USD\\\"val installments = price allocate 3 // [USD 33.34, USD 33.33, USD 33.33]val total = installments.allocations().sum() // USD 100.00To allocate in proportional parts, pass a list of Percentage values to the method:val amount = 2345.89 money \\\"USD\\\"val result = dueAmount allocate listOf(50.percent(), 30.percent(), 20.percent())val allocations = result.allocations() // [USD 1172.94, USD 703.77, USD 469.18]val total = allocations.sum() // USD 2345.89As you can see in the previous examples, both results totaled up to the original monetary amount. No cent was lost or gained. By default, the library automatically allocates the difference. But you can tweak how the difference is allocated in the allocations list. For example, suppose your company requires the difference to be always allocated to the last item. You can do it by creating the allocator object directly with the desired allocation strategy:val price = 100 money \\\"USD\\\"val allocator = EvenAllocator(OnLast)val installments = allocator.allocate(price, 3) // [USD 33.33, USD 33.33, USD 33.34]val total = installments.allocations().sum() // USD 100.00Wrapping upThis post is just a glimpse of the library’s capabilities. I intend to keep the library’s API concise and to expand its capabilities gradually, including supporting Android development and out of the box persistence and serialization. Nevertheless, I hope it’s useful in its current version for people manipulating monetary amounts in Kotlin projects.Refer to the usage guide on how to work with Money. The library has built-in support for 306 circulating currencies and 2283 cryptocurrencies. The installation procedures are explained in the project’s README. Give it a shot!\", \"author\": { \"@type\": \"Person\", \"name\": \"Eriksen Costa\" }, \"publisher\": { \"@type\": \"Person\", \"name\": \"Eriksen Costa\" } }",
    "commentLink": "https://news.ycombinator.com/item?id=41776878",
    "commentBody": "Kotlin Money (eriksen.com.br)256 points by eriksencosta 5 hours agohidepastfavorite150 comments eriksencosta 5 hours agoManipulating monetary amounts is a common computing chore. However, no mainstream language has a first-class data type for representing money, it’s up to programmers to code abstractions for it. This isn’t an issue per se until dealing with rounding issues from operations like installment payments (e.g., buy now, pay later), foreign exchange, or even simple things like fee processing and tax collection. Inspired by my days at N26 Brasil dealing with these challenges, I introduce Money: a Kotlin library that makes monetary calculations and allocations easy. reply kens 0 minutes agoparentThe IBM 1401 mainframe (1959) optionally supported pounds/shillings/pence (£sd) arithmetic in hardware. In those days, there were 12 pence in a shilling and 20 shillings in a pound, so arithmetic with UK money was non-trivial. (This wasn't even microcode; this was literally boards full of transistors to add, subtract, multiply, divide, and format values.) reply yett 2 hours agoparentprevC# has a decimal type: \"The decimal type is a 128-bit data type suitable for financial and monetary calculations.\" https://learn.microsoft.com/en-us/dotnet/csharp/language-ref... reply nsxwolf 1 hour agorootparentThat provides the basis for solving precision and rounding issues but for a money library you need more abstractions. The ability to assign a currency code and supply conversion rates and convert between currencies at a minimum. reply epolanski 11 minutes agorootparentAlso, avoid making errors like summing different currencies. reply tightbookkeeper 1 hour agorootparentprevThat’s an application design choice, not a minimum. An alternative is to work internally in one unit and convert at format time. reply maest 48 minutes agorootparentThat is not a viable alternative. reply serial_dev 32 minutes agorootparentEven though my gut reaction is to agree with you, it’s true that it is an app design decision, so in certain scenarios it might very well be a good design decision. reply jsiepkes 2 hours agoparentprevJava has JSR 354 for money [1]. There is also a reference implementation [2]. So there is official support for money in Java. [1] https://jcp.org/en/jsr/detail?id=354 [2] https://javamoney.github.io/ reply owlstuffing 1 hour agorootparentWould be cool to hook this up as a manifold unit[1]. This way you could write code like: Money ask = 2.1M USD; What I don't see with the Java JSR is how exchange rate services are integrated (if at all?). In the best of worlds, as with manifold's units I could write. Money deposit = 300 USD + 500 EUR; Where internally the deposit automatically maintains the amounts separately and uses exchange rates only for spot display/calc, transfer, etc. 1. https://github.com/manifold-systems/manifold/tree/master/man... reply hathawsh 1 hour agoparentprevI have questions about some edge cases I've encountered in dealing with money. - Let's say I load two money values from a database. Value A is 1 USD and value B is 1 BTC. If I try to add them together, what happens? (I would expect a runtime exception. In fact, I would hope for a runtime exception, because the operation usually indicates a programming error.) - If I divide $2.00 by 3, do I get $0.66 or $0.67? If I want to specify the rounding rule, is there a simple way to do it? I see there's support for allocation by percentage, but sometimes the allocation rules are more complex and I need to be able to specify the rounding rule. - Does this library help parse user input? When parsing user input, what happens to extra digits? Does \"0.015\" get interpreted as $0.01 or $0.02? Edit: one more question. Sometimes people bend the rules on the number of digits; for example, gas stations may charge $3.599 per gallon. Can the library deal with that or would I have to convert to decimal, multiply, and then convert back to money? reply eriksencosta 38 minutes agorootparentThanks for the questions. Answers: 1. You get an exception 2. You may specify the rounding rule: https://github.com/eriksencosta/money/blob/trunk/docs/usage/... 3. It has some parsing capabilities. The extra digit is kept, rounding is only applied when doing an operation with the Money object 4. Same as 2 reply hiddew 5 hours agoparentprevHow does it compare to the Java money API (https://jcp.org/en/jsr/detail?id=354) and the related Kotlin DSL in https://github.com/hiddewie/money-kotlin/?tab=readme-ov-file...? reply stickfigure 4 hours agorootparentI'm surprised nobody has mentioned Joda Money yet: https://www.joda.org/joda-money/ From the same person that brought us Joda Time (ie, what the java time API was based on). I've used Joda Money a lot and it's great. Honestly I prefer APIs that look like APIs and I think this trend towards inventing DSLs is a bad one. Rails works because there's a critical mass of people who have adopted what is essentially a whole new language on top of Ruby. A money library doesn't warrant a new language, it's unnecessary cognitive load. This new money library would look fine with simple constructors and method calls. reply eriksencosta 34 minutes agorootparentJoda is impressive and has great performance. The examples were written using the infix notation but you can just use regular method calls. For example: val price = Money.of(100, \"USD\") val shipping = Money.of(5, \"USD\") val subtotal = price.plus(shipping) val discount = Percentage.of(10) val total = subtotal.decreaseBy(discount) total.allocate(2) total.allocate(60.percent(), 40.percent()) reply nogridbag 2 hours agorootparentprevI personally went with Joda money versus the Java money API mentioned above. Our needs are a bit simpler and the Joda Money API is a bit simpler to understand. Our app only deals in USD so I wrote a small utility class to help initialize Money instances so devs don't have to write: Money.of(CurrencyUnit.USD, amount) ...everywhere and do a few other things like total Money instances. reply rafaelferreira 4 hours agorootparentprevAnother library in this space is Eric Evans' (of DDD fame) Time & Money library https://timeandmoney.sourceforge.net/. reply proper_elb 59 minutes agoparentprevFirst, congrats on the library and thank you for sharing it! 1) A hint about potential prior art: F# (and/or C#?) have a first-class unit system (physical units I think), which sounds a bit similar to monetary calculations. However, physical unit are easier to model than monetary unit I think. 2) Currently, I am building something tangentially related in Rust: A backtester (test trading strategies on historical and/or simulated data) with focus on accuracy. So one thing I included already is that Assets (like etfs) are valued in a currency. If I may be so bold: How would you approach these questions / where could I read more about that? 1) When simulating, can I always assume that the exchange will work? (For assets, that is not always the case, sometimes one has to wait a bit until there is a buyer, or there might not be a buyer at all) 2) Is there public domain data in exchange rates? 3) If I have to choose, which exchange rate should I pick? The lower one, higher? What would make the most sense in the context of trading etfs, stocks, options, crypto etc.? 4) How to approach rounding, is there a best practise? 5) I assume it is best to immediately substract taxes in every transaction, even if they are formally defined annually, right? 6) Would you model inflation? I currently plan to ignore it and present it at the very end: \"Your portfolio has a final value of X.X ¥. Adjusted for inflation, that would be Y.Y ¥ today (2024-10-08).\" reply wiremine 2 hours agoparentprevNice! Reminds me of the ergonomics of Rebol's money type: https://www.rebol.com/docs/core23/rebolcore-16.html#section-... > $100 + 11 $111.00 > $10 / .50 $20.00 In general, Rebol's type system was very expressive. Would love to see more libraries like this provide that type of experience. reply eriksencosta 33 minutes agorootparentThis is great! reply getfroggie 5 hours agoparentprevIt's kind of strange that spreadsheet languages don't support money well. Using spreadsheets for escalator style automation is actually quite good and would really be amazing in a language that took typing seriously. reply ebiester 5 hours agorootparentI think there's a good reason for it to be part of a library. The problem with currencies is much like dates: they're a social construct, and change more than most of the social constructs we embed in programming languages. I don't want to update my interpreter or compiler because Turkey changed their rules of daylight savings time, or Ethereum becomes popular. reply JumpCrisscross 2 hours agorootparentOh, this reminds me of my first job out of college at a Swiss bank. Apparently every time a currency conversion was done in a particular model, there was a routine that translated back and forth between the pre-Euro currency and Euro at the conversion rate. So a USD-EUR transaction with a party in France would be run as USD-FRF --> FRF-EUR. All in COBOL. As a result, every so often, you'd get a slightly different result running a USD-EUR trade with a party in France versus e.g. Germany or the U.K. reply tomcam 1 hour agorootparentSo what happened when those discrepancies arose? reply tvaughan 24 minutes agorootparentThey became the basis for the plot of Superman III reply JumpCrisscross 34 minutes agorootparentprev> what happened when those discrepancies arose? They were just passed along. reply coreload 4 hours agorootparentprevYes, and sometimes the context is not just social but legal or contractual, e.g. rounding currency. reply ebiester 4 hours agorootparentYes, and rounding currency is just something that is always handled, as is the number of places that you take a currency out to - for example, gas is often priced at thousandths of a dollar rather than hundreds but presented to the customer in hundredths at the end. Or Yen in most cases does not have a decimal point, except that the places where you round or don't round can be consequential in large enough quantities. These are largely things that can be handled by a library, but if it's in the language you best not get it wrong because it's so much harder to change! reply benatkin 1 hour agorootparentFrom my perspective those are tenths of a cent. Stripe has integer values for cents. Am I wrong here? https://stackoverflow.com/questions/35326710/stripe-currency... reply skybrian 2 hours agorootparentprevYou could say the same of Unicode, though. Some cultural abstractions become increasingly rigid because they’re embedded in computer systems everywhere. reply carapace 3 hours agorootparentprevThis. But more than being changeable they (time and money) are supra-logical or trans-rational. In other words, computers are limited to what can be modeled or calculated with the one logical operation (it has lots of names, I like \"Quine dagger\") but these phenomenon are not. reply eriksencosta 5 hours agorootparentprevI couldn't agree more as someone who has been using more spreadsheets than actually coding in the last 10 years. reply weego 3 hours agorootparentprevSpreadsheets, browsers, databases. Everything is decided to be an 'abstraction' and it's someone else down the line that has to be concerned. Over the last 30 years of starting as a developer I've really lost faith that the majority are actually concerned with solving anything vs just indulging conceptual whims. reply chipdart 2 hours agorootparent> Spreadsheets, browsers, databases. I think you're mixing up stuff that's unrelated to your concern. The concerns you're expressing only apply to operations and financial transactions. That's not handled by spreadsheets, browsers, or databases. In fact, the primary concern of a browser is to provide views over data fed by servers. In addition, it sounds like you're confusing minor conveniences with something being somehow broken by design. The reason why no one bothered to standardize a money type is the fact that there isn't a technical requirements for it at all. reply vintagedave 1 hour agoparentprevDelphi has a currency type, as does C++Builder (so, a native Currency type available in C++ with that toolchain.) This one seems to carry units, as in, it is not a type with math for a known amount of fixed point precision that differentiates this library, but that it captures that plus the unit -- the currency, USD, EUR, etc -- that it is in. reply eriksencosta 28 minutes agorootparentYou are right. Languages indeed have support for currencies and decimal numbers. My implementation is based on Fowler's Money pattern. The Money object is thus a value object representing a monetary amount in a given currency. reply sgt 1 hour agoparentprevWhat's the best library for JS or TypeScript? reply Ygg2 5 hours agoparentprevNice library! Manipulating money is probably trickiest thing since time was invented. Library looks very usable. I have to ask though: > val transactionFee = 1.25.percent() // 1.5% How is it 1.5? reply eriksencosta 5 hours agorootparentOh sorry, that's a typo. Thanks for pointing out! reply sandGorgon 5 hours agoparentprevjust curious - what is the backend api framework that N26 uses ? is it kotlin specific ? or generically spring boot or something ? reply eriksencosta 5 hours agorootparentIn Brazil (where I worked) we used Kotlin + Ktor. In Europe, they are heavy Kotlin users. References: Brazil: https://blog.eriksen.com.br/en/platform-engineering-n26 Europe: https://medium.com/insiden26/engineering-at-n26-a-tour-of-ou... reply atemerev 5 hours agoparentprevCool! As underlying values, do you use integers, bigdecimals, or a decimalized double hack like in OpenHFT? reply eriksencosta 5 hours agorootparentIt uses BigDecimal. My first goal with the library was to provide a well-designed API. So to keep it simple for myself, I relied on BigDecimal for the calculations. reply atemerev 5 hours agorootparentI think you are right, API is the most important part; internal implementation can be optimized later. reply vamega 1 hour agorootparentprevWhat is the double hack used in OpenHFT? I tried looking this up and came up short. reply psd1 4 hours agoparentprev> no mainstream language has a first-class data type for representing money I don't think that's correct, absent some no-true-scotsman gymnastics. F# has units-of-measure (UoM) out of the box, and it supports decimal numbers. I've come across a python library for UoM as well. The big problem with handling money in code is not, IMO, the rounding (your allocate function is a nice utility but it's not core); it's unit confusion - adding baht to ren mi bi, adding cents to euros, etc. This problem is very well solved by F#'s UoM. reply __MatrixMan__ 4 hours agorootparentI don't know either well, but I took a glance at both and it doesn't seem like UoM is well set up for making decisions based on which peer is going to give you a better exchange rate. We sometimes pretend that money is measuring something, but in reality it's much messier than that. reply chipdart 2 hours agorootparent> (...) making decisions based on which peer is going to give you a better exchange rate. Neither does a money data type. reply oblio 4 hours agorootparentprevOk, what do I do in F# if I want to not think about the low level details of FX conversions, rounding, etc? Which libraries can I use? reply slekker 3 hours agorootparentprevSounds interesting! How would it look like? Do you have some code to share? reply williamcotton 2 hours agorootparentHere's something along those lines in F#: https://gist.github.com/williamcotton/b67ff641eeec7673131715... reply chipdart 2 hours agorootparentprev> I don't think that's correct, absent some no-true-scotsman gymnastics. Yeah, I think OP's claim is not valid. Even .NET provides System.Decimal, which by design and explicitly mentions financial calculations. Taken from the intro docs: https://learn.microsoft.com/en-us/dotnet/fundamentals/runtim... > The Decimal value type is appropriate for financial calculations that require large numbers of significant integral and fractional digits and no round-off errors. reply nostrademons 2 hours agorootparentThis is often not what you want with monetary calculations. You want the rounding: you'll be making a payment of $25.86, not $25.85714285714... But you just want to make sure that the next payment is $25.85, not $25.86 or $25.857142851, and that all 7 payments together equal $181 and not $181.02. reply explorigin 2 hours agorootparentI can't speak for C# but the Python Decimal type handle significant figures correctly. > The decimal module incorporates a notion of significant places so that 1.30 + 1.20 is 2.50. The trailing zero is kept to indicate significance. This is the customary presentation for monetary applications. For multiplication, the “schoolbook” approach uses all the figures in the multiplicands. For instance, 1.3 * 1.2 gives 1.56 while 1.30 * 1.20 gives 1.5600. reply eriksencosta 26 minutes agorootparentprevLanguages indeed have support for currencies and decimal numbers. My implementation is based on Fowler's Money pattern. The Money object is thus a value object representing a monetary amount in a given currency. https://martinfowler.com/eaaCatalog/money.html reply bayindirh 5 hours agoparentprev> However, no mainstream language has a first-class data type for representing money... I beg to differ. Java has \"Decimal\" class which guarantees to be safe from IEEE754 floating number side effects, and specially created to handle cases like money and financial calculations. In these days it's used as BigDecimal, it seems [1]. [0]: https://docs.oracle.com/javase/8/docs/api/java/text/DecimalF... [1]: https://docs.oracle.com/en/java/javase/23/docs/api/java.base... reply jeremyjh 4 hours agorootparentCan BigDecimal tell me which currency a monetary value is denominated in? reply bayindirh 4 hours agorootparentNo, but Java has a specification (JSR 354) to build money and currency APIs [0]. A library built upon it can be found here [1]. [0]: https://jcp.org/en/jsr/detail?id=354 [1]: https://javamoney.github.io/ reply mhluongo 4 hours agorootparentprevTell me you've never worked in fintech without telling me you've never worked in fintech :) Decimals aren't enough. You have frequent currency conversions and all sorts of other chores. Using a fixed-decimal datatype doesn't solve those problems by itself, it's just a tactic. reply bayindirh 4 hours agorootparentSee JSR-354 then: https://jcp.org/en/jsr/detail?id=354 Yes, I never worked in fintech, but lots of my family members work or worked in banking sector. So, I'm not an alien when it comes to money, and how it works and processed in IT side of the things. reply boronine 5 hours agoparentprevI think most of this is covered by a good Decimal API, currency stuff probably shouldn't be embedded into a language because it changes: currencies come and go, get redenominated etc. Although one simple thing that would be useful is keeping track of abstract units, e.g. throwing an error when attempting to do 10 USD + 10 EUR. reply oblio 4 hours agorootparentDon't we embed timezones, though? reply explorigin 2 hours agorootparentTimezone conversions don't change by the minute. Currency conversions do. reply shortrounddev2 5 hours agoparentprev> However, no mainstream language has a first-class data type for representing money This is literally the entire point of COBOL reply millerm 5 hours agorootparent\"no mainstream language...\" COBOL is has not been a mainstream language for many decades now. reply wiether 5 hours agorootparentIt's still quite mainstream in domains where they manipulate a lot of money : banking/insurance. The core systems of many old institutions still relies heavily on COBOL. reply eriksencosta 5 hours agorootparentI think I will add a footnote on COBOL. COBOL is huge in Brazil, lot of insurance/financial companies are still using mainframes. reply throw16180339 52 minutes agorootparentprevThere are billions of lines of COBOL in production. It's not going away any time soon. reply ppeetteerr 5 minutes agoprevWhat is up with that API? `1.25.percent()`? `1 money 'USD'`? Love the spirit of a money library, but this is a little odd. reply foooorsyth 1 minute agoparentEven as someone familiar with Kotlin, it's hard to decipher what this library is doing without syntax highlighting here. The author is using infix functions and custom extension functions on primitive types. Non-Kotlin-natives will scratch heads. reply occz 4 hours agoprevCool stuff! The use of infix functions reads a bit weird to me. If I were to design an API like this in Kotlin, I think I would have gone for regular extensions for many cases and perhaps extension properties, think as such: val fiveBucks = 5.usd val fiveBucks = 5.money(\"USD\") val tenPercent = 10.percent How come you went for \"increaseBy\" and \"decreaseBy\" instead of overloading `plus` and `minus`? Just curious, preference is a valid answer. reply sigh_again 3 hours agoparentNothing is preventing you from using it this way ? Infix functions are just syntactic sugar, some prefer it, some don't, but there's zero downsides to it (aside from your coworkers abusing it.) 5 money \"USD\" is literally the exact same thing as 5.money(\"USD\"), and Int.usd = this.money(\"USD\") + and - are already overloaded (see val subtotal = price + shipping), increase/decreaseBy are for operating over percentages (and could be written as subtotal * (1 - discount), which is much less clear). As the other comment say, it has an actual, real life meaning that people understand clearly. Your price increased by 10 percent. the By convention is also already present in the Kotlin stdlib, although it's more for grouping operations, numeric operations are taking the Of suffix now (sumBy has been deprecated in favor of sumOf, increaseBy could become increaseOf without any loss of clarity) reply refulgentis 3 hours agoparentprevThis does a better job of showing an uneasy feeling I have about Kotlin than anything I could say. - The infix is weird and footgun-y. - Extension methods on int/double serving as constructors smells funny. - Using infix operators as constructors but not using infix operators for addition/subtraction smells funny. In general, at least in a corporate environment switching off Java for Android, I found Kotlin a distracting step sideways. Code reviews tended to involve a lot of bikeshedding over how to make it Kotlin-y, and there's a sort of \"why not?\" approach to language features that creates much room for the bikeshedding. It left me feeling like we were unconciously choosing to have the same arguments C++ programmers had in 1990, all over again. Except it was even more destructive, because those arguments were centered, and conflated with \"proper\" coding in the fancy new language. I'm not against new and shiny: I was the first to use Kotlin in the org., and I dove right into Swift. There's something alarming with this transition. I'm heartened by starting to see some debate in Android dev communities about whether Kotlin/Compose were a bridge to nowhere that shouldn't have been a focus for years. reply zoogeny 1 hour agorootparentI hear what you are saying but there is the other side. Perhaps the opinion/feeling you are having is related to getting older. We've learned a lot about what works and what doesn't in programming languages. Goto considered harmful and all that kind of stuff. If you want to get a Lisp/Haskell fanatic really going point out how so many of the features in those languages have finally made their way into mainstream languages (lambdas, etc.). What we don't often consider are all of the language features that didn't make it. This process didn't stop sometime in the past. It is happening right now. That feeling of unease may not be an indication of the quality of the features you are considering. It may largely be uncertainty about what features will or will not stand the test of time. Perhaps as we get older, we want languages that have all of the good stuff we've learned from the past and none of the experimental stuff that we aren't too sure about yet. That might be because we are starting to notice that we won't have enough time left in our remaining days to sort all the new toys into the good/bad bin. reply refulgentis 1 hour agorootparentStirring call to action for creativity, but it is unclear how a comment that boils down to \"new things might be good\" applies in this context. as OP refers to, custom operators are considered harmful in languages ranging from C++ to Swift. It's a great contemporary example of goto. reply zoogeny 17 minutes agorootparentI suppose the more poetic: \"don't speak too soon, for the wheel's still in spin\" is another way to state it. It isn't \"new things might be good\" it is more a reminder that your self-described feeling of unease may say more about you than it does about the language feature under question. I've seen some horrors in my time due to custom operators. I've also suffered through some horrors when they are missing and would clearly be appropriate. They seem appropriate for linear algebra libraries for example. Not everyone agrees, obviously. As an aside, I have been watching a lot of YouTube videos of people programming C. I notice that goto shows up very frequently, especially in modern C. Usually it is a label at the end of a function to manage resource cleanup before returning, almost like a manual `defer`. Sometimes it is to break out of nested loops. I mean, I've always taken Dijkstra's point to be that long jumping out of a procedural boundary was the real problem, not the keyword \"goto\". And built-in language features that obviate the need to use goto even for the reasonable use cases are my preference. I feel the same about custom infix operators. I too share an unease about them. But I have to admit they feel right sometimes. I admit I don't have enough information on their use in this kind of case to know if it is one of the good ones or one of the bad ones. reply t-writescode 2 hours agorootparentprevI have used Kotlin professionally for a couple-few years; and, in my experience, infix operations are a choice and you don't have to use them. - in fact, I don't think any bit of code in anything I've used uses infix operations, this is my first time seeing them in Kotlin in the wild. For example, I haven't used them even once. That said, I, personally, have done almost no Android programming in Kotlin, so perhaps I'm missing the main environment where such things are done? For me, Kotlin has mostly been an aggressive amount of syntactic sugar to make Java a nice experience? And most of the DSL-style code that I write uses function pointers as the last parameter, so I can do doTheThing(parameters) { anonymous function } and that's about it? I'm sorry that the organization you work with has aggressive bikeshedding. Perhaps this is something your organization, in general, could have a conversation about? reply refulgentis 58 minutes agorootparentI agree, you nailed it. Operators are something that feels like using the new shiny but are repeating well-trodden mistakes that are well-understand in languages ranging in age from C++ to Swift. reply mrcrumb1 1 hour agorootparentprevYou can bikeshed in any language. Kotlin introduced a lot of optional syntactic sugar so that Java devs could choose their level of comfort with the language features. I don't really see this as a problem unless your devs are prone to this sort of bikeshedding (see: your use of \"smells funny\"). I've used kotlin for Android since right before it was officially supported and there has been almost no downside other than the occasional hiccup with Java/Kotlin nullability interop reply refulgentis 1 hour agorootparentHear hear, agree whole heartedly. Minor nit: bike shedding refers to, in the original, arguing about the color of the paint on the shed. It follows that not all discussion is bike shedding. In this instance, the references to C++ allude to a common best practice for programmers of avoiding custom operators, which goes far beyond an aesthetic, i.e. style, i.e. color of paint on the bike shed difference. There are engineering consequences. This also applies across languages, I'm familiar with it only from trodding the same path you are, through Swift. Bike shedding bike shedding is indeed possible, so I won't suggest an umabiguous definition. :) The bike shedding reference in OP is to the different flavors, but equivalent, syntactic sugar that you mention. This uses the new shiny. But this creates toxic baggage, because among other things, because to a naive implementer, there is no solid engineering reason to e.g. avoid custom operators, it's just a scarred C++ graybeard enforcing their opinion :) reply nwatson 4 hours agoparentprev`decreaseBy` is a multiplication and subtraction combined, map naturally to commerce domain, and is more complex than plain addition / subtraction. reply serial_dev 24 minutes agoprevCongrats on the library, I’ll be looking into it for some nuggets of knowledge. However, the Kotlin code looks absolutely… wrong? Strange? It just feels like a lot of magic to end up with ugly code. This is all subjective, so my question is only this: is this how Kotlin is like in 2024? reply bojanz 4 hours agoprevI like the support for custom currencies, as that is an edge case that often pops up. On the other hand, be careful about tying the symbol to the currency, as symbols are locale specific. For example, the symbol for USD is $ in eu-US but US$ in en-CA and en-AU (Canada and Australia), and then $US in French locales. https://cldr.unicode.org/ is the magical dataset behind most good implementations that deal with currency display. Updated twice a year, available in JSON, providing currency symbols and formatting rules for all locales, as well as country => currency mappings and other useful information. Disclaimer: I maintain a Go solution in this problem space: https://github.com/bojanz/currency reply eriksencosta 20 minutes agoparentI'll introduce l10n support in a future release. My starting point was to make currency names and symbols unaware of the locale as I embedded cryptocurrency data in the mix. Anyway, the library uses the CLDR dataset through ICU: https://github.com/eriksencosta/money/blob/trunk/docs/append... reply dkarl 4 hours agoparentprevI'm curious, is there a standard practice of library developers in a certain space collaborating across languages, sharing issues and corner cases and solutions? Is this a common practice with a name? Or is it up to you to look through issues and release notes on projects in the same space to glean useful information? reply samatman 4 hours agoparentprevI know this is a mere quibble as a rider on a helpful post, but a disclosure is not a disclaimer. Disclaimers separate you from the comment, examples: > Disclaimer: I am not a lawyer and this is not legal advice > [says things about $company] Disclaimer: I don't work for $company, I heard this from someone who does but I can't link to a primary source Disclosures are additional information which you think it's proper to add, to be open about your interest or stake in the topic: > Disclosure: I wrote a similar library > [replies to thing about $company] Disclosure: I used to work for $company reply ahoka 2 hours agorootparentDisclaimer is more often used for humblebrag, not to disclose any information. reply bojanz 4 hours agorootparentprevRight, indeed! reply zoogeny 1 hour agoprevWhat I want more than a library is an exhaustive test suite for all of the edge cases segmented by currency or finance authority. Tangentially, I also often think about super-strict typing. I know people mention some languages that already do this sort of thing (Units of Measure in F# was talked about). It seems silly to me that so many low level programming languages still use uint64, size_t, or char equivalents for the vast majority of the code. Why not `celsius` vs `farenheit`? Or `meters` vs `feet`. That would stop a lot of possible errors. And even more so, if the language supported things like (2 feet * 2 feet) = (4 square feet). Or (10 meters / 5 seconds = 2 m/s). reply wiseowise 1 hour agoprevInfix functions is one of the worst features of Kotlin. reply donjigweed 3 hours agoprevNice. Looks like it satisfies all the requirements detailed here [0]. Also, good discussion of the major difficulty dealing with money here [1]. [0] https://cs-syd.eu/posts/2022-08-22-how-to-deal-with-money-in... [1] https://www.reddit.com/r/java/comments/wmqv3q/standards_for_... reply Etheryte 5 hours agoprevDoes this library handle rounding rules [0]? In many countries, prices are rounded to the nearest 5 cent, but the rules can often be elaborate. It looks like the allocation interface might support this, but at the moment I didn't find any mention of it without digging into the docs themselves. [0] https://en.wikipedia.org/wiki/Cash_rounding reply graypegg 5 hours agoparentI think one common feature of those rounding procedures is that they are only done for cash payments, rather than plastic, so rather than representing a monetary value, it would have to represent a payment specifically. (With knowledge of payment method and time of transaction since a lot of these rules had a start date.) Possibly a good library to extend off of this! reply eriksencosta 5 hours agoparentprevThis is something I am aware but there is no support for this rounding scheme at the moment. reply amluto 5 hours agorootparentWait, how do you round? A fixed table from currency to minimum increment? You’re not about to find 1/100-Yen coins, for example. reply vetinari 4 hours agorootparentYou are not going to find 1 or 2 eurocents anymore either, but it is still a valid amount. You can pay that electronically, but not in cash. So rounding for cash is a different problem that rounding money in general. reply sigh_again 2 hours agorootparent>You are not going to find 1 or 2 eurocents anymore either You may want to tell that to my wallet, as well as the payments I make with them. There's a cool 37 billion coins outside in the wild, so you're going to find them rather easily throughout Europe, even if your own country has stopped using them. reply cyxxon 4 hours agorootparentprevHuh? 1 and 2 eurocents have not been deprecated, afaik only Finland and the Netherlands don't use them anymore... reply vetinari 3 hours agorootparentAlso Belgium, Ireland, Italy, Slovakia... Technically, you can use them for payment, they are still valid money; but the price will be rounded to 5 cents when paying in cash and you won't get them in the other direction. reply criddell 5 hours agorootparentprevThings like gasoline can have a price that is a fraction of a cent. The ultimate price is rounded. Canada has these guidelines: https://www.canada.ca/en/revenue-agency/programs/about-canad... reply afh1 2 hours agoprev>However, no mainstream language has a first-class data type for representing money Parcal has a Currency type. Though, I can understand not calling it mainstream... Fun fact it's a fixed point type which is just a Int64 behind the scenes, at least in Delphi. reply textlapse 3 hours agoprevKotlin has the problem of \"I had N problems, so I think I can create 1 new solution, now I have N+1 problems\" (obligatory https://xkcd.com/927/). The 'money/percent/usd' are almost like new keywords - which to me seems bad. Why not a formatter or another tool that simplifies but doesn't make it too clever or worse, hard to read. Kotlin is really cool and arguably better than Java. But the language is very hard to read ('easy' to write). And with so many different ways of doing a single thing (and many of them exist to support Java, I understand) plus new 'macro-like' things expanding the language automagically makes it very hard to grasp. I hope I am not the only one with this same feeling... reply ttymck 16 minutes agoparent> Kotlin is really cool and arguably better than Java. But the language is very hard to read ('easy' to write) I had the same immediate reaction. This style of code is something the Scala community used to be in love with, and was criticized for it. The community has largely moved away from this style, so it's interesting to see history possibly repeating itself with Kotlin. reply dakiol 1 hour agoparentprevSame feeling. It’s rather painful to read Kotlin code because of so many features that imho are not really that needed… and every developer wants to use them all. reply occz 2 hours agoparentprevI think one clear tradeoff that Kotlin - arguably intentionally - makes, is that it's harder to work with than other languages without the use of an IDE. It is after all made by an IDE developer. It's also quite a bit more liberal in introducing new features than Java is, and with a larger feature surface there's more potential for misuse. On balance, I think using Kotlin over Java is worth it, though. reply zellyn 3 hours agoprevI'm new to Kotlin. Can someone explain how this function creates a Money object incorporating the given count of them? This looks like it's ignoring the Number and creating a new Money object (of denomination 1?) > public infix fun Number.money(currency: String): Money = money(currency, defaultRoundingMode, null) reply thomascgalvin 3 hours agoparentIn Kotlin, an infix method can be called without the `.` operator, and without the parens surrounding arguments. 100 money \"USD\" is the same as 100.money(\"USD\") `Number.money(currency: String): Money` is an extension method; Kotlin provides syntactic sugar which allows you to \"add\" methods to existing classes. The above is basically equivalent to: fun money(count: Number, currency: String): Money reply zellyn 48 minutes agorootparentThanks! I allowed myself to be distracted by all the weird infix stuff. I was thinking \"but it's not passing itself into the money constructor\" but it's actually just delegating to a different-signature version of `money` _on itself_ that will use its value then. reply lolinder 3 hours agoparentprevIt'd be easier to follow if you could provide a link to the GitHub line you're looking at, but most likely the `money` function being called is a second extension method of the Number class, which means that it implicitly gets the Number object as `this` and presumably uses it to build the Money. reply zellyn 50 minutes agorootparenthttps://github.com/eriksencosta/money/blob/4bef95a1d2158e308... reply lolinder 42 minutes agorootparentYeah, that's just an infix function that provides some default parameters to this extension method: https://github.com/eriksencosta/money/blob/4bef95a1d2158e308... reply rebeccaskinner 2 hours agoprevNeat. It seems to me like this is filling three separate gaps: - fixed point arithmetic - tagging values with units - localization for parsing currency names into units I'm curious if Kotlin's type system is expressive enough to allow you to catch at compile time cases where you might be trying to, e.g. add USD to GBP. reply eriksencosta 18 minutes agoparentThe library will throw an exception if doing an operation with different currencies: https://github.com/eriksencosta/money/blob/trunk/money/src/t... But I think I'll make it explicit in the documentation. Thanks for pointing out! reply ackfoobar 1 hour agoparentprev> catch at compile time Not in this library, but I think it's possible to put the currency as a type parameter. reply DaiPlusPlus 4 hours agoprev> no mainstream language has a first-class data type for representing money Visual Basic 6 and VGA had a `Currency` type (replaced by `Decimal` in VB.NET): https://learn.microsoft.com/en-us/office/vba/language/refere... T-SQL has `money` and `smallmoney` types: https://learn.microsoft.com/en-us/sql/t-sql/data-types/money... ...am I missing something? reply DaiPlusPlus 1 hour agoparent> Visual Basic 6 and VGA *VBA, sorry; typo. HN won't let me edit my posts argh. reply sam0x17 4 hours agoparentprev> mainstream ;) reply DaiPlusPlus 4 hours agorootparentWhat could be more mainstream than VB6? reply Exerosis 4 hours agoprevMy only complaint is that there seems to be too much infix. Why not just do 50.btc, 25.3.usd This would keep it inline with the time API doing 20.seconds Also percentages could be standard library if you ask me but would probably also need to be 2.3.percent. Looks cool, always happy to see Kotlin love! reply eriksencosta 10 minutes agoparentThanks for commenting. I'm still learning Kotlin and I overlooked the usage of get() with vals. This will be the next syntactic sugar into the mix. I think it makes sense. When I was designing the API, I created methods like toUSD() and toEUR(). But with 306+ circulating/tender currencies and 2000+ cryptocurrencies, I thought it could lead to a bad experience when using code completion. reply yafetn 5 hours agoprevThe currency codes could probably be inline value classes. That way, you can do val price = 100 money USD Note the lack of quotes around USD. reply sigh_again 3 hours agoparentMaintaining an up to date currency list is, quite frankly, hell. Your code will always, always be more up to date than said list. reply 946789987649 3 hours agorootparentYou could argue the same for timezones in a date library, yet they have them. I would think a library dedicated to money will in fact be the most up to date. reply sigh_again 3 hours agorootparentDo they ? I've never once had a library that stores Europe_Paris, or Offset_Plus_7_45, they've always been stringly typed. Do you have an example of who'd be crazy enough to maintain a wrapper around tzdb? reply bradley13 4 hours agoprevLook nice. I do find the wordy operators reminiscent of Cobol. Instead of \"subtotal decreaseBy discount\" in Kotline I would expect either \"subtotal.decreaseBy(discount)\" or perhaps \"subtotal * (1 - discount)\". reply mplewis 3 hours agoprevBanks typically use a fixed floating point of 1 integer step = 1/100 cent. Is this value configurable in your library? reply pasc1878 2 hours agoparentI doubt Japanese ones do. reply jpollock 47 minutes agorootparentYes, because partial units still have meaning when dealing with interest and taxation. reply xiaodai 4 hours agoprevcool. whoever uses these libraries better validated it very well. reply Exerosis 4 hours agoprevMy complaint is, bit too much infix :( What about 50.btc 25.usd Keeps it inline with the time API as well with 20.seconds and what not. reply eriksencosta 1 minute agoparentThanks for commenting! I'm still learning Kotlin and I overlooked the usage of get() with vals. This will be the next syntactic sugar into the mix. I think it makes sense. When I was designing the API, I created methods like toUSD() and toEUR(). But with 306+ circulating/tender currencies and 2000+ cryptocurrencies, I thought it could lead to a bad experience when using code completion. reply sam0x17 4 hours agoprevThis is cool and it's great to see people adding better first-class support for currencies in as many languages as possible! I am the author of a similar crate in the rust ecosystem: https://crates.io/crates/currencies major features include: * support for all ISO-4217 currencies (though not all have been explicitly tested as it is hard to find native users of some) * compile-time macros for specifying an Amount in the native format (with symbol, etc) * support for non-base-10 number systems (there are a few ISO currencies that needed this) * every currency uses an appropriate backing data type, and new currencies and backing data types can be defined as long as they meet the trait requirements * opt-in ability to enforce only checked math ops (but using the usual +,/,-,* etc symbols). This is critically important for crypto and finance applications where a panicking math op can, for example, brick a blockchain or real-time trading system * support for parsing and printing currencies in their native format at runtime * currencies use the appropriate format style (https://github.com/sam0x17/currencies/blob/main/core/src/cur..., i.e. symbol can be \"suffix attached\", \"suffix spaced\", \"prefix attached\", \"prefix spaced\") * support for a number of cryptocurrencies, basically popular ones and ones I've bothered to add. Will always accept PRs adding others! * ability to define your own currencies using the `define_currency!` macro. Though these will not be supported by the built-in `amt!` macro unless I add them to the crate. e.g., here is how a few of the core currencies are defined: define_currency!(USD, u64, 1_00, \"$\", \"United States Dollar\", PrefixAttached, true, false); define_currency!(BTC, u64, 1_00000000, \"BTC\", \"Bitcoin\", SuffixSpaced, false, true); define_currency!(ETH, U256, u64_to_u256(1_000000000000000000), \"ETH\", \"Ethereum\", SuffixSpaced, false, true); One disadvantage right now is there is no ability to have a generic \"amount of some arbitrary currency\" other than through generics, as the underlying traits aren't object-safe. A good way to work around this is to define an enum that contains all the currencies you plan to support. I am working on a feature that will let you easily generate this enum at compile-time :) parsing is done using my Quoth parsing crate which provides a very safe, lexer-less way to do parsing of UTF-8 strings that relies on recursive parsing in a way somewhat similar to syn, but there are no token streams https://crates.io/crates/quoth reply eriksencosta 2 minutes agoparentGreat reference, Sam. I will definitely bookmark your library and learn with your implementation. For cryptocurrency data, take a look at the DTIF.org dataset: https://github.com/eriksencosta/money/blob/trunk/docs/append... reply systems 5 hours agoprevwhat type of language is kotlin? Is it functional , OOP or something else, which paradigm does it represent? reply lolinder 5 hours agoparentIt's all of the above. Most modern languages (including everything from Java to OCaml) don't fit neatly in any one box because they have added a bunch of features from other paradigms that make multi-paradigm programming possible. Kotlin is that way to an extreme, because instead of strapping on functional features to an OOP core like Java did it was designed out of the gate to be all of the above. When I program in Kotlin I'm constantly shifting between \"paradigms\" based on what is actually needed in the moment. It's one of the best languages I've ever worked with for learning the strengths and weaknesses of different programming styles because it has such strong support for most of them. reply moritzruth 5 hours agoparentprevKotlin was originally designed for running on the JVM, so it is generally object-oriented, but the language and the standard library allow for and encourage a functional coding style. Kotlin is well-suited for DSLs, especially declarative ones (see kotlinx.html[0]). [0] https://github.com/Kotlin/kotlinx.html reply lolinder 4 hours agorootparentThis understates how functional Kotlin is—you wouldn't say that Scala is generally OOP with some functional support just because it was built on the JVM. Scala's clearly a functional language with some OOP support. Kotlin, in turn, is very balanced. The standard collection library uses OOP syntax (chains of method calls), but is extremely functional in its philosophy towards how we think about manipulating collections. reply ragnese 25 minutes agorootparentI think a comparison to Scala is apt. Working with both languages makes it quite clear to me that Scala is most certainly much more functional than Kotlin. Kotlin is really not very functional in practice, in that it really doesn't encourage a functional style, nor is it optimized for the patterns that are common in functional programming. Scala has `Try` and `Either` for modeling domain failures as values as opposed to throwing (unchecked) exceptions, which are side-effecting. Scala also has for-comprehension syntax built in to make it more convenient to compose and chain fallible operations that use `Try`, `Either, `Option`, etc. Kotlin's `Result` type is not designed for modeling fallible operations (not a sealed class, no type parameter on the error variant, error must be `Throwable`, etc), and Kotlin does not offer convenient syntax like for-comprehensions despite being more than able to (given that many of us have implemented near-perfect analogues to Scala's `Try` and for-comprehension syntax in Kotlin). Similarly, no official Kotlin libraries or APIs ever return errors as values and always opt for throwing exceptions instead. Scala's collection types are implemented as persistent collections, which are optimized for cheap updates. If you want to avoid direct mutation in Kotlin, you have to make a full copy of a collection. Scala's mutable and immutable collection types are actually distinct from each other and cannot be used interchangeably. In Kotlin, List is a supertype of MutableList, which means I can pass a MutableList into a function that expects a List. That means that the list can be changed in another thread while my function is running, so I can't even assume that checking `list.size` at two different points in my function will return the same value. Scala has actual type classes. Kotlin has extension functions which are not nearly as useful (and they have very surprising semantics when it comes to static vs dynamic dispatch). Type classes are certainly not required for functional programming with a statically typed language, but it definitely helps when it comes to modeling things without needing to lean on writing more classes and/or utilizing inheritance. Also, Kotlin's \"functional\" APIs on collections are much more janky than Scala's. For example, if I have a `Set` and I call `.map((T) -> R)` on it, Kotlin will give me a `List` while Scala will give me a `Set`, which makes way more sense. Kotlin is cool, and it would be dishonest for me to say that it's not at all functional, but after having worked in other many other languages, I'm very comfortable saying that Kotlin is an OOP/imperative language first with some functional stuff added in (sealed classes, convenient lambda syntax, top-level functions, and some of the typical collection combinator APIs). Whereas Scala is quite clearly designed to be actually GOOD for functional programming without taking an extra-hard performance hit. reply umanwizard 2 hours agorootparentprevThe JVM doesn't necessarily imply object-orientation. Clojure (a JVM language) is not really object-oriented at all; I'm not an expert but I think the only time objects are used in idiomatic Clojure is when doing interop with Java libraries. reply graypegg 4 hours agorootparentprevHuh, I've never actually looked too hard at Kotlin. That is a lot more syntactically flexible than I thought it was! That HTML builder reminds me of Ruby DSLs a lot. reply dtech 4 hours agorootparentIt's not really syntactically flexible, but made explicit syntax for the use cases other languages used flexibility for, like DSL-builders and extension methods. This avoid the problem that you have in more flexible languages where everyone does a pattern in a slightly different way. reply ragnese 5 hours agoparentprevIt's much more \"multi-paradigm\" or \"unopinionated\" than Java, but since it is a pretty thin layer over Java and uses its standard library, the ecosystem and idioms are still very much OOP by convention. But, I see the language itself as more akin to C++ in that it really doesn't strongly push much in one direction or another, but they also both lack built-in tools or optimizations for doing real functional programming. So, I'd say that Kotlin, like C++, is an unopinionated language that does well for OOP and/or imperative styles. reply beeforpork 5 hours agoparentprevLike Java, but nicer. Used for Android app devel. Me, I would not call it multi-paradigm, because it really feels primarily like Java (though with many niceties), i.e., it is single dispatch ('this'), objects and classes everywhere. It is completely compatible with Java, and you can mix the languages freely (this is done in Android). It does have standalone functions. reply eriksencosta 5 hours agoparentprevKotlin is a multi-paradigm language with OOP and FP support. reply speed_spread 3 hours agoparentprevAs a Java replacement, it's still mainly an OOP paradigm with some functional bits added. The type system is mostly unchanged from Java. Kotlin's null safety is interesting, but JVM null pointers are nowhere near the problem they are in C. Otherwise its value proposition mostly relies on overcoming perceived constraints from Java syntax, allowing to redefine parts of the language to build DSLs. Whether this is a good idea is disputable; ask any maintainer of large projects where those capabilities were used in full, or just look at the continuing train wreck that is Gradle. reply g-b-r 4 hours agoparentprevA mess, in my limited experience, so far reply slt2021 2 hours agoprevI dont understand the need for this. I always has used integer data type and counted cents. Why need this? reply eriksencosta 8 minutes agoparentYou don't need if your solution fits your use case. The library is an implementation of Fowler's Money pattern: https://martinfowler.com/eaaCatalog/money.html reply proper_elb 51 minutes agoparentprevMore precision and/or more safety. Will depend on the domain/audience/... the software is being written for. reply dlahoda 5 hours agoprev [–] crypto needs support for decimals, determinism, rounding directions, uplifting to higher dimensions during long term accrual, down lifting fosome kind of quantization, path dependance. eth is whole number 10*18. usdc is 10*6. usd is if to speak is 10*2 number. solana eth price is less than eth eth price because of bridge risk. etc. there are on decimal money to out of crypto. there are logarithmic money in crypto. so many many moneys. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Kotlin Money is a new library designed for precise monetary calculations and allocations, addressing common issues like rounding errors in financial operations.",
      "The library supports a wide range of currencies, including 306 traditional currencies and 2283 cryptocurrencies, and is set to expand for Android development and serialization.",
      "It ensures accurate distribution of amounts, preventing financial discrepancies such as losses or overcharges, and supports various mathematical and percentage operations."
    ],
    "commentSummary": [
      "Kotlin Money is a library created to simplify monetary calculations in the Kotlin programming language, addressing common issues such as rounding in financial operations.",
      "The library is inspired by challenges encountered at N26 Brasil and supports currency conversions and rounding rules, similar to Java's JSR 354 and other money libraries.",
      "It utilizes BigDecimal for precise calculations and offers a user-friendly API, emphasizing the importance of accurate monetary handling in programming."
    ],
    "points": 256,
    "commentCount": 150,
    "retryCount": 0,
    "time": 1728392392
  },
  {
    "id": 41772624,
    "title": "An illustrated proof of the CAP theorem (2018)",
    "originLink": "https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/",
    "originBody": "Blog An Illustrated Proof of the CAP Theorem The CAP Theorem is a fundamental theorem in distributed systems that states any distributed system can have at most two of the following three properties. Consistency Availability Partition tolerance This guide will summarize Gilbert and Lynch's specification and proof of the CAP Theorem with pictures! What is the CAP Theorem? The CAP theorem states that a distributed system cannot simultaneously be consistent, available, and partition tolerant. Sounds simple enough, but what does it mean to be consistent? available? partition tolerant? Heck, what exactly do you even mean by a distributed system? In this section, we'll introduce a simple distributed system and explain what it means for that system to be available, consistent, and partition tolerant. For a formal description of the system and the three properties, please refer to Gilbert and Lynch's paper. A Distributed System Let's consider a very simple distributed system. Our system is composed of two servers, $G_1$ and $G_2$. Both of these servers are keeping track of the same variable, $v$, whose value is initially $v_0$. $G_1$ and $G_2$ can communicate with each other and can also communicate with external clients. Here's what our system looks like. A client can request to write and read from any server. When a server receives a request, it performs any computations it wants and then responds to the client. For example, here is what a write looks like. And here is what a read looks like. Now that we've gotten our system established, let's go over what it means for the system to be consistent, available, and partition tolerant. Consistency Here's how Gilbert and Lynch describe consistency. any read operation that begins after a write operation completes must return that value, or the result of a later write operation In a consistent system, once a client writes a value to any server and gets a response, it expects to get that value (or a fresher value) back from any server it reads from. Here is an example of an inconsistent system. Our client writes $v_1$ to $G_1$ and $G_1$ acknowledges, but when it reads from $G_2$, it gets stale data: $v_0$. On the other hand, here is an example of a consistent system. In this system, $G_1$ replicates its value to $G_2$ before sending an acknowledgement to the client. Thus, when the client reads from $G_2$, it gets the most up to date value of $v$: $v_1$. Availability Here's how Gilbert and Lynch describe availability. every request received by a non-failing node in the system must result in a response In an available system, if our client sends a request to a server and the server has not crashed, then the server must eventually respond to the client. The server is not allowed to ignore the client's requests. Partition Tolerance Here's how Gilbert and Lynch describe partitions. the network will be allowed to lose arbitrarily many messages sent from one node to another This means that any messages $G_1$ and $G_2$ send to one another can be dropped. If all the messages were being dropped, then our system would look like this. Our system has to be able to function correctly despite arbitrary network partitions in order to be partition tolerant. The Proof Now that we've acquainted ourselves with the notion of consistency, availability, and partition tolerance, we can prove that a system cannot simultaneously have all three. Assume for contradiction that there does exist a system that is consistent, available, and partition tolerant. The first thing we do is partition our system. It looks like this. Next, we have our client request that $v_1$ be written to $G_1$. Since our system is available, $G_1$ must respond. Since the network is partitioned, however, $G_1$ cannot replicate its data to $G_2$. Gilbert and Lynch call this phase of execution $\\alpha_1$. Next, we have our client issue a read request to $G_2$. Again, since our system is available, $G_2$ must respond. And since the network is partitioned, $G_2$ cannot update its value from $G_1$. It returns $v_0$. Gilbert and Lynch call this phase of execution $\\alpha_2$. $G_2$ returns $v_0$ to our client after the client had already written $v_1$ to $G_1$. This is inconsistent. We assumed a consistent, available, partition tolerant system existed, but we just showed that there exists an execution for any such system in which the system acts inconsistently. Thus, no such system exists.",
    "commentLink": "https://news.ycombinator.com/item?id=41772624",
    "commentBody": "An illustrated proof of the CAP theorem (2018) (mwhittaker.github.io)239 points by tripdout 18 hours agohidepastfavorite78 comments refibrillator 15 hours agoCAP theorem is great, though it does omit latency. Which leads you to the logical extension, PACELC [1]: If there is a network Partition you must choose Availability or Consistency, Else the tradeoff is Latency vs Consistency. This offers practical intuition for certain design choices. For example Google Spanner [2] is a distributed DB that offers globally consistent reads/writes, but to achieve high performance (low latency) nodes must synchronize with multiple extremely accurate reference clocks (GPS & atomic) and follow a complex two phase commit protocol that ensures transactional linearizability using lower bounds and uncertainty of timestamps. As another example, your multicore CPU leverages a cache coherency protocol that faces remarkably similar tradeoffs. Perhaps others have made this connection before…it does feel like some sort of universal law of physics. [1] https://en.m.wikipedia.org/wiki/PACELC_theorem [2] https://static.googleusercontent.com/media/research.google.c... reply danielheath 13 hours agoparentIs a Partition meaningfully distinguishable from especially high Latency? reply refibrillator 4 hours agorootparentIn theory no, a network partition is indistinguishable from infinite latency. Though in common use I think “latency” tends to imply a response and measurable timing. reply shepherdjerred 14 hours agoparentprevCAP doesn't omit latency. Availability essentially is latency. PACELC only says that even during normal operation you still need to make tradeoff between availability and latency whereas CAP only deals with a tradeoff during a partition event. reply tux3 8 hours agorootparentThe A in CAP doesn't mean what people think it means, it has nothing to do with nodes being up, or crashes, or latency, or SLA, or any abnormal dysfunction. Availability in CAP is purely a software decision, it's an algorithmic property. Roughly speaking, it is the decision to continue accepting requests during a partition, possibly sacrificing Consistency. If your refuse requests during a partition, you conserve Consistency, and you lose Availability. If you keep accepting requests during a partition, it's the opposite. High latency is considered a partition in CAP. Any hardware error, any network trouble, any bug, crash, any unreachable machines is never an Availability issue. reply shepherdjerred 5 hours agorootparent> If your refuse requests during a partition, you conserve Consistency, and you lose Availability. If you keep accepting requests during a partition, it's the opposite. I agree > High latency is considered a partition in CAP. Can you support this claim? I don't think this is true unless you're specifically talking about high latency between nodes rather than latency between the sender and the system. reply tux3 4 hours agorootparent>high latency between nodes rather than latency between the sender and the system Yes, that's what I meant. To clarify, latency between the sender and the system would still not be an availability issue, but it also wouldn't be a partition. It's just out of scope of the CAP theorem. The user might be on a bad mobile connection, but it doesn't impact the distributed system itself. reply rtpg 14 hours agorootparentprevAvailability's definition: > every request received by a non-failing node in the system must result in a response I don't believe that encodes latency Instead, here's consistency: > any read operation that begins after a write operation completes must return that value, or the result of a later write operation \"after a write operation completes\" feels like where latency kicks in? Because within that space you can play around with completing a write operation to get what you want. reply shepherdjerred 14 hours agorootparentIt's impossible to distinguish between high latency and unavailability. You can model unavailability as infinite latency. In a real system you can wait for a partition event to resolve itself before replying which preserves consistency at the cost of latency (availability). reply nextaccountic 14 hours agorootparent> In a real system you can wait for a partition event to resolve itself before replying which preserves consistency at the cost of latency (availability). This is true, but PACELC states that even if there is no partition you still have a consistency vs latency tradeoff (because the processes that guarantee consistency eat up latency in form of network roundtrips) reply shepherdjerred 14 hours agorootparent100%, I don't think what we're saying conflicts. There is _always_ a tradeoff between consistency and availability whether you're thinking of PAC or PACELC. PACELC just makes it explicit that this tradeoff exists whether you're partitioned or not. reply Retr0id 6 hours agoparentprevI'm sure I'm far from the first, but I've also made that connection before. I think I phrased it \"modern CPUs are just very small distributed systems\" reply ojkelly 5 hours agoparentprev> Perhaps others have made this connection before…it does feel like some sort of universal law of physics. This has been on my mind too, and I can’t help but think the fundamental concept underpinning it all is causality. Reading about “consistency as logical monotonicity” — CALM [0], after diving into Spanner, there’s definitely something to databases beyond CAP. I’m yet to find a simple and clear law or theorem that captures what you’re hinting to, but it feels like we must be getting close. This has been bouncing around my head for a few years since I first wrote a toy CRDT DB. It seems to show up anywhere we have more than one system with independent memory (a place where state can be held), needs to maintain a shared representation or fact about something. Within one memory (akin to a reference frame in quantum physics), we can do anything we want. We can mutate state without any interaction or interference from the outside world. This also sounds like a pure function. By itself, this is academic, theoretical—it does not, it does not exist. If a tree falls in the woods. So if we want to interact with any other systems, we then need to coordinate, and the question is how. The issue and pattern seems to rhyme everywhere. CPUs, HDD, SSD, file systems, networks, UIs, people, teams, etc. The best possible collaboration seems to be that which requires the least coordination. Money is a good example here, someone can string together a series of products from companies who know nothing about each other, by coordinating with money - as a means of exchange. Not to mention being able to buy complex technology with no idea the supply chain behind it. I don’t have to coordinate with a mine to use a computer, which contains something from said mine. It sort of looks like distributed databases build a virtual memory on top of many smaller memories, which need to share some parts with each other to protect the system as a whole. New information may need a few writes before it can be considered a new fact. I think this is an implementation detail, in that it’s irrelevant to the observer (who has no control over it). This isn’t eventual consistency, which is perhaps the cruder form of this where the implementation detail above is wide open for all to see. Instead new information is available immediately, just your definition of immediately is different to the databases. It follows then, that as an observer of the system you cannot violate causality in any way by learning information from the future, while they are still in the past. My understanding from Spanner is that when you ask for a read, you provide or are issued a timestamp which provides the causal information to determine what you are allowed to know. The system can then maintain both a true and correct representation of what it knows, and an incomplete working memory of what it is trying to know next (the writes which need to be committed into multiple memories). Memory being anything from ram, ssd, carrier pigeon, lines in sand, etc. I think where this breaks most of our brains is that it’s a universe simulation. And both time and causality are fundamental invariants of the stability of the system, but are leaky abstractions that we need to deal with. In CALM this is abstracted into what is effectively entropy. If your program never moves backward in time/loses entropy it’s CALM (I think). In earlier works I think Lamport and vector clocks were used, in Spanner it’s based on very precise measurements of our own time, where the maximum speed of information (ie speed of light) is the greater of the smallest unit of time we can measure (the precision of the GPS clock) and the time it takes for new data to become available in the system. The other part where this differs from the read world is that the speed of information, the latency of a request, is different for reads and writes. Not true in the quantum world where an everything is a wrote (I think). Then, consider that in our own reference frame we can do a huge amount of work while waiting for a db read/write, something that would violate the speed of light if not in our virtualised world. We cannot break causality in the world we live and breathe in, but we do it all the time in our simulated ones. [0] https://arxiv.org/abs/1901.01930 reply kstrauser 4 hours agorootparentIt “feels” to me like the uncertainty principle. Think of availability as an interval of time by which all nodes have to be connected. If you set A high enough, sure, you can have both CP to your heart’s delight. As A shrinks, you lose the ability to have both C and P and have to pick one. It’s something like CxP/A>n, where n is a constant within a system. reply mrfox321 6 hours agoparentprevsimultaneity is relative. That's all. reply stevebmark 14 hours agoprevI prefer the walkthrough of the CAP theorem in “Designing Data Intensive Applications,” which says that the CAP “theorem” is an undefined and generally unhelpful concept in distributed systems. “Available” has no formal definition. And it’s confusing that it’s three letters, because it’s not “choose two”. It’s not that a system is “partition tolerant,” it’s if there’s a network partition, you choose availability or consistency. And obviously you choose availability for the distributed systems you most commonly encounter. reply er4hn 29 minutes agoparentAvailability is similarly poorly defined for CVSS scoring, i.e. what gets used to decide how bad a CVE is. reply yas_hmaheshwari 10 hours agoparentprevI also like the fact that how he says that that theorem was a good theorem for the time but is now not that relevant Maybe PACELC is better theorem, maybe not - but I guess three letter acronyms would always rule better than a six letter one reply sethammons 6 hours agorootparentEsp since CAP is easily pronounced. \"PACELC\"? Is it \"Pace-elk\"? \"Pak-Elk\"? \"Pacel-C\"? reply chuckadams 2 hours agorootparentI think you got it with the third one. Picture an elk wearing saddle bags. A Pack Elk. reply dijit 6 hours agoparentprev> And obviously you choose availability for the distributed systems you most commonly encounter. fail safe (rather than fail open) is generally regarded as the most acceptable thing we can do as CRUD programmers; that’s true, however it’s categorically untrue that this is a foregone conclusion. There are many cases (especially in financial services) were failing safe is a much preferable option and having retry logic in application is much preferred reply stevebmark 1 hour agorootparentIn distributed banking back-ends, if one of your datacenters goes down, you don't take down the other one for safety. You don't force global consistency/linearity of all transactions before allowing UI updates. There are delays in financial reconciliation all the time, the important thing is they are eventually consistent with a ledger, not that if one thing fails, you stop the train. And the reality of distributed systems is things fail constantly. Hard drives, networks, bugs, clock drift... This is in contrast to something like a supercomputer, or a distributed map-reduce job, where if one node fails as part of a distributed process, it will corrupt your data, and you have the luxury to stop the whole thing, fix the issue, and restart the whole process. reply tajd 6 hours agoparentprevFor the interested reader you can see a paper talking about this by Martin Kleppmann https://arxiv.org/abs/1509.05393 - the author of DDIA. reply jeremyjh 5 hours agoparentprevThe formal definition for Available is given in TFA. reply stevebmark 1 hour agorootparent\"No formal definition\" includes where we are today, not the original, outdated idea. By the original (not useful) definition, an \"available\" distributed system can return a response 10 years later, which is not helpful nor relevant when thinking about distributed systems. reply puzzledobserver 11 hours agoprevOne thing that I've always wondered about: Is the CAP theorem really making a non-trivial claim? If a distributed system is consistent and available, it must return the last written value, and successfully do this all the time. How can it do this if the system is partitioned, and the node receiving the last write was unable to propagate this to other nodes? The proof described in this website appears to confirm this. Am I missing something? reply wesselbindt 9 hours agoparentYou're not missing something. In the original paper the proof is half a page long (and still worth a read, very low investment, decent payoff). I think the value of the CAP theorem is not so much in its statement (CP or AP, choose one), but rather in its proof. It helps you cook up similar arguments/reasonings for more interesting situations and constraints. reply dijit 5 hours agorootparentI think it’s also very interesting to point out that very often people try to choose all three but end up choosing only one inadvertently. We should also point out that it’s not a foregone conclusion that you will even be able to achieve two of three. CAP theorem really is a best case scenario. reply colmmacc 3 hours agoparentprevLong before the CAP theorem paper I remember learning the same thing in the context of routing protocols like BGP and it being an \"aha moment\". It really helped me understand that there is no single version of the state of distributed systems and that it is all local and a matter of perspective under a partition. When the paper came out I remember thinking how trivial and obvious the conclusion was, and it confused me that it was getting attention ... but in retrospect the reformulation and acronym helped bring understanding to a far broader audience, especially software people. That's really good impact and effectiveness and I wish more academic papers were focused on this. reply kentosi-dw 2 hours agoprevI was a little surprised that they author went though such detail to explain Consistency, and yet Availability was just 2 sentences and a quote... reply vzaliva 15 hours agoprevThe text left me wanting a more formal treatment of the theorem. I went ahead and found a paper which does just that: https://dl.acm.org/doi/10.1145/564585.564601 PDF: https://users.ece.cmu.edu/~adrian/731-sp04/readings/GL-cap.p... reply fithisux 12 hours agoparentI was always wondering the same. Thank you for the references. Above I asked for a mechanized proof. reply jascha_eng 16 hours agoprevThis is trivial but the problem is that especially consistency is not a binary choice. Heck even non distributed systems can give you varying consistency guarantees it's the whole point of isolation levels of most RDBMS. It's good to visualize that there is a trade off to be made. However that trade off does not have to be binary. You can get a bit more consistency for a little less partition tolerance or availability. All of Designing data intensive applications is about those trade offs. reply dilyevsky 13 hours agoparentConsistency in CAP and Consistency in ACID have entirely separate meanings. reply gpderetta 10 hours agorootparentThe C in ACID has a different definition of Consistency, yet the combination of guarantees given by ACID should also imply Consistency in the distributed system sense, right? I.e. a distributed database that claims to be ACID cannot sacrifice consistency [edit: at least for some isolation levels]. reply anonymousDan 9 hours agorootparentIsolation (the I in ACID) is more closely related to the notion of consistency in the distributed system community. reply anonymousDan 9 hours agoparentprevConsistency in the case of CAP refers to linearizability. reply magnio 15 hours agoprevThe \"proof\" is kind of weird. We assume there exists a system that has all three of CAP, but how can we assume that system has the layout in the post with two servers and one client? reply sushibowl 14 hours agoparentThe proof is not really formal, but you could view the shown system as a minimal subset of an arbitrarily shaped large system. For the system to be distributed it must have at least two nodes, and to be available all nodes must respond to requests. So however the rest of the system is shaped, the proof still holds. reply dmurray 10 hours agorootparentThe minimal subset is too small. It should have a second client, to avoid solutions like \"the client stores a copy of all the messages it sent, so it can detect the stale value\". reply jeremyjh 5 hours agorootparentThe theory has nothing to do with what the client knows. It’s only concerned with the server’s responses. reply evertedsphere 11 hours agorootparentprevwhat if the graph remains connected when you remove that link, so the two nodes can communicate through other nodes? reply dmurray 11 hours agorootparentPartitioning is defined so that all, or at least arbitrarily many, of the communication links may be down. In practice you're absolutely right and one approach to distributed systems is to make partition tolerance less important by having lots of redundant links instead. reply whatshisface 17 hours agoprevHow about this: 1. A read is returned with a map of the network the replying node has become consistent with. 2. A client that is not satisfied with the map can read again from the other partition. These two steps get around the proof by changing one of its assumptions (that the operation to read a value can only involve a request to one node). reply anderskaseorg 16 hours agoparentYou’re certainly allowed to make the client a more active participant in your consensus protocol, but then it needs to play by the same rules if you want the system to have guarantees. For example, you need to handle network partitions between clients and some servers, and you need to be able to reconcile multiple reads from servers that might have seen different sets of writes. The CAP theorem still applies to the system as a whole. reply Dylan16807 15 hours agoparentprevDo you have a plan for doing writes in that scenario? It's not proper availability without writes. If the partitions are configured for consistency, and they can't hear from each other, then at most one will accept writes. If the client relays metadata between the partitions to make the write happen in both, then you don't actually have a partition anymore. Also in practical terms, the nodes almost always have better contact with each other than the client has to the nodes. The situation where the client can connect to both sides of a partition is unlikely enough that if you add code for it you're probably getting negative value. It wastes time and can add scary bugs. reply fallingsquirrel 17 hours agoparentprevConsider the following sequence* of events: 1. client A reads from partition X 2. client A is unsatisfied with the network map, and requests another read from partition Y 3. (meanwhile) client B writes a value to partition X 4. client A reads from partition Y, sees the value is the same as partition X's (stale) value, and accepts the value as consistent This is the same kind of behavior you might get if your servers used e.g. a buggy version of Raft or something. You can't get around the proof by just relabeling some of your server nodes as client nodes. * In the spirit of distributed systems, I use this term loosely :) reply Dylan16807 16 hours agorootparentThe value is now stale, but it was correct at some point between the read starting and the read finishing, right? That can happen with any read. Even without any partitions. Can't it? In that case I don't see the problem. reply lmm 16 hours agorootparent> The value is now stale, but it was correct at some point between the read starting and the read finishing, right? Not necessarily. Maybe both versions of it were from partial writes that were never committed, so your invariants are violated (if we're talking about e.g. a credit account A and debit account B scenario). > That can happen with any read. Even without any partitions. Can't it? Depends on your isolation level. If your system has serializable transactions then it's supposed to give you a history equivalent to one where all transactions were executed serially, for example. reply Dylan16807 15 hours agorootparent> Not necessarily. Maybe both versions of it were from partial writes that were never committed, so your invariants are violated (if we're talking about e.g. a credit account A and debit account B scenario). I'm pretty sure the scenario above is looking at committed writes. If you're reading uncommitted writes, you're not really in the market for consistency to being with. (Or you could be handling consistency by waiting to see if the transaction succeeds or fails, making sure it would fail if the data you read got backed out. But in that situation nothing goes wrong here.) > Depends on your isolation level. If your system has serializable transactions then it's supposed to give you a history equivalent to one where all transactions were executed serially, for example. Even then, a new write can happen before your \"read finished\" packet arrives at the client, making the read stale. Your entire transaction is now doomed to fail, but you won't know until you try to start committing it. For pure read operations, I'm not convinced it's a proper stale read unless the value was stale before the read operation started. reply lmm 14 hours agorootparent> I'm pretty sure the scenario above is looking at committed writes. > If you're reading uncommitted writes, you're not really in the market for consistency to being with. But what does \"committed\" mean when you're only reading from one partition in a partitioned scenario? You literally can't tell whether what you're reading is committed or not (or rather, you have to build your own protocol for when a write is considered committed). > For pure read operations, I'm not convinced it's a proper stale read unless the value was stale before the read operation started. I think you can get a read that is half from a prior stale operation and half from a subsequent uncommitted operation, or something on those lines. reply Dylan16807 12 hours agorootparent> But what does \"committed\" mean when you're only reading from one partition in a partitioned scenario? I would say you can't make new commits in that situation? I don't know, I didn't make up the scenario, I think you need to figure out your own answer and/or get clarification from fallingsquirrel if you want to talk about that kind of problem. > I think you can get a read that is half from a prior stale operation and half from a subsequent uncommitted operation, or something on those lines. What's the full timeline for that? If you're specifically talking about the ABA problem, that's trivial to fix with a generation counter. reply lmm 4 hours agorootparent> I think you need to figure out your own answer and/or get clarification from fallingsquirrel if you want to talk about that kind of problem. Right. The point is that fallingsquirrel hasn't solved the hard part of the problem. > If you're specifically talking about the ABA problem, that's trivial to fix with a generation counter. Maybe, but you need to specify that that's what you're doing, and it may come with undesirable consequences. reply Dylan16807 1 hour agorootparent> The point is that fallingsquirrel hasn't solved the hard part of the problem. Sure. My point is that I don't see any issue with the read they described, not that I think there is a solution to partitioning here. reply satisfice 17 hours agoparentprevHow can it know what it is consistent with? Anything could have happened since the last update. All it knows is that it most recently got an update at a certain time. It may or may not be consistent. reply dmitry-vsl 16 hours agoprevSo, it's impossible to transfer a value from one machine to another if there's no network connection between them? How did this extremely trivial observation become a well-known theorem? reply crdrost 13 hours agoparentSo, when it was originally phrased, the primary thing that you would have learned about databases, was that they enable ACID transactions. (And if you were a practitioner you would have learned about the various isolation levels and dirty reads and dirty writes.) But if you wanted to go from this level to implementation, typically you could get a prototype working, but it would be slow. When things are slow, the WD-40 of the programming world is to add a cache. And this is where you get the quip that there are only two hard problems in computing, cache invalidation and naming things. (The “and off-by-one errors” is a later addition.) The problem is that cache invalidation shows up as consistency bugs in your database. Someone does a rare combination of commits and rollbacks and some cache doesn't get wiped quite as fast as it needs to, or is wiped overoptimistically causing a pull from uncommitted data, and your isolation level has dropped to READ UNCOMMITTED. The CAP theorem was originally raised as a conjecture, something like, “once you shard the database, I don't think there's any way to solve these cache problems without one of the replicas just going silent for arbitrarily long pauses while it tries to at least partially synchronize its cache with the other shards.” Phrased that way, you can understand why it was a conjecture, it relies on nobody at MIT having a super clever way to deal with caches and cleverly routing the synchronization around the sharding. BUT, you can make that statement for many different reasons, and this was not for Pedagogical Reasons, its point was rather Evangelism! The author was attempting to introduce the idea of Eventual Consistency, and gain adoption by ditching all of the wisdom about ACID transactions. This antagonism was deliberate, eventual consistency became the E in a rival acronym BASE. And so the argument was that we could explore a new corner of design-space. It was later that someone decided they could prove it by coming up with a universal subgraph, “whatever connection you've got, it has to contain this: two nodes, fighting over one value, with a network connection possibly passing through other nodes but we can abstract all that away.” And then you have a proof, and then you have a bunch of people comparing the proof to the stated claims of various database vendors, and finding that over and over they claim to be both shardable with high availability among the shards, and to support ACID transactions that keep everything consistent. It turns out those statements are usually made assuming a happy path! (You also get Paxos and Raft, “here is how to get consistency without arbitrary latency on two-phase commit via majority vote”, and the Jepsen blog “you said this had consistency level X, let’s fuzz it and see if we can generate a counterexample”, and some interesting exceptions like Datomic saying “this one part is not scalable and it's a single point of failure to sacrifice P for the CAP theorem’s sake, but in exchange we can simplify our C and A guarantees so that you can scale the reads of the system consistently.”) reply lmm 16 hours agoparentprevBecause, sadly, a lot of system designers want to believe they have a way around it. reply dang 15 hours agoprevRelated: An Illustrated Proof of the CAP Theorem - https://news.ycombinator.com/item?id=17528817 - July 2018 (71 comments) reply ljsprague 17 hours agoprevIs availability sacrificed more often than the other two? reply shepherdjerred 14 hours agoparentIt depends purely on the application you're writing. Many applications prefer availability over consistency, but the application is built to cope with inconsistent data. reply anonymousDan 9 hours agoparentprevThe only way to sacrifice P is to have have a single node (i.e. non-replicated) system. So in practice it's a choice between C and P. reply wmf 17 hours agoparentprevProperties are only sacrificed during partitions. Due to Murphy's Law, if you assume partitions never happen they will happen more often but if you can tolerate partitions they happen really rarely. reply anderskaseorg 16 hours agorootparentThere are plenty of systems that sacrifice consistency even while the network is fully connected, in the name of performance—for example, DNS, or any system with a caching proxy server. reply wmf 16 hours agorootparentYeah, CAP is about the best possible behavior a system can have but you can always do worse. reply shepherdjerred 14 hours agorootparentprevThat is not true with PACELC https://en.wikipedia.org/wiki/PACELC_theorem reply shepherdjerred 18 minutes agorootparentTo clarify I’m not saying PACELC invalidates PAC, just that it expands to consider the case where there isn’t a partition. reply Groxx 16 hours agoparentprevNot really. Both are all over because they address vastly different (literally incompatible) needs. There is a fair bit of industry hype in the past decade or so around eventually consistent systems, because a lot of components of a business can use them, and that opens up a lot of extremely desirable performance options that can be fine tuned to the moon. But they're a real nightmare to use (i.e. often literally impossible) for anything that needs to be correct, so they are often just used in addition to the more classical consistency-oriented databases like postgres. reply mrybczyn 17 hours agoprevThank you! That makes a lot more sense than several other descriptions of the proof I have read (and promptly forgotten!) reply lysecret 14 hours agoprevI always think of capital asset pricing theorem first. reply fithisux 12 hours agoprevIs there a formalization of this proof? Lean, Coq, .... ? reply peter_d_sherman 15 hours agoprev>\"G2 returns v0 to our client after the client had already written v1 to G1. This is inconsistent.\" This is absolutely true IF AND ONLY IF client and servers (and data) have no notion of time... If client and servers are say, synchronized to a central clock, and do include a timestamp with any data updated, and include timestamps with any response/\"done\" messages and check those timestamps for accuracy (the client should perform timestamp checking as well as the servers), and if the client checks timestamps of response messages from different servers, it could then check different servers that it would later connect with, to see if they had been updated appropriately or not. If later-connected-to-servers that should have been updated were not appropriately updated, then the client (if client and server are exchanging data and timestamp information) could decide how to proceed at that point. If a later-connected-to-server was determined to be inconsistent, then depending upon how the client code was written, it could do many things to mitigate the problem. It could notify other servers that it knows about of data inconsistency on the inconsistent server(s), for example... Hmm, now that I think about it, on any distributed database, for any given row of data, there should not be one, but TWO timestamp fields, one for the time that the data was updated on the first server it was updated on, i.e., the one the client connected to. The second timestamp field would be for the time that a secondary given distributed server received the data and processed it... Those two fields could be separated by mere nanoseconds of time (if distributed servers are tightly coupled), but it could be up to weeks if a secondary server was knocked offline for a long enough time period... But see, if the client software is software engineered properly, and contains the client's history, then the client (or main server, or server multiplexing proxy) can check the veracity of any arbitrary distributed server it connects to by asking it to \"read me back this data\", getting its timestamps and comparing with the local copies... All of that coupled with databases that do not delete/overwrite old records when data is updated, but rather keep a log of all updates with a timestamp, aka \"append-only\" aka \"immutable\" database, such as InfluxDB, Apache Cassandra, CouchDB, SQL Server Temporal Tables, (and I think that RethinkDB may have done something like that in the past) should equate to, at the very least, the client being able to know if a given server in a distributed system was updated properly (is consistent), or not... If it were engineered properly, the client itself could determine what to do under such anomalous conditions... It could even take it upon itself to update the server properly IF it contained a copy of the correct most up-to-date data AND had the authority to do so... which wouldn't be the case for some types of applications (i.e., banking, due to necessary security constraints), but might be the case for other types of applications (i.e., a distributed social media app, where the client is posting to the user's own account and has total permission to update any of the user's data as needed...) Maybe a better question to ask when dealing with the CAP theorem is not so much \"is it true\", so much as \"what kind of distributed database requires consistency such that the CAP theorem is required?\" (i.e., banking), and \"what kind of distributed database doesn't require consistency such that the CAP theorem isn't required?\" (i.e., distributed social media over a plethora of distributed servers)... If we see that CAP is required in only some specifc types of database/application/database contexts, then perhaps those specific databases/applications/distributed systems -- should be individually separated from non-CAP requiring ones... This being said, I think Michael Stonebraker is a brilliant Computer Scientist, and I have tremendous respect for him and the CAP Theorem... reply raincole 16 hours agoprevWhat if the client just reads from every server and compares the timestamps? reply shepherdjerred 14 hours agoparentIt is possible but difficult at scale. https://dl.acm.org/doi/pdf/10.1145/112600.112601 https://cloud.google.com/spanner/docs/true-time-external-con... reply googledocsftw 13 hours agoparentprevRead from every server is not necessarily possible, unless we assume no network partitions. reply af3d 15 hours agoparentprevUnfortunately, timestamps are not immutable. The system clock can be miscalibrated or even deliberately manipulated. It is however something of an open question. CAP is still a bit lacking in terms of rigorous mathematical proof (albeit the arguments are pretty convincing). reply coolThingsFirst 15 hours agoparentprevit violates the consistency rule. it must get the value that it was written reply DarkmSparks 14 hours agoprev [–] The problem with the example is it never actually visualises a partition, because the client can always reach both servers. an actual partition is when clients and servers are partitioned and cant talk to each other. solving for the situation presented is fairly trivial, and is pretty much exactly what blockchain systems solve. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The CAP Theorem in distributed systems posits that a system can only achieve two out of three properties: Consistency, Availability, and Partition Tolerance.- Consistency ensures that any read after a write returns the latest value, Availability guarantees responses from non-failing nodes, and Partition Tolerance allows operation despite network message losses.- The theorem, proven by Gilbert and Lynch, demonstrates that a system cannot maintain all three properties simultaneously, as network partitions can lead to inconsistencies."
    ],
    "commentSummary": [
      "The CAP theorem explains that in distributed systems, only two of the three properties—Consistency, Availability, and Partition Tolerance—can be achieved simultaneously.- The PACELC theorem builds on CAP by stating that in the absence of partitions, a choice must be made between Latency and Consistency.- Systems like Google Spanner use advanced protocols and precise clocks to maintain consistency, illustrating the trade-offs in system design."
    ],
    "points": 239,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1728347538
  },
  {
    "id": 41772551,
    "title": "Video Surveillance with YOLO+llava",
    "originLink": "https://github.com/PsyChip/machina",
    "originBody": "MACHINA CCTV viewer with realtime object tagger [WIP] Uses LLAVA YOLO 11 OpenCV How it works Simply it connects to a high-resolution RTSP stream in a separate thread, queues the frames into memory as it is and resamples it for processing. YOLO takes this frame, application gives a specific id based on it's coordinates, size and timestamp then tries to match the same object on every iteration. Another thread runs in background, iterates that object array continuously and makes LLM requests to Ollama server for object tagging Object matching It calculates the center of every detection box, pinpoint on screen and gives 16px tolerance on all directions. Script tries to find closest object as fallback and creates a new object in memory in last resort. You can observe persistent objects in /elements folder Test Environment Every input frame resampled to 640x480 for processing, got avg 20ms interference time with yolo 11 small model (yolo11s.pt) on Geforce GTX 1060 which is almost 7 years old graphics card. Other models available in \"models\" directory Stream delays by 1-2 seconds on every 10~ minutes due to network conditions, script also have a frame skip mechanism on 3 seconds of detection idle. Prerequisites Clone the repository Install ollama server Pull the LLAVA model by running ollama run llava Open app.py and set your rtmp stream address at line 18 Install the dependencies by running pip install -r requirements.txt Run the script py app.py Shortcuts S : snapshot, actual image from input stream R : start/stop recording. it records what you see. Q : quit app Project direction This is a living project, trying to create a complete headless security system by taking advantage of modern vision, object detection models on my spare time. Feel free to contribute with code, ideas or even maybe a little bit donation via ko-fi or bitcoin -https://ko-fi.com/psychip -BTC: bc1qlq067vldngs37l5a4yjc4wvhyt89wv3u68dsuv Created by PsyChip root@psychip.net .eof",
    "commentLink": "https://news.ycombinator.com/item?id=41772551",
    "commentBody": "Video Surveillance with YOLO+llava (github.com/psychip)223 points by psychip 18 hours agohidepastfavorite54 comments 01100011 4 hours agoIf you're interested in DIY security+AI, check out Frigate NVR(https://frigate.video/), Scrypted(https://www.scrypted.app/) and Viseron(https://viseron.netlify.app/). reply gh02t 3 hours agoparentI've been using Frigate for a long time and it's a really cool project that has been quite reliable. The configuration can be a little bit of a headache to learn, but it gets better with every release. Viserion is new to me though, that looks really cool. reply dfc 2 hours agoparentprevI just recently got frigate up and running. How do the other two compare? reply yu3zhou4 12 hours agoprevCongrats! What hardware you use to run the inference 24/7? I built a simpler version for running on low end hardware [0] for recognizing if there’s a person on my parcel, so I know someone have trespassed and I can launch siren, lights etc. https://github.com/jmaczan/yolov3-tiny-openvino reply matrik 1 hour agoprevMobileNetV3 and EfficientDet are othwr possible alternatives to YOLO. I was able to get higher than 1.5 FPS on Raspberry Pi Zero 2W which draws 1W on average. With efficient queuing approach, one can eliminate all bottlenecks. reply pmontra 12 hours agoprevThis runs with a Geforce GTX 1060. By a quick search it's 120 W. Maybe it's only the peak power consumption but it's still a lot. Do commercial products, if there are any, consume that much power? reply moandcompany 21 minutes agoparentThere's a wide range of inference accelerators in commercial use. For \"edge\" or embedded applications, an accelerator such as the Google Coral Edge TPU is a useful reference point where it is capable of up to 4 Trillion Operations per Second (4 TOPS), with up to 2 Watts of power consumption (2 TOPS/W), however the accelerator is limited to INT8 operations. It also has around 8 MB of memory for model storage. Meanwhile a general purpose or gaming GPU can support a wider range of instructions, single-precision, double-precision floating point, integer, etc). Geforce GTX 1060 for example: 4.375 TFLOPS (FP32) @ 120W (https://www.techpowerup.com/gpu-specs/geforce-gtx-1060-6-gb....) There are commercial-oriented products that are optimized for particular operations and precision. Here's a blog post discussing Google's 1st-generation ASIC TPU used in its datacenters: https://cloud.google.com/blog/products/ai-machine-learning/a... (92 TOPS @ 700 Mhz - 40W) https://arxiv.org/abs/1704.04760 reply hcfman 11 hours agoparentprevI have something similar. It's not tracking though. Drawing around 10W on a pi, around 7W on a Jetson. reply 4ggr0 9 hours agorootparentnot sure if i'm misunderstanding - you've got a similar GPU to a 1060 hooked up to a pi? reply lelag 9 hours agorootparentOP is probably using an AI accelerator like this: https://coral.ai/products/accelerator which works great on a PI and uses very little power. It will do the Yolo part, but you can't really expect it to do the multimodal LLM part, although you could try to run Florence directly on the PI too. reply mobilemidget 6 hours agorootparentThis works better in my experience, https://hailo.ai https://www.raspberrypi.com/news/raspberry-pi-ai-kit-availab... reply synergy20 3 hours agorootparentcoral has pcie module which is 1/4 to 1/3 of the price reply hcfman 24 minutes agorootparentprevNot a pi. A Jetson. Still an arm SBC though. reply phito 3 hours agoparentprevYou can use a Coral USB Accelerator, doesn't use more than 10W. reply hcfman 21 minutes agorootparentYeah. But it’s likely it’s an 8-bit quantised, likely very small model with a small number of parameters. Which translates into poor recall and lots of false positives. How many parameters is the model you are using with hailo? And what’s the quantisation and what model is it actually ? reply nicholasjarnold 3 hours agorootparentprevCan confirm. The Coral inference accelerator is quite performant with very low power draw. Once I figured out some passthrough and config issues I was able to run Frigate in an LXC container on Proxmox using Coral USB for inference. It's been working reliably 24/7 for months now. reply Eisenstein 2 hours agorootparentprevYou can see here: res = rest(ollama, { \"model\": \"llava\", \"prompt\": genprompt(box.name), \"images\": [box.export()], \"stream\": False }) They are calling the ollama API to run Llava. Llava is a combo of an LLM base model and + vision projector (clip or ViT), and is usually around 4 - 8GB. Since every token generated needs access to all of the model weights, you would have to send 4 - 8 GB through USB with the Coral. Even at a generous 10gbit/s that is 8GB / 1.25GB = 6.4seconds per token. A 150 (short paragraph) generation would be 16minutes. reply formerly_proven 7 hours agoparentprevYOLO is quick enough that you can just run it on a CPU, assuming you don’t want to run it at full resolution (no point) and full frame rate (ditto) for multiple streams. When you run it scaled down at a 2-3 fps you’ll get several streams per CPU core no problem. Energy use can be minimized by running a quick motion detection pass before, but that would obviously make the system miss things creeping through the frame pixel by pixel (very unlikely if you ask me) reply rocauc 13 hours agoprevA suggestion: I'd swap llava for Florence-2 for your open set text description. Florence-2 seems uniformly more descriptive in its outputs. reply jerpint 10 hours agoparentI found grounding-dino better than Florence and faster reply netdur 7 hours agorootparentI found YOLOS to be faster and better, bot real time but 22k objects under half second reply xrd 7 hours agoprevI'm confused about why you need yolo and llava. Can't you simply use yolo without a multimodal LLM? What does that add? You can use yolo to detect and grab screen coordinates on its own, right? reply andblac 5 hours agoparentSkimming through the source it seems to run 'car' and 'person' objects through llava with the following prompt: - \"person\": \"get gender and age of this person in 5 words or less\", - \"car\": \"get body type and color of this car in 5 words or less\". So YOLO gives the bounding box and rough category, while llava describes the object in more details. reply michaelt 6 hours agoparentprevAlmost certainly using yolo to segment the cars, then llava for the more detailed \"silver sedan\" description reply doctorhandshake 8 hours agoprev>> It calculates the center of every detection box, pinpoint on screen and gives 16px tolerance on all directions. Script tries to find closest object as fallback and creates a new object in memory in last resort. You can observe persistent objects in /elements folder I’ve never implemented this kind of object persistence algo - is this a good approach? Seems naive but maybe that’s just because it’s simple. reply anshumankmr 5 hours agoprevCould try with Florence by Microsoft instead of Yolo and Llava, though the results are not going to be as great. Florence will do the inference on CPU. This is just for fun. reply vaylian 9 hours agoprevHello from the privacy crowd! Please use this responsibly. Tech can be a lot of fun and I encourage you to play around with things and I appreciate it when you push the boundaries of what is technically feasible. But please be mindful that surveillance tech can also be used to oppress people and infringe on their freedoms. Use tech for good! reply ferar 14 hours agoprevCan you specify ideal hardware (camera, computer) to deploy the solution? Thanks reply skirmish 12 hours agoparentHere are hardware recommendations from another similar (and well established) project: [1] [2]. Even though they don't recommend Reolink cameras, I have both Amcrest and Reolink cameras working well with Frigate for more than a year now. [1] https://docs.frigate.video/frigate/hardware [2] https://github.com/blakeblackshear/frigate reply moandcompany 40 minutes agorootparentMany Amcrest IP Cameras are manufactured by Dahua and use localized versions of Dahua firmware. The same applies to the Lorex brand in the United States. Some things that matter when it comes to configuring your IP Cameras (Beyond security, etc): - Support for RTSP - Configurable Encoding Settings (e.g. h264 coded, bitrate, i-frame intervals, framerate) - Support for Substreams (i.e. a full-resolution main stream for recording, and at least one lower-resolution substream for preview/detection/etc) ... Make sure the hardware you select is capable of the above. Configurability will matter because Identification is not the same as Detection (Reference: \"DORI\" - Detection, Observation, Recognition, and Identification from IEC EN62676-4). If you want to be able to successfully identify objects or entities using your cameras, it will require more care than basic Observation or Detection. reply hcfman 20 minutes agorootparentIsn’t it illegal now to import HIKvision and Dahua to the states now ? reply jamesbfb 8 hours agorootparentprev+1 for Frigate and Reolink. I have it running in a Proxmox VM on an old dell r710 (yes, it’s sucks watts and needs replacing) but all said, Frigate, is, amazing! The ease of integration with HA is equally great. reply npteljes 5 hours agoparentprevI can recommend the Axis brand. Very user friendly while power user friendly as well, true local offerings. I personally bought mine used, it's an older model, and even then, it holds up really well. reply toomuchtodo 1 hour agorootparent+1 for Axis reply moandcompany 14 hours agoparentprevYou'll want to find an IP Camera that supports the RTSP protocol, which is most of them. If your budget supports commercial style or commercial grade cameras, looking at Dahua or Hikvision manufactured cameras would be a good starting point to get an idea of specs, features, and cost. reply meow_catrix 14 hours agorootparentMaybe don’t buy surveillance hardware from those brands reply sinuhe69 14 hours agorootparentNot OP, but the reason may be: US - FCC Ban The US Federal Communications Commission (FCC) banned Dahua and Hikvision from new equipment authorizations in November 2022. Most products that use electricity require FCC equipment authorizations; otherwise, they are illegal to import, sell, market, or use, even for private individuals. Jul 5, 2024 reply hcfman 10 hours agorootparentShame, they are the best cameras available. reply formerly_proven 7 hours agorootparentAlso it’s not like you stop supporting these OEMs if you buy other made in china cameras. They’re essentially all designed and manufactured by very few of these large OEMs, all of which are implicated in CCP state surveillance. You’d have to buy from actual Western companies like Axis or Dallmeier. reply moandcompany 13 hours agorootparentprevA lot of the commercial-style or commercial-grade IP Cameras sold are rebadged Dahua or Hikvision products. Compromised firmware or other backdoors are a concern for a wide range of products. With IP Cameras, a commonly recommended practice includes putting them on a non-internet accessible network, disabling any remote access, UPnP type features, etc. You can run IP cameras in an air-gapped configuration as well. Home/consumer-grade cameras have plenty of shortcomings too. reply hcfman 10 hours agorootparentIf they are rebadged, that's fine :) reply avh02 14 hours agorootparentprevYou're going to have to explain the reasoning here reply meow_catrix 14 hours agorootparent”Analysts noticed that CCTV cameras in Taiwan and South Korea were digitally talking to crucial parts of the Indian power grid – for no apparent reason. On closer investigation, the strange conversation was the deliberately indirect route by which Chinese spies were interacting with malware they had previously buried deep inside the Indian power grid.” reply 2Gkashmiri 12 hours agorootparentlink? i am close to CCTV retailers and dahua and hikvision are only brands of CCTV widely available with two exceptions of \"cp plus\" and \"hawkvision\" which are in all lilkelihood rebranded or made in china products. https://www.amazon.in/s?k=cctv+system+4+channel so what are your options? i have been contemplating getting a door phone + cctv for my home for the past so many years but problems like these prevent me from investing into an ecosystem. edit: oh. looks like pager attacks has their attention now. https://trak.in/stories/pager-bombs-govt-can-ban-chinese-cct... i guess time will tell and then there is lobbying so yeah reply formerly_proven 4 hours agorootparent> are in all lilkelihood rebranded or made in china products IPVM did all the legwork on this a while ago and unconvered that, not that surprisingly, two and a half OEMs (including Dahua and Hikvision) are manufacturing essentially every not-completely-garbage CCTV camera coming out of china, and a bunch that very explicitly claimed to not come out of china. reply nativeit 14 hours agorootparentprevCould you elaborate? What’s up with those brands? reply llm_trw 14 hours agoparentprevDefault yolo models are stuck at 640x640, so literally any camera that is at least capable of that resolution. Llava I believe is about the same. You'd need ubuntu and something that can run a llava model in vaguely real time, so a 4090/4080. reply nikolayasdf123 12 hours agoprevhow about llama3.2 vision? should it get better performance? reply _giorgio_ 16 hours agoprev [–] All I see, usually, is some AI YOLO algorithm applied to an offline video. This is the first time that I've seen a \"complete\" setup. Any info to learn more on applying YOLO and similar models to real time streams (whatever the format)? reply yeldarb 14 hours agoparentWe’ve got an open source pipeline as part of inference[1] that handles the nuances (multithreading, batching, syncing, reconnecting) of running multiple real time streams (pass in an array of RTSP urls) for CV models like YOLO: https://blog.roboflow.com/vision-models-multiple-streams/ [1] https://github.com/roboflow/inference reply llm_trw 14 hours agoparentprevJust stream it one frame at a time to the model and eat the latency: https://www.youtube.com/watch?v=IHbJcOex6dk if you need more hand holding. There's a reason why there's a whole family of models from tiny to huge. reply yeldarb 14 hours agorootparentIf you do it naively your video frames will buffer waiting to be consumed causing a memory leak and eventual crash (or quick crash if you’re running on a device with constrained resources). You really need to have a thread consuming the frames and feeding them to a worker that can run on its own clock. reply llm_trw 11 hours agorootparentThat's not how loop devices work on Linux. reply hug 15 hours agoparentprev [–] This repository seems to be exactly what you are asking for. It's YOLO analysis of video frames passed in through Real Time Streaming Protocol. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MACHINA CCTV Viewer is a work-in-progress project utilizing LLAVA YOLO 11 and OpenCV for real-time object tagging from high-resolution RTSP streams.",
      "The system processes frames with a 20ms interference time using a YOLO 11 small model on a GTX 1060, with a mechanism to handle stream delays and idle detection.",
      "The project aims to develop a headless security system leveraging modern vision and object detection models, inviting contributions from the community."
    ],
    "commentSummary": [
      "The GitHub project \"Video Surveillance with YOLO+llava\" by psychip is gaining traction for its application in DIY security and AI, sparking discussions on alternative surveillance solutions like Frigate NVR, Scrypted, and Viseron.- Frigate NVR is noted for its reliability, though it has a steep learning curve, and hardware recommendations include using a Geforce GTX 1060 or Coral USB Accelerator for better processing efficiency.- The project also raises privacy concerns and emphasizes the responsible use of surveillance technology, with debates on using YOLO with llava for detailed object descriptions and alternatives like Florence-2 and MobileNetV3."
    ],
    "points": 223,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1728346863
  },
  {
    "id": 41769971,
    "title": "Is the attack helicopter dead?",
    "originLink": "https://hushkit.net/2024/10/07/is-the-attack-helicopter-dead/",
    "originBody": "October 7, 2024 Is the attack helicopter dead? The attack helicopter is costly and complex to operate, yet it is taking a mauling in the Russian invasion of Ukraine. Russia’s full-scale invasion attempt of Ukraine starting in 2022 has shown both the vulnerability of helicopters and the effectiveness of small, uncrewed aircraft against armour. With this in mind, we ask: Is the attack helicopter dead? Ron Smith Few observers thought Ukraine could withstand the Russian onslaught of 2022. Footage released in April footage of the destruction of a Russian Kamov attack helicopter was a huge morale boost. And more followed. The war in Ukraine has been marked by staggering losses of both anti-armour helicopters and armour. VIDEO: Ukrainian forces shoot down Russian helicopter with Stugna-P anti-tank missile. – @Kochevenko https://t.co/jlbtMPXigy — Conflict News (@Conflicts) April 5, 2022 Armour operations Typical Western doctrine (offensive or defensive) uses manned armoured reconnaissance ahead of the Forward Line of Own Troops (FLOT) to locate enemy forces and determine their intentions. Increasingly, manned operations will be supported by other ISR (intelligence, surveillance, and reconnaissance) platforms, such as Uncrewed Air Vehicles (UAV) and later Uncrewed Ground Vehicles (UGVs), to augment the manned platforms. Recce: This is driven by a recce Plan determined by the Commander’s Critical Information Requirements (CCIRs), designed to fill in gaps in intelligence and distinguish enemy feints and deception tactics from their main force’s true intentions and timing. Other objectives would typically be to locate enemy command and control, logistics, air defence units, long-range artillery, and other high-value/high-threat components. The recce info will then shape the deployment of main armour and infantry (again offensive or defensive), supporting anti-armour helicopter and precision long-range artillery operations. Manned armoured reconnaissance beyond the FLOT (i.e., in enemy territory) is likely hazardous, particularly if the enemy has effective electronic surveillance capabilities. Traffic analysis can be used to locate signal traffic from unknown forces and, even if encrypted, is likely to result in unwelcome attention. The US tends to assume its comms cannot be read, so it reports every enemy observation. The UK is more concerned about detected transmissions (even if not read) and operates largely under radio silence. Terrain masking to avoid detection may make Very High Frequency traffic difficult, so HF or datalink to SATCOMs may have to be used. Armour and Mechanised Infantry: In addition, armour, on both sides, is having a hard time. In the Ukraine case, the threat has proven to be a combination of precision artillery and long-range missile attack, combined with top attack by armed drones. The author identified this latter threat as a concern more than a dozen years ago – having noted that Hezbollah, in the first Lebanon conflict, had deployed armed drones against Israeli armour. Because the high mass of protective armour leads to weight and mobility issues, MBT protection is concentrated against direct fire attacks from other MBTs. Top protection is typically reduced, primarily against artillery near misses rather than direct hits, which are now the norm. Even with these measures, deployed MBT mass is typically around 62 tonnes, and top protection is one area that is typically traded off to achieve acceptable mobility. Active protection systems are not yet regarded as mature and may introduce hazards to nearby personnel (if operating with infantry, for example). I am unsure how successful these are in Israeli use, or whether they have been used successfully in Ukraine. Furthermore, Western armour generally has no organic means of detecting or countering the drone threat, although directed energy weapons or RF countermeasures may offer some capability in the future and are undoubtedly being actively researched and trialled. So heavy armour is looking increasingly vulnerable, as, in the Ukrainian conflict at least, attack helicopters. However, heavy armour is clearly still important for taking and holding ground, so it will most likely continue to be central in many operations. Attack Helicopter operations When the UK was developing its thinking for GST3971 to acquire a dedicated attack helicopter in the mid-1980s, the vision was of a helicopter that could engage in autonomous direct-fire attack of heavy armour. The threat was essentially Cold War, with massed Soviet armour operating across the North German Plain. Organic air defence (then primarily radar-directed ZSU-23-4) was a significant threat, leading to a desire to stand-off outside its lethal range. Priority targets were enemy air defence, command and control centres and heavy armour. The solution was deemed to be a low-signature helicopter (radar and IR signatures, particularly) fitted with a mast-mounted sight and using terrain screening. A long-range fire-and-forget weapon was required so that the helicopter would not be exposed throughout the weapon’s flight time. Initially, Apache was not favoured because the AH-64A was regarded as having large visual and radar signatures and an inadequate sighting system. Without a mast-mounted sight, Scout helicopter support would also be required for target acquisition and designation. The AH-64D with Longbow and RF Hellfire largely solved these problems by acquiring targets at long range and engaging in indirect fire. However, the missile and target detection range exceeded the recognition and identification range of the TADS sight (which also required the helicopter to be exposed to gain a line of sight to the target). This introduced some concern about the ability to achieve positive target identification when operating under restrictive rules of engagement. The Situation in Ukraine Russian operations over Ukrainian-held territory Today, taking the Ukraine experience as representative, Russian attack helicopters are operating over large regions of Ukrainian-held territory without air superiority and with a dispersed infantry threat armed with capable MANPADS systems. The defending forces can adopt positions that are well hidden, but which offer good fields of fire. The difficulty of detecting and countering this threat, combined with extensive areas lacking terrain cover, significantly increases the risk to attack helicopters in transit to and from their targets. This is compounded by the apparent ineffectiveness of the helicopter protection and countermeasures equipment. There are reports of both sides in Ukraine using armed drones for anti-personnel operations against individual soldiers, so operation under cover, if not actually below ground is becoming necessary, if there are enemy drones in the area. This undoubtedly reduces the opportunities for, or increases the risk of, MANPADS operation. Ukraine perspective – early phase In the early phase of the invasion there was an armoured attack along the borders, but particularly moving south towards Kyiv from Belarus. This was largely canalised along main routes, as were its supporting logistic columns. This resulted in heavy losses. These were inflicted mainly by mines and artillery. Flooding of off-road terrain reduced the transit route options for the invading force. Later Developments After being pushed back from Kyiv in the initial armour thrust, Russian armour and mechanised infantry have been grinding out attacks from Ukraine’s borders, particularly from the south and east. This relatively static land battle is accompanied by long-range missile attacks on critical infrastructure and population centres. Both sides have effective anti-aircraft missile systems, and neither side has achieved full air superiority over the battlefield. The later Russian attack has featured the use of medium- to long-range stand-off weapons (cruise or ballistic missiles and glide bombs), air-or ground-launched, often from within Russian territory. There seems little scope to counter this, while the political does not exist to mount attacks on launch locations well into Russian territory. The best possible missile defence system may ameliorate damage but will not hasten the end of the conflict, which has become strategic rather than tactical. Significant numbers of western ground-to-air missile systems are also being supplied. Ukrainian anti-armour operations have increasingly been able to use precision artillery such as HIMARS and ATACMS. The availability of such systems and their munitions is likely to be in short supply and is dependent on enduring political support from EU and NATO countries. It is, therefore, vulnerable, for example, should Donald Trump be returned as US President following the November election. It seems likely that NATO surveillance assets (E-3, RC-135W, U-2S and satellite cover) are gathering real time intelligence over the battlefield – whether such information is being passed to inform Ukraine deployments and targeting decisions has not been revealed. In any future conflict, using such overhead assets and effective datalinks to transmit near real-time intelligence is likely to be key to effective offensive or defensive operations. Both Russia and the Ukraine have adopted the use of armed drones for the top attack of armour and these appear to have been very successful. (Relatively little imagery has been released showing Ukraine anti-armour helicopter attacks on Russian armour, or indeed Russian helicopter attacks on Ukrainian armour – Western or otherwise). NATO nations are beginning to supply air-to-ground weapons such as Brimstone and Storm Shadow, and F-16 aircraft have entered Ukrainian service. It is not known whether Western air-to-ground missiles have been integrated for release from existing Russian-built equipment operating with the Ukrainian Air Force. Suggested Success Factors for Helicopter anti-armour operations What do you need for successful helicopter anti-armour missions? Ideally, you want air superiority and not to operate over large swathes of enemy-held territory occupied by determined resistance, equipped with capable MANPADS and other air defence systems such as S-200 and S-300. Here is a list of possible success factors for postulated helicopter anti-armour operations. Accurate intelligence as to disposition and movement of enemy armour: satellite, aerial recce, stand-off radar, comms / SIGINT, manned armoured reconnaissance, SF, etc. A command and control infrastructure capable of providing updated target information in near real-time Ability to comply with restrictive rules of engagement when necessary Preferably having air superiority over the area of operations Ability to reach an engagement position with minimal exposure to threat systems Ability to engage at long-range The necessity of avoiding enemy drone threats to AH is likely to favour mobile rather than static operation. Carriage of sufficient weapons to inflict significant attrition on the enemy force (likely to determine the number of helicopters in the attack) Use of longer-range missiles (Rafael Spike NLOS quotes 27 km range, helicopter-launched Brimstone is said to have similar range capability). Proven and effective countermeasures against unexpected missile attack – missile launch detection and tracking, plus sophisticated countermeasures and effective signature reduction. Today, there must be some query as to the availability and effectiveness of such systems. Ballistic tolerance at least against small arms and medium machine gun threats Reliable, low-maintenance platform, capable of operation in all weather and climatic conditions. Crashworthy fuel systems Run-dry transmission systems Defensive Operations The above factors suggest that deploying attack helicopters operating defensively (over one’s territory) could still be effective. If the enemy uses the same or similar equipment, there would still be problems to solve regarding positive target ID. Also, effective command and control to deal with a fluid ground situation could be problematic, as could maintaining a supply of munitions to the AH force. Missile countermeasures remain an uncertain problem. Offensive Operations Long-range indirect fire engagements would be preferred for both offensive and defensive operations, and they would probably be essential in the offensive case. The high helicopter losses sustained by Russia in current offensive operations probably reflect high risk operations, in the face of determined opposition with capable weapons and not much terrain cover for the helicopters. Also, no air superiority to provide top cover and hinder ground air defence, together with apparently ineffective measures to hinder missile lock-on and to break lock, once engaged. Moreover, the threat is not the organic air defences of battlegroups or a Soviet Motor-Rifle Regiment or Brigade but dispersed and well-hidden infantry and special forces units equipped with modern MANPADS missile systems. Furthermore, because the enemy forces are operating over the defenders’ own ground, the defence can be cued and alerted to approaching helicopters, given good data connectivity. In the case of offensive operations, it would appear that stand-off operations from the ground already held by one’s own forces might be the order of the day. In this case, the helicopters might operate similarly to a highly mobile precision artillery unit, able to redeploy kilometres across the field of operations in minutes. With a lack of local air superiority, the Russian use of stand-off weapons launched from within their territory supports this proposition. A further consideration is that maintaining the mobility of the helicopter force is likely to benefit it by hampering any drone threat targeted at it. The focus of attack might shift towards enemy logistics – MBTs without fuel or ammunition cannot conduct manoeuvre warfare. Increasing the range at which the attack is conducted could suggest the use of larger helicopters to carry the heavier weapons likely to be required – feasible if operating over safe ground. The carriage of Exocet on certain export Sea King aircraft is an example of such a usage. Rafael Spike and Brimstone are also attracting interest because of their long-range capability. Clearly, target selection would be entirely dependent on the higher-level ISTAR infrastructure, although salvo-fired Brimstone has already shown some autonomous target discrimination capability. An alternative to using one heavy long-range missile per tank destroyed might be to use a larger helicopter to launch long-range drone-carrying systems. This could allow several medium helicopters to launch attack and surveillance drones into a given operational area, possibly in the enemy’s rear. Command and control, logistics, comms, armour, barracks, and hardened targets could all be engaged in this way. Forward-launched recce drones could provide target designation and satisfy positive ID requirements when operating under tight rules of engagement. Such an approach could also overload the enemy air defence command and control and be usefully deployed in conjunction with simultaneous missile and/or manned aircraft operations. This capability is alluded to in several planned US programmes, including the abandoned FARA and FLRAA. We are talking about air-launched effects (LE) for reconnaissance or attack and Future Tactical Unmanned Aircraft Systems. The air-launched effects were described (Vertiflite March / April 2024) as being deployed from FARA, FLRAA and Black Hawk “to decoy, disrupt or destroy enemy air defences and to spot targets for joint forces”. The same article indicates that ”the Army plans first flight of a fully-integrated ALTIUS – Air-Launched, Tube Integrated Unmanned System from a Black Hawk this year” potentially for a rapid fielding decision in 2025. The US’s ”long-standing interest in technologies that enable a single operator to control multiple UAS is associated with this.” pic.twitter.com/sbyvDYWw1c — Hush-Kit Aviation News, History & Satire (@Hush_Kit) October 7, 2024 Perhaps network-enabled command and control, ISTAR, and other means of target verification can integrate existing AH capability in defensive operations. Medium helicopters operating further back could launch a mix of longer-range weapons and ‘Launched effect UAS’ in both offensive and defensive scenarios. Further to the suggestion of stand-off medium helicopters for anti-armour ops over enemy territory (and the US reference to Air Launched Effects), see here. It is also worth noting that Sea King was cleared for export customers to launch Sea Eagle (India) and Exocet (Qatar, Pakistan), suggesting plenty of payload for air-launched systems controlled by medium support helicopters. [A good role for the FAA Merlin Mk.4 force?] The Drone Threat to Helicopters In a traditional mechanised offensive, armour and infantry fighting vehicles (IFVs) operate collectively to gain and hold ground. Helicopters are used forward to take out enemy armour and attack command posts while scouting and designating targets for precision artillery strikes. Infantry also relies on helicopter support for air cover and casevac. Recently, drones have been used in kamikaze attacks on helicopters. Used in this way, drones could significantly hamper helicopter operations and severely affect infantry morale. Both helicopters and ground vehicles now need to adopt design and protection / defensive measures cognisant of the drone threat. In this scenario, the twin tail rotors suggested on some Westland designs (admittedly for other purposes) could provide a degree of redundancy. General Observations As the earlier discussion shows, the systems are more important than the platform. Ideally, you want to be network-enabled (so that someone else sorts out the targets and satisfies the rules of engagement). Then you want a long-range fire-and-forget weapon system capable of defeating enemy countermeasures and with a tandem charge, warhead to deal with ERA. If the missile sensor can discriminate between target types, so much the better. If I were in a tank, I’d still be worried about drones – as I said in a briefing a dozen years ago. Given the right network integration and the right weapons, you could inflict a deal of pain in a fairly basic helicopter while staying well out of the way of any air defence. You still have to protect yourself against chance encounters – partisans or special forces with shoulder-launched weapons, for example. This appears easier said than done. Assuming conditions allow offensive aircraft operations, integrating western weapon systems such as Brimstone on suitable platforms, such as Frogfoot, could provide the ability to salvo fire against multiple targets. Its MMW radar seeker is supposed to support this capability, with the weapons themselves avoiding duplication of effort and allocating targets across the salvo (fire-and-forget en masse). The capacity offered by a medium helicopter in this role could extend to area denial or countermobility operations. This type of platform might be used to deliver area denial or scatterable countermeasures (even mines, perhaps) to rapidly counter enemy armour. Missiles such as Brimstone might be more effectively employed in this scenario. Whether in a defensive or offensive posture, an agile and responsive command and control system will be required to maintain a responsive decision-making process. This is known as the OODA-loop (OODA stands for observe, orient, decide, act). There is some question as to whether current NATO surveillance assets are providing near-real-time intelligence to Ukraine. It is clear, however, that long-range stand-off anti-armour operations will require a persistent (probably stealthy) high-flying or stand-off system to provide situation awareness, detect armour targets across the battlefield and enable the use of precision indirect fires (whether by artillery or helicopter, operations). Use Code DISCOUNT15 for a healthy 15% discount on your pre-order of The Hush-Kit Book of Warplanes Vol 3 here. One very good use case for low or zero sensors but good comms is to have airborne nodes in a ‘scrum half’ position behind the tactical edge. Anything up threat (exquisite and LO) can use directional comms to get data back / receive C2 and Intel from the nodes; the nodes then use any route to get to the optimal place – including space and terrestrial – from a position that cannot be easily targeted by OPFOR. Urgent Operational Requirements manage rapid change during conflict, usually in response to painful lessons learned. This is generally at the subsystem/protection level rather than the system and platform level. Examples could be the rapid introduction of electronic countermeasures, protective screens, and responses to enemy countermeasures. The targeting infrastructure required to support helicopter indirect fire long-range attacks appears a little different from that required to support MLRS / HIMARS / ATACMS operations and should, therefore, be available, provided suitable tasking orders can be accommodated. Interestingly, the available description of the Leonardo AW249 mentions the ability to operate air-launched RPVs. The latest Aerospace magazine indicates more on its network capability: “acts as a sensor ISR node on a C4 network, and (can) control and manage UAVs – with a Wide Band LOS Datalink … LTE Gateway and Link 16.” The articles do not address the routine concept of operations, but the connectivity and network capabilities could allow a range of collaborating systems to provide targeting data. Now they just need to adapt AW149 and/or NH90 TTH to the stand-off anti-armour role …” Tentative Conclusions There are many problems facing armoured units in modern land warfare. Broadly, these fall into (1) threats: enemy armour, helicopters, armed drones, precision artillery and missiles, minefields and obstacles; and (2) the difficulty of sustaining operations over time at long range: logistics – fuel, ammunition, repair, crew sustainment, rules of engagement. Similarly, one can discuss the problems facing the counter-armour forces – again dependent on terrain/area of operations, posture, equipment and C4ISTAR systems and their connectivity. Operational changes may arise under TTPs (Tactics, Techniques, and Procedures) rather than wholesale doctrinal revisions. The challenge is to inflict heavy casualties on enemy forces while increasing one’s own chances of survival. Used carefully, existing attack helicopters operating over ‘friendly’ terrain can still be effective. Increased use of ‘network-enabled warfare’ seems essential, combined with the ability to engage targets primarily at range and preferably non-line-of-sight. You might end up with some new operational concepts and the reprioritisation of target lists. Flooding of land to ‘canalise’ (literally and metaphorically) the routes available to armour (and logistics); out-of-contact launching and controlling of recce/designator / armed drones – and longer-range missiles from medium helicopters looks like a decent tactic for anti-armour operations and may have a place in both defensive and offensive postures. Brimstone 2 (helicopter launched) has a stated range of 40 km+. As an operational concept, half a dozen AW149s (or NH90s, or Merlins, or Sea Kings), each with eight Brimstone 2, could do a lot of damage providing indirect fire—provided near real-time networked stand-off target information was available. In this role, the helicopter fleet operates as a highly mobile precision artillery force. Exploitation of night capability and simultaneous attacks along a front might come into play. Deep strikes into enemy training and rear areas (and recruitment centres) might also be targeted to affect public opinion and morale. Other options could include using dummy armour supported by signals deception activity to draw in enemy forces or distract from more covert operations. Finally, it would appear that heavy armour forces do need organic close-in air defence. Perhaps the naval approach (e.g., Phalanx)—whether by high rate-of-fire radar-directed gun systems, electronic countermeasures (potentially including EMP to disrupt connectivity of control systems), or directed energy means—might go a good way to countering the ‘kamikaze drone’ threat. Target detection and tracking systems would have to be modified to suit the targets to be engaged. The low cost and simplicity of the drones mean that they have a significant number of advantages, and identifying and then defeating drones once in the air is hard; their low profile and low signature are a challenge, and their agility makes physical defeat hard. This strongly favours electronic countermeasures might be the preferred approach. There’s a Hush-Kit Book of Warplanes Vol 1, and there will soon be a Vol 2 and then a Vol 3! Thank you for reading the Hush-Kit site. It’s all been a massive labour of love to which I have devoted much time over the last 12 years. There are over 1100 free articles on Hush-Kit; think of the work that’s gone into that! To keep this going, consider donating (see button on top of page) or supporting on Patreon. Not having a sponsor or paid content keeps this free, unbiased (other than to the Whirlwind) and a lot naughtier. We can only do this with your support. I love this site and want it to continue; this is where you come in. To those who already support us, I’d like to thank you. The discussion suggests that intelligence, communications, and the ability to counter enemy operations are becoming dominant factors in future land warfare. Land platforms and helicopters should now be designed, considering enemy drone operations as a key threat. Equally, friendly drone operations – offensive, defensive, intelligence gathering, defence suppression, etc. —should be integrated into and with operational planning and land and air platform capabilities. RV Smith Dr Ron Smith joined the British helicopter company Westland in 1975, working in Research Aerodynamics, and remotely piloted helicopters (before they were cool), and later became Head of Future Projects. He had a strong influence on the design of the NH90 helicopter, and was involved in the assessment of the Apache for Britain. He also explored a variety of exotic future technologies for Westland. One such exotic machine was a secret stealth attack helicopter. Credit is also due to John Puddy, Robert Hopkins, Jeremy Smith, and Jim Smith for the valuable insights they provided. Use Code DISCOUNT15 for a healthy 15% discount on your pre-order of The Hush-Kit Book of Warplanes Vol 3 here. Share this: Twitter Facebook Like Loading... Related Written by Hush Kit Posted in Uncategorized Tagged with defence, news, russia, ukraine, war",
    "commentLink": "https://news.ycombinator.com/item?id=41769971",
    "commentBody": "[flagged] Is the attack helicopter dead? (hushkit.net)189 points by speckx 23 hours agohidepastfavorite568 comments MarkMarine 17 hours agoIn the war I fought in, there was a markedly different approach to combat air ops between even just the different service branches. The Army tended to use the Apache like it was a flying tank, hovering and delivering ordinance; the Marines (which is where I fought) flew as low and as quickly as possible even while sending rounds and hellfire missiles downrange. The marines were not losing aircraft in anywhere close to the numbers of the Army when I was there. You need a skilled operator to hit a helicopter moving at 100 knots when it's 15m over the buildings, and we mostly operated at night. I remember watching a ZPU gunner pointing the cannons directly at us and firing, and laughing as the rounds just flew behind the tail. It's my understanding (and from watching the videos that I can get as a civilian) that the Russians still aren't operating their helicopters in a manner that I would be comfortable with if I was inside one. I certainly wouldn't be pumped flying in the environment they are in, with so many MANPADS out there, but there is no way a machine I was in would be hit with an anti-tank missile while we hovered (as was in the article.) Lot of preamble to say: no, I don't think the attack helicopter is dead. Attack helicopters are nimble and can hide in terrain quite well, and even when an attacking force can see them it takes a skilled operator to actually hit them. The single use drones that operate like kamikaze vehicles may throw a winkle into the mix, but a helo flying at 150knots is going to be very challenging to hit for one of those. I expect there will be quite an arms race countering and then counter countering these in the future wars. reply warner25 15 hours agoparentI'm a former Army helicopter pilot (but Black Hawks, not Apaches) and I think this is an interesting observation. By 2011, when I went to war, the main thing we'd learned was to fly high up above small arms range: above 1,000 feet AGL. Only our Kiowas were generally allowed to operate below that, flying exactly the way you describe Marine helicopters operating; that was part of the Kiowa's nature as scouts relying mostly on the pilots' eyes (and sometimes their M4 rifles pointed out the door). The aircraft (Kiowas, but also Apaches and Black Hawks when in support of troops-in-contact) that got chewed up were invariably operating down below that. By that time, Apaches were also mostly a deterrent. The point was for them to be seen. That kept the enemy in hiding under cover while we did whatever else needed to be done. Before firing a shot, they'd circle for 30+ minutes recording video and talking into the tape recorder to establish positive identification of targets and explicitly go through all the steps that the lawyers came up with to mitigate civilian casualties. It was all very unlike e.g. Iraq in 1991 or 2003, to my knowledge, or present-day Ukraine. Not at all stealthy or fast. And there has been an effort in recent years to unlearn all of this, and get back to the tactics that would be needed in a fight like Ukraine's. reply MarkMarine 13 hours agorootparentI was in Iraq in 2003, so like you said very different. We did take small arms fire all the time, pretty ineffective though. We had one Cobra come back looking like Swiss cheese but it did manage to fly back to the fob. reply throwup238 16 hours agoparentprevWe’re still in the very early stage of drone development for warfare and Ukraine is using a lot of civilian gear. Now the armed forces of the world are plowing their funding into R&D I expect them to develop quickly. For example, aluminum air batteries are perfect for this use case but havent been developed because until now single use batteries haven’t seen any demand. Those will at least double or triple the range for armed drones. High end solar panels can allow them to sit and wait for a trigger to attack. Combine that with the tech behind the Redbull F1 camera drone [1] that can fly at 200mph and drones become much deadlier to attack helicopters. Slap a rocket motor on it for final approach, even a sub-M civilian model rocket motor, and it’s over. Imagine the drone just sitting there listening for a helicopter to get close enough - humans wouldn’t even need to be involved except to place it strategically. [1] https://youtu.be/NDUcoNlgPrk reply michaelt 10 hours agorootparent> We’re still in the very early stage of drone development for warfare and Ukraine is using a lot of civilian gear. Now the armed forces of the world are plowing their funding into R&D I expect them to develop quickly. I'm not sure that follows. Military drones like the Predator have been around for 30 years - at a cost of $30 million a drone. US military contractors are many things, but they're never cheap. And at that price, you don't have many and so they're never where they need to be. The battlefield impact in Ukraine has been because for $500 you can strap a grenade to a DJI Mavic and you've got 60,000 times as many of them. And sure it's got much less range and inferior sensors and less jamming resistance and so on - but the price lets it be it's in the right place at the right time. Defence contractors aren't famous for their cost-effective practices, so I'm not sure they can improve on the most important aspect of these drones. reply pjc50 8 hours agorootparentWe're back to \"is the purpose of a defence contractor to siphon public money, or is there a war currently on which might impact the personal lives of the C-suite of the defence contractor?\" reply sofixa 9 hours agorootparentprevBut exactly - Ukraine's defence contractors and suppliers have to innovate, and do it on the cheap. As a result there will be lots of lessons to learn, and after the war, hardware and concepts to sell (like Israel does, it's a top military exporter because it has had to develop and innovate). Also, the US has shown it can stomach its pride and buy foreign off the shelf designs which are better (okay, not always, cf. the KC-45 vs KC-46, but still). And of course there's the whole rest of the world. reply norswap 9 hours agorootparentprevThere's a new generation of defense contractors (Anduril, Ares) coming online that seem to promise order of magnitude improvement on the status quo. reply nradov 4 hours agorootparentIt's good to have more options but Anduril and Ares are mostly a lot of hype. They won't achieve anything close to an order of magnitude improvement. Costs are largely driven by the laws of physics, and those are the same for everyone. reply nradov 6 hours agorootparentprevA DJI Mavic with a grenade has a flight time of only about 20 minutes, and can only operate at low attitude and close to the operator. The MQ-1 Predator can travel hundreds of km under satellite control and orbit for hours at medium altitude to provide persistent overwatch with advanced sensors. The cheap drones used in Ukraine are in no way a substitute for large, expensive drones like the Predator / Reaper. They address totally different missions and it's naive to compare them. NATO has been flying large, expensive drones equipped with long-range radar at the edges of Ukrainian and Russian airspace. You don't hear much about it but this has been tremendously helpful for feeding Ukraine targeting data and warning about attacks. Can't do that with a cheap drone. reply 15155 4 hours agorootparent0 of these heavy UAVs will be able to operate in contested airspace. This is why you no longer see Bayraktar footage anymore, and they aren't even remotely as heavy. reply nradov 4 hours agorootparentSuccessor heavy UAVs such as the RQ-180 are specifically designed to operate in contested airspace. These are far more capable and survivable than anything Turkey can produce. reply ahmeneeroe-v2 16 hours agorootparentprev>Imagine the drone just sitting there listening for a helicopter to get close enough Imagine a drone which outputs the signature of an attack helicopter to draw out that loitering drone and then destroy it, leaving the space open for an actual attack helicopter to swoop in and do its business. reply throwup238 15 hours agorootparentHow? A helicopter is on the order of 75-80 decibels at 1000 feet. That’s the equivalent of a giant flying stadium speaker consuming kilowatts of power, that has to catch a much smaller 200mph drone while being just as cheap. The attack drone can just move and triangulate the sound, eliminating anything that’s trying to mimic a helicopter without outputting enough decibels. reply TeMPOraL 12 hours agorootparentHow much would it cost to slap some plywood on an old/scrapped heli engine and make a remote-controlled decoy that just looks and sounds a bit like an attack chopper? Drones don't need to be small, and big doesn't always mean expensive. reply Turskarama 12 hours agorootparentMore than the drone for sure, and you'd run out of old heli engines pretty fast. reply michaelt 10 hours agorootparentAh well you see, you recover the busted engines from all your shot down helicopters. /s reply ahmeneeroe-v2 15 hours agorootparentprevUse your imagination. The counter-drone doesn't have to output the exact same energy profile as an attack helicopter, just close enough to trigger the anti-helo-drone's activation. Examples: the counter-drone outputs only a specific frequency (the anti-helo drone isn't running a whole sound analysis, just a narrow range). It outputs that at much lower decibels (the anti-helo-drone just thinks the helo is farther away). It outputs that sound in bursts and directionally (the anti-helo-drone is only listening in a specific place). Once found, the counter-drone dispatches a kill drone which can match the anti-helo drone's speed. Sure all of these \"hacks\" will be countered by future versions of the anti-helo-drones, but that's kinda my whole point. reply throwup238 15 hours agorootparent\"Just close enough\" is doing a lot of heavy lifting there. It doesn't matter if the decoy can match frequency if it can't match amplitude because it's trivial to triangulate the position and eliminate anything that's too quiet. Any helicopter that sounds \"farther away\" than its actual position is obviously a decoy. Measuring the time of flight on reflections eliminates directional speakers. These aren't even hacks, this is something an Alexa smart home speaker is equipped to do today. Add a rudimentary radar and the decoy now has to have the same radar cross section as a big metal helicopter. Chaff isn't going to work when sensor fusion includes computer vision. > Once found, the counter-drone dispatches a kill drone which can match the anti-helo drone's speed. Once it's dispatched, how is it going to target and intercept a small drone with a tiny radar cross section that has thrust vectoring? That's a job for static CIWS/AA, not a cheap counter drone dispatched from a decoy. My point is that attackers have the technological and cost advantage here, possibly forever. Civilian quadcopters can't easily take down a 150 knot helicopter now but the technology to make 200+ mph military drones is already here, it just hasn't been combined into a weapon yet. No imagination needed, it's practically inevitable. reply loopdoend 12 hours agorootparentSwarms of autonomous AI-targeting high speed death squads are inevitable, the technology is even open source already. reply worldsayshi 12 hours agorootparentprevThat's a lot of specific engineering just to protect the helicopter. Or you can just spend that engineering effort and money on replacing the helicopters with more advanced drones. reply tomooot 10 hours agorootparentprev>the anti-helo drone isn't running a whole sound analysis, just a narrow range Why? Sure you might be limited to that if you're using an Arduino but with an FPGA or even a cheap \"edge AI\" NPU you could do a very thorough analysis (even credit card sized image recognition modules with camera areThe single use drones that operate like kamikaze vehicles may throw a winkle into the mix, but a helo flying at 150knots is going to be very challenging to hit for one of those. All you're seeing is makeshift COTS drones picking targets of opportunity. If you know that MANPADS can easily take down a helicopter then you are already aware that there is decades-old technology already quite able to take down helicopters, and the only difference between the drones you're seeing today and those that can be easily produced today is the product design requirements. reply ahmeneeroe-v2 16 hours agoparentprevEveryone disagreeing with you is only assuming improvements to drones and not the counter-drones (or the counter-counters you mention). reply HenryBemis 11 hours agorootparentI sometimes frequent on 9gag, and someone had posted a video of UKR drones attacking RUS drones/UAVs. I don't remember seeing a speedometer on the feed of the attacking (UKR) drone, but if I can estimate it was at least (RUS UAVs) 80-100km/h (just cruising/spying) while the (UKR) drones were coming in at twice the speed. Considering how UAVs and/or smaller drones have evolved and used in the battlefield the past few years, we need to rethink the way to conduct war. > assuming improvements to drones and not the counter-drones And I think we just began. The good thing about this (if there is ever a good thing in war/death-dealing) is that a drone carrying a small explosive device to release it over a vehicle will not kill 10k civilians. reply actionfromafar 7 hours agorootparentOTOH drones are used by Russian forces for \"human safari\" hunting in cities now, so war crimes will always find a way if the will is there. reply torginus 11 hours agoparentprevHonestly I don't want to sound like a smartass and second-guess you, but the main problem with attack helicopters imo is that they are expensive to buy and operate, going comfortably into lower-end jet fighter territory, so to justify their existence, they need to possess some indispensable qualities. I'm not sure what those are, but I think they probably have to do with the ablity to hover in place/land anywhere, a capability probably much more meaningful in transport helicopters. And it seems the US has decided to choose the V-280 Valor, which is a tiltrotor rather than a helicopter. I don't follow the space closely, but it seems to me there's no active program in the US that's developing a combat helicopter that's likely to enter service, so I don't think the US military considers them to be worth investing in that much. reply MarkMarine 4 hours agorootparentAn AH-1Z costs about 4,500$ an hour to operate, a F-15E costs about 29,000$ an hour. Helicopters can operate from basically anywhere you can drive a fuel truck to, jets not so much. You’re talking about a tilt rotor to replace a troop carrying helicopter, it’s a different role with different requirements. The AH-1Z is more like the A-10 warthog than a traditional jet fighter, and in the wars we’ve been in recently serves a similar role, close air support. To the Marines on the ground, they are indispensable. The airframes were “just” (in the terms that make sense for an airframe that has been in service since the late 60s) upgraded to 4 rotor with a number of other updates. Being able to literally point at the enemy and have the pilots see you and put ordinance where you are pointing… that is way way different than trying to call in strikes from jets or freaking arty as some people were saying. reply virtue3 11 hours agorootparentprevthe united states stopped investing in them because they're more of a near-peer type weapon. They are absolutely devastating to columns of tanks. And they help control the \"z-axis\" the the united states military is dependent on. Helicopters give you the ability to have air \"presence\" and keep situations in check with low-peer adversaries. When you start bringing in MANPADS or stingers the game changes. Oddly enough things like the US Javelin anti tank system and the british NLAW are making tanks relatively obsolete as well. I suspect attack helicopters with some sort of very small automated phalanx system (directed energy weapon? net launcher?) to destroy drones would be incredibly effective still. The Apache is still an effective platform for delivering a shit ton of ordnance down range from out of no where and then skidaddling. reply torginus 8 hours agorootparentThe Russian Ka-52 has a soft-kill system that can blind the IR seekers of Soviet and US MANPADS the Ukrainians use. We've seen videos videos of it working... about 70% of the time, which means you have to shoot it 3 times instead of once, but it goes down just the same, and that's not saying anything about bullets, which you can do nothing about. I think modern military doctrine dictates that you shouldn't even give a chance of an enemy to shoot at you. I don't think they are a near peer weapon at all. Even small groups can have weapons that can hurt it, in contrast with an F-16, which, unless you have an air force of your own, or anti-aircraft batteries, you can do nothing about. reply MarkMarine 4 hours agorootparenthttps://en.wikipedia.org/wiki/ALQ-144 reply sofixa 9 hours agorootparentprev> They are absolutely devastating to columns of tanks Artillery or missile strikes are too. reply Sephr 17 hours agoparentprevI imagine that moderately sized autonomous VTOL jets will eventually become cheap enough to completely displace attack helicopters for most use cases. reply richardw 17 hours agorootparentI’d think a variation (vary size, shape to suit task) of this with weapons would do well, since it’ll already be replacing the black hawk. https://en.m.wikipedia.org/wiki/Bell_V-280_Valor reply nostrademons 16 hours agorootparentIt's interesting to look at the design of FPV racing drones today: https://www.youtube.com/watch?v=9pEqyr_uT-k When they fly, they basically turn horizontal, relying on body lift + vectored thrust. They're small enough, with high enough power/weight ratios, that that's enough. Apparently there's no need for a tilt-rotor, because the whole airplane becomes a tilt-rotor. Similar principal as cruise missiles, which have short stubby wings to augment body lift + vectored thrust. When the airframe gets light enough, you don't need much in the way of wings. reply swagasaurus-rex 14 hours agorootparentThe french designed a plane in the late 1950s that would take off vertically, and its wings were a tube. https://interestingengineering.com/videos/this-bizarre-plane... There were a few drawbacks. It required a seat that pivoted 90° forward, so that when pilots could see when taking off and when landing. Unpowered landings would inevitably result in damage to the airframe. Powered landings looked like space-x rockets, and were at the time difficult to pull off, as their instrumentation and and flight systems weren't developed enough to reliably land vertically. They noted the airframe would have a habit of spinning when hovering vertically. It was cancelled after a failed test flight, but with modern technology I think one could be built flightworthy. The plane does look cool, and would fulfill a critical role of a jet aircraft that can be launched without a runway. reply nostrademons 2 hours agorootparentNote that most of the downsides there relate to having a pilot that you want to survive in an emergency. Get rid of the pilot, and you get rid of a lot of constraints on size, weight, G-forces, survivability, emergency response, etc. reply richardw 16 hours agorootparentprevThat thing is amazing. I suspect optimised for shorter distance and dynamism, whereas I think the 280 is basically a faster helicopter that can cruise longer distance? Not expert, just wondered about the tradeoffs given the relatively bad safety record of the v22 Osprey it replaces. So this is an Osprey, but better and safer because simpler mechanics. On new approaches, I saw something about new US missile research where they get rid of the fins and point the nose to turn. My Google-fu is failing me though. reply rjurney 15 hours agorootparentprevThey stall and aren't maneuverable at the speeds you need. reply nradov 16 hours agoparentprevAttack helicopters might still have a limited role in some theaters. But the Marine Corps seems to realigning to fight China in the Western Pacific where, regardless of survivability, regular attack helicopters lack the range and speed necessary to be relevant. They might also face a threat from manned fighters which are potentially very dangerous to helicopters, even those flying evasively at low altitude. Thus the shift in force structure away from attack helicopters and towards the F-35B. I'm not trying to argue with you and I appreciate you weighing in with firsthand expertise. It's just that current USMC leadership seems to be focusing on different priorities. reply rjurney 15 hours agorootparentWell, actually helicopters are already critical in both anti-submarine and anti-ship warfare. They can extend range and distribute shots of anti-ship missiles to make concurrent salvos from multiple directions more deadly. reply nradov 14 hours agorootparentWell, actually you missed the point of the original article and of my comment. No one is claiming that all military helicopters are dead, just attack helicopters. The helicopters used by naval forces for anti-submarine and anti-surface warfare (along with other missions) generally aren't classified as attack helicopters. reply rjurney 3 hours agorootparentI did not miss the point of the article, I just don't get his interest in medium helicopters when the missile he wants 8 of on a medium helicopter weighs 100 pounds. reply Log_out_ 12 hours agorootparentprevnot true sub launched drone variations include helicopter like platforms . reply sneed_chucker 22 hours agoprevPart of a broader pattern in military technology right now. All weapon systems that consist of an expensive vehicle and an expensive-to-train crew are being re-evaluated against drones right now. If you're fighting a highly asymmetric conflict where your enemies can barely touch your expensive toys then it's less of a concern. If you're fighting near-peer it's a different story. reply OliveMate 20 hours agoparent>All weapon systems that consist of an expensive vehicle and an expensive-to-train crew are being re-evaluated against drones right now. Worth mentioning that this already happened to an attack helicopter 20 years ago! The Comanche[0] was a revolutionary recon/attack helicopter with some mental stealth engineering behind it - everything from limiting sound profile via blade design & fenestron, a radar presence a fraction of an Apache, they even directed the exhaust down the tail boom so that the heat generated could easily be dissipated by the tail rotor! Unfortunately for helicopter nerds, UAVs were a fraction of the price, suitable for recon and attack, and pilots could survive it being shot down. [0] https://en.wikipedia.org/wiki/Boeing%E2%80%93Sikorsky_RAH-66... reply navbaker 19 hours agorootparentI spent tons of hours as a kid playing Comanche on our old 486! reply vFunct 17 hours agorootparentMy game of choice was Gunship on the Commodore 64, the AH-64 Apache attack helicopter simulator from Microprose. Spent YEARS playing that. Best part was the instruction manual that came with it that was basically a guide of all the military equipment of the Soviet Union that you could target in the game. reply CoastalCoder 12 hours agorootparentMe too! And in retrospect, it's amazing what they managed to pull off with the C64's limited hardware. reply xbar 17 hours agorootparentprevThank you for mentioning it. It was a revelation. reply the_af 17 hours agorootparentprevGunship 2000 here! I loved that it had a dynamic campaign where the frontline moved according to how well you did. Before that, I also enjoyed LHX. > Best part was the instruction manual that came with it that was basically a guide of all the military equipment of the Soviet Union that you could target in the game. Do you remember what the copy protection was for MicroProse's F-19 Stealth Fighter? It was the silhouettes of US and Soviet fighters and bombers from the Cold War era: \"identify this aircraft\". Somehow they thought my teenage self, obsessed as I was with Cold War military tech, wouldn't learn the shapes. It's how I learned the shapes of most fighter jets. Yes, I had a pirated copy. We all did back then, legal games were unheard of. reply alisonatwork 17 hours agorootparentIf you remember LHX fondly, there's a new game out with similar aesthetic: https://store.steampowered.com/app/1906230/Thunder_Helix/ Still EA for now, but it looks promising. reply debo_ 16 hours agorootparentWow, it looks almost exactly like LHX. You weren't kidding. But can I watch from the viewpoint of my TOW missile camera, I wonder... Thanks for the link. reply keyle 12 hours agorootparentThat guy has been very active on twitter since the start of the development of the game. I don't have his account anymore since I stopped caring about twitter but ... he's probably still there journaling! -- edit: I don't like half assed comments so I went and dig him up https://x.com/HiddenAsbestos reply pferde 10 hours agorootparentprevI only learned like 4-5 of those shapes, and kept restarting the game until I got one of those. :) reply debo_ 16 hours agorootparentprevComanche, LHX Attack Chopper, Gunboat and Wolfpack. A handful of military sims meant hundreds of pages of specs to sift through -- best copy protection I ever had to deal with. I probably spent more time reading the manuals than I did playing the games. reply mdaniel 16 hours agorootparentSame fond memories about LHX and F117A. While searching, I was shocked how much my recollection of that experience vastly differed from its actual graphics: https://www.myabandonware.com/game/lhx-attack-chopper-xo#scr... I don't recall having played Comanche in order to compare the two. The other game I spent innumerable hours in was F117A [1] - partially because -- again, my recollection -- one had to damn near real-time fly from the base to the target and then back, all the while in stealth mode, which usually meant going slow and terrain hugging 1: https://www.myabandonware.com/game/f-117a-nighthawk-stealth-... reply animal531 11 hours agorootparentI played F-117A, but my favourite by far was definitely F15 Strike Eagle II: https://www.myabandonware.com/game/f-15-strike-eagle-ii-n6 Around the time of F-117A I discovered Jetfighter II which felt a lot smoother handling wise, it was great to just fly around doing stunts to be honest. I spent a lot of time just doing carrier take-offs with an immediate 360 and back into landing. https://www.myabandonware.com/game/jetfighter-ii-advanced-ta... reply debo_ 16 hours agorootparentprevYes, I also played a ton of F117A. The terrible graphics were actually what let me run it and LHX, I had an anemic 386. I only got to play Comanche at my uncle's house. LHX actually looks exactly as I remember it. I remember those blocky polygons very fondly. reply 01HNNWZ0MV43FF 14 hours agorootparentprevI remember Wolfpack! Never figured it out, I was way too young reply hyperbovine 18 hours agorootparentprevThe voxel-based graphics and resulting frame rate were one of those distinct “wow” moments I had while gaming as a kid. Up there with playing Doom or Flight Simulator for the first time. reply animal531 12 hours agorootparentprevToday its graphics look so outdated, but back then it was amazing how you could fly through valleys to get to targets. There were a few games like Comanche, X-Wing, Magic Carpet and Descent that felt like they really pushed the technology while trying to show how we could utilize 3d in a different way from the other titles of the time (which were usually all FPS games). reply navbaker 2 hours agorootparentOh yes, I found Comanche after playing Tie Fighter to death! reply rjurney 15 hours agorootparentprevFlying down canyons was so much fun, like a trench run. reply shiroiushi 19 hours agorootparentprevYeah, that was an amazing helicopter, and it's really too bad it was cut, but as you say, it just didn't make economic sense any more when UAVs were invented. I guess it's something like the Japanese battleship Yamato, with the largest guns ever installed on a warship. It was amazing, but easily sunk by airplanes flown from aircraft carriers, so it was already obsolete when it was launched. reply ldargin 12 hours agorootparentI worked with a former army officer / test pilot who was formerly involved with the Comanche project, when the news came out that it got cancelled. He was quite disappointed with that, and disagreed with what was said about it's survivability. He said if they can't see you, they can't shoot you. reply sofixa 9 hours agorootparent> He said if they can't see you, they can't shoot you. He should tell the F-117 pilot who got shot down with a few decades old anti-air system that, while keeping in mind that the F-117 flew higher and faster and quieter (relatively). reply faggotbreath 7 hours agorootparentnext [6 more] [flagged] sofixa 6 hours agorootparentAnd still, it was supposed to not be vulnerable to enemy radar. And a multi decade old anti-air system, with the benefit of good intelligence and incredibly sloppy American operations, managed to shoot it down. Why would anyone think a helicopter that would be flying much lower to the ground, would be invulnerable to e.g. man portable air defence systems? reply onepointsixC 5 hours agorootparentBecause low flying aircraft are harder to detect than high flying aircraft. More over when their rcs has been significantly reduced. It’s not “invulnerable” no more than any stealth aircraft, submarine, tank, or any other platform is. It’s significantly harder to defeat. reply sofixa 5 hours agorootparent> Because low flying aircraft are harder to detect than high flying aircraft From afar. But an attack helicopter will by definition be near the battlefield/enemy, so they'll have plenty of opportunities to see it and react. reply red-iron-pine 3 hours agorootparentprevit wasn't vulnerable to enemy radar, serbian AA realized that it was the exact same pattern day in and day out, did some quick calculations, and fired at the spot it knew it would be at the next day. and that worked. reply sofixa 2 hours agorootparentNo, they timed their radar scans so that they caught the F-117 with its bomb bay open. reply bluGill 17 hours agorootparentprevaircraft carriers are even more vulnerable. battleships are obsolete not because they are easy to sink but because airplanes are more versitle for most purposes. When doing a shore assult a battleship is more useful than airplanes but that is not enough to be worth the cost of running them. reply jabl 13 hours agorootparent> battleships are obsolete not because they are easy to sink but because airplanes are more versitle for most purposes. The main reason really is range. A battleship can obliterate a target within about 25 km (yes, I know the guns can shoot longer than that, but practical accuracy against a moving target such as another ship..) whereas an aircraft carrier can launch strikes from hundreds of km away. Further, the carrier can launch reconnaissance aircraft (nowadays with radar obviously, but thinking of the WWII era when battleships were obsoleted) so it's aware of what's happening around it. So it can, say, stay away out of range of enemy battleships, as well as detect enemy targets at long range to launch strikes against. Yes, mistakes can still happen, see the battle of Samar. And yes, the battleship likely has floatplanes, but compared to a carrier, few of them, shorter range, and needs relatively calm seas to recover them. All this being said, yes it took a lot of planes launched from a lot of carriers to sink the Yamato. But due to the range issue explained in the previous paragraph, the carriers could safely do this well out of range of the massive guns of the Yamato, whereas the Yamato could do nothing more than sit there impotently taking hit after hit until it finally succumbed. > When doing a shore assult a battleship is more useful than airplanes but that is not enough to be worth the cost of running them. In principle, yes. But to do that the battleship needs to get awfully close to whatever it's going to shoot at, running the risk of hitting mines, or being targeted by shore-based anti-ship missiles etc. And if you already have the overwhelming superiority to get rid of all such enemy systems before bringing the battleship in, why not use those same assets to hit the same targets the battleship would hit in the first place? reply bluGill 5 hours agorootparentYou are mostly correct, except for one key point: the battleship was armored so that it could get close to the action and have somewhat reasonable chances of surviving. Most ships today could not take near the hits the Yamato did. (the Yamato shows why it is pointless to try) reply picture 12 hours agorootparentprevAgreed. Super pedantic comment: it's Battle off Samar. reply ethbr1 16 hours agorootparentprevOne reason airplanes are more versatile is because they're modular. You can swap a carrier air wing to 2 years newer planes. You can't swap a battleship to 2 years newer tech. reply bluGill 5 hours agorootparentThe versatility is about range. That you can swap them out is a nice bonus, but range compared to the big guns is the real key. reply lazide 16 hours agorootparentprevAirplanes can do over the horizon missions. Battleships aren’t useful for that. Missile cruisers/destroyers are the battleship replacements. But airplanes can also carry and launch missiles even better, with some warning and planning. Battleships are useful for the naval equivalent of a bar brawl or a street gang fight. Aka up close, nasty, ‘punch them in the face until they can’t get up again’. They’re the equivalent of Mike Tyson in his prime for that. Which even now would have some PR value, and no matter the time period will always be a spectacle. But tactics have evolved more since then, and we just don’t have those type of fights that much anymore. And when we do, we just bring a ‘gun’ instead of relying on our ‘fists’. Of course, anything is possible and maybe we’ll turn New Jersey into a spaceship to fight our space naval battles in a hundred years. Odds are low though. reply d1sxeyes 10 hours agoparentprevWhile this is inevitable, I wrote a blog post once upon a time about the trend this generates and why I'm worried about it. In principle, wars between armies are proxy wars between nations/governments/etc. A long time ago (Sumeria maybe), soldiers started to fight soldiers, and civilians could get on with civilian life while fighting continued (farming, production, etc.). Now obviously that doesn't mean that no war has ever had civilian casualties, or that armies have never targeted civilian populations, but it made warfare a fairly symmetric endeavour. Rather than having your farmers hacking at each other with hoes until there are no farmers left, you can pit some of your strongest and best trained men against your enemy's strongest and best trained men, and accept the results of that to avoid total annihilation of your whole populace. But that only works because both sides have skin in the game, and people are dying on both sides. If we move to a model where a stronger power can fight a war remotely with no risk to real people, then the only way to take the war to the enemy will be to target civilians. Terrorism, asymmetrical warfare, etc. will be the only way to respond to drone strikes and the like. I don't know what the answer is, but it worries me. reply pjc50 8 hours agorootparent> If we move to a model where a stronger power can fight a war remotely with no risk to real people, then the only way to take the war to the enemy will be to target civilians. Terrorism, asymmetrical warfare, etc. will be the only way to respond to drone strikes and the like. This is hardly new, it's been the reason for the prevalence of suicide bombings in the Israel/Hamas war for decades. reply d1sxeyes 9 minutes agorootparentThat’s slightly different. The Israel/Palestine conflict is already bound to be asymmetric due to one being occupied by the other. reply HPsquared 22 hours agoparentprevEfficiency starts to matter in a near-peer conflict. reply Retric 22 hours agorootparentNear-peer conflicts have more meaningful targets which favors these kinds of expensive weapons platforms. A drone that can do meaningful damage to a factory 500+ miles from a front line is either an easy target or it starts to look a lot like a missile with all the associated costs from that. reply torginus 21 hours agorootparentI think it's more complex than that. The US made Switchblade drones which cost tens of thousands of dollars were outperformed with lightly modified FPVs with grenades, which came in under a thousand. reply SJC_Hacker 20 hours agorootparentWe don't know if they underperfomed so much as weren't cost effective. If the switchblade costing $10k results in a kill 80% of the time, while the $1k drone is 30% of the time, you just get 3 times as many $1k drones, average about the same kill rate, and save 70% to boot. Or spend the same amount and get about 3x the kill rate. reply jandrewrogers 20 hours agorootparentIt is not just production cost, the average latency between target detection and target destruction has a large impact on battlefield dynamics. More precise weapons can destroy most of the capability of less precise weapons before they are ever used. Additionally, precision weapons typically have a much smaller logistical footprint, and logistics can make or break military campaigns. Much of the US focus on precision terminal guidance is derived from this calculus in a straightforward way. It may be more expensive in a unit cost sense but significantly cheaper in terms of net expected effect on the battlefield. This \"precision versus quantity\" argument played out to greatly favor precision in Ukraine. reply SR2Z 19 hours agorootparent> This \"precision versus quantity\" argument played out to greatly favor precision in Ukraine. Yes, but the defining attribute of the Ukraine war seems to be CHEAP precision - the ability of drones to respond and attack car-sized targets in real time is what has turned this war into a slog. The American-made stuff is great, but I've seen multiple examples of Ukrainian missile crews reacting contemptuously to the idea that they could use a Javelin/NLAW to take out an older Soviet piece of equipment; that kind of task seems to be reserved for Soviet-era weapons or (preferably) drones. reply nine_k 17 hours agorootparentOTOH the highly precise HIMARS played a crucial role many times. Regular artillery has to shoot dozens of shells before it hits the exact high-value target. This betrays the position of the cannon; if it's close enough it will be fired at. HIMARS is precise so it can pack up and leave before the projectiles even reach the target. FPV drones are precise because they're remotely piloted by experienced pilots. This allows them to inflict large damage with small payloads applied at a critical point, Luke Skywalker-style. reply khuey 13 hours agorootparentHIMARS is highly effective exactly because it's cheap precision. An air force capable of executing the missions that HIMARS can would cost Ukraine many many billions of dollars. HIMARS clocks in at $5M per truck and $200k per rocket. reply SJC_Hacker 2 hours agorootparentprevHIMARS is precise, but my understanding maybe 25% are actually getting through to their targets these days. But still until recently Ukraine didn't have anything of comparable capability reply nine_k 2 hours agorootparentMuch like 30% of Russian drones are not actually shot down but driven off course by EW these days. Things progress at a ridiculous pace in a high-stakes environment like a war for existence. reply InDubioProRubio 10 hours agorootparentprevFPV-drones can also be precise post-mortem. You record the flight as command-inputs in sim from start location. Then you deploy the drone from some carrying vehicle, land and loiter, listening for a trigger. Trigger comes, the drone flies only gets a connection for a lineup if any and flies through the \"line up\" trajectory. Pilot involvement can be optional. reply nine_k 3 hours agorootparentShould work as long as the drone's inertial and visual navigation stay adequate. (I suppose that GPS and the like gets constantly jammed near high-value targets.) reply QuiteSocialized 1 hour agorootparentprev\"What is the Kelly Blue Book value of a 1989 Toyota Hilux?\" reply nostrademons 19 hours agorootparentprevThe reason drones are kicking butt right now is because you get both precision and quantity. Advances in electronics, software, communication links, and sensor technology mean that you can make guidance systems as a hobbyist that would be a million dollar missile from a specialized defense contractor just 15 years ago. You lose range, but urbanized warfare of the 21st century seems to be a very different battlefield calculus from the strategic bombing campaigns of WW2. The vast majority of engagements these days seem to be within easy drone range, probably because they can be produced in quantities that negate the \"just destroy everything within 200 miles\" strategy of WW2 carrier battle groups. reply ethbr1 16 hours agorootparentAlso small drones, which is to say smart grenades, are a counter to trench warfare. reply nradov 16 hours agorootparentprevThe fact that recent engagements have been within easy drone range is an accident of geography. The same situation won't necessarily obtain in the Western Pacific. The quantity of drones you can produce won't matter if the launching platform can't survive long enough to get within range of the target. reply nostrademons 49 minutes agorootparentThis gets complicated, because technology usually advances on multiple fronts at the same time. As others have mentioned, we've seen drones primarily used as an air-to-ground weapon in Ukraine because the airspace is not particularly contested. We have not yet seen them used in air-to-air combat. There are multiple reasons to believe that drones' advantages over piloted aircraft are even greater than drones' advantages over tanks. Take the pilot away and the G-forces you can pull increase many-fold. Take the pilot away and you have no compunctions against sacrificing a drone for tactical advantage. Take the pilot away and you can field 10x or 100x as many aircraft, since pilot training is often the limiting factor in the growth of your airforce (see eg. Japanese WW2 experience from 1943 onwards, or the need for Top Gun in Vietnam). More aircraft can play airspace denial, since the presence of a bogey creates a kill zone in the area where they can bring their weapons to bear. Computer algorithms can play physics and geometry games where no matter where a piloted aircraft turns, there is always something waiting to shoot them down. Computers can run these simulations instantly, overwhelming the pilot's ability to react. The human becomes the weak link in the weapon system. The equilibrium I see is drone designs with a range made to just out-range cheap weaponry like glide bombs and common anti-ship missiles, maybe 50-80 miles. For anything fancy (like the supersonic cruise missiles that the Russians have with 200-300 mile range), you want directed energy CIWS instead, but you need those anyway to defend against enemy drones. Then you pack these drones into shipping containers, and launch and retrieve them directly. A single container ship carries its own air force of roughly 10,000 drones, and makes the airspace around it out to ~100 miles completely inhospitable for foes. The convoy becomes its own aircraft carrier, just like the escort carriers of WW2, but the air wing follows the shipping containers and can be packed onto trucks or rail at its destination. Then you bring the convoy to where it needs to be, creating a no-go bubble around it at all times. reply ajb 14 hours agorootparentprevYeah, although given the number of TEU shipped from China to the US, I would not count out a significant number of drones having been prepositioned in US territory. reply wongarsu 18 hours agorootparentprev> This \"precision versus quantity\" argument played out to greatly favor precision in Ukraine With artillery that's certainly true. On the other hand, Ukraine moved from expensive Bayraktar drones in 2021 to primarily drones in the 1k-10k price range today. Cheaper weapon systems allow them to be deployed in more places. Getting 5000 drones for the price of 5 drones might be worse for logistics, but it also means some will always be where you need them, doing wonders for the latency between target detection and target destruction. reply torginus 12 hours agorootparentprevThose FPV drones (either of the bombing or suicide variant) seem to be precise enough - there's plenty of footage of them hitting moving vehicles in weak spots like engines/hatches, individual soldiers etc. As for AI features when the comms are jammed, Russian lancet drones, which have some autonomous capability, seem to be running on Nvidia Jetson boards, and those things cost like $200. reply dgroshev 7 hours agorootparentWould you ever see footage of them not hitting weak spots? reply SJC_Hacker 3 hours agorootparentprevI'm not just including precision, but ability to get through defenses - i.e. total battlefield effectiveness. Precision in terms of \"circular error probability\" isn't the biggest issue now. Its the EW environment. My point was if system A gets through defenses 30% of the time, but is 10x cheaper than system B which gets through 80% of the time. System A is generally the better choice, except for some very specific circumstances, very high value targets with limited strike opportunity. reply zmgsabst 15 hours agorootparentprev> Additionally, precision weapons typically have a much smaller logistical footprint, and logistics can make or break military campaigns. Only if you exclude manufacturing. > This \"precision versus quantity\" argument played out to greatly favor precision in Ukraine. Until the allies of Ukraine fell behind on artillery manufacturing — allowing Russia to gain dominance and grind down the Ukrainian military. That mass produced artillery out sustained precision munitions is a major lesson in Ukraine’s defeat. reply aguaviva 15 hours agorootparentIt's one thing to make a speculative assessment, or a prediction. But the use of the implied past tense in reference to a situation that has many variables and which in any case is far from decided is definitely quite pretentious. reply zmgsabst 7 hours agorootparentI don’t think anybody serious questions the outcome of the Ukraine war — as evidenced by the international realignment caused by NATOs defeat, increases talk about Ukraine relinquishing ground, etc. What event do you believe could change the outcome at this point? And since Ukraine was defeated, we can discuss why: their inability to match artillery exchanges for most of the war. reply aguaviva 6 hours agorootparentSince you not only \"know\" the outcome, but it apparently it's ancient history for you already - why are you asking? reply lazide 13 hours agorootparentprevHaha, since when is Ukraine even close to defeat? Defeated enemies aren’t making regular incursions into the ‘victors’ land which the ‘victor’ can’t stop, or launching attacks agains the ‘victors’ capital. This just reads like Russian delusion/cope. reply zmgsabst 7 hours agorootparentWhat are you talking about? Kursk was stopped after small gains and prior to any major captures — with Ukraine losing their best units. That loss has led to cities along the line of battle being captured, including the fortress city of Vuhledar. There’s now increased talk of Ukraine giving up territory — which is their defeat. Edit due to rate limit: You’re citing areas Russia withdrew from during the Istanbul talks as “lost” while ignoring that Russia posses 18% of Ukraine and is advancing. Russia isn’t losing “more and more control” on any front, they’re forcing Ukraine back — including driving Ukraine from places like Vuhledar they’ve held for the entire war until now. To use your Canadian analogy: It would be like if the US seized the 20% of Canada closest to the continental US and then proceeded to shell Canadian army to dysfunction from there — which would be seen as a sane and effective strategy. reply lazide 7 hours agorootparentOh talk. [https://en.m.wikipedia.org/wiki/Russian-occupied_territories....] Looks like Russia has lost everything but a tiny portion they gained, at immense cost - including the near total collapse of their economy. And are going to be locked in trench warfare on land they don’t control, with uncertain supply lines, with no air superiority - going into winter. And is losing more and more control of the little they have left. This is Russia’s Afghanistan writ large, and will lead to the total collapse of the Russian gov’t (and society) soon. It’s already nearly destroyed an entire generation of Russian men - in the middle of an already epic demographic collapse. Don’t get me wrong, this has wrought terrible damage to Ukraine too. But with Russia’s economy (previously) and population being 10x larger, this whole debacle is a huge embarrassment to Russia. Even bigger than the collapse of the USSR. It would be like if the US went to invade Canada, and couldn’t even hold Ottawa. Edit to answer your edit: maybe if the 18% was the land near Alaska. And they’re at almost the same amount of land they had control of when this whole mess started. All the major economically productive areas of Ukraine are still under Ukraine’s control. reply meiraleal 7 hours agorootparentprevZelenski (which presidential term ended) complains every day that they can't properly fight with what they have. This looks like losing for me reply lazide 7 hours agorootparentThat’s called fundraising. reply meiraleal 6 hours agorootparentNo, it is called a losers fundraising reply sgc 18 hours agorootparentprevSince they are ramping up to build switchblades in Ukraine [1], I would say they are a quiet success. They were just extremely overhyped before they got there. [1] https://kyivindependent.com/us-company-aerovironment-plans-t... reply pletnes 1 hour agorootparentI’m guessing they just don’t have camera links so they don’t make the best videos, i.e quiet sucess reply sgc 2 minutes agorootparentThey have camera links. I think it is US opsec requirements keeping the videos to a minimum. fullspectrumdev 10 hours agorootparentprevThe 600 is significantly better than the 300 (which was provided in higher numbers). Odds are there will be local adjustments made - different, more robust radio link and such to replace the fucking shit one that originally came with the switchblade. reply closewith 16 hours agorootparentprevThe reality is that Ukraine is producing 300,000+ drones per month, so the ratio is closer to 10,000:1 cheap drones to Switchblades. No Western military is prepared for a ground war with hundreds of thousands of drone attacks per day, which is what near peer would mean now. reply fullspectrumdev 10 hours agorootparentprevSwitchblade cost closer to 50k$, its payload was around 100 grams of explosive, and its range and success rate in the electronic warfare heavy environment of Ukraine are lower than a 300$ FPV that can carry 1.5kg of explosive. Switchblade was designed for a different war entirely. reply rolandog 20 hours agorootparentprevAnother thing commonly left out of these napkin math scenarios is cyber security risk... it may make sense to cut down on human resources, but you better make sure your drone fleet won't be commandeered by an adversarial nation-state's script kiddies. Cheaper to make, but perhaps also cheaper to have them turn on you. reply theelous3 18 hours agorootparentConsidering we're looking at an adversarial nation state (famously full of script kiddies) which is absolutely hell-bent and motivated to tackle their drone problem, and not once has that state or its script kiddies commandeered a single drone - nevermind a fleet of them - (nor are the script kiddies even remotely in range?) I don't see this being a problem now or in the near future. reply Eisenstein 18 hours agorootparentIt isn't a problem until it is one, and the it can be a huge problem. I don't know anyone who was ever made to look foolish saying 'it is improbable, but let's prepare for it anyway' whereas plenty of graves are filled with people who said 'that will never happen'. reply SJC_Hacker 3 hours agorootparentSadly generals, or at least the high command, tend to fight the last war, and tend to be fairly conservative. WW2 was a classic example. Every nation except the US still had bolt-action rifles as the standard infantry weapon, on the belief that giving every infantryman semi-auto was a waste of ammo/too expensive/too heavy on logistics. Also motorization was not appreciated until late in the war, even in the German army - which despite all the attention devoted to the panzer/panzergrenadier divisions, was maybe 20% motorized at its peak. Mostly their soldiers marched from place to place, or used rail. There is kinda a reason for this, that there are counter examples were new tech wasn't all it was hyped to be. And until something is battle tested, its hard to say how it would perform. Like early in the Vietnam war, US infantrymen may have been better off with the old M1 garand, because early models of the M16 tended to jam in combat conditions. reply guappa 13 hours agorootparentprevYes, not a problem at all. It never has happened before. Oh wait! https://en.wikipedia.org/wiki/Iran%E2%80%93U.S._RQ-170_incid... reply torginus 12 hours agorootparentprevI just wonder how much does professional image comes into play. I can't imagine US troops using drones which are basically a bunch of PCBs screwed together and mounted to a sheet of laser cut carbon fiber, even if those things are technically the most cost effective way to build a drone. reply JohnBooty 17 hours agorootparentprevI would think there are other advantages to large numbers of cheap drones too. Trying to defend against 3x-10x as many enemies brings its own challenges, even if each one is less lethal. reply OrigamiPastrami 20 hours agorootparentprevYour analysis assumes collateral damage is irrelevant. reply pclmulqdq 18 hours agorootparentRussian military doctrine favors collateral damage. I think part of the US's love of precision weapons comes from the fact that they media will go nuts if the US kills non-targets. 20 civilians dying in Iraq to a helicopter that thought their camera was a gun was a national embarrassment. For Russia, 100 civilians dying in a mass artillery bombardment is a normal workday. reply guappa 13 hours agorootparentUSA doesn't kill many civilians because Obama defined that \"if you die in a drone attack you weren't a civilian\". https://www.thebureauinvestigates.com/opinion/2012-05-29/ana... reply hnbad 11 hours agorootparentSpecifically, the US considers anyone who is male and \"of fighting age\" not a civilian - and the \"male\" part is often optional. This does somehow still result in a lower ratio of dead civilians than when applying the same definitions to Russia or Israel. This shouldn't be seen as a way to excuse the behavior of the US but rather as a way to recontextualize the actions of the latter two, whether you support or oppose their military operations. reply guappa 8 hours agorootparentI don't think it helps anyone to separate what israel does from what USA does. Everything that israel does is authorized and aided by the USA. It'd all stop the very second the USA told them to stop. Related reading. https://chomsky.info/20210512/ reply mcphage 5 hours agorootparent> It'd all stop the very second the USA told them to stop. What makes you think that? And which “the USA”, since Netanyahu has been in discussions with both Biden’s administration, and Trump. reply hajile 4 hours agorootparentprevPeople are really misinformed about the Ukraine war. Russia cares about civilian casualties more than Ukraine (see below) and the total civilian casualties (as reported by both Ukraine and Russia) is astronomically low for such a large-scale war. > Since 24 February 2022, conflict-related violence in Ukraine has killed at least 10,582 civilians and injured 19,875 (30,457 total civilian casualties). This number includes 587 killed and 1,298 injured children (1,885 child casualties) That's from the UN report Feb this year (the latest I know of). They give a breakdown of civilian deaths by region. Nearly 6,000 of those civilian deaths are in places controlled by Russia since the first week of the war which means those civilians were almost certainly killed by Ukraine rather than Russia. Many of the remaining 4000 MAY have been in Russian-controlled areas, but it isn't as easy to determine. Most wars have 5+ civilians killed for every soldier. This war with around 1M dead soldiers has the reverse with more like 100 soldiers killed for every civilian. https://www.ohchr.org/sites/default/files/2024-02/two-year-u... reply sgc 18 hours agorootparentprev> For Russia, 100 civilians dying in a mass artillery bombardment is a normal workday. More specifically, it is a success to them. They clearly use civilian casualty and the terror it brings as a tactic to dishearten their victims. reply hajile 4 hours agorootparenthttps://www.ohchr.org/sites/default/files/2024-02/two-year-u... 10k civilians killed and at least 6k are solidly inside territory Russia has controlled since the start of the war meaning that Ukraine -- not Russia -- has been responsible for the overwhelming majority of casualties. There are evil people on both sides, but the casualty numbers speak very clearly for themselves. This shouldn't be a surprise. I started sporadically following the war since 2014 and there were loads of videos where Ukrainian Nazi units would launch artillery and mortar attacks on 100% civilian areas just to hurt/kill people. reply bluGill 17 hours agorootparentprevthey use it to hearten the folks back home. Civillian deaths mostly make civillians want to support the war and so is not a good idea. In turn this is why the us doesn't reply jajko 11 hours agorootparentprevLast week I've seen russian military coming from 'official' TG channels boasting how they dropped grenades on civilians, Donetsk IIRC. Literally civilians driving in their cars or walking on pedestrian crossing with shopping bags, having grenades dropped on them, killing many including women. Sarajevo tactics all over again, just not serbs anymore (although both societies share a lot in common). Also during beginning of the war there were videos of russian soldiers setting up machine gun posts next to bigger roads and literally gunning every single unsuspecting civilian car that came along... not much better behavior than hamas attack last year. Bucha, civilian mass graves with people having hands tied behind their back with wire and headshot found on territories won back from them. Shows how depraved that society is that this doesn't even cause any upheaval, instead is something to boast about back home and to whole world. Now do a simple projection for next decades. I know China is #1 topic for US right now, but China views US rather as a competitor. Russia views whole west and US specifically as existential threat to actively fight against (and it did in asymetric subversion warfare for past 2 decades). Not whole russian population, they don't give a fuck whether whole world burns as long as they can drink vodka into desperate oblivion, but all their rulers and that's all that matters there. Now how to tackle and survive that due to all the resources required from that land I don't know but future in that regard looks bleak. reply bitkrieg 17 hours agorootparentprevWhat the US public opinion is and what the US government does are two different things. Americans are hilariously self-delusional in that regard. Just compare the civilian death tolls between the first two years of the invasion of Iraq and the first two years of the invasion of Ukraine. For the last twenty years in the Middle East alone, the number of civilian deaths in which the US is either directly or indirectly involved is easily in the millions reply pclmulqdq 15 hours agorootparentUnless you're counting a lot of definitions of \"indirect involvement\" (eg including things Israel does on its own and any proxy wars the Saudis start), you're going to have a hard time counting to 1 million civilians with any authoritative sources. Most of the civilian deaths in the US's \"war on terror\" were to IEDs and other devices set up to kill Americans. People who create studies suggesting those wars killed 5 million people include a lot of ludicrous definitions of \"killed\" to get numbers that big. reply rjurney 15 hours agorootparentWhen you topple a foreign government, destroy all the infrastructure for pointless \"shock and awe\" and then send the ethnic majority but recently oppressed armed forces home... you bear responsibility for the millions of extra deaths that follow when traumatic civil war rocks the nation. You are the exact example of the delusional American he means. reply pclmulqdq 14 hours agorootparentYou are the exact kind of person to demonstrate why the US builds the best precision weapons in the world and doesn't kill civilians if at all possible. If you are going to blame every single death in a conflict, including indirect deaths (eg excess heart attacks) and deaths at the hands of the other party (IEDs laid by the other side), on the US, there's no reason to give you any more ammunition or make your argument seem rational. reply jychang 13 hours agorootparent> You are the exact kind of person to demonstrate why the US builds the best precision weapons in the world and doesn't kill civilians if at all possible. Wait is that a good thing or a bad thing? reply pclmulqdq 13 hours agorootparentNo value judgment, but he's a good demonstration of why the US does the thing he's accusing the US of not doing. The US goes out of its way to minimize collateral damage because it gets accused of causing all collateral damage in the first place. reply rjurney 3 hours agorootparentWe took out tons of infrastructure in Iraq during shock and awe. Utilities were on the target list. We were about to occupy it. That was incredibly stupid. The infrastructure itself was not collateral damage, it was targeted. We have no occupation plan, it was that stupid. The destruction resulted in millions of extra deaths due to the impoverishment and destruction of Iraqi society. Yes, we bear responsibility for all those deaths. You break it, you own it. That's war. reply guappa 13 hours agorootparentprevI mean, USA could stop doing wars everywhere in the world no? It's not like iraq had tanks by the USA border, ready to roll in no? It also didn't have any of the terrible weapons that USA claimed they had. reply pclmulqdq 13 hours agorootparentWhen you are the world police and you stop \"doing wars everywhere,\" everywhere starts doing wars with you (usually through your weaker/looser allies). Hence Ukraine, Hong Kong, the Mexican cartels, Iran's proxy wars, and let's not forget 9/11. In all cases, the US has demonstrated a level of weakness on the foreign stage, and terrible people have come to exploit that. Like it or not, those little wars in Iraq were the long arm of the Pax Americana, which is ending now, to the tune of the first land war in Europe in quite some time. And one of the bloodiest conflicts in recent history. This is what happens when you are a world-spanning empire. An empire, by the way, that Europe, India, China, and the rest of the civilized world has benefitted massively from in the form of free security and safe transport of goods. When there is no dominant empire, the world gets messy. reply guappa 12 hours agorootparentThis needs a very large \"citation needed\" banner. reply pclmulqdq 12 hours agorootparentAh yes, the \"source?\" argument. The classic cry of people who want to disagree but have nothing productive to add to the discussion. I could point you to literally dozens of books on the Pax Americana and its decline (google is your friend) and America's de facto empire, as well as historical studies of the Pax Brittanica and the Pax Romana. Or Chinese histories that discuss the waves of peace and prosperity following the growth of major dynasties which end exactly the same way. I suspect you won't read any of them though, since nobody who asks for a source in an online discussion really wants a source (nobody ever asks for a source when they agree with you). They just want to claim that their counterpart is uninformed. reply lucubratory 10 hours agorootparentThis would be a fantastic copypasta for anytime someone requests you prove the outlandish claims you're making. reply pclmulqdq 6 hours agorootparenthttps://en.wikipedia.org/wiki/Sealioning You want to engage in a debate involving cited sources? What's good for the goose is good for the gander - write a response with a citation or two that rebuts a key point. Otherwise, asking for sources in online arguments is borderline trolling. reply LtWorf 49 minutes agorootparentYou want people to \"read the books\", you better be prepared to say which books… AnimalMuppet 32 minutes agorootparentprevLook. You made the claim; you have the burden of proof. What can be claimed without evidence can be disbelieved without evidence. But also, on an online forum, a post is written once, but read many times. When you say \"look it up yourself\", that doesn't tell one person to look it up, it tells 10 or 100. That's inefficient - the looking up is done multiple times rather than once. And, I can google for why the earth is flat and find plenty of resources. The fact that I can find stuff on google that supports your position doesn't say much. So, yeah. Maybe you could supply some resources that you think are solid, and why you think they are? hnbad 10 hours agorootparentprevThe problem with narrativized framings like \"Pax Americana\" is that they only work if you focus on internal peace. The \"American\" century began with World War 2 (arguably) and was defined by continuous proxy wars and assassinations. The US also didn't stand unchallenged at least until the decline of the Soviet Union (remember: the commies even won the \"Space Race\" before the goalposts moved to putting a man on the moon) but arguably that was also a crucial step in the rise of China as a direct challenger. In the case of Pax Americana the framing is also dubious as it wasn't American dominance that kept the peace in Europe (on this side of the iron curtain) but arguably more the shared market and the necessity of cooperation to recover from the wounds of two world wars while facing the threat of annihilation in the conflict between the US and the Soviet Union. Even in Europe this period was heavily defined by oppressive policing in both East and West Germany (culminating in the fall of the Berlin Wall in the East and the student protests and RAF terrorist attacks in the West), civil war in Northern Ireland (with terrorist attacks reaching deep into England at times), separatist movements in the Basque region, the excruciatingly slow death of fascism in Spain and Portugal, the violent suppression of striking miners in the UK, and the birth pains of neoliberalism and austerity. The \"pax\" in these titles always only applies in a very narrow sense to the affluent in its imperial core, i.e. the American upper middle class of the 1950s or the British bourgeoisie of the colonial era. Even the Pax Romana is not a coherent description of life in the Roman Empire for the time frame it is often applied to and was defined by expansion (i.e. military conquest) not an absence of war. If anything, the \"prosperity\" these terms often imply always only existed because of a hierarchical system of exploitation and the \"peace\" refers to the absence of serious challengers to disrupt this exploitation. The prosperity in Britain during the Pax Britannica specifically only existed due to the violent oppression of British colonies and the absence of powerful challengers to claim those colonies instead. Following the war economies of WW2, the 20th century saw a massive redistribution of wealth and public infrastructure to the financial elites, especially under Reagan in the US and Thatcher in the UK, while colonialism largely evolved from the crude brutal oppression of e.g. the British Raj to loans and privatization, aka \"soft power\" (promoting the production of worthless cash crops for international trade at low margins instead of vital food crops, making the economy dependent on imports to keep the local population fed, or exporting raw resources rather than building up local infrastructure to refine those resources into goods that can be sold at a higher price and thus having to import the finished goods at exorbitant prices). So, yes, for you or I living in the imperial core - whether literally in the US or by extension in Europe - the \"decline\" and the rise of challengers is worrisome and can only be negative. But ultimately, especially to those living outside that core, the challengers are no worse or better than the status quo. reply pclmulqdq 5 hours agorootparentYes, I agree with you that the \"peace\" mostly applies to those in the fold, and the only people who enjoyed a real, enduring peace for the whole time are the middle and upper classes of the very core of the empire. Personally, I would suggest that much of NATO (but not all of it at all times) has had relative peace during this time. The borders of empires have always had belligerents that need \"putting down\" from the perspective of the empire, which means small proxy wars. However, the \"peace\" usually refers to wars between nation-states. Much of Europe's economic policy benefits from the huge subisdy that the US covers them with its guns - a drain of 6-10% of GDP may otherwise apply to NATO countries that find themselves up against Putin (and in a hypothetical world - maybe against each other). The Marshall Plan is also a relatively visible indication of how intertwined Europe's post-WWII growth was done with America's involvement, and when you look at US foreign aid (\"imperial economic stimulus\"), a lot of it today goes to poorer European nations. I agree with you that the EU (post-iron-curtain project) has been, as you suggest, a solely European initiative driven more by European solidarity than US guns. However, it exists in the world of the petrodollar (not any more) and with the quiet reassurance that many of the leading nations in the EU are NATO members. As we have seen with Ukraine, sometimes that NATO membership matters. Empires are always a lot looser than we think - the Roman empire was a great example of this, where the nation-state of Rome (in the modern idea) didn't extend beyond the Alps until the Caracalla years, where Roman citizenship was truly extended to the provinces (note: after the end of the pax Romana). Egypt and the levant were basically completely autonomous, much like the EU is today. reply guappa 9 hours agorootparentprevWhat you call \"policing\" they call \"exploiting\". Every single country that has dared to vote too left wing has had CIA or USA army having something to say about it. This happened in europe, south america, and middle east. > I suspect you won't read any of them though That's very unacademic of you to suspect I won't read \"the books\", which you didn't even bother to list. I have read this book in the summer. Perhaps you want to give it a read and step out of your bubble? https://www.amazon.it/del-marcio-Occidente-Piergiorgio-Odifr... > Pax Brittanica That's now how you spell it. reply phs318u 20 hours agorootparentprevIt’s not that collateral damage is irrelevant. It’s that the calculation as to whether collateral damage is “worth it” in the context of the specific goal/target is usually relative and calculated unemotionally. Some may say inhumanly. reply hnbad 10 hours agorootparentOf course it's also worth pointing out that this question hinges on the perceived cost of collateral damage. For countries like the US which at least ostensibly claim to care about human life indiscriminately and to fight for \"liberty and peace\" and all that, there is a considerable cost to collateral damage, although of course that also depends on who the victims are and the cost can be higher for a Democrat leader than a Republican. Putin's Russia infamously responded to a hostage crisis in Moscow by killing not only all hostage takers but also more than three times as many hostages and injuring most of the survivors. That alone should make it easy to extrapolate what the cost of collateral damage in Ukraine might be in Russia's calculations. Israel similarly seems to use a much lower cost than the US although in Palestine this is also shaped by the perception that anyone who isn't a militant or supports the militant is eventually going to turn out that way anyway (e.g. the child who died would have grown up to become a threat anyway). reply littlestymaar 20 hours agorootparentprevCollateral damage is much less relevant in symmetric conflicts. Nobody is using either a Switchblade or an FPV in the middle of civilian areas in Ukraine right now. reply sgc 18 hours agorootparentRussia is using FPVs to kill civilians on their bicycles or buying fruit, and posting the videos on telegram to laugh about it. This happens every day, it is not a few isolated incidents. It is not boredom, but a chosen tactic. reply kspacewalk2 17 hours agorootparentHere's a great piece[0] about these Russian \"human safari\" tactics in Kherson, written by what seems to be the only Western journalist living in that city. [0] https://kyivindependent.com/human-safari-kherson-civilians-h... reply littlestymaar 13 hours agorootparentprevI hadn't heard of that before, but it really isn't a counter argument to what I'm saying: when you're targeting civilians themselves, you don't have “collateral damage”. reply usrusr 12 hours agorootparentprev\"Look at how much pain we can inflict, you want to be friends with us, that's the only logical conclusion\". That seems to be the explicit strategy here, and I've come to believe that they genuinely think that this is how it should be, that there can't be a different world. Perhaps some linguistic quirk that makes the difference between friendship (that's not based on a power gradient) and allegiance (unite with the strongest, even when they're monsters, in particular when they're monsters) different to express and think about, perhaps it's a long term effect of socialist ideology having co-opted all concepts of friendship based on equality for a system that never was. But the pattern seems to go all the way through society, from the infamous prison hierarchies to imbalanced spousal relationships to the KGB state to the relationship between state power and its barons (who are commonly called oligarchs, but they are the exact opposite, powerless pawns on the political floor that are allowed to hold a fief until they aren't) reply immibis 20 hours agorootparentprevIt is, or it's an advantage. reply thaumasiotes 19 hours agorootparentprev> If the switchblade costing $10k results in a kill 80% of the time, while the $1k drone is 30% of the time, you just get 3 times as many $1k drones, average about the same kill rate, and save 70% to boot. Sanity check: 80% success is an 80% success rate; 3 shots at 30% success is a 66% rate, which is much, much worse. You need 5 cheap 30% drones to beat an 80% success rate, still a major savings at the prices you give, but 70% more than 3 drones. reply szvsw 19 hours agorootparentObviously this is just a binomial distribution, but another thing to consider I suppose would be if all trials are performed sequentially or simultaneously. If performed sequentially, on the one hand, you have a non-zero chance of not needing to expend the subsequent trials; on the other hand, it seems reasonable to think there might be a degraded (or increased!) probability for each sequential trial. If conducted simultaneous, similarly, it seems reasonable to think that that the individual chance of success is higher due to saturation of one form or another, but you are also guaranteed to expend all resources. Point is just that it seems a little silly to try to reductively do these calculations - seems meaningless to try to compare without more information… reply thaumasiotes 19 hours agorootparent> but another thing to consider I suppose would be if all trials are performed sequentially or simultaneously. Yes! That definitely came up while I was thinking about the problem. I concluded that, in cases where you desire to eliminate (1) a particular target (2) under time constraints, only simultaneous attempts make sense. (And that this combination of needs is common.) If instead your goal is to cause random deaths, you can ignore the simultaneous/sequential distinction, treat every drone as having a different target, and just say that 3 30% drones will get 0.9 kills for every 0.8 kills from 1 80% drone. reply EVa5I7bHFq9mnYK 13 hours agorootparentprevBoth 80% and 30% are imaginary numbers, nobody measured it, so all the math is pointless. I've read that it takes 10 to 15 FPV drones to finish off a \"turtle tank\". reply jajko 11 hours agorootparentprevSwitchblade 300 definitely underperformed and disappointed, many many reports from Ukraine frontline, they preferred using normal Mavic 3 drones instead. Switchblade 600 is a bit better but still overpriced what civilian market can deliver at a fraction of a cost, in vast numbers, not blocked by various political negotiations etc. reply onepointsixC 5 hours agorootparentWhat civilian market drone has the 8.5kg explosive payload of a Javelin warhead? Because that’s what the Switchblade 600 has. reply m4rtink 17 hours agorootparentprevWhile the regular Switchblade is essentially a glorified flying granade, many FPVs use RPG7 warhwads and are regularly used to take out tanks (possibly using multiple hits, but still). Also there is a trend recently to see more and more AA FPVs taking down Russian recon drones, some flying up to 3 km high! This already had an interesting side effects of many such drones being covered by expletives or even fake Ukrainian markings - did not really help. reply onepointsixC 19 hours agorootparentprevSwitchblade 600’s have the same warhead as the Javelin. With 8.5kg of explosives, it’s an entirely different category of weapon than the drones you’re thinking of which had closer to 200g of explosives. reply torginus 12 hours agorootparentThere are drones with shaped charges. reply onepointsixC 5 hours agorootparentYou need mass on target to reliably kill heavily armored targets. A drone dropping grenades doesn’t have that payload capacity. reply Retric 19 hours agorootparentprevLightly modified FPVs with grenades are a major concern for soldiers, but so are mortars and artillery shells etc. There’s a lot of low cost long range weapons vs infantry, but a drone with a grenade isn’t really effective vs tanks etc. A fleet of cheap drones just don’t do anything if bomber aircraft can simply fly higher than they can reach. Leave the realm of mass production and you can build drones that would be, but they quickly start looking like existing systems because militaries have been working with drones since WWII. reply bhickey 19 hours agorootparent> but a drone with a grenade isn’t really effective vs tanks You may be thinking of AP grenades, but broadly speaking this isn't true. UA has been dropping RKG-3 anti-tank grenades since early in the invasion. Any drone with a 3 pound lift capacity can knock out armor. https://www.rferl.org/a/ukraine-cheap-grenades-expensive-tan... reply Retric 14 hours agorootparentCan a RKG-3 in the right situation knock out some armor, definitely. But they don’t seem to be that effective vs amor designed to deal with shaped charges such as you’d see with a peer adversary. reply scanny 55 minutes agorootparentThose shaped charges weren’t envisioned coming from directly above, especially precisely dropped on the engine or on hatches, hence the drones are hitting spots with little to no armour compared to the front and sides. reply nradov 17 hours agorootparentprevFPV drones can only work at short ranges (line of sight) or in permissive EW environments. So, not as relevant to a future conflict with China. reply 05 11 hours agorootparentThere are fiber optic FPV drones now with up to 10km range. reply wongarsu 18 hours agorootparentprevCurrently most air-defense systems heavily depend on rockets, so you can just send more of those cheap easy targets than the enemy air defense has loaded rockets. Of course everyone sees this happening in Russia right now and is adapting their next generation, if they weren't already doing so. But that will only shift the sweet-spot for saturation attacks, not eliminating them reply nine_k 18 hours agorootparentThe Israel's \"Iron Dome\" is supposed to include lasers, and they did use lasers to shoot down incoming rockets. In a stationary setting, like a factory or a bridge, lasers can be hard to overload, with their fast targeting, straight-line shooting, and the cost of a shot measured in single dollars. Small / cheap / slow drones with 1-2 kg payload would be an easy target. Tanks / APCs / IMVs / other armored devices that go close to the front line seem like having much more of an existential crisis. reply simiones 8 hours agorootparentThe Iron Dome was easily overwhelmed with the ~200 ballistic rockets fired by Iran recently, many of which hit the military bases they were targeting. So it I think the point stands. reply onepointsixC 5 hours agorootparentIron Dome is for rockets like the one Hamas fires, not for short range and intermediate range ballistic missiles like what Iran fired. Those are very different things and have different requirements. You may as well be talking about body armor ineffectiveness against a tank shell. reply bluGill 17 hours agorootparentprevTanks and the other things you list do much better when used by well trained troops in ways that the trainers tell you to. russia isn't doing that so they look bad but that is russia not the concept reply hajile 14 hours agorootparentYou're talking about a year ago. Today, Russia has the largest and most experienced infantry on the planet. Ukraine tried NATO tactics in last year's offensive and got slaughtered. If they'd tried to bunch up even closer (as some NATO generals were pushing for), the losses would have been far worse inside of those kill boxes. It's not training. Tanks are trivial for spotter drones to find at which point they can die to stuff like drones dropping RPG shells onto the weak upper armor (even the most modern Abrams tanks can be penetrated easily) or even just calling in an artillery strike. The best case for either of these attacks is very often a mission kill and the worst case is a complete loss. Tanks made to fight other tanks are a dead end. The future is pure infantry support. You want something with more armor than a Bradley so it can't be taken out without specialized weapons and with enough firepower to be a must-answer threat, so a bigger cannon than the one on the Bradley is needed. Rifled barrels should probably make an appearance again because they offer better accuracy and HESH rounds are great for infantry support and fortification busting. It also needs to haul troops because you can't afford an extra vehicle that can't hold troops. Merkava shows a path in that direction. reply bluGill 7 hours agorootparentRussia has some evperienced infantry but they have and are using a lot of untrain troops. Even their well train infantry is often still being use wrong for the training. Every military commentator who has credentials to believe they know something [as opposed to say me who doesn't] notes how poorly trained most russians are. This is not soviet war doctine which russia knows and worries nato, it is something new and not expected. NATO tactics have never been used as those start with air power which ukraine doesn't have. NATO hasn't always given good advice but this isn't the way they would fight. ukrane is using tanks as they are made to fight. That isn't fight other tanks if there is any other option. tanks in previous world wars were fighting tanks but not today. Russia is sometimes using tanks like that and there they do well. reply hajile 5 hours agorootparentThe only military commentators saying Russian troops are untrained are pretty ignorant and biased. Russia certainly sent untrained troops in the early part of the war, but most of them were by mistake and got recalled quickly. Russia recognized the need to train their troops (they only sent 100k troops and planned on an early peace that Boris Johnson scuttled). To buy training time, they hired Wagner. Wagner needed bodies, so they recruited untrained guys from prison to die for them (though some small percentage survived and are presumably still working for Wagner). After 6 months of this, the Russian training pipeline started pushing out troops at a steady pace and has been ever since. This is in stark contrast to Ukraine where you get several videos every week from someone who was kidnapped off the streets and sent to die in the trenches 24-48 hours later. A couple guys on my dev team haven't left their homes in months (female family getting them stuff) because they are so afraid of getting shanghaied. As to \"used wrong for the training\", everyone is training/preparing for the last war. Nobody is sure how to train for this war as the only part that has a historical analog is trench storming, but that was over 100 years ago and the tactics have changed. Did ANYONE expect calvary to reappear? I don't think so, but Russian troops are dumping money into buying small motorcycles and dirt bikes so they can mount up and charge the enemy trenches. The real issue for me is that Russia is working out how to fight the new style of war while we in the US are not. Russia is going to walk away from this war with a massive 1M+ army of seasoned veterans while we can barely muster around 70k of active infantry most of whom aren't veterans and NONE with combat experience in the new way of war. reply aguaviva 4 hours agorootparentThis is in stark contrast to Ukraine where you get several videos every week from someone who was kidnapped off the streets and sent to die in the trenches 24-48 hours later. You mean \"sent to training\". It definitely seems strange to suggest that Russia has a smooth, efficient \"training pipeline\", while Ukrainians are brutally sent \"to die in the trenches\". As if their onboarding process is in any way different, or newly trained Russian soldiers aren't also being sent to die in trenches. We all know what war entails, so there's no need for weird, emotionally manipulative language like this. reply bluGill 5 hours agorootparentprevRussia is still sending about 1000 troops to the front lines every day with a week or two of training. I guess that isn't completely untrained, but it is the next thing to and the death totals show that lack. reply oneshtein 10 hours agorootparentprevUkraine tried Ukrainian tactics two months ago and found no Russian army at all. reply nine_k 16 hours agorootparentprevRussian troops are definitely poorly prepared. Likely Saddam's troops were in a better shape in 1991, when the same tanks clashed in Kuwait: Abramses and Chieftains vs T-72s and T-80s. Then the Western tanks showed an overwhelming advantage. Now about a quarter of Abrams tanks in Ukraine were rendered inoperable, some of them plainly destroyed. Tanks did become more vulnerable to anti-tank weapons. reply vasac 15 hours agorootparentThere were no T-80s in Iraq or Kuwait. reply jandrewrogers 15 hours agorootparentprevIn fairness, the Abrams in the Ukraine are ancient export-version M1A1s. The current US standard is A2v4. Other than basic shape, the technology is completely different and several decades apart, the armor bears almost no relation. A lot of the old export Abrams had armor similar to the Israeli Merkava tanks, it didn’t have a lot of similarity to what the US used. Something that gets lost in these discussions is that the US does continuous “Ship of Theseus” upgrades to their systems and they mostly don’t export the state-of-the-art. Abrams armor in US systems is regularly completely replaced with new tech but the details are classified and not exported. reply nradov 17 hours agorootparentprevThat only works in areas like Europe and the Middle East where targets are relatively close. For drones to be relevant in the Pacific fight they'll have to be much larger, faster, and smarter; and thus more expensive. reply titanomachy 21 hours agorootparentprev> near-peer I prefer the Culture term “equiv-tech” reply SJC_Hacker 20 hours agorootparentIts not just tech but capability. You can give some random country F35s, that doesn't mean they are useful. reply pavlov 20 hours agorootparentprevThere’s something icky about discussing killing real people like it was fan fiction of a sci-fi franchise. reply AlbertCory 20 hours agorootparentI guess you don't want to read anything by actual military people, then. Dehumanizing the enemy is a requirement for those folks. reply simonh 20 hours agorootparentThat’s not the case. It happens, for sure. I know some hair raising army jokes, but plenty of military people recognise their opponents as people just the same. reply kergonath 20 hours agorootparentprevIt is also something that must be resisted, because that’s how you get war crimes and genocides. reply sidewndr46 20 hours agorootparentprevI live in the US. A near-peer conflict involves a nuclear exchange. The world will change in ways forever that none of us can ever foresee at that point. reply JohnBooty 17 hours agorootparentA near-peer conflict involves a nuclear exchange Respectfully, I think you're misunderstanding the term. The term is meant to represent the level of resources and weapons each combatant is bringing to the theater of conflict. It does not mean that the two sides are necessarily using the most destructive possible weapons in their arsenals. A hypothetical US/China armed conflict over Taiwan (god forbid) would be \"near-peer\" even if neither side goes nuclear. \"Near-peer\" is meant to distinguish that sort of conflict from, let's say, US vs. Taliban in Afghanistan where the two sides had vastly different levels of technology and capability. Or maybe you're making the point that two nuclear states would be hard-pressed to fight an open war that did not devolve into a nuclear exchange. Which is a very valid concern. If that's your point, I apologize. reply andrewflnr 16 hours agorootparent> Which is a very valid concern. If that's your point, I apologize. It's a valid point to argue, but it does need to be argued, not assumed. reply energy123 19 hours agorootparentprev> A near-peer conflict involves a nuclear exchange. There are many steps on the escalation ladder before a nuclear exchange. reply Demiurge 14 hours agorootparentHow many steps would you guess are left between US and Russia? reply hnbad 10 hours agorootparentGiven that neither side has directly attacked the other yet? Almost all of them. Using nuclear weapons against an opponent who has enough nuclear weapons to retaliate is a \"flip over the chess board and stomp on the pieces\" move. Presently the US isn't even playing against Russia, at best it's sitting behind Russia's opponent and whispering chess moves into their ear. reply energy123 9 hours agorootparentThere's also gradations of nuclear exchange, including a limited exchange (i.e. not against cities) that doesn't necessarily escalate to a strategic exchange. While obviously extremely dangerous and unpredictable, some think you can skirt that line successfully in a war. reply marginalia_nu 19 hours agorootparentprevWorth noting that Russia has nuclear weapons, yet elects not to use them against their near peer Ukraine. reply cjbgkagh 19 hours agorootparentThe old ‘Russia will not use nukes because they have not used nukes’ routine so people can feel safer about poking the bear. There is always a first time and I’m very thankful that it hasn’t happed yet. To me a near peer implies that either side has a good chance of losing the war. It’s my opinion that Russia has not yet been at a real risk of losing this war and thus has not yet had a need to use nuclear weapons. I’m aware that the NAFO line is that Ukraine still has this in the bag - but I still don’t see a Ukrainian victory as a likely. I assume this is why the gp post suggested ‘near peer’ implies nukes. reply kspacewalk2 16 hours agorootparentBoth the US and the USSR lost major wars during the Cold War without resorting to nuking their opponent when they felt they were \"at a real risk of losing a war\". In Vietnam and Korea, the Soviet involvement was considerably more than the current Western involvement in countering the Ukraine invasion. Soviet pilots on Soviet planes killed Americans in American planes. Soviet operators of Soviet-made SAM sites shut down American planes as well. The reality is that nuclear weapons are a deterrent against existential threats, and all else is a bluff. So it's not a risk of losing this war that will push Russia to commit such murder-suicide, but an existential threat to its own survival as a nation. reply simiones 8 hours agorootparent> The reality is that nuclear weapons are a deterrent against existential threats, and all else is a bluff. So it's not a risk of losing this war that will push Russia to commit such murder-suicide, but an existential threat to its own survival as a nation. Note that there have been numerous documented cases of near nuclear launches, especially in the 60s and 70s, it is by no means a bluff or an idle risk. reply kspacewalk2 1 hour agorootparentIt is certainly a bluff. Accidents or misunderstandings aside, the only time the US chose to press the issue as it were was when it faced a serious threat to having its nuclear deterrent rendered completely ineffective (Cuban missile crisis). No one's launched nukes because of non-nuclear events in Korea, Vietnam, Afghanistan or Cuba, and no one will seriously contemplate it over losing pieces of eastern Ukraine or Crimea. Even taking the war into Russia proper won't do the trick, murder-suicide is only on the table when the threat is existential. The bluff does, however, work very well in slowing down and dissuading Western help to Ukraine by cultivating the \"don't do X else nukes tomorrow\" memes and propaganda talking points. Very effective foreign policy tool for a nuclear-armed fascist dictatorship, other will certainly take note for future invasions. reply bigfudge 10 hours agorootparentprevI mostly agree, but it does assume rational actors in charge. If the goal of conflict is to cement the position of a dictatorial elite, it’s not clear to me that ‘smaller scale’ nuclear exchanges are ruled out, especially if leaders are isolated, paranoid etc. reply kspacewalk2 1 hour agorootparentEver since the US made crystal clear that a nuclear strike against Ukraine will mean the US annihilating all Russian forces in Ukraine by conventional means, such small scale nuclear exchange is in fact ruled out. This will in effect invite Russia to simply swallow such a devastating blow, or else end it all. Russia is in fact ruled by rational actors, so it rationally backed off. Thus in effect proving its rationality and the emptiness of its \"but what if we're insane\" bluff. They're not insane. reply keybored 1 hour agorootparentprevEveryone is worried about the desperation nuke. Yet all nukes in history have been to teabag civilians once you’re already winning. reply keybored 1 hour agorootparentSlightly more serious. There have been times where we’ve gotten close during the Cold War. You can’t trust people to not use nukes on account of it being suicidal. People can be irrational like that. And/or chains of command can be irrational. reply onepointsixC 4 hours agorootparentprevThe Russians haven’t used nukes because they’ve been told under no uncertain terms what would happen if they did. reply hajile 3 hours agorootparentAre the French going to destroy their country and kill most of their people for Ukraine? The English? Germans? Anyone in Europe? I can assure you that we in the US aren't going to commit global suicide over Ukraine. Remember that we were all set to sign off on using UK/American missiles to hit targets in Russia. Then Putin said he'd view that as an attack by the UK/America and would use nukes. We immediately backtracked and said our policy wouldn't be changing (Biden seemed particularly unhappy about the announcement). If you know about the whole no-nonsense, \"strong leader\" mentality in that region, this wouldn't be a mystery. Putin making fake red lines would severely damage him politically. Look at Ukraine. He said he'd invade if they tried joining NATO. We claimed they were and Putin invaded even though it has cost his country a fortune. reply onepointsixC 1 hour agorootparentFunny thing about deterrence conversations in the west is that it’s so often characterized as a one way street. That the west can be deterred limitlessly and that others like Russia are impervious to deterrence. As if Putin were some fearless automaton with complete confidence. Because if anything spells confidence it’s having 4 out of 5 of your latest in service ICBM tests fail, including the most recent. Just how confident is Putin, having personally fostered such an endemically corrupt society, in his recently manufactured pits? Russia’s pursuit of a nuclear powered drone that would attempt to be a weapon of mass destruction by virtue of creating an irradiated tsunami reveals an intense fear of the credibility of their current deterrence. reply bee_rider 19 hours agorootparentprevUkraine was not considered to be a near peer to Russia before the war. It seems likely that they thought they’d have a quick win. Possibly, whatever it is they are after, it isn’t worth the pariah status using nuclear weapons would produce. (Or maybe they still think they can get it done conventionally). reply hajile 3 hours agorootparentRussia never intended to take over Ukraine in 2022. 100-150k troops aren't enough to do that vs a country with that many people. Their intent was a quick military action to either get an agreement from Zelensky not to join NATO and to give autonomy to the Donbas region or replace him with someone who would do those things. The lack of a troop recruiting and training pipeline until months into the war is especially damning evidence for this idea. Putin was succeeding too. He had Zelensky's government at the table. The treaty was mostly signed, then Boris Johnson showed up and shut down the peace plan by promising lots of NATO equipment and support. Ukraine was not considered a near-peer before the war because they are NOT a near-peer without our NATO equipment, our NATO intel organizations, our NATO operators on the ground, our NATO trainers, etc. reply HKH2 17 hours agorootparentprevAmerica lost the Vietnam war. Do you think Vietnam is America's near peer? Also, if you're not sure what they're after: Russia has been systematical",
    "originSummary": [
      "The relevance of attack helicopters is being questioned in the context of the Russian invasion of Ukraine, where small drones have effectively targeted armored units.",
      "The conflict has exposed vulnerabilities in both helicopters and heavy armor, with precision artillery and drones posing significant threats.",
      "The future of attack helicopters may hinge on integrating advanced intelligence, surveillance, and reconnaissance systems, and developing countermeasures against drones and missiles, highlighting the growing importance of intelligence and communications in modern warfare."
    ],
    "commentSummary": [
      "The debate centers on whether attack helicopters remain relevant in modern warfare, given the rise of drones and advanced technology.",
      "Proponents argue for helicopters' agility and effectiveness in specific combat scenarios, while critics point to cheaper, unmanned alternatives.",
      "This discussion is part of a broader trend of assessing costly military systems against more affordable options, particularly in near-peer conflicts."
    ],
    "points": 189,
    "commentCount": 568,
    "retryCount": 0,
    "time": 1728329290
  },
  {
    "id": 41775449,
    "title": "John Hopfield and Geoff Hinton Win Physics Nobel Prize [pdf]",
    "originLink": "https://www.nobelprize.org/uploads/2024/10/press-physicsprize2024.pdf",
    "originBody": "Attention Required!Cloudflare . nobelprize.orgCloudflare 8cf86259a9a3cb96 • 4.227.115.140 •",
    "commentLink": "https://news.ycombinator.com/item?id=41775449",
    "commentBody": "John Hopfield and Geoff Hinton Win Physics Nobel Prize [pdf] (nobelprize.org)147 points by chemd0ge 9 hours agohidepastfavorite2 comments ChrisArchitect 4 hours ago [–] More discussion: https://news.ycombinator.com/item?id=41775463 reply dang 1 hour agoparent [–] Comments moved thither. Thanks! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [],
    "points": 147,
    "commentCount": 2,
    "retryCount": 0,
    "time": 1728381078
  },
  {
    "id": 41770249,
    "title": "Sam Altman Goes Full Emperor",
    "originLink": "https://nonzero.substack.com/p/sam-altman-goes-full-emperor",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"nonzero.substack.com\",cType: 'non-interactive',cNounce: '50850',cRay: '8cf8625ddff03185',cHash: '440dd97d6fcd943',cUPMDTk: \"\\/p\\/sam-altman-goes-full-emperor?__cf_chl_tk=GwTLyifqUj3qhfWPwIKZfysDa4hV.WwxKTWrFXyG6jo-1728414135-0.0.1.1-4202\",cFPWv: 'b',cTTimeMs: '1000',cMTimeMs: '120000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/sam-altman-goes-full-emperor?__cf_chl_f_tk=GwTLyifqUj3qhfWPwIKZfysDa4hV.WwxKTWrFXyG6jo-1728414135-0.0.1.1-4202\",md: \"FQFgWYpIC0Pux1DllQ63D4TIXTQY4Rd6BUSZX6Jnrb8-1728414135-1.1.1.1-vbJtG2lpheq_QZ7ATQ52TpkZ0B4y00i5NkWTuVxvKdrD3VSK3g2wvZXh_TR0C_YHlbvbA1fggxR2HikT4P9noP1TnXUqjqKnuMW6BcnraERzM35qj0.6I6zyHisBoZ.SGZwrhZwMCicpN.jqX6b8e7SdO2SOje_93rpZGXKnBZZ25EZuV00Liq0QrZYZ6kS4pjhp.aHNuGGHU22rKXJl_G1AuJbjyCH6UwWUpf6YnpnuxuLop5PvVPpj4khO3muh9CH3YhlAs_Esq2QbrLbXNVvMZnHLKLqphclFPOH5ATB0Lx_yS4QmkyBe13LJuIV9rtNBg6Wc49oWrU7V6Rh1B7knojA6q9xJQu01_H0_UxopOhKQ70KUOeGhps4rAgQUj0a.GaYpDDudCXCPbsBAq1I_VwPchpjod22lWdF8EGXYx0yJHj2Pi6ANrh8ZWJpEAGkC1vWK2cfXf4bubG08uxiia3q20vAsam8aQ5WMc3mmDFEXI2gDI3XmNSdSsRDNNEYGX.bJVY5MJxY8QeXSq74txpayxqAwNQ1ZHSjcwDHHOopnagt9uGP_VX35IWCvVLUKA6wpA6289IRCvLm5qe2QdZLfdk2N2kvn.ZlppKaXKFM1CvovCHN6VdInWL7VELrM8CsgQsMi7s4NxRWvcfgpjhtZtzNOUlLsSAkmZhofbuWxjMX1lt3YAqUAmpt5JnRRSCq11zUY14TYMdQ4f4jjqlwIZIrxCVOrZrGjH_s5E84H57gdbMMf6rGMFmludq5MwXFrEkm3aJdaZ4grDFS3gLctZvthzTZYOssnU0Zvp_oS82WcG0.XfU_wYo06oVJOW3lPclcCiWaHJ6QL6XsUEGc67LK9HGkR.EgCbeOKocgCGwEZtPwZasGSke7MqG64FQnBat8KUmVb5P6szLB5uqNeQ58PzTmwOV_WA_d1g28Yxhh5LC3Hv7wzm3lgXwEtbjF.hRJf7LmCjb0XzUzXCrSsuHiFj6Br5JILPY6VDMTpxRdeetMAH6XoubB6wkUX_UJd9n2lSnglXb2PzKZcHcdAF0B1UZX70RGAj2h8sY2O10iw3boDa9IyvqZzzW6Sj5Nvhjo4GkkhHEmrtDUGaSe7m7UQb260_Nffpo2A3BcqMmDzLhiy4ciiHj_r8Ari4TsCzwuMo3Kwv2jA9fBQJtD9vfL0CR8HMByVeXlXgHmcBFwwQ_0EvYM6BrXfBqws6yx6Iel_vgg2CZe8G_BCLcfSKaD3AJD9qNOMzSSLt1S8XxvbTkqnwn_mbBCvQM32E0jUNub2FZboC7VnfZ2oMBc.9bAi9NvnkzOcN4AXX_VXIkd4KKgfMD5XEsKB93bswBB2oCZOkVMiqr1adDO92CKhxGF6XUjMvhf5aR1_yXbmNjeDdGkNZVB5R_zqXQGsVot4lYXcjmfu5_prwkAJ9ymhhK_0GxX2W8UmDio6vNytGhg2YkNntgXkHcGEs0hMFOG.MSr_er.7RQb0G4d4vbqGGrMYG976tey8H0S_GUvqAQVogdZQBzqkmmr_wPdP9sk.ZaOu5vC.CAhPqqYoj5AfunmFWLxKsilALj0eetn882lI1ozoA6n.bYRUNX8xhE1q3PbygzTJLGOz6YcmeCLMU.6pWr.5SKMiLFRfsTsKO4VaGMz2oYMeYSJq2kpoYyrqnm_a2Qu5VxV0vQ\",mdrd: \"_QjN80qho9DwPIRKCPygNXjgq_K565aFJrnhD9lM5dk-1728414135-1.1.1.1-44npRRhsII0FfTOEh_byboelcFaarkHcPTPr3xDfVOYEhUKgLJogxTirxTjf9Mm2kOczamgLeeM4w01B89csGIXUfvYjez7uY1M2TQE.SAs4lW1M_JgdLTyUGuawx89fz5CAdaNVDI0EZXkGC1kMzxvYprLejdwTFPg.ZQDZ1JRTgxwyFsAOld4lgdhR7ehoOqLs4IkIb.V0Wc.7LlHPkrSkh2YPYt4wySb64hRmSwEZrV0KoKZ4tGDRJ.URrZE8lGOhx8mGWS4CC2.WSvqN2h0_l3wI5X8iUX6xVj7Qq41RPODRhDMU4s2RhweOIquiuybSwpDB.h06CBppDHMUQo2glZHKGLNBcRyGBmZaFEjYZF4CK34jVXhZIL5aXijcF7ekBi.dCab5_zB0WTMjmjOipAna92rGsO5ltGyJofgrpMxQNa5aeRVxglj89jGgTwSsag5gNvY3DjOuSc2tDH4bY52juPMdQGI_dFrpM_3.dkrvSq6MM8vVZdMfXDmdIXA2kcxSG8Nv5zhqN2OityL01f7gH_rNnSuRgM2TpAfRgVZIbs7cw81qEha_2bXHH0UEJ7U9F6CBxKBl.iyWLTGfkbAVrjtGJAQqwRsLj1yO2_554GgBQHFy6AEfbAC8KpcZYpA9lfc2fJhII.IFwqq.Bw12omZ3CKdOl4v6NO7blznXzC4G4vwpPuMugTgGHlmbXX6xX3H4XjqSoOBP6PPjyFmP4yc4RngVPx5SqwWhkbZo3Wy6CrTsiRUAw7T6gK30dEJ6GH5Fb.Hqzzj6vspO.cppZZRkPpLsuUSOLPbcc30eTdOwx9Okuw9uESysz_meFcR0ZhcdoWml8UM8KLueXb6zXs3MaeUjaXA.j6tXeLNsBXXkEU.dT8QMROtlTgL_txffLC_JgDDONFk4NCHyCubw2i_WLLr0rhIbhGo803eaPAmo8DtSvtycBjiTMxsde8sOF2PdWsbPYUB45gW1ZpRgJJKVkj1gJWi7yWlYHktn9eun9GHDuID5s1lO685U8pE8Xj7PZe1YC0pb.uVH9JgYJ3ZqrLovg.nWXoNtoxrZt8KzwihxJgmIeSOj6hA7GKteKe.9LqJHocBRnxTyZLxL7iA_4Cv_yvhEvtwTejroyulBS4IoMK96T2q1CbZc07nvljXPB2u_45OLqJSXg60Ajb4ci3QtjHUQ52O4X2JuwC6TChaVBCvdGmdGBjSoPH6GEy5.yi8FY22FJinmhYiF4ZIxkFsa4cXEkiNuybelGSGevX17cabFxZ1CBQYtw0vGNlthLL_asCqyzlIG5COLWIt459lokErc8JaiuCM6RA0jCpouxwKl1q2ktOG1wfTWSaJ4j9c8yLB3G2A5X91W6wqLCwhpHiWpa5ngzpDbXQ1xPcWgK69e38OFGVzb6PCiZcABpfVZSH2tDrKkMaFsdWoT6mKJQ4sjGl_QaCjQtw1a_4EUyFqueminLqzG2UM5F4.9HRh4TNN9SwAq6tPzDxyccfn2g_kshl6vyrsKkkiybgU8zGUHNPhBKr7yHf28yajCUXUaMxLYR75sLroMFAlW_4C.BfD9KvruhN10U6I5LdW_1TmHrvev6FrQ4uRr6ojgkgmaVFvEu_D_w5e2GwR0AsPAzKLlmD4tgFSdIhviIKv5D82zbRtCt5vzKVWdIMtalSZ8VM2wXw16c2hfmU.e5ukww71nVCUyZWhEPhS5l4Sk3dW8VOcwwtudq9kFT44gZ5M8n5QnqXBVt3pJbIUNrZ.6lLVNP9dZW2dyTw_k0kEkRyxtaiwmZBygsFFIXuDSyqx2rGirmNWBk5FSYhdiNb22Se4d8v4Akv.AHk7R5u1Hg7.8a4J3emXCyeoQxtLwYaDw7WcybktVWMuOXL9.eI2W5GnM9SrkS_r_lJJTIS3HpC.XWOqQ.6n_TiXs_jfcBCY1jf9na0A4zKT4klV1BnsJQeDzK0YQKb_lgflwCZmdp8O4DM2q4IwvkMrj.6DuHxyuCSDoFENGeqeyPJWhlYBID50MI16i_HEpUOvvX7oKEc1bYtdI1ukMu5miG9616GVIQazdZCte0JOffXSSenbTDRxIkI9SG6CFzViSSeGQEpe0Ff7bDYAZGjsWeo7Tcb8lEJh5mUFPLoVD.fC56lF_OcIboZJihh1PLumdFWXtmPH3kvFa2UAxUNinvtec6MwqU46ysOz07O1ulrYrQjYoqFM3YrF7rPWvKWd1Mq2Z3.giY0snSWE1FZZjhPUDxLt6FJBtkXIbTLzB52cUpyRUKPebtKNdqmj8NIN3NlyfdPXU2l9mnDQOr2MzTevrRm7pjJc8bB59LSoLb8ofZgouuqwCMbszd9yx_.zM20LGJtRe.kfYH_L.0siJSNSS9qAobOAa8Q\",cRq: {ru: 'aHR0cHM6Ly9ub256ZXJvLnN1YnN0YWNrLmNvbS9wL3NhbS1hbHRtYW4tZ29lcy1mdWxsLWVtcGVyb3I=',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',d: 'xgN8lFrPERTkUpzjdaKRM5JzdTfGYQacOa4ju57KK3avcesQu1mQPT+sGnLj3WgoEvumtIFwCaCMYHRWld7XIK5eDIogMH4FpUnIxQwCs5MtJaXgtA5rJmLOUOptjuEa4kR55bkM/DrwV7V4/Yco/eLqC4cy2O/dRT/vrO2IkAgqEmK7Q8ExCo0zIHOxX03FcH6NNNjWI7Es6nq2igvZFcrqgyl2gEVHzAQmy3HJiAXE4V/38vyVj4CArBOCTXT6/p3+mCK9wxJzdoTchRB2xZrz72UY40V5PRuevC8h38d+yFR7UzBLNhNfOKwb4sdHnf1wSQWKlWr/M1oPPDbWBiMhb6QiRq9W0qHbh0+/wC3LOAQLKhRvkRu2ThkluGfBmRdLr1M4PZ71b9vKCJ/BWrSjvGBupQyrBdBoiFKXR56J43oFvCbIEi2o8KBaJLegBp5j0M5JFEzbuJYgBEpazWfjDyuxgoOyOduLjvof9bmLm2xoukoNhDMl4YLCy61QwIr7r1V4oSu1wlsn/V3dIBvWk/MFuyJ4t/4/8MI6eL/HrUz9F3BQiEv4FFWJU99SbduZnXTq6Zn2/1GHqbs8KA==',t: 'MTcyODQxNDEzNS4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: 'MNEQK71gkObCcHMWN4jBTwREAUcVGepHPrZQijV/LbM=',i1: 'QbtaP6Z3J5uK2NPqc6AI3A==',i2: 'LY5H4mLNaSFG2iDaPGSlBQ==',zh: 'o01jypKJQ++/gkxUTvC40nYpXBhuMc66cm0hd/Tc920=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'gxKvGb8m6kA4elWmHaR7ns45uJJkNcEy3DMdNieChRc=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8cf8625ddff03185';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/sam-altman-goes-full-emperor?__cf_chl_rt_tk=GwTLyifqUj3qhfWPwIKZfysDa4hV.WwxKTWrFXyG6jo-1728414135-0.0.1.1-4202\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41770249",
    "commentBody": "[flagged] Sam Altman Goes Full Emperor (nonzero.substack.com)116 points by _1 23 hours agohidepastfavorite98 comments AlexandrB 22 hours agoInteresting that Worldcoin[1,2] isn't mentioned (at least in the non-paywalled portion). It's another example of world-spanning ambition masquerading as egalitarianism while riding the latest tech trend. [1] https://worldcoin.org [2] https://en.wikipedia.org/wiki/Worldcoin reply tim333 19 hours agoparentI guess it's because OpenAI is getting traction as a powerful company whereas Worldcoin and Helion (fusion) are not really. But he likes his grand projects. reply whimsicalism 22 hours agoparentprev> It's another example of world-spanning ambition masquerading as egalitarianism this reflexive distaste for ambition is exactly what Nietzsche talked about in his Genealogy of Morality reply piva00 22 hours agorootparentYou can't bring Nietzsche's view of ambition and consider it as truth without even bringing more contemporary criticisms of it, even if you'd like to see it through Virtue Ethics it should be considered as a virtue in a diverse set of virtues, ambition shouldn't trump other moral values. As entertaining as it was to read \"On The Genealogy of Morality\" when I was 20 years old I'd say it's rather... Reductionist, at least. Sloterdijk updates on it even bring up how to consider \"will to power\" not as an individual ambition but as a holistic way to actualise oneself to give something back to the world, not as a power over others which is the main way corporations are run. Pursuing your ambitions at the expense of the rest of the globe is not moral. Please update your philosophical repertoire, you're stuck in the 1800s. reply whimsicalism 22 hours agorootparentI'm not going to engage further because you're coming from a condescending angle that doesn't invite discussion, but I can't help but laugh at a virtue ethicist telling me I'm stuck in the philosophical past. Something something glass houses and stones. reply arp242 21 hours agorootparentYou posted a one-line dismissive and condescending put-down yourself, which basically added nothing to the conversation. Don't hold others to higher standards than you hold yourself. reply whimsicalism 21 hours agorootparentI was commenting on the notion that ambition is in some way prima facie bad. In response, I was told that my understanding of philosophy is like that of a 20 year old and that I am intellectually stuck in the 1800s (in a comment comically premised on the moral philosophy of the ancient greeks). I do not see my comment as a put-down at all and it certainly is not anything like that response. Nonetheless, I will take your feedback into account - clearly it came across to multiple people as condescending. reply humptylumpy 18 hours agorootparent> I was commenting on the notion that ambition is in some way prima facie bad. You were in fact commenting on the strawman you constructed that the op “notion[ed] that ambition is in some way prima facie bad”. The op mocked, and in a way more reserved way than I would, the type of “ambition” that this unethical sociopath and his supporters endorse. If this unethical sociopath was ambitiously pursuing universal healthcare then he’d get my support. Instead he has found his place by stealing from the impoverished, world coin, and now creatives, OpenAI. That to me is an abhorrent form of ambition. reply piva00 20 hours agorootparentprev> In response, I was told that my understanding of philosophy is like that of a 20 year old and that I am intellectually stuck in the 1800s (in a comment comically premised on the moral philosophy of the ancient greeks). Please tell me how Sloterdijk is premised on Plato or Socrates. It's a continuation of thought from Nietzsche's approach of \"will to power\" in a contemporary view, if Sloterdijk is invalid so is your use of Nietzsche as a foundation. reply piva00 21 hours agorootparentprevIt's a condescending angle because you were condescending at first, even more when attempting to use 1800s philosophy to argument for ambition based on very fossilised philosophy. I like Nietzsche, I wouldn't use Nietzsche as the sole basis of morality argumentation since there are much more updated thinkers considering our moral standards in the contemporary world. Receding from the discussion doesn't take that away, you were being reductionist in your argumentation, I just pointed out you were stuck in the 1800s. Since then I read your profile and saw you are actually a consequentialist, I don't want anything to do with Effective Altruism true believers so thanks for not engaging further. reply karmakurtisaani 22 hours agorootparentprevI for one don't understand what you're saying, but get the feeling it's in defense of Altman. I'd like to point out that the key here is the world-spanning ambition, which to me reads like an unhealthy megalomania. reply preommr 22 hours agoprev> His boundless ambition is putting AI, and the world, on a dangerous path. Has the narrative really become that Sam Altman is single-handedly responsible for the massive leap in AI? I really don't think that Altman is even close to being in the top 5 worrying techbros. At best, he enabled OpenAI researchers to get their work done 1-5 years sooner. This stuff was going to happen with or without Altman. The advancements to come will happen with or without Altman. These kinds of articles are alarmist nonsense. reply eikenberry 22 hours agoparentThe article doesn't even attempt to explain why \"accelerationism\" is a dangerous path. I'm not sure if I share that assumption or not as I don't even know what exactly the author thinks it is. reply sanex 22 hours agoparentprevI am curious who your top 5 is now. reply yesbabyyes 2 hours agorootparentMe too, so I tried to get an objective list. After some prodding, these are the top 5 worrying techbros according to ChatGPT: 1. Elon Musk 2. Mark Zuckerberg 3. Sam Altman 4. Peter Thiel 5. Jeff Bezos reply jon309 22 hours agoprevSave yourself the read. This article started strong, but never ended up making a logical point about why Sam is dangerous. reply alurgyro 22 hours agoparentI believe the implication is that it's irrelevant whom has the power, just the someone can attain a lot of it. reply deepfriedchokes 21 hours agoparentprevAnyone who seeks power is dangerous. reply dmitrygr 22 hours agoparentprevGrifters in position of power always are. I don’t think anybody needs proof of this. If you do, I can recommend a few good history books. reply mierz00 8 hours agorootparentI know that was tongue in cheek, but I am interested in any book recommendations about grifters in power. reply dmitrygr 3 hours agorootparentAnything on this guy is a fun read: https://en.wikipedia.org/wiki/Ferdinand_Marcos reply apsec112 22 hours agoprevIs there a non-paywalled version? reply snek_case 22 hours agoparentCan we petition for HN to block paywalled and ad-riddled content? As it is there's an incentive to spam paywalled content around social media websites to earn yourself more money. Additional point: we can't have a balanced community discussion if only a small percentage of viewers have access to the full article. This is a community website, so we should favor content that is openly shareable. reply dang 22 hours agorootparentRe paywalls: if there's a workaround, it's ok. Users usually post workarounds in the thread. This is in the FAQ at https://news.ycombinator.com/newsfaq.html and there's more explanation here: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&so... https://news.ycombinator.com/item?id=10178989 The converse is also true: if there's not a workaround, it's not ok. reply OutOfHere 22 hours agorootparentIs there a link to an unpaywalled version? reply dang 22 hours agorootparentAs far as I know, there is no workaround in this case. reply bbor 22 hours agorootparentprevWell Mr. Dang, we've got a new edge case for you lol: An article with substantive content before the paywall, but that doesn't have any workarounds for the rest of the article. I would love to be proven wrong, but AFAICT we'd need a subscriber to this particular person's Substack to host a version for us. reply dang 22 hours agorootparentYes, that was my point as well. reply tzs 17 hours agorootparentprev> Additional point: we can't have a balanced community discussion if only a small percentage of viewers have access to the full article It's pretty common on non-paywalled articles for only a small percentage to read the article, yet we often manage to have balanced discussions of those. reply richwater 22 hours agorootparentprevThe blind hatred of paywalled content is exactly how we ended up with an ad-riddled shitty internet. reply loceng 22 hours agoprevIt appears the establishment and \"big tech\" - not all but those toeing the same line, are happy for him to be there, and protective of him. reply lackoftactics 22 hours agoprevThe rest of the article is behind a paywall. I'm still on the fence about Sam Altman, and as someone who lives in Poland rather than Silicon Valley, it's difficult to form a solid judgment about him. It's much easier for me to see through Elon Musk's facade in his interviews, where he only plays at being an expert. Altman has some mystique surrounding him, though I think his frequent appearances on podcasts are ruining it. I sometimes wonder how he finds time to appear even on minor podcasts. reply bbor 22 hours agoprevAmazing article, thanks for posting! I don't know this author, but they've definitely got a solid understanding of the relevant facts, IMO/AFAICT. That said: Altman could now get equity in OpenAI—around $10 billion worth He claimed to employees last week that he won't be following through on this. See: https://www.cnbc.com/2024/09/26/openais-sam-altman-tells-emp... Do I believe he won't pull a \"whoops who knows\" or a \"it's not giant equity stake, just a big one\"? Meh. But it's at least in doubt now. What’s scary about him isn’t that he’s good at getting rich (he’s a billionaire even without any OpenAI equity) This surprised me when I first learned it, but appearently it's true. Wikipedia has this (uncited!!) language on the topic: \"Sam Altman has recently expanded his investment portfolio to include stakes in over 400 companies, valued at around $2.8 billion. Some of these investments intersect with companies doing business with OpenAI, which has raised questions about potential conflicts of interest, though Altman and OpenAI maintain that these are managed transparently.\" Friendly reminder that a billion is a thousand times a million... $2.8B is not a number to glance past like it's normal. According to Statista, he's one of ~10,000 in the entire world: https://www.statista.com/statistics/621447/billionaires-tota... Though Altman (wisely) wouldn’t use this term for it, I’d say it boils down to accelerationism Eh, that term has a lot of loaded meaning among academic circles (or just hacker / e/acc ones...) that I don't think Altman openly subscribes to -- especially if you include its founder Nick Land, who's now a \"Hyper-fascist\" with some appearent brain damage. Long story short it involves burning down the current system, not just building a new one. See this amazing Guardian article: https://www.theguardian.com/world/2017/may/11/accelerationis... I'd call Altman simply... arrogant. I don't think he subscribes to any academic trend, simply because he doesn't seem interested in reading any academia. Case in point is his recent decision to try to be the one to name the new era of human development, a task for which he chose \"Intelligence Age\" (https://ia.samaltman.com/); that's some serious confidence, at the very least. IMO he is a normal MBA-type who's been caught up in something that feels world-changing, and he's at the point where any amount of deceit or malice is worth it to keep his influence over that. In this way, I see him as a much more well-spoken Elon Musk; they both are true believers in the power of AGI, and their defining purpose is to be credited with the benefits it'll bring about. As I said in an old post on Altman: made-in-house bias is strongest when the house is your own skull. [ETA in response to a comment below, b/c deleting a long paragraph feels like abandoning a project!]: Fair enough! I myself have limited working experience with executives and have never met Altman, so I'm going off his blog posts mostly, along with the negative personality pieces that have popped up over the past year (e.g. https://www.reddit.com/r/OpenAI/comments/1804u5y/former_open... , https://mashable.com/article/open-ai-board-why-fired-sam-alt... , https://www.techspot.com/news/103176-lies-psychological-abus... ). I agree that he's quintessential Silicon Valley rather than the traditional image of \"MBA type\"--a white man in a fancy suit in New York or Chicago, mostly--but he seems to otherwise fit the bill. Namely: - Personal overconfidence/hubris, as I discuss above. - Tendency to overpromise his organization's capabilities, as a rule. \"Move fast and break things\" type vibes. - Prioritizing growth/scale over other concerns -- I think the switch to for-profit makes this objectively accurate. - A noted aversion to transparency in general, as best embodied by OpenAI's approach to opensource. - A history of dodging accountability, namely in the ouster fiasco. - A charismatic but potentially manipulative leadership style (the main gist of this article). reply rmbyrro 22 hours agoparentI'm sorry, there are 10,000 individuals on Earth worth ~$3b or more? Wow, I would imagine this club was a lot smaller reply whimsicalism 22 hours agoparentprev> Eh, that term has a lot of loaded meaning among academic circles (or just hacker / e/acc ones...) that I don't think Altman openly subscribes to -- especially if you include its founder Nick Land, who's now a \"Hyper-fascist\" with some appearent brain damage. Long story short it involves burning down the current system, not just building a new one. See this amazing Guardian article: https://www.theguardian.com/world/2017/may/11/accelerationis... I'd call Altman simply... arrogant. I don't think he subscribes to any academic trend, simply because he doesn't seem interested in reading any academia. Case in point is his recent decision to try to be the one to name the new era of human development, a task for which he chose \"Intelligence Age\" (https://ia.samaltman.com/); that's some serious confidence, at the very least. I think you would be shocked at how much these philosophical trends actually are part of the discussion in these SF circles. Sam Altman is also absolutely not a normal MBA-type, having met many of those. reply jaybrendansmith 21 hours agoparentprevI'm not sure I can even blame Altman here. I think it's quite easy to move into a mode where all forward 'progress' is perceived as unequivocally good. It is so difficult to move the ball, once the ball starts rolling, it's absolutely exhilarating. He's the person on the crest of the wave at the moment, and it's either Sam or someone else is there. Is he a moral man? Can he dare to pause and ask if these features should exist? I doubt it. Perhaps his request for regulation was in earnest: He maybe knows that only governments can slow down a market that is cresting, and only governments can stop and ask questions. Since I believe in government (I know that many do not!) I think we must immediately create a Department of AI and a President's commission. This shit is about to become very real. reply gom_jabbar 19 hours agoparentprevI think focusing on Nick Land's provocations rather than confronting the predictive validity of Accelerationism, which the Guardian article highlights, is just a nice coping strategy for people who are low on decoupling. I'm doing a primary literature review of Land's core thesis that AI and capitalism are teleologically identical at https://retrochronic.com/ and I hope it will show that there is at least some substance to his work, such as his perspective on AI in the context of capital autonomization. reply stadia42 22 hours agoprevnext [30 more] [flagged] tux3 22 hours agoparentThis guy writing longform articles and publishing books doesn't know what he's talking about. Take it from me, a random internet commenter with no discernable credentials. reply scyzoryk_xyz 21 hours agorootparentthis is the orange site though, so you never know reply drawkward 22 hours agoparentprevWhich of Altman's credentials do we consider relevant to global-scale wielding of AI? reply akira2501 22 hours agorootparentAltman has the job. Dozens of people are writing about him. Not all of that writing is relevant or useful in analysis. In particular, writing an article that contains a worry that people are \"hating on the wrong part of Altman,\" is a bit of a giveaway that the author lacks the ability to a deep technical analysis of the problem and has instead decided to focus on personality. reply KaiserPro 22 hours agorootparent> a deep technical analysis of the problem Altman isn't a deep technical problem to be solved. flood management is a deep technical problem Energy policy is a deep technical problem Altman is a dude whos wildly rich, in charge of a darling company, and having the same smoke blown up his arse as the other silicon valley darlings. Like Musk, he's deeply predictable. What he does next depends on how much money he thinks he can burn in the next year. He will lobby for extension of copyright for fair use (or similar). He will lobby against any kind of data protections law (that fucks up the training pipeline) He will dabble with custom silicon. reply akira2501 22 hours agorootparent> Altman isn't a deep technical problem to be solved. He's running a company that has created one. > What he does next depends on how much money he thinks he can burn in the next year. Which is why personality analysis is entirely the wrong tool here. It offers you absolutely zero predictions. Why you would double down on this is beyond me. reply KaiserPro 2 hours agorootparent> Which is why personality analysis is entirely the wrong tool here I mean its not really. What is his attitude to risk, how well does he understand people's motivations? what narrative is he selling his investors? what is he aiming for? what's his personal goal? All of this shape the outcome of the company, and those are dependent on his personality. In the same way that Musk is short sighted and thin skinned, means that twitter is the way it is. Zuck is happy to burn billions so long as the research looks promising. Bezos is all about market share. reply rmbyrro 22 hours agorootparentprevHum.. he led OpenAI to their achievements? Like him or not, the guy is competent. reply drawkward 22 hours agorootparentOppenheimer therefore has the right to wield nuclear weapons? reply hluska 22 hours agorootparentprevI’d interview someone who had been President of Y Combinator and most likely offer them my job by the end of the conversation. Kidding aside, it’s at least in the same world. I’m not even sure what qualified to lead the scaling of AI would look like. reply AshamedCaptain 22 hours agoparentprevAnd from which worldwide schools of fashion you need credentials to even dare to remark that the emperor has no clothes? reply stadia42 22 hours agorootparentTo remark - none. To be taken seriously -- probably some, otherwise the noise of millions of bloggers is too much to handle. Which credentials, I'm not sure, hence my question. FWIW, the author has university education and is currently a Visiting Professor of Science and Religion at Union Theological Seminary, New York. I personally don't find it relevant to the topic, but was curious to see what others thought. reply lrvick 22 hours agoparentprevWhen you resort to ad hominem attacks, it makes it seem as though you were unable form any specific objection to the actual content. reply stadia42 22 hours agorootparentThis is not an ad hominem attack. It's fair to ask about an author's credentials when they write a public article. (I do believe he lacks the credentials, but happy to hear a counter-argument.) reply drawkward 22 hours agorootparentThe author's credentials might help us understand their motivation for writing something, or help us understand any implicit bias they carry, but in no way do they indicate the quality of the argument myself. Trust me, I went to Yale. reply ndr 22 hours agoparentprevWhich parts you credential do we consider relevant to rate the expertise on the topic at hand? Seriously though, I think the author is overworried about accelerationism but correctly rates sama power grab inclinations. What's your thought re TFA rather than the author? reply stadia42 22 hours agorootparentThe non-paywalled start of the article reads like a ChatGPT answer to a high school essay question (i.e., no new insight beyond things anyone knows). reply iLoveOncall 22 hours agoparentprevNot saying he's making a good point (or not), but you don't need specific credentials to write an article on your blog about an opinion you have. reply stadia42 22 hours agorootparentOf course you don't. I thought, however, that you may need some credentials to be upvoted by an audience of highly technical readers. reply mattgreenrocks 22 hours agorootparentNothing says hacker culture like needing sufficient credentials to even consider someone’s ideas. Edit: I hope you can see from the sea of replies that this sort of credential check is not welcome here. reply drawkward 22 hours agorootparentprevThe argument itself is the currency, not the credentials of the person making it. reply zonotope 22 hours agorootparentprevI think you need to make insightful points for that. Having credentials is not a requirement for having insight, although they are sometimes correlated. reply MostlyStable 22 hours agorootparentprevNope. In order to be upvoted by an audience of highly techincal readers, I would hope that all one needs is to make a strong argument, or provide something interesting, or otherwise of value. Credentials can be a shortcut/filter to finding something of value. Someone may reasonably choose not to spend time reading something from someone with no credentials, under the assumption that most of everything is garbage. But, after having chosen to read it, the credentials no longer have any bearing. It's either good or it's not. reply taco_emoji 22 hours agorootparentprevwhy? reply ur-whale 22 hours agorootparentprevThere's also the other approach: actually reading the content and judging it on its own merit. https://en.wikipedia.org/wiki/Argument_from_authority reply dekhn 22 hours agorootparentthe criticism of argument from authority is really only valid for logic-based arguments (which only exist in math). In nearly every argument online, the topic is not logic-based, but more a combination of fuzzy reason and rhetoric. In such situations, we normally allow for some prior belief that people who obtained education and have worked in an area have some level of expertise that makes their arguments carry more weight. While you can argue whether this makes sense, it certainly seems reasonable to me- although I still apply skepticism to expert opinions. reply stadia42 22 hours agoparentprevBTW, why is the article now flagged? Is it because it's paywalled? reply justin_oaks 22 hours agoparentprevWhat are your credentials? reply stadia42 22 hours agorootparentNone, and that's exactly how many blog articles I wrote on this topic. reply dottjt 22 hours agoprevlol post flagged reply minimaxir 22 hours agoparentLikely more due to the paywall than the fact it's anti-Altman. reply dymk 21 hours agorootparentProbably not, every paywalled article gets an archive.is link reply whimsicalism 21 hours agorootparentnot substack reply bitcharmer 22 hours agoparentprevThis is the new norm on HN. Gang-flagging is rampart but the mods are ok with it most of the time. Altman is a YCombinator darling so of course this post won't stay up long. reply OutOfHere 22 hours agorootparentIn this case the flagging was because of the paywall that could not be bypassed. reply whimsicalism 22 hours agoprevI miss the era when the chattering class didn't know anything about tech. So nice to not be the product of think-pieces and in the ire of NYT readers. The funniest bit is that the previous villains -- financiers and oil barons, etc. etc. - haven't gone away. I don't understand why the high-powered critics have completely pivoted to hating on tech. Say what you will about Google, OpenAI, etc. but we're not funding mass killings in the Niger river delta or foreclosing on people's homes. reply allturtles 22 hours agoparent> I miss the pre-covid era when the chattering class didn't know anything about tech. So nice to not be the product of think-pieces and in the ire of NYT readers. The \"chattering classes\" in general and NYT in particular have been writing think pieces about tech for decades [0] [1] [2] [3]. So I'm not sure what you're talking about and what COVID has to do with it. [0]: About Facebook in 2014: https://www.nytimes.com/2014/07/01/opinion/jaron-lanier-on-l... [1]: About the risks of the Internet for children in 2009: https://www.nytimes.com/2008/02/28/technology/personaltech/2... [2]: About greedy dot-coms in 1998: https://www.nytimes.com/1998/12/27/magazine/fast-forward-gre... [3]: About whether children need to learn computer literacy in 1984: https://www.nytimes.com/1984/01/13/opinion/false-notions-abo... reply whimsicalism 22 hours agorootparentAgree to disagree, then. I think the direction of the trend has been pretty clear and I'm an avid reader of the news, but it is a difficult thing to quantify in the aggregate. reply surgical_fire 21 hours agoparentprevEh, I think this scrutiny, skepticism, and even disdain towards the tech industry in general is highly welcome. Long gone are the days when optimism and naivety was warranted. Those large companies abused it to become the ruthless behemoths of today. reply rmbyrro 22 hours agoparentprevBut the AIs we're developing surely are going to eradicate humankind from this Earth. Haven't you read the news that an AI agent took over administrator control over a startup CEO, founder, whatever and corrupted the machine to a halt? I heard it used some `sudo` magic spell. It could have `sudo'ed` an Iranian nuclear launch site and plunged the Earth into full scale nuclear WWIII. reply raxxorraxor 10 hours agorootparentI am a serious sucker for science fiction, but I find the alleged inevitability of glorified chatbots dominating humans to be quite a colorful thought experiment. That said, some part of it is true. There will be a stupid \"AI\" that reduces your credit score to some value. There will be no recourse and no human you can ask how the score was calculated, you have no method to correct false information. Perhaps it is just because you are ugly, verified by the ugly algorithm. Perhaps you aren't visible enough on social media, Here you are indeed slave to the machine, but the news would perhaps just be, that this is already the case anyway. reply drawkward 22 hours agoparentprevI, too, like gatekeeping! reply whimsicalism 22 hours agorootparentNot wanting everything to become politicized - and, beyond that, politicized in a very ressentiment-leaning direction - is not gatekeeping. reply drawkward 22 hours agorootparentAt no point did your original post say anything about the politicization of tech; you literally were upset about the \"chattering class\" (definitely apolitical, unloaded term there) simply knowing about tech. reply whimsicalism 22 hours agorootparentChattering class strongly connotes politicization that is detached from material reality, it is basically the purpose of the word. I can tell that this is not going to be a productive back-and-forth, so I'll just leave it there. reply piva00 22 hours agorootparentprevEverything with power is political. Tech is extremely powerful, and even if not directly inflicting harm it does in reality inflict harm, if not by intent then by carelessness or omission. Tech hasn't pursued wars like the oil or food industry but enabled hybrid warfare by omission, it hasn't killed people directly but has created even more leverage for elites to dehumanise processes, e.g. customer support, setting rental prices, showing ads, etc. There's no way for tech to not become politicised, it's wishful thinking, and wishing it away doesn't change the reality, the further tech embeds into our lives the more power it has, the more political it becomes. reply whimsicalism 22 hours agorootparent> Tech hasn't pursued wars like the oil or food industry but enabled hybrid warfare by omission, By making everything equivalent linguistically, we lose the language to condemn terrible and awful things. I absolutely reject the notion that anything tech has done is comparable in magnitude to the actual wars and actual mass killings funded by the oil industry. Your rejoinder is replacing some customer support roles? reply piva00 21 hours agorootparent> Your rejoinder is replacing some customer support roles? No, it was an e.g., it is right there in the post. > By making everything equivalent linguistically, we lose the language to condemn terrible and awful things. Completely agree, at the same time the harm created isn't inconsequential, do you mind coming to a term which we can use? And by the way, you attacked tangent points of my argument, nothing in the substance of it. Power is politics, tech has power, so it's inherently politicised. Please attack this argument, not tangents. reply whimsicalism 21 hours agorootparent> And by the way, you attacked tangent points of my argument, nothing in the substance of it. Power is politics, tech has power, so it's inherently politicised. Please attack this argument, not tangents. That part is a relatively compelling argument and one that I am partial to. I think that politics is an overloaded term nowadays and many, quite reasonably, consider the personal to be political and power to always be political. In these cases, I again have the same worry about making everything equivalent linguistically - I fear we lose the usefulness of the word 'politics'. But acceding to your definition of politics, I would change my original comment to be: I do not like the direction in which tech is being politicized. I think there are larger-scale power arrangements that do not get nearly enough attention and I worry that the current discussion is more around 'how can tear down those who are succeeding' and less of 'how can we better share in the bounty that is being created'. reply jauntywundrkind 21 hours agoparentprevThe point about the historical villains all being there still still being awful to everyone is so apt. But a couple of things. Tech defines such an overwhelming share of the market that it's an impossible to disregard giant. And the world has changed so much owing to tech. But I don't think tech has had a positive human narrative in almost a decade. The noveau riche arose as semi-gentle intermediaries originally, empowering & connecting the small, and every single play we see is to intermediate, not serve. So where is the contemporary good to report on, where is the modern earned goodwill? Instead what is emitted is double trash. It's all inscrutable/doesn't serve a clear need to boot. And it's far more owned and intermediated than ever... Bitcoin/cryptocurrencies, VR, and now AI. None showing the genuine enrichment humans could really tangle with that tech had brought us. Neutrality is not enough, only mildly bad news is not enough. We need to make things that fill needs, and that expand imagination/open horizons, in ways where we ourselves can be part of the narrative. But yes please let's also cover the genuinely detestable parts of the world as such. Let all be accountable. reply rakoo 22 hours agoparentprevMeta has had an active part in the genocide of Rohingya, though: https://www.nytimes.com/2018/10/15/technology/myanmar-facebo... It is also responsible for a rise in hate crimes: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3082972 reply whimsicalism 22 hours agorootparentI don't agree with the premise that people using your platform to post hate or incite violence makes you an 'active part' in genocide in an even remotely similar fashion to Shell actively funding the militant groups engaging in genocide. It is more akin to a paper company being blamed for the writings on it or a phone company being blamed because the orders to invade were sent over text message. > It is also responsible for a rise in hate crimes: > https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3082972 Very interesting attempt to gain causality through internet blackout, but I'm not really convinced by a study that provides no evidence that they pre-registered their analysis. reply hnlmorg 21 hours agorootparentThe fact that Facebook algorithms intentionally promotes hostilities as a side effect of its mission to every increase engagement doesn’t exactly make Meta passive like a phone service. It’s even more damning for Meta when you consider just how insidious their tactics are to get people hooked on their platform. They might not be selling the guns nor pulling the triggers, but they’re not exactly innocent either. reply raxxorraxor 10 hours agorootparentThat is still not the fault of Facebook. It is the fault of people writing these comment and those that respond to them and want to kill other people. That they now have a common platform of communication is a fact everyone needs to adapt to. You might level the criticism against the advertising industry. This is a legislative issue. To accuse Facebook to help a genocide is just distracting from the guilt of those that attempt genocide. reply hnlmorg 9 hours agorootparentYou're looking at things too binary. It's not an \"either / or\" but instead a spectrum of guilt. Your argument is akin to saying someone who stole a chocolate bar isn't a criminal because they weren't carrying a knife. Or someone else who stole a wallet at knife point isn't a criminal because they didn't kill their victim. Or that a murderer isn't a criminal because they didn't commit genocide. There's always going to be instances where some bad things are worse than other bad things. But that doesn't mean that the less-worse bad things aren't also themselves bad. Meta built their platform to be addictive and one of the negative consequences of constantly pursuing \"engagement\" is that breads negative interactions. And this was a very intentional move on Meta's part. So they're not innocent. They're just not literal murderers. reply raxxorraxor 9 hours agorootparentIt is not at all binary, it is about criminal responsibility. On the contrary, I think the one who stole the chocolate bar is guilty, not the shop owner who lacked a \"no knife policy\" and didn't protect its sweats enough. Or more fitting advertised them too much. The shop owner is just innocent in your example and the blame lies solely on the one who stole. Same with the people committing genocide. The meme that Facebook was a part here is just faulty reasoning. The \"stochastic terrorism\" crowd comes to mind, who seem to create a new olympic discipline of reaching. They too like to accuse platforms that were used to communicate. That is just distracting from those that are responsible for the crimes at hand. If there hadn't been a Facebook, they would have used Twitter or any other social media platform. Advertising is manipulative, but Facebook isn't enabling me to commit crimes. These issues need a clear separation. Otherwise any statement would be too dangerous if you generalize your concept of responsibility. That is not a healthy road to go down. reply hnlmorg 8 hours agorootparent> On the contrary, I think the one who stole the chocolate bar is guilty, not the shop owner who lacked a \"no knife policy\" and didn't protect its sweats enough You're moving the goal posts by talking about the shop owners when I'm talking about how a spectrum of \"bad things\" doesn't mean one guilty party makes another guilty party innocent. There's other issues with your shop analogy, but I'll cover that further on. > Same with the people committing genocide. The meme that Facebook was a part here is just faulty reasoning. I never said Facebook took part in genocide. That was a different commenter. I said Meta aren't an entirely innocent party in the same way that people talk about phone services. Once again you're looking at things too binary when what I'm making is more of a nuanced point. > That is just distracting from those that are responsible for the crimes at hand. Some people, like myself, can say there are plenty of people to blame and not be distracted by it. To say \"this bad thing is a distraction from this less bad, but slightly unrelated, bad thing\" is exactly why I claimed you were looking at things too binary. > Advertising is manipulative, but Facebook isn't enabling me to commit crimes. These issues need a clear separation. Otherwise any statement would be too dangerous if you generalize your concept of responsibility. That is not a healthy road to go down. Another really binary take. If you cannot have a conversation about enablement for fear of a theoretical eventual end conclusion then it demonstrates a complete inability to understand that, like with most grey areas, you can draw a proverbial line in the sand before you reach that theoretical worse case conclusion. If you cannot, then you're looking at things too binary. A better way to frame the question is this: Is Facebook's algorithms passive or not? A phone service is passive because it doesn't recommend content. Facebook's algorithms are not passive because it does recommend content. So the next question is whether those algorithms create harm, and if so, whether Facebook are aware of that. Sadly the answers to both of those are \"yes\". Sure, Meta's algorithms aren't always harmful and even when it is, it's usually it's only slightly harmful. But it's never completely beneficial for the consumer. This doesn't mean Facebook are complicit in genocide but it does mean Facebook are not innocent service providers like a phone service. So lets frame your shop keeper service examples differently: Is a shop keeper allowed to sell alcohol to children or people already super drunk? No they're not. In most territories they have a legal obligation to limit who is entitled to purchase alcohol. The problem with your shop analogy is that people are consumers. We don't steal from Facebook, we consume their product for free because we are also their product. So you cannot compare Facebook to stealing. But you can compare Facebook to the consumption of safe vs potentially dangerous substances. With regards to Facebook: sometimes that product is mostly harmless (like chocolate). Sometimes its harmful to the wrong audiences (like alcohol). And Facebook knowingly serves and even promotes harmful products to the wrong audiences. So Meta are not innocent. They might not be monsters like those who commit genocide, but that doesn't mean we can view Meta as being innocent for fear of being distracted by other, unrelated, monstrous things. The world isn't black and white like that. It's perfectly fine to say more than one party of doing bad things, of different severities and in different ways. reply raxxorraxor 4 hours agorootparentI don't think I move the goalpost when I pick up from your example. I simply do not agree that Facebook can sensibly be responsible here. No, the misdeeds lie with those that use the platform for their personal quarrels. A recommendation algorithm does not make you a partner in crime. If we talk about guilt, we need to talk about the advertising industry as a whole that doesn't only include Facebook. Your argument is analogous to rock music making kids more violent without there being a direct causal link. Without that is remains speculation and even statements that they are \"a bit guilty\" have to be rejected. That the advertising industry as a whole is detrimental is likely true, but then Facebook taking part of genocide should not be a starter. > I never said Facebook took part in genocide. That was a different commenter. I said Meta aren't an entirely innocent party That is pure semantics. No, they are not a guilty party. And if they are really at fault it recently was about removing too much content, which they correctly self identified being a problem. So they have at least that. reply hnlmorg 38 minutes agorootparent> Your argument is analogous to rock music making kids more violent without there being a direct causal link. No it’s not. Not even remotely. > That is pure semantics. No it’s not. You can’t misread my post and then argue that your interpretation is still correct because of “semantics”. > And if they are really at fault it recently was about removing too much content We might just have to agree to disagree on this. reply miki123211 18 hours agoprev [–] It's worth keeping in mind that Altman likely neither wants nor needs the equity in Open AI, but investors are forcing him to take some to align incentives.[1][2][3] [1] [see the Open AI section] https://archive.is/S9rwj [2] https://archive.is/0To6q [3] [and the Open AI section again] https://archive.is/ejoOx reply Gud 15 hours agoparent [–] Well if he doesn’t want it, he can give it to me! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion centers on Sam Altman, CEO of OpenAI, and his ambitious projects, such as Worldcoin, which elicit mixed reactions regarding their potential risks and necessity for progress.",
      "The conversation includes philosophical debates on ambition, referencing Nietzsche and modern critiques, highlighting differing perspectives on the role of ambition in technological advancement.",
      "There is a debate about the political influence of tech companies on societal issues, alongside concerns about paywalled content affecting the accessibility and inclusivity of community discussions."
    ],
    "points": 116,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1728330853
  },
  {
    "id": 41771272,
    "title": "Rust is rolling off the Volvo assembly line",
    "originLink": "https://tweedegolf.nl/en/blog/137/rust-is-rolling-off-the-volvo-assembly-line",
    "originBody": "October 7, 2024 Rust is rolling off the Volvo assembly line Dion Embedded software engineer embedded automotive rust In my job I get to speak to lots of people about Rust. Some are just starting out, some have barely ever heard of it, and then some people are running Rust silently in production at a very large company in a very serious product. A while back, I had the fortune to talk with Julius Gustavsson from Sweden and he squarely falls in the last category of people. From 2019 onwards, he has been the main software architect for the low-power processor ECU (electronic control unit) at Volvo. This ECU is responsible for the (low) power management of the car. Electric cars obviously have massive high-voltage batteries, but the classic 12 volt lines are still there. Those lines are always on and can drain the battery if there's any power usage, so you want all car systems to be turned off when you're away from your car. The ECU is responsible for waking up the electric system when needed, for example when you approach the car. This ECU was not actively being worked on in 2019 and so Julius became part of a new dedicated team. But even back in 2017, when Julius joined Volvo, he already knew about Rust and saw its potential to replace existing C and C++ code. It turned out the low-power processor was a perfect fit for using Rust! It was not classified as a safety-critical component and it was an Arm Cortex-M processor, so there was no technical or bureaucratic blocker for using Rust. And so it has come to be that, at this moment, EX90s and Polestar 3s are rolling off the assembly line that would not work without their Rust components. I think that's a great milestone for Rust! I wanted to know more about this and thought the world would too, so Julius has kindly agreed to let me interview him. Here's everything we talked about: Q: Why did you pick Rust? Julius told me his first job was building air traffic control software, where a lot of Ada is used. A competitor was even required to use Ada by the US Air Force. \"The language is amazing in its own way. However, the consensus at the company was that Ada was both too arcane and to proprietary for them, at that time.\" And so he used a mixture of C and C++ for about 15 years. \"At all different companies I worked at they all had different strategies and strictness, but memory-related bugs were always a problem\". \"It always felt unsafe; Most codebases have a bunch of invariants and assumptions that are not written down but everyone must uphold. As the project grows in complexity and especially team size, this will inevitably fail at some point. After debugging the umpteenth bug, the thought came, 'Is this it? Isn't there a better way?'\" He had discovered Rust before its 1.0 release in 2015, and began paying more attention to it after the release. So when he joined Volvo Julius had a little bit of hobby experience. He had found it tricky to pick up the Rust concepts and had to read the O'Reilly book twice. However, \"once it clicked, I got very enthusiastic.\" Picking Rust for the ECU project didn't come out of the blue. \"When we were prototyping the precursor to the project, and doing interop with Android, I created a vehicle HAL in Rust using futures 0.1, back in the days before async, for Android that spoke grpc to the Rust system,\" he explained. Describing the project, he said: \"We'd have buttons on the screen to control the fans of the car. I had to write a lot of code before I could compile it all, a big jenga tower. But once it compiled, the fans started to work! Very impressed.\" It was difficult to figure out how to build Rust for use with Android, which was the platform this prototype ran on. Today much more effort has been put in tooling around this, but Julius was there very early. With this prototype he proved to himself and the people around him that Rust could be a serious option for production code; It delivered on its promises. Q: How did it go? Aside from the project being a good fit for Rust due to it not being safety-critical and running on common hardware, it was also quite straightforward due to its limited feature set. In 2020 they had made a first proof-of-concept in C before continuing the project with Rust. What wasn't so straightforward was that the ECU had to communicate over CAN with the other systems in the car and they had to implement all diagnostics systems and port over the standard Volvo protocols. So they needed to reimplement a lot of things. According to Julius though, they \"got much higher quality\". And they found they were writing far fewer bugs compared to C and C++. Julius wasn't the only one really liking Rust. One of his colleagues had to leave and said: \"It's hard to think about having to go back to something that's not Rust\". Still, a healthy dose of scepticism remained. As Julius put it: \"I always had the feeling, is Rust too good to be true? I'm always looking for the big pitfall. So far I have not found anything bad. Only some small things like const generics not being fully done.\" As the project progressed, they got \"a bigger and bigger pile of proof that Rust does actually work well\". There were regular cross-team meetings where team leads could discuss their problems. As time went on it became more and more noticeable that Julius didn't bring up many issues at all and when he showed his results, his colleagues were often left impressed. Q: Would you recommend Rust to others? \"Definitely\", Julius answered promptly. He continues: \"For any project where you have very strict reliability and availability requirements, and you want to be confident that what you deploy is actually correct, then Rust is an excellent choice! Also cargo and all the other available tooling make the whole cycle of developing high quality software a really nice experience.\" Rust also works great for teams with high turnover because there's a lot of confidence in the code. \"Other people can just take over the code and fiddle around safely because when it compiles, it almost always works\". \"For prototyping, then maybe it's not the best option because things are rigid. The compiler forces you to work more on the edge cases and minute details up front, something you are not always interested in doing at that particular point\", he noted. This, of course, is an often expressed sentiment. But to put that in perspective, Julius says: \"Rust would work for most of the software I've worked on professionally. There are absolutely cases where Rust is not the best fit. But I think we're at that point where instead of asking 'Can we use Rust for this?', we should be asking 'Why can't we use Rust for this?' And then you have the discussion.\" Q: What's missing that got in the way? It wasn't easy to create the software so that it properly fit the requirements, according to Julius. This is mostly a tooling issue. For example, it was hard to run the unit tests on the embedded target. Other challenges included code coverage, runtime profiling, software BOM and license tracking. This is my personal experience as well, although the state of these issues has much improved over the last couple of years. Julius and I agreed that it would be very valuable to build more and better tooling. He said: \"Most are halfway there, but you still need to do a lot yourself\". During the project, things got better. Julius explicitly mentioned the Knurling project, for example, and that those tools helped a lot. Q: Are you going to use Rust in the future? \"Yes.\" In fact, Julius is actively cheerleading for other projects to pick up Rust. And there seems to be an overall enthusiasm for Rust at many layers in the company. A couple of days before my meeting with Julius, he had the final project presentation with the management. The result of that meeting was a common consensus among management to look into using Rust in more places. Conclusion From our conversation it seems that using Rust has been a great success at Volvo thus far. People are happy, the quality of the product is high, and the company seems poised to use more Rust in the future. It's obvious that there's more work to be done still, but with more safety-critical tooling like Ferrocene becoming available, Rust is readier than ever for use in the automotive industry. Dion Embedded software engineer dion@tweedegolf.com embedded automotive rust Stay up-to-date Stay up-to-date with our work and blog posts? Related articles June 10, 2024 Tock binary size Tock is a powerful and secure embedded operating system. While Tock was designed with resource constraints in mind, years of additional features, generalizing to more platforms, and security improvements have brought resource, and in particular, code size bloat. embedded open-source rust Read article February 20, 2024 Sequential-storage: efficiently store data in flash While using a full-blown filesystem for storing your data in non-volatile memory is common practice, those filesystems are often too big, not to mention annoying to use, for the things I want to do. My solution? I've been hard at work creating the sequential-storage crate. In this blog post I'd like to go over what it is, why I created it and what it does. tools embedded rust Read article February 6, 2024 Rust for hardware vendors At Tweede golf we're big fans of creating applications on embedded devices with Rust and we've written a lot about it. But if you're a hardware vendor (be it chips or full devices/systems), should you give your users Rust support in addition to your C support? In this blog I argue that the answer to the question is yes. embedded why-rust rust Read article",
    "commentLink": "https://news.ycombinator.com/item?id=41771272",
    "commentBody": "Rust is rolling off the Volvo assembly line (tweedegolf.nl)113 points by ladyanita22 21 hours agohidepastfavorite86 comments daghamm 13 hours agoThe fact that they could go from zero to proof of concept in a year and then into production just 2-3 years later is impressive. Given these results I feel the industry will slowly move to Rust once a certified toolchain for safety critical systems exists. At the same time, let's not forget that this is a highly competent team with tons of experience. It's not guaranteed that other developers can have the same success. reply themoonisachees 3 hours agoparentGive this is already rolling off the production line, the toolchain they use must be certified iso 26262. More than actual engineering (though there still is some), the hard part is getting that certification at all, or you can't put it in a car. reply Cu3PO42 10 hours agoparentprevFerrocene [0] exists today! I'm mainly interested in the space from the point of view of a theoretical computer scientist, so I'm not sure if there's additional boxes that need to be checked legally, but it's looking pretty good to me. [0] https://ferrocene.dev/en/ reply steveklabnik 6 hours agorootparentIn the sense that there are a variety of requirements that need to be checked, there are. Each industry is different. Ferrocene has mostly been driven by automotive so far because that’s where the customers are, but they’ll get to all of them eventually. reply daghamm 10 hours agorootparentprevThat looks very interesting. I think these sort of activities must come from outside because the core Rust team has currently no experience in these areas. reply dostick 16 hours agoprevAfter reading part of article I realised it’s about Rust the programming language. Not the rust-colored car called Rust as author obviously intended to confuse people with that image and ambiguous title. reply pahbloo 6 hours agoparentRust (the language) is rolling off the Volvo assembly (not the language) line reply philwelch 16 hours agoparentprevOr, indeed, that Volvo’s manufacturing quality had declined to the point that the cars themselves were shipping with their bodies literally already rusting reply kevinventullo 15 hours agorootparentThis is absolutely how I initially read it. I’m surprised the title was approved by their comms team! reply wright08 16 hours agoparentprevHuh interesting observation. I wonder if anything in the first two sentences of the article can shed any light. In my job I get to speak to lots of people about Rust. Some are just starting out, some have barely ever heard of it, and then some people are running Rust silently in production at a very large company in a very serious product. Yeah I've definitely heard of people \"running (iron oxide) silently in production\". Super ambiguous reply aschla 16 hours agoparentprevIt's almost as if it was an intentional artistic choice in phrasing... /s reply MBCook 16 hours agoprevThe article mentions a few times that Rust is a good choice because the code is NOT safety critical. Is that because the safety critical code requires the compiler/libraries/etc. to have some certification Rust currently lacks? If not I don’t understand why it’s phrased that way. reply adrianN 16 hours agoparentYes, that's the reason. Certification requirements usually force you to use some ancient niche toolchain. reply Eplankton 1 hour agorootparentAnd apparently Segger Studio says NO to \"old granpa style toolchain\" by introduce this several weeks ago: https://www.segger.com/news/pr-240927-ozone-support-rust/ reply AlotOfReading 15 hours agorootparentprevAnd those ancient, niche toolchains are horribly buggy as a rule. For example, a certain Santa Barbara based vendor ships a high integrity compiler that you can crash with entirely normal standards compliant C/C++. reply SilasX 15 hours agorootparentThat ... feels like it defeats the purpose of designating a special, certified library for safety-critical code. reply AlotOfReading 15 hours agorootparentWould it make you feel better if I told you that these kinds of offerings usually also don't offer modern validation tools like sanitizers? They expect people to just wing it with whatever the proprietary IDE happens to give them. A big part of the job of safety critical development is knowing the difference between box checking best practices/regulations and building actually safe systems so you can do both. reply yjftsjthsd-h 3 hours agorootparentI would assume the solution is to run your code through multiple compilers/toolchains - in dev, CI can run the certified compiler to make sure your code stays compatible with it, but also through modern clang/gcc with every linter and static analysis tool you can think of. Then for the \"official\" prod builds you use the certified compiler. Automated testing should probably use both, and even compare the behavior of binaries from each chain to look out for bugs that only exist in one. That way you get most of the benefits of both worlds (not all, since you can only write code that all compilers can handle). reply AlotOfReading 2 hours agorootparentThat's a common partial solution, but it's not complete. For example, it essentially requires you to be able to observe all safety-relevant behaviors of the code in both compilers. This is a much more comprehensive degree of validation than almost any system actually achieves. You also run into issues where the behaviors you're observing (e.g. low bits in floating point results) depend on intimate details of codegen that aren't identical between compilers. The complete solution depends on the application and the integrity level. It's not one size fits all, but rather about producing documentation showing you've considered various failure modes and developed mitigations for them (or otherwise accept the risk). Sometimes that's binary analysis of the compiled output to ensure it meets some formal model, sometimes that's a formally proven, decent compiler like concert, and so on. An additional wrinkle is that the business model for high integrity compilers can also be a huge obstacle here. Some charge seats by how many people have modified the code that's running through the compiler. These aren't cheap licenses either, so companies have a large incentive not to use methodologies that require many eyes making all bugs shallow. There are also issues running these compilers in CI. They might require online license verification on every file, for example, or not allow ephemeral licensing at all. reply steveklabnik 3 hours agorootparentprevIt isn’t. The idea is to quantify the risk. A buggy toolchain is okay if the bugs are known and you can demonstrate how you’re mitigating them. All software has bugs, you cannot rely on the idea of bug free software to ensure safety, you must have a process that is robust in the face of problems. reply yjftsjthsd-h 3 hours agorootparentSure, but if you can do something to reduce the number of bugs it seems like you should still do that? reply steveklabnik 3 hours agorootparentI don’t disagree that in general, reducing the number of bugs is a good goal, but there’s always a limit to how far you go. It’s not like every line is formally proven, for example. Just because you can use a specific technique doesn’t mean that you must. But also I don’t work directly in these industries and so maybe my impression of this aspect of their processes is incorrect. reply estebank 15 hours agorootparentprevIts not so much about ensuring the best tool chain is used, but rather about setting the lowest bound of quality. By being slow moving it avoids the potential for temporary regressions. It is also ass-covering by demonstrating you followed \"industry standard procedure\". If you do something different, even if it is quantifiably better, it might make for a stressful deposition explaining why the worse but standard approach wasn't used instead. reply darthrupert 14 hours agorootparentprevIf the compiler crashes, no safety-breaking code was generated. reply steveklabnik 6 hours agorootparentprevFerrocene is breaking several norms in this area, and “ancient toolchains” is one of them. They’re able to certify new ones remarkably quickly. reply yjftsjthsd-h 3 hours agorootparent> They’re able to certify new ones remarkably quickly. Do you know how they do that? Is it something special about rust, or some process improvement they're doing? reply steveklabnik 3 hours agorootparentI have some knowledge but as an outsider. For example, rustc has a very large test suite that is run on every single commit. There is also a language reference that describes the language in some detail. One of the things Ferrocene brings to the table is the paperwork and auditing that the test suite corresponds to the specification. With other vendors developing their own toolchain, they would have to do all three parts of that work (well, in the case of C or C++, two ish not three, since they have a specification, but there are always extensions and platform specific behavior to document) instead of just one. This isn’t the only thing they do, but it’s one example. It’s not so much something special about Rust in an abstract sense, but in the practical sense that the Rust Project takes robust software engineering seriously, and being downstream of that is useful. reply MBCook 16 hours agorootparentprevThanks. I figured that was the most likely. Is that being worked on? Rust seems like a much better choice than C or C++ to me. reply rhaps0dy 16 hours agorootparentYes. Adacore is working on it. They announce the first qualified compiler, for some qualification, here: https://www.adacore.com/press/adacore-announces-the-first-qu... reply yababa_y 16 hours agorootparentprevCheck out the requirements in AUTOSAR and MISRA, it’s more than just certifying some golden toolchain. Although Ferrocene is working on that as well :) https://ferrocene.dev/en/ reply estebank 15 hours agorootparentYou might also want to check out this comparison of MISRA's rules against idiomatic Rust code: https://github.com/PolySync/misra-rust/blob/master/MISRA-Rul... reply carlmr 9 hours agorootparentprevVector has AUTOSAR with Rust modules using a certified compiler now: https://www.vector.com/int/en/news/news/safety-applications-... reply bschwindHN 16 hours agorootparentprevSee ferrocene: https://ferrocene.dev/en/ reply jbit 15 hours agorootparentprevHightec also have an ISO26262 qualified compiler focused on automotive: https://hightec-rt.com/rust So there's lots of focus on having a good alternative to C/C++ reply bmitc 15 hours agoparentprevThe article also does absolutely nothing to motivate the choice of Rust. It's not like it's hard to find a better language than C or C++, so why Rust? Ada seems like it wasn't even considered, as the only mention of it was at the person's first job, some 15 years earlier. For example, if running on Android was a requirement, what made Rust a better choice than say Java or Scala? The article doesn't explain anything as to why Rust was chosen and why it was (supposedly) a win, as anything mentioned as a plus is superficial enough to be covered by dozens of other languages. reply Larrikin 12 hours agorootparentIn Android development, Java is basically deprecated at this point and Scala never really worked well. reply bmitc 6 hours agorootparentSo is it Kotlin? reply Larrikin 4 hours agorootparentEverything is Kotlin unless you have a specific need to use the NDK. reply exabrial 16 hours agoprevSorry for dumb question, but does rust have an LTS release? Seems like it’s a lot of nightly builds still reply awestroke 16 hours agoparentThere's a nightly build every night. There is a stable release every now and then. There are no official LTS releases. The question has been asked every now and then, but I see no real need for an LTS release. Just pick any version and keep using that specific version for as long as you want to. You could pick the same version as some LTS linux distro version. reply GolDDranks 15 hours agorootparentThe stable release is every 6 weeks, i.e. once in a month and a half. Only the newest version at the time is supported. The qualified Ferrocene toolchain has \"2 years of patch releases for select versions\", so they have 2-year LTS releases, but that's a paid support plan. Overall, the Rust community hasn't felt much need for official LTS releases. reply daghamm 10 hours agorootparentSerious question: Can you really call it stable if it is updated every 6 weeks? reply GolDDranks 8 hours agorootparentEqually serious answer: yes, if it doesn't break backwards compatibilty between the updates. This is what the Rust project means by stable. You can update and your code will continue building. (There's a bunch of documented caveats though.) Rust has been stable in this sense since 1.0, almost ten years. Of course, you might have different semantics for \"stable\". Some seem to mean \"rarely updating\" or \"each update is small\" by that. In the latter sense, too, Rust has becoming stabler over the last few years. In the \"rarely updating\" sense, Rust is not going to change course. Frequent, time-based releases have demonstrably made the progress smoother, and in a sense, \"stabler\", as in, more predictable and bug-free. reply consteval 2 hours agorootparentprev> but I see no real need for an LTS release For one, providing approved and certified toolchains for safety-critical systems. reply bmitc 15 hours agorootparentprev> but I see no real need for an LTS release What makes Rust special over other programming languages and operating systems and software systems that have LTS releases? For example, .NET and Ubuntu have LTS releases. reply plorkyeran 14 hours agorootparent.NET and Ubuntu are notably not programming languages. C# does not have LTS releases. LTS releases are for things which end up in your runtime environment. Compilers typically don't have LTS releases because there isn't much room for critical bugs which aren't discovered for a long time. Rustc (as with most AOT compilers) does not attempt to be safe to use on untrusted source code, so a bug when it's given a malicious file isn't a security vulnerability. It's theoretically possible for rustc to have a codegen bug which causes security problems in the code which it compiles, but in practice such things don't really happen and there's nothing unsafe about using a ten or twenty-year-old build of a compiler. LTS releases of the rust standard library could potentially need to become a thing. That could have bugs which need to be backported to old versions, and I assume it just hasn't really come up yet. reply miki123211 10 hours agorootparentThat, and then there's the fact that due to editions, modern Rust compilers can still compile older Rust code, which isn't always the case for other languages. There's Python 3.10 code out there that won't run under 3.13, especially so if it relies on components written in C that use Python's C API. If you didn't have LTS releases for Python, you'd have a choice between constantly having to port your code to run under the latest Python version or using an older, insecure one. Rust doesn't have this problem, old Rust code should compile just fine under newer versions of the compiler and stdlib. reply pjmlp 4 hours agorootparentEditions sales pitch never mention the fact that only applies to small grammar changes, your code will break if there are library or semantic changes across editions. reply tialaramex 2 hours agorootparentYes and no. Yes obviously this just works for \"small\" grammar changes such as introducing new keywords without fear (which is why Rust's async is called async, not \"co_async\") and doesn't need awkward keyword reuse like \"requires requires\" and \"class enum\". But it enables far more. Lets take an existing edition first, in Rust 2021 Edition (what you get today out of the box when you just start writing Rust) the array types impl IntoIterator. Which makes sense, why shouldn't I iterate over this array with a for loop ? But, Rust 1.0 could not possibly have provided this, how would it work? It didn't in Rust 1.0 you can't make an array into an Iterator. Now, if this was some obscure rarely used feature maybe you'd just say \"Who cares\" but this is IntoIterator which is used to make for loops work, so that's high profile. So in fact what happens is that a modern Rust compiler (in which there even is a 2021 edition) knows that in earlier Editions it should pretend that arrays did not impl IntoIterator. You can loop over them just fine, but mysteriously they don't impl IntoIterator, so that code which used to mean one thing (because they didn't implement this) still means what it used to. So that's an example of seamlessly making Rust 2021 edition have better semantics and yet all the old software still works. In 2024 edition the semantics of certain RPITs (Return Position Impl Trait, an existential type) with respect to lifetimes are expected to change. In most cases either what you wrote already is technically wrong but will now be correct, or, what you wrote was wrong but you got away with it and now you'll get told you got it wrong if you move editions. Editions is not a panacea but it's vastly better than the previous status quo, look at how miserable the situation is in Java, in C++, in Python. Vastly different approaches, worse results on all dimensions. reply pjmlp 1 hour agorootparentI still don't see it being much different from using language switches, especially when language semantics, ABI across versions, and standard library are part of the whole upgrade story. Additionally I have my doubts how long this will scale when Rust has like 40 years of history behind it. reply pjmlp 13 hours agorootparentprevYes it does, C#, F#, VB, C++/CLI versions are tied to specific .NET versions. Not only do they depend on CLR changes, they also depend on the BCL that is shipped alongside. reply AlotOfReading 15 hours agorootparentprevC++ is the most direct comparison. Neither GCC nor Clang have LTS releases. MSVC does via Visual Studio, but I've never seen anyone list it as a benefit vs the other two. What advantage does LTS have for compiler toolchains if no one seems to want it? reply pjmlp 13 hours agorootparentThey kind of do, that is why you get GCC 10 when GCC 15 is around the corner. ABI stability for one. reply slicktux 16 hours agoprevSo, will RUST ever have standards for safety critical systems like C/C++. Example MISRA for car programs? Or is the migration or certification too expensive and time consuming? reply BD103 16 hours agoparentYou may be interested in Ferrocene[0], a version of the Rust toolchain that is vetted for critical systems like automobiles. It's offered by Ferrous Systems, the same people who help maintain Rust Analyzer (the de-facto LSP for Rust). [0]: https://ferrocene.dev/en/ reply AlotOfReading 16 hours agorootparentNote that what Ferrocene is currently offering is a toolchain. Things like core and std are not part of the current certification package. It's an incredibly exciting offering, but it's not quite ready to ship today. The fact that the certified toolchain is just the normal, publicly available one is great too. reply tialaramex 1 hour agorootparent> Things like core and std are not part of the current certification package As with C++ I'm not sure this makes coherent sense because of the relationship between the language and some elements of the supporting libraries - with respect to `core` specifically, the Rust programming language requires some of core. Suppose you write a for loop. In Rust that's just sugar, and it's de-sugared into a loop that uses IntoIterator::into_iter, Iterator::next, Option::Some and Option::None which are all from the core library. reply AlotOfReading 1 hour agorootparentHence the warning. They're not separable, but it's what the current state of the offering is. If you ship core anything depending on core or std, the burden is on you to ensure those parts of your code are appropriately qualified until they can get the situation sorted. reply estebank 15 hours agorootparentprev> The fact that the certified toolchain is just the normal, publicly available one is great too. And speaks to the standards of quality that the project holds itself to. reply steveklabnik 15 hours agorootparentYes, Ferrocene is able to be qualified more easily in part by how good upstream development practices are. A lot of qualified compilers need to be written from scratch because the existing compilers do not do testing and other things that are required for qualification, but the upstream Rust project has a development process far closer to a safety qualified compiler than not. It’s something worth celebrating about rust as a project. reply slicktux 16 hours agorootparentprevThank you for the reference! Will definitely look into this! reply bmitc 15 hours agorootparentprevI was recently looking into things along these lines, and my understanding of Ferrocene is that it's just regular Rust with extra tests added. I'd love to know if that's accurate or not. If it is accurate, I've wondered why Rust doesn't just include those tests in the core build. reply steveklabnik 15 hours agorootparentIn my understanding, no additional tests, but some additional platform support. The issue isn't more tests upstream, it’s more the chain of responsibility for guaranteeing that results are connected to the specification and all of the paperwork that’s required, and ensuring it is accurate. reply howenterprisey 16 hours agoparentprevI looked into MISRA specifically for my previous job and Rust effectively complies with most of it out of the box, and what's left is either inapplicable or not difficult to catch with further tooling. reply nextaccountic 16 hours agorootparent> further tooling. Just a heads up, Rust does have further tooling. I wish they were more widely used Here are three of them https://github.com/creusot-rs/creusot https://viperproject.github.io/prusti-dev/user-guide/ https://model-checking.github.io/kani/ reply Eplankton 1 hour agoparentprevhttps://www.segger.com/news/pr-240927-ozone-support-rust/ reply monocasa 16 hours agoparentprevThe ferrocene morph of the toplchian is ISO 26262 and ASIL-D, and as this blog post is about rust in the ECU of a production vehicle of a large manufacturer. It seems like it already has support in the relevant safety critical standards, at least in the automotive space. reply RealityVoid 12 hours agorootparentDifferent kind of standards. MISRA is a coding guidelines standard, ISO 26262 is a functional safety standard, it concerns the whole system, including processes and the tools used (here is where the certification from Ferrocene and HighTec step in). There is overlap, but they mostly do different things. reply RealityVoid 12 hours agoparentprevSAE has a coding standard in the works for Rust in safety critical systems. https://standardsworks.sae.org/standards-committees/safer-ru... reply _giorgio_ 16 hours agoprevYou don't want to see any rust in a brand new car. reply truetraveller 16 hours agoprev [–] When I see a Rust post, I don't buy into the hype. It's usually compared with raw C, even C++. This is not a good comparison IMHO, since C/C++ has too many footguns/confusions. Instead, compare it to a nicer/stricter \"C\" equivalent like Zig. Now, Rust doesn't shine as much. reply stackghost 15 hours agoparentI actually think embedded is one of the few places where rust makes sense. In 99% of cases outside embedded, a GC'ed language would be better, but a long time ago someone started the meme that GC is slow, or that your users will notice the pauses, etc but those fears are massively overblown. But on embedded where resources are constrained and you can't run e.g. a JVM then Rust makes sense to me, since you can eliminate a whole class of errors from the get go. reply Nullabillity 4 hours agorootparentUltimately, a lot of Rust's safety features (which I'd argue are desirable everywhere, regardless of performance) require the sort of precise tracking people complain about. And once you have that, you might as well use it to free memory too. The idea of \"Rust but GC\" is fundamentally nonsense, because for GC to make sense you'd first need to rip out so much of Rust's selling point to begin with. It mostly seems to come from a perspective of \"But surely all this GC research must be good for something, right? Anything?\", rather than a concrete idea of where the GC would actually help. reply sham1 15 hours agorootparentprevI would imagine that the kinds of embedded systems like cars would probably benefit from Ada instead. Not only is there of course SPARK, if one wants to do formal verification, Ada has a proven track record in things like military applications. Of course, passenger cars don't have quite the same level of care needed as military stuff (although a lot of care is still needed since cars are hundreds if not thousands of kilograms and can absolutely kill people), but I could still see Ada being useful even in the automotive industry. reply kstrauser 14 hours agorootparentI’m not sure if that’s true. I’ve never been around things like airplane flight systems. I have been trained on other military hardware with instructions on how to reset it and under which circumstances. I wouldn’t be utterly shocked if an F-16 pilot learns that which such and such happens, you flip this switch back and forth 3 times and then turn this other knob to reboot the computer. You would never, ever get that to be an acceptable procedure for a car’s anti-lock brakes. reply stackghost 13 hours agorootparentprevYeah I agree that Ada is probably technically superior but when has that ever swayed anyone. reply carlmr 9 hours agorootparentI'd say Ada is a great choice, but I wouldn't call it technically superior. Some Ada features are nice (e.g. delta types for fixed point calculations), some Rust features are nice (e.g. very expressive ML inspired type system with sum types, borrow checker helps with concurrency and memory lifetimes, ...). reply pjmlp 13 hours agorootparentprevYes you can, that is the whole business of PTC, Aicas and microEJ. PTC real time JVMs are famously used in military deployments, and you surely don't want pauses in a battleship targeting computer system (Aegis), or missile tracking system (thales). reply stackghost 52 minutes agorootparent>Yes you can, that is the whole business of PTC, Aicas and microEJ. I'm saying that not all embedded devices have the horsepower to run a JVM. Nobody's running Java on the automotive equivalent of an 8-bit AVR, for example. >you surely don't want pauses in a battleship targeting computer system (Aegis), or missile tracking system (thales). That'd be the 1% of times when it does matter that I alluded to previously. reply bmitc 15 hours agorootparentprevI even think on embedded it's overblown in terms of not being able to use a GC language. C#, F#, OCaml, Java (and I suppose all JVM languages), Erlang, Elixir, etc. can run on embedded devices, including some microcontrollers. In my opinion, the software industry has dug its head in the sand thinking that only \"hard-core\" languages can be run on embedded systems. Even LabVIEW could be a choice if the limited SoM hardware selection is okay. It's just as performant (if not more so for multicore systems) and infinitely safer than C/C++. reply AlotOfReading 14 hours agorootparentThere are embedded Java systems. I hope you never have to work with any. In general, embedded systems suffer from severe lack of tool developer attention. People standardize on the very few things that reliably work like C, C++, and printf debugging because they don't have the bandwidth for anything more. Anything outside the beaten track has a high chance of running into showstopping bugs halfway through a project and embedded teams are already struggling to find developer time in the typical situation of 1-10 people maintaining 1M+ LOC codebases. Rust is the first real alternative to C and C++ in decades because it's actually trying to address the ecosystem issues. reply Eplankton 1 hour agorootparentNot even \"printf\" is included in any standard, I'm afraid. Arm's Keil MDK toolchain has an typical implemetation of baremetal C/C++ environment called microlib, but unfortunately it doesn't support RTOS because of the missing of re-entrancy, so you have to provide or use a third-party alternative. reply itishappy 5 hours agoparentprevZig looks quite interesting, and I'd love to read about how it's currently being used in production too! Anybody got that article? reply tmikaeld 5 hours agorootparentThe most famous project is Bun, the Javascript runtime reply timeon 11 hours agoparentprev> Now, Rust doesn't shine as much. Except for memory safety. reply pjmlp 13 hours agoparentprev [–] Zig is Modula-2 type system with revamped syntax for C folks. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Volvo has integrated the Rust programming language into its assembly line, specifically for the low-power processor ECU in electric cars, due to its reliability and reduced memory-related bugs compared to C and C++.- Julius Gustavsson, a software architect at Volvo, has played a key role in this integration since 2019, leading to successful outcomes and high-quality products.- Despite initial challenges, Volvo plans to expand Rust's use, viewing it as a valuable asset for projects requiring strict reliability, although improvements in tooling are still needed."
    ],
    "commentSummary": [
      "Volvo has successfully implemented the Rust programming language in production, transitioning from concept to production within a few years, highlighting its growing adoption in the automotive industry.",
      "Ferrocene provides a certified Rust toolchain, compliant with ISO 26262 standards, which is crucial for safety-critical automotive systems.",
      "Rust is favored for its safety features compared to C/C++, with regular stable updates every six weeks, although there is ongoing debate about the suitability of other languages like Zig or Ada for similar applications."
    ],
    "points": 113,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1728336641
  },
  {
    "id": 41773559,
    "title": "The costs of the i386 to x86-64 upgrade",
    "originLink": "https://blogsystem5.substack.com/p/x86-64-programming-models",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"blogsystem5.substack.com\",cType: 'non-interactive',cNounce: '59527',cRay: '8cf862701b3c2f59',cHash: 'f1165fa4c7aed81',cUPMDTk: \"\\/p\\/x86-64-programming-models?__cf_chl_tk=nU7.tDE3xGeQTmlZcM4cbCaxMmxUEG.isWbsyne8rfw-1728414138-0.0.1.1-4223\",cFPWv: 'b',cTTimeMs: '1000',cMTimeMs: '120000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/x86-64-programming-models?__cf_chl_f_tk=nU7.tDE3xGeQTmlZcM4cbCaxMmxUEG.isWbsyne8rfw-1728414138-0.0.1.1-4223\",md: \"C54GmgFM2NjuAWAeRKXUVB_KWmQuPFEHRwbpnxMsHi4-1728414138-1.1.1.1-nNBDz3oKOm3d2KbNd0aalewz4lx1RuwT._L8qXUBc25VrvtRADT77eD5ktBg58I4r_w6fZxAGF2TkW0EgRYjN6gM40WS3NwSW8Xe2IyQZXkre3adpTxthZkS_.4ku_eI03uXT.5SctOBfx6Yj2PdpUSy5ZPYfI5OP52Kdsd8A_8EGWCogKzHEZGpkHPphXiH_GNXv63CZ8_Z1lFzyVujyDRq1._5QTOn4qtB_X4wOT18u8FXa0ovcz1PuHuvRkqkjS0GgTsZbyjnZfdBVinhamviVkff6g1cfLut_a_X2dQQl04uCuGiMO7c1PAbdVJmAefsbRP23qNBgDoZ55CYtz6v_jRPbYA9c5z7lTox6jqSFGFVKtB8ju2oFZ_VE_O.spbJdbKzyf76MdieXuGtQf1Vk1rvFnsR6Qe3OnUYpTuNSXzX7pRY0oOfMaI0cc.YCPkMAf5yuxkhAnP0UoP7NQETkSlVTo1lfqRETDpBQLZ5.IFrrq1zEjpvDmb2FfhC.f1Yhe2Iha4XPQTv8IkTkXx9BY0_kZwzKe1BaQNBqbP43pljB41p.sED0WQjOM.oFcb34FK_HU1j87vvDJXjWPBpfzD.5YKN6IZK.VDXkNHB.AnDMEDP3e4tGMf7f4TNrgoAeTcXl5Navp2d.n3oR_smyFYP_OdhVJBl.qR_3ZJJyQIiBEyO_v0qv2vcXBLW9rG8CIvxa_ZHK1B7wS.doew4KXF2YGYQJQxndtOaHquBiU8lkekADywvkDRFTmqkZDVLZ74xGAu.HQ9bx1qPqeieZU9l2WIz5zq8EI05Esx1fNfCbOXCIKMtuD09sdWeh0jaMjBmH4R5E98xg5LrmdIMU9Jjkdxq46d5mTIQlZTELRClIOAicsUddVqnRqvtD3nXqXIeWHy6Uu8uVOQFloENzmyHHhyhyGvGedE6d2LWK0zcLx5mPAKcjtCBxIxeBwaMvkhJkvaFHid7W2SZmXDkZaofqBwVL72xtuw1LvUZ_cNP1bBziwsR3gXicNueP82tlbJ2716bwxQF382UQsmcVraUP8OJ_vV_J4zYYnxub5phDTOgGY8JNE6wUXEFpxZJXhQTB.qSCPioBI538YyV8L1pE_CcB6LQGA1KcE590TwZRT4vBRX.ak2bpP.L5egEUbWwYhMKkYuIfDy8u8LuJhtN1FjNrwh3Dgjrh7M0Sv1PyaE_Jd92S2_u461df0IFM4EVAKgqx0su5ntnXtUPDik3XgWtChNaqzB6fsAJ23NdFWl6KzrxEBL1TTsJQ2zDNwlHQMoujQzCuvhFqm6acBmyoU3g4NyH1sBnKVGwYOU4e5f0alKsj802u1e6brHK5dIAryoBAH6BPMo1HOJ1nfEGHyf66.v0XPkIdsDCnUgK1oQCKzbn50pTskM.Nyc.RDaHRHBN54MoDjhQkQFeB7seyXUtGTrmrJM8IpFQ.oUi3Mo_6OLbreWjAd9pUh8m0GhnaWjaqOwlDUzKZlTS7TEj7VPHE5_fmHGwf_wRNymxAyIx2oxYqlZfPpsHD89tJWtzdggsRS1YsylU6Nlj5Rd6MznvE7d.8zU0Iq5z1Hdbyrgtsu1KY3keIRRlHjJxtzp5DyFftRa_9ZLKg4ovEg1fJN6.66gy4L0ELxwXorUSjmMR2D28_UOa.9V7TYdfWDSo1snYURwxBwCS5g\",mdrd: \"duYF4U2oqMFjmIXQis2vMmSRti0L3HVL6vWf0A85KhI-1728414138-1.1.1.1-dwKwFVsbvwvvWorMgvtExopxb.tg.1eXgoJStMiDWIbDj_Qcd1t2v8NcRm3ljW9ISiPyxDWyNpvlUbWiWju8QBWpeH6vdNfiZb_3b9xAs2Ee_h_A0WbuBwiWEuyjv7.Hpss7k074AKLrj.KHnuOG81myLLgio__foqIhnYS6bOBYA0bqOc5EVmm9dwxin9yPKDgPL6Ac6yAUa60ax8Re.lb_sBMFPL_F1PV8dUPMKcp0W08lmpJc5D5hlCMIVPst4R_kXC2evjXK5VRTfQDxUKyi4EwnKgqA6JnpGZtLQEsQa9si7BSQvqs6cG_.dgGD3ezLbpLKI8LdejwqzEGPnQk7JOT0f5cEaUoWSlCTeO3_igj1cwA5Ny0xhzG.BZU7rekT0UqlL_lkzx6ahNVutemyQsgVd_.XuNw0TpsksswjVaaKkFQXDIzv9tf_NMRfJuU1683x.EfnKOv6eM1rujOGRXf_Zi_rOeLCLgNxmmeQdqMXeIEo8I1eVwFXcXqH8mLD0Fuq07cmb3dCXzzn7pJStFTmJr66BLY.pI4YxiuKzChSU4RiXon1rkJkqZFla6QaFevZTruGPD6AB4fT3Z70uNO.UKp8n_eykRf9dvh9T8d1jrp.fOGQodZN0qTCEKB.6V9hFoNPi3plctljicvUX4ARx6vSj3Dj2B_2bqC0H26FixNiTAuPRAoNdw8IgRFiMgZl9O0akOg8XAgTojtUo1s0ch83tS3X1.HF3mBNzgTB9loJQJpUgjT7eYrUKq7RZx8.tc2ibkLK.qcSgQH9vIcFdR3CeSyrrYQr2GnUB8IRV5YpU2V_IWgvjlvxZjiX6OUJTzkZ5GwOXyFHXpEbtjH8MpnHunsGDmiAfB8Nn5rn0q8zsuySR_IHdU07HyYRm.THotUW55lC6vAplBHNBQUD9g1TDoQM.F1np5bCmeH2PawJHdKu6.rpeQIrKKEj63OU5iGiNaQmIaI58RETt4JT2722_hIv7pTWEcPicA4oowModSeGFXznZBtgQBB1Ic3piChv7E03X2bLNkaA6HY6USorl6.jTqLPpVnZPMYBtwVKqgrCvCr7wlKUa7u6m_DK7ONhckjLl3aDBKV17tFyrwXSCDwCF2nD6WCmWAqrpAjv1Kjfwl0zyqwn4aybcoWVRBhuhmREz3XVV26n.89Kf_fhLF_I2ZMp6QLNomOXqFr4pevTTb5CPpzjgiFJi3Pu4tAKYaTT4HJb4BbUqd_xc7HfB.p3a4ltJsLvGuvIqTWms.xcWVn6TmeQI80gRw48qdL6Hhvs7Q7sG4WRL0LQYjNnMgFUoHx4FsaEoyGmjwiahOvDglDhS6oKfHpn7to9.ki8dqgStO8hbK5wlnb_l.qU9uO1jDHoEv869__.JpTLiBnKyliMNF332lij5M2I3uB3Hi6cibiXE32FdEvz.zo5tdlF9mL0i07eNI7AFwp.IIcynFGdME3YFIKAlDWxZs1MlYLslR1GHlUrQxI5qn61eJe.XeylAKAT0cc1bP32ydbSIWfYUaCqYUFMf0mO4WynyrDuEKHj6ZgHjon1xtZydlLsOBnS7edS57citNnRIRPhl0E_oeKFw67U0Qm.V8PyVsKJbfFJYoaxOjdmhsJgpYnxOyltDzeI37n6g1pMDKuWcwTgbOca9w6W1zNlf7eIfyCTut0Que23msSBKad8P_afupCWiqXRdda.ppAeZSWI9xYpXZ1H8mHwcfDOduQk_8n_dFJOuIBGQYdIXKC8Rz6moo8vg96w21r55dsBWwTCQm0Wjs3MHRb6C6ZybwBZYAHDkxDe2PO48ujrs7tYwII4cpCnxNTGnmGzKpCmn52hdjHd2BefQjGURV.M9Zjad2bS0VXYCl0uAICZy.1KBhMuTwHJLGyWW1i.vz4N_qndNHgqm8k.xHFKGymbE7auDqaAG5LCzupebhmIFHud_lZ_aVuiiK4J0tDYCFkNHjdhH6DJ3lakuTlYbNRfVfQtZsqhbddDbno_8kDHj3L7Za1UfpQ3Lr_6SF5.uG9VhyFDaCQfON9nK_Of05cl9iMoZGtoKGu81B3PqlJ314PWTtr2qVaLuroSPqpr.b57hy5s2cZWnD4QcpJyAscQwUmDSWcYj7UMbeENZ43Hl1naQXTWFkiU4ffCuBz7UJ0g6sCxzo4aTNOkyR_estHhRfMHav4G9z7208vJinIcqxFpUiMNnMWBCcamHlWny9bBKNZazuPjl6YvZmGExC717GrPoeQVJ4BUbhPcKj6Ta6cuPcOzmwhhdgSsewTfBJCnx50dY9MwRRBwc4HJW3smebr6fRBPkkebVE3kr8OCkQrIIyFaunD8fh9sB3mhhar.pzc_wSlwhnRoiMacwT525s06WztA4lrdkYERINkEomX4dIKZohaXS1E\",cRq: {ru: 'aHR0cHM6Ly9ibG9nc3lzdGVtNS5zdWJzdGFjay5jb20vcC94ODYtNjQtcHJvZ3JhbW1pbmctbW9kZWxz',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',d: '02pXhCI3ZRiDigMbPczdv2ds5+DsFePunJrzLDQiO/S+FWz9gIC3BXyLVH2+a1Oqj03XBOp+3yWiF4dzWvLOl3xfUOCCSaVl0/2OArfteAbT0s7c5YB2gDemCyGsL52oOtfcdzjARKyxfe30JtBk2gY9j+3KTxmd3oaEVZ9S8HR3EZg5YL5A9FG1wtSIgy0FghNgdBgH91ECetrO+h/PDOl8VbDhJNGczOvuGf7HMpXsRWzJweTTVwuT1NsAEMfhFucnr6cjoW4kIYjiK6coygNUW4cUU1G6G+ptQ0r8dMrRNaX2HhavgpF0E7dTFFHNZKTuWumBbpzJOL2BtAZo+R2gZFroj+G/hSQe19CTnQfr5e2o1JKfGKX9lYeP9mnU/gAQ2qS53ZhYgXN69ketM8ji5/XVStVgfutSb84DsBak41jJlCcr8ZqQgb5VMk3LqvqKgsZ8a0N5WVSBphhCbarb5kJ+IhCdGqGjLoZ/eT7mPFbWti4IM0gr1rxZ76ppsp5rWqYEhV0RJZcLEV/aRaOo798dnliVvreNZCZMIX+VO4aZu3y1vusB13TN7qdLZG+fwUWYoCM4enDqagq49w==',t: 'MTcyODQxNDEzOC4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: 'NdyuZQzJzLiR4ed69GfNxxsVVbn4esP+E5a8JjkyJQM=',i1: 'xrkspbqR3RVHPhiUvMb9KQ==',i2: 'KtSiHyJVyFKGDkc7dI3W7g==',zh: 'o01jypKJQ++/gkxUTvC40nYpXBhuMc66cm0hd/Tc920=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'qVPvx9fvIt0on9xRjk6t5D9VxGQ9+waVjpZi/ZAxFDY=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=8cf862701b3c2f59';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/x86-64-programming-models?__cf_chl_rt_tk=nU7.tDE3xGeQTmlZcM4cbCaxMmxUEG.isWbsyne8rfw-1728414138-0.0.1.1-4223\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=41773559",
    "commentBody": "The costs of the i386 to x86-64 upgrade (blogsystem5.substack.com)100 points by thunderbong 15 hours agohidepastfavorite61 comments armada651 6 hours ago> We now know that LP64 was the preferred choice and that it became the default programming model for 64-bit operating systems That is incorrect, Windows never adopted the LP64 model. Only pointers were increased to 64-bit whereas long remained 32-bit. The long datatype should be avoided in cross-platform code. reply jagrsw 5 hours agoparentAll C's native datatypes should be avoided for cross-platform data structures (networking, databases, file storage) because the standard only guarantees minimum sizes. Additional problem is the endianess. uint64_t is a bit verbose, many re-def this to u64. reply coldpie 5 hours agorootparentI think I agree, but I'd be interested in more discussion about this. I always understood the native types to be the \"probably most efficient\" choice, for when you don't actually care about the width. For example, you'd choose int for a loop index variable which is unlikely to hit width constraints because it's the \"probably most efficient\" choice. If you're forced to choose a width, you might choose a width that is less efficient for the architecture. Is that understanding correct? Historically or currently? Either way, I think I now agree that unspecified widths are an anti-feature. There's value in having explicitly specified limits on loop index variables. When you write \"for(int32_t i; ...)\", it causes you to think a bit, \"hey can this overflow?\" And now your overflow analysis will be true for all arches, because you thought about the width that is actually in use (32-bits, in this case). It keeps program behavior consistent & easier to reason over, for all arches. That's my thinking, but I'd be interested to hear other perspectives. reply 2ndbigbang 5 hours agorootparentThere is int_fast32_t and int_least32_t but it is probably less confusing to just use exact sized types (and would make porting to other architectures simpler). reply kibwen 4 hours agorootparentprev> I always understood the native types to be the \"probably most efficient\" choice, for when you don't actually care about the width. This itself is a platform-specific property, and is thus non-portable (not in the sense that your code won't run, but in the sense that it might be worse for performance than just using a known small integer when you can). reply marcosdumay 1 hour agorootparentprev> I always understood the native types to be the \"probably most efficient\" choice Both of int32_t on Windows and int64_t on Unixes can't be the \"probably most efficient\" choice on the same machine. Besides, struct bloating is a perfectly fine C optimization that your compile can do at any time to get the most efficient implementation without that \"probably\" part. It almost never does, tough, because it's a shitty operation and because CPUs that handle 64 bits perfectly but fumble around with 32 bits are a historic oddity only. reply nyrikki 3 hours agorootparentprevHistorically that is incorrect. Remember that the C standard came about many years after the language was already in use, the C abstract machine wasn't an explicitly design for portability and performance, it was documenting an existing system. C compilers being performant and portable is partly due to luck but mostly due to hard work by very smart people. Last time I looked, clangs analysis and optimizing code was more than a quarter of a million lines as an example. C being imperative is probably a lens for understanding how the type of optimization you are talking about are opportunistic and not intrinsic. Another lens is to consider that the PDP11 had flat memory, but NUMA, l2 and l3 caches and deep pipelines make the compiler far more complicated despite maintaining that simple model on the abstract machine. Ironically, FORTRAN, which was written on IBM machines that had decrementing index registers. While the base one indexing is explained as being simply a choice of lowest value. In the historic context is is better conceptualized as a limit index. That more closely matches what you are describing above. If you look at the most recent CPP versions adding ranges, that is closer to both FORTRAN and the above IMHO. https://en.cppreference.com/w/cpp/ranges That history is complicated because Dennis Ritchie's work on college was on what he called 'loop programming', what we would call the structured paradigm today. That does have the concept that any loop that you know the number of iterations will always halt, but being imperative, C doesn't really enforce that although any individual compiler may. C compilers are u reasonably effective in optimization, but that is in spite of the limits of the C abstract machine, not because of it . As shown above, all it takes is one powerful actor like MS making a decision, that probably was justified at the time, to introduce side effects across all platforms. Often it is safe to assume that the compiler will make good decisions, other times you have to force it to make the correct decision. But using the default types is a decision more of a choice to value portability than about performance IMHO. reply nyrikki 3 hours agorootparentProbably should point out that for loops in C are syntactic sugar for while loops at the language level. for loop Executes a loop. Used as a shorter equivalent of while loop. https://en.cppreference.com/w/c/language/for I am amazed at how good compilers are today. There is also the difference between portability, where it means it compiles vs meaning that the precision and behavior is similar across platforms. long would be more portable for a successful compilation but may cause side effects. I shouldn't have switched meanings in the above reply context. reply af78 4 hours agoparentprevThe article focuses on Linux and FreeBSD, which are LP64. reply zokier 10 hours agoprevI find it weird that the convention to use char/short/int/long/long long has persisted so widely to this day. I would have thought that already back in the 16 -> 32 bit transition period people would have standardized and moved to stdint.h style types instead (i.e. int32_t etc). Sure, that doesn't change pointer sizes, but it would have reduced the impact of the different 64-bit data models, like Unix LP64 vs Windows LLP64 reply jraph 8 hours agoparentI see two good reasons: (1) DX: typing \"int\" feels more natural and less clunky than choosing some arbitrary size. (2) Perf: if you don't care about the size, you might as well use the native size, which is supposed to be faster. In Java, people do use the hardware-independent 4 byte ints and 8 byte longs. I guess (1) matters more, or that people think that the JVM will figure out the perf issue and that it'll be possible to micro-optimize if a profile pointed out an issue. reply Tuna-Fish 1 hour agorootparent> which is supposed to be faster. If you care about this, you figure out exactly how much you need and always use the smallest type that meets this criteria. There have been architectures in the past where the \"native\" size was in practice faster than the smaller types, but those architectures are now long dead. On all modern architectures, none of the instructions for smaller data types are ever slower than the native size, and while using them doesn't directly win you cycles of execution time in the cpu (because they are no faster either), it wins you better cache utilization. As a rule, the fastest data type is a byte. There is no reason to ever use \"int\", other than inertia. reply epcoa 2 hours agorootparentprev> Perf: if you don't care about the size, you might as well use the native size, which is supposed to be faster. You always care about the size (or should), especially if you're writing C or C++. Though it is often reasonable that 32767 is a sufficient limit and you're guaranteed at least that with int. reply loeg 1 hour agoparentprevThe stdint types only date to C99. 32-bit transition happened much earlier than that. reply chipdart 9 hours agoparentprev> I find it weird that the convention to use char/short/int/long/long long has persisted so widely to this day. I don't think this is a reasonable take. Beyond ABI requirements and how developers use int over short, there are indeed requirements where the size of an integer value matters a lot, specially as this has a direct impact on data size and vectorization. To frame your analysis, I would recommend you took a peek at the not-so-recent push for hardware support for IEEE754 half-precision float/float16 types. reply zokier 8 hours agorootparentThe cases where you want platform-specific integer width (that is not something like size_t/uintptr_t) is extremely niche compared to cases where you want integer to have specific width. I don't see the relation to fp16; I don't think anyone is pushing for `float` to refer to fp16 (or fp64 for that matter) anywhere. `long double` is already bad enough. reply chipdart 6 hours agorootparent> The cases where you want platform-specific integer width (that is not something like size_t/uintptr_t) is extremely niche (...) I think you got it backwards. There are platform-specific ints because different processors have different word sizes. Programing languages then adjust their definitions for these word sizes because they are handled naturally by specific processors. So differences in word sizes exist between processors. Either programming languages support them, or they don't. Also, there is also specific needs to handle specific int sizes regardless of cpu architecture. Either programming languages support them, or don't. And you end with \"platform-specific integer widths\" because programming languages do the right thing and support them. reply zokier 4 hours agorootparentThe fact that we have all these different 64 bit data models demonstrates clearly how the connection between word size and C types is completely arbitrary and largely meaningless. And this is not specific to 64 bit either, same sort of thing happens on 8 bit platforms too. So you can not rely on `int` (or any other type) being word sized. Furthermore I argue that word size is not really something that makes sense to even expose at language level, the whole concept of word size is somewhat questionable. CPUs operate on all sort of things that can have different sizes, trying to reduce that to single \"word size\" is futile. reply manwe150 7 hours agorootparentprevMy recollection of history is that the standardization of stdint.h happened long after the transition to 32 bit, and is only just finishing up becoming available on some major compilers after the transition to 64 bit is well behind us reply layer8 3 hours agorootparentYou could fairly easily create your own portable stdint.h equivalent in C89 (using the preprocessor and INT_MAX etc.). I remember doing that in the 90s, before C99. However, it was also conventional wisdom to use int by default to match the architecture’s “natural” word size, and maybe add a preprocessor check when you needed it to be 32-bit. Another consideration is that the built-in types have to be used with the C standard library functions to some extent. reply jcranmer 5 hours agorootparentprevstdint.h was introduced in C99, and MSVC didn't introduce it until 2010. reply blueflow 10 hours agoprev> To support those needs, there were clutches like Intel’s PAE, which allowed manipulating up to 64GB of RAM on 32-bit machines without changing the programming model, but they were just that: hacks. You can go look up how the 32-bit protected mode got hacked on top of the 16-big segmented virtual memory that the 286 introduced. The Global Descriptor Table is still with us on 64-bit long mode. So, its not PAE that is particularly hacky, its a more broader thing with x86. reply af78 4 hours agoparentWhile a PAE system can address more than 4 GiB of physical memory, individual processes still use 32-bit pointers and are therefore still restricted to 4 GiB. I think this is why the author calls PAE a hack. In x86-64 long mode and i386 32-bit mode, pointers are really 64- and 32-bit, respectively; I would not call this a hack. reply rft 1 hour agorootparentTo add another layer on top of these hacks, Windows has Address Windowing Extensions [1] that allows a 32bit process to use more than 4GB of RAM. Of course pointers are still 32bit, so you need to map the additional memory into and out of the virtual address space. x86 and its history is full of things that look hacky, and might be, but are often there for backward compatibility. If your x86 PC still boots in BIOS mode, it comes up in 16bit real mode [2], ready to run DOS. It then moves through the decades into protected mode and lastly (for x64 systems) long mode. [1] https://learn.microsoft.com/en-us/windows/win32/memory/addre... [2] https://wiki.osdev.org/Real_Mode reply junon 1 hour agorootparentprevImportant missing info I suppose for some readers - that's what the \"p\" in \"pae\" stands for - physical address extension. It has no bearing on virtual addresses. reply lmm 4 hours agoparentprevThat other hacks exist does not make a given hack any less hacky. reply tzot 10 hours agoprevx32 ABI support exists at least in the kernel of Debian (and Debian based) distributions, and I know because I've built Python versions (along with everything else needed for specific workloads) as x32 executables. The speed difference was minor but existing, but the memory usage was quite a lot decreased. I've worked with a similar ABI known as n32 (there was o32 for old 32, n32 for new 32 and n64 for fully 64-bit programs) on SGI systems with 64-bit capable MIPS CPUs; it made a difference there too. Unfortunately I've read articles where quite-more-respected-than-me people said in a nutshell “no, x32 does not make a difference”, which is contrary to my experience, but I could only provide numbers where the reply was “that's your numbers in your case, not mine”. Amazon Linux kernel did not support x32 calls the last time I tried, so you can't provide images for more compact lambdas. reply gregw2 5 hours agoparentFor the curious, \"x32\" Linux is a \"L64P32\" programming model. There is some lwn.net 2012 commentary on performance implications at: https://lwn.net/Articles/503541/ reply marcosdumay 1 hour agoparentprevI don't know where you get that \"it makes no difference\" opinion. Back then when the VPSes you could rent had 256MB of RAM or some times even 128MB, it was common knowledge that using a 32 bits distro would have a huge impact on your memory usage. Maybe you are reading those opinions wrong, and what they are really saying is \"it's not pointers filling 4GB of RAM, the pointer size makes no difference on modern machines\"? Because I can agree with that one. reply zh3 7 hours agoparentprevIndeed, for many years we've been running multiple systems with X86_64 kernels and a 32-bit userspace, running many standard 32-bit applications (including browsers); only thing we've ever needed to do is run 'linux32' before starting X so that 'uname' reports i686 rather than x86_64. reply martijnvds 6 hours agorootparentThe X32 ABI is not the same as the 32-bit mode used to run \"i686\" binaries on x86_64 (that would be the i386 ABI). reply zh3 43 minutes agorootparentThanks for the correction, having a read of the wikipedia x32 ABI [0] page now. [0] https://en.wikipedia.org/wiki/X32_ABI reply gregw2 6 hours agoprevIf I recall correctly, UNIX vendors in the late 90s were debating a fair bit internally and amongst each other whether to use LP64 or ILP64 or LLP64 (where long longs and pointers were 64bit). ooh, found a link to a UNIX Open Group white paper on that discussion and reasoning why LP64 should be/was chosen: https://unix.org/version2/whatsnew/lp64_wp.html And per Raymond Chen, why Windows picked LLP64: https://devblogs.microsoft.com/oldnewthing/20050131-00/?p=36... and https://web.archive.org/web/20060618233104/http://msdn.micro... For some history of why ILP32 was picked for 1970s 16 to 32 bit transition of C + Unix System V (Windows 3.1, Mac OS were LP32) see John Mashey's 2006 ACM piece, partcularly the section \"Early Days\" sechttps://queue.acm.org/detail.cfm?id=1165766 No peanut gallery comments from OS/400 guys about 128-bit pointers/object handles/single store address space in the mid-1990s please! That's not the same thing and you know it! (j/k. i'll stop now) reply senkora 2 hours agoparentFrom the \"Early Days\" section: > PDP-11s still employed (efficient) 16-bit int most of the time, but could use 32-bit long as needed. The 32-bitters used 32-bit int most of the time, which was more efficient, but could express 16-bit via short. Data structures used to communicate among machines avoided int. Oh, interesting. So \"short\" meant 16-bit portable integer, \"long\" meant 32-bit portable integer, and \"int\" meant fast non-portable integer. reply crest 7 hours agoprevWhat the FreeBSD ISO size comparison overlooks is that to provide 32 bit application compatibility FreeBSD/amd64 will include a i386 copy of all libraries (unless deselected). reply jmmv 2 hours agoparentOh, good point. Somehow I missed that when looking at the contents. Will need to check again why. reply yjftsjthsd-h 4 hours agoparentprevDoes Debian not include multilib by default? reply gnabgib 15 hours agoprevSmall discussion already (16 points, 10 hours ago, 7 comments) https://news.ycombinator.com/item?id=41768144 reply chasil 5 hours agoprevSolaris famously compiles everything in (/usr)/bin as 32-bit. Alas, my SmartOS test system is gone, or I would show you. reply quesera 4 hours agoparentIt looks like there's some variability: smartos$ uname -a SunOS smartos 5.11 joyent_20240701T205528Z i86pc i386 i86pc Solaris Core system stuff: smartos$ file /usr/bin/ls /usr/bin/ls: ELF 32-bit LSB executable, Intel 80386, version 1 (Solaris), dynamically linked, interpreter /usr/lib/ld.so.1, not stripped smartos$ file /bin/sh /bin/sh: symbolic link to ksh93 smartos$ file /bin/ksh93 /bin/ksh93: ELF 64-bit LSB executable, x86-64, version 1 (Solaris), dynamically linked, interpreter /usr/lib/amd64/ld.so.1, not stripped And then the pkgsrc stuff: smartos$ which ls /opt/local/bin/ls smartos$ file /opt/local/bin/ls /opt/local/bin/ls: symbolic link to /opt/local/bin/gls smartos$ file /opt/local/bin/gls /opt/local/bin/gls: ELF 64-bit LSB executable, x86-64, version 1 (Solaris), dynamically linked, interpreter /usr/lib/amd64/ld.so.1, not stripped reply yjftsjthsd-h 3 hours agoparentprevThat was my first thought, too:) But is that x32 (amd64 with 32-bit pointers), or full i386 32-bit code+data? reply wang_li 3 hours agoparentprev$ uname -a SunOS bob 5.11 11.4.68.164.2 sun4v sparc sun4v kernel-zone $ pwd /usr/bin $ file *grep 32-bitwc 46 1008 8890 $ file *grep 64-bitwc 1036 21449 185122 I think Solaris is famous for doing away with static linking. E: A Solaris 10 amd64 box is all 32-bit in /usr/bin. reply renox 9 hours agoprevthe RISC example in the article is a bit weird: on one hand, it may take even more instructions to load an address in a RISC, on the other hand all the RISC I know have an 'addi' instruction, no need to do 'li r2, 1; add r3, r1, r2' to add 1 to a register! reply ChrisArchitect 3 hours agoprev[dupe] More discussion: https://news.ycombinator.com/item?id=41768144 reply sjsdaiuasgdia 8 hours agoprevI'm overly annoyed by the AI generated image of CPUs, with one showing a horrible mottled mess where the nice clean grid of contact pads should be. There's endless actual pictures of processors from both eras. Using actual images here would have been as fast, possibly faster, than the process of writing a prompt and generating this image. reply chefandy 4 hours agoparentAnd that's why laymen with prompts will never replace trained artists/designers for anything but trivial use cases— the ability to decide a) how best to visually communicate the right thing to the right audience, b) whether generative AI is the best choice to achieve that and the capability to use more precise tools if not, and c) that what you have is cruddy enough, or the message is superfluous enough, that not using an image is more effective. This image fails and this is a trivial use case. While it's depressing to see so many lower-end commercial artists lose their livelihood and their depressing wages on the market upstream, I can't help but have a little schadenfreude seeing things like this after so many tech people with dunning-krueger-informed confidence about visual communication have gleefully called me a buggy whip manufacturer. reply stale2002 1 hour agorootparent> why laymen with prompts Thats the baby mode stuff dude. You have missed the forest for the trees if the only thing that you can engage with, is the simplest, most low effort usecase for AI. There are so many other things that can be done with AI. The immediate, obvious stuff would be anything to do with Video To Video AI generation. IE, imagine someone shoots a video the normal way. With all the creative input that this involves. And then you take that video, and you change things in it, using AI. I don't know, you see the video and you realize that you need to add an additional lightsource in, and you want all the shadows to autocorrect. You could use AI to do that. Thats just a random/intermediate usecase off the top of my head, that involves a lot more creative input than just \"prompt in, video out\". I am sure that there could be a lot more crazy usecases, but you aren't going to be able to see then, because you are instinctively losing your mind by only talking about the dumbest and most easy usecase of prompt engineering. reply sph 7 hours agoparentprevNot only that, they had to manually edit the generated image to add the i386 and x86-64 labels on them. When all you have is a hammer... reply Retr0id 5 hours agoparentprevThe garbled pads were straight up trypophobia-inducing, genuinely stopped me in my tracks reply chrsw 7 hours agoparentprevI was going to comment on this but then decided not to because I thought I was being too petty. But I'm glad to see other people agree. It's disturbing. I see someone else commented that it's probably due to copywrite/licensing. I agree there too. That's a shame. So, because of usage policies we end up with AI generated pictures that aren't real, aren't accurate and usually off-putting in some way. Great. reply Filligree 7 hours agoparentprevFirst though, you would have needed to find a picture you can be sure isn’t in copyright. Or which is licensed appropriately. reply Retr0id 4 hours agorootparentI'm sure the same diligence was also performed when constructing the AI's training data set. reply sjsdaiuasgdia 7 hours agorootparentprevimages.google.com -> search for \"386 cpu\" Click \"tools\" then \"usage rights\", pick \"creative commons\", pick an image. Now search for \"core cpu\" and pick a second image. Yeah that sure was hard and time consuming! reply Kye 6 hours agorootparentEven easier: Step 1: go to Wikimedia Commons https://commons.wikimedia.org/wiki/Category:Intel_i386 reply hedora 4 hours agoparentprevOh wow, I noticed and thought \"When was the last time I saw a JPEG that was this crappily encoded?\". I must be getting old. reply quesera 4 hours agoparentprevI would love it if AI images were tagged with the prompt that generated them. I assume PNG/etc image file formats have internal tag-like data structures. Browsers could display the image as usual, and show the \"origin\" tag data alongside HTML alt tag data. Of course people could null out, or overwrite the origin data, but this seems like a reasonable default practice. reply Retr0id 4 hours agorootparentThere is indeed support for in-band alt text, it's not especially widely supported though. reply faragon 6 hours agoprevUsing indexes instead of pointers in data structures works well, and the cost of the base address + offset is negligible, as similar address calculation is already generated by the compiler when accessing into an element of a data structure. In addition to that, mention that indexes can be used as offsets, or as an actual indexes of the size of an individual element, i.e. in that case non-trivial data structures with e.g. >= 32-byte elements could address hundreds of gigabytes of RAM. A practical use could be e.g. using bit fields can be convenient, e.g. having 32-bit indexes, with the higher bit for the color in a Red-black tree. And in case of requiring dynamic-sized items in the tree nodes, these could be in different 32-bit addressable memory pools. reply jauntywundrkind 8 hours agoprevTalking about the ISA needing to spend so much time addressing memory, I'm reminded of the really interesting Streaming Semantic Registers (SSRs) in Occamy, the excellent PULP group's 4096-core RISC-V research multichip design. https://arxiv.org/abs/1911.08356 Just like the instruction pointer which implicitly increments as code executes, there are some dedicated data-pointer registers. There's a dedicated ALU for advancing/incrementing, so you can have interesting access patterns for your data. Rather than loops needing to load data, compute, store data, and loop, you can just compute and loop. The SSRs give the cores a DSP like level of performance. So so so neat. Ship it! (Also, what was the name of the x86 architecture some linux distros were shipp8ng with 32 bit instructions & address space, but using the new x86-64 registers?) reply tzot 1 hour agoparentRe your parenthesized question: x32, as discussed in the article, is an ABI using the full x86-64 instruction set and registers, but pointers are 32-bit. I believe you are talking about the same thing, because any “32-bit instructions” (assumably x86/i686 instructions) cannot use “new x86-64 registers” (either in full count of registers or their 64-bit width). reply ChrisArchitect 6 hours agoprev [–] [dupe] Some more discussion: https://news.ycombinator.com/item?id=41768144 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The i386 to x86-64 upgrade discussion emphasizes the complexities in programming models and data types across various operating systems, noting that Windows did not adopt the LP64 model, unlike Linux and FreeBSD.- The conversation suggests using specific-sized types like int32_t in C for cross-platform compatibility, considering historical context and performance.- The debate also addresses the persistence of traditional data types and challenges related to using AI-generated images in articles."
    ],
    "points": 100,
    "commentCount": 61,
    "retryCount": 0,
    "time": 1728357841
  },
  {
    "id": 41770383,
    "title": "How private intelligence companies became the new spymasters",
    "originLink": "https://engelsbergideas.com/essays/private-intelligence/",
    "originBody": "Essays How private intelligence companies became the new spymasters September 24, 2024 Shashank Joshi Themes: Intelligence In a world awash with digital data, private intelligence companies now compete with state agencies, turning everyone into potential spies and transforming the age-old craft of espionage into a high-stakes technological arms race. Satellite image of a Russian airfield at Borisoglebsk, July 2024. Credit: Simon Matthews / Alamy Stock Photo In 2014 Dan Geer, a computer security analyst, gave a speech at the RSA Conference, an annual gathering of cyber-security specialists, titled: ‘We Are All Intelligence Officers Now’. It described the ways in which computers were insinuating themselves into every aspect of life, the resulting haemorrhage of data, and the change in what it meant to be a collector of intelligence. In his talk, Geer asked: ‘Is it possible that in a fully digital world it will come to pass that everyone can see what once only a director of national intelligence could see?’ Fast forward and it is possible to see Geer’s vision being realised. For a flavour of this, consider an episode that unfolded in 2021. Analysts noticed that CCTV cameras in Taiwan and South Korea were digitally talking to crucial parts of the Indian power grid – for no apparent reason. On closer investigation, the strange conversation was the deliberately indirect route by which Chinese spies were interacting with malware they had previously buried deep inside the Indian power grid. The analysts were in a position to observe this because they had been scanning the entire internet to find command and control (C2) nodes – such as the offending cameras – that hackers tend to use as pathways to their victims. The attack was not foiled by an Indian intelligence agency or a close ally. It was discovered by Recorded Future, a company in Somerville, Massachusetts, which claims to have knowledge of more global C2 nodes than anyone in the world, and which it uses to constantly disrupt Chinese and Russian intelligence operations. The firm, like others, also scrapes vast amounts of data from the dark web – a part of the internet that can only be accessed using special software – collects millions of images daily, extracts visible text to find patterns, and hoovers up corporate records. The Chinese intrusion serves as a microcosm for intelligence in the modern age. The cameras in Taiwan and South Korea are among more than one billion around the world, forming a metastasising network of technical surveillance – visual and electronic, ground-level and overhead, real-time and retrospective – that has made life far harder for intelligence officers and the agents they need to develop, recruit and meet. That those cameras could be used to sabotage India’s electricity supply shows how digital technology has enabled covert action on a grand scale; what previously required front companies, physical infrastructure and agents carrying tools of sabotage can now be done virtually. That this could be watched in near real-time by a private company illustrates the revelatory quantity and quality of data that oozes out of the digital world. Intelligence is being democratised – blurring the boundary between what is secret and what is public. As society has migrated to the internet, so have its secrets, and, therefore, so has intelligence. Consider the deep web, a part of the internet that is not indexed by search engines, and the dark web, which requires specialised software to access. They offer a degree of anonymity attractive to a variety of unsavoury people: terrorists, paedophiles, drug dealers, and cyber-criminals. But that anonymity is superficial. Consider the example of Flashpoint, a so-called threat intelligence firm. Its original work involved building fake personas, such as an analyst pretending to be a jihadist, to infiltrate extremist groups online and gather information about their plan – a form of virtual human intelligence. It now normally deals in data. By tracing extremist groups’ cryptocurrency ‘wallets’, for instance, you can spot anomalous movements that might hint at an impending attack. This kind of intelligence can be semi-secret: tucked out of sight, accessible but often ephemeral. Joseph Cox, a journalist, notes that administrators of criminal and hacker chat rooms on Telegram, a social media platform, frequently wipe messages in one channel and establish another. ‘It really is like missing a whispered conversation in the bar.’ Collecting those messages requires vigilance or automation. If one approach is to observe what is happening out there – on the internet, on the deep and dark web, in particular places – then another is to combine that with what is happening inside one’s own networks – ‘in host’. The firms that build key hardware and software – Google for email, Microsoft for operating systems, and Amazon for cloud computing, to name a few – have unprecedented and unmatched insight into the traffic moving over their networks. The result is that these companies are, in one sense, the largest signals intelligence agencies on the planet. Microsoft tracks more than 78 trillion ‘signals’ per day. These companies observe not just the traffic on their own networks but, like counter-intelligence services, map and track the activities and signatures of their adversaries, including state-linked hacking groups known as advanced persistent threats or APTs. It was Microsoft, not the American government, which publicly revealed that ‘Volt Typhoon’, a Chinese hacking group, had targeted American critical infrastructure since at least 2021, including water and energy facilities, probably as preparation for wartime sabotage. The fact that Western cyber-security companies have been involved in the defence of Ukrainian networks from the earliest days of the war means that they also see some Russian cyber threats that Western agencies might not be aware of. Private intelligence companies are not unconstrained, however. They are subject to the law. They may not break into buildings, as domestic security services can. They may not breach computer networks in violation of hacking laws, as a cyber intelligence agency might do. Many of them are also proprietorial and cagey about protecting their methods, data and clients. Yet the open nature of the private sector can also be an advantage. Thomas Rid of Johns Hopkins University has noted that counter-intelligence work was once ‘highly secretive’ and ‘cloistered in small teams and communities’ – think of the CIA’s notorious James Angleton, a spycatcher who became a reckless paranoiac. What changed in the 2010s was the maturation of ‘digital counter-intelligence’, most notably in the field of cyber threat intelligence. Companies began openly countering Russian and Chinese hacking, often publishing their findings in great detail. The debate, explains Rid, became ‘more evidence-based and far less secretive’. These companies were often hunting the same groups of hackers from China, Russia, North Korea and Iran and they created a community of learning and tradecraft, in which different parts of the jigsaw could be put together. People often moved between firms, but also between intelligence agencies and the private sector, bringing know-how with them. All this is an opportunity for spycraft. For one thing, it expands collection capacity. Take the example of the Falklands War. America found that its spy satellites, designed to watch the Soviet Union, were in the wrong orbit to point at the South Atlantic (‘Nobody ever thought there’d be a damn war in the Falklands for God’s sake’, noted Robert Gates, later the CIA director). The private sector has since solved that problem. The spectacular growth of the commercial satellite industry allows states to enjoy near-blanket coverage. Britain has gone from buying hundreds of thousands of dollars of commercial satellite images every year to multiple millions. Other examples abound. In Gaza, for instance, Israel’s armed forces and signals intelligence units have used private firms, including Google Photos, to assist with facial recognition of Palestinians. A second advantage is that secrets acquired by non-secret agencies can be shared more widely. In space intelligence, for instance, according to the historian Aaron Bateman, the United States rarely shared satellite images with its NATO allies except Britain. In some cases it did not acknowledge certain sorts of satellites, such as those which collected radio emissions or which used synthetic aperture radar, even existed. That began to change in 1991 during the first Gulf War. But it is now routine for governments to buy and publish high-resolution satellite images to expose malfeasance by an adversary. Governments can also tip off outside analysts to look for certain things that they want to be publicised, and those analysts often stumble on intriguing things themselves. In August 2021, there were rumours that China was building new ICBM launch sites. Decker Eveleth, a young analyst, looked for them using common sense: they would be on flat land, and far from American radars in Japan and South Korea. Having slogged through satellite images of Inner Mongolia without luck, he found what he was looking for in next-door Gansu: 120 missile silos under construction. Open-source analysts later found the same telltale grid pattern in a remote part of Xinjiang. Intelligence agencies offer recruits the allure of working for organisations with a sparkling history, a mandate for public service and a licence if not to kill then to break domestic and foreign laws in service of the state. The drawbacks have grown more prominent. ‘It’s a hard sell to anybody who’s in a leading AI lab to join the intelligence community and then be told you’ll have to wait a year to get a security clearance,’ says Jason Matheny of RAND. The chasm in salaries is another issue. Working conditions are a third. ‘We cannot offer certain conditions that are taken for granted today,’ notes Bruno Kahl, the head of the BND, Germany’s foreign intelligence service. ‘Remote work is barely possible… and not being able to take your cellphone to work is asking much from young people.’ When Joe Morrison of Umbra, a radar satellite start-up, was asked by Western officials why they ought to work with commercial unclassified satellite vendors, his reply was both glib and truthful: ‘Access to talent that likes to smoke weed.’ The most radical interpretation of all these changes is that Western intelligence is broken and needs to start again from scratch. ‘The UK intelligence community (UKIC) is facing an existential challenge,’ argued Lucy Mason, a former British defence official, and Jason M, a semi-anonymous serving intelligence official, in a paper published by the Alan Turing Institute, a research centre in London that works closely with the intelligence services, in November. ‘It is being out-competed by providers of open-source intelligence and data companies.’ The authors proposed a completely new model ‘away from one where national security is done only by some cleared people in highly centralised, closed, organisations, to one which is open, collaborative, and joined up by design’. This is probably going too far. To be sure, non-secret sources are increasingly important. Open source contributed around 20 per cent of British defence intelligence ‘current processes’, noted General Jim Hockenhull, then chief of the service, in late 2022, ‘but the availability and opportunity means that we’ve got to invert this metric.’ The same appetite exists in the non-military intelligence world. ‘If I’d gone and collected all of China’s military procurement records, I’d probably have got an OBE,’ says a former British intelligence officer. ‘The fact that they were, for many years, just sat there in open source just completely bypassed everybody.’ A flourishing trade in personal location data harvested by advertising brokers from apps on mobile phones is a rich seam for state agencies around the world. In April 2024 America’s communications regulator levied $200m in fines on the country’s largest telecoms firms for selling such data without permission to firms who then sold it on again. There are limits to private-sector intelligence. The fact that public data can answer many questions that would once have required secret intelligence does not mean they can answer all such questions. Open sources did shine a light on Russia’s military build-up before the invasion of Ukraine in 2022. Nonetheless, only states had access to the most incriminating evidence, such as intercepts of Russian war plans and indicators that Russia was, for instance, moving blood plasma to the front lines at a crucial moment in mid-January 2022. No commercial or public source has established Russia’s development of an orbital nuclear weapon, Iran’s provision of ballistic missiles to Russia, or Iran’s computer-modelling work relevant to the design of nuclear weapons – all recent stories in the public domain that are based on secret intelligence collected by states. The second problem is that it is misleading to think about open and secret sources as two separate things, kept apart from one another. Sometimes the former can substitute for the latter, at least to a reasonable degree. Public estimates of losses of Russian military equipment in Ukraine appear to be pretty accurate. But public data is often most useful and revealing when it is fused with something that is non-public, or secret. The problem is that bridging the unclassified (the ‘low side’, as government officials call it) and the classified (‘high side’) world is both technically and institutionally difficult. Consider, for instance, the case of a spy agency which has its own data on the movement of Russian intelligence officers, perhaps acquitted by tracking phones or devices. It may wish to juxtapose that with a publicly available database of visa or travel records – perhaps one leaked on the dark web. ‘What’s actually sensitive is the question you ask,’ says a person familiar with this sort of operation. ‘As soon as the question comes from the high side down onto the low, that question is detectable and the data you pull up is detectable.’ In other words, interrogating the public dataset can reveal what you do or do not know about Russian spies, perhaps tipping them off. But pushing all the data up onto the high side is too expensive because cloud computing built to handle highly classified data is a scarce resource for all but the very wealthiest of governments. Western agencies are still grappling with this problem, with many reformists frustrated at the slow pace of change in their organisations. ‘If you’re not willing and able to engage with the world of data’, complains the insider, ‘you just cannot be efficient, and your costs go up’. The third issue has to do with the legal and ethical challenges that arise when states are competing over access to data and its exploitation. China has long seen the acquisition of data as a key resource in its strategic competition with America and the wider West. In 2015 Chinese hackers stole more than 22 million American government security clearance records held by the Office of Personnel Management. In 2017 they acquired the records of 148 million Americans and 15 million Britons from Equifax, a credit reporting agency. In 2021 they targeted Britain’s electoral commission. In February 2024 files leaked from iSoon, a Shanghai-based firm that hacks and then sells data to Chinese government entities, showed the range of its ambition: immigration data from India, phone logs from South Korea, and road-mapping data from Taiwan. This activity spans a broad range. Much of it is traditional intelligence gathering. Some of it enables China to catch Western spies. Both of those things are no different to what Western spy agencies would do in the other direction, but it also offers other possibilities. ‘Building databases of society has been [Chinese] intelligence… methodology since the 1930s,’ writes Peter Mattis, a China expert and former CIA analyst. ‘Start with the broadest possible data on individuals, then filter and target them for intel and influence.’ Some people would like the West to learn from this approach. ‘If we do not find a way to merge the great capabilities of Western governments and the private sector to defend our own values and interests’, argues Duyane Norman, a former CIA officer, ‘these adversaries will continue to close the gap.’ That is easier said than done. Democracies tend to impose stringent requirements on the sort of thing that may or may not be collected. In Britain the intelligence agencies do collect ‘bulk personal data’, but if they want to ‘retain or examine’ it then they must jump through a few hoops: they need to get a warrant and then show that getting, keeping and using it is proportionate to some specific aim. It is not enough to believe that it might prove useful. Some data is thus ‘more easily accessed and used by the private sector than by government organisations’, write Lucy Mason and Mr M, the authors of the paper published by the Alan Turing Institute. American spies are similarly constrained. It is ‘hard or impossible’ to ‘identify and scrub’ data on Americans from large datasets, notes Emily Harding, a former CIA analyst now at CSIS, a think-tank, making it hard to comply with the law. American agencies are thus ‘far behind private sector entities with no such restrictions’, she says. One former European intelligence official observes that the VENONA project, a celebrated Allied effort to collect and slowly decrypt Soviet wartime intelligence transmissions, which eventually revealed a number of Soviet agents in the West, would not have been possible under the law as exists today in some European countries. In 2013 the disclosures by Edward Snowden, a disgruntled contractor working for America’s National Security Agency, prompted an intense and unexpected public debate over the activities of intelligence agencies and their ability to collect, if not actively read, vast amounts of phone, internet and other traffic. In the decade since, much has changed. The majority of internet browsing and personal messaging now takes place with the protection of end-to-end encryption, making it harder for spies to read what they might intercept. More data is also being encrypted ‘at rest’ – on devices, and in use. That trend, too, has been driven by the private sector, as large tech companies – Apple, Google and Meta, above all – have embraced encryption and user privacy in the face of opposition from law enforcement agencies around the world. At the same time, daily life relies more than ever on digital technology: more things run on software (fridges, cars, phones), those things have a greater array of sensors (GPS receivers and radio transmitters) and they are increasingly connected, often over the internet, allowing data, often embodying our most personal secrets, to flow to and fro. The paradox of the modern world is that, while we have more means to keep our data secret, there is so much more data to contend with and so many more places from where it can seep out into the world, where a sprawling ecosystem of private intelligence can collect, analyse and use it. Author Shashank Joshi More about Shashank Joshi More from Intelligence Angus Reilly ‘We need to see these terrorist groups through their own mindsets’ — in conversation with John Sawers Latest essays Jay Mens The beginning of a reckoning: the Middle East after 7 October Mick Ryan Mobilising for the moment Nayef Al-Rodhan To the far side of the Moon: the battle for lunar resources Angus Brown The trials of a president",
    "commentLink": "https://news.ycombinator.com/item?id=41770383",
    "commentBody": "How private intelligence companies became the new spymasters (engelsbergideas.com)98 points by dsr12 22 hours agohidepastfavorite32 comments rurban 13 hours agoTheoretically a very good development regarding lawfulness and accountability. State spies are basically illegals without accountability, like the various mafia networks. (CIA did have close connections to the Italian mafia, btw in their various illegal activities, such as drugs and torture. The NSA is regularly above the constitution.) Private spies are not yet connected like the mafia, but still can get caught operating out of the legal or constitutional boundaries. reply jongjong 21 hours agoprevLooking at the past 10 years of the software industry, I still can't wrap my head around the approach that most large companies have taken to hiring software engineers; treating them as literal cogs in the machine, designing processes which place trust in the hands of middle managers and bureaucrats instead of engineers. There was literally no vetting process for engineers. Now every corner of the internet is full of viruses, spyware and backdoors and of course middle managers had no idea. Nobody is responsible for the software so it belongs to intelligence agencies and hackers. The software industry turned out so different from how I thought it would. When I decided to pursue it as a career, I thought that software engineers would be treated and given responsibilities like managers. It's crazy when you think about it; managers are responsible for their people, whom they have limited control over... Yet software engineers have zero responsibility for the software they produce, which they have almost full control over. reply dataviz1000 21 hours agoparentI was a private yacht chef for 7 years. They would hire anyone off the street to work on a $35,000,000 private yacht without checking references or a background check. I had unprecedented access to CEO's of Fortune 100 companies and phone numbers of a couple billionaires on my phone. I thought about writing a spy novel where a bunch of college students got entry level jobs on a yacht and used the access to plant bugs. The plot is they get caught and have to escape the Caribbean while being chased. reply stonethrowaway 18 hours agorootparentYou have my preorder. Post your keybase in your profile and let’s get the ball rolling. reply dataviz1000 11 hours agorootparent1. A group of EECS graduates get jobs as deckhands and stewardesses on mega yachts in order to bug the yachts to glean information for trading securities. 2. They install computers in the electronics cave below the wheelhouses because nobody knows what most of the electronics there do in the first place. Today there are hundreds of mega yachts in Fort Lauderdale, Florida with thousands of unscreened workers maintaining the yachts before they leave in November for a season of cruising and charters in the Caribbean. 3. They get caught by Russian mafia while in Martinique or St. Lucia. 4. They MacGyver their way out of the Caribbean while being chased by thugs with unlimited resources. I'll get around to writing it one of these days. reply currency 4 hours agorootparentVisiting Ft Lauderdale as students on spring break and chatting with barflies gives one of them the germ of the idea.... reply aeternum 20 hours agoparentprevIn almost every industry this is the case. Perhaps with the exception of some government contractors. Even with projects that went to extreme cost to maintain secrecy ultimately failed to do so, IE the Manhattan project. Most tech companies (and non-tech companies) take a fairly pragmatic approach. Generally trust your employees but configure systems with an audit trail so you can hold them accountable later for malicious actions. If accidental, there's not much you can do anyway so just buy insurance. reply gavmor 21 hours agoparentprev> Nobody is responsible for the software Sounds like the accountability sink[0]. 0. https://www.ft.com/content/2e1042d5-5e89-4fb6-bbee-de605a534... reply poopiokaka 16 hours agoprevThis blog post is so scattered reply cyberax 22 hours agoprevA couple of years ago, a dipshit moron in the US Army leaked a bunch of top secret documents on Discord, mostly related to the Ukrainian war. The thing is, these documents were kinda bad. The information in them was not any better than the work of open source intelligence, and analyses were as good (bad) as that of many armchair analysts. So it's no wonder that spy agencies are getting left behind. reply JumpCrisscross 21 hours agoparent> information in them was not any better than the work of open source intelligence Now look at the dates on those documents. Big difference between knowing the Japanese fleet is off Pearl Harbor at 7AM versus 8:01. reply cyberax 13 hours agorootparentThey did not reveal anything new in particular. To be clear, CIA and other agencies probably have HUMINT sources that are still ahead of the open source intelligence. Their SIGINT is likely still ahead as well, although even that advantage is fading. During the Ukrainian conflict, we were able to track the activities of the armies by using NASA's publicly available infrared brush fire tracker satellites (FIRMS - https://firms.modaps.eosdis.nasa.gov/map/#d:24hrs;@38.1,48.0... ). And you can literally pay $100 and get a picture of any area on the planet, with a resolution that is good enough to track vehicles. reply tolerance 21 hours agoparentprevI don't understand why your comment is being retrieved so unpopularily thus far. The decline in quality that you're describing not withstanding, I'm not surprised that private intelligence companies are on the rise as opposed to state agencies. I reckon that won't be for long though and that eventually any distinction between the two will be nominal. reply ImPostingOnHN 21 hours agorootparent> I'm not surprised that private intelligence companies are on the rise as opposed to state agencies Me, neither. The private sector almost universally pays more for top talent, so much of the top talent will go there. It's also probably a better culture. As more government agencies outsource intelligence (and consequently, decision-making) to the private sector, companies like Palantir and OpenAI will become even more the de-facto government than they already are. reply tolerance 20 hours agorootparent> As more government agencies outsource intelligence (and consequently, decision-making) to the private sector, companies like Palantir and OpenAI will become even more the de-facto government than they already are. This is basically what I was alluding to. The stage is set all too well for this not to occur. reply kridsdale1 20 hours agorootparentI predict we’ll head to a Holy Roman Empire or Snow Crash style of federated fragmented powers that in aggregate we can call The United States but in reality it’s a bunch of jockeying nobles and oligarchs. Maybe it always was, and the US Revolution was to allow this by tearing down unitary monarch power. reply Nasrudith 12 hours agorootparentThe problem with said situation is that being big is such a winning move post-industrialization, even before divide and conquer shenanigans to play at 'colonizing India'. Fractal balkanization isn't exactly a winning move and there is a reason why a unified Germany became a significant power above and beyond its most bellicose states. reply sudoshred 21 hours agorootparentprevThis is a feature of capitalism, nothing to see here. reply martinky24 22 hours agoparentprevAny source for the \"not any better than the work of open source intelligence\" part? reply cyberax 14 hours agorootparentI'm following the war pretty closely, and the documents basically added no real analysis compared to the open source intelligence community (Christo Grozev, Conflict Intelligence Team, Oryx). E.g. their analysis of Wagner group was inferior to the one published by investigative journalists. reply l33t7332273 21 hours agorootparentprevI think it’s GP’s own evaluation reply vjulian 22 hours agoparentprevI’d prefer a neutral account. In conclusion, is it fair to say that the leak was a breach of US protocol or law and was publicly-available information? reply stonethrowaway 22 hours agoparentprevWell don’t leave us hanging, what did the documents reveal? reply red-iron-pine 39 minutes agorootparentThis was the Thugshaker incident where an an AF reservist released a bunch of crap online for clout. Takeaways from the wiki link that was posted: Battle of Bakhmut: Late February 2023: Russian flanking maneuvers near Bakhmut, Ukrainian military discussions on response, and supply shortages. February 25: Ukrainian forces nearly encircled; low morale among soldiers. Kyrylo Budanov described the situation as “catastrophic”; offered to deploy elite units to safeguard the supply line. Deployment of reinforcements, including elite units, prevented encirclement but depleted seasoned forces needed for the spring counter-offensive. Casualty Estimates: Documents cover U.S.-provided military resources, Pentagon estimates on casualties, and Ukraine’s planned counteroffensive. U.S. estimates: 189,500 to 223,000 Russian casualties, 124,500 to 131,000 Ukrainian casualties. Soldiers killed in action: 15,500 to 17,500 Ukrainian, 35,500 to 43,000 Russian. Significant casualties for Spetsnaz GRU due to their use in the war. Russian Military Planning: Russian General Staff plans to counter NATO-provided tanks, including paying soldiers who destroy NATO tanks. U.S. aware of Russian plans to destroy a hangar containing drones near Odesa. Russia–NATO Aircraft Encounters and Near Shootdown: September 2022: Russian fighter jet nearly shot down a British surveillance plane off Crimea. Incident disclosed by Ben Wallace in October; involved two Sukhoi Su-27 jets, one firing a missile at the Rivet Joint. Potential NATO response if the missile had hit the plane. Document details other encounters with Russian jets, including the 2023 Black Sea drone incident. French and British reconnaissance flights between the near-shootdown and February 26, 2023. U.S. defense officials stated the Russian pilot misunderstood commands from a radar operator. Weapons Use by Ukraine: Ukraine’s air defense (S-300 and Buk missile systems) expected to be depleted by May. Documents refer to Ukraine using weapons within Russia; Zelenskyy suggested UAV strikes in Rostov Oblast. Potential increase in Chinese aid to Russia if Ukraine strikes within Russia. Exposure of LAPIS, an advanced satellite system used by the Ukrainian military. Proposed “Combat Power Build” of 9 planned brigades supplied by the U.S. and allies. Weapons Use by Russia: Russia attempted to disrupt Starlink systems provided by SpaceX to Ukraine. Western Special Forces: List of countries with special forces in Ukraine: UK (50), Latvia (17), France (15), U.S. (14), Netherlands (1). U.S. special forces at the U.S. embassy in Kyiv for VIP security and oversight of U.S. equipment and supplies. reply r721 22 hours agorootparentprevhttps://en.wikipedia.org/wiki/2022%E2%80%932023_Pentagon_doc... reply Modified3019 20 hours agorootparentOh, the thugshaker incident. Now I remember. reply tourmalinetaco 22 hours agorootparentprevTheir post is somehow even worse quality than the stuff they’re complaining about. To answer your question, a lot of the documents were vehicle/weapon data, thickness of armor plates of tanks and such. Specifically regarding what is best searched as “War Thunder Discord leaks”, as it was, supposedly, a bunch of War Thunder players trying to one-up each other on how knowledgeable they were on military hardware. Some of them (there were a good handful over the years) are detailed here: https://steamcommunity.com/sharedfiles/filedetails/?l=polish... reply neaden 21 hours agorootparentWar Thunder are to my knowledge the only game studio who have had to publicly tell their fans not to send them classified material in order to advocate for a balance change. reply cyberax 14 hours agorootparentRussia: pls nerf F35, it's too OP. reply jklinger410 21 hours agoprev [–] Sounding like a broken record here. Your bank and state government will sell your data to these brokers. Just in case any of you think your TOR browser saves you. reply JumpCrisscross 21 hours agoparentNot what this article is about. reply hammock 21 hours agoparentprev [–] Sell and buy reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Private intelligence companies are increasingly competing with state agencies, transforming espionage into a tech-driven arms race by leveraging vast digital data.",
      "Unlike state agencies, these firms operate openly, sharing findings and fostering a community of learning, but face legal and ethical challenges in data collection.",
      "The rise of private intelligence underscores the need for collaboration between governments and the private sector to protect national interests, reshaping the future of espionage."
    ],
    "commentSummary": [
      "Private intelligence companies are emerging as new leaders in intelligence, providing more accountability compared to state agencies that sometimes operate beyond legal limits.",
      "The software industry and other sectors face vulnerabilities due to inadequate vetting, which are exploited by hackers and intelligence agencies.",
      "Companies like Palantir and OpenAI are assuming roles traditionally held by government agencies, driven by better compensation and work culture, raising concerns about the balance of power between private and state entities."
    ],
    "points": 98,
    "commentCount": 32,
    "retryCount": 0,
    "time": 1728331570
  },
  {
    "id": 41770941,
    "title": "Smart TVs are like \"a digital Trojan Horse\" in people's homes",
    "originLink": "https://arstechnica.com/gadgets/2024/10/streaming-industry-has-unprecedented-surveillance-manipulation-capabilities/",
    "originBody": "Ad-session Smart TVs are like “a digital Trojan Horse” in people’s homes 48-page report urges FTC, FCC to investigate connected TV industry data harvesting. Scharon Harding – Oct 7, 2024 5:55 PM Credit: Getty ImagesChristopher Ames 135 The companies behind the streaming industry, including smart TV and streaming stick manufacturers and streaming service providers, have developed a \"surveillance system\" that has \"long undermined privacy and consumer protection,\" according to a report from the Center for Digital Democracy (CDD) published today and sent to the Federal Trade Commission (FTC). Unprecedented tracking techniques aimed at pleasing advertisers have resulted in connected TVs (CTVs) being a \"privacy nightmare,\" according to Jeffrey Chester, report co-author and CDD executive director, resulting in calls for stronger regulation. The 48-page report, How TV Watches Us: Commercial Surveillance in the Streaming Era [PDF], cites Ars Technica, other news publications, trade publications, blog posts, and statements from big players in streaming—from Amazon to NBCUniversal and Tubi, to LG, Samsung, and Vizio. It provides a detailed overview of the various ways that streaming services and streaming hardware target viewers in newfound ways that the CDD argues pose severe privacy risks. The nonprofit composed the report as part of efforts to encourage regulation. Today, the CDD sent letters to the FTC [PDF], Federal Communications Commission (FCC), California attorney general [PDF], and California Privacy Protection Agency (CPPA) [PDF], regarding its concerns. \"Not only does CTV operate in ways that are unfair to consumers, it is also putting them and their families at risk as it gathers and uses sensitive data about health, children, race, and political interests,” Chester said in a statement. Beyond rising streaming subscription fees and the increasing presence of ads in streaming services, the growth of streaming has a \"steep price,\" the report says: The widespread technological and business developments that have taken place during the last five years have created a connected television media and marketing system with unprecedented capabilities for surveillance and manipulation. The report notes \"misleading\" privacy policies that have minimal information on data collection and tracking methods and the use of marketing tactics like cookie-less IDs and identity graphs that make promises of not collecting or sharing personal information \"meaningless.\" \"As a consequence, buying a smart TV set in today’s connected television marketplace is akin to bringing a digital Trojan Horse into one’s home,\" it says. Generative AI CDD's report highlights the CTV industry's interest in using generative AI to bolster its targeted advertising capabilities. Approaches currently being explored could alter what one viewer sees when streaming a show or movie compared to another viewer. For example, Amazon Web Services and ad-tech company TripleLift are working with proprietary models and machine learning for dynamic product placement in streamed TV shows. The report, citing a 2021 AWS case study, says that \"new scenes featuring product exposure can be inserted in real-time 'without interrupting the viewing experience.'\" Peacock is also working with TripleLift to develop \"In-Scene\" Peacock ads that owner NBCUniversal says it's currently testing: When a user plays episodic content, your brand’s product or message is dynamically placed in the frame of targeted scenes, creating a non-interruptive ad experience that aligns the programming with your campaign theme/goals. Generative AI could also enable advertisers to show different elements in ads, depending on who's streaming the ad, the report says. As a 2023 blog post from data-collection firm Experian and cited in CDD's report says: Some AI tools can generate several versions of the same CTV ad — swapping the actor’s clothing and voiceover elements like store locations, local deals, promo codes, and more — and can create up to thousands of personalized iterations in just a few seconds. CTV companies are also turning to generative AI for free ad-supported (FAST) streaming channels that are increasingly popular as streamers get tired of streaming costs and as a way to push ads. Speaking to Ars Technica, report co-author Chester shared concerns that generative AI techniques for harvesting data from streamers will grow without checks, \"making regulation much harder.\" He suggested regulation methods like identifying where generative AI in advertising can't be used, such as with pharmaceutical products or products targeting kids, and settling on a review process to limit harm derived from generative AI in CTV advertising and how much data is collected from this ad tech. Data collection yields concerns around pharmaceuticals, politics The report details concerns around the advertising of pharmaceutical products using CTVs. It notes that the US is \"one of only two countries that allow direct-to-consumer advertising of pharmaceutical products.\" Drug advertising, the report argues, has \"generated concerns from the public health community over its high-pressure sales techniques, misinformation, and deceptive practices.\" Despite claims that health data for ad targeting is anonymous, identity management and ad tech tools allow health marketers to target specific people, the report argues. Similarly, the report's authors describe concerns that the CTV industry's extensive data collection and tracking could potentially have a political impact. It asserts that political candidates could use such data to run \"covert personalized campaigns\" leveraging information on things like political orientations and \"emotional states\": With no transparency or oversight, these practices could unleash millions of personalized, manipulative and highly targeted political ads, spread disinformation, and further exacerbate the political polarization that threatens a healthy democratic culture in the US. “Potential discriminatory impacts” The CDD's report claims that Black, Hispanic, and Asian-Americans in the US are being \"singled out by marketers as highly lucrative targets,\" due to fast adoption of new digital media services and brand loyalty. Black and Hispanic communities are key advertising targets for FAST channels, per the report. Chester told Ars: There are major potential discriminatory impacts from CTV’s harvesting of data from communities of color. He pointed to \"growing widespread racial and ethnic data\" collection for ad targeting and marketing. \"We believe this is sensitive information that should not be applied to the data profiles used for targeting on CTV and across other platforms. ... Its use in political advertising on CTV will enable widespread disinformation and voter suppression campaigns targeting these communities,\" Chester said. Regulation In a letter sent to the FTC, FCC, California attorney general, and CPPA , the CDD asked for an investigation into the US' CTV industry, \"including on antitrust, consumer protection, and privacy grounds.\" The CDD emphasized the challenges that streamers—including those who pay for ad-free streaming—face in protecting their data from advertisers. “Connected television has taken root and grown as an unregulated medium in the United States, along with the other platforms, devices, and applications that are part of the massive internet industry,” the report says. The group asks for the FTC and FCC to investigate CTV practices and consider building on current legislation, like the 1988 Video Privacy Protection Act. They also request that antitrust regulators delve deeply into the business practices of CTV players like Amazon, Comcast, and Disney to help build \"competition and diversity in the digital and connected TV marketplace.\" Scharon Harding Senior Product Reviewer Scharon Harding Senior Product Reviewer Scharon is Ars Technica’s Senior Product Reviewer writing news, reviews, and analysis on consumer technology, including laptops, mechanical keyboards, and monitors. She’s based in Brooklyn. Prev story Next story 135 View Comments Comments Forum view Loading comments...",
    "commentLink": "https://news.ycombinator.com/item?id=41770941",
    "commentBody": "Smart TVs are like \"a digital Trojan Horse\" in people's homes (arstechnica.com)93 points by cx0der 22 hours agohidepastfavorite35 comments krunck 3 hours agoLets not forget that any \"Smart\" TV that has voice control can probably record audio in your home at any time. https://www.schneier.com/blog/archives/2015/02/samsung_telev... Any \"Smart\" TV that has a camera to see who is watching (to customize content and ads) does just that... reply 486sx33 19 hours agoprevThe most frustrating part is that the last time I was able to buy a \"regular\" tv was 2020 EVERYTHING is a damn smart tv now reply 20after4 6 hours agoparentYou can get a large monitor with no smart tv features and just use it like a tv, however those are also starting to disappear and be replaced by “smart monitors” reply gruez 18 hours agoparentprevJust buy a smart tv but don't connect to wifi? reply meowster 3 hours agorootparentJust don't have any visitors in your house either, as they might connect it to their cell phone hot spot to watch one of their Netflix shows or similar when you're not looking. As much as you think this scenario is paranoia, your visitors will think you not connecting your TV is just as paranoid. reply saurik 16 hours agorootparentprevI'm sure this will soon be solved using the hack of accessing shared Wi-Fi fabrics that some ISPs now offer (as in, the thing where the router will offer a generic network such as CoxWiFi, and allow random people to pay to use your WiFi; even if you don't have it, maybe your neighbor does)... and even then, new IoT longer-range WiFi services can act as a backstop. reply J_Shelby_J 4 hours agorootparentOr inexpensive cellular modems. Someone in the future will make decent money converting smart tvs to dumb tvs. reply retrochameleon 4 hours agorootparentprevIt literally isn't good enough anymore. Smart TVs try to phone home in many ways. Thanks to things like Amazon Sidewalk, they can jump on that network for connectivity without your knowledge if it's available nearby. reply amiga 12 hours agorootparentprevThe last smart TV I had flashed an annoying light if there were no wifi connection. Cover the light, I thought! ...the annoying light is adjacent to the IR receiver. Cover the light, no remote. Is this intentional? reply tmerc 5 hours agorootparentProbably not international in context. Most IR receivers go behind a special semi-transparent plastic. That's also the cheapest place to put an LED. I think there are films you can get to block non IR light. Some tvs also have a connection to add an external ir receiver. reply bmitc 6 hours agorootparentprevHow do you use it then? A Roku is more secure? reply tmerc 5 hours agorootparentRoku TVs \"phone home\" a lot. I had one with pihole blocking it's collection, but they still updated my menus to suggest garbage for me. I wasn't willing to let the device go un-patched and still be on my networks, so there was probably still data getting back to them. A computer is easier to secure but still has all the same issues by default. The difference is that a computer isn't designed to spy on you. Netflix in a browser is still going to tell Netflix about your viewing habits, but at least it doesn't tell Roku via screen scraping as well. reply notyourwork 6 hours agorootparentprevNvidia shield is what I use on all my TVs. reply horsawlarway 4 hours agorootparentSame here. Nvidia shield with FDroid sideloaded and a custom launcher is pretty solid. No Ads with the custom launcher. I don't have to be logged into anything I don't want to be, the devices are... not excellent but probably the best you can get right now for the price range. Media format compatibility is good. Bluetooth connectivity exists for peripherals (incl audio bars and headphones). It has USB ports to take a thumbdrive or other android support peripherals (incl USB audio DACs). Good support for CEC and the remote has IR support for controlling other hardware (ex - I can make it work with my Epson projector just fine). I don't really like the toblerone remote form factor - and it should be against the law into include dedicated streaming service buttons (netflix... blegh), plus every now and then I have to reboot the device. But generally speaking... if one died I'd probably buy another as the replacement. reply mgh2 3 hours agoparentprevWhat about smart monitors? reply sickofparadox 5 hours agoparentprevSceptre sells 4k tvs that are not smart, though they have been hard to find as of late. [1] [1]https://www.sceptre.com/TV/4K-UHD-TV-category1category73.htm... reply retrochameleon 4 hours agorootparentThank you. I've been looking for a link to TVs that are still dumb. reply goalonetwo 18 hours agoprevcommon advice is to never connect your smart TV to the network. Only use the HDMI inputs. reply abcd_f 6 hours agoparentReasonable advice. However it's worth keeping in mind that HDMI supports Ethernet passthru so it too can be used to connect out. reply reginald78 5 hours agorootparentTechnically true but this feature never had much update and I believe hdmi ARC and this are mutually exclusive/use the same wiring path? Anyway I think the real threats will be: 1) Aggressive wifi search connecting itself, including deals with ISP routers to allow them to bypass you or even other devices. 2) Time-bombs causing the TV to become non-functional or degraded if you don't connect it to the internet, after the warranty or return window has expired 3) In-built 5G modem connectivity (everyone says this is to expensive but manufacturers could cut bulk deals and could limit the bandwidth usage, even just sneaking in firmware updates has a lot of abuse potential) reply Scotch3297 10 hours agoprevI became fully aware of this when a few months ago, my Xiaomi smart TV turned on by itself and displayed an AD to subscribe to Netflix (I did have the Netflix app installed because I had an account a while ago, but I had already unsubscribed, I simply forgot to uninstall the app). Needless to say, from that moment onwards, no wifi and no ethernet for the TV. I got an Xbox with Kodi connected to it. I am not saying the Xbox is immune to data harvesting (probably they collect a fair bit), but feels less intrusive and obnoxious than the whole package of the smart TV. reply anfractuosity 7 hours agoprevThere isn't any way to allow certain streaming services via a firewall whitelist, but block all the extraneous connections a TV might make is there? (As the TV manufacturer might use the same CDNs/IP ranges as legitimate services?), ideally without hacking about with the TV itself. Or would it be best just to never connect the TV to a network and use a computer to access streaming services. reply tmerc 5 hours agoparentYes, generally that concept is possible. I don't know of software that makes a whitelist firewall easy to use. You also run into problems when your streaming provider updates ip addresses or cdn DNS names, which can be frequent. The other issue with this is that the streaming provider that you pay might also be adversarial. You may want to allow some of their traffic but not other. So you end up maintaining some kind of list that can break your streaming experience if you don't maintain it. As content providers consolidate on shared infrastructure (AWS, gcp, etc) the chances of good and bad actors using the same IP increases. This decreases the effectiveness of firewalls that operate on ip:port matching. Most firewalls do this. Realistically, what you probably want as a tech savvy consumer is home network level DNS blacklist. It is not a firewall and it doesn't technically block traffic. It does prevent traffic from leaving the device if the DNS the device wants to send to is blacklisted. This exists (pihole) and can be added to a network fairly quickly. Bad actors could bypass your DNS or use known ips directly. Whitelisting dns would also work with the caveat that you'll need to update the list frequently and I don't think pihole was designed for this. All of that is fairly complicated. A wireless keyboard and mouse and HDMI cable are cheap and laptops are plentiful. You will have the same adversarial content provider issues with a laptop, though. Scriptsafe and ublock can help. Laptops actually shut down when you tell them to. Your tv is probably on even when the screen is off. I made this decision recently when I inherited a Sony TV with a house. It has not been connected to a network and I use a laptop to stream. I also run pihole, scriptsafe, ublock, and I pay for most of my streaming providers. They're still getting data on me, but less than most people. reply adriancr 2 hours agorootparentit's actually quite easy to set up for netflix for example: https://github.com/AdrianCX/pico_hole no need to overcomplicate, your concerns are valid but we're not there yet. Above has worked fine for 2+ years as is. reply a-french-anon 10 hours agoprevTelescreen and you have to pay for it. \"The future is so bright I don't need my eyes to see it.\" reply quantified 21 hours agoprevThe title and subject sound like they are about smart TVs, but the example problems sound like they are about streaming in general, which might be streamed from my cable box, or on my computer monitor. Are the streaming issues really limited to the smart TVs? reply ok_dad 21 hours agoparentI think everything spies these days, I don’t know why the government is not just cutting all of that off with privacy laws. They’re attacking the heads but this stuff is like a hydra. Just pass a comprehensive law against data harvesting and pro-privacy. reply 8jef 17 hours agorootparentBecause governments are on it too, big time. It's not just about surveillance politics, or big businesses in some surveillance economy, or credit card purchase data leaked everywhere, or Echelon, or platforms spilling their (our) guts. It's about surveillance everything. Because it's not an option if you're McKinsey, a data broker, a private security firm, or anyone contracting them. Data collection is an obligation, a requirement. They need to know about what's everyones up to, even if it's only through real time metadata. Face recognition cameras everywhere, automatic photo radars, license plate readers at busy corners, everything going through apps in potentially always operating and recording pocket pcs we call smartphones, with potential trojans everywhere, in potentially everything. TV's are just one evocation of the disease, mainly directed at old folks, because nobody else cares about TVs and cable subscriptions anymore. Anyone with just an once of understanding about how computer networking actually operates will actively put up all sorts of firewalls and air gaps around anything they own, because why not. Anyone else, who shrugs at geek talk, is nothing but fair game, and will remain until someone suddenly pulls the rug from under them. Think massive actionable intelligence used against large parts of a population in a war, or a conscription, or a coup, or a full scale invasion, or whatever. Anything less will only be laughed at and dismissed. You're offering a comprehensive law against that? That's not enough, far from it. Pass anything, I guaranty you the hydra will still be well and thriving anyway. reply quantum_state 20 hours agorootparentprevWould like to second this … reply autoexec 1 hour agoparentprevThe linked report has a lot to say specifically about smart TVs as well as specific streaming services and platforms. Smart TVs are a major part of the problem, but far from the only thing to be concerned about. reply add-sub-mul-div 15 hours agoparentprevRight. It's no more acceptable for Amazon, Google, Apple, or Roku to have my data than the TV brand. But it's hard getting away from all of them. reply lotsofpulp 15 hours agorootparentI’m paying Apple to watch things, and sync them been my devices. I don’t see how Apple could not have “my data”. reply kotaKat 6 hours agoprevThe cool thing is when you buy it and the manufacturer decides to assault you months down the line with software updates against your will that add malicious advertising and bullshit to your TV. Love that predatory bullshit, and it keeps on happening with every TV platform. reply nonameiguess 2 hours agoprevWhat they're attempting to do seems fundamentally impossible to me. Personalization requires there is a specific person tied to the output. With phones and PCs, that's a fairly reasonable assumption. With a television, it quite often isn't. Services allow you to create individual \"who is watching\" profiles, but the reality at least for my family is no one uses those. We all watch from the same account and same profile. We also watch together, in which case there is no answer to a question that assumes only one person can watch at a time. Sometimes, no one is watching and the stream is simply left on while everyone is sleeping or out of the house and autoplay is streaming to an empty room. Sometimes, we leave things on intentionally for the cats. My wife has ADHD and puts something on only to walk away two minutes later, but it's still on. In some extremely dystopian future that I'm sure is coming quickly, a television may be equipped with video surveillance capability that can identify eyeballs in real time and decide exactly what animal is viewing what part of the screen and estimate from bloodflow in the face and pupil dilation the extent to which they care and are paying attention, but we're definitely not there yet. Right now, this is still just snake oil they're selling to ad buyers. Why I get almost all fast food, beer, and insurance ads, even though I don't drink, haven't eaten fast food since 2002, and haven't changed insurance providers since 2008. reply schainks 15 hours agoprev [–] I told my boomer elders NOT to plug in the smart TV. They just can’t resist the temptation of convenience. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Center for Digital Democracy (CDD) has urged the FTC (Federal Trade Commission) and FCC (Federal Communications Commission) to investigate the data collection practices of the connected TV industry, describing smart TVs as \"digital Trojan Horses\" due to their invasive tracking.",
      "The report raises privacy concerns, emphasizing that streaming services and devices gather sensitive data, which could affect consumer privacy and influence political campaigns.",
      "The CDD calls for stronger regulations to protect consumers, especially minority communities, from discriminatory data practices and suggests antitrust investigations into major industry players."
    ],
    "commentSummary": [
      "Smart TVs are criticized for potentially recording audio and customizing ads using viewer data, leading to privacy concerns.",
      "Users frustrated by the lack of non-smart TVs sometimes choose large monitors or avoid connecting smart TVs to Wi-Fi, though connections like Amazon Sidewalk can still occur.",
      "Alternatives such as Nvidia Shield or using a computer for streaming are recommended for enhanced privacy, yet the convenience of smart TVs often results in users connecting them, perpetuating privacy issues."
    ],
    "points": 93,
    "commentCount": 35,
    "retryCount": 0,
    "time": 1728334505
  },
  {
    "id": 41773212,
    "title": "FTX creditors will make money on bankruptcy",
    "originLink": "https://www.cnbc.com/2024/10/07/ftx-bankruptcy-judge-approves-more-than-14-billion-payback-plan.html",
    "originBody": "SKIP NAVIGATION MARKETS BUSINESS INVESTING TECH POLITICS VIDEO INVESTING CLUB PRO LIVESTREAM Search quotes, news & videos WATCHLIST SIGN IN TECH FTX creditors will make money on bankruptcy: $1.19 for every dollar PUBLISHED MON, OCT 7 20245:36 PM EDTUPDATED MON, OCT 7 20246:11 PM EDT MacKenzie Sigalos @KENZIESIGALOS KEY POINTS A Delaware bankruptcy judge approved FTX's reorganization plan almost two years after the crypto exchange spiraled into bankruptcy. The company says it has collected between $14.7 billion and $16.5 billion worth of property that it plans to distribute to creditors. According to the court-approved plan, 98% of FTX's creditors will get 119% of the amount of their allowed claim. Dado RuvicReuters Almost all of the creditors of failed crypto company FTX will end up profiting from the money they put into the exchange, a federal bankruptcy judge ruled Monday. Nearly two years after FTX spiraled into bankruptcy, a Delaware judge approved the company's reorganization plan, which involves paying out more than $14 billion to customers of the collapsed cryptocurrency exchange. \"Looking ahead, we are poised to return 100% of bankruptcy claim amounts plus interest for non-governmental creditors through what will be the largest and most complex bankruptcy estate asset distribution in history,\" said John Ray, who took over as FTX CEO following the company's bankruptcy filing in late 2022, in a statement on Monday. Ray, who also shepherded Enron through bankruptcy, added that the estate is working to finalize arrangements to make distributions to creditors around the world. The company says it has collected between $14.7 billion and $16.5 billion worth of property for distribution. FTX previously estimated that it owes creditors around $11.2 billion. According to the plan approved by Delaware bankruptcy Judge John Dorsey, 98% of FTX's creditors will get 119% of the amount of their allowed claim as of November 2022, when the exchange filed for bankruptcy protection. The price of bitcoin is up roughly 260% since FTX's failure. FTX raised the money by selling a number of assets, including venture investments held by the exchange and other investments held by Alameda Research, Bankman-Fried's crypto hedge fund. One of FTX's most high-profile investments was in artificial intelligence startup Anthropic, which is backed by Amazon. FTX sold most of its stake in Anthropic this year for nearly $900 million. The bankruptcy estate says it will make a separate announcement about the date the payout plan will go into effect and when it anticipates the start of distributions. FTX founder Sam Bankman-Fried was convicted of seven criminal counts last November, including charges related to stealing billions of dollars from FTX's customers. He received a 25-year prison sentence. — CNBC's Dan Mangan contributed to this report. WATCH: Caroline Ellison sentenced to two years in prison for role in FTX collapse WATCH NOW VIDEO01:42 Caroline Ellison sentenced to two years in prison for role in FTX collapse Subscribe to CNBC PRO Subscribe to Investing Club Licensing & Reprints CNBC Councils Select Personal Finance CNBC on Peacock Join the CNBC Panel Supply Chain Values Select Shopping Closed Captioning Digital Products News Releases Internships Corrections About CNBC Ad Choices Site Map Podcasts Careers Help Contact News Tips Got a confidential news tip? We want to hear from you. GET IN TOUCH CNBC Newsletters Sign up for free newsletters and get more CNBC delivered to your inbox SIGN UP NOW Get this delivered to your inbox, and more info about our products and services. Advertise With Us PLEASE CONTACT US Privacy Policy CA Notice Terms of Service © 2024 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Market Data Terms of Use and Disclaimers Data also provided by",
    "commentLink": "https://news.ycombinator.com/item?id=41773212",
    "commentBody": "FTX creditors will make money on bankruptcy (cnbc.com)92 points by koolba 16 hours agohidepastfavorite126 comments eftychis 15 hours agoThe statement is misleading. People are making 18% interest on the value of Bitcoin et al. at the value of 2022, which is less than $20k. Now that is $60k, back to the value levels of 2021. Thus, the only reason there is interest is that the cryptocurrencies found gained back their value, and the bankruptcy court gets to consider the values when the bankruptcy started in 2022, not current/before 2022 values. reply arduanika 14 hours agoparentYou are correct. As phrased, this headline and large parts of the article are fake news. The first sentence about \"profiting from the money they put into the exchange\" is particularly egregious. Nobody was putting money into the exchange when withdrawals were frozen, which is when these marks are from. The reference amount that's being \"repaid\" is a low quote from near the bottom of the crash. Nobody signed up for this correlation between (1) crypto price crash and (2) the exchange halting withdrawals. It was a straight-up theft of optionality. That said, the repayments do exceed expectations. That is newsworthy. I just wish they could report that news factually. reply tim333 11 minutes agorootparentSome people like me did put cash equivalent (usdc) in just before they froze, so I guess I'm making 18%. Though there's an opportunity cost. reply FreeTrade 14 hours agoparentprevI'm seeing a pattern of misleading headlines wrt this. My guess is that it is PR at work to convince public that FTX was a victimless crime - this is to help SBF avoid his full sentence. reply arduanika 14 hours agorootparentThere's definitely a pattern, but I don't want to assume motive. I doubt SBF will get his retrial, but still, it's good PR for a lot of people -- for Effective Altruism, for Stanford, for Sequoia -- whose reputations took a hit here. It's even good PR for the bankruptcy team to say that they got full restitution. And for the journalists, of course, it's a headline that really pops. But sitting here, we can't really know why we're being lied to. All we can do is take note of the lies, and of who's repeating them. reply marcuskane2 5 hours agorootparentOr, it's just kinda and interesting story on it's own, no crazy conspiracy theories needed? When Bernie Madoff or Enron or any of the other major headline-grabbing frauds fell apart, the victims generally got back almost nothing. The fact that FTX is returning all of the user's money, plus interest, is quite unique and newsworthy. reply Scoundreller 4 hours agorootparentMadoff is kinda like an FTX: on average, everyone has received 72% of their “investment” back. But there was some rule about everyone getting their first $1m or something back 100%. Funny thing about madoff is that it is still ongoing, distributions have diminished but last one was this year: https://www.madofftrustee.com/index.php?mobile=false Where madoff is a bit different is that they were more aggressive in taking money back that people took out. You’re really only getting back what you put in (and obvious losses through time value of money). And madoff didn’t gamble with the money, he mostly just sat on it. reply arduanika 3 hours agorootparentprevSure. As I wrote in my other comment, \"That said, the repayments do exceed expectations. That is newsworthy. I just wish they could report that news factually.\" So to flip it back on you: repaying the lowball marks, but not the actual full stolen value, is an interesting story on its own. No lies and exaggerations from the media are needed. Also, where you write: > \"The fact that FTX is returning all of the user's money...\" No. This is not a \"fact\". This is a lie. You have been misinformed. That's my whole point. Do not call it a fact. reply jimmydddd 5 hours agorootparentprevBut it's not really \"all of their money.\" That's just the way the news is spinning it. I think that's the point folks are discussing. reply darepublic 3 hours agorootparentprevI think it has to do with the incredible and increasing amounts of competition for people's attention. And of course human nature in what titles people click on. reply KoolKat23 11 hours agoparentprevI struggle to see the issue with the headline, this is how bankruptcy works, it's how they would usually report in relation to creditors. reply sobellian 5 hours agorootparentDuring sentencing, SBF attempted to argue that creditors had experienced \"zero harm\" as even then it was apparent FTX would be able to pay them back. John Ray himself rebutted that argument: https://www.courtlistener.com/docket/66631292/415/united-sta.... > And even taking into account the potential for achieving anticipated recovery levels, which is by no means assured, customers still will never be in the same position they would have been had they not crossed paths with Mr. Bankman-Fried and his so-called brand of “altruism.” The opportunity cost is real and cannot be ignored. reply KoolKat23 4 hours agorootparentI'm not arguing that, it doesn't change the fact that a crime occured. I'm just saying the title is not misleading. They mentioned it is bankrupt and by definition creditor rights are curtailed. reply sobellian 4 hours agorootparentTo the common man, \"made money\" and \"experienced economic harm\" would contradict each other. In that way the title misleads. reply KoolKat23 2 hours agorootparentThey mentioned it is bankrupt and by definition creditor rights are curtailed. reply sobellian 2 hours agorootparentOkay? I don't see how that makes it any less misleading. Compared to a universe where FTX did not go bankrupt, the creditors have much less money. reply norswap 10 hours agorootparentprevI don't know how bankruptcy documents work, but this is not a filling, it's a general-audience article. The truth is if you had one Bitcoin in FTX, that was worth 20k. You might have bought for more or less than that. Now it's worth 60k. You didn't get the 20k back immediately (in which case you could have repurchased the Bitcoin immediately and not lose anything). - If you bought Bitcoin above 20k, you lost money, whereas you wouldn't have otherwise. - If you would have kept your Bitcoin, you would have 60k now. You didn't get a choice in the matter. The problem if of course \"what is money\" — the thing you owned was a Bitcoin, and now you're getting back its value from back then in dollar terms. This value changed meanwhile, shocking! But quite clearly, most people would have had more money now if that hadn't happened. So while it's possible that some people would have sold lower than 24k (it didn't stay that low very long), most people wouldn't have, and so they lost money, in the commonly accepted undertanding. Imagine the government seized your house 10 years ago, then paid you back today its price from 10 years ago +20%. Did you not lose money? reply Sakos 5 hours agorootparentThis is such a bad faith argument. Imagine you put up your house as an investment into some crypto exchange and the exchange goes bankrupt because it turns out they're misusing customer funds and defrauding their customers. You'll get your house back when legal proceedings are done. What value that house has before or after is sort of irrelevant except as a way for you to twist the issue to fit your narrative. Nobody made you put up your house in some nonsense crypto exchange. That was you. Be glad the government is involved at all or you might not be getting anything back. reply jimmydddd 4 hours agorootparentBut what if instead of getting your house back, you're only getting the cash equivalent of what your house was worth THEN, plus some interest. Meanwhile, your house, which you no longer own, has tripled in value. reply jjeaff 14 hours agoparentprevDoes it not also have to do with the increased value of some of the other assets FTX bought? I believe SBF invested a large amount in some AI companies. reply manquer 14 hours agorootparentFTX invested $500M in Anthropic for 8% (at the time) and the bankruptcy estate sold 2/3rds of that for $884M, while it is tidy sum, it doesn't move the needle much in the overall money owed to creditors of $11.2B . The estate has recovered around $16B of the money, or basically close to half of the assets at the time, the bulk of the money is coming from bitcoin tripling in value, to put it another way if Bitcoin was same prices as 2022, then they would have only recovered ~ $5B or FTX continued operating without being frozen by the courts, they would need come with $33B to make their depositors whole in Bitcoin. reply JumpCrisscross 10 hours agorootparent> bulk of the money is coming from bitcoin tripling in value Source? I thought FTX's estate barely held any crypto. reply manquer 5 hours agorootparentThey barely held any bitcoin or ether in their assets 0.1% and 1.2% respectively that customers had bought or deposited on the platform, they did hold a lot of crypto assets though. Notably SOL sales accounted for close to half of recovered money here is a link to the last batch of $2.6B sale they made in May 2024 (https://dailycoin.com/ftx-estate-sells-last-2-6b-of-heavily-...) There was controversy from creditors over the steep discount, a discount itself is not unusual given the size of the block sale and the fact the tokens are locked for 4 years with monthly vesting. Naturally there was dispute on how much discount is acceptable . while Solona has grown 10x in price since the bankruptcy, it is not like people who had deposited SOL tokens are now covering for other deposits with just their holdings. What depositors assets had against their accounts at the time had little correlation to what FTX itself had as assets, the two most popular tokens Bitcoin (0.1%) ETH(1.2%) assets were lot less than what they would have been just storing the customer tokens as is. It is simpler to talk in bitcoin price given its popularity and use as baseline rather than prices of tokens and assets actually held by FTX itself or by users on FTX. reply jessriedel 14 hours agorootparentprevThe FTX stake in Anthropic was liquidated at a very high return back in ~May. reply ryanjshaw 14 hours agorootparentprevThe article mentions a stake in Anthropic that was sold for $900m, while it owes creditors $11.2b, so nah it wasn't enough to make a dent unless there were MANY other smaller investments that collectively added up to $3b on top of that. reply OccamsMirror 14 hours agorootparentNot to be pedantic but I think 8% of something can be considered a dent. reply paulpauper 10 hours agorootparentprevAs big of a piece of shit SBF is, he was technically not lying about FTX having the money. It's just that those tweets by CZ triggered a run on the assets at the worst time, which combined with mismanagement/fraud on SFB's part, did not help. reply JumpCrisscross 10 hours agorootparent> he was technically not lying about FTX having the money They didn't have the money. These gains are due to appreciation. reply paulpauper 10 hours agorootparentas early as Jan 2023, before bitcoin had appreciated, $5 billion had already been recovered https://www.forbes.com/sites/dereksaul/2023/01/11/bankrupt-f... Anthropic was another $1 billion reply JumpCrisscross 10 hours agorootparent$6bn out of twelve is very much not having the money. reply paulpauper 10 hours agorootparenta far cry from zero, and the CZ tweets triggered a run. How many other exchanges have enough assets on hand to cover every depositor at once instantaneously? Even mainstream banks cannot cover everyone (this is what a bank run is and is why central banks exist to provide a backstop in such an event). reply JumpCrisscross 10 hours agorootparent> far cry from zero Straw man. You said SBF \"was technically not lying about FTX having the money.\" He was. If you ask me to hang on to your $12 and I spend half of it, I don't have the money. > How many other exchanges have enough assets on hand to cover every depositor at once instantaneously? All of them. Exchanges and clearinghouses in a proper financial system are fully collateralised. > this is what a bank run is and is why central banks exist Banks are leveraged. FTX was not supposed to be levered. It should have been able to survive a \"run,\" because it wasn't supposed to have asset-liability mismatches. reply paulpauper 9 hours agorootparentAll of them. Exchanges and clearinghouses in a proper financial system are fully collateralised. According to coinmarketcap and coingecko, there are 200+ exchanges. you're saying all of them are fully collateralized? doubt it. reply JumpCrisscross 9 hours agorootparent> there are 200+ exchanges. you're saying all of them are fully collateralized? In crypto? No. Because it's a marketing term there for brokers. FTX was, at the end of the day, a broker. (As is Coinbase and the other \"exchanges\" for how most people use them.) In finance? Yes. Most exchanges (all in the U.S.) don't handle settlement; that's done by a clearinghouse, where the counterparty risk lives. They're fully collateralised [1]. [1] https://dtcclearning.com/products-and-services/settlement/ri... reply eftychis 14 hours agorootparentprevI am not sure. I don't think so but I haven't had time to read how the equities will get liquidated. reply bobsyourbuncle 14 hours agorootparentIt literally says they made 900M off Anthropic in the article reply eftychis 14 hours agorootparentLet me rephrase my answer: FTX made a good number in the double digits of investments and acquisitions. (https://www.crunchbase.com/organization/ftx-exchange/recent_...) I believe Anthropic was the most acclaimed/highest current value, and they still have about 1/3 of the original 8% investment. a) I am curious at what discount they sell Anthropic shares right now; b) I am not sure what is the prognosis for the other shares FTX owns; [ c) which creditors have preference to which money pot; usually there is a pyramid. Here it talks about consumers. (Specifically those owed less than $50k.) And there is a separate matter for shareholders who are looking at getting some of the seized by DoJ proceeds. (https://www.reuters.com/legal/crypto-exchange-ftxs-liquidati....) ] Best way in general is to read the actual pleadings: news is not the best at giving a good idea what the court is actually ordering. reply paulpauper 10 hours agoparentprevWhat if Bitcoin had fallen to $4k or something. then converting to cash would in hindsight seemed brilliant and creditors would be happy. reply moomin 10 hours agoparentprevIn yet another “crypto is just speed-running regular finance” moment, they ran the same crock about _Nick Leeson_. And that was a far from victimless crime as well. reply yieldcrv 2 hours agorootparentor crypto is regular finance its just a bankruptcy case being handled well, and far faster because of the blockchain records showing where things went. reply kwar13 11 hours agoprevI keep seeing this \"headline\" and it is the very definition of fake news. If you held SOL on FTX they will pay you at the Nov 2022 prices which was under 9 per SOL. It is trading at ~150 now. Bitcoin was trading at 17k, it is now 62k. FTX creditors didn't hold US dollars. They held crypto. A good chunk didn't even buy any of the crypto WITH US dollars. Many are in countries that US dollars is not legal tender. Guess what they're getting back for their claims? You guessed it. US Dollars. reply graeme 11 hours agoparentThat's putting it a little strong. FTX went bankrupt. You might normally expect to lose a substantial portion of your assets when that happens. To instead get back everything in dollar terms with a gain is remarkable. If you sent crypto to FTX legally you no longer owned them. You owned a claim to $X on FTX. It just wasn't analogous to a regulated broker where the client is the legal owner of a security. Iirc the contract with FTX is the creditors sold their stake to FTX. It is valuable to explain that these creditors underperformed simply holding crypto but calling it \"fake news\" really misrepresents the situation. reply kwar13 11 hours agorootparentNot really. You owned a claim to the very specific asset you deposited in an exchange, which is how segregated accounts work. Why US Dollars? FTX.us was domiciled in the US but FTX.com was in Bahamas. Why not some other arbitrary currency? Why not Bahamian dollar? Why not in Bitcoin? FTX has paid close to 1 billion dollars in fees to army of lawyers, consultants, bankers etc. in what was even at the time an 8 billion dollar bankruptcy. Even if FTX froze in time and did nothing at all, its assets would've recovered completely that 8 billion gap in its funding. It's been a boon to everyone involved and they're taking full advantage. I have no sympathy for FTX. It was a clear case of theft. However the creditors are getting robbed twice. Once by FTX, once by the bankruptcy proceedings. reply graeme 10 hours agorootparent>You owned a claim to the very specific asset you deposited in an exchange, which is how segregated accounts work. The company went bankrupt. Bankrupt. They did not have the assets they purported to have. FTX owed money to a variety of creditors including to crypto traders who deposited. They gambled on handing over their assets to a largely unregulated entity and it went bust. If a regulated securties broker goes bankrupt you still own the securities. Brokers need to follow very strict laws to be in that position. FTX faced no such regulation and if you sent them crypto you no longer owned it. FTX did. And they went bust. What you're saying makes sense if FTX were a US registered securities broker for listed securities on an exchange. But that wasn't what it was. And they went bust. reply kwar13 10 hours agorootparentI think you are not distinguishing between what a bankruptcy vs. theft means. I worked over a decade in investment banking including on large bankruptcy proceedings. A bank can go bankrupt and your deposits might be in jeopardy, because there is fractional reserve banking and by law they are allowed to hold far less (in the US it would actually be 0%) of your deposits and can deny your request to redeem your assets in full in cash. That is to prevent bank runs. FTX was an exchange, and while the holding company can go bankrupt the customer assets should be always fully funded in segregated accounts. FTX stole from customers and used the fund to front run their own customer via Alameda research. Most of FTX customers were outside US and are not US residents. US Dollars in this context holds no significance. For the record, FTX.us was a registered broker. https://brokercheck.finra.org/firm/summary/158816 And with SEC as an exempt broker. https://www.sec.gov/Archives/edgar/data/1876386/000187638621... reply JumpCrisscross 9 hours agorootparent> FTX was an exchange, and while the holding company can go bankrupt the customer assets should be always fully funded in segregated accounts FTX marketed itself as an exchange. That didn't make it one. Giving it money was legally akin to handing any small business in your town money. > Most of FTX customers were outside US and are not US residents. US Dollars in this context holds no significance. FTX was a U.S. company. Even the Bahamas outfit had U.S. dollar bank accounts. FTX's customers were obviously subject to U.S. jurisdiction. > FTX.us was a registered broker They owned a FINRA-member broker-dealer. Most FTX customers weren't doing business with its b-d. > with SEC as an exempt broker Not what Form D means. (\"Exempt broker\" isn't a thing under U.S. securities law.) Also, side note, banks can refuse withdrawals but specifically not to prevent a bank run [1]. A bank restricting withdrawals due to illiquidity is going under FDIC conservatorship. [1] https://activitycovered.com/can-a-bank-refuse-withdrawal/ reply norswap 10 hours agorootparentprev> FTX faced no such regulation and if you sent them crypto you no longer owned it. FTX did. This is at best only partially true, you own a claim on the underlying asset. This is not a matter of regulation, it's a matter of your contractual agreement with FTX. I don't know how more regulated brokers work, but I also doubt you own the asset outright, you also probably own a claim, which is why if the broker goes bankrupt because of fraud you might not recover it. Regulation wouldn't have changed anything here: as FTX simply broke the law, which they could have done regardless of regulation & reporting requirements (e.g. WorldCom, Enron, ...). What they did was not legal, even wrt to what regulation they were subjected to. reply JumpCrisscross 10 hours agorootparent> you own a claim on the underlying asset No, you're describing a secured claim. No crypto exchange I know of voluntarily gives customers a secured claim. At the moment of bankruptcy, unsecured claims are a claim on the company. Not on any asset. > don't know how more regulated brokers work The assets are segregated and customer claims prioritised and guaranteed by the SIPC. > Regulation wouldn't have changed anything here: as FTX simply broke the law None of what FTX did would have been remotely plausible if they'd been regulated as a broker-dealer. They'd have failed their FINRA audit on day one. Not saying what they did is impossible at a regulated b-d. It would just take a lot more thought and work than the shitshow they were running [1]. [1]. https://www.bloomberg.com/opinion/articles/2022-11-14/ftx-s-... reply JumpCrisscross 10 hours agorootparentprev> You owned a claim to the very specific asset you deposited in an exchange, which is how segregated accounts work There weren't segregated. The segregation claim was made by an entity in bankruptcy. FTX's customers have unsecured claims. > if FTX froze in time and did nothing at all, its assets would've recovered completely that 8 billion gap in its funding The FTX estate barely held any crypto when it went under. reply ForHackernews 10 hours agorootparentprev> You owned a claim to the very specific asset you deposited in an exchange, which is how segregated accounts work. Maybe in a real bank you do. Not in cryptoland. \"Not your keys, not your coins\" as they are so fond of saying. reply a_dabbler 11 hours agoparentprevI held mainly dollars on the exchange at the time. I see your point regarding the crypto holders on the exchange though. reply paulpauper 10 hours agoparentprevBut what if bitcoin crashed even more. Then it would not seem like such a bad deal to get dollars. reply Frummy 12 hours agoprevI’ve been getting legal mails for the entire process since I had like 0.000000000003 cents in a wallet called blockfolio that was acquired by FTX which was pretty funny to follow reply linotype 15 hours agoprevThe people that sold their stakes to people like Scott Galloway must be kicking themselves. Great trade. https://www.youtube.com/watch?v=TPFiRlZaclQ reply ignoramous 15 hours agoparentGalloway says he bought $1mn claim for $270k. That's a nice ~4.5x profit. reply fsckboy 12 hours agorootparentlooking at individual investments is fallacious, need to look always at your entire portfolio (i.e. not just winning lottery tickets) reply arder 12 hours agorootparentWhile that's true, if you have a good understanding of bankruptcy law, and a reasonable understanding of what assets FTX owned you could make a reasonable guess of how much money the eventual bankruptcy would pay out. Since the administrators publicly published what assets there were quite early on I think it's fair to say $270k always looked like a good deal. reply paulpauper 10 hours agoparentprevYeah, SBF was not lying about FTX having the money. It was not totally worthless as many had assumed. it shows how someone can be dishonest in some ways but honest in others. I too thought he was telling the truth. Had FTX not had money, he would have just shut up. I think such a long sentence may have been a miscarriage of justice in this regard. reply Nursie 10 hours agorootparent> Yeah, SBF was not lying about FTX having the money. Yes, he was. The reason people are being made whole now is that a couple of years down the line, some of his investments and acquisitions are now worth considerably more than they were at the time of bankruptcy. But at that point t FTX was insolvent and SBF was telling lies all over the place. reply paulpauper 10 hours agorootparentas early as Jan 2023, before bitcoin had appreciated, $5 billion had already been recovered https://www.forbes.com/sites/dereksaul/2023/01/11/bankrupt-f... Anthropic was another $1 billion reply Nursie 10 hours agorootparentEven that article says the assets there are not enough to come close to liabilities. FTX was insolvent at that time. reply paulpauper 10 hours agorootparentIt did not help that CZ triggered a run on the assets at the worst time; otherwise it likely would have been fine. When FTX ran out of money, every depositor instantly became a creditor. I doubt this is unique to FTX. many exchanges may have some shortfall between deposits and credits. reply kelnos 9 hours agorootparentThat's not how actual regulated exchanges work. No crypto \"exchange\" is actually an exchange, no matter what their marketing materials tell you. In the US, a regulated exchange is required to hold your securities in segregated accounts, and cannot play fun games with them. Crypto \"exchanges\" are a joke. > It did not help that CZ triggered a run on the assets at the worst time; otherwise it likely would have been fine I find that unlikely. SBF was doing a bunch of risky things with FTX's assets. If he hadn't been found out, he likely would have done more and more risky things, and as Bitcoin's price recovered, he would have used that higher price to justify doing even more risky things. I doubt there would have been many (if any) times when FTX could have paid out all its depositor obligations. reply Nursie 9 hours agorootparentprevI mean, they shouldn't, that means they're also running insolvent. Not only is that generally illegal, it's been the end of a long line of crypto exchange businesses like Quadriga, and possibly even going back to MtGox (though they were doing it as a cover for theft, rather than mismanagement, IIRC). And the FTX token that had a run triggered was something like 90% held by FTX - the value they accounted for was based on a tiny circulating pool of them. It was almost the classic \"If I print 10m of these, and sell you one for a dollar, I've got tokens worth $10m now, right?\" reply Scoundreller 14 hours agoparentprevMiami-Dade County did that: sold their $17m claim (because they owned the stadium that they sold naming rights to FTX) for probably about a third: > “I’ve never worked on a bankruptcy case that got better. It always gets worse,” said Commissioner Raquel Regalado, a lawyer who now works as a broadcaster. “The idea of just getting out as early as possible seems like a great idea to me. “ Those were some expensive words. And in general, always somewhat expensive words because the hedge fund buyers generally don't work \"lose\" into their models. https://www.miamiherald.com/news/local/community/miami-dade/... Selling your claim is only a good deal if the hedge funds are drunkenly stupid, you have no other assets/lending sources and are going to die soon or have debt at payday loan rates. reply ipsento606 14 hours agorootparentSelling your claim, or a portion of your claim, might also make sense from a risk tolerance / declining marginal utility of money point of view, if it represented a large enough portion of your net worth. Or put another way - if there were an investment opportunity that that had an 80% chance of 3x-4x returns in the next 2-3 years, I might consider investing 25% or even 50% of my net worth in that opportunity. But I certainly wouldn't invest 95% of my net worth. reply kelnos 9 hours agorootparentprev> Those were some expensive words. I find it weird that you condemn that decision based on perfect hindsight. > Selling your claim is only a good deal if the hedge funds are drunkenly stupid, you have no other assets/lending sources and are going to die soon or have debt at payday loan rates. Selling your claim reduces your exposure and eliminates the risk that you'd get even less after the bankruptcy process concludes. It also lets you book the loss now and move on. That's valuable to some people. Consider that people have different motivations and needs than you do. reply metaphor 13 hours agorootparentprevI fail to see how the decision was anything less than decisive prudence. Your cited article makes it abundantly clear that the provenance of said $17 million claim was a default clause entitling Miami-Dade County to three years worth of naming-rights fees. They sold that speculative claim for $5 million cash---effectively recovering that year's otherwise uncollectible receivables---then immediately turned around and locked in a 17-year, $117.4 million agreement with Kaseya[1]; back-of-the-envelope says that's an implied ~$5.4 million (2023 dollars) per year with 3% annual inflation adjustment baked in. Call me naive, but I imagine that if you're in the business of running a multi-purpose arena with real opex, you've gotta be the dumbest risk manager in South Florida to allocate expensive legal resources in chase of speculative claims when a mutual opportunity to repair a gapping hole in your balance sheet presents itself and you have a willing long-term replacement suitor lined up. [1] https://www.miamidade.gov/global/news-item.page?Mduid_news=n... reply Scoundreller 12 hours agorootparentThe overarching question is: why should the County have thought the hedge funds are overpaying for the claim and to take the money and run? Usually when you have several suitors that purely have profit in mind, you're the mark. Doubly so when their cost of capital is higher than your own. > to allocate expensive legal resources in chase of speculative claims On a claim this big, the bankruptcy trustee takes care of that for you. They're literally a fiduciary. The cost would be reading whatever gets mailed to you, but at the end of the day, there isn't much control you have over the ultimate outcome. And uhhh, in terms of credit worthiness, Kaseya has an interesting history: https://en.wikipedia.org/wiki/Kaseya_VSA_ransomware_attack . reply kelnos 9 hours agorootparentOverpaying or underpaying was irrelevant: the dollar amount they got was what mattered, and they were satisfied with that amount. reply s1artibartfast 12 hours agorootparentprevThey don't have to be overpaying. It was a win win. The way I read it the county got more money this way than if they held it. They they sold the stake ultimately worth 17 million, but they got their rights back, which they resold for 16 million. As long as they sold their stake for 1 million or more, they are in the green. reply Scoundreller 4 hours agorootparentThe rights were back to them at the time of default. It was independent of the claim sale. (They won on the reselling of the naming rights too by leasing them out for more per year than ftx) reply s1artibartfast 4 hours agorootparentThanks for the clarification. I thought the two were tied reply flomo 13 hours agorootparentprevnext [4 more] [flagged] Scoundreller 13 hours agorootparentFrom a public policy standpoint, you don't want local government authorities taking a quick buck now instead of (on average) more money a few years later. But to an elected politician that might not even be in office in a few years, money now is worth more at any cost than money later. A gov agency is best suited to ride these things out because their cost of capital is among the lowest. Generally dumb for a county to sell an asset to a hedge fund: the HF has to pay more in interest than a county does just to pay you money now. There's nothing to do here except wait, nothing to whip in shape and make more profitable. (Also cities shouldn't own stadiums, that's a gamble on the success of your local sports team and solvency of whomever you sell the naming rights to) reply JumpCrisscross 10 hours agorootparent> gov agency is best suited to ride these things out because their cost of capital is among the lowest Municipalities have a higher borrowing cost then the Treasury, though it's still relatively low. reply nroets 13 hours agorootparentprevThe buyers of these claims often have inside information. By selling during bankruptcy they gambled that the \"experts\" were wrong and it turn out not to be the case. That's why exchanges often suspend shares during bankruptcy: To make it clear that price manipulation and outright corruption is likely. I have both a claim in FTX and shares in a suspended (\"bankrupt\") company listed outside the US. I just ride these things out because I don't need the money right now. reply tiffanyh 15 hours agoprevDumb question: why are creditors getting paid more than they are owed? reply teractiveodular 15 hours agoparentInterest. From the article: > \"We are poised to return 100% of bankruptcy claim amounts plus interest for non-governmental creditors.\" For what it's worth, the article also points out that Bitcoin has gone up 260% since FTX's failure, so if FTX had not collapsed, somebody hodling their BTC there might have earned 260% instead of 19%. reply cpitman 15 hours agorootparentYeah, this is not creditors \"making money\". Anyone who had 1 bitcoin in FTX is not getting their 1 bitcoin back, which is massively more valuable. Instead, they are getting 119% of the USD value of a bitcoin in late 2022. They are massively losing out. They are effectively getting back 33% of their assets. reply Scoundreller 14 hours agorootparentaren't a lot of the FTX creditors cash creditors? they're definitely making money. Dunno what the breakdown between bitcoin and cash creditors are, but the only way to make bitcoin creditors more whole would be to stiff the cash creditors. And the FTX token creditors are making [DIVIDE BY ZERO] reply csomar 14 hours agorootparentOne way to think about it, is that if FTX was whole, then it's 119% cash (since that's the where the 19% is coming from). reply listenallyall 15 hours agorootparentprevThe creditors are only \"earning\" 19%. The first 100% is their own investment. The comparison you are trying to make is 260% vs 19%, not 119%. reply teractiveodular 15 hours agorootparentThank you, corrected! reply tiffanyh 14 hours agorootparentprevBut this assumes the person wouldn’t have withdrawn their funds, during that period of time. reply clhodapp 11 hours agorootparentThey could also have withdrawn their funds and invested them in something else. reply Nursie 10 hours agorootparentprevFTX didn’t have their BTC though. That’s part of the problem. reply Nursie 15 hours agorootparentprevThankfully for the investor, the non-cryptocurrency assets generated enough return to make them whole and even give them a profit. reply ToValueFunfetti 15 hours agorootparentIf bitcoin is up 260%, the non-cryptocurrency assets must bringing the average return down, right? reply Nursie 10 hours agorootparentFrom what I’ve read there wasn’t really that much bitcoin left by the time they were shuttered, and their own tokens were worthless. That’s part of the whole issue - SBF was just doing whatever he felt like with customer assets and balances. Plus inventing assets out of thin air. The profit that people will get has largely been driven by FTX’s investments in AI stuff, which turn out to have done great. Think about it this way (exaggerated to make a point) - you give SBF $10k to buy Bitcoin on FTX. You expect him to have that amount of BTC locked away somewhere for you. Instead he blows your $10k on houses for himself, giving money to politicians, sponsoring sports grounds and buying stuff for his parents. He’s throws some of it into AI firms. At the time of bankruptcy all he’s actually holding for you is $200 of BTC. That goes up in value to $460. W00t. But wait, two years later those few million he threw at AI seemingly for shits and giggles are now worth a few billion, so you can be made whole and even get a little profit. reply Scoundreller 14 hours agoparentprevdunno why nobody has answered your real question, which I think is: \"Why aren't debt creditors getting made whole (as of date of bankruptcy) with the balance going to equity holders, like every other bankruptcy?\" reply cma 15 hours agoparentprevIf your ming vase is stolen should you get it back after it appreciated, or the thief gets the upside and you just get cash as if it were a forced sale at theft time? Not an exact analogy but I think it at least shows there is a spectrum of situations to consider. reply kortilla 15 hours agoparentprevYou’re asking why the creditors are getting their assets back reply immibis 10 hours agorootparentbut they aren't reply arder 11 hours agoparentprevThis was covered in some of the coverage much earlier about the bankruptcy proceedings. Essentially it's within the court's power to not only pay the creditors but to pay them interest on their losses if that's possible. That's obviously balanced against the rights of the equity holders to get back any value if there is any equity left. In this specific case the people with equity were: the fraudsters who ran the scam, venture capitalists. No one wants to pay off the fraudsters and the VCs would rather pretend this whole thing didn't happen (because it makes them look like drunken coked up degenerate gamblers on a weekend at Vegas) so everyone agreed the court should be generous with how they calculate the return to customers. Government entitires also have a claim for any fines or taxation or whatever, but they're relatively happy for the retail customers to be protected first too - but they care less about the equity getting wiped out. My guess would be anything above what the customers get may well go out to government fines rather than returning to the equity holders. reply zoklet-enjoyer 15 hours agoprevI bought a Solana NFT that I never took off of FTX. Anyone know if I can do anything about that? reply namjh 14 hours agoparentThere was an NFT section in the claim form so certainly they are aware of but I'm not sure it's still open reply coffeebeqn 12 hours agoparentprevWhat’s the current fair market value of a “solana NFT”? reply zoklet-enjoyer 18 minutes agorootparentI dunno. $1? I paid like $200. I just kind of want the picture back. I didn't have a Solana wallet when FTX was crashing and didn't want to go through the hassle of making one. I got all my other stuff off there that was actually worth something reply olalonde 11 hours agoprevImagine spending 25 years in federal prison knowing you might have avoided it if only you had not filed for bankruptcy. reply garaetjjte 5 hours agoparentNo, it only works because of magic of bankruptcy law converting liabilities to dollar value at the time of filling. reply olalonde 3 hours agorootparentAh I see, so they didn't recover the actual crypto that was owed, just the estimated USD value at the moment of bankruptcy? By the way, I didn't mean to imply SBF wasn't guilty, simply that he might have been able to cover up the fraud if he had been given a bit more time. reply lolc 6 hours agoparentprevSo could FTX, at the time of its bankruptcy, let everybody get the assets they had title to? Because that was the issue wasn't it? They said they were holding stuff for customers, but didn't. The way I understood it the fraudsters only held a fraction of the Bitcoin they were supposed to hold, for example. How would the scenario work where bankruptcy wasn't declared? They would have refused to provide assets to customers, the customers would have sued, and the fraud would have come out anyway. Delaying discovery when you're underwater on your obligations means you're just piling on more crimes. Which is probably what lawyers explained to the chief fraudster. It gets harder and harder to claim an honest mistake. reply paulpauper 10 hours agoparentprevblame CZ. had he not triggered the run on FTX assets by making those tweets, likely FTX had enough assets to survive until Bitcoin began its rebound. reply kelnos 9 hours agorootparentI see a disturbing trend in your posts: you seem to want to place the blame anywhere but on SBF's shoulders, where it rightfully belongs. Exchanges shouldn't be like banks. FTX should have had customer assets on hand to return, no matter what. That's how regulated exchanges are supposed to work. But this is crypto-land, where nobody does the right thing. reply yieldcrv 2 hours agorootparentalthough I agree because SBF shouldn't have been running the exchange like this at all the truth is that in the US none of this gets prosecuted while people are making money, or being reimbursed as a remedy at the company's own volition. very few exceptions, you basically have to piss off a completely different industry, like bragging about raising drug prices instead of silently like everyone else, for prosecutors to search for improper accounting to nail you with. reply immibis 10 hours agorootparentprevThis wouldn't help because it would still not have enough Bitcoins to pay its customers. reply paulpauper 9 hours agorootparentthere are hundreds of exchanges. how many of them are fully collateralized? doubt all of them are. reply kelnos 9 hours agorootparentThen they're not exchanges. They're just places to put assets while the people who run them do whatever they want with those assets. reply olalonde 3 hours agorootparentprevThose that aren't fully collateralized are committing fraud. reply immibis 2 hours agorootparentOr they are banks. Fun fact: I got a permanent ban from the r/cryptocurrency discord for saying exactly this. reply whatever1 15 hours agoprev [–] Now imagine if we did not put sbf in jail and he kept leveraging. By now it would have been a quadrillion dollar company. reply kelnos 8 hours agoparentNo, SBF would have continued to take ridiculous risks with customer assets, and eventually it all still would have collapsed. Don't look at this as validation of SBF's methods. This was luck. And there still isn't enough to make customers whole. For customers who deposited Bitcoin, for example, they're now still a lot worse off than if they'd held onto the coins themselves. Sure, they're getting back the cash value of their Bitcoin from several years ago (plus interest), but if they got the Bitcoins back, they'd have significantly more. reply Analemma_ 15 hours agoparentprev [–] That's not how any of this works. If you steal money from the cash register to bet it all on black in Vegas, you're still going to jail even if you happen to hit and be able to return what you took. reply helsinkiandrew 11 hours agorootparent> That's not how any of this works. If you steal money from the cash register to bet it all on black in Vegas, you're still going to jail. But, if the investments hadn't hadn't gone bad and FTX hadn't run out of money, it's probable that no one would have known that he had stolen/borrowed customer money. The same probably goes for Elizabeth Holmes/Theranos and Nick Leeson/Barings Bank - its only when things go wrong that misdeeds are found. reply JumpCrisscross 10 hours agorootparent> its only when things go wrong that misdeeds are found Counterpoint: Shkreli. reply whatever1 14 hours agorootparentprevWell if you observe me just for the moment I have on hand 1B, my net worth is 1B and JP Morgan will be willing to lend me 10B. Worst comes to worst tax payer bails again the banks out. reply 8note 11 hours agorootparentWhy do you think the tax payer taking a gigantic loss is a good thing? I'd prefer that the government fund food for children rather than confidence men/women reply whatever1 1 minute agorootparentWe did it for Elon and Twitter. So why not for SBF? FireBeyond 14 hours agorootparentprevThat is, coincidentally, how we still have FedEx. Fred Smith taking the company's last $5K to Vegas and luckily winning $27,000. Mind you at that point, pilots were putting fuel on their personal credit cards, payroll had been bouncing for weeks. (Funnily, some people here think he did the right thing.) reply vlovich123 14 hours agorootparentThat’s the story he likes to tell and it’s repeated uncritically often enough, but I find it stupendously unlikely to be reality that he converted 5k into 27k playing blackjack of all games. And that that one week was enough to see him through to close 11m at an unspecified future date after having burned 80m getting the company up and running. I chalk it up more to myth building and would love to see a reporter that dug into that story to know what actually happened. reply sidewndr46 6 hours agorootparentIt's survivor bias. It seems unlikely, but we know FedEx to be a successful company to some reasonable level at this point in time. It stands to reason at some point in the past the company was very close to collapse. If it had collapsed we would never have heard about it. reply helsinkiandrew 11 hours agorootparentprev> That is, coincidentally, how we still have FedEx. Fred Smith taking the company's last $5K to Vegas and luckily winning $27,000. The difference is it was the companies money - not FedEx customers. reply listenallyall 12 hours agorootparentprevDo you actually believe if paychecks were bouncing, pilots would be paying for fuel with their own money? Myths are kind of cool sometimes but let's stay within the boundaries of reality. I'm sure the blackjack story is highly exaggerated, probably also the story that his professor gave his business plan a failing grade. reply chimert 15 hours agorootparentprev [–] Yeah but what if you return 119% of what you took? reply JumpCrisscross 15 hours agorootparent> what if you return 119% of what you took? You go to jail. It’s not a hypothetical. reply qingcharles 14 hours agorootparentprev [–] You can go to jail for stealing \"nothing.\" Two Illinois cases I'm thinking of: https://casetext.com/case/people-v-kotlarz https://case-law.vlex.com/vid/people-v-haissig-2110726-88540... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Delaware bankruptcy judge has approved FTX's reorganization plan, which allows creditors to receive $1.19 for every dollar claimed, indicating a surplus in collected funds.",
      "FTX has gathered between $14.7 billion and $16.5 billion to distribute, surpassing the $11.2 billion owed, ensuring that 98% of creditors will profit.",
      "The funds were raised through asset sales, including a stake in AI startup Anthropic, and the payout plan's start date will be announced later."
    ],
    "commentSummary": [
      "FTX creditors are expected to receive 100% of their bankruptcy claims plus interest, but this is based on the value of cryptocurrencies at the time of FTX's collapse in 2022, not their current higher values.",
      "Critics argue that the media is portraying this as a positive outcome, despite creditors not receiving the full value of their original cryptocurrency holdings.",
      "Some speculate that this narrative is intended to enhance the reputations of those associated with FTX, including its founder, Sam Bankman-Fried (SBF)."
    ],
    "points": 92,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1728353782
  },
  {
    "id": 41770111,
    "title": "Is AWS S3 having an outage?",
    "originLink": "https://news.ycombinator.com/item?id=41770111",
    "originBody": "AWS status https:&#x2F;&#x2F;health.aws.amazon.com&#x2F;health&#x2F;status shows all green but I am having internal server errors returned from S3. Anyone else having this issue? Downdetector has spike for AWS outage coincidentally https:&#x2F;&#x2F;downdetector.com&#x2F;status&#x2F;aws-amazon-web-services&#x2F;",
    "commentLink": "https://news.ycombinator.com/item?id=41770111",
    "commentBody": "Is AWS S3 having an outage?91 points by GGO 23 hours agohidepastfavorite43 comments AWS status https://health.aws.amazon.com/health/status shows all green but I am having internal server errors returned from S3. Anyone else having this issue? Downdetector has spike for AWS outage coincidentally https://downdetector.com/status/aws-amazon-web-services/ mopatches 23 hours agoAWS has posted the outage: https://health.aws.amazon.com/health/status reply gslin 22 hours agoprevSomething related/non-related, it's still painful to read specific timezone not UTC. reply nnf 22 hours agoparentI've long wished for built-in browser functionality that converts times to the user's preferred time zone, with perhaps a dotted outline indicating that a change was made by the browser to the page. reply crgwbr 21 hours agorootparentI’d always hoped this is what HTML’s time tag would become. Unfortunately it does almost nothing. reply yellowsir 1 hour agorootparentsame with gps - the user should deside how to open direction / location links. reply daniel_sim 21 hours agorootparentprevThis is worth proposing. A tag where fallback text is provided within which can be overridden by the browser with a formatted date string would be excellent. reply colanderman 21 hours agorootparentIt exists: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/ti... As a nearby comment indicates, it's not clear any browser makes use of it. reply spartanatreyu 19 hours agorootparentI used theelement in a subscription dashboard. All times on the page are in UTC and are wrapped in aelement. The raw UTC time is on the datetime attribute and a fallback more easily readable time is inside the tags. Some JS on the page removes whatever text is inside the tag and replaces it with the user's locale specific format (no libraries required, it's a part of the browser standards). User friendly times wasn't actually the reason we implemented it. Our largest concern was our E2E testing. We needed to make sure that the dates/times displayed were always right (and since subscriptions involve money, we wanted to make sure that part of the website was the most tested.) The E2E testing simply ignores whatever is inside the tag and reads the datetime attribute instead. Then we can fastforward or rewind the simulated time inside the test to make sure everything is working as expected. reply krick 21 hours agorootparentprevYeah, but, I mean, the least you could do is to say UTC-7. I'm sure everybody living in PDT knows it's, well, their time, but how the fuck should everyone else know what time PDT is. reply quesera 19 hours agorootparentAlso, some timezone labels are ambiguous, e.g. \"CST\". reply pxx 16 hours agorootparentWhat I learned recently is the way Python strptime deals with this. It only parses the current time zone or \"GMT\" or \"UTC\" and all have the same effect (of returning a tz-naive object). This behavior is amazing because I don't think it's ever what you want. $ TZ=Asia/Shanghai python -c \"import datetime; print(datetime.datetime.strptime('4CST', '%H%Z').astimezone(datetime.timezone.utc))\" 1899-12-31 19:54:17+00:00 $ TZ=America/Chicago python -c \"import datetime; print(datetime.datetime.strptime('4CST', '%H%Z').astimezone(datetime.timezone.utc))\" 1900-01-01 10:00:00+00:00 $ TZ=America/Havana python -c \"import datetime; print(datetime.datetime.strptime('4CST', '%H%Z').astimezone(datetime.timezone.utc))\" 1900-01-01 09:29:36+00:00 $ TZ=America/Havana python -c \"import datetime; print(datetime.datetime.strptime('4CDT', '%H%Z').astimezone(datetime.timezone.utc))\" 1900-01-01 09:29:36+00:00 $ TZ=America/Los_Angeles python -c \"import datetime; print(datetime.datetime.strptime('4CST', '%H%Z').astimezone(datetime.timezone.utc))\" ValueError: time data '4CST' does not match format '%H%Z' That last error was real fun to debug when something worked in production but not locally. reply OhMeadhbh 17 hours agorootparentprevHow is CST ambiguous? Are you thinking of all those counties in Indiana that don't observe daylight savings? In theory at least, a specific instant in CST maps to a single specific instant in UTC, GMT, CUT or Zulu Time, whichever you set your watch to. And it does seem like people sometimes forget that CST is not the same thing as CDT. Several months ago (after the 2024 PST -> PDT crossover) I had someone across town tell me they wanted to set up a meeting at something like 9AM. But when the invite came, the time zone was set for 9AM PST instead of 9AM PDT. I assumed it was PDT since we were in the same locality. But I did make sure my schedule was clear for the hour before on the off chance they had some weird software bug that picked time zones at random. If your point is something similar, then I heartily agree. In theory, converting between time-zones and daylight and standard times is easy, but in practice there are several situations where it's made more difficult than it should be. reply quesera 4 hours agorootparentI was referring to the multiple timezones that are abbreviated to \"CST\", as described in a sibling comment. But you bring up another good example. I've worked with people who write times as \"PST\" or \"EST\" all year long. This bothers me in its simple incorrectness -- I do know what they mean but I hate autocorrecting them. But I've also worked with people in parts of Indiana, and Mexico. When they say \"CST\" at any time of the year, they might mean it precisely! My strategy is to write, e.g. \"8:30 AM US/Pacific\". Which probably annoys other people, but at least it's precise and unambiguous. I think it's less awkward than the equivalent \"America/Los_Angeles\". Full list of US lower 48 timezones: US/Arizona, US/Central, US/East-Indiana, US/Eastern, US/Indiana-Starke, US/Michigan, US/Mountain, US/Pacific. And the +2s: US/Alaska, US/Aleutian, US/Hawaii reply chucksmash 17 hours agorootparentprev> How is CST ambiguous? - CST: Central Standard Time UTC−06 - CST: China Standard Time UTC+08 - CST: Cuba Standard Time UTC−05 reply quesera 19 hours agoparentprevYes, this can be super painful, especially when correlating information from several sources, or when traveling. It can become almost impossible when reviewing historical data. My solution to inconsistent time rendering in AWS (sometimes UTC, sometimes localtime) is to run a separate browser profile for AWS (and third party status pages) that that's always running in UTC. But seriously, status page people: there's no excuse for being vague about timezones! reply szvsw 22 hours agoprevus-east-1 gang rise up!! For once I can feel mild pleasure at seeing the tables turned… To be honest I don’t know why all my projects are always in USE1, I guess it’s just because that’s where we have always had them for my lab so I’ve stuck with it for no good reason… reply jedberg 20 hours agoparentUS East 1 was the default region until a few years ago. If your account is older than that, then most likely all your stuff is there. reply szvsw 19 hours agorootparentYeah the account is from like 2019 or so. But still, I’m spinning everything up with Terraform or AWS Copilot, so it is still an active choice on my end to put it in us-east-1. reply averageRoyalty 20 hours agorootparentprevUnless - like most people - you and your audience are not in the US. reply jedberg 20 hours agorootparentThis wasn't an \"everyone is in the US\" type of post. Even for non-US folks, for a long time the default region was us-east-1, until they switched it to eu-west-1, and about 1/2 of all of AWS customers are in the US, or at least used to be until recently. reply EvanKnowles 12 hours agorootparent\"Where's my new server gone? ... oh, it's hanging out in us-east-1, damnsit.\" reply cr125rider 22 hours agoparentprevThey launch all the new fun toys there! reply iJohnDoe 18 hours agoparentprevIt’s usually always cheaper there. reply synhare 23 hours agoprevElastic Beanstalk, Lambda, and CloudWatch returning errors for us. us-east-2 reply aertmann 23 hours agoprevCan confirm, S3 backed CloudFront experiencing random errors in us-east-2 for the past 15 minutes at least. reply chromatin 23 hours agoprevCloudfront is: my small, not even yet profitable SaaS landing page and javascript frontend, served by CloudFront, are down since about 17 minutes ago (3:28 US Eastern) the API whcih sits behind ELB is working fine edit: us-east-2 reply mastry 20 hours agoprevI wonder if this is related to the NHC outage? https://news.ycombinator.com/item?id=41771629 reply austinpena 22 hours agoprevLooks back up: https://www.taloflow.ai/is-aws-down/us-east-2 reply GGO 23 hours agoprevS3 on us-east-2 stabilized for us as of 2 minutes ago reply mopatches 23 hours agoprevWe're seeing CloudFront and S3 issues in us-east-2 in multiple accounts. No errors in us-east-1 or and ap-south-1. reply paulddraper 22 hours agoparentNo issues in us-east-1 (for once....) reply mopatches 22 hours agorootparentThank you! I was misreading our logs. Can confirm no errors in us-east-1 for us as well. reply dn0 20 hours agoprevNext time you can also check https://cloudstatus.page/cloud/aws/issues I guess I'll increase the frequency of some probes to get better aligned with the official timeline :) reply wbobeirne 23 hours agoprevAlso seeing Cloudfront failures on my end, both in us-east-1 and us-east-2. reply MuffinFlavored 23 hours agoprevhttps://health.aws.amazon.com/health/status Rhetorical question (I know why, humans manually involved, incentive to not report SLA breakage, etc.): How does their status page not auto-update when one of their core APIs goes to basically 99% 500 (or even above 5% 500) status error? reply gottorf 23 hours agoparent\"Show me the incentive, and I'll show you the outcome.\" reply jamroom 23 hours agoprevus-east-2 seeing tons of S3 errors. reply MuffinFlavored 23 hours agoprevYes. I can't tell if listing/reading is fine but putting (uploading) for sure seems to not be working (500 error). reply jerjerjer 23 hours agoparentHave issues reading (500). reply sdv0389 23 hours agoprevSeeing CloudFront + S3 errors in us-east-2 on our end as well. reply sdv0389 23 hours agoparentAnd now we're back up. reply sgt 22 hours agoprevThis is why I use Hetzner's Object Storage. Proven and tested! /s reply 7874cole 20 hours agoprev [–] Next time my boss complains about uptime, I will tell him, even AWS have downtime. Boom! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "AWS S3 faced an outage, primarily affecting the us-east-2 region, with users encountering internal server errors.",
      "Despite AWS's status page indicating normal operations, Downdetector showed a significant increase in outage reports, with additional issues noted in CloudFront, Elastic Beanstalk, and Lambda.",
      "The incident highlighted challenges with time zone inconsistencies in AWS status updates, although the situation eventually stabilized."
    ],
    "points": 91,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1728330114
  }
]
