[
  {
    "id": 42690473,
    "title": "Snyk security researcher deploys malicious NPM packages targeting cursor.com",
    "originLink": "https://sourcecodered.com/snyk-malicious-npm-package/",
    "originBody": "HOME SERVICES TRAINING BLOG CONTACT Snyk security researcher deploys malicious NPM packages targeting Cursor.com Published January 8, 2025 Every morning I get up and check what malicious packages my detector had found the night before. It’s like someone checking their fishing nets to see what fish they caught. As I was looking at last nights malicious packages I noticed something strange: Someone from Snyk had deployed several packages to NPM. Even weirder, the names of those packages appeared to show they were targeting Cursor, the hot new AI coding company. These packages were deployed by an NPM user named sn4k-s3c. The packages are named things like “cursor-retreival”, “cursor-always-local” and “cursor-shadow-workspace”. If you install any of these packages they will collect data about your system and send it to an attacker controlled web service. You can find the packages on NPM here: https://www.npmjs.com/~sn4k-s3c You can see in this screen shot that the package is grabbing the output of a env command which will include many configuration options for your system. Often things like AWS keys, NPM tokens, GitHub credentials and other sensitive variables are exposed by the env command, so guess what? The threat actor now has all those credentials too! You can see in the screenshot that the data is then exfiltrated to a website that the attacker owns. Now, typically, when we see packages like this, they are attempting to perform a dependency confusion attack on a specific company. I don’t know if Cursor.com has a bug bounty program or a specific background. Still, I would suspect that Cursor has several NPM private packages named “cursor-always-local”, “cursor-retrieval”, and “cursor-shadow-workspace”. The person who created these packages is probably hoping that Cursor employees accidentally install these public packages, which will send their data to the attacker-controlled web service. Luckily, in addition to me seeing these files, the OpenSSF package analysis scanner identified these packages as malicious. OSV generated 3 malware advisories: MAL-2025-27, MAL-2025-28 and MAL-2025-29. You can see the malware advisories here: https://osv.dev/list?q=cursor&ecosystem=npm Who deployed these malicious packages? Okay, we know what the packages do when installing them, and we think they target Cursor.com. Who would do this? Well, the answer is in the NPM package metadata. The user who published the NPM package uses a snyk.io email address for the Snyk Security Labs team. This part of the metadata cannot be faked. The author field in the metadata specifically mentions an employee at Snyk. This part of the NPM package metadata can be faked, but since the publisher is a verified Snyk email, my guess is that this genuinely came from Snyk. What can you do? I’ve alerted NPM but these packages haven’t been marked as malicious yet, so no security tool could protect you from these malicious packages. Unfortunately, that’s how most software supply chain security tools work: you have to know that a package is malicious before the tool can protect you. But in general, it’s a good idea not to install NPM packages blindly. If you know what to look for, there are definite signals that these packages are dodgy. All of these packages have just two files: package.json and index.js (or main.js). This is one of several flags that you can use to determine if a package is legit or not. Hopefully, NPM will remove these packages soon. Paul McCarty SourceCodeRed.com Security Research & Trainer https://www.linkedin.com/in/mccartypaul/ Read about Software Supply Chain Red Teaming Learn More Copyright © 2024 – SOURCECODERED All Rights Reserved",
    "commentLink": "https://news.ycombinator.com/item?id=42690473",
    "commentBody": "Snyk security researcher deploys malicious NPM packages targeting cursor.com (sourcecodered.com)540 points by arkadiyt 20 hours agohidepastfavorite270 comments n2d4 16 hours ago[EDIT: See the response by a Cursor dev below — looks like it was not authorized by them] Sounds to me like Cursor internally has a private NPM registry with those packages. Because of how NPM works, it's quite easy to trick it to fetch the packages from the public registry instead, which could be used by an attacker [0]. Assumably, this Snyk employee either found or suspected that some part of Cursor's build is misconfigured as above, and uploaded those packages as a POC. (Given the package description \"for Cursor\", I'd think they were hired for this purpose.) If that's the case, then there's not much to see here. The security researcher couldn't have used a private NPM registry to perform the POC if the point is to demonstrate a misconfiguration which skips the private registry. . [0] In particular, many proxies will choose the public over the private registry if the latest package version is higher: https://snyk.io/blog/detect-prevent-dependency-confusion-att... reply ArVID220u 15 hours agoparentcursor dev here. reasonable assumptions, but not quite the case. the snyk packages are just the names of our bundled extensions, which we never package nor upload to any registry. (we do it just like how VS Code does it: https://github.com/microsoft/vscode/tree/main/extensions) we did not hire snyk, but we reached out to them after seeing this and they apologized. we did not get any confirmation of what exactly they were trying to do here (but i think your explanation that someone there suspected a dependency confusion vulnerability is plausible. though it's pretty irresponsible imo to do that on public npm and actually sending up the env variables) reply nomilk 14 hours agorootparent> \"pretty irresponsible\" Wouldn't it be more like \"pretty illegal\"? They could have simply used body: JSON.stringify(\"worked\"), i.e. not sent target machines’ actual environment variables, including keys. reply reubenmorais 11 hours agorootparentIt's an unfortunate incentive structure. If you're doing offensive security research, there's two ways you can go about it: you can report the potential vulnerability without exploiting it, in which case you risk the company coming back to you and saying \"thanks but we don't consider this a vulnerability because it's only exploited through misconfiguration and we're too smart for that\". Maybe you get some token reward of $50. Or you can exploit it and say here's the PoC, this many people at your company fell for it, and this is some of the valuable data I got, including some tokens you'll have to rotate. This puts you into actual bug bounty territory. Certainly the PR side of things alone will incentivize them to pay you so you don't make too much of a noise about how Cursor leaked a bunch of credentials due to a misconfiguration that surely every good programmer knows about and defends against (like so many vulnerabilities seem so dumb in hindsight). reply xmodem 7 hours agorootparentCursor does not have a bug bounty though, and its hard to see how this constitutes anything other than a direct attack on them, their users, or both. \"The incentive structure made me do it\" does not justify acting like a criminal. reply grajaganDev 5 hours agorootparentCursor asks researchers to report vulnerabilities to their GitHub security page. The same incentive to show impact applies even without a paid bounty. reply px43 5 hours agorootparentprev> Cursor does not have a bug bounty Shouldn't this alone be considered criminal negligence at this point? Cursor isn't some random open source project. It's a company that has funding, and subscriptions. Hell, I pay Cursor for a monthly subscription. Pretty incredible that they have no bounty program. reply britannio 5 hours agorootparentThe lack of a bug bounty program doesn't prohibit them from rewarding reported vulnerabilities. reply taskforcegemini 1 hour agorootparentdo they though? reply miki123211 8 hours agorootparentprevYou can also console.log those credentials as a PoC, and then show that the console.log could trivially be replaced by a fetch(). Kind of like a lot of exploit PoCs just \"pop a calc\" (AKA open the Calculator app), not because opening the calculator is valuable to an attacker, but because if you can open calculator, you can do anything. reply objectified 6 hours agorootparentThe problem there though, is that with PoCs like this, as an attacker you want to have a ping back to your system so that you know the attack has been successful (in this case they probably expected/hoped someone at Cursor to install the package, that's the usual objective in a dependency confusion attack). But what they could have done, is send a less sensitive thing like just the current working directory or current effective user, instead of the whole environment. reply fkyoureadthedoc 4 hours agorootparentWhat actually changes though in your scenario? Potential bad actor gets RCE on your dev machines, it doesn't really matter what they sent home, you're rotating keys and doing your due diligence either way. reply mistercow 9 hours agorootparentprevI wonder how viable it would be to find a public key your target owns and use it to encrypt the data you send back. Then you could prove to them that you exfiltrated real data without exposing it to anyone outside the company. Alternatively, you could hash it and say “Look, it’s a sha of your database password hyphen “yougotpwnd”” reply necovek 7 hours agorootparentHTTPS certificates should already have that public key for you, so it should be trivial. reply Szpadel 6 hours agorootparentprevwouldn't capturing only env names without values be ideal middle ground? look we had access to your Aws tokens, we could take over your account but we didn't steal actual token, we just got proof that we could access it reply reubenmorais 1 hour agorootparentYes I agree names only would have been a better approach here. reply whimsicalism 2 hours agorootparentpreva prerequisite of “offensive security research” is that it is solicited, no ifs or buts. what they did was absolutely wrong and frankly likely illegal reply 6mile 10 hours agorootparentprevYeah, I agree the incentive structure is broken for bug bounty hunters. Until the BB platforms themselves create some rules for their customers and researchers, we are gonna continue to have the sh*t show that we do now. The reality is that bug bounty hunters are deploying a significant percentage of the total malicious NPM packages each month. reply mcherm 9 hours agorootparent> The reality is that bug bounty hunters are deploying a significant percentage of the total malicious NPM packages each month. I don't actually think that is a bad thing. The TSA screening at airports would be vastly better if TSA maintained a \"red team\" that regularly tried smuggling guns (or water bottles or whatever) into airports. The agents would be more attentive if the number of incidents they dealt with was large enough that they could practice more often. The system could improve if it had actual feedback on how accurate and effective it was. And instead of agents overreacting or underreacting they could tune their responses to an appropriate level. The same applies to supply chain attacks. The REAL ones are rare, dangerous, and performed by experts; having a chance to practice catching them, to assess our detection rates, and to adjust our reactions is healthy. reply dagw 9 hours agorootparentThe TSA screening at airports would be vastly better if TSA maintained a \"red team\" that regularly tried smuggling guns They actually do have this. TSA seem to still suck at their job: https://www.forbes.com/sites/michaelgoldstein/2017/11/09/tsa... https://www.gao.gov/products/gao-19-374 reply LtWorf 2 hours agorootparentYou'd also suck if you knew your job is useless busywork. reply peanut-walrus 9 hours agorootparentprevYeah, it sucks, but that's the way it is. It is super common for bug bounty findings to be ignored or downgraded unless you show actual code exec on their machines or dump some of their creds. reply DigitalNoumena 8 hours agorootparentprevIt may interest you that Guy Podjarny, one of the Snyk founders, now has an AI coding company (https://www.tessl.io/about) that looks like a competitor of yours reply syndicatedjelly 15 hours agorootparentprevnext [3 more] [flagged] benatkin 14 hours agorootparentYeah, I strongly disagree with the way it's characterized here. reply TimTheTinker 14 hours agorootparent> we reached out to them after seeing this and they apologized. How does this make it sound like they made Snyk apologize? reply IAmGraydon 14 hours agorootparentprevnext [19 more] [flagged] not_a_bot_4sho 13 hours agorootparentIt was a thing back in the late 90s. I still do it in casual conversations with friends, less so in professional settings. It's a gen X thing, like using \"lol\" to mean literal laughter reply johnny22 13 hours agorootparentprevit's been a thing at least on irc for at least 20 years. i've been used to it for a long time. reply dovin 14 hours agorootparentprevI like to call it informal case. reply furyofantares 13 hours agorootparentprevWhen I grew up online in the 90s, on IRC, AOL/AIM, ICQ and web forums, it was extremely common. Most of the people I know from then still do it, and I still do it with them and in many other places, although for whatever reason I don't do it here. Although it's 50/50 when on their phones now that phones auto-capitalize by default now. reply urig 12 hours agorootparentprevRules are put in place to be followed, for a reason. Capital letters at the start of the sentence increase readability. People who don't bother with them are being incosiderate towards their readers. reply wahnfrieden 10 hours agorootparentnot at all reply pizza 13 hours agorootparentprevyes but there could be many possible reasons, for instance - it's muuch faster on mobile - you're aiming to convey litheness to potential target audiences who will know to recognize it as intentional litheness - you've gotten used to minimizing the amount of keystrokes necessary for communicating things, to the point it's second nature - you've worked a lot in the past with older nlp systems, where ignoring capitalization was a given for inputs anyhow, and just got used to treating it as syntactic cruft only strictly necessary in more formal settings ;) reply cjbprime 12 hours agorootparentWith the current default mobile keyboards, I'd guess it's slower, not faster. reply stouset 11 hours agorootparentprev> it's muuch faster on mobile This isn’t 1998. Mobile keyboards autocapitalize. You have to go out of your way to avoid capitalization on mobile. reply Piisamirotta 12 hours agorootparentprevI have been thinking of this too. I find it super annoying to read and it looks unprofessional. reply demarq 11 hours agorootparentprevhow does this bother you, what greater meaning does it have? reply Atotalnoob 14 hours agorootparentprevIt’s a techbro thing. Sama does it too reply benatkin 14 hours agorootparentYou're writing in rust-inspired English it seems, omitting the punctuation mark at the end of your second sentence so it gets returned. reply compootr 13 hours agorootparentit's typesafe and efficient reply brookst 13 hours agorootparentpreve. e. cummings, techbro. who knew? reply mmaunder 13 hours agorootparentprevIt’s a low effort flex. As in: you’re unimportant, this is unimportant, and I’m very busy, so I can’t or won’t bother to capitalize. Which is ironic because it’s more effort to not capitalize. reply wahnfrieden 10 hours agorootparentit's many more keypresses, and using modifier keys is generally rsi-prone reply maxbond 10 hours agorootparentWithout commenting on this subthread (I don't have an opinion), you or anyone else with this concern should look into sticky modifiers (modifiers that apply to the next key press without being held). They were a game changer for me personally as far as managing RSI, as I had a bad habit of tilting my wrist to eg type a capital T. reply arkadiyt 15 hours agoparentprev> If that's the case, then there's not much to see here They could have demonstrated the POC without sending data about the installing host, including all your environment variables, upstream. That seems like crossing the line reply nomilk 15 hours agoparentprev> If that's the case, then there's not much to see here. Allowing someone full access to the contents of your environment (i.e. output of env command) is a big deal to most, I suspect. reply LtWorf 2 hours agorootparentIf /proc is mounted you can read all of that. reply NitpickLawyer 12 hours agoparentprevWasn't this supposed to be fixed in NPM? I remember a talk by the researcher behind portswigger (sorry blanking on his name) doing this a while back, with great success (apple,ms,meta, basically all faang were vulnerable at that time). reply tankster 10 hours agoprevAlso interestingly the Snyk cofounder has started a competitor to cursor https://www.tessl.io/ https://techcrunch.com/2024/11/14/tessl-raises-125m-at-at-50... I hope there is no foul play. reply guappa 10 hours agoparentGiven how all my interactions with them have been extremely negative (see my other comment), I think it's rather likely that there is foul play. reply gortok 4 hours agoprevThe only part of the article I disagree with is this line: > But in general, it’s a good idea not to install NPM packages blindly. If you know what to look for, there are definite signals that these packages are dodgy. All of these packages have just two files: package.json and index.js (or main.js). This is one of several flags that you can use to determine if a package is legit or not. This works -- maybe OK for top-level packages. But for transitive dependencies it's nearly impossible to vet every transitive dependency. If you're pulling in a package that has 400 dependencies, how the heck would you even competently check 10% of that surface area? https://gist.github.com/anvaka/8e8fa57c7ee1350e3491#top-1000... reply ziddoap 4 hours agoparent>If you're pulling in a package that has 400 dependencies, how the heck would you even competently check 10% of that surface area? This would be where different security advice would apply: don't pull in a package that has 400 dependencies. reply krainboltgreene 3 hours agorootparentGiven the nature of software development and software developers, especially given American companies decide to value shareholder profits over programmer productivity, this might as well be effectively \"You don't need to get vaccines, simply don't get sick from other people.\" reply wyldberry 1 hour agorootparentThings like this are suppose to be provenance of an organizations security engineering teams. Helping to ensure you don't ship something like this. It's also hard for them too because no one wants to force developers to re-implement already solved functionality. reply krainboltgreene 1 hour agorootparentI also have never met a security engineer that was eager to do that. reply nightpool 2 hours agorootparentprevOut of curiosity, I've always meant to ask, are you related to the famous Geoguesser content creator in any way? It's a pretty distinctive last name. reply krainboltgreene 2 hours agorootparentI believe he might be a distant cousin. I've done some family tree searching myself and haven't found many things, since the Rainbolt side has mostly been scoundrels and vagabonds there aren't many details, but we do have a mountain that we named after ourselves after we stole it from natives. reply chamomeal 3 hours agoparentprevWait how in the world does a React carousel component have over 400 deps… reply jbreckmckye 48 minutes agorootparentDo you mean https://www.npmjs.com/package/carousel-react? By the looks of it, this was published by someone 7 years ago as part of a personal project. Nothing uses it. Going through that list... they all look like personal projects, with no dependents, and a single release by a single person. reply chamomeal 14 minutes agorootparentOk now that I’ve actually looked at the package.json, it seems like this must be a joke or something. It’s got packages for CLI arg parsing, math expression evaluation, hashing, etc. When I’m back on my computer I may look at the source and confirm my suspicion that none of those are required for the carousel functionality lol reply cloverich 2 hours agorootparentprevHistory of \"micro dependencies\" where many flexible utilities are split up into separate packages, such that many npm dependencies are a single function (ie rather than a package exporting ten methods, its ten separate dependencies). Then because there is no standard library, many reinventions of similar but incompatible utilities. etc. reply tristor 2 hours agorootparentprevBecause Javascript is a drug that makes developers stupid. It's almost trite at this point to comment on the obsession that Node has created with developers to reduce functionality to the smallest possible reusable parts, even trivial things, and publish them as packages, then to import and use those dependencies. The idea, in and of itself, is not terrible, but it's been taken to a logical extreme which is very much the definition of terrible. reply jbreckmckye 47 minutes agorootparentNearly all of these look like demo projects. You're making inferences about an entire group of developers based on a meme plus a search over the very 'worst' offenders. reply KuhlMensch 3 hours agorootparentprev/giphy \"first time?\" meme reply Sohcahtoa82 2 hours agorootparentprevDid you think the meme about node_modules having more gravity than a star was just a meme? It's very much based on reality. The npm ecosystem is just absolutely fucked. reply XorNot 3 hours agoparentprevThis is really where SELinux had the right idea overall: preclassifying files with data about their sensitivity, and denying access based on that, does adequately solve this problem (i.e. keeping npm installations away from id_rsa). reply beardedwizard 2 hours agorootparentThe issue with SElinux is usability. A company called intrinsic tried a similar \"allowlist\" approach to javascript based on the assumption that you could never control this sprawl and had to assume every package was malicious. I never saw the technology take off because generating the allowlist was of course error prone. im not sure what has to change in UX to make these approaches more palatable, but if you have to frequently allow 'good' behaviors, my experience is it never takes off. reply __MatrixMan__ 1 hour agorootparentI think we need to to focus on empirical consensus rather than taking as authoritative some file which makes claims about what a particular piece of software will or won't do. So before running any code you'd hash it and ask your peers: \"what do we think this does?\" If it does something surprising, you roll back its effects (or maybe it was in a sandbox in the first place) and you update your peers so that next time they're not surprised. I keep saying \"you\" but this would just be part of calling a function, handled by a tool and only surfaced to the user when they ask or when the surprising thing happens. It could be a useful dataset both for maintainers and for people who want to better understand how to use the thing. reply loaph 1 hour agoparentprev> If you're pulling in a package that has 400 dependencies, how the heck would you even competently check 10% of that surface area? At my place of work we use this great security too called Snyk. Definitely check it out /s reply 3eb7988a1663 15 hours agoprevI need to get serious about doing all development inside a virtual machine. One project per VM. There are just too many insidious ways in which I can ignorantly slip up such that I compromise my security. My only solace is that I am a nobody without secrets or a fortune to steal. IDEs, plugins, development utilities, language libraries, OS packages, etc. So much code that I take on blind faith. reply redserk 15 hours agoparentVagrant’s popularity seems to have died down with Docker containers but it’s by far my favorite way to make dev environments. Several years ago I worked somewhere that prohibited web browsers and development tools on laptops. If you needed to use a browser, you’d have to use one over Citrix. If you needed to code, you’d use a VDI or run the tools in a VM. At the time I thought their approach was clinically insane, but I’m slowly starting to appreciate it. reply arcanemachiner 12 hours agorootparentI still like Vagrant. But I believe it's yet another victim of the Hashicorp license change debacle from a year or two ago. Unlike with Terraform/OpenBao, I know of no community effort effort to keep the open-source version of this project alive. The latest open source version is still available on the Ubuntu repo, but who knows who long it will work until somefor of bit rot occurs. reply pizza234 5 hours agorootparent> I still like Vagrant. But I believe it's yet another victim of the Hashicorp license change debacle from a year or two ago. The license change is irrelevant - from the licensing page: > All non-production uses are permitted. Devs who use Vagrant in a development environment can do it as they used to do it before. > The latest open source version is still available on the Ubuntu repo, but who knows who long it will work until somefor of bit rot occurs. Hashicorp products have always been intended to be downloaded from the website, since they're statically linked binaries (I don't like that they're huge, but matter of factually, they make distribution trivial). reply fancyswimtime 11 hours agorootparentprevmore so a victim of speed reply hresvelgr 8 hours agorootparentprevDevcontainers[1] are the new incarnation of this pattern. We use them at work and they are a dream for onboarding new developers. The only downside is the VSCode lock-in but if that's a concern there's always DevPod[2]. [1] https://containers.dev/ [2] https://devpod.sh/ reply bluehatbrit 6 hours agorootparentIt looks like the team behind it have been moving it towards more of an open standard over the last year. There's now a CLI reference implementation, and the Jetbrains IDE's have an implementation for it. There's also a thread for Zed about a path to implementing it there [0]. Hopefully it'll become a bit more common over 2025. [0] - https://github.com/zed-industries/zed/issues/11473 reply roland35 6 hours agorootparentprevI think vs code is the easiest way to set up dev containers, but once they are created I mostly just shell into them and use neovim! reply pmontra 13 hours agorootparentprevA customer of mine still uses vagrant on a project, for local development. That project started in 2016. We are developing on a mix of Linux, Mac, Windows and it's not as straightforward as it could be. Linux is easier, Windows is messier. A newer project fires up VMs from a Python script that calls an adapter for EC2 (with the boto library) when run on AWs and for VirtualBox (by calling VBoxManage) when running locally. That allows us to simulate EC2 locally: it's a project that has to deal with many long jobs so we start VMs for them and terminate the VMs when the jobs are done. That also runs better on our mix of development systems. WSL2 helped to ease the pains of developing on Windows. We call the native Windows VirtualBox, not the one we could have installed inside WSL2, but we keep most of the code that runs on Linux. reply tacticus 14 hours agorootparentprevThis is the practice in many government sites these days. Except the vm is some old windows version without any tools on it. no shell access. can't actually do anything useful on there at all. VDI systems could work if implemented properly. but that's the last thing a security team actually wants to do. reply dacryn 11 hours agorootparentVDI is actually preferred by our security teams, because they have complete deep packet inspection on literally all traffic going in and out. On our laptops, there are still some flows that avoid the vpn etc.. reply spike021 11 hours agorootparentprevAt my first job almost 10 years ago we had the concept of \"X-in-a-box\" using Vagrant + VMs and I miss that pattern so much ever since (multiple job skips later). None of my jobs since have had any semblance of a better way to set up a local dev environment easily. It was just way easier to encapsulate services or other things in a quickly reproducible state. I digress.. reply flyinghamster 7 hours agorootparentprevI started using Ansible a few years back to set up VMs (or Raspberry Pis) with a consistent environment. Once I wrapped my head around it, I've found it very nice for any situation where I need to treat systems as livestock rather than pets. reply bloopernova 1 hour agorootparentI use Ansible in local only mode to install/configure macOS as a development environment. Works well with Homebrew, and copies all the config files that devs often don't set up. reply buildbot 14 hours agorootparentprevVagrant is still kicking! But yeah not as popular as back in 2014-2016? A hybrid(?) alternative is enroot, which is pretty neat IMO, it converts a docker container into a squashfs file that can be mounted rw or used in an ephemeral way. https://github.com/NVIDIA/enroot reply whitehexagon 12 hours agoparentprevIt's horrible that trust is being eroded so much, and seeing monthly GB updates to my OS doesnt reassure me at all. I like the idea of having a stable isolated VM for each project. Are there standard open-source tools to do this? Specifically I'm transitioning my Go and Zig development environments from an old mac to an M1 with Asahi Linux and getting a bit lost even finding replacements for Truecrypt and Little Snitch. Do these VM tools support encrypted VM's with firewall rules? I saw Vagrant mentioned here and that sounds like it might cover the network isolation, but what else would you suggest? reply pritambaral 11 hours agorootparentI run all my dev environments under LXD. Even the IDE: full graphical Emacs (or Vim) over X11 forwarding over SSH. Host is Wayland, so security concerns with X are handled. WayPipe also works, but is jankier than X, probably because X, unlike Wayland, was designed for network transparency. LXD, unlike Docker, doesn't play fast-and-loose with security. It runs rootless by default, and I don't allow non-root access to the LXD socket on host. Each container is a full userspace, so it's much more convenient to configure and use than Dockerfiles. SSH from a container to a remote works transparently because I forward my SSH Agent. This is secure because my agent confirms each signing request with a GUI popup (on host). reply 3eb7988a1663 10 hours agorootparentCan you point to a write-up somewhere that details this setup? Part of the appeals of VMs is that they were built with security as a primary objective. I probably have to do something stupid to break that isolation. A custom ad hoc configuration makes me a bit nervous that I will unknowingly punch a Docker sized hole through my firewall and have less security than if I ran a stock workflow. reply cheema33 9 hours agorootparentFor me, I don't use LXD, but use Proxmox containers. These are non-root Linux containers by default. Super lightweight compared to a VM. Proxmox makes managing LXC containers a little easier with a UI, compared to managing containers strictly using command line. If you go this route, create a container template that has everything you want in every instance. And then spin out new containers whenever you need one. reply khimaros 6 hours agorootparentyou might be interested in the incus webui reply stevage 10 hours agorootparentprevI always used to do that, using Vagrant. Mostly because it was the only practical way to maintain independent environments for the tools I was using. These days I work in JavaScript and rarely have issues with project environments interfering with each other. I've gotten lazy and don't use VMs anymore. In theory docker type setups could work but they just seem so much effort to learn and setup. reply smatija 10 hours agorootparentSeconding vagrant - especially because it's the only reasonable way I found so far to test linux release on my windows rig (would prefer to dev on linux, but windows-only company is windows-only company). Basically I put a Vagrantfile in src folder, then run docker compose with db, caddy, app server and other services inside it - then I forward ports 80 and 443 from vm and use localhost.whateverdomain.igot with self-signed cert on caddy (since https is just enough different than http that I otherwise get bitten by bugs every so often). When I start a new project I can usually just copy the Vagrantfile with minimal changes. reply mjl- 9 hours agoparentprevi develop on linux, on various projects. i'm mostly concerned with all the tools, build scripts and tests that may read sensitive data, or accidentally destroy data. so i'm limiting access to files when working on a project with linux namespaces, using bubblewrap. i've got a simple per-project dot file that describes the file system binds. while i'm working on a project, new terminals i open are automatically isolated to that project based on that dot file. it has very low (cognitive) overhead and integrates pretty much seamlessly. i suspect many developers have similar scripts. i looked for projects that did this some time ago, but couldn't find it. either because it's too simple to make a project about, or because i don't know how others would describe it. if anyone has pointers... i don't limit network access (though i did experiment with logging all traffic, and automatically setting up a mitm proxy for all traffic; it wasn't convenient enough to use as regular user). there is still a whole kernel attack surface of course. though i'm mostly concerned about files being read/destroyed. reply arkh 11 hours agoparentprevTime to main Qubes OS on your development machine. https://www.qubes-os.org/ reply 3eb7988a1663 10 hours agorootparentI actually did try to install Qubes over the holiday, but I repeatedly encountered installation failures and could not ever login to the system. Someone had posted an identical issue, but they were similarly stymied. I should revisit, but my initial foray tells me I am going to have to withstand quite a few papercuts in order to get the isolation I want. reply sim7c00 9 hours agorootparentnever had issues with qubes like that but i did pick something tested (hw). u can check hardware compat list. it has also some good links to forums for specific hw related tweaks u might need. that being said, runing qubes fully and workin with it is something else... i decided i am uninteresting enough just to use ubuntu these days :p... maybe sometime ill have the patience again. reply dacryn 11 hours agoparentprevI wonder how this is mitigated by my current workflow of running jupyter and vscode from a docker container. I did not start doing this because of security, but just to get something more or less self managed without any possibility to break different projects. I am tired of my team spending too much time on extensions, versions, packages, ... Docker compose files have saved our team many hours, even if it's extremely wasteful to have multiple vscode instances running alongside each other reply technion 15 hours agoparentprevI think a lot of the issues in this particular example is the ease with which api keys, once leaked, are single factor passwords. If you ran a key logger on my machine you would never get into any major site with mfa. You couldn't watch me log on to the azure console with passkey and do much with it. But if you scrape a saved key with publish abilities bad things happen. reply chrismarlow9 14 hours agorootparentWhat's to stop me from installing custom certs and MITM your login session proxying the info. Or an extension to harvest the data after you login. I'm pretty sure if I have root it's game over one way or another. The surface is massive. reply technion 12 hours agorootparentAt that point you've done something much more invasive and detectable than exporting a .env file and you've walked away with a very short lived token. There's always \"something more an attacker can do\", I'll stand by the view that requiring further authentication to perform interactive actions and pushes is worthwhile. reply cedws 13 hours agoparentprevI started doing development under a separate non-admin user on my MacBook. I switch to another user for personal stuff, or the admin user to install stuff with Homebrew. Doesn't protect from zero days but it's better than nothing. reply 3eb7988a1663 10 hours agorootparentI toyed around with this a bit, and it feels like it has significant merit. User separation is about the only security boundary built into Linux from the beginning. I was not totally happy with the workflow I adopted, but it is probably going to be less burdensome than the VM approach. reply cedws 5 hours agorootparentWith Fast User Switching on macOS it's pretty convenient too. The difficulty is remembering to switch user when changing contexts. I tried to set a different wallpaper/icon for each user to make it more obvious which user I'm on, but macOS just resets them all to be the same. reply weinzierl 9 hours agoparentprevI know where you are coming from and I considered this myself again and again. For me and for now it is not something I want to do and not primarily because of the effort. The VM might protect me, but it will not protect the users of the software I am producing. How can I ship a product to the customer and expect them to safely use it without protection when I myself only touch it when in a hazmat suit? No, that is not the environment I want. My current solution is to be super picky with my dependencies. More specifically I hold the opinion that we should neither trust projects nor companies but only people. This is not easy to do, but I do not see a better alternative as for now. reply guappa 10 hours agoparentprevI just stick to using whatever is on my distribution for personal use. For work use I use a work machine and if it gets compromised it's not really my own problem. reply Alifatisk 4 hours agorootparent> For work I use a work machine and if it gets compromised it's not really my own problem. Is that really a good mindset for a organization? reply guappa 4 hours agorootparentI guess so… there seems to be absolutely no consequences to getting hacked, so from a business perspective it makes a lot of sense. It's not up to me to decide what policy to use, and if it was I couldn't just do whatever I wanted, I'd have to justify its cost. And every company does the same… I can decide the policy at my home :) reply pjmlp 9 hours agoparentprevThe security, and overall application stability attack vector, is why I now vouch for processes with OS IPC instead of shared libraries, even if it requires more resources. It doesn't fully sort out the trust issue though, even if everything is sandboxed in some fashion. reply uticus 4 hours agorootparentI know of IPC, but it has never occurred to me to view as an alternative to shared libraries. It's an intriguing viewpoint I'm having trouble wrapping my mind around. Are there battle-tested real-life examples of IPC being used where shared libs could have been used instead? reply pjmlp 4 hours agorootparentVSCode would be one such example. All the stuff using Android intents, out-proc COM extensions in Windows, XPS in macOS, are other relevant set of examples. I assume you are kind of new to the computing world, OS IPC is how we extended applications almost 40 years before shared libraries became common feature across all major operating systems. Naturally with them being around, shared memory in-process was much easier, and less resource intensive. IPC calls require processes, which take more kernel resources, and context switch. Microservices isn't a new concept, rather re-branding. Sun had as marketing quote, \"The network is the computer\", exactly because of how it used to be. reply XorNot 13 hours agoparentprevThe real problem is video performance in VMs. It still just...kind of sucks. Running Cinnamon in a VM is just about impossible to get GL acceleration working properly. nvidia gates it's virtualized GPU offerings behind their enterprise cards, so we're left with ineffective command translation. IMO: I can tolerate just about every other type of VM overhead, but choppy/unresponsive GUIs have a surprisingly bad ergonomic effect (and somehow leak into the performance of everything else). If we could get that fixed, at least amongst Linux-on-Linux virtualization, I think virtualizing everything would be a much more tenable option. reply alias_neo 9 hours agorootparentThere are ways around it. There is a community of people who use Nvidia enterprise cards with vGPU for gaming, performance is excellent, or PCI pass through an entire GPU. If you can't do that because it's for company/corporate purposes then I can sympathise with not wanting to pay Nvidia's prices. reply danieldk 6 hours agorootparentprevBut would it matter much for development? Either SSH into the VM and use vi/emacs or use an IDE/editor with remote support. VS Code even lets you use a container as a development environment (I know, not a VM by default): https://code.visualstudio.com/docs/devcontainers/containers reply dsissitka 5 hours agorootparentI don't know about VS Code's dev containers extension but the SSH extension's README says: > Using Remote-SSH opens a connection between your local machine and the remote. Only use Remote-SSH to connect to secure remote machines that you trust and that are owned by a party whom you trust. A compromised remote could use the VS Code Remote connection to execute code on your local machine. https://marketplace.visualstudio.com/items?itemName=ms-vscod... If you're worried about extensions there's also: > When a user installs an extension, VS Code automatically installs it to the correct location based on its kind. If an extension can run as either kind, VS Code will attempt to choose the optimal one for the situation; https://code.visualstudio.com/api/advanced-topics/remote-ext... reply z3t4 11 hours agorootparentprevYou can get good security without virtualization, for example SeLinux and namespaces in Linux. Jails in BSD and zones in Solaris. We would have many viable and competing solutions if it wasn't for Microsoft monopoly. reply petesergeant 12 hours agoparentprevI wonder how long until this is standard, and PFYs coming into the industry look at our current practices much like people now look at non-encrypted credentials being sent over the network. reply pinoy420 13 hours agoparentprevWhy would you do anything but work related activities on a work machine. If you really want trust for software. Don’t use a computer. reply smokel 10 hours agorootparentIt is good to wind down every now and then during work time. Also, many people here work on multiple projects for different customers. Having a security breach for one affecting the other is not something you'd be happy with. reply 3eb7988a1663 10 hours agorootparentprevI never said anything about personal stuff on a work machine? I want my own hardware to have isolation between my email/banking/etc and side project programming. reply pinoy420 9 hours agorootparentThen have a separate machine if you’re that paranoid. Funny how it doesn’t cause issue for the hundreds of thousands of other people in the world reply guappa 10 hours agoprevsnyk is the same company that instead of rotating oublic keys just… changes them without notice. https://github.com/snyk/cli/pull/5649 They also mark projects as \"abandoned\" if they move to any other forge that isn't github. And they stay abandoned even if new releases appear on npm/pypi :D Their competence isn't as big as their fame, in my opinion. Also one of their sales people insulted me over email, because apparently not being interested in buying their product means you're an incompetent developer who can only write software filled with vulnerabilities. reply azemetre 2 hours agoparentThey also penalize libraries that are \"done,\" and require minimal development. Completely backwards software that corpos only seem to buy because their insurers force them to check off some security list box. reply alp1n3_eth 1 hour agoparentprevThat's extremely unfortunate, especially about the \"abandoned\" labelling. I've been looking to move off GitHub recently as well, it feels like it's got a bit too much control. Codeberg looks interesting, and there are self-hosted ones like Forejo that also look great if you're okay with the maintenance. reply gyoridavid 10 hours agoparentprev\"insulted me over email\" - whoa, that's wild, do you still have the email? would be fun to see it :D reply guappa 10 hours agorootparentSorry, I searched, it seems all my emails from before the last company rename are gone. edit: or microsoft outlook sucks… I tried to sort in reverse my inbox to see what's the oldest email there and \"the request cannot be satisfied\" reply unixhero 9 hours agorootparentOuch, I kind of trusted it. ... more than Gmail and Google reply ceejayoz 7 hours agorootparentprevI get surprisingly many cold emails these days with a passive aggressive “shall we schedule a call, or are you a bad person who doesn’t give a shit about security?” approach. reply matwood 4 hours agorootparentYeah. Or 'make this change to help our processes'. Um, that's not my job. reply bilekas 10 hours agoparentprev> hey also mark projects as \"abandoned\" if they move to any other forge that isn't github. And they stay abandoned even if new releases appear on npm/pypi :D Well theres a sign of a good team.. /s That's actually an interesting take, I haven't heard too much about them except that they do have an ego. reply Ylpertnodi 6 hours agoparentprevI'm sure you can provide the body of the [appropriately redacted] said email? reply guappa 5 hours agorootparentI was also sure until I found out that outlook refuses to search old emails. reply woodruffw 18 hours agoprevWithout more context, this doesn't look great for Snyk either way: either they have an employee using NPM to live test their own services, or they have insufficient controls/processes for performing a legitimate audit of Cursor without using public resources. reply tru3_power 16 hours agoparentWhy not? NPM behaves oddly when there is a public package named the same as one on a private repo, in some cases it’ll fetch the public one instead. I believe it’s called package squatting or something. They might have just been showing that this is possible during an assessment. No harm no foul here imo reply woodruffw 15 hours agorootparent> They might have just been showing that this is possible during an assessment. No harm no foul here imo You're not supposed to leave public artifacts or test on public services during an assessment. It's possible Cursor asked them to do so, but there's no public indication of this either. That's why I qualified my original comment. However, even if they did ask them to, it's typically not appropriate to use a separate unrelated public service (NPM) to perform the demo. Source: I've done a handful of security assessments of public packaging indices. reply guappa 10 hours agorootparentComments here seem to indicate that cursor did NOT ask them to (unless of course someone inside the company did and didn't tell the others) reply compootr 13 hours agorootparentprevif Cursor is secure it shouldn't be a problem for them! (and, according to their comments, it is) reply woodruffw 13 hours agorootparentIt's not about being a problem or not. It's a basic responsibility when doing security research: maintaining an isolated test environment is table stakes. reply mmsc 12 hours agorootparentHow should it have been done differently? How else is the researcher supposed to know if the attack works? \"Hey random company, we have no proof it's going to work but we think maybe your system, which we can't see, is vulnerable! Go waste time and check!\" reply cheema33 9 hours agorootparentCursor team has already stated here that they did not ask Snyk to perform a security audit. I wonder if Snyk's actions are equivalent to me coming to your house late at night and then trying to open any and all doors and windows. In the name of security research. Without an invitation from you. How else am I to validate that your house is secure? reply bostik 12 hours agorootparentprevLocal DNS override, and two registries. One mirroring the relevant public NPM packages as they are, and one \"normal\" internal one. Make the mirror registry resolvable with the same name(s) as the real, public NPM registry. Then test the behaviour. reply mmsc 11 hours agorootparentI think there's an incorrect assumption that the Snyk team has any access to Cursor's systems, or their source code. reply BeefWellington 13 hours agorootparentprev\"No Harm No Foul\" in this case would be a simple demonstrative failure case, not functioning malware. reply fintechie 5 hours agoprevHopefully this makes the Cursor team reconsider security (which doesn't seem very good really). Stopped using it for serious stuff after I noticed their LLMs grabs your whole .env files and sends them to their server... even after you add them to their .cursorignore file. Bizarre stuff. Now imagine a bad actor exploiting this... recipe for disaster. reply miohtama 5 hours agoparentSecurity often means the opposite of scalability and growth, so why should they? The business goal is to make sure Cursor grows large enough that they have economics of scale to be a viable business. If you want secure LLM you can use Mistral, which comes with all the EU limitations, good and bad. reply yunwal 4 hours agorootparentMistral (an LLM company) is not really a substitute for cursor (an IDE). Tabby is probably the closest open-source alternative. https://github.com/TabbyML/tabby reply nikcub 17 hours agoprevLooks like a white hat audit from Snyk testing. Got flagged because oastify.com is a default Burp Collaborator server. They should be running a private npm repo for tests (not difficult to override locally) and also their own collaborator server. reply Cthulhu_ 8 hours agoparentIt's not white hat because they actively extract data; if it was just to prove it worked they could've done a console.log, cause npm install to fail, or not extract a payload. reply that_guy_iain 5 hours agorootparentThe data they extract is nothing sensitive and this way they can see how many hits they get. The more affected the bigger the headline for them. reply __jonas 4 hours agorootparentIn what world is \"all environment variables\" nothing sensitive? reply dannyallan 5 hours agoprevSnyk Research Labs regularly contributes back to the community with testing and research of common software packages. This particular research into Cursor was not intended to be malicious and included Snyk Research Labs and the contact information of the researcher. We were very specifically looking at dependency confusion in some VS Code extensions. The packages would not be installed directly by a developer. Snyk does follow a responsible disclosure policy and while no one picked this package up, had anyone done so, we would have immediately followed up with them. reply luma 4 hours agoparentSpraying your attack into the public with hopes of hitting your target is the polar opposite of responsible. The only \"good\" part of this is that you were caught in the act before anyone else got hit in the crossfire. In response, you suggest that you'll send a letter of apology to the funeral home of anyone that got hit. Compromising their credentials, even if you have \"good intentions\", still puts them into a compromised position and they have to react the same as they would for any other malevolent attacker. This is so close to \"malicious\" that it's hard to perceive a difference. edit: Let's also remind everyone that a Snyk stakeholder is currently attempting to launch a Cursor competitor, so assuming good intentions is even MORE of a stretch. reply yabones 4 hours agoparentprevThis is grey-hat at best. Intent may have been good, but the fact is that this team created and distributed software to access and exfiltrate data without permission which is very illegal. You may want to consult with the legal department before posting about this on a public forum fyi. reply senorrib 4 hours agoparentprevCool. Why phone home the user's environment, then? The vulnerability could very much be confirmed by simply sending a stub instead of live envs. reply etyp 4 hours agoparentprevSeems reasonable enough, but why would it (allegedly) send environment variables back via a POST? Even if it's entirely in good faith, I'd rather some random package not have my `env` output.. reply austinkhale 2 hours agoparentprevUpvoting this since presumably you're actually the CTO at Snyk and people should see your official response, but wow this feels wildly irresponsible. You could have proved the PoC without actually stealing innocent developer credentials. Furthermore, additional caution should have been taken given the conflict of interest with the competitor product to Cursor. Terrible decision making and terrible response. reply pizzalife 2 hours agoparentprevWhat is responsible about sending the environment over in a proof of concept? reply kittikitti 3 hours agoprevNPM packages are the most bloated and unreadable pieces of code I've encountered. The creator of Node apparently hates all software and yet Google gave him the captain's hat and we're left with the absolute crap shoot that is web development. I feel guilty with an additional 1KB of code or 500 bytes of RAM but this is seen as an outsider opinion. I hope big tech rots and this is just a symptom. https://news.ycombinator.com/item?id=3055154 reply zelphirkalt 3 hours agoparentNPM packages VS Wordpress plugins ... I think it is a head to head race there. reply mirkodrummer 15 hours agoprevLooks like NPM is generating jobs for those in the security field. It’s an unfixable mess, I really hope some competition like JSR will put enough pressure on the organization. reply devjab 9 hours agoparentIt's not just NPM, it's the trust in third party libraries in general. Even though it's much rarer, you'll see exploits on platforms like Nuget. You're also going to see them on JSR. You have more security because they are immutable, but you're not protected from downloading a malicious pacakge before it's outed. I think what we're more likely to see is that leglislation like DORA and NSIS increasinly require that you audit third party packages. This enforcing a different way of doing development in critical industries. I also think you're going to see a lot less usage of external packages in the age of LLM's. Because why would you pull an external package to generate something like your OpenAPI specification when any LLM can write a cli script that does it for you in an hour or two of configuring it to your needs? Similarily, you don't need to use LLM's directly to auto-generate \"boring\" parts of your code, you can have them build cli tools which does it. That way you're not relying on outside factors, and while I can almost guarantee that these cli tools will be horrible cowboy code, their output will be what you refine the tools to make. With languages like Go pushing everything you need in their standard packages, you're looking at a world where you can do a lot of things with nothing but the standard library very easily. reply rettichschnidi 16 hours agoprevOT: Has anyone ever gotten (proper) SBOMs for Snyks own tools and services? Asking because they want to sell my employee their solution (which does SBOMs). reply KennyBlanken 15 hours agoparentSnyk is founded by people from the Israeli Army's Unit 8200. I wouldn't install it if you paid me to, because it feels a lot like Unit 8200 pumps out entrepreneurs and funds them so that (like the NSA) they have their foot already in the door. reply alpb 13 hours agorootparentWiz.io (who almost sold to Google for $25bn) also had founders from IDF Unit 8200. Dozens of other companies like Waze, Palo Alto Networks were also the same. reply sgammon 10 hours agorootparentprevIncredibuild is on this list (at least with regard to current leadership) reply woodruffw 14 hours agorootparentprevConspiracies and politics aside, the reasons for the prominence of 8200 are somewhat boring: it's the largest unit in the IDF, in a relatively small country. Teenagers who demonstrate just about any degree of technical savviness get funneled into it for their mandatory service. It's the equivalent of observing that SFBA startups tend to have a lot of Stanford grads at the helm. (I don't have any particular love for Snyk as a product suite. I think most supply chain security products are severely over-hyped.) reply manquer 11 hours agorootparentTalent or skills is essential but alone is not enough. while the size and quality of the talent pool helps it is not sufficient to explain the success rate, considering that there are similar or better quality talent pools which are larger in many countries around the world, but they don't have the success rates Israeli startups and 8200 ones specifically have compared to their home market and talent pool size. It is not some conspiracy either, success as founder has strong network effects and positive feedback loops, right mentorship, access to talent pool, or access to funding and people who can open doors all becomes easier when your network already has some success. Similar reason second time founders have it easier they can tap into their personal version of a network. It is not unusual to Israel/8200, the valley itself benefits from this effect heavily after all. reply woodruffw 2 hours agorootparentRight, it's not about talent. It's the fact that it's an extremely strong network with a flywheel between defense spending and startup tech. The same things that make the US's startup industry indefatigable. reply ignoramous 7 hours agorootparentprev> benefits from this effect \"Benefits\" from whose perspective? For instance, the Brazilians (the State apparatus, specifically) are also benefiting [0], but are their citizens [1]? [0] https://www.jstor.org/stable/48595312 [1] https://idanlandau-com.translate.goog/2016/02/04/technologie... reply manquer 6 hours agorootparentbenefits from the perspective of the startup, i.e. chances of its success or growth. Who in turn benefits from that in terms wealth, power, influence is whole different topic for which i have no expertise, i was only talking about frequency of successes in startup clusters. reply ignoramous 8 hours agorootparentprev> Conspiracies Not when the dissidents put their name to paper. We, veterans of Unit 8200, reserve soldiers both past and present, declare that we refuse to take part in actions against Palestinians and refuse to continue serving as tools in deepening the military control over the Occupied Territories. It is commonly thought that the service in military intelligence is free of moral dilemmas and solely contributes to the reduction of violence and harm to innocent people. However, our military service has taught us that intelligence is an integral part of Israel's military occupation over the territories. The Palestinian population under military rule is completely exposed to espionage and surveillance by Israeli intelligence. While there are severe limitations on the surveillance of Israeli citizens, the Palestinians are not afforded this protection. There's no distinction between Palestinians who are, and are not, involved in violence. Information that is collected and stored harms innocent people. It is used for political persecution and to create divisions within Palestinian society by recruiting collaborators and driving parts of Palestinian society against itself. In many cases, intelligence prevents defendants from receiving a fair trial in military courts, as the evidence against them is not revealed. Intelligence allows for the continued control over millions of people through thorough and intrusive supervision and invasion of most areas of life. This does not allow for people to lead normal lives, and fuels more violence further distancing us from the end of the conflict. https://www.theguardian.com/world/2014/sep/12/israeli-intell... (and that's from 2014) reply woodruffw 5 hours agorootparentI don’t think this conflicts with what I’ve said. I’m not claiming Unit 8200 is moral or absolved; I’m saying only that you will run into a lot of 8200 veterans if you interact with any Israeli startup, since it’s a massive unit. Assuming that those people don’t have opinions of their own is likely incorrect, as this letter demonstrates. reply davedx 11 hours agoparentprevLots of false positives IME reply gunnarmorling 10 hours agoprevIn the Java world, you need to prove ownership of a given namespace (group id), e.g. via a TXT record for that domain. Isn't there a similar concept for NPM? The package is named sn4k-s3c/call-home, how will a victim be tricked into referencing that namespace sn4k-s3c (which I suppose is owned by the attacker, not Cursor)? I feel like I'm missing part of the picture here. reply hennell 9 hours agoparentYou're not really missing anything so much as adding a misguided assumption of competence to NPM. Npm doesn't really do namespaces. There's just no ownership to prove as most packages are published like \"call-home\" with no namespace required. This gives exciting opportunities for you to register cal-home to trap users who miss type, or caII-home to innocuously add to your own or open source projects or whatever. Fun isn't it? In this case the call home package is namespaced, but the real attack is the packages like \"cursor-always-local\" which has no namespace. Which can sometimes (?) take precedence over a private package with the same name. It's not a pretty picture, you were better off missing it really. reply Vaguely2178 1 hour agorootparent> Npm doesn't really do namespaces. Yes it really does. npm has namespaces (called scoped packages) and even explicitly encourages their use for private packages to avoid this sort of attack. From the npm docs: \"A variant of this attack is when a public package is registered with the same name of a private package that an organization is using. We strongly encourage using scoped packages to ensure that a private package isn’t being substituted with one from the public registry.\" [1] > This gives exciting opportunities for you to register cal-home to trap users who miss type, or caII-home to innocuously add to your own or open source projects or whatever. Fun isn't it? npm actively blocks typo-squatting attacks during the publishing process: \"Attackers may attempt to trick others into installing a malicious package by registering a package with a similar name to a popular package, in hopes that people will mistype or otherwise confuse the two. npm is able to detect typosquat attacks and block the publishing of these packages.\" [1] This thread is full of people demonstrating the concept of confirmation bias. [1] https://docs.npmjs.com/threats-and-mitigations reply hu3 11 hours agoprevA colleague of mine vendors npm dependencies to diff code between third party lib changes. Those are also covered in pull request reviews. Helps in cases like this. reply absqueued 9 hours agoparentCould you please explain a little more. I can use such practice in my dev workflow. reply robszumski 32 minutes agorootparentthis is an area that is top of mind for me right now. you don't have to vendor your deps to get a detailed report of what changed, and bonus, how your app calls into it. just wrote about it: https://edgebit.io/blog/code-diff-reachability/ reply hu3 8 hours agorootparentprevSure. They don't include \"node_modules\" directory in their .gitignore file. So any third party code changes end up in git commits and are easily visible and reviweable. So running npm update/upgrade includes the code that changed in the dependencies in the commit. reply MortyWaves 8 hours agorootparentSurely there has to be better ways of “vendoring” (including hosting your own package repository that doesn’t automatically pull new versions) than adding thousands or maybe tens of thousands of files to the git repo? reply compootr 8 hours agorootparentif it's dumb and it works it isn't dumb! another rather simple solution is a git mirror of each package, then point npm to a git url reply xdennis 6 hours agorootparentprevIf my podcast memory serves, that's how Isaac (the NPM guy) said it was intended. You would `npm install` and then `git commit`. That's why npm didn't have a lock file back then. Git was the lock file. reply VPenkov 7 hours agorootparentprevThis is an option but that makes it easier to conceal malicious code within node_modules as an internal threat actor or make super sure there's a culture of actually reviewing those changes. In cases like that it helps to do npm install on the CI and make sure you end up with identical code. Decent trade-off. reply nomilk 15 hours agoprev> All of these packages have just two files: package.json and index.js (or main.js). This is one of several flags that you can use to determine if a package is legit or not. Wouldn't a lot of small packages consist of just these two files, meaning seeing just these two files in a package may raise an eyebrow but hardly be a smoking gun? reply 6mile 10 hours agoparentIt's not a smoking gun. It is just one of a number of signals you look for when identifying potentially malicious packages. Other things you look for are number of collaborators, how long it existed, domains it talks to, and artifacts it pulls in. reply jdthedisciple 27 minutes agoprevSeriously: How do we know there aren't dozens or hundreds of comprimsed npm packages installed on every other server out there at this point? Think xz-utils but even much less sophisticated exploits. I don't see any systematic protection against this? reply supriyo-biswas 14 hours agoprevIs there a link for the \"githax\" tool shown in the blog post, which seems to be quite useful? There's [1] but it's just a banner image. [1] https://www.githax.com/ reply edm0nd 13 hours agoparentThe dev is https://github.com/6mile (same as author of the article) seems to be either a tool that isnt out yet or perhaps not available for free or the public. reply 6mile 11 hours agorootparentGitHax is a labour of love right now and is in heavy development. I'm going to create a small beta testing group soon. Hit me up if you want to be in that group. Contact deets are in my GH profile. reply bugtodiffer 10 hours agoprevWe have read this exact story before, please learn not to leak too much sensitive data with your PoCs reply stuaxo 10 hours agoprev\"It's a good idea not to use npm packages blindly\" Yes, but also impractical. reply lopkeny12ko 16 hours agoprevWhy, after all these years, are we still doing this stupid thing of using a global namespace for packages? If you are a company with an internal package registry just publish all your packages as @companyname/mylib and then no one can squat the name on a public registry. I thought we collectively learned this 4 years ago when dependency confusion attacks were first disclosed. reply 0xbadcafebee 14 hours agoparentThe usual reasons: laziness, ignorance, poor design. Most package managers suck at letting you add 3rd party repos. Most package managers don't have namespaces of any kind. The ones that do have terrible design. Most of them lack a verification system or curation. Most of them have terrible search. None of them seem to have been exposed to hierarchical naming or package inheritance. And a very small number of people understand security in general, many fewer are educated about all the attack classes. But all of that is why they get popular. Lazy, crappy, easy things are more popular than intentional, complex, harder things. Shitty popular tech wins. reply SebFender 5 hours agoprevBehind hundreds of builds Snyk has been a challenging integration that ultimately creates very low value. I recommend using a decent team that goes in for flow weaknesses as these are most responsible for significant findings... reply jijji 14 hours agoprevnpm is rife with this activity, its like wordpress plugins reply mrweasel 11 hours agoparentAs much as I don't like NPM, these issues aren't limited to NPM. It's just that NPM is getting so much attention that we're more likely to find and hear about these issues when when they target NPM. I'm fairly concerned about the state of Python packages. It's not every week, but I frequently stumble upon packages that are not what they appear to be. Sometimes not maliciously, sometimes the author just got overly ambitious and failed to deliver, other times, someone is clearly typo-squatting or attempting to get you to install the wrong thing. reply skirge 9 hours agoprev\"no one can hack us\" and then \"you can't hack us, how dare you\" game, 25 years and more reply cheema33 9 hours agoparent> \"no one can hack us\" Did Cursor made claims to this effect and invited public to hack them? Or are you equating someone saying they \"take security seriously\" to \"it's an open season, please attack our systems.\"? reply skirge 6 hours agorootparentyes it is, like independent product reviews or crash tests of cars. Anyway Kim Jong Un doesn't care. reply justmarc 9 hours agoprevnext [2 more] [flagged] cheema33 9 hours agoparent> Yawn. Wrong forum perhaps? Or wrong story? But you clicked the story. Read it. And then even bothered to comment on it. You are putting a lot of effort into something that does not interest you. reply PoppinFreshDo 14 hours agoprevI'm sure it's all part of some tiktok prank video. reply bbqfog 18 hours agoprevJust a reminder that Snyk was founded by ex-IDF Unit 8200 soldiers. I would not trust them given what we've seen Israel do to supply chains. https://en.wikipedia.org/wiki/Snyk reply kstrauser 17 hours agoparentI don't have a dog in this hunt. I've never worked with Snyk, I've never been a customer, and I don't think I even know anyone who works there. That said, they've built their whole company around being trustworthy and doubt they'd knowingly do anything to risk their entire business. Also, I can hardly imagine someone better positioned to protect against supply chain attacks. Your criticism sounds to me like \"just a reminder that this armed bodyguard service comprises Navy SEALs and Army Rangers\". Uh, great! reply xyzzy123 14 hours agorootparentI'd give good odds it was a mistake by a staff member (or small group) who overstepped and was not part of any formal work. Most companies where I've worked as a security researcher, you get some time as part of your job to hack on random stuff to be able to generate interesting talks / research. This feels like that. This isn't a special cyber spooky practice, most pentesting companies do this to generate IP (rarely, lol), buzz (reasonably often) and keep the staff happy (this is really the main thing). It's rare for management to be fully across the scope of this. reply CuriouslyC 17 hours agorootparentprevMaybe if you change that to \"armed bodyguard services employ ex KGB assassins\" reply nullityrofl 16 hours agorootparentI think you've missed the point: it's Americentric to assume that Navy SEALs and Army Rangers are inherently pure, good and have done nothing evil on behalf of the American government when we largely know that to be untrue. reply kstrauser 15 hours agorootparentThat wasn't my point at all. The point was that often the best people to protect a resource are the ones who know how to attack it. reply manquer 11 hours agorootparentprevI would say it is on similar to criticism of TikTok or Huwaei and China. It has less to do with whether it malicious intent from the start of building an organization for explicit intent of capturing core infra. It has more to do with how the Government of Israel operates and the legal requests they can make of their citizens and/or veterans. Perhaps concern over Israeli products should be probably higher than for China as Israel more well known incidents of exploits as a State actor like with Stuxnet, Pegasus or more recently with pagers etc. China no doubt has their own share of operations but they either have not used them as publicly in a large scale overt operation or been more discreet about it. Point is the concern is valid just as it would be valid for China. reply kstrauser 3 hours agorootparentYou mean like how we found out that China attacked and pwn3d the entire US phone system? That’s not a shining example of discretion. reply bbqfog 14 hours agorootparentprevI have no downside to seeking alternatives. The pager incident ensured that I will always look for non-Israeli tech. reply kstrauser 14 hours agorootparentAnd what does that have to do with Snyk, other than that some of their employees use to work for IDF? I'm a US Navy veteran. Would you also stay away from my employers because they have veterans on staff? Seriously, I get what you're trying to say, but I don't understand the broader point you're trying to make. So Snyk has some ex-IDF employees. Find a high-profile infosec firm that doesn't. They military service they were compelled to has a reputation at being really, really good at infosec. I see no reason why companies shouldn't want to hire them afterward. reply defrost 13 hours agorootparentWithout wanting to take a position here, the GP comment had a specific narrow point. The claim was that Snyk was founded by Unit 8200 members. Not that it had a few Israeli veterens, almost all Israeli's serve in the IDF after all. https://en.wikipedia.org/wiki/Unit_8200 To be fair I have a former Unit 8200 member in my larger extended family who left and has since been vocal in opposition to Netanyahu so membership in an elite Cyber Unit alone doesn't define a person. That aside, most Governments would keep an eye on a company started by, say, former NSA employees and watch for covert activity under any overt actions. reply dekelpilli 6 hours agorootparentIt would correlate strongly that 8200 alumni end up being educated and working in tech, and likely living in Tel Aviv. This is a group of people who, by and large, are not big fans of the current government. reply dekelpilli 13 hours agorootparentprevBased on the pager incident, I'd think you should avoid companies that don't have a publicly-known link to Israel. It's not like Hezbollah thought they were buying pagers from 8200 alumni. reply PoppinFreshDo 14 hours agorootparentprevWhat pager incident? reply mhitza 14 hours agorootparenthttps://en.m.wikipedia.org/wiki/2024_Lebanon_electronic_devi... reply PoppinFreshDo 10 hours agorootparentWell, if the mossad put \"made in israel\" on those devices I doubt they would have worked. reply defrost 14 hours agorootparentprevThe recent one in which Israeli techs compromised pager supply chains. It was very widely reported across the globe. reply myth_drannon 16 hours agorootparentprevnext [27 more] [flagged] PessimalDecimal 16 hours agorootparentThis is a tiresome motte-and-bailey argument. You are trying to conflate the OP comment with something it's not (base antisemitism). Just like companies founded by say former operatives of the CIA, NSA, MI6, etc. would (and maybe should?) be viewed with skepticism, so too are companies founded by former members of Unit 8200. Mentioning that Israel's military (like many others) has engaged in some less than ethical behavior is not equivalent to antisemitism. Trying to pretend otherwise is ridiculous. reply lolinder 16 hours agorootparentIsrael has mandatory military service. If anyone who has ever served in the IDF is tarnished and has that part of their life periodically dragged out as evidence that they may be untrustworthy, you're saying that the entire Jewish population of the state of Israel needs to have a giant asterisk attached to them reminding everyone that they were in the IDF. That may not be strictly antisemitic—maybe you're totally fine with Jews as long as they were raised anywhere else—but it's still not a healthy way to treat people. reply joseppudev 15 hours agorootparentI don't understand the purpose of creating ambiguity by confusing mandatory military service and intelligence corp that operates under secrecy. Original post getting flagged is not a great sight either. reply lolinder 15 hours agorootparentIDF Unit 8200 consists of thousands of conscripts serving their mandatory military service. If I were in Israel subject to conscription, I would absolutely have attempted to position myself into that unit for my mandatory service, as would most here. Beats the infantry. What exactly am I confusing by pointing that out? Were you under the impression that this unit was something like the NSA, staffed with people who chose to spy on people as a career? Because it's not. It's staffed by kids who are very good with computers and who—when given a choice between covert intelligence and a branch that actively shoots guns at people—chose the intelligence arm. Which would you have chosen? reply PessimalDecimal 15 hours agorootparenthttps://www.timesofisrael.com/hezbollah-pager-explosions-put... Just months ago, some of those \"kids who are very good with computers\" caused compromised pagers to explode, with no knowledge of who would be near them. Civilians, including children, died as a result. It is right to think people who are \"good with computers\" in this way might not have the best intentions in their other applications of computers. reply lolinder 15 hours agorootparentThe other alternative that those kids were given was to shoot guns or missiles. Are you really comfortable blaming them for the rest of their lives for choosing the option that likely gave them the smallest chance of killing people? Any Israeli citizen in that age bracket today is going to be running a real risk of killing people. They don't have a choice (dodging the draft doesn't count as a choice). If you're going to hold that over for them for the rest of their lives I don't know how that's distinct from racism (or countryism if you prefer). reply PessimalDecimal 15 hours agorootparent> Are you really comfortable blaming them for the rest of their lives for choosing the option that likely gave them the smallest chance of killing people? Yes. The \"just following orders\" excuse has been tried in the past. People didn't buy it then and we won't buy it now. https://www.nbcnews.com/news/world/israel-soldiers-arrest-ab... If the IDF wants to name the specific individuals from Unit 8200 who were involved in maiming or killing civilians including children by blowing up electronics in their faces, that might change things. Then it'd be a lot easier for people to avoid having concerns about that entire unit. Not naming them seems a lot like tacit support by the IDF for the actions of those in Unit 8200 who killed those children. Otherwise, people very well may have concerns about that entire unit. That's not \"racism.\" reply lolinder 14 hours agorootparent(I deleted a comment that didn't seem relevant any more now that you added a bunch.) So it's okay to blame vets of Unit 8200 for its actions 10 years after they founded Snyk (I have no idea how long after they left the unit) on the grounds that the intelligence arm of the IDF doesn't name names? So just in case and in the face of all the facts of the timelines, we should make sure to drag out these people's former mandatory service and remind everyone they served alongside bad guys 10+ years ago? I'm not okay with blaming soldiers for following orders. When it's that or getting shot by your own side, there isn't a real choice. But I can't even begin to understand the mindset that would blame soldiers for the orders that other, unrelated soldiers followed more than 10 years later. That's some next-level hatred. reply mardifoufs 10 hours agorootparentYes, because it's an institutional problem. I'm sure you have no issues using products developed by say, ex FSB agents just because it's been 10 years? reply lolinder 5 hours agorootparentThe FSB is no comparison because it's more equivalent to the NSA—it was a career path, not a place to serve out mandatory military service. FSB agents worked there for decades and chose that instead of any number of other things they could have done. Unit 8200 conscripts worked there for at most 2 years 8 months and chose it instead of a different, more gun-blazing branch of the military. Mandatory military service completely changes the profile of the vets in a way that makes all these comparisons totally irrational. They're founded in fear and hatred for Israelis, not any reasonable similarity. reply mardifoufs 4 hours agorootparentFear of Israelis, sure. But hatred? Come on. Israel has done a lot in the past year, and is being accused of genocide. The fact that is used a conscript army makes it worse, not better. Also, okay then let's switch it up to the Russian army. Would you use a product with known ties to some electronic warfare russian army unit. Or rather, would you consider any doubts or hesitations over using said product to be \"russophobic\"? reply lolinder 57 minutes agorootparent> The fact that is used a conscript army makes it worse, not better. I'm not defending the state, I'm defending the individuals who were conscripted. The entire point of this subthread is that it's heinous to confuse the two. > Would you use a product with known ties to some electronic warfare russian army unit. Or rather, would you consider any doubts or hesitations over using said product to be \"russophobic\"? If I suddenly learned that some founding members of the JetBrains team had previously been conscripted into the Russian army and had served in a cyberwarfare unit, that would change absolutely nothing for me. And yes, I do consider the backlash against JetBrains in the aftermath of the invasion of Ukraine to have been highly rusophobic. reply danenania 14 hours agorootparentprevWhy doesn’t refusing the draft count as a choice? reply lolinder 14 hours agorootparentBecause it means a serious risk of the end of your life as you know it. I'm not willing to hold someone else to a standard that I know that I couldn't live up to. If you truly believe that you'd risk your government's wrath instead of just picking the least dangerous and least likely to kill people branch of your military, then feel free to throw stones. For myself, my plan if the draft were reinstated in the US while I was still of that age was to find out how to join a cyberwarfare division, which would have led me straight to Unit 8200 if I were Israeli. reply KennyBlanken 15 hours agorootparentprevThose \"kids who are very good with computers\" designed a black-box AI that has been designating people terrorists which the military then uses to bomb not just them but their entire family. https://www.npr.org/2023/12/14/1218643254/israel-is-using-an... reply lolinder 15 hours agorootparentAnd their peers in the other branches are killing civilians in other ways. Your point? The only way to hold this against the individuals rationally, especially for those on this forum who would absolutely have chosen Unit 8200 as the least bad option given conscription, is to blame every citizen of the state of Israel and hold them all in distrust for having ever been in any branch of the IDF. I'm personally not okay with that level of sweeping blame and distrust. Are you? reply KennyBlanken 15 hours agorootparent> is to blame every citizen of the state of Israel nobody has said or even implied this > hold them all in distrust for having ever been in any branch of the IDF nobody has said or even implied this > that level of sweeping blame and distrust There has not been any such thing in this discussion. We're done here. reply lolinder 15 hours agorootparentYes, it was done by OP, the comment that was rightly flagged and then later resurrected: > Just a reminder that Snyk was founded by ex-IDF Unit 8200 soldiers. I would not trust them given what we've seen Israel do to supply chains. Given that Unit 8200 is staffed by conscripts, how is this anything other than attempting to ensure that any person who ever came of age in Israel has that held against them for the rest of their careers? Members of Unit 8200 weren't given a choice between that and the private sector—they were given a choice between that and shooting a gun, which for a technically inclined new-adult isn't much of a choice at all. And am I seriously supposed to believe that OP would argue that choosing to be a grunt who shoots a gun at people would be the morally purer choice that would make someone more trustworthy? reply joseppudev 15 hours agorootparentprevSize seems to be classified. Their officers seem to be classified as well. I understand how getting into the unit might be very normal. But doubt here is the healthy thing. Especially as a goyim. reply RHSeeger 16 hours agorootparentprevThey just recently snuck bombs into a supply chain and then remotely detonated them in positions where the caused civilian injuries. I would assume the comment has nothing to do with religion/race, and everything to do with the actions taken. Even for someone that is a supporter of that government, it's hard to deny they've taken some actions that are unsupportable. reply lolinder 16 hours agorootparentWho is \"they\"? Are we talking about Snyk? IDF Unit 8200? The IDF as a whole? The state of Israel? Jews in general? The reason why OP's comment feels like a racist dog whistle is because it's an enormous and dangerous generalization that seems to encompass an entire country. Israel has mandatory military service—if everyone who's ever served in the IDF is untrustworthy because they served in the IDF then you're by definition excluding nearly every Israeli citizen from trust. I guess that's not strictly antisemitism—maybe you're happy to trust Jews that don't live in Israel—but it's definitely an unsavory position to take. reply KennyBlanken 15 hours agorootparentGodwin's got an itch he can't scratch and doesn't know why.... \"Encompassing the entire country\" would be anti-zionist, not antisemitic. There is a huge difference, and that does not change because the majority of people in that country are a particular religion, just like it's not \"Anti-Protestant\" if someone attacks Great Britain policies, or \"Anti-Hindu\" if someone criticizes India. There is a difference, to the extent that there are plenty of jews who are anti-zionist. Would you like to accuse them of being antisemitic because \"nearly every Israeli citizen is Jewish\"? Also, it's your construct that criticizing the policies and actions of a country's military and government is \"anti\" that county... reply lolinder 15 hours agorootparent> Also, it's your construct that criticizing the policies and actions of a country's military and government is \"anti\" that county... No, it's not—we're in a subthread where the OP said \"Just a reminder that Snyk was founded by ex-IDF Unit 8200 soldiers. I would not trust them given what we've seen Israel do to supply chains.\" They took the country's current policy and made it personal against specific IDF vets. That's what I'm standing against. For the rest, I specifically said that it may not be antisemitic given that it's country-specific, so I'm not sure what you were getting at. I'm still not okay with blanket blaming an entire country's citizenry for its government actions. I wasn't okay with that when it came to Russia and Ukraine, I don't know why I should treat this differently now. reply Der_Einzige 15 hours agorootparentprevIt's not just the IDF, you have a CHOICE to join the spymaster side of it, vs being a regular grunt. That unit is part of Aman, the military version of Mossad. reply lolinder 15 hours agorootparentAnd why would choosing to be a grunt be more morally pure? I'm a techie, if I were forced into conscription I would absolutely choose an option that let me use computers over one that forced me to shoot a gun. There's no way on Earth I can hold it against a bunch of kids who were forced to make that choice that they chose the intelligence arm. And frankly, I have a hard time seeing how someone on this forum could hold that against them in good faith. Nearly everyone here would make the same call given that choice. If you think you wouldn't have, you're probably deluding yourself. reply myth_drannon 16 hours agorootparentprevHow the hell that is connected to a private software company? Nvidia, Google, Microsoft, Intel is full of ex-8200. reply weatherlite 9 hours agoparentprevSo every Israeli is now a Mossad agent and every customer is an enemy of Israel like Hezbollah? You won't buy from Snyk because you want to boycott Israel, just own up to it it's a popular position to take. reply bbqfog 4 hours agorootparentI’d put Unit 8200 and Mossad in the same basket. I think I made it clear I’m boycotting Israeli products, I’m not hiding that. reply Cthulhu_ 8 hours agoparentprevAs the pager / radio terrorist attack showed, it's the Mossad involvement you don't know about that you should be worried about. Same with the CIA, they were behind \"secure\" radio communication in Europe for decades (https://en.wikipedia.org/wiki/Crypto_AG) and nobody had any idea. reply krembo 10 hours agoparentprevThat's absurd. If that's your claim, do you know how many of your daily tools and hardware you should also drop? reply bbqfog 4 hours agorootparentI’m dropping as many as I can as is my prerogative as a consumer. reply lolinder 14 hours agoparentprevJust a reminder that Unit 8200 is staffed mostly by conscripts who are serving out their mandatory military service and chose to accept an invitation to serve in the cyberwarfare arm of the IDF instead of choosing to shoot guns. In other words, it's staffed by Israeli kids who made the choice most of us would have made under the circumstances. It seems a bit unfair to hold that against them more than 10 years later, no? reply lmm 11 hours agorootparent> In other words, it's staffed by Israeli kids who made the choice most of us would have made under the circumstances. It seems a bit unfair to hold that against them more than 10 years later, no? You could say the same about the guy in a call center in India trying to pull a tech support scam on you over the phone. Yes, he's probably making the best choice he can for his own livelihood, probably the same thing you would do in his position. No, that doesn't mean you should trust him. Just as you have to treat all Chinese companies as under control of the PRC government and all Australian companies as compromised by their security services, you have to treat all Israeli citizens as under the control of the Israeli military. Any adult can be conscripted and they have a history of disguising military operations as civilian ones. Someone might tell you they left the Israeli military 10 years ago and they're probably telling the truth, but if you make a habit of believing that statement you're going to get burned. reply lolinder 5 hours agorootparent> You could say the same about the guy in a call center in India trying to pull a tech support scam on you over the phone. Yes, he's probably making the best choice he can for his own livelihood, probably the same thing you would do in his position. No, that doesn't mean you should trust him. No, you can't, because the scammer in the call center is choosing that over thousands of other options. Are they choosing to maximize their pay? Maybe. But for every scammer there are thousands of Indians who show a different option. Choosing to dodge or resist the draft is totally different—very few people do it, and those who do get prison terms. If you sincerely believe that you'd have chosen to go to prison rather than be drafted, more power to you, but I and most others would aim to minimize the likelihood of ourselves dying and minimize the number of people I'd have to kill. For me that would have meant signing up for cyberwarfare, which in Israel would have meant Unit 8200. The rest of your comment is totally irrational fear-based speculation. Anti-Israel sentiment may not be antisemitic, but it sure shares the same tendency towards irrational fear and aggression. reply lmm 4 hours agorootparent> the scammer in the call center is choosing that over thousands of other options. No, they're the people who don't have other options (because they lack the skills and/or qualifications and/or are discriminated against). It's not malice, it's just desperation to get money to live on (or, often, to provide for people who depend on them). But of course the end result is the same. > The rest of your comment is totally irrational fear-based speculation. Entirely rational given the historical pattern of behaviour shown by the Israeli military, and the fact that they have no reason to change (quite the opposite). reply weatherlite 5 hours agorootparentprev> Just as you have to treat all Chinese companies as under control of the PRC government and all Australian companies as compromised by their security services, you have to treat all Israeli citizens as under the control of the Israeli military Got it , and are now all American companies suspect because they are managed behind the scenes by Musk and Trump? reply lmm 4 hours agorootparentAll American companies are suspect given the National Security Letter system yes. (Also South Korea and Kazakhstan, and obviously also any country where the \"rule of law\" is low enough that governments can do as they wish without formal legal powers) reply bbqfog 4 hours agorootparentprevI feel the same way about companies with CIA founders. reply bbqfog 4 hours agorootparentprevI would under no circumstance join the IDF or even live in Israel. They’re not “kids”, they are military personnel. reply arccy 4 hours agorootparentkey word: \"conscript\" if you're born there, you have little choice in the matter. reply bbqfog 4 hours agorootparentI've never met an Israeli who wasn't a dual citizen. It's a choice to stay in Israel and fight in the IDF. In fact, the Snyk founder lives in London now: https://uk.linkedin.com/in/guypo reply lolinder 1 hour agorootparent> I've never met an Israeli who wasn't a dual citizen. Given that unless you are in Israel you're most likely to be meeting Israeli expats or at the very least people who travel, that's hardly surprising and not great evidence for anything. > In fact, the Snyk founder lives in London now So you're acknowledging that you're going to hold their country of origin against them even after they've moved. Got it. reply bbqfog 48 minutes agorootparentI don’t understand your complaint. People are free to vocally denounce Zionism. These founders have not done that. Quite the opposite, Snyk has offices in Israel and has been vocal about their ties to the IDF. It’s absolutely within my agency to not use their products. Again, there’s zero downside to do that. reply lolinder 24 minutes agorootparentCorrect, you're welcome to do that, and I'm welcome to denounce you for advocating boycotting a product because of the country of origin of its founders. People can't help where they're born, and you're wrong to hold that against them. You're welcome to work through that cognitive dissonance however you like, but in the meantime I will continue to advocate for treating individuals as individuals. reply bbqfog 20 minutes agorootparentNo one is entitled to my business. I have no cognitive dissonance, my business interests are aligned with my moral interests in this case. I don’t use Israeli tech whenever possible. You “denouncing” people who make a rational calculation isn’t really helping to market the firms you are supporting. reply lolinder 0 minutes agorootparentI'm not supporting firms, I'm supporting the right of individuals to be seen as individuals. That said, this obviously isn't going anywhere, so have a nice day. yard2010 13 hours agoparentprevDon't hate the player hate the game ;) reply sneak 13 hours agoprevSide note: Snyk (founded 2015, computer and network security) has nothing to do with @sneak (hacking since 1998, computer and network security). I was dismayed to learn about their choice of brand, and think it might cause confusion. :( reply vips7L 12 hours agoparentI don’t even read those the same. To me snyk is read as snick and not sneak. reply xyst 16 hours agoprevYou either die as a white hat or live long enough to see yourself become a black hat. reply nathabonfim59 16 hours agoprevThings like this could _synk_ their reputation... reply guappa 10 hours agoparentThey're terrible already. If you invest enough in marketing nothing matters. reply dalton_zk 15 hours agoprev [–] Literally a test in production. The dev commit their work go to home thinking \"not will happen\" reply Sophira 13 hours agoparent [–] If it was really a test, then why would it be sending environment variables via HTTP POST? There are many better ways to do this if you're legitimately deploying code remotely. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Snyk security researcher released malicious NPM packages targeting Cursor.com, an AI coding company, to collect system data and send it to an attacker-controlled service.",
      "The packages, identified as \"cursor-retrieval,\" \"cursor-always-local,\" and \"cursor-shadow-workspace,\" were flagged by the OpenSSF package analysis scanner, resulting in advisories MAL-2025-27, MAL-2025-28, and MAL-2025-29.",
      "This incident highlights the importance of scrutinizing NPM packages before installation to avoid potential security threats."
    ],
    "commentSummary": [
      "A Snyk security researcher released malicious NPM (Node Package Manager) packages aimed at cursor.com, highlighting dependency confusion vulnerabilities. - The incident has sparked a debate on the ethics of security research, particularly regarding the public exposure of environment variables. - Cursor.com clarified they did not authorize the action, and Snyk has since apologized, underscoring the challenges in balancing offensive security research with ethical standards."
    ],
    "points": 540,
    "commentCount": 270,
    "retryCount": 0,
    "time": 1736807907
  },
  {
    "id": 42696081,
    "title": "I Switched to Firefox and Never Looked Back",
    "originLink": "https://www.howtogeek.com/why-i-switched-to-firefox-and-never-looked-back/",
    "originBody": "Why I Switched to Firefox and Never Looked Back By Faisal Rasool Published 2 days ago Follow Like Thread 20 Link copied to clipboard Firefox RELATED Chrome Is Top Dog, but Firefox Is Still My Favorite Browser Spectrum Just Raised Its Prices Again Why You Shouldn't Sign In With Google or Facebook Sign In To Your How-To Geek Account Lucas Gouveia/How-To Geek QUICK LINKS Everything That Chrome Can Do and More Superior Tab Management Built-in Pocket So You Never Lose a Link Keep Your Real Email Safe Built-in Screenshot Tool Handy ChatGPT Button in the Right-Click Menu Other Thoughtful Touches My work PC is an old potato, and Chrome makes its fans cry whenever I open a lot of tabs. I always thought it was just my aging computer’s fault, until I switched to Firefox and found out it was Chrome all along. Everything That Chrome Can Do and More For as long as I can remember, Chrome has been my go-to. All my passwords, bookmarks, and extensions are always available wherever I log into my Google account. I only use the browser on my PC, which is why I’ve never felt the need to upgrade it. At least until recently, when it started to struggle when I installed a couple of new Chrome extensions. I figured it’s finally time to add more RAM to this machine or say farewell to it entirely. For the time being, I switched to Firefox. I made a new account for it and linked it to the sync chain on the PC and my phone. To my surprise, my old timer PC runs it just fine, even with a ton of tabs open. No more angry fan noises. Lucas Gouveia / How-To Geek And even more surprisingly, Firefox does everything Chrome does. The sync works perfectly across devices. You get a huge selection of browser add-ons, and you can customize a lot of the interface. It even has many neat features that Chrome doesn’t. The one feature it doesn’t have is the ability to turn regular web pages into web apps that you can launch from the desktop or taskbar. That’s something I wish the devs would add, but except for this nitpick, I don’t think I’ll be switching back to Chrome. Let me try to convince you why you should try Firefox too. Superior Tab Management Other than the search tabs feature, managing tabs in Chrome hasn’t changed in almost two decades (I’m not counting “Tab Groups” because they’re messy and confusing). A lot of people keep countless tabs open and all Chrome gives you is a cramped-up bar filled with tiny buttons that hide the text. Good luck finding a tab without hovering over each one. Firefox has similar tab bars and buttons, but it has something Chrome doesn’t: Firefox View. Firefox View is a window where you can see all your open tabs in one place. It’s conveniently stashed in a corner and opens with a single click. You can sort the open tabs by recent activity or just by tab order. You can also search for open tabs. You can cycle through recently closed tabs, the entire search history, and even the tabs you’ve got open on other devices—all easily accessible, searchable, and sortable. There’s also a recent browsing tab where all the open tabs, recent tabs, and tabs from other devices are pooled together. If you’re someone who keeps a lot of tabs open and wastes too much time rummaging through them, trust me, you’ll love Firefox View. Built-in Pocket So You Never Lose a Link You know when you don’t want to lose a link, but it’s also not important enough to bookmark? Firefox has a button for that. It’s called Pocket and it keeps all your links safe in a tidy little collection. Even more importantly, it does so with a single click. Just click the tiny Pocket icon next to the address bar once, and it’ll be added to your saved collection. The collection syncs directly with your Firefox profile, so you can access it anywhere. To view your saves, you can open the Pocket app and find all your saved URLs in a beautiful layout. You can organize, tag, and archive the collections too. Keep Your Real Email Safe Firefox Relay is an in-built privacy feature for protecting your real email addresses. When you’re signing up for a website, instead of giving out your real email address, you can share any of the five randomly generated Relay emails that Firefox provides. Any emails sent to these aliases will be forwarded to your real email address. That way, the real email addresses stay hidden, but you still get your mail sent to them. There is also a handy Firefox Relay extension that autofills these burners when you’re filling out forms with email addresses. Built-in Screenshot Tool Firefox makes it super convenient to take screenshots. You don’t need to install any clunky browser extensions. Just right click anywhere, and click “Take Screenshot.” You can choose a full-page view or select an area to capture. It also detects web page elements, so you can capture perfect rectangular or square screenshots. I know Chrome has a screenshot tool hidden in the developer options, but it’s not user-friendly at all. Handy ChatGPT Button in the Right-Click Menu If you use ChatGPT or other AI bots like it often, you’ll appreciate how Firefox handles them. In Firefox, you can quickly send ChatGPT a prompt with a single click. Just right-click anywhere on any webpage (or select a chunk of text) and ask ChatGPT to “Summarize,” “Explain this,” or “Quiz me.” It’ll open an AI Chatbot panel on the side where you can ask follow-ups or tweak the original prompt. If you don't find it on your Firefox, open Settings and look for the \"AI Chatbot\" feature in your Firebox Labs settings. Other Thoughtful Touches I also found some neat little features that Chrome doesn't have natively. Picture-In-Picture for Any Video On Firefox, you can pop out any video into its own little window. That way, you can watch multiple videos side by side, or work on other tabs or apps while the video plays in the corner. You can use this Picture in Picture feature by clicking the tiny pop-out icon that shows up when you play a video. Very handy. Firefox Omnibar Is Far More Useful Than Chrome’s You can only search with the default engine on Chrome’s address bar. Firefox lets you pick how you want to run a search each time. Simply click the small search engine icons to quickly search with Wikipedia, Bing, or DuckDuckGo. Network Settings to Configure Browser Proxies Most people will probably not need this feature, but it’s nice to have. If your ISP is blocking a website for some reason, you can configure a proxy in the network settings to bypass those restrictions. Smooth Scroll Firefox has a buttery smooth scrolling animation that I enjoy. This one’s an aesthetic preference, so you might prefer Chrome’s version. Mutes Auto-Playing Videos Some websites autoplay videos, full volume, which I’m sure everybody hates. Firefox automatically mutes playback for videos like that. Using Firefox for just a week convinced me to change the default browser on my phone and PC, and I don’t intend to change back any time soon. Why don't you give it a try? Web Firefox Web Browsers Follow Like Share Readers like you help support How-To Geek. When you make a purchase using links on our site, we may earn an affiliate commission. Read More. THREAD 20 Sign In To Your How-To Geek Account We want to hear from you! Share your opinions in the thread below and remember to keep it respectful. Reply / Post Images Sort by: Popular Oldest Newest MEGA_ME Plus when you use Firefox you are taking away from the Google monopoly. Firefox isn't a chromium browser. I use Firefox and it is amazing! 2025-01-12 21:49:06 5 Eric I also switched to Firefox from Chrome. You pointed out some handy features I had not found yet. Thank you 2025-01-12 22:04:08 3 Johnny I've been using FF for >19 years, I had no idea there was the AI Chatbot thing until I read this ! (It seems it is turned OFF by default). I didn't know about the safe email relay either ! Let's not forget that Chrome has nerfed ad blocking by using Manifest v3, whereas Firefox fully supports v2 and has full ad blocking capabilities. 2025-01-13 02:08:27 3 David Firefox supports progressive web apps with an extension. I use it all the time. 2025-01-13 03:20:45 2 2 HTGMember Which one? 2025-01-13 04:15:27 2 ericnsmith Me too. I'm using Progressive Web Apps for Firefox. 2025-01-14 12:48:19 Rob The best feature of Firefox is when Chrome implements new manifest UBlock Origin will keep working in Firefox. I predict a ridiculous number of new Firefox users that day... 2025-01-13 08:37:07 1 Kefah I couldn't agree more. I have very similar experience. Firefox is by far my favorite and default goto option. 2025-01-13 01:21:48 1 Mike I switch between Vivaldi and Firefox. I prefer the layout of Vivaldi, but I've been using Firefox for many years. And Netscape Navigator before that. 2025-01-12 22:59:24 1 Ashish I don't know if anyone's gonna like it. But my laptop is also old. Edge seems to be working fine for me than Chrome. It also has some additional features. Will also think about Firefox now 2025-01-13 10:29:53 Pat Some site doesn't work, some plugin doesn't work. I have to go back with a chromium browser. I wish switching is that easy 2025-01-13 23:28:20 Charles Mozilla dex. Support is abysmal. Unusable. I need a more robust mobile browder 2025-01-13 17:52:11 Palanivelu Firefox is ok, but I prefer Opera because of its \"Workspaces\" & sidebar customizable sidebar features And I use Brave browser which has powerful built-in ad blocker. 2025-01-13 01:57:02 Ed Been using FF for over fifteen years now , don't think I would ever use any other browser 2025-01-14 05:05:08 TheDragon What about chrome built in password autofill...will that be available if switching to FF?...if not... Suggestions? 2025-01-13 10:33:42 Zen I've been using Duck Duck Go and I Love it. It's what the Tor browser uses, that says alot. If you value your privacy then get it and be free and safe. ;-) 2025-01-13 14:18:17 Ben I really like using an extension called simple tab groups. Since I'm a college student I have one for personal and then one group for each class when you change groups you only see the tabs in that specific group. It even integrates with firefox's containers feature. The containers feature acts similarly to having multiple users registered in Chrome each container can have different account logins saved for the same websites. So I can tell any tab that I use for school to only open tabs in the school container so the same link on my homepage that brings me to Gmail can open My personal email in my personal tab group, then if I'm in one of my classes tab groups it will open my school email. I also use another extension called containerize to force certain websites mostly banking websites to open in their own separate container so that they are a bit more separated from the rest of my browsing 2025-01-13 09:38:24 Cathy I gave used Firefox forever (I worked at a university and they prefered Firefox even bacķ then). I tried Chrome for about 2 days and went back to Forefox. I appreciate this article because there are some features in Firefox that even I was unaware of! 2025-01-13 09:44:10 PanYan I tried switchng from a Vivaldi and unfortunately Firefox is noticably slower and a lot more unstable. Some webpages which worked totally fine in Vivaldi, caused my Firefox to freeze and not respond. So no, thank you... At least Thunderbird is more reliable. 2025-01-13 08:42:52 Raymond Yes I agree, Firefox is just very good, I have just changed my old laptop to run Linux Mint and started to use Firefox all the time, I do perfere it to chrome ... 2025-01-13 03:23:17 Terms Privacy Feedback RECOMMENDED Microsoft Office vs. Google Docs, Sheets, Slides: Which Is Best? Microsoft Office Which office suite is for you? 15 Aug 27, 2024 I Won't Use a VPN Without These 6 Features VPNs These are the VPN features I consider non-negotiable. 12 Aug 28, 2024 I Paid for Google's Drive Storage. Here's Why I Don't Regret It Google Drive The convenience is worth 2 dollars a month. 12 Jun 29, 2024 Don’t Share That Google Photos Memory Yet—Make These 4 Edits First Google Photos Supercharge your memories 4 days ago What Happens to Old Websites? Internet Does a website ever \"die,\" and if it does, where does it go? 4 2 days ago Amazon is Killing Its Try-Before-You-Buy Program Web Good luck trying to fit your shoes with AI. 23 hours ago DESKTOP MOBILE How I Use the Microsoft To Do App to Maximize My Productivity 3 hours ago GPD's New Gaming Handheld is Not Just Another Steam Deck 4 hours ago MSI’s New Gaming PC Has a Touchscreen Case, and I’m Slightly Obsessed 22 hours ago See More TRENDING NOW Why the Witcher 4 Trailer Being \"Pre-rendered\" on an RTX 5090 Means Nothing What Is Widevine and Why Does It Matter for Mobile Streaming? Over a Decade of iPads: How Apple's Tablet Became My Most-Used Computer",
    "commentLink": "https://news.ycombinator.com/item?id=42696081",
    "commentBody": "I Switched to Firefox and Never Looked Back (howtogeek.com)480 points by Vinnl 7 hours agohidepastfavorite391 comments ustad 5 hours agoCurrently the main attack facing Firefox is coming from advertising companies such as YouTube. It’s crazy to think that some software engineers might actually intentionally degrade user experience on non-Google browsers or for people using adblockers. The mentality here is pretty disturbing: it’s almost like punishing users for making the choice to browse the web without ads, or without the surveillance mechanisms that come with them. Instead of building a better experience, these engineers seem to be focused on sabotaging alternatives in the name of profit or control. The kind of mindset behind this reeks of the same tactics we see in some ad networks or big tech companies - if we can’t convince you to opt in, we’ll make sure you’re inconvenienced or frustrated until you do. It’s a dangerous precedent because it introduces a toxic game of cat-and-mouse, where the user is constantly playing defense, trying to protect themselves from deliberate misdirection. It’s not just an ethical concern, but also an issue of how we value user autonomy in the digital space. For the hackers out there, this is a opportunity to dig into the JavaScript code responsible for this. There’s almost certainly some interesting obfuscation or odd behavior hiding in the code, and by pulling it apart, we can both understand how these tactics work and build tools or methods to counteract them. Let’s make sure the only thing that slows down the web is bad design or slow servers, not malicious code aimed at punishing the user for making their own choices. reply squarefoot 4 hours agoparent> Currently the main attack facing Firefox is coming from advertising companies such as YouTube. I would add to the list the Linux Foundation too. https://www.linuxfoundation.org/press/linux-foundation-annou... reply surajrmal 4 hours agorootparentNote that the effort there is to shift chromium to a more open governance model. This would mean Google has less influence on the project. reply evanjrowley 1 hour agorootparentI don't believe splitting Chromium governance model across Google, Meta, Microsoft, and Opera will help Firefox in any way. reply Yizahi 2 hours agorootparentprevHow is that possible? Would Chrome Chromium maintainer make a different implementation decision from the original Chrome, and then support and develop a real branch in the code? To have Google less influence? I highly doubt it. It is all chromewashing, to make it sound as if Chrome Chromium is an independent browser. reply ilbeeper 1 hour agorootparentThe origin(al) is developed within the chromium project, Chrome is already a Google styled chromium fork. reply Yizahi 1 hour agorootparentThat's how it is advertised. But in reality all decisions are made by Google for Chrome and other Chrome forks just implement all of them without questions. Google wants to add a new protocol - all forks add it. Google wants to cripple adblock support - all forks do it. Etc. reply troyvit 2 hours agorootparentprevAnd yet Google is a member of the initiative. Maybe, possibly, this initiative coupled with detaching Chromium from Alphabet might lead to an opening of the Chromium engine, but more likely Alphabet joined so that if it _does_ get split off from the mother-ship due to anti-trust they'll still have sway over Chromium's direction. And that will be an advertiser-centric direction. I'll add that whatever the purpose of this project, it isn't going to help the overall openness of the web and will only continue to boost the adoption of an engine that already has an outsized influence over web standards. reply xvilka 1 hour agorootparentprevThey should go all in for Servo as the only future-proof browser engine. reply dotancohen 4 hours agorootparentprevThis is so backwards it seems like a joke. Honestly it reads like a rebel group announcing peace with the dictator and joining the oppression. reply 20after4 4 hours agorootparentLinux foundation is far from a rebel group. Look at who is involved. reply daghamm 3 hours agorootparentLinux Foundation is much closer to an Evil Corporate than a rebel group. It is a pay-for-legitimacy scheme that abuses the Linux name and goodwill. I wish Linus & co would distance themselves from these people. reply gjsman-1000 3 hours agorootparentLinus & co do not follow, or respect, the values of the FOSS zealots. He actively dislikes the GPLv3, has a good working relationship with Google on Android and ChromeOS, and has criticized attitudes in the Linux desktop community for over a decade. He famously roasted his own distribution's package maintainer for wasting their life. All hats off to him, frankly. The Linux community can be extremely delusional at times. reply segasaturn 3 hours agorootparentAll that Facebook money has gone to his head I guess. Thankfully we should still have the ability to fork the kernel if he fully loses the plot to corporate interests. reply immibis 3 hours agorootparentLet me copy the actually important information from the sibling comment that's about to be deleted, because this is actually important: Linus has hated GPLv3 since at least 2006. Linux development has been over 80% corporate funded for over a decade. FOSS contributors do not have enough talent or interest to maintain the kernel for even a few weeks. If corporate interests weren't in the kernel, the kernel would not run on modern devices, period. It would have fallen behind the times and been abandoned like countless other technologies, or replaced with a new proprietary kernel from someone else. Linux on the desktop is not somewhat usable in spite of corporate interests. Linux on the desktop is usable today because of corporate interests. reply gjsman-1000 3 hours agorootparentThe original comment I was replying to has an inaccurate mindset: Linux supporters generally still envision this as a community project, with community contributors, and they are so successful, that companies knock at the door politely and are lucky to get code into the kernel. It's actually the other way around: This is a collaborative corporate project, with corporate employees contributing, but there are some random community members who can knock at the door politely and are lucky to get code into the kernel. The community-first development model died about 2 decades ago. When the Linux Foundation talks about \"community,\" they are talking about their corporate contributors and their communities, not us. This is also why I cringe at the excessive (not all, just excessive) hate for corporations in the online community. Without their work, rip out 80%-90% of the kernel commits every year for the last decade, and see how advanced Linux would be. This same change is also underway at another open source project - Blender; which is now increasingly corporate funded and developed. When I see online forum posts arguing that Blender is a perfect example of how we can beat the corporations as a community, I just shake my head now. reply segasaturn 2 hours agorootparentI actually agree with you that Linux development has been captured by corporations. Except that I believe it's not sustainable. Eventually the Shareholders are going to come knocking and ask why so much engineering time and money is being wasted on some hippie-dippy Open Source junk and not returning value to them. It needs AI in it, or maybe a Linux Pro subscription with ads for the freeloaders. This is why I'm glad the kernel is tied to the GPL, so we can fork when their interests stop aligning with ours. reply nh2 2 hours agorootparent> ask why so much engineering time and money is being wasted on [Linux] Most likely the corporations will say \"because that is much cheaper than developing our own; 10 of our devs on Linux an 99% of devs from other corporations are much cheaper than 1000 of our devs on our own OS\". And the shareholders will likely accept that. The key thing is that for most corporations that contribute to Linux, Linux is not the product (except Red Hat, SuSe etc). Google, Facebook, etc, just need a good OS to run their billions of servers on. > so we can fork when their interests stop aligning with ours You can fork but you likely cannot maintain Linux as-is. Where do the 1M hours/year come from? That's hard to do in free time. That is also fine from the perspecitve of Free Software. The 4 freedoms do not include \"the program must be maintainable with little enough manpower for people to do it in their free time, free of independence on corporate interests\": https://www.gnu.org/philosophy/free-sw.en.html#four-freedoms The GPL is great in that it gives large power to users of the software, no matter if those users are corporate or personal, and even if the makers of the software are mostly corporations. reply segasaturn 1 hour agorootparent> You can fork but you likely cannot maintain Linux as-is. Where do the 1M hours/year come from? That's hard to do in free time. Maybe a question too radical for Hacker News, but why does Linux need 1M hours/year? How much \"worse\" would Linux be for the end user if this year, that time spent dropped to 100k or even 10k? And which \"type\" of Linux user was benefiting most from that time spent (person or corporation)? Why is more automatically treated as better than less? > The GPL is great in that it gives large power to users of the software, no matter if those users are corporate or personal, and even if the makers of the software are mostly corporations. Indeed, I respect the wisdom and forethought of Stallman greatly in drafting the GPL. reply atq2119 53 minutes agorootparentI think it's a reasonable question to ask, and there's surely some churn that we could do without. But don't underestimate the effort that goes into device drivers. reply gjsman-1000 43 minutes agorootparentprevA. How do you contribute to the kernel in a way that only benefits the contributing organization? That's quite literally impossible in this kind of project. Even the more niche stuff like virtualization support is used by homelab enthusiasts. It's also not like Linux has 100,000 APIs for every customer under the sun. B. Most of the effort goes into hardware enablement; CPUs, GPUs, power management, etc. Without corporate interests, try running Linux 2.2 from 1999 on a modern PC (which came out just before the $1B IBM investment). See how well it works. Fork modern 2025 Linux, and try running it on a computer that comes out in 2028. See if it even boots. If Intel's only done a minor refresh, it might work; if it's something bigger like the split to P cores and E cores, expect a brick. Even if it does boot, don't be surprised if it crashes, acts unstable, has borked performance, broken sleep/wake, broken audio, broken USB, you name it, it's probably broken. C. A forked Linux would not have the same level of security research behind it. For example, the Linux 4 era was marked by the introduction of fuzzers and the fixing of countless bugs. A C codebase with handwritten Assembly is rather unlikely to ever become bug-free. How well would your forked non-corporate codebase handle Spectre and Meltdown, just an example, with Google's experts contributing the technique for fixing these problems efficiently (Retpoline)? TL;DR: A forked Linux, is a broken Linux, that will never run well on newer hardware, and will quickly become insecure. This isn't a hypothetical: The FSF didn't like the practice of proprietary firmware blobs being in the kernel; so they made their own commercial-interest-free version of Linux called Trisquel. It still uses commercially written code if it's open source; so even it can't be called completely free of commercial influence. The kicker: It runs on almost nothing, and people were complaining about how it works on nothing 13 years ago. reply gjsman-1000 2 hours agorootparentprevYou're assuming that community driven FOSS development is sustainable, or can make a good long term project the size of a kernel, or a multimedia package, or anything larger than a tool or library. In practice, I'm going to be honest and blunt, it's never worked. 3 decades of trying to replace Photoshop with GIMP (founded 1995)? Barely a dent. 3 decades of trying to unsettle Windows with the Linux desktop (KDE, 1998)? Barely a dent. 3 decades of trying to beat 3D packages with Blender (founded 1994)? Finally working now, ironically only because corporations started getting involved. Before then, Blender 2.7 was never going to do it. 2 decades of Apache trying to kill Skype with OpenMeetings (founded 2007)? Not even a dent. 2 decades of trying to kill proprietary CAD packages with FreeCAD (founded 2002)? Not even a dent. 4 decades of trying to beat Microsoft Office with what is now LibreOffice (roots in StarOffice, 1985, which was ironically a proprietary corporate project for the first decade and a half)? Barely a dent. The Linux community, and FOSS communities, overestimate their strength without corporate interests. They have none. reply segasaturn 2 hours agorootparentWhy should I care that Microsoft Office has more users than LibreOffice? I care which is the better product and has my interests as the user, and not the product, in mind. For example, and relevant to the article, I can use an ad blocker on Firefox without Big Brother Google stepping in and taking it away. Photoshop takes 30 seconds to open and illegally scrapes its users' private data for AI training. Windows has mass surveillance built in with Recall and shoves tabloid garbage and ads into the Start Menu. It means nothing to me that the worse products have more users, they are still worse products. reply dotancohen 1 hour agorootparent> Why should I care that Microsoft Office has more users than LibreOffice? Because people are going to send you documents in Word format, and expect you to be able to send them documents in Word format. Including embedded objects, RTL text, animations, and many other features that LibreOffice barely support and do not transfer well between its own native format and the Word format. reply jacoblambda 4 hours agorootparentprevIt's not too terribly unreasonable. It's largely the Linux Foundation trying to wrest control over chromium from Google before the FTC antitrusts them or before Google does more manipulative market controlling BS. In more polite terms they are framing themselves as an ideal long term steward for the chromium project given that courts have already ruled that Google isn't a suitable steward anymore. Chromium wouldn't be so problematic if it wasn't run by such an anticompetitive organisation. If the Linux Foundation ran chromium and orgs like Igalia (who already do a near majority of the dev work for chromiumm) took over the brunt of senior development and leadership control then it'd be a pretty solid technology stack (albeit with some weaknesses). I personally prefer Firefox and it's associated technologies but I also acknowledge the appeal of Chromium distributions like Vanadium. reply pkasting 2 hours agorootparentIgalia is a valued Chromium contributor, but your notion that they do a near-majority of the dev work is off by an order of magnitude. reply jacoblambda 2 hours agorootparentAh yep. I'm mistaken there. I had read somewhere at one point that they were the second largest contributor to Chromium and made assumptions I shouldn't have. My apologies. reply tgv 4 hours agorootparentprevMy first though: WTF? All hail Manifest v3? reply basilgohar 4 hours agorootparentLinux Foundation is made up of corporations. This should not be a surprising outcome when you think about it that way. Edit: https://www.linuxfoundation.org/about/members reply mossTechnician 4 hours agorootparentAnd the Chromium supporter group is just a subset of those corporations. Several leading organizations have already pledged their support for the [\"Supporters of Chromium-Based Browsers\"] initiative, including Google, Meta, Microsoft, and Opera. reply immibis 3 hours agorootparentprevReminds me of the Open Source Initiative. People tell me that licenses like the SSPL aren't open source because the OSI says they aren't. I tell them to look at who comprises the OSI. Nobody has yet showed me a reason why we should believe the OSI when it tells us what open source is or isn't. reply bartread 5 hours agoparentprevIt’s also laziness in software development practices. Developers (still) only develop and test with Chrome. My last job a bunch of us used Firefox as our main browser, which was hugely helpful. As recently as yesterday I ran into an e-commerce site that didn’t work in Firefox (CPC Farnell, I’m looking at you), giving some obscure security error in multiple languages. I thought it might be caused by an extension at first (e.g., uBlock Origin) but, after trying various workarounds, I realised the site would only work in Chrome. It’s not OK. reply PaulHoule 4 hours agorootparentFor years I have used Firefox as my daily driver, anything I work on works on Firefox. Maybe once a year my tester finds a problem w/ Chrome, if that. Developers like myself are the thread that Firefox keeps hanging on by. reply phkahler 2 hours agorootparent>> Developers like myself are the thread that Firefox keeps hanging on by. Yep. A majority of HN crowd claim to like open source and all that, but then they use Chrome instead of Firefox due to some small perceived convenience. Nobody makes decisions based on principles these days, only their immediate wants. Hoe_math is right, we're on the edge of civilization collapse because to that. reply mrweasel 3 hours agorootparentprevTo some extend this is also down to developer having to stop trying to be clever. I can understand having something look a little weird, maybe not align 100% correctly, but how to you actively go about building something like an e-commerce site that doesn't work in Firefox? My guess is that the developers didn't actively try to do that, but used some framework that's all well an good for a SPA or something that needs to be more like a \"real\" application and applied that to something that just needs to be a bloody website. People need to stop doing that. reply gorhill 2 hours agorootparentprevI randomly browsed the site with Firefox stable and I couldn't see any obvious malfunction. What exactly is not working? Is there a specific webpage where the malfunction can be seen? reply PaulDavisThe1st 55 minutes agorootparentprevrei.com generally continues to have issues with firefox. Completely absurd. reply theshrike79 5 hours agorootparentprev> Developers (still) only develop and test with Chrome I've heard this before... Oh yeah, replace Chrome with IE and you've got the same thing happening again. reply ethbr1 4 hours agorootparentDevelopers will always be time crunched / lazy. Why target multiple platforms when you can just support one? reply basilgohar 4 hours agorootparentThis is a management problem, not a developer problem. Yes, developers should advocate, but it's not the developers' burden to make time out of thin air. reply rileymat2 4 hours agorootparentI have never had a manager that said “don’t make it work for firefox”. What I have seen is developers do it wrong to start, then tasks to fix it get low priority due to market share based priority. reply doctor_radium 13 minutes agorootparentEarly fall 2023 it certainly feels like I caught Verizon discriminating against Firefox. It was a CSS issue in their payment portal where some information wasn't rendering as a DHTML popup but at the bottom of the page. You could still pay your bill, but to an untrained eye it looked broken. I reported it and was sent to \"Executive Custom Service\", which would never acknowledge the problem. They would call once a week and make some statements like the problem was on my side and they couldn't reproduce it at all, to which my BS meter kept responding \"I don't believe you.\" After several weeks of this, the issue mysteriously disappeared one Saturday morning, with no further word to me. I'd also complained to my state PUC (this was a landline bill) and think the added pressure helped convince them to do the right thing, even though the PUC has no online jurisdiction. At the time I hadn't thought to go back to tech support and ask somebody there to simply try it with Firefox. Then Verizon would have been pointing fingers at themselves. Any Verizon developers here? I'd love to know the real story. reply PaulHoule 4 hours agorootparentprevI had one who did say \"don't make it work for firefox\" but he was the only one. The basic mechanic is that the off brand browser has to work hard to be compatible whereas the dominant browser works hard to be incompatible. If you develop Firefox first (have some really ideological devs) you'll find Chrome related bugs eat up 1% of your time if that. If you develop Chrome first you'll find supporting other browsers is a bear. (In the early 2000's when IE was dominant I was afraid it wouldn't be possible to browse the web with Linux. I worked at a library that would have deployed Sun Rays as public computers if we could get Mozilla to compile on Solaris but we couldn't, even with the help of Sun support. I developed Mozilla-first and then Firefox-first and helped keep the flame alive back then.) The system I work on now works on both because I develop Firefox-first. There's one screen that loads up 40,000 rows (crazy you say?) worth of data that performs fine on Chrome and is laggy on Firefox, but otherwise the site spins like a top on both of those. Once in a while we run into a serious headscratcher on mobile Safari that burns up some dev*weeks. reply assimpleaspossi 1 hour agorootparentThis is why I always develop to web standards and not to any browser. You follow the web standards and then check to see which browsers do it right. Then adjust for that browser if necessary. reply horsawlarway 3 hours agorootparentprevI agree that this is a \"management problem\" in the sense that if you want to support Firefox, you should allocate resources for testing on Firefox. But also - it's not high up the priority list given Firefox's marketshare. In most cases, you'll get the support by default, but I don't really see many US managers being tasked with allocating resources to support UC browser, or Opera, and those are both in the same space marketshare-wise. My management is actively discussing EOLing several Firefox products because we have basically no real paying customers on them, and Mozilla is unpleasant to deal with in the extension space (genuinely - https://www.neowin.net/news/ublock-origin-lite-maker-ends-fi...) reply samuellavoie90 3 hours agorootparentprevThe goal of a standard is to not be forced to code specific things for each implementation out there. This is failure of the web standards that the google implementation has become the standard. reply cj 3 hours agorootparentWe have web standards, but one area they breakdown is adoption of those standards. Each browser seems to pick and choose which standards they want to adopt and when. Sometimes Chrome will support a new CSS syntax for months or years before another browser finally picks up support (or vice versa). For web standards to truly work, there would need to be better coordination between browsers to adopt new standards in unison. Until then, developers (should) keep track of whether the syntax they're using is supported by all major browsers. Or, develop just for Chrome, which seems to be favored by most. reply pkasting 2 hours agorootparentWe vendors disagree about the relative value of different standards. Adopting at different times makes life harder on web devs, but it also seems like the only route forward. Do you want any one vendor to be able to force the others to implement something they disagree with, or (vice versa) to have veto power? reply segasaturn 5 hours agoparentprevThe irony that Google, who made their bones on the \"open web\", is now attacking open web standards and trying to turn the internet into their own walled garden that they control every aspect of I hope is not lost on the people here. reply delecti 5 hours agorootparentI have trouble seeing that as irony in a world where \"embrace, extend, extinguish\" exists. reply ryandvm 4 hours agorootparentAgreed. It would be ironic if it wasn't literally the exact same arc that every single company in this industry goes through. * Scrappy upstart catches the industry off guard * Wild success and growth * Becomes bloated, unable to innovate, and addicted to its cash cow * Begins turning the screws on its users to appease shareholders reply 20after4 4 hours agorootparentIt's all just a natural part of the enshittification progression. reply fouc 4 hours agorootparentprevhttps://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguis.... We could also start calling it Embrace, Extend, and Enshittificate reply kurble 4 hours agorootparentExtinguish is fine. reply diggan 5 hours agorootparentprevOnce the love of \"Microsoft Loves FOSS Again\" fades away as they aim to enter the next phase, some other company (Cloudflare? Tailscale?) will receive all the developer love until yet again, people realize that for-profit companies don't actually have their best interest at heart. Rinse and repeat forever... reply bluGill 4 hours agorootparentThe only one who has your best interests at heart is you. And you sometimes get it wrong. It is very common the case that someone else will do something that aligns with your best interest. (love for example) In fact it is often in your best interest to do something that helps someone else and appears to harm you. (giving money to the poor at first glance appears to harm you and thus be illogical - but there are a number of secondary results of this that make it in your best interest anyway) reply ragnese 2 hours agorootparentprevI was convinced at the time--and I'm still convinced--that there was a TON of astroturfing on places like Reddit and even here when Nadella became CEO of Microsoft and there was that whole \"Microsoft hearts Open Source\" campaign. Every other comment was \"You're just stuck in the past. You're as bad as the conspiracy theorists. It's not even the same people running the company anymore. Blah blah blah.\" And now they own Github and they're training their AI models on you and your code and forcing that crap into a bunch of PCs. They were about to push out a \"feature\" to Windows that periodically took screenshots of what you were doing and used AI to analyze what you were doing. Then they sprinkle some glitter for the easily-distracted and tell you that it's actually a feature for you. Last I heard, they shelved the idea for now because of the backlash, but we all know they'll circle back around. But, yeah, I'm a tinfoil hat weirdo who's just a \"hater.\" reply tttttrhowwwwai 4 hours agoparentprevmaybe my rant is going to be a bit out of place here but here it goes anyways: sometimes im glad im a technical person that can get away with a somewhat \"healthy digital life\" im basically immune to all the crap going on. i don't need to work too hard to meet my digital needs because im also a simple person. but i really feel bad for the normies who have to deal with all the shit the tech industry throws at them. they don't even know what's wrong, they can't pinpoint what's giving them that extra stress, building up day by day when they use their devices, handle their info, or consume entertainment. like account exhaustion, confusing UI changes every day, or why they have to navigate a sea of crap just to unsubscribe. and why do they need a new computer for software that worked fine 15 years ago? and don't even get me started on what they're doing to older people. cable companies for example are ripping them off with terrible TV boxes and nonsense plans. all their appliances need subscriptions or apps and have cryptic buttons. stores now feel like border control, straight out of a black mirror episode. i can't imagine the frustration they must feel. it just feels backwards. reply neilv 3 hours agorootparentAFAICT, current tech industry culture is most like what I understood of the '80s stereotype of Wall Street bro culture: sociopathic unchecked-greed that will do whatever it can get away with. I'm not saying this to complain, but to suggest a risk of what might come next. So far, they've run wild, and taken over computers, the Internet, AI, and information technology in general. What happens when there's a disruptive breakthrough in medical care, and the exploiters rush in with the same thinking? Right now, one of the few firewalls against that might be that doctors generally have traditions of ethics, and some stature to hold their ground and influence things. Earlier Internet didn't have the same formalized ethical traditions, but had a lot of very smart people people who had altruistic intentions, as well as suspicion of those who'd attempt to twist online potential. All those ethical people were pretty much swept away in a funding gold rush, suddenly with little to no influence over it. (Google did grab some of those people, because Google said the right words, so the altruistic techies thought it was their people, but look what eventually happened even there.) Just like virtually every IoT product and Web site violates every user, what happens if a medical gold rush (say, some kind of implant, or transformative process) means that what we thought was a bulwark of ethical practitioners, is easily bulldozed over, by investment money and culture. And then everyone's body is violated by the newly unchecked industry-wide socipathy, with no alternatives to even live? reply depingus 2 hours agorootparent> What happens when there's a disruptive breakthrough in medical care, and the exploiters rush in with the same thinking? Allow me to simultaneously assuage and stoke your fears. There is little chance of big tech disrupting the medical field; Because every aspect of the medical field has already been seized by the insurance companies. See United Health / Optum. reply Yizahi 1 hour agorootparentprevWe have never asked for this (c) :) reply HunOL 4 hours agoparentprev> It’s crazy to think that some software engineers might actually intentionally degrade user experience on non-Google browsers or for people using adblockers. Pretty sure that was happening back in a days when Opera was using own engine (Presto). They shipped browser with scripts to fix some popular sites. Actually Firefox also has some fixes for particular sites about:compat reply immibis 2 hours agorootparentEven market-dominant companies do this. Windows ships a bunch of backward compatibility patches. Graphics card drivers (especially Nvidia) wholesale replace shaders in popular games. reply darknavi 2 hours agorootparentWebkit does this. Examples: - https://github.com/WebKit/WebKit/blob/main/Source/WebCore/pa... - https://github.com/WebKit/WebKit/blob/main/Source/WebCore/pl... reply jshen 1 hour agoparentprevDon't like YouTube's ads, great don't use it. You aren't entitled to get it for free though. reply segasaturn 55 minutes agorootparentGoogle isn't entitled to invade my privacy, harvest my data and waste my time with ads. Installing an adblocker isn't an act of entitlement, it's an act of self-defense. reply recursive 37 minutes agorootparentAnd google is entitled to infer that you're using it and serve you different content, or none at all. reply observationist 1 hour agorootparentprevIf your internet server serves content, I'm entitled to connect to it. If you don't want to serve content without a login, you have the option to not do so. That's the way the internet works. You don't get to have your cake - free and public access to content - and eat it, too, by imposing your own requirements on the technology, introducing an adtech gatekeeping system. YouTube or any of the others could simply put up a login gate, and then nobody could access any of the content unless they're logged in, and have agreed to additional terms of use. As it stands, all the content is free and public. In legal terms, as per the Supreme Court of the US, the gate is up, and they are not entitled to impose additional restrictions except where allowed or required by law, such as age restriction, moderation, or copyright situations. You are entitled to get those videos for free unless or until YouTube decides to lower the gate. That's how the internet works, and it's a wonderful, good thing. Fuck ads. Block them all. Eventually they're going to be regulated and companies will be forced to stop mass commercial surveillance under threat of fines and hopefully prison time. Absent surveillance and mass data harvesting, adtech becomes much less lucrative, and maybe we'll see markets develop that compete on product quality, and value to the consumer, instead of the endless cycle of enshittified garbage and attempts to derail the open and free public internet. reply bdhcuidbebe 41 minutes agoparentprevfreetube is a superior experience for consuming youtube content in every way, including not running google’s javascript so they cannot mess with the users in the same way. it has adblock and sponsorblock built in. that said, firefox has been my browser of choice as a web dev for most of my career. (im old enough to have used netscape before that). i remember having super powers compared to other devs with the help of firebug :-) reply PaulHoule 4 hours agoparentprevAlso it boggles my mind that an advertising company (1) offers its own ad blocker to block competitors ads, and (2) circumscribes what ad blockers can do, and (3) nobody stops them... All when the FBI is saying you should run an ad blocker to avoid being the victim of a crime. reply paulryanrogers 4 hours agorootparentAnti trust has been a joke since the 70s, when the threshold moved to \"consumer harm (so blatant people will vote me out of office)\" reply hmmm-i-wonder 4 hours agoparentprev>it’s almost like punishing users for making the choice to browse the web without ads, or without the surveillance mechanisms that come with them. I don't think its \"almost like\", I think it \"actually is\", and that its intentional. There is a perspective that is now prevalent in tech and business that users are good only as far as you can monetize them. Any concepts of respect or value outside of that have been discarded. There used to be a sense that you needed to continue improving a product to keep charging the same or more for it. Now companies expect you to pay more every year while products are stagnating or being enshittified to extract higher profit margins on top of the increased prices they are charging. Tech is now run by Business/Sales people, and every user is a statistic in a spreadsheet they are trying to extract the most money from for the least amount of investment. Data collection and behaviour tracking is one side of the coin, but we really don't talk about why companies are willing to pay so much for that data or what they do with it... that's a conversation I think needs to be focused on. reply cornstalks 2 hours agoparentprev> It’s crazy to think that some software engineers might actually intentionally degrade user experience on non-Google browsers Is this actually a thing? As far as I'm aware all degradations in non-Chromium browsers have been unintentional bugs, either caused by a YouTube bug or a non-YouTube bug (i.e. in the browser or an extension) (note I'm specifically not commenting on the last portion of your comment regarding \"for people using adblockers\"). reply recursive 35 minutes agorootparentIf you have a lot of technical churn, and only test perf on Chromium, then you could certainly claim that the result is \"unintentional\", but it's almost guaranteed based on that circumstance. reply Timshel 4 hours agoparentprev> Currently the main attack facing Firefox is coming from advertising companies such as YouTube. While I agree; between an up-to-date uBlock Origin and https://addons.mozilla.org/fr/firefox/addon/chrome-mask YT is quite usable. Long term I'm more worried by Mozilla leadership than Google shenanigans. reply normie3000 4 hours agorootparentFrom your link: > Please don't use Chrome Mask on YouTube. It won't resolve any issues, and it will make your experience worse over time. If some issue got fixed after toggling Chrome Mask on, it most likely got fixed by the addon clearing the cache. But you can do that yourself, too, without the need for this addon. reply Timshel 4 hours agorootparentI can't seem to find your citation from the add-on page. Might be a placebo but YT appear more responsive with it on than off after a ctrl+f5. Edit: appears to be in the reviews: https://addons.mozilla.org/en-US/firefox/addon/chrome-mask/r... reply tapoxi 5 hours agoparentprev> It’s crazy to think that some software engineers might actually intentionally degrade user experience on non-Google browsers or for people using adblockers. Why would I, as a developer whose income stream is based on advertising, intentionally cater to users who are costing me money? There is a web based on hobbyist platforms like PeerTube and Mastodon, and you can clearly see why they haven't captured the masses. reply notanastronaut 3 hours agorootparentThere is no reason I, a user, will intentionally use your product when you fill it with ads that are, at best annoying, and at worst malware vectors. You have your right to develop things your way, I have a right to say no thank you. Google, though, is so big it is basically saying \"you don't have a choice.\" That's the problem and one that Google spends billions to enforce. They use the weight of the uninformed to apply pressure to the rest of us. It was no better when Microsoft did it with IE, nor is it any way proper, now. reply apricot 1 hour agorootparentprev> Why would I, as a developer whose income stream is based on advertising, intentionally cater to users who are costing me money? Thank goodness you're not a doctor. reply bee_rider 4 hours agorootparentprevThis is basically true. The ad supported web sucks, but the solution is to not use it. reply wruza 1 hour agorootparentThe solution is how we solve it. There’s a technical end to every demand, and at the end of the day regulation only can do so much for both sides. The reality sorts everything else. The solution you mentioned is valid too. But you cannot ignore the fact that internet is for everyone and not for google. Google minus all the shit it does to the internet can definitely exist in some form. Claiming it’s either this or nothing is just defeatist. If google and youtube disappeared tomorrow, I’d be the first among those guys who buy hdds and torrent videos from these. For no money, like I did with all torrents in my life. There would be less professional videos obviously, but almost everyone agrees it’s a good thing (quit SM, anxiety, kids social issues, etc talks). reply bee_rider 1 hour agorootparentSorry, I was ambiguous. I just meant not to use the ad-supported part of the web. Yes, the rest of it is fine. Even a large chunk of the ad supported internet is happy to continue sending you bits if you don’t render their ads. This is fine, the convention has always been I’ll send whatever (non-malicious) bits I want, you send whatever you want, and we’ll render it however we want. YouTube specifically doesn’t send bits to people who don’t render their ads, on purpose, which is also fine, they just don’t want those of us who don’t render ads around. Entitled ad guys don’t get to change the social convention to add some obligation to render their ads. If they don’t want to serve bits to users that block their ads, that’s fine, but if they send bits I’ll render them however I want on my system. reply wruza 52 minutes agorootparentExactly. It’s amazing that ads-ers send bits regardless and expect them to be consumed as is, as if it was some fundamental law of nature to do so. Simply don’t send, wink. That wink makes them feel uneasy because it breaks that wonderful narrative of theirs. “If you don’t want to watch ads, just don’t visit”. Yeah, just paywall us then, come on, we’re all yours, signed in, vendor locked. I’m so ready to leave and delete the bookmark, what are you waiting for? reply bee_rider 41 minutes agorootparentPeople are playing this cat-and-mouse game with YouTube specifically, where they’ll circumvent the desire to block them for not rendering ads. I think this is a bad thing for users to do. But I mostly think it should make the ad providers uncomfortable. Because they know that most people won’t play cat and mouse for their content. In any case other than YouTube, people would just move on. They know it. We know they know it, because if they really didn’t want to send bits to ad-blockers, they’d copy the first step of the back-and-forth that Google did with YouTube, and those users would no longer be a problem. reply lentil_soup 1 hour agorootparentprevBecause it's not catering, it's actively making it worse for the rest of us? Because not everything is about money? Because of ethics? Why would I, as a doctor whose income stream is based on people getting sick, intentionally support policies that make people healthier reply p3rls 4 hours agorootparentprevYou can tell who has never been in control of a budget and had to fire people because more than half their audience is using adblockers. reply wruza 1 hour agorootparentWhy you even start a business so risky and bad mannered? reply pif 1 hour agorootparentprevI get your points, but have you tried with less invasive advertising? Like, you know, static pictures downloaded from your domain with a HREF on them? reply Workaccount2 4 hours agorootparentprevPlease stfu and work for free so I can maintain what I am entitled to. If you really need money just give more invasive ads to the idiots who don't adblock. Thanks. reply eipi10_hn 4 hours agorootparentprevBecause you cannot even control your ads to users? No one of you devs gets punishment for tracking users' personal information, pushing scam, phishing and malware to users, and now users are not even allowed to protect themselves? Users don't drop trackers and malwares to your servers, why do you drop trackers and malwares to users' machines? Because you are working for a corporation that joins in World Wide Web Consortium, who literally says this in the Ethical Web Principles? > People must be able to change web pages according to their needs. For example, people should be able to install style sheets, assistive browser extensions, and blockers of unwanted content or scripts. We will build features and write specifications that respect people's agency, and will create user agents to represent those preferences on the web user's behalf. https://www.w3.org/TR/ethical-web-principles/#render If you cannot maintain your service, paywall your features, not forcing malwares and trackers to users. No one forced you to serve 1080p, 1440p or 4K videos to everyone for free. You were the one literally \"advertised\" yourself as a \"free\" service at beginning, in order to hoard how many users you could. And now when you cannot control your own costs, you push malwares and trackers to users? The mentality of hoarding users with \"baits\" like \"free\" are the real poisons for the internet, for both of you and your users, NOT users who are doing exactly what World Wide Web Consortium tells them. Where are all your MBAs in your corporations? The ones bragging about themselves on LinkedIn and now the only resolutions you can think of is pushing malwares and trackers to users? All of the finance classes in your college should be simplified to advertisement classes I guess? That would save a lot of resources for everyone. reply Workaccount2 3 hours agorootparentLet me remind you that Ad-Block Plus collapsed when it's users revolted over their plan to whitelist simple vetted advertisements in a truce with advertisers. ABP was foolish and actually believed it's users were trying to make a statement about invasive ads. Really their users just didn't want to see any ads at all, ever, regardless of the circumstances. reply eipi10_hn 2 hours agorootparentABP didn't even address any trackings with their program. It's just pure cosmetics. > Really their users just didn't want to see any ads at all Because the internet was filled with malicious ads before any content blockers having more people? The hazardours time of Windows XP/7 with malwares-affected from the ads appear like meals in every day's news? Sorry, internet ads are doomed from those times. They are migrained to everyone's minds that users are walking in a landmines with those ads. If a business is entirely dependent on those ads, that business should not exist. Doing business is hard, right? I mean, like, most of other ethical jobs on the world. Users are just doing what World Wide Web Consortium says. reply debugnik 2 hours agorootparentprevYou forgot to mention it involved paid whitelisting, and the requirements for compliance were so weak that even major malvertising vectors, like Google, were considered acceptable. reply p3rls 4 hours agorootparentprevThose corporations with MBAs will find another way-- you're only hurting the independents and destroying the open web with your hipster nonsense reply eipi10_hn 2 hours agorootparent> Those corporations with MBAs will find another way Not YouTube. Those \"nonsense\" are from World Wide Web Consortium, users are just doing what they say. The \"hipster\" are the ones not respecting those Ethical Web Principles. Users are not injecting trackers and malwares to those independents' servers. Why do those independents inject trackers and malwares to users' machines? The ones who destroyed the open web are the business, including independents and corporations, with the mentality of luring more users to use their \"free\" services, without any plans of controlling the cost, ETHICALLY and MORALLY. Scale, scale, scale, more users, more beautiful number; until their pocket is burnt and now their resolution is pushing those trackers and malwares to compensate the cost. Ads, malvertisements and trackers are not the open web. reply ethbr1 5 hours agoparentprevWhat doesn't work with YouTube on Firefox? Asked as on mobile I run as few apps as possible, so use the web version. Haven't seen any issues. reply diggan 5 hours agorootparent> What doesn't work with YouTube on Firefox? The performance is way worse (which Google engineers will explain by some browser API being slower in Firefox and they haven't yet had time to optimize it, N years later [they did the same with Inbox + Firefox before]) and you'll also see more ads if you're not a paying user and using Firefox compared to if you used Google Chrome. reply jeffbee 4 hours agorootparentThe last serious performance issue I saw with FF+YT was when YT added a glowing border around videos when the tab was in dark mode. FF just wasn't able to efficiently run that effect. I don't think it's very reasonable to say that YT or any other site should be limited by the performance problems of FF. Maybe they should have detected the issue before release but the explosion of browser x platform x dark/light theme x graphics driver is a large space to sweep. reply WorldMaker 4 hours agorootparent\"Should have detected the issue\" implies it was an accident. YouTube has intentionally tanked performance in non-Chrome browsers before and been caught. Even when they weren't actively sabotaging other browsers they had big Chrome banners and \"Works Better in Chrome\" signs for several years in the past. If they did it _then_, it's hard to give them the benefit of the doubt that they just \"missed it\" now, and easier to assume they do things that are broken in other browsers intentionally. reply cornstalks 2 hours agorootparent> YouTube has intentionally tanked performance in non-Chrome browsers before and been caught. Can you please share sources regarding this? I'm not familiar with any instance like this. reply WorldMaker 14 minutes agorootparentEdge (Spartan or Legacy) had a big fight with YouTube that YouTube was doing a hidden (not visible to users) DOM animation underneath the video player in a way that Chrome ignored but tanked Edge performance. There were several release cycles where Edge would specifically target that hidden animation performance, only for YouTube to make the animation worse and ratchet it back. I lived through that as a user. (I was one of the like 5 Edge Spartan users, I know, lol.) I could see the dumb animation in dev tools and manually delete it for better performance. It was a nice thing I had some technical skills. I know for mainstream users the solution was \"watch YouTube in Chrome\". It's hard to find to other sources because Microsoft intentionally broke the SEO on the Edge brand and you know Google is the only other major search engine. Not that they'd intentionally down-pagerank bad news about a Google property, I'm sure. reply jeffbee 3 hours agorootparentprev\"Intentionally tanked\" is just nerd spin. I've never seen an actually convincing recitation of these stories. reply ustad 5 hours agorootparentprevA lot of the reported issues with YouTube on Firefox (especially when paired with adblockers) involve things like increased page load times, UI elements not functioning as smoothly, or even video playback glitches. Some of this is due to JavaScript that’s intentionally designed to slow things down if you’re blocking ads or using a non-Google browser, as we’ve been discussing. reply Izkata 4 hours agorootparentI would guess most of that is probably Polymer. IIRC the story was, when Youtube was redesigned a while ago they used an early spec for Web Components, that they were pushing to be standardized and was fully implemented in Chrome. But they had to add Polymer as a polyfill for other browsers. Then the version of Web Components we actually got wasn't entirely compatible with that early spec, so Polymer is still in use for non-Chrome browsers. I don't know how much of that's changed since then, but the complaints are basically the same as when that happened. reply ethbr1 4 hours agorootparentprevI haven't seen any bugs on Firefox mobile + uBlock Origin + Android + Pixel 4a 5g (I hate upgrading phones, sue me). The only glitch I reliably get is watching videos at 1.5x sometimes freezes video (but audio still plays). Expect that's more hardware and memory pressure related tho. Also, I wasn't aware YouTube mobile has ads? I think uBlock might be eating them. Although possibly whatever is lagging others experiences too... reply officeplant 5 minutes agorootparent>Also, I wasn't aware YouTube mobile has ads? I think uBlock might be eating them. That would be the point of an ad-block add-on wouldn't it? reply elephanlemon 5 hours agorootparentprevI ended up switching back from Firefox to Chrome after a few weeks because I found that if I had more than about 6 YouTube tabs opened, the YouTube interface would become very laggy. I blamed it on Firefox at the time but maybe it was something intentional by Google. reply flexd 4 hours agorootparentMy Firefox does this on Windows. I have no idea how many tabs I have open, but regularly the whole YouTube tab I have open freezes, especially if you try to watch one video, and then another, and the whole UI is delayed by many seconds. Even closing the tab will have the audio playing for several seconds in the background. It's not due to load or hardware as far as I can tell. The videos play just fine in Chrome or Edge. I still use Firefox as my daily browser (previously Chrome), but these issues are super annoying. I don't want to have to restart my browser or PC all the time. I don't know if it's some combination of extension/ad-blocking or YouTube doing stuff, but it's very annoying. Unrelated to that, but on a Ubuntu laptop I have Firefox tabs regularly stop working entirely. They just won't load anything, and the only fix is to open a new tab and that loads fine most of the time. Other times I have to restart Firefox. I've tried searching for others experiencing this problem and even asked in Mozilla channels on Matrix, but even then I didn't come up with any answers. The laptop's hinge broke last year so I haven't used it since then, so likely never going to figure out what was going on. reply wussboy 4 hours agorootparentprevHow…how many videos are you watching at one time? reply wruza 4 hours agorootparentI go through my feed or history and bg-open the links I want to watch. Then I watch them. What a strange confusion, as if all people must have the same \"workflow\". Sorry, no intent to sound negative, but why not give it some thought at least. It's \"6 tabs\", not \"6 videos playing at the same time\". reply WorldMaker 3 hours agorootparentAs someone who hates the auto-recommendation system on YouTube and turns it off, I also appreciate this is sometimes the safest/easiest way to watch only the videos I actually intend to watch. This seems intentionally YouTube's UX design fault, they too heavily try to push you to \"auto-play\". YouTube has a \"Watchlist\" feature where you can build a playlist. When it works it is exactly what I want, but it feels like every so many months it mysteriously breaks for a while or they hide the button for it behind some new hidden gesture or menu they expect you psychic out of their UI. (If you've never heard of \"Watchlist\", no wonder. It seems intentionally hard to discover.) Lately I've been complaining that YouTube adds random \"auto-play\" videos even to a manually curated \"Watchlist\" if you don't pay enough attention or watch past the end of the list (even with auto-play and recommendations entirely off). reply scott_w 4 hours agorootparentprevNot OP but I read it as \"6 tabs\" not \"6 YouTube tabs.\" reply lxgr 4 hours agorootparentI sometimes do have several Youtube tabs open to line up things I want to watch next. reply ethbr1 4 hours agorootparentTo this, have you tried running a no-autoplay style extension? (Not exactly this scenario, but lists might be modifiable) I expect YT is probably doing some preloading or heavyweight running in a loaded-but-not-playing tab. Convert that to load-on-click, and you'll likely fix your issue. reply wruza 40 minutes agorootparentWe’re shifting targets here. The fact is, it doesn’t happen in Chrome for “magical” reasons, according to a comment few levels up. And regular non-tech users won’t debug this with click to play or whatever. We expect that YT does it absolutely intentionally. It bends userbases however it wants due to its multi-dimensional reach, and we’re like “hmm maybe extension would help prevent accidental preloading issue”. I just don’t get it. reply lxgr 2 hours agorootparentprevNo need – Firefox does that out of the box for tabs opened in the background (I open tabs via middle/command click)! So there is no problem for me. reply ethbr1 4 hours agorootparentprevOn the internet, no one knows you have compound eyes. reply 20after4 3 hours agorootparentprevAre you on Android? AFAIK Mobile Firefox on iOS is just safari with a different skin and on Android it's still not really the same as desktop Firefox. I think what's actually happening is that they are targeting uBlock + Firefox on desktop for punishment. reply ethbr1 2 hours agorootparentMobile Firefox on Android. reply conradfr 4 hours agorootparentprevNot totally related but on Firefox mobile you can't have a Youtube video playing while switching to another app anymore. reply tuukkah 4 hours agorootparentI think this is something that Google requires on Play Store, but there's a Firefox extension you can install to make it work: https://addons.mozilla.org/en-US/android/addon/video-backgro... reply prmoustache 4 hours agorootparentprevAren't every firefox user using newpipe or other yt frontends on mobile? I mean if you care enough to not use the default mobile browser, surely you found out about newpipe and the myriad of other youtube frontends. reply officeplant 1 minute agorootparentMy main issue is NewPipe struggles with being attached to an account. Its a great app for me to open a video link in / use to download it. While using firefox mobile + ublock its easier to be logged into a youtube account and dig through favorites, etc. rurban 2 hours agorootparentprevWith Firefox on Linux HD Videos are the default, whilst Chrome hasn't integrated DRM for a long time, leading to SD only. On Android, Firefox has much more extensions, such adblockers. FUD reply asdfasdf1 5 hours agoparentprevabout youtube being totally unusable on firefox: is it just youtube/google being evil as is customary or also firefox having loads of memory leaks, as its usual too? (plenty of mem leak bugs with video/audio reported over the years, many very recent and still open) reply danielbln 4 hours agorootparentI was about to write that YouTube works flawlessly for me in Firefox on Mac, but I just upgraded to a monster of a M4 MBP, so it's probably just overcoming these issues (malicious or otherwise) via brute force. reply kome 4 hours agorootparentI watch youtube on a 10 years old macbook air 11, and it works flawlessly with firefox and ublock origin. reply josephd79 4 hours agorootparentprevI've used firefox for a very long time and have never had an issue with youtube... reply prmoustache 4 hours agorootparentprevFirefox + ublock origin seems to be the combo allowing me the best user experience with youtube. I have no idea what the previous poster is talking about really. reply dartos 5 hours agorootparentprevYes reply dismalaf 4 hours agorootparentprevYouTube works perfectly on Firefox if you pay for YouTube Premium. Haven't noticed any bugs, if it leaks memory or something it's not noticeable on my machine. reply snarfy 4 hours agoparentprevIt's not the engineers making these decisions. They write the code they are told to write. Some middle manager / VP gets a promotion if they 'increase engagement', 'increase ad-spend', or some other hollow metric they chase. They are the ones deciding to send any 1-3 star ratings to customer support, and 4-5 ratings recorded as an actual rating. It's not about the users at all. It's about gaming the system for some manager's benefit. reply LegitShady 3 hours agorootparentI am not a person who normally moralizes to others, but I can say I have quit jobs where I found the work to be unethical or that company policies required me to bend my ethics. The engineers implement all of the \"features\" that these management types decide on. I understand there are infinite engineers so eventually the features will get implemented, but I do not blame the managers alone for tasks done by unethical engineers who do not consider the effect of their work in the long run. reply adamc 3 hours agorootparentThis. If you only shoot the crowds when your overlord demands it, that does not make you innocent. reply snarfy 3 hours agorootparentYes because implementing a pop-up is akin to murder. reply adamc 2 hours agorootparentThe moral issues are the same even when the gravity of the offense is different. reply snarfy 3 hours agorootparentprevThat's privilege talking. Not everyone is in a position to quit their jobs over the morality of implementing a pop-up. reply i_love_retros 4 hours agoparentprev> Currently the main attack facing Firefox is coming from advertising companies such as YouTube. Can you explain this more? I don't understand what this means. reply 20after4 3 hours agorootparentYoutube intentionally degrades the user experience if you use Firefox, at least if you are using a proper ad blocker. And there really isn't much reason to use Firefox if you aren't also using uBlock. So by targeting the users of uBlock+Firefox, YouTube is aggressively degrading the experience of Firefox users. Things I've noticed include: 1. Every video defaults to the absolute lowest resolution (240 or 320) until I manually switch it to a higher setting. 2. Occasional (but fairly frequent) 30-second delay before a page loads (loads enough to show a black page, then just freezes for a while. During this delay, refreshing the page gives the same result. 3. Rarely, interstitial notice pages threatening vague consequences if I continue to use an ad blocker. reply rsyring 2 hours agorootparentI'm only an occasional YT user, but I don't have any of those issues and use uBlock+Firefox and NextDNS. reply i_love_retros 3 hours agorootparentprevI wonder if using DNS level ad blocking would prevent this. I avoid YouTube as much as possible anyway as they force me to login. reply 20after4 3 hours agorootparentThey may actually be implementing something on the server side to degrade the performance of connections because they have me flagged as a ublock user. reply jacoblambda 3 hours agorootparentprevGoogle has a habit of intentionally delivering degraded versions of their services to not Chromium based browsers, particularly non-Chrome versions of their browsers (determined by User Agent). There's a pretty famous example of Google deploying a specific variations of Youtube to Microsoft Edge browsers (back when Edge had it's own engine) and that specific variation would cause Edge's hardware acceleration to break. If you overrode the user agent to present as google chrome, the problematic invisible parts of the page disappeared and everything worked as intended. And what the specific problem HTML was would change just as fast as the MS team could roll out fixes. In effect they were playing a game of \"break the browser\" against their competitors to force them to apply temporary fixes that would then later have to be removed resulting in unnecessary code churn in their competitors' code bases. https://news.ycombinator.com/item?id=18697824 reply vanous 5 hours agoparentprevA while back nobody would believe that Google's search dominance could be disturbed... and now many have either switched away or stopped using search altogether. It takes me two clicks to set a search to DDG, Kagi or other and Google has lost this customer (often a family) forever. So let them be arrogant and loose their YouTube customers over time too. reply scarface_74 5 hours agorootparentGoogle still has close to 90% market share with DDG being a little more than a half percent. https://gs.statcounter.com/search-engine-market-share/all/wo... Edit:Wrong year - that was 2020 this is 2024 https://gs.statcounter.com/search-engine-market-share/all/wo... reply normie3000 4 hours agorootparentYou've linked to 2020. 2024 is at https://gs.statcounter.com/search-engine-market-share/all/wo..., but the numbers seem to be identical. reply dartos 5 hours agorootparentprevChange is sometimes slow. Let’s see how Google does as a century old company. In the grand scheme of things, they’re still a fairly young giant. reply prmoustache 4 hours agorootparentThe thing is I see it everywhere around me. People don't care looking for a better search engine. Worse I am pretty sure that most people do not know they can choose their search engine and can define whatever is used when searching in the url bar. reply scarface_74 4 hours agorootparentprevI didn’t realize I was looking at the 2020 stats. But the 2024 stats are the same reply bachmeier 4 hours agorootparentprevDefining the market correctly is always an important first step. Those numbers don't include LLMs. reply scarface_74 4 hours agorootparentWhile I’ve been using ChatGPT with web search for almost two years as a paid user, the majority of people don’t and that has just gone free in the last few months. But when I just want a simple search, I still use Google first out of habit. reply cnotv 2 hours agoparentprev> these engineers seem to be focused Managers. reply Der_Einzige 3 hours agoparentprevYou used LLMs to write this comment. reply WorldMaker 3 hours agoparentprev> It’s crazy to think that some software engineers might actually intentionally degrade user experience on non-Google browsers or for people using adblockers. It's also crazy that we've let ad companies tell us that using a non-Google browser is the same thing as using an adblocker. It is not the same and it never was. I use Firefox with no adblocker installed. I don't mind ads to an extent. I do mind tracking and find micro-targeting disgusting and creepy and evil, so I use Firefox, and I use its Enhanced Tracking Protection, and I only log in to the major Ad Companies like Google/YouTube, Amazon, Meta, others in dedicated containers that only are for their sites themselves. It's sad and annoying how many ad networks accuse me of having an adblocker just for using Firefox (or Safari) with relatively cleaner than average cookies. Show me the old school of ads, the \"Superbowl\" broadest audience ads, the stuff that advertising companies \"knew\" for centuries of their existence as \"common sense\" that was the most useful way to make and sell ads before tech companies got involved and decided that user privacy was up for auction to the highest bidder. The way I see it: If an ad network can't do that and sees this as \"adblocking\", it deserves to die and something better needs to step up and eat their lunch. That includes Google and Meta's ad networks. That includes \"Admiral\" and any other network that buys ads from creepy \"Temu\". reply 2OEH8eoCRo0 2 hours agoparentprevThe firehose of cash is ads and user tracking, not serving better video. It's such an unprecedented amount of money that it corrupts everything else and distorts the market. reply wruza 5 hours agoparentprevThat's how Chrome started. I remember it showing a banner with itself on /. which froze a page on scrolling over it for a few seconds. In all browsers except Chrome. Never understood this Chrome-go-go mob mentality that everyone had back then. It was literally an ads-network prodived crappy browser with just tabs and urlbar. It was fast, because it did nothing and had no cpu pressure from the banners. I wouldn't be surprised if it was \"fast\" all this time only due to special treatment from google, youtube and the corresponding ads/tracking scripts. \"Precedent\", yeah. reply ethbr1 5 hours agorootparentIt was fast because in 2008 it used V8 [0] and other browsers didn't. Eventually competitors caught up. [0] https://en.m.wikipedia.org/wiki/V8_(JavaScript_engine) reply wruza 4 hours agorootparentAnd that was fast because google pushed on megabytes of javascript and tight loops in it. Regular ajax (now known as htmx) webpages worked absolutely fine in other browsers. I regularly scrolled through a whole freebsd single-html handbook and it never lagged in e.g. presto. Websites aren't expensive to run even on a slow interpreter. Even medium-complexity apps don't do much and could be written in python or ruby back then. The only source of website lag is ads networks. reply Apocryphon 1 hour agorootparentNah, I remember Firefox in 2008 being a miserably bloated and slow experience. Guess it was because of no Electrolysis and any other refinements in the last two decades. reply bigstrat2003 1 hour agorootparentYep, same. Firefox now is decent, but back in the day it was awful. I remember trying it out early on and immediately going back to IE because Firefox was significantly slower. Chrome was a marked improvement over both IE and Firefox, so it won. reply dismalaf 4 hours agoparentprevUsing an ad blocker (and not paying for a subscription in the case of YouTube) isn't the \"user making their own choices\", it's stealing content. If a creator puts up ads or a paywall, it's because they want to be compensated. You should either respect their wish or simply not view their content. reply godshatter 4 minutes agorootparentAccessing a web page using standard protocols with no authentication and filtering what I want to see of it on my computer is not stealing content. YT might want me to do something else, but I am not bound by their wishes. reply basilgohar 4 hours agorootparentprevI understand this perspective, but I disagree with it. If someone wants to use a public space (i.e., the Internet), then they have accept that technological solutions to annoyances are also part of that. Block it with a subscription if you don't accept this reality. But getting the benefits of a free, global audience doesn't entitle the artist to any means of revenue they choose, including what annoys and harms people. It's like saying you have to walk the long way around to your exhibit through the concessions hall before seeing my display, when someone can just take a shortcut and skip that, and blaming them for doing so. reply carlosjobim 2 hours agorootparentA restaurant is also a public space. But you can't eat for free or behave as you wish there. reply dismalaf 4 hours agorootparentprev> But getting the benefits of a free, global audience The benefit of the audience is literally the ad views (or Premium views). reply asdfasdf1 4 hours agorootparentprevusing an ad blocker is the ONLY option to avoid adds. You can pay evilcorp for a subscription/premium account/whatever and they'll still try to force you to watch 10 minutes of adds for a 1 minute video. Fuck them. We own them nothing. Banksy said it better: People are taking the piss out of you everyday. They butt into your life, take a cheap shot at you and then disappear. They leer at you from tall buildings and make you feel small. They make flippant comments from buses that imply you're not sexy enough and that all the fun is happening somewhere else. They are on TV making your girlfriend feel inadequate. They have access to the most sophisticated technology the world has ever seen and they bully you with it. They are The Advertisers and they are laughing at you. You, however, are forbidden to touch them. Trademarks, intellectual property rights and copyright law mean advertisers can say what they like wherever they like with total impunity. Fuck that. Any advert in a public space that gives you no choice whether you see it or not is yours. It's yours to take, re-arrange and re-use. You can do whatever you like with it. Asking for permission is like asking to keep a rock someone just threw at your head. You owe the companies nothing. Less than nothing, you especially don't owe them any courtesy. They owe you. They have re-arranged the world to put themselves in front of you. They never asked for your permission, don't even start asking for theirs. reply dismalaf 4 hours agorootparent> using an ad blocker is the ONLY option to avoid adds. You can pay evilcorp for a subscription/premium account/whatever and they'll still try to force you to watch 10 minutes of adds for a 1 minute video. Fuck them. We own them nothing. On YouTube? No. I pay for Premium, there's no ads. reply HanClinto 3 hours agorootparentI pay for YouTube Premium. I'm thankful that it exists. I still get sponsored segments in the middle of my videos (from the content creators themselves). I haven't (yet) installed SponsorBlock -- currently, I have no plans to, but I do fast-forward to skip those commercials in the middle of the videos. I pay for Amazon Prime, and they've started showing me preroll ads on my streaming content. I also still get sponsored product recommendations in my search list. I pay for Kagi search. Thankfully, this area is still relatively clean. reply dismalaf 3 hours agorootparentMost of the creators I watch don't have sponsored segments. I do agree, Prime is annoying with their ads, it definitely affects how much I watch on their platform. reply shultays 3 hours agorootparentprevThere is still embedded ads or promotional content or whatever that you can only block with sponsorblock reply Workaccount2 4 hours agoparentprev> it’s almost like punishing users for making the choice to browse the web without ads, A local cafe I go to has a \"pay what you can\" business model. One of the smartest decisions I ever made was to go there and not pay. I seriously don't have to pay for one or sometimes two meals a day. Usually just a free coffee and bagel though. I recommend others to try it too. You can just not pay and they still give you food. I cannot figure out why people still pay them. If they understood their customers, the food would just be free to everyone. But whatever, in the meantime I will eat free. reply wruza 4 hours agorootparentYou forgot to tell another half of this story where this cafe used all sorts of tactics to kill competition and uses semi-related businesses to ensure its dominance. Then they nicely suggested everyone to pay what they can, or else. It's not an innocent local cafe as you paint it. It is a corporate network monster whose win strategy is \"leave no survivors\". reply Workaccount2 4 hours agorootparentAnd rather than stop going to this evil cafe, people just go and don't pay. So as long as you make out your flavor of the month business as \"greedy and evil\" you can paint yourself a moral crusader by going there and taking things for free. How convenient, eh? \"This coffee shop is a terrible place, therefore I will eat there for free everyday in protest!\" reply jraph 3 hours agorootparentThe network effect kinda prevents you from finding coffee at an honest place. (The content is on YouTube and nowhere else) Until this changes and one can choose to go somewhere else, I wouldn't worry too much about the terrible cafe's income, because it is one of the richest entities in the world, it already shouldn't be that rich and powerful, and if it disappeared, it would finally let one go find coffee somewhere else. The other possibility is to stop drinking coffee, of course. Though you can't really do this with everything. reply Workaccount2 3 hours agorootparentYouTube is hardly the only website on the Internet. And besides that, YouTube splits ad revenue 40/60 yt/creator anyway. So I suppose those creators are all in on the scheme too? reply wruza 1 hour agorootparentprevAnd rather than blocking me access, like in “please pay to watch it”, they squiggle and babble incomprehensibly. Note that I’m not freeloading Nebula etc. Your analogy was shallow from the start. Continuing it makes little sense. reply PaulHoule 4 hours agorootparentprevPart of the problem is a lack of a feedback channel that pushes back against the worst tranche of ads. It is one of these situations https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty_Model where you have no \"Voice\". At home we were talking about food ads on Youtube. Sure, once in a while you see an ad for a meal box that is actual food but I see a lot of ads for things like Huel which float in this strange space where it's not \"I used to eat bread and meat and vegetables and now I drink all my meals\" but where it's normal to drink your meals (they pose as if they were trying to persuade you to switch from some other meal replacement), where you have to work just as hard taking supplements every day as you would work lifting weights or not eating junk food -- there's McDonald's and there are ultra-processed foods, but this is ridiculous. (A friend of mine received a huge quantity of 4Patriots dried food from his mom who was sucked in by some ad that claimed it was on sale because they made too much. We got some and the smell when my son made it turned my stomach.) In terms of sponsorships there was the \"Established Titles\" scandal; I am a big fan of Ryan Szymanski who's a world authority on battleships. One day he got bribed to make a video about https://en.wikipedia.org/wiki/Scapa_Flow which was a good reason to talk about battleships and Scotland. Pretty soon he's adding a cringy pitch to all his videos and unfortunately it is so hard to give somebody like the right kind of \"tough love\" which will set him straight, although after the scandal popped most of the people involved went back to remove the junk. reply Workaccount2 4 hours agorootparentYears ago, when it was the dominant player, Ad-Block Plus sought to strike a truce with advertisers, where they would dial back the invasiveness of ads, and ABP would sign off on these and whitelist them. This quickly led to a revolt from ABP users, and the ultimate collapse of the plugin. That is when uBlock was born and become the king. What we have is a positive feedback cycle where creators are forced to resort to worse and worse ads to cover the cost of the ever increasing number of ad-block users. It's just plainly true that every revenue generating ad you block (not necessarily profit generating ad) is an ad that must be fed to someone else to view for you. reply PaulHoule 3 hours agorootparentBad ads just aren't just on the web. I've had a longtime gym habit which sometimes has me in front of the TV around noon where the ads are all for products for people who don't have any money. I remember seeing a series of ads where my first thought was \"anybody except a TV executive or a politician would look at that and say it it's a medicare scam\" and watching the ads for a decade before it got in the news that it really was a scam and people are going to jail. Those ads win an auction to get there, they might be the optimal ads for that slot, but if you want to know why people have low trust in the media and low trust in the government, start there. I watched Tubi a lot last summer, which is in a wonderful honeymoon period, and was watching saturation advertising for P&G products that featured upbeat black people cleaning up (their own messes) with Dawn and Tide. Great, I say. They've got some awareness that they shouldn't run ads that drive viewers away. Maybe targeted ads will be good for television but the specter of https://en.wikipedia.org/wiki/Enshittification haunts the industry. reply ceejayoz 4 hours agorootparentprev\"I Don't Know How To Explain To You That You Should Care About Other People\" https://www.huffpost.com/entry/i-dont-know-how-to-explain-to... reply Workaccount2 4 hours agorootparentWhere is the article titled \"I don't know how to explain that ads (and the \"suckers\" who view them) are what keep the internet running\" reply endemic 1 hour agorootparentSure, I don't mind the ads. The pervasive tracking and data collection and profile building is where I draw the line. Tons and tons of JS churning my browser to sell me stuff. If my adblock eventually causes some sort of economic disaster, so be it. reply cobbaut 3 hours agorootparentprevThe Internet worked fine without ads though. reply Croftengea 4 hours agorootparentprevImagine your local cafe notices and starts feeding you poisoned food instead of asking to pay. reply Workaccount2 4 hours agorootparent>> it’s almost like punishing users for making the choice to browse the web without ads, reply carlosjobim 3 hours agorootparentprevYet hackers would be outside shouting and banging the doors, demanding to be let in to have the free poison, writing five hundred miles of comments about why they should not pay. reply ToucanLoucan 4 hours agorootparentprevYou are the exact type of person who ruins everything good in our society and burns out everyone who tries to do good for others because of your bottomless selfishness. And no, this is not a personal attack. This is an evaluation of your character as stated in your own comment. You and people like you are everything wrong with the modern world. People like you are why we have the most productive economy in human history and still have people starving to death next to grocery stores full of food. People like you are why people work 60 hours per week and still can barely afford to live. People like you built this awful, inhumane system that we're all forced to live under that exploits us at every single turn because there is no law against doing so, and so you do it. You put the screws to every last thing in your life to get maximum value returned for minimum effort. I genuinely do not use the word hate lightly, but I would use it here. reply staindk 4 hours agorootparentThe free coffee story is clearly just an analogy to the adblock thing. reply ToucanLoucan 4 hours agorootparentThat's possible, but it doesn't sound like an analogy to me, and I've known enough selfish assholes in my life to absolutely be able to picture this as a real thing that's currently happening. reply Workaccount2 4 hours agorootparentgestures towards the masses of shameless ad-blocking internet users Even here on HN, the first thing people do when a paywalled article is posted is provide the archive.ph bypass. reply taylodl 1 hour agoparentprev> it’s almost like punishing users for making the choice to browse the web without ads AKA depriving content creators of their revenue. If you're saying their content isn't good enough to pay for directly, and isn't good enough to endure ads in order to engage, then why are you trying to consume it? Look elsewhere. > or without the surveillance mechanisms that come with them I agree with this depending on what you mean by \"surveillance.\" There's a minimum amount of \"surveillance\" required to measure ad penetration and effectiveness and essentially provide assurance to advertisers that they aren't getting scammed. There's a whole other level of \"surveillance\" where the ad network (usually Google) is building a dossier on all your interests and every site you've ever visited. Some of that information enables targeted advertising, but you should always retain the right to opt-out, and see all the data that's been collected on you and edit it. You should also be able to opt-in to that data being sold and getting a cut of the proceeds, should you so desire. I wouldn't, but I could imagine some people would. Bottom line - people gotta make money to eat and oftentimes they're not giving away content for free. If you don't want to pay for it - that's your choice as a user: pay and consume or don't pay and move on. Calling on hackers to figure out a way to steal it may not have a future that works out to your liking. reply internet_points 5 hours agoprevIt's the closest we have to a browser not controlled by the corporate giants. Sometimes Mozilla makes unpopular choices and people raise a stink about it, but we do that because we hold them to a higher standard. With Microsoft and Google, we just expect them to Do More Evil, with Mozilla we expect Good and will complain loudly when they fail to uphold our principles, and we recommend Firefox because we feel like it is possible to expect Good from them. reply input_sh 5 hours agoparentMore like \"we'll complain all the time regardless of what they do by repeating the same talking points over and over again\". > How much do they pay the CEO? Why aren't they exploring other funding options? At the same time, why are they \"wasting resoures\" working on other things!? They should exclusively work on Firefox! > ...and that's why I stick to this Chromium fork with its own digital advertising service and its own cryptocurrency, but you can easily switch it off! reply mossTechnician 5 hours agorootparentOf all the ways to critique Brave, consider Mozilla's exploration of \"other funding options\" has recently been digital advertising. They purchased two advertising companies - Anonym[0] and FakeSpot - and have integrated FakeSpot directly into Firefox. Mozilla has an ad sales division [1]. Mozilla even added extra telemetry just for advertisers[2]. [0] https://www.theregister.com/2024/06/18/mozilla_buys_anonym_b... [1] https://www.mozilla.org/en-US/advertising/formats/ [2] https://www.privacyguides.org/articles/2024/07/14/mozilla-di... reply diggan 5 hours agorootparentprevYou know parent made a good point when comments come in attacking points parent didn't even mention or brought up. reply woolion 3 hours agorootparentprevI almost never use Chrome-based browsers, but recently was forced because debug points were simply not working on Firefox. You can strawman all you want, there are unfortunately technical points where Google is abusing its position to force its standards, but the primary architects of Firefox downfall is Mozilla. For the record, I used a Firefox phone for many years (and yes it did cause me a lot of problems), and remember vividly when they announced a luxury Firefox phone about one week before killing the project. reply pessimizer 2 hours agorootparentprevSo weird to paint consistency as a vice. \"Talking points\" is from the same land as \"gotcha questions.\" \"Talking points\" are the points that people are talking about that you'd prefer not to talk about because you don't have good answers for. So you pretend like repeating an unanswered question is an dirty underhanded plot. > How much do they pay the CEO? Why aren't they exploring other funding options? At the same time, why are they \"wasting resoures\" working on other things!? They should exclusively work on Firefox! This isn't a quote. Don't make up quotes. This is you putting words in people's mouths, and choosing the ones that allow you to reply with something about Brave. At the same time, you're excusing Firefox for doing things because Brave does similar things. The people switching to for-profit Brave from Firefox would have prefer a non-profit, user-focused Firefox, but have been pushed to the point where they don't see any moral difference between the two, so they might as well experiment. When Firefox was innovating, it was the founder of Brave that was running it. Most Firefox haters use Firefox. They just wish that it wasn't so bad, that it wasn't so much torture to put it into a usable state, and that the developers weren't actively fighting the users to keep them from putting it in that state, rather than centering on the users. They largely blame this on the company, Google, who subsidizes Firefox while competing with it. And on the company, Mozilla, that sucks all of that subsidy up in salaries, while seemingly neglecting the browser. reply pveierland 5 hours agoparentprevMozilla does plenty of really useful things! Super happy with Firefox as my primary browser. Shout-out to MDN as well for being an excellent reference on all things web: https://developer.mozilla.org/en-US/ reply kokada 5 hours agoparentprevYes, pretty much. While I don't concur with Mozilla 100% of the time, it is still the only major browser that I can have control (e.g.: by still having Manifest V2 extensions available). Also most of controversial choices in Firefox can be disabled or changed in `about:config`. reply scarface_74 5 hours agorootparentWhat about the choice not to optimize for battery efficiency on my Mac? reply julienwaj 5 hours agorootparentCan you please elaborate on that? reply scarface_74 4 hours agorootparentNeither Firefox nor Chrome optimize for battery efficiency like Safari does on Macs or Edge does for Windows. I’m not trying to be the “just Google it” guy without citations. But I couldn’t find a definitive citation - just general discussions and some YouTube videos including earlier discussions on HN. I searched for “firefox vs safari battery mac” and the same for Edge on Windows. reply lern_too_spel 6 minutes agorootparentChrome doesn't optimize for battery efficiency like Safari on Macs. It optimizes better than Safari. https://birchtree.me/blog/everyone-says-chrome-devastates-ma... reply Klonoar 4 hours agorootparentprevThey may be referring to the fact that Firefox is probably the worst on battery of the 3 main browsers when used on macOS. Safari does admittedly set a very high bar though, and only cares about 1-2 platforms at most. reply baxtr 5 hours agoparentprevI actually really like Safari… sometimes tabs sync across devices is buggy, reloads a lot. But other than that I’m quite content. reply politelemon 57 minutes agorootparentTo continue GP's comment, > With Microsoft and Google, we just expect them to Do More Evil, with Mozilla we expect Good And with Safari, a loathsome browser that's intent on recreating the IE6 conditions of yore, we give it a free pass. reply infinityplus1 4 hours agorootparentprevI tried switching to Safari 2-3 years back after getting a new M1 Air . After using it for a few hours, websites would just stop working and only fix was to restart the browser. After a few times, I gave up and went back to Firefox. reply p_ing 1 hour agorootparentprevI find the UI atrocious and primitive. The extensions are ManifestV3 alike and worse yet, pollute /Applications (why?!). I don't particular find Safari fast, it uses just as much memory as any other browser, and all the claims about power efficiency are never backed by any numbers, just like /r/macos parroting \"macOS good cus UNIX\" while not understanding there have been plenty of shit UNIX distributions. Plus the incompatibility with various sites... Just sticking with FF. I can certainly appreciate an OS-integrated browser, though. It makes life simpler for users and if you have the full Apple ecosystem, the tab sync is useful. reply segasaturn 5 hours agorootparentprevI find Safari on iOS to be nice, and Safari on macOS to be horrifically slow and inadequate, even on the newest M-series processors. It's like two different worlds, you can really tell that all of the engineering time is going into iOS because that's where all the money is at. reply ethbr1 4 hours agorootparentI heard someone recently describe Apple as a great hardware company with a few software people. Rings true! Most of the iOS / MacOS software issues are things that more bodies could fix. reply segasaturn 4 hours agorootparentIndeed, although most of the real work on the hardware side is done by TSMC on the processors, and Apple just does a good job wrapping that piece of silicon into a shiny glass and metal body. Apple's real superpower is getting people to spend money inside their ecosystem. They've essentially turned into a finance corporation pretending to be a tech company. reply ethbr1 2 hours agorootparentI'd strongly disagree. Apple designs their own processors (now), specs/sources their components (e.g. screens), and then does all the integration engineering. That's the bulk of device work. Which isn't to say that semi manufacturing isn't hard, but is to say there's a lot of effort between a chip and a device. reply frizlab 4 hours agorootparentprevI use Safari on macOS and don’t find it particularly slow reply frizlab 4 hours agorootparentprevI like it too. I use the Add to Dock feature a lot! E.g. for slack, which does not have a native app, I use the website instead. reply jampekka 5 hours agorootparentprev> I actually really like Safari… I guess you don't do web dev? reply redman25 5 hours agorootparentI do web dev and prefer safari. It’s less power hungry on a laptop. If you develop for the lowest common denominator, every other browser just works. There’s something to be said for adding _less_ features to web browsers. A simple web is a web where open source solutions can compete with chrome. It helps avoid a browser monoculture. reply dartos 5 hours agorootparentYeah but we’re not in a simple web. Safari isn’t trying to make it simple for you, they just use it to keep you in their walled garden. PWAs are a great example of this. The general idea was even a product of the Jobs era of Apple, before the App Store. Safari and iOS’s poor support of PWAs is exactly a result of Apple wanting to prevent app distribution channels other than their App Store. Choosing safari is choosing a more closed web, where missing standards means that you, as a safari user, are unable to access certain features or apps that Apple doesn’t want you to access. reply mrweasel 4 hours agorootparentI get that Apple shouldn't be allowed to dictate which features belong on the web, but you're just letting Google to it instead if you opt to use Chrome. Maybe I don't care about PWAs (which I don't), maybe I don't feel like the majority of APIs introduced lately belongs in the browser. There's very little of what you should be able to do on the web that you could not do 10 years ago. Yes, flexbox is awesome, let's have that, so is the dialog tag. WebGL, Blutooth, USB, device memory, battery status... No, the browser doesn't need to support that. reply gjsman-1000 3 hours agorootparentprev> exactly a result of Apple wanting to prevent app distribution channels other than their App Store Nah, it's because PWAs were a standard created by Google, with Google being the primary market driver, solely with the interest of advancing Google's own interests (both in undermining Apple, and making lower-end devices more usable in developing markets). Don't think Google invented PWAs, or heavily pushed them, out of some charity. Notice also that as the ultra-cheap phones (~$100) have become more powerful, and as Apple refused to take the bait, that Google's efforts behind PWA have mostly ended. The same goes for RCS, even though it was initially made by a neutral vendor forum. Google became the heavy pusher of RCS, not just for the sake of Android, but because they had carrier deals to use Google's own infrastructure (Jibe) for RCS, and forcing Apple to accept and integrate with their own infrastructure is a better position to be in. This is also, let's be clear, not the first time that Google has tried an \"open\" standard to advance their interests and bludgeon competition. AMP is what happens when the standard catastrophically fails. reply jamespo 4 hours agorootparentprevMissing standards like Manifest V3 that everyone was crying out for? reply mrweasel 4 hours agorootparentprevProbably depends on how you do web development. I don't like Chrome for web development, but others claim it's better than Firefox and Safari. I normally use Firefox, but would probably pick Safari over Chrome, if nothing else to avoid having to install yet another browser. We all know that the best web development tools ever to be created was those that shipped with Opera when they still used Presto. reply baxtr 5 hours agorootparentprevThat I do in Chrome I admit :) but for my personal browsing I use safari reply anthk 5 hours agoparentprevIcecat it's far more free than Firefox. reply Idesmi 2 hours agorootparentIcecat is Firefox. reply ekianjo 4 hours agoparentprev> Sometimes Mozilla makes unpopular choices Sometimes? They tend to hit the mark of bad decisions more often than not reply ziddoap 4 hours agorootparentPeople just remember the shitty decisions more vividly and for longer than people remember the dozens of good decisions made in between. Most good decisions don't get a full press cycle (because they are boring). reply mossTechnician 4 hours agorootparentMozilla's brand identity is tethered to specific moral prescriptions[0] that their products are supposed to abide by. People sold on that identity are bound to care. [0] https://www.mozilla.org/en-US/about/manifesto/ reply ziddoap 4 hours agorootparentThis seems unrelated to whether or not Mozilla makes bad decisions more often than not. I'm talking about frequency, you're talking about severity. People don't remember the 1000 times you did something correctly. reply scarface_74 5 hours agoparentprevMost of Firefox’s revenue comes from Google…. reply KaiserPro 5 hours agoprevI have been using mozilla for _years_ it got shit, then better, then shit, and now its close enough. The thing I _Love_ is container tabs. I can isolate empires by using container tabs to sandbox cookies and other web state. This means that ebay doesn't change my adverts to the last thing I searched on every site, and autoplay embedded youtube doesn't fuck up my video recommendations. It means I can hide my work gmail from my home, and separate search histories (although thats less relevant now with AI.) lastly, being able to scroll left and right on my tabs, rather than new ones being unaccesable is great. reply Vinnl 5 hours agoparentAnd for those who do actually feel they want to separate their extensions and passwords and such as well, there's a Profiles revamp coming up that's looking really good in Nightly: https://connect.mozilla.org/t5/discussions/here-s-what-we-re... But yes, people should learn about Multi-Account Containers if they haven't, yet. It's a killer feature that no other browser has. This is the extension to enable the UI for it: https://addons.mozilla.org/firefox/addon/multi-account-conta... reply asabla 4 hours agorootparent> there's a Profiles revamp coming up that's looking really good in Nightly Oh wow! I totally missed this. Thank for sharing! I've been using multiple browsers for as long as I can remember. But always liked Firefox ocer the others. Especially now with container tabs. And the only thing I keep wishing for, has been a better experience with profile management, but also running the browser in different profiles. I'm really looking forward for these updates reply WorldMaker 3 hours agorootparentI've been using the silly hack of using two versions of Firefox side-by-side (so, multiple browsers but they are both Firefox today), one which is Default in the OS and focuses on a single profile and Container Tab management. The other launches into the ProfileManager at startup to choose a Profile and doesn't pick up random links because it isn't Default. Better Profile Management tools may be nice to see. Maybe I won't need dueling builds of Firefox. Or maybe I'll keep it, we'll see. reply pxoe 4 hours agorootparentprevFinally, it only took them 10 years to get around to updating that decades old UI. Wonder which other decade old UI parts are they gonna tackle next? ooh, will they finally do something about Library and the whole bookmarks/history menu/sidebar/window mess? It's a little insane how so much time has passed and so many versions were released, and some interface stuff still remains unpolished and disparate. Firefox simply can't get it together on that front. For tab containers, maybe there's a \"good reason\" that no other browser has that feature, cause it is confusing both as a concept and in use, and doesn't separate the rest of the stuff (or even the stuff in intends to separate when it's cumbersome and peculiar to use). Like, shared history, or inability to have separate extensions, defeats many of the purposes people use profiles for - which is an actual complete separation of things. reply vianneychevalie 3 hours agorootparentAs a consultant, switching between my many clients, testing, and home accounts is simply Alt+F+B+Arrow down (\"Open new container tab\"), all within the same UI, in the same window, with colored tabs, with the same extensions, and same password manager. I've been in situations needing up to half a dozen different Microsoft accounts (multiple Teams clients in Firefox, for instance), other browsers haven't solved this daily use-case for me. It's an easier account management tool. reply greggyb 1 hour agoparentprevI have 4 Microsoft accounts I use regularly for work. I also do some consulting and often end up with credentials provisioned at a client (don't get me started on this). It is so convenient to have container tabs. All my extensions are available in new containers, unlike multiple Chromium profiles (or Firefox profiles). Container tabs also pair very well with Simple Tab Groups, which allow you to pin a container to a group, so that everything for one account ends up in one place. reply magicmicah85 5 hours agoparentprevI'd been using Firefox for my work device for years but I only discovered containers and how awesome they are. My company was acquired and we still use microsoft accounts for different purposes. Jira works with this account, but sharepoint works with that account. Can't be logged in with the same azure account at the same time, but with containers, I can. It's great. reply prmoustache 4 hours agorootparentIt is really useful to log on different aws account at the same time too. reply _zamorano_ 1 hour agoparentprevI agree on the desktop version (Wi",
    "originSummary": [
      "Firefox is praised for its superior tab management, built-in Pocket feature for saving links, and a privacy-focused email relay, making it a strong alternative to Chrome. - Additional features like a user-friendly screenshot tool, a ChatGPT button, Picture-in-Picture, customizable search options, and smooth scrolling enhance the browsing experience. - Although Firefox lacks Chrome's web app feature, its thoughtful design and reduced resource demands make it a preferred choice for some users."
    ],
    "commentSummary": [
      "Firefox users face challenges from platforms like YouTube, which may intentionally degrade the experience for non-Google browsers or users employing adblockers. - This trend raises concerns about user autonomy, as it penalizes those opting for an ad-free and surveillance-free web experience. - Firefox offers unique features, such as container tabs, which enhance privacy and usability, making it a favored choice for users seeking independence from major corporate-controlled browsers."
    ],
    "points": 480,
    "commentCount": 392,
    "retryCount": 0,
    "time": 1736854678
  },
  {
    "id": 42687932,
    "title": "Sonos CEO steps down after app update debacle",
    "originLink": "https://www.reuters.com/business/retail-consumer/sonos-ceo-patrick-spence-steps-down-after-app-update-debacle-2025-01-13/",
    "originBody": "reuters.com#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}Please enable JS and disable any ad blockervar dd={'rt':'c','cid':'AHrlqAAAAAMAl5pnFgxguYcArMi08A==','hsh':'2013457ADA70C67D6A4123E0A76873','t':'bv','s':46743,'e':'97abffb06feaf1774bc6926350dbfe2303755360fa852007a9f276482c8afb37','host':'geo.captcha-delivery.com','cookie':'qx37WficR5b98NKukCh5Ozoy0XjPDW~3EN653ha4rkvM~eRW9sI_qbwr3DmKhHw2HemzW5gG3bK_GBkO~T4X~L_y~DNaB2b36CAgANRN~yExPwnKkT_JbnGnC38D7NKH'}",
    "commentLink": "https://news.ycombinator.com/item?id=42687932",
    "commentBody": "Sonos CEO steps down after app update debacle (reuters.com)409 points by saaaaaam 23 hours agohidepastfavorite493 comments crooked-v 22 hours agoIt's less the app, more the business decision to tell people who had spent thousands and thousands of dollars on elaborate sound systems to go throw it all in the trash and start over, all at once. Even Apple has never been that bad. They drop support for things over time but even their roughest transitions (x86, Apple Silicon) have come with extensive day 1 support for previous functionality. reply schappim 21 hours agoparent> throw it all in the trash and start over People will think what you’re saying is hyperbole; however, I was on a walk with the family, and I saw a Sonos speaker in the trash. It looked like new and a fairly recent model. I lugged it home, and it was a $US500 Sonos Play:5 speaker system [1]. Once home, I plugged it in, and it powered up. I tried to pair it with my iPhone using the new Sonos app, and it didn’t work (the app never found the speaker). I then tried the same again using my development Android device, and it instantly worked! Once it was set up with the Android app, I could access it via the iPhone version of the app. I can only imagine some iPhone owner literally threw it in the trash because he couldn’t get the iOS app to work. Bonkers… [1] https://files.littlebird.com.au/pb-BfEVPbWlDe-hkxfK0.png reply dmazzoni 15 hours agorootparentI have some old Sonos speakers that have been gathering dust for a while. I decided to sell them because they still have some value but I don't really want them, especially with what the company has done recently. However, I wanted to set them up again to make sure they work. I spent hours trying to get them to set up again with no luck. I'm sure this is exactly what other users are experiencing. The old app was so nice and reliable. I don't have an opinion on the new app because I just literally can't get it to connect. And I know they're not dead. One has an audio-in jack and still plays. It works great. There's no reason any of them shouldn't be fine. The only thing that changed was the app. I just want to get them set up so I can sell them on Marketplace for a good price as fully working. reply jwr 7 hours agorootparentOld Sonos hardware works great with Roon. I am very annoyed at the planned obsolescence that Sonos has been pushing for a while now. I stopped buying new Sonos hardware, I'm still using all my old hardware, just not with the terrible Sonos apps, but with Roon. I also took to aggressively repairing very old hardware that was actually failing (ZP80 players), because of the Sonos planned obsolescence policy. Recapping the PSU did the job, and I intend to keep them going for as long as I possibly can. reply CamelCaseName 9 hours agorootparentprevIt's insane to think of the collective number of hours wasted on this. Yet people will still buy Sonos! reply Spivak 4 hours agorootparentAre there any alternatives (for multi-speaker synced audio) since the Chromecast Audio was discontinued? reply applied_heat 2 hours agorootparentI’m still using chromecast audio they work great! reply petepete 10 hours agorootparentprevFunnily enough I bought a Sub Mini last year and had to borrow an iPad to add it to my system because it failed on Android, even when being walked through the process by someone from Sonos support. reply aksss 20 hours agorootparentprevEEVBlog had a video about mod'ing a dumpster-found Sonos Play 5 into a cloud-free working system. EDIT: Whoops, here's the link: https://www.youtube.com/watch?v=IeIk-4ItQ70 They (Sonos) basically willfully attempted to brick their consumer devices, and since many sonos customers were prosumer enthusiasts but not technical (hw or sw) it really did signal EOL for the products. Bananas. I still have a my Play1/3/5 infrastructure operating through Home Assistant and AirBridge that turns them into Airplay devices. It's not perfect but still gives them utility. Considering how much they f'n cost.. reply schappim 20 hours agorootparentPerfect! It turns out this was a Sonos Play 5 too[1], although mine is seems to be a newer Model S100! Funnily enough, I own an electronics company and Dave is just down the road :-) [1] https://files.littlebird.com.au/pb-BfEVPbWlDe-hkxfK0.png reply isatty 21 hours agoparentprevAt the risk of defending a megacorp: Apple has always been great about supporting their devices for a long time. reply HanClinto 4 hours agorootparentIt boggles my mind that I'm not able to download the oldest released version of software that was compatible with my old version of iOS. My iPad is too old to upgrade to the new OS, but yet no software is available for it in the store, because all new apps are encouraged to be re-released for the newest version of the OS. My device is completely frozen in time from whatever software was installed on it when it went out of support. reply Ntrails 1 hour agorootparentI have an old iphone somewhere and I also experienced this frustration. I appreciate you're not compatible with my ios - so give me the one that was. I don't care about whatever features you've added However, I do suspect app developers don't want to be on the hook for supporting old versions, should they continue to serve things in need of security fixes etc etc. I don't entirely attribute it to malice. reply philistine 1 hour agorootparentprevWhat are you talking about? You can absolutely download the last compatible version of an app: https://appleinsider.com/inside/ios/tips/how-to-get-apps-for... reply HanClinto 49 minutes agorootparentThanks for the link! I wasn't aware of some of these workarounds. Your link is very helpful, but also notes some of the limitations. Namely, this doesn't work if the software has been purged due to not being updated recently, and it doesn't really work to find new-to-me software (that I haven't purchased previously). Even if it's technically possible to reinstall software that I've previously purchased, it is very limited in its ability to install new-to-me software. reply troad 16 hours agorootparentprevBy phone standards, yes. By computer standards, absolutely not. reply cocacola1 15 hours agorootparentI dunno, I ran my mid-2012 MBP until ~October 2021. In that time, I got it serviced once for a screen issue that they fixed under some program (after the warranty period). I think it got security patches as recently as then. That seemed like a solid run to me. reply troad 14 hours agorootparentThe last new OS that a mid-2012 MBP received was High Sierra, in 2017. That was the OS that added warnings about the impending breakage of all existing 32-bit apps (!), you may recall. My own MBP from the same era as yours succumbed to a logic board long before then, and I replaced it with a late 2016 MBP, which came with a touch bar + butterfly keyboard, had terrible performance, stopped receiving updates after Monterey (2021), no longer receives security updates, and (obviously) can't run modern ARM-based Mac software. (Incidentally, it was also the single most expensive computer I ever bought, even to date!) Not a very solid run, I'd say. Personal anecdotes aside, I don't think it's too disputable that Mac has never taken backwards compatibility or computer longevity anywhere as seriously as Windows or Linux have. reply cocacola1 14 hours agorootparentI had the Retina, which went up to Catalina (which is the last major OS mine had), but it also got security patches up until 2022. I upgraded to the M1 MBP when they were released, but last I tried, my old MBP still booted up. Ah, yeah, I do recall the horror stories about the butterfly keyboard ones. Sorry to hear it. I was able to skip that entire generation because mine ran like a champ. > Personal anecdotes aside, I don't think it's too disputable that Mac has never taken backwards compatibility or computer longevity anywhere as seriously as Windows or Linux have. I think this is probably true. Unfortunately, the reason I moved to MacBook's in the first place was because I had a terrible run of Windows PCs & laptops. I think I had 4 or so between 2002 and 2012, but only 1 between 2012 and 2021. I suppose that's why I'm partial to Macs. reply troad 14 hours agorootparentI hear you! You had a great device through some of the best years of OS X. I wasn't as lucky, but that was a big impetus for eventually pushing me to Linux, where I'm very content with my combo of a Mac-ish DE and actually being in control of my device. reply cocacola1 11 hours agorootparentYeah, if I ever were to switch OS’s, it’d probably be to Linux thanks to it being more Maclike. Could never go back to Windows at this point. reply adamors 9 hours agorootparentprevWhat are computer standards actually? I have two macbook pros from 2015 running still, perfectly fine for regular \"computer\" usage (non-development). reply mixermachine 9 hours agorootparentYour Macbooks no longer receive (security) updates. They already have missed three MacOS releases: https://eshop.macsales.com/guides/Mac_OS_X_Compatibility Please don't do anything security critical with them. Other OS providers do support the devices longer. At least for core OS updates. reply philistine 1 hour agorootparent> Other OS providers do support the devices longer. At least for core OS updates. Microsoft is abandoning 63% of its user base later this year, with an untold amount of those users unable to update to Windows 11 due to the requirements of a processor released after 2017. Keep in mind that with how the average Windows user buys their device, it's common to see brand new computers with two years old CPUs. With the pandemic having forced everyone to scrape the bottom of the barrel for laptops, there are so many people getting bitten by Microsoft right now. reply davweb 8 hours agorootparentprevThe last security update to Monterey was in July 2024. 9 years of OS support seems pretty good to me. reply msoad 9 hours agorootparentprevNot sure why you say this. I know multiple 10+ yo MacBooks still operation. reply coro_1 19 hours agorootparentprevUsually yeah. Though it sure appears that a lot of apps requiring a recent iOS lately don't need too. It's curious where that push is coming from, if they're all individual company choices, made at once, for the first time ever. reply rogerrogerr 19 hours agorootparentIt’s relatively easy to justify supporting only one or two major versions back if you’re writing an iOS app. There are stats out there on how many active devices are on what version, it’s pretty striking. Especially compared to Android. reply coro_1 19 hours agorootparentAgreed of course. Though currently iOS 16 is the standard and that goes back about 2.5 years. Which is sort of a shift from many major apps supporting an iOS dating back 4-5 years. reply marcellus23 18 hours agorootparentWhere are you getting these numbers from? Do you have stats to back them up? When I worked as an app developer we would only support back 2 or 3 versions, and that was 5 years ago. Anecdotally I have not noticed a shift to only supporting more recent OSes. reply pcl 18 hours agorootparentpreviOS 16 is supported on devices back to iPhone 8, which came out in September 2017. That’s seven and a half years ago. Apple has done a good job of supporting old devices with new OS releases; they also subset old OS’s. That seems like a fair trade. reply NoPicklez 19 hours agoparentprevThat sounds a bit over the top I have two Play 5's that I have had for a decade and they're still currently set up working completely fine on an Apple device. That's a speaker that was released 16 years ago and still works through the Sonos app, still allows me to play Spotify, still works natively with the Playbar to watch movies and TV. That sounds pretty good to me. If people want to throw out their hardware and buy new that's fine, but they haven't needed to throw out their Play 5's. If I was still using an Apple iPhone from 2009 you can bet it would be a terrible experience reply mrWiz 16 hours agorootparentThere was a time when Sonos really tried to EOL \"Gen 1\" devices, including the Play 5. There was such a backlash that they backpedaled a bit, but Gen 1 devices lost the ability to interact with Gen 2 and later devices and you need to use a different app for them. reply NoPicklez 16 hours agorootparentGen 1 devices included among their product line was really only the Play 5 (Gen 1). Every other device, Play 1, Play 5 (Gen 2), AMP, Play 3, Playbar, Playbase, Sub all of these products were made compatible with both S1 & S2 apps. Outside of the Play 5 (Gen 1) there weren't really many other products people were buying that were left out. reply exodust 11 hours agorootparentI'm a Sonos hater. I will never ever buy a speaker again that comes pre-bricked unless you \"activate it\". I will never ever buy a speaker again that demands I enable precise location in order to \"discover\" the speaker on my network. Approximate location is not enough. Sonos demands your home address before it permits you to use your speaker. Even aux line-in. I will never ever buy a speaker again that requires I log-in before I can set certain things unrelated to online use, such as the volume limiter. I will never ever buy a speaker again that has an obscene amount of delay even when using the aux line-in. And yes I toggled the setting in the app to \"reduce delay\" and followed all the steps to reduce the delay as much as possible, but the delay was still there. Forget about using a Play5 gen2 for home theatre or anywhere you need low-latency. Rant over! reply jjcob 8 hours agorootparentRequiring \"precise location\" is probably necessary because it wants to use Bluetooth to discover speakers. Any app that uses direct bluetooth could theoretically get your precise location from a Bluetooth geotag, so Apple requires apps to get \"precise location\" permission before being allowed to use bluetooth. reply exodust 37 minutes agorootparentNot correct, not even close. reply pcchristie 13 hours agorootparentprevKind of dishonest to compare a speaker to an iPhone isn't it? reply ssl-3 20 hours agoparentprev2 out of 3 of my Sonos devices were rendered useless by their policies. One day they were functional and working, and the next day they were not. One of these was a fancy, very expensive jog-wheel remote that I rather liked (every one of these in use all got absolutely bricked, deliberately, in a bullshit move), and the other was a Sonos Bridge (a wireless access point) that they didn't deem worthy of working with new software (even though that was also bullshit). The remaining device has mechanical issues (as old speakers sometimes do). This one is disappointing, but at least it isn't irrational. reply flybrand 16 hours agorootparentwe moved into a home that had wired speakers installed in every room all to a central Sonos enabled device - it is all old. It worked perfectly until this. Funny thing is, we thought it was silly when we moved in - then we grew to love it. Now I hate them! reply matwood 8 hours agoparentprev> It's less the app, more the business decision I like to reverse decisions further back. The connected speaker is basically a commodity at this point. Sonos does have some nice features, but they are very expensive. I think the ceo saw the down sales and lack of new products and rushed out the app hoping it would work and boost sales. Obviously it was a disaster, but I’m not sure if sticking to the status quo would have led to any different outcome in sales. reply Closi 12 hours agoparentprev> It's less the app, more the business decision to tell people who had spent thousands and thousands of dollars on elaborate sound systems to go throw it all in the trash and start over, all at once. As a Sonos purchaser, ironically product longevity was the reason I bought so much of their stuff! While other similar systems would drop support for old devices eventually, I could be confident with Sonos that I was investing in stuff that would continue to work. … until now! I’ve started to lose confidence. Which is a shame - I’m moving into a new house and wanting a sub, but now questioning if that’s a sensible decision given I don’t know how long my older speakers will work for now they are going glitchy. Real shame! reply alkonaut 10 hours agoparentprev> It's less the app, more the business decision to tell people who had spent thousands and thousands of dollars on elaborate sound systems to go throw it all in the trash and start over, all at once. What does this refer to? Did Sonos drop support for products? When was this, which products? reply philjohn 5 hours agoparentprevIf this is the thing YEARS ago, they backtracked and they still work via the S1 app. reply mandibles 20 hours agoparentprevAre there any projects working on open protocols for digital audio distribution? Any chance manufacturers opt into open protocols? reply paradox460 19 hours agorootparentThere's a bunch of stuff built around the old Logitech media server system, with open source implementations running on esp32 and raspberry pi, as well as a slew of other devices reply noman-land 1 hour agorootparentGot any links you can share? reply kjkjadksj 22 hours agoparentprevWell that is basically the model of the home stereo today. People don’t realize sound was solved decades ago. How they could get the same stereo their grandfather could have ordered from the sears catalog and some cabinets from that sears catalog and that would be better sound than they are capable of ever perceiving, and how it would last them their entire life on that one stereo and probably the lives of multiple generations of family members. With IO that has always been a standard and always will be a standard. And a stereo like this isn’t even terribly expensive. A couple hundred up front for never having to make another home audio equipment purchase in your life is some serious savings. Instead they are sold soundbars and other crap tiny speakers that are not built to last, and might use specific io to connect over open standards that have been around for decades. They end up spending quite a lot more money for a shit experience that they are none the wiser that there are even alternatives to, without becoming audiophiles themselves consuming hundreds of pages of relevant media in that niche. What a cash cow of an industry. reply jnwatson 21 hours agorootparentI've been dabbling in Hifi for most of my life, a hobby inherited from my father. I have some awareness of consumer Hifi over the last 50 years. Speaker and amplifier design are vastly better than even 15 years ago, partially because of better engineering and mostly because of advances in electronics. An entry level receiver today would wipe the floor with consumer level equipment from the 80s. Still, traditional Hifi is dying to the \"crap tiny speaker\" folks. The company that owns Denon and Marantz may go out business this year. It is ironic because traditional Hifi is in an amazing place in terms of value. I recently bought a budget ( The company that owns Denon and Marantz may go out business this year. Oh man. I guess I better stock up on the latest Marantz before the go out of business. The last one I had was my dad's and it lasted 50 years. Actually, it still works, it just requires you to manually power it on. reply kuschku 17 hours agorootparentprev> Speaker and amplifier design are vastly better than even 15 years ago Let's break this down into the components: Speaker drivers: very little change Speaker chassis design: still changing, last major change was improved computational modeling Amplifier: Class D was the last major change, not much since DSP: Still evolving, getting better every day AV Receiver control boards: Standards are changing every day, whether that's new HDMI standards, new bluetooth versions, or new AirPlay/Chromecast protocols. TL;DR: Buy old speakers and a new receiver/amp. reply pcchristie 13 hours agorootparentOr buy a great, \"dumb\" amp and a modern Streamer (e.g. Wiim) as the best way to minimise waste when standards inevitably evolve. reply alkonaut 9 hours agorootparentNeeding cables between a \"streamer\" box and my amp, and then cables from the amp to the speaker(s) already makes it a whole different category of gadget from Sonos. The key thing Sonos sells is the single power cable setup. Wiim does sell an amp model that removes one of the steps. That's probably the one I'd go for if I accepted speaker cables. Less waste reduction BUT at least you don't have the separate amp volume knob and power switch to worry about. reply Terr_ 14 hours agorootparentprev> Still, traditional Hifi is dying to the \"crap tiny speaker\" folks. I wonder if it also ties into living situations and customers that are in a separate house. With my apartment-situation, I'm always using a headset (or bluetooth headphones.) Perhaps not crap tiny speakers, but not so big that making them good takes as much effort. reply stetrain 21 hours agorootparentprevWell one of those options lets me click a button on the phone in my pocket and play music across multiple rooms without running any wires between rooms. And similarly supports surround-sound audio without running wires around or inside walls. I appreciate the value in a basic stereo system but there are some major differences in functionality to the end user. reply xp84 21 hours agorootparentI'd point out that all that was needed to add that capability to a 1970 stereo is one of these devices: https://www.sonos.com/en-us/shop/port Although I laughed out loud that they're asking $450 for that little box. That's pretty cheeky. The BOM on that must be $15. Margin level: Apple! I wonder if they make it $450 to discourage doing just what I'm describing. To make people consider that for that kind of money they could buy one decent Sonos speaker and \"simplify.\" Even though the Sonos speaker won't have anywhere near the sound quality or longevity of a 40-year-old stereo amp and speakers. reply ssl-3 20 hours agorootparentSort-of. Neither a Sonos Port nor something like an Alexa Echo Dot nor the long-discontinued Chromecast Audio can awaken my stereo (whether from 1955 or 2025), select the appropriate input, and allow me to start playing music from my phone. A Sonos speaker does allow that, though. And so might a modern sound bar when combined with things like CEC and a regular-ass $25 HDMI Chromecast. reply xp84 19 hours agorootparentThe Sonos Port claims to be able to trigger your amp to turn on, though I don't know how it works. It's called a \"12v trigger.\" Quick searching mostly found people asking on Reddit how the heck they could use it and mostly getting \"most hardware doesn't support it.\" I did find this interesting comment, though: > You can get a secondhand Sonos Connect (Gen 2) for about $100 these days; they are the predecessor of the Port and are functionally the same for your purposes. Also if I wanted to make a product like the Connect/Port I think I would spend another $3 in materials to add both an IR blaster (like the Harmony hub has -- it's so powerful it bounces off the walls perfectly well even to devices on different shelves) for amps with remotes, and to also offer as a separate purchase, a simple relay switch module for old stereos that don't have remotes -- they could be left on and have their power controlled by the Sonos. As far as I know that's not a thing with any Sonos or competing product, though. reply kuschku 17 hours agorootparent> though I don't know how it works. It's called a \"12v trigger.\" THX introduced the trigger port to allow one amp to start other amps. Before that amps would have a 110V passthrough socket. THX trigger is a mono 1/8th inch / 3.5mm TS plug. Each device usually has one 12V in and a 12V out. While it's on, it'll output 12V at up to 30mA[1]. Due to current fluctuation and the low max amp it's recommended to use an opto-electronic isolator at the input. THX originally introduced it to allow for home cinema surround. At the time commercially available amps only supported 2 channels, so the first THX systems had one receiver decoding the dolby signal, providing a line level output that you'd connect to multiple stereo amps. Due to the currents required the 110V passthrough wasn't an option, so 12V trigger was born. Before 12V trigger existed the IR/Remote port, which allowed you to connect an external IR receiver to TVs, VHS recorders and Amps. This used the same plug, but would modulate the IR remote signal directly. You could also use this to connect multiple devices and allow them to send remote control codes to one another. But that feature disappeared quickly due to limited compatibility. In computers 12V trigger and remote ports inspired the I²C based DDC standard for VGA monitors, which allowed turning them on or off or changing settings. DVI and DisplayPort kept DDC as is, while HDMI expanded DDC into the CEC standard, which also allows controlling volume or sending media controls in a standardized way. Nowadays 12V trigger is mostly being replaced by HDMI CEC. ________________________ 1. Some devices support up to 80mA, Sonos even provides 100mA reply ssl-3 14 hours agorootparentprevSuch a 12v trigger would be useful for a plain stereo amplifier, which are relatively simple things -- so simple that they may not even have a volume control. This would allow a Sonos Port to have a dedicated amplifier connected (for driving one big stereo pair of speakers, or maybe an array of 70v distributed audio speakers, or who knows what) and control when it is powered on. But it won't turn on my AV receiver (it has 12v triggers, but they're all outputs), nor switch its input mode appropriately. (Yeah, sure. I can hack something up with an ESP32 with IR or RS-232 or even Lego Mindstorms or something from Switchbot, but Sonos buyers and hardware hackers are naturally somewhat diametrically opposed: A person who buys Sonos gear wants stuff that just works, not a new hobby.) reply erinaceousjones 18 hours agorootparentprevChromecast Audios are still easy to pick up on eBay (or if you're in the UK, CeX, that's where I got one). Any old cheap plug tied to Home Assistant (or plain old Google Home in my case) for auto powering on my Cambridge Audio amp. (I'm not fancy enough to care about automated input switching between TV and music, I just get up and turn the knob, but turning off the hifi remotely I like) Music Assistant supports streaming to Chromecast from TIDAL at the native (24 bit, 96khz, flac/m4a?) format. And TIDAL mobile app itself supports casting to Chromecast devices as you'd expect. Those 3 things combined got me an old school hifi set up which I can include in my Chromecast groups of shitty sounding second-hand nest minis, so I get multi room audio where one room has the most audio :-) but I could swap out the shitty pucks for some more CC audios if I wanted to fork out for more amps and bookshelf speakers. I trust Google to at least not intentionally brick their old devices and chromecast is built on mDNS and documented http endpoints enough that you can automate your own stuff in your LAN that you should be able to keep that stuff working in home assistant + music assistant should Google ever decide randomly they wanna sunset Google home (so, 50% chance of them announcing that in 2025). Homebrew you can roll your own DIY multi room hifi audio using stuff like Hifiberry, too. Pipewire/PulseAudio/JACK on raspberry pi / NUCs should be able to get you surround sound over the network with minimal latency (although you probably want decent ethernet), since you can make a virtual sink that bridges the audio servers together. You have one of those fancy hifis that has hdmi inputs and digital input selection and whatnot? Okay yeah you'd have to roll your own HDMI CEC automation again with a raspberry pi or whatever. Eminently doable. There's definitely ways to get multi room audio of equivalent or better quality and at-least-equal user experience as long as you're willing to invest the time in doing loads of DIY shenanigans, but honestly it's pretty easy these days. For me, I think the \"this is too complicated for me to implement\" bar is not high enough to warrant buying Sonos reply javier2 20 hours agorootparentprevYes, this is annoying. I settled for the cheap variant: Let any hdmi device grab focus. The tv has spdif to the amp. Amp is always on the spdif input. I can change sources on the tv and the sound will follow, if I want youtube or spotify to play, I have to use chromecast on the tv or airplay to apple tv. It works ok for only a single cable. If the tv is off, the sound is off. reply gizmo 20 hours agorootparentAn amp will wake on hdmi (arc) input, but it won't wake on spdif. Unless you figured out something clever you still have to mess with multiple remotes and turn devices on/off individually. reply hmottestad 21 hours agorootparentprevI have a 40-year old amp and speakers at home. My dad’s old stereo. Works fine, but it has so much static buzz. Sounds great though. I’m just a bit hesitant to leave it powered on all the time which means I don’t use it much compared to my Bluetooth speakers. Old power supplies are not very efficient. They can get hot. There is also a decent amount of dust. And then there is the risk of some old cap blowing. reply mixmastamyk 1 hour agorootparentBuzz is not normal. Either it was really low quality, (unlikely since it has lasted this long), or it is not properly grounded. reply tshaddox 20 hours agorootparentprevI would be surprised if that device can power cycle or control the volume of a stereo from 1970. reply turbojet1321 13 hours agorootparentprevMy favorite recent discovery in the HiFi world (after losing interest about 15 years ago) are the WiiM network streamers. Connect them up to any old system via RCA, toslink or coax and you can: - stream from a wide number of subscription services - stream from your own DLNA server or samba share - cast from Chromecast or AirPlay - with multiple devices, you can do multi-room synchronized streaming - apply parametric EQ, including (in the higher end models) auto room correction - hook up a digital source (eg, TV) so you can apply EQ - hook up an analog device (like a turntable) and stream it to the rest of the devices in the house The app's surprisingly good, the firmware updated regularly. The cheapest version is under $100. They're like Chromecast Audio's on steroids. When (eventually) they die or get superseded, it's easy to replace without needing to touch the rest of the system. I have 3 at the moment, the main one hooked up my amp and speakers from the 80s, which I picked up used in the 2000s. reply pcchristie 12 hours agorootparentWell said. I have a Wiim Pro & Mini, and love them both. And it's the best way of minimising waste (given some waste is inevitable as standards change, until they let us change the board inside the Wiim or something!) reply turbojet1321 12 hours agorootparentI've been really impressed by how they keep pushing features out to old devices. Like, there was no reason for them to give the Mini 10 band PEQ - they could have made people upgrade. But no, the working (seemingly quite hard) to get the performance out of the chip in the Mini to do it, and pushed the update out to everyone. reply tyre 19 hours agorootparentprevI have a raspberry pi running an AirPlay server[0] and nothing else. Turned some nice analog speakers into airplayable for like $20 [0]: https://github.com/juhovh/shairplay reply semi-extrinsic 20 hours agorootparentprevIf only there was a small and very cheap device with wifi and aux out that you could plug into your old stereo, and instantly get the possibility to cast music directly from all your Android apps. Like a Chromecast but for Audio. Seriously, this was a thing 10 years ago! I bought five, and they all still work perfectly. They do multiroom audio. They are compatible with the new Nest speakers. The only reason we can't have them today is corporate greed and rent-seeking MBA fuckers. reply addicted 20 hours agorootparentThe Chromecast Audio was a wonderful device. I unfortunately lost all mine in a move but there’s been absolutely no way to replace them :-( reply ssl-3 19 hours agorootparentThey're still out there. In the US, MSRP at launch in 2015 was $35. With inflation, that's worth ~$46 today. I see one on eBay right now (open-box, allegedly never used) for $60, delivered, in buy-it-now format. $60 is not an ideal sort of price, but it's not something that seems extortionist or anything compared to the inflation-adjusted price from 2015. reply addicted 12 hours agorootparentTrue, but relying on old units available on eBay is not a long term solution. reply applied_heat 35 minutes agorootparentIt is Probably just fine for the next 10 years. Chromecast audio are working great for me with my 70’s receiver and modern mini amp and Bluetooth speakers with line in. reply izacus 10 hours agorootparentprevThere are companies out there that make similar devices now luckily (sadly they're more expensive :/ ) reply jamesy0ung 17 hours agorootparentprevUsed Airport Express is pretty good if you're an Apple household. reply ramses0 12 hours agorootparentBelkin SoundForm Connect + a physical power button amp. So many people chasing so much complexity, but this seems like the precursor to the WiiM(?) - first I'm hearing of that one. (FYI, I chased that route, there is/was _one_ model that worked as an airplay2 device, but it still didn't feel as \"native\" as the modern HomePods ... icon was different, pairing was slower and slightly flakey... I moved to the belkin directly and have been happier. That and home assistant allowing single target airplay1 support to chrome cast / google nest devices sometimes is useful in a pinch) reply herf 15 hours agorootparentprevPeople seem to like the WiiM streamers, but I have not tried one yet. reply turbojet1321 13 hours agorootparentI have 3 - they're awesome. reply JetSetIlly 12 hours agorootparentOh interesting. I was recently in my local HiFi shop (been a customer there for 40 years) to buy a new CD player and I noticed a WiiM box behind the counter in a display cabinet. I just assumed it was some sort of aging Nintendo Wii gimmick. I'm being serious. If it has nothing to do with Nintendo then it's terrible branding. reply turbojet1321 12 hours agorootparentThere are a bunch of hifi brands that are making great products but don't have great name branding: SMSL, Topping, WiiM, Fosi (I own 3 of those 4, lol). The upside is that they mostly seem to care about making good products rather than branding. reply JetSetIlly 12 hours agorootparentRight. I'll go back to the shop and have a closer look in that case. I like the idea of a streaming device to connect to a normal stereo system. TBH, I didn't even know such devices existed. I thought that if I wanted to stream from Spotify without a PC I would need to go down the Sonos route, which I obviously don't want to do. The problem with not having good branding is that potential customers walk right past your products. It's only chance comments in this thread that's made me take a second look. Thanks for the info :-) reply dfltr 21 hours agorootparentprevIt feels like one of those low-sci-fi settings where we thought it'd be funny and quaint to have post-collapse scavengers endlessly repairing retro tech, but now it's actually happening and it's not funny anymore. Like for example: My dad bought a hulking integrated Akai amp / cassette / turntable combo in the early 80s. Every user-facing component was brushed aluminum, the volume pot was the size of a Dallas church, and it probably would have killed any living organism you dropped it on. My dad died over a decade ago and I guarantee that amp is still sitting in someone's living room heating the place up. I'm just mad it's not in mine. reply kd913 22 hours agorootparentprevI think there can be a difference here. Was looking recently at the power requirements of an amp + subwoofer + 5 5.1 JBL surround speakers. The setup was done decade ago, and the power needed for it was nuts. Something like 500W for a Denon amp and 250W for a JBL subwoofer? For reference something like a OG HomePod consumes what 45W? The Sony srs xg500 boombox can last 30hours and is a giant room shaking boombox. The difference in power efficiency between these old and new setups are nuts. Nevermind compatibility with AirPlay, streaming etc… reply kristjansson 21 hours agorootparent> 500W Amplifiers are quoted in peak output, not average (and play some games with other parameters e.g. resistance) to capture bigger-number-better sales. A 750w system will consume nowhere near 750w at typical listening volumes (just like your 750w PC doesn't use 18 kWh every day.) reply throw-qqqqq 21 hours agorootparentprevUnless you’re playing REALLY loud, I don’t think you are anywhere near 250 or 500W of consumption. I would guess it is the maximum rated power? Even with quite old and inefficient amp + speaker combo, 30W of sound is usually a lot(!). Tube amps are an exception. They can be very power hungry, but it’s difficult to buy such tech today compared to class D etc. reply kingnothing 21 hours agorootparentprevThere's also an absolutely massive difference in audio quality between a HomePod or Sonos anything and a proper amp + speakers. reply jkolio 21 hours agorootparentYup. Newer products use various tricks to try to fill in the gaps that their physical reality can't overcome, but ultimately there's no getting around that reality. I will say that the Sony upright boom boxes aren't to be slept on (and, if one is active, fat chance). They're quite good for their intended use cases (parties, and closed Best Buys during clean-up/inventory). reply tpm 21 hours agorootparentprevA 500W amp is probably a class A and can't really be made more efficient. It would still be 500W in 2024. Decades ago there were more efficient setups too, though of course now they sound better and also have lots more features and connectivity. reply rurp 21 hours agorootparentprevYep, and this kind of needlessly wasteful consumerism is everywhere in the tech industry. All of the token statements about sustainability that come from the same industry that normalized and celebrates this kind of product strategy drives me a little crazy sometimes. reply whatevaa 6 hours agorootparentprevSound might be solved, but multi-room audio is not. On major renovations you could layout speaker cables, but then you can't adjust positions. Custom solutions with, like, snapcast and raspberries (like mine), works and you don't need to deal with any of this, but then you need to deal with software setup annoyances. It get's technical. reply marcosdumay 6 hours agorootparentprev> People don’t realize sound was solved decades ago. Not wireless transmission, and not uniform spatial distribution. AFAIK, Sonos was about those two. They didn't solve them either, there's still plenty of space to make a dent there. reply PaulDavisThe1st 21 hours agorootparentprev> A couple hundred up front for never having to make another home audio equipment purchase in your life is some serious savings. I have a rather nice NAD amplifier that I bought about 29 years ago. It had to be repaired once at about the 6 year mark. Recently, it has developed a new electronic failure mode that I don't believe can be repaired. So ... yes, but let's not overdo the \"never have to make another home audio purchase\" part ... reply mitjam 21 hours agorootparentprevStill enjoy my Elac speakers from 20+ years ago at an analog amp, a class D amp wouldn‘t be bad, though. For smaller speakers at computers I like active nearfield monitors and a good interface like Focusrite. Can recommend Genelec speakers, for example. reply a-french-anon 10 hours agorootparentNB: the D in \"class D\" doesn't stand for \"digital\". reply theshrike79 20 hours agorootparentprevI had a fancy separate stereo system with a HDMI switcher in the AV amp, well reviewed speakers I bought from a hi-fi enthusiast friend and all that. It was a massive pain to put out all the cables, adjust the system manually little by little (the setup mic kinda helped, but wasn't that good). Then I got a Sonos Beam and that set of \"crap tiny speakers\" with a fancy DSP brought so much more dimension to movies that it wasn't even funny. Upgraded to a Sub and it automatically offloaded those frequencies to it and the Beam got even better now that it didn't have to cosplay a subwoofer. For setup all I had to do was walk around the space and wave my phone around and the difference was clearly audible even to my non-discerning ears. Later I upgraded to an Arc + got two rears and everything got a lot better. The v2 app is utter crap, I haven't had to use it for anything else than Trueplay adjustment when we moved a while ago. The v1 let me debug what the soundbar was receiving (my TV was sending data in the wrong format and I was just getting fancy stereo instead of Dolby Atmos). V2 doesn't have any power user features at all. I'm not going back to a wired setup with a separate amp unless I get a dedicated theater room I can sound proof and manage the acoustics. I _am_ considering switching to a brand that doesn't need an app to setup, but it's slim pickings in the upper tier of soundbars. reply kridsdale1 20 hours agorootparentSimilar to you I had lugged my 7.1 speakers and amp and wires around to every address I’ve had in 20 years. For the current house I had enough and put a HomePod in every room and top tier Samsung bar + satellites + sub. It’s not as good at dimensions as discrete speakers but now I have reflected Atmos Waves off the ceiling and setup was super easy. I had to use the app one time to calibrate but I already had it since I have a Washing machine it connects to. reply theshrike79 11 hours agorootparentThe DSPs in sound bars are absolute marvels. I haven't checked the AV amp market in a good half decade, but I'm guessing there aren't any valid options if you want 4k 120Hz + room correcting DSP that are even close to the price of a mid/high end sound bar. reply sgarland 18 hours agorootparentprevI never had a “proper” HT setup; my first was an Arc + Sub. I thought it was pretty great, and then I added two Era 300s for rears. My god. I’m sure things can get better, but I’m pretty happy with my setup as-is. I’d probably splurge on an OLED TV first. I have an 85” Sony X91J that I quite like, but I can’t deny the absolute inky blacks of OLED (just couldn’t justify the price at the time at that size). reply theshrike79 11 hours agorootparentIMO Sound bar + sub is perfectly enough for 90% of home theaters, with properly placed rears it easily goes up to 98%. Just a basic sound bar instead of the shitty rear-firing TV speakers is a complete game changer for few hundred monetary units. reply creddit 16 hours agorootparentprev> People don’t realize sound was solved decades ago. This really isn't true at all. HiFi has an obscene amount of snake-oil and non-rigorous design decision making. Audio Science Review (https://www.audiosciencereview.com/forum/index.php) has documented this very clearly and well. reply worik 22 hours agorootparentprev> Well that is basically the model of the home stereo today. The entire digital ecosystem seems to be heading this way. Even cars reply gazchop 22 hours agorootparentprevNailed it. You don’t even have to buy new stuff now. Still rocking my early 90s system. Has required a couple of amp repairs (capacitors and sticky relay) but no big issue. Bought a Bluetooth DAC for streaming stuff. Job done. reply DidYaWipe 21 hours agorootparentprevExcept the industry is nearly dead. Almost nobody is buying legitimate stereo systems anymore, and the ones that are out there (at almost any price) are mind-bogglingly incompetent. I'm shocked that Sonos is even a going concern at this point, although I suppose it is because of what I relate below. The home-audio market is consolidated into a tiny number of manufacturers masquerading under once-proud brands they bought. The crippling incompetence of the products themselves is depressing. A few years ago my Denon A/V receiver crapped out and I decided to go \"upmarket\" and get an NAD T758. I accept a bit of quirkiness from a smaller name, but \"quirkiness\" doesn't come close to describing the design and functionality defects that plagued this thing. Everything from baffling menu navigation (not kidding: Pressing Enter did not select a menu entry; you were supposed to use an arrow key) to the fact that it would only pass 720p video because it reported erroneous EDID info to HDMI devices. It didn't pass the info from the connected display device; it just provided its own EDID blob to everything, which reported a max resolution of 720p. The NAD also featured Dirac processing, which I shelled out for to get the full license and spent hours with a test mic profiling my room and speakers. Then... it would just lose the entire configuration. Deleted off the receiver. \"We haven't been able to figure out why this happens,\" said NAD. In fact, in several years they never fixed a single one of the crippling defects I encountered and reported. But NAD isn't the only shitshow in town. Let me address the biggest impediment to whole-home audio (or even multi-zone audio): manufacturers' bizarre conceit that anyone can use secondary zones that only play ANALOG sources. The NAD was crippled by this stupidity, as is the top-of-the-line Pioneer I bought to replace it. In the case of the NAD, I addressed this defect by running RCA cables across the back of the receiver, from its preamp outputs to a CD-player input; and assigning that input to Zone 2. Why the hell didn't NAD just do that internally with a switch? On the Pioneer, it's actually worse. There ARE no preamp outputs. It has THREE zones, one of which I can tie to the main one but the third, yep, can only play analog sources. All I want to do is play the same shit on ALL MY SPEAKERS. My living-room ones, my patio ones, and my backyard ones. All I need is A, B, and C speaker switches. But NOPE. As far as I can tell, nobody makes this. Nobody addresses the 99% use case for multiple \"zones.\" There are at least NINE AMPS in my receiver, but I can't play the same source on three pairs of speakers. BTW, I did build a patch bay with switches, to wire the secondary zone in parallel with the first... but this overloaded one pair of amps in the NAD and destroyed the entire receiver. Yep: NAD doesn't have a simple overload breaker. They just burn the entire amplifier board up; that's the breaker. Unfuckingbelievable. But back to the main issue: Who is seriously going to dick around trying to select sources and adjust volume to each zone (with what, by the way, an app?) on one receiver instead of simply buying a bookshelf system for every remote room you want to play music in? I sure as shit wouldn't, and I'm the kind of person who ran digital cables under my house to an equipment closet so I could have a proper surround setup in my living room. I have a projector and home-built screen, but even I would never bother with the stupid usage scenario Pioneer, NAD, and the two other makers envision: This scenario revolves around nonexistent people who are going to put on a RECORD or TAPE, then go to the other side of their house or down to their rec room for half an hour... and then come running back to the other side of the house to flip the record or tape over. WTF. reply vessenes 20 hours agorootparentRisking major flames here but .. my Sonos amps do this perfectly. Analog cable through the house, amps on eth in the media closet, it’s is very very solid. Also I hate the new app with fiery passion reply DidYaWipe 16 hours agorootparentYeah, that's why I added the caveat at the top of my rant. Too bad they messed up the app so badly. I've written some hardware-control applications and they're not necessarily easy, but... well, that's the job. Meanwhile I've had my time stolen on numerous \"ghost job\" postings. Maybe someday, somewhere someone will take a lesson from Boeing and Sonos and other companies that have suffered from grossly incompetent software engineering and put a halt to the despicable disrespect for our time and knowledge. reply baq 10 hours agorootparentprev> All I want to do is play the same shit on ALL MY SPEAKERS. Actually that's what Denon's HEOS does, might want to take another look at their mid-level X1800H or the bigger ones if you need more zones from a single AVR instead of multiple devices. reply 100pctremote 20 hours agorootparentprevThe NAD downfall was so frustrating and sad to experience. Mine has been boxed and shelved in the garage for years now. reply DidYaWipe 20 hours agorootparentThey should just fold. I read in some other forum that they just cobble together crap that they source from numerous and variable providers, so one unit's guts can vary widely from the next. It's the absurd design defects that I will never excuse. I mean... incompetent MENUS? A modern receiver that doesn't support even HD video? My burned-out T758 is gathering dust in my office; I'm keeping it in hopes of using the chassis for a project case someday. I would replace my stupid Pioneer too if anyone made a stand-alone surround processor with preamp outputs. Then I'd get separate amplifiers and that would be that. But nobody makes such a processor, as far as I can tell. reply skydhash 1 hour agorootparent> I would replace my stupid Pioneer too if anyone made a stand-alone surround processor with preamp outputs What you’re looking for is this. https://emotiva.com/products/basx-mc1-13-2-channel-dolby-atm... reply 100pctremote 20 hours agorootparentprevYes. The entire platform -- hardware & software -- is just a mess. I bought an MDC phono module for my digital amp only to discover it wasn't supported by its firmware. I waited 18 months to be able to actually use it. I experienced the same non-persistent configuration problem you described and also very sketchy things like the power button simply not working. Unacceptable by any measure and at any price point as far as I'm concerned. reply DidYaWipe 17 hours agorootparentOh yeah, I forgot about the power-button problem! I had the same thing. Super fun to reach back behind the equipment rack to unplug the POS. reply turbojet1321 13 hours agorootparentprev> The home-audio market is consolidated into a tiny number of manufacturers masquerading under once-proud brands they bought. The crippling incompetence of the products themselves is depressing. There's quite a rise in Chinese HiFi companies that are making some great equipment. I've found audiosciencereview.com an excellent resource for getting back into hifi and avoiding much of the nonsense. I recently picked up a Fosi amp which, to me, functions at least as well as my NAD from the 80s. It cost me half of what I just spent on getting the NAD serviced. > All I want to do is play the same shit on ALL MY SPEAKERS. My living-room ones, my patio ones, and my backyard ones. All I need is A, B, and C speaker switches. But NOPE. As far as I can tell, nobody makes this. Nobody addresses the 99% use case for multiple \"zones.\" There are at least NINE AMPS in my receiver, but I can't play the same source on three pairs of speakers. Look into WiiM streamers. Cheap and quite impressive IME. Multi-room streaming from digital or analog sources, PEQ, room correction etc. reply _fzslm 18 hours agorootparentprev> All I want to do is play the same shit on ALL MY SPEAKERS. My living-room ones, my patio ones, and my backyard ones. All I need is A, B, and C speaker switches. But NOPE. As far as I can tell, nobody makes this. Nobody addresses the 99% use case for multiple \"zones.\" There are at least NINE AMPS in my receiver, but I can't play the same source on three pairs of speakers. Maybe a smart speaker switch like an Audioflow[0] is up your alley? [0] https://flow.audio reply DidYaWipe 17 hours agorootparentThanks for that reference. Hadn't seen that one before. \"This three way switch has Zone A and Zone B in Series. Zone C is in Parallel with A+B.\" Important info that they provide up-front, which I like. reply DidYaWipe 21 hours agoparentprevDo you have details on that? How and why was that necessary? reply sorenjan 21 hours agorootparent> Sonos has a good reputation for building quality speakers, but its latest move has disappointed some buyers. Recently, the company offered a trade-up program, giving legacy customers 30 percent off the latest One, Beam or Port. In exchange, buyers just had to \"recycle\" their existing products. However, what Sonos meant by \"recycle\" was to activate a feature called \"Recycle Mode\" that permanently bricks the speaker. It then becomes impossible for recycling firms to resell it or do anything else but strip it for parts. > Sonos suggests that after bricking the device in Recycle Mode, users drop it off at a recycling facility or give it to Sonos to do the same. https://www.engadget.com/2019-12-31-sonos-recycle-mode-expla... reply DidYaWipe 20 hours agorootparentThat truly lives up to the term \"outrage.\" reply philjohn 5 hours agorootparentExcept they reversed course after the outrage, and people are happily still using those speakers, albeit with the S1 app. reply Mindwipe 7 hours agoparentprev> They drop support for things over time but even their roughest transitions (x86, Apple Silicon) have come with extensive day 1 support for previous functionality. Catalina literally just dumped half the software that ever ran on MacOS overnight to make the transition to Apple Silicon seem smoother than it actually was. reply YetAnotherNick 22 hours agoparentprevFirst of all \"Even Apple\" implies Apple is particularly bad, in fact it is one of the better ones in supporting older usecases and devices. But even then x86 to Apple silicon is not the roughest by far. For me, it is the removal of x86-32 bit software support. The removal wasn't needed at all and broke all the steam games. reply hmottestad 21 hours agorootparentI assumed it was part of the migration plan to Apple silicon. Rosetta 2 makes x86 apps work on Apple silicon, but I had assumed that Apple could only really get 64-bit x86 apps working smoothly and that’s why they removed 32-bit support a few years earlier. reply dagmx 21 hours agorootparentRosetta supports 32 bit apps. I've read conjecture on here that the removal of 32 bit was due to unresolvable pointer security issues on their 32 bit SDK, which was different than how its done with their 64 bit system. reply ClassyJacket 21 hours agoparentprevI mean, the week the iPhone X came out, they put out an irreversible update for the iPhone 7 that made it unusable. They also tried to charge me 2,300$ to fix just one broken keyboard key. Apple is definitely that bad. reply hmottestad 21 hours agorootparentI tried to search for info about an update that broke iPhone 7 phones. Couldn’t find anything. Can you point me to some more info? reply lotsofpulp 21 hours agorootparentIt never happened. I used a 6 and a 6S Plus, fully updated, for many years after my I got my wife an XS. Not that it proves nothing happened to the 7 the year before the XS came out, but, A) it would have been huge news if Apple bricked all iPhone 7, and B) it makes no sense to brick iPhone 7, but not the ones before it. reply DidYaWipe 20 hours agorootparentYeah I used my original SE until iOS 16 came out (actually until last year) and it was never bricked. reply hoorible 16 hours agorootparentprevLooks like we found the “things that never happened” double Jeopardy for today reply acchow 1 hour agoprev> He’ll remain an adviser to the Sonos board through June and get paid $7,500 per month until then. He’ll be paid a cash severance of about $1.9 million, and his unvested shares in Sonos will vest. Incredible vesting schedule reply dguido 21 hours agoprevPlease stop putting salespeople in charge of highly technical product companies like Sonos. I'm so glad that Tom Conrad is an engineer by training. I hope he can turn this mess around. The key technical change that broke Sonos was abandoning their reliable UPnP (Universal Plug and Play) system for device discovery in favor of mDNS, while also shifting from direct device communication to a cloud-based API approach. This new architecture made all network traffic encrypted and routed through Sonos cloud servers (even for local operations), adding significant overhead and latency, especially for older Sonos devices with limited processing power. They also switched from native platform-specific UX frameworks to a JavaScript-based interface while moving music service interactions through their cloud instead of direct SMAPI calls, resulting in slower performance and reduced functionality. For a more extended discussion, see this excellent LinkedIn post from Andy Pennell, a principal engineer at Microsoft with a deep technical understanding of Sonos systems. He created one of the most successful third-party Sonos apps for Windows Phone and worked directly with Sonos on their official Windows Phone 8 app. https://www.linkedin.com/pulse/what-happened-sonos-app-techn... reply jedberg 20 hours agoparentI don't think having a sales person in charge was the problem. The problem is the fundamental disconnect between what's good for users and what's good for the company. The company wants you to have to pay them money every month and control how you interact with the product, so that they can be a services company with recurring revenue. The consumer wants a device that they buy once and it just works. reply griomnib 14 hours agorootparentI have experienced this most acutely with the most recent round of macOS and iOS updates. Nothing Apple is shipping seems to be for me, the user. Rather it’s a grab bag of crap “AI” for Wall Street, ways to make it harder to run software of my choosing, and wholesale trashing of perfectly fine UX to cram in whatever useless feature some PM landed for their promotion. I could say a few hundred things much worse about the direction of windows 11, which is even more obnoxious than Apple, but then I’d have to relieve the horror of being forced to submit my email address to Microsoft to install the damn OS. Day by day I feel the devices I’ve spent a huge sum of money on no longer belong to me. I’m getting really fucking tired of it, and something has to give. reply 4ggr0 8 hours agorootparent> but then I’d have to relieve the horror of being forced to submit my email address to Microsoft to install the damn OS. all it takes to install Windows 11 without an account is to press SHIFT + F10 on the \"Connect your internet\"-screen and execute this command: OOBE\\BYPASSNRO never in my life have i linked an MS-Account to my personal windows, i always use a local account. reply martin_a 7 hours agorootparent> all it takes to install Windows 11 without an account Well, that does not really look very user-friendly, does it? Which probably only underlines the point of the parent. reply whywhywhywhy 10 minutes agorootparentit’s actually not even as “simple” as that comment they’ve changed it to be a bit more obtuse to get to the command part, exemplifying exactly why going along with it is a problem. reply 4ggr0 5 hours agorootparentprevWe're on a tech-focused site where someone mentioned that they don't install windows, because they don't want to login with an online-account. i agree that my described work-around is not made for the common enduser and i hate that this feature is so hidden, but i think executing a single command you find after 30 seconds of googling is not too much to ask for from a tech-adjacent person :) i see posts on here of people reverse-engineering firmwares, hacking together new things, finding and using exploits etc., not sure why installing a windows seems to be a huge topic, then. reply griomnib 12 minutes agorootparentBecause they made it a worse product, they made it my job to fix it. That’s the point. reply griomnib 17 minutes agorootparentprevIf I wanted to type in commands to install my OS I’d use Linux desktop. reply Gazoche 3 hours agorootparentprevStep 1: add online login as an option Step 2: make online login the default option Step 3: make online login mandatory, leave an escape hatch for technical usersStep 4: remove the escape hatch reply nzach 6 hours agorootparentprevI wonder if 'OOBE\\BYPASSNRO' will be the FCKGW-RHQQ2-YXRKT... for the new generation of people entering the IT world. reply godzillabrennus 6 hours agorootparentDoubt it. Kids today are phoners who live on mobile devices. reply jkestner 4 hours agorootparentAt what point in time were “kids today” into computers? If it wasn’t phones, it was video games or comic books or serial Dickens. It’s always been a subset who want to play with the tech beneath. reply 4ggr0 5 hours agorootparentprevit's certainly a step i teach to kids coming into the IT-space, right before teaching them about Mass Activation Scripts :) reply lupusreal 7 hours agorootparentprevOh that's all? Just some obscure magical incantations which will probably be gone as soon as Microsoft management learns of it. Brilliant. reply 4ggr0 5 hours agorootparentsibling, we are on _hacker_ news. if a single command is too much to ask for, i don't know what to think. ever installed Linux? takes exponentially more knowledge than this windows-local-only workaround. i'm sure that management is aware of this feature, as it exists for years now and can be trivially found, it's not like this is hidden somewhere in a vault, you know. Same as MAS. i'm not even a defender of Windows and only use it at home because i game, but if i see that someone has never installed a windows just because they don't want to give M$ their e-mail address (hope they don't have a github or linkedin account, but, you know...), then i want to give them the hint they need :) i use them same functionality to install windows for my parents etc., as they want to have local-only accounts as well. even without this weird work-around, i would still be the one installing windows. OS installation is not hard, but already too difficult or confusing for lots of endusers. not sure why you chose to reply in such a snarky tone :( reply lupusreal 4 hours agorootparentI use linux because it's much easier than fixing Windows. I lost interest in tinkering with my computer years ago. reply rocketvole 5 hours agorootparentprevMicrosoft knows about this. Its why they included the option in the command line. The fact that Massgavel's activation scripts still work on windows is telling of how much they'll care. reply scarface_74 14 hours agorootparentprevIf you turn Apple Intelligence off, how is the UI in iOS 18 any different than the previous version? reply azraellzanella 9 hours agorootparentI have it off, it still uses 5GB of storage... reply griomnib 12 minutes agorootparentHey, just pay extortion prices for more storage! reply griomnib 14 hours agorootparentprevMail is dogshit. Photos is dogshit. Image playground is streaming hot dog shit. Etc etc. reply scarface_74 14 hours agorootparentYou can modify the Photos app to be just like pre iOS 18 just by using “Customize and Reorder”. Absolutely nothing has changed about mail if you turn off Apple Intelligence and Image Playgrounds is just an app that you don’t have to use. reply miramba 12 hours agorootparentI did not know that, thanks. But still - if I have to research now how to do that it‘s still going in the wrong direction, no? Besides, it‘s rare that Apple gives a choice, usually you have to adapt at whatever they decide. reply scarface_74 5 hours agorootparentSo Apple shouldn’t make things more customizable? reply wao0uuno 12 hours agorootparentprevThere is no way to get the old Photos interface back. reply sunnybeetroot 13 hours agorootparentprevI see mail now has mandatory images next to each mail item, how can that be turned off? reply hypothesis 13 hours agorootparentSettings -> Apps -> Mail -> Show Contact Photos reply sunnybeetroot 13 hours agorootparentWow as simple as that, thank you. reply dt3ft 12 hours agorootparentprevBluetooth is horrible. I see spinning loader (connection indicator) even when I switch bluetooth off. It’s been stuck at it for days. You’d think that this would be core functionality and ultra stable by now. reply dacryn 11 hours agorootparentreboot your phone at that point ... reply godzillabrennus 6 hours agorootparentprevMail has been terrible since inception. It’s just more terrible now. Photos in iOS 17 was fantastic but the new version in iOS 18 is unforgivably bad. It’s the new “pc load letter”… reply educasean 14 hours agorootparentprevNot an Apple user here. What's changed? Can you share more details about what made them \"dogshit\"? reply wao0uuno 11 hours agorootparentMail got category buttons on top that split your inbox so now to check your mail you have to click around because shipping notification are in a separate list from work emails. Photos had a perfectly fine interface with tabs that got changed into a long list of often redundant categories. Thankfully it can be customized a bit. New control center (wifi toggles etc.) was replaced with a customizable grid of widgets that is buggy, slow and looks ugly and unprofessional in comparison with the old interface. Gimmick. Home screen icon size and color is customizable now and it looks out of place. Gimmick. If you have a dark theme enabled then icons in settings become themed and look different than icons on the home screen with is weird and inconsistent with the rest of the interface. All animations were reworked and feel like crap. There is a delay to every action and it feels like animation smoothness takes priority over interface responsiveness. Home screen swiping animation stutters every time. Even though there is not a single new feature available for EU users other than the interface changes the entire OS feels sluggish, bloated and unfinished. Performance is terrible. This update made my iPhone 12 slow down to a crawl. Feels like running Vista on a Windows XP machine and since they dropped security updates for iOS 17 I had no choice but to upgrade. This combined with the recent news about iPhones listening to people at homes makes me want to get rid of my phone entirely. I don’t want a new iPhone and I sure as hell don’t want an Android. reply lloeki 11 hours agorootparentMail: top right (...) menu -> List View reply griomnib 14 minutes agorootparentYes I had to do that, which is my entire point - everything worked, and they made it worse. scarface_74 5 hours agorootparentprev> Photos had a perfectly fine interface with tabs that got changed into a long list of often redundant categories “Pin” the categories you want access to. reply geraldhh 8 hours agorootparentprevamen home screen icon theming hit like an empty bus reply griomnib 10 minutes agorootparentUsually when they shamelessly copy from Android they made some improvements, this isn’t even close to material on Pixel, which is pretty nice. (Not a fanboy of either; use both.) conradfr 8 hours agorootparentprev> and something has to give Well yes, the user. reply btreecat 5 hours agorootparentprevSounds like your ready for some flavor of Linux reply griomnib 9 minutes agorootparentI use Linux all day on the server, but I’ve never liked it on desktop. I do think I’ll be forced into it within a few years. reply jimt1234 11 hours agorootparentprev> Nothing [insert company] is shipping seems to be for me, the user. I have a 90/10 rule when it comes to new products/features these days: they're 90% benefit to the company and 10% benefit to me. reply redeux 14 hours agorootparentprevIt's called enshittification, and it's pervasive throughout our entire economy. https://en.wikipedia.org/wiki/Enshittification reply marcosdumay 6 hours agorootparentIt's called monopolization, and it's dependent on those companies selling products that you can't switch for another competitor. Or, some times it's plain simple cartelization, making sure no competitor is better. That seems to be the case with smart TVs for example. It's good to have a word for the impact it causes, but focusing on that novelty makes it looks like it's a new phenomenon that we don't know the causes or how to fix. reply redeux 5 hours agorootparentAbsolutely. I don't mean to imply that it's \"just happening.\" It's happening for very good reasons, like the ones you mentioned. reply InDubioProRubio 6 hours agorootparentprevThe natural state of a ex-free-market economy sliding into feudalism without a systemic competition present. reply astrange 14 hours agorootparentprevApple doesn't have PMs. reply griomnib 14 hours agorootparentI’m sure they have some “magical” Cupertino world for infighting assholes putting their careers before users, whatever that may be. reply LudwigNagasena 13 hours agorootparentprevDoesn’t seem so. https://jobs.apple.com/en-us/details/200318153/get-connected... reply astrange 10 hours agorootparentThat is not in the OS. I also sort of suspect they're being hired as a prank because there is basically no power structure for them to have control over anything. Execs and designers have all the power. (Note: there are \"EPMs\" but it's a totally different thing.) reply Czarcasm 12 hours agorootparentprevMy team at Apple had PMs. reply mrandish 16 hours agorootparentprev> The company wants you to have to pay them money every month and control how you interact with the product, so that they can be a services company with recurring revenue. Yes! This pervasive trend has nerfed so much consumer tech. I simply won't buy any more hardware that relies on proprietary clouds reply danielmarkbruce 17 hours agorootparentprev> The problem is the fundamental disconnect between what's good for users and what's good for the company The fundamental problem with 95% of companies, and 99% of publicly listed companies. reply BrenBarn 10 hours agorootparentAt that point it's really a fundamental problem with our society that allows and even incentivizes the growth of such companies. reply danielmarkbruce 3 hours agorootparentActually it's fine - they go bankrupt. Look at the list of companies that make it through time, it's very short. Being selfish is common in human nature. reply Earw0rm 12 hours agorootparentprevThat suggests it's perhaps about what's good for investors, not what's good for companies themselves. reply gadders 7 hours agorootparentprevIt's 100% of PE-owned companies. reply benreesman 17 hours agorootparentprevI haven’t owned Sonos gear in a long time, but certainly back in the day they had just amazing products. That SUB where it was so perfectly balanced? They did a demo (that you could easily reproduce at home) where you could have it driving “call the cops” noise disturbance bass without upsetting a nickel set lengthwise on top, just a great unit and not the only one. Awesome stuff. But while superior products at a price point can capture a bunch of share, after that they grow at the rate of the market. Those markets have “matured”. For whatever reason we don’t as a society let “tech” markets mature. We demand growth long after everyone is satisfied. This is where ideas like “growth” and ideas like “useful” diverge: raise your hand if you like Facebook or Google in 2025 more than 10-15 years ago. Sonos (and I’m aware of the structure) “grew” right out of a sustainably profitable business with happy customers. reply vachina 17 hours agorootparentIt’s a company that makes speakers. Unbelievable that it can have such value to be able to be listed on NASDAQ. My Google Home costs $30 second hand, don’t sound as good, but I’ve not spent a single cent on it after setting it up. What is SONOS doing? reply belthesar 16 hours agorootparentI think you're underselling the technical complexity of doing what Sonos did. It was a pretty impressive feat for them to do what they did over WiFi. The reason your Google Home can do it is because, while it's a pretty decent technical challenge, it's not insurmountable, and Google decided that the price tag Sonos put on themselves was more expensive then Google dedicating a reasonable quantity of their highly talented engineering staff to recreate the technology. I think that's the kicker. It was revolutionary when it came out, and it's a solid technical solution, but Sonos was novel over a decade ago. reply skydhash 6 hours agorootparentEvery novel invention becomes commodity over time. The issue is that, instead of trying to invent something new, they’re adding gimmicks and present it as growth. reply jkestner 4 hours agorootparentTrue, but as the comment a few above mentions, “we demand growth long after everyone is satisfied.” Why even grow at all once you’ve achieved a great networked speaker? If the product is mature, everything after is gimmicks especially weighed against user satisfaction, the ultimate goal. reply bmelton 16 hours agorootparentprevThe market has matured, but as of a year ago, there isn't another solution that I could drop in that could replace my SONOS system. SONOS is so far ahead and had to establish themselves by solving for so many fringe use cases that they are generally the only ones who have things like the connect:amps to bridge wired outdoor speakers and architectural in-ceiling/in-garden speakers within the same ecosystem I'm sure that at some point, Samsung or Google or Sony or some upstart will catch up, but it will be a long time before someone eliminates SONOS from contention despite this multi-year setback reply glitchinc 14 hours agorootparentHEOS-capable gear from Marantz and Denon cover a lot of the applications you referenced. I decided I would never buy another Sonos product after the S2 rollout, and I now have a mix of eleven Denon and Marantz receivers driving both built-in, freestanding, and outdoor speakers of my choice all over my house. reply baq 10 hours agorootparentHEOS is amazing for the size of the dev team, which I think is a couple folks somewhere in a large garage in Minnesota[0]. The amount of things they never touch is amazing. I appreciate the stability - my HEOS 1 speaker is still working, streaming tunein and tidal without issues - but when it comes to the app, it's borderline stagnation at this point. [0] I have no idea what it is actually reply kdmtctl 11 hours agorootparentprevThis probably costs a fortune. Certainly there is a market. reply simondotau 13 hours agorootparentprevSo basically the only USP of Sonos is mindshare. reply bluescrn 10 hours agorootparentThey had a fairly unique and high-quality product in the early days. It just did’t evolve very far or very fast, or even adapt pricing to better fit a rapidly changing market. They switched away from a focus on multi-room hi-fi (or at least mid-fi) audio and users with their own hoard of digital audio to focus more on streaming services and chase the trend of little monophonic speakers. The higher-end devices remained good but became ever more niche. Then they broke everything, particularly customer trust, with the app update. reply Newlaptop 12 hours agorootparentprevHeh, this thread reminded me that I own Sonos speakers that I haven't used in several years because at some point they updated and I needed to install an app or make an account or something to use them and never did. So while it's maybe neat that they solved fringe use cases, it's unfortunate that they failed at the basic use case of \"just easily play audio from my phone\" reply iamacyborg 9 hours agorootparentprevLook into Roon. reply dehrmann 15 hours agorootparentprevYou can always short SONO. It'll probably muddle along for 5+ more years until someone buys it up for the brand name. There just isn't the market for their speakers that there used to be. reply _factor 13 hours agorootparentprevI did this with an amplifier and a couple cheap AudioCast devices as inputs. I can go to the app and pick which zones play together. reply vikramkr 16 hours agorootparentprevNot exactly sure what you mean - is there some reason companies that sell speakers shouldn't be able to be publically traded? reply jkestner 4 hours agorootparentYes. It will further abstract the owners’ responsibility to the users, and the product will get shittier faster. reply vikramkr 2 hours agorootparentThat's a general rant against publically traded companies. I'm specifically asking about the original posters take that a company that makes speakers specifically shouldn't be publicly traded. Like it sounded like they thought a speaker company couldn't be big enough to be on NASDAQ or something? reply Earw0rm 12 hours agorootparentprevAmen. reply Newlaptop 12 hours agorootparentprev> For whatever reason we don’t as a society let “tech” markets mature. We demand growth long after everyone is satisfied. The reason is tax law and it applies to all companies not just tech. Removing the double-taxation of dividends would fix so much of our economy. If you run a stable, no-growth but profitable company, and each year return the profits to the owners (shareholders) in the form of a dividend, that's bad because the income is first taxed when the corporation declares it as income and then again when the shareholders receive the dividend. If instead you don't issue the dividend, but re-invest to grow the company, then the value of the shares can increase without creating a taxable event for the shareholders. We could avoid a lot of the boom-bust cycles, enshittification of products and other economic problems if we just structured tax law to encourage stable, profitable companies issuing boring predictable dividends instead of our current system that requires infinite growth. reply callmeal 11 hours agorootparent>that's bad because the income is first taxed when the corporation declares it as income and then again when the shareholders receive the dividend. Why is that bad? The first case is income to the corporation and they pay income tax on it. The second is income to the shareholder and they pay income tax on it. How is it different from the corporation's employees paying income tax on money received from the corporation? >If instead you don't issue the dividend, but re-invest to grow the company, then the value of the shares can increase without creating a taxable event for the shareholders. That's true as long as the shareholders never sell their shares. Once they do, it's a taxable event like the dividend. reply dmurray 10 hours agorootparent> How is it different from the corporation's employees paying income tax on money received from the corporation The money paid to employees is only taxed once. We (pretty much everywhere) tax companies on their profits, but individuals on their income. It seems unfair, it leads to some weird but accepted inequalities (like the cost of renting a house vs buying), but no alternative seems to work. reply consp 12 hours agorootparentprevOr tax sale of shares the same so there is no loophole and you can either spend it on something useful or lower taxes for everyone instead of just for shareholders. reply lifeisstillgood 12 hours agorootparentprevSo is this the difference between capital gains and income tax? reply dmurray 10 hours agorootparentprevThis is nonsense because companies can and do replace dividends with share buybacks. While sometimes criticized as \"executives juicing the stock price because that's what their incentives are tied to\", in fact investors recognise that buybacks are economically equivalent to dividends, but tax-advantaged (for exactly the reasons you gave, they don't create a taxable event for the shareholders). One problem with buybacks is it's socially difficult for companies to replace dividends with buybacks - by convention, dividends are usually issued on a regular schedule and buybacks are ad-hoc, so \"cutting dividends\" is seen as a sign of a company that no longer has reliable profits. But that really is just convention and it would only take a few companies switching to normalize this. reply lotsofpulp 17 hours agorootparentprev> For whatever reason we don’t as a society let “tech” markets mature. We demand growth long after everyone is satisfied. That reason is people like more money than less money. No one logs into their brokerage account and invests in Sonos because they have a great product that is growing (or shrinking) at the rate of the speaker market. People want to see their year end report at least equal the broad market returns. The directive for all business leaders is to hit those benchmark returns, not pump out a solid speaker for however many years. And if a private business owner operates their company in a way that lags the market’s returns, then they are basically doing charity work. They’re going to have to pay a lot of cash compared to their competitors who can use RSUs to incentivize employees. reply benreesman 17 hours agorootparentWell, we could at least examine the idea of paying executives over a longer time horizon. Clearly everyone likes money. We could pay them for good things rather than the transient illusion of good things. Yes it would be imperfect. No it wouldn’t be worse than this mess. Bell Labs didn’t invent the transistor on this model, JFK didn’t send us to the moon on this model. This “privatize the commons of a century of effective public/private partnership” model is going rather shit in fact. reply lotsofpulp 16 hours agorootparent>Well, we could at least examine the idea of paying executives over a longer time horizon. Every publicly listed business already does this, in the form of stock grants and options with various targets to hit at various intervals. See bottom of page 51 for an example: https://investor.apple.com/sec-filings/sec-filings-details/d... It’s where all those rage bait headlines of extreme executive compensation come from, from maturing equity granted before the stock appreciated a good amount over the course of a few years. reply benreesman 14 hours agorootparentThere is absolutely no basis for the sweeping, extraordinary claim that “every publicly listed business” is managed and incentivized around sustainable long-term value. I hate to be aggressive but it’s really pretty godawful that people let absurd, corrosive claims like this fly. There is a creeping normalcy to weird Art Laffer talking points and weird Milton Friedman Freak Offs with no evidence. Things suck for the typical person since Dick Cheney and Art Laffer started “cutting taxes”. You’re wrong in a way that demands a complete ignorance of everything from news to history to human empathy. This mindset needs fucking therapy and where therapy fails the legal system for a fucking change. reply lotsofpulp 14 hours agorootparent> Well, we could at least examine the idea of paying executives over a longer time horizon. This is not > There is absolutely no basis for the sweeping, extraordinary claim that “every publicly listed business” is managed and incentivized around sustainable long-term value. There has been plenty of research into figuring out how executive compensation can be tied to longer term performance, but “sustainable long term value” is such a nebulous term, I have no idea what it could mean other than a fantasy where people are able to magically measure everything they want. https://en.wikipedia.org/wiki/Executive_compensation I only meant to highlight the fact that it is standard practice at publicly listed businesses to hire consultants whose job it is to figure out how to align executives and reward them for achieving long term goals. Maybe you think the current timetables are not long term enough, or the measures are not correct, but it’s not as if cash is being handed out Willy nilly. reply benreesman 13 hours agorootparentNVIDIA is posting profit margins up there with the Dutch East India Company (check it) on the back of the “agents” that are about to obsolete not just programmers specifically but white collar workers generally. We’re handing out trillions in cap for press releases. What on God’s green earth the fuck are you talking about? Willy nilly? Will Wonka with a chocolate factory is closer to earth. reply consp 11 hours agorootparentAnd NVidia is pretty much a monopoly in its field like the VoC was, only not legally bound. But the AI boom is pretty much a tulip mania at this point so I would hedge my bets. reply alkonaut 10 hours agorootparentprevBut Sonos doesn't sell any services/subscriptions, just products, correct? So even if they wanted to have recurring revenue how would they do it? They sell gadgets? reply wiether 8 hours agorootparentThey sell \"Sonos Radio HD\", a subscription based radio service which is supposed to be an upgrade from their free offering. But as much as I dislike the \"new\" app, it doesn't push subscribing to this service, so I'm not sure they absolutely want device customers to become subscribers. reply mfld 6 hours agorootparentIt would be a bad timing if they pushed the subscriptions already... reply Iulioh 6 hours agorootparentprevThey don't push the subscription..yet I hate the slippery slope fallacy but this is how was gonna end reply mixermachine 9 hours agorootparentprev...so far, yes. But somebody has to pay all of that new network traffic and cpu cycles ;). reply alkonaut 9 hours agorootparentI'm sure it's one of the biggest questions asked by the Sonos C-suite: how do we get recurring revenue or make the moat wider. But that goes for every product company in the world. reply givemeethekeys 12 hours agorootparentprevBait and switch is the fundamental problem. Abuse of power. reply atoav 11 hours agorootparentprevAs a music fan one would think I'd be their target group. But I haven't even considered their product and classified it as \"some smart crap that is an excuse to syphon data out and lock me in\". So all stick, no carrot. reply Nursie 6 hours agorootparentIt never really was that at the beginning. It was a good, locally-controlled system which would build itself a wifi mesh (back when that was unheard of) be configured to pick up things like samba/cifs shares and play your library, with some really neat features like combining speakers into stereo pairs or surround systems, and then playing your music and any input devices arbitrarily across these zones you have set up. At some point they integrated spotify and other similar services, which risked what you talked about, but was fine. There are even third party controller frontends available on linux. But recently (mid 2024) they delivered an absolute stinker of a new app which routes everything via their cloud, fails to load half the time, barely responds, and looks suspiciously like that grab for control you imagine reply nelox 13 hours agorootparentprevAgree. Just ask Steve Jobs. reply observationist 20 hours agorootparentprevEngineers are in a better position to understand what the customer wants and needs. Salespeople are there to sell their product, and fundamentally don't need to understand what the customer wants, or needs. Give a good salesperson a handwavy outline of something to sell, and they will sell it. They don't need technical accuracy for success. Yes, this is bad for customers, and makes life harder, and results in ridiculous, counterproductive, infuriating situations for IT staff, engineers, and other people who have to deal with the technical realities of every day business. A salesperson can just mash psychological buttons in manager's brains, and they'll make the sale. The consumer, in enterprise level markets, is hardly ever the team or individual in charge of operating the technology. The consumer is the manager, or managerial team, looking to check boxes and shuffle numbers and spend $X on Y department, for which they get rewarded for a wide array of arbitrary outcomes, almost none of which have anything to do with the practical impact of the product in question on the people who end up most affected by the purchase. If an engineer with a solid understanding of the product being sold is in charge, he's in the best place to rein in the sales and marketing teams, and to direct development based on customer reality. This probably results in lower profits, overall, but a better product, and a better reputation in the long run. reply dkokelley 19 hours agorootparent> Engineers are in a better position to understand what the customer wants and needs. Salespeople are there to sell their product, and fundamentally don't need to understand what the customer wants, or needs. Why do you say that? My gut reaction is that the opposite is true. Salespeople must understand their customers' wants and needs in order to effectively sell! Engineers are generally a step or two removed from the customers. This may be an unpopular take on HN but I'd wager the people who spend time directly with the customers have a better chance at understanding what they want. Taken a step further, customer support probably has the best understanding of their markets' needs! reply atonse 19 hours agorootparentI'd go as far as to say that the role doesn't matter, it's the attitude of the individual. I've worked with a few developers AND sales people that didn't give a hoot about what their customers thought. In the case of Sales, they only cared about making their targets. In the case of the devs that didn't care, they spent 99% of their time doing silly (in my opinion) arguments about frameworks, design patterns, and whitespace and formatting rules in CI. Not that things like design patterns are inherently silly. But if they don't result in a better customer experience (via more stable and maintainable software, for example), then it's a waste of time. I'm a developer by trade but have ALWAYS had an attitude of \"it only matters if it's useful to the user\" – and have butted heads sometimes with developers on which features to prioritize. reply majormunky 19 hours agorootparentprev> Taken a step further, customer support probably has the best understanding of their markets' needs! People working in customer support, from my experience, sort of see the anti-survivorship bias working in action. Not many people call up to say how well something works. I would agree with you though on good Salespeople (ones that do try to understand what customers need and all that, not necessarily ones that sell the most) knowing what the customer wants/needs. reply saghm 18 hours agorootparent> People working in customer support, from my experience, sort of see the anti-survivorship bias working in action. I used to see this all the time at an old job where my team worked on open source client libraries for using the main product that our company sold. A decent number people seemed to think that an increasing number of tickets being filed against one of the libraries was a sign that users weren't happy with it, but it always seemed obvious to me that you couldn't easily conclude that; you might have 99 happy users with no issues for every 1 unhappy user who filed a ticket, or you might have literally only unhappy users and nobody without issues. On the other hand, getting literally zero tickets might mean that you have plenty of happy users, or it might mean you have basically no users at all. I'd often talk to younger engineers who were interning on the team or recently joined full-time about how this dynamic informed how I approached my job; usually, we'd only hear from users who had issues, so the \"goal\" in some ways to was to make the software so good that you'd never hear from them. If you did hear from a user, that was a valuable opportunity where you might learn something you could do in the future to make things better the first time. reply chiefalchemist 17 hours agorootparent> so the \"goal\" in some ways to was to make the software so good that you'd never hear from them. Yes. There are people who talk about product experiences that delight or whatever. Nah, the ultimate experience is one that's so flawless, so frictionless that it's completely forgettable. The user doesn't want to remember anything. They have a problem a/o need, the goal is to make it disappear w/out a trace. reply magicalhippo 17 hours agorootparentprevIn my experience it's more like customer-facing people, sales and support, get to know the customers needs and pain points, while good technical people knows the limitations and possibilities of the systems involved. By working together the sum can be greater than the parts. As a dev I strive to talk to sales and support for this reason. It's not seldom I can do a small change that drastically improves the user experience for one or more clients, be it existing or potential. reply Wolfenstein98k 18 hours agorootparentprevThink about individual incentives rather than of the role, though. I agree with your assessment, except that an engineer has the incentive to make the product work as specified. A salesperson is given their goals by management, and they are compensated on achieving that goal - not necessarily what the customer wants. reply ako 12 hours agorootparentToo many developers only focus on the specifications, and don’t try to understand the specifications by trying to understand the user. Instead they complain that product owners, product managers, designers, or analysts fail to give the proper specifications. I don’t see many developers really trying to understand their users. But this may be different per domain… reply alkonaut 10 hours agorootparentprev> the people who spend time directly with the customers Unless engineers spend time directly with customers, something is broken in the organization to begin with. If salespeople and customers dream up solutions and then hand the task to produce this solution over to engineers, then that business is frankly doomed. reply observationist 19 hours agorootparentprevYour gut reaction is something salespeople play off of. I've been in the sales position before, handling the people in charge of making the purchasing decision, selling them bells and whistles they absolutely didn't need, but giving them the emotional satisfaction of a \"successful\" transaction, leaving with a sense of victory, that translated into a strong relationship and many years of repeat sales, with incremental upselling over time. Good sales, ethical sales, aren't parasitic. A vast majority of sales in todays markets, especially in enterprise markets, are parasitic. The salespeople are interchangeable. The ones that make the most money are the ones most willing to be parasitic. The sales script is targeted and tailored to the intended audience, which in most large companies, is several degrees of separation from the eventual user of the product. You don't need to know what the end user needs. You need to know what the person in charge of buying wants, and that's ultimately emotional validation, hope, a sense of \"innovating\", a feeling of victory in pricing negotiations, being respected and treated well, and so forth. You can run them through the wringer with sales engineers and migrations after the contract is signed, and even if the end user and the product engineers recognize that your product is the wrong tool for the job, that won't matter if the buying manager is emotionally satisfied with the transaction. People will bend over backwards to justify what they know is \"right.\" A salesperson CEO will make more money, but will make the world a shittier place, because they're the cotton candy of management. They'll burn credibility and reputation in exchange for profit, kick the can down the road for someone else to clean up the mess later. Sure, in a healthy, respectable, ethical, functional company, you'd be right, and the CEO would also be the best salesperson for the product, because they'd know it, and the customers, inside and out, and be able to explain and demonstrate exactly what was necessary and why, and justify all the costs and benefits. This is a world that has Goodharted the measure of success - profit - and empowered people in the execution of shitty behavior. The market rewards higher profits and punishes \"failures,\" often completely out of sync with quality and merit. We don't live in a good world - companies that behave like you describe would be wonderful. We live in a thoroughly enshittified world, and a whole lot of people \"earning\" a whole lot of money are in between you and any meaningful change. From Apple and Microsoft on down, companies want endless, infinitely increasing returns year over year, and they will do anything that isn't explicitly illegal to get it. They'll also do illegal things if the cost of getting caught is less than the profit earned. Alignment with end user needs, benefit to the consumer - these are far down the list of things meaningful to the systems and people making decisions on how money is spent. The job of a salesperson is to understand that system, and exploit it for the benefit of their company. reply redserk 20 hours agorootparentprevNot sure if I agree with an engineer inherently being better here. The ideal case is having leadership who uses the product, or at least is willing to walk in the shoes of an end-user. Plenty of engineers do not do this either. reply sgarland 19 hours agorootparentAnecdotally, having worked at multiple small-medium companies with a variety of leadership backgrounds, the worst have been sales background. Engineering backgrounds have ranged from OK to great. reply scarface_74 14 hours agorootparentprev> Engineers are in a better position to understand what the customer wants and needs As an engineer, I had no idea about: - what the utility companies wanted when I was working for a SaaS company that printed and processed bills - what the field service techs wanted when I was writing software for ruggedized windows ce devices - what the railroad car owners or repairmen wanted when I was working for a company creating a SaaS (https://public.railinc.com/sites/default/files/documents/CRB...) - I knew nothing about what the healthcare industry needed in the three SaaS companies I worked for including software for health care workers dealing with special needs kids - the various “enterprises” mostly in the edtech or state and local government space in consulting. reply rezistik 13 hours agorootparentIn all of your examples you're working at a company, ideally the person running the company had that domain expertise. reply ako 12 hours agorootparentNo, the person running the company has expertise running companies. Customer understanding lies with designers, analysts, product owners, product management, but also sales: what is the pain we’re addressing, how can ensure the customers really understands the consequences of not addressing the pain, how can we ensure the customer sees our product is the best to address their pain. reply karaterobot 17 hours agorootparentprev> Engineers are in a better position to understand what the customer wants and needs. Salespeople are there to sell their product, and fundamentally don't need to understand what the customer wants, or needs. There's no reason to believe an engineer would understand the customer needs more than a salesperson. I know a lot of engineers who would do literally anything to avoid dealing with a real customer. At the companies I've worked for, engineers don't even talk to customers if there isn't a specific, technical issue they need to be there for. Meanwhile, salespeople actually talk to customers, probably more than anyone except support. reply jedberg 18 hours agorootparentprev> Engineers are in a better position to understand what the customer wants and needs. Salespeople are there to sell their product, and fundamentally don't need to un",
    "originSummary": [],
    "commentSummary": [
      "The Sonos CEO has resigned following a controversial app update that required users to replace costly sound systems, causing customer dissatisfaction. - The update introduced a cloud-based system, moving away from the reliable Universal Plug and Play (UPnP), which led to connectivity issues and increased complexity. - This situation underscores the conflict between business strategies and maintaining customer trust, as the CEO transitions to an advisory role with a severance package."
    ],
    "points": 409,
    "commentCount": 493,
    "retryCount": 0,
    "time": 1736797368
  },
  {
    "id": 42696691,
    "title": "In the belly of the MrBeast",
    "originLink": "https://kevinmunger.substack.com/p/in-the-belly-of-the-mrbeast",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"kevinmunger.substack.com\",cType: 'non-interactive',cRay: '901fe4679a41e600',cH: 'fRVQOBO7Jy.ZvMr2JHbQz90T.PsCl8y0CIIzfRchxSQ-1736881470-1.2.1.1-MoBJ4zxzcAPXUtqtLTYZEwiWHMhXtq1cd5Tk2mmMC4YuYx5n9zIhYfVVwNJ1lFEd',cUPMDTk: \"\\/p\\/in-the-belly-of-the-mrbeast?__cf_chl_tk=.hI5vsGyd6nDt5dOdzpcqY34qOspSGki.uZyo_SBmiw-1736881470-1.0.1.1-qGGWE7p9jSD8IFYxfhfsoWb_Fd4jONsafaowRmwsNh8\",cFPWv: 'b',cITimeS: '1736881470',cTTimeMs: '1000',cMTimeMs: '120000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/in-the-belly-of-the-mrbeast?__cf_chl_f_tk=.hI5vsGyd6nDt5dOdzpcqY34qOspSGki.uZyo_SBmiw-1736881470-1.0.1.1-qGGWE7p9jSD8IFYxfhfsoWb_Fd4jONsafaowRmwsNh8\",md: \"l4TNcLDvd.uzJUcSydebXogQXGn8fYYCRZ9Wp6JMzLg-1736881470-1.2.1.1-paRwFxsXtt6WIIdx53q0xWN1sQ5oy566UEO6yDR6PACX4aHlnD9qDoPrLzzItww28mRuawHK79szlC0HNd3p7_gtQLOMtUZ5CVVSHPqY6Wc_iBW6eLIWByIM.gY0xkx0rmlD9Uii4YexfMKSegfb_MBC8RPKfoanatOJRfHSa3zSdBvdpKz7YerdTgVzU89K1zr2m0cv.JeWfjudO6d77cZh1FmhetG5PHAbWWiLZf54i9FyrF8MmCLhXdOPCWSbZS9UaFeU5TSmvPLx4i2lCXxvxyl_SU9.1zB7PMqEmObNoAggNAZ.TWly4S.n.HEGawOXPu9k6PTQlelpSL3sjdypoRCm2UWR4DAr27rsnnF7fROQf7FDmwlGtAOvmxdf46Woa8G30lg2KTKhdCSniU3cQ0omE6kheUrwMu_48Y.1WnS_3MuLIYs1.HXSdkD53k_NGGC_405I9BAt5LmoRQHlC_RsoyKvuWQKc0rD67Jl.Fjx3pEx.tLm6Ck8HWabAVfURQBDeYNWPAKvrGsczwvhVfYgDZunUqbfSXMb_ospuUujD0ruyygE5fiGZcqEoSSOJHi2K5yzHtB_x7Ldh6WClhAVdmx8tn2Uy.veWk11UJEMrgfhtRm6jAo0.02sUl0ar6iJS1N181UiO_AWhnGy_bZp.xVNyc.HH39aJnNDnnWOfljPFJJurWdk6kH9xUWoozKdkQyWdtkVB6z.hgb1FNXyr9Q8._YLeGtULB5GR_XWzD.iGiEVXIYwU8UGWxBDJWkfAwUv2sKekB3GehmKfQoHaXVmYKplyWazGnxERtcJIACxCcKKCHhSlMU_2SeJ6wlB9rXQydTzWrUwL2dVCUn1gwlW7T2mD3cTYS2FhqFRwsV9GBc4x0lgzBe35t2n2FX_OAw9gDH12xmCnK.vj4x_abHByNBndOuWRVb57GCWmeGe03Lsgc9Q9ZCW_quyKXebpi4OnuU8PttL7nJQjoTaMAs_OQ6w0pZbS6hgnQc73T0SgE7RepbMBzQ8RMq1pxcg.NZ1KvYAsYf9ZUUE8B.C5LV8NEgNx639Zq3rvQhdSojlE7en063cO0Hubs6uUundS3DpZpMjj1T9Tm1aBWWoMPdkvmDG9dCVFXV5QdwqU98CFXpJHFf91rDRy8L2XUO.OUQKRyO_Ludx49HWE.hGxYBM6WBkdJRf7.AzhtAIbeYCLS5kSq5t16DI2jubHppU3LJT2pqCpm.7SLKy_T76UvsyR7U9NJKz.wvDxGlu2fq_T5_XwuUAvwrv2Mr8gyRD9mqULl82b1b4ehdSMhRZRx7sFQ0xbcjXsYUdCMm95dIxQt_MjIZugnh_8MiqwASVBtBKSIoD3D3IWgrqYlyQTBBrU51Vf7XcPqH755EOCXqVueqaldKZOKLUTn57lIVkK2fC5SzLRulkTs93KIgThu4rQ_6ovnoju8IuLGVJj.dPmMj8dVtdKkFHkwtq0pLuaSRTNM.z7RTb9oUzifFOD3hoeALyX8FjxW5mwLLk0AWC1Cy97YGp9Z6f6aOqbCDd1zGwMW9JphW34HBy4PxYfFOcnCIYxAT4DeONOpYIYuo6I.ne3T5Nrvx64MW7bs2DeDfrsL2uJFt9tMqCxzy84s1UxbVncBsvLsjtFMoTu4MXdF97KVxIrzhf5YVoXMio158Tf5nnroy9UL84oV5ojQSqo8pf3G_DNdbY012bN.oCYhfw1QeNoohkfqqPdda7nMWNQpkejv6T8lLIZn7N5iTrMXFM6PXsczk671rO4dHNKIhFk076youlZQZ.zDr8RqNp52KSwLMVVeQi1kFmT59Zoh9vD.saBvs\",mdrd: \"kd2UD5DyD6V6w3TYBpBSerB9VwjIJHdjydRfZQdycwc-1736881470-1.2.1.1-M8OVxxAnn_QzuZDAVmKgGLE_zJPsFT1ILtN8uvsy_S1y505NLyRPGcwDOQCtZOijnImwd8GTMPpK_MTBpWwrRwFEJTwom373umvRjWj4eVsNuz4VIgx6O.hQQ3Gpq4mcIEdGoPODIwkOZZFg9.CXytVlJFZkmTSASQjLNf8VieUPxfensgfeKxRTsj89pq3DqYOQoLpd49Sld9SZ.QfrpRLjJKDvv59LSocY2cyrM14bMHpU4tomH.ClP5HURu7kHcqnNJ9m8e3V.kcekKUxAt0r8ztrOuL.Kq0j0W.vgIfujafSEFiA4ywHP2aTggFo.meGZSnulAeV7ba06gAh0iKSolBFN9w87.7hGRijadDyoRB22STXy7eNkBASQ380wxNo60X9OxB6rv0ffYZkmmaECpv62wjP1oq1kKeeMqDc0AsRILkohFd7jg9itIxRbY.3QYHQ0xoKZTH2sKtKZXlhTc.CwNsVEUnIN0LCwxmud8Sqfaymd_t3v3I2cRqm_vw07llbz2PYLWhBxHPZHLvBcBrqT_U9_b_almd4a3jK7BGybYBehfVZJ6MaUXW5nEkmZeEvmLlrsZljcUPcCP9VJfDx64V4WLNH0GP5RWmT8W77Ms1fGJ7HJJCPMqYEu3i07E0M4iBwgzPfa2pEeQB3uMOicp67k.auf0lCGau85KWdMpQo2yl4IdpKzd.IUBqPOvbPGv4LjhnCd4HahTW87jr0ic9zzF3ZqTtdxiUe2ET69QrA9mHFdoft8t8g1ejsG3eJWxq8o_9G_7XZiGUJrRIai5Ay0aiqKqYtP7bZxO5L.CsHQX.AjTEVZdvcOWu_1cuCGy6tRjWUFb0EhElj04niKAIZUbC9lb.9Y2Xhm5laU5TT_CiuDO8aHYAMNLSzvLk.NBp8HubhHAe6SwN6J.H3BP8FHa8y4wgMTvbnXqk8vvgHTGGq_k7.ZYOZstna6khKfxb1I046F_gb0oQyCyADoDDWC89wg4mNx4RiOy8vbnCRFGieRmrGd510peaOt6XnOl4lZfPrzCn9X9i.1jPY5ujhKUdqrEezOHBKAfK1uAQ7HvastQtxObppLeRiOq_nnQtAZ6UTmI8QFgaM9tR0Rm6a_DOgoM.09kiUYoeLBKhhfyTLIZ0hcu1zmTqghPAqfz2mKZ2E2JWZxZ6UlHNibNkHBz0ircupH80w6lTgOuZAitCXs3iAkTdKRCuQ4x7qOxty5_xj3YwPHCmNZ0wQcixM6qE06NVbb.Cd_LnBtsvUT.Oa6DR11mmUes3hJtwcx9RbKFwlAPTOjuVeoz3YDp_XpvZoqespxwgX7EkL8XWsWAb.UDbZKbEwwnXEwPIC.XaXFpbNxXxO2EL4KjKK2MNVVB0gESSV_yH1JsvlYdZZnaFyPaLPtMbUcAxeCzy._XyWCfouPns.d3aN2Us5W6qKGr89btTRRqWkHlitaqR0NQ4sZnAQw4n.MmnIcwtTrxtpAN9Z3CcZk9ahnZ7cZNTQzbnny5vkcEBvlzHzILxesg4LMUNlrfi1NlFd7oO9ubjCuq9nJL5mNdqHKdgEyDujHgPvjhyhYWSsqNSGfZbz8zuEVhSHPueRi3QnHUvE9fUkdJHKLFqhTBMhJyzH4uuMTxGrVuP9jSY.AYmXkA3R7lDRZK_JQU1EVDlNcuUAPzkx6JCU9B2qSqJxPNQbQ4mNEzaUZMcW2hGCFP6ppfnY2esrU7LqvG7ekozv2uWBQaHWriBMIpAV7nNrcHpSt5bySR85rPOu2ZOqeFDFBZJqj.qjLpVwGUwpr8rmrDpiGWLXdGVyTKBglTQvBak7ptP5M.jn_dfbfVoJi99R_NN9CXtGNauY8JoVXd9HVc.JBJnOxoextJQ6VYHOgZWhs_z.ULOi1SPMJLHHThkshgKKJcxY5p.jrWtmQ9DO7AGRShaD8Xs64hCtMTnrMP10XNOvea7p74jybEkWd4oahmPvVeRhqVdEB7_cuhCE6ANEPwCOZqrus8fbxq9CJgngAFTSuOzul.QC4AM3Ic3Ge38YXoAMds2dMJ4CDN7sB7N2EsyVjf5aJDGSDH.FIPxKGiZaxCCkrfU6NtcQBm9holX9e4AUY9fxPoRw2mngMw9p2DNS6e2TUklRsSv1JGUE3VpQTrjl3HxZRtY4UpiAOIj.QJQkqe0xfnoxm2Cs.QrfKja.LDvzGS1tnVMm3nYKnvQhcT6.06FYap4XG02St9vPHNDIvwr2huZzuxnqoM1XR8..lXqt8wTy7b2vwwlra9HVcFBNVJgE3No8bpCpPB1An3LDkag1QEI5qy_sjkXc5RqqIbE0QG.AETJlzIDGQlFwfMuLZuCTZ8jjZmyrge9SN9BEehkjVQHgZR3qsrIVzPMfI_ebYRv1NXocOXoJMmTE5N1BlgYTZTMapqVDuK_0oyx4FU8Kk4qf\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=901fe4679a41e600';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/in-the-belly-of-the-mrbeast?__cf_chl_rt_tk=.hI5vsGyd6nDt5dOdzpcqY34qOspSGki.uZyo_SBmiw-1736881470-1.0.1.1-qGGWE7p9jSD8IFYxfhfsoWb_Fd4jONsafaowRmwsNh8\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42696691",
    "commentBody": "In the belly of the MrBeast (kevinmunger.substack.com)369 points by stafford_beer 5 hours agohidepastfavorite258 comments iambateman 4 hours agoFirst of all – the essay is phenomenal and his book is available online for free – https://www.cambridge.org/core/elements/youtube-apparatus/36... > “Communication within the YouTube Apparatus has no meaning.” The rapid feedback loop between creators and audiences (as constructed by platform metrics) means that the system more and more responds to itself. Rather than trying to go somewhere (as is the case with political ideology), the creator seeks simply intensification, to draw more and more of the world into his whirlpool of content. This idea – that meaning is replaced by intensification – helps me understand a lot about the world today. reply Salgat 3 hours agoparentFor people confused like me on what intensification means, it means maximizing the amount of attention and interaction that occurs. On Youtube this would be the metrics that drive engagement, including views, likes, comments, shares, and watch time. The issue is that the content focuses on driving engagement at the expense of communicating ideas with coherence and depth, for example by sensationalizing or oversimplifying a complex issue (especially for things like political discourse focused on sound bites and emotional appeals, or with virtue signaling and outrage culture). I think the above commentor is right, in my opinion, intensification shapes our world into being very reactionary, with only a superficial understanding of issues, and platforms like Youtube Shorts and Tiktok take this to its furthest possible level. reply llamaimperative 3 hours agorootparentFor an excellent, prescient, hilarious, and terrifying book on this topic, I highly recommend \"Amusing Ourselves to Death\" by Neil Postman. reply stafford_beer 1 hour agorootparentOP here -- excellent suggestion, I've been heavily influenced by this book and would also recommend Postman's \"Technopoly\" reply lalalandland 1 hour agorootparentprevThe creators publication frequency is also an important factor. If you don't put out content at least once per week you fall off the recommended and lose a lot of views. Once your content is shallow, simple and without reflection, you are trapped in a hamster wheel of click bait vapidness. reply cool_dude85 1 hour agorootparentIs this accurate in all cases? Isn't Jenny Nicholson one of the bigger YouTubers, with videos coming out maybe once or twice a year? reply radpanda 50 minutes agorootparentSeems like it might be the exception proving the rule. People say “every” restaurant these days needs to use something like Toast to provide online ordering and needs to play nice with DoorDash for delivery and needs to host ghost kitchens to increase income, etc. Of course there’s that one old-school place with the established reputation that does simple dine-in only and is thriving. But the new upstart can’t just not play the game - that privilege is reserved for those who have already won. reply gilleain 11 minutes agorootparentprevThere are a few 'long form' creators like Jenny Nicholson (I recommend the one about the failure of the Star Wars Hotel!). Contrapoints (eg the Twilight one), Big Joel's (recently made a 6hr one!), FoldingIdeas and so on. It's a very different model, and a number of these creators also make videos for Nebula. reply nemomarx 32 minutes agorootparentprevJenny Nicholson and similar accounts rely on other channels than YouTube notifications. basically their video releases become events big enough to get minor news attention, chatter on discord, xitter traffic, etc. if your channel doesn't have dedicated enough fans to do that it's not gonna work on you. and you almost certainly aren't getting news coverage of your review of a star wars hotel, you know? Jenny is rare for that. reply prpl 2 hours agorootparentprevYou see this a lot in strange ways these days. Rage bait, feigned ignorance, and things like that. It’s anti-quality and it’s just as effective (if not more) than quality content. reply _DeadFred_ 1 hour agorootparentWhat was the Twitter joke. 'If I want an answer to a programming question, I post the question, and then an incorrect response from a different account.' No ones posting to help, but a lot will post to smugly correct the wrong answer. reply brandall10 2 hours agorootparentprev\"at the expense of communicating ideas with coherence and depth\" To be fair, while shorts is clearly designed to generate high virality and compete w/ TikTok, YouTube does incentivize longer form content. For regular videos the platform appears to optimize for engagement at about the 10 minute mark. Political/social discourse is complex and I believe goes beyond a simple soundbite problem. One could argue this began with 24 hour news cycles with all the time in the world, and news had to become entertainment to fill the space. The movie \"Network\" presaged this sensationalized this culture situation well before it became a thing, and certainly well before social media was conceptualized. reply bilbo0s 3 hours agorootparentprevI think the above commentor is right, in my opinion, intensification shapes our world into being very reactionary, with only a superficial understanding of issues In fairness, this is how the world has always been. In the US for instance, back when there were only 3 networks and a channel for public tv, people were \"reactionary, with only a superficial understanding of issues\". reply Salgat 2 hours agorootparentTo some degree yes. Funny enough, llamaimperative's book suggestion goes into detail on how television is where this really started ramp up and how the Age of Reason was likely the peak of rational argument, where the focal point of transfer of information was through the written word. \"He repeatedly states that the eighteenth century, the \"Age of Reason\", was the pinnacle for rational argument. Only in the printed word, he states, could complicated truths be rationally conveyed. Postman gives a striking example: many of the first fifteen U.S. presidents could probably have walked down the street without being recognized by the average citizen, yet all these men would have been quickly known by their written words. However, the reverse is true today. The names of presidents or even famous preachers, lawyers, and scientists call up visual images, typically television images, but few, if any, of their words come to mind. The few that do almost exclusively consist of carefully chosen soundbites. Postman mentions Ronald Reagan, and comments upon Reagan's abilities as an entertainer.\" https://en.wikipedia.org/wiki/Amusing_Ourselves_to_Death reply lupusreal 1 hour agorootparentReagan apparently hated reading and would often skip written briefs given to him by, for instance, the CIA. Then somebody got the idea to put those briefs in the form of a television news style video made just for Reagan. Some of them are on youtube now. They have the tone of spoonfeeding a midwit. reply 1659447091 44 minutes agorootparentTrump was/is the same. At one point they tried powerpoint like presentations with graphics. I don't know about Reagan, but from my personal experience with dyslexia (though I love to read--and dislike videos--even as it takes forever), I think Trump may be dyslexic. I would not be surprised if Reagan were too. I only wish it was more public (if true). It would help eliminate the stigma and eliminate most of the cheap shots about how he can't read or spell and how his speech is \"simple\" (as he has trouble pronouncing more complex words). Things that those of us with dyslexia can have problems with also. *I did not vote for him reply _DeadFred_ 1 hour agorootparentprevThat's such a wrong take. Sunday TV was so boring because it was filled with panels of knowledgeable people calmly talking about subjects they were extremely knowledgeable about in calm, rational productive manners. Todays panels start with known battle lines already drawn populated with non-knowledgeable grifters. TV was also required to air a minimal amount of educational television for children under 16 during the day. I learn way more on days home sick (latchkey kid) than I'd learn at days in school. reply achierius 3 hours agoparentprevBaudrillard just gets more relevant every day. Honestly I find it hard to imagine how someone could have media literacy in the modern day without coming to an intuitive understanding of semiotics, whether they know it or not! reply thundergolfer 2 hours agorootparentHim and also Marshal McLuhan. McLuhan realized all the way back in the 60s that computer technology (like all technology) in some sense wants things and manipulates the user to get it. The 'electric' technologies have their own logic and are not neutral on questions of humanity, politics, nature, etc. reply Communitivity 3 hours agorootparentprevI called myself a Semiotics Engineer for 4 years, but the title didn't catch. I did domain analysis, logical model creation, concrete model creation in XML/OWL/KML, model review and improvement, semantic reasoning-based system design/implementation, and message system design/implementation. This was before the rise of ML. reply Xmd5a 2 hours agorootparentWhat's your take on LLMs ? I ask you to comment on any aspect, whatever you think is the most interesting from a semiotician's perspective. reply pjc50 2 hours agorootparentEveryone who is familiar with Baudrillard goes \"simulacrum!\" whenever they encounter LLM output. LLM output is after all a pure chain of symbols that is extremely far removed from a connection with ground truth reality. reply garte 2 hours agorootparentI'm not sure it's that direct of a connection. There's something to be said about the structuralist part of it: using large amounts of text as a rule set to return a semblance of truth seems to be a structuralist's wet dream. It's like drawing the map for the king: the real is being represented by reducing a huge number of data points to a mixture of randomness and hard rules that pretend to be real. At the very least it's a form of hyperreality as far as I understand it. reply Xmd5a 18 minutes agorootparentIndeed this is what I was aiming at, however the concern for (a semblance of) truth seems rooted in a view that locates meaning in what signs refer to. This view feels incomplete when faced with a dyadic model where the relationship between signifier and signified takes precedence over reference. The notion of simulacrum only emerges in a technical culture that has elevated 'reality' to a special status. After all, what is 'reality' in technical systems if not itself a simulacrum? Hilbert's program, symbolic AI, rule systems, ontologies, the semantic web - they all struggled to capture reality as a whole precisely because they tried to grasp it through formal objects claiming universal scope via the machinery of said formalisms. reply j45 3 hours agorootparentprevThat collection of skills is still valuable. reply jpm_sd 3 hours agorootparentprevYes, the 21st century is the age of simulacra and simulation. Post-truth society. reply coliveira 1 hour agorootparentI'm pretty sure this was set in motion in the 20th century. This century is only about refining and monetizing it to the nth power. reply stafford_beer 1 hour agorootparentprevOP here -- I like Baudrillard and McLuhan but the media theorist who best captures the present IMO is Flusser: https://kevinmunger.substack.com/p/the-discourse-is-the-cybe... reply aiono 3 hours agorootparentprevI find the ideas of Baudrillard really accurate in describing some parts of modern life, but to be honest I feel like he just saying random stuff when I tried to read one of his book. It's so metaphorical and abstract it's very difficult to understand what exactly he is saying. reply kelseyfrog 3 hours agorootparentMy best experience reading Baudrillard was out loud with a group. Some passages spoke to some but not others, but most generated discussion. Some are also obvious to us now in the TikTok age - uncannily so. reply aiono 1 hour agorootparentDefinitely when I read his works even though I didn't understand some of his writings it made me think about it. reply cess11 3 hours agorootparentprevHe's not \"just saying random stuff\", he was a very serious thinker. Unlike Derrida he wasn't much of a joker. Perhaps language is fundamentally metaphorical, and perhaps reality is actually abstract. reply aiono 1 hour agorootparentThat's just what I feel I didn't claim that it actually is just random stuff. But I value clarity and Baudrillard doesn't seem to try to be. However, as I said I do find his general points very valuable just his style is not my cup of tea. reply throwway120385 3 hours agoparentprevIt also explains why there's been an alarming trend over the last 10 years of people just getting more vehement about everything. reply dialup_sounds 1 hour agorootparentWe started attaching public comment boxes to everything and now everyone thinks their opinion on everything is important. reply dymk 3 hours agorootparentprev10? We’ve been getting steadily more polarized since at least the 80s. reply ffsm8 3 hours agorootparentPossibly true, but I'm sure you'd agree that it can't really be called steadily since around 2010-2014 reply kevin_thibedeau 3 hours agorootparentThere is a straight line through 70s Falwell, 90s Limbaugh, tea party, to MAGA. All fueled by a self-reinforcing rage machine. reply RajT88 3 hours agorootparentLeft leaning folks are swept up in rage machines too. Leaf through the BoingBoing BBS sometime to get a sense for it. reply dmurray 54 minutes agorootparentWait, in my media bubble the American left is the one consumed by rage. The right is stupid or craven or greedy or just evil, but true righteous fury is reserved for those who saw a woman's rights not getting respected one time. reply llamaimperative 3 hours agorootparentprevWhat an excellent example of the wild asymmetry of the \"both sides\" narrative: \"The right wing is off the rails, here is a list of various lunatics each with audiences in the tens of millions. There are actual theocratic and neo-Nazi elements just one or two hops away from the President.\" The left is crazy too, just look at the BoingBoing BBS!\" Good lord do you hear yourself? reply RajT88 2 hours agorootparentI wasn't suggesting an equivalence, just that the phenomena of the rage machine exists on both sides. As an exercise, try coming up with some metric to measure it. Could be inflammatory posts, or the comment count on inflammatory posts. Compare BB BBS with some rough equivalent right-leaning place. You'll find it's worse in the right-leaning forum, no doubt. But the phenomena exists on both sides of the political spectrum. Many trends among one side of the political spectrum are mirrored to a lesser extent on the other side as well, and that's interesting don't you think? reply llamaimperative 2 hours agorootparentI don’t find it that interesting because it’s obviously a consequence of our information environment. We have constructed algorithmic outrage machines and deferred thought and curation to them. It’s far more interesting to me how one side of the political spectrum was so totally swallowed by this system, to the extent that literally every single news story is received with outlandish conspiracy theorizing from rather mainstream right wing media. The null hypothesis is that actually both sides should be equally distorted, but it is very obviously the case they are not. That is what deserves inquiry. reply geodel 1 hour agorootparent> but it is very obviously the case they are not. It not obvious and also doesn't seem true at all. Still one may continue to investigate with this assumption but then result will neither be truth or much useful. reply RajT88 1 hour agorootparentI would agree it's not obvious - but also if you don't think it's true, I'd love to hear why you think that. If you have numbers, even better. reply llamaimperative 1 hour agorootparentprevYeah, it really is obvious. Here's one excellent example: the dominant right wing media apparatus knowingly engaging in a conspiratorial lie that fetched them a $787 million punishment. https://apnews.com/article/fox-news-dominion-lawsuit-trial-t... reply ahmeneeroe-v2 1 hour agorootparentHere is an excellent example that many people think you're wrong: https://en.wikipedia.org/wiki/2024_United_States_elections reply llamaimperative 1 hour agorootparentYou must've forgotten what the conversation is about. It's about the degree to which each side is wrapped up in an outrage machine. That would be reflected in the election results, and not in the way you're implying. reply ahmeneeroe-v2 1 hour agorootparentwhen my side wins it's good and true and when the other side wins it's the outrage machine reply llamaimperative 1 hour agorootparentThat's not my belief, which is why I didn't post the terrible evidence of election results. You did. I posted a court settlement for the crime of knowingly producing untrue, defamatory outrage at massive scale. Note how mine is evidence for my argument. Yours is evidence for nothing at all. reply davrosthedalek 1 hour agorootparentprevThe murder of the united healthcare CEO, or more specifically, the positive reaction towards it, seems rather associated with the left, doesn't it? People who want a certain party to be in power should hold that party to a higher standard. Independent of the party. Being \"better than the others\" is not good enough. reply llamaimperative 1 hour agorootparentNo, not really. Harris vs Trump voters who... Approve: 5-11% vs 2-8% Neither approve nor disapprove: 6-12% vs 7-13% Disapprove: 65-71% vs 72-78% Not sure: 6-12% vs 4-10% Not a super substantial difference. The outrage machine wins again! Source: https://d3nkl3psvxxpe9.cloudfront.net/documents/Reactions_to... reply ahmeneeroe-v2 1 hour agorootparentso the data shows that the left's approval of the murder is 37% higher on the low end up to a max of 5x higher (depending on how the confidence intervals map to reality). And that that the left is anywhere from 20% to 3x more likely to be undecided about the morality of an assassination. reply llamaimperative 1 hour agorootparentJust make sure you're able to get yourself out of this knot at some point, amigo. reply ahmeneeroe-v2 1 hour agorootparentit's your data, not mine. I just did the math on it. reply TimTheTinker 1 hour agorootparentprevThat data is super helpful. From browsing Reddit, my impression was that the left strongly approved. reply llamaimperative 1 hour agorootparentTerminally online not-rich people across the spectrum approved. Other not-rich people seem to land in the \"vaguely disapprove\" realm IMO. Obviously the plutocrats are all terrified and think it's the worst crime ever. reply flir 1 hour agorootparentprevBoingBoing is still very much made in Doctorow's image. Michael Moore is an earlier example. Not suggesting equivalence, in fact I would be really interested to hear theories as to why right-wing polemicists are so much more popular (and numerous) than left-wing polemicists. On the face of it, there are a lot of left-wing things to be justifiably outraged about (especially right now). So why isn't left-wing outrage reliably bankable? I don't think it's a pattern tied to the zeitgeist, because you see it in talk radio too, which predates social media's Skinner box algorithms by decades. Side-question: why are there more left-wing political comedians than right-wing ones? reply llamaimperative 1 hour agorootparentSee these are interesting questions. I don't have great answers. IQ gap between the sides? reply flir 59 minutes agorootparentMe either. I think that's possibly a self-serving guess, to be honest. But how would we test it? On the comedians question: some people think it's because it's easier to be funny when kicking up than kicking down. reply RajT88 45 minutes agorootparentprevThis is a just-so rationalization, which feels good, but people have looked into many of these, and they don't really hold up. The most common one is that poor white people are overwhelmingly voting for Trump. The average household income of a Trump voter is something like 75k - hardly poor (depending where you're at). Anecdata: I know plenty of Trump voters who are very smart. A friend's dad has multiple PhD's and accomplished career as a theoretical physicist. He's also pretty racist. My father is a retired engineer, and doesn't like Trump, but keeps voting for him, because the Democrats are on the wrong side of issues he cares about. (Gun control, namely) The reality is likely to be - they have used the mountains of publicly available data, and fine tuned their messages with the help of a highly partisan rage-baiting media ecosystem to capture more voters. It seems to me, the right wing is more organized, and manages to keep their voters and party members more aligned and on-message. They also have a much more voracious appetite for fighting dirty (rough talk, conspiracy theories, whisper campaigns, untraceable mailers giving wrong polling place info to black communities, etc.) - something the Democrats do not have the stomach for. reply llamaimperative 28 minutes agorootparentThis explains election results (agreed) but I'm more curious why outrage-generators and conspiracists seem to have culturally taken a stronger hold on the right over the course of decades. reply ahmeneeroe-v2 1 hour agorootparentprev>There are actual [people that I label with bad labels] just one or two hops away from the President! My latest understanding of the US political landscape is that 2008-2024 the left got very adept at defining things as bad and then attacking those things. In 2016 the right started to learn to counter that, and in 2024 that finally died. In other words, you'll need to try harder than just calling people nazis. You're getting downvoted because people don't buy that 1) tens of millions of their fellow Americans are lunatics and 2) that the left doesn't have their own moral failings. reply dragonwriter 1 hour agorootparent> My latest understanding of the US political landscape is that 2008-2024 the left got very adept at defining things as bad and then attacking those things. In 2016 the right started to learn to counter that, and in 2024 that finally died. Every piece of this understanding is wrong. For one thing, the far Right in American has been better and more effective at that than any part of the Democratic coalition, since at least the 1980s. reply llamaimperative 1 hour agorootparentprevTheocracy is bad and neo-Nazism is bad. Trump had dinner with Nick Fuentes, who 1) is an open anti-semite, 2) praises Adolf Hitler, and 3) calls for white ethnonationalism. I don't need to write a treatise to explain why this is bad. reply ahmeneeroe-v2 1 hour agorootparentYou don't need to write the treatise because the era of that kind of \"logic\" winning elections is over. (ie the left being able to label whole political movements as bad because certain bad people associate themselves with it) reply llamaimperative 33 minutes agorootparentI didn't label a whole movement as bad, ya goofball. Well except for neo-Nazism and theocracy, the latter of which is explicitly counter to the US Constitution and the former is... well... you can defend it if you'd like. I said extreme ideologies (including the two I mentioned) are bad, and there's an asymmetry in their representation and proximity to power on the different ends of the political spectrum. reply cruffle_duffle 2 hours agorootparentprevOne only needs to observe societies response to Covid to see how “left leaning folks get swept up into rage machines”. People were cheering on cars getting towed from popular hiking spots, skate parks getting filled with sand, crazy people “protesting” beachgoers, etc. if you dared to suggest schools should open you were a grandma killing MAGA hat wearing pariah. Don’t forget the level of censorship, vaccine passes, wishing death upon those who didn’t get vaccinated, etc. No sir, people of all tribes are fully capable of getting swept into rage machines. At the end of the day we are animals operating on animal instinct. No tribe gets to claim otherwise. reply harywilke 3 hours agorootparentprevReminds me of this quote: \"The system itself could not have intended this in the beginning, but in order to sustain itself it was compelled to go all the way.\" -They Thought They Were Free: The Germans, 1933-45[0] [0] https://press.uchicago.edu/Misc/Chicago/511928.htm reply liontwist 2 hours agorootparentprevI don’t think you understand these groups and their motivations very well. Fear and concern for the future are much more significant than “rage”. reply nemo44x 3 hours agorootparentprevSo basically since when cable TV came into mainstream existence. reply spokaneplumb 2 hours agorootparent- Huge shift in (near-total abandonment of) antitrust enforcement starting in the late 70s, driven by Chicago school assholes. Centralized economic power. - Fairness Doctrine killed in the 80s, resulting rise of partisan AM radio and, somewhat later, Fox News. - Media ownership concentration rules neutered in early ‘00s (iirc). More centralization, again in the hands of big capital. - None of those rules ever applied to the Web, so when its power as a propaganda and agitation tool skyrocketed with increased use by normal folks (rise of Facebook; usable smartphones with the iPhone) that immediately headed bad directions. Now we have LLMs, which are at their most-useful by far when you don’t care about accuracy or reputation—so, scams and propaganda getting a big boost in productivity. reply dylan604 3 hours agorootparentprevI think you're confusing the issue. Cable TV wasn't coming into mainstream that was the problem. The issue was the 1996 Telecommunications Act that was the starting gun. reply jazzyjackson 3 hours agorootparentprevTurning attention away from each other and toward images of each other reply n3storm 3 hours agorootparentprevand I think \"literally\" abuse is a sympton of that reply alt227 3 hours agorootparentThey changed the definition of 'literally' to fit the modern meaning. You can no longer call it abuse now as the misuse fits the new definition. See definition 2 here: https://www.collinsdictionary.com/dictionary/english/literal... reply feoren 3 hours agorootparentThat definition genuinely gives me cancer. I seriously, 100% am going to die now because dictionary editors don't seem to grasp that this is simply a \"tone\" of ironically over-emphasized speaking similar to sarcasm, and not a new definition of one word. I'm 250% honestly in chemotherapy now because they don't get that. Veritably, indubitably, unarguably cooked now. Thanks, dictionary editors. reply jhanschoo 1 hour agorootparentThe stronger player was handicapped when they gave their opponent a handicap, and yet they still won; they now held in their hands their prize that was the match's prize. reply dghlsakjg 3 hours agorootparentprevLiterally false: https://www.merriam-webster.com/grammar/misuse-of-literally Use of literally in, well, the non-literal sense dates back hundreds of years. reply alt227 3 hours agorootparentI literally had no idea. reply iainmerrick 3 hours agorootparentprevBut come on, that's been going on for literally centuries. reply bena 3 hours agorootparentprevDickens did it. And people have been doing it since the 1700s. Not to mention, if you're using the word \"literally\" to mean \"something that actually happened\", you are also using the word wrong. Because it means \"relating to or expressed in letters\". I also notice people complain about \"literally\", but they never complain about \"really\" which also gets used in the same ways even though it means the opposite. And I've noticed people do it as a substitute for intelligence. They complain about these things to seem intelligent. To seem knowledgeable. But when confronted with knowledge that contradicts the complaint, they try to dismiss the knowledge rather than adjust their point of view. Similar with fewer/less. These words mean the same thing. There are no rules as to when to use one or the other. There was the preference of one guy, who even said that he had no reason for it, he just liked it. And people took that as an ironclad rule. Or the gif debate. People try to invent all of these rules, but get pissy when you point out all the places where English does not follow those rules. reply stonogo 13 minutes agorootparentThere have been thousands of years of written language, and the worst thing that ever happened was the invention of the dictionary, which enabled generations of prescriptivists to pretend that word meanings can't change once they're written down, despite thousands of years of evidence to the contrary. Maybe look up 'hidebound' sometime. reply alt227 3 hours agorootparentprevWhat would you suggest using instead. Actually? reply jamincan 1 hour agorootparentTruly? reply bena 2 hours agorootparentprevPeople are generally good at context. Tone, expression, etc, all of these things are parts of communication that do matter. Assume your audience is at least as smart as you are. reply alt227 2 hours agorootparentWhen communicating through text only, tone and expression is all but lost which means we need to rely on the literal/actual/exact definition of words to convey our intended meaning. However it seems people dont agree on the exact meanings of words (using literally in this case), and so the intention often gets lost in translation and causes disagreements. I feel personally this is a big reason why communication across the internet is becoming much more intense and full of conflict. reply Applejinx 3 hours agorootparentprevI think human nature dictates that this opens up a literal market for the opposite. People aren't served by exhausting hysteria, it's just a cheap date, a way to grab low hanging fruit. The more that's focussed on, the more an opportunity arises to cover abandoned needs and wants. The question becomes, is YouTube's algorithm good enough to itself pick up on this new market and serve it? I see no reason it couldn't. It's possible human algorithm-minders might sabotage this instinct by going 'no, this is the big win' and coaxing it towards MrBeast stuff, but surely the algorithm will eventually win out? reply parsimo2010 3 hours agorootparent> is YouTube's algorithm good enough to itself pick up on this new market Something I find interesting is that there are good channels producing very high quality (non-extreme or non-intense) content for many interests on YouTube and they coexist with the hyperbolic large channels. I suppose that they make less money, but they do so without a large production crew. I think the algorithm is supporting both types of content (content for myriad mindless viewers, and content for the fewer discerning viewers) and accommodates both scales. reply cess11 3 hours agorootparentprevBy \"human nature\", what exactly are you referring to? The statistically most common amount of extremities? reply Applejinx 1 hour agorootparentPeople tire of being poked with an algorithmic stick, even though it ensures a reaction. reply oulipo 2 hours agoparentprevExactly, intensification or acceleration, this is exactly the root of most issues. Since we've mastered energy (and in particular oil&gas), the world has been on an acceleration binge, which is now causing a lot of friction and overheating in the relationships and environment. We need to slow down and to connect back to nature reply worldsayshi 1 hour agorootparentSlowing down is not a solution since we're heading for a wall in some dimensions and a cliff edge on others. We need to find ways to drastically change course. We need to build maps and steering wheels. reply pixl97 1 hour agorootparentAnd we need to convince everyone to do it, or we just end up in the Red Queen scenario. reply nvarsj 37 minutes agoparentprev> This idea – that meaning is replaced by intensification – helps me understand a lot about the world today. I don't see much difference to the \"old world\" either. Yellow journalism existed in the 1800s. We just do it in a more modern format. reply lbotos 2 hours agoparentprevYou might enjoy https://en.wikipedia.org/wiki/The_Society_of_the_Spectacle reply irrational 4 hours agoparentprevNow I understand why numberphile has videos about infinity. I jest, but it seems like only certain content creators can get on the intensification train. reply EA-3167 2 hours agorootparentSeriously though, this is true. My YouTube feed has none of this \"intensification\" stuff. Perun, Blancolirio, everything Brady Haran has made (he's the guy behind Numberphile, Sixty Symbols, etc), Applied Science, etc. I think the idea that media aimed at education or sharing a passionate hobby is different from media that exists in the first place to just make money. If you start out with a goal that involves communication, I think it's more likely to stick than if your goal was just to become the Death Star from the start! reply hahamrfunnyguy 2 hours agoprevI ran a YouTube channel seriously for a couple of years. Chasing the whims of the algorithm contributed to burnout and now I only release one or two videos a year. My reason for starting a channel was to have a discussion around some of the projects I was working on that I found interesting. This never materialized. I never had a ton of engagement, but if I did most questions asked by viewers that are answered in the video. I monetized my videos and started making beer-money amounts of revenue. I put more and more time into them but never gained traction. I had a few \"evergreen\" videos that would make maybe a thousand bucks a year, the rest of the videos hardly got any views at all. Eventually, I found myself making videos to feed the algorithm not because it was a project that I wanted to do. This is where I had to stop. I realized that I just don't like editing videos. My channel makes no revenue now because YouTube requires an upload schedule and shorts. Mr Beast's job sounds awful to me. The videos I make now only get dozens to hundreds of views when they're published. I mostly share them with friends and in online communities where the info contained might be helpful. reply AndrewStephens 1 hour agoparentThank you for your story. I have been running a low traffic blog for decades now and there was a time when I craved engagement. I never put too much effort in but I did change the things I wrote about to try to get noticed, a strategy that was unmarred by success. The creators that find success need to pump out content at a ridiculous rate. It is a faustian bargain that sucks in a lot of people. reply coliveira 1 hour agorootparentThese people are essentially competing against an algorithm, not against other humans. I consider this to be an extremely distasteful endeavor. reply eitally 4 hours agoprevAt the top of the heap (Mr Beast, Nastya, Ryan, etc), this is true: > The ideal creator has no distance between themselves and their persona. They have been interpellated by audience metrics; their subjective experience already takes audience reactions into account. > Or more simply, YouTubers are not “Creators” but Creations. Audiences, rationalized by the platform, and the vloggers who upload the videos those audiences consume are not separable either theoretically or empirically. It's pretty obvious, too, because these YouTubers have a distinct theme where their popularity is dependent on 1) the whims and algos of the platform on one side, and 2) the ability for their audience to care and relate to something pretty dang detached and irrelevant from their everyday lives (unboxing, aggressive acts of charity, etc). While you hear plenty (Most? All?) YouTubers complain about the ranking algorithms & capriciousness of their overlord, I don't believe most channels are quite as vapid as those at the top of the heap. Lots of deep subjective content, and lots of freaking annoying CapCut edits, but also a primary focus on meaningful content relevent to viewers. These people may not be getting rich from their vlogging, but it's also not fair to call what most of them are doing \"vlogging\", either. It's video-based short form content curation for a clearly identified audience. Not remotely the same as how the big guns like Mr Beast have to view their work [where they're much more similar to a cable TV network or a commercial production company than an independent producer]. reply dmonitor 1 hour agoparentWell put. As long as channels like Technology Connections can remain financially viable on the platform and not beaten down by the algorithm, I really don't care how many Mr Beasts are making \"slop content\". reply dom96 20 minutes agorootparentI do. Slop content is melting the brains of the people watching that content to the detriment of society as a whole. reply antasvara 3 hours agoparentprev>but also a primary focus on meaningful content relevent to viewers. These people may not be getting rich from their vlogging, but it's also not fair to call what most of them are doing \"vlogging\", either. It's video-based short form content curation for a clearly identified audience. There's a fine line between \"content created for X people interested in Y topic in Z form\" and \"content that's relevant to my viewers.\" The former is a channel that is avoiding the \"creator\" described by the author. The latter is on a path towards the author's \"creator.\" For a long time, the two can be very similar. The group you are tailoring your content for and your viewers won't necessarily diverge quickly, especially in niche areas or highly technical fields. But they will inevitably diverge. Worth noting that the form this takes will depend on the topic. It's rare to find a creator that can avoid this trap long-term. I see it even with small channels I follow. reply hylaride 3 hours agoparentprevYoutube is also killing a lot of history channels because if there's any violence (eg war) they get demonetized, the algorithm avoids them, or they can even have their channels disabled. Most now blur out pictures of the holocaust, which negates a lot of the otherwise serious impact on a serious subject. https://www.youtube.com/watch?v=24QgMpvX3mw reply lolinder 48 minutes agorootparentObligatory plug for Nebula, where a lot of educational YouTube has gone for refuge from demonetization. Many creators will have different versions that they upload to Nebula containing the content that YouTube wouldn't let them add in. reply okdood64 3 hours agoparentprev> YouTubers are not “Creators” but Creations This is such a broad and general statement for a platform that is unfathomably big. I don't any of the mass market Mr Beast, Nastya, Ryan videos on my feed. At all. I get smaller (but still large) creators with videos that actually engage the mind. Example: https://www.youtube.com/@blancolirio But I guess that's the distinction between a Youtuber and Creator. reply mhartz 4 hours agoprev> The ideal creator has no distance between themselves and their persona. They have been interpellated by audience metrics; their subjective experience already takes audience reactions into account. Isn't this sort of one of the themes from The Prestige(2006)? That certain magicians were so dedicated to their craft that they became inseparable from it. The performance never actually stopped reply ericmcer 2 hours agoparentThey were dedicated to the craft though, there have been countless people who dedicated themselves to pushing the boundaries of their profession and lost their personal lives in the process. Losing yourself to achieve something new in math, art, science, etc. can be seen as a worthwhile sacrifice. Content creators feels more perverse because they are sacrificing themselves to making metrics go up. The act of creation is in service to metrics that please an algorithm so views go up. If the magicians didn't care about magic at all but were obsessed with optimizing the show around ticket sales it would be a shitty movie. reply suyash 4 hours agoparentprevGreat analogy! As a performing magician and a big fan of the movie, I get how obsession with a craft can blur the line between reality and performance. But that line still exists. The best actors, creators, and magicians make us feel they’re being real, even when they’re not. reply HanClinto 3 hours agorootparentThis is why I struggle with enjoying Andy Kaufman's content -- I'm never entirely sure where that line is. I respect his dedication to the craft, but I have a difficult time enjoying it -- on a meta level, it's unsettling. reply kevinsync 2 hours agorootparentKaufman was Daniel Day Lewis-level dedicated to the character, but there are others, Tom Green for instance, who ostensibly was just as dedicated for the first arc of his fame and career, then loosened his grip on the persona with age. I often think about his trajectory compared to the average social media influencer -- he pioneered so many things and has worked in a bunch of mediums while they're basically imprisoned in their chosen persona, doomed to repeat the formula / gimmick / character day in and day out until the novelty wears off for everybody and they burn out entirely 12-24 months later. The ones with the most longevity seem to have been able to retain autonomy as a creator rather than a creation, as mentioned in the article, allowing them to grow and evolve rather than forever being a one-note wonder whose entire raison d'etre is eating shoe polish on camera. reply jprd 3 hours agorootparentprevAlso, exactly his aim reply kayvulpe 3 hours agoparentprevA couple times that theme appears (there are more) --- https://youtu.be/uckLb_8LEGQ?t=36s ANGIER (scorn) It's misdirection- he leaves those things lying around to make you think he's using a double. OLIVIA All the time? He doesn't know when I'm looking ANGIER All the time, Olivia- that's who he is, that's what it takes- he lives his act, don't you see?! --- Also the dialogue after the fishbowl performance https://youtu.be/J8ZXT2HTxqE?t=34s BORDEN (points) This is the trick. This is the performance, right here. This is why no one can detect his method. Total devotion to his art... reply michaelcampbell 3 hours agoparentprevThis isn't purely new, either. I'm perhaps dating myself a bit but I recall that over the years I have seen a few actors have this weird vibe where they're never \"human\", they always \"on\" and seem like their actor-thing has totally subsumed their humanity. David Cassidy and Shirley McClain come to mind for me on this. reply islanderfun 43 minutes agorootparentI grew up watching The Rock. As an adult, it's hard to look past the persona he shows when talking about anything on any medium. reply qskousen 3 hours agorootparentprevI realize I'm probably in the minority for this, but for me when people create a \"persona\" for their media, it turns me away. I prefer watching people who are more genuine, whose content is less entertainment and more just themselves, even if that isn't what the internet seems to be looking for. reply michaelcampbell 2 hours agorootparentI find it somewhere between \"very uncomfortable\" and \"creepy\". Even as a kid something felt very off in those interviews. reply mrguyorama 2 hours agorootparentprevThe people you consider \"more genuine\" are just cultivating a different persona. Don't ever believe you \"know\" someone you don't. Parasocial relationships are harmless at the low level but quickly become toxic. Always meet your heros so you can understand they are normal and flawed humans reply cjs_ac 3 hours agorootparentprevPeter Sellers also had this problem; in his case, it was a problem with his personality (or lack of one) rather than something acting did to him. reply esafak 2 hours agorootparentComedians seem to exhibit this trait more often than others. Norm Macdonald had a somewhat similar vibe. reply triyambakam 3 hours agorootparentprevJohnny Depp maybe? reply banannaise 3 hours agoparentprevOne of the problems with modern social media (and digital media in general) is that this is now happening, to some extent, to everyone. This is particularly a problem for children, who are exposed to this so early that they may never internalize the difference between existence and performance. Bo Burnham said it really well in an interview: \"I'm saying I feel very stressed because I feel like I'm on stage panicking in front of thousands of people... and I feel like I'm trapped within a performance and I'm freaking out because of it. And 13-year-olds were going 'yeah yeah, I feel like that every day'. And I go 'what are you talking about?' and I realize that the stresses of a C-list comedian were democratized and given to an entire generation.... Social media has made life a performance.\" I'm not sure where the original interview is, but I found the quote at 9:43 of this analysis of Inside: https://www.youtube.com/watch?v=iHat1OlMPeY reply criddell 3 hours agoparentprevVonnegut also uses this in Mother Night. We are what we pretend to be, so we must be careful about what we pretend to be. reply vishnugupta 3 hours agoparentprev> they became inseparable If one spends most of their waking hours in front of camera producing video after video it's bound to happen subconsciously whether they like it or not. reply jplrssn 4 hours agoparentprevArguably also true for some (many?) tech entrepreneurs. reply liontwist 2 hours agoparentprevAnd that those who most successful are able to appear magical because they are willing to do things so unreasonable that the possibility doesn’t even cross your mind. reply infecto 4 hours agoprevNot entirely related to MrBeast but related to YouTube. I genuinely miss the older algorithm where after watching a video you would go progressively further down a hole of videos somehow related to the one you just watched. It was quite entertaining and really uncovered fascinating videos. reply hn8726 3 hours agoparentI have no clue how to use YouTube. It seems like as soon as it latches on 3-4 interests of mine, the entire home page is exclusively filled with videos relating to that. I can mark videos as \"not interesting\" but it doesn't do much. I will see exactly the same videos on the home screen, ones that I'm not interested in and don't plan on watching, for weeks or months sometimes. I'm sure there's plenty of interesting content about topics I haven't searched for, but YouTube seems intent on not letting me out of whatever bubble it thought out for me. reply NAHWheatCracker 3 hours agorootparentI think what you describe is what infecto was saying. You can't use YouTube to find interesting content anymore. You can only use it to find more of what you've already seen. In the past, it was better at unearthing new things. Personally, I added uBlock filters so the home page is empty and recommended videos aren't shown. I only ever go to subscriptions now. reply rendaw 2 hours agorootparentIt doesn't even show me more of what I've already seen, half the sidebar is videos I've already watched (or watched halfway before dropping, with a helpful indicator of my lack of progress). Like, \"we see you like video X, why don't you watch video X today?\" Thanks, I already have bookmarks. reply xoxxala 2 hours agorootparentprevSimilarly, I use Unhook because it gives me fine control over what YT displays. I now find YT to be completely unusable without it. reply OJFord 2 hours agorootparentprev> I added uBlock filters so the home page is empty and recommended videos aren't shown. I only ever go to subscriptions now. There's a setting to turn it off, no need for uBlock filters for that reply NAHWheatCracker 1 hour agorootparentIt's the hammer I have and it works on those nails, hah. reply JasserInicide 34 minutes agorootparentprevI've come accustomed to deleting cookies on browser close. The first ~10 or so YouTube page requests, the sidebar of recommended videos is pretty good. After that, as you said, it gets way too muddled. I think a good plugin for YouTube would be to always delete cookies before opening a video so that you're getting as close to a pure vanilla recommended feed as possible. reply magicalhippo 3 hours agorootparentprevWhile I do agree it has a very strong focus on suggesting more of what you've recently watched, I feel it's also managing to suggest new and interesting unrelated stuff from time to time. Some habits I have is to subscribe to channels which I truly enjoy, instead of marking as \"not interested\" I select \"do not suggest channel\", and be cautious of click-bait titles. If I get lured in, I remove them from my history. So for me it's mostly great, though I get your frustration as well. For example I recently watched a couple of informative videos on the LA fires as I have some relatives living in the area, and suddenly my feed is tons of that and little else. reply hbn 3 hours agorootparentI've found sometime in the last year or so YouTube has been suggesting random videos from very small channels much more, which I like a lot. Most of the videos are garbage, but every once in a while I'll find a gem that entertains me and my friends. Recently I found a video of a young kid doing a taste test of a sour soda, and then demanding his dad come over from the other room to try it too. At one point the kid does a really loud burp that I found funny. Obviously not something that will do numbers, but it satisfies my people-watching itch. reply jonasced 2 hours agorootparentprevI too liked to prime my own algorithm but Yanis Varoufakis book Technofeudalism kind of ruined it for me. On a individual level it's nice to get good recommendations, but on a societal level I think it's starting to get a bit scary to the point of me wanting to opt out and instead curate my own feeds based on first hand sources. reply magicalhippo 2 hours agorootparentYeah I get your point, though I almost exclusively use YouTube as an alternative to TV entertainment. That is, rather than watching Mythbusters, I'm watching Numberphile, FarmCraft101 and such. I specifically do not normally view \"pure\" news or similar. I might make the rare exception, like in case of the LA fire where I saw a clip from PBS. That is a very conscious choice, for reasons similar to what you express. reply kccoder 2 hours agorootparentprevI made the mistake of clicking on a Jordan Peterson video several years back. I'd never heard of him before and the title seemed interesting, so I clicked. 15 seconds in my charlatan detector went off, so I exited the video. For the next couple weeks I was playing wack-a-mole with a never-ending supply of manoshpere and right wing nonsense. Easy to see how so many people get sucked into sphere of influence. reply Arkhaine_kupo 1 hour agorootparentprev> It seems like as soon as it latches on 3-4 interests of mine, Its worse than that. I thought that Youtube worked as you described, trying to find videos suited to your interests but it actually works the other way around. Youtube has a series of rabbit holes that it knows maximise engagement, so its trying to filter you the human down one of those rabbit holes. Do you fit the mr beast ssniperwolf hole, or the jordan peterson joe rogan rabbit hole? Howabout 3 hour video essay rabbit hole, is that one your shape? Its designing paths for engagment and filtering humans down not filtering videos for humans, its perverse and awful and it explains why the algorithm simply does not work for humans, because you are not the target audience, you are the data being sorted. reply mavhc 3 hours agorootparentprevDon't use the homepage, use the subscriptions page reply cheschire 3 hours agorootparentWhen you turn off search history, it makes the homepage useless and the subscriptions page becomes unavoidably the next step. Discovery of content happens in the sidebar from videos I enjoy now, and only when I'm in the mood to discover something. reply x187463 3 hours agoparentprevI obviously don't know your personal experience, but your description is still how YouTube works for me. For example, over the holidays I would occasionally put on a video from a channel that plays holiday music with various videos of this guy's model train setup in the background. I immediately started receiving model train videos, which, of course, I had to click on and now I know a little bit about trains and building realistic environment models. That being said, occasionally I do have to go into my Google data and clear/clean the watch history to reorient my recommendations. reply infecto 3 hours agorootparentI don't think thats the case. Don't confuse homepage recommendations with end of video queue recommendations. It used to be end of video recommendations were heavily weighted on the current video or chain of videos you just watched. Essentially you could keep going to the next video and go down a weird hole of obscure videos. Now the algorithm will quickly circle you back to your profile homepage of videos as opposed to the video you just watched. reply x187463 2 hours agorootparentOh, I see. I suppose I do recognize more of the 'general recommendations' in the post-video grid rather than basing those solely on the video itself. That being said, I don't use that mechanism generally and tend to rely on the homepage-refresh and side bar to discover additional videos. reply 98codes 1 hour agorootparentprevSame, and now I've spent the last two weeks trying to convince YouTube that I don't need several different videos of Christmas music playing over a fireplace. Feels a whole lot like the dumb emails I get from places like Home Depot, where because I bought a table saw they feel I should know about all these other table saws they have. reply okdood64 2 hours agorootparentprevAgreed. This is still how YouTube still works for me. It's great. > That being said, occasionally I do have to go into my Google data and clear/clean the watch history to reorient my recommendations. Can you elaborate on this? What effect does this produce for your specifically? reply x187463 2 hours agorootparentIf I find I am receiving recommendations in which I am uninterested and are clearly based on a handful of videos I watched previously, I can clear those from the history and the algorithm doesn't use them for future recommendations. The simplest example would be watching videos for a one-time use case such as repairing a specific home issue. I definitely don't need more recommendations to fix that/related issues, but YouTube is likely to spend a little time sending them my way. I can fix that quickly by removing the original videos from my history. reply okdood64 2 hours agoparentprevThis is exactly how YouTube still works for me... I'm still finding new interesting content and creators everyday. Do you subscribe to creators you enjoy, and like their videos? You still need to feed the algorithm. reply nimajneb 3 hours agoparentprevI miss YouTube where you could just browse topics, like right around when Google bought it is when I liked it the most I think. I much preferred categories/topics based UI over this spoon fed algorithm. I think there's also a sweet spot in production value that I prefer. I like Technology Connection, Adrians Basement, Cathode Ray Tube Guy (name?), etc level of production much more than LTTs high production value. reply ravenstine 3 hours agoparentprevI don't. My experience with their algorithm between 2014 and ~2020 was that autoplay would quickly turn into a form of video diarrhea composed largely of Jordan Peterson and Lex Fridman. Was pretty bizarre because I only watched a few Peterson videos in the beginning, mostly his \"Maps Of Meaning\" videos which I think are mostly poppycock, and ever since then YouTube would quickly bring me back to his content even though I was never navigating to it organically. I had to resort to clicking \"Not interested\" and \"Don't recommend channel\" on several videos, which sort of worked, but it wasn't fool proof. These days it happens way less often, though usually that loop contains a lot of \"gurus\" in general and less of Peterson. I hope I never have to hear the voices of Jordan Peterson or Lex Fridman again. I'm not a fan of either one, but YouTube insisted I was for many years. reply antoniojtorres 1 hour agorootparentThis was at the center of controversy many years ago, described as a sort of alt-right pipeline. I believe there are studies about that exact algorithm behavior on youtube. My understanding is that it was changed to loop back around to trusted content sooner. reply thinkingtoilet 3 hours agorootparentprevFunny, I have the opposite experience. I used to get relevant videos to what I was watching. If I'm watching a Phish video, it would recommend other Phish videos. These days, if I'm watching a Phish video I will literally, as in literally literally, get a Candace Owens video recommendation. I have literally never clicked on one of her videos ever. I don't watch political content on youtube at all, and if I did I am very left leaning. I can't fathom what has made the algorithm so terrible that if you're watching 90s Phish videos it recommends right-wing talking heads. reply ryandrake 2 hours agorootparentIt's so weird and obvious that shenanigans are going on in the recommendation algorithm. I'll watch a Video Game Streamer, and in the sidebar, the top ten recommended related videos are: - Same streamer, different video - Different streamer - Far right pundit blasts immigration - Video game streamer - Video game streamer - Video game review - Same streamer, similar content - Ben Shapiro OWNS Liberals with FACTS - Video game streamer - Video game streamer I've never watched one of these blowhards in my life, but man, YouTube thinks I'd love it. Because I watch video games? Is this the gamer-to-alt-right pipeline I keep reading about? reply mrguyorama 2 hours agorootparentThere is massive overlap between those who watch video game streamers and those who watch the right wing rage content. Youtube is recommending you the videos those other people who watch video game streams watched next. reply jamincan 1 hour agorootparentAren't a lot of video game streamers basically alt-right rage streamers now too? reply Applejinx 3 hours agorootparentprevI think they can be paid to do that, but I'm not sure quite how it was arranged. That, or the Peterson pipeline is a good representation of a local maximum: a fairly obvious way a set of videos can direct people to related videos and increase the appetite for them. That'd produce algorithmic reinforcement without anybody getting paid. Apart from Youtube, content-agnostically hungering for being paid in views on their platform. It could have sent a very strong signal that 'this content maximally sends a statistically significant number of viewers down MASSIVE youtube rabbitholes never to emerge, therefore take the gamble and try to show everyone the content, ???, profit!' reply matsemann 3 hours agoparentprevI don't miss watching a video about a dog herding sheep, and then getting nothing but dog herding sheep videos the next week, heh. But I also don't like the new algorithm, it is as if youtube has assigned me to a demographics and really wants me to watch what other techy males around 30 y.o. watch, constantly trying to give me some rage political content to test the waters. reply infecto 3 hours agorootparentWhat I am describing is not the home page recommendations but the hole you would go down on post video recommendations, essentially the queue that Youtube would create for you had for a long time a heavier weighting on the current video you were watching. The simple example being you watch the dog herding sheep, then you the next video was about sheep, then you got to some video from a different country with sheep in it, then finally you ended up with some person who pretended to be a sheep. Purely making that example up but it often even in weird obscure videos quite quickly. reply alecco 3 hours agoprevWatching YouTube anonymously with different browsers and cycling VPNs frequently, I see it quickly ends up suggesting the same videos during the same week. Not similar videos but the same ones. Many of those videos are below 1M and not particularly notable. This is after only watching a couple of videos and those videos are different every session. Either it has some magic fingerprinting I am not aware of (and I go to lengths to avoid this) or it quickly puts me in a bin of generic results. It feels like the YouTube algorithm is either way more manual than we think or it has rules that end up showing the same things. Or both. Or something more sinister. I've never, ever clicked on short videos with girls in skimpy clothing doing something \"based\" and yet it keeps trying to hook me up on those. Even after clicking around very different videos (infosec, low level code, workshop). It's like it refuses to learn what I want to watch. When watching with my account on YouTube mobile app it keeps trying to push dumber content. I wasted years giving it feedback with \"not interested\" and \"Don't recommend channel\". It only keeps pushing videos of channels I liked 1 video 1 time long ago. If I like a DefCon video the algo will pester me with garbage shock content for infosec. Recently, I liked a cppcon wait free programming presentation and then YouTube started pestering me (again) with the Indian programming 101 videos with terrible sound and rushed video. I had to give it like 10 \"not interested\" / \"Don't recommend channel\" for it to stop. Ironicaly, about a year ago, I started watching a really good ML channel by an Indian guy with great animations an in-depth explanations. Top level. And YouTube rarely suggested his content. I had to go to his channel to look for things or search the channel name and some keywords. It feels like YouTube punishes sophisticated content. I think there is no true algorithm. Or that it has rules to never suggest me the content I actually want to watch. And don't get me started with YouTube search. Sadly most of the content I want to watch is hidden deeply in the garbage pile of YouTube. reply xg15 2 hours agoparent> I've never, ever clicked on short videos with girls in skimpy clothing doing something \"based\" and yet it keeps trying to hook me up on those. There was another post on HN recently about \"multi-armed bandit\" problems and an algorithm which occasionally retries previously nonperforming choices on purpose to \"test\" if their performance has changed. I wonder if YouTube's algorithm works similarly, i.e. occasionally suggesting a video that has nothing to do with your preferences, to see if it can hook you. reply hnthrow90348765 1 hour agorootparentThis seems logical to me, there have been times when I wanted to hop off a deep dive after watching enough and wanted to move to something else. But I was probably immune to suggestion before getting to that point. That satisfaction threshold is probably understood for someone like me who doesn't browse anonymously reply CYR1X 44 minutes agoparentprev> I've never, ever clicked on short videos with girls in skimpy clothing doing something \"based\" and yet it keeps trying to hook me up on those. Even after clicking around very different videos (infosec, low level code, workshop). It's like it refuses to learn what I want to watch. This has made me realize that YouTube is like the leading platform for piracy and porn. If you have any interest in sports the frontpage will be littered with pirated livestreams from channels like ESPN, and while they may not be explicitly pornography, the skimpy girl content is basically that. reply derektank 3 hours agoparentprevI find that going into your history and removing offending videos that seem to be driving the algorithm is more effective than using the \"not interested\" option on newly recommended videos reply alecco 3 hours agorootparentYes. Forgot about it. I keep the history clean, too. But it's only fractionally better. reply geerlingguy 2 hours agoprevThere's a lot of drama around the MrBeast YouTube channel lately—some of it justified, a lot of it manufactured... I think the main thing is Jimmy Donaldson (MrBeast) has stated numerous times his goal in life (at least publicly) is to make the best YouTube videos possible. Realistically, a lot of the things that feed into drama are related to that goal: overwork, inadequate planning. They take 'move fast and break things' to the extreme to make the videos they make, and unfortunately the 'things' they break are often people. The tough thing is, at least until recently, it seemed like MrBeast and the 'Beastification' of YouTube (where all content is loud, shouty, super-quick cuts) was inevitable. And in many corners (especially kids-centric content) it kind-of is. But luckily I think some people have pulled back. I feel like we're currently in kind of the anti-thesis of the '2001 Space Odyssey' era of entertainment. Instead of long, thoughtful content for consumption, it's fast-paced, zero-thought content with splashy colors. reply cedws 2 hours agoprevI think MrBeast and other high end influencers like the Paul brothers are harmful to children. Kids see them flaunting their huge wealth and abandon all their other ambitions in favour of wanting to become a YouTuber. Which, now, is a very competitive platform few succeed on. Kids should be nudged towards working fruitful careers beneficial to society. Although MrBeast has done some good things with it, I find the way he flaunts his wealth perverse. reply andrewla 1 hour agoparentIn general I'm in agreement that they present a life where being an \"influencer\" is a goal in and of itself, but I think it's mostly harmless, like kids wanting to be a rock star or a professional athlete. These are unobtainable for most people but learning some music or sports or video production isn't a bad idea for anyone because you don't know where it will lead. The specific criticism of \"flaunting their huge wealth\" does not apply at least to MrBeast -- he specifically is not very wealthy (I mean, he may be, but he says that he is not and he does not flaunt any such wealth; on the few occasions where his personal life is highlighted it seems he lives rather humbly). He claims to put all of the money he earns back into his videos; so when he makes enough to buy a \"lambo\" or whatever he will buy one and give it away to whoever can swallow the most toothpicks or whatever. MrBeast does not push a life of luxury as his lifestyle, he presents a life of being a celebrity influencer whose life is making more spectacles. reply walthamstow 26 minutes agorootparentIn my opinion, giving away large sums of money, loudly and publicly, is very much flaunting wealth. It’s good too, it’s great, but it’s also flaunting wealth. reply andrewla 12 minutes agorootparentI guess what I mean is for a typical \"influencer\", you want to be that person to both be famous and also be rich and have cool stuff like they have. But if you want to grow up to be MrBeast, you want to just be famous. Maybe you want to be MrBeast-famous and also buy cool yachts and lambos and private islands for yourself, but that's not the \"lifestyle\" that he's selling. The lifestyle he's selling is \"be famous but still hang out with your loser friends but get to give away and/or destroy awesome things\". This is maybe not the thing we should aspire to, but for kids I think it's fine to imagine that for yourself the way that you imagine being an NFL quarterback or something. Not every kid imagines growing up and being a moderately successful CPA. reply munchler 2 hours agoparentprev> Kids should be nudged towards working fruitful careers beneficial to society. It’s all about incentives. I think we should nudge society towards rewarding kids who choose fruitful careers. reply andrewflnr 1 hour agorootparentYes, that too, but it might not help kids whose main perception/exposure of \"society\" is MrBeast et al. Kids can be quite oblivious to how \"society\" works in practice and what will be rewarded. reply ndileas 2 hours agoparentprevFranz Liszt is a Menace to Society and all those whose consider themselves Decent, Hardworking, Folk should warn their Children aginst[sic] him. Composition is of course a Good, but the competition is too steep, and if the Young seek to imitate the likes of him it will end in Tears. The Young should be guided, steered into more reliable, beneficial aspirations. reply tdb7893 2 hours agoprevSo firstly I think for understanding YouTube it's much longer but it's better to just read Mr Beasts onboarding guide (https://drive.google.com/file/d/1YaG9xpu-WQKBPUi8yQ4HaDYQLUS...). It gives a more complete picture straight from the horses mouth (and I always prefer primary documents if I can). That being said I think the author here is taking some things for granted. An example of this to me is \"As I wrote in the book, “If creators are speaking their authentic truths, how can they also be accountable to audience feedback? I am personally bemused to see 'authenticity' invoked as a criterion for what is ultimately and obviously a performance\". So firstly I don't view authenticity as some binary thing that is mutually exclusive with taking feedback and context. Just because I act differently with my boss, my parents, and my friends based on feedback from them I'm not being inherently inauthentic. To me authenticity and external pressures are at odds but from the few videos and interviews I've seen of Jimmy he seems to genuinely enjoy creating the spectacles he does so beneath all the artifice in the videos I think you're still seeing the core of Jimmy making content that he wants to make. Anyway, I think if you stop looking at stuff like authenticity as less rigid rules for how to act and more as a spectrum or very broad category what the creators say makes more sense (because it's not just Mr Beast saying similar things). reply lanternfish 2 hours agoparentYour conclusion is the exact same one the above essay comes to in the next paragraphs. It concludes that the \"alignment\" between MrBeast and his work is a result of the larger thesis: creators are ultimately created by the audience conditions of the platform. Or, authenticity doesn't mean much when the root of the creator isn't a ground truth, but a synthesis of demand. reply tdb7893 1 hour agorootparentWe do not come to the same conclusions. The last paragraph is this: “Luckily, I’d say I’m a pretty predictable guy.” Luck has nothing to do with it, Mr. MrBeast. Your predictability is the result of years of an information diet consisting of audience feedback metrics. You are the proudest creation of the YouTube Apparatus.\" Audience feedback metrics are only part of what a creator does. They are people with complex motivations and being sensitive to audience feedback metrics doesn't eliminate that. I could see saying the ecosystem being a synthesis of demand (I mean that's just trivially true, we don't need an essay on Mr Beast to say that) but from interviews Mr Beast is very much a product of the pressure of YouTube mixed with the very specific nature of who Jimmy is as a person (from interviews he seems like a pretty weird guy and his videos definitely reflect his particular quirks). Edit: I'm trying to see how the author and I agree but unless the author is saying that people who succeed on a platform are the people that do things that are successful on the platform (i.e. align with audience metrics) then I don't think we agree. And I don't think that's all they are saying because that's just trivially true everywhere and it would make all the talk about philosophy and authenticity useless cruft. I think that Mr Beast is the sorta platonic ideal of a \"content creator\" driven by metrics and even he cannot escape his own Jimmy Donaldson-ness in his videos. reply artur_makly 1 hour agoprevDhar Mann’s channel is another interesting cultural signal of what kind of content tweens are being groomed with: https://youtube.com/@dharmann?si=vsNv2M2S7LfbVvVt What is abhorrently revolting is the total amount of “Gold Digger” videos +100 and counting.. https://www.google.com/search?sca_esv=76583c995a4c1c88&rlz=1... reply snakeyjake 46 minutes agoparentDang. I wanted to see what \"the youths\" were watching so I scrubbed through a couple of those videos. The people in them make me feel like the world's most accomplished actor. reply roland35 3 hours agoprevIt's interesting how this is happening in software engineering YouTube content as well. It seems like things like \"go sucks rust is great! Now rust sucks and zig is great!!\" get way more views since it is basically clickbait for nerds. It's too bad that nuanced discussion doesn't do too well on social media. reply mcintyre1994 2 hours agoparentThe incentives with YouTube just seem bad. Whenever I research a product (recent examples: Garmin Watches, DJI drones) I'll find a few great videos with informative and useful content. I hope those channels are doing well! But then my YouTube recommendations related to those will have titles/thumbnails with things like \"don't buy until you WATCH this\" or \"I was wrong!\". reply kccoder 2 hours agoparentprevI've similar trends here in regards to new languages, technologies, ... People love to bandwagon. reply xyzzy4747 3 hours agoparentprevIt also reminds me how the most upvoted comments on Reddit often reflect the consensus opinion but not necessarily the truth. reply OJFord 2 hours agorootparentHow could a voting system anywhere be expected to represent truth rather than consensus? reply xyzzy4747 2 hours agorootparentIt probably depends if the audience is intelligent and open-minded, but I agree, it will always be biased towards their preconceptions. reply OJFord 1 hour agorootparentEven then that's consensus on what the participants believe to be true (whether it's what they believed beforehand or not) - not a method of determining what is actually true. reply okdood64 2 hours agorootparentprevThis is a great line, thanks. reply Klonoar 2 hours agoparentprevI noticed this as well and it’s been the first real moment where I feel “old” as a dev. I should acknowledge that our industry has always had some form of this - but it was contained predominantly to mailing lists/forums/blogs and eventually Twitter. It felt like all of these mediums (yes, even Twitter) required some form of proof that you’re an authority or experienced on what you’re writing about. I don’t feel like that’s what’s happening with YouTube/Twitch here; these creators may very well be skilled/experienced/authorities (and I am explicitly not saying they are or aren’t) but I don’t see anywhere near the level of healthy skepticism that I feel like we’ve always had in our industry. Maybe it’s a generational divide as the window of developers shifts. Maybe it’s just the sheer size of the distribution channels now. I’m open to being wrong. tl;dr: Something about these mediums turbo charges the information in a way that I’m not sure is healthy. reply SirHumphrey 2 hours agoparentprevNuanced discussion can only happen in good faith. It’s impossible to enforce that so to prevent being turned in to 4chan, social media turns to the most obvious proxy- likes upvote etc. The logic underpinning this is that if a person is a jerk they will be downvoted- therefore there is an incentive to not be a jerk. However, because the person on the other side is anonymous and therefore people can’t instinctively presume good faith, upvoting system turn in to a voting system - the goal is not to develop ideas, but to submit ones people will most agree with. When the main danger is apathy, there is no reason from self-moderation. Nerds are not immune. reply coliveira 1 hour agoprevConsider the following: my personal youtube feed has never shown a video of MrBeast. I never asked to remove it from my feed. I only know the he exists because I see it being debated in the media. So, this tells me more about what people in general are interested in and click to watch, than about the nature of youtube itself. reply wodenokoto 3 hours agoprev> in cybernetic terms, a long lag time in production is deadly. Does \"long lag time\" or \"deadly\" mean something else in cybernetic terms than in regular terms? I found the \"in cybernetics terms\" insert quite puzzling. reply drawkward 3 hours agoparentCybernetics has a lot (everything?) to do with feedback loops; the word itself comes from the Greek for \"steersman\". If you have a long feedback loop in a process that is supposed to self govern, it would be potentially deadly to the equilibrium. reply cyost 3 hours agorootparentSimilarly, in a positive feedback loop (as in the article), a long lag time would decrease its growth rate. reply bobbylarrybobby 3 hours agorootparentprevAlso the etymology of kubernetes reply Xmd5a 2 hours agoparentprevIn control theory, this is called dead-time: >Dead time is the delay from when a controller output (CO) signal is issued until when the measured process variable (PV) first begins to respond. https://controlguru.com/dead-time-is-the-how-much-delay-vari... reply criddell 3 hours agoparentprevI googled for a cybernetics definition and this came back: > Cybernetics is the scientific study and mathematical modeling of regulation and control in systems, focusing on the flow of information and how it is used by the system to control itself. So maybe a long lag time is deadly because they lose control of the system? That doesn't really make sense to me either though because what control do they have in the first place? The author says as much when they call it an ever-shifting target. reply Tryk 3 hours agoparentprevAn interpretation that made sense is \"cybernetics\" as the ancient Greek word for the one who steers the ship. reply nmeofthestate 3 hours agoprevI'm interested in how many people here on HN watch Mr Beast - I've never watched any of his videos ever, and I spend far too much time on YT. reply thedman9052 1 hour agoparentI watched one of his videos and quit pretty early because it was boring. Thinking back on what I remember, it seems very weird. It was the one where he \"gave away\" a chocolate factory, after he did the Willy Wonka thing with his chocolate bars where you could win a chance to be on the show. I clicked because I was curious what he was actually \"giving away\", if it was actual chocolate factory property, shares in his snack brand, or some disused industrial building. They had a \"candy room\" with plants supposedly made of real sweets but it looked like a cheap imitation of the Willy Wonka movie, the walls were mostly white and it seemed like it could have used more set dressing. The actual content was a game show (seems to be a lot of his videos) but it didn't make good use of the space they built, I think it was a basic scavenger hunt. Then the contestants had to throw a giant Mento into a giant Coke bottle, it was impressively large but the game wasn't exciting at all, they just threw the disc at the bottle over and over without any drama. MrBeast even said something like \"we're going to be here a while\" so he started their ad read, that's when I turned it off. Unlike a TV game show or reality show the contestants had no characterization, they didn't play up any rivalries or reactions or drama. It seemed like they were there doing the most basic challenges so MrBeast could talk about what they made and give away something expensive at the end. I found it all very odd and it reinforced that I am very far from the median viewer since I found none of it interesting. reply cvoss 3 hours agoparentprevI don't, on principle. A few years ago, if you opened up YouTube without being logged in, the algorithm would show you its default recommendations in the purest state, uninfluenced by your proclivities. MrBeast and similar dumpster clickbait videos were prominently featured. These days, I think you have to at least search for and watch some things before you are told what to watch. If MrBeast has ever shown up on my YT front page in the past, I slapped YT's hand until it stopped. Haven't had a problem since. reply queuebert 1 hour agoparentprevI have never watched one, but I consume a lot of YouTube content. My teenager calls MrBeast-type channels \"brain rot\". He says teenagers watch YouTube when they want to make time disappear. (I guess they are uncomfortable being bored.) I find it sad because YouTube is actually a great source of educational content. reply nemesis1637 1 hour agoparentprevI watch it all of the time but only because of my daughter. I definitely wouldn't watch them on my own but it's tolerable. reply OJFord 2 hours agoparentprevI'd never even heard of him/it until a previous submission here (and I also watch a lot). Still hadn't heard of any of the other apparently big ones mentioned in another thread. I assume most of us aren't using YouTube for that kind of doom-scrolling click bait scream face 'content' about nothing in particular, but I could be wrong. reply tim333 2 hours agoparentprevI've watched like three. They are quite entertaining but tend to follow a similar formula. reply ThrowawayTestr 46 minutes agoparentprevI've watched a few of his videos, they're pretty good. reply ajkjk 2 hours agoparentprevIt's a younger-people thing primarily. reply nonameiguess 1 hour agoparentprevWhat I feel gets missed in these kinds of discussions are that YouTube is a thousand things to a thousand people. I probably have it running more than any other streaming service, but I almost exclusively watch music videos and skateboarding videos, and there is nothing obviously algorithmically driven about their production. They're not made for YouTube at all. YouTube just happens to be one of many distribution channels they end up available on, but the basic style and production methods of these videos hasn't changed a whole lot since the late 1980s. I'd have never heard of Mr. Beast if not for HackerNews talking about him all the time. My wife is probably closer to a YouTube-native watcher, in the sense that what she's watching is created for YouTube specifically, but even then, it's informational deep-dives, lately on liminal spaces lore, Twin Peaks fan theories, and 3d printing. She raved glowingly lately about a 4-hour long Twin Peaks explainer. I'm sure that is many things, but it isn't flashy, short, there is no skimpy clothing, bright colors, or whatever it is that YouTube is supposed to be incentivizing. Whoever made it almost certainly made no money off of the effort and dumped decades of his life into the study of what ultimately came out there, and nobody is watching it because of the algorithm or a clickbaity thumbnail. The only people watching something like that are the most serious of serious nerds who deeply love Twin Peaks and probably have for most of a lifetime. reply JohnMakin 3 hours agoprevIt is indeed a fascinating topic, and it’s completely changed content (for the worse, in my opinion) in the last ten years. I always wonder though, does the dead-eyed creepy smile factor into his metrics analysis? it must, or he wouldn’t do it. something has always felt a little “off” about that guy, but if your entire adult waking life is devoted to the whims of the massive YT content space, I guess you’d probably seem a little kooky. reply yifanl 3 hours agoparentIt does at the moment. At some point in the future, it might not rank, at which point he and anyone else devoted to the rat race will get their teams to replace their thumbnails with whatever new thing gets more clicks. reply grahamj 1 hour agorootparentPlease god let it be something other than faux surprise and arrows reply grahamj 1 hour agoparentprevIf there’s no border between him and the Apparatus then his is literally the face of the Apparatus. reply mrkramer 3 hours agoprevSo formula for success on YouTube is to be constantly making crazy and then even more crazier videos and hope they become viral so more people discover you? I knew that even 15 years ago when I was watching crazy pranks pulled by French YouTuber Rémi Gaillard[0]....he was so popular back in the day on YouTube. [0] https://en.wikipedia.org/wiki/R%C3%A9mi_Gaillard reply Applejinx 3 hours agoparentThe formula for success is more basic than that. Make people watch more YouTube. Crazy videos might become passe or burn people out, at which point the 'formula' will change, but the underlying reality is the same. It's a paperclip maximizer. To succeed at YouTube make people watch more YouTube. reply coopykins 3 hours agoprevReally liked this sentence: \"YouTubers are not “Creators” but Creations. Audiences, rationalized by the platform, and the vloggers who upload the videos those audiences consume are not separable either theoretically or empirically.\" reply nemesis1637 4 hours agoprev\"They have been interpellated by audience metrics; their subjective experience already takes audience reactions into account.\" This is great. I think there's a body of research to be done regarding the creation of self in the age of social media. (Not just creators but everyone) reply summarity 3 hours agoparent> creation of self in the age of social media That's a large part of the field of Cyberpsychology, and of course there's quite a body of research already. reply adamc 4 hours agoparentprevExcept that it's \"interpolated\". reply gertrunde 3 hours agorootparentPerhaps not: https://en.wikipedia.org/wiki/Interpellation (Specifically the top item, \"the process by which we encounter a culture's or ideology's values and internalize them\"). Edit: Doh! On checking the article, that's even the same link the author embedded! reply rahimnathwani 4 hours agorootparentprevNo, it's \"interpellated\", i.e. 'brought into being'. reply nucleogenesis 3 hours agorootparentprevI suspect they’re using the second definition of the word (per Google): PHILOSOPHY (of an ideology or discourse) bring into being or give identity to (an individual or category). —- I read it as saying the audience and their reaction to the content is what gives the “creator” their identity. reply dmd 3 hours agorootparentprevNo, that's inserting a value. Interpellation is the international police organization popularized by Carmen Sandiego. reply thfuran 3 hours agorootparentprevNo, that's a different word that doesn't work in that context. reply add-sub-mul-div 4 hours agorootparentprevThat was my first instinct, too, but instead of reflexively posting about it I double checked and found I was wrong and learned something new. reply adamc 2 hours agorootparentI sit enlightened, although I don't like the word much. reply ionwake 3 hours agorootparentprevooof reply andrewflnr 1 hour agoprev> I am personally bemused to see “authenticity” invoked as a criterion for what is ultimately and obviously a performance Imagine someone is actually an actor. They might play two different roles, one in a character and show they find boring, and one in relatable character in a show whose message they think is important. Don't you think their performance in the second one might be more authentic, despite being a \"performance\" in both cases? This essay starts interesting, but I think it overreaches at the end. reply hartator 3 hours agoprev> and I confess that I feel vindicated by the analytic approach in the book I feel the opposite, everything seems reasonable, business-centric, and marketing-aware strategies. reply n4r9 3 hours agoparentIsn't that the point? By purely focussing on business-centric strategies, the videos no longer have meaning. reply senko 3 hours agorootparentThis presumes that MrBeast intended to create \"videos with meaning\" in the first place. In his defense (!?), most of what's churned out by the streaming platforms, hollywood, and the music industry, is also not very bothered by lack of meaning. reply lanternfish 2 hours agorootparentThis seems an insufficient analysis. The meaning expressed by contemporary music, film media, or streaming television isn't very profound, but they at least still make a passing effort to \"signify\" something. The highest grossing movie of 2024 - Inside Out 2 - is not a deep text, but it does have a thesis. The \"Pixar apparatus\" is definitely increasingly consumed by audience demand, but they're at a minimum in a transitional phase: something like Seeing Red would never get workshopped out of committees. Youtube and other social media (emphasis on media) is ground zero for the decay of meaning into intensity; the ultimate incestuous product of auto-simulacra. reply n4r9 2 hours agorootparentprevThere's no such assumption being made. If anything, the linked article is about how MrBeast is intentionally making vapid slop. reply liontwist 2 hours agorootparentprevYeah, what major piece of film of the last 20 years isn’t a carefully crafted business plan? I think YouTube was so exciting initially because it was so authentic, and now it’s back to big studios. reply hartator 3 hours agoprev> This beauty is an ever-shifting target. The platform architecture and viewer preferences can change overnight; in cybernetic terms, a long lag time in production is deadly. MrBeast needs to be able to adapt to trends, vindicating my audience-driven framework for understanding YouTube. That's actually not true. MrBest is saying the opposite in the leaked PDF, that fundamentals don't change much since he started. reply anal_reactor 3 hours agoprevThe more I learn about successful people, the more I realize that being an office drone with a satisfactory salary is where I want to stay. reply criddell 3 hours agoparentYou don't think of yourself as being successful? Do you think of success mostly in terms of what your job is? reply queuebert 1 hour agoparentprevYou should watch Severance. reply Invictus0 3 hours agoprevBreathless navel gazing. It's not that he's wrong, it's just that this article adds nothing new to the conversation other than excessively technical mumbo jumbo. Just read MrBeast's original document. reply lanternfish 1 hour agoparentThe actual work underlying the essay - the one published in Cambridge Core - is pretty strong and has a lot of pretty compelling analysis. It's just long. reply queuebert 1 hour agoparentprevIronically I think one huge contribution that YouTube has made for the good is elevating the quality of STEM didactics. Channels like 3blue1brown and Veritasium have shown what STEM instruction could look like when not relegated to tenured professors who DGAF about teaching. reply campbel 2 hours agoprevThe reciprocal relationship between speakers and audiences is well documented in rhetorical studies. The example of Hitler's development as a speaker is discussed in Ian Kershaw's biography \"Hitler: 1889-1936 Hubris.\" According to historical accounts, Hitler's early speeches in 1919-1920 for the German Workers' Party were rather technical, focusing on economic topics like inflation and the Versailles Treaty's economic impact. Through audience reactions, he learned which themes resonated most strongly and adapted his rhetoric accordingly. His latter speeches focused on topics like nationalism, anti-semitism, anti-marxism, etc... topics far more popular with his audience. reply stafford_beer 1 hour agoparenttotally agree--and I think this is key to Trump's success as well, that he used audience feedback on Twitter to figure out that there was unmet demand for harsh anti-immigration policy and then win the 2016 primary reply _blk 1 hour agoprevThanks op. This sums it up pretty well for me: In what sense is any of this authentic? reply lern_too_spel 1 hour agoprevI was thrown off by the use of the word, \"wordcel,\" which the author defines as almost the opposite of what I would expect it to mean. Just like \"incel\" is a portmanteau, I expect \"wordcel\" to mean \"word celibate.\" It didn't fit the context. The word is linked to a longer article that has the author's definition buried in it, which just distracted more from this article. reply andrewla 1 hour agoparentI'm perhaps too online, but this is not the author's coining. There was discourse ages ago about how some people are \"shape rotators\" -- that is, they could reason about complex stuff in their heads, and their counterparts, the \"wordcels\", that could express ideas through writing. The latter admittedly does not make sense as a portmanteau, likely because a shape rotator came up with it. reply jasonmarks_ 3 hours agoprevHis view counts seem cooked to me. I would be interested to see what countries his viewers are claiming to be from. This article even reads as a guerilla upsell that his numbers are legitimate. Surely the urge to cheat is unbearable with millions of dollars on the hook. (Alot of apps on the app stores also claim to have quarter million 5 star reviews. Uhhuh) reply kube-system 2 hours agoparentHis viewers skew younger. Kids have a lot of time on their hands. Given how ubiquitously well-known he is among younger people, I doubt there's much fraud necessary. reply jasonmarks_ 2 hours agorootparentI agree the kids will take it at face value all the more reason to not tolerate massive deception. What if his teaching them fraudulent representation pays. All pro athletes cheat a little bit at the highest levels but exceptional cheating is never tolerated. reply spiderice 21 minutes agorootparentWhat evidence do you have of him cheating other than your feelings? reply kube-system 1 hour agorootparentprevI don't understand what you're saying. Kids don't watch the channel because it has a high number of views. And what \"massive deception\" are you referring to? reply 01308106991 2 hours agoprevKhbib reply satisfice 3 hours agoprev [–] Interesting experience to read an essay of such insight regarding a subject that is the opposite of insight. Best thing I’ve read this week. I am happy to say I have never seen a Mr. Beast video, and now I will be sure never to see one in the future. reply WolfeReader 3 hours agoparent\"YouTubers\" are one of those things that a lot of people are interested in, yet everything I learn about them makes me not want to start. The world has so much good film, music, novels, even video games and TV - in a choice between any of those and watching a YouTuber, why would anyone choose the latter? reply OJFord 2 hours agorootparentThe 'Youtubers' I watch are those that do things that are also my hobbies or interests, for education/demonstration/inspiration. Woodworking, machining, 3D printing, electronics, that sort of thing. A modern alternative to magazines basically, or to regional/cable/'public access' (I don't really know how it works, not sure if we ever had that sort of thing here) TV shows like the fictional 'Tool Time' show within the sitcom Home Improvement if you ever saw that. I got started via 'how to do x' for a couple of DIY things, realised there's so much stuff like that, started watching for fun/interest (vs. actually having the job to do myself) and from there the more 'maker' (hate the term) side of doing it for a hobby to create a thing rather than household DIY/repair. reply jazzyjackson 3 hours agorootparentprevI mean, there certainly is a genre of \"YouTuber\", but there's lots of quality content. I just enjoyed a little 20 minute history of the Panasonic 3DO console that I managed to never hear about before. reply xyzzy4747 3 hours agoparentprevThere's not much you're missing. His videos try to appeal to the lowest common denominator and are relatively vapid. Sort of like the junk food of YouTube. reply drawkward 3 hours agorootparentIn analogy with the article: what is the junk food experience, but the craving for more junk food? It is literally engineered to make us want more. reply ajkjk 2 hours agoparentprev [–] By never seeing one you are sure to insulate yourself from... something? guilt by association? Makes no sense. See one or don't, it has no moral meaning. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The essay examines how YouTube's algorithm influences content creation, using MrBeast as a case study, highlighting a shift towards engagement-driven rather than meaningful content. - It discusses the broader implications for media literacy and the cultural impact of platforms like YouTube and TikTok, suggesting a trend towards superficial and reactionary content. - Various perspectives are considered on the role of algorithms in shaping content and the influence of popular creators on cultural norms."
    ],
    "points": 369,
    "commentCount": 258,
    "retryCount": 0,
    "time": 1736859931
  },
  {
    "id": 42691184,
    "title": "GitHub Git Operations Are Down",
    "originLink": "https://www.githubstatus.com/incidents/qd96yfgvmcf9",
    "originBody": "Help Community Status GitHub.com Incident with Git Operations Incident Report for GitHub Resolved On January 13, 2025, between 23:35 UTC and 00:24 UTC all Git operations were unavailable due to a configuration change causing our internal load balancer to drop requests between services that Git relies upon. We mitigated the incident by rolling back the configuration change. We are improving our monitoring and deployment practices to reduce our time to detection and automated mitigation for issues like this in the future. Posted 19 hours ago. Jan 14, 2025 - 00:28 UTC Update We've identified a cause of degraded git operations, which may affect other GitHub services that rely upon git. We're working to remediate. Posted 19 hours ago. Jan 14, 2025 - 00:15 UTC Update Actions is experiencing degraded performance. We are continuing to investigate. Posted 19 hours ago. Jan 13, 2025 - 23:57 UTC Update Pages is experiencing degraded performance. We are continuing to investigate. Posted 19 hours ago. Jan 13, 2025 - 23:46 UTC Investigating We are investigating reports of degraded availability for Git Operations Posted 19 hours ago. Jan 13, 2025 - 23:44 UTC This incident affected: Git Operations, Actions, and Pages. ← Current Status Powered by Atlassian Statuspage Subscribe to our developer newsletter Get tips, technical guides, and best practices. Twice a month. Right in your inbox. Subscribe Product Features Enterprise Copilot Security Pricing Team Resources Roadmap Compare GitHub Platform Developer API Partners Education GitHub CLI GitHub Desktop GitHub Mobile Support Docs Community Forum Professional Services Skills Contact GitHub Company About Customer stories Blog The ReadME Project Careers Newsroom Inclusion Social Impact Shop © 2025 GitHub, Inc. Terms Privacy (Updated 08/2022)",
    "commentLink": "https://news.ycombinator.com/item?id=42691184",
    "commentBody": "GitHub Git Operations Are Down (githubstatus.com)324 points by hunkins 19 hours agohidepastfavorite250 comments jcims 18 hours agoTangential at best but I work in a regulated industry and we're starting to get some heavy scrutiny from external auditors and regulators on the way we plan to address extended outages and forced exits from third party vendors. This goes beyond basic DR/BCP and plans are reviewed with at least a high level scenario exercise. https://www.federalregister.gov/documents/2023/06/09/2023-12... On the surface a product like managed git repos would seem to be relatively straightforward to deal with, but these same regulated firms are also under tremendous scrutiny for access management, change management, SDLC, etc etc. They also have a huge software footprint which just increases the impact. Self-hosting is obviously the traditional answer, but that's not exactly a simple one either. Just an interesting problem. reply thayne 15 hours agoparentLet's say you self-host Github. Now you are responsible for maintaining uptime, and you have less expertise with the service and less resources to dedicate to keeping it up, so it's going to be hard to match, much less exceed the uptime of Github cloud. And it doesn't protect you from a \"forced exit\" either. Github could terminate your contract, and change the terms of the license in a way that you found unacceptable, or even go out of business, and being self hosted would leave you in no better position than if you had used cloud with external backups. You can somewhat mitigate this risk by self hosting an open source solution, so that in the worst case scenario, you can fork the project and maintain it yourself, but there is still risk that the project could be abandoned, or possibly have the license changed in future versions. To be clear, I'm not saying that you shouldn't self host and SaaS is always better. But it isn't a magic bullet that solves these problems. reply bgrainger 14 hours agorootparentWe self-host GitHub using GitHub Enterprise Server. It is a mature product that requires next-to-no maintenance and is remarkably stable. (We did have a period of downtime caused by running it on an underprovisioned VM for our needs, but since resolving that it hasn't had problems.) Of course we have a small and mostly unchanging number of users, don't have to deal with DDoS attacks, and can schedule the fairly-infrequent updates during maintenance windows that are convenient for us (since we don't need 100% availability outside of US working hours). I don't have the metrics in front of me, but I would say we've easily exceeded github.com's uptime in the last 12 months. reply anbotero 4 hours agorootparentI was the administrator of a GitHub Enterprise Server instance back in 2015-2016 (I think 2014 too). Rock-solid stability, for a company with 300+ microservices, 10+ big environments, 50+ microenvironments, who knows how many Jenkins pipelines (more than 900, I’ll tell you that). We deployed several times a day, each service on average had 3 weekly deployments. As a company, I think GitHub (public) should do better, much better, given this is happening more frequently as of late, but if big companies (even medium ones) don’t have their own package caches, they are all in for a ride. At a previous Startup we had GitHub + GitHub Actions, and we were on AWS. We setup some OCI images cache. Sure, if GitHub went down we could not deploy new stuff, but at least it wouldn’t take us down. If we really needed the pipelines, I suppose we could have setup some backup CLI or AWS CodePipeline (eww) workflows. reply jcims 14 hours agorootparentprevThings start to go sideways when you have tens of thousands of users. reply randmeerkat 14 hours agorootparent> Things start to go sideways when you have tens of thousands of users. If that’s really the case, run another GitHub instance then. Not all tens of thousands of users need access to the same codebases. In the kind of environment described someone would want identity boundaries established around each project anyway… reply lukevp 12 hours agorootparentIt’s fairly stable, but with a large codebase I’ve seen it take a day + to rebuild the search index, not to mention GHES relies on GitHub.com for the allowed actions list functionality which is a huge PITA. It should not rely on the cloud hosted version for any functionality. That having been said, I don’t think there’s much of an alternative and I quite like it. reply naikrovek 5 hours agorootparentyou don't have to manage access to Actions that way. on GHES you can use https://github.com/actions/actions-sync/ to pull the actions you want down to your local GHES instance, turn off the ability to automatically use actions from github.com via GitHub Connect, and use the list of actions you sync locally as your whitelist. My employer did this for years. It worked very well. Once a day, pull each action that we had whitelisted into GHES and the runners would use those instead of the actions on github.com. reply bigiain 12 hours agorootparentprevI would have thought if you had tens of thousands of developers all needing access to the same git repos, then you'd probably have a follow-the-sun team of maybe 50 or 100 engineers working on your git infra. reply paulddraper 11 hours agorootparentprevMost self hosted instances would not have tens of thousands of users. reply jcims 6 hours agorootparentAgreed, that’s why products of that nature start to break when you do. reply naikrovek 5 hours agorootparentprev> Things start to go sideways when you have tens of thousands of users. Hm not really. I manage the GHES instance at my employer and we have 15k active users. We haven't needed to scale horizontally, yet. GHES is amazingly reliable. Every outage we have ever had has been self-inflicted; either we were too cheap to give it the resources it needed to handle the amount of users who were using it, or we tried to outsmart the recommended and supported procedures by doing things in a non-supported way. Along the way we have learned to never deviate from the supported ways to do things, and to keep user API quota as small as possible (the team which managed this service prior to my team would increase quota per user anytime anyone asked, which was a capital-M Mistake.) reply shortrounddev2 13 hours agorootparentprevCould have a self hosted git or ci/cd pipeline for deployments and code access during outages. They don't need to be up constantly, just need to be able to keep a backup of the code somewhere and have some way to run critical deployment scripts if github actions are unavailable reply chrisandchris 13 hours agorootparentSounds like a backup one never tested, nobody verified and absolutely will not work if needed. Either you go full in, or you'll better don't do it. reply shortrounddev2 12 hours agorootparentWell these things should be tested and verified periodically, just like ANY backup. You shouldn't just tick the \"enable backups\" box in AWS and then never actually test them reply paulddraper 11 hours agorootparentprevWhat self hosted CI do you recommend? reply homebrewer 10 hours agorootparentWe've been using gitea since 2019 with no problems. Drone for CI, although these days you can just stick with the built-in \"actions\". It's always funny reading the news about yet another GitHub outage, when our gitea instance hasn't had a minute of unplanned downtime in 6 years. (And very little of planned downtime, always in non-working hours.) reply rurban 11 hours agorootparentprevWhatever the current gitea is named this year. See codeberg.org. I think currently it is called Forgejo https://forgejo.org/compare-to-gitea/ reply shortrounddev2 10 hours agorootparentprevWe use gitlab at my company. the k8s yaml files are a bit complicated but the simpler shell based ones (publishing npm packages, etc.) are pretty straight forward reply macintux 17 hours agoparentprevThe nice thing about git, from my perspective, is that if your entire hosted service vanishes, you can still reconstruct what you need from your users’ working directories. All of the important branches should be there. Somewhere. And any important integration branches that aren’t cached can be reconstructed. Of all the many dependencies on cloud services, git is by far the last I’d worry overly much about. reply deathanatos 16 hours agorootparentThe source code, perhaps, but a good many of the orgs I've worked at also use Github for PRs, Actions (CI), and for triggering deployments. Those things take time to setup, and across a whole org, I wouldn't want to have to have an unplanned change to another vendor. In particular, I've moved a CI for a large repository between different CI systems. It was anything but trivial: you want to believe \"it's just a YAML that runs commands, right? Translate the format, right?\" but it's really not; differences between how CI systems map commands to machines, external integrations (e.g., in this case, into Action's artifacts system, or output system) etc. all make it more complicated. reply notpushkin 14 hours agorootparentTotally agree (and also that’s the reason I think all CI ecosystems are a nightmare nowadays). But GitHub Actions are somewhat portable: there’s the standalone act [0] runner, and the Forgejo/Gitea Actions (e.g. on Codeberg [1]) that use act under the hood and are pretty much drop-in replacement – they even use GitHub-hosted actions transparently. It might not be a 100% compatible standard, but it’s pretty nice. It would be nice for others to follow lead! [0]: https://nektosact.com/ [1]: https://docs.codeberg.org/ci/actions/ reply physicsguy 12 hours agorootparentprevThis is a good reason for keeping your build steps in scripts or a Makefile rather than jumping head first into the ecosystem. I think unless you’ve been burned by having to move CI provider before it’s easy to lean in. I had to change from Travis many years ago because of pricing changes. reply jamesfinlayson 12 hours agorootparentprevUgh, agreed - I remember doing a GitHub+TeamCity to GitLab migration and I had specifically designed all of my jobs to just directly call out to a bash script. Artifacts and GitLab's infinite hooks made that much harder than it seemed like it would be. reply jcims 17 hours agorootparentprevI think my point is we are losing the option to worry about it or not. There needs to be an answer with a runbook to restore services within a given window of time should we lose that vendor. reply dangoldin 17 hours agorootparentprevProblem is that often you also end up relying on GitHub for CI/CD so not as easy of a change. Imagine GH being down and you need to deploy a hotfix. How do you handle that? Especially, if you followed best practices and set up a system where all PRs need to go through code review. reply hamandcheese 16 hours agorootparentSystems like these should have an escape hatch of some sort. The key part is that it needs to be auditable. Anything you do in CI should be possible outside of CI, at least by some subset of users. reply citizenpaul 16 hours agorootparentI've seen numerous \"escape hatches\" over the years that actually just turned out to be painted on the wall. If you actually tried to use them. No one ever does though. I don't think its malice. I just think its pretty uncommon for anyone to intentionally back out of a structural tech decision so it gets forgotten about and remains un-battle tested.. That or the timeline is longer than SaaS has been around. reply dangoldin 16 hours agorootparentprevYea - definitely. Just not ideal and something that needs to be built out, tested, etc. reply hamandcheese 15 hours agorootparentYes, it is easier said than done. At my company we use buildkite and many people wrote scripts that simply fail outside of buildkite. GitHub actions is even worse, it seems like it was designed from the ground up to create lock in. Nix helps a bit on the bootstrapping and dependency management problem, but won't save you from writing a script that is too tightly coupled to its runtime environment. reply supriyo-biswas 12 hours agorootparentprevThis is why I personally like to use none of the CI features, and mostly use it like a shell script executor. Images? Stick to OS images only so that you can easily spin them up with `docker run` locally. Artifacts? Read and write them into S3 buckets and avoid the native artifact features. This is obviously more difficult in the Github actions ecosystem, but I have mostly used Gitlab CI so far. My CI pipelines mostly look like this: image: ubuntu:24.04 before_script: - apt-get install ... script: - ./ci/build-project.sh after_script: - ./ci/upload-build-artifacts.sh reply nosefurhairdo 16 hours agorootparentprevI've run into a scenario where one of our rarely used environments needed a hotfix and the GitHub action we used to deploy there was broken. Was easy enough to translate GitHub action steps to shell scripting for a quick, manual deployment. reply theteapot 16 hours agorootparentprevGit is only a small part of Github these days. reply Over2Chars 17 hours agoparentprevI don't see how self-hosting solves the problem of 3rd party vendors unless you're standing up a self-hosting solution as a hot/cold backup to your 3rd party vendor \"in the event of an extended outage\". Kinda eliminates all those pennies saved (in theory) for outsourcing to \"the cloud\" if you have to duplicate your infra. Hybrid has always seemed the most optimal approach, but there's always someone in charge who thinks spending money on safety nets is just wasted money. reply hamandcheese 16 hours agorootparentSince git is distributed, I wonder if it's enough to demonstrate the capability to spin up an alternative, but not necessary keep it up as a live backup 24/7. reply Over2Chars 16 hours agorootparentIf all you care about is insurance, I think you can sometimes merely attest \"yeah, it will work\" and check a box. No demo necessary (sadly). If you actually care about uptime, then a real demo with usage is likely the better approach: switch over to your \"backup\" on a regular basis and make sure it works 100% as expected. reply hamandcheese 15 hours agorootparentMy hypothetical universe is \"I believe GitHub is too big to fail and want to spend as little resources to please the auditor as is reasonably possible without resorting to fraud\". So really what I'm asking is \"how strict are these audits really?\" reply Over2Chars 15 hours agorootparentGithub is owned by Microsoft so I'm assuming, maybe incorrectly, that they're well funded. Internal audits are always subject to gaps, but if the stated issue is correct \"a load balancer config change gone pear shaped\" an audit wouldn't have caught that necessarily. Unless the audit wants to test their change control, deployment methods, and redundancy. Are they changing all of their load balancers all at once? Seems non optimal. Maybe change only one at a time, or a small batch. Are they propagating load balancer changes from a canary to production without vetting it's good? Or did they vet it and they were wrong - some difference in their canary or analysis had a short coming? And even if all of that was A-OK why did a mistake (and we all make mistakes) not get reverted quickly? Were there insufficient internal controls to revert small mistakes and keep them from becoming site wide outages? And so on. I suspect these kinds of discussions are happening. Or, maybe not. Who knows? It's a 3rd party, and even if your whole organization's life depends on it you only know what they tell you. Welcome to \"the cloud\". reply theteapot 16 hours agorootparentprevDoesn't it exactly solve \"extended outages and forced exits from third party vendors.\"? reply Over2Chars 16 hours agorootparentSelf hosting as an alternative (excluding the 3rd party) or self-hosting as a method of redundancy (in addition to the third party)? If you self host as an ALTERNATIVE to the 3rd party you have all of the same problems - more because you know about them, and the 3rd party can make all these claims you can't verify until they fall over with a \"load balancer misconfig\" story you also can't verify. If you self-host redundantly to a 3rd party you have no special benefit (it does the same thing) AND the additional cost of a redundant infrastructure. Why not just have redundant 3rd parties (so-called \"multi-cloud\") if you can't or won't trust your 3rd party. reply theteapot 16 hours agorootparentI believe the point was protecting against risk of 3rd party falling over. If you self host that reduces the risk. At least you have visibility into the falling over process. reply Over2Chars 15 hours agorootparentIt reduces the risk only if your self-hosted solution also doesn't fall over. It's like saying \"I can reduce the risk of my rental car failure by owning my own car\", assuming your own car you keep undriven in your garage, doesn't have a dead battery, no gas, flat tires, and proves to be unusable for hauling. The \"cloud\" was touted as the fix for all that nuisance in self-hosting. Magically Jeff's bit barn would work to five 9s of uptime, and you could sit back and write your code, unshackled to infra. Until Jeff's bit barn went tits up. I say the \"cloud\" is just another guys data center behind an API. You wanna cloud experience? Put an API in front of your own servers and burn a $100 bill. reply parpfish 17 hours agoparentprevbut if you self host, how do you anticipate power outages and natural disasters? you shift it from a problem of software reliability to a problem of physical infrastructure. at some point in the chain somebody has to do that, but i'd prefer the person doing that was somebody with DEEP experience in it that could give you some nice confident assurances. reply jcims 17 hours agorootparentMost of the companies exposed to this are already going to be running a number of geographically diverse datacenters and have been exposed to regulations around basic DR/BCP for decades. >at some point in the chain somebody has to do that, but i'd prefer the person doing that was somebody with DEEP experience in it that could give you some nice confident assurances. Yes. This is part of the reason why services like git are being moved outside the datacenter. Most of the product offerings on the market don't scale well, have terrible reliability and are still very expensive to run. reply 0xbadcafebee 17 hours agorootparentprevBasically you rent space and machines in datacenters that are geographically distributed and designed to resist natural disasters reply Gigachad 15 hours agorootparentThat's exactly what Github does already. I wouldn't bet on my own org being better at hosting github than github. reply 0xbadcafebee 4 hours agorootparentAgreed. I have worked for several companies who tried to self-host their VCS etc, and their uptime was way worse, the overall cost was higher, and there were less features. Having a backup is always a good idea though, and an emergency plan for how to onboard to a competitor. reply mrweasel 10 hours agorootparentprevPerhaps not better at hosting Github, but some sort of code repository. We've been running on-prem Bitbucket for years and our uptime is easily better than Githubs. The feature set is small, and the CI/CD pipelines are a separate issue, but I still think we come out on top. Depending on your size your requirements may be much lower and easier to manage. Github has to be all things to all people and that comes with complexity and that can make things more fragile. reply Over2Chars 16 hours agorootparentprevYou're just using your own data center instead of Jeff's bit barn. I mean seriously people, a \"cloud\" is just someone elses' data center. Am I missing something? reply parpfish 16 hours agorootparentYes, but if it’s somebody else’s data center it’s on them to figure out how to earthquake proof or whatever. The cloud isnt just renting a computer, it’s renting a computer with a guarantee of uptime that somebody else can be financially liable for reply Over2Chars 16 hours agorootparentIf Jeff is using DataCenter XYZ, and then letting me use his API to manage my VMs on his \"cloud\", and I decide to rent a cage at the exact same DataCenter XYZ on my own servers, I'm now \"self-hosting\". Same Datacenter. Same reliability infrastructure wise - power, earthquakes, tsunami, typhoons, black plague, monkey pox, etc. reply ikiris 14 hours agorootparentYou seem to equate the some straw man version of the cloud to simple rack hosting in a single location. They are nothing alike. A cloud service is almost always geographically diverse and highly available in a way that is beyond most people to build out. reply Over2Chars 13 hours agorootparentAm I? Cloud providers usually quote price estimates for their least redundant single region services to give the impression of cost competitiveness. But their virtual offerings are much less reliable than a standalone system by a lot (they guarantee to refund you the 25cents for your instance if it goes down, not the value of the service interruption or its cost. lol! Read that TOS) What's the solution to their inherent unreliability? Redundancy at more cost. Well, hey, you can rent two colocation facilities if you really need redundancy across geographic regions. And maybe you can just use your colo as a source for a CDN that is geographically diverse (for latency, not hurricanes). Geographic diversity and HA is beyond most people? If you're the kind of business that needs that, you can hire the exact same people that Amazon Pip'd and fired because they didn't hit some arbitrary ticket metrics, to scale your business. e.g. https://www.forbes.com/sites/lucianapaulise/2022/10/27/amazo... reply globnomulous 15 hours agoparentprevI work on one part of a huge suite of interconneted services that have extremely strict SLAs for up-time. It really is an interesting problem, and the quantity of engineering resources devoted to ensuring availability and avoiding downtime -- basically fighting to make inherently unstable, complex systems stable and reliable -- is dumbfounding. When I'm trying to explain to people what it's like to work on this kind of software, I like to use an analogy: it's as though I have my own personal brick, or group of bricks, in the great pyramids of Egypt, just a a tiny piece of a stupefyingly, inconceivably larger whole -- and when I twist my chisel and strike my block just so, at exactly the right (or rather the wrong) angle, I can shake the very foundations of Egypt. reply dangero 17 hours agoparentprevThat's a lot of overhead. Do you know how they are calculating the possible risk of these events? It feels like there are a million rabbit holes like this you could go down when modern infrastructure is so cloud connected. Is the risk of your git repos higher than a chip shortage causing you to lose access to the infrastructure you need? So many factors to consider. A chip shortage doesn't seem that unlikely with geopolitics. The list of scenarios you mitigate for seem like they could very easily be an arbitrary list of the of scenarios a single person came up with. reply jcims 17 hours agorootparentIt's an astonishing amount of overhead that slows everything to a veritable crawl. It also creates downstream issues because you need to build in contingencies for your service consumers until you are able to fully abstract the dependency to a point where rehoming doesn't impact them. The risk calculations are very primitive at the moment, I'm guessing they will be refined over time as industry feedback starts to resonate. reply 0xbadcafebee 17 hours agoparentprevFirst pay a consultancy a fortune to tell you which SaaS you are able to use based on compliance requirements. Then run your own IdP, use service providers that have a data takeout mechanism, take regular backups, and use standards-based technology. Line up a self-hosted fallback for each non-self-hosted option for if you're forced to exit them. Basically you line up the exit strategy for the auditors but hope you never have to use it. reply outworlder 15 hours agoparentprevMy company is replacing the entire system we built with Github actions. Our previous DR plan involved running our automation scripts to reprovision the infrastructure that manages the rest of the infrastructure (runs jenkins jobs, etc). They are replacing everything with Github actions. I wonder what they are going to do when Github is down. reply st3fan 17 hours agoparentprevGitHub not being available for 45 minutes is not an \"extended outage\". reply jcims 16 hours agorootparentAgreed, that's why i said 'tangential at best'. reply cheeze 17 hours agoparentprevAnd the ultimate problem that you don't need a solution for, until you _need_ it. Which often leads to \"yeah we have backups\" but without regular testing, can you trust them? reply crest 19 hours agoprevIt's almost as if only Git is distributed, but people sold out to Github for convenience. Too bad Git lacks a distributed bug tracker and wiki system like Fossil. Guess Github has to fail a lot more for things to change. reply sixo 18 hours agoparentpeople could not be more clear that their preference is for reliable and easy-to-use centralized services maintained by professionals, and not decentralized systems that require a great deal of user expertise reply eru 18 hours agorootparentI actually don't care whether it's centralised or decentralised, or who's managing it. But you are right that I want reliable and easy-to-use services. And centralisation is often one way to go there. As an interesting counterpoint: Git itself is decentralised and replaced centralised services like Subversion. And that made git easier to use, especially easier to get started with: no need for a server, no need to be online, just do `git init` in any old directory. A GitHub-clone could be more decentralised, but they'd need to use that decentralisation to drive those other features that people actually care about day to day. reply rad_gruchalski 17 hours agorootparent> no need for a server, no need to be online, just do `git init` in any old directory svn doesn’t require a server and there is no need to be online. It works perfectly fine over the file:// protocol. reply eru 15 hours agorootparentInteresting. Was that always the case? I remember it being quite a hassle to set up (following tutorials online), but that was about 15 to 20 years ago or so. reply ascar 17 hours agorootparentprevAnd a `git remote add name url` and you are setup to use another remote server. reply umvi 16 hours agorootparentOnly if your repo doesn't have any other critical integrations like CI/CD, jira, etc reply eru 15 hours agorootparentWhy? We use github and its CI/CD system, but locally I still only need to add the git remote to work with it. reply ajb 17 hours agorootparentprevThere is not actually a need to choose between a single centralised monopoly and going full-on techno-prepper and running all your own services in your garage as an individual . We could have intermediate points, such as having services run by professionals but based on portable open standards. reply alkonaut 11 hours agorootparentgit is a great portable standard. But if I were GitHub, I'd make damn sure I didn't have issues, actions, and the rest of it be based on something users could just yank out in a portable format and take elsewhere though. Portable VCS is simple. Portable anything with the integration everyone expects (issues connects to source which connects to builds which connects to releases) is hard. Git being so open and portable means it isn't a moat. reply __MatrixMan__ 17 hours agorootparentprevAnd I'm sure they'll continue to feel that way right up until the first time they experience \"the\" internet from a minority partition for more than a few days. I just hope that the distributed stuff is easy enough to limp along with if/when that happens. reply umanwizard 17 hours agorootparentNo, they'll continue to feel like that even after that. GitHub being down once in a blue moon is more acceptable to the vast majority of users than having to cobble together your own nerdy distributed version of everything. reply __MatrixMan__ 17 hours agorootparentI was imagining something a bit more disastrous than that. A big enough solar flare could take parts of the planet offline for months. Years if they can't source enough replacement transformers. There are also political reasons that countries go offline. Then it'll be up to the nerds who manage to cobble together their own distributed version of everything--even if it's a significantly reduced definition of everything. reply arrowsmith 17 hours agorootparentIf large parts of the planet lose their digital infrastructure for months, I really don’t think that “finding a good platform to host my code” is going to be one of my biggest problems. reply __MatrixMan__ 12 hours agorootparentI think that how big those problems get is going to depend on how much critical infrastructure we can hack back into a working state despite the fact that it can't phone home, which is going to be a problem if nobody knows how to work offline anymore. Or, if it's a political scenario, it may depend on how well we can coordinate en masse without the cut connection. If we can exceed a certain threshold then we'll have removed the incentive to cut it in the first place. reply thfuran 16 hours agorootparentprevEspecially if the problem was due to a lack of electric grid as they're suggesting. reply ascar 17 hours agorootparentprevEven if that's a concern in a doomsday scenario, self-hosting gitlab is super easy and a good (some would argue better) alternative. reply homebrewer 10 hours agorootparentSelf-hosting gitlab is not and has never been easy if you do it right, it's very heavy on resources and take lots of time and effort to upgrade. It's also extremely complex and has many moving parts. Stick to gitea or forgejo, they upgrade just by restarting the daemon. MySQL for the database if you want comparable ease of maintenance (same thing: upgrading between major versions requires replacing the binaries and restarting the daemon). reply vikramkr 16 hours agorootparentprevAt that point the enormously powerful central players like big tech and militaries and tax collectors will be more than incentivezed to use every remaining resource they have to bring everything back online and re-centralize power. And if they can't - society and power wasn't exactly more distributed in the distant past lol. Your local warlord/military dictator/whatever will probably not be supportive of nerds acting independently. reply Idneedagun 17 hours agorootparentprevYou've described a scenario disastrous enough that my primary concern would be drinkable water. reply lol_me 17 hours agorootparentprevok fine, ill thank the nerds in that case. reply __MatrixMan__ 6 hours agorootparentI doubt it, I don't think the distributed stuff is anywhere near ready. Instead it'll be time to kiss the ring of whoever manages to grab control during the gap. reply ajross 18 hours agorootparentprevIronically github is sort of the exception that proves the rule: decentralized in the one way that really matters (decoupled development on individual systems), but centralized for easy interaction in the way the market demands. reply nine_k 17 hours agorootparentBut it demands both. The ability to develop in a parallel, decentralized way, and the ability to integrate things at a central point, an authoritative source and a blessed official destination. It's similar to how databases allow to begin parallel, concurrent, even contradictory transactions, and also guarantee serialized, consistent database state, and rejection of invalid updates, at commit time. Both aspects are utterly important. reply TZubiri 18 hours agorootparentprevSimilar thing that happens with crypto exchanges, also swift transfers and federal states for that matter. reply eru 18 hours agorootparentYes, subsidiarity is a great principle.. in-principle, but in practice it often gets the curb. See https://en.wikipedia.org/wiki/Subsidiarity So far, having individual small countries seems to keep the centralisation at bay for longer than just having states in a federation. (Look at Germany, Austria, Australia, the USA for examples of the latter. Interestingly, the UK is legally not made of federal states, but in practice they have granted more autonomy to eg Scotland over the years. And everyone knows that Scotland would secede and get away with it, if there was a power grab by London. In that sense, they are more federal than the US, where secession is very much verboten.) reply flats 15 hours agorootparentprevthis should be on a wall somewhere reply dangoodmanUT 18 hours agorootparentprevthis, especially if it's a business reply cyanydeez 18 hours agorootparentprevThats mostly because of herdmentality not because of a considered approach. Decentralization assumes the majority are anti social. reply theultdev 18 hours agorootparentHow so? Decentralization can be hidden from the user, it's an implementation detail. There's literally a popular decentralized social network. It's less about the tech, and more about the execution. Historically we can look at LimeWire or PopcornTime as an example. Both decentralized, both popular due to the ease-of-use. reply p-e-w 14 hours agorootparent> There's literally a popular decentralized social network. No there isn't. Not a single one. There are a few federated social networks, which is a fancy way of saying that they are centralized networks that have (or can have, in principle) more than one \"center\". In practice, the overwhelming majority of users of such networks gravitate towards one or a handful of large providers. And many of those providers actually refuse to federate with other providers unless they follow an ever-growing list of politically-charged rules. This is just centralization with extra steps. reply theultdev 9 hours agorootparentbluesky has over 27 million users reply p-e-w 8 hours agorootparentBluesky is federated, not decentralized. reply sixo 15 hours agorootparentprevNo, it's because complexity comes with a cognitive cost, and delegating responsibility to other entities minimizes this If you don't account for the benefit, it looks irrational, but this is true of absolutely anything reply zuppy 18 hours agorootparentprevwhat a convoluted way to say you do not agree with this. when you are dealing with people of all skill levels, every step that you put on the development process costs real money. over that, not everything is and has to be open source. we all have source code that is proprietary and has a value for us as it is. making that decentralized and private is not something easy to achieve (and I don't really see a benefit). the problem from my point of view is that we have a single player (github) that managed to attract a huge percent of the market and the competition, while it exists, it's minor. reply cyanydeez 3 hours agorootparent...ironic reply nine_k 18 hours agoparentprevYes, conveniences like: - A canonical name and place on the web; - Access policy enforcement (who can commit and when); - The whole pull request thing, with tags, issues, review, discussion, etc linked to it; - Code review, linked to said policy enforcement; - Issue tracking, even as basic as what GitHub offers; - A trusted store for signing keys, so commits are verified; - CI/CD triggers and runners; - A page with releases, including binary releases, and a CDN allowing to use the download links without fear. This is way more than distrusted version tracking. Actually the above is not even married to Git; it could be as valuable with Mercurial, or even Perforce. This is a large product, actually a combination of many potentially self-contained products. It should not be compared to Git, but rather to Gitea or BitBucket. Not all of this can be reasonably decentralized, though quite a bit can. reply bluGill 18 hours agorootparentThe above is why my company left mercurial years ago for git. Mercurial of 10 years ago was better version control than git (git still can't track a branch and how it changes) - but the rest of github is much better. reply manwe150 17 hours agorootparentThe git reflog tracks branches and how they changed. Is that roughly what mercurial has? (It’s been more than a decade since I switched from hg to git as well, so my remaining memory is minimal). GitHub also has an API for querying historical branch info, which is more permanent than reflog, though quite annoying to parse for that info if I recall right. reply bluGill 17 hours agorootparentHg names the branches and keeps the name. The other day I was looking at a sequence of commits trying to figure out where they came from and knowing the branch would have helped. mg always kept history though. Git has always encougaged squashes and rebase to keep a linear history so that information was lost. reply smrq 16 hours agorootparentWe all want history information to be lost. (Unless you are running a version control system that timestamps every keystroke.) Reasonable people may disagree on what information should be kept. reply ncruces 8 hours agorootparentprev- CI/CD triggers and runners; I've used up 17h of CI time these two (slow) January weeks, for free, testing stuff across ~20 different OS/CPU combinations. That's on just one \"personal\" project; a bigger dependency of that, of which I'm a maintainer, spends an order of magnitude more. Can you (GP post, people complaining, not parent) blame us? Should we instead self host everything and beg for donations just to cover the costs? reply eru 18 hours agorootparentprev> - Access policy enforcement (who can commit and when); Interestingly, what GitHub mostly enforces is where your branches point to. Not who can make commits. That's mostly because of how git works, not because of any grand design on GitHub's part. reply nine_k 17 hours agorootparentIt controls who can push commits to the main branch hosted by GitHub (and other branches if you want to configure that). You can have OWNERS files to control who can push commits touching particular parts of the tree, or who must approve such a push / merge (see \"pull request\"). Out of the box, git does not offer that, and this does require a single point of enforcement. reply eru 15 hours agorootparentMy point is that in git branches are just mutable pointers to commits. Tags are internally nearly the same, but socially they are meant to be immutable. Anyone can make any commit they want in git. That includes merge commits, too. GitHub mostly lets anyone push any commits they feel like, too. (What restrictions are there on pushing commits is mostly to deal with denial of service and people being a nuisance.) Where the policing comes in is in giving rules for how these pointers (aka branches) can be mutated. OWNERS files, PR reviews, CI automation etc is all about controlling that mutation. See also the new-ish merge queues[0], which really bring out that difference: the merge queue machinery makes the merge commit of your approved PR branch with 'main', runs the CI against that, and iff that passes, moves the pointer that is 'main' to point to the newly created commit. It's exactly the same commit (with exactly the same hash), whether it passes the CI or not. The only difference is in whether it gets the official blessing of being pointed to by the official 'main'. It really speaks to the design of git, that conceptually the only thing they need to lock down is who can mutate this very small amount of data, these handfuls of pointers. Everything else is (conceptually) immutable, and thus you don't need to care about who can eg make commits. [0] Really a re-implementation of bors-ng. reply adamtaylor_13 18 hours agoparentprevI don’t know anyone beyond hobbyist hackers who want to set up and maintain this stuff for themselves. As a professional software developer, I want tools that just work that I can rely on. GitHub 99.99% uptime is something I can rely on. reply Over2Chars 16 hours agorootparentfour 9's uptime https://uptime.is/99.99 Daily: 8.6s Weekly: 1m 0.48s Monthly: 4m 21s Quarterly: 13m 2.4s Yearly: 52m 9.8s If you assume that \"uptime\" means all tools are available https://statusgator.com/services/github this appears to be 45 minutes in just one day Incident with Git Operations 30m Jan 14, 2025 9:01 AM Down Incident with Git Operations 10m Jan 14, 2025 8:51 AM Down Incident with Git Operations 5m Jan 14, 2025 8:46 AM Down Not much margin to hit four 9's left for the rest of the year. reply gerdesj 18 hours agorootparentprevA bloke called Linus Thorvalds created git for Linux development when the commercial service used for that ceased to be useful, for one non technical reason or another. github basically shoves a webby frontend and workflows on top of someone else's work. That's all fine and good but github is not git. As a professional IT consultant, I want tools, I use lots of other's and I also create my own and I also generally insist on hosting my own. I'm also a fair carpenter and several other trades. I have tools for all my trades and I look after all of them. That way I can guarantee quality - or at least reproducible and documented quality. I'm sure you are fine with abrogating responsibility for stuff that you are not able to deal with - that's all good: Your choice. EDIT: Sorry, forgot to say: \"Yay cloud\" reply jrockway 17 hours agorootparentLinux development is also centralized. Instead of Github they use an email list that has patches sent to it. If that goes down, your change isn't going into Linux today. reply confooseddd 16 hours agorootparentYou do know what's a mailing list right? You seem to be confusing it with GitHub. A mailing list can go down and nothing would happen. The main point is to post patches to the maintainer. The mailing list is for a public record of things. The only centralised thing is repo hosting on kernel.org. And that isn't the only official place, you can get the repo published on googlesource or GitHub, so it isn't exactly central enough. reply Tmpod 16 hours agorootparentprevI suppose that's true. In any case, though, getting a backup mailing list going is much much easier than something like GitHub, and you can always mail patches directly if maintainers allow it. reply LPisGood 17 hours agorootparentprevI contend that if you submit a patch under any circumstances your change isn’t going into linux today. reply Over2Chars 16 hours agorootparentprevI believe he found the open source tools being used (CVS?) weren't good enough, and he started using a commercial closed source tool called \"bitkeeper\", which rankled the ire of the FOSS community who wanted to eat their own dogfood. So Torvald's opted to \"clone\" the features of bitkeeper into an open source version he named 'git'. That's the story I heard, no idea if it's true. reply wongogue 13 hours agorootparentThey were using BitKeeper for years but git was created when BitKeeper pulled the rug licensing-wise. Source: A Git Story from https://blog.brachiosoft.com/en/posts/git/ reply IshKebab 11 hours agorootparentBitkeeper pulled the rug because they agreed not to reverse engineer it and then someone did. reply Dylan16807 14 hours agorootparentprev> GitHub 99.99% uptime is something I can rely on. Their enterprise level SLA is only 99.9% (measured quarterly) and the remedy is a 10% credit, increasing to a 25% credit if they drop below 99%. reply TZubiri 18 hours agorootparentprevAs a professional software developer, you rely on software written by those hobbyist hackers. Whenever you do a clone or an npm install or apt get or pip install, etc... You choose github because your dependencies chose git reply eru 18 hours agorootparentSure, but as you say those hobbyist developers aren't responsible for keeping a specific server up. They are 'just' writing some software. (And even among professionals, there's a big difference between Site Reliability Engineering and Software Engineering.) reply fragmede 18 hours agorootparentprevIt was down for ~45 mins according to the linked page page, which would put it at 99.897% uptime for the month, assuming no other downtime. reply eru 18 hours agorootparentThey had some more downtime a few days ago, too. And that's just the one I happened to notice. reply ikiris 14 hours agorootparentprevAnd if your central hub for your distributed vcs needs more than 2-3 9s of uptime for your service to be reliable, honestly you’ve done something really wrong in the design phase like using version control as a database. reply xelxebar 18 hours agoparentprev> Too bad Git lacks a distributed bug tracker Not your point, really, but fortunately, git is easily extensible. This in-repo issue tracker is surprisingly feature complete: https://github.com/git-bug/git-bug. Anyone else given it a whirl? reply never_inline 1 hour agoparentprevIf you have a local development setup, few hours of not being able to push should be a not problem most devs. Except if you have a release planned but most don't at that time, statistically. Problem is that people get comfortable with pushing to branch -> deploying in dev and testing from there. reply kspacewalk2 18 hours agoparentprevCounterpoint: it's a 45 minute outage once in a blue moon. Very small price to pay for the convenience of a centralized VCS with many features that aren't easy to reliably set up in standalone installations. reply vrosas 17 hours agorootparentOnce in a blue moon? It’s like, monthly at best. reply Idneedagun 16 hours agorootparentWell, despite our intents, we may have established the moon might be blue then. reply kspacewalk2 14 hours agorootparentprevWhen was the last time you noticed? Not saw a HN post, but it actually stopped you from pushing commits or commenting on an issue or whatever? reply saagarjha 12 hours agorootparentToday ;) reply doublepg23 13 hours agorootparentprevOnce a full moon maybe? There's one tonight. reply koito17 18 hours agoparentprevI've been keeping an eye on radicle[1] but the documentation for setting up a peer and web frontend is a bit complex. It seems to offer what you're describing: a \"decentralized\" Git frontend with issue tracking. Seems to be missing wiki functionality, however. [1] https://radicle.xyz/ reply tomnicholas1 18 hours agoparentprevIs there a world in which GitHub used an open protocol for the social network part of their product like BlueSky's AT protocol[0]? [0] https://docs.bsky.app/docs/advanced-guides/atproto reply theultdev 18 hours agorootparentnot p2p, but federated: https://forgefed.org (ActivityPub extension) I believe Gitea has support for it, not sure to what extent. reply bramhaag 18 hours agorootparentForgejo (Gitea fork) has been working for multiple years to add support for this. It will still take a lot of effort to finish, I doubt we will see anything usable this year. Originally the plan was to PR the federation support to Gitea as well. I'm not sure if this is still the case, considering the rising tensions between the two projects and the fact that Forgejo is now a hard fork. reply codetrotter 18 hours agorootparentprevForgejo, a Gitea fork that I use, has support for it according to the page you linked. But the FAQ for Forgejo mentions it's on the roadmap so not sure how complete ActivityPub support is in Forgejo either. https://forgejo.org/faq/#is-there-a-roadmap-for-forgejo I only use my Forgejo instance for myself currently so I haven't looked at the ActivityPub features of it before. reply NetOpWibby 18 hours agorootparentprev...this is an interesting thought exercise, thank you. reply freewizard 18 hours agoparentprevGit is distributed. Distributed system does not guarantee 100% uptime or real time consistency. You can take the whole history with you and push to a different remote. reply TZubiri 18 hours agoparentprevContrary to popular belief, sarcasm makes you harder to understand and is no longer cool reply tokioyoyo 18 hours agoparentprevPeople said that when GitHub got bought out, and only more people ended up moving there. It's really not fun to manage your own Git servers, and when things go down, they get fixed much slower than in-house hosted version of it. reply bastardoperator 18 hours agoparentprevIt's this type of negativity ruining the internet. Nothing thoughtful to say, nothing to add, and hoping for failure. I hope everything is okay over there... reply liontwist 17 hours agorootparentThey are advocating for decentralized tools. That’s actionable and hoping to prevent failure. reply vv_ 11 hours agorootparentThere is no reason to host 'decentralized' tools besides regulation. It's considerably cheaper to use GitHub (or other alternatives like GitLab) than hosting your own and hiring people to maintain and support the solution. Their issue tracking system is very convenient for small teams too. reply liontwist 2 hours agorootparent> It's considerably cheaper to us This is not true. The cheapest option is to not have services that require servers to maintain. Git continues to work if GitHub is down. So do shell scripts when CI is down. So why can’t we have an issue system where the underlying data is text files in a git branch? I understand at scale you can pay people to optimize a process for the larger team, but there is a ton of unnecessary fragility before getting to that scale. reply bastardoperator 2 hours agorootparentprevExactly, hire a team of 3 and pay 500K in compensation, or spend 100K on a system that works and you get a support person to call in the event of an issue. The math is so simple. reply liontwist 2 hours agorootparentExcept you’re not considering the cost of when you can’t deliver something on time for a customer because infrastructure you don’t control is down. You don’t outsource things that prevent you from doing your core competency. reply bastardoperator 1 hour agorootparentAnd for most companies, building and managing an SCM is absolutely not their core competency. Your point is valid, but not in the way you're trying to convey it. reply Dylan16807 14 hours agorootparentprevThey want people motivated to design systems that can handle github going down. That doesn't strike me as negativity, and especially not negativity ruining the internet. It's not the most thoughtful thing in the world but it's a reasonable opinion, and most comments are also not the most thoughtful things in the world. reply Over2Chars 16 hours agorootparentprevYou're quite a Mary Poppins for someone with the heavy handle of @bastardoperator. AFAICT the internet was built on negativity. Here's the 2nd post from a random USENET group I found: https://www.usenetarchives.com/view.php?id=comp&mid=PDQ5ajZp... reply nextaccountic 17 hours agoparentprev> Too bad Git lacks a distributed bug tracker Well there is https://github.com/git-bug/git-bug reply joecool1029 18 hours agoparentprev> Too bad Git lacks a distributed bug tracker Email and mailing lists? reply Groxx 18 hours agorootparentThat's the same as not having one. Otherwise you can claim Facebook is distributed because you can email people links to Facebook pages. reply lucasoshiro 18 hours agorootparent> That's the same as not having one. That's the way the Linux kernel (the first Git repository) and Git [2] itself manage their codes. There's even a git send-email command, that prepare the commits as patches and send them following the using the correct template. [1] Linux kernel, IIO subsystem: https://lore.kernel.org/linux-iio/ [2] Git mailing list: https://lore.kernel.org/git/ reply Groxx 16 hours agorootparentI agree that Git has more of a claim to this than Facebook, but that's kinda like saying a turtle is more of a car than a banana is a car. Like, yes, it's true. Unlike a banana, turtles have 4 movement-enabling things, they use them to move mostly forward and backwards and not sideways, and other things can ride on them. It's probably more of a car. But it's not a car. Git has no issue tracker. It's really not a controversial statement. The git community has common practices using something else to work around that, but if that's all you need to say \"therefore git has X\" then you can claim git has a CI framework because everyone and their dog uses GitHub. Which also has email integrations. reply confooseddd 16 hours agorootparentA CI infra just needs to communicate. It can communicate over email, like it does for the kernel. A bug tracker is just assorted communication. One can easily build it over email. You're just indulging in hyperbole for the sake of it. Nobody said git has an issue tracker in it. reply Dylan16807 14 hours agorootparent> You're just indulging in hyperbole for the sake of it. Nobody said git has an issue tracker in it. Yes they did. That's what this comment thread is about. https://news.ycombinator.com/item?id=42691624 (Unless you're splitting some really fine hairs about what \"in it\" means?) reply confooseddd 1 hour agorootparentThey just mentioned the most common communication tool used with Git? You're the one splitting hairs here. reply TZubiri 18 hours agorootparentprevBut git has built in email features And it was developed itself by email. reply whalesalad 18 hours agoparentprevThe GitHub wikis are actually git repos. reply remram 17 hours agorootparentI forgot about that, I wonder if they were broken too. reply tracerbulletx 17 hours agoparentprevI mean I could very easily still push to another remote until it comes back? I do not feel locked in at all. reply paulddraper 16 hours agoparentprevConvenience is nice. reply evbogue 17 hours agoparentprevMakes me wish for the good old days of git-ssb reply XorNot 10 hours agoparentprevgit was never really decentralized though. The whole system is aggressively a funnel towards central repositories, it's just that because it deals in whole repos, every git repo has the potential to be promoted to that role. Nothing is built into git to let it actually run decentralized: there's no server or protocol where someone can register say, an identifying public key and then just have a network of peers all communicate updates to each other. It's even pretty damn unsafe to just run a repo through basic file-sync (I do this for myself with syncthing with bare repos in a special folder, which seems to work fine but I'm hardly loading it up to chase down why it doesn't). reply freewizard 18 hours agoprevIt was down for ~2 hours. The status website claims \"degraded performance\", but in reality we get git@github.com: Permission denied (publickey). Either GitHub didn't know how to communicate, or they were not sure about the real impact. This is bad. reply manfre 17 hours agoparentStatus pages are rarely honest. The company will lie to salvage their SLA. \"Degraded performance\" or \"some customers are experiencing an elevated error rate\" should be interpreted as \"service unavailable / outage\" reply croemer 17 hours agorootparentSomeone else lamenting the delayed status page updates almost 2 years ago: https://news.ycombinator.com/item?id=35887213 reply croemer 17 hours agorootparentprevI'd be curious by how much they downplay downtime. Wouldn't be too hard to put together an honest status page that pulls & pushes something new to main every 5 minutes, creates an issue, comments on it etc. Very basic high level checks. reply vrosas 17 hours agorootparentPMs would never let an automated system make the company look bad, nor would they let engineers have time to build such a system. reply enasterosophes 16 hours agorootparentprevI'm not convinced it's deliberate dishonesty. Just a communication disconnect. Firstly, it can take time from the first yellow flags to the full realization that there really is an incident underway, secondly it needs someone to decide how to communicate that incident, and thirdly the engineers who are actually working on the incident need to be able to get on with it instead of being pestered for an update every 10 minutes. reply deathanatos 16 hours agorootparentprevThey used to be. Github's is a prime example of how \"useful info\" has turned into \"PR mouthpiece\" — it used to display graphs of a few choice Github system metrics, and those spiking could often usefully indicate \"yeah, they're having a problem\" well before a human could update the page. But yeah, also status pages seem to be under the domain of non-engineers who are too concerned with how things look, vs. conveying useful information in a timely manner, and ultimately, fail at both. reply spacedcowboy 16 hours agoparentprevYeah, I've been trying to check out the SDL3 suite for the last hour or so, and it's still failing on SDL_ttf... fatal: clone of 'https://github.com/libsdl-org/freetype.git' into submodule path '~/src/SDL/SDL_ttf/external/freetype' failed ... fetch-pack: unexpected disconnect while reading sideband packet fatal: early EOF fatal: fetch-pack: invalid index-pack output ... fatal: clone of 'https://github.com/libsdl-org/harfbuzz.git' into submodule path '~/src/SDL/SDL_ttf/external/harfbuzz' failed Failed to clone 'external/harfbuzz'. Retry scheduled ... Failed to clone 'external/freetype' a second time, aborting For a problem that's supposedly \"fixed\" that's a whole lot of errors... reply itsjustjordan 18 hours agoprevI was going insane doubting my SSH knowledge, stopped short of creating new keys thankfully! reply Layvier 18 hours agoparentwell on my side I'm the proud owner of a new ed25519 key.. The status page didn't update quick enough reply smus 16 hours agorootparentas am I! reply sashank_1509 13 hours agoparentprevI for a second thought was I getting fired reply shaftway 10 hours agorootparentAs someone who found out that way twice in the last two years, I also thought I had been let go. Anxiety is a hell of a drug. reply sashank_1509 2 hours agorootparentSorry for you, it should be illegal for companies to fire with no notice! reply atonse 18 hours agoparentprevI thought my account was hacked and ssh keys removed. Panicked a little bit and then double checked that my keys were still there. Then went to github status and calmed down. reply eru 18 hours agorootparentI briefly entertained the notion that I was fired and my ssh keys revoked. But I still had access to slack and email etc, so I banished that thought. reply NautilusWave 16 hours agoparentprevI had just upgraded to Windows 11 last week, and for some godforsaken reason earlier today, I could SSH via WSL but not from the host OS even though they were both using keys served from the Windows OpenSSH agent! I'm just going to blame this service outage and hope for the best tomorrow. reply G1N 17 hours agoparentprevWas trying to install homebrew on a device and kept wtfing because the clone step kept failing… thought I was crazy reply donohoe 18 hours agoparentprevSame - but created new keys :) ... which also didn't work, and then I went to check... oh well. reply vinayan3 19 hours agoprevExperiencing this as well. I was a bit concerned something was wrong with my key but alas it is not my key but an outage. Developer \"snow day\". reply TheRizzler 18 hours agoparentGIT is down today, Code rests in snowy silence, Developers play. reply itissid 18 hours agoparentprevSpent like 30 mins tryig to figure out why ssh auth was not working. Compared sha256 signatures, doubted my reading abilities and pulled my hair. reply jcgrillo 18 hours agorootparentthis coincided with an os upgrade for me.. made for a very confusing 15min until i checked gh status reply guluarte 18 hours agorootparentprevsame.. reply sc68cal 18 hours agoparentprevsame here I was scratching my head trying to figure out if something had corrupted my system or what reply parpfish 18 hours agoparentprevdamn, why couldnt it happen during east coast business hours? reply tom1337 18 hours agoprevNot sure if I am just noticing GitHub's issues more often as I am using their tools pretty much every day but their availability is kinda not great. Be it Actions failing or something \"not core business\" (read: git operations) but I can't remember a month in the past where I was not annoyed by any outage on GitHub reply croemer 18 hours agoparentAgreed, I wonder what their downtime percentage is. If guess it's down on the order of one hour per month, so 1/1000. Update: They promise >99.9% on a quarterly basis for enterprise customers - https://github.com/github/docs/blob/main/content%2Fsite-poli... reply mcdeltat 6 hours agorootparent99.9% uptime corresponds to about 2 hours downtime per quarter, if my maths is correct. If that is indeed the guarantee, based on the experience at my company, GitHub has failed its promise recently (or is getting damn close). I recall 2 decent outages in the past few weeks alone. It's making me begin to doubt if GitHub's reliability is appropriate for an enterprise service. reply FridgeSeal 17 hours agoparentprevThe whole product feels like it’s getting g progressively jankier. The front-end is glacial nowadays and frequently has issues actually loading the page, actions frequently has some kind of panic attack and breaks or just grinds along a glacial speeds. The UX has gotten worse (why no merge-queue button?). reply tom1337 10 hours agorootparentAgree with the second part. Github actually has merge queues, but only for the enterprise tier… reply IshKebab 10 hours agorootparentprevI wouldn't say glacial. If you want glacial try Jira. Mind-bogglingly slow. reply FridgeSeal 5 hours agorootparentOh I know, I have to use both at work. God forbid you mis-click in Jira. Navigating around takes so much time, it should probably have its own timesheet code. reply burgerrito 10 hours agoparentprevI'm not sure if it's just me but I swear GitHub UI is one of the slowest web app I've used. reply cdme 18 hours agoprevIt's just a hub at the moment. reply jxi 19 hours agoprevGitHub Actions are also failing with 500 (gateway timeout) errors when trying to fetch the repository. reply hunkins 18 hours agoprevUpdate: looks like the problem has been identified. \"We've identified a cause of degraded git operations, which may affect other GitHub services that rely upon git. We're working to remediate.\" reply clintonb 18 hours agoprevUnclear if related, but the Terraform Registry is also having issues serving data: https://status.hashicorp.com/incidents/jypswvyh0h3z. In a wonderful twist, we are relying on a couple modules served from GitHub! reply remram 19 hours agoprevI hope you didn't wait until now to push your day's work! reply l33t_d0nut 18 hours agoparentI did :( reply localghost3000 19 hours agoprevCan't pull anything from my repos which is not great. reply normie3000 16 hours agoparentIs it possible to download a zip of a repo through the GUI? reply hunkins 19 hours agoparentprevYeah, this is not good. I've experienced other outages on their other products (e.g. GitHub Actions), but not even being able to do a basic git pull is an entirely different level. reply localghost3000 19 hours agorootparentI'm effectively dead in the water here. I guess I'll go touch some grass. Thank you to the SRE's who are looking at this. reply tonetegeatinst 18 hours agorootparentLooking forward to a blogpost or writeup from github on this. reply james33 18 hours agoprevAll checkmarks just turned green and my push went through. Snow day over. reply arnath 18 hours agoprevIt's odd to me that there's nothing indicating an issue is ongoing on the github.com homepage reply eru 18 hours agoprevThey were also down a few days ago, but HN flagged my submission as a dupe. :) reply lukeh 19 hours agoprevYup, SSH rejecting my key, thought it was something at my end but no. Can't run any Yocto builds... I guess a good opportunity to take a walk or do some life admin. reply lukeh 18 hours agoparentBack up now for me. reply impure 18 hours agoprevI thought it was my internet. Oh well, time to finish that game of Civ 6. Edit: and it literally came back up the moment I posted this. reply JSTrading 18 hours agoprevPanic for a minute SSH rejected a key! reply burgerrito 18 hours agoprevThankfully I use Forgejo! No reason to stick with GitHub when Git itself is distributed by nature reply simondotau 18 hours agoparentTrue. Also there's no reason not to stick with GitHub when Git itself is distributed by nature. That's the beauty of distribution. reply the_svd_doctor 18 hours agoprevHa so that's why my git pull were so slow. I should have checked HN faster. reply parpfish 17 hours agoparentit'd be great if they set up their CLI tools such that if there's an error/timeout, they'll do a check of their status page so you don't get the standard 'error' but rather a 'dont worry, youre not doing anything wrong. its borked, our bad' message. reply Aperocky 17 hours agorootparentThat's just an indirect manual dependency on the human that gets to decide to update their status page. reply croemer 17 hours agorootparentprev*great not break :) Make an issue in gh CLI repo, I like the idea reply __turbobrew__ 19 hours agoprevYep, 100% of git operations are failing. CI/CD and dev operations are at a halt. reply 486sx33 18 hours agoprevDamn you azure! Or is Microsoft not even running their precious GitHub in azure reply bobnamob 10 hours agoparentWho said it was an infrastructure failure? There's innumerable causes of this kind of failure that aren't rooted cloud service provider shenanigans (Admittedly the duration of the outage does \"feel\" like an infra outage) reply hunkins 19 hours agoprevGitHub git operations are down. Any git operation returns a 500 error response. reply j45 18 hours agoprevI guess it's a good time as any to setup a backup or check out alternatives that could mirror or standalone. Gitlab, Gitea, any others worth checking out? reply homebrewer 9 hours agoparentJFYI, the next version of gitea (which should come out in April) will have full GitHub mirroring functionality (which will let you set up a mirror and have it pull code/issues/wiki/PRs/etc. every few minutes). The current version can either migrate the full repo once, or mirror the code and nothing else. reply kivikakk 18 hours agoparentprevConsider Forgejo: https://forgejo.org/. reply vv_ 10 hours agoparentprevWhat's the point of having a mirror? It'll only lead to conflicts that'll be difficult to resolve once the main service you use is back up again. For example, I doubt you would be able to easily merge any pull-requests or use the same CI/CD code for the same services without hacky solutions. reply dboreham 18 hours agoparentprevGitea works for us. reply codetrotter 18 hours agorootparentI use a fork of Gitea called Forgejo. It works nicely as well. https://forgejo.org/ reply acidburnNSA 17 hours agorootparentWhat drove you to the fork? reply codetrotter 5 hours agorootparentFirst I was using Gogs. Someone forked Gogs and made Gitea, because Gogs was under control of a single person and some other people found that frustrating. https://blog.gitea.com/welcome-to-gitea/ I was using Gitea for a long time, and then someone forked Gitea to create Forgejo. At this time, my installation of Gitea was already out of date a bit because I had previously been manually building and installing Gitea from source. Soon after Forgejo was created, it landed in FreeBSD ports and then it became available in the FreeBSD package manager. So at this point, and having read a bit about Forgejo and seeing that Forgejo was maintained by people with connection to Codeberg, I thought “hey I need to migrate my current Gitea setup anyway. Either to Gitea installed from FreeBSD packages, or to something else. I might as well try Forgejo.” And that’s how I ended up installing Forgejo and I’ve stuck with it since. reply acidburnNSA 5 hours agorootparentAha, makes sense. Thanks for explaining. I see that Forgejo was created at least partially due to concerns that Gitea was trending towards freemium as well. Good to know. reply ashishb 18 hours agoprevWhy does GitHub go down almost once a month? reply 1propionyl 13 hours agoparentAcquisition. ducks reply __d 19 hours agoprevSSH access appears to be rejecting my key too. reply noplacelikehome 18 hours agoprevI've just ended my Pro plan; enough is enough. I've been debating moving my repositories to a self-hosted forge for a while; it'll be an interesting opportunity to move more CI operations out of Actions and into Nix. reply qqqult 18 hours agoprevlol I changed my ssh key 2 times until I figured out pubkey permission denied was an issue on their side reply souenzzo 14 hours agoprevwindows window operations are down reply rasengan 18 hours agoprevJust the info I was expecting to see on HN. Unfortunately (or Fortunately?), a better source for these kinds of things than anywhere else. reply 0xbadcafebee 18 hours agoprev> all Git operations were unavailable due to a configuration change eats popcorn waiting for explanation of why they didn't catch it in non-prod reply pnw_throwaway 17 hours agoparentHave you never fixed a prod-specific bug before? They’re common enough, and it sounds like they patched this one within a reasonable amount of time. reply 0xbadcafebee 4 hours agorootparentI expect more from billion-dollar companies. If you have that much money, you can pay somebody to ensure the changes are properly tested. (I've worked in billion dollar companies, and usually they are too cheap to do this, despite their massive wealth. They just leave it up to ICs and hope they are testing right, rather than making sure) reply atulvi 18 hours agoprevI just reset my ssh key lol. reply JSTrading 18 hours agoparentThey are going to get DDoS's by people trying to do this haha. reply Rexogamer 18 hours agoprevthe incident has been marked as resolved; I am now able to push reply xyst 16 hours agoprevYet another reason to self host your VCS. Only thing hosted to “the cloud” these days are my backups - split between S3 and GCS. ~$25/mo reply orf 7 hours agoparentThat’s expensive, I get it for free with GitHub. And a loooot more functionality. reply unwoven 19 hours agoprev [–] lmao i deleted and readded a new key thinking my key was fucked reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GitHub faced a Git operations outage on January 13, 2025, due to a configuration change affecting the internal load balancer, lasting from 23:35 to 00:24 UTC. - The issue was resolved by reverting the configuration change, and GitHub is working on improving monitoring and deployment processes to prevent similar incidents. - The outage also affected GitHub's Actions and Pages services, highlighting the interconnected nature of their platform services."
    ],
    "commentSummary": [
      "GitHub faced a major outage impacting git operations, leading to confusion among developers who initially suspected issues with their SSH keys or local configurations. - The incident underscored the challenges of relying on centralized services, prompting discussions on the advantages of self-hosting and decentralized systems. - Although the issue was resolved, it highlighted concerns about GitHub's reliability and the risks of depending on third-party platforms for essential tasks."
    ],
    "points": 324,
    "commentCount": 250,
    "retryCount": 0,
    "time": 1736812051
  },
  {
    "id": 42694596,
    "title": "ZFS 2.3 released with ZFS raidz expansion",
    "originLink": "https://github.com/openzfs/zfs/releases/tag/zfs-2.3.0",
    "originBody": "openzfs / zfs Public Notifications Fork 1.8k Star 10.9k Code Issues 1.4k Pull requests 138 Discussions Actions Projects Wiki Security Insights Releases zfs-2.3.0 zfs-2.3.0 Latest Latest Compare behlendorf released this · 161 commits to master since this release zfs-2.3.0 bc06d81 We are excited to announce the release of OpenZFS 2.3.0. Key Features in OpenZFS 2.3.0: RAIDZ Expansion (#15022): Add new devices to an existing RAIDZ pool, increasing storage capacity without downtime. Fast Dedup (#15896): A major performance upgrade to the original OpenZFS deduplication functionality. Direct IO (#10018): Allows bypassing the ARC for reads/writes, improving performance in scenarios like NVMe devices where caching may hinder efficiency. JSON (#16217): Optional JSON output for the most used commands. Long names (#15921): Support for file and directory names up to 1023 characters. Bug Fixes: A series of critical bug fixes addressing issues reported in previous versions. Numerous performance improvements throughout the code base. Supported Platforms: Linux kernels 4.18 - 6.12, FreeBSD releases 13.3, 14.0 - 14.2. Additional Information: Documentation - OpenZFS documentation for Linux and FreeBSD. Change log - Complete v2.2.0 - v2.3.0 change log Thank you to all 134 contributors who participated in this release cycle Module option changes - See the module parameters documentation for the complete list of the options and what they control. New module options Removed module options Modified module options Assets 5 Loading 37 11 97 42 23 5 133 people reacted",
    "commentLink": "https://news.ycombinator.com/item?id=42694596",
    "commentBody": "ZFS 2.3 released with ZFS raidz expansion (github.com/openzfs)302 points by scrp 11 hours agohidepastfavorite215 comments scrp 11 hours agoAfter years in the making ZFS raidz expansaion is finally here. Major features added in release: - RAIDZ Expansion: Add new devices to an existing RAIDZ pool, increasing storage capacity without downtime. - Fast Dedup: A major performance upgrade to the original OpenZFS deduplication functionality. - Direct IO: Allows bypassing the ARC for reads/writes, improving performance in scenarios like NVMe devices where caching may hinder efficiency. - JSON: Optional JSON output for the most used commands. - Long names: Support for file and directory names up to 1023 characters. reply jdboyd 11 hours agoparentThe first 4 seem like really big deals. reply snvzz 10 hours agorootparentThe fifth is also, once you consider non-ascii names. reply cm2187 11 hours agoparentprevBut I presume it is still not possible to remove a vdev. reply ryao 10 hours agorootparentThat was added a while ago: https://openzfs.github.io/openzfs-docs/man/master/8/zpool-re... It works by making a readonly copy of the vdev being removed inside the remaining space. The existing vdev is then removed. Data can still be accessed from the copy, but new writes will go to an actual vdev while data no longer needed on the copy is gradually reclaimed as free space as the old data is no longer needed. reply lutorm 10 hours agorootparentAlthough \"Top-level vdevs can only be removed if the primary pool storage does not contain a top-level raidz vdev, all top-level vdevs have the same sector size, and the keys for all encrypted datasets are loaded.\" reply ryao 10 hours agorootparentI forgot we still did not have that last bit implemented. However, it is less important now that we have expansion. reply cm2187 7 hours agorootparentprevAnd in my case all the vdevs are raidz reply mustache_kimono 11 hours agorootparentprevIs this possible elsewhere (re: other filesystems)? reply cm2187 11 hours agorootparentIt is possible with windows storage space (remove drive from a pool) and mdadm/lvm (remove disk from a RAID array, remove volume from lvm), which to me are the two major alternatives. Don't know about unraid. reply lloeki 11 hours agorootparentIIUC the ask (I have a hard time wrapping my head around zfs vernacular), btrfs allows this at least in some cases. If you can convince btrfs balance to not use the dev to remove it will simply rebalance data to the other devs and then you can btrfs device remove. reply mustache_kimono 11 hours agorootparentprev> It is possible with windows storage space (remove drive from a pool) and mdadm/lvm (remove disk from a RAID array, remove volume from lvm), which to me are the two major alternatives. Don't know about unraid. Perhaps I am misunderstanding you, but you can offline and remove drives from a ZFS pool. Do you mean WSS and mdadm/lvm will allow an automatic live rebalance and then reconfigure the drive topology? reply cm2187 11 hours agorootparentSo for instance I have a ZFS pool with 3 HDD data vdevs, and 2 SSD special vdevs. I want to convert the two SSD vdevs into a single one (or possibly remove one of them). From what I read the only way to do that is to destroy the entire pool and recreate it (it's in a server in a datacentre, don't want to reupload that much data). In windows, you can set a disk for removal, and as long as the other disks have enough space and are compatible with the virtual disks (eg you need at least 5 disks if you have parity with number of columns=5), it will rebalance the blocks onto the other disks until you can safely remove the disk. If you use thin provisioning, you can also change your mind about the settings of a virtual disk, create a new one on the same pool, and move the data from one to the other. Mdadm/lvm will do the same albeit with more of a pain in the arse as RAID requires to resilver not just the occupied space but also the free space so takes a lot more time and IO than it should. It's one of my beef with ZFS, there are lots of no return decisions. That and I ran into some race conditions with loading a ZFS array on boot with nvme drives on ubuntu. They seem to not be ready, resulting in randomly degraded arrays. Fixed by loading the pool with a delay. reply ryao 8 hours agorootparentThe man page says that your example is doable with zpool remove: https://openzfs.github.io/openzfs-docs/man/master/8/zpool-re... reply formerly_proven 6 hours agorootparentprevMy understanding is that ZFS does virtualphysical translation in the vdev layer, i.e. all block references in ZFS contain a (vdev, vblock) tuple, and the vdev knows how to translate that virtual block offset into actual on-disk block offset(s). This kinda implies that you can't actually remove data vdevs, because in practice you can't rewrite all references. You also can't do offline deduplication without rewriting references (i.e. actually touching the files in the filesystem). And that's why ZFS can't deduplicate snapshots after the fact. On the other hand, reshaping a vdev is possible, because that \"just\" requires shuffling the vblock -> physical block associations inside the vdev. reply ryao 5 hours agorootparentThere is a clever trick that is used to make top level removal work. The code will make the vdev readonly. Then it will copy its contents into free space on other vdevs (essentially, the contents will be stored behind the scenes in a file). Finally, it will redirect reads on that vdev into the stored vdev. This indirection allows you to remove the vdev. It is not implemented for raid-z at present though. reply formerly_proven 4 hours agorootparentThough the vdev itself still exists after doing that? It just happens to be backed by, essentially, a \"file\" in the pool, instead of the original physical block devices, right? reply ryao 4 hours agorootparentYes. reply Sesse__ 10 hours agorootparentprev> Do you mean WSS and mdadm/lvm will allow an automatic live rebalance and then reconfigure of the drive topo? mdadm can convert RAID-5 to a larger or smaller RAID-5, RAID-6 to a larger or smaller RAID-6, RAID-5 to RAID-6 or the other way around, RAID-0 to a degraded RAID-5, and many other fairly reasonable operations, while the array is online, resistant to power loss and the likes. I wrote the first version of this md code in 2005 (against kernel 2.6.13), and Neil Brown rewrote and mainlined it at some point in 2006. ZFS is… a bit late to the party. reply ryao 10 hours agorootparentDoing this with the on disk data in a merkle tree is much harder than doing it on more conventional forms of storage. By the way, what does MD do when there is corrupt data on disk that makes it impossible to know what the correct reconstruction is during a reshape operation? ZFS will know what file was damaged and proceed with the undamaged parts. ZFS might even be able to repair the damaged data from ditto blocks. I don’t know what the MD behavior is, but its options for handling this are likely far more limited. reply Sesse__ 9 hours agorootparentWell, then they made a design choice in their RAID implementation that made fairly reasonable things hard. I don't know what md does if the parity doesn't match up, no. (I've never ever had that happen, in more than 25 years of pretty heavy md use on various disks.) reply ryao 9 hours agorootparentI am not sure if reshaping is a reasonable thing. It is not so reasonable in other fields. In architecture, if you build a bridge and then want more lanes, you usually build a new bridge, rather than reshape the bridge. The idea of reshaping a bridge while cars are using it would sound insane there, yet that is what people want from storage stacks. Reshaping traditional storage stacks does not consider all of the ways things can go wrong. Handling all of them well is hard, if not impossible to do in traditional RAID. There is a long history of hardware analogs to MD RAID killing parity arrays when they encounter silent corruption that makes it impossible to know what is supposed to be stored there. There is also the case where things are corrupted such that there is a valid reconstruction, but the reconstruction produces something wrong silently. Reshaping certainly is easier to do with MD RAID, but the feature has the trade off that edge cases are not handled well. For most people, I imagine that risk is fine until it bites them. Then it is not fine anymore. ZFS made an effort to handle all of the edge cases so that they do not bite people and doing that took time. reply Sesse__ 9 hours agorootparent> I am not sure if reshaping is a reasonable thing. Yet people are celebrating when ZFS adds it. Was it all for nothing? reply ryao 8 hours agorootparentPeople wanted it, but it was very hard to do safely. While ZFS now can do it safely, many other storage solutions cannot. Those corruption issues I mentioned, where the RAID controller has no idea what to do, affect far more than just reshaping. They affect traditional RAID arrays when disks die and when patrol scrubs are done. I have not tested MD RAID on edge cases lately, but the last time I did, I found MD RAID ignored corruption whenever possible. It would not detect corruption in normal operation because it assumed all data blocks are good unless SMART said otherwise. Thus, it would randomly serve bad data from corrupted mirror members and always serve bad data from RAID 5/6 members whenever the data blocks were corrupted. This was particularly tragic on RAID 6, where MD RAID is hypothetically able to detect and correct the corruption if it tried. Doing that would come with such a huge performance overhead that it is clear why it was not done. Getting back to reshaping, while I did not explicitly test it, I would expect that unless a disk is missing or disappears during a reshape, MD RAID would ignore any corruption that can be detected using parity and assume all data blocks are good just like it does in normal operation. It does not make sense for MD RAID to look for corruption during a reshape operation, since not only would it be slower, but even if it finds corruption, it has no clue how to correct the corruption unless RAID 6 is used, there are no missing/failed members and the affected stripe does not have any read errors from SMART detecting a bad sector that would effectively make it as if there was a missing disk. You could do your own tests. You should find that ZFS handles edge cases where the wrong thing is in a spot where something important should be gracefully while MD RAID does not. MD RAID is a reimplementation of a technology from the 1960s. If 1960s storage technology handled these edge cases well, Sun Microsystems would not have made ZFS to get away from older technologies. reply amluto 2 hours agorootparentprevI’ve experienced bit rot on md. It was not fun, and the tooling was of approximately no help recovering. reply TiredOfLife 10 hours agorootparentprevStorage Spaces doesn't dedicate drive to single purpose. It operates in chunks (256MB i think). So one drive can, at the same time, be part of a mirror and raid-5 and raid-0. This allows fully using drives with various sizes. And choosing to remove drive will cause it to redistribute the chunks to other available drives, without going offline. reply cm2187 4 hours agorootparentAnd as a user it seems to me to be the most elegant design. The quality of the implementation (parity write performance in particular) is another matter. reply c45y 11 hours agorootparentprevBcachefs allows it reply eptcyka 11 hours agorootparentCool, just have to wait before it is stable enough for daily use of mission critical data. I am personally optimistic about bcachefs, but incredibly pessimistic about changing filesystems. reply ryao 8 hours agorootparentIt seems easier to copy data to a new ZFS pool if you need to remove RAID-Z top level vdevs. Another possibility is to just wait for someone to implement it in ZFS. ZFS already has top level vdev removal for other types of vdevs. Support for top level raid-z vdev removal just needs to be implemented on top of that. reply unixhero 9 hours agorootparentprevBtrfs reply tw04 9 hours agorootparentExcept you shouldn’t use btrfs for any parity based raid if you value your data at all. In fact, I’m not aware if any vendor that has implemented btrfs with parity based raid, they all resort to btrfs on md. reply poisonborz 8 hours agoprevI just don't get it how the Windows world - by far the largest PC platform per userbase - still doesn't have any answer to ZFS. Microsoft had WinFS and then ReFS but it's on the backburner and while there is active development (Win11 ships some bits time to time) release is nowhere in sight. There are some lone warriors trying the giant task of creating a ZFS compatibility layer with some projects, but they are far from being mature/usable. How come that Windows still uses a 32 year old file system? reply bayindirh 6 hours agoparent> How come that Windows still uses a 32 year old file system? Simple. Because most of the burden is taken by the (enterprise) storage hardware hosting the FS. Snapshots, block level deduplication, object storage technologies, RAID/Resiliency, size changes, you name it. Modern storage appliances are black magic, and you don't need much more features from NTFS. You either transparently access via NAS/SAN or store your NTFS volumes on capable disk boxes. On the Linux world, at the higher end, there's Lustre and GPFS. ZFS is mostly for resilient, but not performance critical needs. reply poisonborz 4 hours agorootparentSo private consumers should just pay cloud subscription if they want safer/modern data storage for their PC? (without NAS) reply shrubble 4 hours agorootparentNo, private consumers have a choice, since Linux and FreeBSD runs well on their hardware. Microsoft is too busy shoveling their crappy AI and convincing OEMs to put a second Windows button (the CoPilot button) on their keyboards. reply bluGill 4 hours agorootparentprevProbably. There are levels of backups, and a cloud subscription SHOULD give you copies in geographical separate locations with someone to help you (who probably isn't into computers and doesn't want to learn the complex details) restore when (NOT IF!) needed. I have all my backups on a NAS in the next room. This covers the vast majority of use cases for backups, but if my house burns down everything is lost. I know I'm taking that risk, but really I should have better. Just paying someone to do it all in the cloud should be better for me as well and I keep thinking I should do this. Of course paying someone assumes they will do their job. There are always incompetent companies out there to take your money. reply pdimitar 3 hours agorootparentMy setup is similar to yours, but I also distribute my most important data in compressed ( I trust my own backups much more than any subscription, not from a technical standpoint but from an access one (for example, losing access to your google account). I personally use cloud storage extensively, but I keep a local version with periodic rclone/borg. It allows me access from everywhere and sleep well at night. reply qwertox 4 hours agorootparentprevNTFS has Volume Shadow Copy, which is \"good enough\" for private users if they want to create image backups while their system is running. reply BSDobelix 4 hours agorootparentFirst of all, that's not a backup, that's a snapshot, and NO, that's not \"good enough\", tell your grandma that all her digitised pictures are gone because her hard drive exploded, or that one most important jpeg is now unwatchable because of bitrot. Just because someone is a private user doesn't mean that the data is less important, often it's quite the opposite, for example a family album vs your cloned git repository. reply tjoff 3 hours agorootparent... VSS is used to create backups. Re-read parent. reply BSDobelix 2 hours agorootparentNot good enough, you can make 10000 backups of bitrotten data, if you don't have check-sums on your block (zfs) or files (restic) nothing can help you. That's the same integrity as to copy stuff on your thump-drive. reply BSDobelix 5 hours agorootparentprev>ZFS is mostly for resilient, but not performance critical needs. Los Alamos disagrees ;) https://www.lanl.gov/media/news/0321-computational-storage But yes, in general you are right, Cern for example uses Ceph: https://indico.cern.ch/event/1457076/attachments/2934445/515... reply bayindirh 5 hours agorootparentI think what LLNL did predates GPUDirect and other new technologies came after 2022, but that's a good start. CERN's Ceph also for their \"General IT\" needs. Their clusters are independent from that. Also CERN's most processing is distributed across Europe. We are part of that network. Many, if not all of the HPC centers we talk with uses Lustre as their \"immediate\" storage. Also, there's Weka now, a closed source storage system supporting insane speeds and tons of protocols at the same time. Mostly used for and by GPU clusters around the world. You connect terabits to that cluster casually. It's all flash, and flat out fast. reply GuB-42 8 hours agoparentprevTo be honest, the situation with Linux is barely better. ZFS has license issues with Linux, preventing full integration, and Btrfs is 15 years in the making and still doesn't match ZFS in features and stability. Most Linux distros still use ext4 by default, which is 19 years old, but ext4 is little more than a series of extensions on top of ext2, which is the same age as NTFS. In all fairness, there are few OS components that are as critical as the filesystem, and many wouldn't touch filesystems that have less than a decade of proven track record in production. reply mogoh 7 hours agorootparentZFS might be better then any other FS on Linux (I don't judge that). But you must admit that the situation on Linux is quite better then on Windows. Linux has so many FS in main branch. There is a lot of development. BTRFS had a rocky start, but it got better. reply stephen_g 6 hours agorootparentprevI’m interested to know what ‘full integration’ does look like, I use ZFS in Proxmox (Debian-based) and it’s really great and super solid, but I haven’t used ZFS in more vanilla Linux distros. Does Proxmox have things that regular Linux is missing out on, or are there shortcomings and things I just don’t realise about Proxmox? reply whataguy 6 hours agorootparentThe difference is that the ZFS kernel module is included by default with Proxmox, whereas with e.g. Debian, you would need to install it manually. reply pimeys 6 hours agorootparentAnd you can't follow the latest kernel before the ZFS module supports it. reply BSDobelix 6 hours agorootparentTry CachyOS https://cachyos.org/ , you can even swap from an existing Arch installation: https://wiki-dev.cachyos.org/sk/cachyos_repositories/how_to_... reply blibble 6 hours agorootparentprevfor Debian that's not exactly a problem reply oarsinsync 5 hours agorootparentUnless you’re using Debian backports, and they backport a new kernel a week before the zfs backport package update happens. Happened to me more than once. I ended up manually changing the kernel version limitations the second time just to get me back online, but I don’t recall if that ended up hurting me in the long run or not. reply lousken 8 hours agorootparentprevas far as stability goes, btrfs is used by meta, synology and many others, so I wouldn't say it's not stable, but some features are lacking reply azalemeth 7 hours agorootparentMy understanding is that single-disk btrfs is good, but raid is decidedly dodgy; https://btrfs.readthedocs.io/en/latest/btrfs-man5.html#raid5... states that: > The RAID56 feature provides striping and parity over several devices, same as the traditional RAID5/6. > There are some implementation and design deficiencies that make it unreliable for some corner cases and *the feature should not be used in production, only for evaluation or testing*. > The power failure safety for metadata with RAID56 is not 100%. I have personally been bitten once (about 10 years ago) by btrfs just failing horribly on a single desktop drive. I've used either mdadm + ext4 (for /) or zfs (for large /data mounts) ever since. Zfs is fantastic and I genuinely don't understand why it's not used more widely. reply crest 5 hours agorootparentOne problem with your setup is that ZFS by design can't use a traditional *nix filesystem buffer cache. Instead it has to use its own ARC (adaptive replacement cache) with end-to-end checksumming, transparent compression, and copy-on-write semantics. This can lead to annoying performance problems when the two types of file system caches contest for available memory. There is a back pressure mechanism, but it effectively pauses other writes while evicting dirty cache entries to release memory. reply ryao 4 hours agorootparentTraditionally, you have the page cache on top of the FS and the buffer cache below the FS, with the two being unified such that double caching is avoided in traditional UNIX filesystems. ZFS goes out of its way to avoid the buffer cache, although Linux does not give it the option to fully opt out of it since the block layer will buffer reads done by userland to disks underneath ZFS. That is why ZFS began to purge the buffer cache on every flush 11 years ago: https://github.com/openzfs/zfs/commit/cecb7487fc8eea3508c3b6... That is how it still works today: https://github.com/openzfs/zfs/blob/fe44c5ae27993a8ff53f4cef... If I recall correctly, the page cache is also still above ZFS when mmap() is used. There was talk about fixing it by having mmap() work out of ARC instead, but I don’t believe it was ever done, so there is technically double caching done there. reply taskforcegemini 21 minutes agorootparentwhat's the best way to deal with this then? disable filecache of linux? I've tried disabling/minimizing arc in the past to avoid the oom reaper, but the arc was stubborn and its RAM usage remained as is reply lousken 6 hours agorootparentprevI was assuming OP wants to highlight filesystem use on a workstation/desktop, not for a file server/NAS. I had similar experience decade ago, but these days single drives just work, same with mirroring. For such setups btrfs should be stable. I've never seen a workstation with raid5/6 setup. Secondly, filesystems and volume managers are something else, even if e.g. btrfs and ZFS are essentialy both. For a NAS setup I would still prefer ZFS with truenas scale (or proxmox if virtualization is needed), just because all these scenarios are supported as well. And as far as ZFS goes, encryption is still something I am not sure about especially since I want to use snapshots sending those as a backup to remote machine. reply hooli_gan 6 hours agorootparentprevRAID5/6 is not needed with btrfs. One should use RAID1, which supports striping the same data onto multiple drives in a redundant way. reply brian_cunnie 4 hours agorootparentprev> I have personally been bitten once (about 10 years ago) by btrfs just failing horribly on a single desktop drive. Me, too. The drive was unrecoverable. I had to reinstall from scratch. reply worthless-trash 2 hours agorootparentprevLicensing incompatibilities. reply _joel 6 hours agorootparentprevI'm similar to some other people here, I guess once they've been bitten by data loss due to btrfs, it's difficult to advocate for it. reply lousken 6 hours agorootparentI am assuming almost everybody at some point experienced data loss because they pulled out a flash drive too early. Is it safe to assume that we stopped using flash drives because of it? reply _joel 5 hours agorootparentI'm not sure we have stopped using flash, judging by the pile of USB sticks on my desk :) In relation to the fs analogy if you used a flash drive that you know corrupted your data, you'd throw it away for one you know works. reply fourfour3 7 hours agorootparentprevDo Synology actually use the multi-device options of btrfs, or are they using linux softraid + lvm underneath? I know Synology Hybrid RAID is a clever use of LVM + MD raid, for example. reply bayindirh 6 hours agorootparentprev> Most Linux distros still use ext4 by default, which is 19 years old, but ext4 is little more than a series of extensions on top of ext2, which is the same age as NTFS. However, ext4 and XFS are much more simpler and performant than BTRFS & ZFS as root drives on personal systems and small servers. I personally won't use either on a single disk system as root FS, regardless of how fast my storage subsystem is. reply BSDobelix 6 hours agorootparentprev>ZFS has license issues with Linux, preventing full integration No one wants that, openZFS is much healthier without Linux and it's \"Foundation/Politics\". reply bhaney 5 hours agorootparent> No one wants that I want that reply BSDobelix 5 hours agorootparentThen let me tell you that FreeBSD or OmniOS is what you really want ;) reply bhaney 5 hours agorootparentYou're now 0 for 2 at telling me what I want reply BSDobelix 5 hours agorootparentThe customer is not always right, however a good/modern Filesystem really would be something for Linux ;) reply ruthmarx 14 minutes agorootparent> The customer is not always right, An uninvited door-to-door salesman is rarely, if ever right. reply cesarb 4 hours agorootparentprev> Btrfs [...] still doesn't match ZFS in features [...] Isn't the feature in question (array expansion) precisely one which btrfs already had for a long time? Does ZFS have the opposite feature (shrinking the array), which AFAIK btrfs also already had for a long time? (And there's one feature which is important to many, \"being in the upstream Linux kernel\", that ZFS most likely will never have.) reply wkat4242 4 hours agorootparentZFS also had expansion for a long time but it was offline expansion. I don't know if btrfs has also had online for a long time? And shrinking no, that is a big missing feature in ZFS IMO. Understandable considering its heritage (large scale datacenters) but nevertheless an issue for home use. But raidz is rock-solid. Btrfs' raid is not. reply unsnap_biceps 2 hours agorootparentRaidz wasn't able to be expanded in place before this. You were able to add to a pool that included a raidz vdev, but that raidz vdev was immutable. reply wkat4242 1 hour agorootparentOh ok, I've never done this, but I thought it was already there. Maybe this was the original ZFS from Sun? But maybe I just remember it incorrectly, sorry. I've used it on multi-drive arrays but I never had the need for expansion. reply xattt 8 hours agorootparentprevZFS on OS X was killed because of Oracle licensing drama. I don’t expect anything better on Windows either. reply ryao 7 hours agorootparentThere is a third party port here: https://openzfsonosx.org/wiki/Main_Page It was actually the NetApp lawsuit that caused problems for Apple’s adoption of ZFS. Apple wanted indemnification from Sun because of the lawsuit, Sun’s CEO did not sign the agreement before Oracle’s acquisition of Sun happened and Oracle had no interest in granting that, so the official Apple port was cancelled. I heard this second hand years later from people who were insiders at Sun. reply xattt 6 hours agorootparentThat’s a shame re: NetApp/ZFS. While third-party ports are great, they lack deep integration that first-party support would have brought (non-kludgy Time Machine which is technically fixed with APFS). reply throw0101a 6 hours agorootparentprev> ZFS on OS X was killed because of Oracle licensing drama. It was killed because Apple and Sun couldn't agree on a 'support contract'. From Jeff Bonwick, one of the co-creators ZFS: >> Apple can currently just take the ZFS CDDL code and incorporate it (like they did with DTrace), but it may be that they wanted a \"private license\" from Sun (with appropriate technical support and indemnification), and the two entities couldn't come to mutually agreeable terms. > I cannot disclose details, but that is the essence of it. * https://archive.is/http://mail.opensolaris.org/pipermail/zfs... Sun took DTrace, licensed via CDDL—just like ZFS—and put it into the kernel without issue. Of course a file system is much more central to an operating system, so they wanted much more of a CYA for that. reply BSDobelix 6 hours agorootparentprev>ZFS on OS X was killed because of Oracle licensing drama. Naa it was Jobs ego not the license: >>Only one person at Steve Jobs' company announces new products: Steve Jobs. https://arstechnica.com/gadgets/2016/06/zfs-the-other-new-ap... reply bolognafairy 6 hours agorootparentIt’s a cute story that plays into the same old assertions about Steve Jobs, but the conclusion is mostly baseless. There are many other, more credible, less conspiratorial, possible explanations. reply wkat4242 4 hours agorootparentIt could have played into it though, but I agree the support contract that couldn't be worked out mentioned elsewhere in the thread is more likely. But I think these things are usually a combination. When a business relationship sours, agreements are suddenly much harder to work out. The negotiators are still people and they have feelings that will affect their decisionmaking. reply nabla9 6 hours agorootparentprevLicense is not a real issue. It must be just distributed in separate module. No big hurdle. reply Jnr 5 hours agorootparentFrom my point of view it is a real usability issue. zfs modules are not in the official repos. You either have to compile it on each machine or use unofficial repos, which is not exactly ideal and can break things if those repos are not up to date. And I guess it also needs some additional steps for secureboot setup on some distros? I really want to try zfs because btrfs has some issues with RAID5 and RAID6 (it is not recommended so I don't use it) but I am not sure I want to risk the overall system stability, I would not want to end up in a situation where my machines don't boot and I have to fix it manually. reply harshreality 4 hours agorootparentWhy are you considering raid5/6? Are you considering building a large storage array? If the data will fit comfortably (50-60% utilization) on one drive, all you need is raid1. Btrfs is fine for raid1 (raid1c3 for extra redundancy); it might have hidden bugs, but no filesystem is immune from those; zfs had a data loss bug (it was rare, but it happened) a year ago. Why use zfs for a boot partition? Unless you're using every disk mounting point and nvme slot for a single large raid array, you can use a cheap 512GB nvme drive or old spare 2.5\" ssd for the boot volume. Or two, in btrfs raid1 if you absolutely must... but do you even need redundancy or datasum (which can hurt performance) to protect OS files? Do you really care if static package files get corrupted? Those are easily reinstalled, and modern quality brand SSDs are quite reliable. reply chillfox 5 hours agorootparentprevI have been using ZFS on Mint and Alpine Linux for years for all drives (including root) and have never had an issue. It's been fantastic and is super fast. My linux/zfs laptop loads games much faster than an identical machine running Windows. I have never had data corruption issues with ZFS, but I have had both xfs and ext4 destroy entire discs. reply crest 5 hours agorootparentprevThe main hurdle is hostile Linux kernel developers who aren't held accountable intentionally breaking ZFS for their own petty ideological reasons e.g. removing the in-kernel FPU/SIMD register save/restore API and replacing it with a \"new\" API to do the the same. What's \"new\" about the \"new\" API? Its symbols are GPL2 only to deny it's use to non-GPL2 modules (like ZFS). Guess that's an easy way to make sure that BTRFS is faster than ZFS or set yourself up as the (to be) injured party. Of course a reimplementation of the old API in terms of the new is an evil \"GPL condom\" violating the kernel license right? Why can't you see ZFS's CDDL2 license is the real problem here for being the wrong flavour of copyleft license. Way to claim the moral high ground you short-sighted, bigoted pricks. sigh reply GuB-42 5 hours agorootparentprevIt is a problem because most of the internal kernel APIs are GPL-only, which limit the abilities of the ZFS module. It is a common source of argument between the Linux guys and the ZFS on Linux guys. The reason for this is not just to piss off non-GPL module developers. GPL-only internal APIs are subject to change without notice, even more so than the rest of the kernel. And because the licence may not allow the Linux kernel developers to make the necessary changes to the module when it happens, there is a good chance it breaks without warning. And even with that, all internal APIs may change, it is just a bit less likely than for the GPL-only ones, and because ZFS on Linux is a separate module, there is no guarantee for it to not break with successive Linux versions, in fact, it is more like a guarantee that it will break. Linux is proudly monolithic, and as constantly evolving a monolithic kernel, developers need to have control over the entire project. It is also community-driven. Combined, you need rules to have the community work together, or everything will break down, and that's what the GPL is for. reply mustache_kimono 8 hours agoparentprev> I just don't get it how the Windows world - by far the largest PC platform per userbase - still doesn't have any answer to ZFS. The mainline Linux kernel doesn't either, and I think the answer is because it's hard and high risk with a return mostly measured in technical respect? reply ffsm8 8 hours agorootparentTechnically speaking, bcachefs has been merged into the Linux Kernel - that makes your initial assertion wrong. But considering it's had two drama events within 1 year of getting merged... I think we can safely confirm your conclusion of it being really hard reply mustache_kimono 8 hours agorootparent> Technically speaking, bcachefs has been merged into the Linux Kernel - that makes your initial assertion wrong. bcachefs doesn't implement its erasure coding/RAID yet? Doesn't implement send/receive. Doesn't implement scrub/fsck. See: https://bcachefs.org/Roadmap, https://bcachefs.org/Wishlist/ btrfs is still more of a legit competitor to ZFS these days and it isn't close to touching ZFS where it matters. If the perpetually half-finished bcachefs and btrfs are the \"answer\" to ZFS that seems like too little, too late to me. reply koverstreet 7 hours agorootparentErasure coding is almost done; all that's missing is some of the device evacuate and reconstruct paths, and people have been testing it and giving positive feedback (especially w.r.t. performance). It most definitely does have fsck and has since the beginning, and it's a much more robust and dependable fsck than btrfs's. Scrub isn't quite done - I actually was going to have it ready for this upcoming merge window except for a nasty bout of salmonella :) Send/recv is a long ways off, there might be some low level database improvements needed before that lands. Short term (next year or two) priorities are finishing off online fsck, more scalability work (upcoming version for this merge window will do 50PB, but now we need to up the limit on number of drives), and quashing bugs. reply ryao 7 hours agorootparentHearing that it is missing some code for reconstruction makes it sound like it is missing something fairly important. The original purpose of parity RAID is to support reconstruction. reply koverstreet 3 hours agorootparentWe can do reconstruct reads, what's missing is the code to rewrite missing blocks in a stripe after a drive dies. In general, due to the scope of the project, I've been prioritizing the functionality that's needed to validate the design and the parts that are needed for getting the relationships between different components correct. e.g. recently I've been doing a bunch of work on backpointers scalability, and that plus scrub are leading to more back and forth iteration on minor interactions with erasure coding. So: erasure coding is complete enough to know that it works and for people to torture test it, but yes you shouldn't be running it in production yet (and it's explicitly marked as such). What's remaining is trivial but slightly tedious stuff that's outside the critical path of the rest of the design. Some of the code I've been writing for scrub is turning out to also be what we want for reconstruct, so maybe we'll get there sooner rather than later... reply BSDobelix 6 hours agorootparentprev>except for a nasty bout of salmonella Did the Linux Foundation send you some \"free\" sushi? ;) However keep the good work rolling, super happy about a good, usable and modern Filesystem native to Linux. reply pdimitar 5 hours agorootparentprevFYI: the main reason I gave up on bcachefs is that I can't use devices with native 16K blocks. Hope that's coming this year. I have a bunch of old HDDs and SSDs and I could very easily assemble a spare storage server with about 4TB capacity. Already tested bcachefs with most of the drives and it performed very well. Also lack of ability to reconstruct seems like another worrying omission. reply koverstreet 3 hours agorootparentI wasn't aware there were actual users needing bs > ps yet. Cool :) That should be a completely trivial for bcachefs to support, it'll mostly just be a matter of finding or writing the tests. reply pdimitar 1 hour agorootparentSeriously? But... NVMe drives! I stopped testing because I only have one spare NVMe and couldn't use it with bcachefs. If you or others can get it done I'm absolutely starting to use bcachefs the month after. I do need fast storage servers in my home office. reply mafuy 5 hours agorootparentprevThank you, looking forward to it! reply kwanbix 8 hours agoparentprevHonest question. As an end user that uses Windows and Linux and does not uses ZFS, what I am missing? reply johannes1234321 3 hours agorootparentFor a while I ran Open Solaris with ZFS as root filesystem. The key feature for me, which I miss, is the snapshotting integrated into the package manager. ZFS allows snapshots more or less for free (due to copy on weite) including cron based snapshotting every 15 minutes. So if I did a mistake anywhere there was a way to recover. And that integrated with the update manager and boot manager means that on an update a snapshot is created and during boot one can switch between states. Never had a broken update, but gave a good feeling. On my home server I like the raid features and on Solaris it was nicely integrated with NFS etc so that one can easily create volumes and export them and set restrictions (max size etc.) on it. reply poisonborz 8 hours agorootparentprevWay better data security, resilience against file rotting. This goes for both HDDs or SSDs. Copy-on-write, snapshots, end to end integrity. Also easier to extend the storage for safety/drive failure (and SSDs corrupt in a more sneaky way) with pools. reply wil421 8 hours agorootparentHow many of us are using single disks on our laptops? I have a NAS and use all of the above but that doesn’t help people with single drive systems. Or help me understand why I would want it on my laptop. reply ryao 8 hours agorootparentMy thinkpad from college uses ZFS as its rootfs. The benefits are: * If the hard drive / SSD corrupted blocks, the corruption would be identified. * Ditto blocks allow for self healing. Usually, this only applies to metadata, but if you set copies=2, you can get this on data too. It is a poor man’s RAID. * ARC made the desktop environment very responsive since unlike the LRU cache, ARC resists cold cache effects from transient IO workloads. * Transparent compression allowed me to store more on the laptop than otherwise possible. * Snapshots and rollback allowed me to do risky experiments and undo them as if nothing happened. * Backups were easy via send/receive of snapshots. * If the battery dies while you are doing things, you can boot without any damage to the filesystem. That said, I use a MacBook these days when I need to go outside. While I miss ZFS on it, I have not felt motivated to try to get a ZFS rootfs on it since the last I checked, Apple hardcoded the assumption that the rootfs is one of its own filesystems into the XNU kernel and other parts of the system. reply rabf 4 hours agorootparentNot ever having to deal with partitions and instead using data sets each of which can have their own properties such as compression, size quota, encryption etc is another benefit. Also using zfsbootmenu instead of grub enables booting from different datasets or snapshots as well as mounting and fixing data sets all from the bootloader! reply CoolCold 7 hours agorootparentprevNTFS had compression since mot even sure when. For other stuff, let that nerdy CorpIT handle your system. reply ryao 6 hours agorootparentNTFS compression is slow and has a low compression ratio. ZFS has both zstd and lz4. reply adgjlsfhk1 3 hours agorootparentprevyes but NTFS is bad enough that no one needs to be told how bad it is. reply yjftsjthsd-h 4 hours agorootparentprevIf the single drive in your laptop corrupts data, you won't know. ZFS can't fix corruption without extra copies, but it's still useful to catch the problem and notify the user. Also snapshots are great regardless. reply Polizeiposaune 2 hours agorootparentIn some circumstances it can. Every ZFS block pointer has room for 3 disk addresses; by default, the extras are used only for redundant metadata, but they can also be used for user data. When you turn on ditto blocks for data (zfs set copies=2 rpool/foo), zfs can fix corruption even on single-drive systems at the cost of using double or triple the space. Note that (like compression), this only affects blocks written after the setting is in place, but (if you can pause writes to the filesystem) you can use zfs send|zfs recv to rewrite all blocks to ensure all blocks are redundant. reply ekianjo 8 hours agorootparentprevIt provides encryption by default without having to deal with LUKS. And no need to ever do fsck again. reply Twey 6 hours agorootparentExcept that swap on OpenZFS still deadlocks 7 years later (https://github.com/openzfs/zfs/issues/7734) so you're still going to need LUKS for your swap anyway. reply ryao 5 hours agorootparentAnother option is to go without swap. I avoid swap on my machines unless I want hibernation support. reply jeroenhd 7 hours agorootparentprevThe data security and rot resilience only goes for systems with ECC memory. Correct data with a faulty checksum will be treated the same as incorrect data with a correct checksum. Windows has its own extended filesystem through Storage Spaces, with many ZFS features added as lesser used Storage Spaces options, especially when combined with ReFS. reply _factor 6 hours agorootparentThis has nothing to do with ZFS as a filesystem. It has integrity verification on duplicated raid configurations. If the system memory flips a bit, it will get written to disk like all filesystems. If a bit flips on a disk, however, it can be detected and repaired. Without ECC, your source of truth can corrupt, but this true of any system. reply abrookewood 7 hours agorootparentprevPlease stop repeating this, it is incorrect. ECC helps with any system, but it isn't necessary for ZFS checksums to work. reply BSDobelix 6 hours agorootparentprevOn zfs there is the ARC (adaptive read cache), on non-zfs systems this \"read cache\" is called buffer, both reside in memory, so ECC is equally important for both systems. Rot means changing bits without accessing those bits, and that's ~not possible with zfs, additionally you can enable check-summing IN the ARC (disabled by default), and with that you can say that ECC and \"enterprise\" quality hardware is even more important for non-ZFS systems. >Correct data with a faulty checksum will be treated the same as incorrect data with a correct checksum. There is no such thing as \"correct\" data, only a block with a correct checksum, if the checksum is not correct, the block is not ok. reply mrb 5 hours agorootparentprev\"data security and rot resilience only goes for systems with ECC memory.\" No. Bad HDDs/SSDs or bad SATA cables/ports cause a lot more data corruption than bad RAM. And ZFS will correct these cases even without ECC memory. It's a myth that the data healing properties of ZFS are useless without ECC memory. reply elseless 1 hour agorootparentPrecisely this. And don’t forget about bugs in virtualization layers/drivers — ZFS can very often save your data in those cases, too. reply ryao 10 minutes agorootparentI once managed to use ZFS to detect a bit flip on a machine that did not have ECC RAM. All python programs started crashing in libpython.so on my old desktop one day. I thought it was a bug in ZFS, so I started debugging. I compared the in-memory buffer from ARC with the on-disk buffer for libpython.so and found a bit flip. At the time, accessing a snapshot through .zfs would duplicate the buffer in ARC, which made it really easy to compare the in-memory buffer against the on-disk buffer. I was in shock as I did not expect to ever see one in person. Since then, I always insist on my computers having ECC. reply chillfox 4 hours agorootparentprevMuch faster launch of applications/files you use regularly. Ability to always rollback updates in seconds if they cause issues thanks to snapshots. Fast backups with snapshots + zfs send/receive to a remote machine. Compressed disks, this both let's you store more on a drive and makes accessing files faster. Easy encryption. ability to mirror 2 large usb disks so you never have your data corrupted or lose it from drive failures. Can move your data or entire os install to a new computer easily by using a live disk and just doing a send/receive to the new pc. (I have never used dedup, but it's there if you want I guess) reply e12e 7 hours agorootparentprevCross platform native encryption with sane fs for removable media. reply lazide 7 hours agorootparentWho would that help? MacOS also defaults to a non-portable FS for likely similar reasons, if one was being cynical. reply madeofpalk 8 hours agorootparentprevI'm missing file clones/copy-on-write. reply wkat4242 4 hours agorootparentprevSnapshots (Note: NTFS does have this in the way of Volume Shadow Copy but it's not as easily accessible as a feature to the end user as it is in ZFS). Copy on Write for reliability under crashes. Block checksumming for data protection (bitrot) reply nickdothutton 1 hour agoparentprevOS development pretty much stopped around 2000. ZFS is from 2001. I don't count a new way to organise my photos or integrate with a search engine as \"OS\" though. reply zamadatix 3 hours agoparentprevNTFS was able to be extended in various way over the years to the point what you could do with an NTFS drive 32 years ago will feel like talking about a completely different filesystem than what you can do with it on current Windows. Honestly I really like ReFS, particularly in context of storage spaces, but I don't think it's relevant to Microsoft's consumer desktop OS where users don't have 6 drives they need to pool together. Don't get me wrong, I use ZFS because that's what I can get running on a Linux server and I'm not going to go run Windows Server just for the storage pooling... but ReFS + Storage Spaces wins my heart with the 256 MB slab approach. This means you can add+remove mixed sized drives and get the maximum space utilization for the parity settings of the pool. Here ZFS is still getting to online adds of same or larger drives 10 years later. reply ryao 8 hours agoparentprevWhat do you mean by a ZFS compatibility layer? There is a Windows port: https://github.com/openzfsonwindows/openzfs Note that it is a beta. reply MauritsVB 7 hours agoparentprevThere is occasional talk of moving the Windows implementation of OpenZFS (https://github.com/openzfsonwindows/openzfs/releases) into an officially supported tier, though that will probably come after the MacOS version (https://github.com/openzfsonosx) is officially supported. reply badgersnake 8 hours agoparentprevNTFS is good enough for most people, who have a laptop with one SSD in it. reply wkat4242 4 hours agorootparentThe benefits of ZFS don't need multiple drives to be useful. I'm running ZFS on root for years now and snapshots have saved my bacon several times. Also with block checksums you can at least detect bitrot. And COW is always useful. reply zamadatix 3 hours agorootparentWindows manages volume snapshots on NTFS through VSS. I think ZFS snapshots are a bit \"cleaner\" of a design, and the tooling is a bit friendlier IMO, but the functionality to snapshot, rollback, and save your bacon is there regardless. Outside of the automatically enabled \"System Restore\" (which only uses VSS to snapshot specific system files during updates) I don't think anyone bothers to use it though. CoW, advanced parity, and checksumming are the big ones NTFS lacks. CoW is just inherently not how NTFS is designed and checksumming isn't there. Anything else (encryption, compression, snapshots, ACLs, large scale, virtual devices, basic parity) is done through NTFS on Windows. reply wkat4242 1 hour agorootparentYes I know that NTFS has snapshots, I mentioned that in another comment. I don't think NTFS is as relevant in comparison though. People who choose windows will have no interest in ZFS and vice versa (someone considering ZFS will not pick Windows). And I don't think anyone bothers to use it due to the lack of user-facing tooling around it. If it would be as easy to create snapshots as it is on ZFS, more people would use it, I'm sure. It's just so amazing to try something out, screw up my system and just revert :P But VSS is more of a system API than a user-facing geature. VSS is also used by backup software to quiet the filesystem by the way. But yeah the others are great features. My main point was though that almost all the features of ZFS are very beneficial even on a single drive. You don't need an array to take advantage of Snapshots, the crash reliability that CoW offers, and checksumming (though you will lack the repair option obviously) reply EvanAnderson 54 minutes agorootparent> I don't think NTFS is as relevant in comparison though. People who choose windows will have no interest in ZFS and vice versa (someone considering ZFS will not pick Windows). ZFS on Windows, as a first-class supported-by-Microsoft option would be killer. It won't ever happen, but it would be great. (NTFS / VSS with filesystem/snapshot send/receive would \"scratch\" a lot of that \"itch\", too.) > And I don't think anyone bothers to use it due to the lack of user-facing tooling around it. If it would be as easy to create snapshots as it is on ZFS, more people would use it, I'm sure. It's just so amazing to try something out, screw up my system and just revert :P But VSS is more of a system API than a user-facing geature. VSS on NTFS is handy and useful but in my experience brittle compared to ZFS snapshots. Sometimes VSS just doesn't work. I've had repeated cases over the years where accessing a snapshot failed (with traditional unhelpful Microsoft error messages) until the host machine was rebooted. Losing VSS snapshots on a volume is much easier than trashing a ZFS volume. VSS straddles the filesystem and application layers in a way that ZFS doesn't. I think that contributes to some of the jank (VSS writers becoming \"unstable\", for example). It also straddles hardware interfaces in a novel way that ZFS doesn't (using hardware snapshot functionality-- somewhat like using a GPU versus \"software rendering\"). I think that also opens up a lot of opportunity for jank, as compared to ZFS treating storage as dumb blocks. reply uniqueuid 11 hours agoprevIt's good to see that they were pretty conservative about the expansion. Not only is expansion completely transparent and resumable, it also maintains redundancy throughout the process. That said, there is one tiny caveat people should be aware of: > After the expansion completes, old blocks remain with their old data-to-parity ratio (e.g. 5-wide RAIDZ2, has 3 data to 2 parity), but distributed among the larger set of disks. New blocks will be written with the new data-to-parity ratio (e.g. a 5-wide RAIDZ2 which has been expanded once to 6-wide, has 4 data to 2 parity). reply chungy 9 hours agoparentI'm not sure that's really a caveat, it just means old data might be in an inoptimal layout. Even with that, you still get the full benefits of raidzN, where up to N disks can completely fail and the pool will remain functional. reply crote 5 hours agorootparentI think it's a huge caveat, because it makes upgrades a lot less efficient than you'd expect. For example, home users generally don't want to buy all of their storage up front. They want to add additional disks as the array fills up. Being able to start with a 2-disk raidz1 and later upgrade that to a 3-disk and eventually 4-disk array is amazing. It's a lot less amazing if you end up with a 55% storage efficiency rather than 66% you'd ideally get from a 2-disk to 3-disk upgrade. That's 11% of your total disk capacity wasted, without any benefit whatsoever. reply ryao 4 hours agorootparentYou have a couple options: 1. Delete the snapshots and rewrite the files in place like how people do when they want to rebalance a pool. 2. Use send/receive inside the pool. Either one will make the data use the new layout. They both carry the caveat that reflinks will not survive the operation, such that if you used reflinks to deduplicate storage, you will find the deduplication effect is gone afterward. reply bmicraft 4 hours agorootparentprevWell, when you start a raidz with 2 devices you've already done goofed. Start with a mirror or at least 3 devices. Also, if you don't wait to upgrade until the disks are at 100% utilization (which you should never do! you're creating massive fragmentation upwards of ~85%) efficiency in the real world will be better. reply chungy 4 hours agorootparentprevIt still seems pretty minor. If you want extreme optimization, feel free to destroy the pool and create it new, or create it with the ideal layout from the beginning. Old data still works fine, the same guarantees RAID-Z provides still hold. New data will be written with the new data layout. reply stavros 8 hours agorootparentprevIs that the case? What if I expand a 3-1 array to 3-2? Won't the old blocks remain 3-1? reply Timshel 8 hours agorootparentI don't believe it supports adding parity drives only data drives. reply stavros 8 hours agorootparentAhh interesting, thanks. reply bmicraft 4 hours agorootparentSince preexisting blocks are kept at their current parity ratio and not modified (only redistributed among all devices), increasing the parity level of new blocks won't really be useful in practice anyway. reply wjdp 4 hours agoparentprevCaveat is very much expected, you should expect ZFS features to not rewrite blocks. Changes to settings only apply to new data for example. reply rekoil 5 hours agoparentprevYaeh it's a pretty huge caveat to be honest. Da1 Db1 Dc1 Pa1 Pb1 Da2 Db2 Dc2 Pa2 Pb2 Da3 Db3 Dc3 Pa3 Pb3 ___ ___ ___ Pa4 Pb4 ___ represents free space. After expansion by one disk you would logically expect something like: Da1 Db1 Dc1 Da2 Pa1 Pb1 Db2 Dc2 Da3 Db3 Pa2 Pb2 Dc3 ___ ___ ___ Pa3 Pb3 ___ ___ ___ ___ Pa4 Pb4 But as I understand it it would actually expand to: Da1 Db1 Dc1 Dd1 Pa1 Pb1 Da2 Db2 Dc2 Dd2 Pa2 Pb2 Da3 Db3 Dc3 Dd3 Pa3 Pb3 ___ ___ ___ ___ Pa4 Pb4 Where the Dd1-3 blocks are just wasted. Meaning by adding a new disk to the array you're only expanding free storage by 25%... So say you have 8TB disks for a total of 24TB of storage free originally, and you have 4TB free before expansion, you would have 5TB free after expansion. Please tell me I've misunderstood this, because to me it is a pretty useless implementation if I haven't. reply ryao 4 hours agorootparentZFS RAID-Z does not have parity disks. The parity and data is interleaved to allow data reads to be done from all disks rather than just the data disks. The slides here explain how it works: https://openzfs.org/w/images/5/5e/RAIDZ_Expansion_2023.pdf Anyway, you are not entirely wrong. The old data will have the old parity:data ratio while new data will have the new parity:data ratio. As old data is freed from the vdev, new writes will use the new parity:data ratio. You can speed this up by doing send/receive, or by deleting all snapshots and then rewriting the files in place. This has the caveat that reflinks will not survive the operation, such that if you used reflinks to deduplicate storage, you will find the deduplication effect is gone afterward. reply chungy 1 hour agorootparentTo be fair, RAID5/6 don't have parity disks either. RAID2, RAID3, and RAID4 do, but they're all effectively dead technology for good reason. I think it's easy for a lot of people to conceptualize RAID5/6 and RAID-Zn as having \"data disks\" and \"parity disks\" to wrap around the complicated topic of how it works, but all of them truly interleave and compute parity data across all disks, allowing any single disk to die. I've been of two minds on the persistent myth of \"parity disks\" but I usually ignore it, because it's a convenient lie to understand your data is safe, at least. It's also a little bit the same way that raidz1 and raidz2 are sometimes talked about as \"RAID5\" and \"RAID6\"; the effective benefits are the same, but the implementation is totally different. reply magicalhippo 3 hours agorootparentprevUnless I misunderstood you, you're describing more how classical RAID would work. The RAID-Z expansion works like you note you would logically expect. You added a drive with four blocks of free space, and you end up with four blocks more of free space afterwards. You can see this in the presentation[1] slides[2]. The reason this is sub-optimal post-expansion is because, in your example, the old maximal stripe width is lower than the post-expansion maximal stripe width. Your example is a bit unfortunate in terms of allocated blocks vs layout, but if we tweak it slightly, then Da1 Db1 Dc1 Pa1 Pb1 Da2 Db2 Dc2 Pa2 Pb2 Da3 Db3 Pa3 Pb3 ___ would after RAID-Z expansion would become Da1 Db1 Dc1 Pa1 Pb1 Da2 Db2 Dc2 Pa2 Pb2 Da3 Db3 Pa3 Pb3 ___ ___ ___ ___ Ie you added a disk with 3 new blocks, and so total free space after is 1+3 = 4 blocks. However if the same data was written in the post-expanded vdev configuration, it would have become Da1 Db1 Dc1 Dd1 Pa1 Pb1 Da2 Db2 Dc2 Dd2 Pa2 Pb2 ___ ___ ___ ___ ___ ___ Ie, you'd have 6 free blocks not just 4 blocks. Of course this doesn't count for writes which end up taking less than the maximal stripe width. [1]: https://www.youtube.com/watch?v=tqyNHyq0LYM [2]: https://openzfs.org/w/images/5/5e/RAIDZ_Expansion_2023.pdf reply ryao 3 hours agorootparentYour diagrams have some flaws too. ZFS has a variable stripe size. Let’s say you have a 10 disk raid-z2 vdev that is ashift=12 for 4K columns. If you have a 4K file, 1 data block and 2 parity blocks will be written. Even if you expand the raid-z vdev, there is no savings to be had from the new data:parity ratio. Now, let’s assume that you have a 72K file. Here, you have 18 data blocks and 6 parity blocks. You would benefit from rewriting this to use the new data:parity ratio. In this case, you would only need 4 parity blocks. ZFS does not rewrite it as part of the expansion, however. There are already good diagrams in your links, so I will refrain from drawing my own with ASCII. Also, ZFS will vary which columns get parity, which is why the slides you linked have the parity at pseudo-random locations. It was not a quirk of the slide’s author. The data is really laid out that way. reply magicalhippo 3 hours agorootparentWhat are the errors? I tried to show exactly what you talk about. edit: ok, I didn't consider the exact locations of the parity, I was only concerned with space usage. The 8 data blocks need three stripes on a 3+2 RAID-Z2 setup both pre and post expansion, the last being a partial stripe, but when written in the 4+2 setup only needs 2 full stripes, leading to more total free space. reply cgeier 11 hours agoprevThis is huge news for ZFS users (probably mostly those in the hobbyist/home use space, but still). raidz expansion has been one of the most requested features for years. reply jfreax 10 hours agoparentI'm not yet familiar with zfs and couldn't find it in the release note: Does expansion only works with disk of the same size? Or is adding are bigger/smaller disks possible or do all disk need to have the same size? reply ryao 8 hours agorootparentYou can use different sized disks, but RAID-Z will truncate the space it uses to the lowest common denominator. If you increase the lowest common denominator, RAID-Z should auto-expand to use the additional space. All parity RAID technologies truncate members to the lowest common denominator, rather than just ZFS. reply chasil 10 hours agorootparentprevIIRC, you could always replace drives in a raidset with larger devices. When the last drive is replaced, then the new space is recognized. This new operation seems somewhat more sophisticated. reply shiroiushi 10 hours agorootparentprevAs far as I understand, ZFS doesn't work at all with disks of differing sizes (in the same array). So if you try it, it just finds the size of the smallest disk, and uses that for all disks. So if you put an 8TB drive in an array with a bunch of 10TB drives, they'll all be treated as 8TB drives, and the extra 2TB will be ignored on those disks. However, if you replace the smallest disk with a new, larger drive, and resilver, then it'll now use the new smallest disk as the baseline, and use that extra space on the other drives. (Someone please correct me if I'm wrong.) reply mustache_kimono 10 hours agorootparent> As far as I understand, ZFS doesn't work at all with disks of differing sizes (in the same array). This might be misleading, however, it may only be my understanding of word \"array\". You can use 2x10TB mirrors as vdev0, and 6x12TB in RAIDZ2 as vdev1 in the same pool/array. You can also stack as many unevenly sized disks as you want in a pool. The actual problem is when you want a different drive topology within a pool or vdev, or you want to mismatch, say, 3 oddly sized drives to create some synthetic redundancy level (2x4TB and 1x8TB to achieve two copies on two disks) like btrfs does/tries to do. reply tw04 9 hours agorootparentprevThis is the case with any parity based raid, they just hide it or lie to you in various ways. If you have two 6TB dives and two 12TB drives in a single raid-6 array, it is physically impossible to have two drive parity once you exceed 12TB of written capacity. BTRFS and bcachefs can’t magically create more space where none exists on your 6TB drives. They resort to dropping to mirror protection for the excess capacity which you could also do manually with ZFS by giving it partitions instead of the whole drive. reply zelcon 10 hours agorootparentprevYou need to buy the same exact drive with the same capacity and speed. Your raidz vdev be as small and as slow as your smallest and slowest drive. btrfs and the new bcachefs can do RAID with mixed drives, but I can’t trust either of them with my data yet. reply hda111 9 hours agorootparentIt doesn't have to be the same exact drive. Mixing drives from different manufacturers (with the same capacity) is often used to prevent correlated failure. ZFS is not using the whole disk, so different disks can be mixed, because the disk often have varying capacity. reply tw04 9 hours agorootparentprevYou can run raid-z across partitions to utilize the full drive just like synology does with their “hybrid raid” - you just shouldn’t. reply Mashimo 10 hours agorootparentprev> You need to buy the same exact drive AFAIK you can add larger and faster drives, you will just not get any benefits from it. reply bpye 10 hours agorootparentYou can get read speed benefits with faster drives, but your writes will be limited by your slowest. reply unixhero 9 hours agorootparentprevJust have backups. I used btrfs and zfs for different purposes. Never had any lost data or downtime with btrfs since 2016. I only use raid 0 and raid 1 and compression. Btrfs does not havr a hungry ram requirement. reply tw04 9 hours agorootparentNeither does zfs, that’s a widely repeated red herring from people trying to do dedup in the very early days, and people who misunderstood how it used ram to do caching. reply FrostKiwi 10 hours agoprevFINALLY! You can do borderline insane single-vdev setups like RAID-Z3 with 4 disks (3 Disks worth of redundancy) of the most expensive and highest density hard drives money can buy right now, for an initial effective space usage of 25% and then keep buying and expanding Disk by Disk, with the space demand growing, up to something like 12ish disks. Disk prices dropping as time goes on and a spread out failure chance with disks being added at different times. reply uniqueuid 9 hours agoparentYes but see my sibling comment. When you expand your array, your existing data will not be stored any more efficiently. To get the new parity/data ratios, you would have to force copies of the data and delete the old, inefficient versions, e.g. with something like this [1] My personal take is that it's a much better idea to buy individual complete raid-z configurations and add new ones / replace old ones (disk by disk!) as you go. [1] https://github.com/markusressel/zfs-inplace-rebalancing reply Mashimo 9 hours agorootparentI wish something like this would be build into ZFS, so snapshots and current access would not be broken. reply uniqueuid 9 hours agorootparentTrue, but I have a gut feeling that a lot of these thorny issues would come up again: https://github.com/openzfs/zfs/issues/3582 reply jakedata 7 hours agoprevHappy to see the ARC bypass for NVMe performance. ZFS really fails to exploit NVMe's potential. Online expansion might be interesting. I tried to use ZFS for some very busy databases and ended up getting bitten badly by the fragmentation bug. The only way to restore performance appears to be copying the data off the volume, nuking it and then copying it back. Now -perhaps- if I expand the zpool then I might be able to reduce fragmentation by copying the tablespace on the same volume. reply wkat4242 4 hours agoprevNote: This is online expansion. Expansion was always possible but you did need to take the array down to do it. You could also move to bigger drives but you also had to do that one at a time (and only gain the new capacity once all drives were upgraded of course) As far as I know shrinking a pool is still not possible though. So if you have a pool with 5 drives and add a 6th, you can't go back to 5 drives even if there is very little data in it. reply shepherdjerred 2 hours agoprevHow does ZFS compare to btrfs? I'm currently using btrfs for my home server, but I've had some strange troubles with it. I'm thinking about switching to ZFS, but I don't want to end up in the same situation. reply ryao 2 hours agoparentI first tried btrfs 15 years ago with Linux 2.6.33-rc4 if I recall. It developed an unlinkable file within 3 days, so I stopped using it. Later, I found ZFS. It had a few less significant problems, but I was a CS student at the time and I thought I could fix them since they seemed minor in comparison to the issue I had with btrfs, so over the next 18 months, I solved all of the problems that it had that bothered me and sent the patches to be included in the then ZFSOnLinux repository. My effort helped make it production ready on Linux. I have used ZFS ever since and it has worked well for me. If btrfs had been in better shape, I would have been a btrfs contributor. Unfortunately for btrfs, it not only was in bad shape back then, but other btrfs issues continued to bite me every time I tried it over the years for anything serious (e.g. frequent ENOSPC errors when there is still space). ZFS on the other hand just works. Myself and many others did a great deal of work to ensure it works well. The main reason for the difference is that ZFS had a very solid foundation, which was achieved by having some fantastic regression testing facilities. It has a userland version that randomly exercises the code to find bugs before they occur in production and a test suite that is run on every proposed change to help shake out bugs. ZFS also has more people reviewing proposed changes than other filesystems. The Btrfs developers will often state that there is a significant man power difference between the two file systems. I vaguely recall them claiming the difference was a factor of 6. Anyway, few people who use ZFS regret it, so I think you will find you like it too. reply averageRoyalty 9 hours agoprevWorth noting that TrueNAS already supports this[0] (I assuming using 2.3.0rc3?). Not sure about the stability, but very exciting. https://www.truenas.com/blog/electric-eel-openzfs-23/ reply endorphine 10 hours agoprevCan someone describe why they would use ZFS (or similar) for home usage? reply mrighele 8 hours agoparentGood reasons for me: Checksums: this is even more important in home usage as the hardware is usually of lower quality. Faulty controllers, crappy cables, hard disks stored in a higher than advised temperature... many reasons for bogus data to be saved, and zfs handles that well and automatically (if you have redundancy) Snapshots: very useful to make backups and quickly go back to an older version of a file when mistakes are made Ease of mind: compared to the alternatives, I find that zfs is easier to use and makes it harder to make a mistake that could bring data loss (e.g. remove by mistake the wrong drive when replacing a faulty one, pool becomes unusable, \"ops!\", put the disk back, pool goes back to work as nothing happened). Maybe it is different now with mdadm, ma when I used it years ago I was always worried to make a destructive mistake. reply EvanAnderson 51 minutes agorootparent> Snapshots: very useful to make backups and quickly go back to an older version of a file when mistakes are made Piling on here: Sending snapshots to remote machines (or removable drives) is very easy. That makes snapshots viable as a backup mechanism (because they can exist off-site and offline). reply ryao 8 hours agoparentprevTo give an answer that nobody else has given, ZFS is great for storing Steam games. Set recordsize=1M and compression=zstd and you can often store about 33% more games in the same space. A friend uses ZFS to store his Steam games on a couple of hard drives. He gave ZFS a SSD to use as L2ARC. ZFS automatically caches the games he likes to run on the SSD so that they load quickly. If he changes which games he likes to run, ZFS will automatically adapt to cache those on the SSD instead. reply chillfox 4 hours agorootparentThe compression and ARC will make games load much master than they would on NTFS even without having a separate drive for the ARC. reply chromakode 9 hours agoparentprevI replicate my entire filesystem to a local NAS every 10 minutes using zrepl. This has already saved my bacon once when a WD_BLACK SN850 suddenly died on me [1]. It's also recovered code from some classic git blunders. It shouldn't be possible any more to lose data to user error or single device failure. We have the technology. [1]: https://chromakode.com/post/zfs-recovery-with-zrepl/ reply vedranm 10 hours agoparentprevSeveral reasons, but major ones (for me) are reliability (checksums and self-healing) and portability (no other modern filesystem can be read and written on Linux, FreeBSD, Windows, and macOS). Snapshots (\"boot environments\") are also supported by Btrfs (my Linux installations use that so I don't have to worry about having the 3rd party kernel module to read my rootfs). Performance isn't that great either and, assuming Linux, XFS is a better choice if that is your main concern. reply Mashimo 9 hours agoparentprevIt's relatively easy, and yet powerful. Before that I had MDADM + LVM + dm-crypt + ext4, which also worked but all the layers got me into a headache. Automated snapshots are super easy and fast. Also easy to access if you deleted a file, you don't have to restore the whole snapshot, you can just cp from the hidden .zfs/ folder. I run it on 6x 8TB disk for a couple of years now. I run it in a raidz2, which means up to 2 disk can die. Would I use it on a single disk on a Desktop? Probably not. reply redundantly 9 hours agorootparent> Would I use it on a single disk on a Desktop? Probably not. I do. Snapshots and replication and checksumming are awesome. reply klauserc 4 hours agoparentprevI use it on my work laptop. Reasons: - a single solution that covers the entire storage domain (I don't have to learn multiple layers, like logical volume manager vs. ext4 vs. physical partitions) - cheap/free snapshots. I have been glad to have been able to revert individual files or entire file systems to an earlier state. E.g., create a snapshot before doing a major distro update. - easy to configure/well documented Like others have said, at this point I would need a good reason, NOT to use ZFS on a system. reply lutorm 10 hours agoparentprevApart from just peace of mind from bitrot, I use it for the snapshotting capability which makes it super easy to do backups. You can snapshot and send the snapshots to other storage with e.g zfs-autobackup and it's trivial and you can't screw it up. If the snapshots exist on the other drive, you know you have a backup. reply PaulKeeble 6 hours agoparentprevI have a home built NAS that uses ZFS for the storage array and the checksumming has been really quite useful in detecting and correcting bit rot. In the past I used MDADM and EXT over the top and that worked but it didn't defend against bit rot. I have considered BTRFS since it would get me the same checksumming without the rest of ZFS but its not considered reliable for systems with parity yet (although now I think it likely is more than reliable enough now). I do occasionally use snapshots and the compression feature is handy on quite a lot of my data set but I don't use the user and group limitations or remote send and receive etc. ZFS does a lot more than I need but it also works really well and I wouldn't move away from a checksumming filesystem now. reply mshroyer 5 hours agoparentprevI use it on a NAS for: - Confidence in my long-term storage of some data I care about, as zpool scrub protects against bit rot - Cheap snapshots that provide both easy checkpoints for work saved to my network share, and resilience against ransomware attacks against my other computers' backups to my NAS - Easy and efficient (zfs send) replication to external hard drives for storage pool backup - Built-in and ergonomic encryption And it's really pretty easy to use. I started with FreeNAS (now TrueNAS), but eventually switched to just running FreeBSD + ZFS + Samba on my file server because it's not that complicated. reply tbrownaw 5 hours agoparentprev> describe why they would use ZFS (or similar) for home usage Mostly because it's there, but also the snapshots have a `diff` feature that's occasionally useful. reply NamTaf 7 hours agoparentprevI used it on my home NAS (4x3TB drives, holding all of my family's backups, etc.) for the data security / checksumming features. IMO it's performant, robust and well-designed in ways that give me reassurance regarding data integrity and help prevent me shooting myself in the foot. reply nesarkvechnep 9 hours agoparentprevI'm trying to find a reason not to use ZFS at home. reply dizhn 8 hours agorootparentRequirement for enterprise quality disks, huge RAM (1 gig per TB), ECC, at least x5 disks of redundancy. None of these are things, but people will try to educate you anyway. So use it but keep it to yourself. :) reply craftkiller 6 hours agorootparentNo need to keep it to yourself. As you've mentioned, all of these requirements are misinformation so you can ignore people who repeat them (or even better, tell them to stop spreading misinformation). For those not in the know: You don't need to use enterprise quality disks. There is nothing in the ZFS design that requires enterprise quality disks any more than any other file system. In fact, ZFS has saved my data through multiple consumer-grade HDD failures over the years thanks to raidz. The 1 gig per TB figure is ONLY for when using the ZFS dedup feature, which the ZFS dedup feature is widely regarded as a bad idea except in VERY specific use cases. 99.9% of ZFS users should not and will not use dedup and therefore they do not need ridiculous piles of ram. There is nothing in the design of ZFS any more dangerous to run without ECC than any other filesystem. ECC is a good idea regardless of filesystem but its certainly not a requirement. And you don't need x5 disks of redundancy. It runs great and has benefits even on single-disk systems like laptops. Naturally, having parity drives is better in case a drive fails but on single disk systems you still benefit from the checksumming, snapshotting, boot environments, transparent compression, incremental zfs send/recv, and cross-platform native encryption. reply bbatha 1 hour agorootparent> The 1 gig per TB figure is ONLY for when using the ZFS dedup feature, which the ZFS dedup feature is widely regarded as a bad idea except in VERY specific use cases. 99.9% of ZFS users should not and will not use dedup and therefore they do not need ridiculous piles of ram. You also really don't need a 1GB for RAM unless you have a very high write volume. YMMV but my experience is that its closer to 1GB for 10TB. reply tpetry 3 hours agorootparentprevThe interesting part about the enterprise quality disk misinformation is how so wrong it is. The core idea of ZFS was to detect issues when those drives or their drivers are faulty. And this was more happening with cheap non-enterprise disks at that time. reply zbentley 5 hours agoparentprevI use ZFS for boot and storage volumes on my main workstation, which is primarily that--a workstation, not a server or NAS. Some benefits: - Excellent filesystem level backup facility. I can transfer snapshots to a spare drive, or send/receive to a remote (at present a spare computer, but rsync.net looks better every year I have to fix up the spare). - Unlike other fs-level backup solutions, the flexibility of zvols means I can easily expand or shrink the scope of what's backed up. - It's incredibly easy to test (and restore) backups. Pointing my to-be-backed-up volume, or my backup volume, to a previous backup snapshot is instant, and provides a complete view of the filesystem at that point in time. No \"which files do you want to restore\" hassles or any of that, and then I can re-point back to latest and keep stacking backups. Only Time Machine has even approached that level of simplicity in my experience, and I have tried a lot of backup tools. In general, backup tools/workflows that uphold \"the test process is the restoration process, so we made the restoration process as easy and reversible as possible\" are the best ones. - Dedup occasionally comes in useful (if e.g. I'm messing around with copies of really large AI training datasets or many terabytes of media file organization work). It's RAM-expensive, yes, but what's often not mentioned is that you can turn it on and off for a volume--if you rewrite data. So if I'm looking ahead to a week of high-volume file wrangling, I can turn dedup on where I need it, start a snapshot-and-immediately-restore of my data (or if it's not that many files, just cp them back and forth), and by the next day or so it'll be ready. Turning it off when I'm done is even simpler. I imagine that the copy cost and unpredictable memory usage mean that this kind of \"toggled\" approach to dedup isn't that useful for folks driving servers with ZFS, but it's outstanding on a workstation. - Using ZFSBootMenu outside of my OS means I can be extremely cavalier with my boot volume. Not sure if an experimental kernel upgrade is going to wreck my graphics driver? Take a snapshot and try it! Not sure if a curlbash invocation from the internet is going to rm -rf /? Take a snapshot and try it! If my boot volume gets ruined, I can roll it back to a snapshot in the bootloader from outside of the OS. For extra paranoia I have a ZFSBootMenu EFI partition on a USB drive if I ever wreck the bootloader as well, but the odds are that if I ever break the system that bad the boot volume is damaged at the block level and can't restore local snapshots. In that case, I'd plug in the USB drive and restore a snapshot from the adjacent data volume, or my backup volume ... all without installing an OS or leaving the bootloader. The benefits of this to mental health are huge; I can tend towards a more \"college me\" approach to trying random shit from StackOverflow for tweaking my system without having to worry about \"adult professional me\" being concerned that I don't know what running some random garbage will do to my system. Being able to experiment first, and then learn what's really going on once I find what works, is very relieving and makes tinkering a much less fraught endeavor. - Being able to per-dataset enable/disable ARC and ZIL means that I can selectively make some actions really fast. My Steam games, for example, are in a high-ARC-bias dataset that starts prewarming (with throttled IO) in the background on boot. Game load times are extremely fast--sometimes at better than single-ext4-SSD levels--and I'm storing all my game installs on spinning rust for $35 (4x 500GB + 2x 32GB cheap SSD for cache)! reply zelcon 10 hours agoprevBeen running it since rc2. It’s insane how long this took to finally ship. reply abrookewood 7 hours agoprevCan someone provide details on this bit please? \"Direct IO: Allows bypassing the ARC for reads/writes, improving performance in scenarios like NVMe devices where caching may hinder efficiency\". ARC is based in RAM, so how could it reduce performance when used with NVMe devices? They are fast, but they aren't RAM-fast ... reply nolist_policy 7 hours agoparentBecause with a (ARC) cache you have to copy from the app to the cache and then dma to disk. With direct io you can dma directly from the app ram to the disk. reply philjohn 7 hours agoparentprevYes - interested in this too. Is this for both ARC and L2ARC, or just L2ARC? reply happosai 8 hours agoprevThe annual reminder that if Oracle wanted to contribute positively to the Linux ecosystem, they would update the CDDL license ZFS uses to GPL compatible. reply ryao 8 hours agoparentThis is the annual reply that Oracle cannot change the OpenZFS license because OpenZFS contributors removed the “or any later version” part of the license from their contributions. By the way, comments such as yours seem to assume that Oracle is somehow involved with OpenZFS. Oracle has no connection with OpenZFS outside of owning copyright on the original OpenSolaris sources and a few tiny commits their employees contributed before Oracle purchased Sun. Oracle has its own internal ZFS fork and they have zero interest in bringing it to Linux. They want people to either go on their cloud or buy this: https://www.oracle.com/storage/nas/ reply jeroenhd 7 hours agorootparentIs there a reason the OpenZFS contributors don't want to dual-license their code? I'm not too familiar with the CDDL but I'm not sure what advantage it brings to an open source project compared to something like GPL? Having to deal with DKMS is one of the reasons why I'm sticking with BTRFS for doing ZFS-like stuff. reply ryao 7 hours agorootparentThe OpenZFS code is based on the original OpenSolaris code, and the license used is the CDDL because that is what OpenSolaris used. Dual licensing that requires the current OpenSolaris copyright holder to agree. That is unlikely without writing a very big check. Further speculation is not a productive thing to do, but since I know a number of people assume that OpenSolaris copyright holder is the only one preventing this, let me preemptively say that it is not so simple. Different groups have different preferred licenses. Some groups cannot stand certain licenses. Other groups might detest the idea of dual licensing in general since it causes community fragmentation whenever contributors decide to publish changes only under 1 of the 2 licenses. The CDDL was designed to ensure that if Sun Microsystems were acquired by a company hostile to OSS, people could still use Sun’s open source software. In particular, the CDDL has an explicit software patent grant. Some consider that to have been invaluable in preempting lawsuits from a certain company that would rather have ZFS be closed source software. reply MauritsVB 7 hours agoparentprevOracle changing the license would not make a huge difference to OpenZFS. Oracle only owns the copyright to the original Sun Microsystems code. It doesn’t apply to all ZFS implementations (probably not OracleZFS, perhaps not IllumosZFS) but in the specific case of OpenZFS the majority of the code is no longer Sun code. Don’t forget that SunZFS was open sourced in 2005 before Oracle bought Sun Microsystems in 2009. Oracle have created their own closed source version of ZFS but outside some Oracle shops nobody uses it (some people say Oracle has stopped working on OracleZFS all together some time ago). Considering the forks (first from Sun to the various open source implementations and later the fork from open source into Oracle's closed source version) were such a long time ago, there is not that much original code left. A lot of storage tech, or even entire storage concepts, did not exist when Sun open sourced ZFS. Various ZFS implementations developed their own support for TRIM, or Sequential Resilvering, or Zstd compression, or Persistent L2ARC, or Native ZFS Encryption, or Fusion Pools, or Allocation Classes, or dRAID, or RAIDZ expansion long after 2005. That's is why the majority of the code in OpenZFS 2 is from long after the fork from Sun code twenty years ago. Modern OpenZFS contains new code contributions from Nexenta Systems, Delphix, Intel, iXsystems, Datto, Klara Systems and a whole bunch of other companies that have voluntarily offered their code when most of the non-Oracle ZFS implementations merged to become OpenZFS 2.0. If you'd want to relicense OpenZFS you could get Oracle to agree for the bit under Sun copyright but for the majority of the code you'd have to get a dozen or so companies to agree to relicensing their contributions (probably not that hard) and many hundreds of individual contributors over two decades (a big task and probably not worth it). reply abrookewood 7 hours agoparentprevThe only thing Oracle wants to \"contribute positively to\" is Larry's next yacht. reply senectus1 10 hours agoprevWould love to use ZFS, but unfortunately Fedora just cant keep up with it... reply kawsper 9 hours agoparentNot sure if it helps you at all, but I have a simple Ruby script that I use to build kernels on Fedora with a specified ZFS version. https://github.com/kaspergrubbe/fedora-kernel-compilation/bl... It builds on top of the exploded fedora kernel tree, adds zfs and spits out a .rpm that you can install with rpm -ivh. It doesn't play well with dkms because it tries to interfere, so I disable it on my system. reply _factor 6 hours agorootparentI could never getting working on rpm-ostree distros. reply klauserc 4 hours agoparentprevI've been running Fedora on top of the excellent ZFSBootMenu[1] for about a year. You need to pay attention to the kernel versions supported by OpenZFS and might have to wait for support for a couple of weeks. The setup works fine otherwise. [1] https://docs.zfsbootmenu.org reply vedranm 10 hours agoparentprevIf you delay upgrading the kernel on occasions, it is more or less fine. reply bitmagier 5 hours agoprev [–] Marvelous! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenZFS 2.3.0 has been released, introducing significant features such as RAIDZ Expansion, Fast Deduplication, Direct Input/Output, JSON output, and support for long file names. - The release includes essential bug fixes and performance enhancements, compatible with Linux kernels 4.18 - 6.12 and FreeBSD versions 13.3, 14.0 - 14.2. - The update is a collaborative effort from 134 contributors, with comprehensive documentation and a change log available for review."
    ],
    "commentSummary": [
      "ZFS 2.3 has been released, introducing features like RAIDZ expansion, fast deduplication, direct IO, JSON output, and support for long file names. - RAIDZ expansion is particularly notable as it allows users to add new devices to an existing RAIDZ pool without downtime, enhancing storage capacity. - The release is considered a significant advancement for ZFS users, drawing comparisons with other filesystems like Btrfs and Windows Storage Spaces, despite some limitations like the inability to shrink pools."
    ],
    "points": 302,
    "commentCount": 215,
    "retryCount": 0,
    "time": 1736838539
  },
  {
    "id": 42690983,
    "title": "Webtop – Alpine,Ubuntu,Fedora,and Arch containers containing full desktop envs",
    "originLink": "https://docs.linuxserver.io/images/docker-webtop/",
    "originBody": "linuxserver/webtop¶ Webtop - Alpine, Ubuntu, Fedora, and Arch based containers containing full desktop environments in officially supported flavors accessible via any modern web browser. Supported Architectures¶ We utilise the docker manifest for multi-platform awareness. More information is available from docker here and our announcement here. Simply pulling lscr.io/linuxserver/webtop:latest should retrieve the correct image for your arch, but you can also pull specific arch images via tags. The architectures supported by this image are: Architecture Available Tag x86-64 ✅ amd64- arm64 ✅ arm64v8- armhf ❌Version Tags¶ This image provides various versions that are available via tags. Please read the descriptions carefully and exercise caution when using unstable or development tags. Tag Available Description latest ✅ XFCE Alpine ubuntu-xfce ✅ XFCE Ubuntu fedora-xfce ✅ XFCE Fedora arch-xfce ✅ XFCE Arch debian-xfce ✅ XFCE Debian alpine-kde ✅ KDE Alpine ubuntu-kde ✅ KDE Ubuntu fedora-kde ✅ KDE Fedora arch-kde ✅ KDE Arch debian-kde ✅ KDE Debian alpine-mate ✅ MATE Alpine ubuntu-mate ✅ MATE Ubuntu fedora-mate ✅ MATE Fedora arch-mate ✅ MATE Arch debian-mate ✅ MATE Debian alpine-i3 ✅ i3 Alpine ubuntu-i3 ✅ i3 Ubuntu fedora-i3 ✅ i3 Fedora arch-i3 ✅ i3 Arch debian-i3 ✅ i3 Debian alpine-openbox ✅ Openbox Alpine ubuntu-openbox ✅ Openbox Ubuntu fedora-openbox ✅ Openbox Fedora arch-openbox ✅ Openbox Arch debian-openbox ✅ Openbox Debian alpine-icewm ✅ IceWM Alpine ubuntu-icewm ✅ IceWM Ubuntu fedora-icewm ✅ IceWM Fedora arch-icewm ✅ IceWM Arch debian-icewm ✅ IceWM Debian Application Setup¶ The Webtop can be accessed at: http://yourhost:3000/ https://yourhost:3001/ Modern GUI desktop apps have issues with the latest Docker and syscall compatibility, you can use Docker with the --security-opt seccomp=unconfined setting to allow these syscalls on hosts with older Kernels or libseccomp Security¶ Warning Do not put this on the Internet if you do not know what you are doing. By default this container has no authentication and the optional environment variables CUSTOM_USER and PASSWORD to enable basic http auth via the embedded NGINX server should only be used to locally secure the container from unwanted access on a local network. If exposing this to the Internet we recommend putting it behind a reverse proxy, such as SWAG, and ensuring a secure authentication solution is in place. From the web interface a terminal can be launched and it is configured for passwordless sudo, so anyone with access to it can install and run whatever they want along with probing your local network. Options in all KasmVNC based GUI containers¶ This container is based on Docker Baseimage KasmVNC which means there are additional environment variables and run configurations to enable or disable specific functionality. Optional environment variables¶ Variable Description CUSTOM_PORT Internal port the container listens on for http if it needs to be swapped from the default 3000. CUSTOM_HTTPS_PORT Internal port the container listens on for https if it needs to be swapped from the default 3001. CUSTOM_USER HTTP Basic auth username, abc is default. PASSWORD HTTP Basic auth password, abc is default. If unset there will be no auth SUBFOLDER Subfolder for the application if running a subfolder reverse proxy, need both slashes IE /subfolder/ TITLE The page title displayed on the web browser, default \"KasmVNC Client\". FM_HOME This is the home directory (landing) for the file manager, default \"/config\". START_DOCKER If set to false a container with privilege will not automatically start the DinD Docker setup. DRINODE If mounting in /dev/dri for DRI3 GPU Acceleration allows you to specify the device to use IE /dev/dri/renderD128 DISABLE_IPV6 If set to true or any value this will disable IPv6 LC_ALL Set the Language for the container to run as IE fr_FR.UTF-8 ar_AE.UTF-8 NO_DECOR If set the application will run without window borders in openbox for use as a PWA. NO_FULL Do not autmatically fullscreen applications when using openbox. Optional run configurations¶ Variable Description --privileged Will start a Docker in Docker (DinD) setup inside the container to use docker in an isolated environment. For increased performance mount the Docker directory inside the container to the host IE -v /home/user/docker-data:/var/lib/docker. -v /var/run/docker.sock:/var/run/docker.sock Mount in the host level Docker socket to either interact with it via CLI or use Docker enabled applications. --device /dev/dri:/dev/dri Mount a GPU into the container, this can be used in conjunction with the DRINODE environment variable to leverage a host video card for GPU accelerated applications. Only Open Source drivers are supported IE (Intel,AMDGPU,Radeon,ATI,Nouveau) Language Support - Internationalization¶ The environment variable LC_ALL can be used to start this container in a different language than English simply pass for example to launch the Desktop session in French LC_ALL=fr_FR.UTF-8. Some languages like Chinese, Japanese, or Korean will be missing fonts needed to render properly known as cjk fonts, but others may exist and not be installed inside the container depending on what underlying distribution you are running. We only ensure fonts for Latin characters are present. Fonts can be installed with a mod on startup. To install cjk fonts on startup as an example pass the environment variables (Alpine base): -e DOCKER_MODS=linuxserver/mods:universal-package-install -e INSTALL_PACKAGES=font-noto-cjk -e LC_ALL=zh_CN.UTF-8 The web interface has the option for \"IME Input Mode\" in Settings which will allow non english characters to be used from a non en_US keyboard on the client. Once enabled it will perform the same as a local Linux installation set to your locale. DRI3 GPU Acceleration (KasmVNC interface)¶ For accelerated apps or games, render devices can be mounted into the container and leveraged by applications using: --device /dev/dri:/dev/dri This feature only supports Open Source GPU drivers: Driver Description Intel i965 and i915 drivers for Intel iGPU chipsets AMD AMDGPU, Radeon, and ATI drivers for AMD dedicated or APU chipsets NVIDIA nouveau2 drivers only, closed source NVIDIA drivers lack DRI3 support The DRINODE environment variable can be used to point to a specific GPU. Up to date information can be found here Nvidia GPU Support (KasmVNC interface)¶ Nvidia support is not compatible with Alpine based images as Alpine lacks Nvidia drivers Nvidia support is available by leveraging Zink for OpenGL support. This can be enabled with the following run flags: Variable Description --gpus all This can be filtered down but for most setups this will pass the one Nvidia GPU on the system --runtime nvidia Specify the Nvidia runtime which mounts drivers and tools in from the host The compose syntax is slightly different for this as you will need to set nvidia as the default runtime: sudo nvidia-ctk runtime configure --runtime=docker --set-as-default sudo service docker restart And to assign the GPU in compose: services: webtop: image: lscr.io/linuxserver/webtop:latest deploy: resources: reservations: devices: - driver: nvidia count: 1 capabilities: [compute,video,graphics,utility] Application management¶ PRoot Apps¶ If you run system native installations of software IE sudo apt-get install filezilla and then upgrade or destroy/re-create the container that software will be removed and the container will be at a clean state. For some users that will be acceptable and they can update their system packages as well using system native commands like apt-get upgrade. If you want Docker to handle upgrading the container and retain your applications and settings we have created proot-apps which allow portable applications to be installed to persistent storage in the user's $HOME directory and they will work in a confined Docker environment out of the box. These applications and their settings will persist upgrades of the base container and can be mounted into different flavors of KasmVNC based containers on the fly. This can be achieved from the command line with: proot-apps install filezilla PRoot Apps is included in all KasmVNC based containers, a list of linuxserver.io supported applications is located HERE. Native Apps¶ It is possible to install extra packages during container start using universal-package-install. It might increase starting time significantly. PRoot is preferred. environment: - DOCKER_MODS=linuxserver/mods:universal-package-install - INSTALL_PACKAGES=libfuse2|git|gdb Usage¶ To help you get started creating a container from this image you can either use docker-compose or the docker cli. Info Unless a parameter is flaged as 'optional', it is mandatory and a value must be provided. docker-compose (recommended, click here for more info)¶ --- services: webtop: image: lscr.io/linuxserver/webtop:latest container_name: webtop security_opt: - seccomp:unconfined #optional environment: - PUID=1000 - PGID=1000 - TZ=Etc/UTC - SUBFOLDER=/ #optional - TITLE=Webtop #optional volumes: - /path/to/data:/config - /var/run/docker.sock:/var/run/docker.sock #optional ports: - 3000:3000 - 3001:3001 devices: - /dev/dri:/dev/dri #optional shm_size: \"1gb\" #optional restart: unless-stopped docker cli (click here for more info)¶ docker run -d \\ --name=webtop \\ --security-opt seccomp=unconfined `#optional` \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Etc/UTC \\ -e SUBFOLDER=/ `#optional` \\ -e TITLE=Webtop `#optional` \\ -p 3000:3000 \\ -p 3001:3001 \\ -v /path/to/data:/config \\ -v /var/run/docker.sock:/var/run/docker.sock `#optional` \\ --device /dev/dri:/dev/dri `#optional` \\ --shm-size=\"1gb\" `#optional` \\ --restart unless-stopped \\ lscr.io/linuxserver/webtop:latest Parameters¶ Containers are configured using parameters passed at runtime (such as those above). These parameters are separated by a colon and indicate : respectively. For example, -p 8080:80 would expose port 80 from inside the container to be accessible from the host's IP on port 8080 outside the container. Ports (-p)¶ Parameter Function 3000:3000 Web Desktop GUI 3001:3001 Web Desktop GUI HTTPS Environment Variables (-e)¶ Env Function PUID=1000 for UserID - see below for explanation PGID=1000 for GroupID - see below for explanation TZ=Etc/UTC specify a timezone to use, see this list. SUBFOLDER=/ Specify a subfolder to use with reverse proxies, IE /subfolder/ TITLE=Webtop String which will be used as page/tab title in the web browser. Volume Mappings (-v)¶ Volume Function /config abc users home directory /var/run/docker.sock Docker Socket on the system, if you want to use Docker in the container Device Mappings (--device)¶ Parameter Function /dev/dri Add this for GL support (Linux hosts only) Miscellaneous Options¶ Parameter Function --shm-size= We set this to 1 gig to prevent modern web browsers from crashing --security-opt seccomp=unconfined For Docker Engine only, many modern gui apps need this to function on older hosts as syscalls are unknown to Docker. Environment variables from files (Docker secrets)¶ You can set any environment variable from a file by using a special prepend FILE__. As an example: -e FILE__MYVAR=/run/secrets/mysecretvariable Will set the environment variable MYVAR based on the contents of the /run/secrets/mysecretvariable file. Umask for running applications¶ For all of our images we provide the ability to override the default umask settings for services started within the containers using the optional -e UMASK=022 setting. Keep in mind umask is not chmod it subtracts from permissions based on it's value it does not add. Please read up here before asking for support. User / Group Identifiers¶ When using volumes (-v flags), permissions issues can arise between the host OS and the container, we avoid this issue by allowing you to specify the user PUID and group PGID. Ensure any volume directories on the host are owned by the same user you specify and any permissions issues will vanish like magic. In this instance PUID=1000 and PGID=1000, to find yours use id your_user as below: id your_user Example output: uid=1000(your_user) gid=1000(your_user) groups=1000(your_user) Docker Mods¶ We publish various Docker Mods to enable additional functionality within the containers. The list of Mods available for this image (if any) as well as universal mods that can be applied to any one of our images can be accessed via the dynamic badges above. Support Info¶ Shell access whilst the container is running: docker exec -it webtop /bin/bash To monitor the logs of the container in realtime: docker logs -f webtop Container version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' webtop Image version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' lscr.io/linuxserver/webtop:latest Updating Info¶ Most of our images are static, versioned, and require an image update and container recreation to update the app inside. With some exceptions (noted in the relevant readme.md), we do not recommend or support updating apps inside the container. Please consult the Application Setup section above to see if it is recommended for the image. Below are the instructions for updating containers: Via Docker Compose¶ Update images: All images: docker-compose pull Single image: docker-compose pull webtop Update containers: All containers: docker-compose up -d Single container: docker-compose up -d webtop You can also remove the old dangling images: docker image prune Via Docker Run¶ Update the image: docker pull lscr.io/linuxserver/webtop:latest Stop the running container: docker stop webtop Delete the container: docker rm webtop Recreate a new container with the same docker run parameters as instructed above (if mapped correctly to a host folder, your /config folder and settings will be preserved) You can also remove the old dangling images: docker image prune Image Update Notifications - Diun (Docker Image Update Notifier)¶ Tip We recommend Diun for update notifications. Other tools that automatically update containers unattended are not recommended or supported. Building locally¶ If you want to make local modifications to these images for development purposes or just to customize the logic: git clone https://github.com/linuxserver/docker-webtop.git cd docker-webtop docker build \\ --no-cache \\ --pull \\ -t lscr.io/linuxserver/webtop:latest . The ARM variants can be built on x86_64 hardware and vice versa using lscr.io/linuxserver/qemu-static docker run --rm --privileged lscr.io/linuxserver/qemu-static --reset Once registered you can define the dockerfile to use with -f Dockerfile.aarch64. To help with development, we generate this dependency graph. Init dependency graph Versions¶ 10.01.25: - Rebase Fedora to 41. 06.12.24: - Rebase Alpine to 3.21. 26.09.24: - Swap from firefox to chromium on Alpine images. 23.05.24: - Rebase Alpine to 3.20, document Nvidia support. 22.04.24: - Rebase Ubuntu to Noble. 16.04.24: - Add docs on PRoot Apps. 14.04.24: - Rebase Fedora to 40. 11.02.24: - Add PWA icons and title variants properly. 06.02.24: - Update Readme about native language support. 29.12.23: - Rebase Alpine to 3.19 and swap back to Firefox. 07.11.23: - Rebase Fedora to 39. 14.06.23: - Rebase to Debian Bookworm. 13.05.23: - Rebase to Alpine 3.18 and Fedora 38. 23.03.23: - Rebase all Webtops to KasmVNC base image. 21.10.22: - Rebase xfce to Alpine 3.16, migrate to s6v3. 12.03.22: - Add documentation for mounting in a GPU. 05.02.22: - Rebase KDE Ubuntu to Jammy, add new documentation for updated gclient, stop recommending priv mode. 21.09.21: - Add Fedora and Arch images, show seccomp settings in readme. 26.09.21: - Rebase to Alpine versions to 3.14. 20.04.21: - Initial release. January 10, 2025 February 7, 2019",
    "commentLink": "https://news.ycombinator.com/item?id=42690983",
    "commentBody": "Webtop – Alpine,Ubuntu,Fedora,and Arch containers containing full desktop envs (linuxserver.io)297 points by weitzj 19 hours agohidepastfavorite57 comments windexh8er 15 hours agoI've been using the LSIO Webtop images for a few years. They're awesome for composable desktops that I run behind a VPN for a quick and easy dirty connection at home. Combine the Webtop images by forcing it's traffic through the Gluetun [0] container and you're up and running. These Webtop containers are nice and snappy as well thanks to Kasm. Awesome OSS. [0] https://github.com/qdm12/gluetun reply Havoc 8 hours agoparentThis is me being rather lazy admittedly, but do you have a compose/similar for connecting them by chance? reply windexh8er 4 hours agorootparentBasically the same, but a bit more complete in terms of the exposed config: https://pastebin.com/hPvs08qh reply usagisushi 5 hours agorootparentprevHere it is https://pastebin.com/64825QxC reply yonatan8070 13 hours agoparentprevCould one build off this to run the desktops on the local host's display? I.e. as an IoT device with a display and some custom UI? reply chrisweekly 17 hours agoprev> \"Warning Do not put this on the Internet if you do not know what you are doing. By default this container has no authentication and the optional environment variables CUSTOM_USER and PASSWORD to enable basic http auth via the embedded NGINX server should only be used to locally secure the container from unwanted access on a local network. If exposing this to the Internet we recommend putting it behind a reverse proxy, such as SWAG, and ensuring a secure authentication solution is in place. From the web interface a terminal can be launched and it is configured for passwordless sudo, so anyone with access to it can install and run whatever they want along with probing your local network.\" I hope everyone intrigued by this interesting and potentially very useful project takes heed of this warning. reply satertek 17 hours agoparentThat warning applies to anything you run locally. And going further, in this day and age, I would never put up any home service without it being behind Cloudflare Access or some form of wireguard tunnel. reply Timber-6539 12 hours agorootparentJust put up basic auth infront of your services and be done with it. reply KronisLV 10 hours agorootparentI've done that in the past, even for securing the admin pages of some software (there was once an issue where the admin page auth could be bypassed, this essentially adds another layer). With TLS it's okay for getting something up and running quickly. Of course, for the things that matter a bit more, you can also run your own CA and do mTLS, even without any of the other fancy cloud services. reply jazzyjackson 5 hours agorootparentAfter coming across a brief tutorial of mTLS in this tool for locking down access to my family photo sharing [0] I have bounced around the internet following various guides but haven't ended up with a pfx file that I can install in a browser. Can you recommend any resource to understand which keys sign what, and what a client certificate is verified against? The guides I find often contain the openssl incantations with little explanation so I feel a bit like stumbling through the dark. I realize how much I've taken stacktraces for granted when this auth stuff is very \"do or do not, there is no error\" [0] https://github.com/alangrainger/immich-public-proxy/blob/mai... reply baq 8 hours agorootparentprevthe fact that we have to keep reinventing kerberos all the time because it doesn't speak http is starting to legitimately annoy me. reply rlkf 7 hours agorootparentFirefox can be configured to use Kerberos for authentication (search for \"Configuring Firefox to use Kerberos for SSO\"); on Windows, Chrome is supposed to do so too by adding the domain as an intranet zone. reply j16sdiz 6 hours agorootparentprevHTTP auth can work with kerberos. Chrome, Firefox, Internet Explorer -- all support some form of kerberos auth in HTTP/HTTPS. reply baq 6 hours agorootparentI mean, I'm aware of SPNEGO etc. It's just that it was... ignored(?) by the startups/the community/google? Whatever little support there is is comparatively a worse experience than what we've got now for no really good reason. reply mschuster91 2 hours agorootparentKerberos is old neckbeard tech, highly complex to set up, with layers upon layers of legacy garbage. Trying to get it working is ... a nightmare, I prefer even the garbagefest that is Keycloak over dealing with Kerberos. At least that just requires somewhat working DNS and doesn't barf when encountering VPNs, split horizon DNS or split tunnels. The only places I've seen a working Kerberos setup outside of homelabs is universities (who can just throw endless amounts of free student labor power onto solving any IT problem) and large governments and international megacorps. reply mschuster91 3 hours agorootparentprevGood luck when the TCP or SSL stack has an issue. These bugs are rare but they do exist and you're getting fucked royally if your entire perimeter defense was a basic auth prompt. Windows and Linux have both had their fair share of network stack bugs, OpenSSL had Heartbleed and a few other bugs, and hell you might even run into bugs in Apache or whatever other webserver you are using. reply gbraad 2 hours agoparentprevI created personalized image with tailscale and kasmvnc for this particular reason, ... not on a public VPS. you can find images on my github as inspiration; do not directly copy unless you understand what you are doing. reply hifikuno 17 hours agoparentprevYeah, I made a mistake with my config. I had setup SWAG, with Authelia (i think?). Got password login working with 2fa. But my dumbass didn't realize I had left ports open. Logged in one day to find a terminal open with a message from someone who found my instance and got in. Called me stupid (I mean they're not wrong) and all kinds of things and deleted everything from my home drive to \"teach me a lesson\". Lesson painfully learnt. But before that happened Webtop was amazing! I had Obsidian setup so I could have access on any computer. It felt great having \"my\" computer anywhere I went. The only reason I don't have it set up is because I made the mistake of closing my free teir oracle cloud thinking I could spin up a fresh new instance and since then I haven't been able to get the free teir again. reply elashri 15 hours agorootparent> The only reason I don't have it set up is because I made the mistake of closing my free teir oracle cloud thinking I could spin up a fresh new instance and since then I haven't been able to get the free teir again. People are automating the process of requesting new arm instances on free tier [1]. You would find it near impossible to compete without playing same game [1] https://github.com/mohankumarpaluru/oracle-freetier-instance... reply 7thpower 14 hours agorootparentWell, I know what I’m doing tomorrow when I get up. reply Maakuth 12 hours agorootparentprevThere are operations that put cryptominers into any unauthenticated remote desktops they can find. Ask me how I know... Way friendlier than wiping your data though. reply unixhero 9 hours agorootparentThere are groups of people who hunt for writeable ftp servers to be used for random filesharing. At least this used to be a thing reply dspillett 8 hours agorootparentprev> Lesson painfully learnt. There are actually two lessons there: 1. Be careful what you open to the public internet, including testing to make sure you aren't accidentally leaving open defaults as they are. 2. Backups. Set them up, test them, make sure someone successfully gaining access to the source box(es) can't from there wipe all the backups. reply doubled112 4 hours agorootparentAn offline backup is incredibly inconvenient, but also very effective against shenanigans like these. Also agree that backups should be \"pulled\" with no way to access them from the machine being backed up. reply dspillett 42 minutes agorootparentI use a soft-offline backup for most things: sources push to an intermediate, backups pull from the intermediate, neither source not backup can touch each other directly. Automated testing for older snapshots is done by verifying checksums made at backup time, and for the latest by pushing fresh checksums from both ends to the middle for comparison (anything with a timestamp older than last backup that differs in checksum indicates an error on one side or the other, or perhaps the intermediate, that needs investigating, as does any file with a timestamp that differs more than the inter-backup gap, or something that unexpectedly doesn't exist in the backup). I have a real offline backups for a few key bits of data (my main keepass file, encryption & auth details for the backup hosts & process as they don't want to exist in the main backup (that would create a potential hole in the source/backup separation), etc.). reply nsteel 10 hours agorootparentprevBut you can have Obsidian access from any device already if you easily setup syncing using the official method (and support the project by doing so) or one of the community plugins. Doing it this normal way avoids opening up a massive security hole too. reply jazzyjackson 5 hours agorootparent* any device you have admin rights to install software on, they are talking about being able to log in from any computer, not just their own It surprises and annoys me that obsidian, logseq, etc don't have self hosted web front ends available. I think logseq will once they wrap up the db fork, and maybe someday we'll have nuclear fusion powerplants too. reply 7bit 17 hours agorootparentprev> deleted everything from my home drive to \"teach me a lesson\". Lesson painfully learnt. I had a mentor in my teenage year that was the same kind of person. To this day the only meaningful memory I have of him is that he was an asshole. You can teach a lesson and be empathetic towards people that make mistakes. You don't have to be an asshole. reply Dalewyn 16 hours agorootparentThe lessons we learn best are those which we are emotionally invested in and sometimes that emotion can be negative, but a lesson will be learned regardless. reply ano-ther 7 hours agorootparentSure. But you don’t have to deliberately destroy all data and be mean about it as in GP‘s case to get an emotional reaction. reply jillyboel 3 hours agorootparentprevNo backups? reply fulafel 14 hours agoparentprevAlso note that their example docker config will allow anyone from the internet to connect, and even add a incoming rule in your host firewall to allow it. This is because they don't specify the port like -p 127.0.0.1:hostport:containerport (or the analog in the docker-compose config). reply asyx 5 hours agoparentprevNo they won’t. Octoprint (3d printing server) had a similar warning but they had to introduce actual user accounts to secure the system because people ignored it. reply macinjosh 4 hours agoparentprevIf a good password is used HTTP basic auth is plenty secure over HTTPS so that everything is encrypted. reply bo0tzz 7 hours agoprevMy pipedream is to have a containerized desktop environment like this that outputs directly to a physical monitor over HDMI/DP without needing an X server on the host machine. So far I haven't found any clear answers on whether that's possible at all. reply jazzyjackson 4 hours agoparentI feel I've been nerdsniped or, some other term for your quest being contagious, I also now need to know if this is possible I found a thread from someone who seems to know what they're talking about saying it's not going to happen \"on your hardware\", but doesn't mention what hardware might be required https://forum.level1techs.com/t/can-intel-integrated-gpu-out... Edit actually reading that link again it sounds like a USB adapter worked right away as a monitor for the VM and the OP is asking how to prevent this ! So seems you just need to enable GPU passthrough, and a USB HDMI will appear to your VM ? Will have to try this later today reply chromakode 10 hours agoprevSelkies[1] is another interesting project in this space. It uses webrtc for low latency streaming and remote desktop suitable for gaming in the browser. [1]: https://selkies-project.github.io/selkies-gstreamer/ reply mch82 11 hours agoprevSince the website doesn’t have pictures or videos… Is “webtop” a way to package GUI desktop apps in a Docker container so that the only dependencies to run the app are Docker Desktop and a web browser? reply weitzj 11 hours agoparentYes. From the documentation there are some Screenshots and this is possible. Like starting a standalone Firefox browser inside docker desktop and accessing it via a browser vnc session. But you get to control the keyboard/clipboard and it can add apparently watermarks to the vnc session for DLP functionality and you have a web http to take screenshots of your vnc sessions. reply ctm92 11 hours agoprevKasm [1] also has ready-to-use images that work similar. They are also customizable to contain own applications or configuration. Intended to be used with their Kasm Workspaces solution, but they also work standalone just fine. [1] https://hub.docker.com/u/kasmweb reply NKosmatos 11 hours agoparentThanks for this, they have many images with an online working demo for 3 minutes to try it out. For sure I'm going to have another look at Kasm. reply ctm92 10 hours agorootparentTheir GitHub repo [1] has also skeleton dockerfiles that are annotated with comments on where you have to put your customizations, quite cool [1] https://github.com/kasmtech/workspaces-images reply mopoke 8 hours agoprevAnd, of course, I decided to see what happened if I fired up firefox in webtop and loaded webtop in it. Oops. reply Dansvidania 7 hours agoparentseems only natural, I sympathize reply iddan 9 hours agoprevBack when I was in middle school in Israel the system used for communication between teachers students and parents was called Webtop. They actually went all the way to implement OS desktop experience in the browser (this is long long ago) it was very silly but cute reply euph0ria 7 hours agoprevWhat are some use cases for this? reply hugs 3 hours agoparentsoftware testing. it's always software testing. reply dymk 13 hours agoprevWe had an application that had quite the complex build process, and targeted only macOS and Linux. The mechanical engineers all used Windows, and needed to use the application. Rather than buying them macbooks or having them manage a Linux box, I wound up building something like Webtop with webvnc, and deployed containers to google cloud. Engineers could go to a URL and access the application, no need to download or install anything. It worked pretty well, all things considered. reply mhitza 17 hours agoprevAnyone have more info on this? Does it run systemd in those containers (I didn't see any systemd specific mounts). This would be interesting to try out, as docker (via compose) is a bit easier to manage than - for example - VMs with virt-manager/cockpit-machines. reply r3c0nc1l3r 15 hours agoparentNo systemd, these just start a shell script on init that launches the WM. They're based around the open-source component of this product: https://www.kasmweb.com/docs/latest/index.html I find that they are slightly more sluggish than Moonlight/Sunshine for remote streaming, but generally faster/better than x11vnc. Not quite good enough for gaming yet, but plenty for web browsing, Blender, etc. reply Jnr 5 hours agoprevHow come Gnome is not there? reply doubled112 11 minutes agoparentWhile I've never used GNOME inside a KasmVNC session, it used to feel slow on reasonably powerful machines in an Xrdp session. That'd be my first guess. reply fosron 17 hours agoprevWhy did i have to find this at 3AM. Thanks though. reply ranger_danger 14 hours agoprevLooks very similar to neko: https://neko.m1k1o.net reply imran9m 16 hours agoprevNice. Finally easy way to test them!! reply bitsandbooks 5 hours agoprevSee also: the RDP version. https://docs.linuxserver.io/images/docker-rdesktop/ reply deelowe 16 hours agoprev [–] I was just looking for something like this. Awesome! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Linuxserver/webtop provides containers based on Alpine, Ubuntu, Fedora, and Arch with full desktop environments accessible through web browsers, supporting both x86-64 and arm64 architectures.",
      "Users can select from various desktop environments such as XFCE, KDE, MATE, i3, Openbox, and IceWM by using specific image tags, and access the Webtop via designated URLs.",
      "Security features include Docker's seccomp option and authentication setup, with customization options available through environment variables, and support for GPU acceleration with open-source drivers."
    ],
    "commentSummary": [
      "Webtop provides containers with full desktop environments for Alpine, Ubuntu, Fedora, and Arch, suitable for quick setups behind a VPN.",
      "Users commend Webtop for its speed and ease of use, particularly when used with the Gluetun container for secure connections, but caution against exposing containers to the internet without security measures due to lack of default authentication.",
      "The project is valued for being open-source and flexible, with users sharing configurations, and alternatives like Kasm and Selkies are noted for similar purposes."
    ],
    "points": 297,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1736810708
  },
  {
    "id": 42697783,
    "title": "1 in 5 online job postings are either fake or never filled, study finds",
    "originLink": "https://gizmodo.com/1-in-5-online-job-postings-are-either-fake-or-never-filled-study-finds-2000549706",
    "originBody": "1 in 5 Online Job Postings Are Either Fake or Never Filled, Study Finds A plague of \"ghost jobs\" is haunting the modern job-seeker. By Lucas Ropek Published January 14, 2025Comments (38)𝕏 Copied! © Thomas Barwick/Getty Images The job hunt can be a slog. Confusing job portals, dense competition, and time-consuming application processes all conspire to make job hunting one of the most annoying experiences on the planet. After all the work that goes into an application, 99.9 percent of the time you hear nothing back. It’s enough to make you feel like you’re firing applications into the abyss—as if the jobs you’ve applied to never existed in the first place. Well, according to a recent study, that may actually be the case. The Wall Street Journal cites internal data from the hiring platform Greenhouse that shows one in five online job postings—or between 18% and 22% of jobs advertised—are either fake or never filled. That data was culled from Greenhouse’s proprietary information, which the company can access because it sells automated software that helps employers fill out job postings. The “ghost job” phenomenon has been growing for some time—much to the vexation of job-seekers. The Journal story cites the experiences of one unfortunate job-seeker, Serena Dao, who searched for a job for over a year. Dao says that, before landing her current position, she applied to some 260 jobs and frequently wondered whether the positions she was applying to were real or not. Some onlookers have speculated that the practice of posting such advertisements is actually a corporate strategy designed to make the businesses posting them seem like they’re growing when, in fact, they’re not. Fast Company writes that this practice may help companies “feign active hiring and growth” and helps the “C-suite hit quarterly goals without the negative perception of removing jobs from their career sites.” Another commentator for Forbes notes that ghost jobs can inflate “the true number of jobs in the market and elongates the job search, much to the frustration of many job seekers.” The plague of such phantom positions has led some platforms to treat job postings in very much the same way that other online content gets treated: as either A) verified or B) potential misinformation. Both Greenhouse and LinkedIn now supply a job verification service, the Journal writes, which allows users to know whether a position is legit or not. “It’s kind of a horror show,” Jon Stross, Greenhouse’s president and co-founder, told the Journal. “The job market has become more soul-crushing than ever.” Greenhousejob listingsLinkedIn Daily Newsletter Get the best tech, science, and culture news in your inbox daily. Select News from the future, delivered to your present. Select Please select your desired newsletters and submit your email to upgrade your inbox. Sign me up You May Also Like Tech NewsArtificial Intelligence AI Was Born to Blog on LinkedIn A study found that most of the posts on LinkedIn are written by generative AI. Is anyone surprised? By Matthew Gault Published November 27, 2024 Tech News Former FTX Executive Is Locked-In on LinkedIn and Federal Prison One of FTX's executives begins a seven year prison sentence with a humorous update to his LinkedIn profile. By Matthew Gault Published October 11, 2024 Tech NewsPrivacy and Security New Open Source Bugs Leave Thousands of iOS Apps Vulnerable to Hijacking The Cocoapods vulnerabilities could threaten TikTok, Snapchat, LinkedIn, Netflix, Microsoft Teams, Facebook Messenger, and many others. By Lucas Ropek Published July 2, 2024 Tech NewsNews AT&T Users Report Major Problems Making Calls in U.S. The issue appears confined to voice calls this time, unlike the complete outage in February. By Matt Novak Published June 4, 2024 Tech NewsNews Big Name TikTok Accounts Reportedly Hacked Via DMs Accounts for CNN, Sony, and Paris Hilton have reportedly been compromised. By Matt Novak Published June 4, 2024 Tech NewsGaming Nintendo’s Bowser Gets Into LinkedIn Brawl Over Plane Seats The President of Nintendo America hopped into the comments to call out an oddly agressive post about deboarding planes Zack Zwiezen, Kotaku Published May 10, 2024 Latest news AR Glasses Still Suck at AR, but They’re Solid Secondary Screens LEGO or Board Games? Enjoy Both With This Brick-Building Monkey Palace Game, Now at Its Lowest Price One of Comics’ Biggest Distributors Has Filed for Bankruptcy Amazon’s Choice Crucial BX500 Internal SSD Slashes Price to a Record Low A New Diabetes Treatment Is on the Horizon—But It Involves Poop Texas Sues Allstate for Collecting Driver Data to Raise Premiums It Takes 36 Days of Nonstop Motion to Move this Log in Super Mario 64. There Is No Reason to Do It. The Latest 17-Inch Touchscreen HP Laptop Is Now $1,800 Cheaper Than a 16-Inch MacBook Pro Best of CES 2025 Awards Best of CES 2025 Awards ➜ Latest news AR Glasses Still Suck at AR, but They’re Solid Secondary Screens 1/14/2025, 12:36 pm LEGO or Board Games? Enjoy Both With This Brick-Building Monkey Palace Game, Now at Its Lowest Price 1/14/2025, 12:01 pm One of Comics’ Biggest Distributors Has Filed for Bankruptcy 1/14/2025, 12:00 pm Amazon’s Choice Crucial BX500 Internal SSD Slashes Price to a Record Low 1/14/2025, 11:30 am Latest Reviews OnePlus 13 Review: A Better Android Phone, but It’s Not the Best 1/14/2025, 10:00 am The Onyx Boox Go 6 Did Not Free Me From the Kindle Store’s Grip 1/5/2025, 7:00 am The Best Laptops in 2025 1/4/2025, 4:10 pm Oppo Find 8X Pro Review: A Great iPhone for Android Lovers 1/4/2025, 8:00 am",
    "commentLink": "https://news.ycombinator.com/item?id=42697783",
    "commentBody": "1 in 5 online job postings are either fake or never filled, study finds (gizmodo.com)273 points by belter 4 hours agohidepastfavorite224 comments dzdt 4 minutes agoI have been required to create fake job postings because of US immigration policy. From the line manager perspective, how it looks is you have a colleague who has been working with you for several years who is on a H1B visa. They want to get a green card and become a permanent resident. To support this, we are required to post a fake job ad for their position, and invent a reason to reject any US citizens who apply for the position. (Non-US applications are ignored.) Our legal advice was that the job posting had to be contain only legitimate requirements for the role, so it could not be highly tailored to only match the resume of the employee seeking PERM status. The result was phone screen interviews were required to reject 8-10 on-paper-potentially-qualified US applicants for the fake position. This is for a highly specialized area within finance, where in real hiring there is an immense effort to find the strongest candidates regardless of nationality. In hindsight I am confident that earlier in my career I had applied to at least one such fake role. One not-well-known advantage of working with a recruiter as a job seeker in such a field is the recruiter will have back-channel information to know to ignore such fake job postings. reply Glyptodon 3 hours agoprevI think the rate of non-fill is higher. But the reasons for it are all over the map. Everything from \"we always leave a posting up even when we're not really looking just in case the perfect candidate happens to walk through the door\" but in the mean time nobody really pays attention to applicants, to \"we weren't getting the applicants we wanted with this posting, so we took it down and are trying a new posting,\" to \"we're legally obligated to post this, but we already have a plan about hiring\" whether it's someone connected, someone internal, or a preference for H1B workers, to all kinds of other scenarios. Anybody who has ever applied for a dozen jobs, sent literate applications and outreach, and has heard from most of them never to months later regardless of actual fit for the job knows this. reply Miserlou57 1 hour agoparentI was a contractor at a FAANG for a few years, and they handed me a job. In the few weeks of transition between the two (some paperwork, etc.) a job posting and req ID was created and posted on their jobs site. I freaked out for a bit, but everything worked out so I can only presume (in California) that was a requirement. What amazed me was it said (maybe on LinkedIN?) how many poor souls actually took the time to apply to the position. It was in the hundreds. I can't help but feel bad knowing they never had a chance. reply Scoundreller 4 minutes agorootparentHappens in public/gov sector regularly. PT role turning into FT… it’s going to the PTer. Temporary budget allocation became permanent and determinate spot becoming indeterminate? Same. reply freedomben 10 minutes agoparentprevI think you're right. Speaking from current personal experience, it's not unusual to get 500 applications for a job, especially higher-level jobs like Principal engineer (where people are chasing the title and salary). I would guess 90% of them are clearly underqualified. Of the other 10%, nearly half will never respond to a follow-up email to schedule interviews. Of those that do, 3/4 of them will reject the offer for various reasons. Given I have a lot of other duties beyond hiring, spending the hours upon hours it takes to sort through that only to have it yield no fruit is ... demoralizing at best. It seems to me that if somebody can actually solve the problem of increasing signal-to-noise ratio, they could do very well. reply duxup 2 hours agoparentprevI always wonder about the gathering resumes \"just in case the perfect person applies\" kind of idea. 1. Would anyone notice if the perfect candidate applied? 2. Does anyone even know what the perfect candidate's resume would look like / are those qualities on a resume / captured by a resume system? 3. Is the perfect candidate actually cold submitting resume to you? It feels like almost certainly these are all \"no\". reply drillsteps5 2 hours agorootparentFrom my experience this is one of the ways it might work. Recruiting (company's internal function, which is part of HR) is tasked with soliciting profiles to see what's available on the market. There's no real position but the recruiter(s) invent one according to what the business told them they would eventually need. There's no hiring manager behind it (as there's no position to be be filled). Recruiter either periodically meets with the business group that requested the research or prepares a report on the results (number of resumes that came in, salary requirements, etc) and presents to the business group that requested it. So there's a reason these resumes are being solicited, it's just the reason is not to hire somebody. Sometimes it is done to justify business decision (ie to move to a different technology, or to expand to a new geographical area). Sometimes the business group _might_ be willing to open a new req if \"the right candidate\" comes up, but it's not guaranteed. It also allows HR and recruiting to justify their presence (they are busy despite the fact that the company might not be hiring at all currently). So there's reasons why these positions are posted and virtually none to prevent the company from doing that. reply johnnyanmac 2 hours agorootparentprev1. With the current AI bots, likely not. And that basically shows how inefficient these systems currently are. 2. The hiring manager does. The bot certainly does not. The odds of someone able to please the latter while meeting the former is low odds, for a candidate that's already low odds to begin with. 3. Not impossible. And that's all the justification they need as long as they aren't penalized for what basically a ghost job. reply Glyptodon 1 hour agorootparentprevI think the answers to these is usually no, but there's one (questionable) person in leadership who's like \"what if somebody from Google applies?\" (or whatever equivalent). Never seen it work. Encountered it a few times. It tends to be magical thinking embellished by narratives around 10x engineers. reply SoftTalker 12 minutes agorootparent\"what if somebody from Google applies\" I'd be immediately suspicious. Why are they leaving Google to come here? reply epolanski 3 hours agoparentprevI feel so lucky I haven't had to apply anywhere in my entire career through postings, the good thing of having a solid network is that you get to know who knows a consultant/freelancer before any position is created. I did post my availability few times on HN \"who wants to be hired\" but with poor results and lots of wasted time (as again, the person on the other end does not know me or has worked with me everything gets bureaucratic again). Also, all of the people I had hired for my clients came again from my network, there was never a public posting. There's also other benefits, in general, you don't get to do silly technical interviews, as you're bringing former coworkers you can vouch for. Not saying this can scale anywhere, but in smaller companies with good teams and professionals they always know someone from their previous jobs or their online communities (common in open source related githubs/discords/slacks) and I like it. reply eulers_secret 2 hours agorootparentIME it's not that bad. My entire network failed when I was looking for work: either everyone was still at my old employer whom I didn't want to return to or they were also out of work. I don't have much online presence, because that's my preference. I did ~11 applications (on company websites, tailored resume), of which like 9 were moonshots (NVDA, Valve, etc). I heard back from everyone, and then interviewed and accepted an offer with a smaller international company located locally. This was during the 2023/4 downturn (Dec '23 to be exact). Caveat: I have 15YoE and work in embedded (especially embedded Linux); it seems this specialization has suffered less than others. I also don't have a degree. I had to accept a slight paycut and hybrid - but I was in office before... and hardware generally just requires you to be present sometimes. Don't be afraid if you don't have a network, the advice is good, but it doesn't apply to everyone. reply qq66 1 hour agorootparentI think that's relevant if you have a highly specialized skillset like embedded Linux. People don't make embedded Linux job postings to \"test the waters\" or \"see if the perfect candidate applies.\" If the listing is up, they're probably hiring an embedded Linux developer, and while there will be a lot of resume frauds applying, they actually need to make the hire. If you're applying for a B2B SaaS product manager job there are 50,000 jobs and 200,000 applicants and it's a completely different situation. reply dennis_jeeves2 1 hour agorootparentprevCurious, what do you earn? reply johnnyanmac 2 hours agorootparentprev11 apps to one job last year, huh? With a 100% response rate. Wish I could have had even a tenth of that luck. Heck even during the best booms my response rate was hovering around 30%. I'm just exhausted with the search. I finished yet another programming take home only for the company to stop hiring at the turn of the quarter. But yea, my network also failed me. Mostly becsuse 80%+ of them were laid off themselves. reply selimthegrim 1 hour agorootparentPaid off? reply johnnyanmac 1 hour agorootparentWhat an unfortunate typo. Luckily I had time to fix that one. But sure, I think almost all of them got severance. reply keb_ 1 hour agorootparentprevHow would I recommend I get into embedded Linux as a total newbie with only Node/Ruby experience? :^) reply TheGlav 1 hour agorootparentNo joke: just start! Learn C and C++. Find a cheap micro pc board, pick one of the embedded linux distros that run on it, and make something with it. Repeat until you get bored, exhausted, or a job. :) reply roland35 1 hour agorootparentprevTry getting a single board computer such as a raspberry pi, and see if you can get it to do stuff! Hook it up to some SPI or I2C peripheral boards to read temperature or light. Stream data to a cloud. Another big part of embedded Linux is managing the OS itself and updates. Things like Yocto handle building an OS image reply selimthegrim 2 hours agorootparentprevI would say the extended parts of my network are still getting the interviews, but I have people I directly literally went to school with, and lived in the same dorm with turn me flat down for work, which was a real slap in the face. I’ve been applying since April 2020 (with about 7 interviews so far and 2-3 upcoming interviews total) and I’m getting kind of discouraged at this point. reply Aurornis 32 minutes agorootparent> but I have people I directly literally went to school with, and lived in the same dorm with turn me flat down for work, which was a real slap in the face. Since referrals became the meta-game, companies have adapted their referral process to be more selective. Most companies I've worked for have required people to enter some basic information about how and where you worked with the referral, why you're referring them, and a statement that your referral means you are vouching for that person's work performance. It cuts down on the number of people referring people they know by happenstance, which defeats the purpose of a referral program. I doubt your friends meant it as a personal attack. They probably just had referral programs that were more rigorous than putting names into a queue. reply selimthegrim 26 minutes agorootparentThey said they hadn’t been happy with the last three months of candidates, and that I was probably going to be it and then rejected me with no feedback and hired some ex-SpaceX person as a contractor. It may have been the investor playing a role. reply epolanski 15 minutes agorootparentprevMaybe you didn't impress them? Network is important as long as people see you as a reliable professional that can help them. There's lots of skills involved, last but not least soft ones. reply cruffle_duffle 2 hours agorootparentprevHonestly in this market there is really only so much your network can do—at least at a “submit my resume for me” level. I’m starting to think I might get a bit more aggressive and bold with my network and have them deliver paper copies to the hiring manager or something. Because even referral submitted applications are black holes at this point. Hang in there and take what you can get. The market is super shitty and you are absolutely not alone. It ain’t you. The market will pick back up again… it always does. reply dennis_jeeves2 58 minutes agorootparent>The market will pick back up again… it always does. It will, but this time it's probably going to be several years. It's the covid lock down train wreck. Most people underestimate the cascading damage done by the lock downs. reply cruffle_duffle 48 minutes agorootparentYup. The damage caused by that nonsense will haunt us for decades to come. “It’s what everybody wanted” is something I often say. “Everybody was cheering this on”. reply dennis_jeeves2 23 minutes agorootparent>“It’s what everybody wanted” is something I often say. “Everybody was cheering this on”. Spot on. I read that somewhere that during WWII when people were sent to the gas chambers, crowds would be cheering on. Common people terrify me. reply selimthegrim 1 hour agorootparentprevIf they won’t pay for traveling for on-site interview or relocation is that a good sign; when they’re demanding three days a week in the office hybrid? reply bearjaws 2 hours agorootparentprevThis is really the best career advice. I was fortunately able to leave a terrible job 2 years ago and immediately had contract work, now I run my own business and get constant referrals from my network. I make more than ever, have incredible work-life balance, and for the most part love what I do. If you don't have a network, the moment you quit/lose a job you are dead to the world. Even now I have people approaching me for FTE roles, I haven't even worked with them for 2 years. Am I some god tier programmer? Not really, but I have a good track record and people always want to go to someone they already trusted. reply recursive 1 hour agorootparentIt's not advice really. If it were advice, it would be something you could do. reply TheGlav 1 hour agorootparentBuilding a network is something anyone can do. Join meetups. Find local user groups. Find online groups and get active in them. Give talks. Write and publish your thoughts locally and/or online. Talk with people. Ask (good) questions. Let people get to know you and the way you think. Many more ways exist than just these. Connecting with other professionals in various ways is all there is to building a network and anyone can do it. They just have to do it. reply hylaride 41 minutes agorootparentThis. I'm still benefiting from being in a BSD users group that I went to between 2000-2008 because it was filled with passionate/talented tech people, most of whom have gone onto other things. Find places to get into discussions and show your opinions and have discussions. If you are in a group where your mind is never changed, then find something else. reply recursive 38 minutes agorootparentprevOk, now that's advice. reply epolanski 13 minutes agorootparentprevYou definitely can. I always built my network mostly at local meetups and online communities. It helps if, like in my case, are into functional programming, as people into that niche prefer working with other functional programmers. reply netruk44 2 hours agorootparentprev> If you don't have a network, the moment you quit/lose a job you are dead to the world. As someone without a network and left their FAANG-adjacent (or whatever the current acronym is) job in 2022, this is mostly true. Amazon still hits up my inbox every month or so, though. reply Caius-Cosades 2 hours agorootparentprevYeah if you're not a social butterfly in the modern world you're just effed. Or about as good as dead, unless you happen to be extremely lucky. reply rwyinuse 2 hours agorootparentIn academic / white collar work for sure. But if you're something like a skilled craftsman whose services are in demand, you can probably do fine with less social networking. reply SoftTalker 9 minutes agorootparentCarpenters, electricians, and plumbers will be able to name their price in the Los Angeles area for the next few years. reply catwhatcat 2 hours agorootparentprevWhat sort of business are you running now, if you don't mind elaborating? reply xeromal 2 hours agorootparentprevI decided I wanted a better job in 2025 after being at my company for 6ish years. I started applying to 2-3 jobs a day starting in december and reaching out to old contacts. Complete ghost silence and bullshit. Managed to get 2 leetcode screens that went nowhere even after doing alright on them. Hit up an old college buddy on linked in, got a referral, went through a ton of interviews (6) and got a job in two weeks. It's nuts how far a referral will get you. reply Foobar8568 2 hours agorootparentprevI posted once with a seconds account on who is hiring, the amount of spam and fishing attempts received is crazy, 10-50 DocuSign and the like a day since then. reply ben_w 1 hour agoparentprev> we always leave a posting up even when we're not really looking just in case the perfect candidate happens to walk through the door I've seen one that remained up after the company itself was closed down… which I knew about by having been in it when it closed; even before that, it was so out of date the salary offered was about 60% of what they'd paid me when I joined. reply fifilura 3 hours agoparentprevI think \"looking for the perfect candidate\" is the most common reason by far. Great developers with domain knowledge are always possible to fit in, simply because they are money generators rather than a cost. reply hn_throwaway_99 3 hours agorootparent100% agree. A big issue with tech is there are so many options and domains that for any particular job it can easily take even an amazing developer 6-9 months to get up to speed if they're unfamiliar with your particular tech stack or business area. That's not the case with most other professions - if I'm, for example, a professional violin player, I can play in basically any orchestra in the world and be proficient from day 1. So if you happen to find that unicorn who is not only a great developer but is also expert in the major areas of your tech stack and your business domain, you hire them in a heartbeat. reply johnnyanmac 2 hours agorootparentSounds like something many technical professions have to deal with. Even with all the licenses and certs in the world, very few lawyers or doctors are just walking in and learning the process in a week. Other types of engineering need to understand the pipeline in another firm compared to their old one. A firefighter needs time to mesh with the team and figure out what equipment and tools are available here. But then again, I bet most of those also aren't trying to rely on AI to find talent. reply hn_throwaway_99 21 minutes agorootparentI can't speak about lawyers, but you're definitely wrong about doctors (have a couple in my family). They can and do travel to completely new hospital systems and are expected to do their normal job immediately (and they do). Even within tech, I think the ramp-up time is faster for literally everyone else besides software engineers, just because the underlying technology can vary so much more (and its more important to be understood at an intimate level of detail) than for other roles. reply rors 11 minutes agorootparentMy girlfriend is an Orthopaedic Surgeon. Great when I've got a broken arm, or need shelves putting up. I wouldn't let her anywhere near my heart or brain. Medicine is super specialised. I hear you on geography though. Luckily the human body doesn't change too much between locations. reply dcdc123 2 hours agoparentprevI think another very common scenario is just eliminating the headcount. Companies cut headcount at a small scale all the time and the first one to go is usually the unhired. reply devmor 11 minutes agoparentprevI once got a developer position through a professional group on Facebook. My soon-to-be manager had to have HR create a job posting on a public facing portal so I could apply through it, despite already essentially giving me the position. I wonder how many people applied for that job before it was taken down. reply kube-system 3 hours agoparentprevHaving interviewed candidates for full-stack positions, and actually asked them about the entire stack (instead of just the backend), I'm surprised the number isn't higher. reply ARandomerDude 3 hours agorootparentI've been amazed by how many times I've had this conversation: Applicant: \"I love ${LANGUAGE} so much! It's amazing! I'm super passionate about it!\" Me: \"Oh that's great! What are some things you like about ${LANGUAGE}, and one or two things you wish the language designers had done differently?\" Silence. (Replace language with database, framework, etc. as needed). reply kube-system 2 hours agorootparentToo often I find \"full-stack\" developers who only know how frameworks operate, but have no idea about how the computer actually works. \"How do you do [x] in SQL?\" > \"I've always had the ORM handle that\" \"How do you do [x] in CSS\" > \"I use this CSS framework and it will do it for me\" \"How does a packet get between the front end and back end of your solution\" > \"I update the object state using [x] in the [y] framework\" reply LeftHandPath 56 minutes agorootparentPerhaps there's a reason why. The market generally doesn't need people who can do it all. In the same way it doesn't need people writing C++ or Rust to know how to write machine code or assembly. Sure, the ones that can are probably more knowledgable, but their experience with the high level language is more important. I've done full-stack with no frameworks or non-std libraries (aside from PDO and OpenSSL, the limitations set by CEO decree) for about 8 years now. I write my own schemas in IBM Db2. Hell, I wrote small application databases in IBM DDS in the AS400's SEU while I was still under the legal drinking age. I've always written our stylesheets from scratch, using SCSS. I've written C++ APIs that run in PASE, talk to the database with ODBC, then send back to a front end through sockets. I do graphic design and photography -- something I started back in middle school and took some formal classes on -- and have led the creation of marketing materials for multiple subsidiaries. I've spent 40 hour weeks working on sysadmin tasks in vim, 40 hour weeks writing libraries in JetBrains and VSCode, and 40 hour weeks working running around with my DSLR or working in Photoshop, Illustrator, and InDesign. But when I look for full-stack jobs, most of them actually want somebody who is well versed in a framework. There's not much point in doing all of this from scratch. It's more tedious, more error prone, and it takes longer to get to market. Some interviewers have given the impression that I'm a little \"less than\" because I haven't used any major frameworks. I think that's actually a valid take, and it's something I've started doing side projects to address. Frameworks improve velocity. Frameworks improve reliability. They reduce the risk of a developer coming up with an out-in-the-weeds solution to a problem they didn't properly understand. They make it easier to maintain the code. They make it easier to onboard new developers who are familiar with that tech. reply tmpz22 19 minutes agorootparentI once did a take-home project for a full stack role that proclaimed any language/framework could be used to build a browser-based application that satisfied a particular task. I opted to use golang and its standard library to produce an application with no external dependencies and no javascript. In the rejection email they stated the use of outdated development methods was a point of disqualification. I'm sure other reasons for disqualification were present, I wasn't a great candidate in retrospect, but I'll never forget the naivety and hubris of their framing. They were of course a NextJS shop. Ultimately disregard role titles. It's a people problem that you have to pull teeth to find out what they really want, and what they really want they often won't say out loud. That's fine, it's their money (and usually a lot of it!) and they should be able to dictate the services that they want. Really sucks for people new to the industry trying to learn the song and dance. reply bostik 33 minutes agorootparentprevThis is an exceptionally good question to identify people who have actually used a technology for real. I've used merely the second part (\"what gripes do you have about X\") in interviews successfully for nearly two decades. If you've used a tool long enough, you've identified warts and misfeatures. And you will have opinions about them. reply duxup 2 hours agorootparentprevI always wonder how much that is influenced by the blog / social media world where a few (or even one) neat features in a product or language produces \"I love this\". So yeah they love it ... in so far as the social media expression goes. reply supriyo-biswas 32 minutes agorootparentI feel that’s more of an artifact of American culture. I remember discussions where the stakeholder declined to use a technology, and said something like “we love X, but are concerned about Y.” reply tombert 2 hours agoprevI've posted this story before, but it's relevant. About two years ago, I was looking for a job, and a recruiter reached out about a software engineering position at a prominent newspaper [1]. I told the recruiter to apply me, they did, and they made me sit through a two hour video course on ethics and sexual harassment, which was weird considering that I hadn't even done an interview yet. About a week later, the recruiter gets back to me, and they declined me because my resume \"reads too much like a manager, no hands-on coding experience\". I was extremely confused, because most of the time people say the opposite, that my resume is too in the weeds, and I need to focus on high-level stuff. Moreover, I don't have any managerial experience on my resume...every role says something like \"software engineer\". And then it hit me: the hiring manager never read my resume. He already knew who he wanted to hire for the role, and for either legal or compliance or bureaucratic reasons, he had to make it look like he was looking for other candidates, and in the process, he wasted my time and the recruiter's. [1] Not going to say which one but you've definitely heard of it. reply hylaride 31 minutes agoparentOne adtech company I applied to ~10 years ago (Chango - doesn't exist anymore) also put me through the strangest interview I ever had. It was for an SRE role. There was a fairly standard phone screening interview, but then when I went in-person the CTO, VP of engineering, and somebody else I can't recall made the whole interview about torrents and USENET feeds for TV shows. Not a single serious discussion was had about the business or technology, despite my attempts to bring it up. I left scratching my head and a follow-up email that said \"they were going to go in a different direction\". I can only guess that the role was going to somebody else they really wanted, but they needed a \"competitive\" alternative. I was annoyed that they wasted my time, though. reply stronglikedan 1 hour agoparentprev> Not going to say which one Nothing will change until online naming and shaming is not considered taboo. reply tombert 1 hour agorootparentI just don't want my name ASSOCIATED with that kind of PRESS, ok?? reply the-chitmonger 1 hour agorootparentI'm glad you clarified - I was expecting NYT! reply tombert 1 hour agorootparentI don't know what you're talking about :) reply dennis_jeeves2 47 minutes agorootparentprevmake an anon account. reply _DeadFred_ 1 hour agorootparentprevAre there laws against companies committing fraud and false advertising? Job sites are directly evolved from classified ads in which ads stands for Advertisement. reply joelfried 1 hour agorootparentYou think there's law on the books that forces companies to speak honestly? And that someone is going to enforce it? reply nitwit005 4 minutes agoparentprevIt's fairly likely they just confused about which candidate was which. Happens all the time. reply hilux 1 hour agoparentprevThis is extremely common. In fact, it is the rule at universities and government agencies and government contractors, who are required to post every job even when they have a preferred candidate, and many big tech companies do the same thing. It wouldn't matter if you named the company – literally every large organization has done this dozens or hundreds of times. reply tombert 1 hour agorootparentIf they had just blanket-declined me then I don't think I would have cared all that much, it's far from the first (or thousandth) job I've been declined for; what annoyed me is that they made me go through a stupid video seminar thing before they had even read my resume. They're going to waste two hours of my time and not even give me the courtesy of reading my resume? Pretty douchey, IMO. reply f1shy 38 minutes agorootparentMy policy is: no tests, no seminars, no long interviews. Max 2hs before there is a clear sign of real interest. I’ve seen enough people doing 2hs tests+ 3 2hs interviews + 2hs disertation showing what you can… at the end seems the probability of being hired is inversely proportional to the effort required. reply hilux 52 minutes agorootparentprevOh, I hear you. In some cases, they may be required to document how many candidates went through the entire process, to \"prove\" that it was genuinely competitive. reply mixmastamyk 54 minutes agorootparentprevSend a bill. reply pragma_x 1 hour agoparentprevWait, which newspaper did you say you work for again? > A major one. reply CretinDesAlpes 3 hours agoprevI've been on a career break / job search for about a year. I used to work in \"AI\" before it became fashionable, here are some observations of the tech job market: 1) There are so much BS jobs in BS companies it's hard to understand if those are even companies doing real thing (cf. David Graeber) 2) 80% of jobs in my field are about LLMs and technology no one understand or in companies that don't even know if they need it but are just following the trend 3) I've seen big and small companies posting over and over the same job ad. For example a big consulting group has been posting the exact same job for more than a year (really) on linkedin and elsewhere - each time there are more than 100+ applicants on linkedin. 4) Recruiters from 'serious' agencies told me it was the worst job market they know of 5) There is also a rise of fake recruitement agencies, it's very easy and quick to set up a page on Linkedin now with fake workers, fake images, fake jobs, etc. 6) The supply demand imbalance allows some small companies (startups) to ask for insane technical assignement that takes hours, which at the end looked like free consultancy. I had one that did not even provide feedback after a rejection, and when asked said \"because we don't\" 7) The increase of centralised platform such as Linkedin has increased competition. Everyone is applying to the same jobs, and many candidates uses AI to beat the HR platform. [This has been reported by FT - https://www.ft.com/content/1429fcb2-e0ef-4e47-b2b8-8bd225ac2... ]. Same problem as in the online dating market. 8) There is so much ghosting, that can happen at any stage of the process. Again, same problem as in the online dating market. reply azinman2 2 hours agoparent> 3) I've seen big and small companies posting over and over the same job ad. For example a big consulting group has been posting the exact same job for more than a year (really) on linkedin and elsewhere - each time there are more than 100+ applicants on linkedin. At the same time I’ve seen on the other end just endless unqualified applicants. Dozens and dozens of people who don’t pass a phone screening. Some jobs are tough to find the right applicant, or you’re looking in an area of high competition for a specific talent. reply CM30 1 hour agorootparentThe question then becomes \"how are applicants getting to the phone screening to begin with?\" Because from what I can tell, it seems like a complete toss up whether a qualified/unqualified applicant will even get that far, let alone how much further in the progress they'll get. I get the distinct feeling that most filtering systems are just dropping a lot of great candidates at the first hurdle, and then letting a bunch of unqualified ones through to the later rounds. reply _DeadFred_ 1 hour agorootparentprevThe issue with that response is that a random posting on LinkedIn isn't how you fill those positions though. Cookie cutter jobs sites are for cookie cutter jobs. reply nine_k 2 hours agoparentprev> did not even provide feedback after a rejection Years ago, when I was heavily involved in hiring, I asked our CTO whether we can provide feedback to rejected candidates, because it could benefit them. The CTO answered that it may become a legal quagmire if a candidate decides to sue due to perceived discrimination, or something, based on the feedback, even without any merit. The probability is very low but the downside is very bad. So we had to abstain from giving feedback :( reply CretinDesAlpes 1 hour agorootparentHow can you be discriminated on a technical level? Is there even a case of a candidate who sued a company at a technical stage we are aware of? This seems like a weak argument considering the hassle of time and potential legal fees, especially for someone who is looking for a job? Although I could understand why a candidate would try to bring a case like this in the US. Anyhow, it's not even the feedback the problem, it is that I have enough work experience to understand some of those startups seem to operate on a thin line between what is a technical assignment related directly to their core tech and getting free consultancy. The least they could provide to candidates who have involved time is what was expected. reply SoftTalker 5 minutes agorootparentprevYeah it's a variant on \"anything you say can be used against you.\" Any feedback you give can potentially be twisted to support some argument of unfair treatment. Even if it's frivolous, employers don't want to spend time dealing with that. So they just say nothing. reply y-curious 2 hours agoparentprevWhat is the point of a fake recruiting agency? I've heard claim of this but I wonder what the endgame is. Is it to harvest contacts? Scam people? Waste people's time? reply nitwit005 0 minutes agorootparentYou got the job, but you'll need to pay a $50 fee for a background check! And voila, they have stolen $50. reply hansvm 2 hours agorootparentprevOne of the endgames is scamming. One that's been around for a few years, seemingly getting bigger as time goes on, goes something like: 1. Slurp up contact information, focusing on people trying to break into a cushier lifestyle (data entry, entry level analysts, LLM evaluation in some specialized domain, ...). 2. Cold-contact them about being eligible for one of many possible remote jobs, with high hourly rates listed (something specify, like a \"salary\" of $38.51/hr). They'll either have a legitimate-at-first-glance looking website (usually the ownership has been transferred a few days prior, sometimes a few months, but one of the operators seemed to have a pool of domains they'd been letting age for years to throw you off a bit more), or they'll spoof the spelling of a real company when they text/email you. 3. Go through some form of hiring process. It's as little effort as they can put in on their end to keep the semblance of them being a real company. 4. Then this turns into normal check fraud. Your cushy remote job requires expensive office supplies, so they \"provide\" those. A local member of the gang delivers fake equipment in real boxes. You pay $5k or something out of the $7k fake check they previously sent, the rest supposedly being a signing bonus. AFAICT, many tens of thousands of people have gotten as far as step 4, and a decent fraction have fallen for the whole charade. If you're struggling to get a real job out of college and haven't seen what the normal interview process looks like, the confirmation bias (and desperation) combined with lack of real-world experience can cloud your judgement. There are tons of other endgames. Not all are quite that nefarious, but none are good. reply CretinDesAlpes 2 hours agorootparentprevMy bet is the collection and reselling of personal information, legally or illegally. Many (most?) people do put their real name, real address, real phone number and real email on their resume. You automate this on linkedin and can get a lot of CVs, I don't think this is a crazy idea. reply mywittyname 1 hour agorootparentThe same vendors that sell Linkedin data in bulk include this level of personal information (phones, personal/work emails, addresses). Perhaps this is how they mine the data they sell, but I think it's more likely they take use the information scraped from Linkedin and send it to other vendors to enrich it with personal information. reply rndmwlk 1 hour agoparentprev>1) There are so much BS jobs in BS companies it's hard to understand if those are even companies doing real thing (cf. David Graeber) This time last year I was searching for a new job, something I've done a few times at this point in my career, and this was such a pronounced thing that I had not experienced in any of my previous searches. It felt so strange, like walking through some funhouse where I had to be skeptical of every turn and decision lest I walk face first into a mirror. I eventually found a great job with a great team at a smaller company that I had some initial reservations about and even held back on applying from at first. Maybe it's just an additional symptom of (4), but if this is the future of finding employment it is a bleak one. reply OsrsNeedsf2P 3 hours agoprevAt one of my previous companies, I recall suggesting to my CEO that we open some job postings \"just in case\" the right person comes along. He candidly noted that we already have open job postings, and gave me access to the email they all went to. I saw over 3,000 applications made over the last 2-3 years. Tailored resumes. Cover letters. This wasn't some LinkedIn \"quick apply\", these were direct \"Fill out the form\" on our website. Not a single one of these applications got read. reply PittleyDunkin 2 hours agoparent> This wasn't some LinkedIn \"quick apply\", these were direct \"Fill out the form\" on our website. Not a single one of these applications got read. Surely this would basically immediately backfire as people would presume a rejection and not apply when you actually wanted to hire. Why would you do this? reply johnnyanmac 1 hour agorootparentIt's so common place that few are going to remember they applied to a specific company years ago to begin with. reply sangnoir 57 minutes agorootparentWith BS postings, low response rates, and the effect of having to apply to many jobs at once, how else can applicants manage their many applications but write things down? The last time I did ran the job search, I needed a spreadsheet to keep track of things. When a recruiter reaches out to me, I'm going to see if their company is in there, and what my notes say about my last experience with them. reply daseiner1 3 hours agoparentprevUnless I have an “in” and can directly send/hand a cover letter to the opening’s hiring manager, I can’t imagine ever writing a cover letter again. reply Glyptodon 50 minutes agorootparentI like writing them when I think there are aspects to why I'd be a good fit for the role that don't get revealed sufficiently by listing skills on a resume or I have questions that can save everyone a ton of time. It seems like people do at least read them before interviews most of the time so I think there's some value. reply jjice 2 hours agorootparentprevWhen I was in uni, I found that just having a boring cover letter drastically increased the odds of an interview (for internships and post grad work). I bet a lot of places just have a filter that adds you as a higher priority purely on the existence of a cover letter. I've never read a cover letter that I found valuable for hiring anyone, though. And I'm sure mine were never of any actual value either. reply daseiner1 2 hours agorootparentI like that insight and should I ever be back in the kafkaesque nightmare of blind online job applications, I will take your advice. As you point out, barring typographical mistakes a cover letter being too generic isn’t likely to result in a rejection, but not “checking the box” very well might. cheers reply sctb 1 hour agorootparentMay you never have to write one again, but if you do, it might be helpful to think of the cover letter as a reflective writing exercise. You might be able to gauge your level of interest in a particular role by how easy it is to write about, for example. Or it could just be some practice at communicating your strengths and abilities (this would definitely apply to me). IMO it's too disheartening to put effort into such personal writing without the awareness of some kind of direct value or benefit, since chances are it's going straight into the void. reply daseiner1 1 hour agorootparentNicely put. reply vlod 11 minutes agoparentprevI remember a post here where some recruitment manager (at a company) said \"Always write a cover letter, which is not generated by AI, otherwise you're an automatically trashed\". I rolled my eyes. Although this might be sound advice, it's not the reality of a lot of people looking for work. Yes, they might do this for the few months, but after what 6 months+ of no or canned responses (even though you have ALL the skills they want) it gets tiresome and you just say F-it, copy-paste a canned cover letter. reply f1shy 3 hours agoparentprevThis is making that company not look very good, is it?! reply chgs 2 hours agorootparentAwful company. They could post “here are our standard job roles, we aren’t actively hiring but if you’re the perfect match please tell us why”, which warns the prospective applicant. reply duxup 2 hours agorootparentprevDoesn't hurt them either I don't think. Nobody knows. It sucks because the whole job hunting system is borked. reply PittleyDunkin 2 hours agorootparent> Doesn't hurt them either I don't think. Well those are 3000 resumes that won't be resubmitted when you actually want to hire. Many of those resumes will belong to people who since found work. Weeding through that would be a nightmare, so you'd have to toss it and write it off as a loss. Or you could just post jobs when you're actually interested in hiring and turn it off when you have enough applications to process. Super interested candidates can always cold email. reply duxup 1 hour agorootparentThey don't care about those 3k and they could reach out. And maybe next round they do apply again. I sure don't remember when I last was applying who I applied for except some big names that ... yeah I'd submit it again if I was looking. I don't like the system, but I don't think they're hurt by it. reply chgs 2 hours agorootparentprevIf 500 people apply for a fake job and don’t get to an interview or personal response stage, then when they need a real job filling they’ve already wiped out a lot of applicants who won’t bother applying next time. reply duxup 2 hours agorootparentI doubt that's how it works out. Last time I was looking I applied so many places I can't remember most of them. reply grajaganDev 3 hours agorootparentprevIt is not making that company look very good. Enticing job seekers to waste their very precious time is not ethical. Edit: fix double negative. reply bbarnett 2 hours agorootparentJust an FYI.. the double negative means you said it makes the company look good. (I don't think you intended that) reply grajaganDev 1 hour agorootparentThank you - fixed it. reply fullshark 2 hours agorootparentprevWhat do you mean? They have open roles so they must be growing? Seems like a good investment. reply extr 2 hours agoprevI've found almost all my career positions through recruiters. I find it's about 100x more productive of an experience. You know the job exists because they're paying someone to fill it. You get to talk to someone on the phone about the job before you have to lift a finger. If you sound good on the phone, they just put you right through to the hiring manager/interview process, and also are materially invested in your success. Getting the formatting right on your resume is an afterthought. They'll give you an entire gameplan and tips on this company's specific process. People hate on LinkedIn but having a presentable profile and using the right keywords is worth it's weight in gold IMO. Even if it doesn't work out, they'll keep you in their rolodex and hit you up for jobs long into the future. reply johnnyanmac 1 hour agoparentMain issue is that recruiters can get every bit as bougy as applicants can get when the market sways in their favor. So in a market like this, you may have less than a 10% response rare from messaging recruiters. Whereas 2021-2022 you'd almost always at least get a reply when you messaged a human. reply extr 20 minutes agorootparentI never message recruiters cold. Only wait for them to message me, or hit up recruiters I have existing relationship with. reply mywittyname 1 hour agoparentprevSame here, but have you looked for a position in the past 2 years? It's dramatically worse than I've experienced in my 20 years as a dev. I only ever apply to jobs that I know I'm qualified for and know that I can demonstrate it, so my application -> offer ratio was historically pretty high. In my last job search, I sent out 99% of the applications I've ever sent out in my career. The tech job market enshitified rather quickly. reply ChrisMarshallNY 2 hours agoprev> The job market has become more soul-crushing than ever. I have often stated that the fact that I was basically evicted from the job market was one of the best things that ever happened to me (I didn't think so, at the time it was happening), and every time I read something like this, it reinforces that. But I was one of the fairly rare (it seems) people that could afford to have that happen. My heart goes out to the folks that have to endure this stuff. One of the saddest things, is that really good workers, that would take their job seriously, and be excellent employees, are being knocked out of the game, and the unproductive, disloyal, rapacious sharks that have learned to game the system, are taking all the fish food. reply WarOnPrivacy 17 minutes agoprevThe headline could also apply to the 1990s. I was an employment counselor for a non-profit for a few years. I collected employment listings from multiple sources (Bureau of Labor was a big one) and printed+sorted them to help job seekers. I found a high percentage of distinct jobs that were endlessly listed. If I sent qualified applicants after them, they invariably never got a response. That was just the ghost listings. Another large chunk were problematic for reasons that had nothing to do with applicant qualifications. Maybe 2 listings in 5 were reasonable and competent efforts to find workers. reply robcohen 3 hours agoprevThis is a spam problem. Spam problems are easily solved by simply charging for attention. Job postings should pay me to view them, and I should pay job postings to apply to them. The only reason why ghost postings exist is because the marginal cost to the company is so incredibly low to do it. In demand people should get paid for their attention. What I don't understand is why are there no systems that actually implement this? Most likely because the user education problem of cryptocurrency wallets and the various UI/UX issues it presents, but there's no mainstream apps that I can think of that actually try this. Seems like it would work in dating apps, in advertising, in CRMs, in social networks of all types. Why hasn't it been done? My guess is because we've only solved half of the problem with crypto. We have the cheap value exchange, but we don't have identity figured out quite yet. reply ryanianian 3 hours agoparentRecruiters and agents have been solving this problem for years. Firms hire a recruiter for jobs that they actively want to fill. Applicants hire a job agent. Those two meet. Very little incentive for spam in this relationship. The problem, of course, is mismatched incentives for the middlemen versus the clients, particularly at the margins. Similar to real-estate brokers. They may be effective in many ways, but they are looking for pareto-efficiency, where they get you 80% of the match (or 80% of the pay) or whatever for 20% of their effort. It's hard to imagine any incentive scheme between buyers (hiring managers) and sellers (applicants) that wouldn' be subject to the same market mechanics, even if at lesser scales when done through more automated means. I don't think crypto really has anything to do this. reply airstrike 2 hours agorootparentThe power dynamics between employee and employer are such that the employer ought to foot the bill for that on their own. Candidates really shouldn't have to go to an agent to find a job. The employer doesn't need to hire an external recruiter either. They just need an HR team that actually does anything other than protecting against liabilities and aggressively managing labor costs down. Most of HR is a practical joke of questionable taste. reply robcohen 2 hours agorootparentprevYes, you can absolutely add a middle man to sort through the spam for you, and that \"solves\" the problem in the sense that you are trading money for time. It's no different than paying for a personal assistant to collect your mail for you and pass along the valuable stuff. That said, it's incredibly inefficient and most people, for most interactions, cannot hire a third party to handle those interactions for them. So no, I don't think adding layers of middle men really solves the problem for most people. reply hansvm 2 hours agorootparent> \"solves\" ... money for time The proposal was two middlemen. It's just an inefficient way to, as you (or somebody up the chain) said, charge for attention to reduce spam. Since the middlemen are being paid, most spammers won't hire them. > incredibly inefficient In practice, yes. In theory, it could be fantastic. Imagine, as a simple example, you have two early-career backend developers. They could each do the same search, or a middleman could do one search and share the highlights with each developer. The fact that you have overlapping demands and information opens up the potential for the work to be amortized, even if you're not adding any value as a middleman other than trading time for money. reply numpad0 1 hour agorootparentprevI've heard that one of tricks recruiting agents use is to maximize mismatch without breaking the illusion of a perfect match, so that victim companies has to come back as often as possible, each time rewarding them with commissions. Value alignment is definitely going to be a problem. reply pjc50 2 hours agorootparentprevUnfortunately there are good and bad agents out there, and the bad ones absolutely do have an incentive to spam. I remember one place I worked at maintained a blacklist of bad recruitment firms. reply lazide 3 hours agorootparentprevI’ve never heard of, or met, a job agent. More info? reply airstrike 2 hours agorootparentYou ask someone to land you interviews and, if you get hired, you pay them a fee. Usually some (fat) percentage of your first couple paychecks. reply lazide 29 minutes agorootparentI was asking for specific people. reply NAHWheatCracker 2 hours agoparentprevMicropayment systems don't work well because there are free options. Convincing people to pay any amount of money is incredibly hard. Would micropayments result higher quality? Maybe, but until you have a critical mass no one can really tell. Free options are more likely reach critical mass and dominate. Paid options thus die off, starved of attention. reply johnnyanmac 1 hour agorootparentAlso, free applications systems are so common that I'd simply see any system that I, the applicant, needs to pay for as a scam. Much more different than a paid forum or news site. I pay $10 for those and I get exactly what on the site, even if the news updates slowly or the forum is empty. If I had to pay $100 for 10 applications and still get ghosted or auto rejected, I don't know what I'd do. That's just theft at that point.And the incentives for recruitment are just perverse at that point. Don't hire, just make a good job app. reply ceroxylon 1 hour agorootparentprevIt would be worth it to build a highly refined and moderated \"free tier\", with a paid option that is even better. From what I noticed during my last job hunt, all the big platforms could vet their submissions better. reply numpad0 1 hour agoparentprevI thought Indeed charge companies for posting and per applicant clicks? That combined with near 100% university graduate capture is what Japanese job market is like, where their current owner's corporate HQ resides. In that environment, the agency maximizes clicks and matches because that earns them most. Applicants are lured to maximize numbers of applications and qualifications(and failed matches), hiring companies go FOMO mode, hype up themselves and tighten up requirements. Everyone's paperclipping everything and producing clinically depressed graduates in big batches. It's a huge resource sink. Then of course fake posting problem isn't even remotely gets solved because the power structure builds up in the background in uncaptured dimensions, parallel to the system. You wouldn't want that. reply dennis_jeeves2 33 minutes agoparentprev>but we don't have identity figured out quite yet Can you explain further? ( btw, your overall analysis is spot on) reply shultays 3 hours agoparentprev(paypal me 0.1$ to see this reply) reply airstrike 2 hours agorootparentI really wish that's how (a subset of) the internet worked. Not for replies, but for quality website access. Think newspapers and other primary sources of information. Fill up your browser tank and go visit these websites. The site then gets paid per view, or per duration of stay. Details are tricky though. reply seabass-labrax 1 hour agorootparentIn my opinion a big barrier to the success of such systems is that newspapers often aren't primary sources. Most outsource the reporting to press agencies and (increasingly) to social media. Press agencies usually do sell individual stories with primary reporting, but not at the prices you and I can afford. For mainstream press though, is it worth the pennies of a microtransaction to read someone's re-hashing of public records and social media posts? That is very much dependent on both the reader's personal expertise and the author's, and if they are mismatched the article becomes worthless to the reader. An article explaining what HN is would be illuminating to many, but entirely unworthy even of pennies to you and I. reply johnnyanmac 1 hour agorootparentprevMorality aside, the logistics of this means you cannot literally PayPal someone 10 cents. The processing cost isn't worth transferring such a small amount. So the answer to this is to pay $5 and be able to see 50 replies. But what if you're unsure you want to even see that many replies? It's now a steep cost to consider. reply immibis 2 hours agorootparentprevOther way around. You should paypal them $0.01 if your reply is worth viewing. But Hacker News already has a cost to posting replies: you can only post a few (I think 5 replies every 4 hours) and although you can make more accounts, there's a limit to that too. So I know this was one of your top 5 in this 4-hour period. reply scarface_74 2 hours agorootparentYour account is being rate limited because your replies were repeatedly against the “rules”. Been there done that reply esafak 2 hours agorootparentprevWho would say their reply is not worth viewing? reply danaris 2 hours agoparentprevIf we assume that a posting costs $1 in either direction, the $100 cost to a company of any significant size of posting a single job to 100 sites is pretty negligible. On the other hand, to someone who has no job, paying $100 to apply to 100 jobs might be pretty harsh—and there isn't the remotest guarantee that this would actually result in getting contacted, let alone getting a job. Going one step further, paying that kind of money to apply also means you'd be expected to have a credit card or something similar. At the very least a bank account. And someone who's got excellent qualifications, but had a medical disaster cost them their previous job and home, and has been spending time on the streets, is going to have a very hard time maintaining a bank account or obtaining a credit card without an income. Basically, any time you make a proposal to \"solve\" the problems with hiring/job searching, you need to ask yourself, \"Is this going to nontrivially exacerbate existing class divides?\" If the answer is \"yes\", that's a) probably why it hasn't been done already, and b) why anyone with any compassion (or understanding of the long-term consequences of inequality in society) should reject such a solution. reply seabass-labrax 1 hour agorootparent> someone who... has been spending time on the streets, is going to have a very hard time maintaining a bank account or obtaining a credit card without an income. Slightly tangential to your main point, but in this day and age electronic transfers are money; cash is in effect just a fallback option for situations where there's no connection to the Internet. I believe that, in the absence of central bank digital currency, banks should be required to have a process for issuing current accounts to homeless people (albeit not necessarily with credit, just like customers who do have fixed homes). That measure alone would immediately fix a range of issues that homeless people face, wouldn't it? reply danaris 48 minutes agorootparentIt absolutely would, as would Postal Banking, which there's already a movement afoot to bring back(? I think it was around before? I'm not super up on it). reply kthejoker2 2 hours agorootparentprevI sympathize but totally disagree, if the $1 I paid guarantees: A) it is an actual job, with intent to hire now B) I will get an actual response, from a human, within a few days Then $100 is completely worth the time saved vs applying to ghost jobs. reply johnnyanmac 1 hour agorootparentThe issue is thst we both know those won't happen. Even if it's just scam shops that abuse it and everyone else plays the honor code. Rotten apples and all that. reply danaris 2 hours agorootparentprevThe problem is, as I noted, spending $100 to post a completely bogus job 100 times is basically nothing to even a medium-sized company. The asymmetry in power & wealth means that if you want the $1 spent by a job-seeker to even come close to the guarantees you describe, you'll probably need to make the company pay $100 per posting or more. And that would effectively require some pretty widespread and strictly-enforced regulation/legislation. If you're going to have to get that just for this middleman solution, why not go all the way and have the regulation mandate that any job that a company posts has to be real, with full intent to hire, and every single applicant must get a timely, non-canned response? reply Aurornis 55 minutes agoprevThis headline was carefully written to trigger confirmation bias, but the phrase “or never filled” is doing a lot of heavy lifting. Most mid-sized companies where I’ve been a hiring manager haven’t had a 1:1 relationship between job postings and hires. Some times we’d post 1 job posting but hire 2-3 people out of it. Other times we’d post 2 or 3 job listings at different levels for 1 headcount because we were open to candidates of wide skill range but a single wide-range posting tends to turn off more experienced candidates. We’ve had situations where an internal candidate expresses interest in a public job posting, so we take it down without filling it and replace it with a different posting for their backfill. So looking back, several of my job postings would be considered “fake or never filled” despite the fact that we were honestly hiring and filling roles. This article and the WSJ article it sources from feel like journalists picking up on a social media trend and working backward to provide fodder for it. There is no 1:1 relationship between a job posting and a hire at many companies, so using job posting data to draw conclusions like this isn’t good logic. It probably feels like vindication to people who are tired of applying to jobs, though. reply hunglee2 3 hours agoprevThe outrage from job seekers is justified but Gizmodo doesn't help matters by categorising fraud (fake jobs) with failure (never filled). Hiring is hard, as anyone who has ever done it will attest, and very many vacancies opened in good faith are not filled for a variety of reasons - budget pulled, hiring manager won't make a decision, internal candidate appears at late stage etc. We also need to draw a distinction between employers posting jobs directly vs 3rd party agencies posting jobs for the company's they represent, or purport to represent. There is a disincentive for the former to post 'fake jobs' - who wants to deal with the applicant flow, but an incentive for the latter to do so - harvest resume's, build a database. Anyways. My point is, there _is_ a problem but mainstream magazine treatment like this from Gizmodo serves to add smoke when there's already a fire reply NVHacker 3 hours agoparentThe way I read it, Gizmodo cannot tell whether those jobs are fake or just never filled. How could anyone tell from outside ? The visible fact is that no-one is hired for those jobs. reply spandrew 3 hours agoparentprevDisagree. If you post a job then reneg on it that still leaves folks out in the cold who are, in earnest, looking for work. Mistakes happen, and I don't blame hiring managers for the shifting financial landscapes they often have to face. But that job wasn't solid enough to count as a real position. Lump them together. reply bdcravens 3 hours agorootparentThere are job postings out there that are solid, but where the company is unwilling to pay the recruiter markup, and hiring organically just doesn't result in solid candidates. Not every company hiring is a Fortune 500 or Big Tech company looking to get over on the world. Many are smaller companies looking to fill roles but may be lacking in the bandwidth or resources to lower expectations and either pay well over market or hire downmarket and train extensively. To say these companies are hiring fraudulently is unfair. reply johnnyanmac 1 hour agorootparent>hiring organically just doesn't result in solid candidates. If you get one bad hire, it's probably on them If you get 20 bad hires, it's probably on the company. At some point, no matter the size, people really need to look at themselves and say if they are really trying to enhance their shop and let talent succeed, or if they are a churn shop and don't deserve solid candidates to begin with. reply bdcravens 1 hour agorootparentI'm not talking about hires, but candidates. Not all markets are awash in talent in every stack. reply johnnyanmac 56 minutes agorootparentIt's the same concept. Even with niche tech. If you can't hire a good candidate in a buyers market, and repeatedly get bad hires, what's your interview pipeline doing? Paying too low, getting reqs wrong in a game of telephone? Hiring through nepotism instead of merit? I'm just a bit tired of the \"but we need to avoid bad hires\" narrative. Especially since a certain blundermouth more or less said the quiet part out loud for the intentions many have with that. It made sense in 2022, but is that really an issue in 2025? If you can't \"find solid candidates\" now, how did you Faire in non-bust markets? reply lazide 3 hours agorootparentprevA posting which was never intended to be filled is still different than one that was intended to be filled, but never actually happened. Good luck telling them apart however. If you make it so every posting has to be filled or it’s ‘fraud’, it will be an even bigger mess. reply ryandrake 2 hours agorootparentIt's even harder to tell them apart in a bear market where the job market is stacked in favor of employers (for the moment). With the current glut of laid off engineering talent in the hiring pool, if an employer cannot find a candidate, they are not really serious about hiring. Yes, there's more filtering involved now, but you can't say that the candidates don't exist. reply johnnyanmac 1 hour agorootparentprevEvery posting needs to have an honest attempt to fill it. I don't know the exact numbers, but if there 1000 applicants per posting and you end up reposting your job 4 times, there's clearly something amiss.this overlap of 1-4000 applications and not one of them are worth a call? Even if we accept 90% is spam, that's still hundreds of candidates in a \"recruiters market\" being passed over. reply kylebenzle 3 hours agorootparentprevMaybe, but it's too hard to distinguish between the jobs that were posted with intention to not be filled and jobs that were posted with intention to be filled but through other circumstances weren't. So the distinction is moot. It's a lot like this website. It used to be pretty obvious which comments were trolls and which are real people but more and more the people have gotten dumber and the trolls gotten smarter so it's almost impossible to tell the difference between maliciousness and stupidity and for the rest of us it doesn't really matter one way or the other. A person wasting our time is a person wasting our time, the intentions aren't important. reply Bjartr 3 hours agorootparent> So the distinction is moot. From the perspective of an applicant's emotional response, sure, but it's absolutely relevant in order to have a conversation about how to solve it since the different causes may need different approaches, or may occur in sufficiently differing rates to influence which should be addressed first. reply grajaganDev 2 hours agorootparentThe distinction is also moot from perspective of an individuals's time being cavalierly wasted by a large corporation. reply lazide 2 hours agorootparentJust wait until you start thinking about dating. But if we’re claiming fraud, either way the intent is actually the deciding factor. You can’t commit fraud without a guilty mind (mens rea)- at least in any jurisdiction I’m aware of. reply johnnyanmac 1 hour agorootparentModern dating sucks, but at least half the time there's a real human on the other side that isn't a corporation trying to sell me something. And yes, that's what audits are for. To deduce intent by investigating from within, something we could never do. reply lazide 30 minutes agorootparentnah, fake profiles are a huge problem. depending on the site, it could easily be 1 to 5 real:fake or more. reply s1artibartfast 3 hours agorootparentprevdifferent is a matter of use case. The difference doesn't matter to the applicant. It probably does if you propose the death penalty for posting fake listings. reply johnnyanmac 1 hour agorootparentA fine large enough to make bad job postings (genuine or not) unprofitable is fine. We don't need reducto ad absurdum here. Just make businesses put thought into their postings and not let someone who has no idea of the qualifications right them up themselves. reply s1artibartfast 52 minutes agorootparentThere is nothing wrong with reductor ad absurdum to make a point about dependency and categories. It is the primary use case. I think there are a million practical challenges to implementing a fine. I wonder if there is enough incentives to draw employers to a verified list service. reply johnnyanmac 1 hour agoparentprevIf you get hundreds of apps and you can't get a single qualified candidate, you either have a horribly inefficient recruiting system or your job needs are so specific that general job boards won't help you anyway. If you have years of inefficiencies happening without being addressed, at what point to we just call it fraud instead? Or possibly you highly overestimate your job needs vs. The requirements posted. Which is endemic of the above reasons anyway. reply reptation 3 hours agoparentprevSure, hiring is hard but the factors you mention are rare, and teams are extremely motivated to fill vacancies. reply derektank 3 hours agorootparentTeams are also strongly motivated to not hire a bad team member that drags down morale and wastes resources. I want to say this is more true in government hiring, where it's difficult to fire people, but I've seen private companies hold out for a long time until they find someone with the right combination of cultural fit and technical skills. reply spratzt 2 hours agorootparentIt’s extraordinary how frequently companies discuss the cost of a bad hire and never consider the opportunity cost of a no-hire. Companies that keep waiting for Mr. Right are really saying that the opportunity cost of not completing their project is very low. In other words it’s not really that important at all. reply danaris 2 hours agorootparentOn the contrary. \"Not completing the project\" is not an option—if they don't hire someone to fill a vacancy on the team, the rest of the team will just be expected to work extra hours to keep up. Oh, not with overtime—you're salaried, remember? (Alternate version: Oh, no, you can't actually log the extra hours; we don't have the budget for overtime, and I, the manager, can't be seen asking for more money, or it would affect my bonus!) And you'd better step up and work those hours. You want to be seen as a team player, right? reply johnnyanmac 1 hour agorootparent>Not completing the project\" is not an option—if they don't hire someone to fill a vacancy on the team, the rest of the team will just be expected to work extra hours to keep up. And that's the opportunity cost we don't talk about. The cost isn't \"we slow down on a project from a bad hire\". It's \"demoralize/burned out engineers quit to a point where the deadline is impossible to reach\". You can't force overtime to engineers that leave and take their institutional knowledge with them There's also a lot of fake job postings as a sort of carrot to overworked engineers that \"promise more help is coming\". Which is just as ingenuous to existing employees as it is to applicants. reply jstummbillig 43 minutes agoprevCompanies dirty secret: Job postings are an invaluable signal generator for companies. Knowing how much demand there is for various positions in your company is super helpful to drive business decisions. And unfortunately the company loses most of the signal when they are candid about just gathering potential applicants (because people will not apply and you know a lot less about their interest and potential) Not defending being uncandid, just a heads-up to be realistic about what's going on here. Unless it's made outright illegal, just assume it's happening all the time, because of how fantastic the upside is and how cheap it is to do. The amount of work the company has to invests in screening incoming requests is entirely variable and scales to 0 if they really don't want to hire right now. reply beezlebroxxxxxx 33 minutes agoparentMost companies, if not nearly all of them, are just really bad at hiring above \"entry-level\" in general. The practice of pushing hiring through HR teams and recruiters often leads to the job posting being weird catch-all abstractions because a huge funnel brings in lots of resumes, which makes the HR teams look busy. Really, postings should be astoundingly specific --- literally, \"This is exactly what we are looking for and the problem we want to solve. Prove to us you can solve that problem.\" Generalist hiring teams are usually unable to get that specific, which is why personal references and recommendations are very valuable. The number of applicants you get should be a good sign that your posting is too general or just right. Positions above the junior level should have significantly less applicants. If not, then you can probably simply hire a junior level. reply nextworddev 12 minutes agorootparentCan confirm. 90% of L7, L8 hires at AWS between 2021 and 2022 flopped. reply juujian 3 hours agoprevThat would actually be a surprisingly low figure as far as I'm concerned. reply pelagicAustral 3 hours agoparentI'm thinking exactly the same. Feel like it's more like 3 in 5, if not 4 in 5. I recently commented on another thread about how I managed 2 interviews and 1 offer out of ~500 applications. Which is kind of telling, since it only took 2 actual interviews to get another job (alas for less money that I make right now anyway)... If the jobs were real, it should be far easier to get them. reply ryandrake 2 hours agorootparentI remember a few years ago I posted that throughout my career, during market ups and downs, my average application:interview:offer ratio was around 100:10:1 and half of HN thought I was exaggerating, or there was something wrong with my interviewing, or that I was shotgunning my resume, and so on. We've got an industry full of young employees who are seeing the first bear market of their lives. 500:x:1 doesn't seem outrageous at all in a down market. The 2:1 interview:offer ratio is actually outstanding, especially where the industry is today. reply johnnyanmac 1 hour agorootparentI guess as a \"newer employee\" (8 years now) I see that and say \"yeah, that was pretty much my first job search. Maybe a bit better reply rate\". I may not have been applying for jobs in 2008, but I feel this bust isn't just about low hiring. And that's what makes it all the worse. For reference, these 8 years and 3 jobs later, I'm probably around 300-20-0. Or 1 if you the count the part time freelancing that just showed up out of the blue. But I didn't even apply for that. reply Cerium 3 hours agorootparentprevIf you get an interview you are already on a short list. The process I usually see is 100's of applications -> screening by recruiter and hiring manager -> phone screen 10-20 -> coding challenge 3-7 -> onsite 2-3 -> hire 1. reply convolvatron 3 hours agorootparentprevThe part I don’t get is that 6 months later I get responses to applications. I’ve talked to recruiters and the picture they paint is hundreds or thousands of resumes in the inbox. They keep shuffling their search criteria and sometimes someone interesting pops out. That doesn’t entirely make sense to me, but something is clearly quite broken, and it seems to be as much due to incompetence as fraud reply daseiner1 3 hours agorootparentI’ll never forget getting a boilerplate rejection email from Lockheed Martin 13 months after I applied for an internship for the upcoming summer. reply bbarnett 2 hours agorootparentI'll try to upstage that! 20+ years ago I applied, and interviewed for a Federal Gov of Canada job. 18 months later they called me to tell me I got the job. I'd been at another job for 16 months! Glad I didn't take it. Government and traditional big corp are very stodgy, slow to change. reply ryandrake 2 hours agorootparentThis one's not as bad but still amusing: I applied to a well-known telecom company that rhymes with \"May Pee and Pee\" and got to the final onsite interview, after which they ghosted me. Afterwards, I did the whole round of interviews at a different company, got hired, moved my family across the country, and got established in that new job. A few months later, I got an E-mail from the telecom company saying \"We would like to interview you one last time. Please let us know when you are free.\" LOL reply Clubber 3 hours agorootparentprev>out of ~500 applications Yea, the process is eating itself. Recruiters automate screening and applications automate submitting, so there is so much noise, it's difficult. I'm not saying there aren't ghost jobs, I'm just saying an already arduous process is even more so with automation being leveraged on both sides. reply ajmurmann 2 hours agoparentprevIt seems like these numbers are purely based on Greenhouse. I bet that many companies use less sophisticated approaches like just sending resumes to a mailbox and those have higher fake rates. reply Scoundreller 7 minutes agoprevAnother 2 in 5 are real, but they’re hoping to replace an existing employee at a lower rate. No net new job but net lower income. reply ethin 1 hour agoprevIt wouldn't surprise me if this was a significant under-count. I've been applying for jobs for, what, 3-4 years now, both when I was in Uni and after. I don't even know how many job applications I've submitted but I think I've gotten maybe 10-15 interviews at most? I have of course gotten the typical advice: \"Build your network\", \"Submit a cover letter\", blah blah blah, but the first bit is completely useless to me (I don't have the finances to go to conferences for example) and I've tried the second bit and haven't gotten anywhere. I've been told to tailor my resume but... Yeah, I'm not doing that when I'm supposed to be submitting hundreds of applications per day or something. Honestly it's hard to muster up the motivation now to apply for jobs instead of working on open-source projects and (maybe) posting something freelance-ish on fiver or something because at least with open-source projects I'll get somewhere and it's something I enjoy; with job hunting and all the automation at play, and with even more things getting automated, it's a lot harder to answer the question of \"why should I even bother\" when companies are slashing headcount like crazy and aren't fined heavily by these platforms for posting ghost jobs and wasting my time (or some equally as harsh punishment that makes them actually pay attention). I still apply occasionally, but given how horrible the market is I know my job application count has significantly fallen. I just hope the market turns around and we see some huge crackdowns on all this automation because it's massively disincentivizing applicants (after all, why apply when you can only submit an application every 10-30 seconds while a bunch of people can submit 10000 applications per minute?). reply Glyptodon 47 minutes agoparentIf you're submitting a hundred applications a day, you're doing it wrong. You should get better results aiming for just a few a day, but each tailored. (Though obviously it's just not a great time right now, I'd argue not being bot-fodder and obvious chaff is extra worth it if any human ever does actually look.) reply grajaganDev 4 hours agoprevThis is clearly fraud and needs to stop. Companies behaving like this demand regulation. Instead of whining about regulation, read the room and don't bring it on yourselves. reply ricciardo 1 hour agoprevSeriously contemplating if it is even worth applying in this type of job market. Being young, would it not be more beneficial to just contribute to Open Source projects in which my actual passion for the field comes from and additionally find outside work to just get by? I guess it all comes down to an individual's ambitions and goals in life, but seeing some of my colleagues and friends do nothing but apply to jobs for a straight year seems extremely unfulfilling (mind you this is a perspective of a new-grad in CS). reply InkCanon 1 hour agoparentI have similar thoughts. I'd say one big upshot of working in tech was they formed very high talent densities during their peak in the 2010s, so you could learn a lot. But now I'm not so sure. Plus it's a circus getting hired as a fresh grad. I'm largely thinking of masters or PhD - in the right place you get that talent density too. reply fsndz 8 minutes agoprevThe ratio is probably 4/5 for YC Startups reply taeric 2 hours agoprevThere is a big gulf between \"fake\" and \"never filled\" that I don't like being washed here. Specifically, there are plenty of reasons you might have a position not get filled that are not nefarious. Could be an aspirational. Could be a company that is so under water that they can't manage a hiring pipeline. Could be one that isn't under water, but doesn't know how to manage a hiring pipeline. Could have been overcome by other events. Plenty of options. Yes, I'm sure there is some fraud. I'd love to see data that went into that detail. I'm assuming it is rather lower than 1 in 5. reply johnnyanmac 1 hour agoparentIf companies were as honest about \"low priority\" evergreen work over the constant need help immediately, that may be acceptable. But I've never see anyone say that in a job posting. If you're indistinguishable from the behavior of a fraudster, that still reflects poorly and has the same results on applicants. (well, okay. Actually honest. How many of those \"urgent\" postings eve felt urgent?) reply Joel_Mckay 44 minutes agoparentprevIn general, some people want ghost-workers for working visa scams. i.e. some desperate individuals pay to not even work in a country to get around immigration rules. This scam was outed by some undercover East Indian journalists. Its gross because cons exploit people, and suppress domestic economic reality by bidding down wage rates. Nothing was done about this by the way... nothing... =3 reply matchagaucho 2 hours agoprevI've noticed sites like Indeed are still showing job listings scraped from our website 5 years ago. I've not chased down every scraper and submitted a remove request. But I can easily see how 20%+ of job listings are dead-ends. reply rdtsc 1 hour agoprev> actually a corporate strategy designed to make the businesses posting them seem like they’re growing Assume these companies don't have morals (that should be the default, btw) and ask yourself why wouldn't they generate 1000s of open job postings? Especially if many steps in the initial process can be automated. This makes them look like they are growing, and maybe their filter might find some rare great candidate and they'll find an opening for them. All upsides and almost no downsides. One downside is having to manage applications. But that can be outsourced or automated. It's immoral, disheartening to potential job seekers and skews job number stats, but that means nothing unless it's illegal. Once they start fearing of getting in legal trouble, they'll keep doing the same. reply lambdaone 3 hours agoprevOne in five seems to be an under-estimate. Based on my experience of Upwork, at least 50% would be a better estimate. reply iknownthing 2 hours agoprevI worked at a company that created fake job postings for H1B reasons. reply aprilthird2021 2 hours agoparentThis is for PERM, not H1B. Many companies did and still do this. Imo, the concept of PERM is flawed, which causes companies to do this stuff. Some have had to settle with the gov't and can no longer do this (Meta). Also, the jobs are not fake, they are labor market test jobs, designed to show that no citizen meets the job requirements thus validating a green card for the H1B visa holder. They are \"fake\" in that they are designed so no one applies for or gets the job. Imo, labor market test should be part of the visa granting process, not the naturalization. reply dzdt 10 minutes agorootparentI have been required to create such fake job postings. From the line manager perspective, how it looks is you have a colleague who has been working with you for several years who is on a H1B visa. They want to get a green card and become a permanent resident. To support this, we are required to post a fake job ad for their position, and invent a reason to reject any US citizens who apply for the position. (Non-US applications are ignored.) Our legal advice was that the job posting had to be contain only legitimate requirements for the role, so it could not be highly tailored to only match the resume of the employee seeking PERM status. The result was phone screen interviews were required to reject 8-10 on-paper-potentially-qualified US applicants for the fake position. This is for a highly specialized area within finance, where in real hiring there is an immense effort to find the strongest candidates regardless of nationality. In hindsight I am confident that earlier in my career I had applied to at least one such fake role. One not-well-known advantage of working with a recruiter as a job seeker in such a field is the recruiter will have back-channel information to know to ignore such fake job postings. reply RainyDayTmrw 2 hours agoprevIn trading, spoofing[1] is placing insincere orders to generate a signal, and presumably influence other participants' behavior, without an intention of actually having those orders filled. Bad actors spoof trades because it works. Spoofing is illegal, and rightly so, although enforcement may be a bit lax. I guess, we're now seeing the rise of spoofing in job postings. I, for one, find it quite tiring. I think there's a parallel. Bad actors spoof job postings because it works. What can we do to make it less effective or less worthwhile? [1]: https://en.wikipedia.org/wiki/Spoofing_(finance) reply esafak 2 hours agoparentJob posting boards can punish them if they detect them as being spoofed through response rates. reply johnnyanmac 1 hour agorootparentCan. Won't. If trading has lax enforcement where this can cost people millions, why would a job board getting paid to post fake jobs care? reply neom 1 hour agoprevI'm starting to wonder if this is something that could/should be regulated...? I can't think of a great reason for allowing this from industry. It seems least reasonable you could be required to go back and remove postings when the position is filled or no longer available?? reply johnnyanmac 1 hour agoparentIt absolutely should be regulated. Especially since there's so many ways companies exploit this for a variety of factors. I can't think of one benefit to applicants. Wastes their time, the increasingly AI-submitted rejections are useless noise instead of feedback on how to improve, and the rise of \"video interviews\" just give more data than necessary to a company without ever needing to send a human to talk to them. The application market needs an entire overhaul. reply CM30 1 hour agoprevMakes sense. Seen an awful lot of jobs on these sites come up time and time again, and it always felt rather suspicious how often that happened. If a job can't be filled within a year or three, that's a pretty good sign that the company isn't particularly interested in filling it. As you may expect, they also tend to be the jobs that don't even respond with a rejection or anything when people apply to them, and where anything submitted seemingly just vanishes into the ether. reply goredsox 57 minutes agoprevThere are companies that scrape linkedin job postings for skills based workforce analytics. These jobs reports are then sent to higher ed institutions to inform classes. So manipulating these markets can signal to higher ed what skills they would like to devalue in the future reply tiffanyh 30 minutes agoprevDoes cross posted job listing mess up this data? Because it's common for the same job to be listed on multiple job sites. reply woofcat 56 minutes agoprevYou mean Aha! isn't hiring 100 people in 100 locations world wide at all times? reply Glyptodon 46 minutes agoparentThe one person I know who worked there was very disillusioned. reply eterm 1 hour agoprevI got an email from LinkedIn prompting me to \"unsubscribe from job alertbecause you haven't viewed it in 3 months\". Indeed I haven't, because every week they email me the same list of the same jobs that have been listed since the first week I signed up. And also because setting \"remote\" effectively turns off the radius, even though I ideally want a job that is remote but also local if possible. reply indiantinker 1 hour agoprevI have been applying to this job at major brick making toy company for the past 3-4 years that is super dope. But i never get it and neither does anyone else. reply ge96 3 hours agoprevI forgot to make a meme about it but I still get these \"We're sorry we went with someone else\" months later from jobs I applied to but it's alright I have a job now. The joke of the meme is I feel ashamed/disappointed but I forget I'm fine. reply siliconc0w 39 minutes agoprevGood opportunity for a fakejobs.fyi site that names and shames companies that do this. Send in perfect resumes that 100% match the job req with 10+ years of experience and see which get a response. This of course leads to a tragedy of the commons but that is what unregulated capitalism demands. reply redleggedfrog 2 hours agoprevMakes me want to use an LLM to apply for a gajillion jobs. See how they like their own medicine. reply smel 2 hours agoprevI would say 4 out of 5 to be honest reply f1shy 3 hours agoprevI have seen that happening inside a company (big one). There is an internal job market, and I would say the ratio is about 20% or more fake. From every 20 applications to postings that seem like a copy of my resume, I get 5 replies (the rest is black hole, or come a reply 10 months later) from the replies, eventually 2 interviews. reply johnnyanmac 1 hour agoparentWeird, I really don't see the reason an internal job board does this. They know all the people and their experiences. Is this just some hr compliance so they can search outwards? reply maybeculdbeyeah 1 hour agoprevMaybe they are there to fake a good faith effort to justify their H1B hires. reply selimthegrim 2 hours agoprevI applied to some New York City series B start up with a Director literally looking over my shoulder after she assured me the job postings weren’t fake. Plot twist: they were fake they just weren’t in her department so she didn’t know and the only job they were really hiring for according to LinkedIn was an Azure contractor for $60 an hour reply Havoc 3 hours agoprevThat’s better than I would have guessed frankly. Internet is making it sound like 4 out of 5 reply nsagent 3 hours agoparentWell, my recruiter callback ratio is likely 1 out of 5, despite having a very VERY niche profile: a PhD focused on NLP for creative text generation, especially in video games, and a prior career as a game developer. Needless to say, I've only focused on roles that fit that narrow profile. One of the recruiters that contacted me didn't even know I worked in games, despite it making up the bulk of my work experience (including as a lead developer). Considering how closely I match this narrow profile, and the number of people that likely do, it's weird how low my callback ratio has been. reply sumtechguy 2 hours agorootparent> One of the recruiters that contacted me didn't even know I worked in games I get that all the time with my setup. \"you look like a good fit and have lots of experience for XYZ tech\". Nowhere on my resume does it even mention it. Sometimes I have to look it up and see what they are talking about. One of them even went on and on about my current job. Despite it only having the start date in that spot and no exp on what I do here. It is blindingly obvious they did not read my resume. They are keyword scumming and hoping for the best. reply dyauspitr 3 hours agoprevYou also have companies like mine (very large) where we don’t even post job descriptions online but just hire through internal referrals. reply ulfw 2 hours agoprev [–] Way way way way more than 1 in 5. Honestly. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A recent study indicates that 20% of online job postings are either fake or remain unfilled, adding to job seekers' frustration. - This \"ghost job\" trend might be a tactic for companies to project an image of growth. - Job platforms such as Greenhouse and LinkedIn have introduced job verification services to assist users in identifying genuine job opportunities."
    ],
    "commentSummary": [
      "A study reveals that 20% of online job postings are either fake or remain unfilled, often due to companies needing to comply with US immigration policies. - Companies may also leave job postings up to find ideal candidates, change requirements, or have pre-selected internal candidates. - The job market is difficult for applicants, who frequently encounter ghosting and automated rejections, prompting calls for regulatory intervention."
    ],
    "points": 273,
    "commentCount": 224,
    "retryCount": 0,
    "time": 1736865860
  },
  {
    "id": 42698557,
    "title": "Making an intersection unsafe for pedestrians to save seconds for drivers",
    "originLink": "https://collegetowns.substack.com/p/making-an-intersection-unsafe-for",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"collegetowns.substack.com\",cType: 'non-interactive',cRay: '901fe4882f59c944',cH: 'CtnofUBRmUe16bVEC8K7r_opMvtb5FgDjR8xr6dLmSQ-1736881475-1.2.1.1-qKMCnFUj8ODUoehw7RyP1GD5AKU0m8YQeCqPcwsfyGUGZ9bNl9g5uEZxXwbKyvBt',cUPMDTk: \"\\/p\\/making-an-intersection-unsafe-for?__cf_chl_tk=46J4YBnm6xlPPqNW_p_kQrE0K8DEWJcsWFuv1UWJDpc-1736881475-1.0.1.1-3LYLgljRJqHgmyO3gDaFN2QF3_h3A_Lv1uJTuaOKg6Q\",cFPWv: 'b',cITimeS: '1736881475',cTTimeMs: '1000',cMTimeMs: '120000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/making-an-intersection-unsafe-for?__cf_chl_f_tk=46J4YBnm6xlPPqNW_p_kQrE0K8DEWJcsWFuv1UWJDpc-1736881475-1.0.1.1-3LYLgljRJqHgmyO3gDaFN2QF3_h3A_Lv1uJTuaOKg6Q\",md: \"yMKo.sg3mO8VneuHZS3W6ACgDFJ2f4SjNozp.BlreUY-1736881475-1.2.1.1-ShQUZ28bKXcq6FbGEmlesmRDMf.1r8qP31JBs4WNAbM8fXh2VLcyYMeLMxjgpYR3mXjSvSy.nb6igN9dmMmXKbNgjEJse.R156Nk8Po7yKMzh3G0yctEUOU0pvEwoO0M1Y.1c60kxWa.AcuKIVAbIhYjGF.kJUTmn4dPnEfd3dVD9cx85theY.y.S4ox6zaTYfM1JgLHz_bvjFNRskpIiAg2Ucnp80u7g6ZFIoyP0A6HFyOh8dlE7SBbyonP5keG1PgKNyMyvmnXE72sk53Lo_WGM5n2RX2PGib9MvdVHQFRV0N30R1OcrAeO1tSCXyRfg16yp9Q20NXrgb2REk2sc63zF5i0Dtyoci8OES7LO0l6ktzhWOBpJtLUusnINH65egG63on1hFGTyDwuhlM7Cr5VAyzvGMKj_40kWwF9mSzbzL6KTK4SqEWK5yhfXRHxd1TDYpgJGKPyjpFDvFU0UmJIPiCzlvO0NbxcawEYOmE2mG6XR6eqaozkPjRnWrM0JcAmZGyT8R_TzpD3yLsYd95d6VXitHkiv_qmmAhnHpZ0Az8IUNH8tKj0yb8qF88W92.BuCR66u0lWel3ENQfcOhvKqyv3rgu.BDSR2OeuuDw3rcfodWG3COOpusTLDNUSEYdKVWNA2PpUscBg.pDz0VESp_CPRBb2iP7_hSD7fPNOcgmr9GMBooqIoitsOQS1i2kmWug.hAj5yqQcGtoPIE7Idcm4.YpeQxKdsvfUAQ_D3GSOb.uHf_7aXSITta00i8cBZq_QsuUVBmuWtU6kVBDEqvSXGv52KILtU5.SefR.E_40uyL7xUeMYnbRsc4l4WmbJs1ohPYmNw2JKdqd0LvZkZq7pT1dNnrjQqAAsJY.1eYH1v_P2MdVE5hc.oEYwQtdxupLIUDTC2HckjIcNW3yDY36VrVleYk76yZCUDZ7nfAhxFDg_vLLYAFnhk49Mf0JOJnVQrd._gh9IHi7YdSFuWFS8NEZelsym90fEbk1zTFcCX.OJOEQgdNPrH7jWLl8Koib_IP6bvzLvq.OTSbvb45eSRxt3Ssn6q708mL4JjMZKyUUNpJvXrlExzK13esob8hDGHOhdtYaZyTXWonq847cRiWtx51xtQiHJxj3B2wLz9EZyh3jpKYf99XvFctRzfYmOaxNcICEdnOsVgf1VgDlUGNsTMHs7gU8h8j2ZFkL.xeeCo3CDqd1Uo5lT2zo_hgXTNMY7I1vjDYQzhCSej2FtjWmLZWipEHDS5jKrfce3FEYSSPMgcmlqVPgGyXFioknQXLJO2iNeniYIEE04Atf2fljgKKhjVHL4Hsd4fGgYNEtqfEovmfEkd1.7e9tWlpzKcS5uLzbLGIpDq26oROwTD9hUoxCU_.7genQ2MUqyKMJiEiANmPBKm9ydpVSkN4mAh0Sv6K9uJqvUqzfQFOfyAzX1K7KB5CTtzgCsEfS8B0VdbfTS_wKsQCPXTniua5IrWne86JuzTiJxsUFWjj1PPLVBGyqZXRRoBv1QW4N8wlutahy6AwMvZIPTdYGvr0E1583sPw1Y_I8fSY5sowvd3m0b1TdF9HI7BJwVh0ks7.WM6_bvmrX.08akua.u8KyJBIwUtllF19LvgdEgGRMjRg.kO0bWOvAoLBk34m7og.SC2Z4jE09db2V9_aWegrZGwRekCVtj0YGt_QWq4I200vauQktn2KGB2fx.s1IbSRgBTKcvBCmvSOFS27wejPlR73kVJpi62oTMZM_awdjIE3.lYKUVFrQi7om4nXsXEjrIU8CrU5EtMjCmS94zmBodHogfbEGLav60KYcqjIPIrp3V82BEz4J1FRnqseFHhqWL_M8WG9EwF\",mdrd: \"xgGxWbGbzM7wVDEDOFlsviGc2ifylSOxln_CeKP3zpc-1736881475-1.2.1.1-LilYxHcyudCd6IyKNto1CrK8TcSkKsNkjZMyXRHp7AtO.4kP7gHn4KyPRgcdERQAIXX5stS6SD4kUTfCFAAuxxEbdhEn10241g41G1y3rVJWVk3kK.4BS9a14wNoG40svX9OAriKYQD8qonSkYhMgB6iInseMsZN_nb0Rl000MkoTaxWu5wJJ.O1CZ6FkQnOC1wCDf0JAlWalRB9CcVs.9fSrZBZqJuuG3cF0powSqDBkaPAs5CmlxmSqbGEI0XcHamtDhdXwtazBPMUBXuy9M9ldhHVNjY1qA01AJjkSwoNff4MEfFXXa7rC4zYfLGMzi6BAAxBvJ0w51lqwWaAkJ79FevseD9sO.x_0omHZYfjTxTNXiCs0AAWNAGNVzr3ALdeHBlQgW.ChrfpTCO0f44spOvLXM0umyUkwFanST1smdkSh7z02MYtOM1Ing4TlmjONNUwFgTtxJ3ToRINQbCF9cKfypf1mhtyAKFmKO8PAyJnZIwsppwLIQxjO62OURxEWjp9tkBDACWTx9xpirmv5g5_rd4srjIXHlhMf_4UoJ7ajB6ZJyScQKMansM7hlEWj3tiZatm1ABYY9pC3nnRLvmCNZ2ww4r0vlj2mqlyXzkInwRoWGSBz7VjbCljHwioSUEaHs37gMx7NnE3YyYO6VExm_jMBKTERKVBi_qDVHRxoyshkMzXMIWDkfFJYogevzVaH6K3HeBQSdAJujwoYo._V2fFVZttplf5hmejdnl0FterFF0krXVt7t6yiRI0FDespR9TCj5FKvGwfumobSnqwgh5LLOQp6jvOcyrJK0gNrxs3Z3cfHQp72XLdsEnX28bbr_TKUhspsRyrlpsfMr6qkaogLb2lTEE7wS9A2oyNb9x24dXM5qomwBSD5K295plGyIFGgoqHnTMgejl18PWic5NlT_Q75666no9j1FyUiQrFjtfErHgOgGIHEPmkYqQ1xx6in1d_8nIUFbGAPnHIOzi88zNJQ8o7GJAbHQoK96vl4Vg4y96t9HIlFvwGxfArXnrPw7wO3lBvYF8fU0H9wZMPcknOWx6vpQlcCsir1G03P3tiyToCFGzoJSnRBRl8wfOp4EOFqjx3aVJHthA2NFL3mzAtI74mah9oSoGD2NU_Mjj8.tWkv9v68WNUcr.e5dHrJ4jPfhfGrnM7O8qLOBU2g04SejHI5e6waZ0XKu2ODrzDkKJ9WUOW_X7.B6NjagyVCJ5yRunidEMelzRC_yPN8ZgHS5C8EsQf7LzioUCK6cNzlyi5ONBM5vQqoTw_7LaMNY5c7k2j.NcX0p.kMIfBzk9_VAZR39dYg8FdIyfZusDem8oVXX412mwwwkd_d960gyq72fxxqbM3e56TQqtrs0B5INRPcmnYhdISZwa8UiNFUfLe_ihEyk3T7TmJJSRpBdqWbnEB8zxTP2nGgiHsjIZWRt1WOK5OGK2eUcGL5kTgsGCyY6jF0V0hRtQwuv5TIBa1nIQN3QWONhQ0Q7uhw9kh7fEfdp9Q3LclxJi2V6iS2OzgMwuTMn6e2ldW_RS.eou3Wm4gLu1J6EdkLHwz12h7tzpc7qBf5mQ9UsdclPh79KHkedhZ35u7FFnry5dIG08uZaZtpg2k.ANCNrNyRWnPfTDEn3w9lM_zL0GMuHnjxN_P0BMuvTMztDs96nT35sMEE8yv0GgNODIANRrntfI4zbQU.p5OnJarr1Q8um2TmbQXeYsyf8jWNhpVH2ELgn3jixu7cOkHSgnfA7qmnSFLyGkNXRNwORXZq3coRxlWT_ZNMCXCVEYM0qKCR.GTfmRCBH1LdVaC7Qx.ERS3Zt3geHDGKuzKmkcZzhZQd71lm9Mykh.8TBpXnIU3ouh7RQ1M3WgpigB4y3MgmOI51QNjxZydRrPOnCqkm2xIBoUlRj7EAKhS842QghMiG54yQOso4wnGpYULPFPG4qe7GPBByeXZF1A6Aznf23OM2I3wQBmj5BBiAX5YloK.x_9HAgDaMJnKxN82tgFyw.Ic7.OqgDlzSYfE1fIO0nQ8gRJgBu.oUuCPPlyYkG7Vx_TLQX1Ldi6jRyC9i2IUi5oydOoBDhrumeKYT6Osk_z5OBYyq5UsdMe0DoA0zH6TSMlTxkHWOIMVYLk3igYwFUMuCsEG8ZePjt289BiF6iz2YUXYljh10RW.rzcGYz2vTD6kxhCXip97LCLUY.7A.jzjJ76D2meGl7fHFPyMe0E7j4PqBLdlL.A7H0M4ef6qIf1ajhrvFlG2l9ti_0yV0BF2XrdoZm.LsmXJKoXy2SwYDcEVA9HwNQaG1jbyGSPxIGrSNrxqcbFW9gALMbQ87gIvrgVkX09NtQN_H9ZW..rp0fV8qNonNcphwJacaVu_YTBOZvuR6P5pQUzd5Jai2EP0wzN6_Lqn8YdWrLp4wOIg1AgIrVUe1Hw\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=901fe4882f59c944';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/making-an-intersection-unsafe-for?__cf_chl_rt_tk=46J4YBnm6xlPPqNW_p_kQrE0K8DEWJcsWFuv1UWJDpc-1736881475-1.0.1.1-3LYLgljRJqHgmyO3gDaFN2QF3_h3A_Lv1uJTuaOKg6Q\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=42698557",
    "commentBody": "Making an intersection unsafe for pedestrians to save seconds for drivers (collegetowns.substack.com)267 points by raybb 3 hours agohidepastfavorite362 comments potato3732842 2 hours agoAs a pedestrian I will take a busy light controlled intersection with a pedestrian scramble type walk signal over a busy 4-way stop where every single time. With the 4-way stop there is never a time in the cycle when all traffic is stopped. The drivers who are present are continuously paying attention to what other drivers are doing which robs them of situational awareness to note pedestrians. You can try and time it but that's risky. With the walk signal there is a brief moment in time when the drivers are doing nothing but waiting for you and are all stopped so you as a pedestrian can account for them in preparation just before you get your signal and make your move. The author can get lost with this sort of textbook correct but questionable in reality take. Legally having the right of way doesn't make you any less dead when the driver who's got three other drivers to pay attention to doesn't see you. reply dylan-m 1 hour agoparentThis is why it's often safer to \"jaywalk\". If you're in the middle of a block, you only have to look two ways. Even if you screw up, a driver going at a reasonable speed is more likely to see you anyway because you're directly in front of them. I'm not exactly advocating for crossing in the middle of a street in North America since it's depends a lot on the situation, but there's a reason why people sometimes just do it intuitively, and it's unfortunate our infrastructure doesn't know how to address it. reply pclmulqdq 1 hour agorootparentJaywalking is very common in the Northeastern US, and I believe it is generally safer when done well. I have a rule that if you don't feel like you can calmly saunter across the street, you shouldn't jaywalk by running across, but many people do not follow such a rule, and just take the soonest opportunity they can find to run across the street. Be careful, though - I once jaywalked when I was with some friends from the Midwest and they were very offended. reply jerlam 1 hour agorootparentprevCalifornia just made jaywalking legal in 2023 too. reply hoherd 9 minutes agorootparentNYC legalized jaywalking in 2024, and the change will take effect next month, Feb 2025. https://www.cbsnews.com/newyork/news/jaywalking-legalized-in... reply throwway120385 2 hours agoparentprev> With the walk signal there is a brief moment in time when the drivers are doing nothing but waiting for you and are all stopped so you as a pedestrian can account for them in preparation just before you get your signal and make your move. Having almost been hit a few times by drivers making a right turn on red, I can tell you the drivers never wait even if you have the right of way. You'll be lucky if they even look for you. > Legally having the right of way doesn't make you any less dead when the driver who's got three other drivers to pay attention to doesn't see you. Also, and I know this is unpopular, but maybe you shouldn't dress like that if you don't want the attention. reply SoftTalker 2 hours agorootparentHere's how I handle right on red: When I have the walk signal, I look to my left for cars that might be turning right. If there are any, I look at whether the driver sees me. Try to make eye contact. If they are moving and apparently don't see me or are going to turn anyway, I wait. I may have the right of way, but I'm not going to win that battle. reply kspacewalk2 2 hours agorootparentI make it clear with body language and eye contact that yes I see them and no I'm not meekly yielding my right of way. However, I leave just enough space to avoid being hit, for those situations when the True Assholes knowingly cut me off anyway. Or maybe they're not assholes by intent, but instead in the 90th percentile for inattentiveness and bad driving habits, which may even be the same thing. I don't know, I'm not a driver psychologist. reply danenania 1 hour agorootparentI think a pretty large percentage of drivers don’t actually know that they’re supposed to yield to pedestrians when turning at lights. I’ve had multiple close calls where the driver looks at me angrily, I point at the white ‘walk’ symbol, and then their anger turns to confusion. They had no idea that they’re supposed to wait. reply grogenaut 1 hour agorootparentI live in seattle where people are pretty good about yielding. It's confusing as eff which lights and what times the peds are going to get a walk signal when I'm taking a right and when they're not. Some also go walk at the same time they go green for right turns. Some slightly delayed. It's hard to watch both lights as a driver and the oncomming traffic. reply danenania 58 minutes agorootparentI agree that it's confusing, which is why I think pedestrians should be given their own exclusive time to cross the intersection, just like cars. It would be easier and safer for everyone. reply kspacewalk2 58 minutes agorootparentprevRights on red are an inherently dangerous design flaw of North American traffic laws. It's not allowed in NYC and soon won't be allowed in DC and Atlanta. reply undersuit 42 minutes agorootparentAny time you grant vehicles a shared path with pedestrians is dangerous. I was in the middle of a long line of cars taking a left from a left turn lane. The green arrow light turned to a yellow arrow light for a brief second before turning full green. I was at the front of the line at the time so I slowed down and waited for the car in front of me to clear the intersection before I turned so that I could see that there if was oncoming traffic who light just turned green. No oncoming traffic, start turning, notice when I'm way to far into the intersection that a pedestrian is trying to cross the 90 feet of crosswalk as well. I violate their right of way and get myself out of oncoming traffic lanes. In the rear view mirror I see the pedestrian waiting in the middle of the crosswalk for the rest of the line of traffic behind me to finish their left turns. The corner is a 120 degree turn, definitely my fault for not being aware of my surroundings but also... 120 degree turn on two 4 lane 40mph roads... the pedestrian needs a dedicated time to cross free of vehicles. reply pnutjam 31 minutes agorootparentprevIf they get that close to me, the car is getting kicked or slapped to elicit a reaction from the driver. reply HnUser12 2 hours agorootparentprevThis is what was taught to me in drivers ed as a driver. Make eye contact with the pedestrian. So I do the same as a pedestrian as well. reply throwawayffffas 2 hours agorootparentprev> Having almost been hit a few times by drivers making a right turn on red, I can tell you the drivers never wait even if you have the right of way. You'll be lucky if they even look for you. Right on red should not really be allowed. It's a real hazard. reply mtalantikite 1 hour agorootparentIt's not allowed here in NYC. I've nearly gotten mowed down by people from the suburbs driving into the city not knowing it's illegal here on a few occasions. They also seem to get pissed and honk at me, as if walking around NYC isn't the default mode of transportation. reply cloverich 1 hour agorootparentTo be fair I've seen NYC _pedestrians_ yell at other pedestrians for walking wrong, NYC isn't exactly an outwardly friendly place in that respect. reply SoftTalker 2 hours agorootparentprevIt isn't in much of Europe. reply smaudet 1 hour agorootparentprevThe real issue are the road rage drivers who can't wait a minute and start honking behind you. We all get it, we are all late now and then, but unless you are literally trying to catch a plane or a boat, in all likelihood you can sit your candy ass down and wait a minute. reply mindslight 2 hours agorootparentprevIMO the problem isn't right on red itself, but rather that vehicles have to be in (and often completely over) the pedestrian crossing area to see oncoming vehicle traffic they have to yield to (at the distance required due to higher oncoming vehicle speeds). This encourages the behavior where drivers plan to have a single stop in that area, where they wait for an opening in vehicles to go - completely failing to take into account the possibility of having to stop before that area due to pedestrians actually using it. The situation is more like two separate stop and yields, and when drivers don't expect pedestrians they skip the first one. reply _DeadFred_ 1 hour agorootparentNot stopping before the pedestrian area is an instant ticket in my small town. They really promote walkability here. All of the issue listed seem to stem from lack of law enforcement. Our town also has bins at intersections with bright orange flags to increase your visibility as well as flashing 'pedestrian crossing' strobes initiated by button at problem location. reply cloverich 1 hour agorootparent> All of the issue listed seem to stem from lack of law enforcement When its a few bad apples its an enforcement issue. When its many bad apples its a design issue. reply mindslight 1 hour agorootparentprevDo you mean bins where people like, take an orange flag out, cross the street holding the flag, and then put the orange flag back in the bin on the other side? This is the first I'm ever hearing of that, and it sounds immediately ridiculous. But with further consideration I could see this being quite interesting for significantly changing the dynamic. reply grogenaut 16 minutes agorootparentIt is completely rediculous and I take every opportunity to ham it the eff up when I use them. They're in in several of the nicer places on the east side of seattle but are being replaced by aggressive pedestrian flashers. I'm 6'2 but I take the opportunity to re-enact my favorite olympics floor ribbion routine. reply manwe150 57 minutes agorootparentprevYes, the flashing lights are more common in my area, but either are a nice signal that someone wants to cross (and isn't merely waiting for their uber or to get in their own car) reply estebank 1 hour agorootparentprevIf there is no way of configuring the intersection so that right on red is safe for pedestrians, then the problem is the right on red. reply mindslight 1 hour agorootparentThe point of looking deeper at the actual dynamics is to brainstorm ways intersections could be made safer, without overshooting and then getting a campaign to undo it all in 20 years. For example: Less visual obstructions so that oncoming traffic can be seen sooner? maybe, but probably not going to change learned behavior Advance the crosswalk even more, with two separate lights? perhaps on a per-intersection basis Hard square corner kerb instead of a round bevel? Might help in general. reply estebank 1 hour agorootparent> Less visual obstructions so that oncoming traffic can be seen sooner? This is called daylighting and California passed a law for it https://www.sfmta.com/getting-around/walk/daylighting > Advance the crosswalk even more, with two separate lights? Pedestrians already have a \"leading signal\" in intersections with lots of people, which makes the wall signal change before the green for cars. Right on red defeats their purpose, which is to ensure pedestrians are on the middle of the street by the time a car wants to turn, putting them where they are easiest to be seen. > Hard square corner kerb instead of a round bevel? Yes. I would go further and have bulb outs https://www.sfmta.com/getting-around/walk/pedestrian-improve... and at grade crossings (the zebra crossing is at the same height as the sidewalk). All of these have been proven to work. > overshooting I don't think there is any risk of \"overshooting\" in making cities nicer and safer for pedestrians and all other road users in the US. If anything it will be an uphill battle to accomplish any change. reply mindslight 1 hour agorootparentI don't know why it feels like you're jumping on me here. Is it just CivE attracting people who overly focus on nouns? What you're calling an \"at grade crossing\" is indeed a good one I missed. I would call them something like crosswalk on a speed bump, which might be \"car centric\" or whatever, but at least isn't overloading a term that generally refers to using different levels for actual traffic separation. Everything we're talking about here is actually an at grade crossing. > I don't think there is any risk of \"overshooting\" in making cities nicer and safer for pedestrians and all other road users in the US. If anything it will be an uphill battle to accomplish any change. You really don't see the possibility of backlash to \"no turn on red\" everywhere creating a campaign of drivers getting frustrated while waiting for timed red lights to change at completely quiet intersections? And also FWIW, \"no turn on red\" doesn't actually prevent drivers from driving into the pedestrian crossing area - it just removes the benefit. It would still take a generation or two to change learned behavior. reply tantalor 2 hours agorootparentprevRight on red is (or should be) never allowed during a pedestrian scramble. That's just asking for trouble. The box must be entirely clear of cars during the walk signal. reply danenania 52 minutes agorootparentLeft turns on green (with no green arrow) are also pretty bad imo, as are right turns on green with no arrow. In both cases pedestrians are supposed to have right-of-way, but cars often don't respect it. reply tantalor 30 minutes agorootparentThat's part of what pedestrian scrambles so great: you always wait for the pedestrian phase before crossing. There is no pedestrian crossing in the car phase. The other great benefit is you can cross the diagonal (kitty corner). reply MrOwen 1 hour agorootparentprevI'm nearby this intersection and there are 2 scrambles- this one and one about 2 blocks down closer to the university. There is very clear signage for cars that there are no turns allowed on red. I've crossed both intersections many times and rarely have I seen cars violating that rule. Perhaps they do but in my experience, they generally respect it. reply afhsrtjwrtj 2 hours agorootparentprevWhy is right-on-red always cited as the biggest problem with turns? My anecdotal experience is that drivers turning on green are way more likely to hit me when I have a walk signal on the cross-street than drivers who turn right on red. reply mitthrowaway2 2 hours agorootparentIt's usually because a driver turning (right) on green doesn't have to worry about merging into traffic, so they only need to focus on pedestrians. Hopefully they will. A driver turning right on red has traffic coming from their left and pedestrians walking in front, and they're usually more concerned about the cars, so they tend to look left while turning right. Ouch. It's a growing issue as well because of the growing size of cars. Littler people can be completely concealed behind a front grille. A car turning left on green is also an issue because while they should be able to see and wait for pedestrians, they're often occluded by other cars and trucks, and those left turners can be in a hurry to proceed through a gap in traffic. reply bobthepanda 1 hour agorootparentAlso, while technically a right on red should require one to come to a full stop, then start their turn, in practice many people are doing rights on red at rolling stops at significantly higher speeds. reply dylan604 1 hour agorootparentprevThe number of people that make right-on-reds that not once during the approach or during the turn look to their right is what makes it a problem. I have often been tempted to do one of those YT videos of people spending their day videoing people at intersections to show how prevalent bad behavior really is. I just have no presence there for it to make it worth my time. I know how bad it is, and adjust my personal behavior accordingly reply tanewishly 2 hours agorootparentprevAre you saying that a right-turn can be green simultaneous with the pedestrian's crossing light being green? Because where I'm from, traffic lights are not allowed to be set up like that. No simultaneous green for crossing traffic flows, unless otherwise indicated (eg, an extra warning light+sign under the turn's traffic light flashing when it's green and off otherwise). reply vikingerik 1 hour agorootparentA car turning on a green light can be simultaneous with the pedestrian's crossing light being green. The driver is obligated to see the pedestrian and wait. What's not simultaneous is a green turn arrow with a green ped crossing. Intersections in the US are designed so that a green arrow will mean the driver has no conflicts and can proceed. Not everyone (both drivers and peds) understands that distinction. reply manwe150 51 minutes agorootparentI feel like I see a lot of fairly crazy intersections in my US city, where it feels like they break at least one expectation of the simple red/yellow/green patterns from drivers ed. I wouldn’t want to trust anyone’s life to assuming that a green arrow should mean I have the unconflicted right of way, let alone that others are even paying attention to their own signal reply toast0 1 hour agorootparentprevYes. This pattern is normal in the US. While vehicles are traveling north and south, the walk sign for crossing north and south is available. But vehicles are typically allowed to turn in the same cycle, protected lefts with their own cycle are common. Some intersections have a dedicated arrow for right turns and those will signal no rights while a walk sign is on, but otherwise pedestrians and right turns conflict. reply davidcbc 1 hour agorootparentprev> Are you saying that a right-turn can be green simultaneous with the pedestrian's crossing light being green? I can't think of many places that I drive where this isn't the case. The pedestrian crossing lights are in sync with the traffic lights, if traffic going N/S is green then the pedestrian lights going N/S will also be green even if cars are turning E/W reply manwe150 47 minutes agorootparentI know at least one intersection that crosses a bike path and walking path near me that changed recents so now oncoming traffic goes with the walk signal while turns are forbidden, then only right turns are allowed, then only left turns. It takes slightly longer to go through the cycle (particularly on busy days where pedestrians don’t yield the street for people to turn), but otherwise makes it much less stressful to go through that intersection regardless of my mode of transit around it reply gowld 1 hour agorootparentprevYes: https://ibb.co/86tqnBM Direct link: https://i.ibb.co/Hn36L27/Green-crossing.png solid green (right turn allowed) + pedestrian green (for crossing). car and ped both have access to ped crossing. (Car should yield to any ped in crossing.) Also, I drew a picture before I realized that this wasn't what you were asking about. But I like the picture. C A R 2v --------- -------- CAR1 -> ---------|ped -> -------||| C A R 2 --------- -------- C ---------| pAed -------R| 1|reply scotty79 31 minutes agorootparentThere is a way to mitigate the danger somewhat by giving pedestrians green light first, so when the car turns they are already in the middle of the road. reply RC_ITR 2 hours agorootparentprevOn a green arrow turn, drivers are looking to where they are going. Legally crossing pedestrians are in that cross walk where the driver is looking. With right on red, the driver is also looking to where they are going, but legally crossing pedestrians are not there, they are directly in front of the car. The riskiest thing for a pedestrian is approaching a right on red car from the left, because the driver is simply not looking at you. reply potato3732842 2 hours agorootparentThe big problem with right on red is that it perfectly synchronizes them to hit each other. Say a driver and pedestrian are at the same corner facing the same way and the pedestrian wants to cross into the area the driver wants to turn. The street is busy so the driver can't turn right on the red and the pedestrian isn't gonna just walk against the signal into the traffic. Cross traffic lets up, either because of a big gap or because the light has cycled to red for the cross traffic. The conditions that both parties require before making their move have just been satisfied at the same time. The pedestrian walks and the driver turns, leading to inevitable conflict. If both the driver and the pedestrian are in a hurry and trying to shoot a gap in traffic and go quickly there can be no time for either party to avoid the accident. Edit: The above example is crosswalks only, no dedicated pedestrian signals. reply tsimionescu 59 minutes agorootparent> Say a driver and pedestrian are at the same corner facing the same way and the pedestrian wants to cross into the area the driver wants to turn. That's not a thing that normally happens though. In a regular four-way intersection, if a driver is at a red light, the pedestrians that are allowed to cross are the ones that are crossing the street the car is on. If the car wants to turn right on red, then the pedestrians it has a risk of hitting don't care about the traffic that the car needs to wait for. reply gowld 1 hour agorootparentprevThis seems to not actually be the case in my experience, because right-turn drivers love to look to the left while turning right, because they are afraid of a fast-moving car appearing from the left, but they think they already verified that no slow-moving peds are crossing on the right. reply dfxm12 1 hour agorootparentprevDrivers have to worry about the traffic which has the green light vs. just looking where they're going. My anecdotal evidence is that everyone is looking out for themselves and people in bigger vehicles will always take advantage of that. reply RandomBacon 2 hours agorootparentprev> maybe you shouldn't dress like that if you don't want the attention. Have you ever taken the selective attention test? https://youtube.com/watch?v=vJG698U2Mvo (short 1:22 video) reply chasd00 35 minutes agorootparentprev>> Legally having the right of way doesn't make you any less dead when the driver who's got three other drivers to pay attention to doesn't see you. >Also, and I know this is unpopular, but maybe you shouldn't dress like that if you don't want the attention. in driver's ed you're taught to \"drive defensively\" i think the same applies to pedestrians. Don't just step into the road when the walk sign comes on, have some situational awareness and protect yourself. reply accelbred 1 hour agorootparentprevWorse yet, at least in Seattle, are right arrow lights that go green at the same time as the walk light. You get a green light to go and pedestrians start crossing at the same time. Having a green light and a walking sign on should be mutually exclusive. reply ensignavenger 1 hour agorootparentprevA pedestrian scramble means that no vehicles should be moving through the intersection period. It is a time in the cycle where ALL vehicles stop, and pedestrians can use the intersection freely in any direction, including diagonally. reply s1artibartfast 2 hours agorootparentprevYou have never had a driver wait? reply memsom 1 hour agorootparentIn the UK, it is very rare for a pedestrian crossing that is controlled by a button press to not completely stop traffic. The first time I was in North America as an adult, I realised that when on a crosswalk drivers will come sailing at you and will cross behind you as you cross over. That is illegal here. The drivers need to wait for the pedestrians to cross, even on \"Zebra\" crossings (which are the ones with no buttons and striped lines across the road.) The only exception to this is if there is a traffic island in the middle of the road, and then they are treated as 2 different crossings. But quite often those are staggered, so the pedestrian can't just walk out directly from one side to the other. The trade off is that the pedestrian has pretty much no right of way anywhere but a crossing, and cars will drive at you (or at least not stop for you) if you try to cross somewhere that is not a crossing. Though \"Jaywalking\" is not a thing and you can actually cross where ever you like. reply OJFord 1 hour agorootparent> The trade off is that the pedestrian has pretty much no right of way anywhere but a crossing, and cars will drive at you (or at least not stop for you) if you try to cross somewhere that is not a crossing. That's not true, or at least it's bad/illegal driving if they do so, a pedestrian who is 'established in the road' as the right of way anywhere. As you said: > Though \"Jaywalking\" is not a thing and you can actually cross where ever you like. Otherwise it would be a contradiction wouldn't it? If the pedestrians allowed to be there, the motorist obviously isn't allowed to run them over, ... I suppose you could say the pedestrian can continue crossing but only after first giving way to the motorist? There'd be more time with pedestrians in the road though. Not that I recommend using that fact to cross when you don't have time, because you will anger motorists. Or they could not see you/be paying attention. They'd be wrong, but it's just not worth it, obviously. reply gowld 1 hour agorootparentprev> I realised that when on a crosswalk drivers will come sailing at you and will cross behind you as you cross over. That is illegal here. It's illegal in most if not all of USA too, but no one cares in practice. Legally, even when a car driver and a pedestrian both have access to a lane separately, if both are present, then a car driver must give a full lane-width of space to a pedestrian crossing or at the corner. Also, even when a pedestrian is committing the auto-industry-invented crime of \"jaywalking\", the pedestrian still has the right of way in traffic, unless it is physically impossible for the car driver to avoid the collision. Car drivers are not judge/jury/executioner. (Nit: \"Cars\" don't \"drive\" (yet, in most places). \"Car drivers\" drive cars.) reply Ensorceled 2 hours agoparentprevThis is just not true. In Toronto for instance, the majority of pedestrian deaths are caused by impaired/distracted drivers with a significant portion of failure to yield by left turning drivers at major, light controlled intersections. There isn't even a category for \"four way stop\" pedestrian fatalities. reply jonpurdy 2 hours agorootparentSpeed is nearly everything and controlling (ie. reducing) speed should be the primary way to influence fatality rates. Having lived in both Toronto and SF, both cities with 4-way stop and controlled lights intersections. I'll take 4-way stop any day since speeds are lower. Much better to get hit by a car at near zero speed than a right or left turning car at higher speed. Which is probably why Toronto doesn't have a category for four way stop fatalities. (The worst are SF's 2-way stops at intersections between equally-sized roads that show up randomly throughout Sunset. Worst of both worlds.) reply Ensorceled 1 hour agorootparent> I'll take 4-way stop any day since speeds are lower. Exactly. People are, at worst, doing a \"rolling stop\" so they are still only going a few kph when they \"didn't see\" you. reply gowld 1 hour agorootparentA municipality could (and should) add speed bumps or other traffic-calming measures even at the approach the light-controlled crossing where pedestrians are often present. reply michaelleslie 1 hour agorootparentprev> (The worst are SF's 2-way stops at intersections between equally-sized roads that show up randomly throughout Sunset. Worst of both worlds.) As a cyclist, I've been yelled at by drivers for not stopping at that type of intersection, where they have a stop sign and I don't. People are working off of their personal version of the rules of the road, where they are always right. reply lolinder 33 minutes agorootparentprevWhat you are describing has a major sampling bias: most pedestrian fatalities will be at large intersections with many lanes crossing each other. Those intersections are on busy streets where drivers are going fast and where there are an insane number of conflict points. Yes, they're invariably controlled by a signal, but that's because a four-way stop is totally out of the question. The signal didn't cause the fatalities, it was necessary to install it because of the same factors that lead to fatalities. Using that data doesn't remotely begin to predict what happens when you take a small four-way stop and add a signal to control it. Adding a signal does not create new conflict points, it does not increase the speed limit on the road, all it does is control the intersection in a more aggressive way. reply Ensorceled 0 minutes agorootparent> What you are describing has a major sampling bias: most pedestrian fatalities will be at large intersections with many lanes crossing each other. Those intersections are on busy streets where drivers are going fast and where there are an insane number of conflict points. That's not what the point plot of the Toronto data shows. Many of our fatalities are on city streets with 40 or 50 km/h speed limits. Anyway, I was responding to the OP who was claiming that they would rather deal with stop lights than 4 way stops. There is nothing that shows that 4 way stops are dangerous at all, let alone more dangerous than light controlled stops in similar situations. itishappy 2 hours agoparentprev> With the 4-way stop there is never a time when all traffic is stopped and the drivers are always paying attention to what other drivers are doing. With the walk signal there is a brief moment in time when the drivers are doing nothing but waiting for you and are all stopped so you as a pedestrian can account for them in preparation just before you get your signal and make your move. That's... not true? With light traffic a 4 way stop should have no cars at all at it most of the time, leaving pedestrians with the right of way, whereas with a traffic light there will always be a road with priority until a pedestrian hits the button. Requiring cars to pay attention to the condition of the intersection is the explicit design goal. This was laid out very clearly in the article we just read. reply PittleyDunkin 2 hours agorootparent> With light traffic a 4 way stop should have no cars at all at it most of the time Unless there's protected right turns, of course. reply itishappy 2 hours agorootparentAgreed, but I would not call an intersection with a dedicated turning lane a 4 way stop, or at least not a low traffic one. reply potato3732842 2 hours agorootparentprev>That's... not true? With light traffic a 4 way stop should have no cars at all at it most of the time, leaving pedestrians with the right of way, whereas with a traffic light there will always be a road with priority until a pedestrian hits the button. Requiring cars to pay attention to the condition of the intersection is the explicit design goal. >This was laid out very clearly in the article we just read.This is what I mean about theory vs reality. 4-way stops don't look like the animation they show you in driver's ed. In practice what happens is that non conflicting traffic tends to parallelize so someone taking a left might start their left while the person across from them is finishing theirs (or one of any other bunch of combinations) so there's a car in motion basically all the time the situational awareness of every driver who's about to get their turn is mostly absorbed in monitoring who's turn it is and who's going where. So when you're a pedestrian and you don't time it right you could find yourself starting to cross right before someone wants to drive where you're crossing. Usually this is because you started walking before it was their turn and they didn't notice you until it was their turn and they started moving (because they were accounting for the other traffic) until it was their turn at which point they started looking where they were going as well. Normally this results in absolutely nothing, you speed up a little, they don't gas it as hard, everyone goes on their merry way. But the potential for things to go badly if the conflicting driver is inattentive or further distracted is very much there. Sure, theoretically the rules say they shouldn't do that but that's not how reality works. There's just so much less potential for conflict if there is a scheduled time when all the cars stop and then the walking happens. Even without a dedicated walk time it's just so much easier to time it when there's a light because you can start walking when all the cars have red and only have to look out for right on red or potential red light runners, it's a much easier problem than the degree of swiveling your head around you need to do to at a busy 4-way. reply vt240 1 hour agorootparentI tend to agree with you. I regularly walk, sometimes up to 40 miles per month, in the suburban hellscape that is South Hill in Puyallup, WA. This is the land of major 4 lane arterials w/ turn-lanes and hundreds of unprotected two-way and four-way intersections. There’s almost no pedestrians, I’ll rarely meet other people on my way to work, and sometimes go the whole two miles without making eye contact with a single driver. This article didn’t touch on it, but there’s another even scarier monster lurking out there. They’ve started to replace some of our larger intersections with these “Smart” traffic lights. Most drivers have a pretty well developed feel for the pattern traffic signals follow. These are pretty much random, adjusting the traffic flow based on some metrics. They use yield left turns with single direction flow and other tricks to try and control traffic. Since the light cycle doesn’t really follow any standard pattern, they’re also pretty much random when they’ll insert the protected pedestrian crossing into the cycle. It’s a death trap. There can be people waiting at a yield left turn which will be going to red, it will click on the pedestrian walk, and the opposing traffic will still be in full green, with drivers never coming to a stop. Add to that, if volume is heavy, you can stand there for 5 minutes or more waiting for a protected pedestrian crossing. reply magicalist 2 hours agorootparentprev> This is what I mean about theory vs reality > Sure, theoretically the rules say they shouldn't do that but that's not how reality works. Do you have any evidence for this or are you just making this up as you type? Because it's a bit rich to be harping about \"reality\" otherwise. A large body of research supports traffic calming measures for pedestrian safety and to increase driver awareness. A four-way stop intersection surrounded by intersections that also have stop signs (as indicated by the article) would fit that bill. reply itishappy 2 hours agorootparentprev> ... the situational awareness of every driver who's about to get their turn is mostly absorbed in monitoring who's turn it is and who's going where. Right, that's the intent. Drivers paying attention to their surroundings is the goal. > So if you're a pedestrian and you don't time it right you could find yourself starting to cross right before someone wants to drive where you're crossing. Usually this is because you started walking before it was their turn... You have the right of way! > There's just so much less potential for conflict if there is a scheduled time when all the cars stop and then the walking happens. How about a system where all cars are expected to stop all the time? reply davidcbc 1 hour agorootparent> Right, that's the intent. Drivers paying attention to their surroundings is the goal. The drivers are paying attention to the cars, not the pedestrians > You have the right of way! Graveyards are full of people who had the right of way. reply pwg 1 hour agorootparentprev> You have the right of way! Which, while true, in no way guarantees the driver sees you. If they miss seeing you for some reason, you very well may end up on the losing end of the physics of a collision between a 150lb object and a 3000lb object. reply david-gpu 1 hour agorootparentprev> Drivers paying attention to their surroundings is the goal. In the real world, drivers don't pay attention to their surroundings; instead, they look for other cars to avoid being hit. Further down the list is avoiding static obstacles like street lights or bollards. Lastly, they may think of looking for pedestrians. In other words, they care about their safety, not their neighbor's. Cyclists, if even noticed in the first place, are seen as nothing but a nuisance that should be overtaken at all cost, even when they are about to reach a stop light and there's no room to pass safely. > You have the right of way! A non insignificant number of drivers believe that \"might is right\" and will knowingly play chicken with you if they perceive that they are safer in the event of a collision. As a vulnerable road user, you don't know whether the driver you are interacting with will be one of the 95% of reasonable people or one of the 5% of insecure bullies. reply enragedcacti 1 hour agorootparentprevare you so engrossed in the driver's POV that you can't imagine an intersection without cars in it? reply enragedcacti 1 hour agoparentprev> The author can get lost with this sort of textbook correct but questionable in reality take I find this perspective very weird when (1) the \"textbook\" take (i.e. the one traffic engineers follow) is to almost always prioritize vehicle speed and driver safety over everything else, and (2) in what world is it questionable in reality when it existed in reality for decades, seemingly without incident? reply standardUser 22 minutes agoparentprevA 4-way stop is the best intersection for pedestrians in terms of speed. Just keep walking and don't yield your right of way. You may need to put up a hand to make yourself seen by the occasional distracted motorist. But because all vehicles need to stop, the average speed you are dealing with is 0-5mph, so the risk is low and everyone has time to react. Compare that with any lighted intersection where some cars are going full speed, making it a far more dangerous scenario. reply rob74 2 hours agoparentprevI get your point, but still, while the \"pedestrian scramble\" is maybe good for pedestrian safety, it's probably the worst solution for pedestrian speed. If the pedestrian lights were at least green at the same time with the car light in the same direction, you would at least have a chance of crossing the street without having to wait. This way, the lights never turn green on their own (as seen in the video), so you always have to press a button and wait. reply throwawayffffas 2 hours agoparentprevIt's not even a textbook correct take. Its less risky to run a stop sign in a clear intersection than to run a red light. There are more people likely to run a stop sign on an empty intersection than a red light. reply JB_Dev 2 hours agoparentprevMake it a roundabout with protected pedestrian crossings. That forces drivers to be looking at the conflict point with pedestrians as they manoeuvre the roundabout. reply roguecoder 40 minutes agorootparentI was very impressed in Denmark, where that roundabout approach worked very well. Every car slowed down & stopped for me at the crosswalks. It turned out that that was because they installed a cobblestone speed bump in front of every crosswalk. Cars slowed down even if no pedestrians were around, because otherwise they were going to pop a tire. It made walking so much safer than anywhere else I've been. reply gs17 2 hours agorootparentprevThose don't fix it in my experience. There's one about a quarter mile from where I'm sitting right now and I avoid it when walking because of how dangerous it is. Yes, they will see you crossing... as they almost hit you. They recently redid it to be a bit safer for driving on (before people were unclear on how many lanes it had and which lanes could turn where) but it doesn't seem to have improved the pedestrian experience much. reply whimsicalism 1 hour agorootparentprevin practice i find this does not work well at all… for some reason in roundabouts is when cars most feel justified in running down a pedestrian in a crosswalk. sometimes i think they’re just afraid to slow bc of the cars behind them reply rhplus 2 hours agorootparentprevThis. Roundabouts with medians. The answer is (almost) always roundabouts. reply unethical_ban 2 hours agoparentprevA stat of how many injuries occurred at this intersection would help settle your point. You're talking a lot of theory, where this person seems to have lived and traversed this intersection many times without incident. Was the upgrade worth $600,000 in this town, this street? And why, if it is a small town with heavy pedestrian traffic, does it default to vehicular movement instead of pedestrian movement? reply whimsicalism 1 hour agoparentprevi hate pedestrian scramble systems they make it so slow to walk anywhere reply dylan604 1 hour agoparentprev> With the walk signal there is a brief moment in time when the drivers are doing nothing but waiting for you In my area, there are plenty of stop lights with pedestrian signals where both are active at the same time. This allows the traffic to flow if there are no pedestrians on the assumption the drivers will recognize the pedestrians have right of way. To me, this is bat shit crazy level of assumptions. Either protect the pedestrians, or you might as well remove the pedestrian signal. reply munchler 3 hours agoprev> I captured two drivers ripping through red lights in that short span Video actually shows two cars entering the intersection on yellow lights, which is legal. The rest of the article seems similarly exaggerated. ---- Edit: For those who disagree, please be aware that the stop lines are out of frame, so both cars are already in the intersection before they're visible on the video. You can get a better picture of what the intersection actually looks like here: https://maps.app.goo.gl/L37hZyvXs8BeWmFE8 reply addicted 2 hours agoparentExcept the article doesn’t claim what the drivers are doing is illegal. The article says that the street design causes drivers to speed up and makes the intersections unsafe. Instead of drivers always stopping, or at the very least slowing down, when approaching the intersection, the new street design leads to drivers speeding up when approaching the intersection. This is bad design for pedestrians irrespective of whether the driver jumps a light, the pedestrians cross when they shouldn’t be, or neither of them are doing anything wrong. It will increase the odds of collisions, injuries and possibly fatalities. reply nirvdrum 2 hours agorootparent> Except the article doesn’t claim what the drivers are doing is illegal. The article states “… and I captured two drivers ripping through red lights in that short span.” I suppose “ripping through” can be left up to interpretation. However, in the video the author says “that person just ran a stop… a red light right in the middle of me filming.” Then the other he says: “I bet this guy runs the light. Yup, see, this person ran the light, too.” “Running” a red light is an illegal act. I think in both cases the cars should have slowed down and had plenty of time to stop before entering the intersection. But, evidently that’s legal in California, while the author indicates otherwise. reply cptskippy 18 minutes agorootparent> The article states “… and I captured two drivers ripping through red lights in that short span.” I suppose “ripping through” can be left up to interpretation. There really isn't enough information given to make a determination. It looks like two of the vehicles traveling on Lemon \"jump\" due to a ridge in the middle of the intersection but that itself isn't an indication of speeding. reply horsawlarway 2 hours agorootparentprevI don't know if California has a different law, but at least in my state it is very much illegal to accelerate into a yellow light. Enforcement is basically non-existent, but it's absolutely \"running the light\" and \"breaking the law\" to accelerate into yellow lights. reply toast0 1 hour agorootparentCalifornia law does not address accelerating on a yellow. The driver's handbook (which is not the law) says > A yellow traffic signal light means CAUTION. The light is about to turn red. When you see a yellow traffic signal light, stop, if you can do so safely. If you cannot stop safely, cautiously cross the intersection. The bright line rule is not to enter the intersection on a red light, defined as crossing the stop line if present, crossing the first line of a pedestrian crossing if present, or actually entering the intersection if there are no lines. reply xiphias2 1 hour agorootparentprevI don't know USA, but in other parts of the world yellow and red are different colors. Just because 2 things are illegal they aren't the same, and it takes away all seriousness from the article for me. reply horsawlarway 1 hour agorootparentGenuinely - why do you care? His point is absolutely correct - the cars used to stop, and now instead they're accelerating to beat a light change. I genuinely don't know if that's actually illegal in cali - but it definitely is in several states, and you'll get ticketed for failing to stop for a red light. --- > but in other parts of the world yellow and red are different colors. Yellow is the light that means \"start stopping\" and red is the one that means \"absolutely stop\". Neither damn color is the \"go faster\" color. reply cortesoft 2 hours agorootparentprevThe video and article specifically said these cars “ran the red light”, which they absolutely did not do. reply micromacrofoot 1 hour agorootparentyou're supposed to slow down at a yellow to prepare to stop, not speed up to get through it, increasing speed through an intersection is inherently dangerous the author's point is valid and we're falling into pedantry reply UseofWeapons1 2 hours agoparentprevI had to look this up. In California in particular, this is true, which surprised me. Per a random law firm: California’s yellow light law permits drivers to enter an intersection during a yellow light. No violation exists unless any part of the car is over the stopping line when the light turns red. However, the law encourages drivers to slow down before reaching the intersection. Whereas in, for example, Massachusetts, this would be considered running a red light. https://www.wccbc.com/red-and-yellow-light-accidents/#:~:tex.... reply the__alchemist 2 hours agorootparentIf this surprises you, consider the alternative: Driving through a yellow being illegal or unexpected doesn't make sense, given the finite stopping distance of cars, and reaction time of humans. This is because the yellow light is the first explicit indicator you must stop. If this doesn't make sense still, picture this scenario: You are driving at the speed limit. You are 500ms from crossing the stop line threshold. The light turns yellow. Your interpretation would make sense only if there were a (paler yellow?) light warning of the yellow light! reply chaoskanzlerin 2 hours agorootparentAustria does that: 4 seconds of the green light flashing in order to announce the yellow light. reply cortesoft 2 hours agorootparentSo a pre-yellow light? This seems like you just changed what we call a yellow light to the 4 flashing greens, and made the yellow the new red. If yellow means “don’t enter the intersection”, how is that different than a red? reply the__alchemist 2 hours agorootparentprevWith this change to the scenario, being required to stop before yellow makes sense. And blowing through red means you extra screwed up! (?) On this note: In the UK, there is a yellow light prior to green; love it. reply gowld 1 hour agorootparentThe US sometimes has something similar: visibile countdown timers for the pedestrian crossing turning form stop to go, which coincides with the car light turning from red/stop to green/go. This encourages people to run the light by trying to turn exactly as the countdown timer hits 0, trying to race against pedestrians trying to cross crossing pedestrians. reply manwe150 36 minutes agorootparentYou could always do that before in most instances just by watching for the yellow on the cross street too. Though I think the green is often slightly delayed relative to the pedestrian light, precisely to ensure the car cannot win that race legally reply tbrownaw 1 hour agorootparentprevHow long until we can get a proper countdown like some pedestrian signals have? reply GuB-42 1 hour agorootparentprevIn France, it is illegal to drive through a yellow light unless it would be dangerous to stop, for example if it required you to break hard. That part is up to the officer judgment. In practice, I have never seen it applied, and it is only a small fine anyways, much less serious than running a red light. I guess it can be used as an excuse if the police really wants to pull you over. reply rlue 1 hour agorootparentprevOn the contrary, I think it could make perfect sense: What's written in the law is one thing, and how it's enforced is another; I would argue that the former should be done with consideration to the latter. Based on my own experience, I'd estimate that well over 99% of traffic infractions go entirely ignored by the law: minor speed violations, unsignaled lane changes, rolling stops at stop signs, expired tags, cell phone usage, and yes, running red lights. When the letter of the law is broader in scope or errs on the side of caution, that enables the police to exercise their judgment in enforcing it (with the obvious caveat that some police will abuse any power you give them). You could imagine a scenario where someone technically runs a red light but it's totally justifiable and safe (heavy load + moderate speed + short yellow + no other traffic) and another where someone technically makes it into the intersection on a yellow light but senselessly severely endangers public safety (busy intersection + rapid acceleration + traffic backed up on the other side of the light). I would be okay with someone evading a ticket in the first case and getting one in the latter. reply Spivak 2 hours agorootparentprevYep, something something Chesterton's fence. If you couldn't drive through a yellow then you effectively have two lights go/stop which makes drivers choose between the safe but illegal thing of running the light or the dangerous but legal thing of slamming on their brakes. You can't have an instant switch between go/stop which yellow— effectively meaning unsafe stopping distance go, safe stopping distance stop— solves very neatly. reply scotty79 41 minutes agorootparent> effectively meaning unsafe stopping distance go, safe stopping distance stop— solves very neatly. That's how it works in Poland and it works reasonably well. On the other hand when light is about to turn green, yellow lights up. So red and yellow at the same time means prepare to go. reply andrewaylett 2 hours agorootparentprevIn the UK, if you're at all over the line when the lights change, you're considered \"in the junction\" and are expected to leave the junction -- the next phase should give you priority to do so. The only way to run a red light is to start crossing the line while the light is red -- although plenty of drivers will start to inch across while they're supposed to be waiting :P. The most annoying scenario is where a driver has either stopped or inched forwards far enough that they can't actually see the lights any more and don't know when they've changed. reply bunderbunder 2 hours agorootparentprevThis is the law in Illinois, too. It, in combination with the way the lights are timed, makes some intersections particularly challenging for pedestrians. The basic way the timing goes is: traffic light changes, pedestrian crossing signal illuminates, traffic going straight that squeezed in on the yellow finally clears the intersection, cars turning left finally get a chance to go, pedestrian can finally safely enter the intersection with approximately 10 seconds left to cross a four lane street, lights change again, cars start honking at the older person with mobility issues who could only get halfway across the intersection in the time they had available to safely do it, impatient driver from further back in the line who doesn't care to figure out why the person in front hasn't started moving even though the light has been green for five full seconds swerves into the right turn lane and guns it, narrowly missing the aforementioned older person with mobility issues as they blast through the intersection. reply kurthr 2 hours agorootparentprevI'm wondering how you would know when the yellow light was going to come on. Do you have some sort of countdown, or innate knowledge? Because, otherwise do you just randomly stop at green lights guessing that a yellow light might come on? Or do you drive so slowly that you can stop in the width of the white line before a pedestrian crossing? Really, I'm trying to figure out how you don't ever enter just as a light turns yellow. Once you do, do you stop in the intersection or try to clear it before it turns red? I hope the latter. For me yellow lights are a warning that a red light is coming. It should be long enough for cars to clear the intersection (in many states without gridlock rules even this is not the case for left hand turns). My experience in Boston is that drivers try to beat the green light change and accelerate while it's still red. reply lofenfew 2 hours agorootparent> Do you have some sort of countdown, or innate knowledge? often, in the form of the pedestrian signal. > try to clear it before it turns red? This is the rule in much of the world, yes. reply kurthr 1 hour agorootparentI assume you mean the perpendicular direction crossing lights? Most pedestrian lights have delays longer than that in California for safety so you might stop at a green light. Also, if nobody presses a button ped-lights don't even turn on, just like left turn signals don't turn on without a vehicle triggering it. reply ImPostingOnHN 2 hours agorootparentprev> For me yellow lights are a warning that a red light is coming Correct, yellow means \"start slowing and stop before the intersection if you can do so safely, otherwise proceed\". Red means \"do not proceed if you aren't already in the intersection\". This is why the opposing traffic signal and walk signal will wait for a second or two after red: to allow people who entered on yellow to finish their transit across the intersection. Indeed, in the author's own video where they incorrectly claim someone ran a red light, the author had no legal right to cross anyways, so there was no chance of the author getting injured unless they ran a red light at the crosswalk. In short, the author seems most frustrated that the situation changed from everyone waiting on him, to him waiting a few seconds for others. reply kaonwarb 2 hours agoparentprevJust rewatched and agree they both entered on orange, which is legal. This clear misinterpretation makes me question the author's take as a whole. Did they consider that cars also regularly run stop signs? Is it possible that this is, in fact, safer for pedestrians, albeit more frustrating while waiting? reply jagged-chisel 2 hours agorootparentOT, but it fired me up a bit - people that enter the intersection on green or orange awaiting a break to turn left. And then don’t clear the intersection on red. Now they’re in everyone’s way. How do you get them to understand they’ve already “run the light” and just need to move? reply cge 2 hours agorootparentAs far as I know, that is both legal and standard practice in California, and at many intersections with traffic and no protected turn, is in practice the only possible way to turn left: there will simply never be a break in traffic, from the moment the light turns green until it turns red, and so without entering the intersection and then turning on red, it is simply not possible to turn left at all. reply Spivak 1 hour agorootparentThey even teach you to do this in driver's ed. I know HN skews \"rules are rigid\" but this one should be known by everyone. reply cge 43 minutes agorootparentIn parts of Europe the practice itself is even rigid, with markings for where in the intersection your car is supposed to be while waiting to turn. reply s1artibartfast 2 hours agorootparentprevIn some jurisdictions, this is literally how it works. You claim the intersection, wait for oncoming traffic to stop, then perform your turn. It's legal in jurisdictions where red means you cannot enter, like California. The major problem is that on very congested streets, the driver won't know if the exit will be free of traffic when the light turns red. Blocking the intersection is illegal. To a certain degree, it is a failing of Civic design and the ruleset. The solution is generally no left turns during peak hours, which is a duct tape fix reply toxik 2 hours agorootparentprevThis is literally everyone where I live, and if you tried to wait before the intersection, people would be (rightly) incredibly angry at you. It just wouldn’t work. Nobody lingers in the intersection after oncoming traffic clears either. reply potato3732842 2 hours agorootparentprevWould you rather they floor it and beat the straight through traffic when the light turns green? 1-2 cars entering the intersection and then getting through when traffic clears on the red is less worse than the alternative. reply jagged-chisel 2 hours agorootparentOne of us has misunderstood the other. Maybe I’m misreading you. Let me clarify my position. If you’ve entered the intersection on green or orange, and must await oncoming traffic before you can safely turn left, then the light turns red before oncoming traffic clears, once that traffic has indeed stopped for the red, you need to complete your left turn to clear the intersection, even on red. This situation is clearly spelled out in the driving manuals for my state. If you are not willing to continue on if the light turns red while you are in the intersection, then don’t enter the intersection until it’s clear - wait behind the line. reply s1artibartfast 1 hour agorootparentFor the last sentence, do you mean continue on straight if the desired left turn is not available? reply pta2002 2 hours agorootparentprevThis is why I always find it weird that in the US (and a lot of other countries) the stoplights are on the end of the intersection, instead of at the entrance. If they're at the entrance, there's no dillema - you can't cross the light if it's red. If it's yellow, you brake if you have time, but if not, it's fine to keep going - the opposing light is going to wait a few seconds before turning green specifically to avoid this. This also encourages drivers to actually stop in the right place (since they can't see the light otherwise), and it's friendlier for pedestrians since it avoids drivers stopping on top of the crosswalk. (I've also never heard of the turn-right-on-red rule anywhere other than the US. Over here in Portugal if it's fine to turn right while the light is red, there's just going to be a separate green/flashing light to turn right. A lot clearer!) reply ars 1 hour agorootparentThe location of the traffic light has no legal meaning, there's a white painted line on the ground, which is the stop line. reply DHPersonal 2 hours agorootparentprevI remember my father telling me that was how it was supposed to be done, as the yellow light for oncoming traffic would convince them to stop and give you the time to complete the left turn. It only worked when they weren't also running the yellow light! These days I prefer waiting to turn so that I'm not stuck out in the middle of the intersection when the traffic light changes. reply avgDev 2 hours agorootparentIf you are stuck in the middle when turning crossing traffic needs to wait until you clear the intersection. reply DHPersonal 2 hours agorootparentI find it's better for me to just miss the turn while I wait behind the line. I've seen too many instances where that doesn't work out the way it's intended to want to make it a habit for me anymore. reply mook 2 hours agorootparentWouldn't you have the same issue at the next light, and still be stuck waiting to turn, making no forward progress at all? Note that I'm assuming an unprotected left turn (with right hand traffic as in the US) at a busy intersection with incoming cars running yellow lights; please let me know if any part of my assumption mismatches yours. reply avgDev 2 hours agorootparentprevThis is really odd and would be extremely frustrating for people behind you. You are supposed to enter the intersection. Keep your wheels straight and then turn whenever there is a gap in the oncoming traffic or when the light turns red and the oncoming traffic stops. reply mitthrowaway2 1 hour agorootparentprevI don't know where you live, but where live, you are allowed to complete the left turn even after the light turns red. Hopefully the red light will convince oncoming cars to stop even if the yellow did not. Cross traffic has to yield to you as you exit the intersection. I hope this gives you more confidence in making left turns safely! reply JB_Dev 2 hours agorootparentprevIf you do not wait in the intersection itself then you would never get a chance to turn in many intersections. The only solution is to always wait in the intersection itself. reply kspacewalk2 2 hours agorootparentprevWhat difference does it make? The main point is that this design induces drivers to speed up even more than they're already speeding (and, this being North America, they're already speeding), at a dangerous point in time when pedestrians are starting to cross. It literally makes no practical difference whether they're entering on a very late yellow or a red. reply Spivak 1 hour agorootparentTraffic engineers aren't blind to the fact that it's NA custom to (roughly) +5 on residential, +8 on state highways, and +5-15 depending on on the lane on interstates. People get up in arms about it on the internet for some reason while IRL the roads are just designed with this in mind. reply kspacewalk2 1 hour agorootparentI have more of an issue with the idea that you can make a previously dangerously fast street/road safer by mere virtue of reducing the speed limit, but leaving it physically designed as before. You lower the limit by -5, the +5 speeding turns to +10 speeding and absolutely nothing changes save for wasted paint. I wish North American traffic engineers (and municipal politicians) were better educated on the idea that the only reliable way to slow down drivers is to force them to slow down by making it physically intensely uncomfortable to speed, and that sending drivers to body shops after fender-benders with traffic calming features is preferable to sending vulnerable street users to the morgue. Alas, both occupations are still stuck in an outdated car-centric view of urban transportation. This competency shortfall is present in other transportation- and infrastructure-related fields. See for example how badly North American construction companies and government bureaucracies handle big transit projects. Third-world levels of mediocrity compared to the cost-effective, competent management in, say, Spain or Japan. reply rascul 28 minutes agorootparent> You lower the limit by -5, the +5 speeding turns to +10 speeding and absolutely nothing changes save for wasted paint. A couple weeks ago, a 55mph limit near me was lowered to 50mph. A cop watched during the busy times for a few days. Now everyone is generally going 5mph slower than they were. Seems successful so far. reply SoftTalker 2 hours agoparentprevYellow generally means do not enter the intersection unless you are so close that you cannot reasonably stop. It is not legal to enter the intersection if you cannot clear it before the signal turns red. Exact rules and enforcement vary by state. reply cge 2 hours agorootparent> It is not legal to enter the intersection if you cannot clear it before the signal turns red. That does not appear to be the case in California, which this article is written about. It seems to be a bit confusing, because there are suggestions that the driver handbook suggests that you should follow the rule you note, but that the law itself has no such requirement. In practice, in many areas of coastal California almost no one would stop at a yellow unless they felt they could not enter the intersection before it turned red, and doing otherwise would likely be seen as impeding traffic by many other drivers. reply jbritton 2 hours agorootparentprevIn CA we have many intersections where one wants to turn left, but there is not a dedicated left turn signal. When the light turns green, you pull out into the intersection. Ideally you pull out enough that the car behind you can also get into the intersection. On busy roads you may not be able to complete the left turn until the signal goes red. If you chose not to pull out, then nobody would ever be able to turn left. I believe CA passed a law some 20 plus years ago that you must be able to clear the intersection before the red light, which is in conflict with what is sometimes necessary. There are situations though where the direction you are headed is backed up, such that if you pulled out you could end up stuck in the middle of the intersection long after the red light. I believe the law was intended for this situation. So don’t pull out if your direction of travel is blocked. reply hevang 2 hours agoparentprevLegality aside, is that not kind of the issue here? Lights in a high foot traffic area could incentivize people to speed up to make it before the red, which is less predictable and has cars traveling at faster speeds compared to a stop sign, which requires all cars to stop. Embellished yes, but point of the article showing that this intersection is now more dangerous to pedestrians stands imo. reply munchler 2 hours agorootparentUsing stop lights to control this sort of high-traffic intersection is totally normal in the US. Stop signs are typically used for lower-traffic intersections. Subjectively speaking, I think drivers are more likely to obey a red light than a stop sign. Perhaps the author of this article is upset that the neighborhood now has more traffic than it used to, but that's a different issue. reply hevang 2 hours agorootparentI'm not sure I've seen evidence that running stop signs is more likely, but even if that is the case which one is higher risk? I'd subjectively say running red lights is more dangerous as you have a higher chance of several pedestrians entering the cross walk all at once, or several cars going at once, since it causes people/cars to move in waves. I think its pretty clear that the author is upset that a stop light that increases risk for pedestrians, cost the school and city money, and provides minimal time advantage for cars was implemented. Also, I'd like to point out that normal does not mean good, or best. reply prmoustache 2 hours agorootparentprevNo, drivers in that neighborhood were used to stop at every stop while now a lot are passing through that intersection much faster to avoid the red light. reply BugsJustFindMe 2 hours agoparentprevBoth may be legal, but the first one is unclear and is definitely unsafe. Safety requirements dictate a slightly different understanding of yellow light than is commonly used by drivers. For safety, yellow must mean \"begin controlled deceleration immediately\". The first driver had plenty of time on yellow to not be just barely entering the intersection on red. They clearly were not decelerating and had very likely sped up to beat the light. This unquestionably is a thing that drivers do all the time, and it's dangerous. reply simiones 2 hours agorootparentThis is very much wrong. When a driver sees a yellow light, they must make a call: do I have time to safely slow down and stop before reaching the stop location, or not? If I do, then I must start slowing down right away - that much we agree o. But if I don't, then I mustn't slow down, as that is more likely to leave me in the middle of the intersection while the lights turn green for through-traffic. reply Ajedi32 2 hours agorootparentprevWhy is it dangerous? (Unless they're breaking the speed limit to make the light, obviously.) Just the risk that they might misjudge the timing and enter the intersection after the light turns red? But lights have a built in delay before turning green to account for that. reply cptskippy 31 minutes agorootparentBecause vehicles are often already traveling at or above the speed limit. Just as the yellow light is intended as a \"start slowing down\" but is interpreted as \"speed up to beat the light\", the speed limit sign is intended as a \"do not exceed this speed\" but is interpreted as \"you must be traveling this speed\". If we assumed that most vehicles are traveling the speed limit or faster, which is the case in my experience, then accelerating further is like pouring gasoline on a fire. reply the__alchemist 2 hours agorootparentprev> yellow must mean \"begin controlled deceleration immediately\" This is not true in the strong form you used. There is a regime where there is no possibility you will be able to stop the vehicle in time using reasonable deceleration. Slowing does no good. There is also a regime where slowing will cause you to enter the intersection during the red light, and not decelerating will not. reply BugsJustFindMe 2 hours agorootparentThat's ok. We can hammer out the details together, but the principle is true if the light turns yellow before you reach the intersection. Note that I didn't say how rapidly you need to be decelerating, and if the light has turned red before the car even clears the crosswalk, as is the case for the first car, then the driver sped up instead of slowing down. reply munchler 2 hours agorootparentprevAgain, please be aware that the video does not show the entire intersection. reply BugsJustFindMe 2 hours agorootparentIt seems like you're stuck on whether someone broke a red light law, but this isn't an article about the legality of dangerous behaviors. It's an article about making intersections more dangerous. The first car isn't even through the crosswalk when the light turns red. Racing through a crosswalk to beat a light is the definition of dangerous driving. reply runako 2 hours agoparentprevThe way I learned this was \"in legal, out legal,\" meaning that you are not allowed to be driving in the intersection while the light is red (aka you have to be finished transiting by the time the light changes). Is this not the law in California? reply toast0 2 hours agorootparentMy understanding is that California has two relevant laws for this discussion: 21453 (a) which prohibits crossing the stop line when the light is red [1]. And 22526 (a) which prohibits entering an intersection when the exit isn't clear. [2] You have to be able to clear the intersection if you enter it, and you have to enter it on green or yellow (except for turn on red after a stop), but you don't have to clear the intersection before it goes red. Common practice (which might not be 100% legal) for unprotected lefts on green (where space permits) is for the first car to fully enter the intersection and the second car to roll over the line a bit, then for both vehicles to clear the intersection when opposing traffic stops which may be in yellow or red. The driver that's only a bit in the intersection can make a judgement call and stay slightly encroaching rather than clear the intersection if clearing seems inadvisable because opposing traffic was slow to stop. [1] https://leginfo.legislature.ca.gov/faces/codes_displaySectio.... [2] https://leginfo.legislature.ca.gov/faces/codes_displaySectio.... reply mrWiz 2 hours agorootparentprevIn my state you are allowed to exit the intersection while the light is red but may only enter while it's green or yellow. In driver's ed they taught us to enter the intersection while waiting to make a left turn so that we could complete the turn after the light turned yellow/red and opposing traffic stopped. reply avgDev 2 hours agorootparentIt is the same in most US states. reply avgDev 2 hours agorootparentprevI believe most states it is LEGAL to enter the intersection(normally marked by a white line) before the light turns red. Cross traffic MUST wait for cars to clear the intersection. reply cosmotic 2 hours agoparentprevNot only legal, but safer than slamming on one's breaks. reply CalRobert 2 hours agorootparentGenerally speaking if you're going the speed limit you don't need to \"slam on your breaks (sic)\" to stop before a light turns red unless you didn't have enough time to clear the intersection anyway. reply HPsquared 2 hours agorootparentSurely it depends how close you are to the line when the light turns yellow. reply cosmotic 1 hour agorootparentprevMy partner slams on his breaks even though he goes below the speed limit and has plenty of time to clear the intersection. It's not just the speed. reply ajmurmann 2 hours agorootparentprevDepends how far you are away from the light when it turns. reply CalRobert 2 hours agorootparentAnd, of course, your speed. reply ajmurmann 2 hours agorootparentClearly both are a factor but you don't need both. Even if I go 20mph I have to slam on the breaks hard if the light turns when I'm just three ft away. The only way around this is to treat every light like a stop sign where you do a California roll Edit: As a related pet peeve I've never understood why we don't have countdowns for car traffic lights like we do for pedestrians. These IMO would not only increase safety but also fuel savings (especially if we had them for each signal change) as I could time my arrival at the traffic light to minimize braking and acceleration. reply AlfeG 1 hour agoparentprevIts only me, who think that 12 seconds of green light is just too small window. That's why every car try its best to pass through. reply DHPersonal 2 hours agoparentprevI disagree. The first car doesn't even cross their side of the pedestrian crossing before the red light blinks on, so they have had ample time to prepare to stop and are running a red light. The second car is more debatable but also had enough time to stop, as the light turns red while they are still in the middle of the intersection. reply crackercrews 2 hours agorootparentThe second car definitely entered on yellow. It doesn't matter if they could have stopped. They have the right to enter on yellow. The first car passed the first line when the light was yellow, but not the second line. The area in between is the crosswalk. I can't tell if \"enter the intersection\" means \"enter any part of the area past the line where you're supposed to stop\" or \"enter the part past the crosswalk, where the roads actually intersect\". Does anyone know what the rule is? reply toast0 2 hours agorootparentIt's well spelled out in vehicle code 21453 (a) > A driver facing a steady circular red signal alone shall stop at a marked limit line, but if none, before entering the crosswalk on the near side of the intersection or, if none, then before entering the intersection, and shall remain stopped until an indication to proceed is shown, except as provided in subdivision (b). [subdivision b allows for turns on red] https://leginfo.legislature.ca.gov/faces/codes_displaySectio.... reply prmoustache 2 hours agorootparentprevThe fact people can't figure what the rules are is a problem in itself vs a stop sign where everybody knows you should stop. reply crackercrews 1 hour agorootparentI know where to stop. I stop before the crosswalk What is less clear is what the word intersection means in a technical sense. Complicated or ambiguous rules are a part of life. If the idea is to get rid of anything that requires lots of rules, then we'd all still be on foot. No cars, no horses, no bikes. Would that be a net improvement? reply bloak 2 hours agoparentprevI've sometimes wondered what the exact rule is with red lights. Presumably you're allowed to continue moving forwards if the front of your vehicle passed the stop line before the light turned red. But if you stopped with the stop line passing through your vehicle are you allowed to start moving forwards again while the light is red? (Whether that would be a sensible thing to do would depend on whether you're driving a long vehicle with just a tiny part of it behind the stop line, or a motorbike with just a tiny part of it in front of the stop line, but does the law distinguish those two cases?) reply simiones 2 hours agorootparentI don't think the law is so specific, but I suspect the right interpretation would be that you should pass through the intersection if the car is in a position where it would block other traffic the moment the light turns red; in any other circumstance, you should stop if the light is red, even if you passed the location where you'd normally wait. For example, say you're entering the intersection on green/yellow, but the car in front suddenly stops while you're on the crosswalk, possibly not even seeing the light on the side of the road, but no part of your car is impeding the cross traffic. Well, even if the car in front now clears the intersection, if the light has turned red, you should almost certainly stop and wait for the next green light, rather than trying to clear the crosswalk: doing anything else is much more dangerous. reply np- 2 hours agorootparentprevIf your vehicle is ever fully stopped past the line, and the light is red, that would be considered a “blocking the box” traffic violation in most jurisdictions. You technically should not have entered the intersection at all without the ability to fully clear it. reply bloak 1 hour agorootparentIn England, I thought it was only the \"crossed out\" intersections that you shouldn't enter unless the exit is clear. Rule 174 here: https://www.gov.uk/guidance/the-highway-code/using-the-road-... reply oangemangut 2 hours agoparentprevI don't see why a re-design like this wouldn't have included both pedestrian and car infrastructure improvements. Tighten all the turn radii, add bump-outs to each corner, and you could have a signalized intersection that is better than it was before for both. reply runako 2 hours agoparentprevFreeze frame: https://imgur.com/a/ASSeakh > the stop lines are out of frame Is the car in the freeze frame in a legal position given the red light? It would appear not. reply toast0 2 hours agorootparentThere's no way to know from a single frame. We would need to know the sequence of events. It's not against California vehicle code to be in an intersection when the light is red. It's not even necessarily against vehicle code to be in an intersection when the light is red for you and green for perpindicular traffic (although it's an imminent hazard, so you better have a good reason). To show a red light violation, you need a datestamped image showing the vehicle behind the stop line with a red light showing, and a near in time image of it in the intersection on red, and probably another one to show that it didn't make an allowed right on red. Really, you also need evidence that the red light was steady, and not a flashing red light which would indicate four way stop and the driver could proceed after stopping. Typically, you wouldn't see red showing on both directions at the same time in a flashing red situation, but cameras are fickle. reply avgDev 2 hours agorootparentprevThere is another line before. We don't really see the entire intersection. reply runako 2 hours agorootparentYes, you are correct. That's why I specifically did not address the car's entry into the intersection. Given the red light, is the car in a legal position in the freeze frame? reply avgDev 2 hours agorootparentYes. I do not understand why this is so misunderstood in the comments. This picture is LEGAL in most US states as long as the car entered the intersection ON A GREEN OR YELLOW light. reply runako 2 hours agorootparentAt least one California law firm disagrees, hence my question: https://www.wccbc.com/red-and-yellow-light-accidents/#:~:tex.... Some quick Googling shows that \"it depends on where\" appears to be the right answer. New Jersey appears to be a populated jurisdiction where this might not be legal. reply avgDev 2 hours agorootparentAs I said MOST US states. I looked at the link and NO, they DO NOT DISAGREE. Read the language, drivers SPEEDING through a yellow light MAY be found negligent if they cause an injury to someone. \"California’s yellow light law permits drivers to enter an intersection during a yellow light. No violation exists unless any part of the car is over the stopping line when the light turns red. However, the law encourages drivers to slow down before reaching the intersection. In California, the yellow light law provides that drivers are automatically “warned” by the light turning yellow that the traffic light is about to change to red. This means that a faulty driver cannot avoid responsibility for an accident simply by claiming that they didn’t see the yellow light. It doesn’t matter if they saw it or not. Drivers speeding through a yellow light may be found negligent for not slowing down if their driving caused an accident or injured others.\" reply runako 1 hour agorootparentI'm reading this differently than you are: \"No violation exists unless any part of the car is over the stopping line when the light turns red.\" But I'm not a lawyer and this is interpreting an interpretation. reply doctorpangloss 2 hours agorootparentprevThe author is pissed off about the design of the intersection. If you have to litigate bullshit like this, surely you see, well, the intersection is poorly designed. You are also litigating whether or not it's legal. A lot of traditions of California driving are legal and really dangerous. My dude, CVC doesn't even apply in a private parking lot for example, so you can accidentally kill somebody in one and legally face no moving violations. \"Legal\" is not an interesting criteria at all, it's misleading. reply simiones 2 hours agorootparentOn the other hand, whether the driver was legally or illegally passing through the intersection is also irrelevant for safety: the fact is that the video clearly shows that the driver didn't put anyone's lives at risk this time, neither themself, any pedestrians, nor any incoming cars. reply avgDev 1 hour agorootparentprevMy problem is that author doesn't seem to understand the traffic laws and wrongly says cars ran a red light. I'm not interested in his opinion after that. If you are going to put something on the internet about bad design you should make sure you understand it first. reply getpost 1 hour agoparentprevAs a nearby Los Angeles resident, I can confirm that a significant percentage, say 30-40%, of drivers 1) don't stop at stop signs, and 2) routinely run red lights at intersections when few or no other vehicles are present. It's true that it's legal to enter an intersection when a light is yellow, but don't let this statement distract from the general traffic-lawlessness that prevails. Law enforcement is even less likely to follow the law (ignoring cases where lights and sirens are activated). I think the defacto rule that many drivers follow is, 'if the intersection appears clear, I don't have to stop.' (I'm not advocating this rule, just saying what I think the rule is.) Cell phones and screens in cars have made this rule especially problematic because drivers aren't paying close enough attention to the road to ascertain whether intersections are clear. This isn't a recent phenomenon in LA, but it seems to have increased during and since Covid. I'd love to find reliable data on traffic enforcement. The problem is cultural, but the apparent lack of enforcement seems to have expanded the population of scofflaw drivers. reply pclmulqdq 1 hour agorootparentThere is local traffic culture in a lot of places. LA residents in particular don't like stopping at stop signs. Boston drivers turn left immediately when the light turns green even if other cars going the opposite direction have right of way. Texas drivers speed like madmen on freeways. New York drivers change lanes with reckless abandon. Law enforcement officers in all these places never pull people over for this stuff. reply xutopia 2 hours agoparentprevOne car enters the intersection on red. reply munchler 2 hours agorootparentThat's false. The stop line for cars is out of frame in the video, and the driver has already passed it by the time the light turns red. You can get a better view of what the intersection actually looks like here: https://maps.app.goo.gl/L37hZyvXs8BeWmFE8 reply DHPersonal 2 hours agorootparentI think it depends on what one uses as the definition of intersection. Is it the actual point where the two roads collide, or is it at the stop line? reply avgDev 2 hours agorootparentYou can't be serious. The stop line is where the intersection begins. If you cross the stop line on yellow you won't get a ticket and it is perfectly legal in most US states. reply ColdTakes 2 hours agoparentprevYou can not say this without the caveat that it is location dependent. This is an illegal action in some cities and states. Like in California, where that video was taken, yellow means STOP if you can safely do so. Both of these cars had ample time to stop and chose to accelerate to make the light. reply avgDev 2 hours agorootparentHow can you tell both cars had ample time to stop? We didn't see how close they were to entering the intersection in the video. They entered the intersection on a yellow light, which is perfectly legal if they could not stop. reply bedobi 3 hours agoprevThis is a solved problem and it's astonishing the world hasn't just adopted the Dutch traffic engineering standards outright. It's FASTER for cars and safer for people. reply ajmurmann 3 hours agoparentThe lack of adoption of best practices from other countries is generally baffling to me. When I first visited China grim Europe and saw traffic lights with countdowns (like in the US) I thought we did immediately adopt this in Europe. Cultural inertia and lack of looking outwards is really frustrating. reply Tarq0n 1 hour agorootparentResearch on countdown traffic lights is inconclusive with regards to their safety [0]. They can not realistically be described as best practice. [0] https://www.maxapress.com/data/article/dts/preview/pdf/DTS-2... reply CalRobert 2 hours agorootparentprevA countdown on a traffic signal seems like a fun way to encourage drag racing. Though it's nice on pedestrian signals. reply amalcon 2 hours agorootparentThe driver can usually see the countdown on the pedestrian signal anyway. It's not obvious that this would be worse. reply RandomBacon 2 hours agorootparentprevIs it a countdown until it turns green, or a countdown until it turns red? I think it's unlikely the latter would encourage drag racing. reply gpm 2 hours agorootparentprevCrazy idea that would be next to politically impossible in North America: Have every traffic light with a countdown also be a speed camera. It'd eliminate the incentive to drag race, would give drivers more information earlier allowing better driving, and would generally make speeds limits actually a limit on roads with traffic lights. reply s1artibartfast 1 hour agorootparentFirst you have to deal with the issue of cities selling camera data to third parties and using it for license plate tracking and face ID reply HPsquared 2 hours agorootparentprevAnother example of \"this is why we can't have nice things\". reply Kuinox 2 hours agorootparentprevHow are countdown signal better ? reply sjg1729 3 hours agoparentprevWhich standards are you referring to? reply masklinn 2 hours agorootparenthttps://swov.nl/en/fact-sheet/principles-safe-road-network (national institute for road safety research) https://crowplatform.com/product/design-manual-for-bicycle-t... (non-profit advisor to the ministry of transport) reply Ensorceled 2 hours agorootparentprevThey are literally referring to the \"Dutch traffic engineering standards\" when they say \"Dutch traffic engineering standards\" reply numerobis 2 hours agorootparentWhat standards specifically? What is the solution to the problem that Dutch standards provide? Duh reply bb86754 2 hours agorootparentIt’s an entire book length of material, but in short, for built up areas drivers are forced through street to design to be higher alert to their surroundings. EX: chicanes in the road, speed tables, brick roads, narrow streets, small/tight turn radius, no turn on red, etc. These all work together to make a system that is amongst the safest in the world for pedestrians, and by happenstance has the happiest drivers. Also, bike traffic and vehicle through traffic are separated on different networks, so a conflicts are minimized. reply Ensorceled 2 hours agorootparentprevWhich requires a long and detailed answer that can be found by simply googling \"Dutch traffic engineering standards\" which leads you to an entire wealth of information. reply Salgat 2 hours agoparentprevTo clarify, aren't these standards mostly relevant where heavy bicycle traffic exists? Do they still apply in areas with little to no bicycle traffic? I'm assuming you're mostly referring to this famous manual: https://en.wikipedia.org/wiki/CROW_Design_Manual_for_Bicycle... reply andrepd 1 hour agorootparentThere is no bicycle traffic because there are no bicycle roads. It's incorrect to claim that we shouldn't build bicycle roads because there's no bicycle traffic :) reply ndsipa_pomu 8 minutes agorootparentA similar concept would be to only build airports where there's lots of planes landing. reply kjkjadksj 1 hour agoparentprevThe hard problem isn’t figuring out what to do. Its to get people on board with shifting from a like for like infrastructure development model where the roads and built environment look more or less the same for decades, to a potential status quo changing model of infrastructure development. If you can solve that fundamental issue, traffic is just a footnote of the long list of problems you also solve on our planet. reply sethammons 2 hours agoprevHA! I was about to tell my story and checked the article. My story is ONE block away from this intersection. I used to work a few blocks from this intersection and would walk daily to the train. Crossing the street was daunting, especially when we time changed and it was dark. I started carrying reflective labels on my backback and I wore a strobe light when crossing. I _still_ had people flipping me off, swerving around me, honking, etc for my audacity to use a crosswalk. Going to remote work probably saved my life. reply parshimers 1 hour agoprevIt's too bad they didn't put a roundabout here, there's one in the middle of old town Orange and it works pretty well. Terrible waste of money to make the intersection worse like they did. It also says something that the behavior of the cars here isn't even illegal in California. Entering an intersection on yellow and exiting on red is fine. Right turn on red is also allowed, and many people combine that with a California stop (though that last part isn't legal). All of the above are extremely hazardous for pedestrians and encourage speeding. reply dleslie 3 hours agoprev> Why don’t lights ever sit idle with the pedestrian crossing on and the cars must wait? The author knows the answer as well as most readers do: because the intersection is being designed with cars in mind, not human beings. reply nmeofthestate 2 hours agoparentUsually a crossing will instantly switch when the pedestrian button is pressed, if enough time has passed since the last \"walk\" cycle. Having a stage where walk is enabled when there's no pedestrians around wouldn't much help pedestrians, and would introduce inefficiency in throughput. And obviously, drivers can't press a button, so it makes more sense for controls to be accessible to the pedestrians. reply dr_kretyn 1 hour agorootparentInstantly? You're definitely not in North America. Many intersections around me, if you missed pressing the crossing button before parallel street had a green light, you missed your opportunity to walk for the next minute. reply dleslie 2 hours agorootparentprev> Having a stage where walk is enabled when there's no pedestrians around wouldn't much help pedestrians, and would introduce inefficiency in throughput It forces drivers to reduce speed and come to a full stop; dramatically decreasing the likelihood of collisions with pedestrians they did not notice. reply crackercrews 2 hours agoparentprev> designed with cars in mind, not human beings This is a bad faith framing. The cars are driven by humans. Or in the case of autonomous driving, are driving humans around. I've come up to plenty of lights that had the pedestrian signal lit even though there were no pedestrians. This happens during the day and at night, and is frustrating. Just happened the other day when I was driving around midnight. Not a pedestrian in sight! reply dleslie 2 hours agorootparentIf the designers were truly considering the well-being of the occupants of the vehicles then they would be designing cities to minimize the time spent in vehicles; which means more than saving a few seconds at a stop light, it means getting them out of their cars entirely. reply crackercrews 1 hour agorootparentThat might fly in temperate parts of California, but it sure doesn't work in places with less pedestrian-friendly weather. reply jplrssn 1 hour agorootparentThere are plenty of examples of walkable neighbourhoods in places with cold and/or wet weather. reply crackercrews 13 minutes agorootparentYes, there are some places that people can walk, nearly everywhere. But GP suggested \"getting them out of their cars entirely\". That is not a nuanced proposal that acknowledges tradeoffs and seeks to find a balanced approach. It's saying that people should not be in cars. Tell that to a parent with 4 bags of groceries and 3 kids and see what the reaction is. If we want better cities and towns, zealotry won't get us very far. It will get us laughed at. And I say this as someone who walks all the time and is about to do so right now. reply asmor 2 hours agoparentprevI'm about 99% sure that was a rhetorical question so you can ask yourself why we put cars before people. reply criddell 2 hours agorootparentPeople are in cars too. reply leonheld 2 hours agorootparentI think we should give priority to the people who are no inside multi-ton metal boxes, pollute less, can get on average healthier due to walking etc etc... At least inside our cities. reply simiones 2 hours agoprevIt's very strange to complain that cars run red lights, but somehow not stop signs. I expect that if the intersection were as empty as it was when he was filming, you'd easily find people driving at a similar speed regardless of the stop signs too. reply itishappy 1 hour agoparentMy experience has been that cars will happily roll through stop signs, but at nowhere near full speed like they're doing here. reply the_sleaze_ 2 hours agoparentprevI know it as the \"California Roll\" - to slow down but continue to cruise through stop signs. reply simiones 1 hour agorootparentIn my own country, where stop signs are relatively rare anyway, this behavior is so common that it doesn't even have a name. I think it's much more unexpected here to see anyone truly stop at a stop sign on an empty street than it is to see them slow down and then continue on. And I would bet police would not bat an eye 99% of the time if they saw someone do it. reply floren 2 hours agorootparentprevThat's old fashioned, the current \"California roll\" is to just continue at full speed through stop signs or red lights. reply benjijay 2 hours agorootparentI am more familiar with (and more partial to) a California Roll consisting of 'crab' sticks, avocado, and cucumber, wrapped in seaweed and then rice. reply mungoman2 3 hours agoprevThis is an annoying change, but the cars in the video weren't actually running any red lights. Doesn't help the case to exaggerate. reply soperj 2 hours agoparentIt's a 34 second video. One enters the intersection after the light has turned red (pause the video, you can see it). The other is half way through the intersection before the light turns red, definitely speeds up to make the light, which is what they're talking about. reply AlfeG 1 hour agorootparentGreen state is very short. 15 seconds is barely enough for 2-3 cars. My guess this force drivers to speedup. reply DHPersonal 2 hours agoparentprevPedestrian \"annoyed\" by driver, funeral details to follow reply runako 2 hours agoparentprevhttps://imgur.com/a/ASSeakh reply mungoman2 48 minutes agorootparentThat triangle doesn't mark the stop line though, it's further back. If cars stopped at the triangle they would block pedestrians crossing the street. reply whimsicalism 2 hours agorootparentprevthink it’s just on the margin - they’re in the intersection in this shot and it’s not illegal (at least where i’m from) to be in the intersection when the light turns red reply Ithildin 2 hours agoprevAside from the debate, 600k seems insanely high for this intersection. No wonder this country's infrastructure is crumbling when it takes over half a million dollars to put in a few lights. reply prasadjoglekar 2 hours agoparentThis sort of work usually costs 3x what is should, because the firm doing the work has to pay state minimum wage and/or hire union labor. reply simiones 1 hour agorootparentMinimum wage in California seems to be $16 an hour. I doubt this intersection took 37 500 man-hours to finish, so I don't think the cost is explained by wages. Also, $200K would still seem like a gigantic amount of money for adding stop lights to a single intersection. reply kjkjadksj 1 hour agorootparentYou probably need an engineer. A couple. They might have to run traffic studies beforehand to estimate the design requirements and light timing. They might have to consider other network nodes beyond this in their modeling. They might have to also run studies afterward to retime the lights to meet realized demand. I’m surprised its not a $6m project honestly. reply danenania 36 minutes agorootparentThere's a proposal to redo a playground in San Mateo's central park—bids have come in around $16M. https://www.cityofsanmateo.org/4142/Central-Park-Playground-... It's a nice playground design for sure, but it's kind of amazing to consider what could be built privately for the same amount. You could literally build a palace on a giant estate with fancy landscaping, a swimming pool, tennis courts, movie theater, etc. Of course there are reasons why public projects are more expensive, but it does seem pretty crazy on the surface. reply whimsicalism 1 hour agorootparentprevthe issue is the prevailing wage requirement (3x+ minimum wage). it would be easy to complete this cheaply with just minimum wage labor reply rafram 2 hours agorootparentprevWould it be better if they hired non-union labor at $5/hour (1/3 the minimum wage)? Would you apply for that job? reply ars 1 hour agorootparentObviously that would be better. If no one applied for the job you raise rates until someone does. You don't artificially start unnecessarily high. If you do you are basically stealing from taxpayers to give gifts to unions. reply alkonaut 3 hours agoprevKnew before I clicked: it's a flat 4-way intersection of two large-ish streets where the",
    "originSummary": [],
    "commentSummary": [
      "The debate centers around whether intersections should prioritize pedestrian safety or driver efficiency, with some favoring light-controlled intersections and pedestrian scrambles over 4-way stops.",
      "Opinions vary on traffic laws and infrastructure design, with discussions on the safety of jaywalking and the risks associated with right turns on red.",
      "Some advocate for alternative solutions like roundabouts or adopting Dutch traffic engineering standards to enhance both safety and efficiency."
    ],
    "points": 267,
    "commentCount": 362,
    "retryCount": 0,
    "time": 1736869194
  },
  {
    "id": 42696080,
    "title": "PostgreSQL is the Database Management System of the Year 2024",
    "originLink": "https://db-engines.com/en/blog_post/109",
    "originBody": "English Deutsch Knowledge Base of Relational and NoSQL Database Management Systems provided by Redgate Software HomeDB-Engines RankingSystemsEncyclopediaBlogSponsorsSearchVendor Login Featured Products: Milvus Datastax AstraRaimaDB Neo4jSingleStore RSS Feed Tags Want to publish an article here? Blog > Post PostgreSQL is the Database Management System of the Year 2024 by Tom Russell, 13 January 2025 DB-Engines is today announcing that PostgreSQL is our DBMS of the Year for the second year in a row, winning for the fifth time overall. DB-Engines is today announcing that PostgreSQL is our DBMS of the Year for the second year in a row, winning for the fifth time overall after also being top-ranked in 2017, 2018, 2019, and 2023. Second in the rankings was Snowflake, followed by Microsoft in third place. PostgreSQL has emerged as the most popular database management system over the past year, outpacing all other 423 monitored systems. Nearly 35 years ago, the database system known as Postgres made its debut. Since then, PostgreSQL has undergone significant transformations, driven by a continuous stream of enhancements that ensure it remains at the cutting edge of DBMS technology, while also offering a dependable and stable platform. PostgreSQL 17, launched in September 2024, introduced additional performance enhancements and expanded replication options, among other improvements. All of this continues to make PostgreSQL one of the most successful open-source projects ever. Snowflake is the runner up and is a cloud-based data warehousing company that has gained significant traction in recent years. Its unique architecture allows for the separation of storage and compute, providing flexibility and scalability. Snowflake's support for multi-cloud environments and its data sharing capabilities have made it a popular choice for businesses looking to leverage cloud data warehousing. Snowflake's rise in the rankings reflects its growing influence and adoption in the industry. Microsoft's Azure SQL Database and SQL Server continue to be strong contenders in the DBMS market. Azure SQL Database offers a fully managed relational database with AI-powered performance optimization and scalability. SQL Server, with its hybrid capabilities, allows for seamless integration between on-premises and cloud environments. Microsoft's commitment to innovation and its comprehensive suite of data services have solidified its position in the top ranks. For more information about navigating the complexities of managing multiple databases, read more here from Redgate, or visit red-gate.com Notes to editors Methodology We calculate the DBMS of the year by subtracting the January 2024 from the January 2025 scores. We use the difference between each DBMS’s score, rather than a percentage growth, which would favor systems with lower popularity at the beginning of the year. The DMBS of the year is an illustration of how much each system increased in popularity during the year. You can read more about our exact methodology here, but in short we are ranking popularity of DBMS based on how much people are discussing and communicating about each system, including job offers, professional profile entries and citations on the web. job offers, professional profile entries and citations on the web. About Redgate Software Redgate offers end-to-end database DevOps to help enterprises streamline software development and surface value from their data faster. Redgate's portfolio of solutions helps organizations reliably solve the complex challenges of database management across the DevOps lifecycle on any database, any platform, anywhere. We make life easier for IT leaders, development and operations teams, increasing efficiency, reducing errors and protecting business-critical data. More than 200,000 companies globally, including 92% of the Fortune 100, trust Redgate to deliver ingeniously simple software. Media Contacts Meghana Shendrikar Allison Worldwide for Redgate Software redgate@allisonworldwide.com Share this page About UsAdvertising and ServicesPrivacy PolicyContact Follow DB-Engines on:Copyright © 2025 Red Gate Software Ltd Featured Products The data platform to build your intelligent applications. Try it free. See for yourself how a graph database can make your life easier. Use Neo4j online for free. RaimaDB, embedded database for mission-critical applications. When performance, footprint and reliability matters. Try RaimaDB for free. Vector database designed for GenAI, fully equipped for enterprise implementation. Try Managed Milvus for Free Bring all your data to Generative AI applications with vector search enabled by the most scalable vector database available. Try for Free Present your product here",
    "commentLink": "https://news.ycombinator.com/item?id=42696080",
    "commentBody": "PostgreSQL is the Database Management System of the Year 2024 (db-engines.com)239 points by plaur782 7 hours agohidepastfavorite79 comments m_st 5 hours agoI so badly wish we could change a big Windows business application to use PostgreSQL rather than Microsoft SQL Server just because of the licensing costs. SQL Server is a fantastic product, but restricted to 128GB RAM and a few CPU cores or you have to start paying so much, that not even our biggest customers can justify it. Migration isn't easy, as this venerable application uses ADO.NET Datasets with TableAdapters and plenty of stored procedures. The syntax is almost compatible though. But not enough unfortunately. For our next product, we're sure to bet on PostgreSQL instead. reply chasil 3 hours agoparentAn enormous flaw of Sybase/Microsoft SQL Server is that it does not implement the SQL/PSM standard. https://en.wikipedia.org/wiki/SQL/PSM The syntax for this does come largely from Oracle. \"SQL/PSM is derived, seemingly directly, from Oracle's PL/SQL. Oracle developed PL/SQL and released it in 1991, basing the language on the US Department of Defense's Ada programming language.\" In any case, I have thousands of lines of PL/SQL written by many people which are currently useless for SQL Server applications. SQL Server should implement SQL/PSM. The sooner, the better. For those trying to escape the licensing costs of SQL Server, Babelfish may be an option. https://babelfishpg.org/ reply munchler 3 hours agorootparentSybase SQL Server hasn't been a thing for at least a decade. The Microsoft fork happened more than 30 years ago. reply sbuttgereit 1 hour agorootparentAnd yet.... it lives still.... https://www.sap.com/products/technology-platform/sybase-ase.... https://en.wikipedia.org/wiki/Adaptive_Server_Enterprise reply kylecordes 4 hours agoparentprevYes, this is such a big challenge for commercial database products. PG is so great that it often makes the most sense to reallocate the money to more CPU/RAM/SSD, rather than licenses. reply belter 4 hours agoparentprevTest this: \"Goodbye Microsoft SQL Server, Hello Babelfish\" - https://aws.amazon.com/blogs/aws/goodbye-microsoft-sql-serve... Or the Opensource project: https://babelfishpg.org/ reply bdcravens 3 hours agorootparentI evaluated this for our database and ran into many cases where it wasn't a 1:1 replacement, especially if you lean heavily on stored procedures. Additionally, our db library (it's a Rails app; the database was originally used with another language) needed features Babelfish didn't support. It may be worth another look for us, but I assume it still shouldn't be considered a 100% drop-in. reply masfoobar 2 hours agoparentprev> I so badly wish we could change a big Windows business application to use PostgreSQL This ^^^ A small businness I (no longer) work for was using Windows Servers, SQL Server, Classic ASP, .NET and other things. It was expensive! I tried sooo hard to migrate to get them to realise the savings moving over to Linux and Postgres, and get their DATED software over over afterwards! Well, it was Linux and MySQL/MariaDB but I have slowly grown fond of Postres over the last couple of years. I will always remember (and find funny) when we purchased a server a third-party no longer wanted to support for us anymore (linux+php) and my boss said \"they only pay £300 a year for that server\" -- yep. reply cheema33 1 hour agoparentprevWe are in the same boat. An older application with lots of dependencies on MS SQL Server. We are slowly chipping away at it with our migration effort. reply accra4rx 42 minutes agoparentprevGo Babelfish reply pmarreck 4 hours agoparentprevLLM's might be able to translate the stored procedure code without too much difficulty, and assuming you have test coverage. Might also do a good job of translating DDL code such as index definitions etc. I too was impressed with SQL Server last time I used it (big note: SQL Server is one of the few commercial DB's that does real nested transactions; PG does not), but I get it. reply dspillett 3 hours agorootparent> SQL Server is one of the few commercial DB's that does real nested transactions More or less. The default ROLLBACK behaviour is to roll back the whole nest. You have to use SAVE TRANSACTION instead of BEGIN TRANSACTION and specify the name in ROLLBACK. If doing this in a procedure that may or may not be part of a nested transaction (an explicit transaction wasn't started before it was called) you have to test to see if you need to BEGIN or SAVE¹ and what to do if a rollback is needed (you likely don't want to ROLLBACK everything if you used SAVE, but have no option if you used BEGIN). Not exactly intuitive. And saved transactions can cause excessive lock escalation, impacting concurrent performance. SQL Server is generally a damned fine product overall, both generally and compared to a lot of other things emitted by Microsoft, but it isn't even close to perfect in some areas. ---- [1] ref: https://learn.microsoft.com/en-us/sql/t-sql/language-element... reply pmarreck 13 minutes agorootparentThanks for the clarification. I'm not one to compliment Microsoft software products, but Analysis Services and SQL Server, at least when I used them at the time over 10 years ago, seemed like darn fine products (which they purchased from someone else, I believe...) reply werdnapk 4 hours agorootparentprevWhat's a real nested transaction? What's postgresql missing? https://www.postgresql.org/docs/current/subxacts.html reply pmarreck 17 minutes agorootparentSavepoints are not considered legitimately isolated nested transactions. To the best of my knowledge. Note: Am not a DBA, merely a full stack dev that has worked with various databases over the years. reply BrentOzar 4 hours agorootparentprev> SQL Server is one of the few commercial DB's that does real nested transactions Not sure where this myth keeps coming from, but no, it does not: https://www.sqlskills.com/blogs/paul/a-sql-server-dba-myth-a... reply pmarreck 15 minutes agorootparentInteresting. Is this still up-to-date? The link you posted is 15 years old reply cpursley 1 hour agorootparentprevYou're getting downvoted by gatekeepers but LLMs are amazing with SQL and this is a great use-case. reply hnthrow90348765 1 hour agorootparentAnecdata, but I agree. I went from a recursive CTE (that occasionally would take 1GB+ of memory for zero rows) to a loop and used AI to do it, and it did a pretty good job reply cpursley 4 hours agoprevTurns out Postgres Is Enough: https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f... (Gist contains a bunch of Postgres ecosystems things, if anything is missing, please let me know) reply emmanueloga_ 4 hours agoparentKind of, with caveats. For one \"extensions can interfere with each other and cause incorrect behavior\" [1], and the practicallity of implementations varies. Say, Cypher queries using AGE can be order of magnitude slower than using a dedicated graph DB [2]. Yes, you can drive a Ford Falcon coast-to-coast, but how much gas are you going to spend? Postgres is a solid database but has roots in the 80s. Optimizing for modern hardware would reduce hosting costs and improve efficiency. [3] This isn’t criticism of Postgres as a database but of the idea that it’s inherently sufficient for all use cases. -- 1: https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-re... 2: https://blog.kuzudb.com/post/what-every-gdbms-should-do-and-... 3: https://cedardb.com/blog/ode_to_postgres/#why-is-everyone-st... reply SOLAR_FIELDS 3 hours agorootparentOf course there are better time series than Timescale. Better graph databases than AGE. Better GIS databases than PostGIS. The point made when it comes to Postgres is 9 times out of 10 you don’t need better thing. And unless you have that compelling optimization already ready to go with receipts to back it up, probably you should pick Postgres reply ants_a 2 hours agorootparentprevNot disagreeing, but for more context. These blog posts also have to be taken with a grain of salt as the authors obviously have their own project to promote, coloring their point of view. The algorithms detailed in the graph DB post can be run on top of PostgreSQL, though one has to do some of the work of the DBMS themselves (maintaining indexes, transforming query to correct form). It's extra work and requires some knowhow, but up to some extent it works \"well enough\". Similarly, the CedarDB comments, that could be boiled down to the lack of column major batched executor model, are mostly applicable to analytical queries. Point query and traversal type workloads are not as different. There are various projects that work around this to some extent by sticking DuckDB into PostgreSQL . This gets vectorized execution on mass data scans, which is usually enough to get into the right ballpark. The point being that the amount of use cases where Postgres is sufficient is highly dependent on the skill and time put into it. And at some point the extra organizational cost of going heterogeneous is going to be worth the payoff. The hard part is figuring that out ahead of time. Which is why my recommendations for starting developers is to just use Postgres until it starts to hurt, then optimize it to work well again and use the insight gained to see what functionality needs to be peeled off into a specialized system. reply caseyohara 2 hours agorootparentprev> Yes, you can drive a Ford Falcon coast-to-coast, but how much gas are you going to spend? Postgres is a solid database but has roots in the 80s. Optimizing for modern hardware would reduce hosting costs and improve efficiency. This is disingenuous. If you’re comparing Postgres to CedarDB, a more apt analogy would be Postgres is a late model Ford F-150. A utility vehicle with roots in the 80s but continuously improved since then. Not the most efficient vehicle or the fastest, but has lots of utility and great reliability. People have collectively driven F-150s for billions of miles. And CedarDB is a concept car that some guy built in his garage. It might be efficient but it certainly isn’t proven to be reliable like Postgres is. If I’m taking a coast-to-coast trip, I’m driving the F-150. I might not get there quickly or efficiently, but I’m sure I’ll get there. And if my F-150 breaks down, there are thousands of mechanics between the coasts that can help me get back on the road. If I take the CedarDB concept car, when it breaks down there are only one or two people that can help me, and they are thousands of miles away. reply pelagicAustral 4 hours agoparentprevReplication with Bucardo reply jasoncartwright 5 hours agoprevAfter coming back to coding after ~10-15 years away, databases are IMHO the most improved element of the dev/devops experience. Managed Postgres on Google Cloud is a fantastic product (I'm sure other cloud's offerings are also similarly good). Backups, replication, point-in-time recovery, managed updates, plus quick & easy system & query insight tooling. All for less than £1/day. reply eerikkivistik 4 hours agoparentWhile I do love Postgres and use it daily on AWS and Google Cloud, I will add that the managed Postgres on Google Cloud is a mess in some areas. For example they use some EOL extensions outdated for 10+ years (a specific example is GEOS) and refuse to update it and give no control for you to upgrade it either. reply refset 4 hours agorootparentI wonder where things will stand in 10 years from now. Will many orgs still be consuming vanilla Postgres, or will most workloads have shifted to ~proprietary implementations behind cloud services like \"Aurora PostgreSQL Limitless Database\" and \"Google AlloyDB for PostgreSQL\" due to unrivalled price-performance? In other words, can progress in OSS Postgres keep up with cloud economics or will things devolve into an even messier ecosystem centred purely around the wire protocol and SQL dialect? reply PittleyDunkin 4 hours agorootparentDatabases seem to grow much slower than other assets, so maybe this price advantage just won't be worth the vendor lockin. Hell my current extremely valuable postgres database worth literally millions of dollars is about thirteen gigs and could be hosted on my mac mini if I really wanted to. Still, the managed hosting is worth it—only without vendor lockin! reply ethbr1 4 hours agorootparentDBMS (and DBAs) tend to be more conservative, so extensions and implementations diverge much more slowly than, say, js. There's also the incoming business argument in favor of not diverging too far from baseline. If I'm AWS/Azure/GCP trying to attract a customer from a competitor service, 'completely rewrite your app to be able to use us' isn't a compelling pitch. MS SQL Server and Oracle have different incentives, but the cloud services would probably prefer portability and decreased maintenance / fork support load. reply cpursley 4 hours agoparentprevIf you think those are nice, check out neon.tech - set up was faster than any of the big cloud providers. reply jasoncartwright 4 hours agorootparentUnfortunately they don't have anything in a region where my code runs. Interesting though! reply nikita 2 hours agorootparent(neon ceo). What region are you in? reply jasoncartwright 2 hours agorootparentHi! London. reply nikita 5 minutes agorootparentOh, that's coming very very soon! London and San Paolo. Def in Q1. andruby 4 hours agoparentprevI love PG. PostgreSQL already had most of its great features 15 years ago. Anything new that you particularly enjoy? reply jasoncartwright 3 hours agorootparentI guess it's the zero-hassle managed service that's the improvement rather than the DBMS itself reply edoceo 4 hours agorootparentprevjsonb reply happymellon 4 hours agorootparentAt 10 years, it is newer than 15 but its not a new feature by a long shot. reply tmountain 1 hour agorootparentRLS (row level security) came out in 9.5, January 2016. It's a game changer when used in combination with JWT tokens for identity and something like PostgREST. Specifically because a client can talk directly to PostgREST and run queries directly against the DB while letting the RLS policies dictate access. Example, a mobile client is allowed to insert data on the auth'd user's behalf, but the same user can only access rows that are associated with their own identity. Supabase rolls this up into an out of the box solution, which basically eliminates a lot of work writing \"middleware APIs\". reply edoceo 3 hours agorootparentprevIt's been available for less than half the time I've been using PostgreSQL. I stil consider it new. reply ExoticPearTree 6 hours agoprevI wish someone that has resources to invest into making the replication in PostgreSQL seamless, easy to configure and easy to change masters without anything like pgbounce and friends. Otherwise, PostgreSQL is fantastic. reply sgarland 4 hours agoparentPgbouncer is a connection pooler; it has nothing to do with replication. That said, it’s not that hard to set up replication [0]. Properly tuning the various parameters, monitoring, and being able to fix issues is another story. RDBMS is hard. MySQL is IMO the easiest to maintain up to a certain point, but it can still bite you in surprising ways. Postgres appears to be as easy on the surface, buoyed by a million blog posts about it, but as your dataset grows, so does the maintenance burden. Worse, if you don’t know what you should be doing, it just eventually blows up (txid wraparound from vacuum failures probably being the most common). [0]: https://www.postgresql.org/docs/current/runtime-config-repli... reply orthoxerox 4 hours agorootparent> txid wraparound from vacuum failures probably being the most common Hopefully OrioleDB can upstream all the necessary changes soon. For those who don't know, it's a storage engine for Postgres that uses undo logs instead of vacuuming old records. reply oliverrice 2 hours agorootparentOrioleDB maintains a very small set of Postgres patches that are targeted for upstream. The storage engine that mitigates the need for vacuuming [1] is implemented in a standard Postgres extension, so that will still need to be installed by the Postgres host in order to take advantage of it. But yeah, looking forward to that day too! [1] https://www.orioledb.com/blog/no-more-vacuum-in-postgresql reply ExoticPearTree 3 hours agorootparentprevYes, you are right, but I was thinking of the ease of having a high-availability setup and pgbouncer was the first thing that came to mind. And yes, I read the documentation and it is still cumbersome to have an HA setup that is easy to maintain. This is what I mean and hope it is clearer now. reply qaq 5 hours agoparentprevProblem is primary devs of Postgres are consulting shops that make money in this space so making it seamless would affect their revenue reply throw0101c 4 hours agorootparentE.g., * https://www.enterprisedb.com/docs/pgd/4/bdr/ reply eatonphil 3 hours agorootparentI work on PGD but I'm pretty sure we actively support open-source options for HA: https://github.com/EnterpriseDB/repmgr reply homebrewer 5 hours agoparentprevI'm hoping for seamless upgrades at some point, like MySQL does it — you install the next major version and restart the daemon. It's completely unnecessary for major operators, but is a life-saver for small businesses, websites that don't need 99.99999% of uptime (i.e. almost all of them), in development, etc. reply rickette 5 hours agoparentprevOut of the box HA would make it complete. Apart from patroni, anyone experience with https://github.com/hapostgres/pg_auto_failover? reply jskrablin 2 hours agoparentprevTake a look at https://github.com/hapostgres/pg_auto_failover it's quite simple to use and manage. You can use libpq support for target_session_attrs (been there since Pg 10 - https://paquier.xyz/postgresql-2/postgres-10-libpq-read-writ... ) so you don't need active loadbalancer in front of your Pg cluster. You can however create your own health/status check service on top of pg_autoctl show state and use HAProxy if required. I don't think there's something easier to setup and manage than pg_auto_failover, Patroni always appeared very complicated to me. reply spprashant 2 hours agoparentprevWhat we really need is a de-facto open source tool to manage logical replication seamlessly. The devs have built all the pieces, and as of v17 there are very few limitations. But I am constantly tripping over the fact that I cannot observe how the replication is progressing, and a good way to mitigate failures. reply _joel 6 hours agoparentprevIsn't citus quite good at that? https://www.citusdata.com/ reply remram 3 hours agorootparentI think Citus only does sharding not replication. You can use it together with Patroni though. reply bblb 5 hours agoparentprevI would say Pgpool-II is still the best we got. This video covers pretty much all the practical stuff. I timestamped the parts in a comment. PgPool II Performance and best practices https://www.youtube.com/watch?v=bMnVS0slgU0 reply cpursley 4 hours agoparentprevTurning on replication in neon.tech is literally just a switch. And it plays well with a CDC library of mine: https://github.com/cpursley/walex reply cedws 3 hours agoparentprevI agree, Postgres is great but I think it's just a little crusty for cloud environments. Clustering should be built in and easy to configure. reply joduplessis 5 hours agoparentprevSomething pg native would be fantastic. reply himinlomax 6 hours agoparentprevPatroni is pretty good at this. reply eatonphil 5 hours agorootparentCan patroni replicate across mixed versions of Postgres? (i.e. can it do logical replication? [and handle DDL replication?]) I thought patroni only did physical replication (only replicates across the same version of Postgres). But maybe I'm mistaken. reply xiphias2 2 hours agoprevIt's a bit strange that SQLite went up only 1 place on the ranking (to the 10th). There's a lot of new articles of how to improve its performance and I love that I don't have to care about the n+1 problem so much. It is now the default production database for Rails for a good reason. reply jabwd 1 hour agoparentSQLite performance is kinda nutty. My design of the DB at the time was probably poor (but I was 15 so cut me some slack :D) but I made an app that had to run on iPod Touches at the time, so we could use the accelerometer for physics class in school. initially the performance was too poor, but after a bunch of reading and some changes in how I was using SQLite I got it to easily do more than 100k rows per second of insertions (the db wasn't very wide). On an old embedded device, mind you. Didn't need that much, but wowza! was my expression at the time. I've had a love for it in my heart every since. reply cpursley 1 hour agoparentprevDon't get me started on Rails and all the anti-patterns that Active Record introduces... reply nttdocomo 6 hours agoprevThe methodology and general concept of this is a bit silly IMO, but that being said I've never regretted going with postgres whenever I choose it. reply shin_lao 5 hours agoparentDB Engine rankings are not very reliable and are constantly gamed, they shouldn't be used for anything serious. reply pbronez 5 hours agoparentprevMethodology details available here [0]. They measure popularity by collecting at several flavors of online mentions, then normalizing and averaging them. Specific sources include: - Number of mentions of the system on websites, measured as number of results in search engines queries. […] - General interest in the system [via] Google Trends. - Frequency of technical discussions about the system [on] Stack Overflow and DBA Stack Exchange. - Number of job offers, in which the system is mentioned [on] Indeed and Simply Hired. - Number of profiles [mentioning] the system [on] LinkedIn. - Relevance in social networks [by counting] Twitter (X) tweets, in which the system is mentioned. Seems like a reasonable approach to me. They should add more social networks now that Twitter/X is hemorrhaging marketshare. Mastodon, Bluesky and Threads should be included. Honestly I see that all over… so many sites have Twitter integrations that haven’t even been update to X yet. Gonna take a while for the broader ecosystem to shift. [0] https://db-engines.com/en/ranking_definition reply paxys 4 hours agoprevFrom their methodology page (https://db-engines.com/en/ranking_definition), it seems they use: - Number of search results for each DB's name - Google Trends - Mentions in Stack Overflow etc. - Mentions in Tweets - Mentions in people's LinkedIn profile Probably gives a vague idea of popularity of the system, but the measure is otherwise pretty useless. reply INTPenis 1 hour agoprevI don't know anything about db-engines.com but I have literally been hearing nothing but good things in regards to postgres for 20 years now. My very first job the boss told me a story of how they helped a client who was throwing hardware at their mysql DB by migrating them to postgres. Ever since I've preferred postgres. Even though I couldn't tell you on a technical level what exactly makes it better. reply pjmlp 4 hours agoprevI wonder how they came to this conclusion given that the ranking page shows otherwise, with Oracle first, having a score of 1258.76 over PostreSQL at 4th place having a score of 663.41. https://db-engines.com/en/ranking reply pella 4 hours agoparentsee -> Methodology ( https://db-engines.com/en/blog_post/109 ) \"Methodology We calculate the DBMS of the year by subtracting the January 2024 from the January 2025 scores. We use the difference between each DBMS’s score, rather than a percentage growth, which would favor systems with lower popularity at the beginning of the year. The DMBS of the year is an illustration of how much each system increased in popularity during the year. You can read more about our exact methodology here ( https://db-engines.com/en/ranking_definition ), but in short we are ranking popularity of DBMS based on how much people are discussing and communicating about each system, including job offers, professional profile entries and citations on the web. job offers, professional profile entries and citations on the web. \" reply stonemetal12 3 hours agorootparentThe listed diff from Jan 2024 puts Snowflake at almost double Pg, and third place MSSQL server is next to last place. Even if they meant Azure when they said MS in third, it is still in negative territory while there are more than 20 dbs with positive ratings. Postgresql +15 Snowflake +28 MSSQL -78 So DB of the year seems to be based on feels rather than their numbers. reply paxys 4 hours agoparentprev> We calculate the DBMS of the year by subtracting the January 2024 from the January 2025 scores. Although by that measure Snowflake should be #1 not Postgres, so who knows. Seems like they are just subjectively picking what is more internet popular. reply mhartz 4 hours agoprevObviously there's some level of subjectiveness here, but how many years could they realistically have gotten his award? reply giovanni_or2 4 hours agoprevDeserved, Postgres is enough for 95% of normal use cases reply zild3d 5 hours agoprev [–] Confused why their ranking has postgres at 4 then? https://db-engines.com/en/ranking reply BrentOzar 5 hours agoparentBecause it's more about trends than current rankings. reply pbronez 5 hours agoparentprevThey specifically look at the absolute change from the score last January. Biggest delta = DB of the year. From the article: “We calculate the DBMS of the year by subtracting the January 2024 from the January 2025 scores. We use the difference between each DBMS’s score, rather than a percentage growth, which would favor systems with lower popularity at the beginning of the year. The DMBS of the year is an illustration of how much each system increased in popularity during the year” reply pseudocomposer 5 hours agoparentprev [–] From that site’s own info page: “The DB-Engines Ranking does not measure the number of installations of the systems, or their use within IT systems.” Their methodology, even as stated, seems to be pretty flawed. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "PostgreSQL has been awarded DBMS of the Year 2024 by DB-Engines, achieving this recognition for the fifth time, surpassing 423 other database management systems.",
      "PostgreSQL, with a history spanning nearly 35 years, continues to innovate, as seen in the recent enhancements of PostgreSQL 17, released in September 2024.",
      "Snowflake and Microsoft secured second and third places, respectively, with Snowflake noted for its cloud-based data warehousing and multi-cloud support, while Microsoft offers robust managed relational databases through Azure SQL Database and SQL Server."
    ],
    "commentSummary": [
      "PostgreSQL has been awarded Database Management System of the Year 2024 by db-engines.com, highlighting its growing popularity and recognition in the industry.",
      "Users are considering switching from Microsoft SQL Server to PostgreSQL due to high licensing costs and resource limitations, despite potential migration challenges.",
      "PostgreSQL is favored for its robust features and cost-effectiveness, making it a preferred choice for future projects, although some users explore alternatives like Babelfish to reduce costs."
    ],
    "points": 239,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1736854677
  },
  {
    "id": 42699099,
    "title": "Google’s OAuth login doesn’t protect against purchasing a failed startup domain",
    "originLink": "https://trufflesecurity.com/blog/millions-at-risk-due-to-google-s-oauth-flaw",
    "originBody": "Attention Required!Cloudflare . trufflesecurity.comCloudflare 901fe49deb2dd638 • 172.200.180.240 •",
    "commentLink": "https://news.ycombinator.com/item?id=42699099",
    "commentBody": "Google’s OAuth login doesn’t protect against purchasing a failed startup domain (trufflesecurity.com)200 points by simiones 2 hours agohidepastfavorite112 comments stackghost 1 hour agoIt's not 100% clear to me, from reading TFA, what the actual vuln is. Suppose DankStartup folds and I, being a morally-dubious sort of fellow, purchase dankstartup.net which I then use to sign into DankStartup's O365, or DankStartup's ChatGPT as a DankStartup employee. Isn't that a failure on DankStartup's part, to not shut down their business accounts? And isn't it also a failure on e.g. Microsoft or OpenAI's parts, since they're providing service to a defunct business entity who can't pay its bills? To describe this as a vuln in oauth doesn't really make sense to me. reply danudey 1 hour agoparentWell, think about it this way: 1. I create DankStartup and my company uses Google workspaces and Google auth for a bunch of stuff, like payroll. 2. DankStartup goes under and we close our Google accounts/let our domain lapse. 3. Someone else buys DankStartup.com, sets up a Google workspace, and attempts Google auth to log into stuff, and it works. The problem is that the original DankStartup has a Google account that they create in #1, and Google goes around telling other sites (via Auth) \"this is user X from company Y\". Then, the impostors in step #3 create a different google account with the same domain, and Google says \"yeah, these are definitely the same guys as before\", even though Google is fully capable of discerning that that is not the case; these are different people with a different workspace account, different names, different payment information, and so on, but Google is saying that if you're holding the domain you are therefore the same people as far as they're concerned and is asserting that to other companies. They are (or were) refusing to provide any indication to those other companies that these are not, in fact, the same people, so those other companies aren't even capable of doing their due diligence of extra validation if they want to. It's similar to looking at a driver's license and just matching the name rather than the actual ID number; it's possible for someone else to have the same name as you, and identity documents have unique identifiers for specifically that reason. reply stackghost 27 minutes agorootparent>Then, the impostors in step #3 create a different google account with the same domain, and Google says \"yeah, these are definitely the same guys as before\", even though Google is fully capable of discerning that that is not the case; these are different people with a different workspace account, different names, different payment information, and so on, but Google is saying that if you're holding the domain you are therefore the same people as far as they're concerned and is asserting that to other companies. Yep I understand the mechanism by which this gets abused; I think we just disagree on the implications. I don't work for Google but it seems from the outside that they're treating the OIDC subject claim as referencing the domain attached to the workspace account, or something similar. I've seen implementations where the `sub` claim is more granular, so to me that indicates the field is underspecified. Given all that, I suppose TFAuthor's proposed solution is a good way forward. I still think classifying this as an OAuth vulnerability isn't correct. reply johnmaguire 14 minutes agorootparentTraditionally, SAML / OIDC trust is established using public/private keypairs. Each IdP/SP pair gets a unique combination. In this case, a domain changing hands would not allow the new owner to gain access to the old owner's accounts. In the case of Google OAuth, it's possible to forego this in order to allow any Google user from any Google workspace to login to your application. See the distinction between \"public and internal applications\" here: https://support.google.com/cloud/answer/6158849?hl=en#zippy=... Some applications (e.g. Tailscale) take advantage of the public Google OAuth API to provide private internal corporate accounts. A common misconfiguration here is to use the domain portion of the \"email\" attribute - this can be spoofed by Google Workspace admins. That's not what's happening here. Instead, Google instructs you to look at the \"hd\" parameter, specific to Google, to determine the Google Workspace a given user belongs to for security purposes. This field cannot be overridden by Google Workspace admins. The trust breaks down when the domain changes hands, a new Google Workspace account is opened, but the old \"hd\" value is reused. You can read more about \"hd\" here: https://developers.google.com/identity/openid-connect/openid... (find the table and read the descriptions for both \"email\" and \"hd\".) You can avoid this issue by using a custom Google OIDC IdP configured for internal access only in your applications, rather than using a pre-configured public Google OIDC IdP (be very careful you mark it internal!) A new domain owner would not be able to retrieve the secret key you previously generated. reply anon84873628 28 minutes agorootparentprevIt seems there are two possible problems. The first is whether taking over a lapsed domain allows you to takeover an existing Google Workspace (or Cloud Identity) organization. This it what houses the corporate email accounts and OAuth client registrations. If Google allows this scenario then the linked account takeover is simply one symptom / side effect among many. TFA is not clear on whether this step actually happened... I assume not, since if it were the case we'd be talking about direct access to the Google account data rather than only linked SP accounts. The second is when an SP doesn't properly use the `sub` claim as a unique identifier. It sounds like some products don't understand this requirement and why it \"seems to change 0.04%\" of the time. I do agree that a unique identifier for the org itself would be a good addition to the token. That said, I'm still not clear how the second problem manifests if the old OAuth client creds (housed in the old Workspace org id) are invalid. Presumably attacker can login to the SP admin account using just email based password recovery, then reconfigure the OAuth integration with new secrets. In that case the SP is failing to do MFA on the email login. Would love to hear if I'm missing something. reply arnarbi 33 minutes agorootparentprev> They are (or were) refusing to provide any indication to those other companies that these are not, in fact, the same people That is not quite true, the sub field will be different. reply Ninn 29 minutes agorootparentBut authors does imply that sub will also change in place for users in step #1, without the workspace beeing recreated. And as such the sub is not usable as a general identifier for the user resource differentiation. reply anon84873628 25 minutes agorootparentThe sub property appearing to change for the same email address is a valid scenario. SPs failing to respect that scenario because they don't understand it, or because it's not what some of their users want, is not a valid excuse. https://support.google.com/a/answer/33314?hl=en&co=DASHER._F... To me it is reasonable that orgs may want to eventually reuse an email address on a different user account. That's a feature decision made by the IdP so SPs need to respect it. I believe other IdPs like Okta and Entra have equivalent features too. reply PKop 58 minutes agorootparentprevYes but he's saying the data on 3rd-party websites should be deleted by the failed startup when they shutdown not just left to sit there. reply PeterFBell 48 minutes agorootparentHe's right, but having failed a number of times, after you've put all your savings into the business, fired all your team, notified and disappointed all of your investors and customers, helped your team find new gigs, filed all the dissolution paperwork, handled all the taxes, disposed responsibly of all of the assets and you now find yourself out of work and often out of cash, occasionally you'll forget to jump through all the hoops to close down all of the SaaS accounts before you stop paying the bill personally to host the email accounts. Of course perfect world you shut down earlier and in a more orderly fashion, but there are so many cases of companies almost failing and then not, it's hard to shutter a company when there is a chance you may go out of business - especially when you feel you're getting close to another raise or becoming default alive :( reply scarface_74 43 minutes agorootparentprevThere are some 3rd party accounts that can be accessed via your SSO or via your personal credentials once you leave. The main ones I can think of is your brokerage account containing your 401K and vested RSUs and your payroll provider like ADP and Paylocity. You still need to have access to past paystubs and end of year tax documents. reply anon84873628 18 minutes agorootparentSSO should stop working when the IdP org is disabled/deleted. IdPs should not allow the org to be resurrected based solely on domain ownership alone. And if a new org is created with the same domain, the SP will need to be reconfigured with new OAuth client creds, and should be relying only on the `sub` claim anyway. Any accounts you need after leaving a company should be tied to your personal email. reply scarface_74 13 minutes agorootparentMy brokerage account could be accessed by both. I agree that is how it should work. But my brokerage account provider is never told to disable access via my IdP. It’s up to my former IdP to not do something stupid like giving someone else my old email address. reply rahkiin 53 minutes agorootparentprevAny domain takeover allows email takeover which allows you to send password reset emails for former employees. Does not matter if it is with oauth or not reply mtkd 31 minutes agorootparentAnd many vendors will send \"restart your service today for $x\" for months afterwards so data not deleted Some SaaS ecommerce platforms and email marketing services will likely give a restarted domain entire customer databases ... reply rahkiin 18 minutes agorootparentThere should be some service for permanently destroying a domain with a single prepaid cost. Somehow preventing bankruptcy laws from getting the domain. Pay X$ up front, then Y$ per month to keep active. Once you cannot pay, it gets blocked forever (paid for by the up front cost). Owned by your service provider so not part of your firesale reply anon84873628 17 minutes agorootparentprevThose password resets should have some sort of MFA step. reply simiones 1 hour agoparentprevYes, why the Slack or HR or interview etc. data would still exist while being inaccessible to the original owner is very strange. The article seems to take it as a foregone conclusion that those accounts should all be expected to still exist with all the business data, and I don't know if this is based on the author's experience, or it's just a way to make the vuln sound far more serious than it really is. On the other hand, I don't think people normally expect that OAuth depends strictly on domain ownership like this. I think most would expect that it depends on some kind of secret being stored on the IdP account side, uniquely identifying the IdP account holder beyond the email addresses presented. With regular password-based authentication, with MFA, you would at least get an MFA prompt if someone had gotten access to your email address and was being sent a password reset code. But with this type of SSO, any MFA verification is done on the IdP side, so if the IdP recognizes anyone who controls example.com as the rightful owner of any claims, then there is nothing you can do as the former owner of example.com. reply chasemiller 1 hour agoparentprevYes, it's a failure on DankStartup's part. Not really much different than a user buying dankstartup.net, setting up a catch-all email, observing what comes in, and performing password resets for those accounts, allowing for account takeovers. Calling it a vuln in oauth may be a bit hyperbolic, but Google could help prevent it. reply OkGoDoIt 1 hour agorootparentI have catchall email accounts in every domain name I own (mostly so I can do differentiated emails for every service to track/combat leakage), and you would not believe the amount of emails I get that are intended for previous domain owners (and typos too). I haven’t actually done any reset password flows, but there are a bunch of social media and SaaS accounts I could easily take over if I wanted. I used to try to track down whoever the emails were intended to go to and forward it to them and let them know to change it, but that got to be too tedious so nowadays I just ignore them. Still, I wouldn’t call this a vulnerability on the service provider’s part, it’s just user negligence. reply LocalPCGuy 27 minutes agoparentprevThe scenario I was envisioning was a simple as a developer that worked at that startup added DankStartup email to their Github account, committed a bunch of code. Company shut down, but dev doesn't think to disassociate that domain/email. Malicious actor uses this technique to then sign into the Github account, gaining access to that developer's account, not just the DankStartup repos which were probably disabled after non-payment. Now, obviously some fault in that scenario lay with the person who 1) used the same account, and 2) didn't remove the old email once the startup failed. But I'm just using that as a kind of example - there may be other accounts as others have said that need to be accessible years down the line, like financial records and the like, regardless of whether the company is still around. reply placardloop 1 hour agoparentprev> Suppose DankStartup folds … Isn't that a failure on DankStartup's part, to not shut down their business accounts? Expecting an entity that has already failed* to not fail again isn’t an effective security control, unfortunately. * - not every startup that folds has “failed”, but the point still stands reply stackghost 1 hour agorootparent>Expecting an entity that has already failed* to not fail again isn’t an effective security control, unfortunately. Sure, I'm sympathetic to that, but again I don't see how that's within the scope of oauth. reply danudey 58 minutes agorootparentI register a Google Workspace and add CorpDomain.com to it. I then use that to OAuth to other companies (e.g. Slack, payroll companies, etc.). Then my company goes under or closes up and the domain lapses. Someone else comes along, registers a completely different Google Workspace but attaches that same domain to it. The e-mail address is the same, but it's obviously a new Google Workspace with new people, new payment info, new users, etc. Google knows that these are two different workspaces and that there is effectively no connection between the two other than the domain, but they are not presenting that information through OAuth (which is possible) so other companies are not able to do any sort of diligence in ensuring that the correct people are accessing that data. OAuth provides the capability to make this distinction, but Google is (or was?) refusing to provide data to other companies to allow them to make that distinction. This sounds hyperbolic, but Google is effectively lying to these other services that that someone else is in fact the original person that service expects, even though Google knows full well (or is capable of knowing) that that is almost definitely not the case. reply horsawlarway 33 minutes agorootparentI'm not entirely clear on what you expect in this case? You're registering with those 3rd parties using a property (the email address under corpdomain.com) that is now owned by the new party. This feels a lot like complaining that you hired a lawn service and told them to mow at your address, and then didn't update the address or cancel service after you moved. You've sold the domain. Assets associated with the domain are under the control of a new party. For all Google knows, you did this entirely above board and in a coordinated fashion. That new party controls the property. Email resets will also dump right into their hands (They control the MX records for corpdomain.com now...). Legally speaking, it's not even clear you're right - the new person might well be the person actually entitled and expressly supposed to be accessing that service as that account (if the domain was sold as part of an acquisition or sale). reply adamc 26 minutes agorootparentprevSeems like relying on domain alone is a design flaw of OAuth? reply placardloop 1 hour agorootparentprevIf a security mechanism doesn’t account for failure cases, it’s a failure of the security mechanism. It’s a hard problem to solve and I don’t have a solution, but it’s a core goal of every security tool to account for edge cases and failure cases like this. If you tell me that OAuth is completely insecure due to a security issue, it’s not going to make me feel any better if you say “but it’s totally not OAuths fault” - I don’t care who’s fault or scope it is, the end result of a security issue is the same, and to avoid it I’m just not going to use OAuth. reply horsawlarway 31 minutes agorootparentSo you use email/pass and the reset password email dumps right to the new party as well, because they control the MX records for the domain? reply lxgr 13 minutes agorootparentThat's why allowing account recovery using (exclusively) email is indeed a security problem. reply stonemetal12 6 minutes agoparentprevWhat if DankStartup doesn't fold and just forgot to renew their domain, or lost control of their domain for some reason. OAuth shouldn't let you Auth someone else's account just because you can hijack their domain. reply cosmotic 1 hour agoparentprevThird parties is google as single sign on. If such an org/domain is abandoned, a malicious person could 'resurrect' the accounts on those third party sites. It's kind of like a similar situation where a user deletes an email account and then someone else creates an new one in its place, and now they have access to all the third party password reset links. Except in the case linked above, the user never had the ability to delete their accounts before off boarding, and the abstraction isn't just an email, but the account itself. reply reginald78 1 hour agorootparentIn emails case all the larger providers I'm aware of retire addresses to prevent this sort of abuse, probably learned the hard way. Could Google OAuth do something similar here? It now occurs to me that large businesses might have the same issue with emails and former employees (easy to imagine John Smith departing and at a later date John Smith being hired) so I wonder how they typically handle this. reply scarface_74 37 minutes agorootparentCompanies generally don’t reuse emails. If you come back, you can sometimes get your old email and access to your old enabled services. I know when interns were at Amazon and left, their accounts were disabled. But when they came back, they got their old accounts back and the related Slack users reply stackghost 1 hour agorootparentprev>Third parties is google as single sign on. If such an org/domain is abandoned, a malicious person could 'resurrect' the accounts on those third party sites. Yes indeed, and that's exactly what I described in my hypothetical. But it's not clear to me why that constitutes an oauth vuln. reply YetAnotherNick 1 hour agoparentprevAnd not only that, almost every form of auth has the same vulnerability not just log in with Google. If you own the domain, you own the email IDs as well and you can very likely reset password. reply horsawlarway 19 minutes agorootparentYeah, this is the part I'm struggling with. This is absolutely not unique to google oauth, it genuinely seems like a misunderstanding of how the web manages trust. If you own the domain, you own all the property associated with the domain, including all the old email addresses. Magic links and password resets are all going to give the new owner access. Your best bet as a solution is to be using strict 2fa (ex - a yubikey might help here) but even that is likely just \"a conversation with support\" away from being circumvented. This is why winding down a company is supposed to have specific stages and policies associated with the dissolution. You don't just abandon the offices and leave all the filing cabinets behind either, for similar reasons... reply lxgr 12 minutes agorootparent> Magic links and password resets are all going to give the new owner access. Which is why you should never exclusively rely on either for sensitive services. reply ajross 1 hour agoparentprevThe contention isn't that you can impersonate DankStartup, that's obviously not a vulnerability since you are indeed the domain owner. It's that former entities with DankStartup accounts might have used OAuth to create relationships of their own. And when the startup folds, they don't magically disappear. Basically if Sally, the CTO of DankStartup, signed up for Taskrabbit or whatnot, it's possible for you as the owner of the domain to impersonate Sally in the context of that relationship. Obviously the root cause here is that someone misused an account to do something not related to the business. And the actual impact is probably low since high value services tend strongly not to take tiny email domains as identity roots (i.e. sally@dankstartup.com clearly doesn't have a Vanguard account to steal). So... like most security announcements it's oversold and spun. But it's real enough as I read it. reply OkGoDoIt 1 hour agorootparentWhy do you assume sally@dankstartup.com doesn’t have a vanguard account? I’ve absolutely had similar retirement account logins that became difficult to access once I left that employer. Had to contact HR and get them to help me log into my account. If the company had folded during that timeframe I would’ve been screwed. Of course for financial institutions you can probably recover your account through some identity proving process, and generally money transfers require a second factor sms auth, but a domain takeover would probably have been sufficient to at least get someone logged in and able to see my account balance. reply ajross 53 minutes agorootparent> I’ve absolutely had similar retirement account logins that became difficult to access once I left that employer. Yes, but your employer's email domain wasn't repurposed. It's still an operating business, and the account is still there, and still yours. And for accounting reasons they still remember who you are and can recover your important information for creditors, etc... The fact that it's difficult for you to access that account is a feature and not a bug, because it means it's difficult for others too. But you can, and people do all the time. The case here is failed businesses who have abandoned their domains and employee account history. Almost by definition that's a violation of financial regulation already. And this, btw, is the reason why DankStartup employees couldn't use their work emails to open Vanguard accounts. reply simiones 1 hour agorootparentprev> Basically if Sally, the CTO of DankStartup, signed up for Taskrabbit or whatnot, it's possible for you as the owner of the domain to impersonate Sally in the context of that relationship. I don't think this is the issue, unless someone went to some pretty extreme lengths. Configuring OAuth such that the company Google Workspaces account is recognized by Taskrabbit as a valid SSO option is not as simple as signing up to Taskrabbit with your company email instead of personal email. reply nijave 1 hour agorootparentEven then (in my experience) it's pretty common to setup an email based account and it will auto link to an oauth one that already exists. Even if Google revoked oauth, many platforms let you use the email directly to login reply ajross 22 minutes agorootparentYes, but that's not a bug with Google OAuth. If Taskrabbit (in the example) decides to trust dankstartup.com emails as a root of trust for identity even though the business failed, that's on them[1], and certainly nothing Google can have prevented. The contention in the article is that dankstartup.com's new owners can leverage their control of the domain to get access to existing OAuth-based sessions that will look to the service providers as if Google has authenticated the account holder. [1] And just to repeat: that risk is precisely why serious businesses (Vanguard in the example) don't allow obscure email domains as authentication anymore. reply ensignavenger 1 hour agorootparentprevThat sounds like a TaskRabbit vulnerability (in your example), not a Google vuln? It is also a vulnerability in any email based sign in, which relies on email alone without a password to demonstrate account ownership. (Including password resets that rely on email). reply riffic 1 hour agoparentprevit's vital to have extremely skilled and nuanced people managing bug and security report triage because it seems many can overlook the complexities being given. reply VILINBR 1 hour agoparentprevwhats is TFA ? reply 0xffff2 56 minutes agorootparent\"The F-ing article\" (derived from old internet slang \"RTFM\", for \"Read the F-ing manual\", a thing that new users were prone not to do before getting online and asking questions easily answered by RTFM.) reply VILINBR 52 minutes agorootparentthanks reply danudey 57 minutes agorootparentprev\"The f___ing article\" reply codetrotter 48 minutes agorootparentIn polite terms it can also mean “the featured article”. And IMO it makes more sense to read it that way in a top-level comment. Whereas reading it as the f’ing article makes more sense when the word “TFA” is used in a response to another comment like “well, you say that but TFA said such and such”. reply VILINBR 55 minutes agorootparentprevthanks reply ds 3 minutes agoprevNearly a decade ago, there was a website called thehunt.com that basically ran out of money and some employees were acqui-hired by pinterest. All of the assets were left to rot and at the time the company was a good match for another startup of mine. So I reached out to the investors I found on crunchbase and asked if I could acquire everything. We worked out a deal and I did. The issue was the complete lack of people from the old company willing to assist and the complete lack of data for alot of things. There was 1 or 2 people who we could ping from the old company to ping who were super helpful, but the big thing was many things were just lost to time- passwords, history, code repos, etc.. Simply creating a new google apps account allowed us to get full access back to everything - We could even read old slack messages (even DMs!) by resetting each accounts password. The whole thing was shocking to say the least, but with that access we got back into literally every service they used and managed to get it up and running again within a week, which was a good thing because nearly every service it was using was threatening to shut it down every day for lack of payment. I think the solution here is actually way simpler than most make it out to be and could easily be a startup for someone: Create a startup that lets customers simply enter in domains. If the domain EVER goes into the \"pendingDelete\" status, inform the customer. The customer would be random SAAS's that want to protect against this type of attack and could simply choose to disallow access to any account that has had their domain go into that status. reply loginatnine 1 hour agoprevI really don't understand here, the proper way to use Google's OpenID implementation to authenticate someone is to use the `sub` claim. Don't use the email, don't verify it yourself, use the `sub` claim. It's a known fact and is properly documented[1]. If the `sub` changes, it's because it's not necessarily the same person so have a flow ready for that. It could be an employee left and came back, a domain change, an IT error that lead to a reprovisioning of the user, etc. I also fail to see how the proposed solution of having a 'A unique user ID that doesn’t change over time' is different from the `sub` claim. However, the new ID associated to the domain could make sense to enforce a strong 'Everyone from the @domain.com has access' statement. [1] https://developers.google.com/identity/gsi/web/reference/js-... reply JohnMakin 1 hour agoparentI've implemented OAuth flow glue logic a bunch in my career and I agree that the logic doesn't seem to follow from what the documentation says. What's not clear to me though while reading this is, if I delete/lose a domain, and someone re-makes the domain and account with the same email address, does the sub value then change? The docs would seem to suggest yes, but then I am not clear what google actually ended up \"fixing\" in its bug bounty. Was that maybe the bug, and this is just not clearly explained in this post? reply Timshel 1 hour agoparentprevIt all depends on how true this statement is: > “The sub claim changes in about 0.04% of logins from Log in with Google. For us, that's hundreds of users last week”. reply loginatnine 1 hour agorootparentI've been working with an app that uses Google to login for the past 10 years, and I've had problems with sub changing when these situations happened : - Domain change - Company being bought by another one and being integrated in their Google Workspace - Employee leaving and coming back To us, it's very very far from the quoted 0.04% which is to me very high. I had to deal with it 5-6 times in the past 10 years but of course that number will vary depending on the usage of your app and I'm not gonna venture and put a percentage on it. reply herczegzsolt 55 minutes agorootparentIn my opponion, all of those cases very well justify a manual check, or some sort of extended identification before the user is let in. It indicates a deeper cultural issue of \"convenience/profit over security\" if those are sufficient reasons to not check the sub parameter. reply saguntum 1 hour agoparentprevYeah, I'm not really clear on the vuln. It sounds like clients don't validate sub claims because they are unstable? Google's docs say they should. When I first read the post, I thought that maybe Google was reusing sub claims when they shouldn't, but on a closer read, maybe it's the opposite problem - that the sub claim is changing when it should not change? From the article - “The sub claim changes in about 0.04% of logins from Log in with Google. For us, that's hundreds of users last week ... Because the sub claim is inconsistent, it cannot be used to uniquely identify users - leaving services reliant on the email and hd claims.\" So maybe clients aren't using the sub claim because validating \"email matches && sub matches\" breaks real users who are not actually changing accounts? AKA, Google is changing Google Account IDs unpredictably? That would be a bug on Google's part IMO. If those account IDs in the sub claim are changing, at the very least that's a bug in the doc you linked IMO. I'd have to read the full OIDC spec [0] to see if the sub must remain constant for the same end user, and if clients are required to validate the sub claim before processing a login. If so, and it's changing without the end user's identity changing, that is a bug in Google's implementation and client implementations for anyone using Google as an IDP. If it's allowed to change, though, and validating sub claim is not required in the spec, maybe clients are correct in not relying on it. [0] https://openid.net/specs/openid-connect-core-1_0.html#rfc.se... Edit: from reading the sign in with google overview, it's unclear if they claim to be OIDC compliant: https://developers.google.com/identity/gsi/web/guides/overvi... it says it's \"based on OAuth\" rather than \"implements OAuth+OIDC\" so I guess not being fully spec compliant wouldn't necessarily be a \"bug.\" reply andrewstuart2 1 hour agoprevThis is more of a fundamental issue with the way we rely on DNS to secure *gestures wildly* all the things. The fact that domains can expire and be registered by someone new allows the new owner to do almost anything the old owner could have done when it comes to anything trusting email addresses, or anything else relying on DNS (ACME certs) for authentication. It's great for \"do they own this right now\" validation and that's what we use it for, but beyond that links will be saved, email addresses will be added to databases and address books alike, and that's more or less a reality of most systems. For example, my snail mail (and occasionally packages) is still mistakenly delivered to my former addresses from time to time just because it's hard to track who has that address, and update it everywhere. The same goes for internet infrastructure. reply simondanerd 1 hour agoparentI was able to take over an Instagram account because I received a password reset email to a domain catch all address that I'd set up years ago. Turns out it was a whole brand, but they refuse to change the email address and don't understand that I'm going to shut it all down. It totally makes my site look bad (it was an adultish brand and I was working on a community project) and I now have the power (and ability to do whatever with the account and any other that I happen upon with an email at that domain. reply gmuslera 1 hour agoparentprevAt least it counts as a new category on the \"It's DNS fault\" list. reply Pxtl 27 minutes agoparentprevI disagree. DNS stores enough information in WHOIS to see if ownership has changed, it's not DNS' fault that nobody looks. Probably the least-wrong thing to do with current DNS is to have authentication servers keep track of the WHOIS UpdatedDate of email domains. If a WHOIS UpdatedDate is newer than the corresponding user's linked email address verification, that user's email address is no longer trusted. Next time they log in ask them to update or re-confirm their email address, and if they try to password reset they can't use an unconfirmed email address. Yes that's more tricky work. Authentication is hard. Nobody should be DIYing authentication anymore in this day and age, it's just too much. reply niij 25 minutes agorootparentWhat does this protect against? If the WHOIS changes because someone new buys the domain then they could simply receive this reset emails, no? reply paxys 8 minutes agoprevIt's crazy just how little effort it takes to get a \"Google = bad\" article to the top of HN. There is no vulnerability in Google OAuth. This is exactly how every OAuth server is supposed to work. If you take over a domain, you automatically own every email address in that domain, and thus whatever external account relies on that email for login. Heck the result would be the same even if that service didn't use Google OAuth, or any OAuth at all. Nothing in that write-up makes sense. reply Ronnie76er 19 minutes agoprevAs others have noted, this feels like an issue in the relying parties not relying on the `sub` field to validate the user. It feels the exact same as this issue here: https://bhavukjain.com/blog/2020/05/30/zeroday-signin-with-a.... In both, the details around the `sub` field, the field that should actually be used to identify the user, is poorly described. I would say that both of these feel a bit sensationalist, but then again, if relying parties are NOT using the sub field to validate users, they should be called out. It seems to be that a good way to make some money is find every such situation where RPs are not using sub, and submit vuln bugs. reply mcflubbins 1 hour agoprev> They also classified the issue as a “Fraud and abuse” issue, rather than an Oauth/login issue. I can _kinda_ see that, I agree they should mitigate it as best as possible too though, especially since they're Google after all. > I thought this would be the end of the story, but 3 months later, they re-opened my ticket (after my Shmoocon talk was accepted), paid a $1337 bounty, and said they were working on a fix. Sad how the only way to get Google's attention to make enough noise about something... reply dylan604 1 hour agoparent$1337 is a very curious amount. Surely, someone was being clever??? reply chasemiller 1 hour agorootparentyeah, google likes to have fun with the Bug Bounty program. See: https://bughunters.google.com/about/rules/google-friends/662... reply dylan604 23 minutes agorootparentit's funny that all of the soul has not been sucked out of the entire company reply mega_dingus 1 hour agorootparentprevIt's leetspeak It spells \"leet\" - see https://en.wikipedia.org/wiki/Leet You're too young to have used BBSes :) reply dylan604 1 hour agorootparentWhat are you on about? You clearly missed the sarcasm. reply richbell 1 hour agorootparentYour comment didn't seem obviously sarcastic. Intent is hard to convey over text. reply banger180 1 hour agoprev> “The sub claim changes in about 0.04% of logins from Log in with Google. For us, that's hundreds of users last week”. What I don't understand is why the `sub` claim is not consistent for those users at Google. To my understanding of the OIDC protocol the `sub` should be unique for a specific user. Additionally as far as I understand if you take over a defunct domain and create a new google workspace with new users those new user account should get assigned a new `sub`. reply caleblloyd 1 hour agoparentI agree, in my limited experience the sub remains consistent even when changing the Google Workspace domain. So the email changes but sub remains the same. The issue seems to be clients matching on email/hd claim instead. I wonder what action is causing the sub to change like the author suggests is happening. reply banger180 1 hour agorootparent> I wonder what action is causing the sub to change like the author suggests is happening. Indeed this would be very interesting. This issue is also very similar to CVE-2024-25618. What we did to mitigate this is the following: - Federated login with OIDC - Look for a user based on the sub claim - If they are found: authenticate that user and optionally update their profile (email, name, ...) based on then new id claims. - Else look for a user matching on the `email` claim and link the `sub` to that user - If no user is found create a new one reply loginatnine 1 hour agorootparentprevAt my current company, if an employee leave and come back, they'll keep the same OID in Entra but they'll get a new `sub` in Google workspace. We had to put in place a process to be able to use an internal tool that used the login with Google. That's most likely dependant on how the IT department handled the deprovisioning/provisioning of users in our Google Workspace, I unfortunately don't have the details for that. reply saguntum 54 minutes agoparentprevThat sub identifier changing without the underlying user changing may be the core of the bug. It's not fully clear from the post IMO. I posted a little breakdown here: https://news.ycombinator.com/item?id=42701030 I don't think the article clearly states one way or another whether those 0.04% of sub claims changing are legitimate end user changes or not. If those sub changes are legitimately the Google Account changing, I don't think that's a bug on Google's part, but rather is a problem on the clients' side for not validating the sub claim. If the sub is changing without the Google Account user actually changing, maybe something internally at Google is swapping out those IDs when it shouldn't be. It doesn't look like a UUID from the example I saw, so maybe there's some code somewhere to just change the user's ID if there's a collision or something? Interestingly, I don't think Google claims that Sign in with Google is fully OIDC-compliant. At least in the overview I linked in my comment, they compare the implementation to OAuth+OIDC, but I'm not sure they claim to be 100% spec compliant. reply robertlagrant 1 hour agoprevThe \"millions of accounts\" is highly speculative, is it not? It relies on the idea that failed startups keep their SAAS accounts enabled, rather than offboarding correctly. reply hangonhn 1 hour agoparentYou would think that because you're a reasonable person. However at my previous startup, which no longer exists, the new CEO failed to save the company and parachuted out so fast that the company who later acquired the startup couldn't get the domain name transferred to them because the CEO and CTO were both gone. They had to bring back the predecessor CEO because he was still able to log into the registrar to transfer the domain. In the case of a fire, some less than conscientious people will fend for themselves first and don't give a second thought to anyone else. reply robertlagrant 1 hour agorootparentI agree there will some number of companies doing this, between 1 and $number_of_companies. I'm just saying it's pretty unlikely it's all candidate companies, which the article seems to be saying. reply toss1 1 hour agoparentprev>> is highly speculative, is it not? I'd say NOT. Shutdown of a small company running out of funds is rarely fully orderly. Critical things may get taken care of, but everything is unlikely, as people have already left. Plus, with things like already-paid-in accounts, there's even an incentive to keep them open until the term expires, e.g., why not keep the prepaid ChatGPT API account live for execs and techs to use between jobs? Just like wiping hard drives on EOL computers — everyone should do it every time, but people are always finding full HDDs and SSDs on eBay and Craigslist... reply dylan604 1 hour agorootparentalso, there are lots of non-technical people running small businesses that use G services because that's all they know. They can barely operate them let alone be cognizant of things like this \"exploit\". reply bpodgursky 1 hour agorootparentprevNot just this, but execs and employees like to keep websites live for a while while they job-hunt (otherwise their resume has dead links). And ideally keep their name@startup.com email working. But to keep those running requires a long tail of \"live\" DNS and finance stuff you can't quite close out. reply dylan604 1 hour agorootparentWouldn't it be cheaper just to pay for the domain registration for an extended time like 10 years vs the 1 or 2 year options? reply dvydra2 37 minutes agoprevThis actually happened to me a few years ago when I closed my consulting company. My bad, I know. My domain was taken over by someone in Vietnam. Back then, he was actually able to see my old emails via the Google Apps. Grandfathered free Apps accounts was a big part of the value proposition. He demanded $500 to delete my emails and docs. I offered $50 for his trouble since I recognized that I was at least partially at fault but he refused. To his bad luck, one of my main clients was Google itself. I reported him via my internal connections and the next day got the following email: \"Oh my G-d, all forty of the domains I bought got Google Apps cancelled\". reply erincandescent 1 hour agoprev> To resolve this issue, Google could implement two immutable identifiers within > its OpenID Connect (OIDC) claims: > 1. A unique user ID that doesn’t change over time. > 2. A unique workspace ID tied to the domain. 1. is the OIDC `sub` claim! I strongly suspect that in those 0.04% of accounts where the anonymous quoted engineer reports that the `sub` claim changed, what actually happened was some provisioning/onboarding/offboarding system resulted in the account being deleted and recreated. 2. is sensible, and is just a versioned version of the `hd` claim. reply anon84873628 47 minutes agoparent1. Yep, your hypothesis seems likely. Consumer gmail addresses can't be used again after they are deleted, but it seems in Workspace orgs they can be reused/reassigned after 20 days: https://support.google.com/a/answer/33314?hl=en&co=DASHER._F... If services are not respecting the `sub` claim in this case, then they are giving the new Google account access to the old account's data. Companies probably wouldn't complain about this because they think it is the expected/reasonable behavior. Also it's likely that in many scenarios it is the same human behind the different accounts, e.g. if they leave a company then return. reply tom1337 1 hour agoprevIs this really an issue? Back when I implemented Google OAuth I used the \"sub\" that Google gave me as well as the email. I'd wager that Google does not re-use a sub for the same E-Mail so if the account is deleted and then somebody grabs the domain and re-created the account they'd have the same E-Mail but a different sub which would make the login fail. Seems to not be an issue in Google's OAuth Flow but rather the implementation on services like ChatGPT and so on?! EDIT: Just read that they claim that “The sub claim changes in about 0.04% of logins from Log in with Google” - never had this happen in the past years but if this is true then I guess thats a bad thing. reply throw0101c 23 minutes agoprevIn iSCSI, there are a few options for addressing the block storage devices, with one being the iSCSI Qualified Name (IQN) that uses the domain name. But it includes a timestamp: - A date code, in yyyy-mm format. This date MUST be a date during which the naming authority owned the domain name used in this format, and SHOULD be the first month in which the domain name was owned by this naming authority at 00:01 GMT of the first day of the month. This date code uses the Gregorian calendar. All four digits in the year must be present. Both digits of the month must be present, with January == \"01\" and December == \"12\". The dash must be included. * https://datatracker.ietf.org/doc/html/rfc3720#section-3.2.6.... * https://en.wikipedia.org/wiki/ISCSI#Addressing iqn.2001-04.com.example.storage:tape.sys1.xyz iqn.2000-02.edu.example.cs:users.oaks:proto.target4 * https://datatracker.ietf.org/doc/html/rfc3721 Clever idea to note change of ownership situations. reply swframe2 1 hour agoprevRelated maybe, I got a new phone number and I was able to use it to sign into the previous owner's account at a site that uses 2FA. I noticed it when I tried to setup a new account for myself. The website wouldn't allow it but it happily allowed to me access the previous owner's account. It was inconsistent, removing the phone from their account required their password but changing many other important fields didn't. reply maerF0x0 54 minutes agoprevSeems like we need a chain of custody for domains, not just current ownership. Kinda like real estate. And then accounts are tied not just to the ownership state, but also the ownership instance ID. Just don't tell the web 3.0 folks cause I don't necessarily mean a blockchain. reply verdverm 50 minutes agoparentWeb 3 already tried this, it was called Handshake. I think their downfall is they wanted to replace ICANN / DNS rather than work with and alongside the current system. reply seeknotfind 54 minutes agoprevDon't let domains you use lapse. Never get rid of a phone number. reply SillyUsername 50 minutes agoprevWell they have kind of known about this kind of problem for 14 years https://issuetracker.google.com/issues/35889152?pli=1 although this is not a domain issue it is one where people can't unlink from company project ownership. reply landryraccoon 7 minutes agoprevIf you think this is bad, wait until you move physical addresses and don’t notify all your creditors! Literally ANYONE who moves into your old house will have access to your bank statements, credit card bills, tax forms, auto registration and who knows what else. And it will all come plaintext and unencrypted! reply pfooti 35 minutes agoprevI think the problem is here in the doc: I have worked with a few of these downstream providers to look for a solution. There is a documented unique user identifier (the sub claim) that could theoretically prevent this issue, but in practice, it's unreliable ... According to a staff engineer at a major tech company: “The sub claim changes in about 0.04% of logins from Log in with Google. For us, that's hundreds of users last week”. The real solution is to use the sub claim, and not hd/email. If sub is unreliable, let's fix that. That said, I'm surprised sub is documented as unreliable here; I wonder if there is perhaps something else going on. I've done a lot of work with oauth and I haven't found sub to be so mutable, but then again, who knows maybe I just missed it? And yeah, lapsed domains => domain takeover => email takeover and impersonation will always be a baseline problem, independent of oauth. reply ciaovietnam 1 hour agoprevThe email returned by OAuth providers is not always verified and thus cannot be trusted, anyone relies on the email as the ID is open to compromise. The sub claim should always be used as the ID, if you can prove that \"the sub claim changes in about 0.04% of logins\" then it's Google flaw and they should fix it, otherwise it isn't and there is no need to add another ID to the claim. reply _pete_ 1 hour agoprevThankfully, apparently this only affects Americans. reply lysace 1 hour agoparent:-) reply r00tbeer 48 minutes agoprevAvoiding this scenario is why Google will renew all the domains for every startup it has ever acquired in perpetuity. reply simiones 2 hours agoprevI would be curious if any other Identity Providers that implement OAuth have mitigations for this issue. If you used sign in with Microsoft or Okta or PingFederate, would those provide different claims to the service? reply p_ing 1 hour agoparentIdeally the trust with the SP would be using a cert. This requires the SP to implement this portion of the standard and the IT department to follow through with implementing a cert. The cert can be self-generated, so there isn't a cost for the cert itself. reply ratg13 1 hour agoparentprevEvery provider has their own set of flaws. Microsoft had a flaw for awhile where you could just change a user’s email to anything with no verification.. and if the SSO implementer was only checking the email field, you could impersonate anyone. reply somanyphotons 41 minutes agoprevDomains are for life, you can never let them lapse reply richbell 1 hour agoprevI'm not sure I agree that it's a flaw in Google's OAuth implementation. Domain ownership is the source of truth for many systems and, as the article alludes to, expired domains can be abused in a variety of ways. reply verdverm 47 minutes agoparentWe've also seen this in the dependency management ecosystem. reply rdtsc 1 hour agoprev> Shmoocon talk accepted - Dec 9, 2024, Google re-opens issue - Dec 19, 2024 Wondering what the internal process there was at Google? Is someone's job to cruise around the various conferences and dev events to look for any Google mentions and report back. Did Google really consider it an issue or just wanted it avoid looking bad in public after the talk was accepted. reply dylan604 1 hour agoparentYes, there are roles where people do nothing but search their names/products/etc specifically to see what people are saying. Hell, some people do it on themselves to the point there are phrases like \"vanity search\" or \"egosurfing\" reply richbell 1 hour agoparentprev> Is someone's job to cruise around the various conferences and dev events to look for any Google mentions and report back. Someone in Google's security team likely saw the talk, or the original blog post, and pushed internally for them to award something. reply ongy 1 hour agorootparentYea. The leet amount of payout seems like this was someone saying that the classification was technically correct, but it's worth fixing either way and it'd be nice to pay an amount. reply riffic 1 hour agoprevGoogle may have quickly closed the original report because a company like that is soooo overwhelmed with garbage security reports and at first glance it is noise, not an actionable item to fix. there's a term for this that I can't quite recall off the top of my head. Bug Bounty Trolling? reply bananapub 1 hour agoprev [–] what a shitty headline and opening paragraph. anyway, if you use SSO on a domain and then let the domain drop, you're an idiot and there will be bad consequences for your data. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion highlights a vulnerability in Google’s OAuth login system when a failed startup's domain is acquired by a new owner, potentially allowing unauthorized access to services.",
      "This issue arises because Google may not distinguish between the original and new domain owners, affecting any system that uses domain-based authentication.",
      "A proposed solution is to use unique identifiers that remain constant over time, though the implementation of this solution varies among identity providers."
    ],
    "points": 200,
    "commentCount": 112,
    "retryCount": 0,
    "time": 1736871241
  },
  {
    "id": 42696822,
    "title": "Using coding skills to make passive income",
    "originLink": "https://www.coryzue.com/writing/solopreneur/",
    "originBody": "Using Coding Skills to Make Passive Income A decade of firsthand advice on going from an employed software developer to successful indie hacker running your own business(es). Jan 14, 2025 — 24 min read In 2017, I stepped down from my job as CTO of a 150-person software company to see if I could make money selling my own software on the Internet. Eight years later, I am now a full-time “solopreneur”—running a portfolio of revenue-generating software products as a full-time job. I now set my own hours, take vacation whenever I want, and, amazingly, earn more than I ever did as CTO. In the talk below, I’ll share how I did it and what I learned in the process. I’ll share the skills that programmers should pick up in order to start selling software on the web, including both technical and non-technical ones. I’ll discuss how to get started, evaluating your ideas, building your product, and getting your first users and customers. The talk will draw from years of work building and selling software myself, as well as the experience I’ve gained from helping hundreds of others launch their own businesses with SaaS Pegasus. If you’ve ever wanted to turn your coding skills into revenue-generating side-projects, I hope this talk both inspires and helps you to get started. TL;DR Someone on Reddit asked me to provide a TL;DR for the talk. This was my off-the-cuff response: First you have to make space in your life for it. You need long blocks of time for deep work. The first idea you pick is unlikely to work, so pick something and start moving. Many of the best products come out of working on something else. When building, optimize for speed. Try to get something out in the world as quickly as possible and iterate from there. Pick a tech stack you’re familiar with, that you’ll be fastest in. Try to spend half your time on marketing/sales, even if you hate it. The most important skill you can have is resiliance. Not giving up is the best path to success. This is hard because there is so much uncertainty in this career path. It’s worth it! The autonomy and freedom are unmatched by any other career. The talk This talk was the closing keynote of PyCon South Africa on October 4, 2024. It’s 30 minutes long, plus another 15 minutes of Q&A. Alternatively, read on for an annotated transcript which I made using a process very similar to Simon Willison’s. The transcript I’m going to talk today about using coding skills to make passive income. This email announcing the talk made me laugh, because the title does sound like clickbait. Hopefully this is the non-clickbait version of this topic. I’ll leave it to you to decide. First I have to explain my job. “So, what do you do?” Whenever I get this question I never really know how to answer it. The most boring answer that I give is I’m a software developer, but I also run my own business. If people know these words, I’ll say I’m a solopreneur or an indie hacker. If I’m feeling really specific, I’ll say I run a portfolio of revenue-generating technology products, which is a bit of a mouthful. If I’m feeling cheeky, I’ll say I make apps that make money while I sleep or… whatever I want? How I actually earn a living is through a portfolio of technology products that are monetized online. Basically that means I make stuff and I put it on the internet, and some of it makes money—either through a one-time payment, a subscription,ads, affiliates, etc. I have a bunch of different things that make varying amounts of money and every day I just kind of work on one of them, support it, build a new thing, and so on. Here’s how I got here: Sorry, this slide had a lot of transitions and so the image doesn’t translate very well. I started possibly like many of you in a normal corporate gig. I didn’t last very long and I joined a friend’s company called Dimagi. When I joined we were like three people and he was like ‘hey you want to be CTO’ and I was like ‘yeah I’ll be CTO’ and I basically larped as a CTO for a few years. But the company became quite successful, and then before I knew it I was the CTO of like a 200-person company and I had like a 35-person team under me. I was supposed to be a real CTO now, and I was, but I also kind of hated it. I was doing all these meetings and management and I hardly ever got to write code. And I eventually burnt out. So I told my friend I needed a break. I decided to take like a six-month unpaid sabbatical to figure out my life. On that sabbatical, I discovered this website called Indie Hackers which basically is a website that told stories of people doing what I do now—building these random apps and making a living off them. I thought “okay that sounds cool, maybe I’ll try that” and so I decided in those six months that I was going to try to earn one dollar doing this indie hacker thing. The first thing I did that succeeded was incredibly silly and I’m still kind of embarrassed about it, but it’s basically an app that lets you make place cards—those little cards that you find at weddings and other events. You upload a spreadsheet of your guests to this website, you download a PDF, you pay me like $5 (100 ZAR). And I was surprised that it actually worked! I made my first dollar and I was completely addicted. It was this most incredible feeling and so then I tried to do it over and over again. Eventually I thought “I bet other people want to do this over and over again too,” and so I got kind of meta and built this product to help other people launch their own apps. This is SaaS Pegasus—a configurable Django codebase that I now sell and how I make probably like 80% of my money now. Today, I’m blown away by how many people have built really cool products and really successful businesses on top of Pegasus code, including YCombinator companies and also just random people’s hobby project that they’re doing with their friends. It has over a thousand people using it, probably hundreds and hundreds of real products have been built with it, which is pretty fun. Let me now clarify some key attributes of this path. I’m talking about products, so the key thing is you’re not trading your time for money—this is something that someone just buys and you get paid without having to do an hour of work for it. I’m talking about monetized stuff. Passion projects are great, I love passion projects, but this is specifically for people who want to replace (or supplement) their income. I’m talking about bootstrapped, which basically means you’re not trying to raise money—you are trying to earn enough from your own profits so you never have to raise money and you can take the profits yourself. Finally, it’s a calm path—the goal is not to grow a 100-person company. You could, but my goal was never to grow a 100-person company, it was just to have this kind of calm, enjoyable life with lots of freedom. A relatively mainstream term for this is indie hacking. My goals for this talk are two: The first is just to kind of convince you that this is a possible career path that you can consider. I think a lot of people don’t think of this as a career path, but it is. And then if you decide that maybe you want to give it a shot, hopefully to give you some tips that help with your chances of success. Here’s my diagram for how this can be achieved: The first thing you have to do is create space in your life. For a lot of people I think this is probably the hardest part—just finding the space to pursue something like this. Then you enter this iteration cycle where you’re basically taking a shot at something, and if it doesn’t work out you apply the lessons learned and take a shot at something else. That doesn’t necessarily mean building a new product but could be trying a different approach to marketing, trying a different way of presenting the UX, and so on. Hopefully eventually something works and then you come out the other side and… profit! Let’s talk about making space first. So what do you need to get started? The kind of boring answer is, basically, nothing! Besides time. And you need a particular type of time where you can do deep focused work on a consistent basis. Which is not always easy to find. So how do you make time? I think the most common path is to fit it into your nights and weekends. This is my friend Wisani who created an app called Boardroom which is like Tinder for LinkedIn. It’s growing pretty popular in South Africa and he’s got like 10 other projects. He’s done all this while working a full-time job at Allan Gray and I think also getting an MBA. Doing this at nights and weekends is definitely the least disruptive way to pursue this career, but it’s really hard. For me, I have kids, I’m always tired at the end of a long day of work—this just wasn’t an option. So what if you can’t pull this off? Another option is to just kind of YOLO it. This is where you quit your job and you’re like “cool I’m going to quit my job and I’ve got twelve months of savings in my bank account and I’m just going to make this work.” I think this is usually not a great plan—it puts so much time pressure and financial pressure on you to succeed. And there’s just so much variance—it’s not like if you just work your butt off for a year you’re guaranteed to succeed in ways that some jobs are more like that. What I did, and the path that I recommend, is more of just a patient thing where basically you try to integrate this quest into your regular life in a slower and more sustainable way. Typically that means working less, and therefor either earning less—you ask your boss if you can have Fridays off and get paid 80% as much—or getting paid more per-hour by switching to contracting or freelancing. Then you build some products and basically whenever those products start earning, you can sort of re-adjust the hours until it works. This is my actual income for my first seven years on this journey: In 2016 I was a full-time employee. In 2017 I went on sabbatical and started doing this thing and I dropped down to halftime at my job and filled most of my income with consulting. I just tapped my network and said “I’m available, I’m going to charge a lot”. And thankfully, some people said yes. There’s this tiny little sliver of yellow there and that’s me selling those place cards. But basically what happened is that it was like a snowball that feeds off on itself and so year two I made a bit more, year three I made a bit more, and I eventually dropped down most of my consulting and then I finally quit my job. Obviously this took a long time, but the nice thing was that I was never stressed out. There was never any financial pressure on me. Now I’m going to jump into the main iteration cycle. I want to zoom in on what this looks like. It’s a simplification but basically you pick an idea, you build it, you sell it, and then you repeat. Going back to the “anyone can entrepreneur” thing—none of this is fundamentally hard; it isn’t rocket science. If you can teach yourself how to code you can teach yourself how to market, or how to validate ideas. This is all stuff you can learn. But it involves massive uncertainty. What that means is you want to go through the cycle as much as possible because on any given iteration you don’t know what the outcome is going to be. If you spend your first two years building a product and then come out the other side and realize nobody liked it, then you’ve wasted a lot of time. Whereas if you can figure out the product is flawed in two weeks or two months then you can go through the cycle a lot faster (and many more times). I like to think of myself as a one-person venture capital portfolio. A VC fund will typically invest in 100 companies and they will expect 90 of those companies to completely fail. But, if they find the next Facebook or the next Uber then everyone who invested in the fund makes tons of money. I think you should think of yourself in the same way where you want to take as many shots as you can on goal, hoping that one of them succeeds. Obviously you’re not going to be the next Uber, but you’ll start making $10, $100, and then eventually you can direct your energy into that project and grow it. Here are some examples from the indie hacking world about this: Sorry, this slide also got mangled by the transitions. Pieter Levels, who just sleeps in vats of money, says his hit rate on projects was about 5%. But that was still enough for him to have this incredible career doing a very similar thing to me. There’s this guy Rob Hope who is a South African—he’s got this project graveyard on his website where he documents all the things he’s tried that have failed. Another example from Twitter, this guy Pat Walls published his failures, and I stole his format and published my own version. Basically you can see I’ve done a lot of these things and only a small number of them have actually worked out. So a lot of things going to fail, and therefore you want to go through them as fast as possible. Let’s look at picking an idea. This is a diagram that I borrowed from a successful entrepreneur named Rob Walling. The key here is basically you want to walk up these steps of difficulty. You want to start on step one with the smallest, easiest possible thing that you can do. For me, that’s like someone can give me $5 to buy a PDF of placecards—that’s a very easy thing to build, and a very easy thing to sell. Once you do that, then you try to do it again, and again, and eventually if you are successful then you kind of own your own time. That’s step 2. Rob’s step three is to go do a big ambitious thing. I drew a dotted line there because you don’t have to go to step three—you can just have a bunch of step two projects and be having a nice life as a developer with a lot of freedom. Go take a moonshot if you want, but you can just do stuff in step two and I recommend that too. That’s kind of where I’ve landed. Start small is the key in terms of thinking about ideas. Your ideal first project should be easy to build, easy to support and easy to sell. And it’s actually good if it’s not a unicorn idea. Don’t try to build the next Facebook or Uber or OpenAI or whatever else—you want to find a really specific niche and go in there. So how do you come up with ideas? There’s lots of stuff you can read on the internet about this by people who know and see a lot more than me, so I’m not going to give specifics apart from saying just go do something! Using an example from my own life: I got married, we had this issue where we had to print these stupid place cards that led to me building this place card application and that was my first thing. Then I was building these applications and I was like “oh that’s another problem” so then I built SaaS Pegasus. Then I had this SaaS Pegasus community that I was trying to support and I kept answering the same questions over and over again so I thought “oh I’ll build a RAG chatbot.” Through building something I found a new problem and then I could go build something else. Don’t do something just because the first thing you’re going to pick is going to work, but do something because by doing something you’ll just get exposed to more stuff and then that will lead you somewhere interesting. Just keep following interesting problems until you find one that you want to solve. I want to quickly mention this book “The Mom Test” which is a great book about idea validation. The key point from this book is when you’re trying to pitch a startup idea to anybody, they’re going to talk to you like your mom would talk to you. You’re going to pitch your thing and they’ll say “sweetie that’s such a good idea, I love it, you’re going to be so successful.” People do this because they don’t want to burst your bubble. You’re coming to your friends, you’re coming to your co-workers saying “I got this cool idea for an app”—no one’s going to tell you that idea sucks, because they want you to not have your confidence destroyed. This is a really good book that hammers that concept home for you and then gives you a framework for trying to get around the fact that everybody’s kind of lying to you when you pitch your ideas. Now I’m going to talk about building and specifically building an MVP—a minimum viable product. Probably a lot of you have heard of MVPs. Basically it’s like you’re trying to build the smallest, useful version of your thing. In this example, a skateboard is useful—you can ride a skateboard and get from point A to point B, whereas if you have a wheel of a car or an axle of a car, that’s not useful. There’s also a concept called an SLC which stands for simple, lovable and complete, which I really like. Before we talk about MVPs, let’s talk about why indie products fail. Why do indie products fail? The main thing I want to emphasize here is indie products are different from most big company software that probably a lot of you have worked on. In traditional day jobs at places like Amazon, you’re probably dealing with legacy code and maybe the person who wrote it left and there’s no documentation and there’s all these scaling issues, performance issues—and none of this matters in the indie world. If you’re building independent projects, the reason that you’re going to fail is no one wanted what you were building, you didn’t market it, or you ran out of time, money and motivation. The takeaway is just when in doubt, optimize everything for speed. That optimizes for how fast you can get to market, how fast you can respond to feedback, how fast you iterate, and how fast you realize your idea was really dumb and you should go do something else. I’m not saying write a bunch of terrible code—I’m just saying be smart about it. Taking something like tests—you shouldn’t care about code coverage or anything like that. What you should care about “is if I write this test, am I going to be able to modify this code more confidently faster later?” If so, do it. If not, maybe don’t worry about it right now. In other words: “Don’t overthink it.” Now let’s talk about design. Design is often the weakest spot for developers and it certainly was for me. Thankfully, you don’t really have to be a designer to make good-looking things anymore. There are all these different open source and paid templates where you can just get these really beautiful designs that work on all screen sizes and they have component libraries you can just drop everything in. You really don’t have to do any design—you can just steal other people’s designs and I recommend doing that again just because it’s faster and because you can make it beautiful or unique later. Also, you don’t have to start from zero. This is a bit of a shameless plug but it’s also the case that I’ve seen a lot of people use products like SaaS Pegasus (mine) to launch their products way faster. They are called SaaS boilerplates, or SaaS Starter Kits. It’s a whole product category with both open source, free and paid options. These projects often have a ton of stuff built for you. Then, instead of your first two weeks just being “okay I’m going to build user accounts and I’m going to build billing and I’m going to build multi-tenancy” and all this stuff, you just have all that ready to go and can focus on the one thing that you need to do. Ok, big question: what tech stack should you use? There is a right answer to this. The answer is: the one you know. If you want to learn a new tech stack as a fun educational project that’s great, but if your goal is to get this revenue-generating product in the world, you want to be working in something you’re familiar with because you want to be as fast as possible. If you don’t know anything, just pick something popular. Popular things have the best communities, best documentation, the language models are the best at working in them and so on. I use Django, HTMX and Tailwind for most of my stuff—I like it but you should do what you know. And remember, if you’re not embarrassed by the first version of your product, you’ve launched too late. That’s a quote from the founder of LinkedIn. This was the landing page for Place Card Me that I used for the first year or something like that. Those are literally font awesome icons and just this giant stupid button. You have to get comfortable putting things out into the world that don’t meet your level of internal quality because you just have to try it. Starting the feedback loop is much more important than building a perfect thing. Let’s move on to selling. I think one of the biggest fallacies that I see in developers is this idea that if they build the best product in the world, they’re going to be successful. They think the reason that some software is successful is because it was the best product, when usually it is because that product had the best marketing team or some combination of a great product and great marketing. An uncomfortable truth is that you will need to spend a lot of time selling your product through marketing or sales. There’s this book “Traction” that I recommend, which is where I got the takeaway that I should be spending half of my time on marketing and sales. I think of it like eating my vegetables—I love coding, I hate marketing. It’s like “I have to do marketing today” and it’s like eating my vegetables before I can have my french fries. I also recommend selling your product before it’s ready. I’m sure we’ve all had this experience where you find some app that looks really cool and you want to sign up, and then you just get this popup asking for your email address. As a consumer, that’s super frustrating, but as an app builder this is really useful for two reasons. One reason is that if you can’t get someone to give you their email address, then it’s going to be very hard to get them to pay you. It’s a good proxy for whether you’re building something that anyone is even remotely interested in. You put this up, figure out a way to drive traffic to it, and get a bunch of emails - that’s a good sign. If you drive a thousand people to this website and don’t get any emails, that’s a bad sign. It’s also really important to have people to tell about your product when it’s actually ready. What often happens is someone will build in the darkness for a long time, they’ll launch their product, put it on Hacker News or something, nobody notices, and then they think that they failed. But they haven’t failed, they just had unrealistic expectations of success. If that person instead had a list of 200 people that they knew were interested in their product, then before launch they could email 20 of them and set up Zoom calls to walk through it and get feedback. You can iterate there, email the next 20, and so on. Then when you actually launch you email the whole list. Hopefully you have people jumping into your product from day one, and it’s better than it would have been otherwise. Let’s talk about getting your first traction. These are some strategies that worked for me. Communities are a really good place to find early users. The great thing about communities is they’re incredibly niche. If you’re building a product for plumbers who play Dungeons & Dragons, there’s probably a Reddit for that, probably 20 Facebook groups for that, and you can go immediately into those communities and talk to your ideal customer profile. One thing to know about communities is that all marketers use them this way, so communities hate marketers. They develop a pretty strong immune systems towards people doing marketing stuff. So go into communities tactfully, be nice in the community, add value, and mention your product when it’s relevant. This is a great way to find early users. Ads are another good way to find early users. Google sponsored links are very prominent, and you can use ads on tons of other platforms. Ads are great to try to answer that question of whether anybody wants what you’re building or if anyone can figure out how to use your product. You can just pay a bit of money for a hundred people to come play with your website and figure out what’s happening. I don’t recommend using ads as a way to make money—you will lose money on this exercise (at least in the beginning)—but you’re essentially trading early bits of money to do some user research. Cold outreach is another uncomfortable one that also works sometimes. When I was building Place Card Me, I spent an hour a day just reading wedding blogs and writing long personal emails to wedding bloggers. I would do this every day and most of them never responded to me, but one of them did. This person helped me tremendously in terms of teaching me about the industry, gave me backlinks on her site, and gave me some place cards designs. Cold outreach can be a good strategy, though it’s getting harder in the age of AI spam. It’s better to write one really good email or Twitter DM than to find some tool that uses an LLM to write a hundred terrible ones. Content is my main way that I market my stuff today. Basically, if you’re building a product for a specific industry you create content that’s useful for that industry. I target Django developers, so I write content about Django. Then people who are Googling how to deploy Django or how to connect Django to Stripe find my guides, and that’s a nice way to get exposure to my product. You get backlinks and so on. I do some of this stuff on YouTube now also. Video is huge—I don’t have really any YouTube following but it still drives a good amount of traffic. This is something that you can do as an individual, just writing these blog posts or recording little screencasts. I hesitated to put this slide on, but this was something that I did a lot which is called “building in public”—that’s just where you share what you’re working on publicly. I did this on my blog. You’ll see this on Twitter all the time; it’s gotten to be a very noisy channel. But the nice thing about this strategy is it requires no work. You just work on your project for two hours and then post a screenshot of what you did. Maybe a few people will find what you’re doing interesting, follow along your journey, and then they become little advocates that will try your products or connect you to other people. Now I want to talk a little bit about psychology. I lied with this diagram—this is not the only thing that happens. There’s another path which is not as good: giving up. Courtland Allen, who is the founder of Indie Hackers, interviewed hundreds of people who have gone down this path. When asked what his biggest takeaway from the success stories was, he said all you have to do is just not quit. There was no other generalizable advice he had—just don’t quit. So how do you prevent yourself from quitting? One way is by having infinite runway, which I talked about already. Setting things up so that money is not the reason you quit is a good way to eliminate that particular constraint. You still might run out of motivation, though. In order to stay motivated, I think one of the most important things to do is to just manage your own expectations. I like this quote from Bill Gates: “Most people overestimate what they can do in a year and underestimate what they can do in 10 years.” This really resonated with me. If you think “I’m gonna go down this path and take a shot and spend three months and launch my app” and then it didn’t work so you quit—that happens to a lot of people. Instead, if you think of it as more of a five-year journey or a ten-year journey, you’re just going to take these really small steps that don’t really look like they’re working, but they’re cumulative and eventually they add up. Embracing learning is another important one. This is kind of like a Dungeons and Dragon’s character skill chart—probably the average person in this room is a pretty good coder, maybe knows a bit about product and marketing and other skills. But in order to really succeed in this career, you have to look more well-rounded. The hard part is really just embracing the idea that you’re going to learn these skills that don’t feel comfortable. I’ve never enjoyed marketing or wanted to be a marketer, but it was something that I had to learn in order to sell stuff. If you’re not willing to get outside your comfort zone and learn things that are outside what feels comfortable, you will probably have trouble. Finally, be resilient. This is a funny graph showing how much money I was making every week on Place Card Me in the beginning of 2020. Things were going great—I was making up to $400 a week, and then all of a sudden there was a global pandemic and people weren’t having weddings anymore. My primary source of passive income just dropped to zero overnight. That’s just one example of things that happen to you because this is a very unpredictable career. The highs are really high, the lows are also really low, and you have to be resilient to these ups and downs. Going two weeks without earning any money and then one day a bunch of money appears in your bank account, it’s a very stressful thing. You have to get used to these big swings that you just don’t have in a salary job. But if you emerge on the other side, hopefully you can profit. This is from my very first blog post when I first started - I just wanted to get someone to pay me a dollar on the internet. That was my goal. Eight or nine years later, I am making more money than I ever made as CTO of my company. But more importantly, it’s a very nice lifestyle. I have time to hang out with my kids whenever I want, I can go on long vacations, nobody tells me what to do, I can take meetings whenever I feel like it (or never). So yeah, I recommend this career. And if it sounds interesting, I recommend you give it a shot, and see if you can make it happen. Thanks for getting this far! If you liked this you can comment below, share it, or subscribe to get email updates when I publish new stuff.",
    "commentLink": "https://news.ycombinator.com/item?id=42696822",
    "commentBody": "Using coding skills to make passive income (coryzue.com)167 points by czue 5 hours agohidepastfavorite90 comments _DeadFred_ 47 minutes agoWhen my life was falling apart and I was trying to fix my relationship with my ex she dictated that we spend 'quality' time together which meant watching horrible reality TV while she was on insta on her phone. Out of mind numbing boredom I made a system for SEO spam websites during this time. I would take expiring domain names (so names someone had gone to the trouble to research but been unable to make work) parse out keywords and lookup popularity for them, lookup ad rates for them, and spit out names to buy and make a SEO spam site for (goal was 300 websites making $1 a day or $100k a year), or good names to domain squat. If a domain turned out bunk I threw my link-spam-network software on it to provide linkbacks to my money/new sites. I made around 30k profit a year plus another $5k selling domain names doing this before life fell further apart and it rotted on the vine. I was really tempted to sell it as a package but could never bring myself that low even deep in addiction. Plus Google started cracking down on that trash. I still think the concept of 300 somethings (though please not SEO spam) that make a dollar a day is viable for us here though because we're in the unique position where the creation/maintenance is just a matter of our spare time since we can do the specs/design/coding/administration/maintenance/etc ourselves. It seems like there are still people doing this. Look at new car model forums. Everytime a new car models is released there's a rush to create discussion forums for that model with people hoping Google blesses theirs so they can add it to their portfolio of money maker car model forums. Maybe the secret sauce is forcing yourself to watch reality TV until your mind rebels and says 'fine, grab me the laptop and we'll make mind numbingly boring software products as that is at least better than watching this'. Edit: To clarify this wasn't my income source this was just what I did while being forced to watch 'The Kardashians' for bonding time. reply dmitrygr 30 minutes agoparentThe world does not need more spam. I do not think watching the Kardashians was punishment enough for you. I wish it was Barney theme in a loop at 100dB reply _DeadFred_ 2 minutes agorootparentYeah I was ashamed to share this anecdote. But decided maybe it can do a little good motivating someone to counter the bad. And I'm pretty sure SEO spam doesn't work anymore so it shouldn't encourage more evil. reply lngr 3 hours agoprevThis is what I call meta advice. He makes most of the money now from persuading others starting a passive income side gig, for which he coincidentally has a starter pack to sale. While this might be a reliable income, it is in no means a template for other people to start a successful passive income business with a working business idea. reply SketchySeaBeast 3 hours agoparentIt's been repeatedly shown that the best alternative source of income is selling to people looking for alternative sources of income. reply aatd86 3 hours agorootparentOne extra level of indirection always solves everything. reply ipython 1 hour agorootparentBusiness idea: I can sell you a list of people who you can then pay to tell you how to make money on the internet! reply el_memorioso 1 hour agorootparentprevExcept for too many levels of indirection. reply avgDev 2 hours agorootparentprevWhen there is a gold rush sell shovels. reply SketchySeaBeast 2 hours agorootparentThe modern version of that is GPUs. reply scarface_74 28 minutes agorootparentOr consulting… reply madcaptenor 3 hours agorootparentprevIt worked for Levi Strauss. reply czue 6 minutes agoparentprevThis is a fair general critique of a category of advice that I try hard not to fall into. It is true that I make a fair share of my income from a starter kit, but I tried quite hard to generalize my advice and only mentioned it in passing once or twice (and the only slide that really pushed it, I acknowledged it was a shameless plug). If you read my writing[1], it will be clear that I've been documenting my journey in a probably-too-transparent way long before I had a product that benefited from getting exposure to other developers. This talk is mostly just a distillation of that knowledge, because I have graduated from \"idiot figuring it out\" to \"experienced person who may be able to say something useful for beginners\". Also, for the record, I hate that starter kits became one of the trendy (and sleazy) products in this space, exactly because it generates reactions like this. I wrote about this last month[2], saying \"They make the whole industry look bad, and make me feel like a grifter selling Pegasus, even though I have worked my ass off on it for 5+ years and think it’s great. Maybe a corollary to this point is that I kind of don’t like marketing in my industry anymore?\" Again, I think it's a fair general critique and a correct reaction to this type of advice, and also I hope that I didn't really do what you said if you read or watch the contents of the talk. 1. https://www.coryzue.com/writing/ 2. https://www.coryzue.com/writing/dec-2024/ reply hn_throwaway_99 7 minutes agoparentprevDo you have more evidence of this? I'm genuinely curious. I read the whole post, and perhaps I missed it but I didn't see a breakdown of his income streams. I say this because, at first blush, I was glad that a bunch of the products he listed that he built seemed generally like real products that I could imagine people finding useful. I say this because it feels like, in contrast, so often in these solopreneur posts they're selling some kind of scammy SEO or ad-spam tool. So yeah, I'd be bummed if this guy turned out to be the tech equivalent of \"Buy my real estate investing course!\", and just curious if that's really what this is. Edit: Nevermind, I saw https://www.coryzue.com/open/. reply factorialboy 2 hours agoparentprevWell, I agree and disagree with this comment. For a minority % for whom Django is the tech-choice, there indeed is a product being offered. But for them, and the majority who might not choose Django, there is enough general-purpose advise in this essay. Everything is meta. Even a shower, a clean shave, and a well-tailored outfit can be classified as marketing / lead-gen / sales. As can brushing your teeth :) reply TheCapeGreek 1 hour agoparentprevCory built and grew SaaSPegasus to success long before the starter kit trend among indie hackers of the last year. reply scarface_74 26 minutes agorootparentEven that is selling a platform to other people trying to start a business that probably won’t be successful reply latexr 1 hour agoparentprev> This is what I call meta advice. That’s what I call a grift. Your description reminded me of Dan Olson’s fantastic video on that type of strategy—where you make money by selling the idea that anyone can make passive income by doing something the seller doesn’t themselves do (anymore)—using the Mikkelsen Twins as the example. In Dan’s words (emphasis mine), the Mikkelsen Twins aren’t special, grifters like them are a dime a dozen. He chose them as the example “because they are of a type. They are a representative sample of a category of grift. And also because they’re kind of incompetent and that makes them entertaining”. He’s not wrong. https://www.youtube.com/watch?v=biYciU1uiUw reply stronglikedan 1 hour agoparentprev> it is in no means a template for other people to start a successful passive income business with a working business idea. it is when the working idea is to sell a template for other people to start a successful passive income business reply bloomingkales 58 minutes agoparentprevhttps://youtu.be/Cv1RJTHf5fk The immortal grifter Tai Lopez lives on. I’m a lot more proud of bookshelf you see. reply sky2224 47 minutes agorootparentI can't believe that video is almost 10 years old now, wow. reply amelius 1 hour agoparentprevSounds like the main ingredient of a Ponzi scheme to me. reply ge96 3 hours agoparentprevsell the shovel reply czue 5 hours agoprevHere's an off-the-cuff summary: First you have to make space in your life for it. You need long blocks of time for deep work. The first idea you pick is unlikely to work, so pick something and start moving. Many of the best products come out of working on something else. When building, optimize for speed. Try to get something out in the world as quickly as possible and iterate from there. Pick a tech stack you're familiar with, that you'll be fastest in. Try to spend half your time on marketing/sales, even if you hate it. The most important skill you can have is resiliance. Not giving up is the best path to success. This is hard because there is so much uncertainty in this career path. It's worth it! The autonomy and freedom are unmatched by any other career. reply ryandrake 34 minutes agoparentThis is not really passive income. What he's describing is running your own one-person business. That's about as far from passive as you can get. Actual passive income is living off the returns and royalties from assets, doing nothing but managing those assets (or maybe not even doing that). reply grahamj 10 minutes agorootparentBut you have to work to get those assets, just like building a website reply martylamb 3 hours agoparentprevGood summary. I've landed on all of the above with my own projects, from a mix of experience, reading, and reason. Hardest for me has been making time between family, work, and other activities that are important for me. Unlike when I was younger I can't just stay up coding until 3AM anymore. In fact I find myself without the mental energy after work that I want to put into my projects, so evenings are out completely for me. So instead I wake up at 5AM and put myself into it before work. It was a big adjustment, but all I needed to do while acclimating to that schedule was ask myself each morning which I wanted more: warm blankets or a successful project? Now it's a pretty energizing way to start the day. reply scarface_74 21 minutes agorootparent> but all I needed to do while acclimating to that schedule was ask myself each morning which I wanted more: warm blankets or a successful project? I choose warm blankets lying next to my warm wife where my heat and shelter is paid by exchanging my labor for money 40 hours a week, paid time off, paid health care, etc reply gottagocode 1 hour agorootparentprevTake the warm blankets into the office with you reply latexr 1 hour agoparentprevIn other words, it’s the exact same bland, generic, worthless advice parroted by every grifter selling you the dream of financial independence via passive income. And if you fail, it’s your own fault, you just didn’t want it enough, you didn’t do the necessary sacrifices. reply flir 1 hour agorootparentThe advice (in the post you're replying to) isn't bad. But you can do it all, and still not have lightning strike. reply f1shy 58 minutes agorootparentI certainly do not think is good. I won’t say I’ve seen destroyed lives because of it, but pretty much miserable in comparison to what it had been if not followed the advice. It is just bot for anyone, and just too often fails. reply flir 53 minutes agorootparentAnd I've seen people succeed (admittedly by spending every spare minute devoting themselves to the pursuit of money). Can we agree that it is, at core, gambling? Like spending all your disposable income on lottery tickets? reply scarface_74 20 minutes agorootparent> And I've seen people succeed (admittedly by spending every spare minute devoting themselves to the pursuit of money). Is that what you call success? reply FrustratedMonky 4 hours agoparentprevWell, when you put it like that, it sounds pretty fluffy. reply sansseriff 46 minutes agoprevIf anyone has trouble focusing on personal projects at home, I've found Focusmate (www.focusmate.com) to be very handy. You hop on a scheduled google-meets style video call with someone random, and then just work. You talk very briefly at the beginning to tell each other what you're working on and then you both mute yourselves for 25 - 75 minutes. It's weird, I've found it really ticks my brain into productivity mode. reply supriyo-biswas 43 minutes agoparentDo pomodoro timers have the same effect for you? I assume it's the pressure of giving yourself fixed amounts of time and the knowledge of the fact that a break is coming up (so that you don't take one unintentionally) that really drives the productivity. reply coold 3 hours agoprevUsing your coding skills: 1) make hello-world-ish portfolio 2) sell courses how to make money using coding skills 3) PROFIT reply mettamage 3 hours agoprevOne part of me is itching to do it. Another part of me can't let it go that I can't beat leetcode interviews. I'm quite close, I think I can do it. I guess it's an ego thing. But not fully though is it? Earning a couple of years of FAANG money opens one up to then just travel the world. I'm from the EU but will make the switch to the US in about a year from now (marriage). So from that perspective, I just don't know if it's strategic. When you have $300K in the bank and you just go to SE asia, you also have \"no schedule\" etc. That should be doable with FAANG. I do feel this path delivers more impact though as life becomes a bit more like a game and you're creating your own quests. You're solving things that you are quick enough at to solve but also things that you find important or just simply fun. Man, I'm torn. Both take quite a bit of a time investment. I'm not sure how I can monetize a \"leetcode with me\" type of thing. If there was still a market for that, I might do that to start both things off at the same time. Maybe I should just become a Twitch streamer :') But I don't think that'd pay off. I guess it wouldn't hurt to try. reply jebarker 2 hours agoparent> Earning a couple of years of FAANG money opens one up to then just travel the world. If you can resist lifestyle inflation reply mettamage 2 hours agorootparentI could now but that'd be tough with kids. reply Mathnerd314 1 hour agoparentprev> you just go to SE asia I could see justifying a trip like that on a cost-of-living basis. If you go to a place like Thailand, you are going to be spending pennies on the dollar vs. the EU, even after paying incredible amounts (in local currency) for first-world conveniences like clean drinking water and internet. So in that sense if you are going to be coding and living life online, you might as well live someplace cheap IRL. But that's different from a tourist crawl where you are just spending money like water, which maybe was more your idea. reply Scubabear68 2 hours agoparentprevWith all the FAANG layoffs is this still a realistic goal for many people? reply mettamage 1 hour agorootparentFair question, maybe I'm a bit too starry eyed. What do you think? reply Scubabear68 1 hour agorootparentI think the question provided the answer. The market is being flooded with ex-FAANG developers and it is no longer a job seeker's market. In today's environment it is a LOT harder to get hired by anyone, let alone a FAANG company. I know really good people who have been out of a job for +6 months now. Based on past history, now is not the time to shoot for the stars, but to start consolidating your base and preparing for the next upturn. reply mettamage 25 minutes agorootparent> preparing for the next upturn. Prepare how? I fled to be a data analyst. For multiple reasons. One: the job interview was a cake walk (for me at least). I was unprepared and I aced it despite not really knowing what a data analyst was. It helps that I have a fairly good statistics background from back in the day. I'm also better paid since they don't pay software engineers that well in the Netherlands, so data analyst salaries seem more competitive locally. But yea, I'd be curious what you specifically mean by it. reply scarface_74 23 minutes agoprevHow is “spending my free time coding after I get off work instead of spending time exercising, spending time with friends and family, traveling, hobbies, etc”, “passive income”? reply czue 1 minute agoparentIf you read the post, that's explicitly a path I acknowledge I couldn't personally do, and I recommend instead creating time by doing things like going down to 80% time in your day job, or finding lucrative contract work. reply bsnnkv 1 hour agoprevGood timing with this submission as I started selling commercial use software licenses using a subscription model this year (Jan 2025) and I'm amazed that 6 people have already signed up and paid for a license. The text-based tech internet has become incredibly hostile to people sharing their work over the past decade, so a few years ago I decided to try and engage people through YouTube instead and I think this has been a decision that has really paid off. For people interested in pursuing something like this I'd definitely recommend trying out video format communication over blog posts and articles if the latter aren't doing well for you. I have done a lot of \"building in public\" on YouTube over the past few years and have built up a really solid product that people have been actively asking me to release a commercial license for so that they can use it at work. I feel pretty good about things right now! reply qoez 1 hour agoprevCool article. I feel like a lot of these 'passive income' things though are just 'X purchaces diffused over time until the market niche is saturated'; hence the need to keep making new sites/products reply daghamm 4 hours agoprevLooking at your portfolio, one could argue that to succeed you need to try a lot of different projects some of which you maybe have no personal interest in. I think some people would not be comfortable with this and rather take a steady paycheck from Big Corp while working on 1-2 darling projects at home. reply czue 3 hours agoparent...maybe? Although that doesn't quite ring true. Every project (even the dumb wedding cards one) arose from some need in my life that turned into a desire to make something exist in the world. That said, I totally agree that some people would rather keep the steady paycheck. The career is a large up-front investment with a variable outcome. But, it's not as hard as it can be made out to be, and the payoff, if successful, is immense. reply jamal-kumar 4 hours agoparentprevIt kind of mirrors my observations in what makes a successful individual in the world of ecommerce, you gotta have the capital to start like ten ideas at once then you whittle out which one don't profit more than 10k a month and come up with new ones to fill the place. Shit sounds like tedium or uncomfortable or whatever to some, but I know multiple millionaires on this tip. reply jbs789 1 hour agoprevKnowing how to code can have very useful local applications, which reduces your competition. Of course it may not immediately scale in the same way but leveraging connections and local know how is an angle that tends to go under-explored at least in the online narrative, is my observation. reply shireboy 1 hour agoprevThis is what I want to do ultimately, but I'm at a sort of crossroads. I have a good job, a consulting side gig, a good family, and 0 hours for my own ambitions. Several years ago I made about 20k on a solo project, so I know I'm capable. I just need to be able to focus on my dream instead of someone else's. Lately I've landed on 'it will happen when it needs to', but I also worry that I'm plateaued and will wish I'd risked it earlier. reply loxias 1 hour agoprevDimagi became successful?!? Awesome! I also worked there as a third person, though I don't think overlapping with you. :) Congrats on living the dream, I tried, failed at that 5 years ago (\"maybe i can just sell my coding directly...\") though I probably gave up too quickly. Nice article! reply roger_ 3 hours agoprevI’ve been wanting to do this for years but I’m still trying to figure out how to get started. My skills are more in algorithm development (statistical signal processing, machine learning) and electronics than web coding though, so it’s probably not as easy as just making a simple website that does something slightly useful. reply acuozzo 2 hours agoparentI'm in the same boat, but my domain is embedded programming. I recently ran across advice here to just copy an existing successful idea and compete on e.g., price, rather than wasting time trying to come up with something novel / innovative. The argument is that if the idea is successful, then most of the market legwork has been done for you already. I'm considering entertaining it. I last seriously did WWW-related work in 2001 or so, but Python with FastAPI + HTMX + Bulma CSS looks easy enough to spin-up on and maps pretty well to my now-ancient understanding of the web. reply roger_ 2 hours agorootparentI’ve done simple one off web stuff over the years and yeah it seems much more straightforward nowadays. Copying and undercutting someone else is certainly easier! reply avgDev 2 hours agoparentprevUnless you are trying to develop something ground breaking, web isn't terribly difficult if you have programming experience. Yes, there will be some new things to grasp. However, tooling is pretty great today and if you pick up a known framework most problems are already solved. You will just fit the pipes together to do what you want. reply TechDebtDevin 1 hour agorootparentCyber plumbing reply ge96 3 hours agoparentprevon the other hand I would venture to say there are less like you (demand) than generic web devs reply cootsnuck 3 hours agoprevGood post! I think the gradual transition you were able to do from salary -> consulting -> software products is very important and not the norm (mainly being able to keep part of your salary while doing some consulting on the side). The only people I've seen able to do that are VPs or C-suite. I'm below those rungs. So I'm quitting my job to go \"all in\" on the consulting. (But I've been prepping and will make sure things line up so I can hit the ground running.) All of this is to say, I think that transition either during or after salary work is the super important part that I see everyone gloss over. My goal is to make a fraction of my salary with consulting for the first couple years, focus just on that, and eventually shift my focus to software products. reply ge96 3 hours agoprevI still want to do this 9 years later I still haven't made something. Still working for someone else. Going to get out of debt first then work on it again, I want to be able to sleep/wake whenever. reply TrackerFF 2 hours agoprevI wonder how LLMs will impact this industry. 10 years ago, when I was chasing this - I'd look for proven business models. Find some small startup / company that sells some software or service, try to figure out what they did and how they did it, then spend time getting into the domain, tech, and what have you. It was a lot of work, and took time. If I do it now, I have the luxury of simply asking my LLM of choice to give me a run-down, and what I need to do. Hell, I've even experimented and gotten a LLM to dish up a working MVP in a single day, which I can iterate on. reply potatoman22 2 hours agoparentBut how do you make sure you're solving the right problem? LLM? reply TrackerFF 40 minutes agorootparentYou find existing solutions to a problem, and copy it. That's it. People spend time chasing novel problems, or coming up with solutions that are looking for problems - when in reality the vast majority of business and entrepreneurship comes down to looking for tested/validated business problems, looking at the existing solutions, and finding ways to enter that market, and win/siphon customers. reply ternnoburn 3 hours agoprevReading this, it feels much more like \"using coding skills to make income\". It's a great description of one person's journey, but \"work hard for a decade, continue to work at a healthy lighter pace after\" isn't really passive income in my mind. And I'm not sure it beats, e.g., work hard and save hard at tech company for a decade, then use the invested surplus as passive income to work lightly thereafter. At least, not in the general case. reply oldandboring 2 hours agoparent> work hard and save hard at tech company for a decade, then use the invested surplus as passive income to work lightly thereafter I used an LLM to help me do the math but it appears you would have to make $1.5 million/year at \"tech company\" if you were to save 20% of your income and have $4 million saved after 10 years. That $4mm saved would allow you to appreciate to $5mm to retire on after 20 years while simultaneously withdrawing $150,000/year in passive income to live on. Of course you can adjust this based on how aggressively you save, how much you need to withdraw each year, and how much runway you have until retirement and how much retirement you need to be comfortable. Regardless, what you're suggesting is available only to the privileged few who can get extremely high-paying jobs early in their careers and hold onto them while having low enough expenses and high enough discipline to save aggressively. OP's approach is a very doable path for folks who aren't so fortunate and/or young, but can code, have some life experience, and don't want to go get another job. reply potatoman22 1 hour agorootparentHow do you spend 80% of a 1.5 million (lets say 800,000 post-tax) salary each year? That'd be an incredibly lavish lifestyle. If you cut your spending down to a cool $200,000/year then you could retire in 5 years and have $150,000/year for the rest of your life. Let's run a different scenario: your post-tax income is $200k and you save half of that. In 11 years, you can retire and get $100k per year at a 4% withdrawal rate. People in either of these scenarios are obviously privileged, but the latter isn't unrealistic for a single FAANG dev. engaging-data.com has cool fire calculators. Highly recommend checking them out reply Jabbles 1 hour agorootparentprevYour choice of numbers is very odd - even though you mention that you can adjust them for your own circumstances, the starting point is unrealistic. - Very few people earn $1.5M/year - Saving 20% implies that you're spending ~$1M/year while working, so $150k/year in retirement would not be appealing Did the LLM pick the numbers for you? reply oldandboring 1 hour agorootparentWhoosh. You missed the point completely. Of course very few people earn $1.5M/year. That's my point -- the poster I was replying to was naively thinking they could just work hard for a tech company and save for 10 years and then live off the passive income of the saved investment, which is silly. The rest of the numbers were conservative figures I chose. $5mm to retire, 20% saved while working, $150k/year passive income. The whole point is that what he's describing is pretty unrealistic. reply FrustratedMonky 4 hours agoprevI want to believe. But is this really still possible in todays world? Isn't there competition from the thousands of software devs laid off in last couple years. They can all make apps. Just like the Flappy Bird guy. Sure, it was big hit, but so easy to have a hundred knock offs within a week. reply kflgkans 4 hours agoparentI think it's simply survivorship bias. Thousands of people try this and fail. And occasionally you read an article like this, which is like the one in a million who managed to get lucky with their ideas and manage to make it a success. And I think they underestimate how much luck they had. reply czue 3 hours agorootparentLuck is a huge factor for sure but I also think it's not as hard as you're making it out to be if you set yourself up for success. I have four products that make money, built over the course of seven years. None of them really benefit from each other. If it was pure luck and 1/1,000 chance of success I don't think my current portfolio would be possible. (I also have a lot of failures, so I agree there's luck and risk, just not as strong as you're making it out to be) reply factorialboy 3 hours agoparentprevBuilding a business is more than just building the app. And everything can be duplicated for cheap, especially with gen-ai. But small-businesses will transform, continue and dare-I-say thrive. reply czue 3 hours agorootparentYeah, one of the critical lessons I learned is that building is really the easy part, and most \"traditional\" developers who fail will do so as a result of not marketing enough, or well. That's an oversimplification, but directionally true. Being able to make apps isn't enough. You also have to develop a broad set of skills to complement that. reply qup 3 hours agoparentprevThe thousands of software devs that got laid off aren't starting businesses. They're also not a cross-domain expert at the same things you are. You might be in the top N coders in a niche, and you might be the only one with the motivation to work on the problem. You also might just do it better than them. And last, you might just split the pie with them. Really, it's okay to have many apps doing the same thing with different approaches. reply Scoundreller 4 hours agoparentprevPart of the goal might be to stay under the radar. In a pre-app world, I wrote some blogs with ads. Some of my favourite ones were dumb but fairly evergreen articles where I had domain knowledge like “best directions to the dmv offices in $mytown”. (Pro-tip: it’s upstairs at the XYZ shopping mall, but if you park by the pizza place, you’ll be at the doors that take you straight there) Reliable and consistent income. Not a ton, but more like a bond than a stock. reply poisonborz 3 hours agoparentprevThe world would require an x-th number of skilled developers existing for problems that could be solved by digital services. Ask in any forum about any niche/hobby/expert field and they tell you dozens of things they would gladly pay for but doesn't exist. It's one thing to be a good dev/coder, but another level entierly to be a one man team delivering a product. reply p_j_w 3 hours agoparentprev>Just like the Flappy Bird guy. Sure, it was big hit, but so easy to have a hundred knock offs within a week. I doubt the creator minds too much, I know I wouldn't: he still made millions off it. reply dirtybirdnj 3 hours agoprev> First you have to make space in your life for it. You need long blocks of time for deep work. This is the obstacle to EVERYTHING in my life. It's very chaotic, which causes a lot of stress and has led to decreasing performance. I try so hard to clean up, to improve things. To try to proactively get ahead of stuff. It never seems to be enough. Something happens I cannot prepare for, or in trying to save and be efficient something goes wrong I cannot afford. My whole plan, saving AND getting things done has now blown up. I no longer have one, I now have three problems and I have also lost/wasted a day. Tomorrow I have four problems, plus I am aware of this dynamic and unable to escape it so technically 5? This compounds over time. How do you escape this failure loop? tl;dr: the \"being poor is expensive\" trap, how escape when so burned out you are struggling to tread water? It's not just money, it's attention span. It's the ability to set my mind to something and accomplish what I set out. Having that muscle atrophy and tear has been traumatic and I am struggling to find emotional or medical interventions worth the effort. reply ndileas 3 hours agoparentIt really depends on the specifics of your life. I get a lot of mileage out of imagining what a more functional adult would do, then doing that (stupid example:doesn't buy the cheapest shoes available and try to make them last 5 years while enduring back pain). It's hard to change quickly; sometimes decisions I made years ago (or that someone in my family made decades ago) throw a wrench in the works. I also took a big step back from various forms of ambition, in favor of building a solid, enjoyable life. I hope it gets better for you too. reply dirtybirdnj 18 minutes agorootparent> I also took a big step back from various forms of ambition, in favor of building a solid, enjoyable life. I think you are onto something here, but there's no way to keep my current situation sustainable let alone live on less. The financial thing I can't do much about but the psychological maybe. It's hard when I feel like there is nobody to help me and I have to do everything alone. reply cudgy 3 hours agoparentprevOf course, I know nothing about your particular situation, but one strategy is to simplify life as much as you can. This could be lowering living costs by moving and getting rid of expensive habits. Lower overhead can be huge factor in reducing distraction and stress. Other strategies are reducing the number of activities, avoid using phones and other distractions during work periods, avoid social media and political discussion and encourage focus on your goals, setting boundaries with family and friends, saying “no” more often to requests, avoiding triggers that distract you or cause stress, create a dedicated and quiet workspace with few distractions, and generally focus on fewer goals at a time. reply dirtybirdnj 16 minutes agorootparent> focus on fewer goals at a time Beyond this very specific thing, I think its also a struggle with trusting myself. I don't trust myself to finish anything. I can try as hard as I want but my locus of control is completely external. I am tired of being lied to about agency and ability. If it was easy as putting effort in I'd be there already. So I work harder and harder in an effort to MAYBE be enough for society / work etc and I am STILL not enough. How can you believe in yourself when you are the source of all failure, lack of consistency, inability to change or adapt. It's me. I'm the problem. I try to be better but at some point I am just masking who I am, which is a WHOLE other problem that is not mutually exclusive. It's another one of those \"can't follow the issue because it's too complicated\" problems that's destroying my life. Nobody undertands, everyone tells me I'm not alone (they are wrong) and nobdody has any reasonable or actionable suggestions because nobody I have talked to yet even remotely grasps what I am going through. My therapist is really the only person who gets it. So many times I have tried to do the \"right\" thing only for it to backfire and make everything worse. It's textbook learned helplessness, but I also have a proverbial textbook of evidence to support my reasons why things won't work. Nobody will listen to me, and then when the thing I tell them won't work FAILS it's my fault for pointing out the laws of physics or nature. I am tired of being the scapegoat for sociopaths and Machiavellian cancer. I accept that I need to accept failure. I am trying, but it's demoralizing and only seems to cause pain not growth. I can usually maintain optimism for a week or more but inevitably the reality of life creeps back in and I can't lie to myself any longer. reply BurningFrog 2 hours agoparentprevSounds like you need to first make your life less chaotic. This could mean making some hard choices. reply oldandboring 2 hours agorootparentThis is usually possible to some degree but the life circumstances creating the chaos may not be things they can realistically get rid of. reply dirtybirdnj 20 minutes agorootparentNail on the head. Lost wife / family (cat) / house over the summer. Mom in and out of hospital starting in November. I'm a cat locked in the dryer and there are no door handles on the inside. reply zb3 3 hours agoprev [–] Unpopular opinion: truly \"passive\" income should be impossible, because this means someone is working hard but not receiving their compensation. EDIT: of course unless it's the robots that do all the work, but then it's not really passive... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author transitioned from a CTO role to a solopreneur, successfully earning more through a portfolio of software products.",
      "Key strategies include focusing on deep work, starting with small projects, iterating quickly, and dedicating time to marketing efforts.",
      "The journey emphasizes resilience due to uncertainties, but highlights the unmatched autonomy and freedom of this career path, encouraging those with coding skills to consider it for passive income."
    ],
    "commentSummary": [
      "A user described generating passive income through SEO spam websites using expiring domain names, earning approximately $30k annually, despite ethical concerns and Google's eventual crackdown.",
      "The post sparked a debate on passive income, with some users arguing it's more akin to running a business than truly passive earnings.",
      "Participants shared experiences and challenges in side projects, highlighting the importance of time, resilience, and strategic planning."
    ],
    "points": 167,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1736860888
  },
  {
    "id": 42690781,
    "title": "Spain proposes 100% tax on homes bought by non-EU residents",
    "originLink": "https://www.theguardian.com/world/2025/jan/13/spain-proposes-100-tax-on-homes-bought-by-non-eu-residents",
    "originBody": "View image in fullscreen Cities such as Barcelona are a magnet for non-EU holiday home buyers. Photograph: Pol Albarrán/Getty Images Spain Spain proposes 100% tax on homes bought by non-EU residents Pedro Sánchez announces measure in response to anger over rising housing costs Ashifa Kassam in Madrid Mon 13 Jan 2025 16.39 EST Share Spain has announced plans to impose a tax of up to 100% on real estate bought by non-residents from countries outside the EU, such as the UK, in an aim to tackle the country’s housing crisis. The measure was one of a dozen unveiled on Monday by the country’s prime minister, Pedro Sánchez, as the government seeks to quell mounting anger over housing costs that have soared far beyond the reach of many in Spain. Sánchez sought to underline the global nature of the challenge, citing housing prices that had swelled 48% in the past decade across Europe, far outpacing household incomes. “The west faces a decisive challenge: to not become a society divided into two classes, the rich landlords and poor tenants,” he told an economic forum in Madrid. The proposed measures include expanding the supply of social housing, offering incentives to those who renovate and rent out empty properties at affordable prices and cracking down on seasonal rentals. In Spain just 2.5% of housing is set aside for social housing, a figure that lags drastically behind countries such as France and the Netherlands, said Sánchez. But it was the government’s plans to crackdown on foreign, non-EU buyers that grabbed headlines around the world. Spain has long been a popular destination for non-EU holiday home buyers, with residents of the UK, US and Morocco flocking to buy properties in places such as Ibiza, Marbella and Barcelona. Sánchez described the tax of up to 100% as “unprecedented” in Spanish history. “Just to give an idea, in 2023 alone non-European Union residents bought around 27,000 houses and flats in Spain. And they didn’t do it to live in them, they didn’t do it for their families to have a place to live, they did it to speculate, to make money from them, which we – in the context of shortage that we are in – obviously cannot allow.” He did not offer more details on how the plan would work or when it would be finalised and sent to parliament for approval. Given his government’s longstanding struggles to pass legislation, one analyst suggested to the Financial Times that the government’s aim was to deter foreign property investors by creating “uncertainty and noise” with a proposal that has slim chances of becoming law. The government’s slate of measures also took aim at tourist flats, which have long been blamed for shrinking the rental supply and leaving locals priced out of the market. Sánchez said regulations on these rentals would be tightened while the taxes they pay would be hiked. “It is not fair that those who own three, four, five apartments for short-term rental pay less tax than hotels,” said Sánchez. skip past newsletter promotion Sign up to This is Europe Free weekly newsletter The most pressing stories and debates for Europeans – from identity to economics to the environment Enter your email address Sign up Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion He argued that the measures were necessary to tackle what he described as an “unbearable” mismatch between rising housing prices and household incomes. “We are facing a serious problem, with enormous social and economic implications, which requires a decisive response from society as a whole, with public institutions at the forefront,” he added. Explore more on these topics Spain Europe news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=42690781",
    "commentBody": "Spain proposes 100% tax on homes bought by non-EU residents (theguardian.com)162 points by vinni2 19 hours agohidepastfavorite254 comments louison11 18 hours agoBlaming foreigners for housing prices is misdirected. The real culprit is slow bureaucracy & zoning laws making it impossibly slow to get a permit to build anything in both Spain and Portugal. Both of these countries for example have so many abandoned houses needing to be renovated, and so many foreigners coming in with money to do it - but they can never do it because you can't get a permit in literally forever... I don't know about Spain, but another problem in PT is the building companies too, are unreliable, and typically don't deliver houses in less than 3-5 years if you decide to build new. Increase the supply, and the prices will go down. reply WorkerBee28474 18 hours agoparentNo, that argument assumes you can only blame 1 thing at a time. Even if the bureaucracy is the worst offender, every foreigner buying a house still results in 1 less house for Spaniards. Sure, fix bureaucracy, but don't pretend foreign purchases have zero effect. reply JumpCrisscross 17 hours agorootparent> every foreigner buying a house still results in 1 less house for Spaniards In a very limited scope, sure. What that foreign capital also does is lower risk and thus capital costs for development and improvement. (In the event of a limited crisis, for lenders as well.) Whether the net effect goes one way or another is more complicated than what you describe. Put another way, if foreigners could only buy unbuilt units, would you still say they're resulting in fewer houses for Spaniards? Do the countries shunned by foreign investors have affordable housing? reply motorest 11 hours agorootparent> Put another way, if foreigners could only buy unbuilt units, would you still say they're resulting in fewer houses for Spaniards? Do the countries shunned by foreign investors have affordable housing? Exactly, and to further drive the point home the real estate investments driven by foreign investment are targeting entirely different markets, such as luxury homes and tourism, whereas the complains about lack of access to housing come from those who already struggle to buy the cheapest units in working class suburbs, where the foreign investments are clearly not being made. So the question you should be asking is how come you're not seeing investments in affordable housing across the country at a time where you see foreign investment in luxury and tourist areas. Then you'd realize that you're discussing two entirely different things that bear no relationship. reply rgtank108 17 hours agorootparentprevWhat is this contrarian sophistry? In Europe foreigners often buy the most expensive historical real estate they can lay their hands on. If they do build something, it is office buildings for investment that take up space and often remain empty (Chinese are good at that). These investments still take up space and drive up real estate prices. Where do you even live? reply JumpCrisscross 17 hours agorootparent> In Europe foreigners often buy the most expensive historical real estate they can lay their hands on Source? (I'm generally hugely sceptical of uniform statements about how capital behaves across the EU, let alone Europe.) reply WorkerBee28474 12 hours agorootparentA source is not required for something to be true. An uncountable number of things that are true have no source to back them. reply motorest 12 hours agorootparent> A source is not required for something to be true. If it was really true then why would you have so much trouble providing anything at all that would back it up? reply ryan_lane 12 hours agorootparentprevWhere's the source for your assertion? You're making a claim that foreign investment is beneficial with no source, but then requiring one when someone disagrees with you? reply sadeshmukh 11 hours agorootparentA theoretical argument was countered with an assertion - it's plausible that investment -> lower risk, but there is no reasoning to get \"foreign investment is focused on X area\". reply ryan_lane 11 hours agorootparent\"What that foreign capital also does is lower risk and thus capital costs for development and improvement.\" Not a theoretical argument. An assertion. reply sadeshmukh 2 hours agorootparentI mean, I can see a reason provided. Isn't that the whole point of foreign direct investing? That's more than an assertion - that's why I call it a theoretical argument. There's no need to debate semantics. reply motorest 11 hours agorootparentprev> What is this contrarian sophistry? In Europe foreigners often buy the most expensive historical real estate they can lay their hands on. Yes, they make real estate investments in luxury and high-end sector, some of which boarded up for decades. It's not like your average working class citizen is on the house for a manor house in the city center. These are not the same markets. reply louison11 17 hours agorootparentprevI'm not saying it has zero effect. I'm saying it's a misdirected effort that would cause them more harm than good. Spain isn't exactly in the fittest economic position. It needs to attract foreigners to cultivate its growth - hence their Beckham law and other benefits for foreigners. You can deter people from coming and see the country stagnate/go down, or you can actually match the demand and foreign dynamism, and use that as an opportunity for the whole place to grow and modernize. reply throwaway4aday 17 hours agorootparentThis is a quick \"fix\" that has a lot of unintended consequences. I've seen it first hand and the only people it benefits are those who are already wealthy. Everyone else gets a lot poorer as their cost of living skyrockets. Homelessness explodes as rents and housing costs increase dramatically, people who were living a humble but decent life before are pushed into poverty, crime both non-violent and violent increases and so does drug use. As far as I can tell the only people that actually benefit from this scheme are landlords and housing developers who slow walk their projects so that they can charge the maximum price per unit. Compared to the previous fairly stable state (which you call stagnation) the locals are much worse off. It also tends to ruin the character of places that were previously seen as a vacation destination for a unique experience, all of that just gets paved over and turned into a bland tourist trap barely different from any other place. Count yourself lucky if you live somewhere that has been passed over by this horrid money making scheme. reply delroth 17 hours agorootparentprevHow does allowing *non-residents* to buy real estate help in attracting foreigners and cultivate growth? reply louison11 17 hours agorootparentMoney invested from abroad is money coming inside the economy - whether the person lives there or not. That money goes to the seller, who'll then get taxed on it, spend it somewhere else... Or that money could be used, as I said, to build new buildings and rehabilitate old ones, thus creating jobs in the process. If the system was well set up for it, foreigners investing in a country is usually a good thing. The US is super foreign-investment friendly for example, doesn't hurt them. Besides, if foreigners are investing solely to speculate - if they did fix the supply constraints, the opportunity for speculation would greatly decrease. It's only an attractive investment because the supply is so finite. reply whazor 12 hours agorootparentAlternatively, I got my current house because of KYC laws. The house bidding was originally won by someone abroad. They overbid the house by a lot. However, because of the KYC laws, that person needed to proof their income is legitimate, which they couldn’t. Therefore, we got the house. Building new houses costs 10 years in my country. So building new houses is not fast enough to create new affordable houses. reply throwaway4aday 17 hours agorootparentprevWorked great for Vancouver /s reply JumpCrisscross 17 hours agorootparentTo be fair, you're referring to one of the largest and fastest-growing economies in Canada [1]. (It also has a massive affordability crisis despite a ban on non-student foreigners buying expensive real estate.) [1] https://www.katrinaandtheteam.com/blog/vancouver-bc-economy/ reply vivekd 12 hours agorootparentHalf the people in Vancouver are thinking about leaving and 25% want to leave within the next 5 years. People are leaving in droves largely because of costs. That seems to make the parents point - that the ecnomic benefits from immigration accrue to the few and the wealthy while making life harder for average people https://vancouversun.com/news/survey-finds-half-of-metro-van... I can sympathize with it because I live in Toronto and am also thinking about leaving. Do I hate immigrants, no there aren't actually that many immigrants in the city core where I live. But certaintly there is an affordability crsis that has gripped the city and the country and wages seemed to be supressed and there seems to be less job opportunities (likely due to all that extra labour coming in) reply iforgot22 44 minutes agorootparentVancouver's population has been steadily increasing. Maybe it's catering to different people than before, but it's not fewer. reply iforgot22 17 hours agorootparentprevIn a hot real estate market, there will be more market pressure to fix the dilapidated properties in good areas. Say they instead keep values artificially low so an EU resident can buy a property for cheap, and it stays cheap. What's the benefit? reply fabrice_d 17 hours agorootparentThe benefit is that more people can afford to buy houses? Really surprising to see a country taking care of their people, and not just the wealthy ones! All the hypotheses claiming that \"the market pressure will improve things for all\" have been proven false at this point. We have decades of data, and this is only widening the inequality gap. reply motorest 12 hours agorootparent> The benefit is that more people can afford to buy houses? Can they? I mean, what is your plan to lower current housing prices? Cut off demand from foreigners with purchasing power and instead replace it with demand from people who cannot afford a home? They are not even the same housing market, are they? reply iforgot22 17 hours agorootparentprevI don't see why this is better than people renting and investing their savings elsewhere, which is how it works with apartments anyway. So you own a house, it makes basically no return, now what? reply JambalayaJimbo 14 hours agorootparentIs the only reason you see for home ownership price appreciation? This mentality is what’s wrong with speculative real estate! reply iforgot22 1 hour agorootparentYes. I don't know how you can buy something and hold it for decades without calling that \"speculation.\" reply bdangubic 17 hours agorootparentprevwhere exactly does a house make no return, especially in say last decade/15 years? I bought three houses in the last 20 years, one doubled, one up 70% and one 40% (still occupying it) reply x0xrx 14 hours agorootparentDo you not see how insane it is to at once 1) demand cheap housing and 2) demand it increases in price at breakneck pace? reply iforgot22 3 minutes agorootparentExactly, it's like complaining that gold is unfairly expensive. Those lucky Boomers got to purchase it at $40/oz, now it's $2600/oz. I should be offered some cheap gold so I can sell it for 65X. bdangubic 6 hours agorootparentprevI am not demanding cheap housing, I was only commenting on so you own a house, it makes basically no return, now what? reply iforgot22 1 hour agorootparentI'm saying that if they find a way to keep houses affordable to buy, they can't be viable investments. The US makes for a decent home investment market. You usually see a house price double every ~10 years once it's in a desirable area. Btw, was your 40% increased house purchased 20 years ago? If so, that's effectively a loss, and I'm not even sure about the one that doubled. 5-10 years would be different. reply iforgot22 16 hours agorootparentprevIn the US, not many places. But that's the complaint from some people. reply bdangubic 15 hours agorootparentgive me some places where it is not and we’ll look at zillow or whatever public data there is for a given region. unless we are talking like rural-no-is-around-for-miles perhaps but otherwise properties over the last 10-15 years have appreciated reply klipt 17 hours agorootparentprevYou could also argue that every Spaniard moving from the countryside to the cities takes away houses from Spaniards born in the cities. Seems like an argument for internal visas like China's household registration system to prevent excessive migration to the cities. The countryside is mostly emptying out so no need to prevent people moving or buying there. reply JumpCrisscross 17 hours agorootparent> Seems like an argument for internal visas like China's household registration system to prevent excessive migration to the cities With the big difference being the Chinese citizen being denied Beijing hukou is still a Chinese citizen. Madrid should properly first concern itself with Spaniards' wellbeing. (This isn't an argument for or against this policy. Just clarifying why restricting non-EU home purchases is different from hukou.) reply Gvaskas 17 hours agorootparentI can't believe I had to scroll so far to find sense. Westerners are so demoralised and broken that they see their own economic zones (I refuse to call them 'nations' any more) as little more than tax havens, investment vehicles, and colonies for foreigners rather than a homeland for themselves and their children. Voluntarily opting for displacement and dispossession over being called 'racist' by hateful strangers. Get a grip. reply JumpCrisscross 17 hours agorootparent> over being called 'racist' by hateful strangers Straw man [1]. You're the only one in this thread levelling this charge. [1] https://en.wikipedia.org/wiki/Straw_man reply Gvaskas 16 hours agorootparentWhat other motivation do they have for selling out their own family and people then? Either they are so demoralised that they truly feel no greater affinity toward their own kin than a random stranger from the other side of the world, or they are so fearful of the social consequences (and their own manipulated internal sense that this is \"bad\") that they consciously and very openly advance the interests of strangers over their own kind. I think many who tell themselves that they're in the first group are only doing so because they're actually in the second group. The \"I don't see colour\" types. It is trendy to participate in the destruction of your own descendants' homelands and future as an advertisement of one's \"anti-racism\". reply iforgot22 12 minutes agorootparentYou're asking what other motivation someone has for encouraging foreign investment, or selling property? JumpCrisscross 16 hours agorootparentprev> What other motivation do they have for selling out their own family and people then? Not wanting to be the next Venezuela, for one. Reflexive protectionism is emotionally satisfying. It rarely delivers the promised relief. I could absolutely see such a tax e.g. taking out a small Spanish bank or two, or, at best, knocking out develoopers' financing such that new-home construction contracts. More likely: it becomes the only thing this government can work on as Spain gets mired in years of EU litigation. > It is trendy to participate in the destruction of your own descendants' homelands and future To the extent anyone is trend following, it's the populists making these sort of black-and-white claims. Again, you're the only one arguing against this imagined anti-racist commenter. Policy written to annoy an imagined foe is going to be predictably bad. reply Teever 17 hours agorootparentprevThat comparison make sense in a world where the well being of a nation's citizens wasn't the priority of a nation. However we live in a world where that isn't the case so a nation deciding to restrict immigration or economic activity by foreigners for the benefit of the domestic population is an acceptable position to take -- provided it actually have that desired outcome. reply klipt 17 hours agorootparentSpoiler: it won't help much. Liberalizing zoning and taxing land would do more to improve housing affordability. reply creer 15 hours agorootparentprev> every foreigner buying a house still results in 1 less house for Spaniards Absolutely not. For example my impression is that foreign demand has been great for the construction industry, both small and large, both in Spain and Portugal. Paying lots of people directly and still more indirectly. The presence of all these buildings that needed renovation (or demolition) shows that the population previously could not afford to use them. Dumping money in the economy causes some inflation, yes, but it also pays many people and allows still more to enter the field. reply alecco 9 hours agorootparentprevBut the foreign investors are doing it because the housing market has an artificial supply shortage. They are buying into a cornered market. Of course, full deregulation is not a fix as seen with the condos built in ridiculous locations back in the sub-prime mania. It would be good to have a reasonable plan. Sadly the plans for making livable neighborhoods was hijacked by the \"15 minute city\" WEF-style politicians. The Netherlands had some very interesting projects that went pretty well. reply surgical_fire 16 hours agorootparentprev> Even if the bureaucracy is the worst offender, every foreigner buying a house still results in 1 less house for Spaniards. Just to be pedantic, it's not about foreigners buying property, it is about non-resident buying properties. A foreigner that actually resides in Spain would not be taxed, if I understand correctly. I don't think that limiting property ownership to residents is a bad thing. I do think, however, that it will not have that much impact in the properties the average people actually need and want. reply ptero 17 hours agorootparentprevForeigner purchase effects are complex. While a unit sold does immediately reduce the supply by 1 unit, new demand and foreign funds can also stimulate more building and, especially important, can prevent areas falling into disrepair and becoming ghost towns. It really depends on the specific area and situation. My 2c. reply AuthorizedCust 17 hours agorootparentprevIf you’re in oversupply, as the parent comment suggested, then is the effect of additional buyers meaningful? reply WorkerBee28474 17 hours agorootparentIf you have extra supply of houses needing renovation, as in the comment, and renovations require labor and/or materials to complete, having foreigners pay to renovate houses to be livable will decrease the ability of Spaniards to renovate houses to be livable. For example, let's assume renovations are 100% completed by local crews. Any crew working for a foreigner is working for them because A) the foreigner is paying more than a local for the work B) the foreigner is paying enough to make a profit and the local isn't (which is a subset of A). There is no situation in which adding foreign money results in more houses for locals. If you eliminate the ability for foreigners to renovate, the renovation crews will take the money that the locals can pay. There will be fewer renovation crews, because some crew will not be profitable at the lower rate, but more crews working to renovate houses for Spaniards. Similarly, for materials, given supply and demand curves (and assuming that the marginal units added won't cause economies of scale) eliminating the ability for foreigners to buy materials for renovations will move the curve intersection down to a lower price and volume. reply JumpCrisscross 17 hours agorootparent> There is no situation in which adding foreign money results in more houses for locals Assuming fixed supply, yes, it's (probably) a zero-sum game. > eliminating the ability for foreigners to buy materials for renovations will move the curve intersection down to a lower price and volume Assuming a frictionless market and no economies of scale, yes. In reality, you'll have a smaller set of options for locals at a slightly (but not dramatically) lower price. (Again, for an example look at all the markets foreign investors shun.) > will be fewer renovation crews, because some crew will not be profitable at the lower rate, but more crews working to renovate houses for Spaniards You absolutely cannot conclude this from first principles. You make valid points. They just need to be followed up with data. The systems you're talking about are too sensitive to generalise like this. reply Gibbon1 14 hours agorootparentprevI have various thoughts. The rough one is that investors driving up the cost of housing increases the countries labor costs. Which harms it's competitiveness. Reduces workers standard of living. Which also causes headaches for political leaders. Foreign investors rub salt in the wound by moving their gains outside the country. And the real risk that they will flee when there is any sort of downturn making it worse. My opinion giving those guys the middle finger isn't unreasonable. reply ETH_start 17 hours agorootparentprevEvery foreigner buying a house is supplying capital for one additional house to be built, and some portion of those additional houses will be unoccupied by the foreigner most of the year and available on the rental market for locals. Even if it's just short term rentals, that means more affordable vacations and temporary housing for the domestic population. reply mkoubaa 17 hours agorootparentThis is one of those arguments that at face value seems quantitatively sound but doesn't survive first contact with reality reply ETH_start 15 hours agorootparentAnd your claim that it doesn't survive first contact with reality is based on you correlating high volumes of foreign investment with lack of housing affordability and assuming that the former is causing the latter, when the correlation is really due to a confounding factor. reply mytailorisrich 9 hours agorootparentprevThe issue not mentioned because it is a very politically charged topic is that, as I understand, net migration to Spain is at an all time high. This is bound to push housing prices up. Hitting foreign investors is easier politically but may not have much effect. reply gruez 17 hours agorootparentprevSo would you say it's fair game to blame \"migrants\" for crimes? After all, you can't steal something if you're not in a country, so letting someone into a country strictly increases the crime rate. Even if migrants commit crimes at a lower rate than the local population, unless it's exactly zero, it'll still increase the crime rate. edit: downvoters, I'm not actually endorsing blaming migrants. It's only used as an example. reply d4704 17 hours agorootparent> Even if migrants commit crimes at a lower rate than the local population, unless it's exactly zero, it'll still increase the crime rate. But that assumes you do not count the person who commit the crime as part of the population count. In this example, “crime per capita” goes down if they commit crime below the average crime rate of population before they joined that population. reply gruez 17 hours agorootparent>But that assumes you do not count the person who commit the crime as part of the population count. Sorry, meant to say \"crime count\", or more precisely, \"native victimization count\". Natavists by definition prioritize the native population over immigrants, so if some native got victimized by a migrant, I doubt a natavist would be convinced by \"well actually, even though there was one extra crime committed by a migrant, there's also 10,000 (or whatever) more people, so the crime rate actually went down!\" reply llamaimperative 17 hours agorootparentprevDo crimes have a liquid market with supply and demand mechanics? If so, then sure, you can blame every criminal for x% of every crime, I guess. reply gruez 17 hours agorootparentThe comment was in reply to: >Even if the bureaucracy is the worst offender, every foreigner buying a house still results in 1 less house for Spaniards. It's pretty clear that supply and demand isn't a consideration here, and the commenter is strictly focusing on the aspect that one house is being removed from the housing supply. reply llamaimperative 17 hours agorootparentIf you remove a house from the supply, by any method, there is one fewer house in said supply. reply motorest 12 hours agoparentprev> Both of these countries for example have so many abandoned houses needing to be renovated, and so many foreigners coming in with money to do it - but they can never do it because you can't get a permit in literally forever... Are these hypothetical houses located in the places these hypothetical foreigners want to live or invest? Because getting a small apartment in Barcelona is a small feat, and Soria is not exactly an alternative. reply vivekd 17 hours agoparentprevI donno if it entirely wrong to blame foreigners. If you have a bunch of silicon valley digital nomads flying to Spain and buing and selling houses to each other I can see how that could easily leave locals out of the housing market. That seems like something that government should control against if locals can't affording housing. I imagine that if a bunch of rich people decided to treat Spanish homes like stocks (holding and flipping) it would be pretty easy to get high prices and bubbles. Doesn't it follow from suppy and demand? >Increase the supply, and the prices will go down. what's wrong with tackling both demand and supply. Why shouldn't spain do both - build more homes to tackle supply while also curbing foreign home ownership to tackle infalted demand reply honestSysAdmin 15 hours agoparentprevBloated/unnecessary bureaucracy is essential to the bribe collection process. reply rednafi 17 hours agoprevThe issue is that countries expect foreigners to bring in money, earn a lot, and pay taxes at the 90th percentile, but they’re (the locals) reluctant to share resources in return. A 100% taxation model turns it into a one-way street. Sure, if you don’t need foreign investment, you can afford to do that. But let’s be real—welcoming foreigners isn’t an act of charity. Governments usually do it because foreigners are often more productive, pay higher taxes, or fill jobs that locals don’t want. Turning it into a one-sided deal has consequences. Immigration policies are funny; every western country treats them like a magical cure-all, only to later blame immigration for any and every problem. reply ralsnop 17 hours agoparentIf India had 25% white EU members similar to Sweden having 25% migration background members (mostly from Africa or the Middle East), perhaps Indians would get a tiny bit protectionist. The accusation that locals are reluctant to share resources is offensive at this point. There is no space and people can barely afford to pay rents. Meanwhile there are \"golden visas\" to Portugal or Cyprus where rich Chinese can gain entry to the EU and buy up everything. For a token \"investment\" like buying stocks to the tune of EUR 1,000,000. They do not exactly build a semiconductor fab. Again the myth that \"foreigners are more productive\". Where does that come from? West Germany did just fine before 1990, everything deteriorated since then. reply rednafi 9 hours agorootparentI completely understand the need for protectionism. That said, Sweden's immigration policy ranks among the worst in Western countries. I'm not saying there shouldn't be any pushback; rather, my point is that these policies are exploitative on both ends. Why bring in refugees in the first place? And if you do, why bring them in en masse? The US handles a much larger number of migrants each year and consistently attracts the cream of the crop. I'm not saying the US doesn’t have issues with migrants, but during my time living there, I didn’t find the situation as severe as in Germany, Sweden, Spain, Portugal, or Italy. Europe's immigration policy is broken. Many immigrants end up draining the social welfare system, overcrowding service providers, and causing religious tensions. But let’s be honest: everyone knows which group is primarily responsible. It’s extremely difficult for that group to enter the US. At the same time, it’s much easier—though still not trivial—for skilled migrants to move there. In Germany, the situation is the opposite: it’s trivial to enter as a charity case but much harder as a skilled migrant. If you can afford to reject immigration, you're free to do so. America can’t, and they’re profiting from it. But why adopt such a self-sabotaging approach, bringing in the worst of the crop and then blaming them for the country’s woes? That’s the part I can’t understand. reply JambalayaJimbo 13 hours agorootparentprevWhat does whiteness have to do with anything?? Indians are protectionist, with regards to immigration from poorer countries like Bangladesh. reply rednafi 3 hours agorootparentUmm what? India has a lower per capita income and worse quality of life than Bangladesh. https://countryeconomy.com/countries/compare/bangladesh/indi... reply icar 12 hours agoprevHouses should not be an investment, but only used for what they are: a place to live. That's directly opposed to why someone not local would buy them. This fall short, it should be straight up forbidden, also for EU residents (who are a big issue as well, looking at you German and French people that buy houses, leave them empty all year but 1 month and/or don't even learn the language and traditions of that place) reply omnimus 9 hours agoparentI think EU is ok as many people actually live somewhere else thanks to EU laws. What should get hard taxed is owning multiple homes. There are people with 100s flats not even under a company but an individual. And companies that do own homes as business should be stevards of properties with max profit margins - it can be good business but not unhinged money printer it is in becoming everywhere. reply mhandley 18 hours agoprevAnything to stop a non-EU resident owning an EU company that owns a Spanish home? reply V__ 18 hours agoparentIt's not trivial to set up a business as a non-eu citizien. As far as I know every EU business has to have an eu citizen representative. Additionally, a company owned property can't just be used privately. reply gruez 18 hours agorootparent>As far as I know every EU business has to have an eu citizen representative You can't hire a nominee director? >Additionally, a company owned property can't just be used privately. They can't \"rent\" it back to the owner? reply ajb 18 hours agorootparentThat sort of thing is a bit risky. One company I followed was bought out by a US vehicle owned by a Chinese investor, and then everything ground to a halt because (it appears[1]) the local agent fraudulently changed the bank accounts into their own name and locked out the owner. Operating stuff in a foreign legal jurisdiction is hard. [1] this seems to have been the judgement of the court, but not all the fillings are free to access. reply JumpCrisscross 18 hours agorootparent> the local agent fraudulently changed the bank accounts into their own name and locked out the owner This sounds like a front more than a nominee. A front legally owns the company and has a side deal with someone conferring control. It's pretty much straight-up fraud. A nominee is similar to a Delaware registered agent; you pay a law firm or whatever a few hundred euro a year to be your glorified P.O. Box reply ajb 17 hours agorootparentI'm not really sure what the technical details were. This is the complaint, in case anyone is curious: https://trellis.law/doc/159246087/complaint-case-initiation-... Although obviously that's only from one side. If may be that it's less risky if there's a common service such as you describe, since the operator will prefer to keep their business going. But if significant assets are involved it may still be somewhat risky. (This was the company that supposedly ended up with the IP of the Kestrel aircraft, formerly owned by Alan Klapmeier and originated by Richard Noble as the Farnborough F1) reply JumpCrisscross 16 hours agorootparent> if significant assets are involved it may still be somewhat risky No more than any asset in the EU. A nominee can steal your property about as easily as any notary. reply ajb 14 hours agorootparentThee context here (and upthread) is about needing a nominee because you aren't in the country. IE if you were in country you'd control the asset directly. reply JumpCrisscross 14 hours agorootparent> needing a nominee because you aren't in the country. IE if you were in country you'd control the asset directly Yes. A nominee is just a local contact of record. If a nominee can steal your shit, any rando with a notary can, too. reply ajb 20 minutes agorootparentAre you positing a corrupt notary? JumpCrisscross 18 hours agorootparentprev> You can't hire a nominee director? Yes, you can, and it's very common. Couple hundred euros in Cyprus [1]. [1] https://blog.wamo.io/how-much-does-it-cost-to-open-a-company... reply defrost 17 hours agorootparentYep. I've a longterm \"internet friend\" and Cyprus resident/native who has been grumbling about this for two decades now, his principal complaint is the sheer number of Russians back dooring their way into becoming an EU company via Cyprus and screwing up the cost of living, housing, etc for the locals who suffer from the pressure of rich transients who do little for the community. A common enough templte compliant the world over, but it has grounds. He'll also admit it's not just the Russians but many others also. reply JumpCrisscross 17 hours agorootparent> He'll also admit it's not just the Russians but many others also Limassol is friendly to Russians. If you're American, the go-to is Ireland, though Luxembourg is trying to eat their lunch. (If you're Chinese, Hungary and Poland.) reply defrost 17 hours agorootparentIn short, there are significant business opportunities for EU citizens willing to front an EU company for other non EU parties. reply JumpCrisscross 17 hours agorootparent> significant business opportunities for EU citizens willing to front an EU company for other non EU parties I'm describing plain-vanilla incorporation or the buying of an incorporated business. No fronting. reply nradov 17 hours agorootparentprevAs a bloc, the EU should be encouraging Russians to move assets out of Russia because this reduces the tax base for the Putin regime. Do everything possible to destroy the Russian economy. Of course, this can have disruptive effects in some local areas like Cyprus. reply rad_gruchalski 18 hours agorootparentprevThe „owner” is the company. reply codetrotter 18 hours agorootparentHe's saying the company could rent the building to the owner of the company. reply rad_gruchalski 17 hours agorootparentIt’s not really clear what they mean. reply codetrotter 17 hours agorootparentPerson A sets up a company in foreign country. Company buys a building in the country. Company rents out the building to Person A. reply rad_gruchalski 17 hours agorootparentYes yes thanks reply gruez 18 hours agorootparentprevfine. \"actual\" owner, \"ultimate beneficial owner\", etc. reply Beijinger 18 hours agorootparentprev\"a company owned property can't just be used privately.\" Why not? reply matt-p 18 hours agorootparentprevI'm British and it's very easy to setup EU companies, many UK companies have HAD to due to Brexit. reply matt-p 18 hours agorootparentprev>As far as I know every EU business has to have an eu citizen representative. Not at all true, infact it's becoming the exception rather than the rule, look at; Estonia, Ireland, Netherlands, Cyprus, Bulgaria, Hungary. Even in Germany I think it's beginning to become possible. >Additionally, a company owned property can't just be used privately. Um yes, the company rents it out? reply zxspectrum1982 18 hours agoparentprevIt's illegal according to European Union law so this is just one more lie by Prime Minister Pedro Sanchez. https://www.vozpopuli.com/economia/el-castigo-fiscal-a-los-c... reply JumpCrisscross 17 hours agorootparent> It's illegal according to European Union law Is this firmly established or contended? Article 63 of the Treaty of Lisbon [1] bans \"all restrictions on the movement of capital between Member States and between Member States and third countries\" [2]. To define \"movement of capital,\" we must look to Annex I to Council Directive 88/361/EEC of 24 June 1988 [3]. It says \"purchases of buildings and land and the construction of buildings by private persons for gain or personal use,\" including explicitly \"investments in real estate on national territory by non-residents\" counts. Looks clear cut! That said, there appears to be a long history of challenging what constitutes a \"restriction,\" because EU. [1] https://en.wikipedia.org/wiki/Treaty_on_the_Functioning_of_t... [2] https://blogs.kcl.ac.uk/kslreuropeanlawblog/?tag=article-63-... [3] https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELE... reply zxspectrum1982 12 hours agorootparentIt is firmly established. Read the article I linked. reply rapatel0 18 hours agoparentprevOne of the more effective (but potentially over reaching) parts of EU law is that the governments usually give enforcement powers with discretion on how to enforce them. On the one hand it’s annoying because there are no clear rules for how to do business at times. On the other hand, it does typically do a better job of articulating the “spirit of the law” and not allowing people to hack around the letter of the law. I’m pretty sure if using a hack became a trend, then they would start suing people in a few years down the road and extract all the money. reply iforgot22 17 hours agoparentprevOr non-EU resident investing in an EU real estate fund? reply matt-p 18 hours agoparentprevOf course not! Such an insane plan. reply rbjorklin 18 hours agoprevThis will undoubtedly make some brexiteers very unhappy. reply floxy 18 hours agoparentIs that because: A.) There is significant overlap between Brexiteers and those with enough extra wealth to afford vacation / second homes in Spain. Is there any way to quantify this? I would have thought that those with a nationalistic bent wouldn't be keen to own homes in foreign lands. Plus I had the impression that the Remainers were more towards the urban, wealthy, citizen-of-the-world types who would at first blush seem more likely to buy houses elsewhere. B.) The Brexiteers were hoping that the Remainers would all move away, so they don't have to deal with them anymore? C.) The Brexiteers want to colonize Spain? D.) Brexiteers wish they would have thought of the idea punitive taxes on foreigners first? E.) Other? reply johannes1234321 17 hours agorootparentThere is a notable amount of \"expats\" who permanently moved to Spain under freedom of movement, then voted for Brexit and then were angry that Spain/EU started to treat them as foreigners. How many hundred that are I don't know, but they made \"fun\" news stories during those times. reply delroth 17 hours agorootparentThose expats are residents though, and thus wouldn't be impacted by the proposal being discussed in the linked article. reply floxy 17 hours agorootparentprev>How many hundred that are I don't know, but they made \"fun\" news stories during those times. Seems like every human story then. The few-and-far-between exceptions get magnified by 100-1000 times their actual significance by people on the other side. reply cmsj 18 hours agoparentprevGood. I love this for them. Source: totally not still bitter Remainer. reply spacedcowboy 18 hours agorootparentSeconded. Bastards. reply archsurface 18 hours agoparentprevDo you have figures? reply ipnon 18 hours agoparentprevIt's quite funny because Great Britain is the reason why the Spanish won their war of independence. reply affinepplan 19 hours agoprevso is there any actual evidence that foreign home ownership is causing meaningful housing price inflation in Spain? or is this just uninformed pandering like it is in the US reply rolothrow 18 hours agoparentTotally anecdotal, but I live in the largest city in Spain, and even in my residential area (as opposed to the touristy spots) every week I can see ads for \"we buy your house, paid upfront over market value, Chinese investors\". Posters in walls, flyers in windshields and so on. reply JumpCrisscross 18 hours agorootparent> every week I can see ads for \"we buy your house, paid upfront over market value, Chinese investors\" It specifically calls out that they're Chinese? Are you sure this isn't a political stunt? reply rolothrow 12 hours agorootparentYes, it literally says Chinese investor.I guess it's to make the idea of buying immediately a flat with cash sound less shady. I have no idea of the reasoning why specifically Chinese people invest in Spanish real state paying with cash, it's just what I see. >Are you sure this isn't a political stunt? It's our president's whole thing to take measures that sorta move the needle in a good direction but are focused on being good moves politically. My guess is he needs to act against rent prices, he can't go after the big guys (blackrock, etc) for fear of retribution and he can't go after the regular joe that buys a second house as investment. Foreign investors don't vote, so they're the next best option. reply CommanderData 18 hours agorootparentprevThis is excellent, assets like property don't grow on trees and needs to be protected from foreign investors. Absolutely need something like this in the UK. reply throwaway2037 14 hours agorootparentDo you think it is bad when foreign investment corporations buy commercial property? This is very common in London. Or only residential property? And, were you upset when foreign capital (Malaysian, mostly) helped to redevelop Battersea Power Station? reply archsurface 18 hours agorootparentprevThe UK first needs the will to do something. The UK is renowned for shell company purchases and laundering. What is wanted by the little home buyers is very different from what is wanted at the top of the pyramid. As the current uproar about the decades long grooming atrocity has shown the rot runs deep. reply matt-p 18 hours agorootparentprevI think the ship has sailed, but regardless isn't it all meaningless? Surely they can setup a company to get around it, or will be ban all foreign ownership of shares too? reply zdragnar 18 hours agorootparentLand is a public good, insofar as \"buying\" the land still comes with obligations to the state (paying taxes, conforming to building codes and zoning regulation, etc). Just because you \"own\" it doesn't actually mean you can do as you please. Given all of that, it is not unreasonable to limit or outright prohibit foreign ownership of land, or ownership of land by companies which are not majority-locally controlled. reply matt-p 10 hours agorootparentIt's interesting, I just think the second order effects might be a bit scary. Having said that I guess for FDI there's always the option of getting a local company to \"JV\" with like in China. reply Retric 19 hours agoparentprevMeaningful is a weasel word here. Even 0.1% price increase which would be impossible to measure directly still adds up across the entire housing sector. But, equally important is simply the number of natives prevented from buying the home they want because someone is getting a vacation property. reply kasey_junk 18 hours agorootparentBut you also need to measure the dampening impact on home building. If builders would have built N units knowing they could easily sell some % them to foreign buyers but now they can’t, then you might lose the whole supply. And all the knock on effects for contractors, suppliers, etc reply Retric 18 hours agorootparentCities are rarely constrained by the willingness of someone to build housing, it’s generally more an issue of being allowed to build housing. reply crooked-v 18 hours agorootparentFor the most extreme example just look at San Francisco here in the US, where the average number of legally-allowed new housing units is currently around 3.5 total per month (https://sfstandard.com/2024/04/08/san-francisco-new-housing-...) in a city of 873,000 people. reply kasey_junk 18 hours agorootparentprevCities typically don’t have draconian taxes on real estate. reply Retric 5 hours agorootparent~0.1% of real estate. If the major concern is these rules change nothing then that applies to both upsides and downsides. reply aaronblohowiak 18 hours agorootparentprevPedantic nit: dampening is to wet, damping is to subdue oscillations. reply egwor 19 hours agorootparentprevI think I read 20,000,000 need housing and this will impact 20,000 per year so broadly the numbers are inline. reply throwaway2037 14 hours agorootparentHow can 20M be even remotely correct? Spain has a total population of about 48M. reply renewiltord 18 hours agorootparentprevYeah, you have 0.1% of a house, sure. But do that across a thousand houses and you have 100% of the houses. It's that simple. reply Retric 18 hours agorootparent500$ on a 500k house might not seem like a big deal, but I’d still rather have the 500$. reply jopicornell 3 hours agoparentprevIn my hometown, Palma, in Mallorca, I live in a street where 50% of houses are owned by foreign people or investors/airbnb. The neighborhood is not 50% but not that low. The problem? Prices skyrocketed, like a 10x in 10 years (for big houses, small houses 4x). I hear more english/german/sweedish than spanish (or catalan) in my dog walks. Besides economic implications (a lot for local people trying to find places to live), there are cultural/social implications. The neighborhood used to be a community, where people were open to help and share. Now this is changing and evolving into an individualist neighborhood. Our oficial language is being minoritized even more. This doesn't seem like the neighborhood we used to live on. Not everything is economy. The intangible heritage is something we should take care more. reply yeknoda 18 hours agoparentprevDepending on the market, market prices can be decided by a very small number of transactions that set things. Probably true for houses in Spain (limited supply) and foreign wealthy buyers (very high potential demand) reply stavros 19 hours agoparentprevWhat's causing it in the US? reply qball 18 hours agorootparentNew development was made illegal in the places people want to live. It's that simple. Now, you may agree with the given reasons for making that development illegal (and/or very expensive), or you may not, but that is the undeniable end result of those policies. We made that bed, now we lay in it; we could theoretically un-make that bed overnight, but there's serious money (and political power) riding on making sure this problem never goes away. reply Passport4-Lurk 19 hours agorootparentprevIt’s always supply. It’s fair to criticize foreign ownership/hedge funds purchasing homes, but the overwhelming reason is that we are not building enough. reply stavros 19 hours agorootparentSure, but it's one thing to not be building enough for people to live in, and another thing to not be building enough for people to keep empty flats as speculation vehicles. reply gruez 19 hours agorootparentHow many % of flats are empty? At least in the US the hottest housing markets usually have the lowest vacancy rates. This makes sense, because the opportunity costs for leaving a property empty is higher, so owners are more tempted to rent them out. reply jedberg 18 hours agorootparentThe vacancy rates are deceiving though. If you have a place that is owned by someone and they are paying taxes on it, and it's not listed as a rental, it's not considered vacant. In big cities there are definitely homes that are empty and not listed being used as a store of wealth. In fact just within view of my own home are two houses like that. Both owned by foreign families who wanted a safer place to keep their wealth than their own country (China and India respectively). reply cscurmudgeon 18 hours agorootparentSo let the people build enough to make houses being stores of wealth useless rather than engage in more govt control. reply gruez 18 hours agorootparentprev>The vacancy rates are deceiving though. If you have a place that is owned by someone and they are paying taxes on it, and it's not listed as a rental, it's not considered vacant. Why would you lie like that? https://www.census.gov/housing/hvs/definitions.pdf Occupied Housing Units. A housing unit is occupied if a person or group of persons is living in it at the time of the interview or if the occupants are only temporarily absent, as for example, on vacation. The persons living in the unit must consider it their usual place of residence or have no usual place of residence elsewhere. The count of occupied housing units is the same as the count of households Vacant Housing Units. A housing unit is vacant if no one is living in it at the time of the interview, unless its occupants are only temporarily absent. In addition, a vacant unit may be one which is entirely occupied by persons who have a usual residence elsewhere. New units not yet occupied are classified as vacant housing units if construction has reached a point where all exterior windows and doors are installed and final usable floors are in place. Vacant units are excluded if they are exposed to the elements, that is, if the roof, walls, windows, or doors no longer protect the interior from the elements, or if there is positive evidence (such as a sign on the house or block) that the unit is to be demolished or is condemned. Also excluded are quarters being used entirely for nonresidential purposes, such as a store or an office, or quarters used for the storage of business supplies or inventory, machinery, or agricultural products. Vacant sleeping rooms in lodging houses, transient accommodations, barracks, and other quarters not defined as housing units are not included in the statistics in this report. (See section on \"Housing Unit.\") reply jedberg 18 hours agorootparentThat happens once every 10 years. They use tax records and other records to estimate it otherwise. Also people will just not return the form, and once again they have to estimate. And in places that impose a vacancy tax, they have incentive to lie or deceive the housing authority to avoid the tax. And in my neighbors case for example they come by once every few months to pick up mail and probably fill out those types of forms. In reality there are a lot of vacant homes that aren't counted as vacant. reply gruez 18 hours agorootparent>That happens once every 10 years. They use tax records and other records to estimate it otherwise. Good thing we did a census in 2020, and the housing crisis (and associated allegations about absentee owners) far predates that. >Also people will just not return the form, and once again they have to estimate. Apparently they're pretty persistent. If you don't fill out a form you'll eventually get an enumerator that shows up at your door. >And in places that impose a vacancy tax, they have incentive to lie or deceive the housing authority to avoid the tax. The housing authority is independent from the census bureau. Is there any evidence they share data? >And in my neighbors case for example they come by once every few months to pick up mail and probably fill out those types of forms. So they're willing to go out of their way and lie to the federal government in order to maybe move the lower the vacancy rate by 0.00001%, when many (most?) people (as evidenced by this thread) are going off vibes and likely won't care anyways? I didn't know that foreign vacant homeowners had such a tight knit cabal. reply 0_____0 18 hours agorootparentprevI think it's really important to press people on this point, because \"vacant homes as an investment vehicle\" gets trotted out as a thought-killing cliche. Surely there are some pied-a-terre and vacant investment properties, but vacant rental housing in NYC for example was 1.4% in 2023. I'm not sure how they measure this, but even if you doubled the amount of available rental housing, it would still be an insanely hot rental market. Places that have stable or decreasing housing prices (NoLa, Austin) have over 10% of rentals vacant. reply PaulDavisThe1st 18 hours agorootparentprevI still have seen no evidence that VC-backed purchases are having any noticeable impact on the US housing market except possibly in 2 or 3 specific locales (and quite restricted ones at that). So, whatcha got? reply epicureanideal 17 hours agorootparentprevIf they want to pay lots of property taxes and contribute to payments for local infrastructure without actually using it, that’s probably a net good thing, IF there were enough additional homes to go around for others. reply renewiltord 18 hours agorootparentprevWell, the US could build ten thousand Burj Khalifas and the property tax from that would sustain Medicare for All. reply golergka 19 hours agorootparentprevWhen too many flats are used as speculation vehicles, the bubble pops and the problem solves itself. reply epicureanideal 17 hours agorootparentExcept at that point the wealthy homeowners will ask for bailouts. reply CommanderData 18 hours agorootparentprevThe return on property is too good to pass up to an investor. This is a step in the right direction and need something like this in the UK. reply somewhereoutth 18 hours agorootparentprevhowever, like roads, it is entirely possible that building more in desirable neighborhoods simply leads to more wealthy people having more options for which (otherwise empty) residence they choose to spend the weekend at. reply thfuran 19 hours agorootparentprevDecades of public support for treating housing as an investment shaping zoning and other related policies, the relative profitability of constructing budget vs luxury housing, and more recently, inflationary monetary policy, reply seanmcdirmid 18 hours agorootparentprevA housing bust in 2008 washed a lot of capital and talent out of the house construction industry, and the current boom is hard to supply with construction capacity even when there is land to build on. And also, even if the land exists, there is already a SFH on it that needs to be torn down, so we are densifying at a slower rate than we need to. Couple that with an even increasing focus of good job opportunities into a few hot metros, the whole US housing market becomes one hot mess. reply epicureanideal 17 hours agorootparentThere are robotic construction companies like FBR, and plenty of open stretches of land along highway 101, 680, 880, etc. reply seanmcdirmid 11 hours agorootparentThere is a lot of cheap housing in the south and Midwest as well, but it isn’t very relevant since people are picky about where they want to live. reply rvnx 19 hours agorootparentprevIn Canada potentially Chinese immigrants in Vancouver/Toronto, in the US it's an over-generous monetary policy (through low interest rates, especially during COVID) reply ziofill 18 hours agorootparentOne should also add that (at least in Canada) newer buildings are not built for families but for investors. Who needs all of those 30 square meter studios? reply dowager_dan99 18 hours agorootparentprevthey've slashed immigration, so I guess we'll find out. BC is also going to tax any sales after less than 2 years of ownership; I'm doubtful this will increase affordability or supply, but it will essentially kill the economic model of renovation & flipping. reply tandr 17 hours agorootparentI don't think it will kill \"reno and flip\" market. It will become \"reno and rent-to-buy later\", or \"reno, hold and sell\". reply iforgot22 18 hours agorootparentprevSeems Canada has a similar money-printing MO as the US. CAD money supply doubled in the past decade. reply affinepplan 19 hours agorootparentprevin Canada, like in the US, it's a lack of supply mostly because of draconian zoning and land-use policies. Chinese immigrants are NOT the primary cause of housing cost inflation, and are likely not even in the top 10 causes. reply OJFord 19 hours agorootparentI don't know or claim that it's any truer, but I thought the oft-reported reason, for Vancouver/BC especially, was Chinese investment, and explicitly not immigration even, the chief complaint that the growth has been/is expected to be such that they're left unoccupied? reply qball 18 hours agorootparent>for Vancouver/BC especially The ALR bans any and all significant development in BC. Land is not scarce in BC; land that it's legal to build on is. reply OJFord 17 hours agorootparentOk - I'm not Canadian, idk what ALR is - I'm just saying what's disagreed with up-thread isn't what, in my experience, is the common claim (whether it's correct or not). reply qball 17 hours agorootparentThe Agricultural Land Reserve prohibits farmland from being sold for housing development. It's one of the oldest modern NIMBY policies. Most of the land in BC is classified in this way. reply OJFord 16 hours agorootparentWell that's not obviously bad I don't think? If Canadians want to be mad about pro-farm regulation, they should look to dairy; milk tokens, cheese availability, etc. reply _whiteCaps_ 18 hours agorootparentprevThis is my experience. The two houses that I share a backyard fence with are empty. A caretaker comes by once a month to have a look around one of the houses but otherwise they're unoccupied. reply hadlock 18 hours agorootparentprevAre you saying prices didn't go up because of Chinese investors, or Chinese immigrants? I haven't heard anyone discussing immigration as a root cause reply iforgot22 18 hours agorootparentprevSame reason gold increases in $ value just by existing or people passively invest in S&P500. New money is created and it has to settle somewhere. There's plenty of cheap land or land that barely moves in value, but the desirable spots in cities are limited, so that's a natural place to invest. reply epicureanideal 17 hours agorootparentLimited yes, but limited by regulation more than anything else. Within a 30 minute drive of SF there are hundreds of square miles to develop on. Pick a dozen at random and build residential skyscrapers. Problem solved. reply iforgot22 17 hours agorootparentThat's pretty much what they're doing. But the apartment that probably requires driving 30 minutes (or 1.5hr train) to work is worth a lot less than something in SF. Edit: SF itself does have strict zoning. But even if everyone there wanted max density, so they tore everything down and built skyscrapers instead (ignoring the soil problem there), it's a fixed supply of land. reply epicureanideal 17 hours agorootparentYeah I’m seeing some of the development but it’s mostly 5 story rather than 50, and very small total area compared to what would be possible. The apartments are still quite expensive even an hour’s train ride away. reply dataviz1000 18 hours agorootparentprevI wonder if it has something to do with advance economies growing at 1%-2% a year while the least developed countries are growing at 4% - 5%? This would cause the demand for building materials to skyrocket as billions of people can enter the market to purchase lumber, steel, and energy who 10 years ago couldn't. reply bee_rider 19 hours agorootparentprevToo much regulation or greedy landlords depending on your political persuasion. reply WalterBright 18 hours agorootparentThere's never been a time when people were not greedy. The \"suddenly, people started being greedy\" meme doesn't make much sense. reply bee_rider 3 hours agorootparentThe point of the comment was not to present a full description of either position. It was to point out that everybody here is just going to reflexively provide their partisan answers to this question. reply renewiltord 18 hours agorootparentprevNah. There was this time when egg farms got greedy and raised the price. Then they became not greedy again and it's fine. Similar situation with software engineers. They got greedy and salaries went up. When they become less greedy, like rights now, things go down a little. reply bakugo 18 hours agorootparentprevPeople have indeed always been greedy, but the greediest are becoming more wealthy and powerful by the day. reply affinepplan 19 hours agorootparentprevNIMBYism making it extremely difficult and expensive to build supply as is needed. in 1946 the US had a population of 141M and built 700k housing units in 2024 the US had a population of 336M and built 90k housing units reply imperfect_light 18 hours agorootparentWhere are these numbers from? How does 5 million housing units from 2020-2023 (this was published in 2024) translate into \"90K housing units\" >The United States has added almost 5 million housing units since 2020, most heavily in the South and most of them single-family homes, making a housing shortage look conquerable in much of the nation. https://washingtonstatestandard.com/2024/05/16/housing-boom-.... reply LeafItAlone 18 hours agorootparentParent used a single month’s count for the whole year reply glaucon 18 hours agorootparentprev> in 1946 the US had a population of 141M and built 700k housing units I think the year after the second world war ended at which point marriages, and therefore household formation, went to unprecedented levels introduces a lot of noise into that signal reply WalterBright 18 hours agorootparentprev1946 was a special case. It was the start of the baby boom, kicked off by the victorious soldiers returning home and wanting to get on with life. reply LeafItAlone 18 hours agorootparentprev> in 2024 the US had a population of 336M and built 90k housing units That was one month’s worth. There were ~1.5 million built in 2024 in the US. https://www.census.gov/construction/nrc/pdf/newresconst.pdf reply giantg2 18 hours agorootparentprev\"NIMBYism making it extremely difficult and expensive to build supply as is needed.\" Only in some areas. There are other factors affecting how expensive houses are across the country, such as materials/labor, preferences for larger/fancier houses, location preference, and increasingly complex/expensive code. reply MattGaiser 18 hours agorootparent> preferences for larger/fancier houses And more space per person, so older houses now house far fewer than they used to. US has more bedrooms without an occupant than ever. https://www.nytimes.com/2025/01/09/realestate/empty-bedrooms... reply LeafItAlone 18 hours agorootparentI wonder how empty-nesting attributes to this. My parents have 3 empty (really, repurposed) bedrooms in their house now. But downsizing in their area wouldn’t actually help financially, so they don’t. reply giantg2 18 hours agorootparentEmpty-nesting has been a thing for about 2-3 generations. Before that there were often multi-generation homes. But it seems like people didn't really up-size 2-3 generations ago. Many of the great generation were happy to build their 1000sqft Sears house and live there the rest of their lives. The last 1-2 generations seems to be more of a drive for trading up to bigger and better everything. Now we see empty-nesters in 2500sqft houses. I think it's natural to not not want to leave a long-time home, even if it is oversized and only filled on holidays for company or parties. But why do we really need that much space in the first place, seems to be more of the question. reply MattGaiser 18 hours agorootparentprevIn my case, most elderly relatives own their largest homes ever for when kids visit. So many bedrooms have never had a full time occupant. reply iforgot22 18 hours agorootparentprevIdk if the article says this (paywall), but: Home ownership is basically subsidized in the US. So to take full advantage of that, someone may want to buy the most expensive house they can afford in the place they want to live. If it has extra bedrooms, so be it. reply MattGaiser 18 hours agorootparentprevYour 90K number is a monthly number, not annual and only for single family units. https://fred.stlouisfed.org/series/HOUST1F reply iforgot22 18 hours agorootparentIt's also a delta being put alongside the absolute US population reply matt-p 18 hours agoparentprevOf course, it's just more demand, like immigration, aging population and so on. Of course those are a much more difficult target.. reply iforgot22 18 hours agoparentprevEven if it does, I don't see why it really matters. Cost of living has nothing to do with the value of the land you live on. Maybe the real problem is foreign investors leave the property vacant? reply scotty79 18 hours agoparentprevDo you need specific evidence that additional demand causes price increase when the supply is pretty much fixed? reply nsklab 18 hours agoparentprevFor the last years we’ve had 500K immigrants coming every year. That’s what’s causing inflation. reply hjgjhyuhy 18 hours agorootparentPrinting massive amounts of money is what caused the inflation. reply nsklab 18 hours agorootparentI was talking about housing inflation specifically. Housing has increased in price more than the rest of goods plus it’s been increasing in price for a long time, long before covid. Adding millions of people and not building anything makes housing prices skyrocket. One of the two needs to be dealt with and, since immigration also makes salaries plummet for the most vulnerable, why not kill two birds with one stone. reply nozzlegear 19 hours agoprevJust tax land value. reply jedberg 18 hours agoparentHow do you calculate the unimproved land value? This is an interesting question with the fires in LA right now. Is the land still as valuable as it was before the house burned down, minus the rebuild cost of the house? Or is the value intrinsically tied to the community that was there but no longer is? Or is the value actually higher now that a developer can come in and remake an entire neighborhood? reply fastball 18 hours agorootparentI definitely recommend reading Lars Doucet's treatment[1] of this subject. You can skip to section 5 if you want the most direct answer to your question, but the whole thing is worth reading. The short answer is that there are many ways you can assess unimproved land value. The \"Multiple Regression Analysis\" method I think is the most relevant here: you'll see from the linked article a table that includes all sorts of factors related to both aspects you mention: factors of neighborhood/community (some positive, some negative) and factors of potential (some positive, some negative). e.g. there is even a factor of \"Proximity to natural disaster areas\", which would definitely decrease the land value after this LA-area disaster. In this particular case, I would expect that Land Values would go down after the fires, as there are many more factors related to positive neighborhood features (which no longer exist if the neighborhood has burned down) than there are factors related to \"development potential\". Though of course it also matters how you weight these things. Anyway read the article, my summary does not do the subject justice! [1] https://www.gameofrent.com/content/can-land-be-accurately-as... reply x-complexity 18 hours agorootparentprev> How do you calculate the unimproved land value? The first thought that immediately came up for me: - Take the average property value per sqft for each given property - Multiply it by a fixed percentage - Take the (your favorite mean / average type) value per sqft and apply that to the empty lot If that undeveloped land and its surrounding developed areas are controlled by one entity: Recursively expand outwards to factor in the value of the surrounding areas as well. Compared to the methods outlined by fastball's link [0] later in the article, it's much more weighted towards public valuations & has fewer subjective areas, with the cost being that it can be gamed if certain properties were sold cheaply (but then that's an auditing issue). No solution would be a silver bullet, but it's 70% silver, and that's good enough to start from. [0] https://www.gameofrent.com/content/can-land-be-accurately-as... > This is an interesting question with the fires in LA right now. Is the land still as valuable as it was before the house burned down, minus the rebuild cost of the house? Or is the value intrinsically tied to the community that was there but no longer is? IMO, the land value is lowered because of the destruction of the properties built on top of it, on top of the rebuilding costs that will come later. > Or is the value actually higher now that a developer can come in and remake an entire neighborhood? Not until (a) the land is actually developed, or (b) the market reflects that decision back onto the land values for that area. reply adverbly 18 hours agorootparentprevIn situations like this, my assumption would be that it doesn't really get calculated so much as it gets measured... to be kind to victims, you might want to assume it drops for tax purposes temporarily, and then raise the valuation once bids go through and you get some post-fire data points. reply kbelder 18 hours agorootparentOne problem is that the calculated or measured land value will recursively affect the value of the land. reply behnamoh 18 hours agorootparentprevInteresting game theory situation: - if land value depends on the community that was there, then owners would all have incentive to rebuild their burnt down houses to regain the values. - but owners probably realize most owners will sell their property as soon as things are back to normal. that would reduce the value of surrounding houses. - so owners will rebuild as fast as possible, probably cutting lots of corners, just so they won't left behind to sell. - some people start selling their houses but the late comers realize it's not worth it for them to sell it because the value has dropped a lot. so they stay. - the new owners move in to the area and house prices go back up. reply kleinsch 17 hours agorootparentDisagree with logic that most will sell. Many people will incur high tax bills (if the property appreciated) or transaction costs to move. People who bought in the 2010s have mortgage rates that don’t exist anymore. Many had a reason to live in the area to begin with. - Many will rebuild to move back - Some will sell their lots to investors - Some will rebuild using insurance money to flip upon completion reply user_of_the_wek 3 hours agoparentprev- Let the owner pick a land value freely - Calculate land tax based on that - If someone offers the owner more than the value they picked, they have to sell :-P reply adverbly 18 hours agoparentprevThis is they way. This would fix so many things. reply inetknght 17 hours agoparentprev> Just tax land value. Another great way to kick out the undesirables^H^H^H^H^H^H^H^H^H^H^H^Hpoor! reply nozzlegear 16 hours agorootparentThat's valid criticism, it can certainly lead to that if implemented poorly. However, two of the goals of taxing land value are A) increasing the supply of housing and B) discouraging speculative land hoarding — one of the major drivers behind unaffordable housing. reply throaway2501 18 hours agoprevCanada should follow suit reply swat535 5 hours agoparentThey did but they left so many loopholes that was it was basically pointless. Foreigners simply started making an incorporation or using any of the quick \"PR\" schemes to be able to purchase a property. Many people will even pool money from the multiple families if need be to purchase residence and then renting it to Canadian citizens for profit or putting on AirBnb. reply switchbak 18 hours agoparentprevBC has already implemented actions to limit foreign ownership without them actively living in the residence. Probably more to be done though, but one needs to be careful about unintended consequences. reply duxup 17 hours agorootparent>without them actively living in the residence This seems like it would be a bit of a difficult thing to police as far as foreigners goes. reply throaway2501 17 hours agorootparentan “unintended” consequence reply throaway2501 18 hours agorootparentprevlike house prices falling to affordable levels? reply bluGill 17 hours agorootparentThat is the intended and predicted concequence. unintended is things you didn't think of and they can take a long time to appear. reply throaway2501 17 hours agorootparentas a canadian, i’m willing to take the chance (s) reply whatever1 16 hours agoprevEnforce taxes for non occupancy instead. Like €1000 per day that a property is not occupied. Currently the excepted cash flow of buying some property and locking it empty is positive. We need to make it VERY negative. reply philjw 8 hours agoprevGood - even as EU citizen from a \"wealthier\" country who also considered buying an apartment in Spain I felt put off by the sheer amount of non-EU citizens taking the easy and cheap route out, coming over to sunny, walkable and high quality of life Spain with good public health system and showing their excitement about the \"low prices\" - which aren't even that low by EU means, at least for locals working local jobs. A friend advised me last March to \"buy an apartment before the flood / US election\" - but no, I'm not buying into the hype. Fix your political issues overseas or be welcome by paying a fair premium adjusted to the higher income and earn respect by becoming part of the community / learning some Spanish. There needs to be some entry barrier / incentive / application process. In general I can understand why the Spaniards resist. Of course debatable whether it should be all non-EU or simply a list of significantly wealthier countries / countries with high wealth gap and oligarch investors that pay the higher entrance fee. reply nayuki 18 hours agoprevThat's essentially an export tariff. reply Terr_ 18 hours agoparentPerhaps if they were mobile homes. :p The comparison breaks down a little further with cases where the foreign owners just rent the home out. reply gruez 18 hours agorootparent>Perhaps if they were mobile homes. :p Tourism counts as an \"export\" even though everything stays within the country's borders. >The comparison breaks down a little further with cases where the foreign owners just rent the home out. So... an investment tax? reply Terr_ 14 hours agorootparentHmmmm, kinda? AFAIK usually an investment tax is on gains, so \"you must pay X% when purchasing an the capital\" tax seems pretty unusual, or perhaps it exists under some other term. It's not quite a usual sumptuary tax either... I'm assuming it's more about ownership than usage, since it doesn't hit local landlords, and there are already visa/immigration systems if it were a matter of people-movement. reply bborud 19 hours agoprevWould it work or would it just make things worse? reply ilya_m 18 hours agoparentEasy! It won't work and it would make things worse. reply bborud 9 hours agorootparentI was hoping for someone to share a bit of insight on why they think so. (I too suspect it will not achieve the desired outcome, but I had hoped someone could shed some light on the particular conditions in Spain rather some default answer) reply krupan 18 hours agoparentprevIt will make things worse reply saguntum 14 hours agoprevThe English language reporting on this reform proposal is not comprehensive. Here's an article on it by one of the national papers of record, El País: https://elpais.com/espana/2025-01-13/sanchez-anuncia-una-int... Some interesting tidbits from the article: - Some local governments, which are run by a party opposed to the governing national party, oppose the existing laws regarding price regulation and refuse to enforce price caps. This is possible because Spain has a lot of power devolved to local governments. The proposal attempts to side-step local governments by giving property owners a 100% income tax rebate if they abide by national price regulations for their properties. It essentially incentivizes individuals to enforce what regional governments are supposed to be implementing. - Spain's public housing inventory is low compared to other European counterparts - Spain's at 2.5%, France at 14%, Netherlands at 34%. - There are some comparisons to the construction rates during the 2000s housing bubble and how the inventory has shifted between single and multi family dwellings. - The measures include plans to promote prefabricated/modular housing as it is much cheaper to produce at scale. Sidestepping uncooperative local governments is an interesting technique given their devolved system of government. I would also be curious to see how prefab/modular housing measures develop. If they are combining some old school \"price cap / limit foreign investment\" strategy with a pro manufactured housing YIMBYism, that would be kind of unique. From my quick scan of the article, the 100% tax on non-EU residents isn't even reported on. The reform is much more comprehensive and, in my mind, likely to get passed in some form even if the 100% tax gets cut from the final bill. There are also some less than factual opinion statements like this dropped in the Guardian's article: > Given his government’s longstanding struggles to pass legislation, one analyst suggested to the Financial Times that the government’s aim was to deter foreign property investors by creating “uncertainty and noise” with a proposal that has slim chances of becoming law. IMO this is under-selling the current president's political survivability, regardless of what you think of him or his policies. He is currently in power because he convinced a separatist Catalonian party whose leader is exiled from the country to join his coalition. I'd rather not get into it on HN, but read about his tenure for yourself. The Guardian's article is not a good enough summary of what is being proposed and is not giving thorough enough context. reply alecco 9 hours agoparent> one of the national papers of record, El País El País has basically become the socialist government's PR department. reply kjsingh 19 hours agoprevwhat about corporate ownership? reply inetknght 17 hours agoparent> what about corporate ownership? Homes, and real estate in general, should not be an investment vehicle. Screw those corporations. reply WalterBright 18 hours agoparentprevIn order to justify a corporate purchase, there needs to be a return on investment. A vacant property is not that. reply jfghi 18 hours agorootparentI disagree. The large corporations in total own hundreds of thousands of homes in their portfolios. The value of renting or selling can be boosted significantly by introducing scarcity on the margins between supply and demand. A vacancy of a small percentage of the portfolio can ensure the rest of the portfolio is worth much more. To elaborate a little further, it’s not necessarily the act of having it sit empty but rather keeping the pricing high regardless of whether the property stays empty. That becoming industry standard becomes a recipe for prices spiraling out of control, at least for a bit of time. reply WalterBright 11 hours agorootparentPricing high just means opportunities for others to undercut it and snatch away the business. Check out those owners of vacant office buildings lately. Oops. reply WeylandYutani 18 hours agoprevAverage house price in Netherlands is 500k. If you offload your house to the next sucker you can still outbid most people when you move to Spain as a pensionado. reply somewhereoutth 19 hours agoprevAnother (better?) target should be homes used for short term let - i.e AirBnB etc. Homes have such extreme valuations because of the underlying cash flow (or 'rent' in its most abstract sense). Without tourists willing to pay many multiples of what they'd pay at home for accommodation, that cash flow wouldn't be there. reply icegreentea2 18 hours agoparentThe article says they are also targeting tourist rentals. reply switch007 18 hours agoprevAh yes the playbook to distract from immigration, and lack of house building, ie the policies designed to increase house prices reply desireco42 18 hours agoprevThis is equivalent from seizing the properties... I can't imagine this or something similar working well for Spain at all. It will just kill inflow of capital and they will alienate anyone willing to work with them. Advantage of Spain is that it has good climate, prices are not high and it is lawful country. As soon as you trip this last one, it is the same like some 3rd world country. reply golergka 19 hours agoprev [–] I want to make sure I understand this correctly. If you bought a house a few years ago, Spain will effectively rob you of it now? Or will it only apply to new purchases, so you'll have to pay x2 market value if you want to buy one? If it's the former, than even flaunting such a plan is a complete catastrophe for any foreign investment in Spain from now on. But if it's the latter, it'll just bring to life a whole industry of middle-men, which will use their EU residency to buy property in their name to be used by other people. Both ways, it's yet another attempt to force a market to do something that will lead to either disastrous, or just bad results. reply alexanderchr 18 hours agoparentWhat make you think it would apply retroactively? Taxes rarely do, I can’t even think of a single example (but would be happy to learn about one). Putting someone else’s name on the deed is a very bad idea for several reasons. I really can’t imagine anyone doing that, unless it’s a trusted family member or something like that. reply jandrewrogers 18 hours agorootparentCalifornia is notorious for implementing retroactive taxes, having done it multiple times. I can't think of an example from another jurisdiction though. reply gruez 18 hours agoparentprev>If it's the former, than even flaunting such a plan is a complete catastrophe for any foreign investment in Spain from now on. There's investments that don't involve real estate. Moreover, property isn't a productive asset, so discouraging investment into that is arguably a good thing. Investing money into a factory means you get more stuff produced. Investing money into property just... sits there. reply WalterBright 18 hours agorootparent> property isn't a productive asset It is when you rent it out. reply iforgot22 17 hours agorootparentIn theory, the market should push owners to rent when prices stabilize. Eventually. In the meantime, it's possible that some foreign investors don't care too much about the opportunity cost. I think some kind of vacancy tax is the only good way to fix this if it's a real problem. reply WalterBright 11 hours agorootparentVacant property is quite a drain on one's pocketbook. Try it some time. When I move and sell the old house, I underprice it to sell it as fast as possible. The other sellers do not seem to understand the time value of money, the maintenance cost, the taxes, the vandalism, and the squatter risk. Oh, and your insurance goes up if the house is vacant. And never mind having $800,000 or so tied up as a millstone around your neck when you could be investing it in stocks. reply iforgot22 1 hour agorootparentGenerally yeah, but idk what it's like in Spain. If the gains are huge or the renters' protections are nuts, it could theoretically make sense to keep vacant. If there isn't high vacancy in Spain, this is moot reply yoyohello13 18 hours agorootparentprevLiteral rent seeking behavior from foreign investors. reply PaulDavisThe1st 18 hours agoparentprev> a complete catastrophe for any foreign investment in Spain from now on No doubt because a) all foreign investment always comes with individuals from the investment source purchasing homes in the investment target country b) Germany is no longer foreign when it comes to Spain, so any money invested by Germany would not count as \"foreign investment\" Am I right? reply jterrys 18 hours agoparentprevHousing prices in spain and portugal are booming to astronomical degrees mainly because of china. This bill is specifically targeted to stop that without explicitly calling out china. Middlemen cost money, making it more expensive to buy houses, which serves the purpose to restrict the market outside of non-eu residents. What's going to realistically happen is foreign investors will claim quick citizenship in a relatively poor and more corrupt eu member state and then buy the property. reply egwor 18 hours agoparentprev [–] believe it is new purchases reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Spain is considering a 100% tax on real estate purchases by non-EU residents, aiming to address the housing crisis and curb speculative buying.",
      "Prime Minister Pedro Sánchez's proposal includes expanding social housing and regulating tourist rentals to tackle the disparity between housing prices and incomes.",
      "The proposal's future as law is uncertain, with some analysts viewing it as a deterrent to foreign investors rather than a guaranteed legislative change."
    ],
    "commentSummary": [
      "Spain is considering a 100% tax on homes purchased by non-EU residents to tackle housing affordability problems. - Critics suggest that foreign buyers are not the primary cause of high housing prices, citing slow bureaucracy and zoning laws as more significant factors. - The proposal has ignited a debate on the role of foreign ownership in housing markets and its effectiveness in resolving affordability issues."
    ],
    "points": 162,
    "commentCount": 254,
    "retryCount": 0,
    "time": 1736809603
  },
  {
    "id": 42699977,
    "title": "Apple will soon receive 'made in America' chips from TSMC's Arizona fab",
    "originLink": "https://www.tomshardware.com/tech-industry/apple-will-soon-receive-made-in-america-chips-from-tsmcs-arizona-fab-company-in-final-stages-of-quality-verification",
    "originBody": "Tech Industry Apple will soon receive ‘made in America’ chips from TSMC's Arizona fab — company in final stages of quality verification News By Jowi Morales published 5 hours ago Mass production could begin as soon as Q1. Comments (5) When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. (Image credit: Getty Images) Apple is already testing the initial batch of processors produced for its devices by TSMC Arizona, reports Nikkei Asia. To begin with, the tests intend to compare the Arizona output to see if the quality is similar to chips produced in TSMC’s cutting-edge fabs in Taiwan. If the chip quality verification testing does not encounter any hiccups, the source says that the first batch of mass-produced chips from the Arizona fab is expected to arrive at iDevice makers as early as this quarter. If this is the case, Apple will likely be TSMC’s first American customer to use locally made chips. AMD and Nvidia will likely follow suit soon, as they’re also running wafer test production there. The entry of locally produced chips in the American market is a big win for the United States’ push for silicon independence, especially as it massively relies on Taiwan for the majority of its most advanced chips. Taiwan is located in a high-risk location, with the belligerent CCP-controlled China having the island in its sights. The island is also prone to natural disasters, which can disrupt semiconductor production and result in supply crunch situations. However, even if Apple gives the go signal to TSMC and the latter starts making chips in Arizona, the processors still need to be shipped back to Amkor in Taiwan for packaging until TSMC completes its facility in Peoria, Arizona. But whatever the case, this is a significant push in the right direction for the U.S., especially as the Arizona fab has been delayed for about a year due to various issues. Aside from TSMC and Amkor, other suppliers to these companies, like LCY Chemical, are also setting up in Arizona. That way, they could stay near their client and simplify logistics. Despite importing about half of its employees from Taiwan, it seems that the common American is also slowly benefitting from TSMC’s presence in Arizona, especially as it’s reported that the company has started aggressive recruitment from American universities. It has also partnered with the Arizona State University for workforce development and research, helping drive American innovation. After what seems to be its initial success with Apple, the Arizona fab is expected to output chips using more advanced technology. TSMC will produce 3nm chips in the U.S., and Taiwan has already given TSMC the go-signal to manufacture 2nm chips abroad. With the CHIPS and Science Act now bearing fruit, the U.S. could once again appear on the semiconductor production world map and give it more stability in its silicon supply chain. Stay On the Cutting Edge: Get the Tom's Hardware Newsletter Get Tom's Hardware's best news and in-depth reviews, straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. SEE ALL COMMENTS (5) Jowi Morales Contributing Writer Jowi Morales is a tech enthusiast with years of experience working in the industry. He’s been writing with several tech publications since 2021, where he’s been interested in tech hardware and consumer electronics. MORE ABOUT TECH INDUSTRY Taiwanese govt clears TSMC to make 2nm chips abroad — country lowers its 'Silicon Shield' Lenovo led global PC shipment in 2024 with 61.8 million units — Apple is gaining PC market share with a 17.3% growth LATEST Doom ported to run directly from a PDF file — DoomPDF port runs at approximately 12.5 FPS SEE MORE LATEST ► 5 Comments Comment from the forums hotaru251 so can we expect the price of devices to go higher as iirc TSMC stated at start the price will be higher for the chips made at the factory and companies rarely foot that increase themself.. Reply helper800 These would not be \"Made in America\" chips, they are \"Assembled in America.\" Reply TheSecondPower Doesn't Apple still build their computers in the CCP-controlled West Taiwan? So the chips will ship from the US to Taiwan for packaging, then to China for installation in a device, then back to the US for sale. Reply Gururu This is awesome! Reply phead128 TheSecondPower said: Doesn't Apple still build their computers in the CCP-controlled West Taiwan? So the chips will ship from the US to Taiwan for packaging, then to China for installation in a device, then back to the US for sale. It's only a fraction of TSMC's capacity. The actual amount to meaningfully on-shore is in hundreds of billions of investment, so it's more of a symbolic on-shoring than any true resilience in supply chain. Reply VIEW ALL 5 COMMENTS Show more comments",
    "commentLink": "https://news.ycombinator.com/item?id=42699977",
    "commentBody": "Apple will soon receive 'made in America' chips from TSMC's Arizona fab (tomshardware.com)156 points by rbanffy 2 hours agohidepastfavorite68 comments digdigdag 32 minutes ago- Over 50% of the workers flew in from Taiwan to work on this plant and make these chips. - The chips still need to fly back to Taiwan to be packaged as there are no facilities here with such a capability. Made in america is a hard sell. But at least showing the glaring STEM field gap in the U.S. is a start to finally addressing the brain drain. reply Xeronate 25 minutes agoparentI read the main problem with hiring chip factory workers in Arizona was the factory just didnt pay enough for the long hours demanded. I looked up the median salary and its only 50k so I'm assuming it's not crazy skilled labor (e.g. brain drain). Taiwanese workers just seem more willing to do it. reply rkagerer 7 minutes agorootparent...just seem more willing to do it That's why manufacturing offshored in the first place, companies feel they're receiving better value for money on wages elsewhere for this kind of work (and these days not to mention more & larger facilities, proximity to component sources, and a strong ecosystem of supporting and complimentary facilities). reply epicureanideal 25 minutes agoparentprev> STEM field gap STEM salary gap I suspect the Taiwan workers have on average much lower salaries. reply lysace 23 minutes agorootparentYes, roughly speaking 1:4 compared to California. reply coliveira 8 minutes agorootparentSuch a great victory for American industry... the future is to bring workers from Taiwan with skills and willingness to receive a fraction of US salaries. reply Cumpiler69 2 minutes agorootparentWhat are your realistic options? Say TSMC pays supper competitive US salaries for US-only labor, labor cost which is making the end product more expensive which makes that fab uncompetitive globally and Apple buying from someone else and TSMC leaving the US. You can't compete with lower-wage countries in a globalized world with no trade barriers and no tariffs, when Apple wants higher profits and consumers lower prices. bee_rider 14 minutes agoparentprevAlso a lot of US STEM grads have their skills wasted in unproductive fields, like the ad business. reply alt227 0 minutes agoparentprevcan you really say the chip was made in America when it is only the die wafer which was made there and the rest was made and assembled in Taiwan? reply isodev 5 minutes agoparentprev> The chips still need to fly back to Taiwan The planet burned, but at least we made a few chips in America. reply fooblaster 1 minute agorootparentyou can fly a few hundred million dollars worth of chips in a single flight. You need not be concerned. The impact from temu shipments is several orders of magnitude higher. reply caycep 30 minutes agoparentprevisn't packaging tech mostly from american companies like applied mat/lam research? or am I missing something? reply ge96 26 minutes agoparentprevbrain drain from where? thought a problem is influx of workers into us although more for software not sure of chip tech reply duxup 24 minutes agoprevSeems like this is actually happening. I saw so many predictions of how this couldn't happen and \"yeah but\" ... but it seems to be happening for the most part. reply ashoeafoot 28 minutes agoprevTaiwan exodus in 3..2..1 reply bitsage 1 hour agoprevFunny enough, Fab 21 was announced in May 2020 and completed construction in July 2022, a month before the Chips Act was signed. reply mywittyname 25 minutes agoparentThe announcement of this plant coincided with the announcement of the Endless Frontier Act and CHIPS for America act, which is what eventually became the bill we call CHIPS and Science Act. This plant was the foundation that the CHIPS act was built upon. The Secretary of State had to secure an agreement with TSMC to build this fab before the bills could be drafted, as a lot of the recipients of the funding are suppliers for this plant. It is completely truthful to assert that this is the result of the CHIPS act. Congress agreed to introduce the bills as a result of TSMC's agreement to build the fab in Arizona. If you have to avoid giving Biden credit, then you can point out that it was Trump's SoS who negotiated this original agreement. reply j_walter 40 minutes agoparentprevWhat makes you think construction was completed in July 2022? The shell of Phase 1 may have been completed, but even now the construction continues in Phase 1B and Phase 2. reply lysace 55 minutes agoprevMade using which process? The article doesn't mention this. https://www.tsmc.com/english/dedicatedFoundry/technology/log... reply entropicdrifter 47 minutes agoparentThe smallest process they've got up and running right now is 4nm, last I checked reply drexlspivey 28 minutes agorootparentSo which device will these be for then? I thought Apple stuff are always on the cutting edge node. reply kcb 9 minutes agorootparentApple still produces older generation devices long after the latest ones are released. That's their whole strategy to address the lower end market. reply alt227 3 minutes agorootparentpreviPhone SE reply dietr1ch 43 minutes agorootparentprevAs an outsider that means somewhere in 2nm-10nm as everyone measures different things or have awfully off-standard rulers. reply ant6n 38 minutes agorootparentI’d say it means TSMC 4nm. reply choilive 47 minutes agoparentprev4nm reply lysace 45 minutes agorootparentI thought Taiwan prohibited export of this kind of know-how? What did I miss? reply j_walter 42 minutes agorootparentThey have adopted a n-2 type of rule for advanaced tech...but as of yesterday they seem to have relaxed this rule and approved transfer of 2nm from Taiwan fabs to the AZ fab at some point in the near future. https://www.extremetech.com/computing/tsmc-cleared-for-2nm-p... reply zanderwohl 33 minutes agorootparentAdvanced lithography is like if a mystery cult were real: Secret knowledge only understood by the most learned initiates, tightly-guarded process, etching symbols that do things... reply lysace 0 minutes agorootparentSadly true. Even more depressing: it's like a very complicated baking recipe arrived at by tweaking parameters over and over a again. There is no understanding... just a gian list of baking paramaters that seem to work, sometimes. lysace 29 minutes agorootparentprevI'd be extremely surprised if Apple is now able to source CPUs for current-gen high-end iPhones from a US fab. 2 gens ago, sure. reply andy_ppp 37 minutes agorootparentprevWow I did not know this and it is fantastic news, surprised Taiwan allowed this as they see chips as being the most important reason America would intervene if they were invaded. reply DennisP 26 minutes agorootparentIn case of invasion, it's not that unlikely that the fabs in Taiwan get destroyed, or at least lose the ability to keep making and selling chips while the conflict is hot. In that case TSMC and Taiwan might prefer having a backup. As long as the US doesn't confiscate the Arizona fab, effectively siding with China, Taiwan would arguably have more leverage by still having something of immense strategic value to trade. reply whimsicalism 34 minutes agorootparentprevI'm a China dove and I'd favor full-throated defense of Taiwan in any invasion (much more so than Ukraine) regardless of chips. reply d3ckard 23 minutes agorootparentI don’t disagree with the core premise, but why much more than Ukraine? reply mdavidn 41 minutes agorootparentprevASML, a Dutch firm, sells photolithography equipment to TSMC. reply xattt 24 minutes agoprevIs this the first “Made in USA” chip in Apple devices since the Fishkill PPC 970? reply triactual 11 minutes agoparentWeren’t the Intel CPUs made in the US? reply datadrivenangel 1 hour agoprevThese chips are still sent to Taiwan for packing, so it's a good step but not a complete step. reply dgfitz 1 hour agoparentUntil 2027, yes. https://www.tomshardware.com/pc-components/gpus/tsmc-is-repo... \"TSMC does not have an advanced packaging facility in the U.S., and its partner Amkor will only start packaging chips in Arizona in 2027. As a result, Blackwell AI silicon produced in Arizona will need to be shipped back to Taiwan for final assembly, as all of TSMC's CoWoS packaging capacity remains in Taiwan.\" reply ttul 36 minutes agorootparentGiven that there may be a 25% chance that China invades Taiwan by 2030, having the ability to package SOTA chips in the US by 2027 seems \"soon enough\". reply ponty_rick 1 minute agorootparentWould be interesting if China uses drones with technology from Taiwan to invade Taiwan. reply risho 12 minutes agorootparentprevwhere did you get that number from reply xeromal 7 minutes agorootparentThere's a window where China will have it max capability to invade for the next few years. After that their population is going to start shrinking and every year will be harder than the next to invade. reply hollow-moe 1 hour agoparentprevwhat is involved in the packaging process ? I believe they don't ship fully assembled chips to Taiwan only to be put in a pretty box ? reply mechagodzilla 51 minutes agorootparent\"Packaging\" in this context means taking the wafer of compute die (made in Arizona), dicing it up into individual die, mounting it onto a silicon interposer (an even bigger die, no idea where that's made, but probably taiwan) along with a bunch of HBM die, then mounting that Si interposer on a somewhat larger, very fine-pitched circuit board ('substrate') that is essentially a breakout for power and high-speed I/O from the compute die. That thing is the packaged 'CoWoS' system, where CoWoS==Chip-on-wafer-on-substrate, that eventually gets attached to a 'normal' PCB. reply eric-hu 17 minutes agorootparentThis sounds like a complex procedure. Are there currently alternative packaging facilities that could do this work, if Taiwan were locked into kinetic war? reply SSilver2k2 54 minutes agorootparentprevI'm making an educated guess but probably the cutting of chips from the wafers, placing them into the appropriate ceramic socket types (DIP, BFGA, SMD etc), soldering the line wires from chip to pin, encasing the chip, etc. reply a1o 37 minutes agorootparent> DIP I am happily imagining opening a recent Apple device and seeing 74 gates with through holes in green PCBs, with an Apple logo made in soldering lead marking in the corner of the board. reply jsheard 56 minutes agorootparentprevI believe packaging in this context means taking the raw silicon dies and assembling them into a package which can be soldered onto a PCB (or put in a socket, but Apple doesn't socket anything). reply virexene 51 minutes agorootparentprevI think \"packaging\" here refers to the process of putting the silicon die in its plastic casing and connecting the die's pad to the case's pins, see https://en.wikipedia.org/wiki/Integrated_circuit_packaging reply j_walter 38 minutes agorootparentprevhttps://www.youtube.com/watch?v=-egYoxajTz0 reply Detrytus 10 minutes agorootparentprevBelieve it or not, sending them overseas just to be put in a box actually can be cost-effective. Like with those pears: \"grown in Argentina, packaged in Thailand, sold in UK\" https://www.birminghamfoodcouncil.org/2022/01/16/part-i-pear... reply m348e912 1 hour agoparentprevHow does this make any financial sense? reply snakeyjake 55 minutes agorootparentThe machines and processes needed to package the individual integrated circuits are fantastically expensive but the margins are so low in that step that it's only profitable at massive scales. So you put the fantastically expensive machines near where most of the customers are and most of the customers are in Asia. Works the same way with fiber optic cables. Making the long skinny bits is hard and high-margin. Actually turning them into cables is easy and low-margin. So Corning makes huge spools of fiber optic cable in Arizona, North Carolina, and New York (I think) and ships it off to Taiwan and China where it is made into the cables that you plug into stuff. reply arcticbull 1 hour agorootparentprevMarine shipping is just about the most fuel efficient way of moving things between any two places, by a lot. A 100,000 dwt ship can get 1050 miles per gallon per ton of cargo. It takes about a teaspoon full of fuel to move an iPhone sized device across the pacific when I ran the numbers last. reply umanwizard 39 minutes agorootparentTo ship things to/from these fabs by sea you have to add the cost of shipping by truck between Phoenix and (presumably) LA. Not sure how big of a difference that makes. reply ponty_rick 0 minutes agorootparentTrains are pretty efficient as well. kstrauser 22 minutes agorootparentprevA semi truck carries +- 15 tons of cargo and gets an average of about 6 MPG, so about 90 MPG/ton. reply nine_k 27 minutes agorootparentprevChips are small, so one truck once a few days may suffice. reply Vt71fcAqt7 45 minutes agorootparentprevInteresting. Could you give a brief description of how you got that number? Eg. what factors were considered. reply eric-hu 21 minutes agorootparentThose numbers match what comes up with a quick search: https://www.extension.iastate.edu/grain/topics/EstimatesofTo... That study uses 1,043.4 mpg for the fuel economy of a 100,000 dwt ship. Videos of transportation ship engines are cool. Each cylinder is wide enough for a person to lay down inside it. https://youtu.be/G0eMyA388bE reply _aavaa_ 1 hour agorootparentprevThis is how most modern supply chains look like. Plus, chips are small in size and cost a lot so you can fit a lot in a container. Per unit shipping costs probably come out to be pretty low. Especially when compared to the political costs and risks associated with not onshoring. reply fblp 55 minutes agorootparentprevI'm suprised they can't ship (flat) packaging that could be used in Arizona with a simple assembly line. If they had that packaging design then for this to make financial sense the two way shipping (and loading, unloading, custom clearance etc) would have to be less than shipping the packaging, the setup cost per unit cost of putting the chip in a box reply krisoft 39 minutes agorootparentWait, wait. In the context of semiconductor manufacturing packaging does not mean what you think it means. It is not putting the product in a paper box. It is about cutting the wafer into individual chips, wire bonding the silicone to pins, and covering the whole thing with epoxy. Here is a video which explains it better: https://www.youtube.com/watch?v=7gg2eVVayA4 It would be indeed crazy if they would ship the ready chips to Taiwan just to be put in a paper box. basically the input of the process is a wafer which looks like this: https://waferpro.com/wp-content/uploads/2016/08/Patterned-Lo... And the output of the process is something which looks like this: https://res.cloudinary.com/rsc/image/upload/b_rgb:FFFFFF,c_p... reply zeusk 31 minutes agorootparentThe packaging in this context is not wire bonding but CoWoS - chip-wafer and wafer-wafer bonding. reply j_walter 38 minutes agorootparentprevYou seem to be confusing the term packaging...it is not the box, it is how the chips are assembled together to make the final product. https://www.youtube.com/watch?v=-egYoxajTz0 reply hettygreen 9 minutes agoprev [–] with required NSA backdoor of course. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple is testing processors from TSMC's Arizona facility, with plans for mass production by the first quarter, potentially becoming TSMC's first U.S. customer for locally manufactured chips. - This initiative aims to bolster U.S. silicon independence, reducing dependency on Taiwan, which is vulnerable to geopolitical and natural risks. - TSMC's Arizona fab is set to produce advanced 3nm and 2nm chips, with ongoing efforts to enhance local recruitment and partnerships with U.S. universities, although packaging will initially occur in Taiwan until the Peoria facility is operational."
    ],
    "commentSummary": [
      "Apple will receive chips from TSMC's Arizona plant, but they need to be sent back to Taiwan for packaging due to insufficient U.S. facilities. - Over 50% of the workforce at the Arizona plant is from Taiwan, indicating a gap in the U.S. STEM (Science, Technology, Engineering, and Mathematics) field. - The CHIPS Act initiative, aimed at enhancing U.S. semiconductor manufacturing, faces challenges as the \"Made in America\" label is questioned due to the packaging process occurring in Taiwan, with plans for U.S. packaging capabilities by 2027."
    ],
    "points": 160,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1736873807
  },
  {
    "id": 42692730,
    "title": "43K fewer drivers on Manhattan roads after congestion pricing turned on",
    "originLink": "https://gothamist.com/news/43k-fewer-drivers-on-manhattan-roads-after-congestion-pricing-turned-on-mta-says",
    "originBody": "A non-profit newsroom, powered by WNYC. Listen Live Donate NEWS 43K fewer drivers on Manhattan roads after congestion pricing turned on, MTA says Selcuk Acar/Anadolu via Getty Images By Ramsey Khalifeh Published Jan 13, 2025 Share We rely on your support to make local news available to all Make your contribution now and help Gothamist thrive in 2025. Donate today Gothamist is funded by sponsors and member donations The launch of congestion pricing led to some 43,000 fewer drivers on average entering Manhattan below 60th Street each weekday last week than would be typical for that time of January, according to data released by the MTA on Monday. The data comes just over a week after the tolls went live. The decline in traffic only amounts to a 7.5% reduction compared to projections based on Januarys from the last few years, before congestion pricing was activated. Under the projections, an average of 583,000 drivers would enter the toll zone each day. But such a reduction, many people in Manhattan have observed, can be the difference between flowing traffic and gridlock. “It has been a very good week here in New York,” MTA deputy chief Juliette Michaelson said at a news conference. She cautioned that congestion pricing had only been in effect for eight days and that traffic patterns could change. Traffic times on all inbound crossings — like the Williamsburg Bridge and the Holland Tunnel — have decreased between 30% to 40% on average, particularly during the morning commute, according to the MTA’s data. Bus speeds also increased after the tolls were turned on. The Manhattan-bound B39 bus, which crosses the Williamsburg Bridge, ran 28% faster compared to a similar January week last year. Other buses like the SIM24 and and the M50 saw increases in speeds, as well. As for ridership on the MTA’s buses, Michaelson said that some express buses including the BM1, QM16, BM4 and SIM9 saw higher than average ridership growth last week, but did not specify by how much. The same data shows that speeds traveling north and south on avenues in the toll zone south of 60th Street didn’t change significantly. The MTA turned on the toll cameras on Jan. 5, charging most drivers a daytime $9 fee to enter the zone. The MTA is using the revenue from the congestion pricing tolls to issue a $15 billion bond to buy new train cars, install accessible elevators at subway stations across the city and other transit infrastructure improvements. Michaelson said the MTA has not looked at the total revenue generated from the tolls in the first week of the program. The MTA estimates it can collect $500 million through congestion pricing every year. Congressional Republicans from New York have vowed to kill the tolls and said they have President-elect Donald Trump’s support. But transit advocates said the first week of data showed congestion pricing is working. \"Drivers are saving tons of time. Buses are finally speeding up, especially express buses full of long distance commuters from across New York and New Jersey,” Riders Alliance spokesperson Danny Pearlstein wrote in a statement. \"With such immediate success, politicians trying to end the program for personal gain must tell us why they want to lengthen millions of commutes, block tens of thousands of infrastructure jobs, and cut home values throughout the city and suburbs.\" Stephen Nessen contributed reporting. Tagged MANHATTAN TRANSPORTATION Ramsey Khalifeh Ramsey Khalifeh is a transportation reporter on the NYC Accountability desk covering the largest transit system in the country. He was previously a general assignment reporter at Gothamist and worked on the Boston Globe's metro and copy desk. Got a tip? Email rkhalifeh@nypublicradio.org Read more Gothamist is funded by sponsors and member donations MORE NEWS",
    "commentLink": "https://news.ycombinator.com/item?id=42692730",
    "commentBody": "43K fewer drivers on Manhattan roads after congestion pricing turned on (gothamist.com)154 points by pseudolus 16 hours agohidepastfavorite199 comments jmward01 16 hours agoRoads in cities are such a waste of space. A long time ago I did a quick survey of SF and found something like 20% of the land was dedicated to cars. Some articles from people here that talk about this [1] [2] [3]. That is the most subsidized land on the planet but people don't think of it that way. They think roads are free so any tax to use them is wrong. That space could be helping out the city in so many ways but instead it is just ugly pavement. Yes we need some roads, but cars driving in the heart of downtown as normal transit? It boggles my mind how dumb that is. Raise this tax until basically nobody is using the roads then rip most of them up except maintenance corridors and put that land to use. [1] https://www.sfmta.com/press-releases/sfmta-completes-citywid... [2]https://thehill.com/changing-america/resilience/smart-cities... [3] https://sf.streetsblog.org/2014/11/03/study-quantifies-how-u... reply vlovich123 15 hours agoparentYou’re not incorrect per se, but it’s important to note that deliveries into downtown would be important for it to be a thriving destination for shopping, residential or business. Not to mention space for heavy equipment to come in to do repairs and construction. Minimal maintenance corridors may not be enough. You also need public transit options into it as well as transportation solutions for “out of towners” who descend onto downtown for some event (eg public parking lots outside the city that has public transit to the event). It can be an easier and more politically popular idea to just use streets to solve this problem at the individual level even if less efficient rather than requiring efficient central management planning by the government. And just to be clear, I’m a fan of the changes SF is making, just highlighting some of the challenges, not to mention that SF isn’t going quite so far as to rip up existing streets with the exception of the latest vote where the entire city basically voted against the will of the outer sunset to convert the highway to a park and not just closed on the weekends as it’s been since COVID (increasing maintenance costs due to erosion are another huge reason it’s a good idea). reply wongarsu 15 hours agorootparentIn any city that isn't hopelessly car-dependent there is some kind of rail to bring in commuters. A subway, tram, light rail, passenger rail, often a combination of all of them. Once you have a stable system to bring in commuters, adding a couple parking lots to stops on the outskirts for \"out of towners\" is pretty easy. The rest is just about not removing all the streets. You also need enough roads for emergency vehicles. But simple two-lane roads for arteries and one-lane roads everywhere else are enough for deliveries, maintenance and (European-sized) emergency vehicles. All the other lanes are just there so everyone can travel downtown in their personal car instead of using more efficient transport options. reply pfg_ 11 hours agorootparentYou can also have fully closed streets open to emergency vehicles as long as a path is kept clear reply bufferoverflow 15 hours agorootparentprevOne-lane road in a city means any car can block the whole road. So if an ambulance needs this road to save you, you're out of luck. reply jacoblambda 14 hours agorootparentJust because a street is one way does not mean it is so narrow that only one vehicle can fit through. Streets may be one way because it discourages unnecessary automotive traffic and it allows the rest of the space to be dedicated to bicyclist or use for residential and commercial purposes (outdoor seating, space for games, etc). So even if the streets are one way, there will often be space for the ambulance to maneuver around blocked vehicles. And if there's not, the ambulance can take another street or road. If it's the only route that can access that location, then with any sane amount of urban planning then the ambulance will be within a short walking distance to the location (and more often than not within eyesight). reply wongarsu 14 hours agorootparentprevProhibit on-street parking on at least one side of the road, make the side walk on that side big enough that an ambulance can use it to pass other vehicles if the road is blocked (I'll skip the question of why the street is blocked in the first place). Actually enforce the parking restriction. You need space for pedestrians anyways, and with traffic restricted to the necessary minimum you don't need bollards everywhere This isn't some kind of rocket science that has never been tried before, it's the reality in many cities around the world. You need an entire concept instead of adding half-backed solutions to an existing system, but the solutions are all well-tried and for the most part very straight forward. reply vlovich123 13 hours agorootparentprevAre you sure that’s not a path dependency that’s difficult to undo? Retrofitting this into a place like the Bay Area seems impractical given how bad public transit is there chronically. reply Over2Chars 12 hours agorootparentThe public transit quality reflects the government quality. reply Qwertious 15 hours agorootparentprev>but it’s important to note that deliveries into downtown would be important for it to be a thriving destination for shopping, residential or business. Not to mention space for heavy equipment to come in to do repairs and construction. Minimal maintenance corridors may not be enough. I used to work at a warehouse, the whole street of warehouses had a street width of at most 10m (30ft) wall-to-wall. People vastly overestimate how much throughput is needed purely for shipping, due to all the passenger cars on the road. Heavy equipment is also less of an issue than you'd think, because it tends to expand to fit the space it's permitted - like all engineering projects. reply wat10000 15 hours agorootparentprevSome cities manage fine with very small roads. Sometimes there isn’t exactly a road at all, but rather a pedestrian area that can be used for deliveries and such when necessary. American city centers are overprovisioned on roads by probably a factor of 10 or more. Ironically, fixing that would be excellent for local businesses, and they’re usually the ones opposing it because they think there’s no way to get customers besides having them drive directly to the business and park on their property. reply Over2Chars 12 hours agorootparent@wat1000 perfectly said. And the small businesses are the most easily frightened by well financed campaigns that make them afraid their business will shutter if car based traffic is even slightly reduced. reply epistasis 15 hours agorootparentprevIn Ancient Rome, private vehicles were banned during the first ten hours of the day. Doing the same for nearly all commercial deliveries would make a lot of sense today too. A huge number of delivery trucks are massively oversized and inappropriate for their task. Charging for oversized vehicles might wake some business owners up to more carefully evaluating their costs and making more rational choices. Heavy equipment is easy to permit. Look at any car-free area and there are very reasonable exceptions to make them function. The important thing is to remove cars as the mandatory way to access locations, and to cease prioritizing cars over more efficient methods of transit. Forcing cars into our cities took a massive amount of changes to our legal and planning system, and huge huge subsidies. Just going back to thinking of cars as one of many ways to get around, rather than as the primary and prioritized method of getting around, would allow for much more efficient systems. New York City has more than adequate public transportation, except for the private vehicles slowing it down. SF has adequate public transit, but without all the cars in the way and with higher ridership it would be amazing. reply Over2Chars 12 hours agorootparentThe small difference between Ancient Rome and the governments of SF and NYC is that ancient Rome had good government. reply tacticus 14 hours agorootparentprev> It can be an easier and more politically popular idea to just use streets to solve this problem at the individual level even if less efficient rather than requiring efficient central management planning by the government. So how many 40 lane roads are you going to build instead of single train lines? reply smcin 15 hours agorootparentprevThis is kind of like an argument-by-consequences since SF funding for transit and roads has viability problems due to SF's comparatively low residential density, as the funding from Covid, federal and then CA state emergency funding that replaced those disappear in 2025. This will cause big service reductions in SF MUNI [0], BART and Caltrain, starting this year. And it wasn't about \"the will of the Outer Sunset\" [1], and some (local) people there rely on car or rideshare access, plus all the rest of us from everywhere that isn't the Outer Sunset also want to be able to drive there to visit. The existing post-Covid time-shared road/park setup on Highway 1 was already incredibly friendly to bikes, pedestrian, pets, children, surfers. And SF Measure K only passed 54.7:45.3% [2]. > \"increasing maintenance costs due to erosion are another huge reason it’s a good idea)\" You could argue the exact same that SF cablecars could be cut because they net lose money (federal subsidy), or about all of us constantly paying for the upkeep of Highway 1 down at Big Sur, which is regularly closed/subsided/storm-damaged, and costs $$$ to repair every winter, but the wishes of the (small population of) locals have to be balanced against the wishes of everyone else (CA + out-of-state residents, tourists) who use it. In any case re the viability of transit at such low neighborhood densities, Seamless Bay Area [3] have for years been pointing out the ongoing insanity, duplication, waste, lack of ticket interoperability etc. of bankrolling 27 different agencies for 9 counties in a metro area of onlyYes we need some roads, but cars driving in the heart of downtown as normal transit? reply fooker 15 hours agorootparentTokyo barely makes it into the top hundred by population density. Also yes, for most large cities you can find news articles about people dying in fires or because of an ambulance getting delayed. reply wat10000 14 hours agorootparentFunny how you don’t see articles about people dying in fires because they live on a suburb that’s 10% as dense as it should be and so the fire station is 3x farther away than it should be. No real surprise, though. People love stories where you can point to a few people and say, they’re the ones who did this. It’s much less fun when it’s systemic and no one person or group can be blamed. reply pclmulqdq 14 hours agorootparentPolice response times in my \"10% as dense as it should be\" suburb (a place that would be the poster child for everything urbanists hate) are 3x faster than they are in NYC. That is largely due to having high mobility through the town. In pure distance terms, I live about 20x further from the police station, though. The average door-to-door time between my house and the nearest level 1 trauma center is 10 minutes shorter than it would be when I lived in Manhattan. It turns out that having the paramedics wait for an elevator really cuts into their response time. A level 3 trauma center is 25 minutes closer (there are no level 3 trauma centers in Manhattan). https://patch.com/new-york/new-york-city/nypds-slow-response... Cities are built for average-case living, and that is fine until you need it not to be. reply fooker 14 hours agorootparentprevAs a rule of thumb, you can't design anything trying to account for black swan events. Optimizing for the regular, daily use case is hard enough. It would help to think of this as a smart but random person reading about a security issue like spectre and offering you software design advice. Common sense arguments are only useful to an extent, the devil is in the details. reply wat10000 14 hours agorootparentI’m not sure how to apply this here. What does optimizing for regular daily use and not black swan events look like when it comes to fire and ambulance services? It seems to me that black swans are a major purpose for them. That’s why the local fire station tends to have a lot of time where the firefighters are sitting around, and why simple calls often get 3x more response than they need. The services are greatly overprovisioned for daily needs because they also exist for the times when an entire apartment building burns down, or some maniac bombs the subway. reply dymk 13 hours agorootparentprevWho cares about news articles? If you're worried that dense cities are dangerous, then back it up with some statistics about deaths per capita due to EMS delays. reply wat10000 14 hours agorootparentprevA cool thing about hard surfaced pedestrian areas, you can build them strong enough for vehicles without allowing the whole world to drive on them. reply apothegm 3 hours agorootparentprevYou keep roads but aside from a few arteries, allow only bicycles, pedestrians, emergency vehicles, and things like dropping off/picking up passengers with disabilities. If the roads are closed to non-emergency traffic, fire trucks and ambulances get where they need to be faster than if the roads are clogged with personal vehicles. reply benhurmarcel 9 hours agorootparentprevhttps://www.youtube.com/watch?v=j2dHFC31VtQ reply tim333 7 hours agoparentprev>That is the most subsidized land on the planet but people don't think of it that way. That's because it generally isn't in terms of paying cash subsidies. What happens is that when the city is laid out areas are blocked out for access. Doing that doesn't really cost you anything. In places that get pedestrianised the road space is still there, just used for people rather than cars. reply modeless 15 hours agoparentprevRoads are useful, but what I really think we should get rid of is parking lots. When cars can drive themselves we should build over all the lots and knock down the garages. The cars can spend the day on the road and the night parked outside the city. There should be zero parked inside the city. reply Qwertious 15 hours agorootparentAbolish free parking, and raise prices on the parking meter until the parking spots are only ~80% occupied (if they're less than 80% occupied, lower the price). If there's not enough parking, let the market fix that problem - if private parking lots are profitable use of land, then people will build them. But people will never be satisfied with private parking lots if they could have used free public parking instead (if they'd just looked harder for a parking spot). In other words, giving out free shit discourages people from buying that shit. Which really shouldn't surprise anyone. reply steele 14 hours agorootparentAny other innovative ways to disproportionately tax the wage class? reply wat10000 14 hours agorootparentCharging money for services is “innovative”? I know the hacker set likes to reinvent other industries and call it new, but this is rather extreme. reply steele 14 hours agorootparentJust say you're a landlord reply wat10000 14 hours agorootparentGive me free stuff. If you say no you’re a landlord. reply steele 14 hours agorootparentFree? Tax-dodging sovereign citizen panhandler too, I see. reply digdugdirk 14 hours agorootparentprevSure - create urban and suburban environments where a car is a necessity for daily function. Financing, insurance, maintenance, repairs, fuel... Cars aren't cheap. Reducing the overall space devoted to them and utilizing that space for useful purposes would be a net benefit. Providing public transport services with that increased revenue would leave the vast majority better off financially, not to mention the quality of life improvements. reply steele 14 hours agorootparentI don't disagree with the objective you describe, but I disagree with the Jonathan Swift-esque idea of abolishing free parking and increasing meters. That would increase the burden on the already-burdened and only nominally affect cost of convenience to the wealthy. I suppose everyone can tip their wait staff by letting them use their residential parking spot-- because without that pre-existing transportation infrastructure, employer provided transport/parking, affordable cost of living, and a living wage for all, I'm not sure how people are getting to work in dense urban areas. Although I love the idea of abandoned luxury vehicles lining the streets with boots on their wheels-- like a broken window theory for late stage capitalism. reply occz 12 hours agorootparentprevThis might seem like a good idea at first, but it would essentially result in complete gridlock as the roads fill up with circulating self-driving cars. No, there's definitely a better solution for this - using self-driving trains to move people. reply jerlam 15 hours agorootparentprevIf the cars can't park, then they're clogging up the roads and preventing them from being used as intended for transportation. I am fine with parking lots as long as they're not publicly funded and are taxed just as every other parcel in the city. And on-street parking should be prohibited. reply gpm 14 hours agorootparentIn fact I'd say that self driving cars will mean that it's important that parking is not more expensive than simply driving in circles. You can bet that companies will drive self driving cars in circles to store them while not in use if it's cheaper than parking, and that takes up both more space, and higher value space. reply jakelazaroff 13 hours agorootparentPerhaps there should be some sort of vacancy tax where the operators of driverless cars are charged for every mile they drive without a human passenger. reply omnimus 10 hours agorootparentYouve just invented a new job which is dummy human who is cheaper than parking lot who drives all day around city in otherwise empty cars. reply Breza 14 hours agorootparentprevI'm not sure if people will want to deal with long wait times for their car to drive to them. Imagine watching the end credits roll at a movie theater only to be gripped by the sense of dread that you forgot to call your car during the climactic fight scene and now you'll be waiting half an hour for it to drive from the suburbs. Don't get me wrong, I'm a huge fan of reducing car dependency, I'm just not optimistic that self driving cars will help. reply geogod42 15 hours agorootparentprevroads are dirty tho, n really expensive reply dexwiz 15 hours agoparentprevHow do you propose we handle logistics or emergency vehicles? I’m all for more walkable cities but rip them all up and replace them with what? Rails which are more expensive and less flexible? Pneumatic tube? Even if you switched to single person cargo bikes you would still want dedicated areas for vehicles versus pedestrians. reply spaceguillotine 15 hours agorootparentThis problem has been solved by equipment designed for narrower roads. It is not a hard problem to solve and cities like this have been around a very long time. There are literally solutions to every issue you bring up that are already on the market. reply browningstreet 15 hours agorootparentprevSee pedestrian first roads in the NL. There are bigger and more complicated cities that have done these things and became the better for it. reply Ar-Curunir 15 hours agorootparentprevOther countries just use more space-efficient vehicles. reply pclmulqdq 15 hours agoparentprevCities have had roads long before there were cars. So many people like to pretend that before \"car culture\" there were no roads in cities or that before cars there were no big roads. There were huge roads in cities in the 1800s to accommodate carriages, streetcars, and all the extra people on the road because a 5 minute trip by car takes 20 minutes on foot. Cities in 1000 AD had roads, and a lot of them were pretty damn wide. Ancient Rome was famous for building roads. Roads are not a waste of space. Roads are infrastructure. reply Ar-Curunir 15 hours agorootparentCars need a disproportionate amount of space for the number of people that they serve compared to every other means of transport. Bicycles, e-scooters, buses, etc serve many more people per square foot compared to mostly empty cars. reply pclmulqdq 14 hours agorootparentYou can certainly pack more bicycles/e-scooters per square mile, but they also move a lot slower. Not to mention cargo capacity of trucks vs. things like e-scooters. Buses and trains also don't go everywhere. If you banned cars and expanded bus routes to compensate, you would get much less utilization of space for your buses. In other words, buses are dense because other modes of transport allow you to only put a bus route on very common paths. The point still stands, though. The roads that they are complaining about were largely planned and built before cars. Downtown SF had roads that were very similar in size in 1900 as they are in 2025. The roads didn't magically get wider when cars came in. If they weren't a waste of space with no cars, they aren't magically a waste of space now. Many other cities that were built up much later have huge parking lots in their city centers, which are a massive waste of space. Roads, on the other hand, are not. reply blackeyeblitzar 13 hours agoparentprevNah roads are great and cars are great. They let people get around in ways that are much faster than public transit, with your friends and cargo, protected from the weather, without the safety issues, directly to your destination. If you overbuild and create density of inhuman levels, and don’t build adequate road infrastructure, you will have problems. But otherwise, it’s fine and it works very well in cities of low-mid density. reply omnimus 10 hours agorootparentNah. reply ekianjo 15 hours agoparentprevDowntown only exists in the first place because roads go there. You know the old saying? All roads lead to Rome. Cities concentrate people and need a lot of resources to be sustainable, and roads are what bring these resources. reply wat10000 14 hours agorootparentGiant American roads mostly don’t bring those resources. They bring vehicles passing through, they bring vehicles filled to 20% or less of their capacity, and they bring street parking, one of the most inefficient uses of land imaginable in a downtown area. Look at what’s needed to bring those resources and people, only those, and you need far less than what American cities have. reply dymk 15 hours agorootparentprevYou know what those roads originally had on them? Small carriages (see etymology) and foot traffic, not modern cars. It blows my mind that people think cars are necessary for modern cities when the best ones to live have very few or no cars reply Ar-Curunir 15 hours agorootparentprevThat’s just pure nonsense. Have you been to, like, any major non-American city? People just take public transit, or walk, or, live in downtown reply shiroiushi 14 hours agorootparentThis entire comment section is simultaneously hilarious and sad to read, because it's obviously a bunch of myopic Americans who have never ventured outside of America and have no clue how other cities in the world work. Honestly I try to avoid commenting in forums like this because it's so fruitless: it's just like trying to have a rational discussion about vaccines (or anything really) with a bunch of Trump followers. reply wat10000 14 hours agorootparentWhat’s funny is that I’m sure most of them know other kinds of cities exist. And they know that people somehow manage to survive and thrive there, even if they don’t know how. But this all gets ignored once you start talking about trying to emulate some of that. For too many Americans, there’s no difference between “that can’t work,” “that can’t work here,” and “we don’t do that.” reply signatoremo 13 hours agorootparentprevDid you know that car ownership in the Netherlands has continued to rise? This is a blog post of a cycling advocate, from 2019 but still relevant - [0] Quote: In 1992, 42% of Dutch households were car-free. By 2016 this had dropped to about a quarter. Car ownership has continued to increase since then. Higher car ownership leads to higher car usage. Almost anyone who can easily afford a car has one and there aren't many people at all who choose to go without if they can afford one: Amongst people of average income, just 12% of households don't have a car and that drops further to just 6% for high income households. In other words, people choose to own a car if they can afford it, even if they cycle frequently at the same time. [0] -https://www.aviewfromthecyclepath.com/2019/08/the-car-free-m... reply SoftTalker 14 hours agorootparentprevAll large European cities have a lot of traffic, public transit notwithstanding. And in the small towns, most people have a car because public transit is not economical in sparsely populated areas. reply jonathan_landy 15 hours agoparentprevI like to drive. Edit: see also this pro-car, pro-toll note by Bryan Caplan. https://www.betonit.ai/p/cars-could-be-even-more-convenient reply starspangled 14 hours agorootparentEverybody likes to drive. It's far more private, personal, and free than even the best public transport, which is why a country like Japan with some of the best public transport on earth has a car ownership rate of 1 per household, and even in Tokyo it's 33% of households, with a large taxi industry. It astounds me that so many on the left seem to be converging on the opinion that it should be a goal to reduce, eliminate, tax private transportation for the common person. Public transport is great and should be improved or encouraged, and road area usage should be as efficient as possible. But private transportation should be made cheaper and more convenient and accessible to as many people as possible. That is a great way to improve quality of life and expand opportunities for people. reply undersuit 14 hours agorootparentI hate driving but every time I get on my bicycle I remember how fun it is... until a car starts driving behind me impatient to get somewhere a few seconds faster. I can bike to many places in my town faster than the drivers can drive if I put some effort into pedaling. reply starspangled 14 hours agorootparentI don't mean everybody likes the act of driving, I mean everybody likes what driving [a private vehicle] can do for them. I didn't mean even that in the absolute literal sense either, but anecdotes from people who don't have a car or get driven by friends and never take taxis or uber anywhere would be interesting and will probably help us to understand why virtually everybody likes driving. reply undersuit 13 hours agorootparentI don't think anyone literally likes driving. Some people like racing, some people like drifting. But who the heck likes getting in their car, waiting at stop signs and lights, staring down a road for hours, and wondering whether the oncoming vehicle veering left is going to turn on their turn signal or straighten their path. reply Daishiman 15 hours agorootparentprevThis is a non-informational take which is just ahistorical, as evidenced by the fact that just 30 years a lot of European cities were very much car-centric and were much more awful by pretty much every metric than they are today. reply starspangled 14 hours agorootparentAbout one in every two households in Amsterdam own a car. I would bet many that don't use taxi services themselves now and again, and almost everybody would indirectly rely on roads used for deliveries, workmen, emergency services. And that's about the best case for a European city. It's comparable to New York City. Paris, London, Prague -- higher. The reality is that these romantic notions people have of cities not relying on cars or roads is an unrealistic fantasy. Yes it's certainly nice if you have good public transport that many people can use for most of their transport. The reality is though that even in the very best cases of those like Amsterdam and Tokyo, personal car ownership rates are still enormous, and the cities would cease to function without small private vehicles for commercial operations, let alone removing the roads for garbage collections, busses, emergency vehicles, etc. reply MattPalmer1086 10 hours agorootparentAnd yet, if you walk around Amsterdam or Rotterdam you see a lot of bicycles and trams and pedestrians, and very few cars. Cars certainly exist, but they are clearly not used by default for everything. Contrast with my recent visit to New Jersey. The hotel was surrounded on all sides by parking lots and multi lane roads). There was no sidewalk. reply starspangled 9 hours agorootparentI haven't walked around those cities, I've walked around certain areas of London or Tokyo as a tourist mostly in central areas that are well serviced by public transport and are very dense, without any real understanding of what it actually takes to live, work, raise children, or anything else in those places. I certainly saw a lot of roads and cars, particularly when looking out the window of trains and busses into actual places people live. > Cars certainly exist, but they are clearly not used by default for everything. Sure, I've noticed a bunch of American cities I've been to are a more difficult to walk or get public transport than any big ones in Europe or Asia I've been to. They're all automobile-centric though. You'll never get rid of cars, taxis, trucks, busses, or roads. Not in any of them. Better walking, riding, and public transport is great, it's just never going to do away with the car, nor is doing away with cars and roads ever going to solve any problems that cities have. There should be more honesty and pragmatism around this. reply fooker 15 hours agoparentprevNo amount of reason will negate the fact that people like the convenience of cars. There is a reason cars, and paradoxically larger cars are being bought in increasing numbers. You can of course force people to give up conveniences they like, you just have to contend with the fact that the modern world makes it easy for people to move or vote with their wallet. reply etrautmann 15 hours agoprevIt's incredibly noticeable while biking. My commute through midtown is so much more pleasant now - it's insane. reply jefftk 16 hours agoprevWhen I see things like: > Bus speeds also increased after the tolls were turned on. The Manhattan-bound B39 bus, which crosses the Williamsburg Bridge, ran 28% faster compared to a similar January week last year. Other buses like the SIM24 and and the M50 saw increases in speeds, as well. I wonder how much cherry picking there is. Did they give the B39 because it's the most improved? Or for some other reason (especially busy?) (Generally strongly in favor of congestion pricing) reply nine_k 16 hours agoparentI think B39 is a good example of an improvement most affected by the congestion pricing. It's a very short route, with very few stops, and the principal part of the route being the Williamsburg bridge. The rest of both Brooklyn and Manhattan traffic affects it rather little. I think that \"cherry-picking\" is when you find outliers and show them off pretending they are typical examples. What I would call this is maybe a \"poster child\": a specially chosen example where the result is most dramatic and clearly seen. reply jon_richards 15 hours agorootparentI’d say a cherry picked example is backed by random chance (possibly counter to the trend) while a poster child example has an explanation (not necessarily correct) for being the most sensitive to the variable being changed. reply btheunissen 16 hours agoparentprevI wouldn’t be surprised if this was across the board for buses into lower Manhattan/around bridges into Manhattan. When living in cities I usually use both buses and trains but when living in NYC I tried to avoid buses when possible as you are at the behest of an insane amount of traffic usually; meaning you can’t reliably be places on time if you are using the bus. reply jon_richards 15 hours agorootparentI like the theory of traffic that basically says traffic will always make the best mode of transportation as bad as the second best. The problem with buses is that car traffic can never be bad enough to make cars worse than buses. Buses are doomed to always be worse than cars unless they have dedicated lanes or parking is unbearable. So cars slow down to equal the metro system, bikes, ferries, etc. A dedicated bus lane can speed up cars more than another car lane because it pulls traffic off the road until driving convenience equals bus convenience. reply post-it 16 hours agoparentprevI parse it as implying that B39 had the highest percentage improvement. reply epistasis 15 hours agoparentprevFor a lot of systems, what you want to \"cherry pick\" and focus on are those 90th-percentile outliers, because they cause the most pain. reply BenFranklin100 16 hours agoparentprevWe will get better stats as the data rolls in over the next several months, but is very unlikely this is cherry picked or unrepresentative of the broad benefits of less congestion. In fact, I anticipate the city to expand dedicated bus lanes and bus frequency to take advantage of the reduced car traffic. Bike lanes too. Mass transit should steadily improve over the next year as enhancements made possible by less cars are deployed. reply Twirrim 15 hours agoparentprevNot sure if NYC would do the same stunt, but London saw an amazing improvement in traffic flow after congestion charge was introduced. Turned out for several months prior to it they'd been slowly shifting the timing of lights to make things less optimal, and then reverted the day congestion charge went live. reply addicted 15 hours agorootparentThis wouldn’t work in NYC even if they did try because the congestion pricing start date has been moved around a lot, including days before it was supposed to start the last time. But even more relevant is the fact that people have seen Manhattan gridlock for decades. If they were planning a move like that they would have had to start it in the 1980s at least. reply teractiveodular 15 hours agorootparentprevWould you have a source for this? reply jeffbee 15 hours agorootparentVarious buttholes, presumably. Anyone who has ever tried to adjust the phase of a traffic signal can tell you that sneaking little changes, all over a large city, is fantasy. reply jonathan_landy 15 hours agorootparentYou’ve done this sort of work? There are a few in Berkeley I would like to try my hand at… reply occz 12 hours agorootparentprevWhat a weird thing to lie about. reply apothegm 16 hours agoprevHopefully this means improved response times for emergency vehicles, which have been pretty bad and getting worse due to traffic. I imagine we’ll start to see data in that in a couple months. reply Breza 14 hours agoparentI hadn't thought about this part. I work with healthcare data for a living. I'll have to keep an eye out for changes once the 2025 records come across my desk. reply meandave 14 hours agoprevI live at a _very_ loud and busy intersection in downtown manhattan, it's usually gridlocked every day from 4pm - 7pm at least. That hasn't happened once since congestion pricing kicked in (I'm enjoying the relative quiet, but I do sort of miss the chaos). The first two days, everything was covered in snow down here. I wonder how much this will hold up into summertime. As an unrelated aside a new bmw sedan driving the wrong way on mulberry street intentionally ran into me at a crosswalk today. So don't let your guard down lol reply Over2Chars 16 hours agoprevBrilliant for many reasons. I hope we see a lot more of this. reply ciabattabread 15 hours agoprevIt was also really cold in NYC last week. reply etrautmann 15 hours agoparentwouldn't that increase driving relative to other forms of transportation? reply ciabattabread 15 hours agorootparentCold encourages suburbanites to stay in their warm home instead of going on a night out. reply etrautmann 14 hours agorootparentI would imagine that’s a tiny portion of the total traffic in midtown? reply daft_pink 13 hours agoprevI’m curious what the real impact of this is as it only shows what the reduction in people entering the district is and not a reduction in traffic rates on any given street. I’m surprised that they are allowed to have these rules as it appears to give preferential treatment to non-residents who don’t live in a district vs residents who live in a district, which runs counter to general principles that roads in America that are funded by all of our tax dollars should treat drivers equally and not offer preferential treatment to residents. reply iambateman 16 hours agoprevSome numbers don’t make sense here… They’re saying a 7% reduction is 43k cars, which infers 550k daily trips into the city. But they think they can make $500M/year. At $9 per trip, that’s only 150k tolls daily. (500M / 365 / $9). In any case, I’m glad it seems to be working. Congestion pricing has the potential to do a lot of good in this country. reply nine_k 16 hours agoparentThere is a number of driver categories that pay somehow less to enter. Also I suppose they predict that the number of daily trips will keep going down, and so will the revenue with it. reply addicted 15 hours agoparentprev$9 is for personal vehicles. Cabs get charged per trip with no limit. Delivery trucks get charged a higher amount and I don’t believe (I’m not sure on this) they have a daily cap, so they can also be charged multiple times. reply Over2Chars 16 hours agoparentprevyou mean implies not infers. You infer, they imply. reply hackernewds 15 hours agoparentprevNot driving is gonna make the drivers happier? A lot of good, depends on who you are really reply pclmulqdq 15 hours agoparentprev$500M/year was the magical thinking that applies any time the NY government wants to create a tax. The revenue projected is always huge so they can spend big somewhere else while pretending to be revenue neutral. The soda tax had the same ridiculous overestimation. reply wk_end 15 hours agorootparentIf I’m reading OP’s math correctly, you’ve got it backwards. They’re saying NYC should be in practice making significantly more than $500M/yr. reply pclmulqdq 14 hours agorootparentOP's math doesn't account for the fact that a small fraction of trips into the city are personal vehicles, and many more are cabs/rideshare cars (which pay differently) and trucks making deliveries (which may be exempt). In any case, there is also going to be widespread toll fraud here just like with every other toll in NYC. reply dottjt 16 hours agoprevI think an issue with this kind of policy (not necessarily in Manhattan) but in other cities is that often there is no alternative other than to drive to the city. For example, my partner needs radiation for her cancer and the hospital is located in the city. There is no other option than to drive. I feel like this type of policy negatively affects people in this situation, with no other alternative. reply lostdog 14 hours agoparentA $9 congestion charge is probably a huge help to you. For just $9 per visit, you get much lower traffic and easier parking. Your very high priority trip is easier because lots of lower priority trips either didn't happen, or used transit instead. reply dottjt 14 hours agorootparentNot if you're poor. $9 daily would be quite a lot for poor people, especially since radiation is daily. Furthermore you often have no choice but to use paid hospital parking due to mobility issues, as opposed to cheaper parking near the hospital. reply OsrsNeedsf2P 15 hours agoparentprevI'm sorry to hear your partner needs cancer treatment. But also, you can still use the roads. reply dottjt 15 hours agorootparentYeah, but why should one have to pay more to use roads they have no options but to use? reply drawkward 4 hours agorootparentYou're right; gasoline should be untaxed. Nah fuckit, gasoline should be 100% government-subsidized. reply redserk 14 hours agoparentprevI think this policy is only feasible in cities with decent public transportation. I’d struggle to list any more than 1-2 other American cities where this could be done though. A lot of cities that do have public transportation seem to have extremely frustrating (i.e. multiple transfers) gaps if you aren’t using the system to-and-from work. reply dottjt 14 hours agorootparentAgain, public transport is usually not feasible if you have a severe medical condition. reply redserk 14 hours agorootparentAgreed. I think this is one area I’d hope to see exceptions for on any implementation. I can’t attest to how fair of a process this is, but MTA seems to be giving medical exceptions some lip service: https://new.mta.info/tolls/congestion-relief-zone/discounts-... reply blackeyeblitzar 13 hours agorootparentprevIt’s also only feasible if actions like this congestion charge are taken to tilt the scales. Most people would not use public transit if they could avoid it. When there is enough road infrastructure to match the density, private transit is preferred because you can drive directly to your destination, not have public safety issues like on the subway, haul cargo, and do it all quickly. The only way to make public transit attractive is to artificially and maliciously mismanage things to make driving cars slow and expensive. Which frankly is hostile towards people. reply ETH_start 15 hours agoprevFewer drivers and less traffic can actually lead to more people being on the roads, because high-capacity vehicles like busses — which can efficiently pay the congestion pricing charges — are more usable when there is less traffic and faster commute times, so more people are likely to utilize them. reply xyst 16 hours agoprevIn addition to the obvious improvements to pedestrian safety with less vehicles on the road. Air quality in these areas is going to improve vastly. This needs to be implemented in every major metropolitan area. reply Over2Chars 16 hours agoparentSan Francisco \"thought about it\" as far back as 2019 and couldn't get their act together to pull it off: https://www.sfcta.org/downtown I'm guessing that Uber and other car based services all threatened to stop funding their re-election campaigns if they did it. reply bpye 13 hours agorootparentVancouver, BC is another city that considered it - but the incumbent mayor lost the last election, partly due to the issue. reply Over2Chars 13 hours agorootparentThat's quite unfortunate. I'm sure the voters can contemplate their victory when they're sitting in a traffic jam. reply whatever1 16 hours agoprevThe poorest 43k to be more accurate reply affinepplan 15 hours agoparentthe people who most strongly value $9 over a drive into lower Manhattan, to be more accurate reply drawkward 16 hours agoparentprev[Citation pending] reply whatever1 15 hours agorootparentFor example: https://www.irp.wisc.edu/publications/dps/pdfs/dp137810.pdf reply drawkward 4 hours agorootparentApples and footballs; in NYC, I suspect the poor don't drive in the first place. reply BenFranklin100 16 hours agoparentprevThis comment is a good example of the type of narrow minded progressive thinking that has held back good public policy like congestion pricing and carbon taxes. Both of these programs are criticized as being regressive. The criticism neglects to take into consideration the society wide benefits like more efficient bus travel or cleaner air that preferentially help the less well off. reply dottjt 16 hours agorootparentI agree with your rebuttal in response to that other person's comment, but ultimately I do think those programs are regressive for the poor, at this very point in time. I guess the question becomes, should those poorest suffer for the betterment of all future generations? I would personally say no. reply nine_k 15 hours agorootparentGive the poorest a discount for parking outside the congestion pricing area, and a discount for mass transit (if they haven't already applied for it). The point of congestion pricing is to make the correct behavior also a better financial choice. Discounted transit ticket achieve the same goal. reply mensetmanusman 15 hours agorootparentprevThe poor will benefit from less lung cancer inducing smoke. reply BenFranklin100 15 hours agorootparentprevThank you for letting me clarify my point with two examples of how these seemingly regressive policies ultimately help the poorer among us: 1. carbon taxes will improve poor air quality which currently impacts the poor more than the wealthy who can afford to live in cleaner areas. The poor will enjoy significant health benefits that far outweighs the small regressive tax they pay know. 2. A Congestion pricing stands to dramatically improve mass transit options like buses, which the working class rely on far more than the wealthy to get to work on time and will even expand the job options they have available to them. reply whatever1 16 hours agorootparentprevWhy not lottery my dude (based on dob, license plate, whatever) ? Didn’t I equally pay for the infrastructure? I would argue that I paid even more than the millionaires, because I cannnot cheat on my taxes. reply bdzr 15 hours agorootparentOh god. Didn't they try to do something like this in Mexico City and it resulted in no change? Clever policy is always rife with unintended consequences; prices are good. reply whatever1 15 hours agorootparentThis is how China and most Europe does it for their big cities. Identical effectiveness minus the regressivity for the poor. If the city wants to buy more buses they can always send higher tax bills to their residents reply lokar 15 hours agorootparentNot true. The rich just get extra car with different plates. reply BenFranklin100 14 hours agorootparentprevYou paid far less. The top half of American pay almost 98% of federal taxes. The top 10% pay nearly three quarters. The American tax system is very progressive. https://www.cbsnews.com/news/tax-irs-income-taxes-who-pays-t... reply whatever1 12 hours agorootparentYou have it wrong. You are grouping in that top 10% the millionaires/billionaires who pay nothing with the 6-figure W2 workhorses who cannot hide anything. reply BenFranklin100 4 hours agorootparentStop equivocating. You said that ‘you’ (as in the lower income half) paid more. This is demonstrably false. The top half of Americans pay 97.7% of taxes. It may be you paid a higher percentage of your income despite the progressive nature of the American tax code which has a higher rate the more you make, via some tax breaks some wealthy people take advantage etc... It can also be that you paid a smaller percentage through an EITC. I don’t know without know your situation. It is definitely false that Americans making between $200-400K paid a smaller rate than you did. Your broad statement the poor are paying the bulk of support for public infrastructure is clearly wrong. Revise your priors. reply whatever1 1 hour agorootparentIt is definitely true the millionaires paid less than me. 0I always thought congestion pricing was always mis-priced, and it should be tied to income/wealth. NYC has a low-income discount system: https://new.mta.info/tolls/congestion-relief-zone/discounts-... But also, the money is going to fund public transit, which disproportionately benefits poorer people. reply breadwinner 16 hours agorootparentprevShould everything be tied to income/wealth? Taxes and college tuition are already tied to income/wealth. Why not food, housing, travel, clothes, healthcare, even drinking water? At that point wealth will stop to have any meaning. reply redandblack 14 hours agorootparentYes - if we financialize all public services, then it makes sense to use income/wealth to subsidize (re-distribute to be more precise) the poor. I remember reading a few weeks back that UK is getting the railroads back to public ownership - not sure if that is true, but would like to hear from UK readers on the impact of financialization (aka privatizing) of public utilities. I am not a fan of public ownership - but a supported of public subsidies for utilities - transport / electricity / heat / water and in this case roads reply mensetmanusman 15 hours agorootparentprevYes, e ink displays in the super market following you around with prices dependent on how many bitcoins in your cold wallet. reply gscott 15 hours agorootparentprevIt will help Amazon and other delivery companies. Less competition from people driving their own cars to get things. California is working to put on a per-mile tax onto drivers because roads wear out faster then gas taxes, sales tax on autos, sales tax on auto repairs/parts, and registration taxes can be collected... reply adgjlsfhk1 14 hours agorootparentprevPoor people in NYC don't have cars. reply manquer 15 hours agoparentprevOnly the rich get to drive too. Cars loans, insurance , fuel and maintenance all costs money. There are lot of people who cannot afford to pay for any of it, we subsidize them too[1] to buy cars or invest in public transit instead ? In a capitalist society , benefits are enjoyed by those with wealth, this what we signed up . I am not saying it is a good or bad we have this, just that congestion pricing is hardly the issue to discuss changing economic systems [1] absence of congestion pricing is a subsidy, costs of transport infrastructure is only partly paid by users of the infra at present . reply BenFranklin100 16 hours agoparentprevThe poor and working class never drove in Manhattan. It’s too expensive to maintain a car and pay for parking. With congestion pricing the poor (not to mention all of us) now get to enjoy more efficient and reliable bus travel. This is a net win for the working class. reply HDThoreaun 15 hours agoparentprevDriving in lower Manhattan should be a rich person only thing. The externalities are massive and they can pay it. reply breadwinner 16 hours agoparentprevonly the rich get to live in nice houses; drive Lamborghinis, fly private... welcome to capitalism! To paraphrase Churchill, capitalism is the worst economic system, except for all the others. reply shipscode 16 hours agoprevComparing to previous Januarys seems dishonest given the vast number of layoffs that have occurred over the past year. Doesn't appear as though they're controlling for this number at all.. reply necubi 15 hours agoparentWhat vast number of layoffs? The national layoff rate is currently 1.1%, which is lower than the the pre-pandemic average [0]. The NYS layoff rate is 0.5% which is one of the lowest in the country. [0] https://fred.stlouisfed.org/series/JTSLDR [1] https://www.bls.gov/charts/state-job-openings-and-labor-turn... reply jeffbee 15 hours agorootparent\"Private sector jobs in New York City rose by 79,800 over-the-year to 4,236,900 in November 2024.\" Amazing what people believe. reply bberenberg 15 hours agoparentprevNumber of employed people rose in NYC over the last year[0] if I’m reading the stats correctly. [0] - https://dol.ny.gov/system/files/documents/2024/12/nychist.xl... reply jeffbee 15 hours agorootparentYou are reading it correctly. There have never been more jobs in NY than there are right now. The unfortunately problem is that it appears all of the extra people are employed in making shit up and posting it on the Internet. \"Vice President in Charge of Charlie Brown's Hoes\" or similar roles. reply nwellinghoff 16 hours agoprevThis seems to be the goto method for most cities now. Got something that isn’t working anymore or the public needs more of it? Just start charging for it and make it a revenue source! reply cake_robot 15 hours agoparentInternalizing externalities is good, actually. reply xyst 16 hours agoparentprevWhat a joke. Urban areas have been gutted so suburbanites can travel by car, park their metal death box, and travel back to their shitty home for decades. Urban areas have also been subsidizing roads mostly used by suburban assholes. Then when those same roads need repair, guess who the burden falls on (it’s not the suburbanite living in shitville county) reply drawkward 16 hours agoparentprev[Citation Needed] reply gorgoiler 15 hours agoprev [–] As a thought experiment let’s take a technocratic moonshot: air traffic control but for 500k surface vehicles on 100k blocks. Pricing reduces congestion, but only indirectly, and only in aggregate over the area to which it applies. Where is your ambition, hackers?! NYC could take this whole idea to the next level — level of hell, I’m sure some would think — and require that every vehicle needs a real time permit to be in motion on a block-by-block basis. Permits are available only when the streets have capacity for another vehicle. When you park up, your permit gets released. When you want to get back on the road you join the back of the line for a new real-time permit to drive. Stop lights could hold back traffic from entering congested areas. If you want to enter an area and it is full up, you have to sit and wait for another car to leave that cell. The central system manages the queues fairly: if a car exits the West boundary then you can enter on the East boundary if you were next in line. It sounds like misery but honestly if the goal of any congestion policy is to ensure that traffic density never exceeds a given threshold, isn’t using globally coordinated block-level traffic control the ultimate way to achieve that goal? The whole thing also sounds like a dream — again, possibly a fever dream — to implement and fine tune. NetEng has some transferable skills in this domain which could come in handy. Slightly tongue-in-cheek, but also slightly hang on this is a great idea. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "After congestion pricing was implemented, there was a 7.5% reduction in drivers entering Manhattan below 60th Street, equating to 43,000 fewer drivers each weekday.",
      "The reduction in traffic has improved traffic flow and increased bus speeds, with some express buses experiencing higher ridership.",
      "The Metropolitan Transportation Authority (MTA) uses the toll revenue, estimated at $500 million annually, for transit improvements, despite some political opposition."
    ],
    "commentSummary": [
      "The implementation of congestion pricing in Manhattan has resulted in 43,000 fewer drivers, leading to increased bus speeds and potentially better emergency response times.",
      "The policy is designed to reduce traffic congestion and improve air quality, though it has sparked debate over its impact on lower-income individuals.",
      "Proponents argue that the benefits include more efficient public transit and cleaner air, while discussions continue on balancing these advantages with the needs of drivers."
    ],
    "points": 154,
    "commentCount": 199,
    "retryCount": 0,
    "time": 1736821606
  }
]
