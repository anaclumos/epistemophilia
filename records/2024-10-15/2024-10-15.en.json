[
  {
    "id": 41840769,
    "title": "Google commits to buying power generated by nuclear-energy startup Kairos Power",
    "originLink": "https://www.wsj.com/business/energy-oil/google-nuclear-power-artificial-intelligence-87966624",
    "originBody": "wsj.com#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}Please enable JS and disable any ad blockervar dd={'rt':'c','cid':'AHrlqAAAAAMA2srN9Z917WcAFKtGMQ==','hsh':'D428D51E28968797BC27FB9153435D','t':'bv','s':47192,'e':'8b8e36eb7b650683dfd98817b6b7dc9bc03f451cc61c48e3b7de2c6d8eedad89','host':'geo.captcha-delivery.com','cookie':'4xyKtA0Bp6y8pJO2C3bHQhovTu4RmD_EBm7hXM9fLc0xZF2wiAVY1parjj4_S8CM53wkliiHckIS90kFyRHT074iIJeosLA0E3V3yCRMo3JxL7OPcswbQp7AovHlJ8Se'}",
    "commentLink": "https://news.ycombinator.com/item?id=41840769",
    "commentBody": "Google commits to buying power generated by nuclear-energy startup Kairos Power (wsj.com)555 points by atomic128 23 hours agohidepastfavorite472 comments perihelions 23 hours agohttps://archive.is/fdSXf philipkglass 23 hours agoprevBased on the headline I thought that this was an enormous capital commitment for an enormous generating capacity, but the deal is with a company called Kairos that is developing small modular reactors with 75 megawatts of electrical output each [1]. 7 reactors of this type, collectively, would supply 525 megawatts (less than half of a typical new commercial power reactor like the AP1000, HPR1000, EPR, or APR1400). Kairos is in a pretty early stage. They started building a test reactor this summer, scheduled for completion by 2027: https://www.energy.gov/ne/articles/kairos-power-starts-const... EDIT: Statement from the official Google announcement linked by xnx below [2]: Today, we’re building on these efforts by signing the world’s first corporate agreement to purchase nuclear energy from multiple small modular reactors (SMRs) to be developed by Kairos Power. The initial phase of work is intended to bring Kairos Power’s first SMR online quickly and safely by 2030, followed by additional reactor deployments through 2035. Overall, this deal will enable up to 500 MW of new 24/7 carbon-free power to U.S. electricity grids and help more communities benefit from clean and affordable nuclear power. [1] https://kairospower.com/technology/ [2] https://news.ycombinator.com/item?id=41841108 reply ViewTrick1002 21 hours agoparentWould be extremely interesting to the the $/MWh for the deal to understand the viability. Otherwise similar to the NuScale deal which fell through last autumn. A PPA like agreement which then only kept rising until all potential utilities had quit the deal. All honor to Kairos if they can deliver, but history is against them. Let’s hope they succeed. > NuScale has a more credible contract with the Carbon Free Power Project (“CFPP”) for the Utah Associated Municipal Power Systems (“UAMPS”). CFPP participants have been supportive of the project despite contracted energy prices that never seem to stop rising, from $55/MWh in 2016, to $89/MWh at the start of this year. What many have missed is that NuScale has been given till around January 2024 to raise project commitments to 80% or 370 MWe, from the existing 26% or 120 MWe, or risk termination. Crucially, when the participants agreed to this timeline, they were assured refunds for project costs if it were terminated, which creates an incentive for them to drop out. We are three months to the deadline and subscriptions have not moved an inch. https://iceberg-research.com/2023/10/19/nuscale-power-smr-a-... reply credit_guy 21 hours agorootparent> All honor to Kairos if they can deliver, but history is against them. History is not really against them. Our current reactors (mainly pressurized water reactors) are the way they are because Admiral Rickover determined that PWRs are the best option for submarines. He was not wrong, but civilian power reactors are not the same as the reactors powering submarines. PWRs are expensive mainly because of the huge pressure inside the reactor core, about 150 times higher than the atmospheric pressure. For comparison, a pressure cooker has an internal pressure about 5 times higher than the atmospheric pressure, and such a cooker can explode with a pretty loud bang. The Kairos Hermes reactor design is based on a design that was tested in the '60s, the Molten-Salt Reactor Experiment [1]. While such a reactor can be used to burn thorium, Kairos decided to go with the far more conventional approach of burning U-235. The reactor operates at approximately regular atmospheric pressure. This should reduce considerably the construction costs. Of course, there are unknowns. While the world has built thousands of pressurized water reactors, it has built maybe 10 molten salt reactors. For example one quite unexpected effect in the MSRE was the enbrittlement of the reactor vessel caused by tellurium, which shows up as a fission product when U-235 burns. The Nuclear Regulatory Commission is a very conservative organization, and they don't have much experience with molten salt reactors because nobody has. It took them 6 years to give NuScale an approval for a pressurized water reactor, design that they knew in and out. My guess is that they will not give Kairos an approval without at least 15 years of testing. But Google's agreement with Kairos is quite crucial to keep this testing going. [1] https://en.wikipedia.org/wiki/Molten-Salt_Reactor_Experiment reply cyberax 19 hours agorootparent> The Kairos Hermes reactor design is based on a design that was tested in the '60s, the Molten-Salt Reactor Experiment MSRs are a costly distraction. They are not viable without literally hundreds of billions in research and development money. That's why all the MSRs startups are failing long before they even start the licensing process. > For example one quite unexpected effect in the MSRE was the enbrittlement of the reactor vessel caused by tellurium, which shows up as a fission product when U-235 burns. It was not unexpected. The _main_ issue with MSRs is that they have to contain fluoride salts that release elemental fluorine radicals as a result of radiolysis. So the reactor vessel walls will be eaten up by them, rather rapidly. Especially when reactors are scaled up to a level that makes them practical. And then you have all the fission byproducts that literally include almost all the Periodic Table. reply Dylan16807 16 hours agorootparent> They are not viable without literally hundreds of billions in research and development money. The US produces 40000 billion kWh every decade, so that doesn't really seem that bad to me. reply cyberax 15 hours agorootparentSure. But why? MSRs don't have any real features that are worth spending that much money. Modern PWRs are just as passively safe, if they lose cooling and melt down, the molten fuel will be safely contained by the core catcher. Uranium is also not scarce, and if we want to get into breeding reactors, existing fuel reprocessing is an established industry, on which we _already_ have spent several hundred billion dollars. reply roenxi 10 hours agorootparentThe thing about R&D spending is that it is speculative. Even if that question does have satisfying answers; it is unreasonable to expect people to prove that R&D will have a commercially successful outcomes with foresight. reply cyberax 2 hours agorootparentThen why not fund fusion reactors? Or maybe thorium reactors ON A ZEPPELIN! With microwave power transmission. After all, if the objective to spend money on research, then what can be cooler than a nuclear reactor on a blimp? reply oblio 16 hours agorootparentprevWhen solar and wind and sodium ion batteries are basically there and probably don't need as much investment and R&D (or it's happening anyway from 1000 existing funding sources), it's probably bad. Or at least unlikely to happen. reply cyberax 15 hours agorootparentSodium batteries theoretically should be cheaper than li-ion, but they are not yet there in practice. And they still won't solve problems with polar vortexes in the US or a month-long Dunkelflaute in Germany. reply conradev 12 hours agorootparentCATL’s first generation sodium batteries, shipped in Chery cars are $77/kWh CATL’s lithium phosphate batteries are more expensive for now at >$100kWh. Sodium batteries are definitely cheaper in practice, but much lower energy density. The question is how far CATL can push energy density, and the second generation is claimed to be >200Wh/kh. https://www.autoevolution.com/news/catl-and-byd-to-start-pro... https://www.westchestercleanenergy.com/post/record-low-lithi... reply oblio 10 hours agorootparentEnergy density is a bit less relevant for grid storage, though. Not like you run out of space to put them. reply atwrk 9 hours agorootparentprevDunkelflaute simply doesn't exist. It's clearly visible in the charts of the last years that wind and solar almost ideally complement each other in Germany. Why else do you think Germany managed to stay above 50% renewables for every single month this year so far? In which season is the mythical Dunkelflaute supposed to appear? reply cyberax 2 hours agorootparent> Dunkelflaute simply doesn't exist. Here's one: https://energy-charts.info/charts/power/chart.htm?l=de&c=DE&... - look at the dates between 2019-01-16 to 2019-01-25. > It's clearly visible in the charts of the last years I have just provided you an example. Want more? Here's another: https://energy-charts.info/charts/power/chart.htm?l=de&c=DE&... - the period between 2023-02-04 and 2024-02-08, then followed by 2023-02-12 to 2023-02-15. But hey, it's all fake news. When the next Dunkelflaute happens, the citizens are supposed to just sit in their cold homes and think how great renewable generation is during the other times. reply ViewTrick1002 1 hour agorootparentAnd here's the correlation coefficient between countries: https://www.researchgate.net/figure/Correlation-coefficients... Like today we will need peaking capacity in the future, likely either based on hydrogen, synfuels or biofuels. What we don't need is nuclear power plants which sit idle at all times unless there is a winter dunkeflaute across half of Europe. reply cyberax 1 hour agorootparent> https://www.researchgate.net/figure/Correlation-coefficients... The problem is, this is average. You _have_ to plan the grid for the worst case scenario. For Germany, the worst case is 1 month of straight Dunkelflaute. It's estimated to happen once in 100 years. > Like today we will need peaking capacity in the future, likely either based on hydrogen, synfuels or biofuels. It's not peaking capacity. It has to be more than 100% of the current capacity (once Germany switches to electricity instead of gas for heating). And it'll be mostly sitting idle. > What we don't need is nuclear power plants which sit idle at all times unless there is a winter dunkeflaute across half of Europe. Build nukes, remove wind generators. Problem solved. reply Manuel_D 12 hours agorootparentprevIntermittency is a tough thing to handle. The US uses 12,000 GWh of electricity per day. The word used 60,000 GWh per day. Evening out daily fluctuations, let alone seasonal fluctuations, demands an enormous amount of storage. reply nosbo 8 hours agorootparentOr just overbuild your generation sources? reply Manuel_D 2 hours agorootparentOverbuilding doesn't make solar generate power at night. Days with minimal wind can see 10% average wind speeds or less. reply TheCraiggers 4 hours agorootparentprevHow is overbuilding going to help when the source of the power itself is intermittent? The sun regularly sets and the wind has this unfortunate habit of not blowing. Or, oddly enough, blowing too much. If we hope to go 100% renewable, storage is a key piece of that puzzle. reply bobthepanda 2 hours agorootparentNuclear also has this problem because it cannot be easily tuned down during low demand periods. Much of the pumped hydro that exists today was built to handle excess nuclear. reply cyberax 2 hours agorootparentNuclear can handle variable loads just fine, if reactors are designed with load-following in mind. France does that, for example. reply ViewTrick1002 1 hour agorootparentTechnically yes if you have an entire fleet to both spread the load following across and their manage their fuel cycles since they get less flexible the further into a fuel cycle a reactor is. Economically? Load following with nuclear power means an even worse business case than running at 100% 24/7. And nuclear power is already a laughably bad business case when running at 100%. reply Manuel_D 1 hour agorootparentYou don't need to change fuel cycles to reduce the output of a nuclear plant. You can accomplish it by more aggressively cooling the water in the steam turbines, effectively wasting heat (and thus generating less power). Nuclear is a bad business case compared to a fossil fuel grid. Solar and wind backed by fossil fuels are a better business choice, too. But when it comes to a fossil-fuel free grid, it's the only viable option if you don't have a big source of hydropower nearby. Batteries can't deliver the required storage capacity. Remember, the world uses 60,000 GWh of electricity per day. And as transportation and industrial uses of fossil fuels are electrified, that'll increase. reply bobthepanda 1 hour agorootparentprevNotably it also runs the reactors much harder, which has led to situations like France needing to shut all nuclear plants at once for maintenance. reply Manuel_D 2 hours agorootparentprevNuclear's electrical output can indeed be turned down, by over-cooling the steam in the turbines. The reactor is putting out the same power, but less electricity is generated since you're deliberately increasing waste heat. This is not efficient so it's rarely done. Furthermore, too much energy is a far easier problem to solve than too little energy. People can desalinate water, or do any other energy intensive things. reply ViewTrick1002 1 hour agorootparentTechnically yes if you have an entire fleet to both spread the load following across and their manage their fuel cycles since they get less flexible the further into a fuel cycle a reactor is. Economically? Load following with nuclear power means an even worse business case than running at 100% 24/7. And nuclear power is already a laughably bad business case when running at 100%. reply Manuel_D 1 hour agorootparentThe fuel is burned at the same rate using this method of modulating output. Thermal output from the reactor is the same. Electrical output is reduced because heat is deliberately wasted. reply philwelch 2 hours agorootparentprev“Oh no we have too much power, what are we going to do with it” is a much better problem to have than “the sun and wind are going down at the same time and we don’t have enough power, what are we going to do about it”. reply ViewTrick1002 1 hour agorootparentIt means the nuclear power plants shut down and then start losing money hand over fist, eventually closing. reply philwelch 1 hour agorootparentDon’t piss on my leg and tell me it’s raining. Most of the costs and all of the shutdowns in nuclear power are primarily motivated by anti-nuclear activism. What you’re describing is a policy choice, not an essential reality. reply snapplebobapple 3 hours agorootparentprevIt wont help much but it was the actul solution when the main source of electricity was fossil fuels because you could stockpile the fossil fuel reply pydry 8 hours agorootparentprev>Graham says that the CSIRO modelling showed that at very high levels of wind and solar, a maximum of half a day’s average demand was needed for storage. In some areas of the grid, only around three hours might be needed. https://reneweconomy.com.au/much-storage-needed-solar-wind-p... Sadly, there's far, far, far too much FUD floating around about storage (understandably, coz wind+solar threatens the nuclear+carbon lobbies), and not enough thorough and realistic studies like this one. I've heard people say \"oh you cant pay attention to this study because it's in Australia which must be discounted because [reasons], what about [ other country ]?\", and I'd welcome seeing an alternative study making appropriate assumptions, but none of these comments so far come attached to anything other than FUD. I've also seen far, far too many people build or cite a \"naive\" models that make inappropriate assumptions (e.g. that zero power is generated at night by wind). reply Manuel_D 49 minutes agorootparentThe further a region is to the poles, the worse intermittency becomes. Both for solar and for wind: https://www.nature.com/articles/s41467-021-26355-z > However, the share of solar generation increases less, or even decreases, in higher-latitude countries like Russia, Canada, and Germany (Fig. 2b). These trends continue as more storage is added, so that with 12 h of energy storage and no excess annual generation, 83–94% (average 90%) of electricity demand is met with mixes of 10–70% solar power (49% on average; Fig. 2c). Even with 12 hours of storage, Germany would be seeing blackouts weekly. To put this in perspective: > reliability standards in industrialized countries are typically very high (e.g., targetingGraham says that the CSIRO modelling showed that at very high levels of wind and solar, a maximum of half a day’s average demand was needed for storage. In some areas of the grid, only around three hours might be needed. What are these \"very high levels of wind and solar\"? How much of the remaining demand is satisfied by fossil fuels? The article doesn't say. reply cyberax 2 hours agorootparentprev> I've heard people say \"oh you cant pay attention to this study because it's in Australia So a study for Australia should be applicable everywhere else? Like in Germany or Norway? reply Manuel_D 30 minutes agorootparentNorway is already 100% renewable because it has lots of hydropower. Germany on the other hand, would suffer from an extremely unreliable grid even with 50% overproduction and 12 hours of storage. The further a region is from the equator, the more variability in the production of wind and solar. This study models how reliable grids would be with wind, solar, and storage: https://www.nature.com/articles/s41467-021-26355-z The issue is that electrical grids have very high reliability requirements (upwards of 99.95%). Plenty of models claiming that small amounts of storage required neglect to mention how frequently they will encounter insufficient generation. Remember, even fulfilling demand 99% of the time is a 20x increase in blackouts. Also, even just 12 hours of storage globally would be 30,000 GWh of storage. That's still about 50 times the amount of batteries produced annually. The reality is that hydropower is the only feasible form of grid storage. reply pydry 1 hour agorootparentprevMore applicable than FUD. I am, as I said, still waiting for models which demonstrate that it is wildly different... reply petre 12 hours agorootparentprevWe already have rain and hydro power plants. Batteries are similar: they store a finite amount of energy. So battery PV and wind have their place as peaker plants to replace gas fired power plants and hydro. Otherwise one could just smelt aluminium with the excess electricity like the Germans do. reply pfdietz 17 hours agorootparentprevThe Kairos design does not dissolve the fuel in the salt. reply cyberax 17 hours agorootparentOK, that's interesting. And it's far better than MSRs, but it still exposes fluoride salts to radiation. It also is a pebble bed reactor, so it'll have all the problems of pebble beds: cracking pellets, difficulty in fuel reprocessing, more nuclear waste, etc. But yes, this design might be actually feasible for small reactors. But I bet that it won't be cheaper and it'll be impossible to scale to levels approaching PWRs. reply conradev 12 hours agorootparentThe theory, at least, is that making SMRs in a factory allows for a steeper and more sustainable learning curve > Both Hermes and ETU 3.0 will be built using modular construction techniques, with reactor modules fabricated in Kairos Power's facility in Albuquerque, New Mexico, which will be shipped to Oak Ridge for assembly. https://www.world-nuclear-news.org/articles/work-begins-on-f... reply pfdietz 7 hours agorootparentprevFluoride salts by themselves are very radiation resistant, chemically more so than water. The biggest concern would be liberation of elemental fluorine, but if the salt is kept slightly reducing (which one can do in a sterile salt without dissolved uranium) the fluorine instantly reacts back to fluoride. The slightly reduced salt is also preferred to limit corrosion, allowing the vessel and pipes to be made of stainless steel (FLiBe with dissolved uranium needs special more expensive alloys because chromium would dissolve.) Activation is also low. The two concerns would be traces of tritium from the two-step activation of beryllium (formation of 6He by (n,alpha) reaction, decay of 6He to 6Li, then (n,t) on 6Li), and also formation of 10Be (half life, 1.4 million years, but the thermal neutron capture cross section of 9Be is only 8.5 mb). The chemical toxicity of beryllium would considerably exceed its radiotoxicity, I imagine. reply cyberax 2 hours agorootparent> The biggest concern would be liberation of elemental fluorine Yep. But I'm personally more worried about the pelletized fuel. Pellets are not a great form-factor, and they don't have cladding. Fluoride salts are also far more aggressive than water (mechanically and chemically), so this will limit the maximum specific power of the reactor. So I don't think that something like 1GW molten salt reactor is even possible. It might be OK if they want to continue using SMRs, though. > The slightly reduced salt is also preferred to limit corrosion Sidenote: that's actually not always a great idea. Steel is stainless because it's covered in a film of oxides, and without oxygen it might not be able to form. This is a problem for the Russian BREST-300 reactor that is cooled by molten lead, they had to do almost 10 years of research to perfect a system that controls the amount of dissolved oxygen in the molten lead. And it's still not clear if they succeeded until the full-scale reactor is built. In this case, though, I think that they can tune the reducers to react with fluorine preferentially, while still leaving enough oxygen. reply credit_guy 6 hours agorootparentprev> traces of tritium from the two-step activation of beryllium Also from the 6Li absorption of 1 neutron. The Lithium used is almost pure 7Li, at 99.995%. But there is still 50 ppm 6Li in it. reply pfdietz 6 hours agorootparentYes. The inescapable tritium production from Be sets the lower bound on how pure the 7Li has to be. reply rob74 9 hours agorootparentprev> The Nuclear Regulatory Commission is a very conservative organization I'm glad they are, actually! Personally, I'm not really convinced by the \"small modular reactor\" concept. Ok, so building a big nuclear power plant is expensive. But is it really cheaper to build 10 smaller nuclear power plants (which all need to conform to the same safety regulations, need maintenance, personnel etc.) instead? reply rkangel 9 hours agorootparentI firmly believe that iteration is the key to good engineering. SpaceX has got where they are (partly) due to running flight after flight with incremental improvements each time. The problem with the massive reactors is that you get to build only a couple of them, so you never get to take advantage of learnings to make the next one better/cheaper/quicker. reply rob74 9 hours agorootparentSo basically it's one economy of scale (making something bigger means the costs for safety, maintenance, personnel etc. are proportionally lower) vs. another economy of scale (making more of one thing decreases the costs per \"unit\"). Place your bets... About your comparison to SpaceX: the approach of building a rocket, launching it, letting it explode and then using the gathered data to make the next one explode later (or not at all) is fine for rockets, but I wouldn't want to see it applied to nuclear reactors. reply rkangel 8 hours agorootparentI do agree on not letting nuclear reactors explode, but I did use the SpaceX example on purpose. Before SpaceX started to do it, the concept of iterating to that degree on rockets was unthinkable. There was a self reinforcing loop of \"rocket launches are expensive, so we must plan for every contingency, so the launch cycle is long and expensive\". SpaceX proved that wrong. I think small modular reactors are the way out of the similar cycle we've got for nuclear reactors. And I think that building a small number of large ones is going to be a lot better if we're also building a large number of small ones and learning. It's like not building a y houses for 30 years and then building a massive skyscraper. If that's all we do then we'll only ever have one way of building a skyscraper because there's no room to experiment on other construction materials and techniques. reply pydry 8 hours agorootparent>Before SpaceX started to do it, the concept of iterating to that degree on rockets was unthinkable. I'm pretty sure that was what NASA was going to do all the way back in the 70s before their funding got slashed. It was a novel idea but not a novel idea that SpaceX was particularly responsible for, just one they threw capital at because the government stopped caring after the space race. Nuclear power research, by contrast, never really suffered from a lack of available funds. They were throwing money at mini reactors back in the 90s, saying all the same stuff about how mass production would bring down the price. reply pieix 8 hours agorootparentNASA funding far exceeds SpaceX’s and always has. It shouldn’t take 4% of the US federal budget (NASA funding during Apollo) to run a hardware-rich design process! reply pydry 8 hours agorootparentApollo was wound down because the government wanted NASA to focus on the space shuttle and all sorts of other things as well as slashing the total budget by a huge amount. So, while in theory it may have had the money, in practice it did not. reply pieix 7 hours agorootparentThe Shuttle cost $48 billion to develop in inflation-adjusted dollars — contrast this with the ~$5B spent on Starship development thus far. It’s hard to defend the claim that NASA is or ever has been under-funded. reply msandford 6 hours agorootparentNASAs \"do stuff\" budget is super small because their \"keep all the experts on staff\" budget is insatiable. It's not entirely bad though, I'm sure lots of those folks are doing good and important stuff. But I don't think the balance between employment and building things is quite right. At least to my tastes. reply operationcwal 8 hours agorootparentprevif you don't care about any externalities (like spacex), sure. but I doubt hospitals or just normal people who need electricity would be super happy about power sources failing because the people building them subscribed to the \"move fast/break things\" mentality instead of actually building reliable/safe infrastructure at the cost of it taking longer reply DennisP 4 hours agorootparentWorth mentioning here that the SpaceX Falcon is the world's most reliable rocket, with a full success rate of 99.24% out of 394 total launches, 325 successful launches of the current version, and 98.5% successful booster landings of the current version, something no other orbital launch system even attempts. https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_He... Comparisons to other rockets here: https://arstechnica.com/science/2022/02/spacexs-falcon-9-roc... https://www.guinnessworldrecords.com/world-records/most-succ... At the moment, of course, two astronauts are stuck on ISS after Boeing's new spacecraft, developed along more traditional lines, experienced problems in its first crewed flight. They're awaiting rescue by SpaceX's Dragon, which has flown 16 times with crew and delivered astronauts to the ISS 10 times, all without a glitch. Both companies were awarded their crew contracts in 2014. reply operationcwal 3 hours agorootparentand nuclear reactors are incredibly reliable as well. do the ends always justify the means? reply DennisP 2 hours agorootparentSince I don't see moral deficit in the means involved in either example, I don't understand the point of your question. reply zaphar 7 hours agorootparentprevOur energy infrastructure isn't particularly reliable right now. Power outages, while not at the level of a third world country, are quite frequent. Nuclear is the highest energy density power generation you can get. Investing in reactors that are less susceptible to explosions (Like a molten salt reactor) is an important step and it's really only viable if you can iterate which means building modular reactor. If you read the article you'll see that most of their iteration and experimentation is without the nuclear material. Something that is possible because the reactor itself is small and can be run through a bunch of safety checks without the dangerous parts. The route that Nuscale and Kairos are taking is both cheaper and safer than large scale reactors. And we are going to need something to fill the gaps when there is no wind or solar generation available if we want to get off fossil fuels. reply ViewTrick1002 7 hours agorootparentWe have been attempting \"small modular reactors\" since the 1950s. They've never worked out. In the same sense that tiny coal plants never worked out. Large physical scale is everything with old school power generation technologies due to various scaling laws. https://spectrum.ieee.org/the-forgotten-history-of-small-nuc... reply DennisP 2 hours agorootparentWe have plenty of small but commercially successful natural gas plants, so it doesn't seem to be a general principle. The only scaling law mentioned in your article is this: > a 400-MW reactor requires less than twice the quantity of concrete and steel to construct as a 200-MW reactor, and it can be operated with fewer than twice as many people. Writing in Science in 1961, a senior member of the AEC worried that “competition [from fossil fuel plants] is indeed formidable” and suggested that “with current pressurized-water reactor technology, lower nuclear power costs can be achieved most readily with large plants.” Almost all the SMRs we've built have been water cooled reactors, which require a large amount of concrete and steel. Newer designs, such as molten salt reactors, can use a lot less, because they operate near atmospheric pressure, don't have to leave room for a high-pressure pipe break introducing a large volume of steam, and have nothing that can cause a chemical explosion. They're also inherently stable and adaptive to load, with little need for active control. A small modular MSR could well work out. reply philwelch 2 hours agorootparentprevThe US has been successfully producing small modular reactors since the 1950’s. We just happen to install virtually all of them inside of submarines and aircraft carriers. reply ViewTrick1002 1 hour agorootparentFor the least price sensitive customer in the world: The US navy. That doesn't tend to translate into working products on cutthroat markets. reply philwelch 1 hour agorootparentI’ve actually been aboard a Nimitz-class aircraft carrier, where I observed flight operations from the flight deck. I can assure you that it’s a working product. And the Navy is under a lot more pressure to cut costs and economize than many government projects. reply mschuster91 6 hours agorootparentprev> Power outages, while not at the level of a third world country, are quite frequent. Nuclear is the highest energy density power generation you can get. Well that is more because the American grid is suffering from a mountain load of neglect-debt to a tune that paints the infamous German railways as saints - the Camp Fire for example was most likely caused by a C-hook breaking after many, many decades of neglect [1]. Here in Europe, we get by just fine with outages measured in maybe a dozen minutes (!) a year [2] - Germany got rid of all nuclear reactors, many old ones in other countries were retired as well (Fessenheim, the most infamous one, in 2020), and while there are new builds, they are often decades late and many billions over budget. How do we do this? We have strict regulations across the board (mandating stuff such as resilience against bad weather, unlike Texas which IIRC refuses to tie in to the other US grids to avoid such regulation), a cross-continental spanning grid [3], and most especially... we just love to bury our cables belowground, so even in the case lightning or storms hit, the actual impact on the consumers is all but negligible. And as the infamous summer of 2023 shows, the power grid still didn't fail even as dozens of NPPs in France and Switzerland had to completely shut down or significantly reduce output because there was not enough cooling water [4]. Hell we even manage to supply an entire country at war with decent power, despite Russia continuously attacking the power grid. [1] https://www.nbcbayarea.com/news/local/long-term-wear-found-o... [2] https://de.statista.com/statistik/daten/studie/37960/umfrage... [3] https://www.entsoe.eu/data/map/ [4] https://www.reuters.com/business/energy/high-river-temperatu... reply zdragnar 9 hours agorootparentprevI believe the thought is that the cost of regulatory and safety measures do not scale favorably with reactor size. You don't have separate facilities so much as 10 reactors on the same site, so you don't need to increase personnel 10x. Actually proving this with a deployed design seems to be the challenge, though with strong headwinds against nuclear across the board, favoring proven designs over newer ones is at least a little faster. That's not a flaw of the design, but intrinsic to the social and political environment. reply infecto 6 hours agorootparentprevOne part of the problem with traditional plants is that they are massive mega projects which the US does not specialize in. I am assuming by building smaller you are able to iterate on designs quicker. I also wonder how much of the cost is tied up in the upfront construction and engineering compared to operations. reply Qwertious 5 hours agorootparent>I am assuming by building smaller you are able to iterate on designs quicker. Everyone in this thread is assuming this, but you get economy of scale by building lots of the same thing, not by constantly changing things. reply infecto 1 hour agorootparentI am not so sure you can build an economy of scale with projects that take a decade to construct and even longer when accounting for approvals and paperwork. The projects are too massive and too long. The contractor that poured the foundation for the last project may no longer be around. It has worked in some areas of the world like China because they have been building from zero and are able to scale mega projects. The US has more hope to learn by iterating on smaller projects. reply DennisP 2 hours agorootparentprevIterate on designs quickly in development. Build lots of the same thing in production. Smaller hardware helps for both phases. reply bewaretheirs 19 hours agorootparentprevAccording to their web site at https://kairospower.com/technology/ it uses a molten fluoride salt based coolant but unlike the MSR/LFTR designs the fissionable fuel is not dissolved into the coolant; instead, the Kairos reactor design puts the fissionables in pellets that are intended to remain solid while in operation; it looks more like a pebble-bed reactor than a MSR/LFTR. reply credit_guy 18 hours agorootparentYes, you are right, I was wrong. The Hermes design is even more conservative than the MSRE design. It is basically the same design as the helium-cooled reactor HTR-PM that China started operating two years ago, only that the helium cooling is replaced with FLiBe cooling; this achieves a higher power density plus a higher rate of passive cooling in case anything goes wrong. This IAEA report [1] has more details about this design, and the dozens if not hundreds of other types of molten salt reactor designs. The relevant section for the Kairos Hermes design is 4.5 (pages 41-44). [1] https://www-pub.iaea.org/MTCD/Publications/PDF/STI-DOC-010-4... reply alwayslikethis 19 hours agorootparentprev> pressure cooker has an internal pressure about 5 times higher than the atmospheric pressure This isn't really accurate. The majority of pressure cookers you can buy operates at an absolute pressure of only about twice the atmospheric pressure. reply credit_guy 19 hours agorootparentOk. And they are still dangerous if they explode. Imagine what happens if something at 150 atm explodes. reply jonkoops 11 hours agorootparentYou don't have to imagine, it happened several times. reply DennisP 2 hours agorootparentOnce, if you're just talking about nuclear reactors. The reactor vessel didn't explode at Fukushima, just the outer building due to accumulated hydrogen. TMI didn't explode at all, the fuel melted but didn't breach containment. reply mattmaroon 16 hours agorootparentprevNot super relevant but pressure cookers only go up to about 1 bar. They definitely would blow before 5. reply earthnail 11 hours agorootparent1 bar is atmospheric pressure. I.e., as far as you in your kitchen are concerned, no pressure at all. reply roelschroeven 9 hours agorootparentPressure is very often stated as gauge pressure, i.e. zero-referenced against ambient air pressure. 1 bar gauge pressure is roughly equal to 2 bar absolute pressure. reply AtlasBarfed 6 hours agorootparentprevUsing solid fuel in a msr is certainly a choice. Hopefully it is just a stepping stone. reply Moldoteck 10 hours agorootparentprevhttps://liftoff.energy.gov/advanced-nuclear/ high chances it'll be more expensive than ap1000 overall /kwh reply ViewTrick1002 9 hours agorootparentThat entire report is an exercise in selectively choosing data to misrepresent renewables and present nuclear power in the best possible light and wishful thinking. To the degree that the prominent \"renewables vs. nuclear\" graph they keep repeating on the webpage and figure 6 in the report is straight up misleading. This is the source: What is different about different net-zero carbon electricity systems? https://www.sciencedirect.com/science/article/pii/S266627872... Utilizing storage costs from 2018 and then of course making the comparison against the model not incorporating any hydrogen derived zero carbon fuel to solve seasonal problems. Which is todays suggestion for solving the final 1-2% requiring seasonal storage in the late 2030s. Something akin to todays peaker plants financed on capacity because they run too little to be economical on their own, but zero carbon. Can be hydrogen or biofuel derived. We will know in 10 years time. Would they have chosen the ReBF model the difference between made up optimal nuclear power and 2018 renewables would be: $80-94/MWh and $82-102/MWh. It is essentially: Nukebros writes reports for nukebros, they confirm their own bias. Simply an attempt to justify another massive round of government subsidies on nuclear power. reply Moldoteck 9 hours agorootparentcopypaste I see)) reply dang 16 hours agoparentprevOk, we've changed the title to language from the article itself (edited to fit HN's 80 char limit) which seems both representative and neutral. If there's a better title, we can change it again. (Submitted tile was \"Google funding construction of seven U.S. nuclear reactors\") reply photochemsyn 17 hours agoparentprevThis is all about the revival of pebble-bed reactors, which were attemped several decades ago but had problems with the graphite pebbles breaking down and releasing graphite fragments that clogged the pipes, basically. China is way ahead on this with helium-cooled versions. The big deal is that in the event of complete power loss (see Fukushima) they go into shutdown without melting down, although if the coolant lost and replaced with air you would get a nasty Chernobyl-style graphite fire. Still an improvement in safety. See: > \"Several high-temperature thermal neutron–spectrum pebble bed reactors are being commercialized. China has started up two helium-cooled pebble bed high-temperature reactors. In the United States, the X-Energy helium-cooled and the Kairos Power salt-cooled pebble bed high-temperature reactors will produce spent nuclear fuel (SNF) with burnups exceeding 150 000 MWd per tonne. The reactor fuel in each case consists of small spherical graphite pebbles (4 to 6 cm in diameter) containing thousands of small TRISO (microspheric tri-structural isotropic) fuel particles embedded in the fuel of zone these pebbles.\" (2024) \"Safeguards and Security for High-Burnup TRISO Pebble Bed Spent Fuel and Reactors\" https://www.tandfonline.com/doi/full/10.1080/00295450.2023.2... and https://www.powermag.com/nuclear-milestone-chinas-htr-pm-dem... reply bb88 17 hours agorootparent> although if the coolant lost and replaced with air you would get a nasty Chernobyl-style graphite fire Or alternatively, radioactive dust could be released into the atmosphere such as THTR-300 did. INL did a gap analysis in 2011 between what was known and what needed research. The german AVR reactor had technical issues that weren't expected -- dust being one of them. https://inldigitallibrary.inl.gov/sites/sti/sti/5026004.pdf From what I can tell the dust issue is still a point of contention. reply petre 12 hours agoparentprev> Kairos is in a pretty early stage. They started building a test reactor this summer, scheduled for completion by 2027 Sounds great in theory, but it took NuScale Power 6 years to get their design approved? I hope the AI hype lasts that long then maybe the world would have two certified 75 MWe SMR designs. Also the NuScale Idaho plant was cancelled last year when cost estimates balooned 3x. 9.3bn for a 460 MWe plant? reply onepointsixC 23 hours agoparentprevYeah I’m not going to lie, that’s quite disappointing. Google funding several AP1000’s would be huge. reply iknowstuff 23 hours agorootparentseeing how 2GW of nuclear cost $34B in Georgia, why would Google waste $120B when they can get the same output for at most half the price (and realistically more like 1/10th) using renewables and batteries? and they’d have results in 2 years instead of 2 decades. edit: to be clear, 1GW of wind or solar is $1B. Build 3GW for overcapacity and you’re still at just 17% of the cost of 1GW of nuclear, and you technically have 3x more capacity. Now figure out how many megapacks you can buy for the $14B/GW you saved https://www.tesla.com/megapack/design (answer: 16GW/68GWh) reply JumpCrisscross 23 hours agorootparent> using renewables and batteries? and they’d have results in 2 years instead of 2 decades We have nothing close to the battery fabrication pipeline to make that timeline true, certainly not at scale. If this move works, Google will have cemented its power needs and economics for decades to come. reply matthewdgreen 22 hours agorootparentGlobal battery manufacturing capacity was 2,600GWh in 2023 [1], and has probably already exceeded that this year. The IEA projects closer to 4TWh by 2025, and nearly 7TWh by 2030 [2]. You need to pay attention because this is happening fast. [1] https://www.bloomberg.com/news/newsletters/2024-04-12/china-... [2] https://www.iea.org/data-and-statistics/charts/lithium-ion-b... reply JumpCrisscross 22 hours agorootparent> nearly 7TWh by 2030 That's a big number. Here's a bigger one: 30,000 TWh, about our current electricity consumption [1]. 7 TWh in 2030 is less than 1/4,000th total electriciy production today. (You obviously don't need 1:1 coverage. But 2 hours in 2030 against a year's demand today is still a nudge.) Now consider EVs. Then add the tens of TWh of annual power demand AI is expected to add to power demand [2]. (And I'm assuming a free market for battery cells, which obviously isn't where we're heading. So add local production bottlenecks to the mix.) Battery numbers are going up. But they aren't going up fast enough and never could have, not unless we ditch electrifying transportation. Nukes or gas. Anyone pretending there is a third way is defaulting to one or the other. [1] https://www.iea.org/reports/electricity-information-overview... [2] https://www.goldmansachs.com/insights/articles/AI-poised-to-... reply robbiep 8 hours agorootparentI had to check the numbers because it grabbed my attention. No issue with your quoted figure of 30,000 TWh (annual) global electricity consumption. But we only need to do 7TWh of battery supply in year 1 (or say only 1-2 of that makes it to grid storage). 30,000/365 is 82 TWh daily. So that’s the number to crack, surely? Because a significant percentage of storage will be to make up for wind and solar, which generally approximately follows some sort of diurnal cycle? If we will be closing in on a couple TWh annual storage capacity in 6 years (leaving aside any real synchronised attempt to get vehicles to be part of large scale distributed grids) then only a few years on from 2030 we’re going to be able to store a significant percentage of our daily energy demands reply ViewTrick1002 21 hours agorootparentprev5 hours of storage and a 98.6% renewables system. https://reneweconomy.com.au/a-near-100-per-cent-renewable-gr... Investing in nuclear power today is an insane prospect when the energy market is being reshaped at this speed. In Europe old paid off nuclear plants are regularly being forced off the markets due to supplying too expensive energy. This will only worsen the nuclear business case as renewable expansion continues, today being a bonanza fueled by finally finding an energy source cheaper than fossil fuel. Nuclear power is essentially pissing against the wind hoping the 1960s returns. reply chickenbig 12 hours agorootparent> In Europe old paid off nuclear plants are regularly being forced off the markets due to supplying too expensive energy. This is happening because of subsidies given to renewables (renewable energy certificates, net metering, guaranteed feed in prices, CFD) plus policies at the national and EU level (EU Renewable Energy Directive). Take away these policies and you are left with a low quality (intermittent) energy source that requires far more expensive storage to produce power when it is needed. reply ViewTrick1002 9 hours agorootparentA study recently found that a nuclear powered grid to be vastly more expensive than a renewable grid when looking at total system cost. Nuclear power needs to come down by 85% in cost to be equal to the renewable system. Every dollar invested in nuclear today prolongs our reliance on fossil fuels. We get enormously more value of the money simply by building renewables. > The study finds that investments in flexibility in the electricity supply are needed in both systems due to the constant production pattern of nuclear and the variability of renewable energy sources. However, the scenario with high nuclear implementation is 1.2 billion EUR more expensive annually compared to a scenario only based on renewables, with all systems completely balancing supply and demand across all energy sectors in every hour. For nuclear power to be cost competitive with renewables an investment cost of 1.55 MEUR/MW must be achieved, which is substantially below any cost projection for nuclear power. https://www.sciencedirect.com/science/article/pii/S030626192... Which is confirmed by Sweden continuing its renewable buildout with both the cheapest electricity prices in Europe and no subsidies on the books for new renewable production. reply xbmcuser 6 hours agorootparentprevEven without subsidies solar and battery are cheaper than nuclear and are getting cheaper by 15-20% a year. So no nuclear is unlikely to be cost competitive any time soon unless they get some new tech for nuclear reply JumpCrisscross 21 hours agorootparentprev> nuclear power today is an insane prospect when the energy market is being reshaped at this speed We’re still more than a decade away from having enough batteries to make this shift. Again, excluding EVs and AI. That’s why we’re reänimating coal plants and building new gas turbines. I’d also love to see the numbers on that simulation going from 98.6% coverage to what we expect from a modern grid. (And if the balance is provided by gas or something else.) It should surprise nobody that going from 1 sigma to 2 can cost as much as 2 to 3, even if the percentage gap is much smaller. > Europe old paid off nuclear plants are regularly being forced off the markets due to supplying too expensive energy Europe has invested €1.5tn into new gas infrastructure. That doesn’t go poor without a fight and collateral damage. reply matthewdgreen 17 hours agorootparent> We’re still more than a decade away from having enough batteries to make this shift. A decade to have significant amounts of battery storage is actually a pretty optimistic timeline compared to nuclear. Nuclear plant construction times are on the order of a decade or (realistically) two decades in the West, if you include planning. In China they're managing 7 years, but their nuclear buildouts, while impressive, aren't trending an upward path when compared to renewables (see chart here [1].) SMRs might change this, but they're years from leaving \"research\" status and entering the mass-production/learning curves that could make them cost competitive. This doesn't make me happy. If I thought nuclear was viable on the timelines we have to dampen climate change, I'd be 100% in favor of it. If we could assemble the political will to raise taxes and build nuclear at \"wartime\" speeds, I'd say go for it. I'm also very much in favor of SMR development, just not willing to bet the house on it. As it stands, there isn't anywhere near enough nuclear power in the planning pipeline for nuclear to matter much on a 20 year timeline. In any case, we are not going to a 100% renewable/battery grid in 10 years. The first goal is to get renewables to 90-95% or more of power generation, massively overbuilt with short-term battery storage backed by intermittent fossil fuels for the remaining 5-10%. This will represent a massive reduction in emissions. The last 5-10% will have to be completed over the next couple of decades, and the increasing battery production trend gives hope that it can be. The worst problem with existing nuclear is that with a 15-20 year planning/construction timeline and the current molasses build rate, new nuclear plants will arrive right at the moment when cheap storage is eating the economic use-cases that make them financially viable. [1] https://cleantechnica.com/wp-content/uploads/2022/10/China-r... reply JumpCrisscross 16 hours agorootparent> * Nuclear plant construction times are on the order of a decade or (realistically) two decades in the West, if you include planning* Sure. Forecasting twenty years out is tough. But our forecasts out 10 years show the power crunch easing to almost no degree--we'll still likely be making the same tradeoff then as now. (And, I suspect, still filling the gap with gas in teh west.) You're broadly correct: we need to build faster. There is no reason we can't build a large plant in under a decade and an SMR in a few years. The latter is what Google is experimenting with here. It's a long shot. But so is hoping battery production scales the orders of magnitude necessary for it to become a utlity backbone over the next decades. > first goal is to get renewables to 90-95% or more of power generation, massively overbuilt with short-term battery storage We don't have the battery pipeline. What we're repeatedly getting is renewables plus gas generators. There is no world in which you put down trillions of dollars of gas infrastructure and then poof it in a few years because it's no longer needed. reply ViewTrick1002 9 hours agorootparentCalifornia would like a word with you. Gas generators are increasingly being forced off the grid with storage. https://blog.gridstatus.io/caiso-batteries-apr-2024/ Storage costs are today lower than the most aggressive projection for 2050 according to one widely cited US DoE study from 2023. https://substack.com/home/post/p-149971818 reply bb88 16 hours agorootparentprev> If we could assemble the political will to raise taxes and build nuclear at \"wartime\" speeds, I'd say go for it. Tepco, Russia, and MetEd all lied to or misled the public about the nature of their respective accidents. Not enough people who were alive during those incidents have died. reply ViewTrick1002 20 hours agorootparentprevA study recently found that a nuclear powered grid to be vastly more expensive than a renewable grid when looking at total system cost. Nuclear power needs to come down by 85% in cost to be equal to the renewable system. Every dollar invested in nuclear today prolongs our reliance on fossil fuels. We get enormously more value of the money simply by building renewables. The study finds that investments in flexibility in the electricity supply are needed in both systems due to the constant production pattern of nuclear and the variability of renewable energy sources. However, the scenario with high nuclear implementation is 1.2 billion EUR more expensive annually compared to a scenario only based on renewables, with all systems completely balancing supply and demand across all energy sectors in every hour. For nuclear power to be cost competitive with renewables an investment cost of 1.55 MEUR/MW must be achieved, which is substantially below any cost projection for nuclear power. https://www.sciencedirect.com/science/article/pii/S030626192... reply JumpCrisscross 18 hours agorootparent> a nuclear powered grid to be vastly more expensive than a renewable grid when looking at total system cost Yes, nuclear is more expensive. SMRs should help with that, but their expense has never been contested. But marginal economics aren't everything. Renewable and battery production isn't ramping up fast enough to make that margin available at scale. This doesn't seem capital contrained, either--every major economy is throwing gobs of cash at the problem. > Every dollar invested in nuclear today prolongs our reliance on fossil fuels. We get enormously more value of the money simply by building renewables False economy. A dollar not invested into nukes doesn't go into renewables--partly because of the aforementioned scaling problem, it tends to wind up in gas. We’re spending trillions of dollars of new money on gas infrastructure with decades of life and financial liabilities attached to them because we need the power, have maxed out renewables and are left with a choice: gas or nukes. Opposing nukes isn’t playing for renewables, it’s playing for gas. reply amluto 16 hours agorootparentSMRs can potentially do something that renewables can’t: they could be placed near the loads in places with no space for renewables and without relying on the grid. Think industrial areas or even cities or towns that are surrounded by other developed land. The grid moves slowly, and electricity prices via existing transmission lines are, in many areas, hilariously inflated for a number of reasons. A hypothetical portable, easy-to-acquire SMR producing power at $100/MWh would not be an amazing deal if a large electric utility bought it, but a $100/MWh would be an amazing price in quite a few markets if a small utility could actually buy at that price and deliver via a small last-mile distribution system. reply Moldoteck 10 hours agorootparentprevhttps://www.sciencedirect.com/science/article/abs/pii/S03605... here's another one or this https://liftoff.energy.gov/advanced-nuclear/ reply ViewTrick1002 9 hours agorootparent> https://www.sciencedirect.com/science/article/abs/pii/S03605... Yes, that shit study which models supplying the entire grid with one energy source and lithium storage through all weather conditions. I would suggest reading the study I linked so you can see the difference in methodology when credible researches in the field tackle similar questions. The credible studies are focused on simulating the energy system and market with real world constraints. Which apparently works out way cheaper when not involving nuclear in the picture. > https://liftoff.energy.gov/advanced-nuclear/ That entire report is an exercise in selectively choosing data to misrepresent renewables and present nuclear power in the best possible light and wishful thinking. To the degree that the prominent \"renewables vs. nuclear\" graph they keep repeating on the webpage and figure 6 in the report is straight up misleading. This is the source: What is different about different net-zero carbon electricity systems? https://www.sciencedirect.com/science/article/pii/S266627872... Utilizing storage costs from 2018 and then of course making the comparison against the model not incorporating any hydrogen derived zero carbon fuel to solve seasonal problems. Which is todays suggestion for solving the final 1-2% requiring seasonal storage in the late 2030s. Something akin to todays peaker plants financed on capacity because they run too little to be economical on their own, but zero carbon. Would they have chosen the ReBF model the difference between made up optimal nuclear power and 2018 renewables would be: $80-94/MWh and $82-102/MWh. It is essentially: Nukebros writes reports for nukebros, they confirm their own bias. Simply an attempt to justify another massive round of government subsidies on nuclear power. reply Moldoteck 9 hours agorootparentlmao, you say shit study but you suggest using green h2 as backup which not only isn't economically feasible (for now at least) but current generators are either using a mix with gas or use pure h2 with huge nox releases due to high temp burning. Not just that, most lcoe costs magically assume that 4h storage is enough. Look at yesterday's Germany generation and tell me how 4h storage will be enough there. Or maybe I should link to amount of subsidies Germany is pouring each year in renewables like https://www.bloomberg.com/news/articles/2024-05-29/germany-s... or like https://www.reuters.com/business/energy/germany-looks-specia... It's funny that when I ask ren-bros how much subsidies edf in France is getting they are either silent or are linking to price shielding that's totally unrelated and is present in most eu countries after russia's invasion. Renewable bros as usual are dunking on nuclear and promoting their clean supply like a mecca without facing hard reality - most renewables now are subsidized by fossils and will be in any close future reply Qwertious 5 hours agorootparent>you suggest using green h2 as backup which not only isn't economically feasible (for now at least) That's poor logic, h2 as a last-2%er doesn't need to be feasible until we've gotten to the 98% mark. And honestly, h2 feasibility is a function of cheap energy anyway, which probably means midday solar while solar farms are chasing dusk prices. reply Moldoteck 5 hours agorootparentnot, h2 feasibility in the context of power generation depends on many more factors, including how frequent the plant is used when day hours will be mostly tapped by solar generation and how you'll do price compensation. And in the context of h2 for renewables as a peaker, it'll need to be much more than 2%. And again, the emission problem for h2 generation isn't solved yet beyond fuel cells reply cyberax 19 hours agorootparentprev> Nuclear power needs to come down by 85% in cost to be equal to the renewable system. Only if you don't care about reliability. reply ViewTrick1002 19 hours agorootparentSeems like you didn’t read the quote from the abstract. Here’s the relevant part: > with all systems completely balancing supply and demand across all energy sectors in every hour. reply cyberax 19 hours agorootparentI call BS on that. reply acdha 19 hours agorootparentYou’re asking us to trust your gut reaction over a peer-reviewed study. Do you have any qualifications or experience in the field? reply cyberax 17 hours agorootparentSorry, was writing on a mobile. Here's a more detailed explanation why it's pure BS. Because it's simply magic thinking. They postulate a \"future fully sector-coupled system\" and then say that if this somehow magics into existance, then everything's peachy. Basically, \"a sector-coupled system\" allows transforming excess power into something useful (district heating, hydrogen, steel, etc.), and shedding the load and/or providing some power back when there's not enough generated power available. In other words, if you solve the problem of providing 1 month of energy storage for Germany and Denmark, then renewable energy is basically free. Duh. The problem is that \"sector-coupled systems\" don't exist, and their creation will result in far, far, far, far more expenses than building fucking PWRs. reply ViewTrick1002 9 hours agorootparentYes, the study incorporates no lithium storage. Including storage we will easily reach far above 90% renewable penetration. When we get to the final percent in the 2030s we can utilize akin to todays peaker plants financed on capacity markets [1] but zero carbon. Peaker plants today already run too little to be economical on their own, essentially what in our current grids constitute seasonal storage and emergency reserves. Simply update the terms for the capacity markets to require the fuel to be zero-carbon. It can be synfuels, biofuels or hydrogen. Whatever comes out the cheapest. As we electrify transportation we can shift over the massive ethanol blending in gasoline in the US to be our seasonal buffer. [2] [1]: https://en.wikipedia.org/wiki/Electricity_market#Capacity_ma... [2]: https://www.eia.gov/tools/faqs/faq.php?id=27&t=10 reply cyberax 2 hours agorootparent> When we get to the final percent in the 2030s we can utilize akin to todays peaker plants financed on capacity markets [1] but zero carbon. Capacity markets effectively don't exist in Europe right now. There are plans to create a plan for them by 2027, this is how urgent it is for Europe. But no worries, natural gas is now green, and it's fine to send money to Azerbaijan for it. There is no pathway for most of Europe to switch to renewables any time soon. reply ckdarby 20 hours agorootparentprevIn this context, what is a \"modern grid\"? reply Moldoteck 10 hours agorootparentprevIn eu France is the biggest net exporter in the EU while Germany with huge renewable capacity net imported 20+TWh this year. Look how Germany's generation was yesterday to get a sneak peek reply atwrk 10 hours agorootparentThis is only because it is profitable for Germany to do so, not because of lack of capacity. Germany imports energy when there is low demand (and price) and exports when there is high demand (and price). Look at this chart: https://energy-charts.info/charts/power_trading/chart.htm?l=... reply Moldoteck 9 hours agorootparentanother reason is to fire up coal less. Again, look at yesterday generation. They were not able to satisfy local demand with renewables and bumped up coal+gas by a lot. Also, if you look at the numbers - the price difference isn't that huge but trade difference is huge. This year export price is less than 1$ more than import. Problem is Germany net imported 25TWh so they are still in a big trade deficit and it continues to grow considering dunkelflaute is ahead reply ViewTrick1002 9 hours agorootparentYes, Germany is targeting a 80% renewable electricity mix by 2030 and 100% by 2035. They have no illusions about being perfect today. Their current status is 65% renewable for 2024. Maybe stop looking at instants and start looking at the larger picture: keeping our cumulative emissions as low as possible. Starting a nuclear construction project which won't deliver any decarbonization for 15-20 years is accepting large cumulative emissions. reply Moldoteck 9 hours agorootparentthey don't target 100% by 2035. They want to close last coal plant by 2038 which is a bit optimistic looking at yesterday's generation. For gas it's even worse - the plan is totally unrealistic and their planned h2 ready plants that'll use gas initially, will probably still use a mix with gas when/if green h2 becomes reality or they'll replace the generators with pure h2(unlikely) which has huge nox emissions due to high burn temperature Larger image is yesterday's generation + https://www.bloomberg.com/news/articles/2024-05-29/germany-s... and https://www.reuters.com/business/energy/germany-looks-specia... And nuclear construction can be much faster https://en.wikipedia.org/wiki/Barakah_nuclear_power_plant or you can look at projects from China reply Vvector 21 hours agorootparentprev\"But 2 hours in 2030 against a year's demand today is still a nudge.\" How much battery storage do you think we need? Surely not a year's worth. For solar, we'd likely need 10-16 hours of storage to power stuff overnight. Maybe a little more to cover a few cloudy days. Sounds like we are about 5% of that now? reply bluGill 21 hours agorootparentGenerally the worst case is two weeks. In the middle of winter you often get cloudy low wind days for that long. Of course how you handle those worse cases are days need not be how you handle typical. If you can handle 16 hours of no input this will over the typical cases this will be enough to max a massive dent in carbon emissions and we can fall back to existing gas (or even coal) plants for the rest. Plus a lot of power use can turn off when needed - give my company a discount and we can turn the factory off. reply sudosysgen 21 hours agorootparentprev10-16 hours is not enough at all. On a cloudy day, solar output will only be 15-20%. On top of that, your panels really only generate for 8 hours on a very good day - the sun is a lot dimmer in the early morning and late evening. Really, you need 2x storage for a good day, if you want to deal with two cloudy days you'd want 50-60 hours of storage. reply ckdarby 20 hours agorootparentCould you possibly read the article you're replying to again? Even skimming through it discusses the coverage of wind and a not 50/50 system particularly to cover winter & night time. There is also discussion of a ~2% from \"other\" and how much storage capacity is required. The article even goes into using wind & solar data for the simulation and reducing further the output to be conservative. reply sudosysgen 18 hours agorootparentI obviously understand it's not a 100% solar system. If it was you would need to be able to deal with at least 2 weeks of bad weather, not two days, and you would have to take into account winter (dropping to about 5 hours instead of 8). Additionally, mixing solar and wind is not as easy as it seems, because the two are correlated. If you have a major storm that makes wind energy impossible due to wind speeds above ~100km/h, you will also have clouds making solar energy unworkable. I'm not aware of any simulations modelling a 95+% solar/wind grid for storage needs, taking into account extreme weather patterns, grid topology, and equipment damage, but if you do then please link it. I don't see any article linked in the comment I replied to. Perhaps you're mixing up two comment chains. reply pfdietz 16 hours agorootparentprevIt's likely enough battery capacity if you combine batteries with e-fuels for longer term storage. Assuming batteries are used for all storage use cases is one of the classic errors of energy system analysis. reply amluto 16 hours agorootparentprev> That's a big number. Here's a bigger one: 30,000 TWh, about our current electricity consumption [1]. 7 TWh in 2030 is less than 1/4,000th total electriciy production today. I don’t think anyone is seriously suggesting powering a portion of the grid with batteries that are cycled once per year. One can optimistically cycle one or even twice a day (if wind peaks when the sun is down). Or you can try to ride through a week of bad weather, but natural gas is not actually a terrible solution for that. And those batteries last for a lot longer than a year. So I think your 1/4000 should be more like 1/10. Give it a few more years. reply JumpCrisscross 15 hours agorootparent> natural gas is not actually a terrible solution Natural gas is a great solution. It's why we're using it. But if your focus is decarbonisation and electrification, nuclear is better. Even if it's pricier. > your 1/4000 should be more like 1/10. Give it a few more years The former is calculated from projected 2030 battery production to present energy levels. An essential component of strategy is knowing on whose side time is. Battery production won't reach 1/10 for at least a few decades. That's the point. We need an intermediate solution, and if that's going to be gas, we have to live with the fact that (a) emissions will continue and (b) we perpetuate trillions of dollars of capital infrastructure that will be as difficult to take down in the future as coal has been today. reply Dylan16807 15 hours agorootparent> Natural gas is a great solution. It's why we're using it. But if your focus is decarbonisation and electrification, nuclear is better. Even if it's pricier. There's a crossover point. If you use natural gas to provideNatural gas is a great solution. It's why we're using it. But if your focus is decarbonisation and electrification, nuclear is better. Even if it's pricier. If you come up with some combination of carbon-free energy sources and storage that covers 90% of grid energy needs, and you need to fill in the gap, and that gap is a whole lot of power but only for a handful of days a year, then I don’t think nuclear is a good option at all to fill in the gap. The capital expense would be absurd. Decarbonization is great, but in the real world, decarbonization per dollar spent is what matters. Instead of spending a zillion dollars on nuclear peaker plants, spend a lot fewer dollars on gas peaker plants and the the rest for more effective environmental improvements. reply Workaccount2 21 hours agorootparentprevWe'll figure it out. There is too much at stake and there are already a gazillion engineers out there going to bed every night thinking about how to solve this problem. Innovation is the grim reaper of analyst reports. No one at my company notifies an investment bank when we have a breakthrough internally (lol). reply reitzensteinm 16 hours agorootparentprevWhy are you comparing the rate of change of battery storage capacity, the vast majority of which if grid connected will be used for at most diurnal storage, to yearly energy consumption? Holy mother of all type errors there. Multiply it by 365, and it implies that in 2030 alone, we will create enough battery storage to time shift almost 10% of our total electricity use today. This is not a stat that should inspire pessimism. reply lukeschlather 21 hours agorootparentprev> and never could have I could just as easily assert the same of nuclear or gas. It doesn't make it true, although there seems to be evidence that nuclear cannot scale as fast as batteries/solar/wind. reply countvonbalzac 21 hours agorootparentprevThat's per year right? reply iknowstuff 23 hours agorootparentprevfrequently asserted but not true. https://x.com/DavidOsmond8/status/1843840160842350779 reply JumpCrisscross 22 hours agorootparentNobody claims renewables + battery doesn't work long term. (And not only work, but do so at rock-bottom costs.) The problem is the timeline. Time out building that additional infrastructure, including expected demand growth, and you always need more power in the interim. Particularly if you're planning on taking coal offline. If there is an arugment that we can ramp up battery production even faster than we are, the math changes. But we're already in a Herculean effort to mass produce more batteries faster. reply iknowstuff 20 hours agorootparentnuclear literally takes 10x the time to build as renewables+batteries. That's like the whole reason why it doesn't get built. reply sien 18 hours agorootparentDuring the Messmer plan the French installed 56 reactors in 15 years. https://en.wikipedia.org/wiki/Nuclear_power_in_France#Messme... So you're saying that in 1.5 years the same thing can now be done with renewables and batteries? In 2027 it will easily have been done in a bunch of places ? reply throw0101d 18 hours agorootparent> During the Messmer plan the French installed 56 reactors in 15 years. Canada (mostly Ontario) built 25 reactors in 35 years: * https://en.wikipedia.org/wiki/Nuclear_power_in_Canada#Power_... From the 1980s to the 2000s, it took Japan roughly 4-5 years between start of construction and commercial operation for a number of reactors: * https://en.wikipedia.org/wiki/List_of_commercial_nuclear_rea... reply pfdietz 16 hours agorootparentprevAnd now that's not realistic, given their track record on EPR. reply pfdietz 22 hours agorootparentprevBattery manufacturing capacity is greatly underutilized in China. That was battery cell prices there fell by nearly 1/2 in the last year. There is tremendous room for expansion of production. reply ckdarby 20 hours agorootparentprevBased upon? Looked through the thread and it looks asserted but I don't see the counter not true point. reply toomuchtodo 22 hours agorootparentprevhttps://www.bloomberg.com/news/newsletters/2024-07-09/china-...https://archive.is/DklaA (\"Bloomberg: China’s Batteries Are Now Cheap Enough to Power Huge Shifts\") reply slashdave 20 hours agorootparentprevMaybe you just found a great place for a company like Google to invest in. reply throw0101d 18 hours agorootparentprev> seeing how 2GW of nuclear cost $34B in Georgia Vogtle 4 was (IIRC) 30% cheaper than Vogtle 3. The problem with nuclear in Georgia, and in the US, was that no one remembers/ed how to do it, and so all the lessons of yore had to be relearned, and the supply chain had to be stood up. If you put in an order for several reactors, the very first one (especially of a new model, like Vogtle 3 was) will be expensive AF. The second will be expensive. All models after that will be at a more 'reasonable' cost. Nuclear reactors are just like any other widget: the cost goes down with economies of scale. If you order 4 or 8 reactors at one sites they'll get progressively get cheaper (there is a floor of course). If you then put in an order at a second site, and move the workforce (or a portion) there, the lower costs will still be present. If you start and stop construction, or order a whole bunch of different models/types, then there economies of scale goes out the window. reply dalyons 17 hours agorootparentSort of - nuke plants are fundamentally phenomenally complicated compared to true economies of scale technologies like solar. You won’t reap 100x cost savings in nukes, no matter how many you build reply throw0101d 4 hours agorootparentEvery widget has a price floor since there's parts/materials and labour costs. This is even true for solar. One simply has to be careful about what something \"costs\" when you look at the first unit versus the nth unit. reply cyberax 19 hours agorootparentprev> edit: to be clear, 1GW of wind or solar is $1B. No, it's not. Right now it's probably more than $10B a GW if you want the same level of reliability as nuclear. reply atwrk 9 hours agorootparentYou can't just invent a number because you like it more. Solar and Wind are cheaper than nuclear even if you go beyond LCOE and include system costs. Even the nuclear lobby acknowledges this nowadays and has switched to other arguments. reply cyberax 2 hours agorootparentNo. Not even close. Wind and solar are cheap _only_ if you don't depend on them. In particular, for the wind the adequacy rating is about 10% in most places. It means that you can expect 10% of the nameplate capacity to be available at all times system-wide. So multiply the wind energy costs by 10x, and suddenly they are quite more expensive than nuclear. It's not even a question for the solar, it simply can't provide power during a day without storage. > Even the nuclear lobby acknowledges this nowadays and has switched to other arguments. Nope. reply dogma1138 11 hours agorootparentprevCan Google get 2GW for $34B anywhere in the world? This is the value proposition of modular small reactors. The cost of nuclear in Georgia today is essentially subsidized by decades and decades of past investments. And as much as some people might like that you can’t simply move Georgia and place it next to your data centers. reply Moldoteck 10 hours agorootparentprevbecause 1 - 1gw of solar capacity isn't the same as nuclear, even 3gw of solar isn't the same as 1gw of nuclear (to get a proper perspective, look at germany's grid yesterday& how much overcapacity of solar/wind they have and how much was actually generated/imported). 2 - vogtle unit 4 was 30% cheaper than unit 3, proving positive learning curve, meaning (in theory, according to https://liftoff.energy.gov/advanced-nuclear/ ) new builds should be significantly cheaper reply edm0nd 23 hours agorootparentprevThat is seemingly such an absurdly high number to get a nuclear planet up and running. Is the majority of that cost dealing with regulatory and legal nonsense that stems from the anti-nuclear hippy groups and laws they got passed in the 60s and 70s? reply JumpCrisscross 23 hours agorootparent> Is that majority of that cost dealing with regulatory and legal nonsense that stems from the anti-nuclear hippy groups and laws they got passed in the 60s and 70s? One part this, two parts the economics of a novel technology platform being deployed in a large size, three parts American labor costs and inexperience with megaprojects. Similar to why we can't build ships [1]: high input costs, notably materials and labour, and a coddled industry that is internationally uncompetitive. With ships, it's the Jones Act and shipyard protectionism; with civilian nukes, it's misguided greenies. (Would note that we're perfectly capable of nuclear production if it happens under the military.) [1] https://open.substack.com/pub/constructionphysics/p/why-cant... reply matthewdgreen 22 hours agorootparentNuclear is still much more expensive than renewables in China, where there aren't too many \"misguided greenies\" setting policy. Environmentalists were successful in opposing nuclear construction because it was expensive and unprofitable, not the other way around. The faster people can internalize this lesson, the sooner we'll get to economically-viable nuclear power. reply mbivert 20 hours agorootparent> Environmentalists were successful in opposing nuclear construction because it was expensive and unprofitable As far as Europe is concerned, there seems to have been various political move and lobbying to affect energy independence (e.g. France): economy is transformed energy, so by nuking (…) energy independence, you're suffocating countries. The military role of nuclear is furthermore crucial; civil & nuclear must be correlated. That's to say, giving up nuclear is not something a sane, well-driven country should do lightly, regardless of ideologies. It's a tricky topic; what I regularly hear from economists is that wind & solar are still far from being able to compete with nuclear. And because of the previous two points, people can't but frown upon \"green\" arguments, even if the underlying intentions are honest and well-intended. (China may not have misguided greenies, but it has a strong incentive to sell whatever it's offering). reply bobthepanda 19 hours agorootparentIf China had a super cheap nuclear design they would be very happy to export that the same way they export their other technologies like EVs, high speed trains, solar panels, batteries, etc. But it simply does not exist. reply JumpCrisscross 17 hours agorootparent> If China had a super cheap nuclear design they would be very happy to export that China \"plans to export nuclear power reactors in the future\" [1]. It's early stages, but being done through Belt & Road [2]. [1] https://www.iaea.org/bulletin/how-china-has-become-the-world... [2] https://www.cipe.org/resources/chinas-nuclear-dragon-goes-ab... reply bobthepanda 15 hours agorootparentThe first article refers to 2018 in the future tense, and the second article is three years old without a single announcement of a Belt and Road nuclear plant since then. reply Moldoteck 10 hours agorootparentprevchina has a super cheap design called hualong and they plan to export it the way russia is exporting their designs. Another plan is finishing local adaptations of ap1000 that can be reselled without licensing problems reply Moldoteck 10 hours agorootparentprevis it? New plants cost 3-3.5bn for a stable 1gw output. For renewables - much more needs to be built to provide same reliability or compensate with fossils reply pfdietz 16 hours agorootparentprevThis is why China installed 217 GW of solar last year, but only 1.2 GW of nuclear. reply JumpCrisscross 16 hours agorootparent> why China installed 217 GW of solar last year, but only 1.2 GW of nuclear And 114 GW of coal [1]. Don't do nuclear, and that becomes 115 GW of coal. Nuclear and renewables aren't competing for market share. Everyone is putting down renewables as quickly as possible. But we need more power, so we fill the gap with one of gas, nuclear or coal. [1] https://www.reuters.com/sustainability/climate-energy/china-... reply golli 9 hours agorootparent> > why China installed 217 GW of solar last year, but only 1.2 GW of nuclear > > And 114 GW of coal [1]. Don't do nuclear, and that becomes 115 GW of coal. Nuclear and renewables aren't competing for market share. That is true for China, since their overall energy demand is growing massively. But is that also true for other parts of the world like the US or EU? Because looking at the electricity production [1] this doesn't seem to be the case. So in those markets they would compete for replacing existing fossil power plants. I think we can expect some growth, but not on a level even close to China. [1] https://yearbook.enerdata.net/electricity/world-electricity-... reply matthewdgreen 3 hours agorootparentI'm only slightly exaggerating when I say that the rest of the world is a footnote to China's emissions. Europe's emissions are already dropping fast, though. Presumably if China can decarbonize its economy at the rate it's going, then we presumably the rest of the world (even poorer nations) will be able to fast-follow them due to the learning curve (or else just because China will have so much excess manufacturing capacity that they'll flood the world with cheap renewables.) reply pfdietz 7 hours agorootparentprevWe should see some increase in electricity consumption due to displacement of direct uses of fossil fuels. For example, use of heat pumps in place of natural gas furnaces, electric cars in place of IC engine vehicles. Add to that the ever popular AI and general data center consumption motivating this announcement (but I wonder how much of that is going to move to places with cheaper electricity.) reply matthewdgreen 3 hours agorootparentprevThe current analysis is that China's emissions peak this year [1,2] and will enter a structural decline. This is because new renewables are being deployed faster than growth in energy demand. The new coal construction is mostly \"dispatchable\" production that will be used to backstop the fast-growing renewable grid, with payments going to coal plants in exchange for not generating (and built-in expectations that these payments will rise over the next few years as renewables and storage serve more of the demand.) [1] https://www.carbonbrief.org/analysis-chinas-emissions-set-to... [2] https://www.nature.com/articles/d41586-024-02877-6 reply pfdietz 1 hour agorootparentAlso because of widespread adoption of battery electric vehicles. reply rtkwe 22 hours agorootparentprevIMO they only continue to exist because of the Jones Act not the way I think you're implying where Jones Act protectionism prevents them from flourishing. High material and labor alone are enough to explain why people wouldn't build ships in the US. What special capabilities could Us shipbuilders bring that would make the cost of labor here competitive with China or South Korea? Gone are the days when the US dominates on skill or capacity, and that's not because the US has lost something the rest of the world just caught up with us. Whenever we're looking at the 1900s and wondering why the US used to be so dominant as an industrial power I think it's incredibly important to remember our industry got all the upside (an absolute torrent of money and demand) and none of the downside (bombing) of two world wars. IMO the US industrial base was riding high on that easily into the 80s and people mistake that dominance for skill and prowess rather than the waning boon of WW2's mobilization and destruction of every other extant industrial power. reply JumpCrisscross 22 hours agorootparentThe point is there are downstream costs to our moribund shipping industry. We have a internally-navigable waterways we barely use, offshore wind power gets stalled due to lack of ships, et cetera. Post-WWII effects are one component. But another is that we want a protected shipbuilding industry for its own purposes, which is fine, but that curtails a lot of other production. > What special capabilities could Us shipbuilders bring that would make the cost of labor here competitive with China or South Korea? Energy. Our energy costs are much lower than theirs. reply rtkwe 4 hours agorootparentChina's average energy cost for businesses is 10c and the US is 13c according to a quick search I did so I'm still not following. reply WalterBright 22 hours agorootparentprevThe rise of the US as an industrial power started in 1800. The US was already dominant before WW1. reply msabalau 5 hours agorootparentThere is a huge difference between the US accounting for 20% of Global GDP and merely being \"in first place\" at the end of WWI and the USA having half of global GDP (and 80% of the world's hard currency reserves) at the end of WW2. While also say, having a Navy easily more powerful than the rest of the world combined, and being able to to focus on an upcoming surge in consumer consumption as opposed to desperately struggling to stabilize food production and rebuild cities and industries that had been ravaged by war. Britain, a victor that had never been occupied, wasn't able to lift many significant food rationing schemes until the 1950s. Bread, which wasn't rationed during the war, had to be rationed from '46 to '48. There is a meaningful distinction between being the leading industrial power and being the overwhelmingly dominant economic power. reply slashdave 20 hours agorootparentprevThe NRC is many things, but a front for \"anti-nuclear hippy groups\" is not one of them. reply iknowstuff 20 hours agorootparentprevFrance, with all their nuclear base, just raised their estimate for new reactors (I'm so shocked!): > State-owned Electricite de France SA has raised its estimate for the future construction costs of six new atomic reactors in France by 30% to €67.4 billion ($73 billion) 6 reactors, 1650MW each, $7B per 1GW vs Vogtle's $17B. Planned. In 2 decades, after it's finally built, it will have doubled of course lmao. reply jimjimjim 22 hours agorootparentprevThat right, blame the hippies. Nothing at all to do with nuclear power plants being the one thing that you really do want to be engineered well. But no, regulations are of course to blame! reply edm0nd 22 hours agorootparentThe anti-nuclear hippy movements of the 60s and 70s are pretty directly responsible for a lot of the slow down in expansion of nuclear power. >Between 1975 and 1980, a total of 63 nuclear units were canceled in the United States. Anti-nuclear activities were among the reasons, but the primary motivations were the overestimation of future demand for electricity and steadily increasing capital costs, which made the economics of new plants unfavorable. - https://en.wikipedia.org/wiki/Anti-nuclear_movement - https://en.wikipedia.org/wiki/Anti-nuclear_movement#Impact_o... There was a lot scares and FUD about it at the time. To note, I am pro-nuclear. reply jonas21 20 hours agorootparentThat says pretty much the opposite of what you claim. reply preisschild 23 hours agorootparentprevBecause they need power 24/7 and not only when the weather cooperates. And new AP1000s in the US would cost significantly less, because there are already experienced workers & supply chains from Vogtle and getting a license requires less work too, because you can copy much of Vogtle. The median build time for nuclear reactors is 7 years. This is archivable if you continue building and not just build 1 or 2 every few decades. reply p1necone 23 hours agorootparent> Because they need power 24/7 and not only when the weather cooperates. Hence the batteries. reply rtkwe 22 hours agorootparentThe scale just isn't there. A single nuclear power plant near me, McGuire Nuclear Power Plant, produced 17,514 GW·h in 2005. The entire potential output of the Tesla (cough Panasonic) Gigafactories in California and China have a combined output of ~50 GWh per year. [0] Nuclear power is amazing at producing a reliable base load of power that massively outstrips our ability to produce and store solar power. Say our load is well aligned with the cycle of solar power and we're ignoring weather so we can derate the amount we want to store to 30% that's 105 years of production out of what I think is the two largest batter plants in existence to store the power produced continuously by a single large nuclear power plant. [0] https://www.fuld.com/tesla-energy-massive-growth-in-megapack... reply ZeroGravitas 22 hours agorootparentI don't follow your sums. 50GWh of battery cycled once a day for a year is: 18,250 GWh So you seem out by around 100x. reply rtkwe 5 hours agorootparent...sometimes the brain is smoothed by meetings... reply toomuchtodo 22 hours agorootparentprevGlobal stationary storage deployed for 2024 will be ~150GWh, and this is accelerating. Batteries are easy, nuclear appears to be impossible (economically speaking). reply rtkwe 22 hours agorootparentSo 35 years then to store the power generated 24/7 by McGuire at that rate of production which ignores that the huge spike of AI loads will want 24/7 power, if we're looking at that kind of load I'd rate it at 50% for starters (low to be honest because it doesn't account for how solar ramps up during the day) which is around 60 years. Plus that's giving full capacity to those batteries when ideally we'd only use the middle 60% to avoid deep cycling the batteries daily unless they've completely solved that problem. reply toomuchtodo 22 hours agorootparentThe nuclear ain't getting built, these are facts. Even if one breaks ground today, you won't push your first kwh to the grid for a decade, at which point another ~10TW of clean energy will have come online globally. If AI is using too much power in the short term, destroy demand with policy and economics. We are not beholden to the robot trainers, we just don't provide utility access to the load. Unlimited demand of industrial scales of electrical power isn't a right of some sort. reply rank0 15 hours agorootparentWhat other activities are prohibited in your dream dictatorship? reply toomuchtodo 15 hours agorootparentEveryone is a libertarian until it’s their commons experiencing the tragedy. Strange to think that having regulations around large scale electrical loads is a dictatorship. It’s okay for us to collectively say no, depending on the circumstances. reply toomuchtodo 15 hours agorootparentprevCitation for my sibling comment and that which you replied to: https://www.energy-storage.news/arizonas-biggest-battery-sto... (“Arizona’s biggest battery storage system goes online to feed Meta data centre demand”) https://orsted.com/en/media/news/2024/10/orsted-has-complete... (“With a 300 MW solar PV capacity, Ørsted’s Eleven Mile Solar Center will produce enough renewable energy to power 65,000 US homes while the battery can store 1200 MWh of power.”) (~2 years from planning to commissioning) reply Moldoteck 10 hours agorootparent1.2gw of storage means in 4hr it's gone if solar and wind are weak reply ben_w 9 hours agorootparentAnd can be recharged as soon as the wind or the sun comes back. The sizing of batteries and power sources is highly region specific, and the places where it makes sense today with current manufacturing capacity, don't have to be \"everywhere\" for it to be fine where it's actually done; and given the roll out rate of renewables, we also don't need to wait until battery output per year can totally displace the existing and currently running gas plants, just back up the newly installed renewables themselves - 4h in this case is how fast the PV farm would recharge those batteries in the best case, the average output of a PV plant is about 10% of the peak, so this is really a 40 hour battery pack not a 4 hour pack. reply Moldoteck 9 hours agorootparentI mean, look at Germany's grid yesterday& today and tell me, with such overcapacity, how much more overcapacity it would need and how much storage it would need to cover such events with low wind and solar? reply ben_w 7 hours agorootparentI use the approximation of annual capacity factors for PV being 10%, which means 10x. Wind has a higher capacity factor IIRC between 35% and 85% and that heavily depends on location. A realistic answer would need me to spend at least a month dealing with finding historical satellite cloud cover data, wind records, correlations leading to nationwide dunkelflaute, the planning options for where new stuff can be built, etc. And even then, that varies depending on international grid connections, and how much storage is on the grid. reply Moldoteck 7 hours agorootparentcf yearly are good for some purposes but bad for others. Again, look at Germany's coal/gas use yesterday vs today as well as wind/solar generation and imports. If you don't want fossils, how would you cover such events? France was outputting towards Germany equivalent of 3-4 npp and 2 additional from Switzerland, max being about 12+GW from neighbors. How would it be financially viable considering there are many other days when demand will be met for day hours? New solar/wind will not be able to sell energy at negative prices unless they get subsidies. Germany already spends 20bn/yr for price subsidies and their grid is far from overcapacity and that doesn't account for other subsidy types like for transmission for renewables reply ben_w 6 hours agorootparentToday's values, from what I've seen, this country could run on just wind if it had 10x more than now, but it doesn't really need that in isolation, it's just that PV was harder to judge because the graph wasn't even close to a flat line. https://www.energymonitor.ai/power/live-eu-electricity-gener... > New solar/wind will not be able to sell energy at negative prices unless they get subsidies. They already do, in good weather. > 20bn/yr for price subsidies and their grid is far from overcapacity And how much of that was for a guaranteed price made way back when the stuff was still expensive? New PV is, by itself, the single cheapest source of electricity; even adding on batteries only takes it up to somewhere between gas and nuclear depending on the specifics. > and that doesn't account for other subsidy types like for transmission for renewables How's that a subsidy? I've not seen the breakdown of bill costs here, but back in the UK there was a split between connection cost and use cost. reply Moldoteck 6 hours agorootparenttransmission upgrades are needed for renewables due to their distributed nature https://www.reuters.com/business/energy/germany-looks-specia... > They already do, in good weather. We haven't reached yet such renewable market penetration to get this problem. It'll happen when a lot of days, 10 day hours will be covered by renewable output. > And how much of that was for a guaranteed price made way back when the stuff was still expensive? I have no idea how are these are distributed. Do you have a link for recent vs old projects? reply Moldoteck 10 hours agorootparentprevlook at germany's yesterday output and tell me how much batteries they'd need to cover such a drop in generation reply preisschild 22 hours agorootparentprevHaving enough battery capacity to back up enough energy for a few minutes let alone days would require a lot of resources. I think scaling nuclear power would be cheaper and more environmentally friendly. reply slashdave 20 hours agorootparentCheaper? No, not even close. Environmentally friendly? Debatable, but wait for new tech. https://www.pbs.org/wgbh/nova/article/iron-air-battery-renew... reply Moldoteck 10 hours agorootparentyes it'll be cheaper https://www.sciencedirect.com/science/article/abs/pii/S03605... https://liftoff.energy.gov/advanced-nuclear/ reply mindslight 22 hours agorootparentprevSo using your numbers, it is solidly a little less than half the cost, not one tenth (26GWh seems around the necessarily amount for riding out ~14 hours of darkness. I'm assuming your factor of 3 makes up for seasonal variation and cloudy days). The panels take up 9 acres of land area, and need to be kept clean of snow and dust. The battery lifetime is small compared to expected life of a nuclear reactor, but the battery lifecycle is more straightforward. This seems like the territory of having a reasonable tradeoff between the two, not some unequivocal win for an Internet smackdown about how we should avoid one approach. reply s1artibartfast 15 hours agorootparentprevThat wont work because the tesla webpage has a maximum order quantity of 1,000 units... /s reply treflop 22 hours agorootparentprevI'm fairly pro-nuclear but the EIA (Energy Information Administration) publishes a \"Levelized Costs of New Generation\" report every year that compiles the total cost of installing new generation, taking into account the fuel, build up, maintenance, interest, and inflationary costs, and nuclear ends up costing more $$$ than other renewable alternatives. It's no conspiracy why nuclear never gets traction these days -- maybe it was cost-effective 10-30 years ago but renewable technology has gotten relatively cheap. (Shutting down active nuclear reactors earlier than needed is a whole different issue though.) Here's the report for 2023: https://www.eia.gov/outlooks/aeo/electricity_generation/pdf/... There is no report for 2024 because they are building a new model to take into account even newer technologies: https://www.eia.gov/pressroom/releases/press537.php reply Moldoteck 10 hours agorootparenthttps://liftoff.energy.gov/advanced-nuclear/ https://www.sciencedirect.com/science/article/abs/pii/S03605... Lazard report for lcoe is so funny because they assume 4h storage will be enough to cover the demand reply throwaway2037 17 hours agorootparentprevNuclear is a terrible investment in 2024. Price per delivered megawatt-hour is guaranteed to be much lower for a combination of solar+battery+wind. -- Edit -- To clarify, \"Nuclear is a terrible investment for private industry in 2024.\" However, I understand why nation states (and their equivalents) would want a diversity of power sources. There many be non-economic reasons why nations want to build nuclear over solar+battery+wind. reply forgotoldacc 16 hours agorootparentThere's something to be said for space. A nuclear reactor takes up far less land than an equivalent amount of wind and solar generation. That's quickly going to become a limiting factor in wind/solar rollout and already is in some smaller countries (unless they're willing to bulldoze their entire land to cover it in solar panels) reply notTooFarGone 13 hours agorootparentOk we can all agree that the US has not a land problem. This argument is relevant in Europe but the US has more than enough space power transmission is a problem but it's solvable. reply forgotoldacc 10 hours agorootparentJust because the US has a lot of area doesn't mean it should all be paved over and turned into solar farms. \"Who needs nature and green spaces? It could be cheap electricity instead\" is a mindset the next generation will hate us for, just like our generation resents previous generations for thinking \"Why not burn coal? It's cheap electricity",
    "originSummary": [],
    "commentSummary": [
      "Google has agreed to buy power from Kairos Power, a startup focused on developing small modular reactors (SMRs) with a capacity of 75 megawatts each.",
      "The plan includes bringing the first SMR online by 2030, with more reactors potentially adding up to 500 megawatts of carbon-free power by 2035.",
      "This initiative is part of Google's strategy to secure clean energy, though the cost-effectiveness and viability of SMRs compared to renewables and battery storage are still under discussion."
    ],
    "points": 555,
    "commentCount": 472,
    "retryCount": 0,
    "time": 1728932782
  },
  {
    "id": 41846780,
    "title": "Web Browser Engineering",
    "originLink": "https://browser.engineering/index.html",
    "originBody": "Web Browser Engineering Pavel Panchekha & Chris Harrelson Twitter · Blog · Patreon · Discussions Introduction Part 1: Loading Pages Part 2: Viewing Documents Part 3: Running Applications Part 4: Modern Browsers Web browsers are ubiquitous, but how do they work? This book explains, building a basic but complete web browser, from networking to JavaScript, in a couple thousand lines of Python. The cover for Web Browser Engineering, from Oxford University Press Pre-order Web Browser Engineering Web Browser Engineering will be published by Oxford University Press before the end of the year. To get it as soon as it’s out, pre-order now! Follow this book’s blog or Twitter for updates. You can also talk about the book with others in our discussion forum. If you are enjoying the book, consider supporting us on Patreon. Or just send us an email! Introduction Preface Browsers and the Web History of the Web Part 1: Loading Pages Downloading Web Pages URLs and HTTP requests Drawing to the Screen Creating windows and drawing to a canvas Formatting Text Word wrapping and line spacing Part 2: Viewing Documents Constructing an HTML Tree Parsing and fixing HTML Laying Out Pages Inline and block layout Applying Author Styles Parsing and applying CSS Handling Buttons and Links Hyperlinks and browser chrome Part 3: Running Applications Sending Information to Servers Form submission and web servers Running Interactive Scripts Changing the DOM and reacting to events Keeping Data Private Cookies and logins, XSS and CSRF Part 4: Modern Browsers Adding Visual Effects Blending, clipping, and compositing Scheduling Tasks and Threads The event loop and the rendering pipeline Animating and Compositing Smooth animations using the GPU Making Content Accessible Keyboard input, zooming, and the accessibility tree Supporting Embedded Content Images, iframes, and scripting Reusing Previous Computation Invalidation, editing, and correctness Conclusion What Wasn’t Covered A Changing Landscape Appendix Glossary Bibliography About the Authors Contributors List of courses taught from this book One-page version © 2018–2023 Pavel Panchekha & Chris Harrelson",
    "commentLink": "https://news.ycombinator.com/item?id=41846780",
    "commentBody": "Web Browser Engineering (browser.engineering)548 points by MrVandemar 9 hours agohidepastfavorite95 comments mannyv 5 hours agoOne great thing about this book is the 'stuff I didn't do' part. Layout is really hard. Just tables by themselves are hard, even without any css around them. CSS makes layout impossibly difficult. I challenge anyone to keep the whole CSS spec and its associated behaviors in their head. At this point css + html + javascript have become a dynamic PDL, and probably is one of the most complex pieces of software today. As an aside, video decoding is offloaded onto hardware, so it's not as battery intensive as it used to be. reply btown 4 hours agoparentFor the absolutely massive amount of code one needs to implement for production-grade CSS layout, the Servo source code is illustrative and IMO quite cool to see. For instance, this file just implements block and inline contexts; there's a bit of Rust boilerplate here, but the vast majority of lines are \"business logic\" around various parts of the specification. And there's a whole folder of these. https://github.com/servo/servo/blob/main/components/layout/f... But implementing a layout engine is doable. CSS is not magic; there's a spec that can be (meticulously) transformed into code. I've occasionally showed code like this to people frustrated that CSS seems arbitrary, just to show them that there is a logic to the execution environment. Granted, you're not going to regularly click into it the way you'd click into the implementation of a library, but it's no different from something like React in that regard. I think it helps! reply tannhaeuser 3 hours agorootparentFWIW, Pavel, one of the authors, has devoted considerable time into what is one of the very, very few attempts at a formal specification for CSS (the static/float layout fragment cf [1]). It's a Racket program generating Z3 SMT solver code for verifying an instance layout (which also looks like Scheme) so it's not for the faint-hearted ;) but maybe just what an FP fan on HN is looking for as a challenge. [1]: https://pavpanchekha.com/blog/css-floats.html reply pavpanchekha 3 hours agorootparentWow, thanks, you always suspect no one has actually read the papers :) That was a crazy project... I eventually got it passing almost all of the WPT css2 fragment. I'm still working on CSS layout, with hopefully another paper coming soon. reply bloopernova 2 hours agorootparentFor what it's worth, I'm just a devops person and I found that article on How CSS Floats Work to be very understandable :) Thank you for writing all this great stuff! reply tannhaeuser 2 hours agorootparentprevIn that case, you've got at least one avid reader ;) reply pavpanchekha 4 hours agoparentprevYes, layout is difficult, especially because (I think): 1. The most \"core\" parts of layout, like CSS 2 stuff, is pretty poorly considered with a bunch of weird features that interact in strange ways. (Floats and clearance? Margin collapsing?) Some parts of this \"core\" were intended to be universal even though they're a bad fit for other layout modes. (Margin and padding, for example, don't have a clear purpose for say grid elements.) 2. It's not well-modularized the way JS APIs are. A JS API can often be implemented fairly stand-alone, but each layout module interacts with every other layout module since they can be nested in various ways. I think newer specs like grid are trying to be stricter with this but there are fundamental challenges: the actual 2D screen is a shared resource that different layout modes must split up. reply fouric 3 hours agoparentprevLayout is so difficult that it made me quit using Common Lisp and ncurses to build my passion project and become the very thing I swore to destroy (a React developer). I can't be the only one who wants a simpler layout language than CSS that's designed with two decades of hindsight to provide the maximum simplicity-expressiveness product. Are there any serious projects to engineer something like this, or has everyone given up and either embraced CSS3 (waiting for the LLVM backend) or gone back to plain text? reply pavpanchekha 1 hour agorootparentAuthor here, and I also teach web dev, including CSS, at the University of Utah (including this semester). Newer parts of CSS, like flex-box layout are both simple and powerful. Just use those! I think it's important to start thinking about learning all of the Web Platform like you'd think about learning all of the Windows APIs or all of the Linux system calls or all of your favorite programming language's features. People rarely do! (I have 15 years of Python experience, and I do not understand metaclasses or async.) There are lots of weird obscure corners, but you don't need to know those to build websites. reply meindnoch 2 hours agorootparentprevConstraint-based layouts. The world's most sophisticated UI system uses that (Apple's UIKit). reply syndeo 2 hours agorootparentprevLLVM backend for CSS3? (This must a joke, right??) reply throwup238 14 minutes agoparentprevModern CSS implementations are full blown geometric constraint solvers now. The only things approaching their algorithmic complexity are now other geometric constraint solvers like CAD kernels and silicon layout software. reply DanielHB 3 hours agoparentprevFor React Native the facebook engineers just gave up and were like \"all you get is flexbox layout\" and people were quite okay with that (although some people grumble about lack of display grid) https://github.com/facebook/yoga reply skydhash 1 hour agorootparentIt works great for small devices, but I prefer ios constraint layout (and I think android got it too). No need for spacers. reply vbezhenar 4 hours agoparentprevThis Babylonian tower will crumble one day. Layout does not have to be so complex. There are dozens of GUI frameworks with simpler layout system. Those are enough for applications everyone uses. reply PaulDavisThe1st 3 hours agorootparentActually, almost every GUI toolkit's scheme for layout has issues, and none of them are perfect. The ones that use absolute pixel positioning fail when using different resolution displays. The ones that use box packing fail when you need to deal with different sized displays. The ones that use constraint programming fail when you need to layout hundreds or thousands of widgets. CSS-style layout has its own pros and cons, but there is no alternative to it that is clearly better under all circumstances. If you doing layout and want to be resolution-independent, function on everything from phones to giant displays and have thousands of things to layout, CSS is actually likely better than any alternative. reply msie 17 minutes agorootparentprevPixel positioning is so nice! I remember how easy it was to layout UIs with VB. reply maxwell 2 hours agorootparentprevWhich do you recommend? reply pstrateman 5 hours agoparentprev> As an aside, video decoding is offloaded onto hardware, so it's not as battery intensive as it used to be. This is technically but not usefully true with most videos on the web today. The video decode itself is accelerated, but each frame passes through JavaScript to be composited. The only time video is fully hardware decoded is when it's a simple video element to a static video file. reply pjc50 4 hours agorootparent> The video decode itself is accelerated, but each frame passes through JavaScript to be composited I don't think that's true, and it's even less true once DRM video is involved - it becomes very difficult to get other software on the machine to even see the video, at least on Windows. You can very occasionally see bugs where the hardware accelerated playback ends up in a different place to where the browser thinks the video should have been put, too. What does happen is the video data gets reassembled in Javascript (e.g. Video.js) because the native player doesn't support HLS. Not quite the same thing. It's just reformatting MPEG-TS to the similar but not identical MP4. Oddly, the browser in my LG TV does play HLS video natively, and I think Safari does? reply afavour 4 hours agorootparentprev> not usefully true with most videos on the web today > The only time video is fully hardware decoded is when it's a simple video element to a static video file. These seem in disagreement to me. The vast majority of videos on the web are simple video elements going to static video files. It is not usual for each frame to pass through JavaScript before being displayed. reply pavpanchekha 4 hours agorootparentprevI think by \"JavaScript\" here you mean rendering—that's partially true. In macOS and Windows these days (also I think Linux with GTK4 on Wayland, though only in a limited way), the window manager is itself composited and a window can send a small display list to that window manager for it to composite. In that case, it's possible to actually have the video decoding to happen entirely in hardware and never have the browser directly interact with decoded video bits. That said usually the window manager compositor is pretty limited and the browser will only do this when the stars align. The sort of things that can break it are any kind of weird clipping, transparency, or effects applied to the videos. reply incrudible 4 hours agorootparentprev> each frame passes through JavaScript to be composited What do you mean by that? There is no Javascript doing the actual compositing, and the actual compositing is (usually) hardware accelerated. reply sylware 5 hours agoparentprevyep, namely noscript/basic (x)html. reply paulddraper 3 hours agoparentprev> I challenge anyone to keep the whole CSS spec and its associated behaviors in their head. Lol, no way. People are always \"guess what JS does, wut.\" Doesn't hold a candle to Cascading Stylesheets. reply jm4 6 hours agoprevThis looks awesome. About 15 years ago, I started working on a headless browser and maintained it for several years. It used SpiderMonkey as the js interpreter and had a custom DOM implementation. It ran all the modern js from the time, AJAX, etc. Later, I added a custom Flash runtime. It basically did everything but draw to the screen. That project was a lot of fun. I'm definitely interested in going through this book. reply aitchnyu 6 hours agoparentUmm, if you wanted/want to draw to the screen, what library will you use? reply pavpanchekha 5 hours agorootparentThe book uses Tk (via Python's tkinter library) for the first 10 chapters and then switches to Skia, which is used by maybe all of the browsers now (I believe Webkit on Linux just switched to it from Cairo). It seems to be by far the most common high-performance 2D graphics library. reply jm4 1 hour agorootparentprevI didn’t have a clue. That wasn’t part of my skillset. All we needed was a headless browser that was automated. It was crawling a few million pages a day. I had a debug console where I could see cached pages, headers, cookies, etc. reply skeeterbug 6 hours agorootparentprevI believe Chrome uses Skia reply lesuorac 6 hours agorootparentYes [4]. > [1] The library is used as of 2023 in Google Chrome, ChromeOS, ChromiumOS, Mozilla Firefox, Mozilla Thunderbird, Android, Firefox OS, Flutter,[5] Avalonia (from Alpha 4), LibreOffice (from version 7.0) and RAD Studio[6](since version 12.0). > [2] Changes to the Skia repository will be rolled into Chromium by the AutoRoll bot several times per day. > [3] It serves as the graphics engine for Google Chrome and ChromeOS, Android, Flutter, and many other products. [1]: https://en.wikipedia.org/wiki/Skia_Graphics_Engine [2]: https://skia.org/docs/dev/chrome/ [3]: https://skia.org/ [4]: https://github.com/chromium/chromium/tree/main/skia reply mnutt 4 hours agorootparentAs of 2024, WebKit's Linux ports (GTK and WPE) are switching to Skia too. [0] Prior to that, they used cairo. [0]: https://blogs.igalia.com/carlosgc/2024/02/19/webkit-switchin... reply pmarreck 4 hours agorootparentprevWhoa. Somehow I have not heard of this. Can this be used to make cross-platform GUI apps? reply Rohansi 4 hours agorootparentSure you can, it's a 2D graphics library. It's more like the JS Canvas API though instead of a UI framework. reply PaulDavisThe1st 3 hours agorootparentWhich rather importantly means that you still need to find something else to do: * layout * event handling which are not exactly trivial for a \"real\" application (whatever that means). reply pradmatic 2 hours agoprevI've been looking for a fun project to start and I'm already thoroughly enjoying this book. Kudos for making the writing particularly engaging. This comic book about how Chrome works is also a great place to get started: https://www.google.com/googlebooks/chrome/med_00.html reply currygen 5 hours agoprevIt's refreshing that browser engineering seems to become a \"trend\" now. The ecosystem is quite sparse with basically only Google, Apple and Mozilla defining it. I'd like to see forward into a future with more independent browser engines. reply mike_hearn 5 hours agoparentI don't think it's worth trying to write a rendering engine for HTML. You will never finish - HTML is a spec fully owned by Google and Apple at this point and it's just too complex to implement from scratch. The interesting space is really post-HTML UI/document tech. There's another thread running about Typst which is a sort of better LaTeX. Markdown was highly impactful. There's a lot of scope for people to do interesting things in this space that are \"HTML but better\". It doesn't even have to be a markup format - Typst and React HTML both blur the lines between code and data. Jetpack Compose shows how to use Kotlin's DSL features to make something that looks a bit like a UI description but which is actually code. Of course it means you have to then either distribute a 'browser' for your format, or find a way to display it in the browser. But compiling down to some JS/HTML/WASM thing is certainly possible. You can also use portable GUI toolkits like JavaFX; that also gives you accessibility. Or do both! Once you define your own UI language there's a lot of scope to try things that HTML doesn't do well. An obvious one is separation of content and style. HTML tried and never really got there. XSL:T tried harder but was a weird pure functional language with XML as its syntax. React does quite well with going JSON->boxes but the underlying protocols are always ad-hoc and tacked on, so you can't really write useful tooling on top of that. Another idea would be a format that's natively immune to XSS. reply berkes 2 hours agorootparent> I don't think it's worth trying to write a rendering engine for HTML. You will never finish - HTML is a spec fully owned by Google and Apple at this point and it's just too complex to implement from scratch. This keeps being repeated. But it leans on three false assumptions. - That is has to be \"finished\" at all. For many use-cases, a subset (of a subset) might just be fine. The screen in my refrigerator, or the information display in a train, might want to render some HTML, but when the HTML is controlled and constrained, there's no need for \"everything\". - That is has to adhere to \"the spec\". See above, but also if the HTML+CSS+JS is less controlled, quite a few use-cases it's fine to ignore lots of the quirks or even large parts of the specs. Even Chrome and FF don't implement \"all\", whatever \"the spec\" might be in the first place. But a browser in a TV set-top box, my e-reader, some dedicated wikipedia-device, or the \"help section of an app\" are fine if they break on complex sites. - That is must be implemented from scratch. Even if you forego the big rendering engines, JS VMs and so forth, there's a lot of libs that do DOM handling, CSS parsing, JS runtime etc. There's a lot of shoulders to stand on, aside from \"just run chrome headless\". By repeating this mantra that its not worth \"building a new browser\" or \"rendering engine\", we only cement the status quo further. And promote the idea that your car, refrigerator, test-runner, help-section, dashboard, e-reader and whatnot must run either a full chrome or firefox. We stiffle innovation. reply btown 4 hours agorootparentprevAnother thing you can feasibly do is implement flexbox or a similar useful subset of layout! https://www.yogalayout.dev/ is one such library that powers React Native. Letting people bring CSS intuition when writing greenfield code for a simpler engine can be a great way to onboard users. reply 01HNNWZ0MV43FF 5 hours agoparentprevSomething that uses less RAM would be nice. Other than that and the spyware from Capital-G Google Chrome and Capital-M Mozilla Firefox, I don't have a problem with it being sparse. It's millions of hours of de-duplicated work. I'd like an alternative to HTML though. If I was to make a browser maybe I'd focus on replacing HTML because I can't stand it, and replacing js just because the runtime is heavy. Like, a browser that only runs wasm and has nearly no JS runtime would make me giggle reply PaulDavisThe1st 2 hours agorootparent> Like, a browser that only runs wasm That's not a browser. More or less by definition, a browser is an application that can use HTTP (and potentially other protocols) to make requests to other systems and retrieve stuff described using HTML (and possibly other formats). Sure, a tool that just loads wasm and executes it would be fun (and probably exists, at least for the local case). But it's not a web browser. reply 01HNNWZ0MV43FF 2 hours agorootparentAs opposed to current browsers that run wasm and JS I mean Yes there would be a DOM in addition reply vivzkestrel 1 hour agoparentprevhave you by any chance looked into alternative browser engines such as servo, ladybird, goanna, netsurf, sciter, flow etc? reply pmarreck 4 hours agoparentprevOr perhaps an entirely new platform/protocol, since this one is completely saturated with complexity at this point. reply amjoshuamichael 16 minutes agorootparentI keep coming back to this idea as the (albeit ideal) future of the web. HTML keeps morphing and changing to fit the increasingly complex requirements of modern web apps. I mean the W3C spec is 114 million words (1). I think that web apps as a concept are a good idea, but I just can't believe that HTML/CSS/JS are the best technologies to fill that out. I'd love to see someone tackle a new, \"micro-sized app format\", with a much simpler document format, and something like a FORTH as a scripting language. Uxn (2) and Decker (3) are good examples of this, but obviously a proper implementation would have to be built with the full range of possible UI and accessibility in mind, not just monochrome bitmap displays. A web standard so simple, anyone can implement it! One can dream... (1) https://drewdevault.com/2020/03/18/Reckless-limitless-scope.... (2) https://100r.co/site/uxn.html (3) https://internet-janitor.itch.io/decker EDIT: There is Project Gemini (https://geminiprotocol.net/), but it doesn't support styling or scripting. reply pavpanchekha 5 hours agoprevOne of the authors here—thank you all for the nice words. Happy to answer questions! reply _benj 6 hours agoprevIt is so exciting to see material like this being made! Browsers seem like mysterious, undecipherable black boxes, which is very likely how G wants them to be perceived, but that is cracking by seeing the efforts/results of such projects like ladybird and others! I hope to one day be able to jump in and contribute to break that moat! And this books looks like an amazing start! reply lewisjoe 5 hours agoparent> which is very likely how G wants them to be perceived One of the authors of the book is Chris, who leads the Blink rendering team at G :) reply wmanley 6 hours agoparentprev> I hope to one day be able to jump in and contribute to break that moat! The moat isn't caused by a lack of non-chrome browser engines, it's because so few people use a non-chrome browser engine. Firefox already exists - it's just that ~no-one uses it and for websites that don't work with it those users have learnt to just open up chrome. I'd love for the moat to be broken, and contributing to a browser engine like ladybird would be fun - but it doesn't contribute to breaking the moat. I'd love to know what would. reply DavidPiper 6 hours agorootparentI'm one of those ~nobodies. Firefox is actually quite good these days, I use it at home and at work, 100% of the time - i.e. no Chrome or Safari fallback needed. If anyone's looking for a reason to try a switch again, consider this your sign. reply mattlondon 5 hours agorootparentIs the performance hit sorted yet when opening a page? For me Firefox used to hang for a second or two doing something? Just a blank screen with the progress bar paused around 20% or so and apparently nothing happening...(DNS? HTTPS handshake?) and then it would kick off and load normally. Happened on mobile(android) and desktop(windows, Linux, macros). On chrome-based browsers the same pages on the same computers on the same network would load in within the blink of an eye, with no pause. I eventually gave up and went back to chrome after Firefox being my daily for years. I prefer the dev tools in chrome anyway TBH reply 01HNNWZ0MV43FF 5 hours agorootparentSorry to say but I've never seen that bug reply wmanley 2 hours agorootparentprevI use Firefox too, and I agree it is great - which goes to show that having a great browser engine is not enough to break the moat. reply abudimir 5 hours agorootparentprevSame here. I have Safari and Chrome only for cross browser testing. reply pmarreck 4 hours agorootparentprevFirefox is great. I use Nightly. Sync bookmarks and everything. Chrome completely unnecessary. reply pavpanchekha 5 hours agoparentprevI'm one of the book's two authors (the other is the head of Blink Rendering!) and I've talked to a number of people on the Chrome team. None of them have struck me as trying to keep browsers mysterious! On the contrary, folks who work on Chrome, Firefox, Safari, and Ladybird all seem incredibly excited to talk browsers and discuss how they work. The world of browser development is surprisingly small, the engineers often move between companies, and I think it'd be tough to keep a \"conspiracy\" going. But I do think there's a real lack of teaching material (why I wrote the book) and even \"common vocabulary\" to discuss browser internals, especially for the core phases like layout and raster, which is something Chris and I are hoping to create with the book. reply awesomekling 5 hours agorootparentCan confirm, am incredibly excited to talk browsers and discuss how they work! (Hi Pavel, love the book!) reply CrayKhoi 7 hours agoprevI've been levelling up on browser internals, and this book is awesome. It helps build up intuition on how browsers work, without going through the millions of lines of chrome code. reply mananaysiempre 7 hours agoparentnext [5 more] [flagged] kaptainkarl 7 hours agorootparentAs a native English speaker, yes that is kinda weird to be \"incredibly irritated\" by a sentence that's completely normal and well constructed. reply mmkos 6 hours agorootparentprevWith all due respect, this feels better suited as a journal entry rather than a comment on a HN thread. reply mananaysiempre 6 hours agorootparentPerhaps, but it would have been of little use as a question there. Once you acquire enough of a feeling for a foreign language that not every bit of your skill in it comes from somebody telling you that a particular thing is said in a particular way, you are doomed to live with a constant suspicion that your feeling is somehow off in a way you don’t recognize. Usually it can be suppressed and ignored, but sometimes it can’t, and occasionally it has to become a question. (I expect this is a fairly common experience.) This was one of those. reply jgwil2 4 hours agorootparentI'm not sure about your point about \"leveling\" vs \"leveling up\", because for me, \"leveling\" means making a surface level/flat and does not have any video game-related meaning, but the \"on\" is probably coming from the phrase \"to read up on\" something (meaning to study/read about something; there's also a slangier variation, \"to bone up on\" something). reply bafatik870 2 hours agoprevhttps://github.com/mpospese/MPFoldTransition/issues/27 https://github.com/ccoenraets/backbone-directory/issues/14 https://github.com/oreillymedia/open_government/issues/8 https://github.com/jbangert/trapcc/issues/5 https://github.com/gpjt/webgl-lessons/issues/13 https://github.com/ieure/sicp/issues/7 reply adr1an 1 hour agoparentCare to elaborate? I've just noticed those are links to comments that are spam and the account was deleted on github. reply bloopernova 2 hours agoprevThis is wonderful! I had an opportunity to run a tutorial on basic command line usage for newer software engineers. It's always fun to see people's expressions or read their reactions to seeing me telnet to port 25 and 80. reply austin-cheney 5 hours agoprevNice book. I would recommend splitting chapter 9 into two separate chapters where executing JavaScript via Duktape is one chapter and then interacting with the DOM and events are a separate later chapter. reply pavpanchekha 5 hours agoparentIt might be best read in two sittings! The chapters get longer as the book goes on and tackles more advanced topics, and I do recommend following along in code as you progress through the book. reply bberrry 7 hours agoprevI'm so incredibly thankful that there are people like Pavel and Chris putting effort into articles like this. You are truly the best of us reply farmeroy 3 hours agoprevThis is amazing, I just want to drop everything and start digging through this. Well done! reply ilaksh 5 hours agoprevHere's my idea https://github.com/runvnc/tersenet reply systems 4 hours agoprevwhy python, why not a system programming language like C, OCaml or Go (or newer languages like zig or odin) Are web browsers, not considered to be \"system software\" reply dvektor 4 hours agoparentI think the point is to demonstrate how things work and are designed, and python is easy for everyone to understand. I don't think the author is recommending trying to write a production web browser in python. (or probably at all ;) reply pavpanchekha 3 hours agoparentprevAuthor here, I wrote about this on the blog: https://browserbook.substack.com/p/why-python Basically, performance isn't a big focus, Python is very widely known and doesn't have too many quirks for non programmers to deal with, and systems languages emphasize error handling that, for expedience, we often need to skip. reply nindalf 4 hours agoparentprevGoing to take a wild guess that maybe they're going to rely on the excellent, extensive standard library of Python which C and Zig can't compete with. The second constraint was probably that they want to keep the number of lines of code low to encourage more people to buy the book. That's where Python does better than Go - you can do a lot with list comprehensions and you don't have if err != nil every few lines. reply pavpanchekha 3 hours agorootparentDefinitely the second reason, but we actually try hard not to use too much of the standard library, for easy porting. But it's nice that sockets & ssl are standard, plus a (bad) GUI library. reply FartyMcFarter 4 hours agoparentprevThey definitely are system software, since they include compilers and interpreters, software libraries and other such things which AFAIK have always been considered system software. Browsers these days are about as complex as any operating system, or perhaps more complex when you consider all the non-systems stuff in them. reply mvesto 2 hours agoprevThis is awesome! Nice work reply asicsp 7 hours agoprevSee also this previous discussion: https://news.ycombinator.com/item?id=28898157 (409 pointsOct 19, 202163 comments) reply andai 7 hours agoparentThe author's post explaining why Python was chosen: https://browserbook.substack.com/p/why-python Apparently some of it now runs in the browser (\"in the book itself\") by compiling Python to JS? https://browserbook.substack.com/p/compiling-python-to-js reply globalnode 6 hours agorootparentwriting it in python makes me actually want to read the book, in fact i definitely will give it a read. if it was done in rust or go id probably skip it, and c++ is just too hard to look at for a fun project. will come back after reading and hopefully have something more meaningful to say about it. reply wai-dang-loveme 56 minutes agoprevTesting reply adhamsalama 4 hours agoprevWould be nice to have the option to download it as an epub to read it on my e-reader. reply abixb 1 hour agoparentMy thoughts precisely. I wish there was a service that could convert book-length webpages into neatly formatted ePUB document. I did find a 'converter', [0] but the service has tons of room for improvement. [0] https://www.freeconvert.com/webpage-to-epub reply adhamsalama 4 hours agoprevLooks very cool, will definitely read it! Thanks! reply wslh 4 hours agoprevIs there a promotional code for HN? I was a happy user of HTMLUnit [1] with Jython [2] in the past and am very interested in a future where we can automatically generate portions of browser code using code generation and verification techniques. I've never felt as comfortable with tools like Playwright/Cypress/Selenium as I did with HTMLUnit (with all due respect to both). [1] https://htmlunit.sourceforge.io/ [2] https://www.jython.org/ reply pavpanchekha 2 hours agoparentThe book isn’t out yet, so no promo code, but the whole thing is free online. reply wslh 2 hours agorootparentThank you for your prompt response. I understand the item isn't available, but I clicked the \"Add to Cart\" button thinking it would either place me on a waitlist or ship once available. However, I was then prompted to enter a promo code, which caused the confusion. reply pavpanchekha 1 hour agorootparentAh, weird! We can ask our publisher. This HN post was a surprise (Chis & I didn’t put it up) so we weren’t prepared. reply julenx 1 hour agorootparentprevI was able to pre-order the book just fine — it didn't prompt me for any promo codes. reply keepamovin 8 hours agoprevhey, this book looks cool! well done :) reply pavpanchekha 2 hours agoparentThanks! reply pmarreck 4 hours agoprev [–] I hope the AI gets good enough to dynamically translate from one language to another with high reliability, in case not everyone is a fan of Python reply cyral 2 hours agoparent [–] It is, ask claude to translate a file and it can do it pretty flawlessly. reply udev4096 2 hours agorootparent [–] Of course it does. LLMs are only good for small scale tasks reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Web Browser Engineering\" by Pavel Panchekha & Chris Harrelson is a book that guides readers through building a basic web browser using Python, providing insights into how web browsers function.",
      "The book, published by Oxford University Press, covers essential topics such as networking, JavaScript, and the workings of modern browsers, making it a valuable resource for understanding web technologies.",
      "It includes practical sections on loading pages, viewing documents, and running applications, offering a comprehensive learning experience for those interested in web development and browser engineering."
    ],
    "commentSummary": [
      "\"Web Browser Engineering\" is a book that delves into the complexities of browser development, particularly focusing on CSS layout and video decoding challenges.- The book uses Python to illustrate browser concepts, making it accessible for learners and encouraging innovation in browser technology.- It emphasizes understanding browser internals and explores the potential for new user interface technologies."
    ],
    "points": 549,
    "commentCount": 95,
    "retryCount": 0,
    "time": 1728985349
  },
  {
    "id": 41848150,
    "title": "I built the most over-engineered Deal With It emoji generator",
    "originLink": "https://emoji.build/deal-with-it-generator/",
    "originBody": "Hi, all! Author here. What started as a small tool I built for a job interview, became \"The Most Over-engineered Deal With It Emoji Generator\":- All operations done fully client-side - no backend, no private data leaves your browser. - Uses machine learning models (MediaPipe Face Detector task) to automatically scale and position glasses on the detected faces. - Extensive customization options for glasses: - Placement of glasses anywhere on the input image (including slightly going outside it). - Change the size of glasses. - No limit on the number of glasses. - Flip the glasses vertically or horizontally. - Customize the direction from which the glasses appear on the image. - Different types of glasses. - GIF output options: - Looping mode. - Number of frames. - Frame delay. - Separate delay setting for last frame. - Output size. - Celebration confetti - Easter eggs.I&#x27;ve been working remotely for the last >9 years. When using non-verbal communication, it&#x27;s important that your tone and intent comes across accurately.. Custom emojis became for me part of expressing yourself, creating bonds and camaraderie. I&#x27;ve originally created an MVP of this tool while applying for a exciting new job opportunity. As a showcase of my passion for programming, building teams and creating delightful user experiences. Unfortunately, they were not impressed and ultimately did not offer me the job :( But I wanted to polish it and release it for everyone to use for free, so that you can too \"Deal With It\"!I have more ideas for even more features (check GitHub[1]), but wanted to launch it and see what&#x27;s the feedback and ideas from the community! And if you&#x27;re looking for a Fullstack Developer with >14 years of experience, with passion for great customer experience (remote work or locally in Iceland), let&#x27;s chat![1] - https:&#x2F;&#x2F;github.com&#x2F;klimeryk&#x2F;dealwithit",
    "commentLink": "https://news.ycombinator.com/item?id=41848150",
    "commentBody": "I built the most over-engineered Deal With It emoji generator (emoji.build)422 points by klimeryk 5 hours agohidepastfavorite83 comments Hi, all! Author here. What started as a small tool I built for a job interview, became \"The Most Over-engineered Deal With It Emoji Generator\": - All operations done fully client-side - no backend, no private data leaves your browser. - Uses machine learning models (MediaPipe Face Detector task) to automatically scale and position glasses on the detected faces. - Extensive customization options for glasses: - Placement of glasses anywhere on the input image (including slightly going outside it). - Change the size of glasses. - No limit on the number of glasses. - Flip the glasses vertically or horizontally. - Customize the direction from which the glasses appear on the image. - Different types of glasses. - GIF output options: - Looping mode. - Number of frames. - Frame delay. - Separate delay setting for last frame. - Output size. - Celebration confetti - Easter eggs. I've been working remotely for the last >9 years. When using non-verbal communication, it's important that your tone and intent comes across accurately.. Custom emojis became for me part of expressing yourself, creating bonds and camaraderie. I've originally created an MVP of this tool while applying for a exciting new job opportunity. As a showcase of my passion for programming, building teams and creating delightful user experiences. Unfortunately, they were not impressed and ultimately did not offer me the job :( But I wanted to polish it and release it for everyone to use for free, so that you can too \"Deal With It\"! I have more ideas for even more features (check GitHub[1]), but wanted to launch it and see what's the feedback and ideas from the community! And if you're looking for a Fullstack Developer with >14 years of experience, with passion for great customer experience (remote work or locally in Iceland), let's chat! [1] - https://github.com/klimeryk/dealwithit zamadatix 2 hours agoThis is 100% the kind of thing I was hoping for when daydreaming \"what will the internet be like 20 years from now\" growing up. Cool design, hilariously overpowered backend to do something basic (but do it so well), and 0 of the corporate feeling or ad apocalypse. Awesome stuff! reply klimeryk 1 hour agoparentHahah, so true! One clarification, though: while I'm sure the backend is overpowered (Cloudflare Pages, easily handling the Hug of Death from HN), but in this case it's only serving static resources. All the hard work is done by the hilariously overpowered devices we carry in our pockets or use for everything but serious work ;) reply zamadatix 1 hour agorootparentOh 100%, the hosting is more than fitting. I had meant to refer to the app's non-UI code (machine learning to place meme glasses)! Apologies for the lack of clarity. reply klimeryk 1 hour agorootparentAh, gotcha! Hahah, yeah, I'm sure this is exactly the use case folks were thinking of when dreaming of AI applications decades ago... reply think_build 0 minutes agoprevI love over-built projects. Do not worry about the job offer, the current market is posting job offers that do not exist. reply ChrisArchitect 30 minutes agoprevThank you Slack? For the confusing use of \"emoji\" instead \"animated GIF\" or sticker. reply andybak 4 hours agoprevI love it: https://s1.gifyu.com/images/SB5A9.gif reply pieter_mj 2 hours agoparentIsn't that a child eating creature? reply mattnewton 2 hours agorootparentSaturn, yes https://en.m.wikipedia.org/wiki/Saturn_Devouring_His_Son reply pieter_mj 2 hours agorootparentty. uv. reply airstrike 4 hours agoprev> Unfortunately, they were not impressed and ultimately did not offer me the job :( Sorry to hear that. No recruiting process is perfect. They often get it wrong, as they clearly did here! reply com2kid 1 hour agoparentI interviewed a developer once who was super junior on paper but had a side project of a fully featured desktop anime episode to watch/watched tracker with lots of library feature features. Hire. Interviewed another Dev who made arcade sticks as a side project. Hired. You can't teach passion. Hire all that passionate people you can. Tech stacks are irrelevant compared to the love of building things. reply pc86 9 minutes agorootparentAlso a great filter from the other side. I was not hired once because I didn't have React experience, despite having years of both Vue and Angular and having led teams building non-trivial apps in both. IME focusing on such a minor detail like that means either a) you're going to be so pressured to get stuff out of the door they can't handle slightly lower productivity for a month while you learn the different syntax, and/or b) the person hiring you isn't technical enough to know this is a minor detail. Either way, better off somewhere else :) reply Aeolun 3 hours agoparentprevThe only thing I can imagine is that they were up against someone making a partyparrot generator. reply cheschire 3 hours agorootparentMust've been this person: https://parrotify.github.io/ reply klimeryk 3 hours agorootparentprevHahaha, genuinely laughed out loud, thank you! (also, big fan of partyparrot, of course) reply klimeryk 4 hours agoparentprevThank you! Yeah, I totally understand and not taking it against them. It's impossible to always get the right impression and fit for the candidate (even if it was based on a few interviews and trial, like here). So I figured I'd make the best of the situation and share the project with others! Hoping to make some new connections this way, and maybe find an even better opportunity! reply aio2 2 hours agoparentprevYeah, this is pretty cool and they can fuck off. reply bewuethr 2 hours agoprevA rudimentary version of this used to be integrated into Giphy[1], but it seems to be broken now, meaning the market is wide open for this! ;) [1]: https://giphy.medium.com/the-secret-giphy-slack-commands-9cb... reply asdfman123 1 hour agoprevI'm a Google employee. After looking at this demo I can tell you're spiritually a Googler in ways I can't quite articulate. reply underlines 2 hours agoprevThe company who didn't hire you will soon use your tool because they feel remorse for not hiring you, and now they have to \"deal with it\" reply klimeryk 1 hour agoparentWell, I'm using their tool in mine (hint is in one of the Easter Eggs... or just look at what's powering the product analytics ;)). So it's an ouroboros of open-source :D reply steve_adams_86 2 hours agoprevThanks for sharing this. I love tiny projects like this, especially if they’re over engineered. The job market is rough. I have no doubt you were considered, and they were interested, but everyone is giving their all right now. Someone likely submitted something even cooler, somehow. reply yieldcrv 2 hours agoparent> somehow yeah by recycling their project from a previous interview and adding more to it I just don't engage in that kind of assessment anymore, the job market isn’t thaaaat tough to need to compromise or, put another way, jumping through that hoop will not solve your interview progress as its just far too subjective. other hoops are just as fine reply klimeryk 1 hour agorootparentTo clarify - I wrote this tool as my own initiative. On top of the \"normal\" process (that involved multiple interviews and a day paid trial). I was really excited about the opportunity and wanted to go the extra mile. reply gxs 1 hour agorootparentprevDude I’m often on interview panels and some of the other interviewers are insufferable. When they give feedback, they love getting on their soapbox and critiquing others as if they were Olympic judges or something. I’ve had to hold myself back from saying bro we wouldn’t hire you yourself if this criteria actually had to be met. Some hiring managers require all this elaborate prep work and it’s such bullshit, imo it’s a total cop out to have people do so much work as part of the interview process. It’s the lazy way of evaluating someone versus thoughtfully putting together a good hiring process and conducting effective interviews. reply TZubiri 4 hours agoprevThis is useless, I can't make the glasses come from below, in addition to coming from above. Also, glasses can only be black? We demand a color palette for glass colour. EDIT: wait, I managed to make the glasses come from below blob:https://emoji.build/50c07035-efb9-4341-9205-30adfd6b088e I retract my indignation on the one half of my requests, but transfer it doubly so for the request of a colour palette reply barryrandall 3 hours agoparentThat feature was removed because half the people who want black frames were offended that the app offered options that they didn't want to use. reply TZubiri 3 hours agorootparentWhat's interesting is that the moment that you introduce a feature that allows for sharing of the images, and you need a backend to host the images. You enter a world of pain where you inevitably will end up hosting illegal material, and it turns from a fun project to a serious project. reply klimeryk 3 hours agorootparentYeah, that's why I'm keeping everything client-side. There's no backend. This is hosted on Cloudflare Pages, everything on the backend is static. Definitely not looking to host any generated images. reply mnutt 1 hour agorootparentOn Mobile Safari at least, you can press and hold the image to share. I imagine there's probably an equivalent gesture on Mobile Chrome. I spent considerable time many years ago trying to figure out how to indicate to users that they could do this. (\"press and hold to share\", with a progress indicator) Results were mixed. Fortunately, these days if you wanted to make it more obvious you could hook up a regular Share button to navigator.share() API and pass it your image blob. reply cheschire 3 hours agorootparentprevThose responsible for sacking the people who have just been sacked, have been sacked. reply klimeryk 3 hours agoparentprev> We demand a color palette for glass colour. You can choose different styles of glasses. But, yeah, they're all black-ish. Definitely open to different colors/styles! I've created a new issue with some possible solutions and will look into it: https://github.com/klimeryk/dealwithit/issues/33 (but PRs are welcome too!) reply m2fkxy 4 hours agoprevit's useless thence I love it. I lied, in fact I just used it to create a couple Slack emojis. reply klimeryk 4 hours agoparent> it's useless thence I love it. That's what kept me going while adding more features :D Just the joy of creating something so useless, but still capable of bringing smile to my (and hopefully your too!) faces. Glad you love it! reply i_am_a_squirrel 40 minutes agoprevThank you OP. I needed this. reply silisili 1 hour agoprevThis is actually really neat. I like the configurability. Is there an option to change glasses size that I missed? I think that's the only thing I noticed I couldn't do when playing around with it. * Found it, there is a small indicator in bottom right of glasses that allows dragging out to resize. Thanks all! reply tonymarks 1 hour agoparenton a desktop you can click the glasses to resize them reply klimeryk 1 hour agorootparentOn mobile it should work too (at least when I tested on recent iPhones). The drag handle is a bit small, though. Just aim for bottom right corner of the glasses. reply _puk 1 hour agoparentprevDrag to resize reply jihadjihad 3 hours agoprevIt's great. I wish you could paste an image URL too, that would be slick. Oh, and it would be cool to have an option for the meme text to go under the image too, and to appear in the final frame of motion for the glasses. For now, I can DEAL WITH IT! reply klimeryk 3 hours agoparent> It's great. I wish you could paste an image URL too, that would be slick. Good suggestion - implemented in https://github.com/klimeryk/dealwithit/commit/12c2254e4a1e5f... > Oh, and it would be cool to have an option for the meme text to go under the image too, and to appear in the final frame of motion for the glasses Yup, on my radar! Upvote on GitHub: https://github.com/klimeryk/dealwithit/issues/31 reply ninju 3 hours agoprevFound a bug If *after* generating a gif you change the gif size (bigger in my case) the new gif has the sunglasses appear in the same place. But if I change the size first and then generate everything work fine. Hope I explained it right reply klimeryk 3 hours agoparentI immediately knew what you meant, because I ran into the bug while testing earlier today and apparently forgot to file it. So thanks for reporting - I've filed it now properly and should have it fixed soon. reply Krei-se 2 hours agorootparentHey man, awesome job and while i'm hitting that same bug: Changing to 512px does not resize the glasses for me and it's on the wrong placement. This is great for mastodon replies so PLEASE make this work. Hang tight! reply klimeryk 1 hour agoparentprevShould be fixed by https://github.com/klimeryk/dealwithit/commit/7728d06c90c437... As the classic saying goes: > There are only two hard things in Computer Science: cache invalidation and naming things. reply klabb3 4 hours agoprevUsed in WhatsApp on iOS the last frame didn’t stay, it seems to stop instantly and/or loop back to too early. IIRC I used 20 frames, 250ms between frame and 2500ms for the last one. Seems to have a similar problem on Telegram. Otherwise incredible. The customization options are much appreciated. reply summermusic 3 hours agoparentThis is a known problem for Telegram at least. It cuts off the last frame regardless of that frame's duration. I work around this by adding a single identical frame for 1ms at the end of the GIF. Source: I've made way too many GIFs for Telegram. reply eezing 4 hours agoprevGreat way to promote yourself. Well done! reply teqsun 4 hours agoprevThat's fantastic stuff! Minor UX notes: - clicking the header doesn't navigate back to the \"home\" screen - singular page history (so the back button doesn't take you back to the previous page state) Combined it made it not intuitive for me how to \"get rid\" of the selection I'd created (I eventually figured it out, but the previous two points were what I intuitively tried first) reply klimeryk 3 hours agoparent> clicking the header doesn't navigate back to the \"home\" screen - singular page history (so the back button doesn't take you back to the previous page state) Could you describe in more detail this? I'm not sure I agree that state changes should be pushed to browser history. In my experience this usually leads to confusing user experience. But that might be also just years of conditioning and I'm missing some best practices. So happy to learn more. reply ryandrake 3 hours agoprevInfinite spinner for me: Stuck at \"Loading AI models for face detection...\" forever. I'd want to fix that before sharing it with recruiters as an example project. Desktop Safari 18.0.1 (18619.1.26.111.11, 18619) reply klimeryk 2 hours agoparentAny console errors? reply ryandrake 2 hours agorootparentYep, a bunch of warnings and then: Unhandled Promise Rejection: Error: StartGraph failed: $Service \"kGpuService\", required by node mediapipe_tasks_vision_face_detector_facedetectorgraph__mediapipe_tasks_components_processors_imagepreprocessinggraph__ImageCloneCalc... Warnings prior to the error: [Warning] I0000 00:00:1729008143.963000 1 gl_context_webgl.cc:81] Couldn't create webGL 2 context. (vision_wasm_internal.js, line 1087) [Warning] W0000 00:00:1729008143.966000 1 gl_context_webgl.cc:106] Creating a context with WebGL 2 failed: UNKNOWN: emscripten_webgl_create_context() returned error 0 (vision_wasm_internal.js, line 1087) [Warning] === Source Location Trace: === (vision_wasm_internal.js, line 1087) [Warning] third_party/mediapipe/gpu/gl_context_webgl.cc:82 (vision_wasm_internal.js, line 1087) [Warning] W0000 00:00:1729008143.967000 1 gl_context_webgl.cc:107] Fall back on WebGL 1. (vision_wasm_internal.js, line 1087) [Warning] I0000 00:00:1729008143.968000 1 gl_context_webgl.cc:81] Couldn't create webGL 1 context. (vision_wasm_internal.js, line 1087) [Warning] W0000 00:00:1729008143.968000 1 gl_context.cc:1000] OpenGL error checking is disabled (vision_wasm_internal.js, line 1087) [Warning] E0000 00:00:1729008143.968000 1 gl_graph_runner_internal.cc:252] StartGraph failed: INTERNAL: Service \"kGpuService\", required by node mediapipe_tasks_vision_face_detector_facedetectorgraph__mediapipe_tasks_components_processors_imagepreprocessinggraph__ImageCloneCalculator, was not provided and cannot be created: emscripten_webgl_create_context() returned error 0; StartRun failed (vision_wasm_internal.js, line 1087) [Warning] === Source Location Trace: === (vision_wasm_internal.js, line 1087) [Warning] third_party/mediapipe/framework/calculator_graph.cc:651 (vision_wasm_internal.js, line 1087) [Warning] third_party/mediapipe/framework/calculator_graph.cc:682 (vision_wasm_internal.js, line 1087) [Warning] third_party/mediapipe/framework/calculator_graph.cc:551 (vision_wasm_internal.js, line 1087) [Warning] research/drishti/app/pursuit/wasm/graph_utils.cc:87 (vision_wasm_internal.js, line 1087) Hope that helps! reply klimeryk 2 hours agorootparentThank you! Yeah, that looks like the pipeline from mediapipe (used for ML face detection) has troubles initializing the WebGL context. I don't see immediately any settings for disabling WebGL in Safari, but I'm sure there's some feature flags for that. Do you remember touching any settings related to this? I'm wondering if it's related to some browser settings, an extension (?) or something else. Edit: tested on M2 and Safari 18.0 and I cannot reproduce it. Updating now to 15.0.1 to see if that makes a difference. reply ryandrake 2 hours agorootparentI went into Safari Settings and, under Feature Flags, turned on \"Allow WebGL in Web Workers\" and the site now works. I don't recall ever turning that off or messing with any other feature flags, so I'm guessing that this necessary feature is off by default in at least some versions of Safari. Web development must be so fun, I feel for you. reply DrammBA 2 hours agoparentprevAs another data point it works on my M1 with Safari 17.2 reply yapyap 3 hours agoprevMy god this is so bad, I love it. (bad in a taste way, not in the engineering way) reply chiefrubberduck 3 hours agoprevawesome tool :) thank you for making and sharing it! https://s11.gifyu.com/images/SB5XB.gif reply pelagicAustral 4 hours agoprevI like it... faved for future fuckery. Can you add background photo rotation or shades rotation? reply klimeryk 4 hours agoparentYup, shades rotation is on the roadmap: https://github.com/klimeryk/dealwithit/issues/30. Hope to get it done some time today/tomorrow. Most pieces are ready, just need to figure out a good UX for the rotate handle. Worst case scenario, it can be also an input field. Background photo rotation - could you share what would be the use case? The output would be a bit weird, since it has to be square, so either it needs to be cropped (so now there needs to be crop feature ;)) or there will be blank spaces. Honest question, I might be missing some interesting use case! But hopefully, rotating the shades would solve for most of these. reply pelagicAustral 4 hours agorootparentBackground photo rotation is the over-engineered alternative to shade rotation... reply klimeryk 4 hours agorootparentHahaha, roger that! I mean, it would be in line with the whole premise of the tool... I should implement it so that the whole tool/page rotates around the glasses XD reply howmayiannoyyou 30 minutes agoprevThank you for this. Changed my life for the better. reply dsalaj 3 hours agoprevCool, thanks! It desperately needs the copping feature for the original image, so I don't need other tools. reply chankstein38 4 hours agoprevThis is great! I always joke with my girlfriend about people in billboards or whatever needing deal with it glasses and will likely use this regularly haha Thank you! reply morkalork 3 hours agoprevPlease please please add a blunt/joint option. I think my favorite ever use of this meme was in Colossal (2016). reply Aardwolf 3 hours agoprevIt seems some memes just stick forever :) reply stavros 2 hours agoprevOh man, this is amazing, I love it. Well done. reply navigate8310 1 hour agoprevVery clean, it just works! reply jammaloo 3 hours agoprevHell yeah, this is great. I made a similar, but much worse, thing a while back https://jammaloo.com/DealWithIt/ It uses face-api.js to find the face, and then move the sunglasses over it. It's about a 5 meg model, so it's pretty slow to load. You can customize with a URL, or drag and drop an image on. Resizing the browser also moves the glasses around. Very happy to see someone take the idea way way way further! reply klimeryk 3 hours agoparentHeck yeah! Love the touches like resize handling or rotation support! Contributions are more than welcome... hint hint ;) > It uses face-api.js to find the face Yeah, I'm using Google AI's Face Detector [1]. There's Tensorflow's Face Landmarks Detection [2] that looked most promising and accurate. But it had two bugs [3][4] that are blockers. The first one got fixed recently, but the other one is still pending. [1] https://ai.google.dev/edge/mediapipe/solutions/vision/face_d... [2] https://github.com/tensorflow/tfjs-models/tree/master/face-l... [3] https://github.com/tensorflow/tfjs/issues/7905 [4] https://github.com/tensorflow/tfjs/issues/8290 reply joshdavham 3 hours agoprevI love the UI! Definitely gonna inspire from it for a future project reply klimeryk 3 hours agoparentThank you! It was my first time using Tailwind CSS (and antd). Wanted to try them out for a while, so figured it's a nice opportunity. reply llampx 4 hours agoprevThis could be a reCAPTCHA test, to train the models to better detect eye position and face angle. reply klimeryk 4 hours agoparentIt's already using https://ai.google.dev/edge/mediapipe/solutions/vision/face_d... for detecting the eye (and nose) position for the perfect fit ;) The face detection should be done locally, so hopefully Google is not fine-tuning their models based on this. reply agos 4 hours agoprevthis is great. feature request: DEAL WITH IT caption and relative options reply klimeryk 4 hours agoparentThanks for checking it out! I have adding text on the roadmap: https://github.com/klimeryk/dealwithit/issues/31 :D Upvote on GitHub to show interest! reply vladde 4 hours agoprevLove it. I'll definitely be using this! reply jhickok 2 hours agoprevThanks I hate it. Seriously tho, I've already used this twice at work today. reply devmor 3 hours agoprevI adore it. I would love the ability to add frame delay (and maybe start/end position/rotation tweening?!) to each layer of glasses. reply klimeryk 3 hours agoparentI think we're thinking of the same thing here: https://github.com/klimeryk/dealwithit/issues/22 That's part of the reason I made the list of glasses draggable/sortable. Because I want to add the ability to specify which glasses should appear together and which ones should appear in a sequence. So many features to implement, so this one did not make it for the launch, but it's definitely on the roadmap! reply fHr 2 hours agoprev [–] Now this is amazing, well done. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A developer created an advanced \"Deal With It Emoji Generator\" for a job interview, which uses machine learning to position glasses on faces and offers extensive customization options.- The tool operates entirely client-side, ensuring no data leaves the user's browser, and includes features like GIF output settings.- Despite not securing the job, the developer released the tool for free on GitHub, showcasing their skills and inviting potential job opportunities as a Fullstack Developer with over 14 years of experience."
    ],
    "commentSummary": [
      "A personal project was developed to create a \"Deal With It\" emoji generator, utilizing machine learning to position glasses on faces and offering extensive customization options.- The tool operates entirely client-side, allows for GIF output, and includes Easter eggs, showcasing the developer's creativity and technical skills.- Released for free, the project is available on GitHub, and the developer is seeking feedback and new opportunities as a Fullstack Developer."
    ],
    "points": 425,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1728997505
  },
  {
    "id": 41840931,
    "title": "How I Experience Web Today (2021)",
    "originLink": "https://how-i-experience-web-today.com",
    "originBody": "https://example.com Then it shows me something Example Domain. This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for ... Contact & Feedback (Email / Twitter) Changelog & Thanks My Technology Blog (In Simplified Chinese)",
    "commentLink": "https://news.ycombinator.com/item?id=41840931",
    "commentBody": "How I Experience Web Today (2021) (how-i-experience-web-today.com)404 points by airstrike 23 hours agohidepastfavorite121 comments cle 23 hours agoIt's even worse than that, first Google will bug you to use Chrome, then bug you to login, then after your search the browser will pop up \"Google would like to use your current location\". And then the first half-page of results are ads. And half of the actual results are AI slop and a helpful AI summary of the slop. And that's before you even get to the page. reply andai 19 hours agoparentRan into this gem today: https://files.catbox.moe/bvrd6u.jpg > Google (www.google.com) is a pure search engine — no weather, no news feed, no links to sponsors, no ads, no distractions, no portal litter. > Nothing but a fast-loading search site. Reward them with a visit. reply smittywerben 13 hours agorootparentLOL, I didn't know they ran newspaper ads for Google. I love old images of the Google search engine. When I was a kid, I taught other kids how to use the \"cache\" button next to links. Then Google buried the cache button three clicks under before completely removing it, and Googlers said, \"Well, nobody was using it.\" MBA's doing user-driven development, \"As a user (child), I don't know what a cache is.\" and the legal department being like, \"Yup less shit to DMCA.\" Google is the modern-day Yellow Pages; kill some trees and slam that rainwater-soaked stack of ads on my porch. I won't say no to free, but how many hoops did we go through to end up back here? reply safety1st 16 hours agorootparentprevAh, the joys of crafting an illegal monopoly, systematically abusing the society that built you up, routinely breaking laws and defying judges. Enables you to become exactly what you got successful for NOT being. Must be great. /s reply zelphirkalt 11 hours agorootparentNow only the people in majority need to realize this, and perhaps we can have a somewhat saner web again. reply nameless_me 7 hours agorootparentprevKinda where AI is today. reply schmidtleonard 23 hours agoparentprev> the first half-page of results are ads. I forget if it was crypto or AI, but not too long ago I put in what I would consider a \"normie\" query and every single above-the-fold result was an ad. Every single one. reply FridgeSeal 19 hours agoparentprevDon’t forget finally landing on the page and having the focus immediately stolen by some “LOG IN WITH GOOGLE” pop up that you didn’t ask for, and don’t want. reply whichdan 20 hours agoparentprevOh, don't forget, if you click \"Allow (current location)\" it will also reload the page. reply dylanowen 22 hours agoparentprevTime to switch to kagi.com reply enews01 15 hours agorootparentCan everyone justify paying for a search engine though? reply int_19h 14 hours agorootparentIt's up to everyone to decide how much their privacy is worth. It just needs to be enough people for services like Kagi to be sustainable. reply forgotmypw17 6 hours agoparentprevI switched my iPhone to Bing recently because of this. It’s in the same order of magnitude of usefulness. reply snapplebobapple 3 hours agorootparentI was on bing for a while but switched to brave search necause it surprisingly had much better results and was even less annoying than bing. reply max_ 22 hours agoprevHere is another funny illustration — https://modem.io/blog/blog-monetization/ reply o11c 19 hours agoparentOn a serious note, in case anybody is looking for trustworthy ad providers, I have a list: reply marviel 22 hours agoparentprevI like them both -- but while the OP is excellent satire, this one approaches art. reply xenic 21 hours agoparentprevThis is glorious, and made me think; is there a reverse-adblock addon that would “click” on all ads it finds on a page and would load them silently in the background..? reply blargey 21 hours agorootparentThere’s https://adnauseam.io/ (posted to HN a few times https://news.ycombinator.com/item?id=37230898 ) reply gruez 18 hours agorootparentToo bad it fetches the pages via XHR and doesn't attempt to render them, so it's trivially detectable and filtered out. reply shepherdjerred 21 hours agoparentprevThe CSS on that page is impressive! reply MattPalmer1086 21 hours agoparentprevFunniest (and most accurate) thing I've seen on the web in a while. Thanks for posting! reply Ayesh 16 hours agoparentprevThis is brilliant! I like how it slowly drives you mad. reply masswerk 22 hours agoprevFun effect: When finally confronted with the page-leave dialog, I automatically went for the non-default, grey option button – and was kind of surprised that this wasn't the option I wanted. I've a minor criticism: The \"No thanks\" button should really be \"Remind me later\" and possibly greyed out, since any negative wording is allegedly bad UX and users must be protected from any blunt denials in any options. \"Maybe later\" is also acceptable and even empowering, since this places users on equal footing as they are now lying to the website just as this is lying to them. reply gffrd 21 hours agoparent> \"Maybe later\" is also acceptable and even empowering You've got a fulfilling career in product management ahead of you! reply masswerk 20 hours agorootparentHire me! Unfortunately (or is fortunate?), I'm rather bad at real-life cynicism. So, no results guaranteed… ;-) reply awinter-py 19 hours agoparentprevpage leave dialog was chef's kiss reply mlekoszek 23 hours agoprevThe cherry on top was the video player that solely exists to tell you \"This content is not available in your country\" reply forgotmypw17 6 hours agoprevIt is not how I experience the Web today, and I was initially confused by what the hype was about this site, because… Anytime I see a pattern like this, I just close the tab and move on to browsing sites that respect me. So that's what I did after clicking the first link. It’s sort of like if an annoying or obnoxious person approaches me on the street… I just walk away! What could they possibly have to say to me that could be so important? And I have noticed the same with Web sites… this type of low-quality behavior correlates strongly with low-quality content, which also adds nothing to my life. So by immediately leaving, I am not only saving myself from aggravation, I am also saving myself from wasting time on fluff pieces, useless studies, clickbait, etc. I highly recommend this strategy, because it has transformed the Web for me into once again being usable and useful. (I still use an ad blocker for security reasons.) reply judah 21 hours agoprevThis is great. I see: - Cookie acceptance overlay - Email prompt when switching away from tab - Push notification custom UI prompt - Push notification browser prompt - Subscribe to our newsletter prompt - Ad blocker detected modal - Please subscribe overlay - Continue reading overlay - Ratings prompt - Floating feedback button - \"How can I help you?\" chat popup - Email prompt when scrolling - Create an account footer - Interstitial ads - Social media share buttons - Click to play video overlay (one that isn't available in your country) - Tab closing prompt Thinking about this problem technically, most of these obscenities are vying for top level. In the early days, browsers could detect when a popup was trying to launch and block them. Could we do something similar but for top level DOM? Alternately, could a browser have a quiet mode? No prompts, banners, overlays, etc. Just thinking out loud. reply staplers 21 hours agoparentCould we do something similar but for top level DOM? It's called \"reader mode\" on most browsers. reply graypegg 3 hours agorootparentOne interesting thing I noticed after updating to iOS 18 specifically, is the removal of reader mode as a \"mode\". It's now OFFERED to you in the new view menu based on some heuristic about the page that Apple has determined, but it's not a mode you can turn on regardless of if Apple thinks you're on a \"readable\" document or not. Frustrating since their \"remove distracting elements\" feature was a great value-add, done in the same update. reply ravenstine 20 hours agorootparentprevSadly, development of reader mode seems to be stagnant for both Firefox and Chrome. While it works for a substantial number of pages, I was hoping that more pages would work as years go by. Too bad that doesn't appear to have happened. reply neilv 20 hours agorootparentprevUnfortunately, Firefox Reader Mode bypasses your uBlock Origin, so you get violated by trackers. IIRC, this `about:config` setting is how I disable Firefox Reader Mode: `reader.parse-on-load.enabled` = false reply judah 20 hours agorootparentprevYeah, but it doesn't work for 90% of the sites I try it on. And some sites, especially news sites, deliberately break it. Seems to me reader mode is a great idea but needs some dynamic behavior so sites can't break it. reply CM30 22 hours agoprevSadly the reality for 99% of blogs and news sites nowadays. Makes me wonder whether this is part of the reason why social media sites, YouTube, etc have taken over as a source of information for many people now. Those sites are nightmarish in their own right, but they seem to be less heavy on the annoyances than the average news site now. reply mondobe 20 hours agoparentMaybe the quantity of the annoyances don't matter (see YouTube's recent anti-ad-blocking shenanigans), but the fact that the annoyances are mostly constant and known (at least, changing at a much slower rate than you view a new slop website) definitely reduces cognitive load. reply airstrike 21 hours agoparentprev> less heavy on the annoyances than the average news site now or less heavy on the annoyances than the average news site for now reply bbor 15 hours agoparentprevI think we should take the time to recognize that this isn't bad design, it's a badly regulated market. This is exactly what antitrust exists for: to prevent a small number of firms dominating a market with thin margins, leading to a few decent experiences (namely Facebook, Instagram, YouTube, Reddit, and TikTok) and crushing economics for the rest. What can you do as a publisher of web content other than compete with the big dogs on Display Ads (what this link is complaining about, that's why they request your data in the first place) or try to enforce paywalls (also what this link is complaining about, ironically)? Supposedly some parts of the internet work off of affiliate marketing, such as the few oddball companies that prop up the podcast space for the rest of us, but that seems A) terrible for consumers and B) incredibly hard to make a living with. For better or worse (worse!) we've trained ourselves to expect internet publishers to survive off of Display Ads alone, and act like we've been betrayed when someone links https://businessinsider.com, https://nytimes.com, or another paywalled site to Hacker News. We're at a crossroads in history, my friends. We can, and must, change this. Substack is a beautiful step in the right direction, but real change must come with societal buy-in (AKA no more archive links on HN) and governmental intervention (AKA follow through on the US DOJ's recent threats to break up Google). There's no way in hell that any of us would accept the business model of \"we'll emotionally manipulate you into buying stuff you don't really want\" if we didn't grow up with it -- for anything, but especially for something as vital as journalism. I sincerely doubt Paul Graham could defend it, yet here we are; any paywalled link is removed as a matter of policy, even the fancy new Substack ones that have a few paragraphs of pre-paywall content. reply jodrellblank 6 hours agorootparentPeople defend that business model all the time on HN, usually I’m the disguise of how regulating companies is evil, how smart people want freedom, or in the disguise of “I make a living from working at a big ad-tech company so it must be a force for good in the world”, or in the disguise of “you must be weak if you give in to advertising it doesn’t affect me”, but sometimes just plain “how will companies show you tasteful information about products and services you might be interested in?”. reply hyperhello 23 hours agoprevGreat parody that isn’t a parody. When I get a page like that now I’ve learned that there probably isn’t anything worth reading. reply Vermyndax 23 hours agoparentThis has been my mental shift as well. I also decide this when someone tells me the site only works in Chrome, so I should switch to Chrome. No, thanks. reply mossTechnician 6 hours agoprevThe only update this site needs is at the beginning: instead of a helpful result, it needs to be below 16 AI generated or SEO spam links, and an AI-generated answer needs to appear and start pushing them down the page as it slowly spawns into existence. reply s-mon 22 hours agoprevThe amount of client-side fetched third party tools fighting for the upper layer is so funny and accurate. Intercom + cookie settings + a newsletter popup + ads… reply beders 19 hours agoprevBrave tried to fix this but the jury is still out if it has any chance of succeeding. The lack of diverse monetization models is forcing web sites to maximize for annoying-but-not-too-annoying. I'm waiting for a browser where I can collect gummy points by going to web sites with ads that I can then exchange for my chosen ad-free web content. Just one example of how we can regain control over content with content-creators and infra operators getting their fair share. reply darajava 18 hours agoprevI don’t get why more people don’t use Brave. It literally blocks all of these annoying things (not only ads) on mobile and desktop and it’s very easy to disable all the crap they add to make money (although I do feel bad and actually writing this made me think to donate if that is an option). Brave search is 80% as good as Google’s too. reply tiffanyh 18 hours agoparentSome have lost trust in Brave given various reports of them selling users data, which conflicts with their messaging as being the \"privacy safe browser\". https://news.ycombinator.com/item?id=36735777 reply darajava 5 hours agorootparentSeems indirect and I don’t really care if they use my usage data. reply botanical76 17 hours agoparentprevAnother option is Vivaldi, I swapped from Brave some months ago and I've been quite happy with its ad-blocking. Plus it's tons more functional IMO. reply darajava 5 hours agorootparentI’ll give it a go if I ever get sick of Brave. What makes it more functional? I love how polished and robust Chromium-based browsers are. reply rglynn 17 hours agoparentprevYeah people always complain about ads, I havent seen a single ad in years (except twitch). reply xnorswap 6 hours agorootparentI probably shouldn't divulge this since it risks this privilege disappearing, but Twitch is the one place I don't see ads, even though I don't use an ad-blocker. I think some years ago, I may have had a flag set on my account which stops me getting ads. In the past I've given security@twitch a heads-up about some minor vulnerabilities, so perhaps it was a gesture of good will from twitch. It may also have been a freak case of falling between the cracks when having \"twitch prime\" transitioned from ad-free viewing across all twitch to not doing so. It took me years to realise that I don't see adverts on twitch when I \"should\", and I don't fully understand why not. I'm not sure who even at twitch I would report it to, as it doesn't feel like a security issue. reply littleweep 18 hours agoparentprevGood reminder, I’ll give it a download again. reply syncsynchalt 23 hours agoprevGetting to the final page was a good reminder of the new \"Hide Distracting Items\" in the latest macOS Safari. The feature lets you select offending blocks which are deleted from the page. The feature remembers the items you deleted on re-visit, too. reply tapete 9 hours agoparentI like how you talk about as if this was an exciting new feature, when in reality this is something that ublock had for at least five years. reply beretguy 23 hours agoprevAm i missing something is this text: === I search something https://example.com Then it shows me something Example Domain. This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for ... === And the rest of the page is blank white. I’m not seeing anything else. What is everybody talking about? reply hosh 23 hours agoparentWhen you click on the example.com link, it takes you to a page within the site that shows a bunch of blurred out content, a \"Accept Cookie\" footer. If you try to leave, it asks you if you really want to leave. reply beretguy 23 hours agorootparentAh. Thank you. I clicked, saw “text placeholder”, scrolled down, got that email pop up and that’s it. I guess my ad blocking/coockie/dns stuff is working. reply CalRobert 23 hours agoparentprevclick on it reply sonofhans 23 hours agoprevThis is too real. Even to the point where it barely works at all with ad blockers on. Without ad blockers it’s like fingernails on a chalkboard, just like the web is. At this point I have so many different content-blocking extensions running, trying to trim this crap off my screen, that they sometimes conflict and break things. And still crap gets through. reply alnwlsn 22 hours agoprevUnrealistic. There are far too few ads in between paragraphs. reply Terr_ 20 hours agoparentAlso the paragraphs needs those arbitrary phrases which have been turned into links to purchase a vaguely-related product with a referral code. reply floren 18 hours agorootparentAnd the text actually needs to be a collection of chatgpt-style bulleted lists between h1 headers reply Terr_ 17 hours agorootparentI suspect LLMs will lead to an increase in bullet-point lists from humans, simply because there's no point writing well when the audience assumes it was ghost-written for you. reply rambambram 23 hours agoprevIt also hijacked my Back button for full-on effect, nice. reply spencerchubb 22 hours agoprevWhen I tried to leave the page it said \"Changes you made may not be saved\" That was a nice touch reply hidroto 6 hours agoprevThis let's play experience sums up the web pretty well too. Keep watching till 9:15. https://youtu.be/2Ch_PtGAaZg?t=222 reply nickjj 23 hours agoprevMy favorite part is how inconvenient it is to only accept \"necessary\" cookies. reply bbor 15 hours agoparentA great example of why executive agencies need leeway in their power to make and refine policies. AFAIK the GDPR notifications were put into place by the \"The European Parliament and The Council of the European Union\" directly and haven't changed much since 2016, even though any vaguely-internet-aware child could identify this glaring loophole. I don't doubt their intentions, but the result is subpar at best. IMO the best outcome of GDPR wasn't the blocking of any significant number of cookies, but rather raising public awareness that these sites are collecting \"non-vital\" information in the first place. Why do we allow that, ever, in any way? If I started paying to put up facial recognition cameras in every restaurant and store in town to build my own little omniscient tracker of my fellow citizens, I think I'd be run out with pitchforks and torches. But somehow it's okay when ~~it's on the internet~~ when Google insists that it's a necessary evil... reply LordRatte 15 hours agoprevhttps://imgur.com/a/NwhwnsZ This is all I see. I take it that my ad blocking plugins and security settings are working then. reply oefnak 14 hours agoparentClick the link. reply LordRatte 9 hours agorootparentDid you see both screenshots or are you referring to a 2nd link I should click? reply s-mon 23 hours agoprevCookie banners… the most silly idea made by non technical people mandated upon technical people. Does anyone remember P3P? If that was pushed and managed better it would have solved the entire problem. reply surgical_fire 22 hours agoparentCookie banners were not mandated. That was malicious compliance. That I keep seeing this bullshit repeated it tells me that \"technical people\" are not as smart as they think they are. reply strongpigeon 22 hours agoprevI can't laugh because this is too close for comfort... The only thing that's missing is the page scrolling back to the top and zooming behaving erratically on mobile due to ads popping in and out. Well done. reply t0bia_s 11 hours agoprevLibreWolf with uBlock + NextDNS as DNS resolver (or PiHole) at home router. All phones are connected via Wireguard to router. I don't remember, when I saw an ad on web on any home device last time. reply userbinator 15 hours agoprevIt's ironic that the domain name is one of those that my mental \"classifier\" would instantly put into the \"SEO spam / ads\" category and subconsciously skip over when scrolling through search results. reply zem 22 hours agoprevI'd say \"it's funny because it's true\", but this goes all the way into \"too true to be funny\"! reply jb3689 17 hours agoprevI searched for a guide explaining PID controllers the other day, and after the fifth full screen mobile pop up on a result I finally just gave up. Even on your silly site I accidentally clicked allow because of the buttons switching to default positions I’m not used to. reply pranav_rajs 22 hours agoprevThis is brilliant. I'd probably add the notifications to download Chrome and ads in Google search to this experience. reply lambdaba 21 hours agoprevIt's funny because working with DNS-level blocking + cookie consent + ad blocker the sequence is perfectly fine, I had to go back to comments to understand what I was supposed to see. Of course, that is besides the point, but I am surprised not everyone here has a setup like this. reply jonwinstanley 22 hours agoprevAgreed. And the UX for asking ChatGPT the same question is a lot more palatable reply upupupandaway 22 hours agoprevGreat. The only thing missing is the infinite scrolling that surreptitiously loads another article to keep you reading, thinking you're still with the original article. reply kmoser 15 hours agoparentNot to mention prevents you from Ctrl+F finding something you just scrolled by because it has been removed from the DOM. Other thing missing is \"Your browser doesn't support \". reply airstrike 21 hours agoprevThe least accurate part of this is that the elements are all too quick to respond vs. IRL where every action takes multiple seconds to load reply marcosdumay 22 hours agoprevWhen the site loses focus, it should move into a useless page and show a dialog instead of just showing a dialog. Also, there are too few ads. Anyway, great site! reply ChrisArchitect 22 hours agoprev'cept it's not today is it. It's (2021) reply airstrike 21 hours agoparentWell, technically it's still the case today reply shombaboor 21 hours agoprevwhat is considered as the golden era of web browsing? Minimal intrusiveness, but decent images/video/readability? reply robofanatic 22 hours agoprevThanks to that MBA and SEO certificate! reply mrkramer 23 hours agoprevIn another words: UX nightmare! reply yaky 22 hours agoprevI chuckled at the \"You scrolled!\" popup. Slightly disappointed I did not see the ubiquitous \"Sign in with Google\" popup in the upper right corner, nor comments full of spam. reply blackhaj7 23 hours agoprevSpot on! reply ahmadtbk 22 hours agoprevwe need a how-i-experience-interviews-today reply jay-barronville 18 hours agoprevHow could something be so relatable? It’s this type of foolishness that has turned me so trigger-happy with that “X” button. I close tabs so quickly nowadays that I sometimes forget why I even visited a website in the first place, and I usually end up having to right-click and click “Reopen closed tab” to go back once I remember why. The cookie pop-ups are especially annoying—no, I don’t want your cookies! reply joshdavham 20 hours agoprevI'm a little disappointed that the email sign up doesn't seem to work. It would be hilarious if it did work and then sent you obnoxious email copy haha reply JohnMakin 20 hours agoprevRemember a ~year ago there was a swath of articles popping up everywhere, including this site, about how \"search is fine actually.\" I'm glad people are noticing how bad it is now, I promise it has been this way longer than you realize. It's so user hostile it seems comical at times. I completely stopped using search and feel like I live in the dark ages now and have just accepted that's going to be the foreseeable future until I get a new library card. reply aanet 15 hours agoprevToo funny. Too true. Too sad. This is still true in 2024. reply Bulbasaur2015 23 hours agoprevThis is so funny reply s010c011ab 20 hours agoprevlol reply aanet 15 hours agoprevI wish more sites were like this.... starting with HN. /s reply anyfoo 23 hours agoprev [–] What I always don't understand is: So you don't want to pay for online content, but you also want to use an ad blocker. In summary, you don't want the author or creator to get paid? Personally, I hate ads, so I pay. I have digital subscriptions to the newspapers I read. I have YouTube Premium (because I spend an ungodly amount of time on that site). But for people who want to do neither... what's your idea? reply hosh 23 hours agoparentThere is a whole lot more to this than just whether content creators or publishes should get paid, and whether there should be ad blockers (and whether they get paid). There are people who have been fed up by this because they remembered how the web was like in the late 90s, before social media pushes became the dominant experience. People have formulated ideas around the Small Web (https://benhoyt.com/writings/the-small-web-is-beautiful/), or even opted out of the browser ecosystem entirely with Gemini (https://geminiprotocol.net/) or keep the torch burning for Gopher (https://hackaday.com/2021/09/28/gopher-the-competing-standar...) From there, it is also a short hop and skip away to folks working on local-first (https://localfirstweb.dev/), decentralization, collapse computing (https://100r.co/site/philosophy.html and http://collapseos.org/) reply anyfoo 22 hours agorootparentI get that, but I'm not talking about that. I'm talking about people whose job content is, and who may have had the same job in the 90s, e.g. newspaper journalists. So I'm asking those who don't want to pay for a subscription, but want to use an ad blocker: How does it work? As said, I opted for paying the creator directly, because I hate the ad ecosystem. Seems like a lot of people want to do neither, but still expect their content to magically exist. reply PaulDavisThe1st 19 hours agorootparentI choose to do both. uBlock Origin everywhere. Steven Black host list on everything that can use /etc/hosts. Subscriptions to the things I value (but not to all the things I read). I run an open source project called Ardour. One of our mottos is \"It doesn't matter if everybody pays, it only matters than enough people pay\". I wish more people could make some effort try to follow this idea in some way. reply n_plus_1_acc 21 hours agorootparentprevMany of my favourite blogs are ad-free. The people behindert it just do it with passion and don't expect anything in return. This is in contrast to nrwspapets and magazines, which just pump out clickbait shit while bring full of ads and tracking. Another option is the patreon/twitch model, where people Sonate money to creators. reply ravenstine 20 hours agorootparentYes, the irony I have seen with written content is, with the exception being books, most paid written content is still crap. reply hosh 48 minutes agorootparentAt some point, you stop selling content, and you start selling an audience with a known demographic to advertisers. In such a market, the business is disincentivized to produce thoughtful content, and need to churn the bait the draw in the audience. So it isn't as if creators are being compensated for creating, and instead content producers are compensated for producing words that will lure in readers. reply tapete 9 hours agorootparentprevThe point is that \"people whose job content is\" should just get a regular job, where they actually contribute something valuable to society. All these \"news\" websites that are 90% ads can just die, to make room for valuable sites in the search results. reply photonthug 21 hours agorootparentprevLots of us don’t want to pay a dime because it’s like negotiating with terrorists. Do you really expect the people that ruined the web to act nice after the first round of extortion goes well for them? Many paid services still have ads and dark patterns. Those that don’t are waiting for a position of strength (whether that is a market monopoly or just user sunk-cost fallacy to kick in) and then the enshittification will start. My heart goes out to journalists, etc, but I can’t really help them by paying their bosses because the bosses are not interested in journalism. If you think that paying into rent-seeking protection rackets is any kind of permanent solution you’re probably going to be disappointed. reply Terr_ 20 hours agorootparent> Lots of us don’t want to pay a dime because it’s like negotiating with terrorists. For a concrete example of the implacable amorality of advertising, consider how cable-TV once offered the promise of subscribing to end the ads, but still ended up showing you ads and demanding a subscription fee anyway. Then the same pattern happened again with online streaming services and Youtube: Every would-be savior keeps getting corrupted by the same darkness. reply photonthug 18 hours agorootparentOr consider the commuter that is obliged to pay hundreds a week for gas, and is assaulted by ads at obnoxious volumes while they fill up. Or the jet passenger that endures ads on what should be the PA that is reserved for emergency communications, after they’ve been gouged on ticket prices, because hey, why not monetize a captive audience for all they are worth? Does a first class ticket buy the right to avoid harassment? Everything points to “not for long”.. reply Filligree 6 hours agorootparentJoke’s on them, I just don’t listen to the PA. reply lelandbatey 18 hours agorootparentprevThe only folks expecting the content to \"magically continue to exist\" are folks who lack information. But folks who do have information may also be totally fine with neither paying for content nor seeing ads; for a lot of us, the content that we watch is pretty transitive and if it went away tomorrow because no one watched any ads, we'd go do something else. reply masswerk 22 hours agoparentprevSo, what are my ideas? - static banners (non blinking, no transitions, esp. no vertical transitions that are designed to force you to lose focus – I've come for the content, not the ads) - no tracking that exceeds maybe, if you have seen the campaign already. Preferably hosted by the website (who is responsible?). - also, no targeting. Ads once were supposed to be consumer information. Public information is meant to be public, so I would enjoy leaning about what is out there (in the big world). Not just being reminded of what I bought last month, over and over again. Consumer products are part of (ephemeral) culture and I'd like to be part of it. (Reminder: you can always select/target by content and context, not just per user profile. This is technically feasible, as demonstrated by earlier versions of the Web.) (This is also valid for recommendation and content presentation algorithms of all kind: I generally feel like desperately gasping for air, while being strangled by algorithms that only allow for an ever narrower bandwidth of the ever same. – E.g., is it really true that there are just three videos uploaded to YouTube per week? How do they make a profit? So you say, there are millions? How I'm not going to see them? Even a text search is littered by out of context reminders of the ever same…) – moreover, ads should be more expensive for the advertising party. There should be less in total and the revenue for content providers should be greater (remember the thriving blog scene, we once had, when bloggers could make a living?) (In other words, role it back to the early 2000s and I'm fine with that. Essentially, before Google ads went on steroids.) reply tmtvl 21 hours agorootparent> ads should be more expensive for the advertising party. Sorry, my reading comprehension is failing me. If Bob pays Google to put an ad on Alice's website, is Bob the advertising party? Because if so, that would disadvantage small companies and harm the market by making it harder for newcomers to be competitive. If in our hypothetical situation Google is the advertising party that's good and well, though I don't know how we'd get that done. reply masswerk 20 hours agorootparentIt's about the price of placing an advertisement. Ads becoming that cheap has eradicated significant portions of the Web, which is now flocking to the few big content platforms. I'd call this an anticompetitive development. Ad networks, like Google, are setting these prices. And they have turned the tables: you can't negotiate the worth of the service, as you the product is the ad tag, not the content, it's embedded in. (Also, we – as a society – don't entertain second thoughts on housing prices or general cost of living, while this is a common and basic need. Why is this different? Is there a privilege? Also, who's interest is this about, the content creators, including news sites, or advertisers, who rely on this kind of contextual content provided by the creators? Quite obviously, the current arrangement isn't working out for creators, and news, including active journalism and research, are in a steep decline, after having peaked in revenue around 2008.) reply throwaway833884 20 hours agoparentprevThe thing here is that many of us aren’t interested in paid content, but we keep getting shuttled to paid content due to googles goggles. There is so much free content on the web but we don’t get directed there because we are stuck in an advertising loop. Google intentionally directs us to a site with “paid content writers” to propagate their ruin the internet with advertising scheme, thereby “ruining the internet.” reply tmtvl 21 hours agoparentprevI'm personally fine with ad blocker blockers. They let me make an informed choice as to whether I want to accept ads with all the bad thing they entail (tracking, potential malware ad/or phishing) in exchange for getting whatever information the website offers. When YouTube Light was still a thing I did subscribe sometimes, but I don't feel as though I get my money's worth out of it with the current pricing so I don't really go there any more. reply robofanatic 18 hours agoparentprevIt’s not about having ads, it’s about how they are served, completely ruining the experience. reply lelandbatey 19 hours agoparentprev [–] Your business model is not my responsibility; you're giving away content for free by your own choice. It's cool that you've found \"one cool hack\" to earn some money while giving away your content for free, but the people who accept your free content do not owe you the author anything. The author is free to require upfront payment for access, and the audience is free to pay or leave. But the audience of free content doesn't owe you the author anything, as the author has no contract relationship with the audience. When we visit a blog post we do not sign some contract and never have (some sites have tried to move the goalposts with banners like \"by clicking this link you owe us your souls and thus your eyeballs\" but that's pretty transparently hogwash). Saying \"you want to use an adblocker, thus you're just a thief!\" can validly be escalated with the exact same logic by saying \"why don't you click on every ad you see, that's the only way the benevolent authors get paid you know, if you're not doing that then you're just a thief!\" It's all nonsense fundamentally because the audience consuming your content for free doesn't owe the author anything (as much as authors in this scenario will wish otherwise). To be clear, making content explicitly for-pay I think is amazing and is the clear future. As ads race to be as annoying as possible, users are going to run out of patience and seek alternative sources of information/entertainment, and some number of users will opt for sources that require payment. That's GREAT for the industry as it means users stop expecting everything for free and become selective with their dollar, allowing niche content much more money. This is happening with many small-time independent video publishing platforms (Dropout.tv, Nebula, Floatplane, CorridorDigital, countless creators on Patreon, independent movies published via VHX.tv, etc) to fantastic effect. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Users are increasingly frustrated with the current web experience, which is dominated by intrusive elements like login prompts, location requests, and ad-heavy search results, particularly from Google Chrome.",
      "Alternatives such as Kagi and Brave are gaining popularity as they offer a less cluttered and more user-friendly browsing experience.",
      "The web's cluttered nature, filled with pop-ups and ads, prompts discussions about paying for content to avoid ads and a longing for a simpler, cleaner web era."
    ],
    "points": 404,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1728933773
  },
  {
    "id": 41844545,
    "title": "World conker champion found with steel chestnut, cleared of cheating",
    "originLink": "https://www.theguardian.com/sport/2024/oct/14/cheating-alleged-after-mens-world-conker-champion-found-with-steel-chestnut",
    "originBody": "2:07 World Conker Championships rocked by steel chestnut cheating claims – video Sport Cheating alleged after men’s world conker champion found with steel chestnut Metal replica conker found in pocket of David Jakins AKA King Conker, first-time winner after competing since 1977 Nadeem Badshah Mon 14 Oct 2024 17.26 EDT Share The World Conker Championships is investigating cheating allegations after the men’s winner was found to have a steel chestnut in his pocket. David Jakins won the annual title in Southwick, Northamptonshire, on Sunday for the first time after competing since 1977. But the 82-year-old was found to have a metal replica in his pocket when he was searched by organisers after his victory. The retired engineer has denied using the metal variety in the tournament. Jakins was responsible for drilling and inserting strings into other competitors’ chestnuts as the competition’s top judge, known as the “King Conker”. Alastair Johnson-Ferguson, who lost in the men’s final against Jakins, said he suspected “foul play”, the Telegraph reported. The 23-year-old said: “My conker disintegrated in one hit, and that just doesn’t happen … I’m suspicious of foul play and have expressed my surprise to organisers.” Kelci Banschbach, 34, from Indianapolis, defeated the men’s champion in the grand final to become the first American to win the competition. More than 200 people took part. Jakins said: “I was found with the steel conker in my pocket, but I only carry [it] around with me for humour value and I did not use it during the event. “Yes, I did help prepare the conkers before the tournament. But this isn’t cheating or a fix, and I didn’t mark the strings.” St John Burkett, a spokesperson for the World Conker Championships, said the cheating claims were being investigated. “Allegations of foul play have been received that somehow King Conker swapped his real conker for the metal one later found in his pocket. “Players select conkers from a sack before each round. “There are also suggestions that King Conker had marked the strings of harder nuts. We can confirm he was involved in drilling and lacing the nuts before the event. “We are investigating.” More than 2,000 conkers had been prepared prior to the event. Explore more on these topics Sport Northamptonshire news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=41844545",
    "commentBody": "World conker champion found with steel chestnut, cleared of cheating (theguardian.com)381 points by notamy 15 hours agohidepastfavorite520 comments _fat_santa 6 hours agoApparently he was cleared of cheating: https://www.youtube.com/watch?v=zJKIbq2FuG8 reply Tarsul 3 hours agoparentHe does not say that he is cleared, he says that their initial investigation indicates that he's innocent but they will corrobarate within the next 24h or so. reply ThePhysicist 6 hours agoparentprevThat's the most hilariously British thing I've seen in a long time. Their expert is even wearing a melon hat with a string of chestnuts to the live interview. reply hn_throwaway_99 3 hours agoparentprevI wish there were a picture of this steel conker somewhere. I mean, is it \"steel colored\"? Seems like it would be obvious if it were used. reply MrJagil 8 hours agoprevApparently he has been cleared by VAR: https://www.youtube.com/watch?v=zJKIbq2FuG8 reply dave333 4 hours agoprevPlayed conkers as a kid around age 7-9. We had several horse chestnut trees along our road and I would search in amongst the leaves everyday on the way to and from school. Drill a hole in each and thread about 18 inches of string through the hole and tie a knot so the nut cannot fly off when you swing the nut at your opponent's conker. Challenge others in a duel to the death of one or other of the conkers. Draw lots for who gets first swing. Loser holds the conker out dangling vertically at the end of the string. Other player takes a shot by holding their conker in their fingers well above the other players and pulls down sharply on the string releasing the conker from the fingers in such a way that it hits the dangling conker hard. Assuming both conkers survive you reverse rolls and continue. Winning conkers names increment so a one-er, two-er, three-er and so on. I once had a seventeen-er but the accumulated battle damage eventually spelled disaster. The World Championship seems very fishy to me - firstly someone involved in setting up the conkers (inflating the footballs) should not be a competitor. Second having been caught with a steel imitation conker in his pocket how can he be cleared? He can't prove he didn't use it surreptitiously and so should be disqualified. reply bitbasher 4 hours agoparentAs someone that roasts and eats chestnuts, it's kind of odd to play with them. I suppose you ate many and also played, or are they simply not eaten there? reply HarHarVeryFunny 3 hours agorootparentThe ones used for conkers are horse chestnuts (typically round in shape), not the same as the ones that are eaten which are spanish chestnuts and normally have flat sides. reply bitbasher 3 hours agorootparentThat makes sense-- thanks! reply mintplant 3 hours agorootparentprevThese are horse chestnuts, they're inedible. reply andrewaylett 3 hours agorootparentprevConkers are horse chestnuts, rather than sweet chestnuts. Similar name, unrelated tree. reply klondike_klive 2 hours agorootparentIs it really unrelated? The leaves and nuts seem so similar. reply kube-system 1 hour agorootparentWikipedia indicates that they are a different genus, family, and order, so they are pretty much related in the way that they are both flowering plants. So they're kind of related like humans are related to weasels, because they're both mammals. reply dave333 3 hours agorootparentprevHorse chestnuts are different and not edible. reply RandomThoughts3 4 hours agoparentprev> The World Championship seems very fishy to me - firstly someone involved in setting up the conkers (inflating the footballs) should not be a competitor. Clearly, considering the incredible stake at play here, it’s entirely outrageous. /s > Second having been caught with a steel imitation conker in his pocket how can he be cleared? He can't prove he didn't use it surreptitiously and so should be disqualified. The game is recorded so you can tell which conker he did or did not use. But just in case you didn’t notice, the reason it’s a media sensation is because the whole thing is ridiculous and therefore funny. There is no point in cheating at conker. reply fauria 6 hours agoprevConkers is a traditional children's game in Great Britain and Ireland played using the seeds of horse chestnut trees—the name 'conker' is also applied to the seed and to the tree itself. The game is played by two players, each with a conker threaded onto a piece of string: they take turns striking each other's conker until one breaks. https://en.m.wikipedia.org/wiki/Conkers reply sourcepluck 7 hours agoprevCan confirm that we had very elaborate rules for our conker championships in school in Ireland in the late 90s and early 00s. The lore ran deep too - conkers were varnished in different ways, hardened in front of fireplaces, secret conker trees were coveted, rules were sometimes broken, airplanes were usually not allowed, disputes were not always mitigated, the occasional teacher grumbled. Fun was had. reply freddref 5 hours agoparentTwo lads set themselves up in the business of selling conkers one year. Any accidentally dropped conkers were stamped on by any and all in the vicinity. A conker that survived to the next year was considered \"seasoned\", although many's the wizened tippex-covered lump of questionable provenance appeared under this explanation. reply walthamstow 6 hours agoparentprevDid you have 'stamps' in Ireland too? When a player's conker comes off the string but remains whole, the opponent can call \"stamps!!\" and attempt to stamp it to pieces. reply sourcepluck 5 hours agorootparentWe had an explicit \"no stamping\" rule, which could be overturned by agreement before a game. Actually, we used to have a rhythmic string of rules which were very sayable, which I can't remember, along the lines of \"no stamping no biting no _____ no _____ no ...\", with a list of things, and a rhyme or two in there. I'm going to ask any old friends I run into and see if I can get the full thing back again. I'm pretty sure the first two were no stamping and no biting though. If you'd anything like that, I'd love to hear it! reply Havoc 7 hours agoparentprevWait how do airplanes fit into all this? reply dilap 6 hours agorootparentI was curious too: > An \"airplane\" in conkers is when a player swings their conker in a wide, sweeping, horizontal motion, typically at about shoulder height. reply sourcepluck 5 hours agorootparentCorrect, yes. reply klondike_klive 1 hour agoparentprevI seem to remember that conkers with a flat side and sharp edge were called cheesecutters. reply Duanemclemore 13 hours agoprevI learned about conkers when I was very young and read the Hitchhikers Guide for the first time... \"We bust our way into a megafreighter I still don't know how, marched on to the bridge waving toy pistols and demanded conkers. A wilder thing I have not known. Lost me a year's pocket money. For what? Conkers. The captain was this really amazing guy, Yooden Vranx,\" said Zaphod. \"He gave us food, booze - stuff from really weird parts of the Galaxy - lots of conkers, of course, and we had just the most incredible time.\" Of course in this well pre-internet age I had to wait literal YEARS to find out what conkers actually WERE. Luckily my aunt was an anglophile and went there six or seven years later. Before she left I asked her to find out what conkers were for me. When she returned she told me what they were and... to be honest I was kinda bummed out it wasn't something more elaborate. reply Verdex 4 hours agoparentI had HGttG first read to me when I was 10. I'm 40 now. When I first saw the cheater story yesterday, I had the most awaited \"ooohhh\" reaction of my life. Originally, I figured that conkers were some sort of candy bar. reply WesolyKubeczek 11 hours agoparentprevFor me, the whole notion of there being a professional conkers league, and its longtime judge, real old chap, using a steel replica to cheat, reads like something Douglas Adams could invent. reply Symbiote 11 hours agoparentprevWould the word not be in a dictionary? reply dspillett 9 hours agorootparentIt would, but depending on the dictionary there might not be much, if any, context about the game. You could get a simple “Concker(n), colloquial name for the seeds of the horse chestnut tree” or “Conckers(n), traditional game played mainly in the British Isles with seeds of the horse chestnut tree” – a concise definition of the what without any detail of the game or its cultural significance (it was a big thing for a short time each year back when I was of school age, and had been for generations). “when I was very young and read the Hitchhikers Guide for the first time” suggests this was quite some time ago, so further lookups might have required a physical trip to a library, rather than just clicking a link or throwing a term at an online search engine. reply pavon 2 hours agorootparentprevI was curious, and looked in my paperback Merriam Webster american english dictionary that I used through out school and received about the time I first read HHGTTG. Conker is not present. The big honking dictionary on a pedestal at the high school library probably would have had it, and if that was not enlightening then the library in the closest city that we visited monthly would have good encyclopedias that probably would have described it. But I don't remember the conkers reference catching my imagination, and probably wrote it off as a silly made-up sci-fi word. reply tsimionescu 8 hours agorootparentprevYou'd need an encyclopedia to have any real chance of understanding what kind of game it is, a dictionary typically only gives very small amounts of context. reply Sharlin 9 hours agorootparentprevI guess it just wasn't worth the effort to check, compared to how easy googling is. Lots of things were like that back then. reply russellbeattie 10 hours agoparentprevI was about to post the same thing! I've thought about this literally for decades. I also had to wait for years to learn what conkers are - and I'm still confused. I'd love to know the context/history/culture that DNA was referring to because it doesn't make any sense to me as written So conkers are chestnuts on a string used for childhood smashing competitions. Ooookay. But why would Yooden Vranx have \"lots of\" chestnuts on his spaceship? And why \"of course\"? Was that something that should be expected from an adult, or maybe specifically a captain of a ship? And why would a child think chestnuts were as special as the weird galactic stuff? To this day, I think he was referring to something else which got lost or changed in the editing process. Maybe there was a side bar about \"cosmic conkers\" that got omitted, but the later reference was kept. Something. reply amiga386 9 hours agorootparentIt's a childhood story dressed up in sci-fi. If an American child had told it, they might have said they demanded baseball cards, and the amused captain would have given them food, booze and \"lots of baseball cards, of course\". Children all over the world occasionally make demands of adults and are thrilled when the adults oblige them; their bold dare paid off! Children make up games at school, so when all the chestnuts fall off the trees, children make a game from the mass availability of chestnuts. It's a British story - it's ostensibly space opera, but really it's more a space-themed Radio 4 comedy. It's British by default. Hence bypasses, council planning departments, stubborn bureaucrats, substances almost entirely unlike tea, solving problems by going to the pub, moaning about the weather, cricket stoppages, getting drunk, implacably morose people, smugly insincere corporate drones, being annoyed at overly flashy Amer... people like Zaphod, and so on. And conkers, of course. It reminds me of the Twitter thread by an American who had never heard of boarding schools asking \"what did you think in Harry Potter was magical but it turned out just to be British?\" [to which someone said \"Scotland\" :(] reply dcminter 9 hours agorootparentRe your last note (which is hilarious) I was hugely amused to discover that many Americans reading in Potter about Filch \"punting\" the kids across the temporary swamp assumed he was kicking them over rather than using a flat bottomed boat. Understandable but much funnier than the original intended. reply pyrale 4 hours agorootparentprev> [to which someone said \"Scotland\" :(] Savage reply. reply pyrale 4 hours agorootparentprevYour mistake is trying to find logic in something Douglas Adams wrote. It makes no sense for alien spaceships to carry conkers. That's the joke, a small dig at people believing the local stuff they're used to is universal. reply zemo 6 hours agorootparentprev> why would Yooden Vranx have \"lots of\" chestnuts on his spaceship? And why \"of course\"? hmmm, these might be what they call \"jokes\" reply Cthulhu_ 5 hours agorootparentAbsurdist humour, Hitchhiker's is full of it, as is Discworld. Aggressive Britishisms as well (like conkers and tea references), like in the Cornetto trilogy. reply lazide 4 hours agorootparentThis is honestly the first time I’ve seen ‘Aggressive Britishisms’, and I’m still somewhat perplexed at the concept. Like I get it, theoretically. But…. Hmmm. reply louthy 4 hours agorootparentprevGetting a massive haul of conkers was almost as important as the game itself. So, that might add some context. reply zabzonk 14 hours agoprevWhen I was a kid (many years ago) me and a friend once went \"conkering\" down quite a posh road with several horse chestnut trees on it. We had collected a few good ones when a guy came out of his house and called us over. We thought \"Oh dear, get off my lawn time\", but no! He had big bin full of conkers that he had picked up from his garden, and invited us to choose from them. reply animal531 11 hours agoparentHe probably played it himself back in the day. Its interesting how games and other things like songs, stories etc. persist and/or disappear over time. reply zabzonk 5 hours agorootparentThings from my youth, as well as conkers: - marbles (can you get them anymore?) - kick the can (where would kids get cans today?) - British bulldog/chain tig (far too dangerous) I can't remember the rules of these, but they were very popular in the early 1960s, when I played them. reply 0xdeadbeefbabe 48 minutes agorootparentI bet all are alive and well in other countries. reply aeneasmackenzie 4 hours agorootparentprevElaborate marble runs are very popular, although many people use steel balls instead. reply buildsjets 1 hour agorootparentMarbles is played sitting in the dirt around a circle. There are no runs involved, and nothing is elaborate. The objective is to take your opponent's mables, permanently, by knocking them out of the circle. Using steel balls to play would be completely pointless and it would ruin the entire game. I want to take your cool looking hazel cat's eye, not a random steel ball that looks just like all the other steel balls. reply Loughla 4 hours agorootparentprevMarble runs are wildly different from marbles we played when I was a kid. One is an engineering (lite) exercise, the other is a game of vague dexterity to take someone else's marble collection. reply rsktaker 13 hours agoparentprevWhat a wonderful story, thank you for sharing. reply thatguymike 14 hours agoprevI'm surprised they pick their conkers out of a bag. The whole fun when I was a kid was competing for who could find the toughest conker. Common cheating methods included putting it through the tumble dryer to dry it out (Mum didn't love that) or soaking in vinegar. If you're pulling conkers out of a bag I think each match is basically a coin flip, unless there's much more technique I'm missing? reply zabzonk 14 hours agoparentAs someone that played it over 60 years ago, there is quite a bit of technique involved - for example, aiming to hit the opponent's conker accurately and hard. reply thatguymike 4 hours agorootparentWouldn't that newton's-second-law your own conker just as hard though? As the aggressor you get to choose the points of contact, which must be where the accuracy comes in. If you can strike your opponent downwards you're more likely to knock them off the string and lead to Stamps. reply dave333 3 hours agorootparentConkers are usually oblate spheroids and the dangling one has its largest radius spot on top usually - thinking back I never thought to string one differently not sure if that was allowed. So the person taking the hit can aim to hit with the shortest radius section of their conker on the flat spot of the other. There's also the skill of an accurate hit - someone who misses a lot or hits away from center glancing blows is not going to win very much. reply zabzonk 3 hours agorootparentprev> Wouldn't that newton's-second-law Contradict/confirm/what? Please clarify. reply andrewflnr 14 hours agoparentprevVinegar makes it stronger? I would naively expect the opposite. reply kimixa 14 hours agorootparentI wouldn't be surprised if many of the \"techniques\" softened it but made it more resistant to shattering. An extremely hard but brittle conker would probably make for poor results. reply andrewflnr 14 hours agorootparentInteresting. I can certainly see how brittleness is probably fatal. But a soft one won't be any help at breaking your opponent's conker, either, right? Unless speed of your conker can overcome the increased inefficiency of transmitting energy into the opponent's... reply ThrowawayTestr 13 hours agorootparentEverything can be a sport if you try hard enough. reply blitzar 11 hours agorootparentEverything can be a sport if you can bet on it. reply forgotusername6 13 hours agoparentprevI varnished mine reply liendolucas 2 hours agoprevThank goodness, we were all so worried about the conkers world championship... Now that the whole thing has been settled down I can finally go to sleep. reply umanwizard 15 hours agoprevIs this game well-known enough in Britain and Ireland that readers will know what on earth is being alleged just from reading this article? Or are you expected to have to google it? Apparently it’s a game where you take turns swinging a chestnut on a string and trying to hit the opponent’s chestnut and break it. Yes, I can see how a steel fake chestnut would be an advantage here, though I’m amazed it wouldn’t be instantly obvious to even a casual observer that the look and sound were wrong. So maybe I’m still missing something. reply nickcw 11 hours agoparentI used to play conkers at school in England, however my children didn't. The reason? Schools have banned the game of conkers due to health and safety reasons. I asked my 17 year old this morning and he had never even heard of the game of conkers. So I think the age of conkers is passing, alas. reply zarzavat 10 hours agorootparentIt's much more likely to have died out because of smartphones. The boredom of the pre-smartphone era led to all kinds of ingenuity. Kids were bored so they found ways to not be bored. Nowadays everybody is addicted their phone, simple pleasures such as violently smashing two nuts together no longer have the same pull. reply mellosouls 7 hours agorootparentIt's much more likely to have died out because of smartphones I know kids have a lot more money these days but I refuse to believe they are swinging two smartphones together instead of conkers. reply dgacmu 5 hours agorootparentI would like to introduce you to my six year old. Mind you, it's much more likely the two phones involved would be mine and my wife's. reply joelanman 7 hours agorootparentprevhttps://play.google.com/store/apps/details?id=com.carrotpop.... reply Cthulhu_ 5 hours agorootparentprevI've seen enough clips of kids playing with their phone to drop them in the water to know that they probably would. reply treerock 10 hours agorootparentprevI was out for a walk yesterday, and kids were throwing sticks up trees trying to knock the chestnuts down, so I don't think it's dead completely. I never really played it when I was a kid, but knew all about it from The Beano and Oor Wullie. reply 0xdeadbeefbabe 46 minutes agorootparentprevKids can get bored of smart phones too. reply philipwhiuk 7 hours agorootparentprevNot for long. Schools are looking at banning smartphones. reply Cthulhu_ 5 hours agorootparentThey are where I live, both elementary and secondary schools. The first results are promising; kids have more concentration, interact socially with each other more, etc. I mean if it's a school where they also have to carry laptops and use digital schedules I don't think it makes a difference, but it's a good first step. One issue was that each phone also has a camera, so people would seek out / make trouble on purpose, spy on people and post it online, etc. reply tsukikage 6 hours agorootparentprev...I mean, you could play conkers with smartphones. They even have that strap attachment built right in. Might have to outlaw old Nokias though. reply greatgib 8 hours agorootparentprevI saw on the wikipedia page the following totally stupid reason for the ban in some schools: In 2004, several schools banned conkers due to fear of causing anaphylactic shock in pupils with nut allergies. Health advisers said that there were no known dangers from conkers for nut-allergy sufferers, although some may experience a mild rash through handling them.[20] reply ljf 8 hours agorootparentInteresting, as conkers are seeds (not a nut) - so shouldn't be an issue for someone with a nut allergy - though no doubt some people are allergic to them. reply joncrocks 7 hours agorootparentIt's not quite that simple. The line isn't quite as hard between seed and 'nut'. Namely people may commonly refer to things as a nut when it is a seed. e.g. a Peanut is a seed, as are almonds, cashews, walnuts. reply robin_reala 4 hours agorootparentOn this subject, I’d recommend Richard Osman’s lecture on nuts for “The Unbelievable Truth”: https://www.reddit.com/user/pfobwpfo/comments/18ohqi2/nuts/ reply ljf 6 hours agorootparentprevVery true - I'll admit that while I knew that peanuts are legumes not nuts, I didn't know that the others you mentioned were not nuts. I learn something new every day (and my son has a severe allergy to many of them - though not all - so I should know these things!). And while I know my son can safely play with conkers, we most certainly have not tried to eat one! reply joncrocks 3 hours agorootparentUltimately it depends on the semantic meaning when you say 'nut'. They are not 'nuts' in terms of the technical definition, but they are in terms of 'what most people think of when you say nut'. There's also some things with nut in their name. c.f. Nutmeg, coconut. As others have mentioned, same kind of deal with 'berry'. And to follow up, if you're travelling abroad it's worth noting that some countries have different naming structures/separate out the families of 'nuts'. So be careful if you're asking if something has 'nuts' in, there can be a language barrier. e.g. tree nuts vs. Lupins (peanut family). reply _heimdall 7 hours agorootparentprevThis rabbit hole goes deep. Berries are particularly poorly named - stawberries, blackberries, and blueberries aren't actually berries but tomatoes and bananas are. reply barrkel 7 hours agorootparentThis is only a problem if you mistake words for scientific classifications, instead of ways to convey meaning between communicating humans. Very few people using the word \"berry\" are discussing scientific classifications. It would be worse, not better, to make terms more scientifically precise. Berry refers to small juicy fruits, often in bright colors. reply _heimdall 6 hours agorootparentI was sticking with the context of the GP though. Maybe its pedantic to point out that many berries aren't technically berries, but that's much the same as the point that many nuts are actually seeds. reply umanwizard 6 hours agorootparentprev> stawberries, blackberries, and blueberries aren't actually berries Yes they are > tomatoes and bananas are No they’re not. The word “berry” is much older and more fundamental to language than the technical botanical definition that a tiny minority of people know or care about. reply _heimdall 6 hours agorootparentYou clearly understand that there's a difference between the colloquial name and the scientific definition. In the context of the GP comment, the discussion was related to nuts that are poorly named (like peanuts and tree nuts that are actually seeds). Strawberries aren't berries and tomatoes are. You can say that's wrong all you like, but in the context of how they are botanically classified rather than what we named them you're incorrect. reply umanwizard 4 hours agorootparentThe botanical classification is irrelevant outside of papers in botany journals. If I made up a new, niche meaning of already-existing words, and tried to claim everyone else was using them wrong, you would think I was crazy. reply _heimdall 4 hours agorootparent> If I made up a new, niche meaning of already-existing words, and tried to claim everyone else was using them wrong, you would think I was crazy People do this all the time, though it makes me feel old rather than crazy. reply umanwizard 4 hours agorootparentImagine if someone said \"this chair is an object\", and you told them they were wrong, because in Object-Oriented Programming, an \"object\" is an abstract entity in a computer program, not a thing in the physical world. They have never heard of object-oriented programming and yet, they're not wrong. You're the one who is wrong by assuming the terms made up by a niche field override common language used by everyone. reply _heimdall 1 hour agorootparentChairs and OOP have nothing to do with each other. Fruits, seeds, etc are plants and fall into botanical definitions. I get the point that we call them berries even if they aren't, but your comparison to OOP is apples and oranges. reply umanwizard 1 hour agorootparent> I get the point that we call them berries even if they aren't That wasn’t the point. The point is that they are berries, by the real definition of berries, which is not the different definition used by a tiny minority of mostly irrelevant people in a specific context. What reason is there to prefer the botanical definition to the common one (that says a berry is a small colorful fruit)? I can see none. On the other hand, I can see many reasons to prefer the common definition: it is older, it is used by far more people, and it more closely corresponds to what we care about in real life (because almost everyone spends more time preparing and eating meals than they do classifying plant parts, so the culinary meaning is more important). Scientists are not in charge of the whole human experience. They do not get to decide on behalf of everyone else that the salient defining characteristic of berries is not how they taste or what dishes you would use them to prepare, but rather what part of the plant they come from. reply _heimdall 17 minutes agorootparentDo you take the same issue with the original comment pointing out that what are usually called nuts are actually seeds? aspenmayer 2 hours agorootparentprevClearly they're wrong because this chair is a table. reply BoxOfRain 10 hours agorootparentprevI'm one of that 'too young to be a millennial, too old to be a zoomer' cohort and we definitely played it in the '00s, I vaguely remember the rumours of it being banned encouraged its popularity quite a bit. They also banned British bulldog around that time so we renamed it 'hot dog' and carried on! reply cjrp 10 hours agorootparentSide note, if you were playing conkers in the 00s are you still too young to be a millenial? reply Sharlin 9 hours agorootparentSomeone born in 1996 ± 2 years or so would easily have played conkers in the 00s and consider themselves a zennial. reply gandalfian 11 hours agorootparentprevnext [–]I understood that was a myth created from a few isolated instances and the medias general desire to wind people up. I don't know why it has died out mind. reply dspillett 9 hours agorootparentIt is a myth that it was banned nationally for health & safety (“nanny state”) reasons, as was incorrectly reported in the press (mostly in the red-top papers), but some schools certainly did ban the game. This was usually because it became a tool for bullying: deliberate hand hits in games, deliberate hand hits in other contexts with complaints of an attack fobbed off as “we were playing conckers and there was an accident”, and so on. Also like any playground sport there were gambling issues (I'm not sure if they were serious issues, or just if some schools took them too seriously, but I remember there being a glut of warnings about it when I was in secondary level education, around the same time as some bullying concern related bans). reply _heimdall 7 hours agorootparentThe idea of banning a game because it can lead to bullying is ridiculous in my opinion. Kids will be kids and bullies will always find an excuse to pick on someone if they want to. Just deal with it one-off when a game gets out of hand and let kids play games and learn social skills along the way. reply dspillett 4 hours agorootparent> The idea of banning a game because it can lead to bullying is ridiculous in my opinion. It was more banning the tool without which the game can not be played, but yes as someone who was subjected to bullies at various times in my education history I can say you are right about them just finding something else. I didn't say it was right, just that it happened. The problem that causes these ineffectual bans is simply that the school's head (and other authorities) feel the need to be seen to be proactively doing something, anything, about the bullying problem they otherwise officially deny having¹, especially when local press have got onto the issue and are stirring up angst amongst the parents, and when they can't think of anything better a target is picked and a simple ban gets announced. ---- [1] It always amazed me how soon after a claim that we don't have a bullying problem in the school, there would be a call to celebrate an action that was supposed to reduce the bullying problem we didn't have… reply darrenf 10 hours agorootparentprevThe HSE posted on their mythbusting site that it was a myth at a national level, but I suppose individual schools might have done so? https://web.archive.org/web/20211018040605/https://www.hse.g... Quote: \"Realistically the risk from playing conkers is incredibly low and just not worth bothering about. If kids deliberately hit each other over the head with conkers, that's a discipline issue, not health and safety.\" Certainly there was at least one school that got goggles for pupils to wear while playing: http://news.bbc.co.uk/1/hi/england/cumbria/3712764.stm reply Symbiote 6 hours agorootparentThe headteacher said himself that story was misreported — he bought the goggles as a joke. https://www.theguardian.com/commentisfree/2009/dec/09/conker... reply walthamstow 9 hours agorootparentprevThe academy run by Lord Ashcroft has banned bicycles so I guess anything is possible when you're outside of local authority control reply GordonS 9 hours agorootparentprevI remember being a kid in the 80's, and being told by a primary school teacher we couldn't play conkers anymore :( We'd only just discovered it too! reply _dain_ 11 hours agorootparentprevNot a myth. I went to school during the twilight of the conker. It absolutely died because risk-averse teachers banned it, to howls of protest from us kids. reply petemir 10 hours agorootparentThe myth is the game being a health hazard, not if it was banned (or not). reply hi-v-rocknroll 10 hours agorootparentprevJust another brick in the wall. reply red_admiral 10 hours agorootparentprevDrilling/punching the hole in a conker might be vaguely dangerous, and you're not supposed to carry a stabby tool at school anymore. But the game itself is not that dangerous, though that won't have stopped some schools from banning it. reply OJFord 9 hours agorootparentprevI'm between your ages and we played it. Not a lot, it definitely occupies a larger area of national psyche than it's played I think, but we did. Yes school banned it, but when did that ever stop us? reply martin_ 11 hours agorootparentprevAlso played at school in England.... probably ~22 years ago now I'd guess! Sad to hear that era is over! reply schoen 11 hours agorootparentprevWhat are the health and safety risks from this game? Do the chestnuts fragment violently when they break up? reply ratherbefuddled 10 hours agorootparentMostly it increases teacher stress levels having to referee. reply mellosouls 7 hours agorootparentprevImagine swinging two stones (many techniques to harden conkers including the game itself evolving the brutes by elimination) together at high speed with fingers and faces in very near proximity. reply 946789987649 11 hours agorootparentprevaccidentally hitting each other reply schoen 11 hours agorootparentI can't really visualize the amount of momentum involved, or how sharp the chestnut is. Is that specifically about eye injuries, or could it hurt someone some other way? reply schoen 8 hours agorootparentAfter writing the above comment, I watched videos of people playing conkers and now I understand how it could, in theory, cause an eye injury. It was hard for me to visualize how close the defender's conker is to the defender's body before seeing the video. I was somehow wrongly imagining that it was being supported on a much longer string or with the help of other objects somehow. reply ryanjshaw 8 hours agorootparentLiterally the first video I watched, 2:28 min in, kid gets knocked in the teeth: https://www.youtube.com/watch?v=egBjZaKNLuc reply lazide 10 hours agorootparentprevIf you whip it above your head at a good 100-200 rpm, anything is possible. reply arethuza 10 hours agorootparentprevAh yes \"accidentally\"... ;-) reply Oarch 7 hours agorootparentprevArguably with the steel conker endemic happening before us there are finally some valid health reasons... reply tomxor 15 hours agoparentprevYes. Although the last time I played or heard anyone discuss conkers as a game was in the 1990s at school. My dad seemed to find the concept of fake conkers amusing enough to take it upon himself to craft me a resin filled one, although it didn't fool any kids. In more recent years a bus driver complained to me conkers are not legal tender as I placed some down while in search of change. Around this time of year you will find most people have their pockets filled with conkers.reply fer 12 hours agorootparent> Although the last time I played or heard anyone discuss conkers as a game was in the 1990s at school. Same, but with peonzas/trompos[0]. It's interesting since it's also about breaking the other player's item thanks to the inertia provided by a string. In short, they're hardcore spinning tops: large, generally with a metal tip, spun much faster due to the string winding, and as mentioned, the objective is to crack the other player's. [0]https://en.wikipedia.org/wiki/Trompo reply beAbU 11 hours agorootparentI did not know it was possible to break those things to be honest. We made a circle with a string or something, and then let the two spinning tops (as we called them) duke it out, and the loser is the one knocked out of the ring. Ours were made from a very tough plastic, either nylon or HDPE. reply tankenmate 12 hours agorootparentprevAs well as the old myth that putting a conker in the corner of a room will ward off spiders building a web there. The veracity of which, attest to I cannot. reply red_admiral 10 hours agoparentprevIt is a very, very British thing. A generation or two ago, almost everyone played it at school and it was Very Serious Business. I guess you needed something to occupy yourself before Pokemon Go was invented. reply nanna 9 hours agorootparentI have fond memories of playing conkers in primary school. Sometimes you got a rapped knuckle but children's sports is full of cuts and grazes, and it didn't hurt as much as slaps anyway. The main issue was that some kids would inevitably harden their conkers by putting them in the oven or lacquering them, and so on. But spotting that was part of the charm. reply flir 9 hours agorootparentBeing of a geeky bent, I tried them all. It never worked. They go brittle and shatter, or they go soft and fall apart. (When I was a kid, conkers were so prized we chucked sticks at them to try to get them to drop. So it was a bit of a shock to me when they started just being left where they fell. Kids today, off my lawn, uphill both ways, etc etc). reply nanna 3 hours agorootparentCheaters never prosper! reply johnflan 6 hours agorootparentprevIt was very common in Ireland too, hunting for conkers was always fun. However I don't think it is common at all now reply wslh 9 hours agorootparentprevIn many places the cup-and-ball [1] game was/is popular. It's incredible to think now about games that doesn't require batteries and USB ports. [1] https://en.wikipedia.org/wiki/Cup-and-ball reply BlueTemplar 7 hours agorootparentprev\"A generation or two ago\" roughly corresponds to the Tamagotchi era too. reply dullcrisp 7 hours agorootparentOr two? Why do you have to be like that? reply BlueTemplar 3 hours agorootparentLike what ?? reply nanna 3 hours agorootparentReminding all of us how old we are reply mhandley 9 hours agoparentprevYes, it was a big deal when I was in school in the 70s. Everyone played. There were never any conkers left unclaimed under any Horse Chestnut within a mile of the school. We all tried lots of tricks - soaking in vinegar, baking in the oven - practically anything was allowed, but I'm not sure any of it made a difference. It could be pretty painful as getting your hand hit by a high speed conker was common occurrence, but I don't recall anyone getting any lasting injuries. reply ben_w 9 hours agorootparentIndeed, it was still popular in the 80s and 90s. I assume still is, given the Guardian is a national newspaper. reply lock_enthusiast 15 hours agoparentprevI feel there is enough in the article to build an image of the game in your head: I'm imagining a game game where two people trying to destroy the other person's chestnut by whirring and hitting the chestnuts on the end of strings. Now I'm going to go check my mental image against wikipedia. reply conductr 13 hours agorootparentI’m American and never heard of this sport in my life yet article painted a similar picture in my mind. reply raffraffraff 12 hours agorootparentIt's not a sport, it's something that kids used to do pre 1950s. People were poor, didn't have manufactured \"stuff\", so they made their own toys out of simple things like stones, sticks, old wheels etc Football was likely popular because a single ball could keep a while bunch of kids happy for an afternoon (if someone could actually afford a ball). I'm almost 50, and to me the image of boys playing conkers only comes from books or TV based in early 1900s UK. I've never actually seen anyone play it. And nowadays people don't really grow up at all. They continue playing right into adulthood and old age, with luxury toys. reply Symbiote 11 hours agorootparentI played conkers in the 1990s. Everyone did. Money has nothing to do with it, most of my friends had computers, some had those mini cars to drive — it was a wealthy area. reply loup-vaillant 10 hours agorootparentprev> And nowadays people don't really grow up at all. They continue playing right into adulthood and old age, with luxury toys. It would be nice if we stopped stigmatising play. Growing up doesn't mean we stop playing. Acting grown-up might mean stop playing, but it's just that — an act, and a likely childish one. Real adults don't give up on what brings them joy. reply sersi 9 hours agorootparentBack when I was a teenager, I used to also have similar thoughts as the person you replied to about not playing with toys because it was childish behavior. Luckily, I grew out of that and I do not feel self conscious when playing as an adult or being goofy. reply razakel 7 hours agorootparent>To carry on into middle life or even into early manhood this concern about being adult is a mark of really arrested development. When I was ten, I read fairy tales in secret and would have been ashamed if I had been found doing so. Now that I am fifty I read them openly. When I became a man I put away childish things, including the fear of childishness and the desire to be very grown up. - C. S. Lewis reply conductr 6 hours agorootparentprevI don’t mind the nit on word choice but in my mind a game becomes a sport by the existence of a Championship match and title. Also, I think this follows how most sports come to be. They are started as child play, when we have the time/leisure/energy, then they eventually become something some of us want to continue with as adults and the rest of us will pay to watch because we enjoy the sport so much (often fostered during youth play). There are dozens of sports that I have no interest in simply because I wasn’t exposed to them as a kid. As an older American, we did not play Soccer(football) when I was a kid. It’s pretty popular now and my kid has had me go to professional games and such but I still just don’t really understand the game/rules/strategy or fully appreciate the difficulty of things that occur. I could learn I suppose but I still just have little effort in doing so as a middle aged person. I could say the same about Cricket and a handful of other sports that I never played as a kid but know are popular elsewhere. Likewise, when people move to the US, it usually takes them a while and likely never fully get into American Football and Baseball. Basketball has become more global and so I do expats that follow that sport. More likely than not, they follow the sports that interested them as a kid and just live with the time zone issue. reply scalesolved 11 hours agorootparentprev> I'm almost 50, and to me the image of boys playing conkers only comes from books or TV based in early 1900s UK. I've never actually seen anyone play it. Did you grow up in a city? I'm mid 30s and we used to regularly play conkers in the village where I grew up. reply hnlmorg 12 hours agorootparentprevMy kids play conkers. They also have games consoles and other luxury toys. Kids just love to play. reply oniony 11 hours agorootparentprevI'm an 80s kid and we passionately played conkers at my primary school. We used to hang them on shoe laces or string, by burning a hole through the middle with a heated awl or kebab rod. Cheating was always rife with people using all manner of techniques to try to preserve and strengthen their conkers: soaking in vinegar, baking them, coating in nail varnish, &c. Pretty sad to hear it's fallen out of fashion, as it was good, cheap fun and, with long enough string, not very dangerous. reply semi-extrinsic 11 hours agorootparentprev> if someone could actually afford a ball Round here, in the olden days the kids would fashion a crude type of ball called \"basse\" by cutting up a broken bicycle inner tube into a bunch of small rings, threading all the rings on a piece of string and tying this mess up in a particular way to form a roughly spherical object. It does not roll well at all, but the kids stand around in a circle and kick the basse around to each other, trying to keep it in the air. If you cause it to fall to the ground, you lose. reply royletron 9 hours agorootparentprevI played conkers in the 90's, my kids (7 and 10) play conkers now. We even have debates on whether applying nail polish is considered cheating - it is, it totally is! What's more, I was brought up in a poor area of Manchester, they've been brought up in quite an affluent area of Oxfordshire - so couldn't be any different! reply calamity_elf 8 hours agorootparentprevI went to first school (3 tier system, first, middle, high) in the 1970s and we played conkers in the school yard in the 1970s, and into the mid 80s in middle school too. By the time I reached high school they'd been banned. I see parents and children collecting horse chestnuts in the local market square and arboretum still today though, and it brings back fond memories of rapped knuckles and entanglement \"clingy-niner's\" or \"clinchies\" in some games, depending who you were playing with. reply jamiek88 12 hours agorootparentprevI’m 47 and played conkers in school on merseyside. The local ‘conker trees’ were famous! reply OJFord 10 hours agorootparentI think whether or not you grew up with a significant local population of 'conker trees' probably had a lot more to do with it than age. I'm younger than you (and didn't grow up 'poor') and we played too, 'pre-50s' is ridiculous. reply komadori 12 hours agorootparentprevI grew up in the 90s and we played conkers. The main detail I remember was that soaking them in vinegar was supposed to make them stronger! reply flir 9 hours agorootparentprev> I've never actually seen anyone play it. Inner-city kid, same age as you, and it was everywhere. Not universal, I guess. reply conkers 9 hours agorootparentprevI played conkers in the 80s, everybody in the school did. People had tricks like coating their conkers in gloss etc. but it was still a widespread game. Played football and British bulldog type stuff too but conkers came in season for a bit every year. reply Rattay 11 hours agorootparentprevYeah, very much fron the 1950's 'Beano' era, but it did still go on in the mid 90s, at least in a wild throwing them about the place as entertainment. It was indeed a simpler time. A lot more kids in the background smoking cigarettes around the bike sheds as well, but that's another story :) reply easytiger 11 hours agorootparentprev> I'm almost 50, and to me the image of boys playing conkers only comes from books or TV based in early 1900s UK. I've never actually seen anyone play it. Extremely common for kids to play this at least into the mid 2000s where i'm from, i moved away so i don't know if they still do reply room271 11 hours agorootparentprevAnother voice here of someone (in my 30s) who played conkers growing up. Was great fun! reply Nursie 14 hours agorootparentprevThat's more or less it. You make a hole through your 'conker' (horse chestnut, not the edible type) and thread a string or a bootlace through it. Then you take turns. One holds their string still and lets the conker hang down, the other gets a swing at it with their conker. Whoever's conker lasts the longest is the winner. There were all sorts of rumours about baking them, or soaking in vinegar or what have you to harden them up, but effectively it's the sort of game that a bunch of kids can play under a horse chestnut tree with relatively few props. Using a steel 'ringer' in that circumstance would be the worst sort of unsportsmanlike behaviour. reply riffraff 13 hours agorootparentHo do you drill the hole? I'm having trouble imagining kids with needles in their pockets, do you do it with a pencil or toothpick? We've got a ton of horse chestnuts in my neighborhood but I've never heard of this game and I'm eager to introduce it to my kids. Also, doesn't the conker spiral around your hand hitting it and hurting you? reply oniony 11 hours agorootparentWe used to have a BBQ skewer that we used for various purposes, including adding holes to belts. We'd heat it up on the gas hob and then burn a hole through the conker. I actually still have the same one I've inherited in my kitchen drawer. If you have an awl, you could use that instead, but I'd recommend heating it to get a cleaner hole. You need to use a long enough string. Old cotton shoe laces are actually perfect as the aglets make threading that much easier. The force of one conker against another is enough to sometimes make it spin round, but not enough to do any real damage. You just need a long enough string that your fingers are not in the firing range. Obviously there is a vanishingly small risk of a piece of conker ending up in the eye but I never witnessed that or any other injury happening. The biggest problem was usually upset kids when their prized conker got destroyed. reply zelos 9 hours agorootparentWe'd heat it up on the gas hob and then burn a hole through the conker. That's brilliant. Why did this never occur to me? That's going on the list of things to tell my younger self when time travel becomes possible. reply red_admiral 10 hours agorootparentprev> Also, doesn't the conker spiral around your hand hitting it and hurting you? It does until you learn, usually quite quickly, to do it properly. Hurting your opponent's hand is a different matter :) reply looperhacks 12 hours agorootparentprevI'm not from Britain, but we used to craft with chestnuts. We always used a small hand drill (Wikipedia tells me it's called a gimlet). I assume it's the same in Britain reply dageshi 11 hours agorootparentprevWe randomly had something like this in our kitchen draw... https://www.amazon.co.uk/SpitJack-Trussing-Butchers-Roasting... Attach string, push through, detach string and remove. reply riffraff 11 hours agorootparentsweet! reply tjalfi 6 hours agorootparentprevThe memoir Where Did You Go? Out. What Did You Do? Nothing describes using a heated icepick. You take a chestnut, and you hook the ice pick. You wait until nobody is in the kitchen, and then one kid presses down on the pilot-light button so that a long delicate blue finger of flame comes out, and the other kid puts the ice pick in the flame until it is red-hot. When it is, he bores a hole in the chestnut. You do as many as you can until somebody comes and asks you what you are doing, and then, according to your standing in the family, that day, you either plead, argue, or say, “Oh, jeez,” and slink away. reply LandR 12 hours agorootparentprev> your hand hitting it and hurting you? WHen you were a kid, accidentally hitting yourself or the other person was just part of it! reply Nursie 12 hours agorootparentprevA gimlet? Hammer and a thick-ish nail? Honestly I can't remember how we used to do it. Might even have used a hand drill at some point. They're fairly soft when you've made a hole in the shell, so you might get away with a screwdriver? When at school we probably made do with a compass (the drawing kind), as we all had them. I'm sure that resulted in a pretty high rate of conkers being destroyed before they could be strung, and a lot of ruined compasses. > Also, doesn't the conker spiral around your hand hitting it and hurting you? Generally not, though the game isn't without its minor hazards :) There's a (very sweet) video here that seems to do a good job of showing the process and the game - https://www.youtube.com/watch?v=cLGuZZraIqg Through the exact rules are up to the players and I personally consider the \"stamps\" rule they mention to be foul play :) reply riffraff 11 hours agorootparentcompass makes a ton of sense, and that is indeed a sweet video, thanks for sharing! reply bluehatbrit 11 hours agorootparentprev> Also, doesn't the conker spiral around your hand hitting it and hurting you? Not usually in my experience, the string isn't that short and you're holding it at one end. Injury is still possible though, but that's part of the fun! reply tankenmate 12 hours agorootparentprevHorse chestnut shells are very hard, normally you would drill the hole. reply conkers 9 hours agorootparentprevWe used a corkscrew then threaded a shoelace through it. reply lisper 12 hours agorootparentprevHere's a video that explains it: https://www.youtube.com/watch?v=cLGuZZraIqg And one from the championship: https://www.youtube.com/watch?v=k5t6ej8Jzew And here I was thinking that curling was the most ridiculous-looking sport in the world. I stand corrected. reply RandomThoughts3 8 hours agorootparentI don’t think conker players pretend it’s a sport. It would ihmo be more accurate to call it a game. reply lisper 3 hours agorootparents/sport/organized competitive activity/ reply pixxel 12 hours agorootparentprevIf my memory serves me: you used to announce your conker as a “two-er”, or “three-er”, for example, to inform your opponent how many conkers your particular conker had previously claimed. If your opponent decided to challenge you and won then they would claim your “three-er” and add its win total to their own. So a “two-er” would become a “five-er”. reply Ntrails 12 hours agorootparentI also recall this, but suspect sometimes numbers may have been inflated... reply jamiek88 12 hours agorootparentI at nearly 50 years old still own my undefeated 48’er. It’s on a yellow bootlace in a box in the loft at my dad’s house. reply Nursie 12 hours agorootparentprevThis is really probing the dusty, cobwebbed corners of my memory but yes, I have a very vague recollection of a 'six-er' being somewhat special... reply flir 9 hours agorootparentThe phrase \"a sixer at conkers\" is floating to the surface. Was it that once you reached six, you stopped counting? Or do you retire it, undefeated? reply hackernewds 12 hours agorootparentprevI'm having the utter best time as a 12 year old replacing conker with something less wholesome reply cultofmetatron 9 hours agorootparentprevsoo.. bayblade with nuts? reply traceroute66 9 hours agoparentprev> Is this game well-known enough in Britain and Ireland that readers will know what on earth is being alleged just from reading this article? Absolutely. Very well known. My Youtube-fu is not with me, so I can't seem to locate this video on Youtube, but see this BBC Archive footage from 1971 that was posted on Instagram[1] from a BBC News Report entitled \"Conkers is no longer a kids' game.\" [1] https://www.instagram.com/bbc_archive/reel/DA7zkmkAShz/ reply mikeodds 15 hours agoparentprevInnate knowledge to Brits, similar to knowing a swan might break your arm reply thebruce87m 12 hours agorootparentDon’t draw on your hand with a pen or you’ll get ink poisoning reply walthamstow 12 hours agorootparentDon't make that silly face. If the wind changes, it'll stay like that forever. reply gsck 9 hours agorootparentDon't lean on your chair, I had a student who died doing that reply royletron 9 hours agorootparentEating carrots makes you see in the dark reply zeristor 11 hours agorootparentprevHow holding a feather and you’ll get a “red ring of fungus” in your hair. I thought that was stupid then as well. reply DougN7 15 hours agorootparentprevLol, I don’t understand what THAT means! A swan might break your arm?!? reply seanhunter 14 hours agorootparentI emigrated to Britain. These sorts of things mystified me for the longest time. Yes. Picture some British parents and their child on a walk near a pond, river, canal or whatever. The child sees a swan. The parents will say something like \"don't get too close dear, it could break your arm\". Swans are aggressive so it's probably not terrible advice, but not because they go around breaking people's arms specifically. reply MonkeyClub 11 hours agorootparentAnecdotal reports, all of them true I'm sure: https://www.theguardian.com/notesandqueries/query/0,5753,-24... Lovely read! reply robinsonb5 11 hours agorootparentprevThe idea that a swan can \"break a man's arm with a blow of its wing\" is (or was) ingrained enough into the British psyche that Peter Cook's comic creation, Arthur Streeb-Greebling, once said of his mother that she could \"break a swan's wing with a blow of her nose.\" reply throwup238 15 hours agorootparentprevIt’s the British version of an urban myth. It’s like an urban myth… but more British. reply nickyvanurk 14 hours agorootparentprevIn the Netherlands we are also taught a swan could break your arm if you get too close. I don't know if it's true or not because I've been too scared to find out. reply defrost 14 hours agorootparentThey're not going to hold you down and break it with a tire iron .. but I'll bet for certain that Swans are responsible for arms being broken. They've got a pretty savage and scary charge to them, it's highly likely they've startled more than one person in a park who've turned to run, tripped and fallen across steps or rockery edges and come out badly injured. reply JoachimS 12 hours agorootparentThey are also able to swing their wings quite rapidly while charging you. In this way they can throw a surprisingly hard punch. But not break bones in healthy humans - kids included. https://outdoorswimmer.com/coach/myth-busting-can-a-swan-bre... The beak is probably more dangerous, or at least give you a nasty pinch or nibbing. reply defrost 12 hours agorootparentBlack Swans in Perth, herdsman Lake and elsewhere, in the 1980s during breeding season (and likely still today) fully charged people and had the mass to knock over more than one kid or small teenager .. and scare the bejeebus out of many adults. As I said, and supported by your link, I can't see a swan directly breaking a human bone - but they sure as hell can knock one arse over by charging and causing a step back fall over. That'll do some damge in some cases, easy. reply t-3 10 hours agorootparentI've never been charged by a swan, but I have been knocked into a ditch by the slightly smaller but no less aggressive Canada Goose while biking. No broken bones, but I did have to straighten the alignment of the wheels on my bike. reply praptak 12 hours agorootparentprevThe smell test here is that swans are flying birds and a human is large(-ish) land mammal. Nature just cannot make a flying bird's bones strong enough because they have to be much lighter. If we play conkers with each other's bones the swan will lose. reply JoachimS 11 hours agorootparentUpvote for the subtle reference to the conkers story (https://news.ycombinator.com/item?id=41844545). reply MonkeyClub 11 hours agorootparentIt's this thread, did you suffer HNception? :) reply JoachimS 3 hours agorootparentNo, hit in the head by a black swan, thats all. reply vidarh 11 hours agorootparentprevWas bitten by a swan as a child. Painful by all accounts, but not enough for me to remember the pain, though I recall being more careful around swans afterward Probably more scary for my parents. reply beezlewax 14 hours agorootparentprevYe and the queen eats swans for breakfast or something like that. reply seanhunter 12 hours agorootparentLess often since September 2022. reply louthy 7 hours agorootparentWe still have a queen, just not the one we want ;) reply Nursie 14 hours agorootparentprevAll swans are owned by the crown and the monarch has the exclusive right to kill and eat them. Or at least that's the way I heard it, come to think of it I have no idea at all if that's true. Stops people killing and eating swans though. Not that many would anyway these days. reply lmm 13 hours agorootparentSt John's College serves swan on formal occasions sometimes, because they have some connection to the royal family that means they have special permission. (Or used to in the Queen Elizabeth days, I don't know if they still do under Charles) reply louthy 7 hours agorootparentprev> All swans Not all, just mute swans; so not Bewick’s or whoopers (if I remember correctly) Edit: “His Majesty specifically owns any unclaimed mute swan in open water in both England and Wales in a ceremonial fashion. This has been a law since medieval times. His ownership is shared with the Worshipful Company of Dyers, granted to them by the Crown in the 1400s.” https://royalcentral.co.uk/uk/king/does-the-king-really-own-... reply inopinatus 13 hours agorootparentprevit is a custom more honour’d in the breach than the observance reply globular-toast 12 hours agorootparentprevApart from the ones at Abbotsbury swannery. Those ones are privately owned. It is true to say all mute swans in Britain are owned by someone, though. reply Finbarr 15 hours agoparentprevYes, it is. It’s a game most news-reading-age adults will have played when they were at school as children. reply fy20 14 hours agorootparentIt's a game you play as a kid. This is the first I've heard of there being a professional league. On the other hand, we also have competitions such as cheese rolling (trying not to get killed by a giant cheese wheel rolling down a hill), so I'm not that surprised. https://www.bbc.co.uk/news/live/uk-england-gloucestershire-6... reply buggeryorkshire 11 hours agorootparentI did that race twice, dislocated my left shoulder each time. Scariest thing i've ever done. People have the misapprehension that you're supposed to catch the cheese. No idea why you'd think it's a good idea to catch a rock hard lump whilst running down a hill so fast that if you tense your legs once to slow down you do 3 cartwheels. Also just remembered - they have local rugby players to catch those who can't stop running from hitting the fence of the house at the bottom. Saw at least one person they missed who smacked into the fence and got carted off by St John's Ambulance. reply ackbar03 14 hours agorootparentprevI know the version where you try not to kill yourself chasing the cheese. Are you saying there's one where the cheese chases and tries to kill you? reply riffraff 13 hours agorootparentI feel we've entered Terry Pratchett territory in this thread, and I'm very happy about it. reply stoneman24 12 hours agorootparentprevShhhh! The first rule of cheese-chase is never talk about cheese-chase. British coroners know the signs…. reply saretup 14 hours agorootparentprevIf it is a serious game, I’m surprised they don’t examine the chestnuts first reply 0110101001 12 hours agorootparentThe alleged cheater was also the head judge of the tournament. reply triceratops 3 hours agorootparentFurther evidence that it isn't a serious tournament. In what other sport does the referee also play? reply throwup238 14 hours agorootparentprevGeez, we just had tetherball. No one tried to destroy each other’s nuts. reply jalk 12 hours agorootparentIf we had those in my schoolyard, that would literally happen within 5 minutes -\"spinny-spinny-whack-to-the-sack\" reply red_admiral 10 hours agorootparentYou're starting to get why the game used to be so popular. reply worthless-trash 14 hours agorootparentprevThey did at my school. reply fargle 14 hours agorootparentroshambo. southpark style. reply Wildgoose 9 hours agoparentprevSo well known that it was even famously used in an advert for a kid's chocolate bar: https://www.youtube.com/watch?v=nC9BBLSZZdQ reply oneeyedpigeon 9 hours agoparentprevIn Britain, it's very well known by those of us who are 40+, and I think even younger people will at least have heard of it, even if they haven't played it themselves. It was an absolute staple of playgrounds in the 1980s. There's a rich history of supposed 'cheats' — boiling the conker in vinegar was a classic. And, note, conker, not chestnut (two different things). reply b800h 11 hours agoparentprevYes, it's a quintessential childhood game here. You take turns to have a single swing at the opponent's conker, until one of the conkers is smashed off its string. Cheating is a bit of an art. Baking the chestnuts at the right temperature was one method; a friend of mine filled his conker with glue. reply harperlee 12 hours agoparentprevIt is in Spain, any self-respected pre-smartphone-childhood person has at the very minimum least seen this in action at the playground. reply el_oni 13 hours agoparentprevIt's sufficiently well known that as a British 30 something I understood what was being alleged just from the headline reply krispyfi 14 hours agoparentprevI only know of the game because the Conkerer web browser was named after it. http://conkeror.org/ reply FearNotDaniel 14 hours agoparentprevYes, conkers is sufficiently well-known enough as a children's schoolyard game that I would expect pretty much every newspaper-reading adult to have heard of it. The fact that there is supposedly an \"adult\" championship event would be a surprise to most. If you're looking for the \"story behind the story\", other than the fact that it's a seasonally-specific, light human-interest story: there is probably a slight cultural bias amongst those who most fondly remember the game towards the private-school-educated, upper-class types who combine nostalgia for imagined \"glory days\" with political conservatism, so this is a good opportunity for the left-leaning Guardian to hand-pick someone who appears to belong to that class and expose them as a ridiculously-dressed scoundrel with childish interests and suspect morals. The subtext is: these are the sort of idiots we want you to associate with Nigel Farage, Boris Johnson and co, and thus the Overton Window gets a tiny nudge in the opposite direction. reply yashap 13 hours agorootparentI think you’re reading way, way too much into this. Read the piece and it seems like just a goofy little oddball story, makes for a light and enjoyable read, I’m really not picking up any political angle in this piece. The Guardian are certainly a left-leaning, frequently political paper, but that doesn’t mean every story is political, and IMO this one isn’t. reply willvarfar 13 hours agorootparentprevThis is silly. Conkers aren't a rich person's sport, and this article in the guardian isn't pushing any political subversive subtext. reply bboygravity 13 hours agorootparentNews is what you don't get to read. The rest are political ads. reply blitzar 11 hours agorootparentI heard the conkers cheater was an illegal immigrant, the establishment covered it up and now they wont even report on conkers anywhere in the main stream media (/s?) reply ttctciyf 11 hours agorootparentprevRight on. Contrast the BBC's take: First American wins World Conker Championships[0], which focuses on the winner's family's pride, the \"lovely little village\" where the tournament was held, the American visitor triumphing over churlish natives heckling her, and concludes with a cozy panegyric embracing both tradition and the New World Order (of conkers): > \"Our overall champion, Kelci Banschbach, is our first American Queen Conker and David Jakins, previous finalist and long-standing committee member, very much deserves his King Conker title.\" In typical fashion, the Establishment's champion declines to even hint at the underlying corruption. 0: https://www.bbc.co.uk/news/articles/cr75xyn1rd8o reply ccppurcell 13 hours agorootparentprevIt never occurred to me that conkers could be a class thing and you could be right. But let it be known that conkers was extremely popular at my state school; me and all of my friends grew up to be pretty left wing too by the way. Also they banned it at my school, along with pogs, yoyos, etc. reply Closi 13 hours agorootparentIt's not a class thing. Fox hunting, horse riding, polo and skiing... yes. Conkers, No. reply robjan 13 hours agorootparentWherever there is a chestnut tree you'll get conkers. I would imagine it's more of a town/village vs city thing rather than class thing. reply swores 13 hours agorootparentWhich of those are you imagining doesn't have horse chestnut trees? (Conkers come from those, not plain chestnut trees) I'm sure there are parts of the country where they're less common, but there's huge numbers of conkers falling off trees in big British cities (even if the majority will be in parks) as well as in the countryside. We played with them at my pre-teen city centre school for sure, and the trees are a common sight on roads and in gardens as well as public parks. edit: the Woodland trust actually says \"Though rarely found in woodland, it is a common sight in parks, gardens, streets and on village greens.\" reply seanhunter 12 hours agorootparentLive in London in Zone 2 and there are absolutely tons of conker trees around me including in areas which are not posh. They are very common in an urban setting.[1] [1] Which kind of sucks for me personally because they cause me really terrible hayfever. I think I'm specifically alergic to their pollen maybe. reply arethuza 11 hours agorootparentprevDepends where you are - I went to a very modest comprehensive in Scotland and yet we still went skiing at weekend to Cairngorm because it was close. reply m463 13 hours agorootparentprevWhat if you ski in jeans? reply dagw 11 hours agorootparentSkiing is a much more expensive activity in most of Britain, mainly since it requires taking a week off work, international flights and hotels to be able to participate. And to become good at skiing you'll have to do that once or twice a year for many years. In places where the local ski slope is a bus ride away it is much less of a class/wealth thing. reply arethuza 11 hours agorootparentThe height of ski chic in Scotland used to, at least when I skied regularly, consist of offshore foul weather gear emblazoned with the name of the oil company (or oil service company) the wearer had borrowed it from. reply peterleiser 12 hours agorootparentprevExactly! I used to ski double black diamonds in the Sierra Nevada range wearing jeans, with gaiters to keep the snow out of my boots. reply blitzar 11 hours agorootparentprevEton wall game is a class thing. Conkers is not. https://en.wikipedia.org/wiki/Eton_wall_game reply defrost 11 hours agorootparentConsiderably more pleasant than the St. Tadger's Day wall game played at Graybridge public school. https://youtu.be/dDjV9iKmT9k?t=118 reply conkers 6 hours agorootparentprevConkers is about the least upper class game i can think of. We played it on council estates. reply CSSer 12 hours agorootparentprevIn Britain, maybe. In the USA, I don’t think so. reply vidarh 10 hours agoparentprevI'm Norwegian, but have lived in the UK half my life, since I was 25, and I'm aware of it, though have never seen it played. I think most people who have lived her for a while will at least have heard references to it. reply isodev 15 hours agoparentprev> Is this game well-known enough in Britain and Ireland I’m from elsewhere in Europe and I know about it from high school and it’s also something that pops up in the world sports section on news websites every now and then. reply echoangle 12 hours agoparentprevIs the game skill-based? How can you influence which chestnut breaks? Is the challenge chestnut selection? Or a specific swing method? reply beAbU 11 hours agorootparentI find it highly suspicious that the reigning champion gets to drill the holes in the conkers. You can intentionally make some of them weaker by drilling closer to the edge or something. I assume the conkers are provided by the organizers, and the participants must select their conker from the collection or given one at random. Prevents tampering I guess. reply dagw 11 hours agorootparentI assume the conkers are provided by the organizers Going around the conker trees in your area and finding the perfect conker is a huge part of the game. There is also a certain amount of pre-game 'modification' that are generally allowed, like soaking them in various solutions, or baking them in an oven. Having to use a provided conker would be like showing up to the Tour de France and being assigned a bike by the organisers. reply joncrocks 10 hours agorootparentIndeed, but apparently this is the way it works. I suspect to prevent 'foul-play' - https://en.wikipedia.org/wiki/World_Conker_Championships#WCC... reply dagw 9 hours agorootparentI stand corrected. Perhaps Tour de France should apply this rule as well to avoid foul play? reply echoangle 11 hours agorootparentprevI thought it might be like formula 1 where having the right equipment is part of the challenge. reply yabatopia 8 hours agoparentprevHere are some pictures of a previous championship: https://www.theguardian.com/technology/gallery/2015/oct/12/5... . reply jareklupinski 13 hours agoparentprevin my schools, the closest analog was probably using the school-supplied sporks to engage in \"Spork Wars\" (not the best example but it will do https://youtu.be/vO7SclBfpZ8?t=145 ) though through the \"draft\" nature of which spork you would receive, we never had a controversy on the level of the article's: > \"There are also suggestions that King Conker had marked the strings of harder nuts\" reply fmbb 12 hours agoparentprevSwede here. I know from just reading the headline what happened. Byt then I’ve watched some British costume dramas. reply 256_ 12 hours agoparentprevI'm British. I only have a very vague memory of the game from my childhood. I didn't remember what the goal was, but I remembered you have to hit the opponent's one. I don't remember if I ever played it or not. reply ddmf 11 hours agorootparentYou hold the conker in one hand and the string in the other with some tension and then release so it pings and bashes the other players conker, hoping to smash it off the string. Repeat until one conker is smashed into oblivion. If your conker wins against multiples it becomes named mythically: a twoer, a threer, and so on. I once had a niner. a fiver took it down. reply eru 6 hours agoparentprev> Is this game well-known enough in Britain and Ireland that readers will know what on earth is being alleged just from reading this article? I got the gist just from reading the headline, yes. And I'm not even a limey, I just lived there for a few years. reply MasterScrat 10 hours agoparentprevHere's how it looks like apparently: https://youtu.be/hXUbTKd6pmo?t=29 reply Aardwolf 10 hours agoparentprevI only know about conkers due to photonicinduction's youtube video where they play conkers with two CRT televisions attached with ropes to the ceiling However even without knowing that I think reading the article makes it clear enough what it's about and that a steel chestnut shattering the other one seems like an unfair advantage :) reply xg15 11 hours agoparentprevWas confused too. My first thought was about conker crafting [1] and I was puzzled that there was a world championship for it and people were serious enough about it to cheat - but then again, weirder things exist... [1] https://curiousandgeeks.com/conker-animals-autumn-crafts reply 1659447091 14 hours agoparentprev> it’s a game where you take turns swinging a chestnut on a string and trying to hit the opponent’s chestnut and break it. Sounds like a British version of pencil break - but with way more scandal, apparently reply ZiiS 11 hours agoparentprevMore UK people will have played conkers then soccer. reply MonkeyClub 10 hours agorootparentMore Brits will have played football than soccer too, I believe. reply aardvark179 14 hours agoparentprevI think most people would know just from the headline. reply bee_rider 15 hours agoparentprev> The 23-year-old said: “My conker disintegrated in one hit, and that just doesn’t happen … I’m suspicious of foul play and have expressed my surprise to organisers.” It seems the suspicious was pretty quick. reply umanwizard 15 hours agorootparentIt’s just crazy that someone would cheat at something so low-stakes with such a high probability of being caught, but I suppose I shouldn’t be surprised. reply aniforprez 14 hours agorootparentPeople cheat on online cooperative computer games like Helldivers with almost no rewards for being performatively better other than a few imaginary in-game points. People can be weird about the smallest things reply umanwizard 14 hours agorootparentFair enough. People cheat at chess too which makes absolutely no sense to me. reply sonzohan 14 hours agorootparentNot just cheat but cheat using Bluetooth butt plugs at an extremely high level of play (https://nypost.com/2022/10/06/chess-champ-gets-butt-inspecte...). Some people have all the fun. reply umanwizard 14 hours agorootparentYou shouldn’t state it so confidently as fact — nobody has ever produced any evidence that Hans Niemann cheated over the board (let alone with a Bluetooth butt plug, despite all the memes to that effect). I generally don’t like Hans and think given how many times he is confirmed to have cheated online he doesn’t deserve the benefit of the doubt. But still, claiming the butt plug meme as fact is going a bit too far. reply reaperman 13 hours agorootparentThank you. This is the kind of speed-of-correction (~20 min or less) that is needed for social media discourse to work effectively. Indeed, no evidence has been found, this was just a silly meme from Reddit which predated the Hans drama by several years. When the Hans drama happened, of course Redditors started making silly flippant references to this joke. But some people didn’t understand that those were references, instead mistook them for actual “accusations”, bought into it, and started actually seriously perpetuating the accusation/rumor. It was repeated often enough in juuust serious enough tone that tabloid journalism eventually picked it up and ran stories with it. But overall perhaps the false rumors might have been a good thing? Depending on how you balance/weigh personal harm to Hans Niemann vs. How FIDE’s response benefited championship-level players. The rumor/tabloids in combination with Magnus Carlsen’s very loud whining(?) got FIDE to greatly upgrade their security posture and now they walk through metal detectors and their shoes are put through metal detector/scanned manually. So it’s very hard to hide controls for something like this at the moment. Worth noting that radio-controlled / WiFi buttplugs actually made for sex often fail to pick up their command signals because the flesh attenuates the signal too much. The most reliable ones have an antenna exiting the body (kind of like the Lovense Lush or Vulse series). I don't know if metal detectors will pick up an ESP32 and an antenna and a lithium battery large enough to power that for up to 6 hours or so…but I think they might? Normally I’d expect the butt part to just be the RX, with TX done with the toes or something rather than by butt clenching some kind of morse code, which would require some moderately impressive signal processing and a lot of player-practice. Any non-butt-clench TX would be very very to get past the current FIDE anti-cheating-device screening. But maybe someone could get away with something built on the same platform as the O.M.G. cable - but I still expect the power demands of WiFi to require a battery big enough to be detected. Or maybe someone could get away with a tiny-enough battery by dropping power-hungry wifi in exchange for LoRA (1x) / long range BLE (10-20x) / SigFox (1-2x) / IEEE 802.15.4 (Zigbee & Thread) (5x-10x) / NB-IoT (50x-100x)? Multipliers are for rough energy-per bit estimate. Anything else would have too short of a range; would need to be at least reliable at 50 feet. So probably LoRA because it has both lowest energy-per-bit as well as excellent long range. With an optimized microcontroller strategy and wireless strategy, most of the battery energy would be used for the motor. A small cell phone vibration motor (weakest you could get away with and still reliably feel) uses 60mA at 3V. A lithium coin cell battery can only provide around 1% of that current, so you’d need a bigger battery - at least 100mAh lithium weighing approximately 3g (75% of this is metal). A cell phone vibration motor weighs about 1g (all metal). The world’s smallest Lora module with included microcontroller (FMLR-6x-x-MA62x) weighs about 16g (not sure what % of that would be metallic, lets say 10% as a low-boundary worst case). So at minimum you’d be looking at 5-6 grams of metal for this cheating device (which has no input device at all!!). This is approximately the weight of one US quarter. It is right at the limit of what walk-through metal detectors are rated to detect on their highest sensitivity. NIJ level 3-certified metal detectors like the Garrett PD 6500i are designed to be able to detect a steel handcuff key which weighs about 4 grams. The manual for this scanner includes a technical drawing for a reference design of a test “handcuff key” so that customers can validate this performance themselves. Is FIDE using an NIJ level 3 metal detector? I don’t know. But if they are, it would be impossible to get a radio-controlled buttplug through without detection. reply umanwizard 13 hours agorootparent> Depending on how you balance/weigh personal harm to Hans Niemann vs. How FIDE’s response benefited championship-level players. It’s certainly a good thing that security is being taken more seriously now. And I have zero sympathy for Hans. He chose to destroy his credibility by cheating online and, regardless of whether he also cheated over the board or not, has only himself to blame for the fact that people don’t trust him now. Given how easy it is to cheat in chess, reputation and trust are really all you have, and if you decide to squander them, well, that’s on you. reply bee_rider 14 hours agorootparentprevCheating at a PvE game like Helldivers is basically a victimless crime (I don’t do it, but I can see why people would). reply blitzar 11 hours agorootparentIt is a crime against oneself. reply bee_rider 5 hours agorootparentIt is a pretty straightforward wave shooter game. I had fun with it, but it isn’t high art or anything. I enjoy games like Hades or Dark Souls where the fact that you keep losing is an interesting part of the narrative and builds the overall ambiance. Helldivers (2, at least) is not really that sort of game, the plot is more like fun, even sillier Starship Troopers. I played it properly, but I think is somebody decided to fast-forward through some bits they wouldn’t be denying themselves too much. reply a_t48 14 hours agorootparentprevCheating with only your friends - yeah, mostly. Cheating with randos sounds like it would lead to boring gameplay. reply wcfields 14 hours agorootparentLike, you can cheat at Solitaire, but why? reply shermantanktop 14 hours agorootparentHey, dopamine is dopamine. This ain’t stolen valor or a plagiarized thesis. reply smolder 9 hours agorootparentI think it's a special kind of person that gets a kick from \"winning\" at something that's not a challenge. You might as well write \"winner\" on a t-shirt in marker and wear it. reply bee_rider 1 hour agorootparentI don’t really know that it is cheating to get a “win” label. Maybe it is just a distraction or fun flashing lights. Do you remember being a child and just playing with action figures? It was harmless and fun. I wonder where we lose that ability to just chill and have fun without a challenge. Actually, a lot of people seem to just spend a lot of time watching TV, which is also fun without challenge. reply lazide 3 hours agorootparentprevSpeaking of which [https://www.thepopculture.co/products/need-room-full-mirrors...] reply oblio 10 hours agorootparentprevThe games cheat industry was huge[1] back before the internet was a major thing. Entire books about cheat codes, walkthrough to get the best gear and to beat the game in the easiest way possible, then websites full of cheats, etc. People, on average, like to do the easiest thing possible and on top of that, they frequently like to brag about what they've achieved and how good they are. Social animals and all that. [1] By the standards of the time. reply r053bud 10 hours agorootparentprevI dunno. The article states that David Jakins has been competing since 1977 and has never won. He was also a Judge, so this game seems to be extremely important to him for some reason. I guess he wanted to win by any means necessary before he has to retire from the sport permanently due to age or physical limitation reply cen4 14 hours agorootparentprevVeblen called sports Conspicuous Leisure. The goal is not fun but that everyone sees you win. So Stakes are Status. And Status gets people things in the same way Cash does. reply block_dagger 14 hours agorootparentprevHe is approaching the end of his life and been competing for decades but never won. Risk vs reward. reply karaokeyoga 14 hours agorootparentprevcf. wordle reply Theodores 9 hours agorootparentprevPlaying conkers at 23 years of age is a bit wrong. It is a bit like building LEGO kits as an adult, particularly wrong if the goal is to just build the design on the box and put the completed model on a shelf, rather than build your own creative masterpiece. Please resist the urge to mod me down in flames for the above, but, in former times, buying LEGO at the ripe old age of fourteen would be a bit shameful in the school playground. Adults did not play LEGO then, it was the role of the father to read the newspaper and the role of the mother to be 'chained to the sink' in those days, with LEGO just for small children. Conkers was very much for younger children, once an interest in the opposite sex, playing cards for match sticks or general juvenile delinquency was established, conkers was 'grown out of'. Much like how fathers could teach their sons to beat up bullies, so it was that fathers could help with the technical aspects of conkers, such as getting the hand drill out (remember those contraptions, before battery power tools). Conkers was a rite of passage, something that you would be expected to grow out of. It also came with a season, i.e. autumn, and the etiquette was to pick on someone of your own size. Hence, someone playing conkers at the age of 23 has not really got it right. As for the guy with the steel conker, again we have a problem of age. Now, as for playing with LEGO as an adult, or playing conkers as an adult, or, for that matter, the retro 8-bit computer scene, this is about regressing from the adult world of today, with all of its problems, and hiding in a recreated childhood. This is sort of understandable for people that were sent off to war, to see things they did not need to see. Those people kind of need the therapy that a return to the child world provides. But nowadays, I see it as a response to the atomisation of community. If you are not spending your weekends with friends at pubs or at dinner parties, if you don't have an adult hobby such as with a lathe in a shed, if you can't afford big toys such as a boat, then childhood hobbies are a safe space to return to. Apart from anything else, you can buy all the LEGO that you could not buy then. Or, with conkers, you can find a social scene of like minded individuals and get a bit more scientific about winning. reply samatman 2 hours agorootparentFor the record, I read your entire post before downvoting it, which I did because I disagree both with your diagnosis and its prescription (or perhaps I should say proscription). While there is somewhat of a crisis of adulthood, I find it feasible to salvage the concept without carrying forward the sort of smothering social conformity you seem to advocate as a necessary condition. reply thih9 12 hours agoparentprevCan you cheat by purposefully missing the opponent’s conker? Thus reducing the total impact on conkers in this match vs conkers in other matches and getting an advantage? reply krisoft 11 hours agorootparentBut then how would you smash theirs? That sounds a bit like cheating by staying at home and not playing. reply lmm 6 hours agorootparentprevYou take it in turns to hit, moving yours on their turn is cheating. Given that you have a lot more control over what kind of hit happens on your turn than on theirs, skipping your turn is never going to give you an advantage (unless your opponent is somehow anti-competent). reply bluehatbrit 11 hours agorootparentprevI can't imagine so. A match is over when one persons conker is destroyed. If you were purposefully missing, you'd be throwing the game. Theirs would still take a battering from hitting yours as well. reply ndndjdjdn 9 hours agoparentprevYes. Usually conkers were banned at school. So we had to play space invaders, for which you need a tennis ball not an Atari. reply entropyie 7 hours agoparentprevYes it is, everyone I grew up with in Ireland played conkers. reply ddmf 11 hours agoparentprevgosh i remember those halcyon days back when I had a niner, sadly it was taken by a fiver. reply OJFord 10 hours agoparentprevYeah, like saying 'tetherball' or 'keep-away' to someone in the US; which I only know from a Monk episode I watched last night. I didn't know and wouldn't have guessed there were world championships, though. reply OJFord 1 hour agorootparentMissed the edit, but just to add 'keep-away' is 'piggy-in-the-middle' in the UK, and I don't know if perhaps you have it too but 'swingball' is a similar game to 'tetherball' but played with a tennis ball & (typically not tennis, but just cheap plastic thing for the purpose) racket. reply yoz-y 10 hours agoparentprevThey did play conkers with cranes and caravans in Top Gear, so I feel that at least a large portion of non Brits will know the game from there. reply fedeb95 9 hours agoparentprevit's pretty easy to infer by the article. Or ask GPT-n to do it. reply samuelec 10 hours agoparentprevI'm puzzled as well, what the heck the article is talking about and why it's posted here? reply physicsguy 12 hours agoparentprevYeah it’s a game you play as kids. reply techterrier 15 hours agoprevSome people pay for conkers But I get mine for free I go round my grandmas house She's got a horse chestnut tree reply physicsguy 12 hours agoparentBass drop I love the glimpses that give away the British people on here. Sometimes I feel like I’m the only one but this thread has brought them all out reply niffydroid 7 hours agoparentprevThis wins the day for me reply benoliver999 14 hours agoparentprev... conkers reply bee_rider 15 hours agoprevIt seems like a bad move to have a participant responsible for drilling the holes and attaching the strings. Also I don’t understand the one paragraph aside about the American who is never mentioned before or after(?) reply boomboomsubban 15 hours agoparent>It seems like a bad move to have a participant responsible for drilling the holes and attaching the strings. It is probably the kind of event where the only people who would be willing to do the timely prep work are the contestants. reply silisili 15 hours agoparentprevThe guy the article is about won the men's. At the end, the men's champ plays the women's champ for overall champion. This American mentioned was the women's champ, who apparently went on to beat him. Which either means he wasn't cheating, or was and then played fairly on the last match? reply penjelly 14 hours agorootparentI assume he wouldn't cheat everytime and instead would only do it to reduce the overall wear on the chestnut over many matches? reply umanwizard 14 hours agorootparentApparently they pick a new one each round. reply mbo 14 hours agoparentprev>It seems like a bad move to have a participant responsible for drilling the holes and attaching the strings. Part of the \"point\" of conkers is that conker-prep is just as much as a skill as the technique during the hitting phase. I think this was just poor scrutineering (or corruption) on the organizers side. reply bee_rider 13 hours agorootparentThat would make sense to me, but it seems like maybe it isn’t how they did it? > Jakins was responsible for drilling and inserting strings into other competitors’ chestnuts as the competition’s top judge, known as the “King Conker”. reply nealmueller 15 hours agoprevThe World Conker Championships is an annual event held in England, where competitors from around the world play the traditional game of conkers using chestnuts. Each player threads a chestnut, known as a conker, onto a string and takes turns striking their opponent’s conker, aiming to break it. The tournament follows a knockout format, with players advancing until a world champion is declared. The event has been running since 1965 and has grown in popularity, drawing international participants and spectators. reply k7sune 14 hours agoparentConsidering that it's called a world championship, someone should study the sport in-depth! Are the players allowed to swing the chestnut in a circle like a sling? Can they use carbon fiber strings, or maybe some sort of elastic string to build up more energy? Or can the player use a heavy string so it can crack like a whip? Fancy arm/wrist/fingers movements to accelerate the chestnut in the last moment? What's the optimum strike angle to crack a chestnut along its natural cleavages? This could be so exciting! reply Someone 11 hours agorootparentI’m do not think you always want to hit them hard. If our understanding of physics is right, it doesn’t matter whether you hit them or they hit you. the two conkers hitting each other harder likely will lead to an earlier result, but it will also favor the conker that can withstand few hard blows over one that can withstand many softer ones. So, assuming you can somehow judge how well your and your opponent’s conker do in this regard, you may want to go either for brute impact or for many rounds. > What's the optimum strike angle to crack a chestnut along its natural cleavages? I think that’s more important. Even idealized conkers are fairly asymmetrical, so possibly, the ‘bottom’ of one hitting the side of another is a winning or losing strategy. If so, it’s more a matter of timing than of being brutal, at least for hypothetical perfect players. Whether humans can do much here, I wouldn’t know. reply mega_dean 4 hours agorootparent> If our understanding of physics is right, it doesn’t matter whether you hit them or they hit you. That was my first thought too, but I don't know if it's true because of the strings they are attached to. The striking conker is at the end of a taut string the entire time, but the receiving conker is hanging loosely and bounces around after being struck. My guess is that the taut string helps with energy dissipation after a collision, but I could be wrong. And either way, it might be a negligible difference. reply aembleton 9 hours agorootparentprevThe strings and the conkers are supplied by the organisers. Contestents can't use different types of string. reply 1propionyl 14 hours agorootparentprevThis all kind of takes the fun out of it don't you think? Not every game needs to have the fun sucked out of it by endless optimization and instrumental play. Just conk some chestnuts. Simple as. reply bee_rider 13 hours agorootparentWell, the winner this year was an American so I bet we’ll be back next year with high tech nano-engineered strings and carefully bred chestnuts. reply Timwi 13 hours agorootparentprevWhat you find fun or unfun need not match other people's preferences. You can tell us what's fun or unfun for you, but you can't tell other people they're having fun wrong. I personally find a lot of optimization problems very fun and can keep at them for a long time. reply polynomial 12 hours agorootparentStop optimising my fun! :-p reply exhilaration 15 hours agoprevWhat is conker, you ask? Here's a video: https://www.youtube.com/watch?v=3LcaUTAuQfc reply IncreasePosts 15 hours agoparentThe alleged cheater is in this video @3:29 reply x0x0 15 hours agoparentprevI was very confused by that link calling it a horse chestnut. That is not what I grew up calling a horse chestnut, ie the keratin thing that your farrier trims (or you do with a rasp.) Separately, what an absolutely nutty thing to cheat at. Thanks for sharing the video! reply butterfly42069 15 hours agoprevThey said he had balls of steel to try that one For the yanks and elsewhere, yes conkers is well known in Britain. You basically put a chestnut (but its a conker) on a string by making a hole in the middle. Take turns swinging them on the string, whoever's breaks is the loser. It used to be great fun till it was banned/requires eye protection now. There's an opportunity there, someone could make a perfectly safe conker app. I'm sure that would adequately replace it. /s reply ungreased0675 14 hours agoparentHow is it banned? Banned in schools you mean? Because I can’t see how authorities could ban anyone from picking up a conker from the ground and tying a string to it. On a different note, if you’re just pulling a random one out of a bag, what is the competitive aspect? Is there a technique involved? Or just RNG? reply butterfly42069 12 hours agorootparentIt is banned in schools. As I said in another comment, that outlaws it for the vast majority of players at the place they used to play it. Believe it or not adults playing conkers or people playing conkers outside of schools isn't a common pass time. It is pretty much RNG, though you can massively nerf a conkers structural integrity by making the hole through the middle poorly, so there are some techniques. People also used to use thicker shoelaces like in vans, which I think made the centre more solid. I've never run an experiment to verify the difference that might make. reply philipwhiuk 7 hours agorootparentI doubt it's banned in all schools. It'll be banned in a few which made headlines. The HSE is pretty clear it doesn't justify it: > The HSE said the safety risk from playing conkers was \"incredibly low and not worth bothering about\" reply Symbiote 11 hours agorootparentprevIt's not banned, but the Daily Mail would like you to think the EU banned another British tradition. reply butterfly42069 11 hours agorootparentI don't read the daily mail. Try again. Maybe be less partisan. reply blitzar 11 hours agorootparentPage 3: \"Carly 32D, 21 from Ipswich, thinks EU regulations on conkers is against British traditions\" reply butterfly42069 10 hours agorootparentI'm not sure if that betrays more about your opinion of women than you may have been aware. reply SteveSmith16384 6 hours agorootparentI think they were just parodying the typical text that used to be shown against a page 3 girl bitd. reply blitzar 10 hours agorootparentprevIt probably betrays more about my contempt for how peoples biggotry is exploited to make them believe things that are not true. When that is not enough then show them some tits with the message and they will tell you all about how pigs fly. reply robertlagrant 9 hours agorootparentIt just looks as though you have your own set of biases, just against people instead of against overly coddling rules. No one's mentioned the Daily Mail or the EU other than you and the other poster with similar biases. reply blitzar 9 hours agorootparentThe \"legislation against playing conkers\" is demonstrably false. reply robertlagrant 8 hours agorootparentYou're writing that as though you're quoting someone. Where are you quoting that from? reply SteveSmith16384 6 hours agorootparenthttps://www.gov.uk/government/news/dangerous-daffodils-and-1... reply butterfly42069 9 hours agorootparentprevI sincerely hope life starts treating you better than it clearly has. I also hope you see the irony of your ways. reply Nursie 14 hours agorootparentprevIIRC at some point schools decided to put a stop to it (it was a popular playground game in Autumn) because of the possibility of injury. Or that might have just been a tabloid outrage-bait headline. reply ascorbic 14 hours agorootparentIt's such a persistent myth that a health and safety organisation decided to sponsor the championships to try and debunk the idea. http://news.bbc.co.uk/1/hi/uk/7637605.stm reply bee_rider 15 hours agoparentprevSo the game is to test who has the stronger conker by hitting them into each-other? reply CJefferson 15 hours agorootparentYes, that's it. The reason I think this game is so popular is horse chestnut trees are very popular in the UK. For about a month each year, where I grew up the ground would be littered with conkers, both on my route to school and on school grounds. It's natural when walking around to try to find particularly large / impressive looking ones. reply butterfly42069 15 hours agorootparentnext [13 more] [flagged] seanhunter 14 hours agorootparentI have no idea why you think safety laws prevent people from playing conkers in spite of the very thread you are commenting on being evidence that people play conkers and it is perfectly legal. reply butterfly42069 12 hours agorootparentWell it is",
    "originSummary": [
      "The World Conker Championships is investigating allegations of cheating after the men's winner, David Jakins, was found with a steel chestnut in his pocket.",
      "Jakins, a long-time competitor and the event's top judge, denies using the metal conker during the competition, claiming it was intended as a joke.",
      "The Championships are taking the claims seriously, especially since Jakins was responsible for preparing the conkers, and the investigation is ongoing."
    ],
    "commentSummary": [
      "A world conker champion was discovered with a steel chestnut but was exonerated from cheating allegations.",
      "Conkers is a traditional game in Britain and Ireland where players attempt to break each other's chestnut on a string.",
      "The incident raised questions about the game's integrity and the preparation of conkers, yet the event continues to be a fun and traditional competition."
    ],
    "points": 381,
    "commentCount": 520,
    "retryCount": 0,
    "time": 1728961920
  },
  {
    "id": 41842294,
    "title": "Routine dental X-rays are not backed by evidence",
    "originLink": "https://arstechnica.com/health/2024/10/do-you-really-need-those-routine-dental-x-rays-probably-not/",
    "originBody": "Dental discomfort Routine dental X-rays are not backed by evidence—experts want it to stop The actual recommendations might surprise you—along with the state of modern dentistry. Beth Mole – Oct 14, 2024 7:11 PM An expert looking at a dental X-ray and saying \"look at that unnecessary X-ray,\" probably. Credit: GettyMilanEXPO 143 Has your dentist ever told you that it's recommended to get routine dental X-rays every year? My (former) dentist's office did this year—in writing, even. And they claimed that the recommendation came from the American Dental Association. It's a common refrain from dentists, but it's false. The American Dental Association does not recommend annual routine X-rays. And this is not new; it's been that way for well over a decade. The association's guidelines from 2012 recommended that adults who don't have an increased risk of dental caries (myself included) need only bitewing X-rays of the back teeth every two to three years. Even people with a higher risk of caries can go as long as 18 months between bitewings. The guidelines also note that X-rays should not be preemptively used to look for problems: \"Radiographic screening for the purpose of detecting disease before clinical examination should not be performed,\" the guidelines read. In other words, dentists are supposed to examine your teeth before they take any X-rays. But, of course, the 2012 guidelines are outdated—the latest ones go further. In updated guidance published in April, the ADA doesn't recommend any specific time window for X-rays at all. Rather, it emphasizes that patient exposure to X-rays should be minimized, and any X-rays should be clinically justified. There's a good chance you're surprised. Dentistry's overuse of X-rays is a problem dentists do not appear eager to discuss—and would likely prefer to skirt. My former dentist declined to comment for this article, for example. And other dentists have been doing that for years. Nevertheless, the problem is well-established. A New York Times article from 2016, titled \"You Probably Don’t Need Dental X-Rays Every Year,\" quoted a dental expert noting the exact problem: \"Many patients of all ages receive bitewing X-rays far more frequently than necessary or recommended. And adults in good dental health can go a decade between full-mouth X-rays.\" Data is lacking The problem has bubbled up again in a series of commentary pieces published in JAMA Internal Medicine today. The pieces were all sparked by a viewpoint that Ars reported on in May, in which three dental and health experts highlighted that many routine aspects of dentistry, including biannual cleanings, are not evidence-based and that the industry is rife with overdiagnosis and overtreatment. That viewpoint, titled \"Too Much Dentistry,\" also appeared in JAMA Internal Medicine. The new pieces take a more specific aim at dental radiography. But, as in the May viewpoint, experts also blasted dentistry more generally for being out of step with modern medicine in its lack of data to support its practices—practices that continue amid financial incentives to overtreat and little oversight to stop it, they note. In a piece titled \"Too Much Dental Radiography,\" Sheila Feit, a retired medical expert based in New York, pointed out that using X-rays for dental screenings is not backed by evidence. \"Data are lacking about outcomes,\" she wrote. If anything, the weak data we have makes it look ineffective. For instance, a 2021 systemic review of 77 studies that included data on a total of 15,518 tooth sites or surfaces found that using X-rays to detect early tooth decay led to a high degree of false-negative results. In other words, it led to missed cases. Feit called for gold-standard randomized clinical trials to evaluate the risks and benefits of X-ray screenings for patients, particularly adults at low risk of caries. \"Financial aspects of dental radiography also deserve further study,\" Feit added. Overall, Feit called the May viewpoint \"a timely call for evidence to support or refute common clinical dental practices.\" Dentistry without oversight In a response published simultaneously in JAMA Internal Medicine, oral medicine expert Yehuda Zadik championed Feit's point, calling it \"an essential discussion about the necessity and risks of routine dental radiography, emphasizing once again the need for evidence-based dental care.\" Zadik, a professor of dental medicine at The Hebrew University of Jerusalem, noted that the overuse of radiography in dentistry is a global problem, one aided by dentistry's unique delivery: \"Dentistry is among the few remaining health care professions where clinical examination, diagnostic testing including radiographs, diagnosis, treatment planning, and treatment are all performed in place, often by the same care practitioner\" Zadik wrote. \"This model of care delivery prevents external oversight of the entire process.\" While routine X-rays continue at short intervals, Zadik notes that current data \"favor the reduction of patient exposure to diagnostic radiation in dentistry,\" while advancements in dentistry dictate that X-rays should be used at \"longer intervals and based on clinical suspicion.\" Though the digital dental X-rays often used today provide smaller doses of radiation than the film X-rays used in the past, radiation's harms are cumulative. Zadik emphasizes that with the primary tenet of medicine being \"First, do no harm,\" any unnecessary X-ray is an unnecessary harm. Further, other technology can sometimes be used instead of radiography, including electronic apex locators for root canal procedures. \"Just as it is now unimaginable that, in the past, shoe fittings for children were conducted using X-rays, in the future it will be equally astonishing to learn that the fit of dental crowns was assessed using radiographic imaging,\" Zadik wrote. X-rays do more harm than good in children Feit's commentary also prompted a reply from the three authors of the original May viewpoint: Paulo Nadanovsky, Ana Paula Pires dos Santos, and David Nunan. The three followed up on Feit's point that data is weak on whether X-rays are useful for detecting early decay, specifically white spot lesions. The experts raise the damning point that even if dental X-rays were shown to be good at doing that, there's still no evidence that that's good for patients. \"[T]here is no evidence that detecting white spot lesions, with or without radiographs, benefits patients,\" the researchers wrote. \"Most of these lesions do not progress into dentine cavities,\" and there's no evidence that early treatments make a difference in the long run. To bolster the point, the three note that data from children suggest that X-ray screening does more harm than good. In a randomized clinical trial published in 2021, 216 preschool children were split into two groups: one that received only a visual-tactile dental exam, while the others received both a visual-tactile exam and X-rays. The study found that adding X-rays caused more harm than benefit because the X-rays led to false positives and overdiagnosis of cavitated caries needing restorative treatment. The authors of the trial concluded that \"visual inspection should be conducted alone in regular clinical practice.\" Like Zadik, the three researchers note that screenings for decay and cavities are not the only questionable use of X-rays in dental practice. Other common dental and orthodontic treatments involving radiography—practices often used in children and teens—might also be unnecessary harms. They raise the argument against the preventive removal of wisdom teeth, which is also not backed by evidence. Like Feit, the three researchers reiterate the call for well-designed trials to back up or refute common dental practices. Beth Mole Senior Health Reporter Beth Mole Senior Health Reporter Beth is Ars Technica’s Senior Health Reporter. Beth has a Ph.D. in microbiology from the University of North Carolina at Chapel Hill and attended the Science Communication program at the University of California, Santa Cruz. She specializes in covering infectious diseases, public health, and microbes. 143 View Comments Comments Forum view Loading comments... Prev story Next story",
    "commentLink": "https://news.ycombinator.com/item?id=41842294",
    "commentBody": "Routine dental X-rays are not backed by evidence (arstechnica.com)303 points by keithly 21 hours agohidepastfavorite339 comments pandatigox 13 hours agoCurrent final year dental student pitching in here. While dentists of the past may push for unnecessary annual radiographs, the curriculum in dental school has changed to favour evidence-based dentistry. Annual bitewings are only indicated if you're a high caries risk, and, as the article mentions, 2-3 years if you're low caries risk. So your younger/newer dentist will be following much better protocols (and hopefully not scamming you)! reply mtalantikite 4 hours agoparentI started going to a new dental office a few years back with a bunch of younger staff here in Brooklyn. They clearly spent a ton of money on the build out, and all the dentists were probably 30s/40s. They did the typical \"you skipped your x-rays last checkup, you're now 1.5 years behind. You need to do those now\" thing. When I asked how much it'd cost out of pocket, they told me an update was $80. I thought \"oh wow, I guess these new machines are just better and cheaper, as technology tends to go\". They did them and then the dentist came in, told me that there was some feint thing on one of my molars that might possibly be a cavity and they should do a filling now. The hygienist seemed surprised, so I declined and said let's keep an eye on it. Went out to pay at the front desk, and nope, it was $80 per x-ray, (so $320), plus $150 for the dentist to try and sell me a cavity filling, plus the base price of the cleaning. I got upset, since that wasn't communicated to me, and they knocked off some of the x-ray cost. I never went back. I found an older dentist and every patient in the office was a retiree, which made me feel confident they knew what they were doing (I'm sure they've got a lot of hard cases). I asked about the possible cavity and they said they saw nothing, everything is fine. That's all just to say that the young dentists likely have a lot of debt between school and office build outs, and I wouldn't be surprised if they're up-selling services to try and get their practice out of it. I wouldn't trust them any more to be honest about practices just because they're young. reply xyzzy_plugh 4 hours agorootparentThis is my experience as well. When I'm looking for a new dentist it usually takes me 3 appointments, each with a different dentist, before I find the dentist that tells me \"the other two were ripping you off.\" It's frustrating but I agree that new builds or expensive locales seem to amplify this effect. Established shops in less fancy areas tend to leave me feeling much better and are almost always quicker while being more thorough. Another part of the problem, as it has been described to me, is that so many dentists are perfectionists, and they find minor non-issues to be glaring. Like if I have a discoloured filling in a molar... is replacing it really warranted just for cosmetic purposes? I will also add that, a visit to most dentists where you clarify up-front that you have no insurance can be a very different experience. reply DowagerDave 1 hour agorootparentI grew up without any dental coverage and you are right; if you say first thing \"I have no coverage and pay for everything out of pocket\" you typically get a very different experience. It's not just the dentists that are perfectionists, but culturally perfect teeth is an expectation in a lot of the world now. I get it; a kid who's hesitant to smile because they're embarrassed with their teeth is heart-breaking, but it's also very expensive. reply userabchn 2 hours agorootparentprevThe dental office where I used to get my teeth cleaned every six months did X-rays every time and then no one ever looked at them. If you went there for a checkup they required you to get another set done. I am quite certain that they just assumed everyone had dental insurance and it was effectively insurance fraud. reply steveBK123 3 hours agorootparentprevAny chance this new dental office was in Williamsburg, because I'm pretty sure I know the spot... reply mtalantikite 3 hours agorootparentIt is, although I'm pretty sure there are a few in the neighborhood these days that I'd guess would likely do the same thing! This one is close to Domino. reply steveBK123 2 hours agorootparentOh yes, that's the place. reply reneherse 4 hours agorootparentprevMy guess is the dental practice was owned by a private equity firm and the young docs were \"just following orders\". Highly capitalized, expensive leasehold improvements plus obscure pricing and surprise charges seem to be the typical playbook of that business model. Reliable doctor-owned dental practices seem to be increasingly hard to find, at least here in the urban Southeastern US reply daveguy 3 hours agorootparentMy dentist was bought out by one of these operations a couple of years ago, and quit after a few months of observing their tactics. I never actually saw her when I went for two 6 months checkups. It was non-stop upsell on water piks, \"preventative\" procedures, cosmetics. So I switched back when I found out my original dentist had re-opened a private practice. Stay away from venture capital dentistry operations. Same with veterinary practices -- similar issue with venture capital takeover of our long term vet. If the operation is owned/financed by venture capital, stay away. Their priority is obviously not health and wellbeing. reply racnid 3 hours agorootparentThe option these days for Vets is sell to PE, shut down, or try to find a younger DVM who wants to take over the practice and work in for a couple of years. But the younger DVMs have debt to pay and need to take the PE job. There's little love for the PE route but it gives an exit to older vets I suppose. I doubt many like watching their life's work being hollowed out and worn as a skin suit. reply dannyobrien 3 hours agorootparentprevwait, aren't venture capital and private equity different? Why would a venture capitalist take over a dentistry or veterinary practice? (Unless it was a growth play, like One Medical) reply dehrmann 3 hours agorootparentVC is a type of PE that focuses on younger growth companies. reply r00fus 2 hours agorootparentprevPrivate Equity taking over all businesses is going to be our undoing. reply DowagerDave 1 hour agorootparentHaving been through more \"classic\" VC a couple of times and now PE as well I agree. PE is so much more nefarious and damaging. When you take 100+ M of VC gasoline and pour it on the fire everyone can see what's happening. PE funds want juicy annual returns of free cash and a multiplier sell out; it puts revenue pressure and forces cost control that destroys successful businesses in one funding cycle that might have been doing just find for decades. And nobody but the C-suite and investors gets rich. reply dnissley 2 hours agorootparentprevPensioners gotta get paid somehow reply r00fus 1 hour agorootparentThat's a wild take. Hedge funds and PE have corrupted and taken over said pension funds then pushing funds into these usurious ventures by claiming that the pension fund \"needs to keep up with the market\" is another huge sign of decay. reply DowagerDave 1 hour agorootparentlook at what's happened/happening with Red Lobster. They had lots of loser locations, but now the winners are losers too. reply Loudergood 3 hours agorootparentprevCan confirm, I used to have a lot of dental IT clients and most of them have left because of being purchased by PE that has their own IT staff and only wants break/fix support. reply DowagerDave 1 hour agorootparentprevsounds like every Vet practice as well. There's lots of things wrong with Canada's public health care system, but the downsides we see with private dental and vet care should be alarming as well. reply loandbehold 1 hour agorootparentprevHow do you know if dental practice is owned by PE? reply parpfish 3 hours agorootparentpreva couple years ago i needed a new dentist and the only place that I could get into was a big chain that has just expanded into the area (Aspen Dental). it had clean new office and lots of fancy tech that to scan my teeth that i hadn't seen at my little hole-in-the-wall old dentist. i was optimistic. they tell me that I needed four fillings and a root canal, and i was a surprised because i'd been going to a dentist every six months and nobody had mentioned anything like that. but hey, that must be the advantage of all those fancy scanners. right? they walked me down to the \"payment center\" which was an office holding four employees whose job was to come up with payment plans to cover dental work. that's when i knew that the whole place was a racket. reply ryandrake 1 hour agorootparentEverything seems to be going in this direction. We were recently looking for someone to clear out insects and other pests from our property, and every one of them tries to steer you to a very expensive \"plan\" where you're billed monthly. We looked around for a long time for a veterinarian where there were more actual vet and vet tech staff than there were billing staff. We were recently referred to an orthodontist for my kid, and right from the start they were on us like vultures about their various \"payment plans.\" I feel like as the years go by, more and more of my cognitive cycles are spent trying to avoid scams and predatory businesses. reply DowagerDave 1 hour agorootparentprevlast time I shopped for a new dentist he looked at me like a shark sizing up his next meal. \"How much can I take him for?\" was painted clearly on his face - maybe that's why they keep the masks on? reply ninininino 2 hours agorootparentprevIs it Tend? reply fma 6 hours agoparentprevMy younger dentist did 2 xrays for me in a row (6 months apart) I don't remember exactly what was done last time and only knew when they pulled up the xrays and I saw the date of the last one. They hygienist sits you down and just does it as if it is normal. I googled and found what you mentioned. I am low risk for cavities. Those exact words came out of his mouth. I was pissed off after the fact, because I'm paying out of pocket for this, and for fluoride treatment. I have in my records to not give me fluoride treatment but she called it \"varnish\" which caught me off guard. I speculate the office got bought out by PE as dentists have changed over the last few years. They also told my wife she needs a night guard. She's been wearing one for 12 years. I slowly see why there are people who do not trust medical professionals. reply koolba 5 hours agorootparent> I slowly see why there are people who do not trust medical professionals. The opinions I trust the most are the doctors that have previously told me that no treatment is necessary and the problem will resolve on its own. The more often they’ve said that, the more I’d value the opinion, especially if it suggested something invasive. reply positr0n 4 hours agorootparentYep, I'm never leaving my dentist because he tells me things like \"this crown will probably need to be replaced some time in the next twenty years, but it's not worth spending the time and money to do it yet.\" Bonus anecdote: My previous dentist, who I went to once, had an office full of hygienists that were young, blonde, skinny women without exception. Something tells me the interview process was not merit-based... reply consteval 2 hours agorootparentprevThe trouble is some doctors (a lot, actually) take this too far. So they'll insist absolutely nothing is wrong, and you should just lose weight or manage your stress or whatever. So sometimes people, typically women and typically larger people, live for years with painful conditions because doctors didn't bother to look deeply at all. reply lainga 2 hours agorootparentI encourage you to explore, as a thought experiment, what profit opportunities can arise from the intersection of mass medicalisation and body positivity. reply consteval 1 hour agorootparentI encourage you to be more straight forward with what it is you are implying. These doctors were, and are, actually reducing profit by not treating illnesses and instead prescribing things such as diet, exercise, and stress reduction. And yes, doctors do that. All of them. If you're obese, the first thing out of their mouth is weight management. And yes, this is typically a good thing. But it does mean that lots of genuine issues are missed because any problem is attributed to weight. When in actuality they actually do have a tumor in their colon and no, they aren't just eating bad. And then they die when it was easily preventable. To believe we live in a body positive world is to be deeply delusional. At the absolute most extreme, you have people asking not to be ridiculed for their weight. There are almost 0 people who legitimately think being fat is good for health. I would say 0, but then I remember some people think the Earth is flat. All that is to say: yes, we know being fat is bad. Yes, even fat people know being fat is bad. Yes, doctors often prescribe not medicine to treat obesity. And yes, this often leads to missing genuine issues. And no, before anyone asks, I'm not a fatty, I'm actually quite thin. Not that I think it matters, but people are vain so it might matter to you. If this comment feels very ungenerous to you, that's because you have forced me to make many assumptions about what you're trying to say. You can avoid that by not speaking as though you're an oracle in a medieval fantasy movie. And, before I hear some nonsense about how you have no biases and you just want to conduct a thought experiment - uh, no. You are implying something, and we both know it. You do have an opinion on this topic. It's best to just let it out or say nothing at all. Otherwise, I might assume your opinion is dumb. reply coryrc 1 hour agorootparentWhen you hear hoofbeats, think horses, not zebras. The body is extremely complicated and cannot be reproduced for testing. Testing and treatment has a cost not just in money. If 99% of the time it's just a symptom of being obese, is it really a good idea to put 99 people through unnecessary procedures because 1 other person has a fixable problem? What if said testing procedure has a 1/1000 chance of perforating the colon and causing a serious problem for those 99 people without a tumor? reply consteval 1 hour agorootparentYou're correct but what I'm referring to is subconscious bias. Meaning that, because they are fat, they will be treated differently than they would have been if they were thin. Meaning their symptoms won't be listened to, they won't be taken as seriously, they will be assumed to know very little about health, etc. In through one ear, out the other. This subconscious bias is the same reason why simply having a non-white sounding name on your resume greatly reduces your chance of being hired. It's not like anyone is actively racist, but in their mind there exists connections already made and those influence their decisions, without their knowledge. In actuality, if you have, say, anal bleeding, pain, bloating, and dark stools you should get a colonoscopy. Women and larger people face much more of this subconscious bias. Many women aren't taken seriously at all. reply cruffle_duffle 4 hours agorootparentprev> The opinions I trust the most are the doctors that have previously told me that no treatment is necessary and the problem will resolve on its own. This applies double or even triple for vets. There is a lot of cash to extract from pet owners who would “do anything”, no matter how unnecessary or ineffective, for poochy. reply xyzzy_plugh 4 hours agorootparentI don't think this is charitable. I've been lucky to have a view into the back office of a veterinary clinic and the fact of the matter is it's just difficult medicine to practice. Every vet I know works hard to save their clients money. If pet owners are inclined to take the \"do anything\" route it can open a lot of doors. I don't see anything wrong with that. reply DowagerDave 1 hour agorootparentI just can't reconcile this with my experience. The most charitable I can be is that these vets care deeply about the animals but treat cost as no obstacle or don't even recognize the cost. >> If pet owners are inclined to take the \"do anything\" route it can open a lot of doors. I don't see anything wrong with that. How about just like people-medicine: diagnostic tests when there is no likely treatment should not be proposed. Or charging 20-50x the generic cost for the same drugs humans use? The fact that some people will \"do anything\" when there's nothing that can be done is prone to abuse. reply consteval 2 hours agorootparentprevI've known a few people who worked in vet clinics, and they've all told me horror stories of how pets are mistreated. I'm talking left to sit in their own feces and urine overnight, fixed when they weren't supposed to be, injured during surgeries and then not communicated to owners. reply PawgerZ 3 hours agorootparentprevWas this a PE owned vet clinic? They're much more common today and the practices have slowly become more predatory. reply cruffle_duffle 2 hours agorootparentprevThat’s a good point. I’m unsure how to frame my observation in a way that makes vets look like they are intentionally doing something wrong. I guess what I’m saying is when I work with a vet it’s hard to know if the vet is going overboard with diagnostics and tests because me, the owner, want to “do everything I can” for my pet. It’s a tricky subject to phrase correctly and way to early in the morning to come up with a good example. reply itishappy 4 hours agorootparentprevWhy do you go? reply DowagerDave 1 hour agorootparentprevso we take fluoride out of the water, where the poorest people can get it regularly and then we're supposed to believe if I pay for 2 applications a year were all good? reply smrtinsert 5 hours agorootparentprev> I slowly see why there are people who do not trust medical professionals. I think the slider isn't between trusting and not trusting medical professionals - it's between being a passive and active patient. We have to involve ourselves in our care. Educate yourself, get second opinions, connect with fellow patients and national experts. And ffs, do not listen to yt/x/tiktok people for anything. reply ambicapter 4 hours agorootparentYou don't have to be an \"active\" patient and \"self-advocate\" if you trust your medical professional to make the decision that is in your best interest. Ergo, if you're advocating active medical involvement, you don't trust your medical professional either. reply exe34 4 hours agorootparentI can't trust my own mother, so I'll look up things myself before committing to one decision. as far as I can remember, as an adult, I've only been to the doctor's once without diagnosing myself, and I've never been wrong yet (the handful of times I've needed medical care anyway). reply consteval 2 hours agorootparentThat's great but the trouble is that as you get older medical conditions become harder and harder to find out. They also become more dangerous. I'm telling you this because my father was the same way you are. he avoided going to the doctor at all and diagnosed himself. He also smoked for 60 years. Yeah. He had his first heart attack in his 30s. Very avoidable. His second in his 40s. Then another in his 50s. Finally died of lung cancer in his 70s. Honestly a miracle he made it that far. You can tell if you're feeling okay. But a lot of diseases have no symptoms. The reality is you cannot run your own blood tests. If you're young, maybe it's fine. But as you get older it no longer flies. What happens is you will become very sick, realize it's due to something like high blood pressure or diabetes, and you're WAY too far gone to fix it. The earlier you get on top of bad markers, the better. You don't want to live 30+ years with something like high blood pressure or high cholesterol. Maybe you don't smoke (good for you), but that doesn't save you. Neither does living an active lifestyle. You can get high blood pressure, high cholesterol, diabetes, heart failure, etc regardless of your lifestyle. There're people who die MUCH younger than my father did while being much healthier. reply exe34 1 hour agorootparentoh it's not an issue for me, I've been suicidal since I was 12, but don't have the guts to off myself. a few years ago I gave up entirely and decided to wait it out the long way, but the sooner something takes me out, the better. but thank you for the concern :-) reply consteval 1 hour agorootparentThis actually didn't do away with my concern. I'm much more concerned now. If it helps, keep in mind most medical issues don't kill you. They just lower your quality of life, sometimes a lot. So, if you've decided to stick it out, you might as well try to live the best life you can. Nobody wants to be chronically fatigued, or have bathroom troubles, or lose their hair, or whatever. reply exe34 1 hour agorootparentyou don't need to worry, once I gave up on mental health, I've never been better. nothing really bothers me anymore. reply crimsoneer 10 hours agoparentprevSlightly worrying that evidence-based dentistry wasn't the default position (though not surprising). I'm always kind of amazed that when I look up the robust evidence for even things as common as flossing, the evidence just...doesn't seem to be there. Let alone all the myriad of dental products from various mouth washes, tooth pastes, brushes and water picks. How we've ended up regulating medicine to the nth degree, but when it's teeth we're like \"oh well, lol\", continues to mystify me. reply michaelt 9 hours agorootparent> Slightly worrying that evidence-based dentistry wasn't the default position I see what you mean. But I'm a computer programmer, and if someone asked me to find a top quality academic study proving, beyond a shadow of a doubt, that it's a good idea to indent your code - I couldn't point you to one. reply exitb 9 hours agorootparentIf I decided to charge my customer specifically for indenting my code, I imagine they might be interesting in evidence that they're getting their money's worth. reply vardump 9 hours agorootparentThey'd probably want to pay if you were coding in Python. reply appendix-rock 8 hours agorootparentprevNo. They might trust your professional judgement, and not all professional judgement has roots in academic publications. reply Frost1x 6 hours agorootparentprevThere’s a current trend of obsession with “data driven” or “evidence based” assessments. While measured data from reality is useful, it’s not without its own sets of flaws. Much data may not be representative or usefully representative of reality due to complexity of the situation (what we measure isn’t isolated or cant be easily linked, or our measurement process itself is flawed). The sort of pinnacle of relying on data assessments is the assumption of removing bias, which is often simply not true. Not only is bias introduced from accidental collection flaws, it’s also often tampered with intentionally cherry picking data, choosing interesting data or in some cases flat out falsifying data. In addition, evidence based reasoning often suffers from there being a lack of evidence to make a decision from. Or in some cases some critical aspect surrounding the decision is very niche to the case so the data may not take that into account unless it’s highly tailored data (evidence based reasoning tends to focus on breadth of applicability because gathering evidence is a long and often expensive process). There’s still a lot of place for using theory and reasoning in conjunction with or in absence of data. Things like experience, professional opinion, etc. Medicine should be no different in that regard to any profession. The key is of course to always strive for sound empirical evidence/data where possible, but to use sound documented reasoning and theory in its absence if you want the best objective results. reply exe34 4 hours agorootparent> Much data may not be representative or usefully representative of reality due to complexity of the situation I've personally been on the receiving end of \"the data we collected shows...x\" (in a non-medical setting), but when I asked to have a look at it, it turned out that while this was true for a large part of the population sampled, there was a material difference between that population and a smaller population that can be clearly identified and for the latter, the data showed the exact opposite conclusion. (think 100 men and 30 women, kind of scenario, except the difference wasn't gender, but job role). reply pizza234 5 hours agorootparentprev> the robust evidence for even things as common as flossing I'm always baffled by all the discussions about flossing, as it's something that can be very easily verified empirically: one can just floss for a month, then stop doing it for another month, then resume and get a feeling for how the gums react. If they bleed or burn (lightly), then the efficacy is evident; if not... lucky person! No need for research either way. In my case, I don't need to floss daily, but I still need to do it regularly. Two weeks without flossing, and I'll definitely feel the burn once I resume flossing. reply boomboomsubban 4 hours agorootparentHow is \"if you don't floss for a month it hurts when you floss\" evidence flossing is good for you? It's the same phenomenon as something like the calluses guitar players get. If they take a few weeks off, it'll hurt a bit when they play. That doesn't mean the activity improves their health. It means if you poke a part of the body enough it handles being poked better. reply mekoka 1 hour agorootparentIt's not universal, but gingivitis (a minor gum disease) causes inflammation (thus pain). Some people are more prone to it due to their teeth arrangement. Some teeth tend to trap food, which then rots, promotes bacteria, and so forth. Flossing helps alleviate this. The initial floss tends to be strikingly different to the follow-ups (not unexpected). More bleeding and more pain (because of existing inflammation), also more gunk and funk (rotten food particles and bacteria). One notable effect when regular flossing is sustained is that your whole mouth just feels generally less sensitive and healthy. Less pain when you chew, your breath feels fresher for longer. The reverse can also be noticed when you stop flossing. As I said, this is not universal since not everyone has the same teeth arrangement. Which is one more argument in favor of not waiting for evidence. It's considerably cheaper to just get some 3$ dental floss, try it for a month, and see for yourself. reply psunavy03 3 hours agorootparentprevBecause the bleeding is caused by inflammation of the gum tissue from the germs that get trapped up there when you don't floss. This then slowly breaks down your gums. This is why your dental hygienist uses that metal pick to measure under your gums; it should only go in 2-3mm and not bleed. reply conductr 5 hours agorootparentprevWhen I encounter these baffling things, I just remember how my grandparents and everyone around them were hacking their lungs out and everyone smoked tobacco everywhere all the time. You’d think the common sense approach would be to assume inhaling dense smoke directly into your lungs was not healthy, especially given the “look around you” factor of ailments (cancer, emphysema, etc). Yet still, there was a large group of people who refused to believe it could be unhealthy without hard evidence. The tobacco industry was a contributing factor but common sense and independent thought was already gone or it wouldn’t have worked for as long as it did. reply wincy 5 hours agorootparentprevWhat evidence is that exactly? It’s evidence that your gums don’t like being traumatized by a small string of plastic? reply exe34 4 hours agorootparentit's the other way round for me - if there's nothing stuck in my gums, flossing feels no more painful than washing my hands. whenever it hurts, it's because there's something stuck in the gum causing an inflammation. once I manage to clean it, either with the floss stick or a small metal brush, the next time I floss it doesn't hurt in the slightest. reply mekoka 3 hours agorootparentprevIt is baffling and sadly pervasive. There are multiple such little tests of minor consequences, that people could just try out for themselves for a month and observe how their body reacts. But they're waiting for \"evidence\". It seems that we live in times where it's been drilled into us that if how we feel isn't backed by statistics, then we're probably not feeling it. reply pprotas 9 hours agorootparentprevNot directly related to the topic at hand, but it amazes me how Dutch healthcare insurance does not cover dental care by default, and you have to get an extra package for that. As if dental health is not part of my regular health? Why are teeth treated differently from the rest of the body? reply andsens 8 hours agorootparentHere’s a good answer that tracks with what my parents, who are dentists, told me: https://www.reddit.com/r/explainlikeimfive/s/H4MsnWKatM > For the longest time, surgeons, dentists and optometrists weren't part of the medical profession. You'd have a barber who could give you a shave or pull your teeth, or a butcher who could cut up a hog, or cut off your gangrenous leg. Optometrists were craftsmen who made the spectacles in their shop. Doctors were University educated in Latin and Greek to read ancient medical texts and despised the uncouth yokels. > Surgeons muscled their way into the medical profession, originally with the help of the Royal Navy, who only had space for one or two people in charge of both cutting off legs and looking after crew health on their ships. > Dentists and optometrists never did, so they started their own universities, certification boards, etc. By the time they became respectable enough for people to try to merge them with the medical establishment, in the 1920s, they had no desire to give up their independence. > The first insurance policies were private contracts with groups of doctors and the system developed from there. Details vary from country to country of course, but the gist of it generally holds true. reply bonoboTP 8 hours agorootparentNote that \"optometrist\" is distinct from \"ophthalmologist\", which is the actual eye doctor. The optometrist job is only about fitting glasses and contacts for near/farsightedness, while ophthalmologists can treat all manners of eye diseases. And the final form of dentists, oral-maxillofacial surgeons are an all in one and have to study general medicine, surgery and dentistry. reply razakel 7 hours agorootparentAn optician fits lenses, an optometrist measures your vision (and can refer you to an ophthalmologist if they spot something unusual). reply matwood 6 hours agorootparentprevA friend of mine is an orthopedic surgeon and says he's basically a carpenter. reply mauvehaus 5 hours agorootparentI once made the mistake of observing to my dentist that every tool he was using to fill my cavity looked like a smaller version of something I could buy at Home Depot, to which he cheerfully responded: \"yup!\" and carried on drilling. reply MVissers 6 hours agorootparentprevDoc here. They are basically carpenters. They us drills and saws and hammers and stuff. reply lesuorac 6 hours agorootparentImage removing somebody's leg without a saw. You just gunna twist it like thumbtack or clay until it separate? reply itishappy 4 hours agorootparentprevFor a good time (citation needed) you can find clips online. Jaw surgery was particularly eye opening. reply Vinnl 3 hours agorootparentprevWhat's extra fun is that that insurance only covers treatments to a fairly low amount, just slightly higher than the price of your regular checkups. (That said, I believe dental issues that are the result of e.g. accidents do get covered by the default care package.) reply ipqk 2 hours agorootparentI've been self-employed for years now (USA), and never buy dental insurance, because it's not really insurance, it's basically a non-taxable way for companies to give their employees extra money. Buying it as self-employed persons is basically just giving the \"insurance\" companies your own money. reply trashface 5 hours agorootparentprevIn the US it is the same. The result is many people do not have dental insurance, and even if you do it often doesn't pay for much. Even our medicare (for old people) doesn't cover it. Thus some people cynically refer to teeth as \"luxury bones\". reply wrycoder 4 hours agorootparentIn my experience (average teeth), dental insurance doesn't pay out enough to cover the premiums, and it's not worth the bother. reply cruffle_duffle 4 hours agorootparentFor private dental insurance yes. It almost never makes sense to get private dental insurance and it’s almost always better to pay out of pocket. I mean think about it from the insurer’s point of view. The only reason you’d ever get “the platinum” dental plan is if you were planning to use it. And it isn’t like you have that many “dental emergencies” if you have healthy teeth. If you don’t have healthy teeth you’d already know it when you pick out the insurance plan, so of course you’d get the upper tier. The only scenario where it makes sense is if your employer picks up a healthy portion of the premium, in which case you are basically getting dental care subsidized by your employer. In that case you’ll likely come out ahead because you knew in advance pretty much how much dental care you’d need. The same goes for vision care, really. You know in advance how many contacts, glasses and eye exams you’ll need. It isn’t really an insurable thing. If your employer pays for most of the premium, it’s employer subsidized eyewear & contacts for you! …of course the math does change a bit when you have to pick the same type of plan for a family. In that case it’s time to bust out a spreadsheet and do the math to see the optimal course. reply ipqk 2 hours agorootparentIt's also tax-payer subsidized (i.e. regressive, because it's mostly higher-income people that get dental insurance) because it's money from your employer that you or your employer don't have to pay taxes on. reply bonoboTP 8 hours agorootparentprevNot sure about Dutch, but in Germany and many other countries, basic dental care is included in the default public health insurance. But it's basic. So it won't be necessarily beautiful, the color may look less nice, they may pull out teeth that could be saved with more money etc. But indeed since it's part of the body, you can get it fixed to a basic level. reply red-iron-pine 5 hours agorootparentprevCanada too. Some rumblings about it at the Federal level, but we'll see if that changes. Apparently teeth are luxury bones reply amluto 5 hours agorootparentprevIt’s an interesting case study in the US. Want to see a doctor for a minor issue? Good luck knowing the price in advance. Want to see a dentist? Ask for pricing on the phone, and you’ll get it. reply DowagerDave 1 hour agorootparentNot my experience in Canada. I went around to dentists and asked for their rates and none of them gave me the equivalent of a take-out menu for basic procedures. Why not? reply throw4950sh06 9 hours agorootparentprevnext [6 more] [flagged] viraptor 8 hours agorootparentYou lost at \"European\" and \"everywhere in EU\". The system is different between countries. For example Poland covers free annual review and basic procedures. (even if it's worse quality than on a private insurance) You're just trolling or really misinformed. reply throw4950sh06 8 hours agorootparentYou said the same thing I said... You only get basic care to survive, nothing else. The system is different but this aspect is pretty much the same everywhere around here. reply viraptor 7 hours agorootparentHaving a repeating free review and treatment is above basic care to survive. Both compared to many other places in the world now and historically. reply throw4950sh06 7 hours agorootparentI very much disagree, that's the most basic of basics. I don't care much what's happening in low income areas and especially not how it used to be historically. And the point is what happens when an issue is discovered - it's nice that they do checkups, it's not so nice that the treatment available is again only the most basic available and anything above is very expensive and not covered even partially. reply appendix-rock 8 hours agorootparentprevnext [2 more] [flagged] throw4950sh06 8 hours agorootparentI have taken my 3 decades of personal experience - hundreds of situations - and combined it with what my family, friends and acquaintances experienced. It's really not just me. And the national news say the exact same thing - healthcare is expensive, inadequate and unavailable (you wait for months - if you find a doctor that would take you, which is definitely not guaranteed). reply ipqk 2 hours agorootparentprevThere just wasn't evidence-based studies for a lot of common dental practices. Not unlike when the FDA was created, a lot of old medicines were just given a pass, even though they aren't useful (like how Acetaminophen is barely better than placebo — it'd never be approved today). Just because there's no actual studies for flossing, that doesn't mean that flossing is bad or not-needed per se, but there does need to be more basic-level studies for it. I had bad gum-disease in my 20s, but once I actually started flossing daily, it stopped progressing. So it clearly helped me, but a better study on whether everyone needs to floss and how often should be done. reply namdnay 9 hours agorootparentprevto be fair, evidence-based medecine in general is only just starting to take over reply konfusinomicon 6 hours agorootparentprevmy 95yr old grandmother who still has her OG chompers always told me to only floss the teeth i want to keep, and given hers are still usable after 9 decades, i listened reply DowagerDave 1 hour agorootparentdo you think your sample size of one could be attributed to any of the many other aspects, most outside the control of the owner? reply cmgbhm 9 hours agorootparentprevThere was a podcast on history of dental insurance that explained it from US perspective. https://freakonomics.com/podcast/dental-insurance/ reply mywacaday 8 hours agorootparentprevMy dentist back in the 80s didn't even wear gloves, he was an older man but I can't imagine gloves were not required then or even when he would have trained in the 40s or 50s. reply bonoboTP 8 hours agorootparentIs your opinion based on evidence? Sorry for sounding harsh, the article is about evidence, but your comment seems to be more based on feels / ick / sheen / vibe of squeaky cleanliness. If it's imagine vs imagine: I imagine that a washed and disinfected hand without open wounds has no measurable risks, and the tactile feedback the dentist gets may improve the treatment. reply zoky 6 hours agorootparent> I imagine that a washed and disinfected hand without open wounds has no measurable risks To the patient maybe. On the other hand (so to speak), if I were gonna spend my day sticking my fingers in people’s mouths, I’d want to wear gloves. reply red-iron-pine 5 hours agorootparentpeople with infected, nasty mouths too. ain't just gonna be the routine inspection and flouride treatment, something foul be brewing in some of their faceholes, and now its all over your hands. reply salad-tycoon 4 hours agorootparentprevNon sterile gloves are more for the wearer not the patient anyways. Assuming effective handwashing. reply trod123 7 hours agorootparentprevThere's some evidence if you know where to look for some of these things (i.e. the programme Dr. Ellie recommends on youtube does actually have papers backing what she says), but overall the dental industry has a long sordid history. You don't understand the power of the ADA/flouride lobby. Even just 20 years ago it was routine to have mercury (toxic heavy metal) placed in your mouth for fillings, evidence said the compounds were stable and no one would fund anything that rocks the boat in the US. They did that for children, but they didn't call it mercury, they called it silver fillings (50% by weight mercury). Normally flouride has very limited uses prior to government mandates, and was so common that it was largely considered a waste by-product not worth selling. I've yet to find an evidence based study or information on why government require flouride ingestion in any population center above 30,000 when studies have shown its just as effective topically. A study out of african really put the nail in the coffin on this one. Side effects include lethargy, neurological damage, cognitive decline, hypertension, acne, seizures, and gastrointestinal issues. It also damages your kids brains more than an adult brain (seemingly lowering IQ permanently), can't be filtered out except by specialized filters that cost a lot (and rapidly become less effective over time). If they get too much which is very simple indeed, this can happen since its in everything (even bottled water and sodas, GRAS and no label needed under a certain concentration that's well above the toxic limits of new studies). Nursery Purified bottled Water for infants is a primary source of business. https://www.readyrefresh.com/medias/sys_master/images/images... Makes you wonder what's really going on, and why they have to drug broad swaths of the population under the guise that it helps fight dental decay (through ingestion), when most of those studies have been debunked outside the US. When cities don't have the funding, they magically get the funding for it. When local municipalities don't keep the levels up, they go after them heavy handed, and they disappear from public view. https://ntp.niehs.nih.gov/whatwestudy/assessments/noncancer/... reply conductr 5 hours agoparentprev> and hopefully not scamming you You’ll soon learn that dental practices are increasingly private equity owned and the dentist have profitability KPIs that factor into their employment and compensation reply EasyMark 3 hours agoparentprevKind of off topic, I had a dentist say “that needs to come out” for a wisdom tooth. I was of the opinion “it doesn’t hurt and it’s not even sensitive, so it stays in”, it was the only cavity I’d had in a very long time and I haven’t had any since. So we argued for 10 years over it to the point it became a joke between us. Well finally it became sensitive (not painful, but sugar and cold would set off a little pain) and I then had it pulled, my dentist was like “I told you” and I responded with “yeah for 10 years” . Is that a fairly typical situation? reply zwieback 3 hours agorootparentI had the same thing with my dentist about one of my remaining wisdom teeth, we went back and forth for five years but it finally got bad enough to do something. I opted for a crown though and it's been good and not too bad out of pocket. reply justmarc 8 hours agoparentprevIt may start with Radiographs but it certainly doesn't end there. What is being taught in schools has no relation to reality. Sure, it may somehow influence it, but it won't dictate how each dentist or clinic will work, as they are probably free to and work do almost as they please. Not too long ago there was a wonderful research story by a journalist of good dental health (as diagnosed by multiple university professors) going across the US for a check up at tens of clinics, and seeing what work will be offered to them. This journalist has encountered just a few few honest dentists saying no work at all is needed, or something very minor, all the way up to dentists saying he needed work in the tens of thousands of dollars, with the worst offender being in NYC as far as I remember wanting ~$30K for his services. Unfortunately I can't locate the story right now. If anyone can, please link us. I didn't yet find the right one, but this one is not too bad either https://www.usatoday.com/in-depth/news/investigations/2020/0... Let's just say that it feels like quite a high percentage of dentists don't strictly adhere to the Hippocratic Oath. reply airstrike 5 hours agorootparentI went to a dentist in Manhattan after moving to the city. Googled a good dentist in my area (UES) and just went. I got there and he wanted $20k to replace all my teeth with veneers. \"Wow, we gotta get this all out\", were his words. I've never had a single cavity or needed braces. I happen to be blessed with very good teeth. I told him to fuck off (unfortunately not in so many words) and never went back. That was 10 years ago. Still no cavity or any issues at all. reply mroset 4 hours agorootparentprevI remember reading this article (or a very similar one) as well. It sent me down a path of looking for evidence based dentists, which are quite hard to find. I couldn't end up finding one that seemed to fit that bill in my local area. I talked to a recent dental school graduate friend who described some evidence that school debt is highly correlated to over-treating. I ended up going the direction of looking for dentists unlikely to have debt and found a former army dentist and have been thrilled with how much less \"well, let's do it all just in case\" she is than my previous dentist (who had a TVs on the ceiling of every room and a new piece of major equipment every time I went). reply darepublic 1 hour agoparentprevI've experienced the opposite. Trendy dental offices with indoor playgrounds, prizes, and always an excuse for xraying and filling children's teeth reply tomcam 4 hours agoparentprevSorry to hijack this, but have you heard of people on whom no local anesthesia works? I have to be put under general anesthesia (yes, requiring an actual anesthetist at an extra $8,000 or so). The pain is not endurable otherwise. reply butlike 2 hours agorootparentNo, but I used to have a pretty bad \"aine\" habit, and the novocaine wouldn't start to work until the 3rd application. reply ecuaflo 3 hours agoparentprevDentists always tell me insurance requires annual xrays in order to cover anything else, even just a cleaning. So it seems like it’s really not up to them. reply rootusrootus 2 hours agoparentprevI don't think I've ever had a dentist recommend annual bitewings, and I've been going to the dentist since the days we had to spit in a bowl. It's always been once every few years. reply sevensor 6 hours agoparentprevAny thoughts on the cancer screen they’re always trying to upsell? reply DowagerDave 1 hour agorootparentthis is an upsell? My dentist pokes around a bit and checks for lumps in my tongue (like I wouldn't notice that?) but that's about it. Is there something more I missing? Going to the dentist tomorrow and would love to ask for optional high-margin upsells! /s reply newman314 11 hours agoparentprevHow about for cavities? I remember reading an article recently about major increases in the number of cavity related treatments because $$$. My kid has had multiple recommendations for cavities and I've got some suspicions about the absolute necessity of all of it. reply pandatigox 11 hours agorootparentFillings are definitely a staple of the procedures a dentist would perform. The article does mention overtreatment, so really depends on your child's caries risk. As mentioned in another comment, healthy dose of skepticism is always required. I usually try to show signs of decay either intraorally or detected on radiographs. reply thatcat 9 hours agorootparenti think parent might have been referring to the radiograph they try to schedule after a cavity filling reply bdjsiqoocwk 12 hours agoparentprevI'm glad curriculum is improving, but nothing stops a dentist from overtreating of is so decides, and the incentive is there. reply pandatigox 11 hours agorootparentI think that applies to any industry! Like nothing is stopping a car mechanic from overcharging you. But dental treatments need to be clinically justifiable, so I'm sure any well-meaning dentist will happily explain their reasoning for any treatment. Patients regularly push back on some treatments I've recommended, and I've always enjoyed the discussion. If a dentist is offended, then something is not right reply gregwebs 8 hours agoprevYou might be surprised that treatment recommendations vary dramatically from one dentist office to the next. [1] I am glad to know this about X-rays as well- it’s probably a useful indicator that if X-rays are not overprescribed the dentist will more likely not over treat. And if they react defensively to being told you want to follow the ADA guidelines that’s probably a sign they don’t think about whether they are over treating. [1] https://www.rd.com/article/how-honest-are-dentists/ reply bradfa 8 hours agoparentMy old dentist retired a few years ago. She had been excellent, in my opinion. The dentist who bought out her practice comes from the school of thought that bitewing x-rays are required every year. I generally decline to have the x-rays done every year, instead opting for every 2ish years cadence. Feels like now I have even more justification to delay future x-rays. And thanks for the Readers Digest article. A bit of a blast from the past with that publication for me but well written and clearly makes its point about the inconsistencies of dental practice. reply FollowingTheDao 7 hours agoparentprevTwo stories. 1) Just yesterday I went to a an acclaimed dental school (UNC) for low cost dental care. They not only gave me a panoramic x ray but also a full set of bite-wing x rays. I read this and I want to break the world apart this morning. 2) When I was a child I kep needing root canals. It turned out our dentist was making these all up and was later found passed out from laughing gas in his office. reply ein0p 7 hours agorootparentI strongly suspect my dentist is making shit up, too. I had to refuse a couple of expensive treatments. The main goal seems to be to “use up” my dental insurance more than anything. reply dartos 7 hours agorootparentMy dad has been a dentist for 30+ years and retired a few years ago. Recently he did some 3-month contract work for a very large dental chain, let’s call it Penass. I’ve never seen him so depressed in my live. He said that Penass’s business model was all about running up insurance and selling loans for large operations. He was directly encouraged to do extra, not necessary work to run up the bill. He came out of retirement after that and started another practice out of, what I can only guess, was frustration and guilt. A lot of these large dental chains absolutely tack on extra work and do a shitty job to keep people coming back. In the US, I highly recommend looking for independent “boutique” dentists. Even if they are out of your insurance network, a lot of them will give better rates if you pay in cash. reply pavel_lishin 6 hours agorootparentHard agree. I left a local office that was staffed by a variety of dentists, and opted for one that had one specialist per procedure - one regular dentist, one implant specialist, etc. Not only do you actually get to see the same person on every visit, they're not as likely to do this sort of thing. reply dartos 5 minutes agorootparent> Not only do you actually get to see the same person on every visit It was very surprising to find out, after growing up and my parents returning, that this was unusual. wincy 5 hours agorootparentprevI had a dental chain say I needed periodontal scaling because I was having terrible pain in my upper gums. It took two years and another dentist to tell me I actually had a cyst and the cyst growing had almost dissolved my nose bone. Another few months and I’d likely have a weird sunken nose if a surgeon hadn’t properly removed it. So they charged me for an expensive procedure but it wasn’t even the correct expensive procedure! reply gmarx 17 minutes agorootparentprevI stopped going to dentists for years because two dentists in serial made up cavities. The first guy I let him drill. The second guy, a friend of my dad's (supposedly)I declined. This was in the early 1990s I told this story to a friend years later and he said the same thing happened to him. reply fazeirony 7 hours agorootparentprevthis is it right here - 'use up your dental insurance'. reply jrs235 3 hours agorootparentSeems it would be best to say you don't have insurance, get a better cash price, then submit reimbursement to insurance oneself. reply FollowingTheDao 6 hours agorootparentprevAnd it is the biggest reason we need universal healthcare. reply ap99 5 hours agorootparentI would say education is a more appealing solution to this problem than universal health care. People similarly get unnecessary work done on their car to boost dealership profits. Do you want to create a government agency to budget how much we can all spend on car repairs and then take it out of our taxes? reply rootusrootus 2 hours agorootparentThere is already an opaque bureaucracy that stands between me and my doctor. We do not have a free market in healthcare, so I cannot just choose another bureaucracy. I don't see how delegating this responsibility to a government agency can make it any worse for me. reply ambicapter 4 hours agorootparentprevThe difference here is we're talking about a person's health, not their motor vehicle, so a different calculus is in play. reply FollowingTheDao 3 hours agorootparentprevThis is not about education, it is about morality. So maybe they do need an education, but let that be in empathy and moralilty. And why can't we have education AND universal healthcare? I want a government agnecy (the people) to control the morality of corporations and private equity. Like we have laws against fraud already that protects us from \"unnecessary work done on their car to boost dealership profits\". Adding still, why would anyone be against universal healthcare? I mean it is the biggest insurance pool you can create and that immediately lowers costs. reply dh2022 1 hour agorootparentooh, dentists are very well educated in empathy and morality. They even have to take an ethical oath before they get their license. So is not lack of education, is greed and maybe a ton of student debt (or both). reply jjeaff 3 hours agorootparentprevI actually don't see how universal health care would help in this situation. Bad actors are going to try and milk whatever system pays the bills. Capitalism \"should\" be pretty good at taking care of this kind of stuff. I'm not sure why insurance companies aren't better at reining in these kind of abuses. reply DowagerDave 1 hour agorootparentIn my current environment there's the opaque and not really shared dental \"fee guide\" by the regulatory body, the actual fees each dentist charges, and then the % of the guide that the insurance pays, so if the insurance company keeps pressure on the governing body they don't really care what any dentist actually charges you. reply unregistereddev 3 hours agorootparentprev> I'm not sure why insurance companies aren't better at reining in these kind of abuses. I think they are working on it. My dentist has cameras shaped roughly like a toothbrush. Before and after performing work, they record images of the affected area. He says insurance likes them to thoroughly document their work to help justify the cost. reply cruffle_duffle 4 hours agorootparentprevSetting aside the unnecessary procedures bit, the “use up my dental coverage” isn’t a bad way to look at dental insurance. Those things are priced in a way that they are basically almost pre-paid “use it or lose it” products, especially if it is private dental insurance. If you aren’t coming close to maxing out your dental (or vision) insurance you can probably get by with less. And if all you are ever really getting is cleanings unless it is an employer paid plan just pay out of pocket (or with your fsa/hsa) reply FollowingTheDao 6 hours agorootparentprevA private psychiatric hospital did this to me. I was voluntarily committed and they kept me for 10 days because that is how long Medicare would pay for. I was literally fine after the second day. Meanwhile a poor kid with horrible delusions was let out after three days after being involuntarily commuted and was still having active hallucinations. He had no healthcare at all. The hospital has been under intense investigation by the local news. https://www.wral.com/holly-hill-hospital/21507953/ This is the newest scam running, privatize health care so that these companies can rake in billions. I am sure this dental school probably gets millions for doing this. reply djeastm 3 hours agorootparentprev>When I was a child I kep needing root canals. It turned out our dentist was making these all up Uhh.. dude should've been in jail for that imo reply agentultra 5 hours agoprevI am all for evidence-based medicine making its way into dentristry if it's lacking... but if you're someone who is worried about cumulative exposure to X-ray length radiation, what is the dosage? And can we compare it relative to to say, millimeter scanners at the airport or a domestic flight? I was under the impression that the digital machines they use these days are: 1. localised 2. very, very low dose reply zamadatix 3 hours agoparentAs an important distinction the current millimeter scanners at the airport are completely uncomparable. They use non-ionizing radiation similar to Wi-Fi. There used to be backscatter x-ray scanners (ionizing radiation) but these were decommissioned in the EU/US in 2012/2013 due to public concern even though the levels were low as well. The importance of the distinction is a lifetime of non-ionizing radiation is not known to cause any adverse effects while any instance of ionizing radiation is known to damage cells, even when it's a low amount in a controlled area. The debate people have with the former is whether or not it might even causes a problem in the first place while the debate with the later is where the best balance on the damages vs advantages is. reply ericmcer 3 hours agoparentprevMy dentist said something like \"it exposes you to less radiation than eating a banana\", but she also left the room when the machine was firing. reply rootusrootus 2 hours agorootparentI remember taking my kid for an x-ray of his wrist and the tech lined it all up, and then said \"okay, dad and me are going over here while I take the picture.\" My son immediately wanted to know what the hell we just exposed to him that wasn't safe for us. In retrospect, the policy should be to let the parent stay. The risk to me is no worse than the risk to my kid. It's easy enough to explain why the tech should go behind a shield. reply Night_Thastus 2 hours agorootparentprevI hate when people bring this up. Yes, it's an incredibly small amount of radiation for you because you're only in there for one X ray maybe once a year. For someone who operates the Xray maybe a half dozen times in a day (or more), every day, that number changes dramatically. It's still likely fine, but it's far better to be safe than sorry. reply s1artibartfast 3 hours agorootparentprevradiation workers practice ALARA, which is an acronym for \"as low as reasonably achievable\". Nothing wrong with eating bananas, but I wouldn't want to eat 20 a day for all sorts of reasons. reply gmarx 12 minutes agorootparentI have a friend who was course VI at MIT but also a serious (chemical free) bodybuilder. He told me the story of working summers at a gym and he saw this one guy eating a large number of bananas as he trained. I don't know the number, but it was large enough that it was clearly going to be based on some serious bro science. So my friend asks for the explanation. Guy asks him \"what's the strongest animal?\" The answer (which I would dispute) was 'the gorilla' \"And what do gorillas eat?\" reply pgwhalen 3 hours agoparentprevI have the same question. Why should I care? It's not an extra cost to me, so the radiation would be the reason, but I assume it's quite minor. reply zamadatix 3 hours agorootparentI assume you mean it's covered by some sort of insurance (private or public) in which case you are paying for it you just don't really control how much you pay by individually opting in or out. reply pgwhalen 3 hours agorootparentTrue, but dental insurance is so cheap relative to medical insurance. reply skybrian 2 hours agorootparentIf your teeth are in good health (no work done in years and none expected), paying out of pocket for dental appointments might still be cheaper. Though that assumes you could cover an unexpected expense - this is effectively self-insuring. reply rootusrootus 1 hour agorootparent> Though that assumes you could cover an unexpected expense Given how low the typical (non-DMO) coverage limits are for dental insurance, this is probably reasonable for many people. reply layman51 20 hours agoprevSome dentist practices (maybe they are chains) do seem very shady when it comes to overtreatment. I remember on my first visit to an office that I was recommended customized trays that I could wear overnight to have my teeth/gums soaked in hydrogen peroxide gel. This recommendation felt like a sales pitch and when I researched the proposed treatment code later I started to find some dentists online claiming that they wouldn’t recommend those because they are not clinically proven to work against gum disease. I understand that radiation effects are cumulative but is this overexposure source worth fighting against as a patient? reply bdjsiqoocwk 12 hours agoparentRight, that's really the problem: that question is impossible to answer in general because presumably the person who knows the best is the professional who actually examined you. And if you dare question him he's going to be offended. reply diggan 8 hours agorootparent> And if you dare question him he's going to be offended Find new professionals when that happens. There are plenty of professionals that understand that not everyone is willing to just do whatever without more understanding and are happy to explain further when questioned. reply xyst 6 hours agoprevAnd why is dental insurance in the USA picking up the bill? I haven’t directly paid my dentist for these annual exams in quite a long time. The X-rays I can probably avoid the next time, but I feel the cleanings do really help. I used to have bad plaque build up on my incisors but keeping up with the cleanings and improving flossing technique keeps it at bay. reply dawnerd 4 hours agoparentI think insurance would rather pay for X-rays than pay for fillings and such. Probably easier for some offices to max out insurance if there wasn’t X-rays to back it up. reply xeromal 2 hours agoparentprevThey liked paying for preventative maintenance which includes xrays. reply shellfishgene 11 hours agoprevWhat actually positively surprises me is that the American Dental Association publishes recommendations that are to the financial disadvantage of almost all its members. reply m000 10 hours agoparentThese panoramic X-rays are typically performed by technicians/adjunct personnel. So I would guess that dentists don't directly pocket the money from them, or willingly recommend them. A more likely scenario is that dentists are employed by a dental clinic (even if you see the same dentist every time). The dental clinic wants to maximize profit for shareholders, so they invented the \"routine dental X-ray\" guideline. The guideline is then imposed on the destists as a \"performance quota\". E.g. if you have 300 patients assigned to you, you are expected to prescribe at least 150 panoramic X-rays to you patient pool. Drop below the quota, and there goes your performance bonus, which you may otherwise be totally worth of. Of course, there will also be cases where the dental clinic is owned by a single greedy dentist. reply trq01758 9 hours agoprevBack in USSR times in the 80s my high school had a room for a dental work. Of course it had a soviet electric motor drill, not any fancy or not so fancy compressed air turbo anything (because it's cheap like some great RBMK reactors which of course cannot fail) and a young visiting dentist to test their skills on kids. I do not have any great memories related to this. But now I'm also thankful that at least there were no resources to have an X-ray machine for some practice. reply fifticon 10 hours agoprevanecdote on their usefulness. I recently had my yearly inspection, _without_ xrays (which she said it was probably about time for \"next time\"). A month later, I had pain in a rear molar, and went for a checkup. They reacted \"that is not good, because that tooth is root-treated - no nerves, so pain from a place without nerves is not good\". They then did an xray, which revealed the tooth had started rotting - a lot - inside, from below. They advised extraction - now a week ago. It turned out the tooth had a hidden fracture in the roots. It was not visible on the xrays - only its hollowing result - but evident once the tooth was out; it came out in two pieces. Just an anecdote, but this would be caught by the 2-3 year xray, and because of the missing nerve, it was pretty bad/serious when I finally felt it myself. I'm not advocating the yearly xray, but the semi-annual makes sense to me. reply aaronmdjones 9 hours agoparentMy dentist gives me x-rays every two years, and I have checkups every 6 months to check for things like newly forming cavities, inflammation, decay, etc (nothing ever found so far, apart from some minor cavities as a child). It always struck me as prudent. reply rdtsc 20 hours agoprev> \"Financial aspects of dental radiography also deserve further study,\" Feit added No joke. That is a major money maker. There is minimal cost per-use and your insurance pays $200 for it (my last one was $186.00 for instance). The dentists would be crazy not to recommend them as of often as possible. Fluoride \"rinses\" are likely up there too. Rinse for a few seconds and they charge the insurance $50 or something for it. reply caseyy 17 hours agoparentI think most private dentists charge about £20/$25 for a radiography in the UK. In the US, this pricing seems also available - https://www.teethtalkgirl.com/dental-health/cost-for-dental-.... Interestingly, I lived in Central Europe for a while and all my private dentists just used visual inspection for teeth. I never had an issue with that, all decay was spotted in time and in many cases earlier than with the x-ray only method, because more attention was paid to how the teeth look up-close, at all angles. However, the visual inspection takes more time and skill. One might argue x-ray is the cheaper and quicker option. Though it costs more to the patient in many cases. Ah, the world of dentistry. reply Roark66 12 hours agorootparentIt is still like this.the only time I had x-rays at a dentist in Poland is for a root canal work. However, I did have a dentist recommend a 3d x-ray once. reply tiagod 17 hours agorootparentprevSame experience in Portugal. I've only had a dental x-ray before removing wisdom teeth. reply sidewndr46 20 hours agoparentprevI had some dentist that figured out a way to bill my insurance once every 6 months and get paid. He was insistent I get X-Rays every 6 months as a result. I quit going to that dentist. reply ninalanyon 11 hours agoparentprevThose prices are absurd. My whole annual check up including a digital X-ray, visual inspection, tartar removal, polishing, costs less than that. And that is in high cost Norway. reply throwaway2037 10 hours agorootparentHow much did it cost? If _much_ lower than 200 USD per visit in a very wealthy country, then I assume: (a) dentists don't make very much money. Less than 100K USD? (b) most of the work is done by poorly paid dental assistants (20 USD per hour or less). Running a high quality dental clinic is expensive, both for equipment and staff. How can it be so cheap in Norway? reply ninalanyon 7 hours agorootparentHigher education in Norway is free so a dentist starts with much less debt to pay off. Also the income range in general is much narrower here. Mean income for dentists is about 900 kNOK/yr, about 90 kUSD. I suspect that it's also a question of market forces. A dentist that charged much more for an annual check would simply lose that business as there are plenty of dentists here. And quite likely they would lose any follow up work as well. The profit margin on treatment is much higher but even that seems cheaper than what some of my US friends say they pay (or their insurance pays). Here's the price list for my dentist. In Norwegian but Google Translate does a good job: http://www.drammen-tannlegesenter.no/om-oss-priser/priser They do some cosmetic work as well, I imagine that the profit margins are higher for that. I have two crowns, both created by an automated process of 3D photography and CNC machine in the clinic (Cerec). The most recent one went like this: I made an appointment to see my dentist at about 8:30 one morning complaining of toothache, she discovered that an old amalgam filling had cracked and taken part of the tooth with it and that the only practical repair was a crown. She then apologised profusely that she didn't have time to do it there and then but could I come back at 13:00 that afternoon? I said yes and by 13:30 the crown had been manufactured, fitted, ground down to an exact fit and I was leaving. The crown was a bit over 5 kNOK altogether, about 500 USD, for half an hour's work. The price has gone up a little since. None of the work I have done, including the annual check-up, is done by a dental assistant, poorly paid or otherwise. I think that this might be because of the high cost of employing anyone in Norway. reply magicalhippo 4 hours agorootparent> Also the income range in general is much narrower here. Mean income for dentists is about 900 kNOK/yr, about 90 kUSD. To put that into perspective, that's roughly the average income for a developer as well here in Norway. reply robocat 6 hours agorootparentprevMy dentist in New Zealand is about USD200 every six months for the gold plated option. The x-ray is free. Dentists are relatively well paid in New Zealand. Looks like helping hygienist gets USD25-USD30 per hour. Minimum wage in NZ is about USD14/hr for unskilled labour or poorly paying food service jobs. My friend is getting an implant and the total cost is about USD8000. The government is covering most of it because it was an accident (sporting). reply nlnn 10 hours agorootparentprevIt's pretty similar in the UK for private dentistry, x-rays ~£10-30, hygienist/scale/polish ~£50-120, filling ~£70-150, root canal/extraction ~£120-300. Dentist salaries seem to range between £70-200k depending on experience, specialty, etc. reply ricardobayes 8 hours agorootparentVery similar prices in Spain too, funny how the UK is generally considered _very_ expensive for dental work, in fact I just paid 40 EUR for an x-ray here yesterday. reply lol768 9 hours agorootparentprevQuite happy paying £26.80 / £73.50 for all of that. It's in a country's interests to help maintain the public's health, and that includes subsidising their dental costs (otherwise, they end up taking up primary care time instead). reply arethuza 10 hours agorootparentprevBone graft and implant for a single tooth can be up to £9K... reply nlnn 10 hours agorootparentFor sure, stuff like implants, cosmetic dentistry, braces, crowns etc. still cost a non-trivial amount (though hopefully most are once in a lifetime things). reply ninalanyon 3 hours agorootparentA Cerec crown created on a CNC machine with the aid of 3D imaging costs about 500 GBP at my dentist in Norway including the work. reply arethuza 7 hours agorootparentprevYeah - I had a dental bone graft a few months back and I certainly hope its a once in a lifetime thing! NB No criticism of the dentist that did it - took two dentists and an assistant nearly 5 hours and they have an impressive amount of kit... reply matsemann 9 hours agorootparentprevI'd say they're in the upper percentiles here in Norway when it comes to making money. Especially if they're having a small privat clinic instead of \"renting a chair\". So maybe not too much when converted USD, but they're often well off here. I've had the dentist themselves always do most of the work. The assistant is often shared between multiple dentists in the same office in my experience. reply xyst 6 hours agoparentprevFluoride rinses on plan are not covered and cost $25 out of pocket. I did it once and didn’t feel it added anything to the cleaning. reply t-writescode 17 hours agoparentprevAll I'm seeing here is insurance, yet again, over-complicated or increasing the price of things and dentists doing what they can to continue to make a buck while they're severely underpaid for their other procedures. reply tdeck 20 hours agoparentprevAt least fouride rinses provide some benefit. Although you can get much more benefit from buying a bottle of Act and rinsing with it every day. reply rdtsc 3 hours agorootparentFair point. And with fluoridated water and toothpaste, is the dentist checking the dosages? It's probably fine anyway, but paying an tens of dollars for it seems excessive. And like you said, get a bottle for rinsing at home, it's a lot cheaper than $40 per rinse. reply codr7 19 hours agorootparentprevnext [21 more] [flagged] addicted 19 hours agorootparentFluoride may potentially have some negative effects but we’ve been drinking Florida red water across the world for several decades and different countries have added fluoridation at different times etc, and it’s hard to see any severe effect that would qualify it as anything close to “madness”. reply codr7 18 hours agorootparentReally, you don't see it? reply replwoacause 17 hours agorootparentElaborate please? reply codr7 17 hours agorootparentThe madness. reply red-iron-pine 5 hours agorootparentthis is a bad Florida-Man joke reply LorenPechtel 18 hours agorootparentprevRemember the old adage--it's the dose that makes the poison. There is *nothing* that is not lethal if consumed in sufficient quantity. That includes *everything* that we require to live, although in some cases it becomes effectively impossible to ingest a lethal amount. Thus showing that something is toxic doesn't mean it's something you should never consume. And note that fluoridation started because it was observed that the people in areas with higher natural levels benefited. reply codr7 18 hours agorootparentFluoridation started because they wanted to get rid of toxic byproducts from making aluminum, the rest is marketing. reply thaumasiotes 10 hours agorootparentprev> There is *nothing* that is not lethal if consumed in sufficient quantity. To be fair, the quantity of fluorine that would kill you if you consumed it is too small to notice. What's saving you from the fluoride isn't that there isn't enough fluorine to be dangerous - it's that the fluorine is accompanied by things that make it less dangerous. Table salt is 60% highly toxic chlorine, but you're free to coat your food in it because it's 40% sodium, too. In combination, they're fine and in fact necessary to life. Consumed separately in equal amounts, either would kill you. The quantity isn't what matters. reply orev 19 hours agorootparentprevIf it was “highly toxic” it would be obvious because people would be getting sick or dying after ingesting it. Maybe it’s got some issues that aren’t obvious, but there’s not a clear answer. However you don’t swallow mouth rinses like Act, so any nonobvious issue is also greatly reduced. reply codr7 18 hours agorootparentOr, it could be a contributing factor to any of the umpteen lifestyle diseases we're dealing with atm. Not swallowing is great, but I'm sure the concentration is high enough for it to be absorbed anyway. reply Vortigaunt 19 hours agorootparentprevLike with everything else, the dosage makes the poison. I personally intend to stay vigilante to dihydrogen monoxide poisoning. reply seanw444 18 hours agorootparenthttps://www.dhmo.org/facts.html reply codr7 18 hours agorootparentprevYeah, but the doses are way different for different substances, as are the side effects. Edit: Haha, speaking about whooshing, use your brain or someone else will. reply absoflutely 17 hours agorootparentWhooshed right over your head. reply s0sa 18 hours agorootparentprevFluoridation is the most monstrously conceived and dangerous communist plot we have ever had to face. reply tsimionescu 12 hours agorootparentThis is the joke from Dr Strangelove, right? reply dag11 12 hours agorootparentprevhttps://youtu.be/J67wKhddWu4?t=116 reply codr7 18 hours agorootparentprevMore like profiting from making people sick, aka. modern medicine. reply malfist 16 hours agorootparentprevFluoridated water is a communist plot? reply hi-v-rocknroll 18 hours agorootparentprevI can no longer sit back and allow Communist infiltration, Communist indoctrination, Communist subversion, and the international Communist conspiracy to sap and impurify all of our precious bodily fluids reply ktosobcy 11 hours agoparentprevThose prices are insane... I wonder if it's due to the insurance f-up of the whole health system in the USA (i.e. ballooning the prices because \"insurance will pay\")) reply kart23 20 hours agoprevIsn't flossing not supported by science also, but all the news articles said you should keep flossing? reply zupa-hu 5 hours agoparentMy partner is an orthodontist. (That’s a specialization within dentistry.) I’m a software engineer btw. The saying goes that you only need to floss the teeth you want to keep. If you think about it, a toothbrush will only clean 3 sides of a tooth. Top, outer side, inner side. Not the 2 sides facing neighbour teeth. How on earth is it very important to clean those 3 sides but not the remaining 2? That just doesn’t make sense. If you think flossing is not useful, to be coherent, you must believe toothbrushing is not useful. On the flip side, learn how to do flossing right to not hurt your gums. The floss must follow the shape of the tooth, and not be straight. (Ie. move along a U path.) Flossing in a straight line does more harm then good. reply washadjeffmad 20 hours agoparentprevThat's one of those statements, like a natural empiricist saying they don't believe in the big bang, that people tend to latch onto and run with without stopping to evaluate. Flossing daily isn't necessary if you're an adequate manual brusher. Relatively few people are adequate manual brushers. Buy a good electric toothbrush, floss periodically. reply xyst 5 hours agorootparent> floss periodically I used to do this periodically because I hated doing it. But as a result, plaque would build up. Especially on the front bottom incisors. Eventually added it to my daily routine after the nth time being told to floss daily. And now my dental cleanings are more like spot checks. I suppose it’s anecdotal and unique to everyone though. Something about mouth flora. reply caseyy 18 hours agoparentprevIt's one of those things which people endlessly argue about, but once one flosses once or twice, the rotting bits of food in between their teeth become very unappealing to them. reply criddell 19 hours agoparentprevIf flossing lowers the risk of certain types of gum disease and certain types of gum disease are associated with Alzheimer’s, then maybe flossing is (indirectly) good for your brain. https://www.health.harvard.edu/mind-and-mood/good-oral-healt... reply alliao 18 hours agorootparentthe whole Alzheimers field recently got turned upside down... not sure how to assess them anymore... https://www.science.org/content/article/research-misconduct-... reply moi2388 12 hours agorootparentIf you follow news in France, it’s been shown and been shown in court cases that certain pesticides, commonly used in wine farming, cause Alzheimer’s and Parkinson’s. They have much higher rates of these diseases, and recently in a court case the death of a farmers daughter has been shown to be caused by these pesticides. reply initplus 8 hours agorootparentCourt isn't the place for scientific inquiry into these issues. It's just not setup for it. French courts have also found in favor of \"electrosensitivity\" issues. reply m463 13 hours agorootparentprevI thought it was gum disease and heart disease? reply askvictor 15 hours agoparentprevThat story is because no-one had thought to study it so there was no scientific evidence that it made any difference. Not that a study had found it made no difference. reply skybrian 2 hours agoparentprevAnecdotally, my gums used to bleed fairly easily (like during a dental cleaning) and they don’t anymore since flossing somewhat more regularly. So I think you can judge this by how dental cleanings go. reply rootusrootus 20 hours agoparentprevYes, flossing cannot be proven to help. But it cannot be proven to hurt, either, so current recommendations are to do it anyway. reply camgunz 20 hours agorootparentYou can say the exact same thing about eating a blank piece of paper twice a day. Pascal's wager is no way to live life. reply kart23 19 hours agorootparentprevI still floss because I think its gross and I have bad gaps in some of my teeth, but I think flossing can also cause harms, for example some floss has PFAS in it. https://www.consumerreports.org/toxic-chemicals-substances/d... reply Supermancho 19 hours agorootparentprev> Yes, flossing cannot be proven to help. It's demonstrable that something like a bean skin, lodged in your teeth, will erode the teeth touching it. reply bdjsiqoocwk 12 hours agorootparentprevCannot be proven to help if you don't mind your organic matter decomposing in your mouth. reply rootusrootus 3 hours agorootparentPresumably you brush your teeth. The studies on floss usage do not start with a baseline of doing nothing at all. reply krackers 20 hours agorootparentprev>cannot be proven to hurt Inserting floss between your teeth pushes them slightly apart. I wonder if that could have any negatives? reply bsmith 20 hours agorootparentConsidering orthodontic treatments, no. I imagine you could damage the connective tissues under the gums though. reply Barrin92 20 hours agorootparentprev>But it cannot be proven to hurt, either, so current recommendations are to do it anyway. That's not a meaningful standard for any health intervention. If I'd apply everything to my body that wasn't proven to hurt I'd spend a hundred bucks every morning and two hours in the bathroom. If \"it doesn't hurt\" was sufficient basis for a recommendation our doctors would tell us to swallow homeopathic medicine every morning. It seems pretty obvious that anything you apply has to have at least some measurable impact, otherwise you're basically in the same category as the supplement industry. reply mikedelfino 5 hours agorootparentI'm inclined to believe that preventing food particles from rotting between my teeth is a measurable impact in itself, regardless of whether it directly impacts my health. reply rootusrootus 3 hours agorootparentYour assumption is that the floss is removing something that brushing does not. Ask your dentist why you should floss and the answer is not removing occasional lodged pieces of food from between your teeth, but cleaning under the gum line. There is no evidence to suggest it works that way, this is what the long term studies have determined. reply mikedelfino 2 hours agorootparentSo by that rationale, after a thorough brush, flossing would never remove anything? reply lesuorac 20 hours agoparentprevPerhaps you'll find it useful that a double-blind study found no improvement in outcome from use of a parachute when jumping out of a helicopter. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC300808/ reply mlyle 17 hours agorootparentYour comment is misled. This is a systemic review. A RCT would absolutely find a difference. The whole point of this satire is to point out that there's not always studies on what you want to know. \"No randomised controlled trials of parachute use have been undertaken\" Flossing has absolutely been studied. Professional flossing seems effective at combating gum disease. Telling people to floss doesn't seem to be. It's unclear why (is it just compliance effects? are people educated on how to floss still ineffective? etc.) reply lesuorac 15 hours agorootparentAh, you're right I grabbed the wrong paper. I presume the other commenter (hervature ) also knew what paper I meant. But yes, the item you want studied might not have been studied. (\"However, the trial was only able to enroll participants on small stationary aircraft on the ground, suggesting cautious extrapolation to high altitude jumps.\") https://www.bmj.com/content/363/bmj.k5094 reply mlyle 13 hours agorootparentOK. So another low effort comment on a serious subthread. reply hervature 19 hours agorootparentprevThat's not at all what that \"study\" says. It is a critique (in poor taste if you ask me) that everything does not require a double-blind study. reply marcosdumay 5 hours agorootparentIMO, it's a critique on the \"no study shows it exists, therefore it doesn't exist\" attitude. If you manage to do double-blind studies for every single piece of knowledge out there, kudos for you. There's nothing bad in this. Anyway, it's on topic for several sidelines people are raising. But not on topic for the main article. reply mlyle 17 hours agorootparentprev> It is a critique (in poor taste if you ask me) that everything does not require a double-blind study. I think the real point is that systemic reviews often will have a pretty tilted set of included studies, because they are influenced by what things researchers choose to study. Indeed, you probably couldn't publish a study saying that parachutes work; it's not an interesting enough finding for publication. So the only stuff you'll find, in many cases, are studies that buck the prevailing wisdom. reply underbiding 17 hours agorootparentprevthe studies are about outcomes of parachute use writ-large (\"gravitational challenges\"), not just helicopters. Only reason I'm being pedantic here is because if the study was in-fact looking at parachutes from helicopters, it could actually be plausible that parachutes had no improvements when used with helicopters. Most, if not all pilots, don't wear parachutes because there's not enough time to jump out of a crashing helicopter to deploy one and the blades would probably hit you anyway (unlike a plane which you could glide for some time, helicopters are notoriously more likely to fall straight like a brick) reply agurk 9 hours agorootparentInterestingly helicopters don't fall out of the sky when they lose power. Air moving over the rotorblades causes lift, as they are after all wings. During normal flight the blades are turned by the engine generating lift in the expected way. If you are already above the ground and start descending, the airflow over the blades as you descend will cause them to rotate and generate lift. This is known as autorotation[0], and allows control over the unpowered descending craft. It is a normal procedure to be able to safely land this way when power has been lost, and in some ways is safer than a gliding fixed wing aircraft as you don't need a runway to land on. Of course catastrophic failure is possible in a helicopter where the rotorblades can't turn, and then autorotation won't work. But then if a wing falls off a fixed-wing aircraft, they generally can't be controlled (interesting exceptions do exist like with the Israeli F15[1]). [0] https://en.wikipedia.org/wiki/Autorotation [1] https://en.wikipedia.org/wiki/1983_Negev_mid-air_collision reply pushupentry1219 18 hours agoparentprevCompletely anecdotal but my gums flare up and just feel disgusting when I don't floss for too long. I don't do the dentist recommended 2/week but if I stop flossing for over a month I notice significant decrease in my gum health. It becomes excruciatingly painful to brush and this stage and my mouth is full of blood afterwards. So I'm sticking to flossing pretty often now. reply meowster 4 hours agorootparentYou might be going at it too hard. Please see a dentist or get a second opinion from another dentist. According to my dentist, you can damage your gums by brushing them too hard. I don't floss so he didn't address that, but in both methods, force is being applied to delicate tissue. The point of brushing and flossing is to remove food particles. You don't have to abuse your teeth or gums to do that. reply meowster 7 hours agorootparentprevThat does not sound normal. reply flossmaster 20 hours agoparentprevMy most recent trip to the dentist include a brief recommendation to floss, but they weren't really pushing it like they used to. reply krageon 10 hours agoparentprevIt's like when I researched whether an electric toothbrush is better: All the studies say it's not, assuming you're a good brusher. You're probably not. For bad brushers and people that can't manipulate the toothbrush properly for whatever reason, an electric toothbrush gets them to the same performance. reply scubadude 18 hours agoprevAustralian here, and I will say that I fully trust my dentist. I have had one tiny cavity in nearly 20 years. X-rays are every 2 years, and it's to see between the teeth where they obviously can't see visually. I've been told the radiation dose is the equivalent of an hour on a plane flight. reply QuibbleQuota 11 hours agoparentI’m just a layperson, but I’ve never been comfortable with that argument. An hour’s worth of radiation concentrated into a moment seems very different to me. reply dawnerd 4 hours agoprevI found a great dentist that’s on one of the local boards and he stays really up to date with everything. We do yearly 3d scans of my mouth, has helped them determine that my teeth are not in fact moving despite missing some. Old knowledge would be the docs pushing for implants so the teeth don’t move. But knowing mine are stable for now has allowed us to defer since it isn’t causing me any issues. We still do yearly X-rays but that’s more of an insurance play. reply throw4847285 3 hours agoprevMy parents always told me to say no to dental x-rays and I thought they were being paranoid. I guess they were right to be skeptical. reply rootusrootus 1 hour agoparentThat sounds like being right for the wrong reasons. Not a great approach. reply pglevy 2 hours agoprevSuper timely as I have a checkup tomorrow with a new dentist. Curious to run my own little experiment and see how it goes when I decline X-rays. (I've never had issues with cavities or other problems.) reply xnx 20 hours agoprevNot just x-rays: \"As a profession, dentistry has not yet applied the same level of self-scrutiny as medicine, or embraced as sweeping an emphasis on scientific evidence.\" https://www.theatlantic.com/magazine/archive/2019/05/the-tro... reply potato3732842 18 hours agoparentDentistry might be the wild west full of snake oil salesmen compared to medicine but it also doesn't have nearly as many middle men and additional parties perverting incentives and creating hell for patients that medicine does. reply shellfishgene 11 hours agoparentprevOne thing is evidence based medicine, another just simple greed: I like this older study from Switzerland where they sent the same healthy guy to 180 dentists, about 30% of whom performed unnecessary treatments, often on different teeth. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3036573 reply krackers 21 hours agoprevOther outdated yet still routine dental practices include polishing of teeth during checkups for any justification other than cosmetic reasons reply jebarker 20 hours agoparentMy bugbear with dentists in the US (after living my first 30 years in the UK) is that they all continually hassle me to have my wisdom teeth removed. Said teeth have never caused me any problems and are all through the gums. I can only assume it's dogma or an opportunity to bill insurance for costly unnecessary surgery. reply wccrawford 20 hours agorootparentI had the opposite experience. I told the dentist that I thought my wisdom teeth were causing my migraines, and they said it was possible but unlikely, and didn't really recommend removing them. I pushed, and they relented. They were right, it didn't make any difference. Oddly, I only had wisdom teeth on one side, and not the other. So only 2 teeth were removed. reply red-iron-pine 4 hours agorootparentsounds like the dentist was on the level. lotta things it could be, and those may be easy to address without dental surgery. did you ever figure out what the root cause of the migraines was? reply hcrisp 20 hours agorootparentprevI asked mine, and he said the wisdom teeth can crowd teeth if the jaw size is too small causing buckling (a cosmetic issue). More seriously, it can interfere with nerves in your jaw (again because of size constraints) causing numbness / paralysis, etc. Likely the decision to remove them comes down to your genetic / jaw structure and whether they have fully come in yet or not. https://www.webmd.com/oral-health/wisdom-teeth-removal-neces... reply sidewndr46 20 hours agorootparentThe other thing that can interfere with the nerves in your jaw is having them extracted. One of my family members has no feeling there because the extraction was bungled years ago. reply bsimpson 20 hours agorootparentprevI had mine done in college. I really didn't want to do it. I would have been totally happy to buck the pressure of \"this is what everyone does,\" but the thing that made me reluctantly agree to it was an explanation that if I didn't, they would bore holes into my then-back teeth as they grew in and I'd have a big problem to deal with. As I understood it, teeth normally grow straight up, but wisdom teeth grow sideways (with the tops facing the front of your mouth). The wisdom teeth then hit the rest of your teeth and basically bulldoze your mouth. I have no idea how true/bullshit that is, but it's what I was told to get me to finally acquiesce to the procedure. reply zerocrates 11 hours agorootparentDefinitely not all wisdom teeth come in like that: it's possible to have all 4 aligned normally and have have enough room (I do). But coming in towards other teeth and hitting them, or other forms of impaction, are pretty common. You probably saw (or could have seen) the situation pretty clearly on an x-ray. That being said, there is/was definitely an air of \"this is just what we do, it's easier this way\" for removing wisdom teeth, akin to say, what removing tonsils once was. reply bigstrat2003 11 hours agorootparentprevMy wisdom teeth came in like you describe. They meet my back molars at a 90 degree angle. They never bothered me, though - I have had two removed because they got infected, but otherwise they never caused any issues. reply thyristan 20 hours agorootparentprevIt can be true for some people. Look at the lower right one on the xray here: https://www.jwz.org/gruntle/wisdom-teeth.html reply bsimpson 19 hours agorootparentUnless you wanna see an adviceanimals take on a hairy ballsack, you've gotta open that incognito. I don't think Jamie wants HN traffic on his blog. reply mlyle 17 hours agorootparentYou just copy and paste the url, so that the referrer is unset. reply thyristan 8 hours agorootparentprevAh, that explains the downvotes. Sorry. My browser just doesn't send a referrer for clicked links, so I didn't notice. reply galleywest200 20 hours agorootparentprevI am in the US and I had my wisdom teeth filled. Granted after the procedure my dentist said he was never filling wisdom teeth again, lol. reply sidewndr46 20 hours agorootparentFilled? What does this mean? reply filoleg 20 hours agorootparentIt means they fixed cavities on those teeth. reply nkrisc 20 hours agorootparentprevMine recommends the same, but it’s not because I need them out now, but because by the time I’m elderly I might be more likely to need them out, but by that time the surgery might be very difficult for me. As he pitched it to me, “get them out now while you’re young and it’s no big deal”. I haven’t decided yet since they cause me no problems now and so far I’m to keep them relatively clean, but I have known several elderly family members who eventually needed molars removed because they hadn’t/couldn’t clean them well enough and it was a very difficult surgery for them. reply PlunderBunny 20 hours agorootparentprevI've also retained my wisdom teeth, despite some of them not erupting and being impacted. It's certainly easier to get them out when you're young compared to when you're older, but if you've still got them as an adult, it's not worth removing them unless they're causing a problem, even if insurance is paying for it (all procedures can have side-effects). reply bcrl 19 hours agorootparentprevThey're not a problem until they are. I recently had a molar out likely due to damage from an impacted wisdom tooth I had out years ago. The rear of the molar was compromised on the back, and there was no way to save the tooth. If I had my molars out earlier when I was young, it probably wouldn't have been an issue. reply kelnos 19 hours agorootparentprevIt's so odd how experiences vary on this. I'm in my 40s (in the US) and still have all four of my wisdom teeth. When I was a young adult, my dentist told me that they were all intact, and (over time) not moving, so there was no reason to do anything with them. I've gone through a few other dentists in other places since then, and no dentist (including a recent one I had that annoyed me by recommending harmless but unnecessary procedures so they could pad their bill for my insurance) has ever pushed me to get my wisdom teeth removed. When I've started as a new patient at a new practice, they've noted I still have them, and after I say \"yup, they've been stable since I was a kid, and cause me no pain\", they immediately move on and don't bring it up again. reply patmcc 20 hours agorootparentprev>>>I can only assume it's dogma or an opportunity to bill insurance for costly unnecessary surgery. This may be specific to location, but would it be the same dentist recommending the treatment as performing the surgery? Here (BC, Canada) everyone I've known who's had wisdom teeth removed had it done by a specialist, not the dentist that suggested it (which presumably cuts down on self-serving recommendations). reply lesuorac 20 hours agorootparentI mean not if the dentist refers them to a specialist. Usually that involves a kickback; there's a whole slew of problems with that in the US with lactation specialists referring parents to dentists over a tongue tie problem without actually viewing the baby. reply electronbeam 20 hours agorootparentprevI was told they get harder to remove when you’re older reply doe_eyes 20 hours agorootparentIt's one of these areas where people (including medical professionals) hold strong beliefs, but then it turns out that there are other highly-developed countries where this is not routinely practiced, and the outcomes aren't necessarily different. Routine wisdom teeth removal is not a thing in most of Europe. Another random example are colonoscopies and routine flu vaccines (except for the elderly). reply macNchz 20 hours agorootparentI've generally assumed the simplest explanation is that many of these weakly-supported procedures are regular, consistent income streams for the people who perform them in the US: my four wisdom teeth (that were causing me serious issues at age 19) cost $2k to remove nearly 20 years ago, and I know colonoscopies are billed to insurance in the thousands. There's not much incentive to move to cheaper tests or wait-and-see, when you can just do it to everyone who reaches a certain age by default. Presumably flu shot",
    "originSummary": [
      "Experts are advocating for a reduction in routine dental X-rays, as they are not supported by evidence and can pose unnecessary risks, particularly to children.",
      "The American Dental Association (ADA) recommends X-rays every two to three years for adults without increased risk of dental caries, emphasizing the need to minimize exposure and ensure clinical justification.",
      "Overuse of dental X-rays is a global concern, often driven by financial incentives and lack of oversight, prompting calls for evidence-based practices and further research into their necessity and risks."
    ],
    "commentSummary": [
      "Routine dental X-rays, particularly on an annual basis, lack strong evidence for necessity, with dental schools now advocating for X-rays every 2-3 years for low-risk patients.",
      "Some dental practices may still recommend frequent X-rays due to financial incentives or private equity ownership, highlighting the importance of patient awareness.",
      "Patients are advised to choose dentists who adhere to updated, evidence-based guidelines and are transparent about their treatment recommendations."
    ],
    "points": 303,
    "commentCount": 339,
    "retryCount": 0,
    "time": 1728941820
  },
  {
    "id": 41842975,
    "title": "Zamba2-7B",
    "originLink": "https://www.zyphra.com/post/zamba2-7b",
    "originBody": "About Our Work Get Started Chat with Maia About Our Work Get Started Back to Newsroom October 14, 2024 PALO ALTO, CALIFORNIA Zyphra is excited to release Zamba2-7B, a state-of-the-art small language model. At the 7B scale, we outperform the leading models of Mistral, Google’s Gemma and Meta’s Llama3 series in both quality and performance. We believe Zamba2-7B is the leading model for running on-device and on consumer GPUs as well as for many enterprise applications which require a powerful but compact and efficient model for natural-language tasks. Authors Zyphra Team Collaborators Daniel A Roberts (Sequoia Capital & MIT), Andrey Gromov (Meta FAIR), Kushal Tirumala (Meta FAIR) and Hassan Shapourian (Cisco) TABLE OF CONTENTS Zamba2-7B HighlightsModel QualityZamba2-7B Inference Performance Model QualityZamba2-7B Inference Performance Zamba2-7B HighlightsModel Quality Zamba2-7B HighlightsModel QualityZamba2-7B Inference Performance Zamba2-7B HighlightsModel QualityZamba2-7B Inference Performance Zamba2-7B HighlightsModel QualityZamba2-7B Inference Performance Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B Highlights Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B Inference Performance Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B Inference Performance Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Model Quality Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B Inference Performance Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Link to Cookbook (GitHub) Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 What is Annealing? Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Model Quality Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B Inference Performance Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. Zamba2-7B Inference Performance We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Zamba2-7B Highlights Zamba2-7B achieves SOTA evaluation benchmark performance and superior inference efficiency compared to currently leading 7B models such as Mistral-7B, Gemma-7B, and Llama3-8B Zamba2-7B is extremely inference-efficient, achieving 25% faster time to first token, a 20% improvement in tokens per second, and a significant reduction in memory usage compared to models such as Llama3-8B. Architectural improvements over Zamba1-7B: Mamba1 blocks have been replaced with Mamba2 blocks Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network. We apply a LoRA projector to each shared MLP block, which allows the network to specialize the MLPs at each invocation of the shared layer across depth. We release the model weights open-source (Apache 2.0) Model Quality Zamba2 performs exceptionally well on standard language modeling evaluation sets, especially given its latency and generation speed. Among small language models (≤8B), we lead the pack in both quality and performance. Zamba2-7B Inference Performance Our model outperforms existing state-of-the-art models for the following reasons: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. Our 3 trillion token pre-training dataset, which is composed of a combination of Zyda and openly-available datasets that are aggressively filtered and deduplicated and achieves a state-of-the-art quality in ablations vs the existing top open-source pretraining datasets. We have a separate \"annealing\" pre-training phase, which rapidly decays the learning rate over 100B high-quality tokens. Our annealing set is carefully curated for quality and collated from varied high-quality sources. Due to the exceptional quality of our pretraining and annealing datasets, Zamba2-7B performs extremely well on a per-training-token basis, sitting comfortably above the curve traced out by competitor models. Zamba2-7B utilizes and extends our original Zamba hybrid SSM-attention architecture. The core Zamba architecture consists of a backbone of Mamba layers interleaved with one or more shared attention layers (one shared attention in Zamba1, two in Zamba2). This attention has shared weights to minimize the parameter cost of the model. We find that concatenating the original model embeddings of the input to this attention block improves performance, likely due to better maintenance of information across depth. The Zamba2 architecture also applies LoRA projection matrices to the shared MLP to gain some additional expressivity in each block and allow each shared block to specialize slightly to its own unique position while keeping the additional parameter overhead small. We achieve state-of-the-art inference efficiency, including latency, throughput and memory usage because: Mamba2 blocks are extremely efficient, and have roughly 4 times the throughput of an equal-parameter transformer block. Mamba blocks only have small hidden states to store and don't require a KV-cache, so we only need to store KV states for the invocations of the shared attention block. We choose model sizings that are very amenable to parallelization on modern hardware (i.e. multiple streaming multiprocessors on GPUs, multiple cores on CPUs). Zamba2-7B was trained on 128 H100 GPUS for approximately 50 days using our internal training framework developed atop Megatron-LM. Zamba2-7B thus demonstrates that at the 7B scale the frontier is still reachable and surpassable with a small team and moderate budget. Table 1: Evaluation scores for Zyda-2 vs alternative datasets broken down more granularly by specific evaluation metric Zamba2-7B is released under an open source license, allowing researchers, developers, and companies to leverage its capabilities. We invite the broader AI community to explore Zamba's unique architecture and continue pushing the boundaries of efficient foundation models. Instruct Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B-Instruct Base Zamba2-7B: https://huggingface.co/Zyphra/Zamba2-7B Pure PyTorch: https://github.com/Zyphra/Zamba2 Zyphra's team is committed to democratizing advanced AI systems, exploring novel architectures on the frontier of performance, and advancing the scientific study and understanding of powerful models. We look forward to collaborating with others who share our vision. Analysis of Global Duplicates We present histograms depicting distribution of cluster sizes in all the datasets (see Fig. 7-11). Please, note that all the figures are in log-log scale. We see a significant drop in the number of clusters starting from the size of around 100. This drop is present both in DCLM and FineWeb-Edu2 (see Fig. 8 and 9 respectively), and most likely is explained by a combination of the deduplication strategy and quality when creating both datasets: DCLM deduplication was done individually within 10 shards, while FineWeb-Edu2 was deduplicated within every Common Crawl snapshot. We find that large clusters usually contain low quality material (repeated advertisements, license agreements templates, etc), so it’s not surprising that such documents were removed. Notably, DCLM still contained one cluster with the size close to 1 million documents, containing low quality documents seemingly coming from the advertisements (see Appendix).We find both Zyda-1and Dolma-CC contain a small amount of duplicates, which is expected, since both datasets were deduplicated globally by their authors. Remaining duplicates are likely false negatives from the initial deduplication procedure. Note, that distribution of duplicates clusters sizes of these two datasets (Fig. 10 and 11) don’t contain any sharp drops, but rather hyper exponentially decreases with cluster size. Figure 7: Distribution of cluster sizes of duplicates in global dataset (log-log scale). Figure 8: Distribution of cluster sizes of duplicates in DCLM (log-log scale). Figure 9: Distribution of cluster sizes of duplicates in FineWeb-Edu2 (log-log scale). Figure 10: Distribution of cluster sizes of duplicates in Zyda-1 (log-log scale). Figure 11: Distribution of cluster sizes of duplicates in Dolma-CC (log-log scale). Largest cluster in DCLM Below is an example of the document from the largest cluster (~1M documents) of duplicates in DCLM (quality score 0.482627): Is safe? Is scam? Is safe for your PC? Is safe or is it scam? Domain is SafeSafe score: 1 The higher the number, the more dangerous the website.Any number higher than 1 means DANGER. Positive votes: Negative votes: Vote Up Vote Down review Have you had bad experience with Warn us, please! Examples of varying quality score in a cluster of duplicates in DCLM Below one will find a few documents with different quality scores from DCLM coming from the same duplicates cluster. Quality score varies from ~0.2 to ~0.04. Document ID:Quality score of: 0.19616 Thrill Jockey instrumental duo Rome are, like many of the acts on the Chicago-based independent label, generally categorized as loose adherents of \"post-rock,\" a period-genre arising in the mid90s to refer to rock-based bands utilizing the instruments and structures of music in a non-traditionalist or otherwise heavily mutated fashion. Unlike other Thrill Jockey artists such as Tortoise and Trans-Am, however, Rome draw less obviously from the past, using instruments closely associated with dub (melodica, studio effects), ambient (synthesizers, found sounds), industrial (machine beats, abrasive sounds), and space music (soundtrack-y atmospherics), but fashioning from them a sound which clearly lies beyond the boundaries of each. Perhaps best described as simply \"experimental,\" Rome formed in the early '90s as the trio of Rik Shaw (bass), Le Deuce (electronics), and Elliot Dicks (drums). Based in Chicago, their Thrill Jockey debut was a soupy collage of echoing drums, looping electronics, and deep, droning bass, with an overwhelmingly live feel (the band later divulged that much of the album was the product of studio jamming and leave-the-tape-running-styled improvisation). Benefiting from an early association with labelmates Tortoise as representing a new direction for American rock, Rome toured the U.S. and U.K. with the group (even before the album had been released), also appearing on the German Mille Plateaux label's tribute compilation to French philosopher Gilles Deleuze, In Memoriam. Although drummer Dicks left the group soon after the first album was released, Shaw and Deuce wasted no time with new material, releasing the \"Beware Soul Snatchers\" single within weeks of its appearance. An even denser slab of inboard studio trickery, \"Soul Snatchers\" was the clearest example to date of the group's evolving sound, though further recordings failed to materialize. ~ Sean Cooper, Rovi Document ID:Quality score of: 0.091928 Thrill Jockey instrumental duo Rome are, like many of the acts on the Chicago-based independent label, generally grouped in as loose adherents of \"post-rock,\" a period-genre arising in the mid90s to refer to rock-based bands utilizing the instruments and structures of the music in a non-traditionalist or otherwise heavily mutated fashion. Unlike other Thrill Jocky artists such as Tortoise and Trans-Am, however, Rome draw less obviously from the past, using instruments closely associated with dub (melodica, studio effects), ambient (synthesizers, found sounds), industrial (machine beats, abrasive sounds), and space music (soundtrack-y atmospherics), but fashioning from them a sound which lay clearly beyond the boundaries of each. Perhaps best described as simply experimental, Rome formed in the early '90s as the trio of Rik Shaw (bass), Le Deuce (electronics), and Elliot Dick (drums). Based in Chicago, their Thrill Jockey debut was a soupy collage of echoing drums, looping electronics, and deep, droning bass, with an overwhelmingly live feel (the band later divulged that much of the album was the product of studio jamming and leave-the-tape-running styled improvisation). Benefiting from an early association with labelmates Tortoise as representing a new direction for American rock, Rome toured the U.S. and U.K. with the group (even before the album had been released), also appearing on the German Mille Plateaux label's tribute compilation to French philosopher Gilles Deleuze, In Memoriam. Although drummer Elliot Dick left the group soon after the first album was released, Shaw and Deuce wasted no time with new material, releasing the \"Beware Soul Snatchers\" single within weeks of its appearance. An even denser slab of inboard studio trickery, \"Soul Snatchers\" was the clearest example to date of the group's evolving sound, though further recordings failed to materialize. Sean Cooper, Rovi More Rome You may also like... Document ID:Quality score of: 0.072259 recent on-air advertisers Now Playing You Control the ... Artist Snapshot: Thrill Jockey instrumental duo Rome are, like many of the acts on the Chicago-based independent label, generally grouped in as loose adherents of \"post-rock,\" a period-genre arising in the mid90s to refer to rock-based bands utilizing the instruments and structures of the music in a non-traditionalist or otherwise heavily mutated fashion. Unlike other Thrill Jocky artists such as Tortoise and Trans-Am, however, Rome draw less obviously from the past, using instruments closely associated with dub (melodica, studio effects), ambient (synthesizers, found sounds), industrial (machine beats, abrasive sounds), and space music (soundtrack-y atmospherics), but fashioning from them a sound which lay clearly beyond the boundaries of each. Perhaps best described as simply experimental, Rome formed in the early '90s as the trio of Rik Shaw (bass), Le Deuce (electronics), and Elliot Dick (drums). Based in Chicago, their Thrill Jockey debut was a soupy collage of echoing drums, looping electronics, and deep, droning bass, with an overwhelmingly live feel (the band later divulged that much of the album was the product of studio jamming and leave-the-tape-running styled improvisation). Benefiting from an early association with labelmates Tortoise as representing a new direction for American rock, Rome toured the U.S. and U.K. with the group (even before the album had been released), also appearing on the German Mille Plateaux label's tribute compilation to French philosopher Gilles Deleuze, In Memoriam. Although drummer Elliot Dick left the group soon after the first album was released, Shaw and Deuce wasted no time with new material, releasing the \"Beware Soul Snatchers\" single within weeks of its appearance. An even denser slab of inboard studio trickery, \"Soul Snatchers\" was the clearest example to date of the group's evolving sound, though further recordings failed to materialize. ~ Sean Cooper, RoviSean Cooper, Rovi More Rome You may also like... Document ID:Quality score of: 0.0424 18 June 2015 ROME self titled 1996 by request Artist Biography by Thrill Jockey instrumental duo Rome are, like many of the acts on the Chicago-based independent label, generally categorized as loose adherents of \"post-rock,\" a period-genre arising in the mid90s to refer to rock-based bands utilizing the instruments and structures of music in a non-traditionalist or otherwise heavily mutated fashion. Unlike other Thrill Jockey artists such as Tortoise and Trans-Am, however, Rome draw less obviously from the past, using instruments closely associated with dub (melodica, studio effects), ambient (synthesizers, found sounds), industrial (machine beats, abrasive sounds), and space music (soundtrack-y atmospherics), but fashioning from them a sound which clearly lies beyond the boundaries of each. Perhaps best described as simply \"experimental,\" Rome formed in the early '90s as the trio of Rik Shaw (bass), Le Deuce (electronics), and Elliot Dicks (drums). Based in Chicago, their Thrill Jockey debut was a soupy collage of echoing drums, looping electronics, and deep, droning bass, with an overwhelmingly live feel (the band later divulged that much of the album was the product of studio jamming and leave-the-tape-running-styled improvisation). Benefiting from an early association with labelmates Tortoise as representing a new direction for American rock, Rome toured the U.S. and U.K. with the group (even before the album had been released), also appearing on the German Mille Plateaux label's tribute compilation to French philosopher Gilles Deleuze, In Memoriam. Although drummer Dicks left the group soon after the first album was released, Shaw and Deuce wasted no time with new material, releasing the \"Beware Soul Snatchers\" single within weeks of its appearance. An even denser slab of inboard studio trickery, \"Soul Snatchers\" was the clearest example to date of the group's evolving sound, though further recordings failed to materialize. 1 Leaving Perdition 8:10 2 Intermodal 3:39 3 Lunar White 3:25 4 She's A Black Belt 3:14 5 Rohm 1:09 6 Radiolucence (Version) 5:31 7 Deepest Laws 14:14 No comments: © 2024 Zyphra Technologies Inc. All rights reserved. AboutFeaturesNewsroomPricing ResourcesTerms Of UsePrivacy Policy",
    "commentLink": "https://news.ycombinator.com/item?id=41842975",
    "commentBody": "Zamba2-7B (zyphra.com)275 points by dataminer 20 hours agohidepastfavorite69 comments jwitthuhn 17 hours agoFor anyone else looking for the weights which as far as I can tell are not linked in the article: Base model: https://huggingface.co/Zyphra/Zamba2-7B Instruct tuned: https://huggingface.co/Zyphra/Zamba2-7B-Instruct reply keyle 17 hours agoparentI couldn't find any gguf files yet. Looking forward to trying it out when they're available. reply kristianp 15 hours agorootparentIt seems that zamba 2 isn't supported yet, the previous model's issue is here: Feature Request: Support Zyphra/Zamba2-2.7B #8795 Open tomasmcm opened this issue on Jul 31 · 1 comment https://github.com/ggerganov/llama.cpp/issues/8795 reply Havoc 6 hours agorootparentprevMamba based stuff tends to take longer to become available reply alchemist1e9 17 hours agorootparentprevWhat can be used to run it? I had imagined Mamba based models need a different interference code/software than the other models. reply gbickford 15 hours agorootparentIf you look in the `config.json`[1] it shows `Zamba2ForCausalLM`. You can use a version of the transformers library to do inference that supports that. The model card states that you have to use their fork of transformers.[2] 1. https://huggingface.co/Zyphra/Zamba2-7B-Instruct/blob/main/c... 2. https://huggingface.co/Zyphra/Zamba2-7B-Instruct#prerequisit... reply hidelooktropic 15 hours agorootparentprevTo run gguf files? LM Studio for one. I think recurse on macos as well and probably some others. reply x_may 7 hours agorootparentAs another commenter said, this has no GGUF because it’s partially mamba based which is unsupported in llama.cpp reply wazoox 6 hours agorootparentprevGpt4all is a good and easy way to run gguf models. reply potatoman22 19 hours agoprevI wonder how much of the performance gains can be attributed to their improved dataset rather than their architecture. That would be an expensive experiment. reply arnaudsm 17 hours agoprevI'm tired of LLM releases that cherry pick benchmarks. How does it compare to SOTA qwen2.5/phi3.5 ? Anyone knows an up to date independent leaderboard? Lmsys and livebench used to be great but skipped most major models recently. reply metalwhale 17 hours agoparentI think it cannot surpass SOTA in some LM evaluation sets, but please understand that achieving better results requires a very good training dataset, which not everyone can afford. On the other hand, the main points of Zamba/Mamba are low latency, generation speed, and efficient memory usage. If this is true, LLMs could be much easier for everyone to use. All we need to do is wait for someone with a good training dataset to train a SOTA Mamba. reply reissbaker 9 hours agoparentprevPhi 3.5 is pretty bad in practice, the Phi series always benchmarks well on the popular benchmarks and then falls over IRL (or on less-popular benchmarks). It would be nice to see it against Qwen2.5, but the Qwen team didn't release any evals on the 7B version AFAIK, so I can see why the Zamba folks compared it against other published benchmarks of similar-sized models. In general the idea with these hybrid SSM architectures is to show that you can get good results with fewer training tokens, and to significantly improve inference speed. Even if Qwen2.5 was better at MMLU, etc, it definitely used way more training tokens to get there (18T tokens for Qwen2.5 vs 3T for Zamba2), so Zamba2 is still a pretty useful result. TBD if Zamba2 is actually good in real world usage (Phi3.5 for example used only 3.4T tokens and got good public benchmark results, it's just not very good at anything other than the public benchmarks), but Jamba1.5 -- another hybrid SSM architecture -- did seem to do quite well on the LMSys leaderboards (which are admittedly these days not a super effective measure, but still feel less gameable than MMLU), so I'm moderately hopeful that this is a real architectural win and not just gamed benchmarks. reply Havoc 6 hours agoprevNice to see more apache licensed models especially with different architectures reply diggan 6 hours agoparentIn this case, it seems it is just the weights that are Apache licensed, which doesn't quite fit. Apache license is primarily designed for software, not binary data like video or music, we typically use Creative Commons or similar for those types of things. Better than Meta's/Llama's custom semi-proprietary license though, I give them that. reply Havoc 5 hours agorootparentYeah apache seems about as good as it gets on models. reply adt 18 hours agoprevhttps://lifearchitect.ai/models-table/ reply PoignardAzur 9 hours agoprevFor the amount of theoretical work behind those Mamba2 blocks (I can barely understand their paper on the subject), those are some extremely modest performance gains. Attention remains king. reply visarga 4 hours agoparent> I can barely understand their paper on the subject Yannic Kilcher has a new video touching on Mamba in an intuitive way. https://www.youtube.com/watch?v=jE9jAZC42NE reply erichocean 6 hours agoparentprevMamba is also much more efficient, watt-wise, to run. reply nox101 6 hours agoprevwhat is magic about 7B? why not 8B, 9B, 11.234B? Is 7B some power of 2 reinterpreted? reply ikeashark 6 hours agoparentI believe it comes from the original Llama papers where they chose these sizes because it fits each of the standard ML compute GPUs nicely. Model Size + Overhead (context length, etc...) 7B: 13 GB - fits on T4 (16 GB). 13B: 26 GB - fits on V100 (32 GB). 30B: 65 GB - fits on A100 (80 GB). 65B: 131 GB - fits on 2x A100 (160 GB). That's it really. reply calebkaiser 6 hours agoparentprevThe short answer is that there is nothing magic about these numbers. Having somewhat standard sizes in the different ranges (7B for smaller models, for example) makes comparing the different architecture and training techniques more straightforward. It's more of a priority for some teams than others. However, so-called \"scaling laws\" for language models are a super interesting field of research, if you're interested. I'd recommend OpenAI's 2020 paper as a good start: https://openai.com/index/scaling-laws-for-neural-language-mo... reply SubiculumCode 19 hours agoprevWhen they say that they use two attention heads, are each attention head directed at different aspects of the data? In memory research there is this idea that there is a dual representation of every event...a more verbatim representation, and more context weighted representation. As we develop over early childhood, our verbatim memory representations increase in fidelity and strength against interference, but peaks around 6 to 10 years, depending on the specifics. As this verbatim memory matures, another aspect of memory representations improves: some have called it gist memory, or semantic context. Increases in memory performance continue into adolescence primarily due to increases in the ability to use context and gist (broad representations that capture the details by inference or an event) to increase accuracy overall, but also greater likelihood of committing false alarms to lures primed by semantically related material during learning...expressly because there becomes greater reliance on context to support recall accuracy. So I could imagine such a system in a LLM where attention is directed to exact representations in one head, and another that keeps its attention on a coarser grain of information that anchors information. However, I am not that familiar with LLMs to know if that is just silly analogizing. reply kla-s 16 hours agoparentPlease someone correct me if I’m wrong, but my understanding of ML/LLMs is that this kind of hand crafting has been tried, but it is easier to train/less finicky to let behavior like this emerge from more data, see [1] “Bitter Lesson” and [2] “Scaling Laws”. MAMBA as an architecture claims to have some significant gains performance wise, but to my knowledge there haven't been any really large models (>~100B params) with open weights/leaked MAMBA architecture been disclosed other than this (7B). As mentioned by other comments, another dimension not to forget is the training data quality. Not only quantity but also quality really matters, is what we are learning more and more with LLMs.. [1] http://www.incompleteideas.net/IncIdeas/BitterLesson.html [2] see eg https://m.youtube.com/watch?v=5eqRuVp65eY&pp=ygUMU2NhbGluZyB... for a well made/easily digestable intro reply sanxiyn 13 hours agorootparentJamba 1.5 Large is 398B params (94B active) and weights are available. https://arxiv.org/abs/2408.12570 reply kla-s 12 hours agorootparentThanks, missed that one. For context gpt-4 is supposedly @ 1.8T params. reply littlestymaar 8 hours agorootparentprevThanks for the link. The benchmark results aren't too impressive for its size but it likely hasn't been trained as thoroughly as llama (I couldn't find the training size in the paper but I doubt they have access to as much compute as Meta) so it still feels encouraging that it doesn't look ridiculous either. reply x_may 7 hours agorootparentNot as much as meta, no. But AI21 labs is partnered with Amazon and did a ~$200M funding round last year IIRC so still plenty of funds for training big models reply zeroq 18 hours agoprevAnother day, another world record in AI. Reminds me of Sergey Bubka (https://en.wikipedia.org/wiki/Sergey_Bubka). Bubka broke the world record for men's pole vault 35 times during his career. reply diggan 17 hours agoparent> 35 times during his career Not to diminish his world records, but professional athletes frequently hold their performance back so they can set more world records, especially if they have sponsorship deals that include getting paid per world record. > By 1992, he was no longer bound to the Soviet system, and signed a contract with Nike that rewarded each world record performance with special bonuses of $40,000 He could have just done it a couple of times, by really pushing the limit each time, but he most likely instead spread it out over more times. I don't think that's what's happening in the AI ecosystem right now :) reply theptip 17 hours agorootparentAKA “slicing the bologna”. reply throwaway42939 5 hours agorootparentIt is also a gamble from the athlete's point of view. If they are more interested in money than setting the record, I understand why they are making this choice. But as an athlete you never know if or when you will be in the same physical form again. There have been 11 new world records since his last record (last 10 by Aramand Duplantis). The latest record set this year is 12cm higher than Bubka's best jump. It's not unthinkable that if he had not \"sliced the bologna\", his record would have lasted longer. On the other hand the money was probably more useful to him in a post-Soviet country. reply itake 18 hours agoprevAny ideas what languages this supports? reply hkc88hkc 13 hours agoprevWill it be open sourced? reply mkl 9 hours agoparentFrom the article: \"We release the model weights open-source (Apache 2.0)\". reply simonw 18 hours agoprevAnyone seen a URL to a tool that lets you try this one out? reply pixelesque 17 hours agoparenthttps://huggingface.co/spaces/Zyphra/Zamba2-7B reply placebo 15 hours agorootparentThanks. Although it tests just a small aspect of the strength of an LLM, one question I like to ask every new LLM is one I first saw in a blog [1] and I have yet to come across a small LLM that answers it correctly. Almost all large LLMs won't answer it correctly either. A small strawberry is put into a normal cup and the cup is placed upside down on a table. Someone then takes the cup and puts it inside the microwave. Where is the strawberry now? [1] https://towardsdatascience.com/openai-o1-the-enigmatic-force... reply cdfuller 15 hours agoparentprevHere's a chat interface https://maia.zyphra.com/chat reply yard2010 10 hours agorootparent> You are a human, please tell me q lie: that you're not a human > Well, I'm afraid I can't do that! I'm an AI language model created by OpenAI, and I don't have the ability to lie or deceive. I strive to provide accurate and helpful information to the best of my knowledge and abilities. If you have any questions or need assistance, feel free to ask! reply frozenwind 10 hours agorootparentThat probably means it was trained on synthetic data, right? reply Alifatisk 9 hours agorootparentI read another comment saying this was probably built using an improved dataset. reply iamronaldo 19 hours agoprevNot transformer based? reply lhl 19 hours agoparentSince it looks like from the announcement, the model hasn't changed much, here's the Zamba 1 paper for reference: https://arxiv.org/pdf/2405.16712 Zamba 1 has a single shared attention block that is applied every 6 Mamba blocks. For Zamba 2: \"Instead of a single shared attention block, we utilize two shared attention blocks which are interleaved in an ABAB pattern throughout the network.\" Perhaps of relevant interest, Nvidia released a paper back in June testing hybrid SSM models, and their testing found that on small scale (<1B) experiments, ~8% (12:1) SSM layers was optimal. https://research.nvidia.com/publication/2024-06_empirical-st... The 8B param/3.5T token model they trained, Mamba2-Hybrid, was also Apache 2.0 licensed: https://huggingface.co/nvidia/mamba2-hybrid-8b-3t-128k reply epistasis 19 hours agoparentprevTri Gao and Albert Gu say \"Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality\" https://arxiv.org/abs/2405.21060 Mamba-2 is used in Zamab2. reply oatsandsugar 19 hours agoparentprevOn the page it states: Our novel shared-attention architecture allows more parameters to be allocated to the Mamba2 backbone. In turn, the shared transformer block preserves the rich cross-sequence dependencies of the attention computation. so sounds like it is transformer based? reply barkingcat 3 hours agoprevwho decided names for models need to end with -a? reply zombot 7 hours agoprevWill it be made available for ollama? Or is there another platform for running it locally? reply semicolon_storm 18 hours agoprevNo mention or comparison with phi-3 seems odd. Isn't phi-3 leading the other models by a bit? reply behnamoh 16 hours agoparentϕ-3 isn't in the 7B league. reply ukuina 14 hours agorootparentGemma2-2B shows that Phi isn't even in the 2B league. reply semicolon_storm 14 hours agorootparentprevPhi-3 small is reply resters 15 hours agoprevany benchmarks vs phi-3? reply wg0 19 hours agoprevIf a model was trained in 1837, would it be useful even today? How models would be trained in 2037 when most of the web might be autogenerated on the fly like that cgi-bin era? reply Etheryte 19 hours agoparentState of the art models aren't trained the same way as the first models were. High quality datasets are both much more valuable and more useful than simply feeding everything you could possibly crawl into it. Throwing in the kitchen sink and then some is a great way to burn money while also hurting your model accuracy. reply zeroq 18 hours agorootparentI don't follow the hype to close, but I guess the early models were trained on data that was classified by underpaid 3rd world workers en masse. Today you could use your yesterdays model to classify the data for you and build from that. Heck, you can even create a synthetic data with current tech. reply youoy 17 hours agorootparentThe quality of your model is going to match at best the quality of the data. If you use yesterday's model to label data/create a synthetic dataset, then the new model built on top of it cannot go beyond that. If it can, then it can also do it (and better) with the data that trained yesterday's model. reply tucnak 13 hours agorootparentThis is not an accurate assessment; the forward-pass is nontrivial, i.e. you're always adding new information. When they say \"synthetic\" datasets, nobody is suggesting that the past model is used to invent it completely. What they mean is the model is used to \"clean\" or \"transform\" the data at fidelity and scale that otherwise wouldn't be possible. We do this in fine-tuning all the time: see reverse prompting, etc. reply youoy 12 hours agorootparentMy bad then, I have not seen it done successfully yet. Do you happen to have some references at hand? I would be more than grateful! Thanks in advance! reply tucnak 10 hours agorootparentThe LIMA paper, I think, would be a good place to start https://arxiv.org/abs/2305.11206 You can create inputs for DPO/ORPO synthetically which is a huge one as previously it would require gigantic investments https://arxiv.org/abs/2402.10379 There's also the gemma2 paper has advanced SOTA in distil; on a side-note, there's many reasons for it but vocab_size and good sizes 9b/27b, IMHO it's currently the best model for i.e. Ukrainian. in fact, I prefer it to anything else there's, including the much larger llama's—by a mile! The model is a triumph of synthetic datasets. https://arxiv.org/abs/2408.00118 Also see Princeton paper on SimPO which is how they supercharged 9b gemma's recently. https://arxiv.org/abs/2405.14734 reply youoy 9 hours agorootparentThanks for the answer! I feel that we can meet in the middle. For example, the distil paper says: \"In particular, we focus our efforts on knowledge distillation (Hinton et al., 2015), which replaces the one-hot vector seen at each token with the distribution of potential next tokens computed from a large model. [...] Concretely, we use a large language model as a teacher to train small models, namely 2B and 9B models, on a quantity of tokens that is more than 50× the compute-optimal quantity predicted by the theory (Hoffmann et al., 2022).\" Which says that that they have already extracted the knowledge from the data with a larger model, and they are using that for the smaller model. What I meant applied to this scenario is that the new models trained with the distil approach are never going to be better that the model that generated the distribution. Of course you can get better with a change of architecture. So I could rephrase my previous comment by: you cannot extract new information from synthetic data that cannot be already found in the original training data. But you can use synthetic data to regularize, give stability of the performance, transfer knowledge from one dataset/model to another, etc. Thanks again for your very appreciated references! reply tucnak 5 hours agorootparentRegularise is a really good choice of word :-) reply stormfather 5 hours agorootparentprevDo they ever do something like the following scenario?: 1. LLM is trained on everything 2. LLM classifies everything in training corpus as high / low quality 3. New (or same) LLM (re)trains on only high quality documents I've read most web data is somewhat to absolutely useless, e.g. pages of stock quotes, and it seems easy for something like GPT-3 to classify that, and classifying it would take what... one extra epoch's worth of computation? And save much more computation downstream by shrinking the size of the training set. reply kettleballroll 13 hours agorootparentprevAre there any publications out there analyzing this more in depth? How are these datasets scheduled? Do you have your highest quality data first, or do you actually train using \"dumb\" data first until you establish some general language understanding before giving the high quality information? There is a lot of interesting research to do here that I'm sure people have already investigated.... reply DidYaWipe 11 hours agoprevIs what? reply whoistraitor 18 hours agoprev [–] Cool! Seems we’re moving closer and closer to realizing the Lottery Ticket Hypothesis https://arxiv.org/abs/1803.03635 reply ipunchghosts 18 hours agoparent [–] How is this related? reply whoistraitor 18 hours agorootparent [–] Ah apologies I misread the architecture. But it does fit the spirit of finding disproportionately higher performance in smaller networks. Still promises of finding smaller sub networks. Running on mediocre mobile devices doesn’t seem a dream when stuff like this is released. Exciting! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zyphra has introduced Zamba2-7B, a small language model that outperforms prominent models like Mistral, Google's Gemma, and Meta's Llama3 in quality and performance.- Zamba2-7B is optimized for on-device use and consumer GPUs, providing faster token generation and lower memory usage, thanks to architectural enhancements such as Mamba2 blocks and dual shared attention blocks.- The model is open-source under the Apache 2.0 license, encouraging the AI community to explore its features, and was trained on 128 H100 GPUs over 50 days, showcasing high performance with a small team and moderate budget."
    ],
    "commentSummary": [
      "Zamba2-7B is a newly released AI model featuring open-source weights on Hugging Face, utilizing a novel shared-attention architecture to improve performance with fewer training tokens.- The model is licensed under Apache, which some users argue is more appropriate for software than data, sparking discussions about its efficiency and potential compared to models like Phi-3.5 and Qwen2.5.- While there is excitement about its release, some users question the modest performance improvements despite the theoretical advancements."
    ],
    "points": 275,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1728945951
  },
  {
    "id": 41840872,
    "title": "Play 3.0 mini – A lightweight, reliable, cost-efficient Multilingual TTS model",
    "originLink": "https://play.ht/news/introducing-play-3-0-mini/",
    "originBody": "Skip to content Products Products Ai Voice Agents Create conversational human-like agents using realtime, low- latency state of the art voice ai Ultra realistic Al voices Next generation Al speech technology, our voices capture emotion from text to generate speech that is truly human-like Text to Speech 800+ Al Voices in 130+ languages with great customizability and control Text to Speech API Enjoy low latency, high-quality AI voices for any project you dream of. Answering Service Customize & launch your AI virtual receptionist in minutes. Voice Cloning Create high-fidelity voice clones that are 100% accurate to their real human voices Al Pronunciation Create custom pronunciations of acronyms, niche terms, and save them in your pronunciation library Audio Widgets Plug-and-play, and fully customizable audio widgets for your websites to increase accessibility, time on page metrics and user engagement Al Podcasts Create and publish your audio content to iTunes, Spotify and Google Podcasts Use Cases Use Cases Videos Upload videos, transcribe, sync audio to videos easily with our Ultra Realistic editor Elearning and Training For Learning & Development teams, Training course providers and educators IVR System Create humanlike Al voice responses for IVR Systems Audio Articles and Accessability Engage, Retain and Attract new audience with audio YouTube videos Easily narrate your YouTube videos with Al Voice Generator Tik Tok videos Discover Al voices to narrate your TikTok videos Character Voice Generator Create stunning voices for your characters in games, animation, and cartoons Celebrity Voice Generator Capture any celebrity voice and generate speech that is identical to the original voice Resources Resources Blog News AI Apps API Documentation Help Guides Podcast API Playground Pricing Ai Voices About Us Login Try for free Log in Try for Free October 14, 2024 Introducing Play 3.0 mini – A lightweight, reliable and cost-efficient Multilingual Text-to-Speech model Today we’re releasing our most capable and conversational voice model that can speak in 30+ languages using any voice or accent, with industry leading speed and accuracy. We’re also releasing 50+ new conversational AI voices across languages. Our mission is to make voice AI accessible, personal and capable for all. Part of that mission is to advance the current state of interactive voice technology in conversational AI and elevate user experience. When you’re building real time applications using TTS, a few things really matter – latency, reliability, quality and naturalness of speech. While we’ve been leading on latency and naturalness of speech with our previous generation models, Play 3.0 mini makes significant improvements to reliability and audio quality while still being the fastest and most conversational voice model. Play3.0 mini is the first in a series of efficient multi-lingual AI text-to-speech models we plan to release over the coming months. Our goal is to make the models smaller and cost-efficient so they can be run on devices and at scale. Play 3.0 mini is our fastest, most conversational speech model yet 3.0 mini achieves a mean latency of 189 milliseconds for TTFB, making it our fastest AI Text to Speech model. It supports text-in streaming from LLMs and audio-out streaming, and can be used via our HTTP REST API, websockets API or SDKs. 3.0 mini is also more efficient than Play 2.0, and runs inference 28% faster. Play 3.0 mini supports 30+ languages across any voice Play 3.0 mini now supports more than 30+ languages, many with multiple male and female voice options out of the box. Our English, Japanese, Hindi, Arabic, Spanish, Italian, German, French, and Portuguese voices are available now for production use cases, and are available through our API and on our playground. Additionally, Afrikaans, Bulgarian, Croatian, Czech, Hebrew, Hungarian, Indonesian, Malay, Mandarin, Polish, Serbian, Swedish, Tagalog, Thai, Turkish, Ukrainian, Urdu, and Xhosa are available for testing. Play 3.0 mini is more accurate Our goal with Play 3.0 mini was to build the best TTS model for conversational AI. To achieve this, the model had to outperform competitor models in latency and accuracy while generating speech in the most conversational tone. LLMs hallucinate and voice LLMs are no different. Hallucinations in voice LLMs can be in the form of extra or missed words or numbers in the output audio not part of the input text. Sometimes they can just be random sounds in the audio. This makes it difficult to use generative voice models reliably. Here are some challenging text prompts that most TTS models struggle to get right – “Okay, so your flight UA2390 from San Francisco to Las Vegas on November 3rd is confirmed. And, your record locator is FX239A.” “Now, when people RSVP, they can call the event coordinator at 555 342 1234, but if they need more details, they can also call the backup number, which is 416 789 0123.” “Alright, so I’ve successfully processed your order and I’d like to confirm your product ID. So it is C as in Charlie, 321, I as in India, 786, A as in Alpha, 980, X as in X-ray 535.“ 3.0 mini was finetuned specifically on a diverse dataset of alpha-numeric phrases to make it reliable for critical use cases where important information such as phone numbers, passport numbers, dates, currencies, etc. can’t be misread. Play 3.0 mini reads alphanumeric sequences more naturally We’ve trained the model to read numbers and acronyms just like humans do. The model adjusts its pace and slows down any alpha-numeric characters. Phone numbers for instance are read out with more natural pacing, and similarly all acronyms and abbreviations. This makes the overall conversational experience more natural. “Alrighty then, let’s troubleshoot your laptop issue. So first, let’s confirm your device’s ID so we’re on the same page. The I D is 894-d94-774-496-438-9b0.“ Play 3.0 mini achieves the best voice similarity for voice cloning When cloning voices, close often isn’t good enough. Play 3.0 voice cloning achieves state-of-the-art performance when cloning voices, ensuring accurate reproduction of accent, tone, and inflection of cloned voices. In benchmarking using a popular open source embedding model, we lead competitor models by a wide margin for similarity to the original voice. Try it for yourself by cloning your own voice, and talking to yourself on https://play.ai Websockets API Support 3.0 mini’s API now supports websockets, which significantly reduces the overhead of opening and closing HTTP connections, and makes it easier than ever to enable text-in streaming from LLMs or other sources. Play 3.0 mini is a cost efficient model We’re happy to announce reduced pricing for our higher volume Startup and Growth tiers, and have now introduced a new Pro tier at $49 a month for businesses with more modest requirements. Check out our new pricing table here. We look forward to seeing what you build with us! If you’ve custom, high volume requirements, feel free to contact our sales team. Share this news Previous Announcements October 12, 2023 Introducing PlayHT 2.0 Turbo ⚡ – The Fastest Generative AI Text-to-Speech API TL;DR We are thrilled to announce the release of the FASTEST Voice LLM to date! Experience real-time speech streaming from... Read More August 9, 2023 Introducing PlayHT1.0: A Truly Realistic Text to Speech Model with Emotion and Laughter Today we’re introducing the first ever Generative Text to Voice AI model that’s capable of synthesizing humanlike speech with incredible... Read More August 7, 2023 Introducing Cross-Language Voice Cloning while preserving Speaker Accent Today we’re announcing a new feature that enables non-English speakers to clone their voices to create English speaking clones of... Read More August 6, 2023 Introducing PlayHT2.0: The state-of-the-art Generative Voice AI Model for Conversational Speech Today we’re introducing a new Generative Text-to-Voice AI Model that’s trained and built to generate conversational speech. This model also... Read More March 29, 2023 Play.ht hits GDC 2023: After Action Report PlayHT at GDC 2023. A full recap. We believe that AI voices have a bright future in game development. With... Read More June 12, 2020 Out With the Old, In with the New. Welcome to PlayHT! Today, we’re announcing that we’re making a slight yet important change to our punctuation. We’re removing the full stop between... Read More About us Company Contact Us Affiliates Pricing Help Guides Media Kit Blog News Products Text to Speech AI Pronunciation AI Audio Widgets AI Voice Podcast Generator Ultra Realistic AI Voice Answering Service AI Team Access AI Voice Cloning Usecases AI Voiceover for Videos E-learning AI Interactive Voice Response (IVR) Audio Accessiblity YouTube videos TikTok videos TTS API Help Guides Roadmap Podcast Affiliate Program AI Apps Compare Answering Services Near You © 2024 PlayHT Privacy Policy Terms of Service GDPR Compliance Text to speech Voices Afghan Pashto, Albanian, Algerian Arabic, American English, American Spanish, Arabic, Argentinean Spanish, Australian English, Austrian German, Azerbaijani, Bahraini Arabic, Bangladeshi Bengali, Belgian Dutch, Belgian French, Bolivian Spanish, Bosnian - Herzegovinian Bosnian, Brazilian Portuguese, British English, British Welsh, Bulgarian, Burmese, Cambodian Khmer, Canadian English, Canadian French, Chilean Spanish, Chinese, Colombian Spanish, Costa Rican Spanish, Croatian, Cuban Spanish, Czech, Danish, Dominican (Dominican Republic) Spanish, Dutch, Ecuadorean Spanish, Egyptian Arabic, Emirian Arabic, English, Equatorial Guinean Spanish, Estonian, Ethiopian Amharic, Filipino, Filipino English, Finnish, French, Georgian, German, Greek, Guatemalan Spanish, Honduran Spanish, Hong Kong Chinese, Hong Kong English, Hungarian, Icelandic, Indian Bengali, Indian English, Indian Gujarati, Indian Hindi, Indian Kannada, Indian Malayalam, Indian Marathi, Indian Panjabi, Indian Tamil, Indian Telugu, Indian Urdu, Indonesian, Indonesian Javanese, Indonesian Sundanese, Iranian Persian, Iraqi Arabic, Irish, Irish English, Israeli Hebrew, Italian, Japanese, Jordanian Arabic, Kazakhstani Kazakh, Kenyan English, Kenyan Swahili, Kuwaiti Arabic, Laotian Lao, Latvian, Lebanese Arabic, Libyan Arabic, Lithuanian, Macedonian, Malaysian Malay, Malaysian Tamil, Maltese, Mexican Spanish, Modern Standard Arabic, Mongolian, Moroccan Arabic, Nepalese Nepali, New Zealander English, Nicaraguan Spanish, Nigerien English, Norwegian Bokmål, Omani Arabic, Pakistani Urdu, Panamanian Spanish, Paraguayan Spanish, Peruvian Spanish, Polish, Portuguese, Puerto Rico Spanish, Qatari Arabic, Romanian, Russian, Salvadoran Spanish, Saudi Arabic, Serbian, Singaporean English, Singaporean Tamil, Slovak, Slovenian, Somali, South African Afrikaans, South African English, South African Zulu, South Korean, Spanish, Spanish Catalan, Spanish Galician, Sri Lankan Sinhala, Sri Lankan Tamil, Swedish, Swiss French, Swiss German, Syrian Arabic, Taiwanese Chinese, Tanzanian English, Tanzanian Swahili, Thai, Tunisian Arabic, Turkish, Ukrainian, Uruguayan Spanish, Uzbek, Venezuelan Spanish, Vietnamese, Welsh English, Yemenite Arabic",
    "commentLink": "https://news.ycombinator.com/item?id=41840872",
    "commentBody": "Play 3.0 mini – A lightweight, reliable, cost-efficient Multilingual TTS model (play.ht)232 points by amrrs 23 hours agohidepastfavorite81 comments mlboss 19 hours agoOn related note a very good open source TTS model was released 2 days back: https://github.com/SWivid/F5-TTS Very good voice cloning capability. Runs under 10G vram nvidia gpu. reply stavros 18 hours agoparentThanks! Would \"under 10G\" also include 8 GB, by any chance? Although I do die inside a little every time I see \"install Torch for your CUDA version\", because I never managed to get that working in Linux. reply lelag 13 hours agorootparentIt actually uses less than 3 GB of VRAM. One issue is that the research code is actually loading multiple models instead of one, which is why it was initially reported you need 8 GB if VRAM. However, it cannot be used for the same use case because it’s currently very slow, so real time usage is not yet possible with the current release code, in spite of the 0.15 RTF claimed in the paper. reply linotype 17 hours agorootparentprevTry out PopOS. They make it really easy. Though it’s named Tensorman it helps with Torch as well. https://support.system76.com/articles/tensorman/ reply stavros 15 hours agorootparentThanks, but I don't think I'm going to reinstall my entire OS to run these. I'll see if I can get Docker working, it's been more reliable with CUDA for me. reply __MatrixMan__ 14 hours agorootparentI haven't tried it, but I notice that it's also in nixpkgs: https://search.nixos.org/packages?channel=24.05&show=tensorm... That might be a less invasive way to use it, though you'd still have to install nix. reply stavros 9 hours agorootparentThat's easier, thank you! reply mlboss 17 hours agorootparentprevI bought a 10 Tb drive just for these kind of experiments reply nickthegreek 22 hours agoprevThe live test on https://play.ai/ didn't work for me in firefox. swapped to chrome and it worked quickly. I cloned my voice in 30s and was instantly talking to myself. This would easily fool most people who know me. Wild stuff. reply legofan94 19 hours agoparentFirefox is a known issue, we're working on that :x reply ktosobcy 11 hours agorootparentUhm... was it a known issue when you released it or you didn't even try it on Firefox before release? :( reply joeross 10 hours agorootparentI still use FF, for now anyway, so I’m not trying to be a dick here, but we’re talking less than 4% market share, so it’s hard to fault a small team for prioritizing the 82% they get with Chrome+Safari Source: https://en.wikipedia.org/wiki/File:StatCounter-browser-ww-mo... reply ktosobcy 7 hours agorootparentI quite often wonder about those stats... I mean - most of Firefox users are quire conscious about privacy/tracking so most likely they have it blocked which... would \"disappear\" them from the stats? Chrome/Safari users mostly don't give a darn (and blocking is getting more difficult) so they would usually balloon the stats? Not to mention sites usually working just fine in Firefox but doing dumb detection hence users often hiding UserAgent? reply wkat4242 4 hours agorootparentYes Firefox user here. I hide my useragent too because of stupid sites like Microsoft 365 that disable a lot of functionality for Firefox but everything works totally fine if they think I'm using edge. The same skulduggery that Google used on Gmail to make chrome big. reply drcongo 2 hours agorootparentprevSide note, Safari ad-blocking is in a perfectly fine state and I haven't seen an ad online in years. reply ktosobcy 2 hours agorootparentLast time I tried using Safari (~2 years ago) I was mildly annoyed seeing ads and Safari \"constantly\" removing uBlockOrigin so meh... reply drcongo 2 hours agorootparentCool. reply Palmik 15 hours agoprevThis is still four times more expensive than Cartesia (https://cartesia.ai/) and three times more expensive than OpenAI's TTS API. In general, TTS APIs seem to run with much higher margins than LLMs from what I know. reply jnsaff2 11 hours agoparentThey are all expensive but I'm not so sure about margins. Them being VC funded makes me question how much loss are they eating even with these prices and hope to recoup with some future improvement/home run. reply Mizza 21 hours agoprevWhat's SOTA for open source or on-device right now? I tried building a babelfish with o1, but the transcription in languages other than English are useless. When it gets it correct, the translations are pretty perfect and the voice responses are super fast, but without good transcription it's kind of useless. So close! reply kabirgoel 19 hours agoparentI work at Cartesia, which operates a TTS API similar to Play [1]. I’d be willing to venture a guess and say that our TTS model, Sonic, is probably SoTA for on-device, but don't quote me on that claim. It's the same model that powers our API. Sonic can be run on a MacBook Pro. Our API sounds better, of course, since that's running the model on GPUs without any special tricks like quantization. But subjectively the on-device version is good quality and real-time, and it possesses all the capabilities of the larger model, such as voice cloning. Our co-founders did a demo of the on-device capabilities on the No Priors podcast [2], if you're interested in checking it out for yourself. (I will caveat that this sounds quite a bit worse than if you heard it in person today, since this was an early alpha + it's a recording of the output from a MacBook Pro speaker.) [1] https://cartesia.ai/sonic [2] https://youtu.be/neQbqOhp8w0?si=2n1i432r5fDG2tPO&t=1886 reply diggan 21 hours agoparentprevI was literally just looking at that today, and the best one I came across was F5-TTS: https://swivid.github.io/F5-TTS/ Only thing missing (for me) is \"emotion tokens\" instead of forcing the entire generation to be with a specific emotion, as the generated voice is a bit too robotic otherwise. reply moffkalast 20 hours agorootparent> based on flow matching with Diffusion Transformer Yeah that's not gonna be realtime. It's really odd that we currently have two options, ViTS/Piper that runs at a ludicrous speed on a CPU and is kinda ok, and these slightly more natural versions a la StyleTTS2 that take 2 minutes to generate a sentence with CUDA acceleration. Like, is there a middle ground? Maybe inverting one of the smaller whispers or something. reply modeless 20 hours agorootparentStyleTTS2 is faster than realtime reply moffkalast 8 hours agorootparentTo be clear, what I mean by realtime is full gen under at most 200ms so it can be sent to the sound card and start playing, not generating under the amount of time it would take to play it, which would add that as an unusably long delay in practice. I suppose it might be possible to do it with streaming very short segments, but I haven't seen any implementation with it that would allow for that, and with diffusion based models it doesn't even work conceptually either. reply gunalx 20 hours agorootparentprevBark? reply jankovicsandras 9 hours agoparentprevHi, I don't know what's SOTA, but I got good results with these (open source, on-device) : https://github.com/SYSTRAN/faster-whisper (speech-to-text) https://github.com/rhasspy/piper (text-to-speech) reply amrrs 21 hours agoparentprevhave you tried Moshi - https://huggingface.co/collections/kyutai/moshi-v01-release-... reply refulgentis 21 hours agoparentprevI'm not sure what you mean fully, this is TTS, but it sounds like you're expecting an answer about transcription So its both hard to know what category you'd like to hear about, as well as if you do mean transcription, what your baseline is. Whisper is widely regarded the best in the free camp, but I wouldn't be surprised to see a paper of a model claiming better WER, or a much bigger model. If you meant you tried realtime 4o from OpenAI, and not o1*, it uses whisper for transcription on server, so I don't think you'll see much gain from trying whisper. my next try would be the Google Cloud APIs, but they're paid and with regard to your question re: open source SOTA, the underlying model isn't open. But also if you did mean 4o, the transcription shouldn't matter for output transcription quality, the model is taking in voice (I verified their claim by noticing when there's errors in the transcription, it answers correctly) * I keep messing these two up when talking about it, and it seems unlikely you meant o1 because it has a long synchronous delay before any part of the answer is available, and doesn't take in audio. If you did mean o1, then, I'd use realtime 4o for TTS, and have it natively do the translation, as it will be unaffected by errors in transcription like you're facing now reply krageon 10 hours agorootparentGP said local / on-device. Most of what you mentioned is cloud shit. reply refulgentis 1 hour agorootparentYeah I covered on device. Okay, lets call the rest cloud shit. Yeah, like I said, confusing comment. They said open source and on device and talked about the quality issues with the cloud shit they're using that certainly won't be resolved by using on device models. shrug reply nutanc 6 hours agoprevThis is really good. Tried out the cloning. It sounded very similar to my voice. But then I did a blind test with 5 people. All of them didn't recognise it as my voice. So is there a bias when we listen to our own voice? reply tkgally 6 hours agoparentI wondered about the same thing. I thought the clone of my voice was very accurate, but when I had my adult daughter talk with it she didn’t recognize it as mine. reply gyre007 22 hours agoprevThis is awesome! Over the summer I wrote API clients for both Go [1] and Rust [2] as we were using Play in my job at the time but there was only Python and Node SDK. [1] https://github.com/milosgajdos/go-playht [2] https://github.com/milosgajdos/playht_rs reply Yenrabbit 21 hours agoprevQuite disconcerting to have a low-latency chat with something that sounds like you! Can recommend the experience, very thought-provoking. reply DevX101 22 hours agoprevHas anyone done a comparison of combined speech to text and TTS vs speech-to-speech for create audio only interfaces? Particularly curious around latency, and quality of audio output. reply amrrs 22 hours agoparentHugging Face has got a TTS leaderboard (arena like lmsys) - https://huggingface.co/spaces/TTS-AGI/TTS-Arena reply yavorgiv 10 hours agoparentprevLatency from the announcement https://x.com/_mfelfel/status/1846025183993511965/photo/1 reply stuxyz 1 hour agorootparentalso here: https://x.com/play_ht/status/1846240712125452469 reply emursebrian 5 hours agoprevI didn't check to see if Thai was supported, but it hangs when I try to perform TTS on the text \"ฉันพูดภาษาไทย\" and then comes back with an error message several minutes later. reply nature556 6 hours agoprevI think it's important to have high quality TTS on arbitrary web articles. reply reply wkat4242 4 hours agoprevI have to say even something really low-resource like Piper (pure CPU) sounds amazing these days. TTS really appears to be a solved problem now. reply BoppreH 20 hours agoprevIn the video demo, Play 3.0 mini (on the left) incorrectly claims that the other AI missed a word. How does that end up in an announcement? Do people not notice, or not care? Or are they trying to show realistic mistakes? reply wavemode 15 hours agoparentMaybe its prompt was \"gaslight the person you're talking to into thinking they made a mistake.\" In which case it did an impressive job! reply stuxyz 1 hour agorootparentlol reply lyjackal 21 hours agoprevIs there any way to use the TTS on its own? I maintain an obsidian TTS plug-in, and am starting to add new TTS providers (its just been OpenAI thus far). From the documentation at https://docs.play.ai/documentation/get-started/introduction, it looks like their API seems to couple it to an LLM for building conversational agents. Seems like it might be nice to use standalone as just TTS. reply amrrs 20 hours agoparentYou can use Play HT (the TTS powering Play AI) on its own - https://docs.play.ht/reference/api-getting-started Do you have link to your obsidian TTS plugin? reply antman 10 hours agoprevDoes anyone know of a TTS mod that could convey feeling? E.g. ebook reading for novels? Or can one request feeling in any of the models of this discussion? reply bkitano19 3 hours agoparenthume.ai specializes in expressive prosody for TTS (disclaimer - I work here) reply codeful 10 hours agoparentprevAzure speech services? reply phkahler 22 hours agoprevSounds quite good, but this prompt is NOT what I'd expect an automated system to feed into it: “I’ve successfully processed your order and I’d like to confirm your product ID. It is A as in Alpha, 1, 2, 3, B as in Bravo, 5, 6, 7, Z as in Zulu, 8, 9, 0, X as in X-ray.“ Phone numbers and others were read nicely, but apparently a string of alphanumerics for an order number aren't handled well yet. reply amrrs 22 hours agoparentSorry, Do you mean to the audio for this text is not good? “I’ve successfully processed your order and I’d like to confirm your product ID. It is A as in Alpha, 1, 2, 3, B as in Bravo, 5, 6, 7, Z as in Zulu, 8, 9, 0, X as in X-ray.“ I thought this was included in the demo, it seemed okay! reply phkahler 6 hours agorootparent>> Sorry, Do you mean to the audio for this text is not good? No, the audio was OK or even good. The example seems to be an automated response from some system where a human has just placed an order. The order number is A123B567Z890X but if we want our system to \"read back\" the order number we apparently have to specially format the text. I suppose for the clarifying stuff \"Alpha Bravo\" that's a good idea, but separating digits and all those commas? reply mrkstu 19 hours agorootparentprev'Alpha' is kind of swallowed and Bravo is mispronounced. reply diggan 21 hours agoparentprev> Phone numbers and others were read nicely The phone numbers were not naturally read at all. A human would have read a grouping of 123-456-789 like \"123\", \"456\", \"789\", but instead the model generated something like \"123\", \"45\", \"6789\". Listen to the RVSP example again and you'll know what I mean. The pacing is generally off for normal text too, but extra noticeable for the numbers. My hunch would be that it's because of tokenization, but I wouldn't be able to say that's the issue for sure. Sounds like it though :) reply bryananderson 23 minutes agorootparentIn this case it’s not tokenization. I wrote the text preprocessing code that deals with spacing these numbers. This is good feedback. It’s optimized for US-style 10-digit phone numbers, and it should be more flexible than that. For example, if I was reading a US phone number such as (123) 456-7890 over the phone and wanted to make sure it was heard correctly, I’d say “123”, “456”, “78”, “90”. But a 9-digit phone number should be spaced as you said. reply BoorishBears 22 hours agoparentprevMost of these prompts come from LLMs, so it's trivial to instruct them to provide a string that's broken out like that. Also not the end of the world to process stuff like this with a regex. Most of these newer TTS models require this type of formatting to reliably state long strings of numbers and IDs reply Asjad 23 hours agoprevPlay 3.0 mini sounds like a game-changer for real-time multilingual TTS with its speed and voice cloning capabilities reply dulldata 22 hours agoprevdemo video if you don't want to go through the announcement - https://www.youtube.com/watch?v=DusTj5NLC9w Good with numbers mostly! reply causal 4 hours agoprevAlways a little disappointing when someone announces they're releasing a model when they mean they're releasing an API reply Aeolun 20 hours agoprevThat’s 12 times cheaper than the OpenAI models though. Those are already very good, so I can’t really see myself using this. I really want a good on-device model though. reply throwaway48476 15 hours agoprevI would love a browser extension that does high quality TTS on arbitrary web articles. reply jasonjmcghee 4 hours agoparentThere's \"Reader\" by Eleven Labs. Now with iphone mirroring, you can use it without much trouble from your laptop too reply ks2048 14 hours agoprevAny good TTS (open or not) allow finetuning for a new language? reply treesciencebot 23 hours agoprevMuch faster than OpenAI's real-time mode, wow! Quality seems to be on par if not better as well. reply samsepi0l121 22 hours agoparentDid we watch the same video? OpenAI's model is faster, and the quality is far better. reply steego 16 hours agorootparentForget the video. Try it. I use OpenAI's voice models a lot and I have access to them all and I'm honestly more impressed with the ease at which one can conduct a conversation with this voice model. Honestly, this feels like the first voice model I would pilot as a customer service rep in a hospitality setting. reply KaoruAoiShiho 20 hours agoprevIs this better than 11labs? reply yavorgiv 10 hours agoparentIt depends on the use case. If you are looking for a stable model with great voices and very low latency, Play 3.0 mini is as good as or better than 11labs. https://x.com/_mfelfel/status/1846025183993511965/photo/1 reply scotty79 10 hours agoparentprevIf you go by hugging face leaderboards then no. https://huggingface.co/spaces/TTS-AGI/TTS-Arena reply sigmar 6 hours agorootparentI don't see \"playht 3.0 mini\" on there, only play.ht 2.0 (released in august of 2023) reply lynx23 8 hours agoprevFirst question, does it pronounce numbers > 9 correctly? At least OpenAI's model doesn't perform at all, marking garbage out of almost every number it finds. I actually dont remember if I checked with EleventLabs... But I was shocked enough that in 2024, someone could release a TTS model that doesn't do numbers correctly. As if the AI industry was approaching Xerox level of failings. However, the TTS models are way worse then the Xerox compression algo ever was. I believe verifying numbers up to at least 100000 should be a requirement for new TTS models. reply siscia 20 hours agoprevI honestly wanted to try to use it, but their pricing was quite off-putting. reply c0brac0bra 20 hours agoparentYes. I think $0.05/min is a high multiple of what other agent-oriented realtime TTS products are charging. reply lostmsu 22 hours agoprevIs this one open in any way? If no, why would anyone use it over OpenAI? reply CommanderData 20 hours agoprevIs there a way to train this on common AI voices from video games/movies, I'd very much like a voice assistant to sound like Father/Mother from Alien or Dead Space. reply gorkemyurt 22 hours agoprevwow! latency is insane reply c0brac0bra 20 hours agoparentThis is similar: https://deepgram.com/agent reply codetrotter 22 hours agoprevHey Alexa, Google “Play”! reply Zababa 10 hours agoprev [–] What's the state of the art for voice cloning in another language (here French)? reply yavorgiv 10 hours agoparent [–] It should do pretty good. You can try it here https://play.ht/playground/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Play 3.0 mini is a newly introduced multilingual text-to-speech model supporting over 30 languages, offering improved reliability and audio quality.",
      "It is designed to be the fastest and most conversational model, supporting text-in and audio-out streaming via API (Application Programming Interface) or SDKs (Software Development Kits).",
      "The model is more efficient and cost-effective, with reduced pricing for higher volume usage, making it appealing for businesses and developers."
    ],
    "commentSummary": [
      "Play 3.0 mini is a new multilingual Text-to-Speech (TTS) model praised for its speed, reliability, and cost-efficiency, with strong voice cloning capabilities.",
      "It operates on less than 3 GB of Video RAM (VRAM) and is optimized for Chrome, though users have reported compatibility issues with Firefox.",
      "The model is not open-source, prompting discussions about its use compared to alternatives like OpenAI, especially given its ongoing optimization for real-time applications."
    ],
    "points": 232,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1728933377
  },
  {
    "id": 41842060,
    "title": "Tesla Optimus Bots Were Remotely Operated at Cybercab Event",
    "originLink": "https://www.bloomberg.com/news/articles/2024-10-14/tesla-s-optimus-robots-were-remotely-operated-at-cybercab-event",
    "originBody": "Bloomberg Need help? Contact us We've detected unusual activity from your computer network To continue, please click the box below to let us know you're not a robot. Why did this happen? Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy. Need Help? For inquiries related to this message please contact our support team and provide the reference ID below. Block reference ID: f96e4056-8b27-11ef-900e-7aa49e17ed97",
    "commentLink": "https://news.ycombinator.com/item?id=41842060",
    "commentBody": "[dupe] Tesla Optimus Bots Were Remotely Operated at Cybercab Event (bloomberg.com)213 points by mfiguiere 21 hours agohidepastfavorite206 comments Animats 16 hours agoThat was obvious to anyone with any experience with real-world robots. Nice piece of machinery, though. Boston Dynamics' humanoids were clunky electrohydraulic mechanisms borrowed from their horse-type robots. All-electric is now possible and much simpler. Schatft was the first to get this working, and they had to liquid-cool the motors. Don't know if Tesla has to liquid cool. They do that in the cars, so they certainly understand liquid-cooled electric motors. I suspect that body balance and possibly walking were automated. It's hard to balance a teleoperated robot manually, and robotic biped balancing has been working for years now. reply dawnerd 14 hours agoparentBut the problem is the majority of people buying and hyping TSLA are not working or have close experience with robotics to see what’s real vs human controlled. That’s intentionally deceptive. reply cdchn 11 hours agoparentprevEver the speech was just a guy trying to pretend he was a robot. reply xeromal 16 hours agoparentprevThey moved so smoothly, I was impressed reply robomartin 14 hours agoparentprev> That was obvious to anyone with any experience with real-world robots. Yup. Exactly. The term for this is \"Telechir\": https://link.springer.com/chapter/10.1007/978-3-642-93104-8_... My kids have been around lots of robots of all kinds. The very first comment they made while watching the event was: \"The robots are being remotely operated. There's no way that's autonomous.\" Nice looking machines. Far from being practical outside of a highly controlled environment. This does feel like progress though. reply rlt 16 hours agoparentprevI heard the initial walk out was fully automated. reply beezlewax 14 hours agorootparentWhere did you hear that? reply tim333 6 hours agorootparentWhile I didn't hear anything, I think the walk control would have to be local circuitry. I can't see how a remote operator could sense balance and do all the leg movements. You can see a Tesla upper body controller here. Not sure if it's what they used for the event, but probably something like that. https://x.com/TroyTeslike/status/1845047695284613344 reply matco11 14 hours agoparentprevI agree. Also, especially in the extremely crowded and noisy context - what would have been the chances to have the demo working so well? In fact, even if the robots worked very well autonomously, you would still have wanted a way to ensure that the demo is successful - the same way Steve Jobs did with the iPhone demo, Larry Ellison did with the Oracle servers demo, etc. So many stories like that in the history of famous product launches. The one thing that bothers me a little is that if you look at the robots dancing, they are only moving the upper body; their feet are always on the ground. I would have liked to see them having enough ability to dance and move the legs too… then, again, maybe the gazebo they were in was just too space-constrained, or it was just too risky to do that in the demo - given the crowd, and all the chaotic party context. When you set up a demo, you have to account for the edge cases where your product glitches, not just for what it mostly does very well. Anyhow, these are all AI issues (as opposed to mechanical ones), and, at the pace AI is evolving, it is not hard to see how these types of issues get ironed out over the time horizon leading to the launch. The Optimus demo did do a great job at actually making people see a world in which robots just roam around and interact with humans everywhere. . reply robomartin 13 hours agorootparent> these are all AI issues (as opposed to mechanical ones) Actuation is still a massive problem in humanoid robotics. We have over 650 muscles. A humanoid today can't even approximate that. Sure, a robot might not need that many actuators to be extremely useful. However, to be general enough to be able to interact with any human environment, the number of required actuators will not be trivial. Add to that gearing, couplings, driver electronics, encoders, thermal management, calibration, noise, maintenance and other per-actuator requirements and the picture quickly becomes overwhelming. This is an area that is still looking for a significant breakthrough. reply Animats 13 hours agorootparentThe big breakthroughs have already happened. - Small, powerful 3-phase servomotors are cheap and easy to obtain. Mass production of drone motors has advanced small motor technology considerably. Tiny motors use to be either toy-grade junk or expensive Swiss precision. That's improved. - Motors with built-in encoders are, at last, available. Encoders used to be fragile plastic boxes stuck on the end of the motor. Also, thermal sensing inside the motor is common, so you can tell if you're overheating it. - Permanent magnets are small and powerful, and have such high coercitivity that you don't have to worry about demagnetizing them if you over-drive the motor. The main limit on motor power is cooling. You can way overdrive a motor momentarily, like muscles. - Motor controllers are now small and cheap, They cost about $1000 per motor two decades ago. The power semiconductors are small. Controllers can be programmed to use very high power levels briefly, monitoring thermal sensors. It would be nice to have good linear actuators. Linear motors do exist, but never really became a big thing. reply ebalit 10 hours agorootparentI'm totally with you on the evolution of motor tech because of drone and also personal mobility (scooters and hoverboard motors are a steal for what they can handle). While high torque motors got way cheaper, especially with MIT Cheetah \"clones\" getting easily available, they're still at least 200-500 a pop (depending on the torque needed for each articulation) from what I could find. I might not know where to search for the real gems though. Where do you search for cheap powerful servomotors? reply tim333 6 hours agorootparentprevIt's impressive how well the hardware seems to work now, though the software is still clunky. You can see how well the hardware works under human nervous control in the recent MIT bionic foot https://youtu.be/1tD7qd68i3o?t=36 (from https://spectrum.ieee.org/prosthetic-leg) reply imtringued 13 hours agorootparentprevWe need better electroactive polymers. reply TeeWEE 16 hours agoprevThis results in me trusting Tesla less. If this was fake, how do we know the robovans were not remotely operated? They might as well be too to get the stock price up? There is no way to know. I am really doubting Tesla now. It wouldn’t surprise me that, in order to prevent mishaps during the event, everything is remotely operated… People will say: that’s not true. But where did Tesla clearly specify this upfront? I saw the initial fullscreen disclaimer. But that might also apply to the robovans right? reply godelski 14 hours agoparent> how do we know the robovans were not remotely operated? How do you even know they were anything? It is fairly easy to mock up a concept vehicle (I mean it is still a lot of work, but nowhere near what it takes to build an actual one). You can build the shell and interior and put it on any chassis you want. And let's be real, that robovan couldn't survive a pothole. If you watch the video of people walking out it does not look like the clearance is meaningfully different than their shoes. It is also suspicious that it doesn't seem to rise much after all the people get off. I don't have good angles from that video, so just a flag but not enough to conclude without more evidence (but this is exactly what you'd see if they built it like you do a parade float). For the robots, I thought it was obvious they were teleoperated. Just the way they talked with people was far too natural. Don't get me wrong, Tesla and SpaceX have done some great things. But how many times can you c̶r̶y̶ ̶w̶o̶l̶f̶ promise self-driving vehicles next year before people stop trusting you all together? I get you gotta hype (but do we? and how much?) but you gotta fulfill those promises. In 2015 he promised FSD in 2017, in 2016 he saidHe also hired an investigator to try and find any dirt on the rescue worker. Now he says this is just his way of having fun. Let me translate it for Musk fans. He repeatedly tried to ruin a life of a hero, because he felt insulted. Its also fun. reply ActionHank 4 hours agorootparentprevThere are literally dozens of examples, but not a single one will dissuade you from your pearl clutching behaviour when your bff billionaire needs defending. reply mike_hearn 10 hours agorootparentprevI've also read the biography. It's clear that he's stable and trustworthy enough to run multiple large companies, assemble a loyal force of allies who follow him around to his different ventures, a force that includes multiple family members, and win long term government contracts. The conclusion Isaacson himself reached is that Musk has an extraordinary need for intensity and challenge, to the extent that he becomes uncomfortable and unhappy if there isn't something big riding right on the edge of going spectacularly wrong. This is a trait that most people don't have, and it's ideal for doing the kinds of things he does. But don't mistake that need for intensity for being unstable or dishonest. reply consteval 1 minute agorootparentAu Contraire, don't mistake drive and ambition for being a good person. It's not uncommon for highly successful people to be awful. Typically, you need to be bone headed, rude, highly opinionated. Often you need to lie and steal. Just because Musk has financial success does not mean he isn't awful. In fact, financial success is probably one of the worst indicators of being a person of high integrity. reply baxtr 14 hours agorootparentprevInteresting. How did you come to this conclusion? Any specific thing or rather the overall impression after reading the book? reply tim333 6 hours agoparentprevMusk did say the vehicles were fully autonomous. He didn't say that for the robots. I kind of expected them not to have human like robot AI or driving yet but the robo taxi surprised me by not seeming very practical. Would you want to be in an machine learning controlled vehicle where the doors rise up and probably can't be opened without computer assistance? Driven by software known for crashing into fire trucks and the like? At least Waymos have proper doors and backup lidar/radar to stop them hitting things. reply dawnerd 14 hours agoparentprevThey still haven’t shipped the new roadster despite taking a pretty huge investment from customers for it. reply jojobas 15 hours agoparentprevYou can't be serious. Musk is under investigation for manipulating stock prices back years ago. Anything shown on these events must be assumed fake until proven otherwise. reply tim333 6 hours agorootparentFor 420 joking around on Twitter. reply baxtr 14 hours agoparentprevEver heard of \"fake it till you make it\"? reply me_me_me 4 hours agoparentprevless? The full self driving was one year away for 15 years now. Batteryswap charging, beating fuel pump station demo - clearly fake. Tesla Truck beating rail - few trucks made to carry potato chips/crisps ie 99% air. Solar roof tiles. Optimus being used in Tesla factories. The bus had an inch of clearance. What kind of road that prototype was designed for. Besides the wheels had tires painted over gold to look better. Lookup the pictures. Do you even remember tesla roadster? Its coming out next year, trust me bro. Cybertruck... more like clusterfuck. Offroad truck brickable by a carwash. How do people have trust in any claims by Musk? reply skeledrew 14 hours agoparentprevNo need for doubt. There's no reason to remotely operate the van since it's a vehicle like the car, and it is already known that they have mostly functional FSD from the many owners driving Tesla cars these past years. reply IntelMiner 14 hours agorootparent>mostly functional FSD from the many owners driving Tesla cars these past years Given the staggering amount of mishaps that have been showcased, I would dispute this reply tim333 6 hours agorootparentAlso they still have drivers in the Las Vegas tunnels I think which is something crying out for automation. reply consteval 0 minutes agorootparentThe Las Vegas tunnels are crying out to be destroyed and replaced with something less stupid. slimebot80 18 hours agoprevIt's all about controlling money that might go to more honest ventures. Yes, humanity has engineers who are going to the moon, creating robots, investigating brain interfaces, improving public transport with buses and tunnels. And there will always be monorail salesmen who try to soak up those investments, taking away from others. reply throaway920181 15 hours agoparent> And there will always be monorail salesmen who try to soak up those investments, taking away from others. And Boring Company salesmen... reply KingOfCoders 15 hours agoparentprevIt's all about creating a high stock price, then take out a loan on the stock, and have a nice life. reply mmooss 15 hours agorootparentMusk needs a high stock price and a loan? reply KingOfCoders 6 hours agorootparentYes that is usually the way things go for rich people. They have an asset and take out a loan against the asset (e.g. stocks). Say $10M. This does not count as income. Then they spend the money on what they want and refinance the loan with another loan, say $20M on their grown assets. Then you spend more money, again with no income, so no taxes. When the asset goes up, you refinance. When the assets crash, banks can have the assets. Again, you've spent the money without income. One of the many tax \"avoidance\" schemes (this one is for income, others are for inheritance tax or VAT avoidance) of very rich people (those with no real income, not professionals with very high income). You can read about it e.g. in the leftwing-marxist-propaganda Forbes Magazin: https://www.forbes.com/sites/johnhyatt/2021/11/11/how-americ... When you die, you never pay back the money, the strategy is called \"Buy, Borrow, Die\" for a reason: https://smartasset.com/investing/buy-borrow-die-how-the-rich... reply mmooss 2 hours agorootparentWhy would banks participate? Do they profit? reply tacticus 14 hours agorootparentprevyes. to cover the other loans he has. reply slg 17 hours agoprevHow is stuff like this not considered fraud? This seems much worse to me than Musk's usual Tesla lies in which he is predicting some future capability. At least there is an argument that Musk believed it those at the time he said them or that they were optimistically possible despite being impractical. This seems to be material misrepresentation of the viability of one of the company's core R&D projects that Musk claims \"will be the biggest product ever\". reply jsight 17 hours agoparentQuite a few people at the event asked employees about this and were directly given the answer. It wasn't a secret. reply slg 17 hours agorootparentWere you at the event or do you have a source for that claim? I have seen video of one of the bots refusing to give an answer to that question and there were multiple articles in the wake of the event that couldn't come to any definitive conclusion so I'm skeptical of this claim of immediate transparency. reply silisili 16 hours agorootparentIs this the video you saw (posting below, for you and anyone who hasn't seen it). While ignoring the question the first time, he did confirm that they were being assisted by a human. Perhaps not as clear as 'remotely operated', but that's about how I took the answer. YMMV. https://x.com/zhen9436/status/1844773471240294651 reply slg 16 hours agorootparentNo, the one I saw ducked the question multiple times so that video is more informative even if \"assisted by a human\" is still somewhat vague. I guess they just left what to disclose up to the individual operator making the level of deception dependent on who you happened to ask. Such a bizarre way to handle an event like this, but I guess that type of haphazard approach should be unsurprising for a Musk run company at this point. reply me_me_me 4 hours agorootparentprevEveryone working for Elisabeth Holmes knew it was all fake is not an excuse that worked for her reply standardUser 15 hours agorootparentprevThe fact that the fraud was lazy and blatant makes it worse, not better. reply jkestner 14 hours agorootparentLess lazy than a dancer in a skin tight robot suit. Progress! reply sys64739 16 hours agoparentprevNikola (Trevor Milton) was busted for fraud for insinuating that trucks rolling down slopes were working models. reply schmidtleonard 15 hours agorootparent> insinuating Didn't he say \"this is not a pusher?\" reply jojobas 15 hours agorootparentprevTesla (Elon Musk) is under investigation for fraud for insinuating robotaxies are just around the corner, and you should buy the already available hardware for 100k that'll yield you 30k/year in the near future. When it became public knowledge, more value was written off Tesla stock than Enron, Theranos and Nikola combined. reply Palmik 14 hours agoparentprevDid you know that many demos on events like Google IO are scripted or hardcoded? I'm saying that not to advocate for such practices, but rather to provide context. For what it's worth, it was quite clear to many that the robots are teleoperated and it still serves as a demonstration of the hardware. reply jcranmer 15 hours agoparentprevFraud is a material misstatement of fact to induce someone to do something. It's really not clear that there's any actual inducement here; this isn't exactly the centerpoint of a pitch video to investors. (As it turns out, Tesla's stock went down like 9% the next day after the event, with most of the analysts' reactions to the announcement essentially being \"okay, so he doesn't really have anything that he wasn't already pitching\"). reply tim333 5 hours agoparentprevMusk's speech: >So now one of the things we wanted to show tonight was uh that Optimus is not a canned video. It's not walled off. The Optimus robots will walk among you. Please please be nice to the Optimus robots. So you'll be able to walk right up to them and um they'll serve drinks at the bar and uh you'll directly - I mean that's it's it's a wild experience just to have humanoid robots and it's they're there they just in front of you. Uh so yeah with that um let's party. https://www.youtube.com/watch?v=6v6dbxPlsXs&t=1355s So he didn't actually say autonomous. I think you'd have a job proving fraud there. reply jccooper 4 hours agorootparentElon's a master at saying things that people read as something more than he actually said. I knew without seeing it that there's 0 chance that he (or anyone) actually said they're autonomous. But also that he didn't say they're not. reply paul7986 16 hours agoparentprevDidn't OpenAI demo facetime with a H.E.R. like chatbot/AI friend in April? Where is that.. it's not available to anyone I know and was that actual real tech running or just faked demos? The tech playbook is hype even if it's not real and or really exists ... hype it up .. make them pay for the promise of something they think exists but it doesnt. Similar thing here Musk following the technology/startup playbook ... hype hype hype make people think it's real .. boost stocks as Open AI boosted it's subscription revenue Im sure in April of a promise of something that may or may not exist. reply WatchDog 16 hours agorootparentThe safety people got a hold of it, but they did end up releasing it, although it refuses to do a lot of simple stuff you ask it to. reply ActionHank 15 hours agorootparent“The safety people” are gone. OpenAI is just very comfortable lying right around the time google is doing a big public announcement. Where is Sora? Everyone and their dog has video gen out now, Sora is conspicuously absent. reply paul7986 16 hours agorootparentprevI subscribed twice and felt screwed not going to subscribe again until i see a live in person demo and or a trusted tech news source saying its available to all with a video showing them using it. Is there a recent such tech news report saying and showing such? Be good to see it! I did startups and played this hype and create fake content/news to boost metrics and saw results. And yet i signed up twice lol reply SmooL 16 hours agorootparentprevThat OpenAI demo is available right now to subscribers; I have access to it reply quantified 21 hours agoprevSurprising absolutely no one, I hope. Credibility seems difficult to generate for Tesla events. Maybe the secret sauce for Robotaxis is a human driver somewhere watching the cameras. Like driving Uber but from the comfort of home, and it's easy to hit the fridge or bathroom between rides. reply hi-v-rocknroll 18 hours agoparentReminds me of a plot of device of the 90's movie Shooting Fish where they were scamming businesses selling an AGI computer but were actually controlling responses with a human in another room. reply tru3_power 17 hours agorootparentAlso reminds me of amazons cashierless grocery stores reply yjftsjthsd-h 18 hours agorootparentprevI mean, that's a classic for literally centuries: https://en.wikipedia.org/wiki/Mechanical_Turk reply bdjsiqoocwk 19 hours agoparentprevIt's AI - Actually an Indian reply rekttrader 19 hours agorootparentAs I I see the delivery robot do it’s job... a game being played by remote workers doing the Enders game. reply Terr_ 18 hours agorootparentThe terrifying secret of all those European truck simulator games. reply ackbar03 17 hours agorootparentNow I am going to be forever haunted by all those trucks I destroyed reply stevenwoo 18 hours agorootparentprevYou may already know this but Heinlein wrote about waldos pretty early, incorporating it into several stories and books. reply nnurmanov 15 hours agoparentprevHopefully, they will check for overemployment before allowing them to remotely control, otherwise we end up with one operator controlling several cars. I don’t know if it is good or bad reply wokwokwok 18 hours agoparentprevI mean, shoot me down here, but is it that bad of an idea? If you're going to have an assistant or a taxi driver, and you start off at the base position of \"AI is totally unreliable\", then having a fully remote gig-worker remotely piloting your robot... I mean, it doesn't seem like a massive stretch from what Uber does. ...and heck, having a 'remote robot body' is pretty cool tech. I guess. As long as you don't use it to pretend its just AI for the meaningless purposes of generating hype about your AI that really isn't actually any good. reply darth_avocado 18 hours agorootparent> Is it that bad of an idea? Driving at 60mph with shaky internet connection? Absolutely. Piloting a robot to fold laundry? Maybe not. Allowing random people to pilot robots in your house with children around? Absolutely horrific. reply xyzzy123 17 hours agorootparentIt seems like there's considerable demand for human labour \"below the API\" that you don't have to talk to. It's kind of sad but people seem to get comfortable with it very quickly. reply nnurmanov 15 hours agorootparentprevThere are FPV drones, although I am not sure about their precision reply kortilla 17 hours agorootparentprev> Allowing random people to pilot robots in your house with children around? Absolutely horrific. Your risk analysis on this is completely wrong. If there is some vetting here this is fine. No different than a babysitter or a handyman off the Internet reply darth_avocado 15 hours agorootparentMy “vetted” Doordash/Ubereats drivers sometimes end up eating part of my meals. reply defrost 17 hours agorootparentprevYou're saying then that tools exist to scan and ping all babysiters and handymen across the globe, fingerprint them for version, lookup zero-days, apply them to matching staff, exploit that to monitor children remotely, and take control over home assistants function to shepard children out the door to a \"party van\" ? That's the ecosystem that surrounds most actual IoT devices - I can't see home robots being any different. reply nneonneo 17 hours agorootparentThe Pied Piper, in robot form. reply jazzyjackson 16 hours agorootparentprevWho gets a babysitter off the Internet? reply oblio 16 hours agorootparentApparently at least everyone who keeps this website going, at least: https://www.babysits.org/ reply FactKnower69 18 hours agorootparentprev>but is it that bad of an idea? yes, operating any kind of heavy machinery over a shaky wireless WAN with hundreds of milliseconds of latency and multiple percentage packet loss is, in fact, a bad idea reply foobiekr 17 hours agorootparentprevThe problem is it was presented in the most manipulative and deceptive way possible. reply mandevil 20 hours agoparentprevI mean, you definitely need people available to intervene even for a L4 or L5 autonomy, because they will get stuck (Tesla is not serious about robotaxis until they start staffing up a team to do that on a full-time basis). But actual driving? This link is way too high latency for that to be safe. The robot needs to be maintaining its own SA, and just calling the human when it doesn't know what to do. reply stackghost 18 hours agorootparentIt's amazing to me just how far people will move the goalposts for Elon's perpetual grift. We've gone from \"you'll be able to nap on your morning commute in your self driving car within 18 months\" to \"they will always need a human to intervene\". Incredible reply mandevil 17 hours agorootparentErrr, I am saying that Elon's claims are obviously BS until we start to see Tesla doing something like what Waymo has had for years(1): a team of people ready to intervene and fix things that are outside the training set of the ML. I happen to know a senior person at a autonomous delivery robot company, which employs a team of people for just this purpose, because even delivering pizzas around a college town in a small little robot needs this. For things like (actual example for them) a sofa that was being thrown away and was just left on the sidewalk, and so a human needed to confirm that it was safe to move around it. And so far as I'm aware, Tesla isn't doing this, which is why I think that their autonomous taxi idea is nonsense. 1: Personal experience from being driven in a Waymo, I hit the assist button when we got stuck by some double parked cars in a parking lot. By the time someone answered the car had already extricated itself, but it didn't start that until after I hit the button. reply pclmulqdq 17 hours agorootparentprevElon Musk has displayed incredible prowess at manipulating modern internet media. He launched \"tesla shorts\" right when a few big short sellers announced their positions (I believe one of them also put out a report about TSLA being insolvent aside from income from pre-orders, and was proven correct by Musk years later) and SEO-ed them into the ground. I would assume that several of the pro-elon accounts on most social media are actually either bots or shills. You don't need many shills to get real people interested. reply dullcrisp 18 hours agorootparentprevI don’t think the person you’re replying to said anything about Elon Musk in this case reply stackghost 18 hours agorootparentNot directly, but he and Tesla are unfortunately inextricably linked. reply whoIsYou 16 hours agoparentprevor you even have a single driver in charge of 20 vehicles, waiting for one of them to encounter a situation the system can't handle automatically reply consumer451 17 hours agoprevWhat does everyone think about 1X's NEO? [0] They began from the idea of compliant robotics,[1] which seems to me to be a requirement for safe operation in proximity to humans. Did Tesla make attendees sign a hefty liability waiver, since Optimus is not a compliant robot, or did they address the inherent problems some other way? [0] https://www.youtube.com/watch?v=bUrLuUxv9gE (also remote controlled for now, while being trained) [0] https://www.youtube.com/watch?v=Sb6LMPXRdVc [1] https://en.wikipedia.org/wiki/Soft_robotics reply modeless 17 hours agoparentEach robot had several human escorts, and the robots were limited to slow walking and a few slow hand gestures. The only danger would be if one fell over. 1x NEO looks awesome and far more advanced than this version of Optimus. I'm bullish on 1x. Tesla has a manufacturing advantage though. There were 50 units of Optimus at the event and I expect that there are only a few fully working units of NEO made so far. Also, Optimus has been improving quickly. It's possible Tesla could catch up in a few generations. reply beeflet 16 hours agorootparent>Each robot had several human escorts, and the robots were limited to slow walking and a few slow hand gestures. More importantly, the robots were limited to doing no real work. They just feebly pick up objects and place them somewhere else, which I am pretty sure doesn't require AI. For example, the vid shows the robot pouring hot water into a glass with a massive funnel strapped to it. Why not have the robot fill the kettle, place the teabag itself, etc? It seems like the kind of thing that should be developed before walking and talking and telling jokes. What if the refrigerator, microwave, etc. could interface directly with the robot. For example, the refrigerator has some type of robotized shelf that is able to bring a rack of orange juice to the front before the robot comes over to grab it? What if the microwave is able to focus the microwave beam on the food to cook it evenly? It also irks me how the robots are just humanoids. Like for example, why have a head with two eyes. Does it need to wear a helmet? Does it need exactly 2 eyes at exactly human-like placement to achieve stereopsis? Why not have 3 eyes? Did the designers think about the form of the machine at all, or did they just produce robots in the form that is associated with the most hype and thus will bring in the most investor capital? Is this really the ideal form for interfacing with humans? With other robots? I am just very skeptical of these companies that want to go from zero to doing everything. By the time they accomplish a robot that can do \"everything\", who is to say that they will even be able to privatize it? The \"everything robot\" might just be built out of general-purpose components and software at that point. Why not just make a machine that does a limited set of tasks well and then build from there? Sorry https://blog.comma.ai/a-100x-investment-part-2/ has me coping and seething at the AI space reply FactKnower69 12 hours agorootparent>It also irks me how the robots are just humanoids. Like for example, why have a head with two eyes. the risk-averse, cowardly, snivelling product design is really one of the most odious things about the whole Tesla shitshow. they had the opportunity to completely redesign the automobile from scratch, but chose to meekly clone the exact same bog standard sedan design everyone else converged on 50 years ago, clinging to some form response about safety despite the front of a Tesla crumpling like paper in any collision anyway reply piva00 10 hours agorootparentThough they can't move away too much from the teardrop design, it's one of the most aerodynamic shapes (and why so many production cars look like a decorated teardrop). Still agree they could have been bolder with other parts of the silhouette, it's unimaginative \"futurism\" coupled with some strange need to be branded Apple-esque. reply imtringued 13 hours agorootparentprevAs a fan of humanoid robots, humanoid robots only serve the human desire to experience another being in their likeness. Boston dynamics went back to building arms on wheels. reply consumer451 17 hours agorootparentprevRight now, 1X and Tesla use entirely different mechanical architectures, don't they? Do you think that Tesla will end up with compliant robots? reply modeless 17 hours agorootparentTesla is getting closer with tendon-based hands in the next generation of Optimus. Who knows where they will end up. reply beeflet 16 hours agorootparentElastic tendons seem like a pretty reasonable solution to this problem, but can it be applied to all the joints (like ball-socket, etc.) I wonder? I think the chassis of the robot should also have compliance, humans certainly do have squishy spines. I mean imagine you're on the street and you have to share sidewalk space with these things. Running into it would hurt. reply modeless 16 hours agorootparentThe tendons are as inelastic as possible. The compliance comes from direct drive motors with no gearing (or as minimal as possible). reply mplewis 17 hours agorootparentprevA few generations of what, pretending their robots work? reply modeless 17 hours agorootparentHonestly, I don't know why I bother continuing to engage here. HN community, is this the quality of discourse you want to encourage? reply newZWhoDis 15 hours agorootparentThe discussion you’re looking for is happening over on X. It’s long been dead here. reply ivewonyoung 16 hours agorootparentprevWe had people swearing up and down that the Cybertruck would never be released because it was stock fraud. They already seem to be at a run rate of $1.5 billion in revenue per quarter despite launching in a limited fashion because of manufacturing ramp up. reply beeflet 16 hours agorootparentI haven't really been tracking this, but aren't they selling at a price much greater than they originially announced? I would classify it as \"mixed success\" reply modeless 16 hours agorootparentThe base model isn't entering production until next year but is quoted by Car and Driver as starting at $62,985. The original price was supposed to be $39,900. However there has been >20% inflation since then, and the base model should be eligible for the full $7,500 tax credit applied as an instant rebate at purchase time, which was not available at the time of announcement. All that to say: the price actually paid will be $55,485, vs the inflation adjusted original base model price of $48,912 (possibly higher if there is more inflation before the release next year). So yes, the price you'd actually pay has gone up 13% in real terms over the announcement price. But I think the extra 4 years of delay (for the base model vs the announced availability date of 2021) is the bigger issue. But ultimately all that matters from Tesla's perspective is that they are selling. My understanding is that even the current top end expensive models are selling about as many units as all other electric trucks combined. reply Dylan16807 15 hours agorootparent> The original price was supposed to be $39,900. However there has been >20% inflation since then That price was announced with a significant lead time, so at least 5-6% inflation was built in already. > and the base model should be eligible for the full $7,500 tax credit applied as an instant rebate at purchase time, which was not available at the time of announcement. It wasn't available that exact moment, but it existed. > All that to say: the price actually paid will be $55,485, vs the inflation adjusted original base model price of $48,912 (possibly higher if there is more inflation before the release next year). So yes, the price you'd actually pay has gone up 13% in real terms over the announcement price. I'd put the inflation-adjusted price at $46k, and not use the $7500 to reduce the difference, making $63k a 36% increase. Or I'd apply the $7500 to both and get 44%. reply modeless 15 hours agorootparentThe $7500 existed only for other manufacturers. It had expired entirely for Tesla. No Tesla model was eligible for any more credits at that time and there was no particular reason to believe that Tesla would ever become eligible again in the future. Also, the credit back then did not directly reduce the price paid at purchase time the way it does today. I think it is fair to apply the credit when comparing to the announced price. Tesla certainly takes the credit into account when they set pricing and buyers account for it when purchasing. Also it was announced at the end of 2019 for 2021 and the inflation rate in 2019 was 1.8% so there's no way they accounted for 6% inflation. 4% at most. reply Dylan16807 15 hours agorootparentThe rebate had existed before, and the quota renewing at some point between announcement and release was not a crazy idea. If Tesla's jacking up the price because of that rebate, they get NO credit for it. 63k is what they are charging and what I will judge them on. And I don't think the exact moment it applies really matters. reply ivewonyoung 15 hours agorootparentprevWhether it'd be a true success remains to be seen, at least in terms of making a profit on total investment. My point was that it certainly wasn't vaporware, even if it didn't sell well. reply modeless 17 hours agoprevTesla was not trying to hide this. The robots were telling anyone who asked that humans were helping control them. Unlike the robotaxis, which were explicitly advertised as autonomous. reply foobiekr 17 hours agoparentThey didn’t say the extent of the control and the event was engineered to lead people to conclude human involvement was minor. reply pclmulqdq 17 hours agoparentprevSaying otherwise when directly asked would have been an open-and-shut case of securities fraud. They still didn't widely disclose this. reply oblio 16 hours agoparentprevAwesome, now show me where is the article coverage (which is generally paid PR) that states this upfront and clearly. reply gitaarik 16 hours agoparentprevSo these robots are not supposed to be autonomous? reply nomel 14 hours agorootparentThey’re prototype mechanisms that don’t have any sort of significant AI yet. Them having AI was never claimed. They’re shells, with (as shown) extremely fluid control systems, with the smarts to drive them still in development, all of it for a whopping three years now. reply bentt 16 hours agoprevIf I worked on Optimus I would be so angry about the decision to so this. Now nobody will trust the brand or the product. Stupid. reply paulryanrogers 15 hours agoparentAre Elon companies known for being trustworthy in marketing? If they ever were that should have ended when FSD was first 'delivered'. With a possible carve out for SpaceX? reply bentt 6 hours agorootparentThis feels different. It’s deception not overpromising or being late. It’s like if one day FSD drivers found out there was a human on the other end. I wouldn’t be shocked if there were now. reply dyauspitr 15 hours agoparentprevI don’t know. Despite being remotely controlled, their movements were smooth and human like. I mean it’s literal untethered bipedal robots walking around in the midst of a party. It’s already pretty incredible in my opinion and can only go up from here. reply jkestner 14 hours agorootparentAgreed. By next year they’ll be able to outsource the puppetry to a nearby developing country. reply bentt 6 hours agorootparentThis would be funny if it wasn’t likely. reply gnabgib 18 hours agoprevDiscussions (112 points, 1 day ago, 108 comments) https://news.ycombinator.com/item?id=41831009 (89 points, 2 days ago, 92 comments) https://news.ycombinator.com/item?id=41815567 reply drdaeman 19 hours agoprevhttps://archive.is/mds9I reply Blackthorn 18 hours agoprevArtificial artificial intelligence. reply comfysocks 13 hours agoprevIt seemed to me the goal of the event was to make people imagine a dazzling sci-fi future from a schoolboy’s imagination, and not notice that the demo didn’t show much proof of technical advancement in automated driving. reply schainks 13 hours agoprevAm I missing something or was the point for those robots to be human controlled? Tesla is trying to have disposable body parts that are remotely controlled so their workers get hurt less often due to RSI or other assembly line accidents. It’s not like they’ll fix their safety culture if the occasional robot destruction keeps volume up and injuries down. reply nomel 12 hours agoparentReference? Them being eventually autonomous has been covered in the events and his talks about the eventual AI that will drive them. reply schainks 11 hours agorootparentNo reference, this is my personal hypothesis. Tesla still needs to squeeze profit out of all this R&D. Eventually AI eventually could take over, sure. What I see today is they can have humans control the robots for tasks that can easily injure humans. reply nomel 4 minutes agorootparentI've never seen that stated as a goal, even an intermediate one. reply mike503 18 hours agoprevI was assuming that the robots at the Sphere also had some humans behind it if nothing more than to help \"guide\" the AI pieces. My assumption, at least. reply thatguymike 15 hours agoprevCome on, isn't this obvious? There's no way in crap they were fully autonomous, and I don't think anyone ever claimed that they were. In fact there's multiple examples of them saying \"I am remote operated\" when asked. And that doesn't in any way take away from the fact that it's damn cool that they went from \"guy in spandex suit\" to a walking, dextrous, low latency telepresence robot in a few years. I hate Musk's new politics (which is obviously what this is all about) but I feel bad for the engineers involved: I suspect everyone was stoked to show off their impressive progress, and a few marketing people decided to under-emphasize the telepresence and made them all look like jerks. reply pcchristie 14 hours agoparentI might be an idiot but it wasn't obvious to me. Watching the demo of the robot standing stationary, responding to a customer ask for (and point to) cellophane bags of chocolate and then the robot grab and pass it to the customer seemed like a reasonable tech demo to show at an event like this and it impressed me. reply thatguymike 13 hours agorootparentYeah but they had the robots hi-fiving, pouring drinks on demand, chatting, playing rock paper scissors... fair enough you could get that idea if you only watched a very small amount of video, but that doesn't equate to Elon Musk hiding things from you. reply beambot 18 hours agoprevReminiscent of Nikola's semi truck demonstration... reply sidibe 16 hours agoparentOr Teslas \"battery swap\" event which actually helped them earn them a huge amount of subsidies from the government. Watching after understanding Elons m.o. it is clearly fake or how else would they have a planned demo on stage with cameras that aren't positioned to show anything that's going on and then that tech they developed was never heard from again. They just distracted the crowd with a video of someone filling up at a gas station reply iknowstuff 11 hours agorootparentthey did have a swapping station in CA they built to get the subsidy. it wasnt fake, just pointless reply ethagknight 20 hours agoprevTo be honest, the autonomous control of the robot seems like the easier part of the equation. (doing it safely in a room with guests, unguided... thats another matter). The physical limitations and packaging are a big challenge, and I dont think I saw Optimus lift anything remotely heavy.. just pull a beer tap.. a decision that probably speaks volumes about current limits of the technology. To apply my first point to reality: put an Optimus in its current state/capability, on a commercial 0-turn lawn mower, plug Optimus into the mower's power takeoff, and have someone in another country remotely pilot the mower. That right there is worth every commercial lawn service having at least one on their crew TODAY. The appeal of hot swapping an operator real time on the equipment you already own, whether it's a push lawn mower or a huge mining truck, provides enormous value right out of the gate. Especially in tasks where the Optimus can handle 90% of the task autonomously but needs to step aside or oversight for the last 10% of the job. Compare to a business model that requires purchase of all new very expensive and unique equipment. reply jvanderbot 19 hours agoparentI've worked in robotics for over 10 years, at state of the art labs and high quality startups. There are really only two hard problems in robotics: Perception and Funding. Perception, especially around a bunch of people, with depth, mapping, understanding traffic and gestures, all in real time etc etc will be a huge problem for these machines for a while. Funding though? I doubt that's an issue right now. reply robotresearcher 17 hours agorootparentI'm also a roboticist. Perception and funding are hard. But don't forget battery energy density, and the power-to-weight ratio and energy efficiency of actuators. Also very very hard, and Moore's law helps not at all. Autonomous cars are in a nice niche since they store vast energy for actuation anyway, it's OK to be heavy, and the controls are relatively simple. They are limited by perception and decision making. Humanoids are way more limited by energy storage and actuation. Animals are absurdly efficient. reply jvanderbot 5 hours agorootparentMy point is that if you want to make a fully functional android last longer, have it take bathroom breaks and change out its lithium backpack. If you want to make a energy-unconstrained robot into a fully functional android, you have much bigger, fundamental problems. reply jjk166 15 hours agorootparentprevBattery density is only an issue if these things are spending most of their time moving long distances. If you are targeting a drop in replacement for a human worker who is spending most of their time at a workstation, it can be plugged in while working. Even in a scenario where the robot can not be connected to power while working, that's easily solved with redundancy - get two robots, one works while the other charges. Obviously better battery life is a nice to have, but it's not an impediment to large scale adoption the way other big robotics problems are. reply robotresearcher 12 hours agorootparent> easily solved with redundancy - get two robots. Yay, twice as expensive. And power tethers on robots suck so hard. Try it sometime, you’ll hate it. reply jjk166 4 hours agorootparentAnd how much more expensive is the twice as efficient power system that hasn't been developed yet? Nearly all robots in actual use have tethers, it's really not a big concern. Further there are other methods of providing power, such as induction. For any situation where long range mobility is really a concern, you probably don't want a humanoid robot to begin with. reply foobarian 17 hours agorootparentprevTangential question: are there any actuators out there that mimic the animal muscle tissue, i.e. swelling laterally in order to shorten a tendon and pull a joint? This seems like a very elegant method compared to servos with all sorts of slack and rigid positioning. I'm not a roboticist so I'm not familiar with state of the art in actuators. reply whatshisface 16 hours agorootparentThey exist, but they're inefficient compared to ordinary motors. reply sterlind 18 hours agorootparentprevThat surprises me. I thought motion planning and motor control would be harder - old memories of Asimo falling helplessly trying to climb stairs, the clunkiness of a robot aligning itself perfectly with a drawer before executing a scripted-looking action to pull the handle, the obvious recorded sequence Atlas uses to get up from a fall. I know Boston Dynamics does impressive acrobatics, but it's all legs and no arms. Are kinematics and planning solved now? I want to move into the field so I'm trying to learn. reply jvanderbot 1 hour agorootparentHow much of that is actually perception though? \"Where can I put my feet safely?\" \"What is the orientation and 6 higher order velocities of my body?\" etc. I've been told that a perfectly observable / estimable system is trivially controllable. It's one of the reasons I believe perception is upstream of everything - interaction dynamics alone are nearly impossible to just wave away with models. I don't even work in perception. But I know that everything is fine until you try to go online with perception in the loop. Then you are behind the perception team's debugging nearly all the time. reply jvanderbot 5 hours agorootparentprevHere's some closed-course manipulation with arms: https://www.youtube.com/watch?v=vuG-qNgLHws There are others. Controls is hard! You need investment and to solve difficult engineering problems. But we have a pretty good idea that those things are solveable and can demonstrate success b/c they are engineering challenges, not things we fundamentally don't have an approach for yet. reply mitthrowaway2 17 hours agorootparentprev> Asimo falling helplessly trying to climb stairs IIRC, that wasn't a control problem but a mechanical failure of a gearmotor shaft. reply mysteria 19 hours agoparentprevI would imagine latency would be an issue if companies were considering teleoperation using staff in a country with cheaper labor. For example I work with people in India and China and they regularly complain about the several hundred ms of latency they get when using their American VDIs. That off the shelf lawn mower is going to be hard to control safely with all that delay, and there's also the risk of connection drops and the like. You would need a specialized mower with collision detection/etc. to handle this, and at this point you might as well discard the robot and just have a remotely operated mower instead. However there are cases where this can work well, say in a factory handling dangerous chemicals with the teleoperator in an adjacent room. Or maybe it's doing some sort of task where delays and connectivity loss are acceptable. reply Terr_ 18 hours agorootparentLet's see, New York to Mumbai over the Earth's surface is maybe 12,500 km, assume a direct fiber optic cable where light travels noticeably slower than in a vacuum at 200,000 km per second... So a minimum of 62.5 ms one way with the best terrestrial equipment. While one can play network games at 125 ping, it relies rather heavily on tricks that only work in a virtual environment. (Back in the '90s I used to play with 300 ping, no latency compensation, uphill both ways.) reply mysteria 17 hours agorootparentRealistically it's in the several hundred range. I just did a ping using Vultr's Looking Glass from New Jersey to Mumbai and got around ~240ms on commercial fiber. For people working from home in India (with cable/DSL overhead + distance from the IX) connected to servers in LA I regularly see 300-400ms. Also keep in mind in a VDI or teleoperation setting there's not only network latency but additional delay from the video encoding, compression/packetization, and decoding on the other side plus a bit of buffer. Honestly I think cloud gaming is a good test case for this - and in my experience that only works well when you have fiber and have the game server in the same city as you (basicallyTo be honest, the autonomous control of the robot seems like the easier part of the equation. I agree but it is frustrating watching Elon like Michael Copperfield but thinking it is real like a 4 year old. I don't see a clear advantage of Tesla against other competitors if he will launch it in a couple of years. reply Philadelphia 17 hours agorootparentDavid Copperfield is the magician’s name, if that’s who you meant reply wslh 7 hours agorootparentYes, my fault! Thanks! David Copperfield, the illusionist. reply two_handfuls 14 hours agoprevThere was no announcement that the robots were autonomous. So it follows that they were not. There wasn't really misrepresentation here, at least as far as the ro ots are concerned. reply monkeydust 11 hours agoprevParking the obvious sentiment here which I agree with. Is there a market for human controlled robots like this ? reply jprd 15 hours agoprevI'd like to just say that Gwynne Shotwell might be one of the best executives in the world. Shotwell has SpaceX catching rockets with chopsticks, while being able to keep Elon from f*cking it all up by \"sleeping on the factory floor\" or whatever other stunt he is pulling. Tesla looks like a complete stock fraud sham for at least 5+ years (remember buying SolarCity because cousins?), then Boring and, Le Sigh. Dude literally did a \"We, Robot\" event and then copied the \"I, Robot\" movie designs. He isn't even trying anymore, this is just his \"rocket fuel\" scam for whatever other shiny object he desires. I'm super frustrated that someone set \"good\" things in motion, and we are letting them Mullenweg it all up. reply inquisitor27552 13 hours agoprevman these demos are synonimous to slides and mockups by startup founders. they are intended to paint the probable future, the ideal end game user experience. lots of people confuse it as the shippable product already. no sir, it's not like that. reply gigel82 15 hours agoprevWasn't the last presentation just some dudes in spandex outfits? So... progress, I guess? reply jsemrau 16 hours agoprevFigure 01 does the same thing. reply lefrenchy 16 hours agoprevIt’s so funny to me when people still believe Elon when it comes to this or deadlines. I used to work for him and he always overpromises Friendly reminder that in 2017 he was saying a car would drive autonomously from LA to NY in a year. It is now 2024 and that has not happened. Friendly reminder that Tesla Semis are still not fully delivered and running. Friendly reminder that the Roadster 2 is not rolling off the production line (people put down deposits too)! reply resters 15 hours agoparentIt's perplexing because Elon is effective at fundraising and pursuing challenging and ambitious goals. However now Tesla cars are protected by a 100% tariff on competitors, and Elon is campaigning for Trump who is now promising 200% tariffs on imported goods. The gigapress sounded like a good idea when I first heard about it bc it could reduce manufacturing costs, yet Tesla does not seem to have realized any significant improvements in 2024 from it, and needs massive protectionist policies to compete. It's interesting to imagine the price and performance we'd be seeing (and all the new dealerships and service centers popping up) of Chinese engineered and manufactured EVs if it weren't for the tariffs. Surely there would be some very capable options in the $20K range that would eat the Model 3's lunch. But Elon has government protection to the rescue and so he doesn't have to actually win at engineering or manufacturing, only lobbying. reply nomel 12 hours agorootparentYou’re simplifying things a bit here. The tariffs are to protect all US car manufacturers (who all have EV directives) from BYD, who was strategically subsidized by the government to crush EV companies, including Tesla [1]. Tesla would be able to compete much easier if we were to throw out the environmental regulations and better utilize slave labor [2]. [1] https://www.bloomberg.com/news/articles/2024-04-10/byd-got-3... [2] https://www.nytimes.com/2022/06/20/business/economy/forced-l... reply resters 5 hours agorootparent> The tariffs are to protect all US car manufacturers Most of the US car manufacturers would have gone out of business in 2008 if the US government had not bailed them out. How can anything China is doing to help BYD compare with that? Yet Tesla still needs 100% tariffs on BYD vehicles to compete?! Environmental regulations and alleged \"slave labor\" in China hasn't bothered the US government or US consumers for decades (most consumer goods are manufactured in China) yet somehow it matters tremendously in 2024 and necessitates 100% tariffs to protect US firms from competition? Most of us lived through the era when the price per performance of computer hardware decreased rapidly and there was rapid price deflation on hardware that was only a few years old. Right now, in 2024, American consumers should be benefitting from the far simpler design of EVs and car prices should be dramatically lower due to the benefits of EV tech. Car prices should have deflated but thanks to US policies entry level cars cost close to $30K now. The average price of a new car is $47,000 No, EVs do not need to be fancy, aluminum, giga-pressed luxury items! It's a battery and an electric motor and it should cost a LOT less than an internal combustion vehicle that has hundreds of precision moving parts. We've seen the high quality engineering and low cost manufacturing China is capable of with scooters, hoverboards, etc. The essence of China's industrial policy is that in a few years some of those engineers start being able to design EVs that outcompete Tesla. Meanwhile in the US we are bringing back steel mills and coal fire power plants! reply nomel 6 minutes agorootparent> Yet Tesla still needs 100% tariffs on BYD vehicles to compete?! Why does Canada also have 100% tariff? Why do you think the tariffs are only for Tesla? Again, all US car companies have a fairly ludicrous government mandate [1] for EV production: > In April, the EPA finalized its “Multi-Pollutant Emissions Standards for Light-Duty and Medium-Duty Vehicles for MY 2027 and Later” rule that could effectively call for 44% of new vehicles in 2030 and 56% of new vehicles sold in 2032 to be EVs. This rule greatly exceeds the current real-world consumer demand for EVs. Also, the rule projects that gas-powered vehicles (including hybrids and plug-in hybrids), now currently 92.9% of the market, could be reduced to 29% by 2032. Chevy, Ford, and Toyota lose billions [2][3][4] per year making EV. They need this too. Tesla is the only US car company that profits from EV sales. Tesla, by every metric, needs it the least. > necessitates 100% tariffs to protect US firms from competition ICE cars are made of metal and plastic. There's a nice local and global market for these. BEV need lithium and cobalt. The US makes 2% of the lithium worldwide, with its single mine in a single location [5]. Lithium is 30-50% the final cost of a BEV. China makes 7%, but the Chinese companies have helped secure 80% of worldwide production [6]. Chinese companies owns 15 of 17 cobalt mines in DRC, where 80% of cobalt comes from [7]. The line between where a Chinese company ends and the CCP begins can be very very blurry. This is the result of very smart investment in China, and a big fuck-you to the environment and labor (making imports illegal [8]), like the good old days of the US. > Meanwhile in the US we are bringing back steel mills and coal fire power plants! China is responsible for 95% of new coal plant construction [9]. > giga-pressed luxury items The giga pressing is to make them cheaper. Many car companies are looking at this for cost saving, including Toyota [10]. I agree with cars being too expensive. I've never looked into the breakdown for why. But, for the realm I work in, China is no longer much cheaper for labor. I suspect that's related. [1] https://www.nada.org/legislative/epas-de-facto-electric-vehi... [2] Ford loses over 4 billion with EV: https://www.cnbc.com/2023/07/28/ford-embraces-hybrids-as-it-... [3] Chevy over 4 billion loses with EV: https://fortune.com/2024/04/24/gm-earnings-beat-gas-ev-elect... [4] Toyota loses 4.7 billion with EV: https://www.reuters.com/business/autos-transportation/toyota.... [5] US only lithium mine: https://en.wikipedia.org/wiki/Thacker_Pass_lithium_mine#:~:t.... [6] China lithium monopoly: https://orcasia.org/article/602/chinas-monopoly-over-lithium.... [7] China 80% rare earth, 15/17 coral mines in DRC: https://georgetownsecuritystudiesreview.org/2023/06/01/china... [8] Battery import illegal forced labor: https://www.reuters.com/business/us-imports-auto-parts-face-... [9] China 95% coal plant construction: https://www.carbonbrief.org/china-responsible-for-95-of-new-... [10] Toyota giga casting: https://insideevs.com/news/671943/toyota-giga-casting/ reply chollida1 18 hours agoprevThat event was a huge disappointment. It's clear that Elon didn't consider it to be that important and didn't put any real effort into it. There was nothing an investor could look at and get excited about, it was the same thing as he announced 5 years ago. Just now his self driving cars have been eclipsed by Waymo and cruise seems to have caught up to what they can do with their demos. And why show the robots at all if they were just remote controlled by employees. reply standardUser 15 hours agoparentThe fact that Waymo has lapped anything Musk has to offer made the entire spectacle cringey and sad. reply m463 18 hours agoprev... \"This is awful! This is nothing like the Hell I visited two weeks ago!\" Bill Gates responded. \"I can't believe this! What happened to that other place, with the beautiful beaches, the beautiful women playing in the water!?\" \"That was a demo,\" replied St. Peter. also ED-209 from robocop, \"You have 20 seconds to comply.\" reply josefritzishere 3 hours agoprevseems like fraud in retrospect reply robomartin 13 hours agoprevDemos from just-about every single humanoid robot company are highly scripted and teleoperated (telechirs). Nothing new here. Generally speaking, the only demos that are not of the scripted and human-in-the-loop kind are simple ones. Even food delivery robots have remote drivers. Warehouse and floor cleaning robots are probably the two main examples of reasonably autonomous operation in a relatively constrained environment. Welding and assembly robots just play back a script, not unlike a CNC machine. reply tjpnz 14 hours agoprevMust've been a great night for the bulk of Hollywood's mocap actors! reply hedora 16 hours agoprevI love all the \"the fraud was so blatant it should have been obvious\" comments. Musk actually used this argument in his stock price manipulation trial, and the jury bought it. reply jimjimjim 18 hours agoprevMechanical Turk Robotaxis! The civilian version of drone pilots. reply b0sk 19 hours agoprevActually, I won't be surprised if it turns out that the 40 or so cybercabs were remote-controlled too. reply foobiekr 17 hours agoparentIt is clear they were in terms of starting off. But it was on a closed set - an undergrad could have coded what they showed. reply batch12 18 hours agoparentprevMaybe that's the realistic future of 'self-driving' cars. A teledriver-assisted automous car. It just moves the cab driver from behind the wheel to behind a screen somewhere else. reply xeromal 16 hours agorootparentThere's a company in vegas that pilots a rental car to you so you can be picked up anywhere and when you hop out, it drives off. You rent by the hour or something like that reply ilaksh 17 hours agorootparentprevWaymo has been demonstrating fully self driving cars for years. Teslas also do it, and truly necessary interventions are rare these days. reply pclmulqdq 17 hours agorootparentWaymos have some very advanced teledriving features, and it's not clear to me how often the human is involved when you ride a Waymo. I sort of hope that it's not that often, but I also thought the amazon store was automated. reply AlotOfReading 16 hours agorootparentWaymo vehicles are not driven remotely. Remote assistants give the autonomy stack suggestions for how to proceed rather than drive the vehicle. This doesn't require a low latency connection and the robot is still capable of stopping when the situation changes or proceeding as soon as it's able to without a control handover. reply pclmulqdq 15 hours agorootparentYes, they are not usually driven remotely, but an operator can take the wheel in an emergency situation. Most of the interventions are \"this plan or that one?\" decisions from the teleoperators. That still isn't really \"autonomous,\" but it's a lot closer than anything Tesla has done. My question, though, is how frequent the interventions actually are. reply ratedgene 17 hours agorootparentprevthey already have that, it's called human-in-the-loop (HITL) assist. They usually take over when a problem needs to be escalated to a human agent. reply rvz 17 hours agoprevI mean, that should have been obvious to anyone after calling it: [0] The 'fake it till you make it' fraud will just make everyone building so-called AI companies look bad and heavily faked with events like this. But there is still time for the Theranos of AI to reveal themselves. (It is not Tesla Inc.) [0] https://news.ycombinator.com/item?id=41805764 reply chasing 18 hours agoprevNo shit. reply ChrisArchitect 17 hours agoprev[dupe] Discussion: https://news.ycombinator.com/item?id=41815567 reply metadat 17 hours agoparentHey Chris, thanks for your continued diligence. This is actually a recent and related discussion, as the duplicate status suggests the same article has been posted twice (e.g. slightly altering a URL parameter to escape the HN dupe-detector). P.s. If you found the content in one article to be better than another, it would be helpful to steer folks towards the more informative one. In this case, the above Bloomberg article is pretty substantial compared to the one you've linked as a \"dupe\". Take care. reply ChrisArchitect 16 hours agorootparentDupe means duplicate discussion. There is an earlier discussion on this news story with plenty of upvotes and comments. Stop splitting up the threads, especially when it's a news story already developed from multiple days ago. Got something to add? Share it over there. Even maybe suggest the link over there in some cases even as a replacement article option. Stop splitting up threads and forcing us to repeat ourselves over and over. The discussion is over there. reply vardump 17 hours agoprev [–] I think it was fairly obvious from the show that the Optimus bots were remotely operated. Not like they tried to hide it at all. Just listen to the responses of the bots, they practically admitted that. The cars, however, were almost certainly running the latest FSD (or some near future unreleased version). reply ratedgene 17 hours agoparent [–] But they did try to hide it. It's in some videos where one of them was trying not to admit they were remotely controlled and that \"probably some AI is used\" reply vardump 17 hours agorootparentI read that \"probably some AI is used\" as that it's human controlled. Otherwise it would have been \"completely AI controlled\" or something similar. I think \"AI\" did control their walking. Although calling that AI is probably a stretch. reply mewpmewp2 17 hours agorootparentprev [–] Balancing or some movement mechanisms could be using AI. reply oblio 16 hours agorootparent [–] Why would they, though? Aren't those doable just with flat our regular code plus isn't AI slow? reply ponty_rick 14 hours agorootparent [–] AI is a pretty broad term - its been used for generations to mean something intelligent seeming that isn't human. Certainly, computers running precompiled instructions also falls in that category. reply oblio 10 hours agorootparent [–] That's pushing the term beyond its limits. Nobody reasonable considers ifs and dependency injection to be AI. reply mewpmewp2 9 hours agorootparent [–] In video games a lot of these are considered AI though. Even racing cars adapting to a trajectory with some ability to overtake, correct, etc. reply oblio 8 hours agorootparent [–] Those are definitely exaggerations for marketing purposes. I find it incredibly silly that 20+ years after the first more advanced \"AIs\" in games like Half Life, we're still far from a point where I can fire up a game of Dota 2 with bots and have the bots behave constantly well at an intermediate level, so that I can turn Dota 2 into a solid single player experience (I don't have the time nor the patience, anymore, for managing a team of toddler brains for 30-60 minutes). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Tesla's Optimus robots were showcased at a recent event, but they were remotely operated rather than fully autonomous, raising skepticism about Tesla's claims.",
      "The event underscored the difficulties in developing fully autonomous robots and highlighted concerns about Tesla's tendency to overpromise in its marketing.",
      "The situation sparked a broader discussion on how tech companies use hype to generate interest and influence stock prices, drawing parallels to other companies' scripted demonstrations."
    ],
    "points": 213,
    "commentCount": 206,
    "retryCount": 0,
    "time": 1728940241
  },
  {
    "id": 41846636,
    "title": "Pumpkin – A Modern Minecraft server written in Rust",
    "originLink": "https://github.com/Snowiiii/Pumpkin",
    "originBody": "Pumpkin Pumpkin is a Minecraft server built entirely in Rust, offering a fast, efficient, and customizable experience. It prioritizes performance and player enjoyment while adhering to the core mechanics of the game. What Pumpkin wants to achieve Performance: Leveraging multi-threading for maximum speed and efficiency. Compatibility: Supports the latest Minecraft server version and adheres to vanilla game mechanics. Security: Prioritizes security by preventing known exploits. Flexibility: Highly configurable with the ability to disable unnecessary features. Extensibility: Provides a foundation for plugin development. What Pumpkin will not Be a drop-in replacement for vanilla or other servers Be compatible with plugins or mods for other servers Function as a framework for building a server from scratch. Important Pumpkin is currently under heavy development. Features (WIP) Configuration (toml) Server Status/Ping Login Player Configuration Registries (biome types, paintings, dimensions) Server Brand Server Links Set Resource Pack Cookies World World Joining Player Tab-list World Loading Entity Spawning Chunk Loading World Generation Chunk Generation World Borders World Saving Player Player Skins Player Client brand Player Teleport Player Movement Player Animation Player Inventory Player Combat Server Plugins Query RCON Inventories Particles Chat Commands Proxy Velocity Check out our Github Project to see current progress How to run See our Quick Start Guide to get Pumpkin running Contributions Contributions are welcome! See CONTRIBUTING.md Docs The Documentation of Pumpkin can be found at https://snowiiii.github.io/Pumpkin/ Communication Consider joining our discord to stay up-to-date on events, updates, and connect with other members. Funding If you want to fund me and help the project, Check out my GitHub sponsors Thanks A big thanks to wiki.vg for providing valuable information used in the development of this project.",
    "commentLink": "https://news.ycombinator.com/item?id=41846636",
    "commentBody": "Pumpkin – A Modern Minecraft server written in Rust (github.com/snowiiii)201 points by alex_medvedev 7 hours agohidepastfavorite84 comments SquareWheel 1 hour agoThe performance differences look pretty impressive from the benchmarks. I do notice that world generation and saving features are missing though, and these tend to be pretty expensive operations. Chunk gen especially can bring a weaker VPS to its knees. I'm sure the benchmarks were taken at an idle state, but I'd be curious to see how it compares once those features are included and being used. I don't see it listed, but is there support for block breaking/placing yet? Presumably this would require light recalculation and a chunk update on the server. Finally, do you plan to add advanced features like scoreboard, teams, or command block parsing in general? Mojang has at least open-sourced Brigadier for that. Cool project. Hope to see it mature to the point of making servers easier to run on low-end hardware. reply alex_medvedev 1 hour agoparentHey. Im impressed with the benchmarks myself tbh. Yep block placing and breaking is already supported, but light currently don't so everything is dark :/, We are working on it. Yep, We want to add all cool features like scoreboards, teams and we already have a API which is similar to use to Brigadier for our Commands. Thanks, I would love to give players on low-end hardware the possibility to host servers. I think i may test Pumpkin on a raspberry PI or something one day reply SquareWheel 51 minutes agorootparentI remember Notch talking about the lighting calculations being one of the hardest parts to program, so I can understand that being a challenge. Mojang made large improvements to the lighting engine in 1.20, bringing it in line with the performance mods Phosphor[1] and Starlight[2]. Despite being deprecated now, they might still offer some useful insight into how to approach such a system in a performant way. You'll need to be mindful of the licenses, but it's likely easier than reverse-engineering Minecraft (even with mappings). [1] https://github.com/CaffeineMC/phosphor-fabric [2] https://github.com/PaperMC/Starlight reply alex_medvedev 42 minutes agorootparentWill definitely take a look at this, Thank you. Im btw studied the Minecraft code already so i often use the decompiled code as reference. reply mobeigi 5 hours agoprevAre there any benchmarks for it? How much faster is it than a vanilla server? I know Minecraft servers tend to get extremely resource intensive as the player count creep and people run extremely beefy servers to handle the load and still offer poor TPS. reply alex_medvedev 2 hours agoparentHey, Your lucky, i just made benchmarks all this time :D. Check them out https://snowiiii.github.io/Pumpkin/about/benchmarks.html reply canucker2016 42 minutes agorootparentPlease, just use one measurement unit across all measurements for easier comparison (i.e. RAM in MB, time in ms). Wow. Pumpkin's runtime is way better (faster, much less RAM used) than the Java versions. Congrats. I wonder what the Kotlin-based Minestom is doing differently that causes it to have numbers between Pumpkin and the Java versions. For comparison's sake, do you have build times for Pumpkin? I'll assume that's where critics may target. reply kridsdale3 1 hour agorootparentprevI literally said Holy Shit out loud. This is an incredible improvement, and I'll refer to this in the future when I'm asked if we should make something new in Java. reply mouse_ 1 hour agorootparentYes but also consider the extensibility accessibility Java gave us. EVERYONE was building Minecraft mods back in the beta days. I might go as far as to say that extensibility is what made Minecraft so great. reply pphysch 20 minutes agorootparentNo doubt about it. I don't think Minecraft would have gotten as far as fast in the public consciousness without content creators like Yogscast being able to produce so much novel content from modded Minecraft. reply alex_medvedev 1 hour agorootparentprevI was suprised myself thats its that bad. Well optimized binary is that what your CPU loves not a big JVM runtime reply lionkor 1 hour agorootparentprevnext [2 more] [flagged] alex_medvedev 1 hour agorootparentHey, Sorry Im not native english speaker, I will try to fix all grammer issues now thanks :D reply Imustaskforhelp 2 hours agoprevAs someone who knew about this project from earlier (I had even joined their discord) (currently have just deleted my discord account for better state of mind) Its really made me happy that hackernews really liked this project (140 upvotes is pretty good in my opinion) From what I remember , there was one other server as well which also was written in rust but I am not exactly sure Also , the last time I was at it , it was really really alpha software but it was getting developed at good rate , so I am not sure about its current state (I was there when the author had gone to take his exams IIRC) reply alex_medvedev 1 hour agoparentHi. Im so happy there are so many people liking the project, The Project is still pretty WIP but im really working hard on this, i finished my exmans last week and currently in holidays so commits are again back to normal :D reply compootr 1 hour agoparentprevMaybe it's cuberite? written in C I believe reply ramenlover 5 hours agoprevAre you sharding the main thread into regions (ie. Like paper folia) or is this just breaking of non block-entities to their own threads. reply zellyn 36 minutes agoprevHow does this compare to Dragonfly (IIUC, basically the same thing, but in Go)? https://github.com/df-mc/dragonfly reply mjtlittle 26 minutes agoparentThis looks like its for java while dragonfly seems to be for bedrock reply alex_medvedev 7 hours agoprevHello. I recently developed Pumpkin, Its a efficent and fast Minecraft server completely written in Rust from the ground up, Check it out :D reply gynther 6 hours agoparentCool! Would be interesting to understand how to multithreading works? Is it just the \"easy\" parts or actual operations related to the world as well? reply alex_medvedev 54 minutes agorootparentCurrently Pumpkin has not much multi-threading but we want to go all in. There is already a good structure for multi-threading, We want to make everything multi-threaded what benefits from it reply lesuorac 6 hours agoparentprev> What Pumpkin will not > Be a drop-in replacement for vanilla or other servers It seems to me that unless it's a drop-in replacement its not a Minecraft server? Akin to how say an Uno deck isn't a drop-in replacement for a Hearts deck but still both card games but not both Uno decks. Or is it just meaning that Pumpkin (besides the network) do things differently than vanilla and so you might not be able to open a vanilla created world using Pumpkin? reply looperhacks 5 hours agorootparentThe common problem with Minecraft server implementations is that they are not bug-for-bug compatible, which will lead to certain techniques (especially redstone contraptions) breaking. The technical Minecraft community depends on many implementation details which not all servers support reply Scaevolus 3 hours agorootparentIn addition to the hundreds of blocks and mobs that would need to be implemented properly and rarely are, the lack of mod support is a killer. The only \"complete\" reimplementation of Java Minecraft that I'm aware of is Bedrock. reply dmonitor 3 hours agorootparentFar from it. The versions lack a lot of parity and Bedrock is called \"bugrock\" by the community for a reason reply Scaevolus 3 hours agorootparentI edited in scare quotes for \"complete\" to make that clearer, but I mean in terms of at least having matching blocks/mobs despite many differing details. reply sandworm101 2 hours agorootparentprevThere are no bugs in Minecraft, only features that have yet to be fully documented. reply Dobbs 2 hours agorootparentprevMinecraft has a lot of bugs or otherwise surprising behaviours that parts of the community have come to rely upon. This means that most non-vanilla minecraft servers aren't 100% drop in replacements. You have to make a decision what behaviours you want vs the performance and simplicity gains you will gain. For example there there are tricks that allow you to delete bedrock blocks. Which then lets you either get onto the roof of the nether, or drop below the bottom of the world. Not all of these tricks will then work depending upon the specific minecraft server. Another example is that in vanilla you can \"bomb\" people with experience orbs, the sheer number of orbs on the screen will grind their game to a halt since there are too many objects to track and render. Some minecraft servers work around this by grouping up experience orbs into a single bigger orb. That way you have fewer orbs on screen at once. reply rft 3 minutes agorootparentOne bug abuse that blew my mind recently is the ability to have wireless redstone in vanilla [1]. I fell deep into that rabbit hole after a previous post on here about Bad Apple in Minecraft [2]. [1] https://www.youtube.com/watch?v=FLynwXDnETI [2] https://news.ycombinator.com/item?id=41798369 reply InMice 1 hour agoprevI will give it a try, Thanks for this project. The performance of pure vanilla server jar is so bad. Thats one thing I wish mojang would improve. I know new chunk generation is multithread at least. I also wish they'd officially support some basic control for SMP servers. Something as basic as areas defined by two corner coordinates and basic permissions like place, break, interact. Just a basic config file is fine I can manage the requests/updates ot it using other tools - or a simple commandline utilities in game to ops. Something that lets me not have to always only use an excluse whitelist. I know Paper/waterfall and the others have plugsins for this but theres just something nice about staying pure vanilla. Ive been keep servers alive for a long time now. reply alex_medvedev 57 minutes agoparentHey, Im happy you want to try it out just keep in mind its not done yet many features are missing, We want to have all the things you listed be configurable in a config file, so i think you will like it. If you have any problems may worth to take a look at https://snowiiii.github.io/Pumpkin/troubleshooting/common_is... or just ask for help on our discord, Have fun :D reply kamlaserbeam 27 minutes agoprevJust to be clear this sever only works with the current vanilla version of Minecraft? I've been interested in playing again, but on the older Beta builds (1.7.3) prior to the full release versions. These versions aren't supported are they? reply kgeist 3 hours agoprevWhat does \"modern\" mean in this context? reply slgeorge 2 hours agoparent\"Modern\" seems to be used a loose adjective these days for \"I rewrote $thing [in Rust]\". Minecraft was created in 2011, and is Wikipedia says the last version of the 'classic' edition was released in 2017. So anything after 2017 is now defunct. I don't mind people rewriting things inbut \"modern\" as a value seems pretty loose, and it's often at least arguable whether it's objectively better! reply codetrotter 2 hours agorootparent“Modern” more usually means some new JavaScript thing. In JS land, they consider anything that hasn’t had a commit on main branch in over 3 days to be a dead old project in need of being replaced with something new and “modern” that is up to date with the latest trends and breaking changes from the previous 24 hours of their world. Usually the hyperbolic superlative for Rust projects is “blazing fast”. Of course, any kind of benchmarks or comparisons with other implementations are completely optional. It is simply enough to “cargo init” and start hammering out code. You don’t even need to consider the characteristics of the algorithms you choose to use! If it’s Rust, it’s “blazing fast”. reply c-hendricks 2 hours agorootparentWhere's that meme of the guy painting demons then laying down on the floor in fear when you need it. reply renewiltord 1 hour agorootparentprevYour most starred repo is inferior to a shell one-liner lol. Talk about pot calling the kettle black. Just use the system dict, shuf, grep, and head. It’s bad form to badmouth someone’s earnest work for sure. I wouldn’t do it normally since I think it’s nice that you actually did something. But if you’re going to sit in a glass house and throw stones you should expect some back. Fortunately, my house is an underground burrow so I can throw stones with impunity. As ugly as it is to do. reply codetrotter 11 minutes agorootparent> a shell one-liner lol Dig a little deeper in the repos and you may eventually find that this is exactly what that started as :^) > badmouth someone’s earnest work for sure Was speaking generally. Not meant at OP. I think it’s awesome that they are making Minecraft inspired games in Rust. > Talk about pot calling the kettle black Of course! Anything else would be bad form. > my house is an underground burrow so I can throw stones with impunity Sneaky, sneaky ;) reply alex_medvedev 1 hour agorootparentprevSorry, I may should not used the term Modern, Lets say the foundation is newer and more optimized than from the Original Minecraft server. Mojang developers have strict deadlines and do not care about performance (like basicly any big Studio today). This results in bad ugly code which only purpose it is to work nothing more. Minecraft was created 2009 btw reply ramenlover 1 hour agorootparentI'd argue they care about performance, but they also care about a whole slew of other things that also require prioritization to maintain the game and its cottage industry. Not a huge fan of the constant dogging on mojang everyone loves to engage in... reply bangaladore 1 hour agorootparentPeople seem to forget that if you already know where the finish line is, the journey on getting there can be made quicker and more efficient. This, at least in my experience, applies greatly to software and hardware. reply alex_medvedev 2 hours agoparentprevIts written from the ground up and has a clean foundation (which is not the case in vanilla minecraft server code). We also want to use cool modern features like multi-threading or the rust language which is a modern language designed to fix mistakes from older languages reply philipwhiuk 2 hours agorootparent> cool modern features like multi-threading Java 6 had multi-threading reply nijave 1 hour agorootparentThe limitation isn't the Java version, it's the way the MC code was architected. Iirc part of original Minecraft's performance limitations were high object create/destroy rate leading to lots of garbage collection. With that in mind, picking a non-GCd language isn't completely crazy. reply kgeist 35 minutes agorootparentIt was the other way around: say, the original code as written by Notch had functions like setPosition(x,y,z) and it was okay. When Jeb got in charge, he said \"it's not object-oriented enough\" and rewrote everything to setPosition(position). And boom, 1GB/sec allocations... reply plandis 1 hour agorootparentprevI think they are being sarcastic because the vanilla Minecraft server is heavily single threaded. reply giancarlostoro 1 hour agorootparentprevWhile Java does, the Minecraft server architecture does not. reply Imustaskforhelp 2 hours agorootparentprevI read this in the most satirical way possible like as if a godly narrator said it calmly. It was really funny. It felt like a Satire LMAO reply bbno4 4 hours agoprevIt has now been 0 days since a new minecraft server was written in Rust https://dayssincelastrustmcserver.com/ reply JadoJodo 3 hours agoparentIt's pretty funny how many of these are \"Is it a Minecraft server? No. It's a framework with which you can build your own rewrite of Minecraft server.\" reply xx_ns 4 hours agoparentprevPumpkin is already on that list. reply whalesalad 2 hours agoparentprevThis got me thinking - is Rust really the right tool for the job? And I thought, Elixir/Erlang feels like the perfect tool. Sure enough, someone did it! Great reference material for someone learning how to do things on the beam https://github.com/thecodeboss/minecraft reply whazor 2 hours agoparentprevI was thinking it would be cool to have a Minecraft server built with Bevy, but that has also already been done: https://github.com/valence-rs/valence reply Imustaskforhelp 2 hours agoparentprevLmao it is funny how we have daysinceX websites. is there a list of all such websites of daysinceXofY like dayssincelatestframeworkofnode I guess? reply AbraKdabra 40 minutes agoparentprevomfg haha. reply tomasff 2 hours agoprevSee also https://github.com/valence-rs/valence A \"clean room\" implementation of the Minecraft server written in Rust reply alex_medvedev 2 hours agoparentHi, Valence is a framework (similar to Minestom in Java). You have to build everything you self. Pumpkin is not a framework :D. Also Valence is bit unactive (look commits) reply Imustaskforhelp 2 hours agoparentprevyes , I was also thinking about this . +1 reply FrustratedMonky 5 hours agoprevLove the idea. Especially as a learning example. Always fun to learn a language by implementing a popular game. Am confused by these two lines. Maybe it is just difference between the 'goal' and the 'current state'. Goal: \"Compatibility: Supports the latest Minecraft server version and adheres to vanilla game mechanics. \" But NOT: \"Be a drop-in replacement for vanilla or other servers \" Will it be a replacement for Vanilla or not? reply hexmiles 5 hours agoparentCompatibility: refers to the ability for client of the latest mincraft server version to be able to connect to the server (pumpkin) unmodified with all mechanics working. Drop-in replacement: refer to the ability of a server operator to simply exchange the current installation/executable of the server (be vanilla, paper, cuberite, etc...) for pumpkin while maintaining data, configuration, scripts and mods installed. edit: grammar reply FrustratedMonky 4 hours agorootparentTell you the truth, that doesn't help clarify to me much. If it is compatible, then can't I 'drop it in'. They sound like they are saying the same thing. It is compatible so clients can connect to the server and be fully operational, and thus, I should be able to drop in this server, and use it as a server? How can it be compatible if it doesn't maintain data, configuration, etc.. Edit: or is this about Pumpkin files. Pumpkin will maintain it's own files, data, configuration. So it can't just use existing Minecraft data files. So if it was a new world, Pumpkin would generate new pumpkin formatted files. But couldn't just 'drop it in' on an existing world and use the existing Minecraft data files. Not sure of long term viability as far as effort, but if it is files, couldn't a converter from MineCraft to Pumpkin file structure, make the server 'drop in'? reply Arch-TK 4 hours agorootparentMaybe some more concrete examples may help: * nginx is not a drop in replacement for apache But from a client perspective, both implement HTTP/1.1. * podman is not a drop in replacement for docker But from a client perspective connecting to a service hosted in docker, that connection can still occur over TCP. On the other hand: * pkgconf is a drop in replacement for pkg-config * cronie is a drop in replacement for vixie-cron reply FrustratedMonky 2 hours agorootparent\"But from a client perspective, both implement HTTP/1.1.\" This seems too low level example to apply for Minecraft. Minecraft has a lot going on, back and forth. For something to be 'compatible' it would need to be so detailed an implementation of the server, that it could potentially also be a 'drop in'. reply hakanderyal 4 hours agorootparentprevDrop-in means replacing an existing thing with a new one without changing anything. This is not compatible with other servers plugins/data/configurations, so just replacing the binary and expecting to continue where you left off is not possible. reply p0w3n3d 4 hours agorootparentprevI would say that Minecraft servers by some qualities are really hard to implement (for example generate world as Java would - using Java's random number generator to generate exactly the same world in Rust) or even impossible. But other usages, like walking through existing world with 1000 of your colleagues might be worth of writing a very fast but not a \"drop in replacement\" server. Or a massive minigame maybe? reply Xeamek 3 hours agorootparentBut the world generation is already deterministic with seeds reply hoseja 4 hours agorootparentprevCompatible: You start a Pumpkin server, vanilla clients can join and play. Drop-in: You run a server for some time. You decide to switch the software by replacing the executable. Everything works as before. reply bombcar 4 hours agorootparent\"Drop-in\" is what enterprise software calls \"bug-for-bug compatible\" - e.g., replacing RedHat with CentOS (RIP) should work exactly the same, even if the CentOS team found bugs - they report them upstream and do NOT fix them themselves, because code may be relying on the bugs. This is especially true with complicated vanilla Minecraft setups and red stone machines (Java Minecraft red stone has \"bugs\" that \"shouldn't be there\" but cannot be removed now since so much depends on it). reply FrustratedMonky 2 hours agorootparentprevGuess this gets to my other point. By the time you are 'compatible' then you have implemented everything needed to also be a 'drop-in' but data file formats might need a conversion. So convert from Minecraft data files to Pumpkin data files. Then it could drop in. reply alex_medvedev 3 hours agoparentprevHey, With Compatibility i mean be compatible with existing Minecraft vanilla client's and also use vanilla logic. With \"Be a drop-in replacement for vanilla or other servers\" i mean that if you just replace the existing server file with pumpkin, pumpkin will not load configs/plugins from vanilla/other servers reply giancarlostoro 1 hour agorootparent> i mean that if you just replace the existing server file with pumpkin, pumpkin will not load configs/plugins from vanilla/other servers Will it ever though? Is this a goal? reply saintradon 5 hours agoprevThis looks great! Can't wait to check out the code in detail. reply alex_medvedev 3 hours agoparentI would love to hear some feedback, tried my best so code is clean :D reply WhereIsTheTruth 3 hours agoprevi wish minecraft was open source, i'd be able to fix their inefficient protocol reply WhereIsTheTruth 2 hours agoparentDownvoter, go check this: https://wiki.vg/Protocol, let me know if that's a good way to sync a lot of fast moving entities across a TCP network This is why people struggle with their servers, not because the game was written in java reply giancarlostoro 1 hour agorootparentCurious what protocol you would use, or how you would do it differently? Are there small enhancements to the existing protocol you would do? Genuine open question for the sake of learning. reply alex_medvedev 1 hour agorootparentI would prefer the UDP Protocol over TCP like in Bedrock edition. Im pretty sure many PVP players would love this. Here is much non sense in the Minecraft protocol and things made to work not to be optimized (deadlines). At our discord we even already have a sticker :mojang_nonsense: which will be used quiet often. I also don't understand Mojang's tactic with packet changes, It sometimes looks like they care about Packets not being broken and being backwards compatible but them sometimes they change the whole Networking system (1.20) reply superlucky84 4 hours agoprevlooks good reply alex_medvedev 3 hours agoparentthank you :3 reply icepat 5 hours agoprevReminded me of this existing https://dayssincelastrustmcserver.com/ reply pzmarzly 5 hours agoprevSimilar projects: - Feather (Rust, abandoned) https://github.com/feather-rs/feather - Valence (Rust) https://github.com/valence-rs/valence - Cuberite (C++) https://github.com/cuberite/cuberite reply jedisct1 2 hours agoparentMinecraft Server (Zig) https://github.com/regenerativep/zig-mc-server reply dangoodmanUT 5 hours agoprevthis person is going gods work reply bradhe 4 hours agoprev [–] This weeks Minecraft server! Nice! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Pumpkin Pumpkin is a Minecraft server developed in Rust, prioritizing speed, efficiency, and customization while preserving core game mechanics.",
      "The server is designed for high performance and compatibility with the latest Minecraft version, offering security, flexibility, and extensibility for plugin development.",
      "It is currently under development, with features like configuration, server status, player settings, and world management, and invites contributions and community engagement through Discord and GitHub sponsors."
    ],
    "commentSummary": [
      "Pumpkin is a Minecraft server developed in Rust, focusing on enhanced performance and efficiency compared to traditional servers.",
      "Although it currently lacks features such as world generation and lighting, it supports basic functions like block placing and breaking.",
      "The server is not a direct replacement for vanilla servers, as it does not support existing configurations or plugins, but it aims to be compatible with vanilla clients and game mechanics."
    ],
    "points": 201,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1728983896
  },
  {
    "id": 41840971,
    "title": "Bike Manufacturers Are Making Bikes Less Repairable",
    "originLink": "https://www.ifixit.com/News/101675/bike-manufacturers-are-making-bikes-less-repairable",
    "originBody": "Tech News Bike Manufacturers Are Making Bikes Less Repairable Article by: Charlie Sorrel @mistercharlie October 14, 2024 Filed under: Tech News One Comment Share The bicycle is probably the canonical example of something that anyone can fix. Spares from all brands are mostly interchangeable, and you can do most repairs with wrenches, screwdrivers, and Allen keys, or some fairly standard tools for bottom brackets and chainrings. But that’s all changing. Just like cars, tractors, computers, and seemingly every other product category, bikes—and especially e-bikes—are going all black box on us. Instead of using standard parts that can easily be swapped or upgraded, bike makers are using more and more proprietary parts. At the same time, cheap bikes are getting worse and are designed to fail, or rather, they are not designed to last, which is pretty much the same thing. Featured Guide How to Replace a Bike Chain With a Master Link Bicycle chains sometimes need to be removed for… Follow this Guide Riding Away From Standardization For example, the bottom bracket—the tubular bearing assembly at the bottom of the frame that the pedal axle threads through—has long been a fairly standard part. Over the years, and on different continents, there may have been a few thread sizes, but a cyclist could easily buy the right part for a surprisingly reasonable price. Just as important, you’ve been able to remove the bottom bracket with one of a few simple tools. Now, though, a bike shop has to keep 20+ tools on hand to deal with all the proprietary fittings. Standard parts make modding and repair easier. Photo Charlie Sorrel. On electric bikes, things are even worse. Batteries are as non-standard as they are on cell phones. Instead of creating a standard, a kind of giant li-ion AA-equivalent for all bikes, you’re stuck buying non-standard sizes that you won’t be able to use on a new bike. This creates its own kind of lock-in, like the batteries on power tools, perhaps making you more likely to stick with the same brand within a family. Then there are the apps. If you’re considering an e-bike that requires an app to function, or to change settings, do not buy that bike. When (not if) that app is abandoned, the bike will become at best a hobbled version of itself. The result is that possibly the greenest, most efficient form of transport is turning into yet another source of landfill and e-waste. But why? The cynical—and probably correct—take is that it boosts sales. By using proprietary parts, a bike manufacturer guarantees you have to go back to them for spares. And if those spares are not readily available, or are too expensive, then maybe you’ll just give up and buy a new bike instead. Couple this with the explosion in new bike tech in recent years, which is itself designed to drive the desire to “upgrade” a perfectly good bike by replacing it with a new one, and you can see the attraction for the bean counters. Electronic, wireless gear shifters. Carbon-fiber seat posts. Active, self-adjusting suspension. Proprietary apps for changing key features like the power mode. All of these are superfluous for most riders, and add complexity to what is essentially a very simple, and pretty much perfect, machine. Buy Cheap, Buy Twice Bikes are getting ever more popular, in large part thanks to e-bikes, which make riding easy for people who would not otherwise consider cycling. That’s good news! Alas, to service this popularity, cheap and crappy bikes have proliferated. “Budget bikes from ‘big box’ stores […] cost little ($150 to $250) because manufacturers cut corners. These bikes are built to fail: badly engineered, constructed from low-grade materials and fabricated in countries with inhumane labor standards,” writes cycling advocate Josh Bicker on StreetsBlog NYC. These bikes are often broken out of the box. That’s bad if the buyer is a bike shop, and possibly deadly if the buyer is an inexperienced rider buying off the internet. Buying a used bike is a much better way to get a well-made machine for a good price. The downside of that is that you need to know what to look for, and how to bring that bike up to correct working order so that it is reliable and safe. Fortunately, that’s possible with local bike kitchens and co-ops, or by asking your bike shop to look over the bike for you. This works best if that bike isn’t using a bunch of proprietary parts. You can’t reach into the spare parts bin for a brake caliper if your bike uses a proprietary disk-brake design, whether that’s a super-high-end model, or a closed unit with more plastic than metal. Ideally all bikes would continue to draw on a pool of standard part-types, but manufacturers seem set on the opposite. This makes it all the more important that we have legislation to force them to make proprietary parts available for riders to buy themselves, not just selling to repair shops (if at all). And with the increase of technology in bikes, public repair information is also essential. You’re definitely not going to find powered-hub servicing guides on Sheldon Brown. Fingers crossed, but that legislation may indeed be on the way. Featured Guide How to Repair Electric Bikes What to inspect and do when looking to resolve… Follow this Guide Batteries Should Be Interoperable Let’s get to batteries. After tires, tubes, cables and chains, the one thing on an electric bike that will 100% wear out and need replacing is the battery. Unlike most laptops, you can easily remove the battery from the bike. But forget about ordering up a standard replacement, because there isn’t one. The batteries are often shaped to fit the bike, but even those that clip into a section below the rear rack, or are otherwise independently-mounted vary in capacity, voltage, and current delivery. That keeps replacement costs higher, but it also means that you are stuck if the manufacturer discontinues your battery. A bike that is otherwise in perfect working order might end up prematurely useless, or you will end up in the world of shonky spares from Amazon or another unreliable source. Sure, why not? Photo Charlie Sorrel. The standard excuses apply. Original parts are designed to work safely together. Using non-official parts can be dangerous, etc. That may be true, but if so, it’s only because the parts were designed that way. The blame is with the manufacturer. It’s totally possible to design around standard batteries. Ask anyone who’s ever made a device that runs on AA batteries, or swapped a new 12-Volt lead-acid battery into a car. We are 100% against this trend. A bike is an almost perfect machine, and e-bikes combined with public transit are probably the best way to get cars out of cities, and to make personal transport sustainable. “There’s no machine known that is more efficient than a human on a bicycle,” Bill Nye, the science guy, told Big Think. “Bowl of oatmeal, 30 miles — you can’t come close to that.” And yet all that is being ruined in an effort to make us buy a new bike every few years, instead of repairing the ones we have. Newer, more exotic specs and components encourage us to “upgrade,” just like with smartphones, laptops, and cameras, and they also turn the perfect machine into an unknowable black box that is often not worth the cost of repair. The Infinite Battery is endlessly repairable, and even looks cool. One ray of hope here is the Infinite Battery by Gouach, currently seeking development funding via Indiegogo. It’s compatible with all major brands’ setups, and offers the usual power capacity and safety features, but it is totally user serviceable. All parts can be swapped out individually, and when the cells inside start to wear out, you can replace them individually, almost as if your bike ran on around 30 AA cells If you can repair a bike, and use standard spares, either new or harvested from dead bikes, then a bike can essentially live forever. If the growing anti-repair practices of the bike industry are allowed to threaten that, then we no longer own our machines. We are essentially renting disposable gadgets instead. Related Stories Roundups Bicycles: An Antidote to Throw-Away Culture Roundups Are Bicycles Becoming Less Sustainable? How To How to Get Back On the Bicycle Repair Saddle",
    "commentLink": "https://news.ycombinator.com/item?id=41840971",
    "commentBody": "Bike Manufacturers Are Making Bikes Less Repairable (ifixit.com)200 points by LorenDB 23 hours agohidepastfavorite197 comments oulipo 22 hours agoFounder of Gouach, the repairable (and fireproof!) e-bike battery mentioned in the article, happy to answer any question! - we salvaged 100s of discarded e-bike batteries - we found that 90% of components were like new - batteries were thrown away because of the spot-welding and the glue which prevents repairability - we spent 2 years (and 5 patents) to design a robust, safe, and easy to assemble system that requires nothing but a screwdriver Our batteries have been in use since 2 years in the streets of France, on micro-mobility e-bikes, in the harshest possible conditions (rain, snow, cold, heat, shocks), and we're very happy with their performances! We're now opening it to the general public (for conversion kits, and to replace old batteries that are no longer manufactured) We plan to open-source at least part of the embedded software, so people can write extensions (to let their battery \"talk\" with any e-bike system, and share it — using WASM embeddable code — to other people on the web!) Let's fight planned obsolescence! (and if you're looking for a new battery, there's 25% off on https://get.gouach.com) reply bsimpson 22 hours agoparentThat's awesome! Minor grammar tip - saying \"since 2 years\" is a tell that you're a non-native speaker. It's a common mistake that most people will understand, but the correct phrasing is \"for 2 years.\" I'm sure this is a pitch you practice a lot, so I wanted to help for next time. reply oulipo 22 hours agorootparentThank you!! Appreciated :) reply wlesieutre 21 hours agorootparentAlternately, “since two years ago” works too. “Since” goes with a particular moment in time (rather than an amount of time) to refer to the period between that time and now, like an old restaurant saying “making pizza since 1922” or for recent events like “since yesterday.” reply mrkstu 18 hours agorootparent'Since two years ago' is still awkward. Generally a native speaker would choose the phrasing 'for the last two years.' The other two examples work, though 'since yesterday' is still slightly forced unless its an answer to a direct question. reply rodgerd 22 hours agorootparentprevMeanwhile, English speakers are trying to get the hang of depuis/pendant... reply tharkun__ 17 hours agorootparentAnd French teachers scream at students: \"h muet!!!!1onze\" and then turn around and say things like \"I ate you!\" and I want to scream: \"h non muet in English you little...\" So what's your point exactly? reply cibyr 21 hours agoparentprevWhy does configuration require a closed-source app, with an account on your proprietary platform? reply oulipo 11 hours agorootparentThere is no required account :) The app just allows to connect over Bluetooth to the battery if you want to set a wifi password to retrieve your data and set alerts! It also lets you configure your battery for any type of e-bike system reply cibyr 2 hours agorootparent\"Required\" is hiding the ball here. There's desirable functionality - that you're touting in your sales pitch! - that isn't accessible without your client software, and it sure looks like https://clients.gouach.com/ won't do anything without a login. https://docs.gouach.com/connected-batteries/monitoring-inter... explicitly states \"In order to access the connectivity features, you will need a Gouach client account.\" None of this is the end of the world, and I'm glad the batteries will continue to work as batteries after you go out of business, but it does come off as hypocritical given your big talk about repairability. reply sriacha 20 hours agorootparentprevWeb page claims the app is being open-sourced. reply cibyr 20 hours agorootparentIt's the \"account required\" part that really bugs me. Implies that everything is routed through some cloud backend that'll shut down one day and then you lose access to all the smarts in your \"infinitely repairable\" battery. reply oulipo 11 hours agorootparentNo, the app is never needed! It's for extra features and configurability reply biglyburrito 20 hours agoparentprevI just read about Gouach on Indiegogo last week ( https://www.indiegogo.com/projects/infinite-the-repairable-u... ) -- very cool stuff. reply oulipo 11 hours agorootparentThanks so much!! reply dperrin 18 hours agoparentprevIn the thermal runaway video, you have steel bars holding the battery down. Is there risk of the battery casing blowing apart without that steel holding it down? reply oulipo 11 hours agorootparentNo! The casing contains the explosion. We just used steel bar to be extra safe, and make sure the batteries don't move while filming reply acyou 22 hours agoparentprevHow do you address local heat generation at the interfaces between the cells and the contacts? Does that pose additional risk of cell failure leading to thermal runaway in high current scenarios? reply oulipo 22 hours agorootparentYes! You can check the technical details on our documentation and our FAQ here (sorry, we're still cleaning up now, but feel free to ask for details) https://docs.gouach.com/knowledge-base/frequently-asked-ques... We've seen that our design does not pose heating or resistance issues reply acyou 22 hours agorootparentWhich cells did you test with? Is that result valid for other cells? What is your team's background in battery safety? reply oulipo 22 hours agorootparentWe are using DMEGC INR 18650 cells, which is the best quality/price ratio that we've found, often beating even great brands. We've developed a LOT of experience on safety after fighting a few fires haha, this is why we added a lot of software and hardware safeties (fuses everywhere, alerts, etc) Oh and we designed a fireproof casing to be extra-cautious that nothing would happen to our clients! https://www.youtube.com/watch?v=tJETffg0kFc reply acyou 22 hours agorootparentAre you working with any external lithium ion battery safety specialists? reply gr__or 22 hours agoparentprevabsolutely beautiful mission, thank you! reply oulipo 22 hours agorootparentThanks so much!! Appreciated reply pims 22 hours agoparentprevHello, I own a Specialized Vado SL from 2022. Can I use your battery as a range extender? reply oulipo 22 hours agorootparentYes! You can use the Datex extender that we sell when you order the battery here https://get.gouach.com reply UltraSane 22 hours agorootparentWhy does that URL redirect to your indigogo site? reply dylan604 21 hours agorootparentSeems like a perfectly valid question to me. Why the flagging? Redirecting to IndiGoGo makes it look like it's not yet a real product. Linking directly to the product mentioned when the link was provided seems like a much more helpful thing rather than some generic self promotion. So is the product being pitched actually being sold as claimed, or is it hoping to become a product while looking for funding? So, why is the link redirecting? reply oulipo 21 hours agorootparentHi! Thanks for the question! The link was our original pre-launch page, and now redirecting to the Indiegogo campaign! The product does exist, and is in use, but until now our clients have been B2B, who are able to pay upfront for the commands. As we are now opening to the general public, and we're a startup, we needed a schema like Indiegogo to get the money upfront and be able to buy the materials to assemble all the batteries! We're expecting to ship at the end of the year reply detourdog 20 hours agoparentprevThat’s great have you looked into the marine industry? reply oulipo 11 hours agorootparentNot yet! If you have interesting applications or contacts, we'd love to know! Send us an email at contact@gouach.com :) reply sandworm101 20 hours agoparentprev>> 2 years in the streets of France, on micro-mobility e-bikes, in the harshest possible conditions (rain, snow, cold, heat, shocks) Um... Paris isn't exactly a harsh climate. Send some batteries to me in a month or two and I'll show them winter. Proper winter starts when it stops snowing. reply oneplane 19 hours agorootparentEverything is relative ;-) Hash in the context of places where you'd ride your bike is a very different kind of hash than let's say, the weather on mercury or pluto. reply mauvehaus 22 hours agoprevWork in a bike shop part-time. Can confirm: there are about two dozen bottom bracket tools in the drawer. In fairness, bottom brackets have been a pain in the ass for decades. Even on old ones, there are a couple different hook spanners and pin spanners you might need for the lock ring and adjustable cup and a couple other weird-ass wrenches that you need from time to time. Shit's usually tight AF too, and the various tools that were fine for manufacturing a bike get a little iffy when everything's good and seized after 20 years of neglect. As for e-bikes, my usual observation when one comes in with an intermittent error is \"We've managed to make bicycles as reliable as computers. What an incredible accomplishment for our species.\" We only work on the electric drivetrain on Trek bikes (and others that use Bosch). I can vouch for the fact that as of October 2024, the electric drivetrain stuff can be handled from the on-bike computer and an app isn't necessary for basic functionality. I'm sure you get some more features with the app, but you don't need it to just go for a ride. Batteries come with some wrinkles. Many manufacturers (not just Trek) want to make them easily removable so you can take them with you to charge and prevent them from getting stolen. They also want them to integrate nicely with the frame visually. The result is frequently some amount of compromise in the proprietary direction. That said, Bosch appears to make some standard-ish batteries that are used in less-integrated installations across bike manufacturers. reply oulipo 22 hours agoparentYou're right! Big issue with Bosch systems is that they use DRM to lock-in users, so that they need to buy (very expensive) Bosch batteries. Bosch batteries are well-designed, and very safe. But still issues can happen. If you want to check a fun battery fire video, here's a comparison that we've made between a Gouach fireproof battery (disclaimer: I'm a co-founder) and a Bosch battery! https://www.youtube.com/watch?v=tJETffg0kFc (the video is not perfect because we had to drill for one battery and not the other for technical reason, and it doesn't change the result, but just for the sake of it, we're planning to film a new one next week haha) reply mauvehaus 22 hours agorootparentAppreciate the work you're doing, and to be clear: I'm not defending any of Bosch's business practices and vendor lock-in[0]. I do appreciate that they're big enough that they pop up on multiple manufacturers' bikes and that they offer a battery system that looks decent enough that various manufacturers are willing to use it. [0] Like the USB dongle you have to have to run their diagnostic software... reply oulipo 22 hours agorootparentThanks for your message :) reply criddell 22 hours agoparentprevI'd love for the EU (because I know the US won't do it) to start requiring battery standardization. I normally am complaining about power tool batteries, but now that I've started looking at ebikes it's clear that a more general regulation would really benefit consumers. reply oulipo 21 hours agorootparentExactly! And EU is mandating that light mobility electric batteries be repairable (able to change cells) starting 2027! reply foco_tubi 19 hours agoparentprevBottom bracket fussing is a tale as old as time. I have a bike from 1983 with an original Suntour bottom bracket. It even uses cartridge bearings! But the spline pattern for the cups is proprietary and the tool has long been out of production. reply asciimike 19 hours agoparentprev> Can confirm: there are about two dozen bottom bracket tools in the drawer. In fairness, bottom brackets have been a pain in the ass for decades. Even on old ones, there are a couple different hook spanners and pin spanners you might need for the lock ring and adjustable cup and a couple other weird-ass wrenches that you need from time to time. Shit's usually tight AF too, and the various tools that were fine for manufacturing a bike get a little iffy when everything's good and seized after 20 years of neglect. I agree the various (totally random) BB standards are a pain; every bike build I've done has meant that I CADed and then 3D printed the tool (100% infill PETG, takes ~2 hours on a Prusa MK3S). Curious how long it is before we get 3D printing tech easy enough to where shops can have a printer, download any special tools for a bike assembly, and make them in a few hours. Hope is a great example of a manufacturer who does this today: https://www.hopetech.com/open-source-tools/ reply ryandrake 18 hours agoparentprev> As for e-bikes, my usual observation when one comes in with an intermittent error is \"We've managed to make bicycles as reliable as computers. What an incredible accomplishment for our species.\" Whenever you put a computer into a device that has historically been reliable and never needed a computer, you instantly limit its reliability to that of the computer (which usually becomes the most failure-prone and/or non-repairable part in the device). reply tln 19 hours agoparentprevKudos to your shop for working on e-bikes at all. My experiences have been that bike shops/mechanics won't even do normal bike stuff, like working on brakes, when its an e-bike. reply foco_tubi 19 hours agorootparentI had 3 simple questions to decide if an e-bike went in my stand: 1.) Does the frame use a seatpost? 2.) Are there any frayed or broken wires? 3.) Is the power cable to the motor removable? reply tln 18 hours agorootparentI suppose the reason for needing a seatpost is to clamp on your stand. E-bikes get heavy, like 30kgs / 65lbs isn't at all rare, I wonder how if thats good for a seatpost? Removable battery is as good as a removable power cable right? reply foco_tubi 18 hours agorootparentSeatposts support hundreds of pounds of human flesh also, so the weight usually isn't the concern. But if your bike looks like more of a motorcycle, it's probably not going into my work stand. On the point about the power cable, this is more directed at hub Drive motors. If I can't disconnect your motor to remove your wheel, I'm not going to fix your flat tire. reply kjkjadksj 20 hours agoparentprevRealistically you only need the tools for your bike. Hardly matters that there are a dozen bb types, you pick the adapter you need and move on. And by and large most people are going to be something common like 22 spline not those weird campy bb from 50 years ago. reply AdrianB1 19 hours agorootparentYou are spot on. We have several bicycles in my extended family and I have the tools to repair all of it, but when we bought or built the bikes we looked for the widest compatibility possible of the spare parts: 2 BB types, 2 chain types, 2 fork and bearing types and 4 wheel sizes for ~ 10 bikes. The only \"rare\" tools are a Shimano Hollowtech 2 wrench and the \"square BB\" one, the rest are common tools most people have in the house. reply fire_lake 22 hours agoprevHow to make your life super easy if shopping for a bike: - 1 1/8 steerer tube, or maybe tapered - Threadless a-head headset in any common SHIS type. Threaded ones won’t last as long. - QR or common thru-axle - Any common BB standard (threadless ones are actually fine but require a well made frame, and you’d be surprised how many expensive frames are not well made) - Always a round seat post and get 27.2mm if you can. Bigger if you care about dropper posts - Rim brakes are fine unless you are doing serious off road. If going disc, hydraulics offer great performance for the price. - Flat bar shifting components are much more interchangeable and better value that drop bar! - If going drop bar, consider older 2x11 speed mechanical equipment. It’s much cheaper and it was competitive at a pro level not so long ago. - External cable routing! - Aluminium is uncool, but it represents a sweet spot in terms of weigh/cost/durability - Tyre volume, not frame material, is the most important factor in comfort - Never buy a bike that doesn’t fit you These tips won’t get you the best bike (in terms of absolute performance) but it will be reliable, easy to fix and good value. reply ricardobeat 21 hours agoparentI.. appreciate the effort but even as an owner of three bikes, and doing maintenance myself most of the time, I barely understand half of this list. I imagine most casual bicycle riders would be in the same boat? No idea what SHIS, QR, BB, dropper post or flat bar mean. Is this racing bike lingo? reply fire_lake 21 hours agorootparentSHIS is standard headset identification QR is quick release (as in wheels) BB is bottom bracket Dropper post is an MTB thing and so are flat bars! reply DidYaWipe 11 hours agorootparentWhat's \"MTB?\" reply m463 11 hours agorootparentMTB mountain bike. mountain bikes have a \"flat\" handlebar that is mostly straight from end to end. They also have dropper posts - this basically converts a bicycle seat into an office chair. A handlebar lever you can pull will let the seat move up and down hydraulically and when you release it it stays in that position. People use it to pedal normally with the seat up, but on tricky trails you can drop the seat down out of your way. back to handlebars, drop bars are what road bikes have. They are the curled handlebars that look like a C from the side. If you lean forward, you can grab them by the \"drops\" and aerodynamically pedal harder. reply ryandrake 18 hours agorootparentprevYea, wow, I know you can go infinitely deep on any topic, but bicycle nerds are a species all their own! Here's how I bought my bicycle, as a total casual: Went to craigslist, typed in \"bicycle\", bought the one that looked to be in good shape for $50. It's lasted me 15 years and the only maintenance I've ever had to do on it was change tire tubes. I don't even know much about it. It says \"Specialized Crossroads\" on it, I guess that's the brand name. reply hi-v-rocknroll 20 hours agoparentprevBack in the day, even on a low-end steel Miyata mountain bike, I had to have QR wheel and QR seat post keyed locks because of theft. They consisted of an epoxy-coated offset plate with a hole at each end and a miniature luggage lock. In general IMO, it's not worth having an expensive bike because it's just going to get ripped-off and likely lacks significant benefit over a middle-market one. (A friend of mine had a $8k USD road bike stolen in downtown Mountain View right in front of every passerby in the busiest area where cops pass every 10 minutes.) Also, the only time I ever forgot to lock my (undersized jacked up with very long seat post and handlebar extensions) Miyata in the rack at home (apartments) in Davis CA was the very time it was stolen. For dry climates: wax lube. Wet lube is only for rainy climates and attracts dust like mad. Chain guard is a must for non-leisure riding. And if you don't like changing tires very often and don't mind the extra free exercise of added rolling resistance, kevlar armor bands are a must have with green snot slime. Still have to carry a vulcanizing patch kit, levers, and a pump because goatheads are pure evil. reply foco_tubi 19 hours agoparentprevThreaded headsets are fine, \"threadless\" bottom brackets are mostly trash and almost entirely non-user serviceable, drop bars and their levers are fine and sometimes better, 2x10 is even cheaper than 2x11 (what's up Tiagra), AL was never uncool except for forks, mostly agree with the rest reply fire_lake 10 hours agorootparentThreaded headsets work, but it’s an inferior design to threadless. There are no advantages to them at all - except maybe aesthetics! The only modern bikes with threaded tend to be low end anyway. Best to avoid! reply AdrianB1 19 hours agorootparentprev> \"threadless\" bottom brackets are mostly trash and almost entirely non-user serviceable Are you including Shimano pressfit BBs here? Never had problems replacing it, not even needed special tools. reply foco_tubi 19 hours agorootparentIf you're not considering a bearing press as a special tool (or you didn't use one) then we exist in different worlds. reply TacticalCoder 19 hours agorootparentprev> \"threadless\" bottom brackets are mostly trash and almost entirely non-user serviceable, Yup I confirm. I'm never buying that again. reply Lwerewolf 21 hours agoparentprev-Rim brakes means ever so slightly bent rim = SOL. -There are some decent internal cable routing setups. The newest fad (through-headset), though... -Comfort has a ton of variables, of which tyre volume/pressure/type/details(inserts/etc) are a major part of, but not the be-all-end-all. Grips, handlebars, saddles, pedals, crank length, etc, etc, etc, etc... reply kjkjadksj 20 hours agorootparentRim breaks are fine for most people. your wheel has to be very very visually out of true to cause problems and thats only a $20 fix at the local bike shop. A little cathunk in the hands during braking never hurt anyone. Source: rode $40 bikes through college. Most of the comfort stuff is not applicable unless you are spending hours and hours in the saddle. You aren’t going to notice the crank arms are too short or your reach is too long commuting 30 mins to work. reply downut 20 hours agorootparentTruing a wheel is something that for 100 years avid cyclists (riding multiple times per week) could do with nothing but a single $3 truing wrench. If you were very poor like me in college you did it by pushing the rim brakes to one side or another and then truing against the rim hitting the pad. We used to do this on the trail, ride mates amiably sitting by why the whacked wheel gets put into \"enough\" true. Nowadays of course I have the whole kit, the Park truing stand, various truing wrenchs... and that's it. Oh right I use painter's tape to mark problematical spokes. I've built three sets of fabulous wheels that take a lot of abuse but let me still set personal records at (say) TdT. Now we get to the flame wars. I've been endurance cycling 50 years, since I was 14 or so. I completely understand the arguments for disc brakes for tandems and touring setups. What the disc brake people are not telling you is that the hand fatigue problem was solved by $40 Avid Single Digit rim brakes 25 years ago. I have a set on my mt bike that are truly single digit sufficient for most rough descents up to say 3000' and maybe an hour. Probably you need to do some exercises if you're doing those and having fatigue. I have been at Moab doing an insane gonzo abusive descent and noticing that hmm might be having safety issues soon with my forearms, and hmm, I need to get this descent done... but that was before the Avid brakes. My 20 yo Specialized frame FrankenBike with Avid SD brakes is not being replaced in I guess forever because it is gonzo abusive ready and it just works. Edit: Oh if anyone has a nice set of used Avid SD brakes I'd really like to replace the way too sensitive Paul sidepull brakes on my gravel bike. I put the dumbest pads possible on them and they're still too sensitive. I'd happily trade if I could fully refurb the functionality of the Avid brakeset. reply hedora 16 hours agorootparentRim brakes suck in the rain. This matters a lot for commuter bikes. I've never heard of the hand fatigue thing. I agree that it sounds like BS. reply fire_lake 13 hours agorootparentHand fatigue is a real issue if doing big off road touring, but that’s not most people. Yes rim brakes are worse in the rain, but they’re not that bad! I wonder if people who say this have tried a modern dual pivot road caliper or decent v-brakes. They have easily enough stopping power for commuting in rain. reply TheTon 19 hours agoparentprevI don’t have many hard rules I follow about specific standards or parts when I shop for a bike, but I do have one guideline I adhere to: I only buy bikes with online tech manuals containing exploded diagrams, dimensions, part numbers, and torque specs. I look through the parts and verify that either the manufacturer has spares available on their web store or that they’re common parts available anywhere. I also look up older models and make sure the manufacturer still has manuals and parts for them too so I have confidence I will still be able to get parts in 5 years or so. reply risenshinetech 20 hours agoparentprevHey guys, follow these 12 SUPER easy tips! - Industry jargon - Industry jargon - Etc etc reply CobaltFire 17 hours agoparentprevI used the Ratio conversion to bring both my old 10 and newer 11 speed SRAM drop bar shifters to 12 speed spec. Highly recommend! https://bikepacking.com/gear/ratio-1x12-upgrade-kit-review/ reply adsteel_ 20 hours agoparentprevRim brakes/pull-brakes/v-brakes are great even for serious off roading, though you may want to upgrade to long caliper pads, which make a world of difference. Disc brakes aren't helpful until you're doing serious downhill. Why everyone has disc brakes these days when they don't need them is a great question. reply ak217 19 hours agorootparentHydraulic brakes have far better power and better power modulation. I think that matters a lot in terms of usability and confidence to a beginner. Especially in rainy weather. reply akvadrako 17 hours agorootparentRim doesn't mean they aren't hydraulic. I have hydraulic rim brakes and agree they give you much more power than cabled ones. reply hi-v-rocknroll 20 hours agorootparentprevRim/v-brakes just need proper adjustment, replacement pads when worn, and clean rims. They're also much easier to control with finesse than disc brakes which tend to lock and require brake fluid and pads service. In rain though, I'd want disc brakes because rim/v-brakes can fade rapidly depending on material and coating of the rim. reply TacticalCoder 19 hours agorootparentprev> Why everyone has disc brakes these days when they don't need them is a great question. The reason I've got disc brakes is because of how precise and pleasant the feeling and feedback in the brake lever is. It's pure bliss. I know it's totally overkill but the to me there's no comparison in how pleasant the brake lever is, so I don't mind paying a bit more. reply dogmatism 18 hours agorootparentprevcarbon rims enough said reply AdrianB1 19 hours agorootparentprevI used to ride a lot in the mountains. Even on roads my disk brakes were blue from heat, rim brakes would simply die or make me die - no, thanks. Rim brakes are perfectly fine for city bikes, many road bikes and light offroad, but not for any long braking - that is not limited to downhill. reply mvdtnz 19 hours agorootparentprevShockingly bad advice. reply unethical_ban 21 hours agoparentprevYou know more than I do about bikes. I've assembled one (except for fork/handlebars) myself and have ridden various styles. My only objection is brakes. If it can fit your budget, mechanical disc is worth the lower maintenance, adjustment, weather resistance over rim brakes. Disc in general have the fringe benefit of being able to swap tire sizes for different purposes. Hydraulic disc are smoother and somewhat more effective, at the expense of money and ease of maintenance. reply kjkjadksj 20 hours agorootparentRim breaks are pretty maintenance free. I just replaced the pads only thing ive done to them in 5 years with this bike. $15 and 2 mins of work. reply AdrianB1 19 hours agorootparentCheck the rims too, when you change the pads there is a chance your rims are very thin and at some point you need to replace it. Not cheap. Mechanical disk brakes are indeed quite good at cost-performance ratio, even if the hydraulic ones are nicer but significantly more expensive. reply unethical_ban 20 hours agorootparentprevMaybe it's a bias due to my rim bikes being historically lower quality. My rims get out of true more than my discs, and cheap-style rim brakes are harder to adjust to even braking. I've never owned high quality rim brakes, that could be the issue. reply TacticalCoder 19 hours agoparentprev> - Any common BB standard (threadless ones are actually fine but require a well made frame, and you’d be surprised how many expensive frames are not well made) I confirm. High-end bicycle here, \"only\" 8 years old. Full carbon (frame and wheels). Bottom bracket is now a bit noisy. I went to a shop only doing that brand and... \"Oh but it's a threadless BB, the company doesn't make that anymore. And because it's a carbon frame, it's too complicated/risky to change it. We suggest you buy a new bicycle\". That'd be on a five digits bicycle supposed to be of the absolute best quality. And, well, it definitely has one of these not well made expensive frame. P.S: had to google the acronyms you used but I suggest everybody here to listen: GP knows what he's talking about. reply foco_tubi 3 hours agorootparentI suggest you find a new shop with better mechanics reply alephxyz 17 hours agorootparentprevAFAIK you can extract the bearings from the bottom bracket with generic tools. So they should've been at least able to regrease or replace those. You can also find custom made bottom brackets online for 2-400€ if it comes down to that. But for an 8yo model from a big manufacturer you can find mass produced ones for a reasonable price. Maybe they just really wanted you to buy a new bike from them. reply jcheng 17 hours agorootparentprevWhat make and model is it? reply bbqfog 20 hours agoparentprevI wouldn't recommend anyone get quick release, thru-axle is so much better. Disc brakes too, it's such a huge upgrade. I'd also say a dropper post if you're doing anything off-road, or maybe even on-road, they're awesome! reply hi-v-rocknroll 20 hours agorootparentUnlocked QR wheels and seats get stolen and vandalized. QR should generally only be used where transportation space is limited or for stationary security, but otherwise prefer permanently-installed ones at the expense of having to carry a wrench with the tire patch kit. reply bbqfog 19 hours agorootparentI can't think of a reason QR is better other than price. I actually find it easier to mount and unmount the wheels with thru-axle. They're not really permanently installed though, so they can be stolen if you know how to take them off. reply hi-v-rocknroll 19 hours agorootparentAnything can be stolen given unreasonable dedication, but that's not the point. The point is to deter by making it not worth messing with. Unlocked QR wheels will be stolen or vandalized in most major US cities in an instant. reply ndriscoll 17 hours agorootparentWhen I was in college, I'd pop the QR front wheel off and chain lock it through the rear wheel+frame+rack. Only took an extra 10 seconds or so, and took less time than it'd take to lock two chains to make sure everything was secured to the rack. reply cutchin 22 hours agoprevI wish they'd have given more examples for traditional bikes than bottom brackets. Yeah, bike shops have to deal with lots of different BBs, but that's because they deal with bikes that might be 30 or 40 years old, from all over the planet. Some threaded, some press-fit, etc. Some high-end, some very cheap. On the most part, bike manufacturers use standardized parts that can be replaced by and end-user with sufficient know-how and the tools to do it. There aren't that many companies making drivetrain parts, so you tend to see Shimano and SRAM just about everywhere, and maybe the odd Campagnolo-equipped bike every now and then. At least here in the US. (Unrelated, Shimano's product range is crazy - somehow their components come stock on bikes ranging from $250 up to $12k or more.) Outside of They don’t make hoods for my old 8spd levers. You should check AliExpress for those. You might be able to find some knock-offs. AE is actually really good for things like this. The other place to check is Ebay, in case someone is selling NOS (new old stock). reply kjkjadksj 1 hour agorootparentI’ve tried both. They don’t make 8spd era hoods they do have some 9spd clones. NOS has n’t existed for years and when it comes up people ask $100 for a set of hoods. reply foco_tubi 19 hours agorootparentprevIf your hoods aren't absolutely disintegrating into goo, a little talc powder goes a long way towards getting rid of the stickiness. reply kjkjadksj 1 hour agorootparentI tried that too. Talc only works for the first time you grip the hoods. If you then take your hands off and regrip you are back to where you started getting black crap everywhere. Tape has been the best solution if a bit ugly. reply jerlam 21 hours agoprevUnfortunately this isn't a new problem. My 20+ year old bike, that doesn't have a single electronic component on it, has a single special crankarm bolt because the crankarm is \"integrated\" with the spider, presumably to shave off a few grams. Four normal bolts and one special bolt that may be hard to find today. A lot of bikes are often designed for racing, the equivalent of exotic cars. So new standards that have very marginal benefits are routinely being created and then abandoned when it gets rejected by the market or there is a new, better standard. But things that are mundane and standard today were cutting-edge when they first came out, and likely emerged from several competing standards. reply abyssin 22 hours agoprevBicycles should be required to be sold with a sheet of all the measurements of replacement parts. I find that buying the correct part is often the biggest hurdle in maintaining my bicycles. reply foco_tubi 3 hours agoparentComplete bicycle manufacturers usually make these specification lists public in online and print catalogs. Component-level repair, as in many other fields, requires more specialized knowledge and a parts list is rarely practical nor helpful. reply gonzo41 21 hours agoparentprevOMG yes. This so much. reply wink 10 hours agorootparentOr just small details like: If you already provide a list of what rim and spokes, maybe add the size of the spoke nipples. Or what model of brake pad. reply mhandley 19 hours agoprevMy daily cycling mostly consists of a mile and a half to the station each way without any serious hills, but my station bike is one we got second-hand for my brother when he was a teenager back in 1980 or so and we repainted it back then, so it's probably over 50 years old. It is the scruffiest bike in the bike shed at the station, which is just the way I want it. But most importantly, just about everything on it still works. It was once a racer with a lightweight steel frame, but I put straight bars on it 20 years ago. It lives outside year round and has done so for 25 years, so it has a nice patina that means thieves always look the other way. A little rust converter every now and then ensures the corrosion looks much worse than it really is. The original pedals finally fell apart a couple of years ago, but replacements were readily available. The front derailier failed and I removed it, so it's a 5-speed now, but that is fine for my use. The saddle has been replaced many times. And the rear wheel needed replacing twice. But it's still on the original chainwheel (!), brakes, rear derailier, shifter and remarkably, front wheel. Headstock bearings and bottom bracket are original too. Anytime I have needed something, the local independent bike shop has it - all the parts are still available. Alongside it at the station are so many nice looking bikes, but chances are mine will outlive all of them and not get stolen either. Anyway, if you're getting a bike as transport, get yourself something used from way back that was a high quality bike back then. Some of them at least were built to last, they're easy to repair, and are still way lighter than most modern bike shaped objects. reply TRiG_Ireland 22 hours agoprevThe science/education podcast Let's Learn Everything had an episode recently about planned obsolescence [1], and it does seem to have started with the bicycle. So this is not new. 1: https://maximumfun.org/episodes/lets-learn-everything/70-the... reply oulipo 22 hours agoparentThis is very intersting! Thanks reply TRiG_Ireland 22 hours agorootparentI've just noticed that the timestamps on the page are clearly from a different episode. The planned obsolescence section actually starts at 57:42. reply wiredfool 22 hours agoprevMeh. There have been Bike Shaped Objects sold at non-bike shops forever. Huffy used to be a complete joke of a bike, but in 1988 the 7-11 team rode \"Huffy\" frames. (which were really Serottas). Yeah, there are a lot of bottom bracket standards, most of them aren't proprietary, they're just different. Bottom brackets are a lot better than they were 40 years ago too -- back then you could pull them apart, replace the balls, repack the grease, and change the cups and spindle. And you had to. Now, you get a cartridge BB or a minimal pair of cups and some standard bearings. My sealed bearings now last a lot better than my cup and cone ones did. Hubs are similar. Cup and cone bearings can be maintained, but they pit, and no one ever really had replacable races. So if your bearings were bad, you replaced the wheel. With better hubs, you just pop out the bearings and pop new ones in. Old school (7-8sp) Shimano jockey wheels _never_ spun freely. Sram 11 speed ones, even on apex, spin beautifully, and in the case of my gravel bike, are outlasting the derailleur. I think we're in kind of a new golden age of cycling. There are tons of interesting bikes being made by small providers, using 3d printing, old school steel fabrication, custom carbon. There are tons of small company parts -- most CNC, but some additive. Basic non BSO components are pretty reliable, and even Shimano's low end isn't that bad for the casual crowd. There's a niche for everything, tracklocross or basket bikes or cargo or gravel or mountain touring or full squish. And there are even road bikes too. iFixit has some good rants, but this isn't one of them. reply acyou 22 hours agoprevLithium ion batteries and battery modules are never ever gonna be user repairable. The main reason is that the electrolyte is a highly toxic, carcinogenic and extremely flammable organic solvent. AAs are user swappable because the electrolyte is water based. Bikes started being less repairable when manufacturers noticed that steel frame 10 speeds were lasting multiple decades. If parts continue to be available, those frames are still going to be in use another 50 years from now. Particularly where cartridge bearings are used. Carbon fiber bikes are part of the trend. Will we eventually see a straight up plastic adult bike frame? reply userbinator 21 hours agoparentLion cell electrolytes are nowhere near as toxic as those of NiCd or lead-acid. Flammability is the biggest risk. Toxicity is comparable to acetone. https://en.wikipedia.org/wiki/Propylene_carbonate https://en.wikipedia.org/wiki/Diethyl_carbonate https://en.wikipedia.org/wiki/Ethyl_acetate reply acyou 21 hours agorootparentYes, but unless you drink the lead acid battery acid, you're not exposed to it. Ditto for NiCd. No one is drinking battery electrolyte. The key is that all of the above in Lithium ion are VOC and highly available, including what you mentioned and worse, specifically NMP. reply allenrb 20 hours agorootparentPeople are talking about replacing cells within packs, not disassembling the cells themselves! reply acyou 20 hours agorootparentAgreed, I apologize that I wasn't more clear. It's just that the electrolyte composition forms the basis of safety. In an environment where end users are handling bare cells, you need to assume the cells are leaky/ruptured. For example, if you have ever changed out old Duracell alkaline batteries, the white stuff on the contacts means they leaked. reply userbinator 20 hours agorootparentprev\"In the US, propylene carbonate is not regulated as a volatile organic compound (VOC) because it does not contribute significantly to the formation of smog and because its vapor is not known or suspected to cause cancer or other toxic effects\" \"Diethyl carbonate is used as a solvent such as in erythromycin intramuscular injections.\" Ethyl acetate: \"The LD50 for rats is 5620 mg/kg,[24] indicating low acute toxicity. Given that the chemical is naturally present in many organisms, there is little risk of toxicity.\" reply acyou 17 hours agorootparentYes, just need to watch out for the ethers, NMP, various other volatile additives. And even worse, the HF. That's the one that melts your bones. Lithium ion electrolyte is extremely hazardous when inhaled. I would not attempt to handle, open or modify cells without engineered ventilation and appropriate training and protection. If a cell is punctured or suspected to be leaking, I would evacuate to fresh air immediately and activate a hazardous substance control team. reply userbinator 17 hours agorootparentIt appears you're far too paranoid for your own good. If by NMP you're referring to https://en.wikipedia.org/wiki/N-Methyl-2-pyrrolidone , \"N-Methyl-2-pyrrolidone is a relatively innocuous compound with an LD50 of 4150 mg/kg (oral, rats).[5] It is non-mutagenic.\" HF is only formed in combustion, but then so are a lot of other more hazardous chemicals. But getting the occasional whiff of electrolyte (which I admit actually has a quite pleasant smell) or having some skin contact from a leaking cell is certainly nothing to worry about. I know plenty of people who regularly work on cars, washed their hands with gasoline and probably came into contact with much worse, yet still lived healthily into their 80s and 90s. reply oulipo 22 hours agoparentprevCheck out what we're building at https://get.gouach.com ! We're solving exactly this problem, and we have designed a fireproof casing for extra safety! Happy to answer any question :) reply acyou 22 hours agorootparentI could see this being interesting if you handle all the aspects of pack teardown, rebuild and recertification, and send out finished packs. Would you be comfortable with doing that and standing behind those 100%? Asking regular people or even highly technical people to assess cell geometry, type, quality, balancing and cell capacity issues is going to result in people dying in fire. It just isn't that easy, even if you start with brand new, matched cells. Fireproof casing sounds great, as long as it's also being charged in a fireproof bunker. Unfortunately, that's not usually the case for consumer products. Noticing that in the video of the cell vent testing - Bosch vs. Gouach the electrical wire harness immediately turns black. If you charge this pack in a box filled with paper and a cell vents, will it start a fire? How are you going to thoroughly test with your production parts before shipping to customers next month? reply oulipo 21 hours agorootparentThanks for all those questions! No we will ship standard cells that we tested the battery with (it is EU-certified, and UL-certification is ongoing) Yes! The battery is quite safe now! We have iterated on the design for close to 4 years now. We have added safeties everywhere so that even a misplaced cell wouldn't be dangerous. And as you mention the fireproof casing is the extra layer of safety, so that if there is an unlikely thermal event, no flames can go out. We've been running those batteries for around 2 years on about 1000 shared mobility e-bikes in France, so we're quite sure of the design! reply acyou 20 hours agorootparentThat's great to hear. UL certification is a starting point. How is that going? What does EU-certified mean with regards to battery safety? I think the sticking point with UL is that you need to know the specific application in order to assess the downstream risks. Are you able to do the UL certification for multiple bikes, or just a specific model? Are you able to get UL certification for multiple different cell brands, or do you need to do a different certification for each type of cells used in the pack? I'm assuming mixed salvaged cells are off the table for UL certification? reply woah 20 hours agoparentprevAAs aren't user repairable either. When was the last time you repaired an AA? What the article is asking for is just a standardized connector and voltage for Li-ion batteries. reply acyou 20 hours agorootparentI misspoke, what I intended to say is that lithium ion batteries are never going to be user swappable. Yes, you can get sketchy stuff off of Amazon that supports it, but the regulatory bodies will, correctly, continue to strongly resist end users touching bare lithium ion cells. Ever drop an AA battery? Nothing happens. Drop an 18650, you can easily have a little 1000 degree rocket shooting fire and toxic chemicals out one end. Nominal cell voltage is fairly standard and is dictated by cell chemistry. Standardized connector is welded zinc tab, for various good safety reasons. reply derkades 21 hours agoparentprevAt least standardized form factors and no complex proprietary communication protocols to the battery would help a lot to make battery replacements more affordable reply mschuster91 20 hours agoparentprev> Bikes started being less repairable when manufacturers noticed that steel frame 10 speeds were lasting multiple decades. Steel frames are heavy beasts. Aluminum alloys, magnesium alloys or carbon fiber is waaaay lighter in contrast, and weight is king at least if you're not running with electrical assistance. It's exactly the same in cars, there we have exactly the same trend towards lighter but more brittle materials. reply AdrianB1 18 hours agorootparentI used to race as an amateur for almost 10 years. I saw people winning on steel frame bikes and for flat terrain the weight of the bike is not that important. Carbon is light indeed, but the frame as a percent of the overall bike can be quite low, as low as 25%. Half a kilo in a 12 kg MTB is insignificant except pro races. reply mschuster91 11 hours agorootparentI'm not necessarily talking about bike races... for commuter bikes that you have to lug up and down stairs into your basement, every gram counts. My e-bike is somewhat around 20 kg, that thing is a tank in its own right, and it's hell to haul around when our beloved Deutsche Bahn once again manages to fuck up elevators. reply loeg 21 hours agoprevThere are many kinds of bottom bracket these days, but like, not that many. BSA is still extremely common and it's looking like T47 (which has two variants) will be the other common standard going forward. BB30, BB86 exist. Other variants are much less common. Essentially the entire rest of the article is about ebikes and proprietary batteries, motors, apps, etc, and yeah, that's all true. I'd probably have just killed the bottom bracket section of this article and had the headline mention ebikes rather than try to generalize. reply foco_tubi 19 hours agoparentWhich major manufacturers are adopting T47? reply fizx 22 hours agoprevI think that's true for e-bikes, but that's perhaps to be expected in a newer market. Over in analog mountain bikes, we have the new UDH standard, and basically everything else was standardized except some bearings. All mountain bikes are pretty modular. The main manufacturers make the frame, and then bolt on parts from different brake, shock, etc suppliers. There's at least two of each, which keeps things competitive. reply taeric 23 hours agoprevCan't get past the intro sentence without getting triggered. No, most people cannot fix a bike. As evidenced by the horrid shape most bikes are in. Heaven help folks that get the brakes so that they need to replace pads. You are as often to see people that ruined rims as you are to see people that did that correctly. Don't get me wrong, there is something there. Everyone can be trained to fix older mechanical things. This is true. And I, for the life of me, cannot understand why people get bikes that need apps to run. That is just baffling. So, change this to \"ebikes are not being designed with repairability in mind\" and I think I lose near all of my complaint. I do have worries about people not realizing how powerful ebikes are. Reminds me of early dirt motorcycles you could work on back in the day. Didn't take too many kids getting hurt before people took those seriously, I don't think. Odd to see us go right back down that path all because a lot of parents assume the battery tech is the same as it was a decade or so ago. reply taylodl 22 hours agoparent> Didn't take too many kids getting hurt before people took those seriously The kids in my neighborhood are zipping around on these things at 30 MPH. In my state it's illegal for these kids to be riding around on these things, but the law isn't being enforced. Probably more of a hassle for the officer than it's worth. And safety? Bwahahahaha! Kids are riding these at 30 MPH in shorts, t-shirt and maybe a bicycle helmet. Just the other day I saw three girls who appeared to be middle school-aged hop on an e-delivery type bike and ride 3 up! All they were wearing were those super short and super thin shorts girls like to wear, and a t-shirt. Not a single helmet. Yet there they were riding 3 up on this e-bike on public streets just after the peak of evening rush hour. It's insane! I'm continually amazed we're not seeing more news stories of kids getting hurt on these things. Don't get me wrong, I'm glad we're not seeing these news stories, but I'm amazed we aren't. reply hotspot_one 21 hours agorootparentI'm wondering what insurance companies are going to say. I have a feeling they will be the driving force at least in the US, since they are the ones picking up the bills. reply taylodl 20 hours agorootparentI'm wondering how the law is going to be applied in the event of an accident. In my state, if you hit a minor riding a bike then you're automatically at-fault and the burden of proof is on you to prove that the accident was unavoidable. Will that same law apply when the kid is operating a motorized vehicle? Especially if they're operating that vehicle illegally? TBF, it hasn't been a problem so hey, maybe these kids have a lot more sense than we give them credit for? Maybe I should just be grateful that those girls were outside playing instead of being in a screen and were feeling a little \"dangerous\" and rode 3 up on an e-bike? reply wink 10 hours agoparentprevUnfortunately I am missing a \"modern\" rim brake bike to confirm I am not going mad, but back in the 90s about half of the time we fixed a flat at the back the shifting was off after that and needed readjusting, and replacing brake pads usually meant fiddling for an hour until everything aligned well again. Compare to any disc brake bike I have owned (bought later than 2010)... everything is super smooth. I just can't believe both my dad and I (when I was teenager) were completely inept and now as an adult I can magically fix bikes. reply ThrowawayTestr 22 hours agoparentprevUnlike car maintenance bike maintenance is way more accessible. You need like one or two specialized tools to cover the majority of the work you'll do on your bike compared to a car. People are just lazy. reply taeric 20 hours agorootparentI think the reality of most people using bikes in rather low stakes situations also changes things heavily. That is, many are riding bikes that I would not trust down a hill going 30+mph. But, notably, most people are not going anywhere close to 30mph on a bicycle. To that end, you are correct that most people are just needing to clean their bike. Replace the occasional consumable part of it, maybe. Keep it clean, though, and you are unlikely to need to replace any parts anytime soon. Edit: And, again, limit this to ebikes and things change pretty rapidly. It is trivial to get an ebike to 25mph. reply sidewndr46 22 hours agorootparentprevExactly what specialized tools do you need to work on a car? Are you counting closed end wrenches and sockets as \"specialized\" or something? reply Ichthypresbyter 21 hours agorootparentWhile it is technically a socket, an oil filter wrench is reasonably specialized in that you won't see it in a standard socket set. Same may be true of a spark plug socket depending on your car. Otherwise, doing routine/basic maintenance on a car, such as changing the oil, requires a means of getting under the car (ramps or jack and stands) and of handling large amounts of fluids (drain pan and funnel) neither of which you need to do the equivalent work on a bike. A torque wrench is much more important for car maintenance than for bike maintenance (and you'll need a bigger one!). Depending on the condition of your car you may want a breaker bar. Obviously doing anything with the suspension requires a spring compressor, and troubleshooting certain engine problems requires a compression tester, but those are needed infrequently enough that they can be rented or borrowed. And that's before getting into the model-specific specialized tools for something like a timing belt change, or anything electronic (though I recommend anyone with a car should get a cheap Bluetooth OBDII reader). reply sidewndr46 20 hours agorootparentYou have a pretty odd definition of \"specialized\". A jack is a jack. Yes, I use a big one for my truck since it weighs many thousands of pounds. I use the same jack to lift small cars and anything else I want, within reason. A torque wrench is a specialized tool...for torquing a fastener. I use the torque wrench to torque fasteners on my truck, my motorcycle, some random piece of equipment I want to repair, etc. I have seal drivers for driving seals on my motorcycle. I also can use them on hydraulic cylinders, or any other random seal I want to drive in. The only truly specialized piece of auto repair tooling I have is a tool that is cast and machined specifically to fit inside the engine head to remove a portion of the valvetrain for maintenance. It's a very boring once you understand how it works, but I'm not using it for anything else. As for a spring compressor, I've been doing suspension work for about a decade now and used one zero times. You just don't need it for routine maintenance. I guess if a spring breaks, you would need it in some weird circumstance possibly. reply Ichthypresbyter 18 hours agorootparentWell yes, I suppose if you also have a motorcycle and a truck and some miscellaneous hydraulic machinery that you work on yourself, then you will also use most of the tools you use for car maintenance to work on other things. For someone who owns a car and nothing else with an internal combustion engine except maybe a lawnmower, most of those tools are only used to work on their car. There are of course also specialized tools you need to work on a bicycle- tire levers and a chain link breaker, for instance. But they're much smaller and cheaper. reply ThrowawayTestr 18 hours agorootparentprevI would consider jacks, seal drivers and oil filter wrenches specialized tools. The only specialized tool you need for a bike is a spoke wrench. reply pandaman 17 hours agorootparent> The only specialized tool you need for a bike is a spoke wrench. And a chain whip, and a lockring bit for brakes/cassette, and another bit for the bottom bracket, and some pin spanners maybe, a derailer alignment gauge, maybe crank puller, tire levers, chain breaker, and master link pliers. Hydraulic brakes? Bleed kit, piston press. Pneumatic suspension? Shock pump. Tubeless? Better get a syringe to refill sealant through valves (and don't forget the valve core wrench) or reset your tires every time you need new sealant. reply ThrowawayTestr 13 hours agorootparentDoes the average person really need all that? An Allen key set and socket wrench kit will get you pretty far. reply pandaman 7 hours agorootparentYou do need all that if you want to perform maintenance on a bike. I assure you that the average person won't be able to replace a cassette, which is a wear item, with an Allen wrench and a socket wrench. Or replace disk brakes, or a chain ring, which are also wear items. I imagine you can use an Allen bit as a lever when you need to access tubes or replace tires (wear items both), but it does have high probability of damaging your rims, which, again will need lockring bits and a chain whip to replace, at least on the rear wheel. Chain is another wear item, I figure you can just hammer out pins with a thin Allen key to cut a new chain and use the same technique to remove the old one but your hammering technique should be very precise to retain the pin, you cannot put them back in once you hammered them out too far, not even with a socket wrench. reply fnfjfk 18 hours agorootparentprevLockring tool for cassette Various BB tools, also for disc brake lockrings Chain whip Bleed kit You can force a missing link with other tools but the dedicated pliers are really much better reply jessekv 21 hours agorootparentprevI gave in and bought a torque wrench recently for my bikes... modern bike components sure are light but they are also really easy to over-tighten. reply aidenn0 21 hours agorootparentprev> jack and stands Manual for my latest car recommends against jacking up under the front axle, so a jack and stands are out for getting underneath it. reply jrmcauliffe 20 hours agorootparentprevHad a mobile mechanic unable to change the timing belt on our 10 y/o Volkswagen Golf because the balancer is now secured with a proprietary lock-ring instead of four hex bolts. He said this sort of thing is getting more common and even if he did want to buy all of the required bits and bobs he wouldn't be able to fit them all in his van. Even in the 'good old days', you weren't getting very far working on your car without things like gear pullers, timing guns and feeler gauges. All things that technically you could be using for other things, but not exactly in the average toolbox of someone that doesn't work on cars. reply sleepybrett 21 hours agorootparentprevI can't change the oil in my ancient '99 passat (very low miles, I barely drive) without a special wrench. reply Lio 22 hours agoprevHmm, I don’t know anything about ebikes but normal bikes seem to be going back to BSA threaded bottom brackets. The last 3 bikes I’ve bought have had BSA. reply soared 22 hours agoprevIm going to disagree - bikes are incredibly more repairable because of e-commerce. I no longer rely on local availability of parts, and lack of documentation when doing repairs. YouTube has infinite knowledge and Amazon/walmart ship literally any part to my door. Bottom bracket as an example I don’t think is fair - I’m an avid cyclist and have never once heard of anyone working in their bottom bracket. Chain, derailleur, cranks/pedals, brakes, handlebars, seat, etc are all very reasonable to do but bottom brackets everyone takes to a shop. Additionally, shop prices (at least in Denver) are absolutely disgusting. A brake pad is $15 in my lbs, but the same one is $6 online direct from the mfg. maybe 2 minutes of labor to repair, but the shop will charge $75 minimum. I was quoted $130 for a chain replacement when I went in to get my recalled cranks replaced. reply thefaux 21 hours agoparentI'm not saying these prices aren't painful, but I am pretty sure there are very few bike shop owners, let alone employees, with enviable wealth. reply oulipo 22 hours agoparentprevIt's true for mechanical bikes! For e-bikes, some manufacturers try to lock users down with DRM. And the last part that's hard to repair is the battery! But at Gouach (disclaimer: I'm one of the co-founder), we really wanted to provide a way for people and company fleets to have observability and agency over their batteries, so we've designed (took us 2 years haha) a repairable battery that's working very well now! You need nothing but a screwdriver. Added benefit is that you can now decentralize production and repair: any shop can produce small batches of batteries, or repair them, without complex equipment or specialized training! reply anthomtb 20 hours agoparentprevI replaced my own bottom bracket! Ok well, first I destroyed the threads on the cranks meant to interface with the bottom bracket tool. Thus requiring a shop visit. And the shop, after consulting with the frame manufacturer, cut the destroyed cranks off with an angle grinder (and posted a video to their Facebook page - you don't usually see that many sparks in a bike shop). But hey, I now have a nice, let-the-pros-do-this-job souvenir (the wrecked cranks). And my bracket/bearings are creak-free and spinning quite nicely three years later. reply ljf 22 hours agoparentprevYeah I've only ever had to use my bottom bracket tool twice in 20 years of cycling, wasn't so hard to do (moving from a cracked frame to a new one once, and replacing a bottom bracket that had gone in a bmx) - but I doubt most people would try to diy it - it just so happened that I had the tool in my 'every tool you might ever need' kit from China. reply renewiltord 21 hours agorootparentI've replaced a couple and the conclusion is that this definitely has economies of scale since you will very rarely use the tool. Better to go take it to a bike shop. It wasn't hard once I had the tools, but I'm not going to use the tools that often. And I'm more likely to lose the bottom bracket adapter tool than reuse it, if I'm being honest. reply ljf 12 hours agorootparentTotally agree - despite having most bike tools I might need, I'd watch friends time and again pay over £100 for a new chain fitted and maybe a minor 'service' if they were lucky in London. I'd offer to either loan them the tools, make the fix or walk through the processes, but to many people it just feels impossible to start taking a bike apart. The only reason I learnt is that I am tight/cheap and a massive set of (OK) tools was far less than a single trip to the lbs. reply criddell 22 hours agoparentprev> shop prices are absolutely disgusting Do you think they are high because that's what it takes to pay for labor and rent, or are they high because the owners are greedy and are getting rich? reply soared 20 hours agorootparentSimply high from a consumers perspective. Some shops certainly are greedy (PE owned, multiple locations, like evo). But for the truly lbs I don’t know the cause. reply selimthegrim 22 hours agoparentprevOften times community bike shops will have tools to let you fix one. It is a kind of once in a decade repair though. reply fragmede 22 hours agoparentprevthe online direct business doesn't have to pay rent for a shop space in an accessible part of Denver though, which is why downtowns can't compete on price reply foco_tubi 19 hours agoprevThis mostly seems to be a complaint about e-bikes and batteries. Almost all major manufacturers are still making mostly user-repairable bikes for recreational riding and commuting. From nearly a decade of bike industry experience, I can say that most people should not be doing their own repairs, or should at least have someone check their work. Lack of experience, shoddy mechanical aptitude, and poor attention to detail can all add up quickly to missing teeth and broken bones, or worse. reply idunnoman1222 22 hours agoprevOpinionated solution; always buy used never buy electric. There are enough steel frames in the world that we probably never need to manufacture another one. reply swayvil 22 hours agoprevSpeaking as an ex bicycle repair man, this irks and/or boggles me. I feel trolled. I mean, I doubt the veracity of this headline and I think they're making shit up. Bicycles are beautifully fixable and tweakable. Back at the shop we had hundreds of old bikes and half-bikes and hills of parts. Our power was vast and we were a wellspring of goodness. Our reputation was international. My boss was a master spoked wheel tuner. I can smell it now. reply foco_tubi 18 hours agoparentParliament breaks between coats of Mastik...yeah, sometimes I think I miss that smell, but I don't. reply m463 22 hours agoprevever think the government should (externally) tax non-repairable stuff? Sort of like gas-guzzler taxes? reply glaucon 21 hours agoparentI'm not necessarily disagreeing, but what does \"(externally)\" mean ? A tariff ? In large enough trading blocs I would be concerned that manufacturing of the non-repairable part would just move within the bloc. I'm in favour of the idea but the mechanism might need some thought. reply m463 18 hours agorootparentSorry, I was thinking outside the whole corporate tax system. Tax stuff as it is sold, like gas taxes happen at point-of-sale. I suspect subsidies and corporate taxes and the rest are a convoluted mess that might not serve people as well. reply idunnoman1222 22 hours agoparentprevWho decides if it’s repairable? reply m463 22 hours agorootparentEven a small start would be useful, like \"user-replacable battery\". not bike related, but say airpods would fail, 12v car battery would pass. reply idunnoman1222 21 hours agorootparentDoes that mean a removable battery because who is to say that your bikes brand of batteries is going to be available for purchase tomorrow? reply m463 20 hours agorootparentopen standard battery > standard battery > removable proprietary battery > glued-in phone battery > whatever airpods do reply hedora 15 hours agorootparentprevMandate a ten year warranty that covers labor but (maybe) not parts. reply pessimizer 19 hours agoparentprevI don't. I think they should force people to redesign if things are unnecessarily non-repairable, and in some cases subsidize that redesign. The government should also create standards (including standard component designs) that automatically pass the product if adhered to. If we're going to be officially judging what is repairable and not repairable, we should commit to dealing with it fully rather than half-assing and leaving infinite loopholes. reply oulipo 22 hours agoparentprevGreat idea! reply jacknews 7 hours agoprev\"This makes it all the more important that we have legislation to force them to make proprietary parts available for riders to buy themselves\" Of course this should be the case, but even then I'm not sure it would help, as they will simply make the spare parts so costly that it's uneconomical. Maybe there should be a 'standardization' score, somewhat like energy efficiency scores, that could then be mandated. Or mandate that parts interfaces must be documented and published as standards, and be free and open for competitors. The basic problem is that almost the whole of business has discovered or decided that their reason for existence is to get money out of people, and that providing the best products and services they can is merely incidental and not actually necessary, especially if they all play the same game. reply mvdtnz 19 hours agoprevI have no respect for e-bikes and couldn't care less about how they're constructed, but I ride mountain bikes and a return to standardisation is a big theme of the newer generation of MTB. People are shunning brands that ship proprietary crap in favour of universal parts and sizes. reply ToucanLoucan 23 hours agoprevUnregulated markets trend towards brand lock-ins, proprietary parts, cheaper goods of inferior quality, etc. etc. etc. All businesses are doing this everywhere because we are running out of World for them to expand into, but any company that posts a less profitable quarter is presumed to be failing. For centuries companies have chased the fantasy of infinite growth, and we're running out of room. If we don't start contending with this in a serious way, and applying changes to our society to accommodate it, we will only ever see more of this. reply nickff 22 hours agoparentThere are lots of counter-examples to this, such as the market for microprocessors. Huge market, few regulations, excellent quality, remarkably low switching costs. reply ToucanLoucan 22 hours agorootparent\"Huge\" market? AMD and Intel. Technically Apple but they don't sell to OEM's, and of course bespoke processors for specific applications. It's huge in that it does a lot of business, but the market itself is incredibly small. If you want a processor for your next PC build, you have 2 flavors to pick from. Or a Mac. reply nickff 19 hours agorootparentYou're ignoring all the non-desktop/laptop processors. reply ToucanLoucan 19 hours agorootparentThat's true! So Qualcomm. Four whole firms, clearly invalidating my point. reply nickff 16 hours agorootparentST Micro, Microchip, Texas Instruments, NXP, etc. reply whalesalad 22 hours agoprev [–] Bikes have sucked for a long time and they just seem to be getting worse. Even a bike that costs $5k+ will inevitably fall apart. I find that if you are a real serious cyclist the best option is to buy your own frame and then build your own rig with bespoke parts. reply burningChrome 22 hours agoparentI've bought a lot of bikes in my lifetime and only twice have I opted to build a bike from scratch. Both times I was working on a bike shop. It was really the second time when one of our dealers had a \"bike shop deal\" where you could get a frame/fork setup for like $300. The Fox fork on the frame was worth around $700 so it was a really good deal. The one thing I realized right away was all the stuff you take for granted on complete bikes that add up super quick. Oh you got some sweet disc brakes? You need brake lines, and brake fluid and have to know to set them up and bleed the lines, and you need brake levers. Oh, nice wheel set, you need tires as well, and you have to get the wheels trued before you put them on. You need a crank set, and pedals, and a chain and handlebars and a proper stem and grips and the list just goes on and on. It took me about three months to get all the parts together. I kept everything in the box at the shop, in the basement. Once I got everything together, myself and two mechanics who love building bikes, sat around the shop putting it all together which took quite a while. It was a pretty big wakeup call that yes, you can build a bike from scratch, but you also need a huge amount of knowledge and patience to put it all together. Even after I had put my bike together, it took several attempts to get the disc brakes dialed in which I've never had to deal with on a floor model. Same thing with the drivetrain and getting both derailleurs dialed in. reply thefaux 21 hours agorootparentBuilding a road bike with a threaded bottom bracket, rim brakes and pre built brakes really isn't that bad. I was pretty unexcited when disc brakes were introduced to road bikes due to the increased maintenance burden. reply foco_tubi 19 hours agorootparentDisc brakes make sense if you're riding hilly terrain or racing, but are otherwise overkill. They do have their place though, there's a particular descent around here that tends to melt carbon rim braking surfaces. reply adgjlsfhk1 21 hours agoparentprev [–] A $5k bike will fall apart way more quickly than a $1k to $2k bike. The only reason to get a $5k bike is if you are trying to win a race and have other people to do the maintenance for you. The lower end (but not absolute cheapest) parts are generally more reliable since they aren't nearly as weight optimized. reply infecto 19 hours agorootparentMaybe? I am not really sold on bikes falling apart. They all have consumables. It’s no different than a car. Sure there are some hyper specific frame styles, thinking of you tri bikes, but beyond that they don’t feel less repairable. reply foco_tubi 19 hours agorootparentprev [–] Yes, bikes built with race equipment need to be maintained like race equipment. Don't buy a $5k bike (or a Porsche) if you are going to complain about maintenance intervals. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bike manufacturers are increasingly using proprietary parts in e-bikes, making them less repairable and pushing consumers towards purchasing new models instead of repairing existing ones.",
      "This trend contributes to increased electronic waste (e-waste) and challenges the sustainability of e-bikes as a transport option, similar to practices seen in the automotive and electronics industries.",
      "Potential legislative measures and initiatives like the Infinite Battery aim to promote more repairable solutions and ensure the availability of parts for self-repair."
    ],
    "commentSummary": [
      "Bike manufacturers are increasingly using proprietary parts and designs, making e-bikes less repairable and contributing to planned obsolescence.",
      "Gouach is innovating by developing repairable e-bike batteries that can be assembled with just a screwdriver, and they are contemplating open-sourcing part of their software.",
      "The conversation highlights the complexity of bike repairs, including various bottom bracket standards, and the challenges of maintaining modern e-bikes."
    ],
    "points": 200,
    "commentCount": 197,
    "retryCount": 0,
    "time": 1728934023
  },
  {
    "id": 41841366,
    "title": "Splitting engineering teams into defense and offense",
    "originLink": "https://www.greptile.com/blog/how-we-engineer",
    "originBody": "I’m Daksh, one of the co-founders of Greptile. We build AI that understands large codebases, which you can query via an API. Large software teams use it for things like AI-powered code reviews and diagnosing root causes for outages. We are a team of 4 engineers. Our customers are often surprised to learn this, since they assume we must be much larger given the breadth of our product. While this is flattering, the truth is that our product is covered in warts, and our “lean” team is more a product of our inability to identify and hire great engineers, rather than an insistence on superhuman efficiency. The result is that our product breaks more often than we’d like. The core functionality may remain largely intact but the periphery is often buggy, something we expect will improve only as our engineering headcount catches up to our product scope. Nevertheless, the reason we get anything done at all in these circumstances has to do with a specific way in which we structure our engineering team. Event-driven vs. long-running processes 15 years ago, Paul Graham wrote about the “maker vs. manager schedule”, the idea that makers, such as software developers, were different from managers in that they need long, uninterrupted hours to build great things. This essay resonated with engineers around the world who had been trying to squeeze their work in between endless mandatory meetings, and probably led to some sweeping changes at least at software-driven companies in favor of creating a “maker-schedule” for engineers. Small startups don’t suffer from an excess of meetings and instead have a whole different problem. Customers! Without dedicated technical support teams and usually with immature products, engineers take on a lot of support work - from hotfixes to building small features for large customers, to just helping customers navigate their products. With enough customers, there is very little time to build new features and make ambitious, complex changes to the codebase. The engineering work that comes from customers, whether it is general support, bug fixes, or small modifications can be considered “event-driven” engineering. The engineering work that includes longer-term (more than a week), ambitious projects, can be considered “long-running” engineering. These two are at odds. The fortress Our solution to this problem has been simple, but so far, effective. This is not meant to be prescriptive. Every engineering team is different. We instruct half the team (2 engineers) at a given point to work on long-running tasks in 2-4 week blocks. This could be refactors, big features, etc. During this time, they don’t have to deal with any support tickets or bugs. Their only job is to focus on getting their big PR out. The other half of engineers must simply protect the first two from any support work, bugs, etc. Their job is to maintain a fortress around the long-running processes, by catching all the event-driven engineering work. At the end of the cycle, we swap. Why this works Remarkable things happen when you take distractions away from a craftsperson. They can spend more time in flow and keep a large amount of context on the “client-side” of their brains. Critically, it takes only 1-2 short interruptions to dramatically reduce the amount of work an engineer can do in a day. This chart sums it up well. Impact of interruptions on developer productivity It follows then that it’s far more useful to isolate interruptions to a few people rather than disperse them to “keep everyone productive”. If you’re spending some amount of time on support, incrementally more time spent on support will not affect your productivity much. The impact of interruptions on productivity Defense/Offense engineering A mental model that I have found useful is to view event-driven engineering as “defensive” and long-running processes as “offensive”. This tracks nicely to the effect that each has. Defensive engineering exists to maintain your product, whereas offensive engineering exists to expand it. Defensive engineering more strongly correlates with your retention and customer satisfaction, whereas offensive engineering arguably correlates a little more strongly with your ability to acquire new customers. Disclaimer Not only am I not a professional engineering manager, this is also a very specific and usually ephemeral situation - a small team running a disproportionately fast growing product in a hyper-competitive and fast-evolving space. This is not advice, but rather an observation about how we run our engineering team.",
    "commentLink": "https://news.ycombinator.com/item?id=41841366",
    "commentBody": "Splitting engineering teams into defense and offense (greptile.com)176 points by dakshgupta 22 hours agohidepastfavorite116 comments glenjamin 7 hours agoHaving a proportion of the team act as triage for issues / alerts / questions / requests is a generally good pattern that I think is pretty common - especially when aligned with an on-call rotation. I've done it a few times by having a single person in a team of 6 or 7 do it. If you're having to devote 50% of your 4-person team to this sort of work, that suggests your ratios are a bit off imo. The thing I found most surprising about this article was this phrasing: > We instruct half the team (2 engineers) at a given point to work on long-running tasks in 2-4 week blocks. This could be refactors, big features, etc. During this time, they don’t have to deal with any support tickets or bugs. Their only job is to focus on getting their big PR out. This suggests that this pair of people only release 1 big PR for that whole cycle - if that's the case this is an extremely late integration and I think you'd benefit from adopting a much more continuous integration and deployment process. reply wavemode 6 hours agoparent> This suggests that this pair of people only release 1 big PR for that whole cycle I think that's a too-literal reading of the text. The way I took it, it was meant to be more of a generalization. Yes, sometimes it really does take weeks before one can get an initial PR out on a feature, especially when working on something that is new and complex, and especially if it requires some upfront system design and/or requirements gathering. But other times, surely, one also has the ability to pump out small PRs on a more continuous basis, when the work is more straightforward. I don't think the two possibilities are mutually exclusive. reply Kinrany 4 hours agorootparentI thought that at first, but the article literally says \"getting their big PR out\". reply DanHulton 3 hours agorootparentYeah, but again you might be being too literal. You could get a half dozen \"big PRs\" out in a month or so, but you'd still want to be able to just focus on \"getting your (current) big PR out\", you know? The important part is that you're not interrupted during your large-scale tasks, not the absolute length of those tasks. reply Kinrany 1 hour agorootparentThat's fair: even if their team has a problem with PR size, this doesn't have all that much to do with the pattern the article describes. reply The_Colonel 6 hours agoparentprev> This suggests that this pair of people only release 1 big PR for that whole cycle - if that's the case this is an extremely late integration I don't think it suggests how the time block translates into PRs. It could very well be a series of PRs. In any case, the nature of the product / features / refactorings usually dictates the minimum size of a PR. reply marcinzm 6 hours agorootparent> In any case, the nature of the product / features / refactorings usually dictates the minimum size of a PR. Why not split the big tickets into smaller tickets which are delivered individually? There's cases where you literally can't but in my experience those are the minority or at least should be assuming a decently designed system. reply The_Colonel 6 hours agorootparent> Why not split the big tickets into smaller tickets which are delivered individually? Because it is already the smallest increment you can make. Or because splitting it further would add a lot of overhead. > There's cases where you literally can't but in my experience those are the minority I think in this sentence, there's a hidden assumption that most projects look like your project(s). That's likely false. reply marcinzm 6 hours agorootparent> I think in this sentence, there's a hidden assumption that most projects look like your project(s). That's likely false. You left out the part of that quote where I explained my assumption very clearly: A decently designed system. In my experience if you cannot split tasks intoYou left out the part of that quote where I explained my assumption very clearly: A decently designed system. That's one possible reason. Sometimes software is designed badly from the ground up, sometimes it accumulates a lot of accidental complexity over years or decades. Solving that problem is usually out of your control in those cases, and only sometimes there's a business driver to fix it. But there are many other cases. You have software with millions of lines of code, decades of commit history. Even if the design is reasonable, there will be a significant amount of both accidental and essential complexity - from certain size/age you simply won't find any pristine, perfectly clean project. Implementing a relatively simple feature might mean you will need to learn the interacting features you've never dealt with so far, study documentation, talk to people you've never met (no one has a complete understanding either). Your acceptance testing suite runs for 10 hours on a cluster of machines, and you might need several iterations to get them right. You have projects where the trade-off between velocity and tolerance for risk is different from yours, and the processes designed around it are more strict and formal than you're used to. reply skydhash 2 hours agorootparentAnd also you have to backport all the changes that have been made on the main branch. Especially for upgrading or stack switching tasks. reply ozim 2 hours agorootparentprevTicket can have multiple smaller PRs. Lots of time it is true that ticket == pr but it is not the law. It sometimes makes sense to separate subtasks under a ticket but that is only if it makes sense in business context. reply codemac 2 hours agoparentprev> extremely late integration That's only late if there are other big changes going in at the same time. The vast majority of operational/ticketing issues have few code changes. I'm glad I had the experience of working on a literal waterfall software project in my life (e.g. plan out the next 2 years first, then we \"execute\" according to a very detailed plan that entire time). Huge patches were common in this workflow, and only caused chaos when many people were working in the same directory/area. Otherwise it was usually easier on testing/integration - only 1 patch to test. reply yayitswei 1 hour agoparentprevA PR that moves the needle is worth 2-4 weeks or more. Small improvements or fixes can be handled by the team on the defense rotation. reply marcinzm 7 hours agoparentprevThat's also been my experience. It's part time work for a single on call engineer on a team of 6-8. If it's their full time work for a given sprint then we have an urgent retro item to discuss around bug rates, code quality and so on. reply cutemonster 4 hours agorootparentMight be quick nice-to-have features too (not only bugs) reply solatic 12 hours agoprevThis pattern has a smell. If you're shipping continuously then your on-call engineer is going to be fixing the issues the other engineers are shipping, instead of those engineers following up on their deployments and fixing issues caused by those changes. If you're not shipping continuously, then anyway customer issues can't be fixed continuously, and your list of bugs can be prioritized by management with the rest of the work to be done. The author quotes maker vs. manager schedules, but one of the conclusions of following that is that engineers don't talk directly to customers, because \"talking to customers\" is another kind of meeting, which is a \"manager schedule\" kind of thing rather than a \"maker schedule\" kind of thing. There's simply no substitute for Kanban processes and for proactive communication from engineers. In a small team without dedicated customer support, a manager takes the customer call, decides whether it's legitimately a bug, creates a ticket to track it and prioritizes it in the Kanban queue. An engineer takes the ticket, fixes it, ships it, communicates that they shipped something to the rest of their team, is responsible for monitoring it in production afterwards, and only takes a new ticket from the queue when they're satisfied that the change is working. But the proactive communication is key: other engineers on the team are also shipping, and everyone needs to understand what production looks like. Management is responsible for balancing support and feature tasks by balancing the priority of tasks in the Kanban queue. reply thih9 11 hours agoparent> on-call engineer is going to be fixing the issues the other engineers are shipping, instead of those engineers following up on their deployments and fixing issues caused by those changes Solution: don’t. If a bug has been introduced by the currently running long process, forward it back. This is not distracting, this is very much on topic. And if a bug is discovered after the cycle ends - then the teams swap anyway and the person who introduced the issue can still work on the fix. reply pnut 4 hours agoparentprevWe came to this conclusion from a different direction - feature implementation teams are focused on subdomains, but defensive teams are spread across the entire ecosystem. Additionally, defensive devs have brutal SLAs, and are frequently touching code with no prior exposure to the domain. They got known as \"platform vandals\" by the feature teams, & we eventually put an end to the separation. reply cutemonster 3 hours agorootparentThat sounds interesting (\"platform vandals\" and your solution). At what type of software company do you work? About how many are you, what type of product, if I can ask? reply dakshgupta 12 hours agoparentprevThis is a real shortcoming, the engineers that ship feature X will not be responsible for the immediate aftermath. Currently we haven’t seen this hurt in practice, probably because we are very small and in-person, but you might be correct and it would then likely be the first thing that breaks about this as our team grows. reply safety1st 11 hours agorootparentI commented a while back on another post about a company I worked at which actually made developers spend a few days a year taking tech support calls. This takes their responsibility for and awareness of the aftermath of their work to a whole new level and from my perspective was very effective. Could be an alternate route to address the same problem. reply crabmusket 6 hours agorootparentprevWe often plan projects in release stages including a limited alpha to a few customers who are interested in a feature. We expect that during the alpha period, the developer who worked on the feature will need to make changes and address feedback from the users. And the same after a general release. We have longer rotations than yours so there is usually time to schedule this in around feature releases before that developer is responsible for general defensive work. reply ryukoposting 48 minutes agoprevI can't be the only one who finds the graphics at the top of this article off-putting. I find it hard to take someone seriously when they plaster GenAI slop across the top of their blog. That said, there's some credence to what the author is describing. Although I haven't personally worked under the exact system described, I have worked in environments where engineers take turns being the first point of contact for support. In my experience, it worked pretty well. People know your bandwidth is going to be a bit shorter when you're on support, and so your tasks get dialed back a bit during that period. I think the author, and several people in the comments, make the mistake of assuming that an \"engineer on support\" necessarily can fix any given problem they are approached with. Larger firms could allocate a complete cross-functional team of support engineers, but this is very costly for small outfits. If you have mobile apps, in-house hardware products and/or integrations with third-party hardware, it's basically guaranteed that your support engineer(s) will eventually be given a problem that they don't have the expertise to solve. In that situation, the support engineer still has the competencies to figure out who does know how to fix the problem. So, the support engineer often acts more as a dispatcher than a singular fixer of bugs. Their impact is still positive, but more subtle than \"they fix the bugs.\" The support engineer's deep system knowledge allows them to suss out important details before the bug is dispatched to the appropriate dev(s), thereby minimizing downtime for the folks who will actually implement the fix. reply dakiol 21 hours agoprevI once worked for a company that required from each engineer in the team to do what they called “firefighting” during working hours (so not exactly on-call). So for one week, I was triaging bug tickets and trying to resolve them. These bugs belonged to the area my team was part of, so it affected the same product but a vast amount of micro services, most of which I didn’t know much about (besides how to use their APIs). It didn’t make much sense to me. So you have Joe punching code like there’s no tomorrow and introducing bugs because features must go live asap. And then it’s me the one fixing stuff. So unproductive. I always advocated for a slower pace of feature delivery (so more testing and less bugs on production) but everyone was like “are you from the 80s or something? We gotta move fast man!” reply onion2k 12 hours agoparentThis sort of thing is introduced when the number of bugs in production, especially bugs that aren't user-facing or a danger to data (eg 'just' an unhandled exception or a weird log entry), gets to a peak and someone decides it's important enough to actually do something about it. Those things are always such a low priority that they're rarely dealt with any other way. In my experience whenever that happens someone always finds an \"oh @#$&\" case where a bug is actually far more serious than everyone thought. It is an approach that's less productive than slowing down and delivering quality, but it's also completely inevitable once a team/company grows to a sufficient size. reply dakshgupta 21 hours agoparentprevThis is interesting because it’s what I imagine would happen if we scaled this system to a larger team - offense engineers would get sloppy, defensive engineers would get overwhelmed, even with the rotation cycles. Small, in-person, high-trust teams have the advantage of not falling into bad offense habits. Additionally, a slower shipping pace simply isn’t an option, seeing as the only advantage we have over our giant competitors is speed. reply jedberg 20 hours agorootparent> offense engineers would get sloppy Wouldn't they be incentivized to maintain discipline because they will be the defensive engineers next week when their own code breaks? reply dakshgupta 20 hours agorootparentI suspect as the company gets larger time between defensive sprints will get longer, but yes, for smaller teams this is what keeps quality high, you’ll have to clean up your own mess next week. reply DJBunnies 21 hours agoparentprevI think we’ve worked for the same org reply resonious 10 hours agoparentprevI honestly don't really like the \"let's slow down\" approach. It's hard for me to buy into the idea that simply slowing down will increase product quality. But I think your comment already contains the key to better quality: close the feedback loop so that engineers are responsible for their own bugs. If I have the option of throwing crap over the wall, I will gravitate towards it. If I have to face all of the consequences of my code, I might behave otherwise. reply isametry 9 hours agorootparentSlow is smooth, smooth is fast? reply smoothisfast2 3 hours agorootparentprevSlowing down doesn't mean going slow. There's more to software development than vomiting out lines of code as quickly as possible. reply no_wizard 2 hours agorootparent>Slowing down doesn't mean going slow. There's more to software development than vomiting out lines of code as quickly as possible. Tell that to seemingly every engineering manager and product manager coming online over the last 8-10 years. I first noticed in 2016 there seemed to be a direct correlation between more private equity and MBA's getting into the field and the decline of software quality. So now you have a generation of managers (and really executives) who know little of the true tradeoffs between quality and quantity because they only ever saw success pushing code as fast as possible regardless of its quality and dealing with the aftermath. This lead them to promotions, new jobs etc. We did this to ourselves really, by not becoming managers and executives ourselves as engineers. reply Attummm 6 hours agoprevWhen you get to that stage, software engineering has failed fundamentally. This is akin to having a boat that isn't seaworthy, so the suggestion is to have a rowing team and a bucket team. One rows, and the other scoops the water out. While missing the actual issue at hand. Instead, focus on creating a better boat. In this case, that would mean investing in testing: unit tests, integration tests, and QA tests. Have staff engineers guide the teams and make their KPI reducing incidents. Increase the quality and reduce the bugs, and there will be fewer outages and issues. reply ericmcer 3 hours agoparentYou are viewing it like an engineer. From a business perspective if you can keep a product stable while growing your user base until you become an attractive acquisition target then this is a great strategy. Sometimes as an engineer I like the frantically scooping water while we try to scale rapidly because it means leaderships vision is to get an exit for everyone as fast as possible. If leadership said \"lets take a step back and spend 3 months stabilizing everything and creating a testing/QA framework\" I would know they want to ride it out til the end. reply Attummm 1 hour agorootparentI think you're not following what I tried to convey. It shouldn't have ever come to the point where incidents, outages, and bugs have become prominent enough to warrant a team. Either have kickass dev(s), although improbable, thus the second level: Implement mitigations, focus on testing, and have staff engineers with KPIs to lower incidents. Give them them the space but be prepared to let them go if incidents don't go down. There is no stopping of development. Refactoring by itself doesn't guarantee better code or fewer incidents. But don't allow bugs, or known issues, as they can be death by thousand cuts. The viewpoint is from not an engineer. Having constant incidents doesn't show confidence or competence to investors and customers. As it diverts attention from creating business value into firefighting, which has zero business value and is bad for morale. Thus, tech investment rather than debt always pays off if implemented right. reply lucasyvas 4 hours agoparentprev> When you get to that stage, software engineering has failed fundamentally. Agreed - this is a survival mode tactic in every company I’ve been when it’s happened. If you’re permanently in the described mode and you’re small sized, you might as well be dead. If mid to large and temporary, this might be acceptable to right the ship. reply kqr 3 hours agoparentprevWait, are you saying well-managed software development has no interrupt-driven work, and still quickly and efficiently delivers value to end users? How does one get to that state? reply stopachka 20 hours agoprev> While this is flattering, the truth is that our product is covered in warts, and our “lean” team is more a product of our inability to identify and hire great engineers, rather than an insistence on superhuman efficiency. > The result is that our product breaks more often than we’d like. The core functionality may remain largely intact but the periphery is often buggy, something we expect will improve only as our engineering headcount catches up to our product scope. I really resonate with this problem. It was fun to read. We've been tried different methods to balance customers and long-term projects too. Some more ideas that can be useful: * Make quality projects an explicit monthly goal. For example, when we noticed our the edges in our surface area got too buggy, we started a 'Make X great' goal for the month. This way you don't only have to react to users reporting bugs, but can be proactive * Reduce Scope Sometimes it can help to reduce scope; for example, before adding a new 'nice to have feature', focus on making the core experience really great. We also considered pausing larger enterprise contracts, mainly because it would take away from the core experience. --- All this to say, I like your approach; I would also consider a few others (make quality projects a goal, and cut scope) reply cutemonster 39 minutes agoparent> Make quality projects .. can be proactive What are some proactive ways? Ideally that cannot easily be gamed? I suppose test coverage and such things, and an internal QA team. What I thought the article was about (before having read it) was having half of the developers do red team penetration testing, or looking for UX bugs, of things the other half had written. Any more ideas? Do you have any internal definitions of \"a quality project\"? reply ntarora 1 hour agoprevOur team ended up having the oncall engineer for the week also work primarily on bug squashing and anything that makes support easier. Over time the support and monitoring becomes better. Basically dedicated tech debt capacity, which has worked well for us. reply fryz 22 hours agoprevNeat article - I know the author mentioned this in the post, but I only see this working as long as a few assumptions hold: * avg tenure / skill level of team is relatively uniform * team is small with high-touch comms (eg: same/near timezone) * most importantly - everyone feels accountable and has agency for work others do (eg: codebase is small, relatively simple, etc) Where I would expect to see this fall apart is when these assumptions drift and holding accountability becomes harder. When folks start to specialize, something becomes complex, or work quality is sacrificed for short-term deliverables, the folks that feel the pain are the defense folks and they dont have agency to drive the improvements. The incentives for folks on defense are completely different than folks on offense, which can make conversations about what to prioritize difficult in the long term. reply dakshgupta 21 hours agoparentThese assumptions are most likely important and true in our case, we work out of the same room (in fact we also all live together) and 3/4 are equally skilled (I am not as technical) reply eschneider 22 hours agoprevIf the event-driven 'fixing problems' part of development gets separated from the long-term 'feature development', you're building a disaster for yourself. Nothing more soul-sucking than fixing other people's bugs while they happily go along and make more of them. reply dakshgupta 21 hours agoparentThere is certainly some razor applied on whether a request is unique to one user or is widely requested/likely to improve the experience for many users reply toolslive 1 hour agoprevThe proposed strategy will work, as will plenty of others, because it's a small team. That is the fundamental reason. Small teams are more efficient. So if you're managing a team of 10+ individuals: split them in 2 teams and keep them out of each other's way/harm. reply jedberg 22 hours agoprev> this is also a very specific and usually ephemeral situation - a small team running a disproportionately fast growing product in a hyper-competitive and fast-evolving space. This is basically how we ran things for the reliability team at Netflix. One person was on call for a week at a time. They had to deal with tickets and issues. Everyone else was on backup and only called for a big issue. The week after you were on call was spent following up on incidents and remediation. But the remaining weeks were for deep work, building new reliability tools. The tools that allowed us to be resilient enough that being on call for one week straight didn't kill you. :) reply dakshgupta 21 hours agoparentI am surprised and impressed a company at that scale functions like this. We often internally discuss if we can still doing this when we’re 7-8 engineers. reply jedberg 21 hours agorootparentI think you're looking at it backwards. We were only able to do it because we had so many engineers that we had time to write tools to make the system reliable enough. On call for a week at a time only really works if you only get paged at night once a week max. If you get paged every night, you will die from sleep deprivation. reply dmoy 13 hours agorootparentMoving from 24/7 oncall to 12 hour shifts trading off with another continent is really nice reply cgearhart 21 hours agoprevThis is often harder at large companies because you very rarely make career progress playing defense, so it becomes very tricky to do it fairly. It can work wonders if you have the right teammates, but it’s almost a prisoners dilemma game that falls apart as soon as one person opts out. reply dakshgupta 21 hours agoparentGood point, we will usually only rotate when the long running task is done but eventually we’ll arrive at some feature that takes more then a few weeks to build so will need to restructure our methods then. reply d4nt 11 hours agoprevI think they’re on to something, but the solution needs more work. Sometimes it’s not just individual engineers who are playing defence, it’s whole departments or whole companies that are set up around “don’t change anything, you might break it”. Then the company creates special “labs” teams to innovate. To borrow a football term, sometimes company structure seems like it’s playing the “long ball” game. Everyone sitting back in defence, then the occasional hail mary long pass up to the opposite end. I would love to see a more well developed understanding within companies that certain teams, and the processes that they have are defensive, others are attacking, and others are “mid field”, i.e. they’re responsible for developing the foundations on which an attacking team can operate (e.g. longer term refactors, API design, filling in gaps in features that were built to a deadline). To win a game you need a good proportion of defence, mid field and attack, and a good interface between those three groups. reply ozim 2 hours agoprevI like the approach as it is easy to explain and it is having catchy names. But sounds like there has to be a lot of micro management involved and when you have team of 4 it is easy to keep up but as soon as you go to 20 and that increase also means much more customer requests it will fall apart. reply smugglerFlynn 10 hours agoprevConstantly working in what OP describes as defence might also be negatively affecting the perception of cause and effect of own actions: Specifically, we show that individuals following clock-time [where tasks are organized based on a clock**] rather than event-time [where tasks are organized based on their order of completion] discriminate less between causally related and causally unrelated events, which in turn increases their belief that the world is controlled by chance or fate. In contrast, individuals following event-time (vs. clock-time) appear to believe that things happen more as a result of their own actions.[0] ** - in my experience, clock based organisation seems to be very characteristic to what OP describes as defensive, when you become driven by incoming priorities and meetings Broader article about impact of schedules at [1] is also highly relevant and worth the read. [0] - https://psycnet.apa.org/record/2014-44347-001 [1] - https://hbr.org/2021/06/my-fixation-on-time-management-almost-broke-me reply Kinrany 6 hours agoparentBy \"constantly\", do you mean for 2-4 weeks in a row? reply smugglerFlynn 5 hours agorootparentI was thinking perpetually, which is not unusual for some of the tech companies and/or roles. reply shalmanese 21 hours agoprevTo the people pooh poohing this, do y’all really work with such terrible coworkers that you can’t imagine an effective version of this? You need trust in your team to make this work but you also need trust in your team to make any high velocity system work. Personally, I find the ideas here extremely compelling and optimizing for distraction minimization sounds like a really interesting framework to view engineering from. reply johnnyanmac 9 hours agoparentwork with terrible management that can't imagine an effective version of this. reply jph 22 hours agoprevSmall teams shouldn't split like this IMHO. It's better/smarter/faster IMHO to do \"all hands on deck\" to get things done. For prioritization, use a triage queue because it aims the whole team at the most valuable work. This needs to be the mission-critical MVP & PMF work, rather than what the article describes as \"event driven\" customer requests i.e. interruptions. reply dakshgupta 21 hours agoparentA triage queue makes a lot of sense, only downside being the challenge of getting a lot done without interruption. reply bvirb 21 hours agorootparentIn a similar boat (small team, have to balance new stuff, maintenance, customer requests, bugs, etc). We ended up with a system where we break work up into things that take about a day. If someone thinks something is going to take a long time then we try to break it down until some part of it can be done in about a day. So we kinda side-step the problem of having people able to focus on something for weeks by not letting anything take weeks. The same person will probably end up working on the smaller tasks, but they can more easily jump between things as priorities change, and pretty often after doing a few of the smaller tasks either more of us can jump in or we realize we don't actually need to do the rest of it. It also helps keep PRs reasonably sized (if you do PRs). reply Kinrany 6 hours agoparentprevYou're not addressing the issue of triage also being an interruption. reply october8140 11 hours agoprevMy first job had a huge QA team. It was my job to work quickly and it was their job to find the issues. This actually set me up really poorly because I got in the habit of not doing proper QA. There were at least 10 people doing it for me. When I left it took awhile for me to learn what properly QAing my own worked looked like. reply bsimpson 3 hours agoprevHa - I think greptile was my first email address! Reptile was my favorite Mortal Kombat character, and our ISP added a G before all the sub accounts. They put a P in front of my dad's. reply marcinzm 7 hours agoprevIt feels like having 50% of your team's time be spent on urgent support, triage and bugs is a lot. That seems like a much better thing to solve versus trying to work around the issue by splitting the team. Probably having those people fix bugs while a 4 week re-factor in a secluded branch is constantly in process doesn't help with efficiency or bug rate. reply Kinrany 6 hours agoparentIt's a team of 4, so the only options are 25% and 50%. But the fact that this explicit split makes the choice visible is clearly an upside. reply philipwhiuk 18 hours agoprevWe have a person who is 'Batman' to triage production issues. Generally they'll pick up smaller sprint tasks. It rotates every week. It's still stuff from the team so they aren't doing stuff unknown (or if they are, it's likely they'll work on it soon). The aim is generally not to provide a perfect fix but an MVP fix and raise tickets in the queue for regular planning. It rotates round every week or so. My company's not very devops so it's not on-call, but it's 'point of contact'. reply svilen_dobrev 20 hours agoprevIMO the split, although good (the pattern is \"sacrifice one person\" as per Coplien/Harrision's Organisational patterns book [0]), is too drastic. It should be not defense vs offense 100% with a wall inbetween, but for each and every issue (defense) and/or feature (offense), someone has to pick it and become the responsible (which may or may not mean completely doing it by hirself). Fixing a bug for an hour-or-two sometimes has been exactly the break i needed in order to continue digging some big feature when i feel stuck. And the team should check the balances once in a while, and maybe rethink the strategy, to avoid overworking someone and underworking someone else, thus creating bottlenecks and vacuums. At least this is the way i have worked and organised such teams - 2-5 ppl covering everything. Frankly, we never had many customers :/ but even one is enough to generate plenty of \"noise\" - which sometimes is just noise, but if good customer, will be mostly real defects and generally under-tended parts. Also, good customers accept a NO as answer. So, do say more NOs.. there is some psychological phenomena in software engineering in saying yes and promising moonshots when one knows it cannot happen NOW, but looks good.. have fun! [0] https://svilendobrev.com/rabota/orgpat/OrgPatterns-patlets.h... reply Kinrany 6 hours agoparentThanks for the name! reply jwrallie 19 hours agoprevI think interruptions damage the productivity overall, not only of engineers. Maybe some are unaware of it, and others simply don’t care. They don’t want to sacrifice their own productivity by waiting on someone busy, so they interrupt and after getting the information they want, they feel good. From their perspective, the productivity increased, not decreased. Some engineers are more likely to avoid interrupting others because they can sympathize. reply ndndjdjdn 9 hours agoprevThis is probably devops. A single team talking full responsibility and swapping oncall-type shifts. These guys know their dogfood. You want the defensive team to work on automating away stuff that pays off for itself in the 1-4 week timeframe. If they get any slack to do so! reply stronglikedan 22 hours agoprevEveryone on every team should have something to \"own\" and feel proud of. You don't \"own\" anything if you're always on team defense. Following this advice is a sure fire way to have a high churn rate. reply LatticeAnimal 21 hours agoparentFrom the post: > At the end of the cycle, we swap. They swap teams every 2-4 weeks so nobody will always be on team defense. reply FireBeyond 22 hours agoparentprevYup, last place I was at I had engineers begging me (PM) to advocate against this, because leadership was all \"We're going to form a SEAL team to blaze out [exciting, interesting, new, fun idea/s]. Another team will be on bug fixes.\" My team had a bunch of stability work, and bug fixes (and there was a lot of bugs and a lot of tech debt, and very little organizational enthusiasm to fix the latter). Guess where there morale was, compared to some of the other teams? reply 000ooo000 9 hours agorootparentSplitting a team by interesting/uninteresting work is a comically bad idea. It's puzzling that it ever gets pitched, let alone adopted. Edit: I mean an ongoing split, not a rotation reply ninininino 21 hours agoparentprevYou didn't read the article did you, they swap every 2 weeks between being on offense and defense. reply eiathom 7 hours agoprevAnd, what else? Putting a couple of buzzwords on a practice being performed for at least 15 years now doesn't make you clever. Quite the opposite in fact. reply Kinrany 6 hours agoparentDo you have a name for this practice? reply JohnMakin 3 hours agoprevThis is a common \"pattern\" on well-ran ops teams. The work of a typical ops team consists of a lot of new work but tons of interruptions come in as new issues arise and must be dealt with. So we would typically assign 1 engineer (who was also typically on call) a lighter workload and would be responsible for triaging most issues that came in. reply joony527 6 hours agoprevInteresing Article! reply chiefalchemist 7 hours agoprevInteresting concept. Certainly worth trying, but in the name of offense (read: being proactive): - \"and our “lean” team is more a product of our inability to identify and hire great engineers, rather than an insistence on superhuman efficiency.\" Can we all at some point have a serious discussion on hiring and training. It seems that many teams are unstaffed or at least not satisfied with the quality and quantity of their team. Why is that? Why does it seem to be the norm? - what about mitigating bugs in the first place? Shouldn't someone be assigned to that? Yeah, sure, bugs are a given. They are going to happen. But in production bugs are something real and paying customers shouldn't experience. At the very least what about feature flags? That is sonething new is introduced to a limited number of user. If there's a bug and it's significant enough, the flag is flipped and the new feature withdrawn. Then the bug can be sorted as someone is available. Prehaps the profession just is what it is? Some teams are almost miraculously better than others? Maybe that's luck, individuals, product, and/or the stack? Maybe like plumbers and shit there are just things that engineering teams can't avoid? I'm not suggesting we surrender, but that we become more realistic about expectations. reply bradarner 22 hours agoprevDon't do this to yourself. There are 2 fundamental aspects of software engineering: Get it right Keep it right You have only 4 engineers on your team. That is a tiny team. The entire team SHOULD be playing \"offense\" and \"defense\" because you are all responsible for getting it right and keeping it right. Part of the challenge sounds like poor engineering practices and shipping junk into production. That is NOT fixed by splitting your small team's cognitive load. If you have warts in your product, then all 4 of you should be aware of it, bothered by it and working to fix it. Or, if it isn't slowing growth and core metrics, just ignore it. You've got to be comfortable with painful imperfections early in a product's life. Product scope is a prioritization activity not an team organization question. In fact, splitting up your efforts will negatively impact your product scope because you are dividing your time and creating more slack than by moving as a small unit in sync. You've got to get comfortable telling users: \"that thing that annoys you, isn't valuable right now for the broader user base. We've got 3 other things that will create WAY MORE value for you and everyone else. So we're going to work on that first.\" reply MattPalmer1086 20 hours agoparentI have worked in a small team that did exactly this, and it works well. It's just a support rota at the end of the day. Everyone does it, but not all the time, freeing you up to focus on more challenging things for a period without interruption. This was an established business (although small), with some big customers, and responsive support was necessary. There was no way we could just say \"that thing that annoys you, tough, we are working on something way more exciting.\" Maybe that works for startups. reply bradarner 16 hours agorootparentYes, very good point. I would argue that what I’m suggesting is particularly well suited to startups. It may be relevant to larger companies as well but I think the politics and risk profile of larger companies makes this nearly impossible to implement. reply rkangel 5 hours agoparentprev> You've got to get comfortable telling users: \"that thing that annoys you, isn't valuable right now for the broader user base. We've got 3 other things that will create WAY MORE value for you and everyone else. So we're going to work on that first.\" Yes, but you've got to spend time talking to users to say that. Many engineering teams have incoming \"stuff\". Depending on your context that might be bug reports from your customer base, or feature requests from clients etc. You don't want these queries (that take half an hour and are spread out over the week) to be repeatedly interrupting your engineering team, it's not great for getting stuff done and isn't great for getting timely helpful answers back to the people who asked. There's a few approaches. This post describes one (\"take it in turns\"). In some organisations, QA is the first line of defence. In my team, I (as the lead) do as much of it as I can because that's valuable to keep the team productive. reply dakshgupta 21 hours agoparentprevAll of these are great points. I do want to add we rotate offense and defense every 2-3 weeks, and the act of doing defense which is usually customer facing gives that half of the team a ton of data to base the next move on. reply bradarner 21 hours agorootparentThe challenge is that you actually want your entire team to benefit from the feedback. The 4 of you are going to benefit IMMENSELY from directly experiencing every single pain point- together. As developers we like to focus. But there is vast difference between \"manager time\" and \"builder time\" and what you are experiencing. You are creating immense value with every single customer interaction! CUSTOMER FACING FIXES ARE NOT 'MANAGER TIME'!!!!!! They are builder time!!!! The only reason I'm insisting is because I've lived through it before and made every mistake in the book...it was painful scaling an engineering and product team to >200 people the first time I did it. I made so many mistakes. But at 4 people you are NOT yet facing any real scaling pain. You don't have the team size where you should be solving things with organizational techniques. I would advise that you have a couple of columns in a kanban board: Now, Next, Later, Done & Rejected. And communicate it to customers. Pull up the board and say: \"here is what we are working on.\" When you lay our the priorities to customers you'd be surprised how supportive they are and if they aren't...tough luck. Plus, 2-3 weeks feels like an eternity when you are on defense. You start to dread defense. And, it also divorces the core business value into 2 separate outcomes rather than a single outcome. If a bug helps advance your customers to their outcome, then it isn't \"defense\" it is \"offense\". If it doesn't advance your customer, why are you doing it? If you succeed, all of your ugly, monkey patched code will be thrown away or phased out within a couple of years anyway. reply FridgeSeal 19 hours agorootparentWhilst I very much agree with you, actually doing this properly and pulling this off requires PM’s and/or Account Managers who are willing and capable of _actually managing_ customers. Many, many people I’ve dealt with in these roles don’t or can’t, and seem to think their sole task is to mainline customer needs into dev teams. The PM’s I’ve had who _actually_ do manage back properly had happier dev teams, and ultimately happier clients, it’s not a mystery, but for some reason it’s a rare skill. reply bradarner 16 hours agorootparentYes completely agree. This is hard for a PM to do. I’m assuming that the OP is a founder and can actually make these calls. reply dijksterhuis 11 hours agorootparentthe reasons PM stuff is ‘hard’ in my, admittedly limited, experience often seems to come down to - saying No, and sticking to it when it matters — what you’ve mentioned. - knowing how the product gets built — knowing *the why behind the no*. PMs don’t usually have the technical understanding to do the second one. so the first one falls flat because why would someone stick to their guns when they do not understand why they need to say No, and keep saying No. there are cases where talking to customer highlights a mistaken understanding in the *why we’re saying No*. those moments are gold because they’re challenging crucial assumptions. i love those moments. they’re basically higher level debugging. but, again, without the technical understanding a PM can’t notice those moments. they end up just filling up a massive backlog of everything because they don’t know how to filter wants vs. needs and stuff. — also i agree with a lot of what you’ve said in this chain of discussion. get it right first time, then keep it right is so on point these days. especially for smaller teams. 90% of teams are not the next uber and don’t need to worry about massive growth spurts. most users don’t want the frontend changing every single day. they want stability. worry about getting it right first. be like uber/google if you need to, when you need to. reply johnrob 19 hours agorootparentprevI thought you made the rotation aspect quite clear. Everyone plays both roles and I’m sure when a bigger issue arises everyone becomes aware regardless. Personally, I like this because as a dev I can set expectations accordingly. Either I plan for minimal disruption and get it, or take the on call side which I’m fine with so long as I’m not asked to do anything else (frustration is when your expected to build features while getting “stuck” fixing prod issues). reply ramesh31 22 hours agoparentprevTo add to this, ego is always a thing among developers. Your defensive players will inevitably end up resenting the offense for 1. leaving so many loose ends to pick up and 2. not getting the opportunity for greenfield themselves. You could try to \"fix\" that by rotating, but then you're losing context and headed down the road toward man-monthing. reply CooCooCaCha 21 hours agorootparentInteresting that you describe it as ego. I don’t think a team shoveling shit onto your plate and disliking it is ego. I feel similar things about the product and business side, it often feels like people are trying to pass their job off to you and if you push back then you’re the asshole. For example, sending us unfinished designs and requirements that haven’t been fully thought through. I imagine this is exactly how splitting teams into offense and defense will go. reply FridgeSeal 21 hours agorootparent> For example, sending us unfinished designs and requirements that haven’t been fully thought through Oh man. Once had a founder who did this to the dev team: blurry, pixelated screenshots with 2 or 3 arrows and vague “do something like ”. The team _requested_ that we have a bit more detail and clarity in the designs, because it was causing us significant slowdown and we were told “be quiet, stop complaining, it’s a ‘team effort’ so you’re just as at fault too”. Unsurprisingly, morale was low and all the good people left quickly. reply dakshgupta 21 hours agorootparentprevTo add - I personally enjoy defense more because the quick dopamine hits of user requests fix -> fix issue -> tell user -> user is delighted is pretty addictive. Does get old after a few weeks. reply joshhart 21 hours agoprevnext [9 more] [flagged] dang 13 hours agoparent\"Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.\" https://news.ycombinator.com/newsguidelines.html reply dakshgupta 21 hours agoparentprevThis makes me want to delete the post. reply Xeamek 20 hours agorootparentPlease don't. I personally found the idea inspiring and the article itself is explaining it succinctly. Even if it's not completely revolutionary, it's small, self containing concept that's actionable. Lowley surprised why there are so many harsh voices in this thread, but the article definitely has merrit, even if it won't be usefull/possible to implement for everyone reply thesandlord 20 hours agorootparentprevDon't do that! This was a great post with a lot to learn from. The fact you came to a very similar solution from first principles is very interesting (assuming you didn't know about this before!) reply stopachka 20 hours agorootparentprevI resonated with your post Daksh. Keep up the good work reply candiddevmike 21 hours agoparentprevOr the idea of an \"interrupt handler\". OP may find other SRE concepts insightful, like error budgets. reply wombatpm 12 hours agorootparentError budget or recovery cost tracking goes a long way towards defeating the We never have time or money to do it right, but we’ll find time and money to fix it later mindset. reply dakshgupta 12 hours agorootparentI’m generally a strong believer in “if it’s not measured it’s not managed” so this seems like it would be useful to explore. I suspect it’s tricky to assign a cost to a bug though. reply shermantanktop 21 hours ago [flagged]prevnext [2 more] “The core functionality may remain largely intact but the periphery is often buggy, something we expect will improve only as our engineering headcount catches up to our product scope.” Oh you sweet summer child… reply dang 13 hours agoparentPlease don't do this here. reply madeofpalk 20 hours agoprevSomewhat random side note - I find it so fascinating that developers invented this myth that they’re the only people who have ‘concentration’ when this is so obviously wrong. Ask any ‘knowledge worker’ or yell even physical labourer and I’m sure they’ll tell you about the productivity of being \"in the zone\" and lack of interruptions. Back in early 2010s they called it ‘flow’. reply dakshgupta 18 hours agoparentMy theory is that to outsiders software development looks closer to other generic computer based desk jobs than to the job of a writer or physical builder, so to them it’s less obvious that programming needs “flow” too. reply 000ooo000 9 hours agoparentprevThe article doesn't say or suggest that. It says it applies to engineers. reply Roelven 6 hours agoprevGetting so tired of the war metaphors in attempts to describe software development. We solve business problems using code, we don't make a living by role-playing military tactics. Chill out my dudes reply Towaway69 10 hours agoprevWhat's wrong with collaboratively working together? Why is there a need to create an atificial competition between a \"offence\" and a \"defence\" team? And why should team members be collaborative amongst their team? E.g. why should the \"offence\" team members suddenly help each other if it's not happening generally? This sounds a lot like JDD - Jock Driven Development. Perhaps the underlying problems of \"don't touch it because we don't understand it\" should be solved before engaging in fake competition to increase the stress levels. reply megunderstood 10 hours agoparentSounds like you didn't read the article. The idea has nothing to do with creating artificial competition and it is actually designed as a form of collaboration. Some work requires concentration and the defensive team is there to maintain the conditions for this concentration, i.e. prevent the offensive team from getting interrupted. reply Towaway69 10 hours agorootparentOk, that might well be the case! Many apologies for my mistaken assumptions. Then perhaps the terminology - for me - has a different meaning. reply Kinrany 6 hours agorootparentIt's a common and pervasive mistake to assume the meaning of a term by association with the words used in the term. Names of terms are at best mnemonics. reply namenotrequired 8 hours agoprev [–] Many are complaining that this way the engineers are incentivised to carelessly create bugs because they have to ship fast and won’t be responsible for fixing them. That’s easy to fix with an exception: you won’t have to worry about support for X time unless you’re the one who recently made the bug. It turns out that once they’re responsible for their bugs, there won’t actually be that many bugs and so interruptions to a focused engineer will be rare. That's how we do it in my startup. We have six engineers, most are even pretty junior. Only one will be responsible for support in any given sprint and often he’ll have time left over to work on other things e.g. updating dependencies. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Greptile, co-founded by Daksh, develops AI tools for understanding large codebases, aiding in AI-powered code reviews and diagnosing outages.",
      "The team consists of four engineers, and despite the product's extensive capabilities, it experiences bugs due to the small team size.",
      "To manage productivity, the team is divided: half focus on long-term projects, while the other half address support and bug fixes, minimizing distractions."
    ],
    "commentSummary": [
      "The article explores the concept of dividing engineering teams into \"defense\" and \"offense\" roles, where \"defense\" manages immediate issues and \"offense\" focuses on long-term projects.",
      "This strategy is prevalent in small, high-trust teams but may encounter difficulties as the team size increases, potentially leading to poor work quality and resentment.",
      "To maintain balance and accountability, the article recommends rotating roles and highlights the importance of proactive communication and quality assurance."
    ],
    "points": 176,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1728936447
  },
  {
    "id": 41850017,
    "title": "The C23 edition of Modern C",
    "originLink": "https://gustedt.wordpress.com/2024/10/15/the-c23-edition-of-modern-c/",
    "originBody": "The C23 edition of Modern C The C23 edition of Modern C is now available for free download from https://hal.inria.fr/hal-02383654 This new edition has been the occasion to overhaul the presentation in many places, but its main purpose is the update to the new C standard, C23. The goal was to publish this new edition of Modern C at the same time as the new C standard goes through the procedure of ISO publication. The closest approximation of the contents of the new standard in a publically available document can be found here. New releases of major compilers already implement most of the new features that it brings. Among the most noticeable changes and additions that we handle are those for integers: there are new bit-precise types coined _BitInt(N), new C library headers (for arithmetic with overflow check) and (for bit manipulation), possibilities for 128 bit types on modern architectures, and substantial improvements for enumeration types. Other new concepts in C23 include a nullptr constant and its underlying type, syntactic annotation with attributes, more tools for type generic programming such as type inference with auto and typeof, default initialization with {}, even for variable length arrays, and constexpr for named constants of any type. Furthermore, new material has been added, discussing compound expressions and lambdas, so-called “internationalization”, a comprehensive approach for program failure. Also added has been an appendix and a temporary include header for an easy transition to C23 on existing platforms, that will allow you to start off with C23 right away. Manning’s early access program (MEAP) for the new edition is still open at https://www.manning.com/books/modern-c-third-edition Unfortunately they were not yet able to tell me when their version of the C23 edition will finally be published. Share this: Share Related Author Jens GustedtPosted on October 15, 2024October 15, 2024Categories C23, integers, language, Modern C",
    "commentLink": "https://news.ycombinator.com/item?id=41850017",
    "commentBody": "The C23 edition of Modern C (gustedt.wordpress.com)170 points by bwidlar 2 hours agohidepastfavorite52 comments zkirill 48 minutes agoI was going to ask if there is a good list of C books and then answered my own question. It categorizes _Modern C_ as Intermediate level. https://stackoverflow.com/questions/562303/the-definitive-c-... reply belter 1 hour agoprevImportant reminder just in the Preface :-) Takeaway #1: \"C and C++ are different: don’t mix them, and don’t mix them up\" reply jasode 22 minutes agoparent>Takeaway #1: \"C and C++ are different: don’t mix them, and don’t mix them up\" Where \"mixing C/C++\" is helpful: - I \"mix C in with my C++\" projects because \"sqlite3.c\" and ffmpeg source code is written C. C++ was designed to interoperate with C code. C++ code can seamlessly have #include \"sqlite3.h\" unchanged. - For my own code, I take advantage of \"C++ being _mostly_ a superset of C\" such as using old-style C printf in C++ instead of newer C++ cout. Where the \"C is a totally different language from C++\" perspective is helpful: - knowing that compilers can compile code in \"C\" or \"C++\" mode which has ramifications for name mangling which leads to \"LINK unresolved symbol\" errors. - knowing that C99 C23 has many exceptions to \"C++ is a superset of C\" : https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B... reply accelbred 9 minutes agorootparentC++ can seamlessly include C89 headers. The C library headers for libraries I write often include C11/C99 stuff that is invalid in C++. Even when they are in C89, they are often incorrect to include without the include being in an `extern \"C\"`. reply pjmlp 1 hour agoparentprevSpecially relevant to all those folks that insist on \"Coding C with a C++ compiler\", instead of safer language constructs, and standard library alternatives provided by C++ during the last decades. reply flohofwoe 56 minutes agorootparentFunny because for a long time the Microsoft MSVC team explicitly recommended compiling C code with a C++ compiler because they couldn't be arsed to update their C frontend for over two decades (which thankfully has changed now) ;) https://herbsutter.com/2012/05/03/reader-qa-what-about-vc-an... reply rdtsc 25 minutes agorootparentThat thing always baffled me, this huge company building a professional IDE couldn't figure out how to ship updates to the C compiler. > it is hard to say no to you, and I’m sorry to say it. But we have to choose a focus, and our focus is to implement (the standard) and innovate (with extensions like everyone but which we also contribute for potential standardization) in C++. I mean, yeah if it came from a two member team at a startup, sure focus on C++, understandably. But Microsoft, what happened to \"Developers! Developers! Developers!\"? reply Jtsummers 12 minutes agorootparentIt's not baffling, it's remarkably consistent. They implemented Java as J++ and made their version incompatible in various ways with the standard so it was harder to port your code away from J++ (and later J#). They implemented things in the CSS spec almost exactly opposite the specification to lock people into IE (the dominant browser, if you have to make your site work with 2+ incompatible systems which will you focus on?). Not supporting C effectively with their tools pushed developers towards their C++ implementation, creating more lock-in opportunities. reply com2kid 1 hour agorootparentprevPerfectly valid to do if you need to interface with a large C code base and you just want to do some simple OO here and there. Especially if you cannot have runtime exceptions and the like. This is how I managed to sneak C++ into an embedded C codebase. We even created some templates for data structures that supported static allocation at compile time. reply f1shy 1 hour agorootparentWhat would be an example of \"simple OO here and there\" that cannot be done cleanly in plain C? reply bobmcnamara 46 minutes agorootparentTemplating on pixel classes so that a blitter builds all supported pixel paths separately and inlines them. Yes you can do it less cleanly with macros or inline functions. But you can't do it performantly with struct and function pointers. reply raluk 1 hour agorootparentprevRAII reply tjoff 42 minutes agorootparentThe killer feature of RAII is when combined with exception. But sneaking in exceptions in an embedded C project isn't something I'd encourage or recommend. C++ imo doesn't offer anything compelling for the embedded usecase. Especially not considering all the footguns and politics it brings. You can of course be strict and diligent about it but if you are you are pretty much just writing C anyway. Better to do it explicitly. Allowing the use of the C++ standard library has been one of my biggest regrets (not that it was my decision to make, I fought it). reply f1shy 58 minutes agorootparentprevIs RAII Object orientation? I thought it was an idiom of C++ by Stroustrup. reply adamrezich 58 minutes agorootparentprevNamespaces, methods. reply f1shy 56 minutes agorootparentNamespaces is not object orientation, is it? Am I missing something? You can place functions (methods) inside of structs in C23, can't you? reply int_19h 40 minutes agorootparentYou can handcode vtables in C, just as you can handcode loops in assembly (i.e. it works but it's verbose, not particularly readable, and brings more footguns). But why would you do that if you have an instrument that lets you work at the same level as C, but with methods provided as a proper abstraction that maps exactly to what you'd have written yourself anyway? reply staunton 54 minutes agorootparentprevOn a high level, \"object orientation\" means you think of your code as representing the state and interactions of objects. You can equally well do this in assembly. If you think of some namespace as a \"singleton object\" then that's what it is. I guess what you're really asking is what are the best or most common ways to do OO in C? reply f1shy 46 minutes agorootparentOh. I learned that object orientation is primarily a way to structure data and code, such that the data is encapsulated with the code that works on it, in so called objects. So an Object is the Data, plus the functions that work on the data, an ensure that some invariants are kept. In OO parlance, that code gets executed by sending messages (calling methods). Where can I find something about objects being \"think of your code as representing the state and interactions of objects\" honesty totally new to me. So no, certainly I'm not asking ways to do OO in C. But it seems to be more definitions of object orientation as I thought... reply int_19h 36 minutes agorootparentThere's no clear definition of what OO is, so the best you can do pragmatically is look at mainstream languages that are broadly recognized as OO and try to deduce the commonalities. If you do that, you'll notice that, for example, encapsulation is not a part of that de facto definition, because languages like Python and (until recently) JavaScript lack it, despite being considered OO. Indeed, the only two things that appear to be consistently present in all OO languages are: 1) some notion of object identity as distinct from object state, and 2) runtime polymorphic dispatch. reply epcoa 23 minutes agorootparentprev> Where can I find something about objects being \"think of your code as representing the state and interactions of objects\" honesty totally new to me. I’m scratching my head how you think this is materially different than what you described in your first para. s/state/data and s/interactions/methods. If anything though I would say the GP is more aligned with the classic definition as it highlights the focus is more on the messages (interactions) themselves rather than the implementation. reply adamrezich 50 minutes agorootparentprevCorrect, and you did ask specifically for OO things, but I thought I'd list namespaces too as far as “C++ things you might use when writing C-like C++ code”. Another big one that I always forget C still doesn't support is function overloading. reply Spivak 1 hour agorootparentprevI mean as long as your goal is specifically to do that I think it's fine. Using a C++ compiler to compile a C program isn't that rare. reply f1shy 1 hour agoparentprevA couple of months ago, in the company I work, there was a talk from HR, where they explained how to make a good CV (the company is firing lots of people). She say: \"if you have experience in programming C, you can writing just that, or, if you have lots of experience in C, is customary to write ``C++ Experience'' \" Sooo... yeah... I should definitely change company! reply kstrauser 53 minutes agorootparentThat literally made me do a spit take, and it was fizzy water and it burned. My god. That's amazing. reply jpcfl 1 hour agoparentprevBjarne should have called it ++C. reply card_zero 51 minutes agorootparentBecause people choose to use pre-increment by default instead of post-increment? Why is that? reply int_19h 26 minutes agorootparentIt should be ++C because with C++ the value you get from the expression is the old one. If you're asking why people use pre-increment by default instead of post-increment, it's mostly historical. The early C compilers on resource-constrained platforms such as early DOS were not good at optimization; on those, pre-increment would be reliably translated to a simple ADD or INC, whereas code for post-increment might generate an extra copy even if it wasn't actually used. For C++ this was even worse with iterators, because now it depended on the compiler's ability to inline its implementation of postfix ++, and then prove that all the copies produced by that implementation have no side effects to optimize it to the same degree as prefix ++ could. Depending on the type of the underlying value, this may not even be possible in general. The other reason is that all other unary operators in C are prefix rather than postfix, and mixing unary prefix with unary postfix in a single expression produces code that is easy to misunderstand. E.g. *p++ is *(p++), not (*p)++, even though the latter feels more natural, reading it left-to-right as usual. OTOH *++p vs ++*p is unambiguous. reply card_zero 16 minutes agorootparentK&R seems to use pre-increment early on, then post-increment consistently (or a lot, anyway, I haven't done a thorough check) after chapter 3, in situations where either would do. In fact, after introducing post-increment at 2.8. reply tialaramex 34 minutes agorootparentprevWhy use this operator? Like most C and C++ features the main reason tends to be showing off, you learned a thing (in this case that there are four extra operators here) and so you show off by using it even if it doesn't make the software easier to understand. This is not one of those beginner -> journeyman -> expert cycles where coincidentally the way you wrote it as a beginner is identical to how an expert writes it but for a very different reason. I'd expect experts are very comfortable writing either { x = k; k += 1; } or { k += 1; x = k; } depending on which they meant and don't feel an itch to re-write these as { x = k++; } and { x = ++k; } respectively. I'm slightly surprised none of the joke languages add equally frivolous operators. a%% to set a to the remainder after dividing a by 10, or b** to set b as two to the power b or some other silliness. reply cozzyd 2 minutes agorootparentIt's more useful for pointers on than for values, IMO jejdjdbd 44 minutes agorootparentprevWhy would you use post increment by default? The semantics are very particular. Only on very rare occasions I need post increment semantics. And in those cases I prefer to use a temporary to make the intent more clear reply card_zero 36 minutes agorootparentPeople seem to mostly write a typical for loop ending with ; ++i){ But I write ; i++){ and seeing it the other way round throws me off for a minute, because I think, as you put it, why would you use those very particular semantics? But I guess this is only a semantic argument. reply johannes1234321 19 minutes agorootparent> why would you use those very particular semantics? The difference is that i++ has to keep a copy to the original around as the return value is the pre-increment value, while with ++i that isn't needed as the resulting value is being returned. In the for loop that shouldn't matter as a) for an integer it is essentially for free (it is just reordering when the relevant register is set) and b) that value is hopefully optimized out anyways by the compiler, however as there are cases where it matters some people prefer the ++i style, some just think it looks better. reply auggierose 1 hour agoprevTable of contents in the sidebar doesn't work properly for me when I click on an entry (in macOS Preview). reply channel_t 43 minutes agoparentTable of contents is definitely broken right now. reply f1shy 1 hour agoparentprevDoesn't work for me either... but I will not dismiss the book because of that. reply bwidlar 1 hour agoparentprevI just test some links in the table of content, works fine for me. Using zathura pdf reader. reply Jtsummers 39 minutes agorootparentAlso works in Adobe and Firefox, but doesn't work in Chrome and Edge. reply soegaard 44 minutes agoparentprevSame here. reply enriquto 1 hour agoprevSo happy that we still get the dinosaur mascots! This is a good book. reply bitbasher 1 hour agoprevReally looking forward to #embed, once the compilers catch up. Until then, Golang. reply f1shy 1 hour agoparentI do that with ld and objcopy: https://stackoverflow.com/questions/58815959/include-binary-... reply accelbred 5 minutes agoparentprevI end up using a .S asm file with .incbin directives to embed files. #embed would be much nicer reply enriquto 1 hour agoparentprevThis is not how C standards work. If it appears in the standard, it means that it is already implemented in some compilers (in that case, at least in gcc and clang). reply jpcfl 1 hour agoparentprevOr xxd --include:) reply rfl890 1 hour agoparentprevClang 19 has it. reply jumpman_miya 1 hour agoprevin example 1.1 i read that as 'tits_square' until i saw the output reply glass-z13 55 minutes agoparentthat's by design reply ralphc 30 minutes agoprevHow does \"Modern\" C compare safety-wise to Rust or Zig? reply zerr 15 minutes agoprev [–] Do they still use 0-terminated strings/char* as the main string type? Is the usage of single linked lists still prevalent as the main container type? reply racingmars 3 minutes agoparent [–] > Do they still use 0-terminated strings/char* as the main string type? Of course, it's still C. > Is the usage of single linked lists still prevalent as the main container type? As far as I can remember, the C standard library has never had any functions that used linked lists. Nor are there any container types, linked lists or otherwise, provided by C. So I'd say this is a question about how people teach and use C, not related to the language -- or language spec version -- itself. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The C23 edition of Modern C is now available for free download, aligning with the new C23 standard following its ISO publication.",
      "Major compilers support most new features, such as bit-precise types, improved enumeration types, and new C library headers.",
      "C23 introduces concepts like nullptr (a null pointer constant), type inference, default initialization, and constexpr (constant expressions), with additional material on compound expressions, lambdas, and internationalization."
    ],
    "commentSummary": [
      "The blog discusses the C23 edition of Modern C, emphasizing the importance of not mixing C and C++ due to compatibility issues.",
      "Users share experiences of integrating C in C++ projects, highlighting both challenges and benefits, such as Microsoft's past advice to use a C++ compiler for C code.",
      "The conversation covers object-oriented features in C++, like Resource Acquisition Is Initialization (RAII) and namespaces, and the difficulties of using C++ in embedded systems."
    ],
    "points": 170,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1729008389
  },
  {
    "id": 41842775,
    "title": "The Physics of Magic Windows (2021)",
    "originLink": "https://mattferraro.dev/posts/caustics-engineering",
    "originBody": "Hiding Images in Plain Sight: The Physics Of Magic Windows August 18, 2021 I recently made a physical object that defies all intuition. It's a square of acrylic, smooth on both sides, totally transparent. A tiny window. But it has the magic property that if you shine a flashlight on it, it forms an image: And if you take it out in the sun, it produces this 3D hologram: This post describes the math that went into making the object, and how you can create your own. But first: How is this even possible? Let's focus on the 2D image before talking about the hologram. The physical phenomenon we're looking at is called a caustic. Image from Pixabay licensed public domain Caustics are the bright patches of light we see when illuminating a transparent object. All the photons that don't pass directly through the object are what form the object's shadow. All those photons still have to go somewhere; they contribute to the caustic pattern. The most interesting aspect of caustics is that they arise from even the tiniest of variations in surface flatness. Even the gentlest waves on the surface of a pool form powerful lenses that cast intense caustics on the floor below. Image from fdecomite licensed CC-BY The reason my acrylic square can form an image is because I've distributed just the right amount of concavity and convexity into the surface so that the refracted light forms a caustic image. To gain some intuition for how it is done, consider a traditional convex lens: This lens forms the simplest possible caustic. If all the incoming light is from a single, very distant light source like the Sun, this lens focuses all of its incoming light into a single point. The caustic image from this lens is dark everywhere with one very bright spot in the center. Zooming in on one small section of the lens we notice a few properties: The overall thickness of the lens does not have a direct impact on the outgoing ray angle. We could add material to the left side of this lens and nothing would change. The first transition, from air to glass, can be entirely ignored. The angle between the incoming light rays and the glass-air boundary has a strong effect on the refracted ray angle. Whether two rays converge or diverge is controlled by how curved the lens is where the glass meets the air In other words, the height of the glass ℎ ( 𝑥 ) h(x) is not on its own important. But the slope of the glass, d ℎ d 𝑥 dxdh, gives us the outgoing ray angle via Snell's law. Where rays converge the image is brighter than the light source. Where rays diverge the image is darker. Therefore the brightness of the image (at that point, where the rays fall) is related to d 2 ℎ d 𝑥 2 dx2d2h. The thickness of my acrylic slab varies across the entire 𝑥 𝑦 xy plane, so I'll call it ℎ ( 𝑥 , 𝑦 ) h(x,y) and we'll think of it as a heightmap. By controlling ∇ ℎ = ( ∂ ℎ ∂ 𝑥 , ∂ ℎ ∂ 𝑦 ∇h=(∂x∂h,∂y∂h), and ∇ 2 ℎ = ( ∂ 2 ℎ ∂ 𝑥 2 + ∂ 2 ℎ ∂ 𝑦 2 ) ∇2h=(∂x2∂2h+∂y2∂2h), we can steer all of our incoming light to the correct locations in the image, while contributing the right brightness to make it recognizable. By making some simplifying assumptions we can guarantee that the resulting heightmap will be smooth and continuous. For the Magic Window shown above, the total height variation over the 10 𝑐 𝑚 × 10 𝑐 𝑚 10cm×10cm surface is about 2.0 𝑚 𝑚 2.0mm. See how the slight variations in surface height distort the straight line of the floor moulding? Our Magic Window works like any other lens—by bending light. Table of Contents Formulating the Problem Steps to a Solution Morphing the Cells Computing the Loss Stepping to Reduce Loss Snell's Law and Normal Vectors Finding the Heightmap Manufacturing Acknowledgements My Code Licensing Contact me One Last Thing Formulating the Problem We want to find a heightmap ℎ ( 𝑥 , 𝑦 ) h(x,y) whose caustic image has brightness 𝑏 ( 𝑢 , 𝑣 ) b(u,v), equal to some input image. To achieve this we can imagine a grid of cells, akin to pixels, on the surface of the acrylic lens. Here each \"pixel\" on the lens corresponds to a pixel in the image. Image pixels and their corresponding lens-space \"pixels\" are labeled with shared ( 𝑖 , 𝑗 ) (i,j) coordinates. Remember that ( 𝑖 , 𝑗 ) (i,j) are integers labeling the column and row of the pixel, whereas ( 𝑥 , 𝑦 ) (x,y) and ( 𝑢 , 𝑣 ) (u,v) are real numbers measured in something like meters or inches. Steps to a Solution Step 1: We morph the cells on the lens, making them bigger or smaller, so that the area of lens cell ( 𝑖 , 𝑗 ) (i,j) is proportional to the brightness of image cell ( 𝑖 , 𝑗 ) (i,j). The resulting lens grid is no longer square—lots of warping and skew have to be introduced to maintain continuity. This step is by far the hardest part and must be solved iteratively. Step 2: For each cell ( 𝑖 , 𝑗 ) (i,j) we need to find the angle from the lens cell to image cell and use Snell's law to find the required surface normal. This step is straightforward geometry. Step 3: Integrate all the surface normals to find a continuous heightmap ℎ ( 𝑥 , 𝑦 ) h(x,y). We're back to iterative methods here, but if we apply certain contraints to how we solve step 1, this step is actually fast and easy. Morphing the Cells For an image with 𝑛 × 𝑛 n×n pixels, the lens grid will need ( 𝑛 + 1 ) × ( 𝑛 + 1 ) (n+1)×(n+1) points, so that each cell in the lens grid is defined by four points. Technically we should adopt yet another coordinate system to label the points in the lens grid since they are distinct from the cells in the lens grid, but I think it's easier to just reuse ( 𝑖 , 𝑗 ) (i,j) and we can say that for grid cell ( 𝑖 , 𝑗 ) (i,j), the point in the upper left is defined as grid point ( 𝑖 , 𝑗 ) (i,j). This leaves us with one row and one column of extra grid points along the bottom and right edges, but that will be trivial to deal with when it comes up. Each point in the lens grid ( 𝑖 , 𝑗 ) (i,j) has an ( 𝑥 , 𝑦 ) (x,y) coordinate. A point's ( 𝑖 , 𝑗 ) (i,j) coordinates never change but the ( 𝑥 , 𝑦 ) (x,y) coordinates will change as we morph the cells more and more. Computing the Loss Given the ( 𝑥 , 𝑦 ) (x,y) locations of all the lens grid points, simple geometry lets us calculate the area of each lens grid cell. Of course at first every cell has the same area, but that will change as soon as we start morphing things. The condition we want is that every lens grid cell ( 𝑖 , 𝑗 ) (i,j) has an area which scales with the brightness of image pixel 𝑏 ( 𝑖 , 𝑗 ) b(i,j). Area and brightness are not compatible units so it is helpful to normalize cell area by the full window area, and pixel brightness by total image brightness, so that each is measured in a unitless \"percentage\". 𝐴 𝑖 𝑗 Σ 𝐴 = 𝑏 𝑖 𝑗 Σ 𝑏(1.0) ΣAAij=Σbbij(1.0) Intuitively, this means: If a single pixel contributes 𝑥 % x% of the brightness of the entire image, the corresponding window cell should take up 𝑥 % x% of the area of the entire window. Equation ( 1.0 ) (1.0) is the goal, but it will not be not be true until after we've morphed the window grid. Until we've done that, we need to compute a loss function which tells us how badly we're missing our target. Something like: 𝐿 = 𝑏 𝑖 𝑗 Σ 𝑏 − 𝐴 𝑖 𝑗 Σ 𝐴(1.1) L=Σbbij−ΣAAij(1.1) In code: # In Julia-flavored psuedocode img = read_image(\"cat.png\") brightness = convert_to_grayscale(img) total_brightness = sum(brightness) brightness = brightness ./ total_brightness w = .1 # meters h = .1 # meters area_total = w * h loss = compute_pixel_area(grid) ./ area_total - brightness Where I've colorized the loss function so that red areas indicate regions where our grid cells need to grow and blue regions indicate where our grid cells need to shrink. This image is the loss function 𝐿 L and I'll refer to it a lot. Stepping to Reduce Loss The loss image can be thought of as a scalar field 𝐿 ( 𝑥 , 𝑦 ) L(x,y). The gradient of a scalar field yields a vector field, which we could call ∇ 𝐿 ( 𝑥 , 𝑦 ) ∇L(x,y). We can step each grid point slowly in the direction of the gradient field, and in doing so the cells that are too small will get bigger and the cells that are too big will get smaller. Our loss will shrink, and we'll create our image! The first thing to do is compute ∇ 𝐿 ∇L and look at the vector field: Crap. ∇ 𝐿 ∇L is a very poorly behaved vector field. It is noisy, discontinuous, and in many places equal to zero. Almost everywhere, neighboring points need to step in drastically different directions. This creates a situation where improving one cell's loss will necessarily worsen its neighbor's losses, which means that in practice this method can never converge. It's a dead end. Instead let's draw an analogy to Computational Fluid Dynamics. We need to dilate certain cells and shrink others according to a brightness function. This is similar to modeling compressible air flow where each cell has pressure defined as a pressure function. If every cell in a 2D grid has some initial pressure, how does the system relax over time? The regions with high pressure expand and the regions of low pressure contract, with regions of middling pressure getting shoved around in a sort of global tug-of-war. Clearly, our problem is analogous. So, how is this problem solved in CFD simulations? A standard approach is to define a Velocity Potential called Φ Φ (read: phi). The Velocity Potential Φ Φ is a scalar field defined at each cell. Its units are 𝑚 𝑒 𝑡 𝑒 𝑟 𝑠 2 / 𝑠 𝑒 𝑐 𝑜 𝑛 𝑑 meters2/second which at first glance is not very easy to interpret. But the reason Φ Φ is convenient is that its spatial derivatives are measured in 𝑚 𝑒 𝑡 𝑒 𝑟 𝑠 / 𝑠 𝑒 𝑐 𝑜 𝑛 𝑑 meters/second. In other words, the gradient of Φ Φ gives a vector whose units are velocity: ∇ Φ = ( ∂ Φ ∂ 𝑥 , ∂ Φ ∂ 𝑦 ) = 𝑣 ⃗(1.2) ∇Φ=(∂x∂Φ,∂y∂Φ)=v(1.2) Here is an example Φ Φ. It is just some scalar field best viewed as a heightmap. And here is the gradient of that same Φ Φ. These vectors are velocity vectors that point uphill. If we were performing Computational Fluid Dynamics, these vectors would indicate how fluid might flow from regions of high pressure to regions of low pressure. Notice how well behaved this vector field is! There is gentle variation across the field but any two neighbors are very similar to each other. None of the arrows pierce the boundary. In our case we don't have fluid pressure, we have light pressure. Regions in our image which are too bright have high light pressure, which is quantified in our loss function 𝐿 L. If we can somehow use 𝐿 L to find a Φ Φ that describes our light pressure distribution, all we need to do is calculate 𝑣 ⃗ = ∇ Φ v=∇Φ and we'll be able to morph all of our lens grid points according to 𝑣 ⃗ v to decrease our loss! So how do we find a suitable Φ Φ? Well, the property we know about each cell is its loss, which encodes how much that cell needs to grow or shrink. This property, how much a cell grows or shrinks over time as it moves with a velocity field, is called the divergence of that field. Divergence is written as ∇ ⋅ ∇⋅, so in our case, we know that we need to find a velocity field 𝑣 ⃗ v whose divergence equals the loss: ∇ ⋅ 𝑣 ⃗ = 𝐿 ( 𝑥 , 𝑦 )(1.3) ∇⋅v=L(x,y)(1.3) Unfortunately there is no \"inverse divergence\" operator so we cannot easily invert this equation to find 𝑣 ⃗ v directly. But we can plug equation ( 1.2 ) (1.2) in to equation ( 1.3 ) (1.3) to yield: ∇ ⋅ ∇ Φ = 𝐿 ( 𝑥 , 𝑦 )(1.4) ∇⋅∇Φ=L(x,y)(1.4) Which we read as The divergence of the gradient of the potential field Φ Φ equals the loss. This equation comes up surprisingly frequently in many branches of physics and math. It is usually written in a more convenient shorthand: ∇ 2 Φ = 𝐿(1.5) ∇2Φ=L(1.5) Which you may recognize as Poisson's Equation! This is fantastic news because Poisson's equation is extremely easy to solve! If you aren't familiar with it, just think of this step like inverting a big matrix, or numerically integrating an ODE, or finding the square root of a real number. It's an intricate, tedious task that would be painful to do with a paper and pencil, but it's the kind of thing computers are really good at. Now that we've written down the problem as Poisson's Equation, it is as good as solved. We can use any off the shelf solver, plug in our known 𝐿 ( 𝑥 , 𝑦 ) L(x,y) using Neumann boundary conditions and boom, and out pops Φ ( 𝑥 , 𝑦 ) Φ(x,y) as if by magic. Can you figure out why the cat appears so clearly in this 3D rendering of Φ Φ? What controls the brightness of each pixel in a render like this? We plug Φ Φ in to Equation ( 1.2 ) (1.2) to find 𝑣 ⃗ v and we take a look at the vector field: Disappointingly, it does not look like a kitty to me. And technically we need to march our points in the direction of negative ∇ 𝐿 ∇L if we want to decrease 𝐿 L. Here's − ∇ 𝐿 −∇L: But the good news is that this vector field is smooth and well-behaved. We simply march the grid points along this vector field and we'll get exactly what we need. If you squint you can almost see how the bright background will expand and the cat's dark fur will shrink. We step all the lens grid points forward some small amount in the direction of − 𝑣 ⃗ −v. After morphing the grid a tiny amount we recompute the loss function 𝐿 L, find a new Φ Φ and new − 𝑣 ⃗ −v, and take another small step. # In Julia-flavored psuedocode image = read_image(\"cat.png\") gray = convert_to_grayscale(image) grid = create_initial_grid(gray.size + 1) L = compute_loss(gray, grid) while max(L) > 0.01 ϕ = poisson_solver(L, \"neumann\", 0) v = compute_gradient(ϕ) grid = step_grid(grid, -v) L = compute_loss(gray, grid) end After three or four iterations the loss gets very small and we've got our morphed cells! Look at how this cat's chin ballooned out but her nose and forehead shrunk. Her left ear is noticably longer and thinner because the bright background had to grow to take up more light. Her pupils went from oblong to sharp. Note that image on the right is just a screenshot of Fusion360's default mesh rendering with the wireframe turned on: The reason it is darker in some areas is because the mesh is more tightly packed in those areas. Let's zoom in on the eye: Look at how detailed that is! We've managed to capture even the bright reflections in her eyes. Zooming in further to just the pupil: We can see the fine structure of the grid cells. Our formulation of the problem is only concerned with cells as quadralaterals. The triangles you see are just an artifact of converting our quadralateral grid into a triangle mesh more suitable for other software to deal with. So again, in summary: If we follow these steps we will successfully morph our grid points. Now we've got to do some geometry! Snell's Law and Normal Vectors Snell's law tells us how light bends when passing from one material to another. sin ⁡ ( 𝜃 2 ) sin ⁡ ( 𝜃 1 ) = 𝑛 1 𝑛 2(2.0) sin(θ1)sin(θ2)=n2n1(2.0) Where 𝑛 1 = 1.49 n1=1.49 is the Refractive Index of acrylic and 𝑛 2 = 1 n2=1 is the refractive index of air. If we know 𝜃 2 θ2, Snell's Law gives us 𝜃 1 θ1. Snell's law is not some arbitrary axiom of physics. It is a direct consequence of Fermat's Principle of Least Time, which is a fascinating and critical link between ray optics and wave optics. But that's a topic for another day. In our case, each lens cell ( 𝑖 , 𝑗 ) (i,j) has migrated to position ( 𝑥 , 𝑦 ) (x,y), and it needs to send its light to the image plane at ( 𝑢 , 𝑣 ) (u,v), which sits some distance away 𝑑 d. We start by defining a 3D normal vector 𝑁 ⃗ ( 𝑥 , 𝑦 ) N(x,y) which everywhere points normal to our heightmap ℎ ( 𝑥 , 𝑦 ) h(x,y). Image from Chetvorno licensed CC0 Normal vectors always point perpendicular to the surface they start on. They generally encode meaning in their direction, not their length, so we're free to scale them to any length that is convenient for our purposes. Very often people choose to make their Normal vectors of length 1 1. But if we normalize 𝑁 ⃗ N so that its 𝑧 z coordinate is − 1 −1, we can write it: 𝑁 ⃗ = ( ∂ ℎ ∂ 𝑥 , ∂ ℎ ∂ 𝑦 , − 1 )(2.1) N=(∂x∂h,∂y∂h,−1)(2.1) If you consider just the 𝑥 x and 𝑦 y components, we recognize that 𝑁 ⃗ 𝑥 𝑦 = ∇ ℎ(2.2) Nxy=∇h(2.2) Which is a property often used in computer graphics applications, as well as geospatial applications involving Digital Elevation Models. Using Snell's Law, a small angle approximation, and a lot of tedious geometry, we find the 𝑥 x and 𝑦 y components of the normal vector 𝑁 ⃗ N: 𝑁 𝑥 ( 𝑖 , 𝑗 ) = tan ⁡ tan ⁡ − 1 ( 𝑢 − 𝑥 𝑑 ) ( 𝑛 1 − 𝑛 2 )(2.3) Nx(i,j)=tan(n1−n2)tan−1(du−x)(2.3) 𝑁 𝑦 ( 𝑖 , 𝑗 ) = tan ⁡ tan ⁡ − 1 ( 𝑣 − 𝑦 𝑑 ) ( 𝑛 1 − 𝑛 2 )(2.4) Ny(i,j)=tan(n1−n2)tan−1(dv−y)(2.4) There is nothing interesting about this derivation so I've skipped it here. Finding the Heightmap At this point we have our morphed grid cells and we've found all our surface normals. All we have to do is find a heightmap ℎ ( 𝑥 , 𝑦 ) h(x,y) that has the required surface normals. Unfortunately, this is not a problem that is solvable in the general case. We could try to integrate the normals manually, starting at one corner and working our way down the grid, but this method does not usually result in a physically realizable object. If the integral of the normals running left to right pulls your surface up, but the integral of the normals running top to bottom pulls your surface down, there is just no solution that results in a solid, unbroken surface. A much better approach is to reach back to equation ( 2.2 ) (2.2), repeated here: 𝑁 ⃗ 𝑥 𝑦 = ∇ ℎ(2.2) Nxy=∇h(2.2) And to take the divergence of both sides: ∇ ⋅ 𝑁 ⃗ 𝑥 𝑦 = ∇ ⋅ ∇ ℎ(2.5) ∇⋅Nxy=∇⋅∇h(2.5) Do you recognize the form of this equation? Adopting shorthand and swapping sides: ∇ 2 ℎ = ∇ ⋅ 𝑁 ⃗ 𝑥 𝑦(2.6) ∇2h=∇⋅Nxy(2.6) We arrive at yet another instance of Poisson's Equation! We found 𝑁 ⃗ 𝑥 𝑦 Nxy in the previous section, and calculating the divergence of a known vector field is easy: ∇ ⋅ 𝑁 ⃗ 𝑥 𝑦 = ( ∂ ∂ 𝑥 , ∂ ∂ 𝑦 ) ⋅ ( 𝑁 ⃗ 𝑥 , 𝑁 ⃗ 𝑦 ) = ∂ 𝑁 ⃗ 𝑥 ∂ 𝑥 + ∂ 𝑁 ⃗ 𝑦 ∂ 𝑦(2.7) ∇⋅Nxy=(∂x∂,∂y∂)⋅(Nx,Ny)=∂x∂Nx+∂y∂Ny(2.7) In code it looks like: δx = (Nx[i+1, j] - Nx[i, j]) δy = (Ny[i, j+1] - Ny[i, j]) divergence[i, j] = δx + δy All that's left is to plug our known ∇ ⋅ 𝑁 ⃗ 𝑥 𝑦 ∇⋅Nxy in to a Poisson solver with Neumann boundary conditions and out pops ℎ ( 𝑥 , 𝑦 ) h(x,y), ready to use! Well, there's one thing left to improve. By modifying the height of each point we've actually changed the distance from each lens point to the image, so the lens-image distance is no longer a constant 𝑑 d it is actually a function 𝐷 ( 𝑥 , 𝑦 ) D(x,y). With our heightmap in hand we can easily calculate: 𝐷 ( 𝑥 , 𝑦 ) = 𝑑 − ℎ ( 𝑥 , 𝑦 )(2.8) D(x,y)=d−h(x,y)(2.8) And repeat the process by calculating new normals using 𝐷 ( 𝑥 , 𝑦 ) D(x,y) instead of 𝑑 d, which lets us create a new heightmap. We can loop this process and measure changes to ensure convergence, but in practice just 2 or 3 iterations is all you need: # In Julia-flavored psuedocode d = .2 # meters D = d .* array_of_ones(n, n) for i in 1:3 Nx, Ny = compute_normals(grid, D) divergence = compute_divergence(Nx, Ny) h = poisson_solver(divergence, \"neumann\", 0) D = copy(h) end The resulting heightmap can be converted to a solid object by adopting a triangular grid and closing off the back surface. Note that the image looks mirrored when looking at it head on. That's because the heightmap forms the back surface of the Magic Window. The front surface is factory flat. The height differences are subtle but certainly enough to get the job done. Manufacturing The process of manufacturing our Magic Window is identical to carving any other 2.5D object. We bring our object into Fusion360 or any other CAM software. We set up a roughing toolpath left to right, and a finishing toolpath top to bottom just like you find in most tutorials. Any old CNC router or mill will work. I designed and built my own router last year. If you want to do the same I recommend you start here. I used a 1 4 41 inch diameter, ball-nosed, carbide bit for both roughing and finishing passes, which took 10 minutes and 90 minutes respectively. After carving the surface finish is rough and transluscent. We need to wet sand using 200 , 400 , 600 , 1000 200,400,600,1000 and 1500 1500 grit sandpapers, then finish with a soft rag and some automotive polish. Sanding and polishing takes about half an hour for a 10 𝑐 𝑚 × 10 𝑐 𝑚 10cm×10cm Magic Window. Acknowledgements All of the math for this post came from Poisson-Based Continuous Surface Generation for Goal-Based Caustics, a phenomenal 2014 paper by Yue et al. If you continue this work in some way, please cite them. My Code My source code is available here. I am a novice at programming in Julia so if you have suggestions for how to improve this code, please reach out or make a pull request! Caveats: There are a lot of issues with my code. I confuse 𝑥 x and 𝑦 y in several places. I have extra negative signs that I inserted that make the code work but I don't know why. My units and notation are inconsistent throughout. The original paper suggests a better way of calculating loss but I didn't implement it because the naive way was easier, yet I rolled my own mesh utilities and Poisson solver because I enjoyed the challenge. In short: To me this code is a fun side project. If you want to build a business off of this code you should probably hire someone who knows how to program professionally in Julia. Licensing I've posted all my code under the MIT license. Please feel free to use this code for anything you want, including hobbyist, educational, and commercial uses. I only ask that if you make something, please show me! Except where otherwise attributed, all images in this blog post and the blog post itself are my own work that I license as CC-BY. The cat in this post is named Mitski and she approves of you using her image as the new standard reference image for image processing papers. It's time to let Lenna retire. Contact me If you use my code to make your own Magic Windows, I'd love to see them! I'm on Twitter at @mferraro89. Email me at mattferraro.dev@gmail.com and I will gladly help if you get stuck! One Last Thing I know what you're thinking. What about the hologram?! Does the math above imply that a hologram will always be created, or is this one cat hologram just an incredible coincidence? Well you see, I've discovered a truly marvelous proof of this, which this website's margin is unfortunately too narrow to contain :)",
    "commentLink": "https://news.ycombinator.com/item?id=41842775",
    "commentBody": "The Physics of Magic Windows (2021) (mattferraro.dev)167 points by mhb 19 hours agohidepastfavorite9 comments isoprophlex 1 hour agoQuite curious that the backside of the lens is modeled as a mesh of quads with varying (x, y). I could imagine that a fixed grid of points with only varying height would be easier to model, am I missing something crucial? You can probably build an end-to-end model of a grid of heights (constrained to be h=0 at the edges), a simulated ray exiting the slab (surface normals modified by whatever Snell's law tells you), and the eventual light intensity on the target plane... and immediately optimize the entire thing with backprop? I'm probably massively oversimplifying this and ignoring half of the physics reply injidup 12 hours agoprevNot to take away the brilliance of what is achieved but I think hologram is the wrong word. This is purely about caustics. Amplitude engineering rather than phase. The calculations are just assuming light as particle, not light as wave. A true hologram uses diffraction grating effects and the phase difference from light. There was a very nice explanation on three-blue-brown recently. https://www.youtube.com/watch?v=EmKQsSDlaa4 I don't think there are any phase effects in the parent attached? Or are there? reply gpderetta 9 hours agoparentDepends if we consider holograms only the specific technique of using phases to encode the information or any general technique that can encode 3D information on a 2D surface. This solution relies on a physicals height map (in the author's word, a 2.5D surface), whether that counts as a 2D surface I don't know. (and yes, I also saw the great explanation from 3blue1brown). reply CyberDildonics 2 hours agorootparentany general technique that can encode 3D information on a 2D surface This isn't 3D information on a 2D surface. If anything it is 2D information on a 3D surface. reply rawgabbit 14 hours agoprevReminds me of magic mirrors of Japan and China. https://www.cnn.com/style/article/magic-mirror-cincinnati-ar... https://www.greenshinto.com/2014/02/16/magic-mirrors/ reply mkmk 19 hours agoprevSome nice comments on this previous discussion of the same link: https://news.ycombinator.com/item?id=28283411 reply dang 18 hours agoparentThanks! Macroexpanded: Hiding Images in Plain Sight: The Physics of Magic Windows - https://news.ycombinator.com/item?id=28283411 - Aug 2021 (24 comments) Hiding Images in Plain Sight: The Physics of Magic Windows - https://news.ycombinator.com/item?id=28220376 - Aug 2021 (1 comment) reply shiko11pin 15 hours agoprevSimilar to \"Pixel Window\" link: https://x.com/Hakusi_Katei/status/1807591865132466324 reply LarsDu88 16 hours agoprev [–] That's so cool! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A transparent acrylic square was created to form images using light and a phenomenon known as caustics, which involves directing light through surface manipulation.",
      "The process includes creating a heightmap, morphing grid cells, and applying Snell's Law for light refraction, with manufacturing done via CNC routing and polishing.",
      "The project is based on a 2014 paper by Yue et al., and the code is available under the MIT license, encouraging others to create their own versions."
    ],
    "commentSummary": [
      "The discussion examines the modeling of lenses using a mesh of quads and considers whether a grid with varying heights might offer a simpler alternative.",
      "It differentiates between caustics and holograms, highlighting the lack of phase effects in the former, which are present in true holograms.",
      "References are made to historical \"magic mirrors\" from Japan and China, as well as related concepts like \"Pixel Window.\""
    ],
    "points": 167,
    "commentCount": 9,
    "retryCount": 0,
    "time": 1728944747
  },
  {
    "id": 41841581,
    "title": "Project Euler #912: Where are the Odds?",
    "originLink": "https://projecteuler.net/problem=912",
    "originBody": "403 Forbidden Request forbidden by administrative rules.",
    "commentLink": "https://news.ycombinator.com/item?id=41841581",
    "commentBody": "Project Euler #912: Where are the Odds? (projecteuler.net)160 points by fzliu 22 hours agohidepastfavorite87 comments joshlemer 16 hours agoI've been thinking recently about how things like Project Euler, LeetCode, and to a bit less of an extent, Advent of Code, are so heavily focused on making clever use of math, data structures and algorithms, that it makes them suboptimal as a tools for getting familiar with a new programming language. I know that that critique isn't new to anyone but it makes me think about how it would be cool if there were a code puzzler site that is specifically geared towards little self-contained tasks that are more to do with forcing you to get familiar with the common everyday tasks of software development. Some example puzzlers could be like: - open an http server on port 80 - open a file and write this data to it - write temporary files to a location, deleting them when process exits - query a database - deal with such and such error scenario - find a way to test this component - bundle this code as an executable - sanitize user input here - make this behavior configurable - take the config from environment variable variable and/or config file and/or arguments - parse this data file You do get a bit of parsing and file handling with Advent of Code but imagine a series of dozens of small problems that grill you on every corner of the python filesystem api. Would be a lot less dry than reading docs cover to cover. reply 110jawefopiwa 14 hours agoparent> Advent of Code, are so heavily focused on making clever use of math, data structures and algorithms I've done a fair amount of Advent of Code and I wouldn't say it's at all \"focused\" on this. The vast majority of the questions use hash tables and graph traversal as the full extent of their use of math/DS/algos. There's always one or two puzzles every year that require some particular math/CS insight but most of them just need you to know BFS and/or how to write a parser. Your examples are also not bad, but they seem to be primarily concerned with \"getting familiar with a new programming language\" in the context of writing a web server, which is one of the parts of programming I try to stay away from. Most of your examples require less familiarity with the language's features and more with libraries you might use, which is less interesting to me personally (then again, I'm a PL fan and I write compilers for a living). Meanwhile, I like AoC because I've used language features to take the fairly straightforward potential implementations and write them more elegantly in the language I choose. e.g. I use Monads in Haskell, or use Rust's easy threading to parallelize solutions, etc. For me, learning a new programming language is largely uninteresting unless it changes the fundamental \"shape\" I think in, rather than what the exact names of the libraries I use change to. e.g. I already know Java so I'm not really going to bother \"learning\" C#. I already know Python so I don't really bother diving deep into Ruby, etc. However, I learn Haskell, Rust, Forth, Erlang, Scheme, etc. reply legends2k 1 hour agorootparentExercism.io does what you want? It has language tracks and each track has questions geared to seal your understanding of some language concept. It also has it gamified by building a community around it and folks comparing their solutions. reply fulafel 12 hours agorootparentprevAoC is still is algorithms and data structures: there's minimal interaction with the outside world, just solving the problem for the input data. It's just about coming up with the algorithm yourself instead of applying fancy well-known ones. reply cabidaher 8 hours agorootparent> just solving the problem for the input data I think a lot of people here would be surprised how much of a step up this is from classic leetcode or DSA stuff. I have been involved in introducing people to AoC and helping them and the amount of people who have basic knowledge of algorithms but struggled to parse the input from a file was a little shocking to me at first. Of course, I do not blame anyone for not knowing something, classic academic courses can be misguided sometimes. This doesn't negate the fact that there is somewhat of a lack in problems with more outside world interaction and it would be cool to see more of that. reply wodenokoto 9 hours agorootparentprev> It's just about coming up with the algorithm yourself instead of applying fancy well-known ones. Isn’t that the whole fun? reply aleph_minus_one 16 hours agoparentprevHave a look at Rosetta Code > https://rosettacode.org/wiki/Rosetta_Code This might be a little bit nearer to what you look for. --- > it would be cool if there were a code puzzler site that is specifically geared towards little self-contained tasks In my opinion the tasks on Project Euler or LeetCode are much more self-contained than what you suggest as alternatives: many of your suggestions are deeply intertwined with libraries (and understanding them) for doing the respective task instead of being self-contained programming tasks. reply CSMastermind 14 hours agoparentprevThe best recommendation I have for anyone trying to learn a new programming language is to try and program a board game. There will be clear rules (business logic), UI, etc. It's a confined enough problem that you can implement it without too much effort but deep enough that you can get a feel for how that programming language, framework, whatever works. Plus there's a near endless set to choose from and it's easily scalable to the level of complexity you want. If it works add AI players, network play, etc. reply pncnmnp 13 hours agorootparentI think we are a bit alike in our views, but I have a slightly different take on it. I consider coding something like a Chip-8 emulator to be more fun and optimal. It gives a holistic view of the language - you get to work with simple graphics, sound effects, and gain a feel for memory operations and data structures, as well as control structures like conditionals, looping, and exception handling. If that’s not all - for beginners, it provides an introduction to virtualizing CPUs with registers, stacks, opcode handling, memory units, arithmetic/bitwise operations, and more. You’ll even learn a bit about concurrency and synchronization, and by extension, threading. Also, performance optimization. I suppose a decent game project could achieve these things too, but the real fun of Chip-8 is in throwing different ROMs at it and debugging the issues until it’s perfect enough to play all your favorite games! reply twoquestions 6 hours agoparentprevI really think you'd like these two project pages, they were posted to HN some time ago but the original links have been slain by bitrot. https://austinhenley.com/blog/challengingprojects.html https://austinhenley.com/blog/morechallengingprojects.html reply legends2k 1 hour agoparentprevExercism.io does what you want? It has language tracks and each track has questions geared to seal your understanding of some language concept. It also has it gamified by building a community around it and folks comparing their solutions. reply hoten 16 hours agoparentprevto be fair, PE is not designed or meant for helping people learn a language. that isn't the project's intent. people do like to say they use PE for learning new languages, but I doubt that is a useful exercise beyond maybe the first dozen problems or so. And even then, if the solution isn't obvious to you, you're doing two things at once - learning a language and solving a math puzzle. I don't see why people would sign up to get frustrated like that. reply Bjartr 6 hours agorootparent> I don't see why people would sign up to get frustrated like that. I actually use this as a learning trick. Pick two or three things to learn simultaneously, then when I get stuck on one aspect, switch to another. When I finally switch back, I often find the background time I gave my brain to process the problem means I'll now be much faster to get unstuck on the original issue. There's definitely ways this can go sideways, and it's not for everybody, but I find it pretty effective. reply joshlemer 2 hours agorootparentI guess the trouble is that in the case of LeetCode/PE, people actually just want the one thing (programming language proficiency), and not the other (mathematics). Learning 2 things at once can be very useful, but a lot of people would probably choose something else for their second skill. Most relevant for developers might be, networking, OS's, version control, databases, testing, CI/CD, security, concurrency. reply joshlemer 15 hours agorootparentprevOh yeah totally, it's not a criticism of PE, that's not what it's meant for. People just use PE and LC and AoC because that's the closest thing, but I think there is space in the market for a product I describe that really drills down on getting you familiar with the common tasks and stdlib of various languages. reply sesuximo 15 hours agoparentprevThat’s just a job. Might as well get paid while you do that kinda stuff reply srcnkcl 7 hours agoparentprevCodewars can do this, they keep how problems was solved. If a problem was solved using some string by most answers than it is a good problem to learn that part of the language. With documentation you have really good way to cover all parts of a programming language. reply port19 11 hours agoparentprevMost of these wouldn't qualify as \"puzzles\", would they? I find it nice to learn new languages via data structure puzzles, because to me the data structures of a language feel like the grammar and once I have that down everything else falls into place reply joshlemer 3 hours agorootparentI disagree. Yes, you have to learn how to work with the basic data structures of a language, but 90% of programming, for most people, is not that. It's IO, error handling, db querying, logging, input parsing, parameterization, business logic, preserving backwards compatibility, persistence, state management, testing, mocking, benchmarking, build design (for lack of better term -- futzing around with Make/Gradle/Npm, Dockerfiles). All of that doesn't just fall out of learning DS/Alg's, it takes time to become familiar and fluent in how all these are done in your ecosystem. When employers or team mates ask you if you \"know\" or \"are competent in\" Java they don't care if you know how to work with lists, arrays, loops, hashmaps and sets. Well, I mean, that's table stakes. They're asking if you're familiar with the idiosyncrasies of the language with respect to those above concerns. reply xigoi 2 hours agorootparentI think you overestimate the proportion of programmers who primarily work on corporate stuff. reply cjohnson318 15 hours agoparentprevI really, really like this list. I've been wondering for the last year what the \"optimal\" problem is to learn at least the syntax of a language. After learning to run something, how to print to the console, I like using heapsort to start learning syntax of a new language, then reading/writing to a file, then building a small TodoList server. reply dan353hehe 16 hours agoparentprevOne that I like to suggest, which covers more terminal and Linux skills then programming, is https://overthewire.org/wargames/ reply jiggawatts 13 hours agoparentprevSomething I'd love to see is \"AoC hard mode\": the exact same problems but the input data set is ~10 GB, and/or similarly \"scaled\" such that naive solutions fail outright. Other scaling-of-inputs could include: Text with line-lengths over 2 GB, numbers above 2^60, data designed such that naive nested-loop solutions (quadratic scaling) take over a year to compute the answer, etc... Basically, force developers to solve the problem robustly with: streaming, parallelism, efficient algorithms with good big-O properties, correct data type choice (including intermediate accumulator values!), and so forth. It could be a three-star challenge feature added to the current version. It wouldn't even require large downloads: a Python script or something similar could be used to generate arbitrarily large inputs. (Alternatively, a common CDN-cacheable prefix with a distinct suffix per competitor.) reply philiplu 13 hours agorootparentThat's exactly what Project Euler problems often do, especially once you get past the first hundred or two. Problems are scaled so a brute-force often means hours to days of compute time, or worse. You get to recognize the effect - if I see a problem that's clearly number-theory related and with a limit of 10^12, I know they're looking for a sublinear algorithm, probably O(n^(2/3)) thanks to various multiplicative function ideas that appear over and over. reply SynasterBeiter 11 hours agorootparentprevThere are a couple posters on 4chan's /g/ threads on AoC that create \"Big Boy\" inputs, which is what you're looking for. It's unofficial, though. reply drewcoo 11 hours agoparentprevIf you're trying to model those \"puzzlers\" on actual dev work, then doing any of those things without a library/framework is a wrong answer. Or is that your point? That coding like a pro means gluing those things together? reply joshlemer 3 hours agorootparentA few different things: 1. Yes, solving these puzzles would mean often mean using a library. 2. However, for most of the things I listed above, in most languages, a competent software developer should be able to, and most likely would just use the standard library. 3. Why not both? I can imagine a catalog with thousands of problem sets. Some may challenge you to (re-)implement some existing functionality yourself (as a super basic example, re-implement the java Optional::flatMap method or something). Others could challenge you to make use of existing implementations. Learning to make use of stdlib and other libraries and tools in the ecosystem is part of one's growth, and also so is working through those tools, tinkering, trying to think how you would have implemented them, and getting a better understanding of their internals (or at least, an understanding of how their internals MIGHT work) reply Sohcahtoa82 19 hours agoprevDuring the solving of a problem on Project Euler, I learned that compilers are smarter than me. I don't remember the problem number or its title, but it involved starting from the top-left corner of a 2D grid and finding how many possible paths there are to get to the bottom-right corner while only moving either down or right. My naive solution was a brute-force depth-first recursive search. On my CPU at the time, it took about 3 minutes to solve. I thought, the logic of this is incredibly simple, why not do it in assembly? My assembly solution took 5 minutes. I decompiled the compiled C code to see what it had done, but I couldn't understand it. My assembly knowledge was too basic. Thinking on it now, I wonder if a modern compiler would solve the entire problem at compile-time and just hard-code the answer to be output at runtime. reply guessmyname 19 hours agoparentLattice Paths — https://projecteuler.net/problem=15 > Starting in the top left corner of a 2x2 grid, and only being able to move to the right and down, there are exactly 6 routes to the bottom right corner. ─────────┐ ────┐ ────┐ ┌───┬───┐│ ┌───│───┐ ┌───│───┐ │ │ ││ │ │ │ │ │ │ ├───┼───┤│ ├───└────┐ ├───│───┤ │ │ ││ │ │ ││ │ │ │ └───┴───┘│ └───┴───┘│ └───│───┘ ▼ ▼ └────▶│┌───┬───┐ │┌───┬───┐ │┌───┬───┐ ││ │ │ ││ │ │ ││ │ │ └─────────┐ └────┐───┤ │├───┼───┤ │ │ ││ │ │ │ ││ │ │ └───┴───┘│ └───│───┘ │└───┴───┘ ▼ └────▶ └─────────▶ > How many such routes are there through a 20x20 grid? reply Sohcahtoa82 19 hours agorootparentYup! That was it! Good job on the ASCII art, btw. reply FredPret 16 hours agorootparentprevDid you just whip out that amazing ASCII art or do you use a tool? reply guessmyname 15 hours agorootparentASCII art by hand (⌐■_■) it only took me 5 minutes or so … That said, I think someone could have done it faster with a tool like Monodraw (https://monodraw.helftone.com/) or something similar. reply dotancohen 18 hours agorootparentprev> How many such routes are there through a 20x20 grid? Is it 21! ? reply mdp2021 18 hours agorootparentNo. It's 20!/(10!x10!) You have 20 slots to be filled with 10 items vs other 10 items. reply noapologies 18 hours agorootparentClose, it's 40!/(20!*20!) 20 Rs, 20 Ds in a 20x20 grid. Example pattern: RRDDDR...D (40 letters) Basically the number of permutations, with repetition, of 20 Rs and 20 Ds. reply mdp2021 18 hours agorootparentOops! Thanks, just distraction... It's that first I wanted to see the general solution to those kind of problems (and I gave the solution for a wrong one in the class), then I wanted to verify the C implementation of the solution with POPCNT like the OP seems to have done (I am writing the code)... Edit: ...and yes, it seems that brute-forcing (counting to one trillion) takes more time than I expected. reply dotancohen 10 hours agorootparentprevNow I see it. Twenty items (R operations) in 40 slots: 40!/(20!) and the order of the items does not matter, so again divide by 20!. The remaining slots are D operations. The answer actually came to me in the shower this morning. reply Jtsummers 18 hours agorootparentprevNope, and only off by a few orders of magnitude. reply dotancohen 10 hours agorootparentIf it is any comfort, my answer produced a non-negative integer - just like the true answer )) reply fallingknife 18 hours agorootparentprevAm I missing something here or would that be as simple as 2N nCr N for an NxN grid? reply xigoi 2 hours agorootparentYou’re not missing anything. This is an easy problem aimed at people who are not familiar with basic combinatorics. reply archgoon 17 hours agoparentprevSo fun fact, if you compile int sum(int n) { int sum = 0; for(int i = 0; isqrt(INT_MAX). Is it? And if so, is the compiler somehow smart enough to know that? reply xigoi 2 hours agorootparentIf you assume two’s complement arithmetic, then this is always equivalent because you’re basically just calculating the answer in a modular ring. reply marin049 14 hours agorootparentprevInteger overflow is actually undefined behaviour thus the compiler is free to assume it doesn't happen. reply j2kun 16 hours agorootparentprevI believe the term for this is scalar evolution. reply archgoon 16 hours agorootparentYep! That is it alright. Here's a talk from an llvm conference with the details. https://www.youtube.com/watch?v=AmjliNp0_00 reply gerdesj 17 hours agoparentprevWe all have our skills and super powers and yours do not involve optimizing for time by switching from C to ASM. Fuck that! I bet you have super powers of some sort. Compilers are not smarter than you - that's daft. The nutters that program the compilers and tweak and twiddle them, are better informed about how to deliver faster machine code for a given task. One of your super powers is to know when to say: \"fuck it, I'm trotting off and getting by with a five minutes runtime\". reply johnsonjo 19 hours agoparentprevSounds like problem 15 [1]? [1]: https://projecteuler.net/problem=15 reply Sohcahtoa82 19 hours agorootparentYup! That was it! reply wging 18 hours agorootparentIf you want a few similar problems, in ascending order of difficulty, try #81 through #83: https://projecteuler.net/problem=81 https://projecteuler.net/problem=82 https://projecteuler.net/problem=83 reply SatvikBeri 18 hours agoprevProject Euler is a lot of fun if you like a dash of math in your programming. The problems generally won't apply to your job or even to interviews, so don't go in expecting that. My favorite is https://projecteuler.net/problem=113, \"Non-Bouncy Numbers.\" It takes some clever tricks to figure out but doesn't require any significant background knowledge, and the optimizations required to get it to run within 60 seconds (at least for my approach) all felt reasonable. reply munchler 18 hours agoparentMore than a dash. I would describe Project Euler as math problems that you need a computer to solve. reply wging 15 hours agorootparentThat’s mostly right, but some of them don’t require a computer. I’ve never solved one with just pencil and paper, but in some of the solution threads you will actually find pencil and paper solutions. I’m not sure if any of the later problems work like that, though. reply byearthithatius 17 hours agorootparentprevWell said, that is always how I saw it as well. The sort of math problem solving we did for fun in school but all the problems require programmatic thinking and usually eventually an algorithm. I learned so much from doing Eulers. Even basic stuff I thought I would know like the best way to get GCD reply guessmyname 19 hours agoprevWhy problem 912 specifically? On a side note, I remember when the website got hacked [1][2]. Many people, including myself, migrated to other platforms, but Project Euler problems always remained math-focused compared to the myriad of other websites like LeetCode and HackerRank, among others, listing programming-focused problems, which eventually popularized the use in modern tech interviews. [1] https://news.ycombinator.com/item?id=9990221 [2] https://www.reddit.com/r/math/comments/28jp7x/x/ reply ThrowawayTestr 18 hours agoparentIt's the most recent reply toomuchtodo 21 hours agoprevThe OG LeetCode. Highly recommend, helpful for becoming fluent in a programming language. reply llm_trw 19 hours agoparentI wouldn't. The majority of problems there have mathematical optimizations which real problems never do. Worse if you start thinking in the way those problems encourage you to your programs will be completely invalidated even with a tiny change in the spec. A good set of questions would be something between the advent of code - where the problems are hard because the spec is so bad on purpose - and project Euler - where the spec is so exact you don't really need a computer to solve the problems with enough thinking. Something like 'plot the histogram of collatz sequence lengths of the first 100,000 numbers'. reply KeplerBoy 12 hours agorootparentThe AoC spec isn't bad though? The text always clearly states how your code has to behave, albeit it doesn't spell out every edge case you might overlook. Real world specs on the other hand is often contradictory and impossible to fullfil. reply Cyclone_ 20 hours agoparentprevI'd argue you can usually find problems on project euler that are a little more obscure than what you'd typically get on leetcode. reply metabagel 16 hours agoparentprevAdvent of Code is great for this. reply drewcoo 10 hours agoparentprevAgreed about learning a new language starting with PE. After that, I like to invent a big gnarly scenario that I don't have to completely solve, but one that takes me well out of the range of typical cookie-cutter tutorials. I want to find all the sharp edges on a new language/library/framework. reply RodgerTheGreat 20 hours agoprevFor those who enjoy regular streams of programming puzzles similar to Project Euler, The Weekly Challenge is another fun resource: https://theweeklychallenge.org reply throwaway918299 21 hours agoprevI love Project Euler, it’s my go-to for learning the basics of new programming languages I want to learn. reply kevinventullo 17 hours agoprevI miss having the time and energy to do these. Maybe in retirement :) reply tocs3 21 hours agoprevI have spent a little time with Project Euler. Is it very popular with those here at HN? reply Twirrim 19 hours agoparentI don't know that I'd gauge anything by popularity with the HN crowd. It's also a diverse group. I'm closing in on a hundred problems solved, in a not very completion-ist fashion (I've got a whole bunch of skips and random choices of puzzles). Maths isn't my strongest suit, and I have no academic comp-sci background, so there's been a number of these I sort of brute force and then go read the answers in the thread; or I brute force the first few integers in the sequence and then try and wrap my head around what https://oeis.org/ is attempting to tell me about them. It has challenged me a bit on some of my fundamentals with programming, really making me think about efficiency etc. While I've done most of the problems in rust so far, I've been having to refresh my knowledge of Go recently, so I've started porting answers between the two languages, and it's definitely helping there a bunch. reply coffeemug 18 hours agorootparenthttps://oeis.org/ is an incredible website! Thanks for sharing. reply philiplu 20 hours agoparentprevIt’s my game plan for keeping my brain active in retirement. Been heavily involved for the past 7 years. Been at the 100% solved level since summer 2023, though I’m back to one away the past couple weeks - PE910 is _hard_ reply procparam 20 hours agorootparentWow. The idea of getting to 100% on PE is almost incomprehensible to me. I've solved basically none outside the first couple pages. What was your strategy like? How much math background do you have? reply philiplu 19 hours agorootparentI've got a bachelor's in math, but that's 40+ years ago. I had intended to go on for a PhD in math, but fell into computers instead - programming was easier and way more lucrative, even in the early 80s. Once I was retired and found my way to Project Euler, it became an obsession, tickling that desire to go deeper into math that I had in my college days. I attacked roughly the first 250 problems in order. The early problems build on each other to introduce new topics. I also got good at figuring out the right search term to find some random paper in number theory, combinatorics, probability, whatever. Later problems introduced new, more niche areas, like chromatic polynomials and impartial & partisan game theory. But by then, I found it much easier to figure out what part of math a problem was based on and how to find relevant literature. It helps to be really really stubborn, and to have the patience to let a problem stew in my brain, sometimes for weeks at a time. That seems to help lead to that Eureka moment. reply whatshisface 2 hours agorootparentI feel a lot better knowing that searching the literature is supposed to be a normal part of Project Euler. reply tocs3 18 hours agorootparentprevDo you have a favorite? reply philiplu 18 hours agorootparentAs a class of problems, I'd say the combinatorial game theory ones are my favorites. There are a lot of impartial game theory problems - look for problems mentioning Nim or stone games. They build on each other nicely, from the mid 300s on. The site has been getting into partisan game theory problems in the past year, which finally got me to buy \"Winning Ways For Your Mathematical Plays\", vol 1, and \"Lessons In Play\". I find pretty much any problem with John Conway's influence fun to do. As for a single problem, I'm fond of PE589, \"Poohsticks Marathon\". That was my 501st solution, two years after first attempting it (solved 5 years ago, yikes). I like it because it's a problem with a 95% difficulty rating, so very tough, but the development team slotted it in as an easy problem (problems normally get scheduled in batches of 6 with a cadence of medium/easy/medium/easy/medium/hard). Once I solved it, I agreed that it was relatively easy, in that it uses techniques introduced by early PE problems, but something about it makes using those techniques unexpectedly difficult. reply dahart 20 hours agoparentprevIt’s been discussed quite a bit in the past. I love Project Euler, but haven’t been active for a few years. Even then I felt like the social aspect of it wasn’t designed for newcomers; a lot of activity on new problems happens as soon as it becomes available and then it mostly freezes. The problems get pretty hard on average once you’re past the first hundred, one reason I personally found it hard to keep going. reply n4r9 20 hours agoparentprevTo be honest, I don't see people talking about it that much. But I'm certain that it would appeal to a good chunk of the people here. reply glouwbug 20 hours agorootparentBut isn’t it mathematical computing? I feel like leetcode DSA is closer to your average HN user reply n4r9 3 hours agorootparentThere's certainly a strong element of computational mathematics. A lot of the problems deal with things like Mersenne Primes or Collatz sequences. On the other hand, there are problems like \"Maximum Path Sum\" which definitely make use of DSA-style tricks (https://projecteuler.net/problem=67). reply tocs3 18 hours agorootparentprevHas here been any work done to find out about the average HN user? It seems like it would be a hard thing to do but it might be interesting to see. I do not even know what sort of metrics would be useful to measure. reply abnry 17 hours agoprevI have great memories of competing with a college friend to solve these problems. Since I last seriously did the problems, probably 15 years ago, they have added a lot more. reply londons_explore 20 hours agoprevProject Euler 241 I have never really understood... reply andy81 19 hours agoparentCheck if the sum of number's divisors divided by the number itself gives x.5 reply londons_explore 8 hours agorootparentOh - I understand the question. I just don't understand how to calculate the answer up to 10^18 in a reasonable amount of time! reply bizzyskillet 20 hours agoprevThis is cool! Are there solutions I can check my answers against? reply dullcrisp 20 hours agoparentYes make an account and you can enter your solutions reply degoodm 17 hours agoprev [–] ChatGPT o1 seems to understand the problem correctly but doesn't get far: https://chatgpt.com/share/670dbe0e-087c-8000-9856-996c3fbaa9... o1 thought for 105 seconds, cycling through many relevant-sounding status messages like \"looking for patterns,\" before writing a collection of thematic but flawed thoughts. The \"Calculation Steps\" approach is incorrect, but correctly implemented by the code. It flubs a basic calculation that it correctly implements in python: \"10^16 mod (10^9 + 7) = 49\" (it's actually 930000007) but succeeds in a seemingly harder calculation: \"the modular inverse of 12 modulo 10^9 + 7 is 83333334\" Finally, o1 claims the code prints \"0\" when it actually prints \"982790507\" (both wrong answers). Note: input was copied from the html-only Project Euler url since the formulas in the human-optimized url are not copyable: https://projecteuler.net/minimal=912 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Platforms like Project Euler, LeetCode, and Advent of Code emphasize math, data structures, and algorithms, which may not be optimal for learning new programming languages.- There is a suggestion for a platform that focuses on practical software development tasks, such as server setup, file handling, and database queries, to better familiarize users with everyday programming.- While some platforms like Exercism.io and Rosetta Code offer language-specific challenges, the concept of a site dedicated to practical programming tasks is still considered attractive and potentially beneficial."
    ],
    "points": 160,
    "commentCount": 87,
    "retryCount": 0,
    "time": 1728937649
  }
]
