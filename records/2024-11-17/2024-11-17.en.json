[
  {
    "id": 42161919,
    "title": "CSS gets a new logo and it uses the color `rebeccapurple`",
    "originLink": "https://michaelcharl.es/aubrey/en/code/new-rebeccapurple-css-logo",
    "originBody": "CSS Gets a New Logo: And It Uses the Color `rebeccapurple` Michael Charles Aubrey // Sun Nov 17 2024 codeCSSdesignrebeccapurplelogo日本語版 🇯🇵 A community vote in the CSS-Next repository on GitHub decided on a new official logo for CSS. The design follows the design language of the logos of other web technologies like JavaScript, TypeScript, and WebAssembly. But perhaps more importantly, the logo uses the color rebeccapurple (#663399), a color that was added to the CSS specification in 2014 in honor of Eric Meyer's daughter, Rebecca, who passed away at the age of six on her birthday from brain cancer. Eric Meyer, author of several books on CSS, has been an important figure in the CSS community since the late 1990s. The color was originally going to be called beccapurple, but Meyer asked that it instead be named rebeccapurple, as his daughter had wanted to be called Rebecca once she had turned six. She had said that Becca was a \"baby name,\" and that once she had turned six, she wanted to be called Rebecca. As Eric Meyer put it, \"She made it to six. For almost twelve hours, she was six. So Rebecca it is and must be.\" Go home",
    "commentLink": "https://news.ycombinator.com/item?id=42161919",
    "commentBody": "CSS gets a new logo and it uses the color `rebeccapurple` (michaelcharl.es)661 points by thunderbong 14 hours agohidepastfavorite138 comments langsoul-com 13 hours ago> The color was originally going to be called beccapurple, but Meyer asked that it instead be named rebeccapurple, as his daughter had wanted to be called Rebecca once she had turned six. She had said that Becca was a \"baby name,\" and that once she had turned six, she wanted to be called Rebecca. As Eric Meyer put it, \"She made it to six. For almost twelve hours, she was six. So Rebecca it is and must be.\" Wasn't expecting tears over a colour reply davrosthedalek 1 hour agoparentThe last two sentences of that quote hit me so hard. reply jvm___ 11 hours agoparentprev..in 2014 in honor of Eric Meyer's daughter, Rebecca, who passed away at the age of six on her birthday from brain cancer. reply userbinator 7 hours agorootparentnext [23 more] [flagged] ChrisMarshallNY 6 hours agorootparentIt is sad to see such a comment come from someone with such high karma and seniority. I hope that it is not reflective of the ethos of this community. I feel we have way too little humanity in tech. With the advent of AI, that does not promise to improve. reply kaladin-jasnah 1 hour agorootparentIt quite reminds me of Richard Stallman's reply on an email list asking people to refrain from posting about the birth of a baby on a technical mailing list. http://www.art.net/studios/hackers/hopkins/Don/text/rms-vs-d... reply bena 6 hours agorootparentprevNot to mention, we have a bunch of names that are just jokes, bad puns, random references, or idle wordplay. C# is named because it’s a step up from C++, which is one better than C, which is the next thing after B. Python is just an arbitrarily chosen name referencing a comedy troupe. Linux is Linus’s copy of Minix, which is a minimal Unix, which is based off of Multics, which is a pseudo-initialism. We have names honoring the dead; Pascal, Ada, Darwin. We can name one color in one spec in honor of one person’s dead child. It is neither a burden nor out of character for the field. If you genuinely believe it is a problem, I ask that you step back and reflect on why you truly believe it is. reply johnisgood 5 hours agorootparentprevWhat kind of humanity are we striving for? Recently, we renamed the \"master\" branch to \"main,\" which was seen by some as a step toward inclusivity. But does this truly contribute to meaningful progress? If terms like \"killing\" processes and their \"children\" in programming are deemed problematic, should we consider changing those too? Such changes risk detracting from the technical context of these terms. Regarding the \"master\" vs. \"main\" debate, it's important to remember that \"master\" in this context refers to control or central authority, not human history or social constructs. For instance, \"master/slave\" configurations in hardware have long described specific relationships between components, unrelated to slavery. Drawing such connections may overlook the technical and historical context of these terms. reply ChrisMarshallNY 3 hours agorootparentI’m sorry that it seems this comment was dinged. It was (in my opinion) a reasonable one, and not delivered in an attack fashion. I can only speak for myself, but I inject a great deal of “humanity” into my technical work. I write software that Serves a pretty marginalized and sidelined demographic. Not many folks are willing to do the type of work that I do. I certainly don’t do it for the kudos. I don’t think most of the folks here, would care, and some, might actually hate me for doing the work. I do it, because I actually have a personal stake in the work, and because I care -deeply- about the people that use my software. Whenever I design an app, I keep in mind the folks that use it, and ensure that it delivers something that they need (not what I think they need; what they actually need). My work is informed by a mental model that I have, imagining the software being used by people, not by it projecting my brand, making money (it’s free), or salving personal insecurities. I’m quite aware that this is not the norm, in the industry, but I have worked for companies that kept a laser focus on the end-user experience, which involves a great deal of “getting into their heads.” reply johnisgood 3 hours agorootparentI did not consider your comment to be an attack in any way. My issue boils down to some completely wanting to change IT terminology because of \"emotions\" which happens because people do not consider the context in which it is embedded. reply ChrisMarshallNY 2 hours agorootparentI meant your comment. It seemed to be unpopular. reply II2II 1 hour agorootparentprev> Recently, we renamed the \"master\" branch to \"main,\" which was seen by some as a step toward inclusivity. But does this truly contribute to meaningful progress? In that case, probably not since the world master has multiple meanings. However, as you noted, it is common to use master/slave terminology in the hardware world. That terminology is definitely problematic because we are humans. We are affected by human history and we are affected by social constructs. Something similar can be said about killing processes. It is also worth noting that people noticed that terminology was problematic long before the current social environment, probably because it affects a much broader range of the population. (For example: I don't see that terminology used much outside of Unix.) reply TimTheTinker 4 hours agorootparentprevI agree with not switching from \"master\" to \"main\" in git branch parliance. (The music industry didn't stop \"mastering\" albums, with good reason -- it's a technical term that refers to technical authority, which is a concept worth keeping.) But I don't think this thread is the place for such a discussion. Technical authority and \"woke\" culture arguments are one thing, but we're talking here about honoring Erie Meier (a seminal figure in CSS history) and his daughter by adding a named color (basically an alias) to CSS and using it in the logo. That's worth doing simply out of love and honor for Eric, his wife and family, and his daughter. reply johnisgood 4 hours agorootparentJust to clarify: my comment was not related to Erie Meier at all. I do not mind the rename from beccapurple to rebeccapurple either. reply Gare 7 hours agorootparentprevIt was not his proposal and it was not in his power to approve it. Community proposed and endorsed it. He only requested a change from becca to rebecca. reply spockz 7 hours agorootparentprevI’m not sure. I think it is what makes human. The details are that what make life worth living instead just the endless turning of the cogs. Besides, if you don’t like it, just use the rgb value. reply zanellato19 7 hours agorootparentprevIt's the sort of emotions over logic we need more, you mean. reply kibwen 4 hours agorootparentNot even this. There's no \"logical\" argument against it. The CSS color names are largely arbitrary and always have been (e.g. \"indigo\" is a shade of purple, when IRL indigo is the plant that produces the dye for blue jeans). Color names in general have been arbitrary since long before Newton coined ROYGBIV and decided to use \"blue\" to mean what we call \"cyan\" today. It's an attitude that presumes that we can apply logic to all walks of life, which ironically is an inherently illogical stance. reply hombre_fatal 43 minutes agorootparentYeah, that's the main oversight of the OP that makes them look silly. There was no logic to the naming scheme. It was all arbitrary, and the names came in waves from various sources like house paint colors, Crayolas, and the whims of people behind various implementations. If they replaced '#663399' with 'rebeccapurple' maybe they'd have a point. reply aziaziazi 5 hours agorootparentprevI mostly agree, but not for code lexical choices. The comment obviously lacks empathy and would be better unsung another tone and not words like graveyard. Names are easier to learn and remember when universal. We know memorization works with associations and Chocolate, PaleTurquoise and Aqua are great for that. Chartreuse and DodgerBlue aren’t. While I can personnaly relate to the first the second is totally alien. Both lacks a bit more universality IMHO. Absolute universality isn’t achievable but I stand that is a usefull direction to head to. I’m deeply sorry for Eric’s daughter and gratefull for his work. I’m sure there’s other ways to honor them. PS: thanks for the HN post, now I can relate to RebeccaPurple! reply edoloughlin 7 hours agorootparentprevI think finding a meaningful way recognise a significant contributor in a way that doesn’t really impact anyone is something to be encouraged. I imagine that most people would use the hex code anyway and only devs/designers would see the name in their tooling. I can’t see how to apply logic to naming a colour. It’s fundamentally a perceptual and, dare I say it, emotional process. I also think your comment is uncharitable and tone deaf. reply scotty79 7 hours agorootparentprevSoftware is a part of human culture. All of human culture is intertwined. reply mikojan 7 hours agorootparentprevYou actually thought of that and then also wrote it down. You had to intentionally press \"reply\" to make the internet see this message. I am stunned! reply userbinator 6 hours agorootparentnext [4 more] [flagged] shiomiru 6 hours agorootparentYou look at the monstrosity that is the CSS spec(s), filled to the brim with horrible ideas like floats, the various overcomplicated positioning modes that no mortal can hope to ever fully understand, and undefined behavior left and right in general. And the \"bloat\" you end up singling out is... an addition to the otherwise 147 entries long color name table.[0] That's just bizarre. [0]: at least when I was implementing it: https://git.sr.ht/~bptato/chawan/tree/351f2f51322c2fa291772c... perhaps there's more now... reply johnisgood 3 hours agorootparentYour list includes all 140 CSS named colors, so as per CSS Color Module Level 3, it is exhaustive. Your list has duplicates which are valid because both American and British spellings are recognized, e.g. \"darkgray\" and \"darkgrey\". If it is not limited to CSS, then you are missing X11 colors (around ~256), for example, although some overlap with CSS colors. If interested, Gpick can serve as a starting point. reply moomoo11 3 hours agorootparentprevWhat’s ur browser called? reply empathy_m 14 hours agoprevEric Meyer's posts about his daughter's illness, and the family's lifelong process of grieving afterward, are heartbreaking. It's arresting, gripping writing. It's wonderful and awful. Hug your loved ones tight. https://meyerweb.com/eric/thoughts/category/personal/rebecca... reply ericwood 12 hours agoparentThank you for linking this. I read bits and pieces of this as it was happening but it never fully registered for me at 24. I'm sitting here 10 years later at 34 having lost our son at 23 weeks. His due date was this past week. It's affected me in ways that still surprise, befuddle, and sometimes scare me. I cannot even begin to fathom what he's been through; the most recent blog post has me in tears. I have really strong memories of learning HTML, CSS, and javascript in high school, and spending time in the school library picking apart css/edge. It felt like the dawn of a new era, I was in awe of the things I saw there. I built more than a few sites trying to get my head around the complexispiral demo, and spent countless hours diving into resources I found there (like A List Apart! I will never forget the suckerfish drop-downs). This is one of the few moments I have such vivid memories of that were directly responsible me for pursuing computer engineering and ultimately going so far into UI/UX and the web. I've never written it out this explicitly but: thank you for everything, Eric. reply ten13 9 hours agorootparentThank you for sharing, Eric. It’s been a few years now for me since we lost our son before I ever had the chance to meet him and I’m not sure it’s any easier. Stories like yours and that of others help us all know we’re not alone in our grief though so I encourage you to keep sharing and telling your story. reply ericwood 2 hours agorootparentHearing other people's stories helps so much, even though it can be a reminder of the long road ahead dealing with grief. I'm so sorry for your loss. reply Cordiali 9 hours agorootparentprevI hope every day is a bit easier than the last for you. reply arrowsmith 13 hours agoparentprevOuch. As a father, that was a gutpunch. Dark, haunting, dripping with grief and pain, but beautifully written and very haunting. I can’t imagine anything worse than what that guy has been through. I’m holding my sleeping baby as I write this and I just hugged him even tighter. Thanks for sharing. reply adastra22 5 hours agorootparentAs a father of two girls, I’m not clicking that link. I don’t think I could handle it. reply heartbreak 2 hours agorootparentI don’t blame you. I haven’t cried like that in a long time. reply czhu12 9 hours agoparentprevHaving never had children myself, his writing moved me in a way that I struggle to comprehend. I spent my 2 hour commute reading through all of his writing on his time, and subsequent grief of his daughter, starting here: https://meyerweb.com/eric/thoughts/2008/06/18/welcome-2/ I found this piece particularly moving, and brought me to tears: https://meyerweb.com/eric/thoughts/2014/06/10/so-many-nevers... reply whatever1 12 hours agoparentprevHow can the game be so unfair for some? People don’t deserve this. reply pglevy 39 minutes agorootparentWas just reading this on the pain of parenting in Medea by Euripides this weekend: \"Suppose that the children have grown into youth And have turned out good, still, if God so wills it, Death will away with your children's bodies, And carry them off into Hades. What is our profit, then, that for the sake of Children the gods should pile up on mortals After all else This most terrible grief of all?\" I try not to think about it too much. reply mewpmewp2 8 hours agorootparentprevMakes you think how life so easily and randomly can be so different irrespective of who you are or what you do to affect you forever. reply efilife 1 hour agorootparentprevThat's the consequence of procreation reply agumonkey 6 hours agorootparentprevit's indeed strange to realize that life / universe can crunch everything brainlessly in some spot while everything else is colorful around reply kaelig 13 hours agoparentprev\"wonderful and awful\" is such a brilliant way to capture this. Thank you reply 29athrowaway 13 hours agoparentprevThose posts are definitely not for everyone. It is a deep dive into the emotions of a grieving father for over a decade. I really hope that man can find peace. reply bowsamic 11 hours agoparentprevnext [8 more] [flagged] arrowsmith 9 hours agorootparentWho are you to tell someone else how to process his grief? reply bowsamic 8 hours agorootparentnext [7 more] [flagged] outadoc 7 hours agorootparentThere's a time to use critical analysis, and there's a time to keep quiet and show some respect. reply mewpmewp2 8 hours agorootparentprevIs he self-destructing? That's a short blog post 10 years after it happened. The latest before that in Rebecca category is 3 years before that. And then he just seems to do those blog posts during birthdays. He's doing therapy etc, what else can he be doing? Writing blog posts is also processing. reply 5643367 7 hours agorootparentprevThere is no evidence this person is self destructing. You've read that in. This isn't coming from Meyer. It's coming from you. You regularly jump into threads to criticize how other people deal with their mental health challenges. I would appreciate if you would stop. It's inappropriate. You've been asked to stop by users and by dang multiple times. Maybe when you feel challenged by the way other people approach mental health, you should treat it as an invitation to practice rather than an invitation to criticize. reply bowsamic 7 hours agorootparent> You regularly jump into threads to criticize how other people deal with their mental health challenges. > I would appreciate if you would stop. It's inappropriate. You've been asked to stop by users and by dang multiple times. You must be thinking of someone else reply butd684 6 hours agorootparentI'm recalling you, specifically. Because I've seen this happen multiple times, you've left an impression. I hope you have a good day and that you weigh your words with care. reply bowsamic 4 hours agorootparentWhy are you making a new throwaway for each post? > I'm recalling you, specifically. Because I've seen this happen multiple times, you've left an impression. But I've never done it before reply WD-42 13 hours agoprevI really don’t like these logos that are boxes with text in the lower right. The post cites a “common design language” with other tech but this has to be the most low effort language imaginable. reply fenomas 5 hours agoparentI once saw an interview with an apparently well-known logo designer, who said something to the effect of: \"When somebody sees my work and says 'that's nothing, anybody could make that', that means they instantly got the logo, understood its structure, with no distraction. That's what it's meant to do, so to me it's a compliment.\" Whether that applies here is naturally subjective, but hearing that changed how I look at logo designs a bit. reply vundercind 4 hours agorootparentI dunno, a lot of professional design these days of extreme flatness looks like stuff I’d have done in the ‘00s while developing something just to have some kind of design and structure, then everyone would see it and be like “the program’s great but of course we’ll need to get the designers on it, ha ha, programmers and design, so bad at it, am I right?” A lot of it would still get that reaction, I think, if a programmer presented them instead of a designer, and these look to me like they’d be among them. reply fenomas 3 hours agorootparentEh, having worked halfway between coding and design my whole career, I'm ambivalent. Design is just one of those things that everyone is confident they have an informed opinion about, even if they've spent a lifetime total of zero seconds thinking about what the criteria for a good design should be, let alone how to apply them. I think most every designer learns early on to ignore all the \"but that's just...\" comments, and rightly so IMHO. That said: > A lot of it would still get that reaction, I think, if a programmer presented them instead of a designer, and these look to me like they’d be among them. Weren't the logos in TFA made and voted on by programmers? reply latexr 5 hours agorootparentprevThere’s a limit to that. By that token, every logo in existence could be a white square with black text on it. Clearly they are not, because people understand the need for some differentiation. Even in this case, the logos benefit from having colour. And they’re not even consistent. Three of them are squares, two of them are different shapes, and despite the simplicity even something as trivial as the font size and spacing isn’t uniform. reply echelon 4 hours agorootparentprev> that means they instantly got the logo, understood its structure, with no distraction. We didn't get that it was supposed to be a logo or a brand though. Labels like this look like placeholders. They leave you feeling empty and convey a sense of amateurishness. These do provoke a visceral response. It's not an \"Oh!\", nor even an \"oh?\", but rather an \"oh...\" The \"brand guidelines\" will be broadly disrespected since the mental threshold for brand awareness is higher than the entropy of a square. reply bradley13 9 minutes agoparentprevSure, but it's good that it's low effort. We don't need fancy branding for languages. Few people will see thrm. These aren't paid products with marketing campaigns. They are just tools of the trade. reply kibwen 4 hours agoparentprevLogos do not exist in a vacuum, so evaluating them requires considering their context. CSS is not a technology that needs eye-catching marketing. The existence of branding is mostly just for the purposes of giving someone something to put on a powerpoint slide, or a sticker to put on a laptop. It's allowed to be boring. In addition, it exists as part of a family of web technologies, so giving it consistent branding with the other web technologies makes sense. You can argue that whoever first came up with this simple sort of branding was unimaginative (I think the JS logo was the first?), but just because something is simple doesn't mean it's not capable of being iconic. reply lemagedurage 12 hours agoparentprevThey could've added some character by letting the text overflow the box :) reply cantSpellSober 6 hours agorootparentThat's been the unofficial \"logo for CSS\" for years: https://i0.wp.com/css-tricks.com/wp-content/uploads/2017/06/... It appears this option was discussed: https://github.com/CSS-Next/css-next/issues/105#issuecomment... reply geon 8 hours agorootparentprevThe rounded corners was a suitable reference to css, I think. reply usbsea 12 hours agoparentprevYou prefer these? https://en.wikipedia.org/wiki/HTML5#/media/File:HTML5_logo_a... https://en.wikipedia.org/wiki/File:CSS3_logo_and_wordmark.sv... reply rozab 2 hours agorootparentYes, I've always thought they were excellent logos. Makes me nostalgic about the optimism of this time. Also people actually use them, a while back every CS student inexplicably had these stickers on their laptop. I can't see these new logos being ever used as stickers because they're just... nothing. reply ohmahjong 12 hours agorootparentprevNot who you are replying to, but I started learning HTML/CSS right when HTML5 and CSS3 had just come out, so I do have somewhat of a soft spot for these reply brailsafe 9 hours agorootparentprevAbsolutely prefer these reply cyborgx7 9 hours agorootparentprevThey're so much nicer. reply oneeyedpigeon 9 hours agorootparentThey remind me way too much of dark-arts virus checker, disk cleaner BS. reply WD-42 10 hours agorootparentprevYes. reply geoffpado 11 hours agorootparentprevYes. reply NBJack 11 hours agorootparentprevThey are certainly more colorblind and vision impairment friendly to be honest. reply HL33tibCe7 9 hours agorootparentWhat is color blind unfriendly about the new logos precisely? Which variant of color blindness will not be able to read them? Which visual impairment exactly will find it easier to parse the previous logos (which are a mess of design scarcely related to the actual technology name) than the current ones, which contain thick bold text indicating exactly what the technology is called? reply NBJack 2 hours agorootparentHere's a good starting point: https://www.sfgov.org/designing-visually-impaired > Do not rely on color alone to denote information > Use additional cues or information to convey content The old icons were certainly ugly. But they had a unique shape (cue) and didn't rely on color. The new logo has text which helps, but this is where visual impairment becomes an issue (lack of focus to read said text). I have no intent to take away from the meaningful choices made in this logo's design. But even just picking a unique shape for each component would go a long way. reply wruza 11 hours agorootparentprevIs this the only choice we have? reply niutech 1 hour agorootparentHow about this? https://www.w3.org/Icons/valid-css-v.svg ;) reply rafark 4 hours agorootparentprev100% yeah reply spiffytech 5 hours agoparentprevWhile they aren't snazzy, they do have some benefits that often go unconsidered: Logos are sometimes printed on shirts (in monochrome, or where rich coloring costs extra), or embroidered onto hats, or read at a distance (like conference booth posters), or printed to B/W official letterhead, or scaled down for an icon pack. A 3rd party will include a logo on something with a preexisting style, and it should look okay there. A logo which is structurally simple and uses few colors can be easily adapted to these scenarios — printed in black-and-white, or as an outline without solid colors. reply niutech 1 hour agoparentprevI preferred the old HTML/CSS/JS logos: https://banner2.cleanpng.com/20180920/kl/kisspng-javascript-... reply kalleboo 9 hours agoparentprevThey should have centered the text in it both vertically and horizontally reply reddalo 9 hours agorootparentIt's impossible to do that with CSS :) reply matsemann 7 hours agorootparentCould've used this classic CSS joke as the logo https://i.etsystatic.com/21468781/r/il/426363/2712010149/il_... reply mattrad 2 hours agorootparentThere was a submission like that :) https://github.com/CSS-Next/css-next/issues/105#issuecomment... reply somat 9 hours agoparentprevDisagree, but then again my soulless engineer's heart has close to zero tolerance for design for design's sake, so what do I know? The most important part about convoying that an item is CSS is including the letters CSS. So while I am a little disgusted they wasted time on an icon at all, I will admit that many of our design language structures demand an icon. So I am somewhat relieved they managed to dodge the design for design's sake crowd and picked the best possible one. A non-descript box with the letters CSS in it. reply oneeyedpigeon 9 hours agorootparent\"Non-descript\" is unfair - it has 3 rounded corners! reply kijin 12 hours agoparentprevI think Adobe started this trend. A box with \"Ps\" inside for Photoshop, \"Lr\" for Lightroom, etc. for all their products. An entire generation of web designers grew up with their heads stuck in the Adobe ecosystem, so this must look like the gold standard to them. At least Adobe made an effort to make their logos look like symbols on the periodic table. reply hxii 12 hours agorootparentTo me these made sense, as I was able to quickly, visually distinguish PhotoShop by the “PS” letters instead of trying to decipher a 32x32 logo. reply tannhaeuser 10 hours agoparentprevYou're absolutely right, especially considering the canonical CSS-in-a-box logo has long been established [1], and they should really embrace it if they had any sense of humor. Perhaps those brutalist logos were designed specifically such that they could be rendered using CSS itself? Though I could understand why they'd want to distance themselves from the old \"shield\" logo that turned out to signify shielding \"browser vendors\" from broad implementation of CSS renderers and to keep a niche of job security at W3C, Inc. due to rampant and unwarranted complexity, but in any case was burnt by being placed next to vulgar metalhand vectors, not to speak of being culturally discriminative when viewed in a \"woke\" interpretation. [1]: https://ih0.redbubble.net/image.13378023.4114/raf,750x1000,0... reply thiht 8 hours agorootparent> especially considering the canonical CSS-in-a-box logo has long been established Is this a joke? I’ve never seen it in my life, not even sure where you’re pulling it from reply nativeit 3 hours agorootparentI’ve been using it for years. A lot of years. reply readthenotes1 12 hours agoparentprevthe design language is really \"keep it inside the box, don't worry about your self-imposed solution constraints\" reply egypturnash 5 hours agoparentprevYeah these are programmer art. Or clones of Adobe’s lame branding. reply kibwen 3 hours agoprevFor your name to recited by the machines for all eternity is a form of immortality. GNU Terry Pratchett reply niutech 56 minutes agoparentLike Linus Torvalds' Linux or Phil Katz' PKZIP. reply lenkite 3 hours agoprevLike Rebecca, I also like #639 - its a wonderful color. Looks great on a web-site as a solid color that you can built a palette from and the hex code is simplicity to remember. I really wish CSS had more color names - would have been great to have named, Pantone colors or another named system. reply niutech 52 minutes agoparentHTML/CSS has a lot of color names: https://htmlcolorcodes.com/color-names/ reply dang 13 hours agoprevRelated. Others? Adding 'rebeccapurple' color to CSS Color Level 4 (2014) - https://news.ycombinator.com/item?id=34186932 - Dec 2022 (1 comment) Adding 'rebeccapurple' color to CSS Color Level 4 (2014) - https://news.ycombinator.com/item?id=9565503 - May 2015 (33 comments) Adding 'rebeccapurple' color to CSS Color Level 4 - https://news.ycombinator.com/item?id=7924677 - June 2014 (25 comments) In memory of Rebecca Alison Meyer - https://news.ycombinator.com/item?id=7863890 - June 2014 (68 comments) reply brianzelip 8 hours agoparentAn official logo for CSS - https://news.ycombinator.com/item?id=42124786 - November 2024 reply pbhjpbhj 3 hours agorootparentI imagine your submission, which you link here, wasn't included as it has no comments. I think dang posts these so people can read the comments made on other submissions. reply shahzaibmushtaq 12 hours agoprevI will never ever forget this color name and the story behind it for the rest of my life. reply miiiiiike 3 hours agoprevEric’s CSS: The Definitive Guide really is the only way to learn CSS. https://www.oreilly.com/library/view/css-the-definitive/9781... reply bdcravens 2 hours agoprevIt's great that Rebecca's name will be find its ways across codebases for as long as we are using named aliases for colors in HTML/CSS. It's nowhere near the significance of her's and Eric's story, but the piece of land where my grandfather built his home in the 1940s or 1950s has his name on it: the \"Paul D. Cravens Addition\". Even though that home is long since gone (in a fire) and the land is owned by someone else, every deed and building permit henceforth has his name attached it. reply graypegg 14 hours agoprevIt’ll be interesting to see where we end up using this. I don’t honestly see the CSS3 shield this is meant to replace very often anymore. Probably the place where it’ll be seen the most is in IDE file trees, where I’m a bit worried it’ll just look like a little purple blob reply kijin 11 hours agoparentFile Browser / Finder maybe, but the text inside the boxes are too small for IDE file trees. VS Code shows \"JS\" in yellow text without the box, against a dark background. CSS is just a blue hash symbol. Maybe they'll change the color to rebeccapurple, but I don't think there's room for a box around the symbol. reply qark 9 hours agoprevIs there any link that explains why this particular shade of purple was chosen to represent Rebecca? reply felbane 5 hours agoparentPurple was her favorite color. #639 is shorthand for about the purplest purple you can make with RGB. Jeff Zeldman proposed the color name on Twitter and in a blog post shortly after she died, and it understandably caught on. reply Ecco 10 hours agoprevWithout even judging the overall design (personally I don't mind the simplicity), why on earth do they use such inconsistent fonts? 3 different font sizes (and maybe also mismatching horizontal spacings) for 5 assorted logos??? This is insane... reply usrusr 9 hours agoparentBecause they are still logos, not one list of short acronyms that just happens to be rendered in a specific way? I really think it's fine: the web assembly gets to play with its parallels between W and A, JS gets to mirror the J's bottom-bend in its S (TS tagging along because those two really are more than just accidental neighbors), whereas CSS can indulge in summetry with its twin S by making them internally symmetric themselves. A logo that contains an acronym isn't really a logo when the characters are just picked from some font instead of tailored as part of the logo. reply latexr 5 hours agorootparent> Because they are still logos, not one list of short acronyms that just happens to be rendered in a specific way? Consistency still matters. If you’re going through the trouble of making logos similar so they are understood as part of a family, don’t give up half way. reply oneeyedpigeon 9 hours agoparentprevYou want them to be even less distinctive? Personally, I think they should lean into that more and embrace the context: e.g. sans-serif for CSS, monospace for JS, serif for HTML. reply niutech 49 minutes agorootparentOld logos were more consistent yest still distinctive IMO: https://banner2.cleanpng.com/20180920/kl/kisspng-javascript-... reply latexr 5 hours agorootparentprevThe current logos are both uninteresting and badly constructed. At least either make them consistent (less distinctive but you can appreciate them as thought out as part of a family) or wildly different (more distinctive but not as clear they’re part of a family). This middle ground is the worst of all possible options. reply cachvico 10 hours agoparentprevIt's incredibly ironic reply npteljes 9 hours agoprevI used rebeccapurple a lot as well, unknowing of the touching story behind it. I coded CSS by hand (back in like 2010), and for placeholders, I used the simple colors I knew, like \"green\" or \"blue\". And \"red\", of course, too. But when typing \"re\" for \"red\", I noticed that it autocompletes to \"rebeccapurple\", which amused me, since I thought it's kind of a nonsense to have a color named like that. Over time, I used it a lot, and it became a kind of a favorite of mine. reply watusername 2 hours agoparentFor the record, rebeccapurple was ratified in June 2014 [0] and was added to mainstream browsers late that year [1]. I imagine it wouldn't be \"web-safe\" until 2015/2016 at the earliest. (Not doubting your anecdote - Just felt like doing some sleuthing on the timeline) [0] https://lists.w3.org/Archives/Public/www-style/2014Jun/0312.... [1] https://caniuse.com/css-rebeccapurple (use \"Date Relative\") reply biesnecker 1 hour agoprevI don’t click on HN articles expecting to cry, but here we are. reply voat 14 hours agoprevFor some reason, I was under the impression that the blue shield was the css logo. But after looking at it, I realized that it was just for CSS 3 and I'm not sure if it was even official? reply asddubs 13 hours agoprev>The design follows the design language of the logos of other web technologies like JavaScript, TypeScript, and WebAssembly. and yet it's 5 logos with 3 different font sizes and at least 3 different font faces 3 of which are perfect rectangles, and 2 of which are slight variations on rectangles i guess it perfectly represents the ecosystem, no notes reply Maken 8 hours agoparentTo fully represent HTML, they should be displayed with sightly different fonts and kerning in each operating system. reply globalise83 9 hours agoparentprevThis is the evolution of \"Design by committee\" to \"Design by 3 committees\" reply laserstrahl 7 hours agoprevhttps://github.com/vic/rebecca-theme I thought it derrives from this. Haha reply kmeisthax 8 hours agoprevGNU Rebecca Meyer reply swayvil 13 hours agoprevIt's a nice purple. reply usbsea 12 hours agoparentA simple one too - it would be on a 216 colour pallete using six values for each of R, G and B. R = 1/5 G = 2/5 B = 3/5 Edit: of course that makes sense it is probably a \"web safe\" one reply jwilk 6 minutes agorootparentIt's R = 2/5, G = 1/5. reply kijin 12 hours agorootparentprevIf it's such a simple combination, I wonder why it wasn't officially named until 2014. CSS has had names for all sorts of weird colors since forever. reply duskwuff 10 hours agorootparentMost CSS color names were inherited from the X11 color list [1], which, in turn, sourced its colors from a weird mixture of Crayola crayons, paint samples, and idiosyncratic personal choices [2]. It's a mess. [1]: https://gitlab.freedesktop.org/xorg/xserver/-/blob/master/di... [2]: https://lists.w3.org/Archives/Public/www-style/2014Mar/0272.... reply labster 10 hours agorootparentprevMaybe it wasn’t named so that long after people like me pass from memory for good, people will still speak of Rebecca and of the love we showed her. reply otteromkram 13 hours agoprev> Update 22 Jun 14: the proposal was approved by the CSS WG and added to the CSS4 Colors module. Patches to web browsers have already happened in nightly builds. (I’m just now catching up on this after the unexpected death of Kat’s father early Saturday morning.) Mr. Meyer certainly had a rough 2014. Kudos to him and all his CSS contributions over the years. I hope he has been able to find some solace since then. reply aryonoco 9 hours agoparentI would say he hasn't, considering a few months ago he wrote \"A Decade Later, A Decade Lost\" https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later... And I can't blame him. They say no parent should see their child die, and that's certainly true; but especially no parent should see their 6 year old child die of brain cancer. Humans are not built to withstand that. reply sureIy 4 hours agorootparent> Humans are not built to withstand that. What's that supposed to mean? Humans grew up being slaughtered by wild animals. Safe housing is an extremely recent invention and many humans still don't have it. reply pino82 9 hours agoprevWhy does it include TS? I would never have called it a 'web technology'. A lot of people use it in their tech stack, but fortunately, the browser does not even understand it, right? reply atlih 9 hours agoprevnext [–]The Wordmark remains an essential identifier of our brand. While our goal is to lead with the N Symbol, we enlist the Wordmark to ensure brand recognition in low-awareness markets or when production limits the use of color. CSS doesn't have a ton of brand awareness. Making something akin to the Nike Swoosh for CSS won't catch on, it's not like they have the money to flood your Instagram feed with it and force that brand recognition on you. Going back to Netflix why would they use a single gently stylized letter where possible? Well, > In high-awareness markets, we lead with the N Symbol. There is power in owning a letter of the alphabet: it’s universal and instantly identifiable as shorthand for our brand. That's right. Netflix wants to own the letter N. I think \"CSS\" is in the same position: owning a combination of three letters is a power move. That's the most valuable thing about the \"CSS brand,\" if ever there were one, so why not lead with it? But maybe your opinion is still that all of these designers are full of it (apparently including Paul Rand). reply thiht 8 hours agoparentprevThis is definitely a logo, by all definitions of the word. It’s not just \"text in a box\", it’s: - text, with a specific font, position, size, weight - a specific color - a box radius in 3 corners - some variants By your definition, the Coca Cola logo is not a logo because it’s \"just text\" reply oneeyedpigeon 9 hours agoparentprev [–] Tell Gap (and all the rest). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "CSS has introduced a new logo, selected through a community vote on GitHub, featuring the color rebeccapurple (#663399).- The color rebeccapurple was added to the CSS specification in 2014 to honor Eric Meyer's daughter, Rebecca, who died of brain cancer at age six.- The new logo's design is consistent with the visual style of other web technologies such as JavaScript and TypeScript."
    ],
    "commentSummary": [
      "CSS has introduced a new logo featuring the color `rebeccapurple`, a tribute to Eric Meyer's daughter, Rebecca, who passed away at a young age.",
      "The color `rebeccapurple` was chosen because Rebecca preferred to be called by her full name, adding a personal and emotional significance to the tech community.",
      "The logo's design aligns with other web technologies like JavaScript and WebAssembly, emphasizing simplicity and unity in web development."
    ],
    "points": 661,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1731817092
  },
  {
    "id": 42159786,
    "title": "The Bluesky firehose viewed in the style of a Windows XP screensaver",
    "originLink": "https://firehose3d.theo.io/",
    "originBody": "Loading...",
    "commentLink": "https://news.ycombinator.com/item?id=42159786",
    "commentBody": "The Bluesky firehose viewed in the style of a Windows XP screensaver (theo.io)456 points by consumer451 20 hours agohidepastfavorite121 comments null0pointer 8 hours agoA lot of commenters here are having their minds blown by this. And while I also love this I get the sense that many others here are maybe too young to remember that this kind of open access to data used to exist for lots websites. It inspired companion sites and loads of creativity. I find it tragic really, what the internet has become. I hope federated, and even more-so p2p, protocols take significant foothold on the internet and help revive this spirit of the web. The corpo-web is so fucking boring. reply paulgb 7 hours agoparentIt’s worth noting that twitter itself owes a lot of its popularity to its openness in the early days. In the early days there were third-party clients, RSS feeds, XMPP support, etc. You could post from a curl command in a cron job, leading to all kinds of interesting automated feeds. Then they walked it all back in the early 2010s. I like that Bluesky’s federation model makes it harder for them to do an “open platform” bait-and-switch like Twitter did. reply AshamedCaptain 6 hours agorootparent> I like that Bluesky’s federation model makes it harder for them to do an “open platform” bait-and-switch like Twitter did. Why would it? They can still lock everything down and few Bluesky users will even notice. This is similar to what Twitter did, or what Google Chat did, etc. Compare this to other federation platforms where a server that locks itself down loses access to a huge chunk of the network, once the other servers reciprocate. reply diggan 6 hours agorootparent> Why would it? Since migrating your personal data was a thing they thought about since day one, migrating to another network than the current one would be way easier than any centralized service and also easier than ActivityPub. Seems there is one piece of the puzzle missing yet (\"AppViews\") in ATProto to be able to run completely independent, but seems they're currently working on getting that in place now. reply shafyy 4 hours agorootparentYou can host your personal data, but as long as Bluesky Social, PBC is running the main Relay and AppView, and there's no easy way for Relays to talk to each other (like e.g. it works in Mastodon), they are in reality a centralized service. Oh yes, and they are the only ones owning and developing AT Protocol, which makes it much more a currently-open-sourced protocol rather than a standard that is jointly developed by the industry. reply rakoo 3 hours agorootparentprevThe big central place is still the PLC directory that effectively means all accounts are centralized at BlueSky, even if your posts are not. They haven't planned to make it any decentralized in the future. reply AshamedCaptain 6 hours agorootparentprevYou could still migrate all _your_ data to another service in Twitter quite easily, and most definitely you could in Google Chat. This did not change things. reply diggan 6 hours agorootparent> You could still migrate all _your_ data to another service in Twitter quite easily Yeah? I don't remember being able to migrate from/to Twitter and taking followers/following etc with you without having to ask/request others to do something too. reply AshamedCaptain 6 hours agorootparentBut I'm guessing that you'll also have to request your followers to use a different AppView if Bluesky did a Twitter. reply glenstein 4 hours agorootparentprev>In the early days there were third-party clients, RSS feeds, XMPP support, etc. Right. This is something I keep pointing out in threads about RSS. Some people will say RSS never left. Well, it left Twitter for one. Google News and Craigslist for others. I almost wonder, to GP's point, if people have just completely forgotten all of this, which is why they think nothing was lost. reply echelon 3 hours agorootparentThe 2000s Internet felt way more innovative than the one we have today, despite all of the WASM, WebGPU, JIT optimizations, and other technologies that have been developed in more recent years. We had torrents, open data, open protocols, and people were sharing data and remixing it freely. Mountains of stuff like this Bluesky demo was released every single day. We had link aggregators to point to the cool things that were happening, and we even had tools that let you pipe data sources between various APIs to enrich and recombine things easily. Platforms stopped this. Facebook, Google, and even Apple put an end to the wildly evolutionary behavior by delivering a canned experience to the masses. We need a return to P2P where single platform silos and their army of product managers don't shape how we interact with technology and the bulk flow of information. reply larodi 56 minutes agorootparentIndeed. Question is whether this all that was in the 90s can again be relevant for the young who grew with TikTok, insta and fb. I don’t have the answer, only doubts… Now with GPTs more than ever people can regain their web presence. But do they do it? I guess not as much as one would expect. You may say we need to go p2p again and perhaps Tim Berns Lee actually meant p2p with the HTML, but are people aware of this daring need? reply 1024core 1 hour agorootparentprev> The 2000s Internet felt way more innovative than the one we have today Because it seems like this stuff is taught in Management 101 in all of the business schools: once you establish yourself with all this talk about \"openness\", etc. then the only way to succeed is by creating a walled garden, either through abuse of your monopoly position or by regulatory capture. Cases in point: OpenAI _and_ Anthropic both pushing for regulation of AI, now that they have a dominant position. I swear, the moment MBAs get involved, they try the same crap everywhere. reply hn72774 2 hours agorootparentprevI see 2 way to do this. A company (and PM) sees demand for the feature and they include it, ot it is forced by regulation. A lot of these companies that originally had open standards formed with huge amounts of VC money and they prioritized growth over everything else. Then when they reached a certain scale, investors valued profitability and they slowly squeezed and monetized users until all of those open standards features were gone. reply ideashower 1 hour agorootparentprevI’m struggling to recall some of those early fun accounts. Do you remember any interesting automated feeds from Twitter’s early days? reply paulgb 1 hour agorootparentI used to run a cron job that would scrape my university's daily bulletin and post every day right after it was updated. It may have been the first “presence” the university had on twitter. I remember following things like weather stations that had automated accounts, as well. reply FranOntanaya 3 hours agorootparentprevirssi had a plugin to read and post to Twitter from IRC, it was neat. reply cma 5 hours agorootparentprevThey are a public benefit corporation that use that as a selling point but then don't disclose their charter. That seems really shady to me, but less than what twitter has become. reply bloopernova 2 hours agoparentprevA long long time ago, LiveJournal used to display all new user-uploaded images in a firehose type page. It was a fascinating glimpse into the shared lives of people all over the world. It was definitely from a simpler time; there's no way something like that would be available now due to the violence/abuse material that gets uploaded. reply weberer 52 minutes agoparentprevI'm not too up to date on Twitter clones. What's the difference between this and Mastadon? reply geek_at 1 minute agorootparentMastodon has about 1 million active accounts, bluesky has 12 and you can also host your own data. Threads (by meta) has 100 million but you can't federate it yet so bluesky is the way to go currently for selfhosters and privacy advocates. reply AI_beffr 3 hours agoparentprevBS is a cynical data-grab and will lock down and back-stab its users as soon as it can do so and be competitive. reply davidcbc 1 hour agorootparentEven if true, which I'm skeptical of, social media sites don't have to be permanent. It's no different from any other service being enshittified, just use it until it sucks and then stop. reply ericjmorey 2 hours agorootparentprevI'm thinking that it's a cynical way to put all the data on an open network rather than a gated and paywalled one. As far as I can tell, Bluesky is still entirely funded by Twitter and that will eventually be cut off. They're betting on the Google/Mozilla type relationship to be maintained for now. They need to make the indexing service easier to replicate before that happens or the network will collapse when funds dry up. reply jazzyjackson 2 hours agorootparentThey have nothing to do with Twitter anymore. Last round was funded by Blockchain Capital https://bsky.social/about/blog/10-24-2024-series-a reply consumer451 20 hours agoprevhttps://github.com/theosanderson/firehose I just love that the open nature of Bsky is allowing people to hack things like this. Now that their growth is crazy, let's hope that the work they did on the protocol and corp structure keeps it this way. reply blitzar 10 hours agoparentA long time ago in a galaxy far, far away ... there was a twitter firehose and people loved how the open nature of twitter is allowing people to hack things ... reply marginalia_nu 17 hours agoparentprevYeah I was looking into the firehose as a potential way to source to discover new domains for my search engine. Even though it didn't pan out, I really appreciate how accessible the data is. reply mariusor 11 hours agorootparentI might have asked this before, but did you look at adding this type of ingestion for ActivityPub? reply marginalia_nu 6 hours agorootparentBriefly, but I've come to learn there's a contingent of aggressively search-engine hostile people that has made a home on the fediverse. The federated nature of it makes it somewhat tricky to untangle the search engine friendly people from the hostile. I don't need the inevitable DDOS:es and death threats you get when upsetting a clique of mentally ill people online. reply mariusor 4 hours agorootparentYou're right, I forgot about the backlash that this type of efforts got from people that don't understand the technology and just make assumptions about element visibility in the network, though maybe calling them mentally ill is a bit much. reply marginalia_nu 4 hours agorootparentThe sorts threatening physical violence almost certainly are. But it's a minority to be sure. reply morkalork 17 hours agorootparentprevWhy didn't it work out? reply marginalia_nu 17 hours agorootparentI decided agains it because it had an incredibly bad signal to noise ratio. Almost all links I saw were either to big websites like newspapers, patreon, onlyfans; or behind url shorteners. Dunno, I may explore it further down the line, but for now the juice didn't seem worth the squeeze. reply dools 15 hours agorootparentI created a website like 10 years ago called birdmine that indexed every link you or one of your followers shared on Twitter, in a Solr search engine so you could search stuff that had been curated to an extent. It was pretty cool, I think I’m the only person that ever used it though. reply djbusby 14 hours agorootparentprevBSky could use a better search, or a better curation of feeds. I'm certain there is more room in the discovery play. reply tholman 16 hours agoprevCrashes like a Windows ME screensaver. Jokes aside, it's very fun to see open firehose access like this. I seem to recall that Dorsey had said that twitter limiting their api access was a mistake, hope we can keep this going. reply consumer451 15 hours agoparentFor people experiencing crashes, Theo mentioned that this will likely work: https://firehose3d.theo.io/?discardFrac=0.6 reply djbusby 15 hours agorootparentI was hoping it was some RegEdit hack to fix driver settings. reply Nihilartikel 6 hours agoprevThis is cool! A long time ago I wanted to make something a little like this for my 20% project at Google/YouTube - a page that rained thumbnails of uploaded videos as soon as they became available. Unfortunately, the idea was nixed since it had a pretty high chance of exposing ugly stuff that would otherwise have been lost in obscurity and never seen. reply do_not_redeem 4 hours agoparentDo you think your idea has any more risk than sites like these: - http://astronaut.io/ - https://obscuretube.com/ reply ipython 2 hours agorootparentAbsolutely 100% yes. Difference is these projects themselves are obscure. Opposed to an official Google branded service that will see significant publicity. reply zamadatix 17 hours agoprevI absolutely love these firehose projects. So much fun. Makes me hope Bluesky gets 10x bigger soon :D. If you add the following line just prior to the return in createTextTexture() the blurriness goes away: texture.anisotropy = renderer.capabilities.getMaxAnisotropy(); The perf could probably be largely solved with reusing texture objects as a pool instead of creating then destroying them as needed. I'm too lazy for that though :p. reply theoretically23 16 hours agoparentThanks - implemented some texture pooling (via LLM). I think the blurriness may [accidentally] help with the retro aesthetic, but I'll try to get that the anisotropy in as an optional parameter. reply Etheryte 5 hours agoparentprevYeah, managing your own memory is a good performance optimization a surprising amount of time when working with large data sets in Javascript. I've seen it used in 3D code, graph problems, etc, and so long as you keep it isolated, it's not too much of a hassle. reply nyanpasu64 10 hours agoprevI noticed that for messages facing the camera, ones further away from the screen occlude ones closer to the screen. I assume there's an alpha layering/rendering order error going on (assuming no order-independent transparency)? reply theoretically23 6 hours agoparentHere's a version with that fixed https://firehose3d.theo.io/babylonjs.html (will probably replace the current one soon) reply issung 9 hours agoprevReminds me of this old website I used to stare at for long periods, found it very relaxing: \"Listen to Wikipedia\" http://listen.hatnote.com/ reply dang 9 hours agoparentRelated: Wikipedia Recent Changes Map - https://news.ycombinator.com/item?id=32649091 - Aug 2022 (36 comments) Listen to Wikipedia - https://news.ycombinator.com/item?id=25560953 - Dec 2020 (34 comments) A Billboard-like chart for Wikipedia articles - https://news.ycombinator.com/item?id=10730695 - Dec 2015 (7 comments) Listen to Wikipedia - https://news.ycombinator.com/item?id=9972781 - July 2015 (63 comments) Listen to a melody made by Wikipedia article changes - https://news.ycombinator.com/item?id=8588576 - Nov 2014 (10 comments) Listen to Wikipedia - https://news.ycombinator.com/item?id=6182576 - Aug 2013 (1 comment) Live map of recent changes to Wikipedia articles - https://news.ycombinator.com/item?id=5693189 - May 2013 (13 comments) Wikipedia Recent Changes (Live) Map - https://news.ycombinator.com/item?id=5687722 - May 2013 (1 comment) Rcmap: real-time visualization of Wikipedia edits around the world - https://news.ycombinator.com/item?id=5645256 - May 2013 (3 comments) reply 0xEF 2 hours agoprevThis is like a visualization of my anxiety. Too much coming in at once to possibly process, so higher order cognitive function just goes welp reply marifjeren 2 hours agoprevI was like.. \"Why do so many of the non-wall posts seem to have fire emojis in them?\" Turns out: if (text.includes('fire-emoji') || wall > 3) { wall = -1; } It's funny how palpable this snippet is while looking at the firehose. https://github.com/theosanderson/firehose/blob/77225acb28985... reply JKCalhoun 16 hours agoprevSeeing some depth-sorting issues with the text on Safari (macOS). Some distant head-on text (not on the sides of the \"tunnel\") is being drawn over nearer head-on text. Also, sometimes top of text is being clipped a bit. Very cool though. reply theoretically23 6 hours agoparent(Here's a version without that problem: https://firehose3d.theo.io/babylonjs.html) reply brookst 2 hours agoprevThis is really cool, and within the first 5 seconds gave me a phrase that will be stuck in my head for a long time: arrogance is not a substitute for intelligence, Sebastian. IDK who Sebastian is, but I will be sure to let him know if ever I meet him. reply pinerd3 13 hours agoprevThis is SO cool I love it. Feels like I'm reading snippets from a million people's diaries one after another. Humbling! reply mbil 17 hours agoprevThis crashes my Safari browser on iOS. reply consumer451 15 hours agoparentFor reference, while it does work much better on my old laptop now, on iOS 18.0.1 iPhone 11 Pro Max, it also crashes until I add https://firehose3d.theo.io/?discardFrac=0.6 reply tsumnia 17 hours agoparentprevFirefox ran it, but very broken. reply wkat4242 5 hours agorootparentWeird, for me it worked great on mobile Firefox reply yazzku 17 hours agoparentprev\"Works\" on Firefox if you can stomach 300-400ms pauses every 2 seconds. Edit: I just profiled it and it spends 42% of exclusive time in texImage2D. It would be better to allocate a set of textures up front and then use glTexSubImage2D to update their contents. glTexImage2D allocates a new texture every time. reply theoretically23 16 hours agorootparentThanks - should be better now hopefully on Firefox reply yazzku 1 hour agorootparentThis did get rid of that bottleneck and the stutters are slightly better, but it still has some more work to go. https://ibb.co/LgtJHMs You'll want to get rid of glTexImage2D completely except for application startup (allocate a pool of N images up front, then re-use them and update with glTexSubImage2D). And short of being able to optimize the text render, which seems to be awfully stupid, you'll want to render offscreen to those textures ahead of time before you need to render them on-screen. reply DaiPlusPlus 15 hours agorootparentprevStill very stuttery before crashing in Safari on iOS on my iPad :/ reply brookst 2 hours agorootparentSmooth and stable on iOS DB3 on iPad… reply theoretically23 17 hours agoparentprevYes, best in Chrome I'm afraid reply Angostura 9 hours agoparentprevIt’s seems to work fir me ok on 18.1 reply matsemann 9 hours agoparentprevAccording to the title, perhaps try IE6 on XP ;) reply billylo 17 hours agoprevLove it! I seriously want to use it as a background for my server. (any chance to publish a version with a configurable speed?) reply theoretically23 17 hours agoparent(Creator here), sure I just added something so you can play with the URL: https://firehose3d.theo.io/?speed=0.9 (but if you slow the movement down too much there will just be way too much content because it's real time) For people on slow machines you can also reduce the number of messages with e.g. https://firehose3d.theo.io/?discardFrac=0.7 reply billylo 16 hours agorootparentPerfect. Thanks! reply rightbyte 3 hours agoprevReally neat. Feels kinda surrealistic. A bit heavy on my broswer though. Is there a way to run stuff like this as an actual screensaver (on Debian)? reply ChrisArchitect 15 hours agoprevWhoa, Johnny Mnemonic (1995) calling. Also, these experiments are good fun, anytime there's a plethora of data available to play with it's a good time.... but anyone else get the weird sense of having been here before? Early Twitter days lots of this kind of thing was going on too with all the tweet data. Until they weren't. When everyone at Twitter woke up and realized it wasn't sustainable financially and technically to keep open firehoses out there. And then the API limits started creeping in and never really stopped. Just saying, we've been here and it's hard to see it playing out a different way even with ATProto's sorta decentralized whatever future. reply TheJoeMan 14 hours agoparentThere could be some pessimism or learned hesitancy, but on the other hand perhaps we can just enjoy it while it is here? I thought the same thing about people building businesses on top of ChatGPT, yet they managed to have exits before any rug-pulls. reply tkiolp4 7 hours agoprevWould be interesting to know how the app is deployed. I see there are some k8s yaml files: does the deployment happen manually (e.g., run kubectl commands inside the cluster)? Is there some sort of pipeline perhaps? (I don’t see any in the repo) reply WithinReason 9 hours agoprevYou can increase the texture resolution if you \"zoom out\" of your browser (ctrl+scrolldown or ctrl+- in Firefox) reply ulrischa 11 hours agoprevI like the possibilities given by the openness of bluesky reply Kye 7 hours agoprevIt feels like Clippy is about to pop out and kick my butt. The authentic XP experience. reply rishabhd 1 hour agoprevThe internet, was supposed to be like this. I used to perceive it like this in its early days. And then it got enshittified. reply smusamashah 15 hours agoprevWhich windows screen saver was this exactly? Is it maze? reply djbusby 14 hours agoparentI think they just mean feelings of early OpenGL (was that what it was?) reply poglet 14 hours agoparentprevIt appears to have elements of '3D Maze' and 'Flying Windows' (Windows 3.1). reply jcpham2 2 hours agoprevTotally crashes chrome on iOS - repeatedly in strange ways reply sandworm101 2 hours agoprevOnce upon a time, browsers had a stop button to pause animations. Now im hunting menus for that button so i can pause the firehose. reply 999900000999 16 hours agoprevCool, but this nearly hard crashed my phone. I'm on a OP12 which is one of the fastest phones you can buy. reply throwaway519 15 hours agoparent$100 Helio G85 with 6G RAM runs fine. Fennex browser. Check your OS or browser for problems. reply petee 16 hours agoparentprevFor a comparison, I'm on a Pixel 8a mid-level device, and with Opera I get fairly smooth frame rates with some stuttering here and there. Maybe something else is running in the background? reply consumer451 16 hours agoparentprevThe creator is here reading the feedback, and committing code as we speak. I wonder how much HN feedback will help. In any case, this is all a fun experiment! update: between when I posted OP and now, the site went from utter jank in FF to 90% smooth on my 7 year old ThinkPad Carbon X1 (5th gen, Intel HD 620) Nice! This is one of the coolest comment->commit experiences that I've ever had! reply qingcharles 14 hours agoprevThis is trippy as hell on my 40\" ultrawide. Love it. reply metadat 13 hours agoprevThis is incredible. It's all I ever wanted. reply leonewton253 14 hours agoprevReally cool! Works smoother in Firefox than Safari reply xunil2ycom 16 hours agoprevI have no clue what \"Bluesky firehose\" even means. reply consumer451 16 hours agoparentBluesky is a microblogging social network, like Twitter, or Threads. However, Bluesky is the only one with open access to the firehose, aka all the activity. Here is a different, less aesthetically pleasing tool to see it: https://firesky.tv reply jeromegv 14 hours agorootparentMastodon is pretty open as well. Just won’t be the entire firehouse due to the decentralized nature of it. reply pfraze 1 hour agorootparentThe atproto relays are crawling aggregations of independent servers. There’s no reason AP couldn’t accomplish the same if they worked on it reply CaptainFever 9 hours agorootparentprevThere seems to be some projects that scrape(?) the most popular servers to turn it into a firehose, like this one: https://relay.fedi.buzz/ reply consumer451 14 hours agorootparentprevI should have included Mastodon in my list, my apologies. Theoretically, it's the most copesthetic project. reply infotainment 16 hours agoparentprevBluesky == A particular Twitter alternative Firehose == The raw live feed of all new posts from all users reply squigz 16 hours agoparentprevGoogle to the rescue: https://docs.bsky.app/docs/advanced-guides/firehose reply esperent 17 hours agoprevThis pretty quickly crashed my tab, using Chrome on Android. reply dicknuckle 15 hours agoparentWorks fine on Kiwi Browser on Android, although I'm using a fairly powerful ASUS phone. reply esperent 14 hours agorootparentI also tried it on Kiwi, using an s21 FE which is a few years old but not exactly a slouch and it crashed after about 10 seconds, same as Chrome. reply yonders 8 hours agoprevIt's a nice visualization, but it reminds me of why I avoid social media. Endless, worthless garbage spewed out into the void. reply globalise83 3 hours agoparentThis is also social media. reply nemo44x 6 hours agoprevThe firehouse will allow the scolds and hall monitors to more easily hunt down the blasphemers and wrong thinkers. reply mouse_ 5 hours agoparentweird take reply asacrowflies 1 hour agorootparentThat seems to the only purpose twitter ever served even before it was \"ruined\" was social witch hunts and mass mob forming. reply firecall 16 hours agoprevWarning: May Cause Seizures reply jauntywundrkind 17 hours agoprevAlso just saw this project, which is a little night sky scene where stars are posts. No real interactivity but fun to see the playing around! https://nightsky.hctr.dev/ https://bsky.app/profile/hctr.dev/post/3lb3ywnxac22n reply bitwize 9 hours agoprevNeeds more Ellie Goulding: https://helloenjoy.com/lights/ reply nektro 16 hours agoprevcrashed my firefox reply oksurewhynot 13 hours agoprevI would like to know how far through the firehose I have traveled reply 082349872349872 9 hours agoparentUse the force to sense how many pixels you've traveled. Then, when you get to the exhaust port, fire the proton torpedoes. reply valeg 16 hours agoprevWhoa! reply catapart 17 hours agoprevThis is fucking bonkers, bro. Love it! reply jaimex2 15 hours agoprevNot sure about your feeds but I got a lot of moping over Twitter/X. reply 2809 12 hours agoprev [7 more] [flagged] threeseed 12 hours agoparentLooking at their investment rounds have seen no Russian investment: https://www.crunchbase.com/organization/bluesky-514d/company... reply leonjza 12 hours agoparentprevCurious about this statement. Can you link to any reading I can do to learn more? reply consumer451 12 hours agorootparentSame here. I just looked up who is behind their Series A lead, and it's not ideal. However, I can't find a moscow connection. In any case, what I would love to know is who has the majority of voting shares, how the PBC relates to that, etc. reply timeon 10 hours agoparentprev [–] Isn't Twitter funded by SA and Russians? reply krjagsh 7 hours agorootparent [–] SA, yes. The full list is at the bottom of this article. While Russians may hide behind one of the many firms, it does not look like they have anything like a controlling stake: https://fortune.com/2024/08/22/elon-musk-x-twitter-owner-lis... reply timeon 6 hours agorootparent [–] > anything like a controlling stake Post (now flagged) was not mentioning controlling stake. So I was referring to this: https://www.dw.com/en/what-do-xs-alleged-ties-to-russian-oli... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion highlights nostalgia for the early internet's open data access, using the Bluesky firehose as a symbol of that era.",
      "Users express a desire to return to the creativity and innovation of the past, contrasting it with today's more closed and corporate web environment.",
      "There is a conversation about the potential of federated and peer-to-peer protocols to revive the open spirit of the early internet, with comparisons to Twitter's initial openness and concerns about Bluesky potentially restricting access."
    ],
    "points": 457,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1731794878
  },
  {
    "id": 42160647,
    "title": "James Gleick's Chaos: The Software",
    "originLink": "https://github.com/rudyrucker/chaos",
    "originBody": "James Gleick's CHAOS: The Software This is a free release of the source, manual, and executables of a 1991 Autodesk DOS program that was called \"James Gleick's CHAOS: The Software.\" The software was written by Josh Gordon, Rudy Rucker and John Walker. Rucker wrote most of the algorithms, except for the Fractal Landscapes algorithms, which are by John Walker. Josh Gordon did the interface, and much of the implementation of the algorithm code. The program was written in consultation with James Gleick about his brilliant book, Chaos: Making a New Science . This release is under a Gnu license. Downloads for the Release 1.1 The CHAOS executables and parameter files. The CHAOS User manual. The CHAOS source code. It's possible to run the Chaos program on any virtually any platform, inside a DOS shell called DOSBox. Details on the Releases page. You are free to alter the Chaos code and upload new versions. Or use our algorithms to spin off smaller programs. See our Chaos GitHub repository for the Chaos code online. The biggest outstanding upgrades for Chaos might be: (1) Increase the resolution or pixel size of the display. (2) Elmimate our use of the old DOS TSR or \"terminate and stay resident\" program metashel.exe, made by MetaGraphics Software Corporation. Chaos uses metashel calls for its graphics. What's In Chaos CHAOS has six modules. MANDEL. A Mandelbrot Set program, incorporating: quadratic and cubic Julia sets, quadratic and cubic Mandelbrot sets, and a gnarly cubic connectedness map called the Rudy set. MAGNETS. A Pendulum and Magnets program showing chaotic physical motion and fractal basins of attraction. ATTRACT. A Strange Attractors program showing the Lorenz Attractor, the Logistic Map, the Yorke Attractors, and the Henon Attractors. GAME. A Barnsley Fractals program showing Iterated Function System fractals such as the famous fractal fern. FORGE. A Fractal Forgeries program that shows clouds, maps, mountain ranges, and planets based on random fractals. TOY. A Toy Universes program that shows cellular automata.",
    "commentLink": "https://news.ycombinator.com/item?id=42160647",
    "commentBody": "James Gleick's Chaos: The Software (github.com/rudyrucker)226 points by signa11 19 hours agohidepastfavorite27 comments master_kuro 4 hours agoThis book changed my life. I was an awful mathematics student in high school, but having a very lukewarm interest in an artistic career I decided to take maths as an advanced subject so that I might pursue architecture or something. I ended up getting a U in my maths exams, which in the British grade system stands for “Unmarked”. I did so poorly that my paper wasn’t even worthy of a mark! Around the same time, I was wandering around the I saw a book cover with the weirdest, most beautiful looking graphics I’d ever seen. I still remember thinking “What the hell is that supposed to be?” as I picked it up. The copy I held had a colored picture segment as the middle pages with crisper, more mindblowing images. I borrowed the book and started reading it, trying to figure out how those images were drawn. Long story short, I ended up becoming quite competent at mathematics. Fractals (albeit statistical ones) actually ended up being an important topic in my doctoral research. I sometimes wonder what my life might have been like if I hadn’t seen those weird images - I’d certainly have become a very mediocre architect at best. reply hermitcrab 45 minutes agoparent>which in the British grade system stands for “Unmarked”. IIRC it was \"Ungraded\". But it was a long time ago! reply flir 3 hours agoparentprev> This book changed my life. Ditto! I thought science was... all about the end state? You mix these two chemicals together, you get these products. You solve a math problem, you get an answer. The idea that the interesting bit was the process, not the outcome, was a whole new way of looking at the world. It was my introduction to the idea that you could iterate - feed the outputs back in to the function as inputs - and not just get feedback squeal. How many genuine paradigm shifts do you get in a lifetime? Right book, right age. I bet most of the people leaving comments like this are circa 50 now. I never became competent at mathematics though :) reply glimshe 1 hour agoparentprevIt is a brilliant book, first book I bought with my own money college. It makes math interesting and approachable. reply dekhn 14 hours agoprevI read this as a high school student and saw a presentation on mandelbrot set around the same time. The presenter showed this equation: z = z**2 + c and explained how complex numbers worked. I went home and thought really hard- harder than I had, clearly figuring out some stuff I didn't know before (like mapping a small floating point interval to the \"high-res\" screen of my apple //e. Eventually I got a working program and started it... and it didn't get very far before I had to go to bed. I didn't even know at the time whether you could leave a computer on overnight- would it overheat? But I did and woke up to... nothing. My BASIC program hadn't gotten to any of the set yet, just the bands around it. At that point, I decided I needed a faster computer and eventually upgraded to a 80286 DOS machine which I think was able to run FRACTINT. FRACTINT was a clever optimization that used integer (which was all my poor 286 could do) and a number of other tricks to speed up set rendering. It was a very useful lesson in how to optimize. That book, and several others (K&R C, Hackers) helped expand my high school mind and point me in the direction of high performance computing, complex systems, and simulation. The butterfly effect played a huge role in my understand of classical causality. reply mbeex 6 hours agoparent> FRACTINT Still available: https://fractint.org/ Back then I learned C from the source files, until then I had been using a mixture of Turbo Pascal and assembler. Later that led to C++, which was the base language for a large part of my freelance career. Nice to be reminded of it again. reply dmd 4 hours agorootparentI wonder how hard it would be to get this running in pcjs so it just runs automatically in a browser. I spent hundreds of hours playing with it in the early 90s. reply sigil 13 hours agoprevGleick's \"Chaos\" got me sent to the principal's office in high school. I went crazy for fractals. Unfortunately all I had at home was an IBM PC XT. Mandelbrot set renderings were agonizingly slow and the CGA palette was too limiting. Around this time my co-conspirator and I realized the library had 386s that almost no one was using for catalog search. They became our fractal render farm. We'd exit the catalog program, insert a floppy with our latest renderer, kick off a deep zoom, and turn off the monitors to avoid suspicion until we could check back next period. The results were thrilling. What a difference the access to compute made. You all know the story -- eventually the librarian found us out and reported us for \"hacking.\" reply jdblair 13 hours agoprevI read Chaos while I was in high school in 1987. I promptly fell into a rabbit hole, coding the Lorenz attractor on an Apple IIe at my school. I was blown away that no matter where I zoomed in, there was more detail. Did humans create those features by inventing mathematics, or did they exist independently in the universe, waiting to be discovered? So many teenage philosophical conversations were prompted by that experience! The program in Applesoft Basic was SLOW! It's too bad it didn't motivate me to learn 6502 assembly. reply jeffrallen 5 hours agoparentAfter reading the book in high school, I was motivated by the description of the water drop interval timings experiment to try to replicate it with an Apple IIe, a laser and a photodiode. I was getting measurements and almost an attractor, but BASIC was too slow and it motivated me to learn assembly to get the measurements I needed. I think I basically lost interest in the physics and math and just kept going with computers. Still am, 40 years later! reply whyenot 14 hours agoprevThe fact that this is on Rudy Rucker’s github makes it doubly cool. Reading his book “Infinity and the Mind” is what got me to go back to school (as a math major). That book changed my life for the better. https://en.wikipedia.org/wiki/Rudy_Rucker reply eigenvalue 14 hours agoprevI loved this book so much when I was in high school. I read it again during college as well. Had a very big impact on me. He’s a really great writer and does a nice job profiling the various researchers and explaining the theory and ideas. reply wglass 2 hours agoprevNice moment of nostalgia seeing that. The Chaos book was mind blowing to all of us young math / cs nerds at the end of the 80s. Spent my Christmas break in college working with an artist coding Mandelbrot drawing routines on a IBM 286 machine. We’d print them out on a dot matrix printer and he’d incorporate them into elaborate collages. Love too that the author is Rudy Rucker, science fiction writer. reply msarnoff 1 hour agoprevIs this where XaoS (long time open source fractal generator) got its name from? https://xaos-project.github.io/ reply maurits 9 hours agoprevFor those who like this domain, the complexity explorer [1] is also a wonderful resource. [1] https://www.complexityexplorer.org/ reply vr46 10 hours agoprevOne of my favourite books and authors, I gave my copy to my photojournalism tutor after I explained how this book helped open up my mind and related directly to the photojournalism concept of “creating order out of chaos”, which has since become applicable to every part of my professional life! Need to go dig out his other books and get myself another copy of this. And clone this repo. reply jaybna 14 hours agoprevOne of my favorite books. The Information is also excellent. Time to fire up DOSBox. reply donatj 9 hours agoprevOh fascinating. This is the sort of stuff that really inspired my interest in computers as a kid of the late 80s. I am sure software of the demonstration sort like this still exists these days but it's far less publicized. I remember watching shows on the Discovery Channel about interesting software as a kid. reply cliffwarden 5 hours agoprevPlease do yourself a favor and read some of Ruckers sci-fi books! Live Robots is a great entry reply colechristensen 16 hours agoprevNeat! This was a very influential book to me when i read it as a kid. reply yapyap 5 hours agoprevHey, I’m reading this book currently. Awesome to come across this lol reply comboy 4 hours agoprevAny books on the same topic that anybody can recommend? I've tried a few and was mostly disappointed. I'd like something diving deeper than Gleick. reply lupire 6 hours agoprevOP Rudy Rucker also wrote the book Infinity and the Mind, on the same shelf in Barnes and Noble, another late 20th Century pop math book for nerds, with off the beaten path mathematical content and a not quite accurate perspective on the direction the world of science was going. reply anonzzzies 16 hours agoprevAh yes, I remember reading that when it came out and programming fractals because of it while reading. reply jonstewart 4 hours agoprevOh wow, another awesome thing about John Walker. RIP. reply pjs_ 16 hours agoprev [–] Amazing book reply kvjoshi 4 hours agoparent [–] Took a course on this subject during my undergrad and it was so much fun. The textbook we used was Nonlinear Dynamics and Chaos by Steven Strogatz who himself has written a number of fantastic popular science books. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "James Gleick's CHAOS: The Software\" is a free release of a 1991 Autodesk DOS program, now available under a GNU license, allowing users to modify and share the code.",
      "The program, inspired by Gleick's book \"Chaos: Making a New Science,\" includes six modules focusing on fractals and chaotic systems, and can run on any platform using DOSBox.\"",
      "Key updates include improved display resolution and the removal of the old DOS TSR program metashel.exe, with contributions shared via the Chaos GitHub repository.\""
    ],
    "commentSummary": [
      "James Gleick's book \"Chaos\" has significantly inspired readers, sparking interest in mathematics, fractals, and complex systems.",
      "Many readers shared personal stories of how the book influenced their career paths and experiments with early computers and fractal rendering.",
      "Rudy Rucker's involvement adds interest, as his contributions to science fiction and mathematics have also inspired many, highlighting the book's lasting impact and nostalgia."
    ],
    "points": 226,
    "commentCount": 27,
    "retryCount": 0,
    "time": 1731801163
  },
  {
    "id": 42160071,
    "title": "Teach yourself to echolocate (2018)",
    "originLink": "https://www.atlasobscura.com/articles/how-to-echolocate",
    "originBody": "Teach Yourself to Echolocate A beginner’s guide to navigating with sound. by Jessica Leigh Hester October 11, 2018 Teach Yourself to Echolocate Sounds bounce off surfaces—and you can practice listening to them. All Illustrations: Kristen Boydstun Wonder From Home See More Daniel Kish navigates the world like a bat does—and he does so without ever leaving the ground. After losing his vision as an infant, Kish taught himself to move around with the help of echolocation. Like bats, Kish uses his mouth to produce a series of short, crisp clicking sounds, and then listens to how those sounds bounce off the surrounding landscape. (Our winged neighbors tend to emit these clicks at frequencies humans can’t hear, but Kish’s clicks are perfectly audible to human ears.) From there, Kish makes a mental map of his environment, considering everything from broad contours—like walls and doors—down to textural details. Kish now teaches echolocation, mostly to students who are blind. For these students, Kish believes that an echolocation practice can buoy confidence and independence. Kish’s own experience is persuasive—he famously bikes along hilly, car-lined streets—and a growing body of scholarly research has begun to unpack exactly how expert echolocaters do their thing. This research has also backed up the idea that this skill is highly learnable. When researchers at the University of California, Berkeley, asked novice echolocators to use tongue clicks to determine which of the two objects in front of them was larger, the newbies were soon able to do so in a way that the scientists couldn’t attribute to chance. Whatever your sightedness, there’s something to be said for learning to listen more attentively to sonic scenery. Kish believes that vision has a way of blunting the other senses unless people work to really flex them. Deft echolocators, he says, are able to perceive fine differences—distinguishing, say, between an oleander bush (“a million sharp returns”) and an evergreen (“wisps closely packed together, which sound like a bit like a sponge or a curtain”). They’re discovering sonic wonder wherever they go. We asked Kish to tailor a lesson for first-timers just learning to listen to the landscape. 1) Practice tuning in Before you begin producing your own sounds, just practice noticing the ways that sounds change around you. Try this exercise next time you’re in a car (assuming you’re not in the driver’s seat). ATLAS OBSCURA BOOKS A Visual Odyssey Through the Marvels of Life Venture into Nature's Unseen Realms with Our New Book Atlas Obscura: Wild Life Order Now Crack open the window and close your eyes. This is a good chance to pass through a varied landscape pretty quickly, and begin to differentiate between sounds. “On a residential street, you should hear the sound of the car jump in and out as you pass other parked cars, possibly trees, posts, mailboxes, or houses near the curb,” Kish says. “Everything we pass reflects the sound of our car differently.” Prime yourself to pay attention to incidental soundtracks. 2) Pick your supplies If you are a sighted person, you’ll want a blindfold. “It’s very, very difficult to discern these kinds of subtleties if your eyes are working at the same time,” Kish says. Occluding one sense gives the less-dominant ones room to stretch their legs. Now is also a good time to stock up on what you’ll need for your practice sessions. First, you’ll need a metal tray or a bowl, so make sure you’ve got one on hand. Once you start moving through space later on, it will also help to have a trekking pole or a cane, or at least a partner you trust to shout if you wander too far off base. For beginners, the best clicks are ones that you can make cleanly and reliably. 3) Choose an environment Expert echolocators like Kish can get a bit fancier with their choices, and try to hear the character of a room. Tin decor, buttresses, or other accoutrements that might make a realtor swoon will also give Kish reason to perk up his ears. “It will sound more alive,” he says. “It will sing to you.” For beginners, picking the right place is a bit of a Goldilocks situation: You don’t want a flat field, where there’s nothing for sound to bounce off. Then again, you ought to steer clear of spots where your hearing will be impeded by, say, a sea of carpet. “Probably the best is a fairly quiet, open space without a lot of clutter, maybe a non-reverberant room,” Kish says. 4) Practice your clicks Clicks are not created equal, and some of them will work against you. “The most commonly produced rubbish click is a ‘cluck,’” Kish says. A cluck sounds something like two clicks on top of each other, which masks the returning sound. A good click can’t be sloppy, and it must be possible to reliably reproduce. For beginners, Kish says that a dental click fits the bill (this is a tsk-tsk sound, Kish says, “like you’re disappointed”). Another contender is the sound you might use to prompt a horse to giddy-up; a “ch” sound, as in “check” or “church,” is another option. The key is finding the option that’s comfortable for you. “You settle on whatever click you can do, and stick to it,” Kish says. Tune in! 5) Start simple The goal with clicking is to take stock of three things. The first is presence/absence (is something there?). Then, the location (what direction is it in?). Finally, distance (how far away is it?). To teach these skills, Kish often starts with this exercise: Students pair up with a partner who holds a bowl or flat paddle somewhere above their head. The student clicks, turns their head, and tries to gauge where the bowl is—straight ahead, or off to the side? Kish doesn’t click all the time—only when he needs to refresh the mental map he’s working from. For beginning students, though, it’s helpful to practice the physical mechanics of clicking, in order to learn how to listen to bouncing sounds. 6) Get moving The next step is to do all of this while in motion. Walk along a hallway and try to listen for differences in sounds that might indicate corners or open doors. At first, you’ll shuffle and fumble through this exercise, and it’s bound to be frustrating. Go ahead and ask your partner whether or not you’re on the right track—but, if you’re using a blindfold, keep it on. “The temptation is very strong to pop the blindfold off and on,” Kish says. “I resist that because there is an adaptation process that has to happen here. You disrupt it entirely when you pull off the blindfold. I wouldn’t use vision to spot-check an experience; I would try to avoid that.” 7) Stop when you need to Moving through the world in a new way can be both thrilling and thoroughly disorienting. Kish has found that people who are sighted, and are unaccustomed to not being able to rely on their vision, need to take breaks every 30-45 minutes. His blind students, for whom non-visual navigation is routine, can hang in longer. Echolocation takes patience and practice. Kish cautions that it’s hard to get good at this—it took him years. But trying it out can open your ears to the world. Next in series How to Turn Plants Into Tinctures, Like an Ancient Alchemist A beginner's guide to extracting flavors from herbs and flowers. serviceeveryday wonderhow toobscura academynavigationsounds",
    "commentLink": "https://news.ycombinator.com/item?id=42160071",
    "commentBody": "Teach yourself to echolocate (2018) (atlasobscura.com)207 points by Anon84 20 hours agohidepastfavorite55 comments almd 14 hours agoThis is often used by audio mixing engineers and taught in a roundabout way at schools and studios. We think a lot about where thins “sit” in the mix. Proximity wise, and even height wise in a stereo mix. Eventually you learn how to locate things in headphones and it’s a really weird sensation when you realize you can do it. The kicker is we start out by simulating real environments in mixes, but then end up having to simulate what people expect from the medium as opposed to real life. For example something I learned doing video audio, if someone is writing something on a train, viewers expect to hear the pen on paper. But irl, there’s not a chance it’s audible. Explosions are always distorted because microphones end up clipping due to the volume, etc. A great book on spatial simulation is The Art of Mixing by David Gibson. Older but forever relevant reply vasco 9 hours agoparent> For example something I learned doing video audio, if someone is writing something on a train, viewers expect to hear the pen on paper Just yesterday was watching Territory season 1 where the characters have an intense suspenseful, almost whispering \"serious voice\" conversation while standing next to a running helicopter, without even raising their voices which took me out of the scene. So the question is, do viewers want it, or do know it all producers say people do and put it in? reply Moru 6 hours agorootparentWhen they say viewers want it, they mean just about 90% won't notice. Most people haven't been close enough to a running helicopter to understand. I'm having problems watching movies at all, there is so many things breaking my immersion. :-) reply hackernewds 13 hours agoparentprevYou went on quite many topics there. Could you expand on the proximity and height? Fascinating The closest analogue I can think of is how due to practice now anyone can close their eyes and imagine typing entire essays how they know exactly where the keys are. Try it. reply high_priest 11 hours agorootparentI have played alot of videogames & at some point identified, how can I guess, the source of sounds. Guess, because it's nowhere near actual approximation. Most often, source is guessed by context. E.g. The door knocking sound illusion, which was used to troll streamers. Then you have directional localisation based on delay between ears, difference in volume & properties of reverberations. Things to the sides are going to arrive in either ear at different moment. Add source if first echo & you have confirmation that a sound is coming from either right or left. The more directly to the side is the sound, the bigger the delay between ears is, so you get approximate angle. Now we consider sound muffling, caused by shape of our head & ears. Things in front are going to sound clearer in the opposite ear, than sounds from the back. The same principle is used for detection of height. Things below are going to get muffled, things above will be clearer. In reality, feeling sounds with the whole body helps in source localisation, which can't be emulated with headphones. reply dnh44 12 minutes agorootparentI once lived in a shared 4 story house and I always intuitively knew where everyone in the house was, even if they weren't being loud. You could just tell where everyone was based on how the house creaked in response to footsteps. We had someone new move in once who walked very quietly and it made me feel slightly uneasy because they were sort of invisible to my hearing. reply sandworm101 1 hour agorootparentprevIve seen a BBC doc that tested this. They had people use putty to change the shape of thier ears, resulting in an inability to judge the height of a sound. Given how differently-shaped ears are, as opposed to the inner structures which are virtually identical, this result points towards a learned skill rather than something genetic. We each must learn how our paticular ear shapes modify sound. reply JoeyJoJoJr 11 hours agorootparentprevThere is a video for the art of mixing. It is indeed fascinating. https://m.youtube.com/watch?v=TEjOdqZFvhY reply romwell 9 hours agoparentprevThat's not at all what echolocation is. What you describe is locating the source of sound using binaural hearing (similar to how we can gauge distances using stereoscopic vision). Echolocation is finding out distance to objects (not sound sources!) by sending a sound wave in a direction, and listening for echos that bounce back. Hence echolocation. The only sound source is you. It's a form of active sensing: literally how a submarine sonar works (or radar, for that matter). Bats do it, too. This has very little to do with \"locating things in headphones\", as that is entirely missing the active part in the first place. Then, locating sound sources using binaural hearing is not the same as analyzing the scattered echoes when the sound source is you (relative to yourself, you know where you are already!). It's interesting that this is currently the top comment. I wonder how many people read the article before engaging in this discussion. reply yazzku 1 hour agorootparent> literally how a submarine sonar works And dolphins and whales, no need to go to submarines. reply planewave 8 hours agorootparentprevThis comment captures a lot of important detail about echolocation. reply bestouff 1 hour agoparentprevI think what you mean is that all your examples don't work when recorded. But a human being in a train may hear the pen on the paper. reply alentred 1 hour agoprevA few years ago, I was a frequent visitor to a public swimming pool, same day, same time. Apparently with similar swimming habits, there was an elderly person who was humming all the time. In the pool, in the shower, in the lobby, rather loud but not too much. I initially attributed it to elderly quirkiness. It was only after several encounters that I realized he was blind. The point is, I only figured that out when I saw him with a white cane outside, not at all by the way he moved inside or used the objects - he was navigating the space just like anyone else, and it was a rather crowded place. That was the day I learned that echolocation in humans is a thing. reply patja 17 hours agoprevThere is a wonderful book about the blind man who was probably one of the earliest innovators in using a cane for echolocation. \"A Sense of the World\" by Jason Roberts is the story of James Holman, who traveled the world in the early 19th century despite being blind, often being in a great deal of pain, and having limited mobility. reply hackernewds 13 hours agoparentWow it just struck me that the cane is for echolocation and not just obstacles. I did learn that the blind have keenly adjusted hearing. reply fao_ 13 hours agorootparentBlind people can use a cane for echolocation, but it's not necessarily reliable (especially in a busy city), and to be honest I'm hard-pressed thinking of any blind people I know that actually know how to do that. reply lynx23 8 hours agorootparentWha? Well, there are blind people who barely know how to use their cane, but... Let me explain. Manfred Spitzer once wrote that he thinks there are two groups of people on this planet who really have good audio location capabilities. Blind people and conductors. Conductors because they need to be able to listen to a particular performer, to isolate them from the rest of the orchester. And blind people, because we use the ear to navigate the world. Now, I actually use everything around me as a source of sound. Tapping with the cane is one of them. However, if I want to \"scan\" my environment, I usually make a clicking noise with my tongue. But those are the a small part of the game. The rest of the noises I use come from outside. Just a small example, before I loose myself in thsi comment: I can hear poles and trees on the sidewalk. Not because they emit so much sound, but because they eat it up. If a car drives behind the pole along the street, I can actually hear the point where the external sound doesn't reach me, infering that there must be a pole or a tree. Echo location is not always about what you send. Its m6ore about you learning how the sound waves around you behave. Sometimes, but this is getting borderline esoteric, I can hear the materials involved. Walking towards a wooden wall sounds destinctly different from walking towards a concrete wall... reply karl-j 3 hours agorootparentFascinating. That’s a lot like Passive Coherent Location (PCL), if normal echolocation is like radar. reply high_priest 11 hours agorootparentprevThey are probably constantly aware of surfaces the cane is bouncing off & use it as a redundant confirmation of what they \"see\" by touch reply vasco 9 hours agorootparentprevFor most it's not, echolocation is not widely taught. reply amatecha 15 hours agoprevI noticed when I was younger that I can \"hear\" when I'm near a wall, or just generally get a sense of the size of space I'm in solely via sound, but it never occurred to me to make a \"ping\" to sense the resulting sound reflections! Super interesting - I will have to try this. Probably my prior spatial sense from hearing was based on really subtle background noise of either my own footsteps or just environmental sounds reflecting around, I guess? I always felt like I am \"hearing the room I'm in\" but never quite knew how else to describe the sensation, but knowing people quite literally make a clicking noise to echolocate suddenly makes it much more clear! reply jcims 14 hours agoparentComb filtering (https://youtu.be/Amj4UevyRfU?si=5pwjHKwAw6bdmG2x) plays a role in this. I was listening to a podcast and realized I could hear the speaker turning pages under the microphone by the way it affected their voice in the microphone rather than the rustle of the page. It was pretty wild. I could ‘see’ it before i recognized what was going on. reply rcMgD2BwE72F 7 hours agorootparentThanks for the video, I wouldn’t have guessed it shows well on a video. Kinda off topic but I’m on a brand new phone (not logged in and no history) and the next video suggested by YouTube is a French fascist promoting (actual) nazis policies. Why would YouTube do that?! It has absolutely zero connection with audio topics. I just have my OS language set to French. That’s so worrying for the youth with being exposed to pure hate for no reason. reply Groxx 5 hours agorootparentBecause it makes Google money. reply at_a_remove 9 hours agoparentprevI did that, too, but I took it a bit further, possibly as a product of not having vision for about a year as a toddler, other than \"light\" and \"dark.\" reply pkoird 16 hours agoprevHere's an idea, use a (portable) ultrasound emitter device that sends a pulse every set second and use an earpiece receiver that produces equivalent acoustics in audible range. The setup may reduce \"tongue-fatigue' and the ultrasound will travel farther and can reflect off smaller objects. Would be an interesting experiment if nothing else. reply usgroup 5 hours agoparentSee here: https://www.youtube.com/watch?v=PD3Y1l8XyUw Another route would be to mix the ultrasound with another sound closer to the ear, then there is no need for an electronic ear at any point. The interference between sound can cause the inaudible frequencies to become audible. reply usgroup 5 hours agorootparentJust on this topic, would it be possible to make a whistle to do the same thing? I.e. crafted so it emits both ultrasound, and the audible counterpart which interferes with it to make the return audible? Perhaps it could be such that the ultrasound warbles whilst interfering sound does not (or vice versa), which would make the sources easier to distinguish also. reply bezmiran 15 hours agoparentprevI suspect it would be a very challenging problem for the earpiece part to recreate the directional info as well as our own ears, since the brain's ability to detect the direction of sounds depends on the shape of the ear itself. Maybe a simple mechanical clicker device like those used for dog training could be a useful tool. reply zafka 15 hours agorootparentI have one of these - purpose built for blind people to use. Pretty sure I picked it up at a NFB convention in Atlanta around the turn of the century. (NFB = National Federation of the blind) reply mmooss 15 hours agorootparentHow well does it work? reply zafka 2 hours agorootparentI will get back to you on that. I just found it in my desk. I myself am sighted, and have never used it for echo location - yet. Looking at it I realized that it was given out by my old employer: Blazie engineering. Coincidentally, I just ran into the founder recently. Next time I see him, I will ask him about the feedback he got on these clickers. I will say that after twenty years in a drawer it sounds good to my uneducated ears. reply gniv 11 hours agorootparentprevIf the wavelengths are not far from audible, wouldn't it be mostly a translation? reply laborcontract 15 hours agorootparentprevSeems like a fun use case for spatial audio on the airpods. reply croisillon 4 hours agoprevRelated: - Humans Can Learn to Echolocate (Livescience, 2015) https://news.ycombinator.com/item?id=10699105 - How humans echolocate 'like bats' (BBC, 2018) https://news.ycombinator.com/item?id=16782557 - Humans Can Learn How to 'Echolocate' in 10 Weeks, Experiment Shows (Sciencealert, 2021) https://news.ycombinator.com/item?id=27404132 - Teach yourself to echolocate - 106 comments https://news.ycombinator.com/item?id=18208334 reply Centigonal 18 hours agoprevrelevant video: https://www.youtube.com/watch?v=PD3Y1l8XyUw It appears that the hardest part of echolocation for humans is the \"produce a directed, crisp click\" part. The \"process the sound\" part is readily handled by our brains with a relatively mild learning curve. reply mmooss 15 hours agoprevI don't have much sense of the reasonably expected or maximium performance of this ability. They give a few sensational demonstrations, but how accurate is it (as in complete, correct, and consistent)? How fast? In what environments? How granular? Is it practical for everyday use? For some interesting context, here is a description of dolphin echolocation: https://www.britannica.com/animal/cetacean/ \"The amount of information obtained by an echolocating dolphin is similar to that obtained with the eyes of a sighted human. ... Toothed whales use extremely high frequencies, on the order of 150 kilohertz, for refining spatial resolution from their echoes. They are capable of “seeing” into and through most soft objects such as other dolphins, though the effectiveness of toothed whale echolocation drops off at distances greater than about 100 metres.\" Maybe with enough practice ... reply hackernewds 13 hours agoparentSounds travels very differently in terms of velocity scatter etc in water though. If somehow dolphins were capable, they would not nearly have the same echolocation capability on land reply lazycrazyowl 7 hours agoprevI initially misread it as “Treat yourself to a chocolate” reply eddd-ddde 1 hour agoparentI misread as \"Teach yourself to e-chocolate\" and was even more confused. reply koinedad 3 hours agoprevI’m wondering if we use it more than we think. When I have my headphones in with noise cancelling on I’m more inclined to bump something in my house I normally wouldn’t or misjudge a distance etc. Pretty crazy to think about forming a subconscious, audio-based world reply browningstreet 18 hours agoprevE- chocolate E- chocolate Don’t get it. Oh..! reply mrblampo 16 hours agoparentYep same. \"Teach yourself to eat chocolate.\" reply acosmism 15 hours agorootparenthad a french voice in my head going \"teache yourself to eatee chocolate\" reply Sn0wCoder 17 hours agoparentprevLOL, I passed by the article a few times reading the same thing. When I finally clicked in thinking it was something to do with the windows package manager. Something about the capital E. As soon as it was spelled with the little e, it clicked. reply hypertexthero 17 hours agoprevMaybe only distantly related to this, but thought it worth sharing that when I visited Seattle for the first time this year I caught a show by a band called La Cerca at Central Saloon and loved their song “Echolocation”, with ethereal sounding guitars, including the bass: https://www.youtube.com/watch?v=1NYeqA2Kve8 reply eschneider 8 hours agoprevThis is really interesting. As someone who's been gradually losing his vision, I've noticed some of this stuff on my own, but it's nice to see a good writeup so one doesn't have to figure out everything from first principles. Just one more thing to add to my bag of tricks. reply djtango 8 hours agoprevI'm so glad this is surfacing. I remember reading about the skepticism scientists had about this only for them to be finally proven wrong. My anecdotal experience is that we are so out of touch with our bodies these days that we routinely underestimate just how adaptable we truly are if we have the will or need to learn. So I get frustrated when very useful things like echolocation are suppressed by ignorant and cynical scientists who are unaware of their blind sides because they think they studied hard and read a bunch of papers. Our realities are shaped by our own experiences but what is sad is when people then shape other people's realities based on their own skewed realities. I'm glad that the internet is so good at spreading disparate, niche and folky knowledge and forcing scientists to reconsider their priors more often. reply dataviz1000 15 hours agoprevMeanwhile, after reading this article, I have my face one inch from a wall making clicks to see if I can hear the echo. Hopefully, nobody sees, or hears, me. reply mmooss 15 hours agoparentWe understand you. <3 reply Eduard 13 hours agoprevit's somewhere between silly and mischievous that AtlasObscura provides cute visual drawings yet fails to provide acoustic examples. reply gnarlouse 4 hours agoprevTeach yourself to echocolate reply sorwin 13 hours agoprevI'm curious if people with aphantasia would also be able to create a \"mind map\" of the area around them reply deegles 15 hours agoprevI have tinnitus and can't hear much in a range around 4.5khz... I wonder if this would still work for me reply schoen 10 hours agoprev [–] (2018) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Daniel Kish, who is blind, developed a method of navigation using echolocation, similar to bats, by producing clicking sounds and interpreting the echoes.",
      "Echolocation can enhance confidence and independence for blind individuals and is learnable by sighted people as well.",
      "The guide outlines steps to learn echolocation, including practicing sound awareness, using a blindfold, and starting in a quiet environment with simple clicking sounds."
    ],
    "commentSummary": [
      "Audio mixing engineers use echolocation techniques to determine the placement of sounds in a mix, considering factors like proximity and height.",
      "Echolocation involves sending out a sound and listening for echoes, similar to how bats and submarines operate, and is distinct from merely locating sound sources.",
      "Humans can learn echolocation to navigate spaces, a skill that can be enhanced with practice, and some blind individuals use it for navigation, supported by various tools and techniques."
    ],
    "points": 207,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1731797029
  },
  {
    "id": 42159713,
    "title": "Bluesky is currently gaining more than 1M users a day",
    "originLink": "https://bsky.jazco.dev/stats",
    "originBody": "atlasstatsrepo explorercleanup Bluesky Post Count and Author Stats Aggregate stats for all posts in Jaz's Bluesky index. WARNING: Stats other than Total Users are now falling behind as of November 15th, 2024 from the activity influx, numbers past that date are incomplete. Followers per User Percentiles Post Data Collection started May 1st, 2023 Total User Count is directly from the Bluesky API Large bot accounts are excluded from statistics and Top Posters Built by jaz 🏳⚧loading...",
    "commentLink": "https://news.ycombinator.com/item?id=42159713",
    "commentBody": "Bluesky is currently gaining more than 1M users a day (jazco.dev)205 points by henrijn 21 hours agohidepastfavorite214 comments jsheard 20 hours agoOn the topic of Bluesky stats, I just learned that blocks are effectively public via the API, so there's a hall of shame ranking the most blocked users on the site: https://vqv.app/blocks.html reply aucisson_masque 20 hours agoparent> a hall of shame Usually that's the opposite that happen with these kind of people. They are going to look forward on being the at the top of the leaderboard, like a child doing stupid things only to get noticed by its parents. reply hombre_fatal 19 hours agorootparentAssuming blocks themselves are never childish. Jordan Peterson is on the list and he doesn't even use the site: https://bsky.app/profile/jordanbpeterson.bsky.social reply arp242 18 hours agorootparentIt has an \"Impersonation\" tag: \"Pretending to be someone else without permission.\" Dunno if that's accurate though. But let's be real: Jordan B. Peterson on Bluesky is not going to be a different Jordan B. Peterson than he is anywhere else. If you don't want to interact with Jordan B. Peterson on e.g. Twitter, then you probably don't want to interact with him on Bluesky either. reply taeric 14 hours agorootparentTo an extent, I agree. In particular, I will not seek out that guy. However, feels virtue signal like to block someone that isn't there. Might as well block \"random jerk.\" What is the value of blocking people by name that may not exist? reply rsynnott 8 hours agorootparentHe likely just appears on a lot of imported Twitter blocklists. reply taeric 7 hours agorootparentAh. That is a fair point. reply TrueSlacker0 19 hours agorootparentprevSeems odd to be one of the most blocked with zero posts reply winwang 18 hours agorootparentprevThere was a script I once saw for Twitter where it blocked all users within some follower/followee radius of a set group of people. For public discourse, I wonder what the right level of agreeable \"echo-chambering\" is. reply mulmen 16 hours agorootparentprevI don’t use Bluesky. How is it childish? If Peterson has no presence then how is a block possible? If a block requires presence then blocking Jordan Peterson seems like a reasonable thing for a person to do. reply ronsor 19 hours agorootparentprevIt's not even the real Jordan Peterson apparently. reply zft 19 hours agoparentprevTop 100 BlueSky accounts Hall of fame https://www.graphtracks.com/1h reply James_K 20 hours agoparentprevA lot of Brazilians there. I guess it makes sense that they are a large portion of the user-base after Twitter got banned. reply jsheard 20 hours agorootparentI wonder what the backstory to two different Brazilian Taylor Swift fan accounts getting onto the most blocked list is... reply stubish 19 hours agorootparentProbably no fault of the feed, so not really a hall of shame. People you follow repost the feeds because they want to share with the world, and the posts end up in your timeline. You block them if you are not interested or if it is overwhelming, without having to unfollow anyone. reply hughw 19 hours agoparentprevalso https://clearsky.app/ reply khaki54 19 hours agoparentprevKind of shows the echo chamber. Looks like the Jordan Peterson account, which has never posted anything, is around number 14. reply m3kw9 20 hours agoparentprevi have a feeling by being on the list, it fuels more blocks, the rich get richer reply chevman 20 hours agoprevHighly recommend folks check out Mastodon as well - fully decentralized, no ads, no algo, no corporate control. It is continuing to grow steadily and has tons of activity compared to a few years ago. https://joinmastodon.org/ reply kaonwarb 19 hours agoparentI appreciate Mastodon and wish it were growing steadily. Unfortunately, activity metrics (see the second chart on this page, for example [0]) suggest that it's on a steady, slow decline. [0] https://mastodon-analytics.com/ reply jszymborski 19 hours agorootparentI see a plateau after a bunch of churn from large waves of migrations. Would be surprised if this won't be the case for bsky. Regardless of MAU count, there's plenty happening there to keep me active, and you get to see Threads users who speak ActivityPub as well as Bsky users via a bridge. reply muglug 19 hours agoparentprevI joined Mastodon in the big post-Elon user exodus. It’s great for geeky stuff, but Bluesky is much better for entertainment and news (i.e. what I mostly used Twitter for, pre-Elon). If geeky stuff is what you’re interested in, you can build that community on Mastodon easily. But if you want more popular content and users, they’re on Bluesky. reply ge96 19 hours agoparentprevI wonder how the world would change if ads just disappeared I get things have to be sold but damn it's out of control reply lostlogin 19 hours agorootparentLife without Pihole and a blocker is just grim. Every so often I get exposed to that world. It’s awful. reply BlueTemplar 5 hours agorootparentI would use PiHole, but them using Github is just a nonstarter (notably because that might be one of the websites I'm considering blocking, catch22 for blocklist updates). Or have they finally moved somewhere else less morally bankrupt ? reply drivingmenuts 19 hours agorootparentprevA lot of free services would disappear if they were unable to make some sort of ad-based income. Some people would be unable to do anything except whatever was provided by their government without ad-supported services (thinking Google products, YouTube, etc.) It would eventually go back to the way it was in the old days - a few actually-useful-but-struggling sites, a few paid-for services that might or might not survive, a passel of vanity sites and some incoherent cranks and weirdos (Time Cube, etc.). Heaven for some, but mostly boring for everyone else after an hour. reply ge96 15 hours agorootparentthat is fair, it's amazing how YouTube can eat a big file for free so you can have other people watch it, no storage cost concern edit: I'm more talking about the influence on people's minds whatever the ad is in particular the bad ones/narrative reply BlueTemplar 5 hours agorootparentIt's not like storage is particularly expensive unless you start to have hundreds of hour-long videos... Speaking of, one of the things that the 2012 Twitter APIpocalypse killed off, was Flattr 1.0 (with its buttons on websites to Flattr stuff so at the end of the month the sum of money you set away would be spread over all the Flattrs you made). reply amanzi 19 hours agoparentprevI signed up to Fosstodon and then followed a bunch of Python and Django folks. This has been great so far, and my feed is full of relevant, interesting posts. I see a lot of posts complaining about Mastodon and pointing to its decline, but for my use-case, I get a lot of value from it and am pretty happy. I'm not sure what benefits I would get by moving over to Bluesky? reply genem9 19 hours agoparentprevDon’t forget nostr! reply nostrfanboi 19 hours agoparentprevmastodon is federated, not decentralized reply tcfhgj 19 hours agorootparentfederation is a form of decentralization reply dyauspitr 19 hours agoparentprevFederated and no control just means it’s going to be overrun by trolls at some point? reply Zak 19 hours agorootparentProbably not. Each server has its own moderation, and servers that tolerate bad behavior from their users get blocked by most other servers. I'm not sure the current model would do well against a large coordinated manipulation campaign, but it handles isolated trolls at least as well as corporate social media. reply stubish 19 hours agorootparentprevNo corporate control. Server admin block nodes they don't want to see, so it is important to join a server with similar views as your own, or run your own server. reply seba_dos1 19 hours agorootparentprevThey already had 8 years to overrun it. reply drivingmenuts 19 hours agorootparentIt's probably a bit more work than a lot of trolls are willing to put in. Trolling doesn't require a lot of thought or creativity, but setting up the infrastructure does. reply dyauspitr 19 hours agorootparentprevYou don’t get trolls unless you have a lot of people on there already. reply m3kw9 20 hours agoparentprevwhy isn't mastodon one of the winners like bluesky? reply teeray 19 hours agorootparentBecause you can go to Bluesky and click “Sign Up” without a confusing explanation about instances. reply grishka 19 hours agorootparentMastodon has a big honkin' \"Join mastodon.social\" button both on joinmastodon.org and in the mobile apps to solve this exact problem. reply teeray 19 hours agorootparentBut the fact they still have this perception of confusing sign-up means they were too late. reply rvz 19 hours agorootparentprevGood solution. Problem is they have chosen a 'default instance' in the app which goes against the idea to encourage federation of the platform and instead accelerates centralization and there was backlash over that change. [0] mastodon.social will only get more centralized and is the only one that is benefitting from that change. [0] https://mstdn.social/@feditips/110233282251253677 reply genem9 19 hours agorootparentprevThis. Nostr could learn from this too. reply jsheard 19 hours agorootparentprevMastodon is confusing for non-technical users, while Bluesky is pretty much a drop-in replacement for Twitter. reply silisili 19 hours agorootparentI consider myself a technical person, perhaps not social media savvy anymore, and Mastodon confused the hell out of me. I don't think it stands a chance with regular Joe. reply agumonkey 19 hours agorootparentprevAnd beyond that, the federated aspect makes it very different from a global site like twitter. It was aimed at having control but in doing so you feel disconnect IMHO. reply ericjmorey 19 hours agorootparentprevIts fundamental design lacks the ability to provide features that many people want, because the developers see those features as anti-features to be avoided. Bluesky's AT Protocol was developed specifically to address what they saw as shortcomings with the ActivityPub protocol used by Mastodon and other similar services. reply Zak 19 hours agorootparentIt's fundamentally reasonably capable of things like full text search and better discovery, which its lead dev and much of the community see as anti-features. There has been some recent progress on search, but being searchable is opt-in only because many users are opposed to search. I think decisions like that are an active choice not to become popular. reply drewolbrich 19 hours agorootparentprevThis isn't the most important reason, but compared to similar web sites, Mastodon's user experience is awkward. reply metadat 19 hours agorootparentprevTry using it, it has extra steps and decisions that add friction and are annoying / challenging for end-users. reply barry-cotter 19 hours agorootparentprev> fully decentralized, no ads, no algo, no corporate control. No one owns it so there’s no team of well paid professionals trying to make it grow. reply Zak 19 hours agorootparentprevIt did see a big surge in popularity when Musk bought Twitter, but user numbers right now are not growing significantly. reply pimlottc 19 hours agorootparentprevThey probably are, but they don’t have a marketing team like BlueSky does reply rvz 19 hours agorootparentprevGood question. When you say Mastodon, my answer is 'which one' or 'which instance'? That basic hurdle is the reason why it is a barrier to many potential new users and it has traded complexity over ease of onboarding when trying to sign up new users (who are not techies or sys-admins). One solution is to set a default instance. I.e 'mastodon.social' and tell users to sign up there. Again, that increases the issue of centralization. To prevent that, you close sign ups and tell users to sign up elsewhere. Then the issue continues on other instances. Along side other issues, that is why new users just went to Bluesky or Threads instead. reply cjensen 19 hours agorootparentprevIt's a worse experience for posters for two major reasons: blocking is not as effective (blocked people can still read and respond), and there are too many weird scolds who yell at people for not adding content warnings for trivial things. I don't post so it doesn't affect me directly. It affects where the people I follow choose to post. reply churchill 19 hours agorootparentprevIt's not idiot-proof. Common-denominator platforms where you're expecting the general population need to be intuitive and work like people expect them to. Mastodon doesn't and their federated model is a pain in the behind. reply quantadev 19 hours agoparentprevnext [11 more] [flagged] jrflowers 19 hours agorootparentIf anybody is wondering what sort of political viewpoints quantadev is talking about, one example is they posted that The Onion and Alex Jones are the same https://news.ycombinator.com/item?id=42138285 reply quantadev 19 hours agorootparentI love having \"followers\" like you, jrflowers. Did you ever figure out how to setup that URL that pulls up just my posts? reply jrflowers 18 hours agorootparentThis site doesn’t have followers but if you see somebody POSTING in the VOICE of a guy wearing a sandwich board that says CHRIST WAS A LIZARD it only takes two clicks to see the other stuff they voluntarily posted publicly here (username -> comments) reply quantadev 18 hours agorootparentThat's very nice. Being from the Conservative-run city of Dallas, I've personally never seen a sandwich-board in real life. reply jrflowers 18 hours agorootparenthttps://knowyourmeme.com/photos/2112840-rent-free reply quantadev 17 hours agorootparentI don't click random, likely dangerous links, but it's good to see you've been rendered speechless. I like that. reply amathyst 19 hours agorootparentprevNobody take the bait reply makk 19 hours agorootparentYeah, boring old trope. reply quantadev 19 hours agorootparentMost people haven't heard of Fediverse, so it's a New Trope to them. reply Nuzzerino 19 hours agorootparentprevthat's a yikes from me reply ksenzee 20 hours agoprevThe infrastructure has been rock-solid. I’ve never seen a service grow this fast without any noticeable outages. The architecture and execution are obviously informed by serious experience at Twitter, but it’s also clear that management is giving them everything they need to do the job right. reply nicce 19 hours agoparent> The infrastructure has been rock-solid. I’ve never seen a service grow this fast without any noticeable outages. The architecture and execution are obviously informed by serious experience at Twitter, but it’s also clear that management is giving them everything they need to do the job right. The world has changed quite bit. If you have deep pockets and you can use AWS etc., it isn't a major problem anymore. However, if they indeed run it on their own data centers, that is impressive. reply crazygringo 19 hours agorootparent> it isn't a major problem anymore This is not true at all. The hard part isn't cloud vs. on-premise, it's the architecture. Most sites can either put all their data in a single massive database, or else have an obvious dimension to shard by (e.g. by user ID if users mostly interact with their own data). But sites where the data is many-to-many and there's a firehose of writes, of which Twitter is a prime example, are a nightmare to scale while remaining performant and reliable. Every single user gets an updated live feed of tweets drawn from every other user -- handling millions of users simultaneously is not easy. reply nicce 18 hours agorootparent> But sites where the data is many-to-many and there's a firehose of writes, of which Twitter is a prime example, are a nightmare to scale while remaining performant and reliable. Every single user gets an updated live feed of tweets drawn from every other user -- handling millions of users simultaneously is not easy. It is definitely not easy. But the core problem of this has been discussed since the release of Facebook. There are very obvious architectures which you can follow and then fix the bottlenecks with money. The cost is still the most relevant problem, which I wanted to say. The current cloud enables much higher optimization threshold and error margin. reply lazystar 17 hours agorootparentbingo. this problem is known and will soon be offered as a fully managed service - 1 click to have your own private social network. reply ksenzee 17 hours agorootparentprevThey moved from AWS to on-prem sometime in the last year or two: https://newsletter.pragmaticengineer.com/p/bluesky And I don't care how many resources you have available to throw at it, plenty of sites would still fall over with the kind of growth they're having. reply xboxnolifes 19 hours agorootparentprevI'm not so sure about this when not even 24 hours ago Netflix has streaming issues running on AWS infrastructure, and existing social media sites still have outages. reply nicce 18 hours agorootparent> Netflix has streaming issues running on AWS infrastructure I think the performance of Netflix is highly dependent of ISP's data centers [1]. But yeah, there are still limits where the cloud won't help you. If you whole infrastructure is designed to serve \"historical\" content instead of streaming, some bottlenecks cannot be avoided if you want to server low-latency sports stream. This came by surprise for me, but apparently betting has still significant role for the viewers. [1]: https://openconnect.netflix.com/en/ reply dangus 19 hours agorootparentprevDeciding to use a cloud provider or not has very little do to with the quality of the application and infrastructure architecture. You can make an app that scales beautifully on AWS or you can make one that chokes. reply porsager 7 hours agoparentprevI've had quite an opposite experience. I wanted to give it a chance, but the loading times for almost any kind of navigation were too long, so I automatically stopped visiting. reply benjaminwootton 20 hours agoparentprevThe performance is really good. Searches and general navigation. reply ideashower 20 hours agoprevIt’s definitely a whole different platform now, compared to when the first exodus happened. I’m loving it! The “starter pack” feature is great. There’s also this website where you can browse created starter packs for groups/interests you care about: https://blueskydirectory.com/starter-packs/all reply NAHWheatCracker 20 hours agoprevAs someone who never used Twitter, I made a Bluesy account and it was okay. I learned that I have no idea how to engage with that style of social media. One thing that put me off is how so much of what I saw was just talking about Bluesky vs Twitter. I hope they can move past that. reply datahack 20 hours agoparentBlue Sky feels like a cocktail party where half the guests are knitting sweaters for their cats, the other half are debating how to save democracy, and I’m just standing there wondering how I got invited. It’s like scrolling through a group chat where everyone forgot the topic but kept texting anyway. Honestly, it’s impressive how they’ve managed to create a platform that feels simultaneously too niche and too random. Idk, I spent a few hours over a few days trying to find something cool about it, and couldn’t. reply llm_trw 19 hours agorootparentThe astro pictures are neat. Everything else ... less so. reply charles_f 20 hours agoparentprevLol, I got curious about nostr, and it's the same thing, with an extra layer of \"crypto currency will save the world\" reply bentcorner 16 hours agorootparentSame - it was actually technically impressive how fast I got crypto spam upon joining nostr. reply andrybak 19 hours agoparentprev> One thing that put me off is how so much of what I saw was just talking about Bluesky vs Twitter. I hope they can move past that. Judiciously using the muting features is required to have a good time in social media. Add \"Twitter\" to muted words to move past that on your own. reply afavour 19 hours agoparentprev> One thing that put me off is how so much of what I saw was just talking about Bluesky vs Twitter That was a huge turnoff with Mastodon for me. Seemed almost everyone was just saying “wow, isnt it so much better here than on Twitter?” over and over and having everyone agree. By comparison Bluesky isn’t so bad, at least right now anyway. reply lz400 19 hours agoparentprevI hope so too. I had to leave threads because my wall was 90% people talking and complaining about Twitter and Musk and memes about the same stuff. Dude, I was here _precisely_ to avoid this, but it's even worse! reply matsemann 20 hours agoparentprevI joined twitter like 3 years ago, so also quite late to this type of game. Compared to forums, hn, reddit etc it's quite difficult to get your voice heard in the beginning. Anything you post is just shown to no one when you have no followers. Takes some time interacting with others and hope they follow or repost to get some traction. reply skywhopper 20 hours agoparentprevPeople talk about what’s on their minds. Most of the users just moved in the past week or two so that’s the hot topic. But it’ll change soon enough. reply davidcbc 19 hours agorootparentThis, it happens for a while after every big exodus moment and chills out after. reply hombre_fatal 19 hours agoparentprevYeah, I followed a bunch of game dev \"starter pack\" account collections and 90% of it was screenshots of tweets from Elon. That's still 80% of Mastodon's content so I don't expect much from Bluesky. reply llm_trw 20 hours agoparentprevThey have, the front page is all about how terrible Trump is right now. reply delecti 19 hours agorootparentWhat is \"the front page\"? Scrolling through the first couple dozen posts on my following feed, I see a selfies, science educators, artists, makers, a couple naked people, a complaint about days getting shorter, and a few people talking about health conditions they've gotten under control. If you don't want to see people talking about Trump, follow people who don't talk about Trump. Or add \"trump\" to your list of muted words. What you see is up to you. If you don't like what you see, there are a ton of levers in your control. reply llm_trw 19 hours agorootparentOpen https://bsky.app/ in incognito mode and you get to see the front page. Currently the top post on the latest refresh is: >I'm honestly surprised he hasn't started selling stool samples. His followers have been buying his BS for years, so it seems like a natural next step... https://bsky.app/profile/calltoactivism.bsky.social/post/3lb... This is not a network I want to join if this is the popular content. We've been told to curate our own garden for reddit, twitter, mastodon, etc. It never works because people who see that and like it join by the millions and those who don't don't. reply delecti 19 hours agorootparentYou can quite literally write your own algorithm for Bluesky. https://docs.bsky.app/docs/starter-templates/custom-feeds reply llm_trw 19 hours agorootparentThat's nice. It doesn't change the fact the default feed is amplifying the same posts that made twitter a toxic wasteland. reply melodyogonna 11 hours agorootparentSerious question here, I use Twitter all the time but I still don't understand this. What do people mean when they say Twitter is toxic? reply valval 11 hours agorootparentprevYou seem to be advocating going to a party where the lobby is full of people yelling about something annoying, and then pushing past them to some separate room where those same people are talking about something else, for the moment. I’d rather pick a different party. reply delecti 4 hours agorootparentExcept there's not really \"a\" lobby. It's a building with equally sized entrances on the red light district, wall street, silicon valley, and capitol hill. A lot of people happen to be coming in from capitol hill at the moment, because a pretty significant event just happened. Just because you know there's an entrance to the building on capitol hill, doesn't mean that's where you're coming from when entering the party. As soon as you have an account, you never need to acknowledge that entrance again. It just seems weirdly petulant to make a stand based on that. Even more so considering the post about Trump winning was similarly a front page post here, and that thread got more votes and comments than almost any I've ever seen here. And here there really is only one \"front page\". reply llm_trw 38 minutes agorootparentWhat do you call the place where everyone has to go through to get to every other place? The lobby. This is a UX decision that the blue sky team made to make signing up more streamlined and its one that's very poorly thought out. Given its the same people who almade twitter it's no surprise they are making the same mistakes. reply stavros 20 hours agoprevDoes anyone know any good makers I can follow on there? I'm mostly interested in making stuff, less in monetizing stuff, so I don't want to follow so much entrepreneurs (ie people who like making stuff to make money) as makers (ie people who like making stuff for its own sake). Any good lists? If anyone wants to follow me on there, I'm @stavros.io. reply bradgessler 20 hours agoparentI have a Ruby hackers starter pack at https://bsky.app/starter-pack/bradgessler.com/3laa47lbuwb2r — Edit: replaced cable modem link with starter pack link reply pocketarc 19 hours agorootparentYou might've pasted the wrong link! Although damn, this modem looks good too, worth thinking about. reply ks2048 19 hours agorootparentprevDo I have to buy this modem to view the Ruby hackers starter pack?? reply Scion9066 19 hours agorootparentprevHere's the actual link to the starter pack: https://bsky.app/starter-pack/bradgessler.com/3laa47lbuwb2r reply stavros 19 hours agorootparentprevThis looks like a really nice modem, but I have fiber :( reply tbalsam 19 hours agorootparentprevDo...do I open the modem and read the link off a piece of paper inside, kinda like a fortune cookie? reply bradgessler 18 hours agorootparentprevhahaha.... oops, I had to send that to Comcast because they're now thinking if I restart my modem for the third time, it will fix the problem. reply qudat 20 hours agoprevGratz to the blue sky team, it’s very hard getting a social media app to gain traction. However, after messing around with twitter and mastodon, I really do not get the appeal. All the incentives are not to have meaningful conversation, rather it is all about engagement. It’s way too much noise and not for me. reply stavros 20 hours agoparentIt strictly depends on who you follow. Follow people who have something to say, and you'll have meaningful conversation. reply qudat 19 hours agorootparentYou could be right but these platforms have not historically been about long form discussions, rather quips and glib remarks to drive clicks. reply BurningFrog 19 hours agorootparentFollow serious people and you can have serious conversations. reply nicce 19 hours agorootparentIf I follow only serious people, can I see their posts in chronological order (aka algorithm free), and without anything extra \"recommended\"? reply unleaded 19 hours agorootparentYes (Following tab) reply stavros 19 hours agorootparentprevYep! reply epistasis 20 hours agoprevBack in the news net days, there used to be a parable about a Berkeley hot tub. The owner would give out the code to people, and it would be a good party with a rotating cast of characters for a while, until eventually a few people ruined the party. Then the code would change, and a different crew would start coming through. Pre-Elon, it seemed that Twitter was doing a pretty good run of keeping a single social network running for a long time. As has Facebook. But for lots of dedicated communities, the new owner has such direct contempt for them and has focused on ruining the party. Bluesky will work for now. Already science Twitter is having a huge renaissance now that links are no longer suppressed and discussion has lower noise: https://substack.com/home/post/p-151688877 reply aorloff 20 hours agoparenthttps://www.berkeleyside.org/2022/09/28/berkeley-hot-tub-guy... reply epistasis 19 hours agorootparentAha, so it was real too? For the past few years I have not been able to find the old text that I used to, and I'm sure my memory has shifted a bit over time too. reply aorloff 16 hours agorootparentOnce upon a time... reply skybrian 19 hours agoparentprevThese starter packs sound like a good idea, but I have a hard time using them to find interesting people to follow. When I look at at the \"People\" tab, they look like pretty impressive people (academics, etc), and then I look at the \"Posts\" tab and it's the usual noise: cat pictures, politics, etc. Not a lot of signal. reply epistasis 19 hours agorootparentMaybe I've just been starved on Twitter/C for so long, but the signal was real for me, but in science there's been a sudden exodus to Bsky and an outpouring of joy that people are able to find new papers again and discuss conference talks live and post whatever they're cooking in their kitchen or lab. It's like the old days of Twitter are back, but it does take a lot of work to find that corner. reply rsynnott 9 hours agorootparentprevI mean, academics are allowed have cats, too. reply countrymile 20 hours agoprevI've had an account for a few months now, it always felt very dead, but something feels like it's shifted. reply pfisherman 20 hours agoparentAgreed. I was on twitter to discover, share, discuss articles and talks in my field of research. A couple months ago I had trouble finding good accounts and content; but now I am starting to find some of the PIs I was following over on twitter. Biosci twitter -> BioSky? reply minimaxir 20 hours agoparentprevBecause there was a certain geopolitical event about two weeks ago that was a primary reason many still used Twitter/X and now that said event is over (and whose outcome will likely cause Twitter/X to further degrade) there is no reason to stay. The exodus is not happening randomly or in a vacuum. reply ideashower 20 hours agorootparentThis plus the fact that starting Nov 15 tweets become by default training material for their language models: https://www.cnet.com/tech/services-and-software/x-is-using-y... reply ericjmorey 19 hours agorootparentAll posts on bsky are public and subject to use for training machine learning models. So a lot of people either don't care or are going to be very disappointed. reply geoka9 20 hours agorootparentprevIn view of this news, the story becomes even funnier: https://fortune.com/2024/11/14/grok-musk-misinformation-spre... reply geoka9 20 hours agorootparentprevOr possibly, once the event was over, the users in question had the idea that Twitter/X affected the outcome in the way they didn't like and they decided to boycott Twitter/X? reply matsemann 20 hours agoparentprevMy niche moved there summer of 2023, took some time to get going, some cross posting for a while etc, but by the end of the year it was almost exclusively on bsky. But have noticed the uptick, gained like 400 followers the last week. But it's a bit weird, as it's a Norwegian community, no relation to American politics. I guess it also can feel dead because it doesn't have a viral algorithmic feed like Twitter. But for me that's not an issue, ad even on Twitter I followed few enough people that I always used the chronological view. But I do like the custom feeds of bsky. Like a search/hashtag on steroids, making it easy to discover others discussing the same theme I'm there for. reply thewanderer1983 19 hours agoprevAm I missing something, or is the heading misleading. Where is the 1M gained users a day? I see statistics on likes, followers etc. Nothing here shows gain in 1M user accounts a day. reply taeric 19 hours agoparentI was confused on that, too. At the top, says 18m users total. So, for how many days did the headline mean? Was it1M+). I wonder why. (also some days are missing there, so maybe something changed in the data collection). reply davidcbc 20 hours agorootparentBrazil banned twitter reply JSDevOps 20 hours agoparentprevGot to be a podcast or something popular that Donald Trump appeared on reply victor9000 19 hours agoprevDoes anyone else have issues with the data privacy side of things? I'm not really feeling the \"everything is public\" aspect of the AT protocol. reply rvz 20 hours agoprevNo surprise as to why Bluesky is taking off, despite calling it years ago. [0] Now it has 18M+ users with 9M MAUs and 3.3M DAUs [1] after removing the invite system. The familiarity is easily transferable for a migration from Twitter / X. If you know how to use Twitter / X then you know how to use 90% of Bluesky. No need to 'choose an instance' or some admin shutting a server down due to 'other reasons' unlike with Mastodon or an arbitrary blackbox algorithm that limits / hides your posts found in Threads or needing a Meta account. Bluesky has learned from the mistakes of others to start first with a default server approach, you choose your own feed + algorithm and a search functionality that (works) can find accounts across the platform. Simple. [0] https://news.ycombinator.com/item?id=35750185 [1] https://bskycharts.edavis.dev/edavis.dev/bskycharts.edavis.d... reply Vaslo 19 hours agoparentAnd I’ll call it right now back to you now. It will go the way less than mediocrity of threads and mastodon. reply hebleb 20 hours agoprevI'm a 100% lurker and it's such a nicer experience before any enshitification. It probably won't last forever, but no ads or spam, and simply seeing a feed of accounts I follow is all I want. reply ersiees 20 hours agoprevWhat is the alternative to AI twitter? Is there some incumbent where it moves? reply minimaxir 20 hours agoparentIt depends on if you define AI Twitter as AI researchers or AI hypesters. Many of the former have indeed migrated. reply pipeline_peak 20 hours agoprevHow do we know the stats are real? reply epistasis 19 hours agoparentThe entire data stream is public. Personally, I've encountered zero bots or spam so far and am finding hoards of real people in my field joining so it seems real from my tiny tiny corner of the data stream. reply threeseed 19 hours agoparentprevThreads is seeing similar growth. So it stands to reason that we are seeing a large exodus of users from X and people are trying out both platforms to see which one suits them best. reply James_K 20 hours agoprevOne million accounts per day, and all of them making posts about their X. reply genem9 19 hours agoprevSo odd that a pseudo-decentralized centralized company gets so much attention when Nostr is actually decentralized but never gets mentioned. reply xigoi 7 hours agoparentWhile Nostr is well designed, it’s unfortunately closely tied with the cryptocurrency community. reply sangeeth96 19 hours agoparentprevI think most people wouldn’t care plus most who know wouldn’t make the mistake of trusting jack again. reply davidcbc 19 hours agoparentprevBecause people don't care about decentralization, they care about vibes and the vibes of Nostr are \"right wing grifters and crypto scammers\" reply kome 20 hours agoprevfinding the same ppl on bluesky needs work, and it's not a job i'm going to do. if twitter decays, good; i will get rid of my last social media app. reply ksenzee 20 hours agoparentNot all that much work: https://chromewebstore.google.com/detail/sky-follower-bridge... reply suzzer99 19 hours agoparentprevI found most of my twitter sports follows pretty easily. reply tcfhgj 20 hours agoparentprevbefore elon banned the api, there were tools to automate this reply steve_adams_86 19 hours agoprevNo one has called me a shitlord, cuck, idiot, or otherwise implied I’m stupid for the entire time I’ve used it. It’s great. The tech community on there is really solid, at least insofar as my interests go. reply genem9 19 hours agoparentWhat happens when they do, are you going to leave? reply happytoexplain 17 hours agorootparentIsn't that the implication? If you're on a platform with a lot of low quality bitterness and another one pops up with less of that, just move. If it happens again, move again. It's not team sports, you shouldn't feel loyalty. The only problems are practical, rather than psychological. reply steve_adams_86 18 hours agorootparentprevI’ll have to complain about it and have a big cry first, but yeah. I’m not actually opposed to people disagreeing with me or thinking my ideas are bad. It’s just pointless chaos and no functional or constructive discourse. That’s more so what bothers me about it. Even in relatively tame topics there tends to be some devaluing interjection of some sort. It gets tiring trying to find interesting content but only finding that, over and over. reply rsynnott 9 hours agorootparentprevIt has pretty good blocking/custom moderation tools. reply medo-bear 20 hours agoprevWhat happened to Threads ? reply threeseed 20 hours agoparentIt's about ~300m MAU and also hitting 1m users a day: https://www.threads.net/@mosseri/post/DCWz7LSvA36 reply KaoruAoiShiho 20 hours agoprevZuck dropped the ball bad. reply ks2048 19 hours agoparentI wouldn't count out Threads yet. But, in my limited use, something seemed off with Theads, but am liking Bluesky. YMMV. reply paxys 19 hours agoparentprevBy building a service that went from 0 to 275 million active users in a year (compared to Bluesky's 18 million)? reply tmountain 19 hours agoparentprevHe’s not the right person for the job of democratizing the interchange of information without bias. reply threeseed 19 hours agoparentprevThreads was the fastest growing app of all time and now has ~300m MAU, 1m new users a day and is on track to being larger than X in about a year. And then once they switch on advertising will be printing tens of billions a year. Hard to see how they've dropped the ball on this one. reply addaon 19 hours agorootparent> And then once they switch on advertising will be printing tens of billions a year. I’ve seen this said before, and I guess it might be true, but I don’t really get why people would use Threads once there’s advertising on it — isn’t it being a better experience their main value proposition? And they’ve just spent the last few years teaching people how easy it is to migrate between these basically-interchangeable services… reply threeseed 18 hours agorootparentX has ads. Bluesky will inevitably have ads. So which platform do you see them moving to ? reply aenopix 20 hours agoprevheavily censored reply citizenkeen 20 hours agoparentPeople blocking jerks isn’t censorship. Do you have a source that there’s any kind of censorship going on stronger than other social media networks? reply genem9 19 hours agorootparentThey removed a bunch of Palestinian journalists reply insane_dreamer 20 hours agoparentprevevidence? reply blackeyeblitzar 18 hours agorootparentI can’t find it now, but in one of the other HN threads, someone had shared a link to some lawyer defending women’s rights for sex-segregated things (like who gets to play in women’s sports). That profile had a label of “Intolerant” at the top, and nearly every post of theirs also had that same word “Intolerant” in a box in the body of each post, in place of the actual content that would be there. A little informational message indicated these labels were applied by an automated system. You would have to click the button to uncensor and view the message anyways, but it makes it much harder to consume their feed since you have to do that for each individual post, every single time you view the page. Someone else pointed out that you can opt out of the default moderation/censorship scheme that applies this labeling but the fact that it is on by default is problematic in terms of offering a politically neutral platform, since that is what most people will get. reply m3kw9 19 hours agoprevbut i'm already on X, I just can't make a move just because of decentralization or \"toxic\" environment everyone talks about. It has a lot more content and the people I follow are all here. reply richrichie 20 hours agoprevnext [13 more] [flagged] UltraSane 20 hours agoparentAs opposed to extremely dishonest far-right grifters like Twitter is now? reply Vaslo 19 hours agorootparentNo worries friend, many of these signups are us on the right going to troll. We don’t plan to support it for long. reply UltraSane 9 hours agorootparentWhat? reply rvz 20 hours agorootparentprevBoth extremes on the left and right have their own 'extremely dishonest grifters' and that issue is not exclusive to Twitter / X. reply UltraSane 8 hours agorootparentNope. The Left simply does not have anywhere near the same number of grifters as the right. There simply is no equivalent of Alex Jones on the left. reply nudpiedo 20 hours agorootparentprevFalse dichotomy doesn’t bring anything to the conversation. However it it true that the far left is the main motivated to quit X, and the progressive views Silicon Valley were also dominant on HN. Just something to accept and think about. Do not blame the messenger. reply UltraSane 8 hours agorootparentI'm not sure what you are trying to say. reply stormfather 20 hours agorootparentprevThe far-right thinks the far-left is dishonest and vice versa. They're both correct. It's all so tiresome. reply UltraSane 8 hours agorootparentNope. What is tiresome is constantly seeing how much the right lies and then lies about how much they lie. Trump told over 30,000 lies while President the FIRST time and still got re-elected. reply stormfather 33 minutes agorootparentDo you sincerely think the left doesn't lie also? reply cpeseethe91 20 hours agoparentprevWith the Dang moderation? And PGs vision? Can't wait to join! reply richrichie 19 hours agorootparentAnd what is PG’s vision? reply quantadev 19 hours agoprevnext [7 more] [flagged] xk_id 18 hours agoparentIt will never stop being funny to me how you can take an argument in American politics, directly apply it to the opposite side, and it will still be mostly true. reply quantadev 18 hours agorootparentWhich would imply conservatives are big censorship advocates? Maybe rethink that. reply xk_id 17 hours agorootparentTwo obvious examples are the pushback against lgbt awareness and elon’s use of twitter to algorithmically suppress the reach of leftwing accounts. reply quantadev 17 hours agorootparentI'm a Free Speech advocate in general, but after a decade of Censorship, Cancel Culture, and Shadow-banning of Conservatives (which Twitter DENIED they were doing, the entire time), I'm fully in favor of a full decade of payback from Elon. Let that sink in. reply xk_id 14 hours agorootparentThe bottom line is that your first post is a mirror reflection of yourself. Beyond this, I don't really care how you excuse your hypocrisy. reply quantadev 13 hours agorootparentGuilty as charged. Meant every word. reply smrtinsert 20 hours agoprevWhat's preventing everyone from putting their faith in another broadcast medium just to have it sold to Elon again? It's hard to trust social media these days. They have 0 incentive to be \"good\" from a variety of perspectives not just political. reply johnny22 20 hours agoparentbecause it's not centralized and you can self host it. reply asddubs 20 hours agorootparentif everyone is in practice using the same instance, they can just un-decentralize it at any moment they want, though reply threeseed 20 hours agoparentprev> They have 0 incentive to be \"good\" Yes they do. X has shown the more trusted and safe your platform is the better it is for advertisers and your bottom line. reply throwawa14223 19 hours agorootparentWhy would I want to be on a platform that is friendly to advertisers? reply blackeyeblitzar 19 hours agorootparentprevnext [2 more] [flagged] threeseed 19 hours agorootparentAssume you're right and advertising companies outsourced responsibility to GARM. Then since GARM was discontinued in August shouldn't all of the advertisers be suddenly flocking back to X. Because ad spend for X continues to be anaemic. And I assure that advertisers very much do care if their ads appears next to neo-nazi, racist and misogynistic content. reply vidarh 20 hours agoparentprevI don't like Bluesky because I feel it's a whole lot of pointless Not Invented Here vs. improving on ActivityPub, but it is still far more resistant to that than X/Twitter because people can migrate more easily. reply rr808 20 hours agoprev [–] Is it better than Mastodon? I signed up for that then gave up quickly. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Atlasstatsrepo Explorercleanup provides aggregated statistics for posts in Jaz's Bluesky index, with data collection starting on May 1st, 2023.",
      "The statistics, excluding Total Users, are incomplete after November 15th, 2024, due to increased activity.",
      "Total User Count is sourced from the Bluesky API, excluding large bot accounts, ensuring more accurate user representation."
    ],
    "commentSummary": [
      "Bluesky is experiencing rapid growth, gaining over 1 million users daily, as users discuss its features and compare it to platforms like Mastodon and Twitter.",
      "Key features under discussion include the public block feature, absence of ads, and lack of algorithmic control, with debates on its potential for meaningful conversation versus engagement-driven content.",
      "The platform's growth is partly due to its familiar interface for Twitter users and recent changes in Twitter's policies, though some users remain skeptical about its long-term appeal and potential issues with data privacy and decentralization."
    ],
    "points": 205,
    "commentCount": 214,
    "retryCount": 0,
    "time": 1731794315
  },
  {
    "id": 42158391,
    "title": "Four dead in fire as Tesla doors fail to open after crash",
    "originLink": "https://myelectricsparks.com/four-dead-tesla-doors-fail-open-crash-fire/",
    "originBody": "Home » Four Dead In Fire As Tesla Doors Fail To Open After Crash Social News Four Dead In Fire As Tesla Doors Fail To Open After Crash Last updated: November 16, 2024 3:49 pm fatima khan Share 5 Min Read SHARE A devastating accident in Toronto involving a Tesla Model Y resulted in the tragic deaths of four individuals and the miraculous rescue of a young woman. The crash, which occurred on October 24, has raised serious questions about the safety of Tesla’s electronic door mechanisms. A Tesla Model Y carrying five passengers lost control while traveling at high speed. The vehicle struck a guardrail and subsequently collided with a concrete pillar, bursting into flames upon impact. The collision took place on a local roadway, as confirmed by Toronto Police Duty Inspector Phillip Sinclair during a news conference. Three men, aged 26, 29, and 32, and a 30-year-old woman were pronounced dead at the scene. A 25-year-old woman survived the horrific accident and was transported to the hospital with non-life-threatening injuries. The sole survivor owes her life to the quick actions of Rick Harper, a 73-year-old Canada Post worker, who came upon the burning vehicle. Harper, along with other bystanders, noticed that the passengers were trapped inside the Tesla, unable to open the electronic doors. Harper recounted to the Toronto Star, “You couldn’t open the doors. I would assume the young lady would have tried to open the door from the inside because she was pretty desperate to get out.” Harper grabbed a bar from his truck and handed it to another bystander, who managed to break the back window and pull the young woman to safety. ALSO READ: Elon Musk Responds to Young Girl Who Found Bug in Tesla Model 3 The Tesla Model Y’s electronic doors, which require power to operate, have come under scrutiny following the accident. Authorities are investigating whether the failure of these doors contributed to the fatalities. Harper mentioned that the thick smoke made it difficult to see the other passengers trapped inside, further complicating rescue efforts. Tesla has faced criticism in the past for the design of its manual release levers, which are considered poorly designed and unintuitively placed. These emergency measures require intimate knowledge of the car, something that may not be feasible in a panic situation. ALSO READ: Tesla Warns Against Wet Towel Method for Supercharging The Toronto Police and fire authorities are conducting a thorough investigation into the crash. Deputy Fire Chief Jim Jessop stated that they are examining the possibility that the intensity of the fire was linked to the car’s battery cells. The crash has also highlighted concerns about the safety of electric vehicles in high-speed collisions. Despite the presence of manual release mechanisms in most Tesla models, the ease of access and usability of these features remain contentious issues. In a press release, Inspector Sinclair emphasized that no other vehicles were involved in the crash, and the investigation is ongoing. He also extended gratitude to Harper for his brave actions, stating, “Thanks very much to that bystander. We have been speaking to them, and obviously, they also are deeply affected by this incident, a very horrific scene for that bystander to step in.” Harper expressed his shock and sorrow after learning about the deaths of the other passengers. “I was totally shocked. It really hit me when I saw the report in the news that four had died,” he told CBC News. Harper was later informed by detectives that the young woman he rescued was recuperating in the hospital. This tragic incident has sparked a debate about the safety features of electric vehicles and the necessity for more intuitive emergency mechanisms. As authorities continue their investigation, the focus remains on understanding the causes of the crash and preventing such tragedies in the future. Tesla did not immediately respond to requests for comment, but the company is likely to face increased scrutiny over the safety and design of its vehicles’ electronic systems. The incident serves as a stark reminder of the potential risks associated with advanced automotive technology and the importance of accessible emergency features. You Might Also Like WhatsApp now lets you send video messages Feature How To Turn On Dark Mode On Snapchat Android? WhatsApp Delights iPad Users with New Beta App: Your Messages, Anywhere, Anytime Meta Launches AI Chatbots for WhatsApp, Messenger, and Instagram: Chat, Translate, and More Facebook’s Meta Releases AI Model for Image Recognition TAGGED:Tesla Share This Article Facebook Twitter Copy Link Print By fatima khan Follow: A brand new writer in the fields, Fatima has been taken under my electric spark's RGB- rich and ensures she doesn't engage in excessive snark on the website. It's unclear what command and Conquer are; however, she can talk for hours about the odd rhythm games, hardware, product reviews, and MMOs that were popular in the 2000s. Fatima has been creating various announcements, previews, and other content while here, but particularly enjoys writing regarding Products' latest news in the market she's currently addicted to. She is likely talking to an additional blogger with her current obsession right now. Previous Article Saudi Arabia Opens NEOM’S First Luxury Island, Kicking Off The Futuristic Megacity Leave a Comment Leave a Comment Leave a Reply Your email address will not be published. Required fields are marked * Comment * Name * Email * Website Save my name, email, and website in this browser for the next time I comment. Stay Connected 235.3kFollowersLike 1.4kFollowersFollow 1.5kFollowersFollow 1.5kFollowersFollow 2kFollowersFollow 2.1kFollowersFollow Latest News Saudi Arabia Opens NEOM’S First Luxury Island, Kicking Off The Futuristic Megacity Smart City November 12, 2024 First painting by humanoid robot sold for $1 Million at Auction Robotics November 11, 2024 Toyota’s Flying Taxi Takes Flight in Japan Transportation November 9, 2024 Rimac’s Insane Electric Hypercar: Nearly 2,000 HP, Face Recognition, and Level 4 Autonomy Transportation November 8, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42158391",
    "commentBody": "Four dead in fire as Tesla doors fail to open after crash (myelectricsparks.com)198 points by json_bourne_ 23 hours agohidepastfavorite174 comments ndiddy 23 hours agoAnother similar incident happened around a week after that one: https://www.channel3000.com/news/dane-county-sheriffs-office... . One thing to note is that the car doors in Teslas are electrically controlled and a different failsafe method of opening the doors is required when the electrical system isn't working. Here's the steps for manually opening the Model Y's rear doors (car in the story the post links to): https://www.tesla.com/ownersmanual/modely/en_us/GUID-AAD769C... and here's the steps for manually opening the Model S's rear doors (car in the story I linked to): https://www.tesla.com/ownersmanual/models/en_us/GUID-AAD769C... . Note that this involves removing the rear carpet in the Model S and the door pocket mat in the Model Y, and that the Model Y instructions note that some cars aren't even equipped with manual rear door releases. It seems like Tesla didn't account at all for what happens if passengers who aren't familiar with the car need to quickly exit in an emergency, especially if the driver's incapacitated and can't give them directions. reply rightbyte 23 hours agoparent* Remove the mat from the bottom of the rear door pocket. * Press the red tab to remove the access door. * Pull the mechanical release cable forward. It doesn't feel very panic friendly to have the emergency release hidden? reply pininja 23 hours agorootparentEvery Uber I take in a Tesla would practically need an airline safety briefing for this. There’s no way I’d find it on my own. reply ipython 19 hours agorootparentThat would be a fantastic idea: sell printed Tesla safety cards in the style of airplane safety cards. reply magnetowasright 17 hours agorootparentI think it'd be fantastic to not need it in the first place. It is just utterly beyond reason that this is even a thing. reply ipython 17 hours agorootparentSorry, I meant “fantastic” in the same sense as the fight club airplane safety cards: for example https://www.etsy.com/listing/1017594442/project-mayhem-fligh... reply justinclift 17 hours agorootparentprevYeah. Wonder if this \"safety feature\" was designed by a Boeing contractor? It'd be on-par for them, or at least the MCAS designers. reply throw0101b 19 hours agorootparentprev> Every Uber I take in a Tesla would practically need an airline safety briefing for this. If your Uber ride is a Model Y you may be SOL: Not all Model Y vehicles are equipped with a manual release for the rear doors. reply FireBeyond 18 hours agorootparentHow did this even get past the NHTSA/DOT - that has to be illegal. Electrical doors, with no failsafe? reply OutOfHere 22 hours agorootparentprevCancel and rebook (another brand). reply pininja 22 hours agorootparentThey've had huge pushes to add EVs to their network, which is great but this means it’s an increasingly likely for someone to get stuck. I’d include these instructions in their in-app safety center if I were them… reply speedgoose 22 hours agorootparentprevWouldn’t the average car safety be significantly below a Tesla Model Y anyway? reply OutOfHere 22 hours agorootparentTesla has the highest fatality rate, so that is ruled out! :) Secondly, it is the coupling of electronic controls with unintuitive manual backups that create the danger. reply remus 21 hours agorootparent> Tesla has the highest fatality rate, so that is ruled out! :) Do you have a source? Genuinely interested. From the little reading I've done Tesla seem to have put quite a bit of thought in to making their cars perform well in crash tests so it seems surprising that they'd have a high fatality rate. reply OutOfHere 20 hours agorootparent\"Tesla Has Highest Fatal Accident Rate of All Auto Brands: Study\" (2024) https://autos.yahoo.com/tesla-highest-fatal-accident-rate-16... reply remus 20 hours agorootparentInteresting quote from that piece: > The study's authors make clear that the results do not indicate Tesla vehicles are inherently unsafe or have design flaws. In fact, Tesla vehicles are loaded with safety technology; the Insurance Institute for Highway Safety (IIHS) named the 2024 Model Y as a Top Safety Pick+ award winner, for example. Many of the other cars that ranked highly on the list have also been given high ratings for safety by the likes of IIHS and the National Highway Transportation Safety Administration, as well. > So, why are Teslas — and many other ostensibly safe cars on the list — involved in so many fatal crashes? “The models on this list likely reflect a combination of driver behavior and driving conditions, leading to increased crashes and fatalities,” iSeeCars executive analyst Karl Brauer said in the report. “A focused, alert driver, traveling at a legal or prudent speed, without being under the influence of drugs or alcohol, is the most likely to arrive safely regardless of the vehicle they’re driving.” reply figassis 11 hours agorootparentSure, makes sense, but then we have the invisible, possibly non existent emergency door release. Do they also go through the effort of pointing this out as a factor in the statistics? Or is that not counted as a design flaw? Whether they’re saying the truth or not, i think in these roles, it’s very easy to omit damaging information while not outright lying. It’s also easy to be taken to lunch by a Tesla person to talk about how to cushion the reports impact. reply OutOfHere 18 hours agorootparentprevI am going to look at the data, not at the subjective reinterpretation or subjective rating. reply remus 11 hours agorootparentA good instinct, but the point is it's important to think about what the data means. The authors of the paper are just saying that the populations of people driving each type of car are different so looking at a percentage of fatalities is not particularly informative. If you took all those people who currently drive 20 year old fords at 10 under the speed limit and put them in teslas, maybe the tesla fatality rate per billion miles would start to look a bit better. reply atoav 21 hours agorootparentprevhttps://www.forbes.com/sites/stevebanker/2023/12/18/tesla-ha... reply speedgoose 21 hours agorootparentIsn’t it missing the death aspect ? reply atoav 9 hours agorootparentIt is found straight at the source: https://www.iseecars.com/most-dangerous-cars-study#v=2024 reply viraptor 21 hours agorootparentprevThat statistic is not controlling for the drivers. It's interesting, but it may be biased by who buys Tesla and how they drive. Similar to likely \"cars with aggressive custom paint jobs have higher fatality rate\". reply JumpCrisscross 21 hours agorootparentDoesn’t matter if you’re getting in someone else’s car. reply viraptor 21 hours agorootparentMaybe. Taxi drivers have different incentives/experience/routes than the other population. It may apply to them, or not. For ride share, the choice of Tesla may have been mainly economical for them. reply valval 19 hours agorootparentprevThe analysis you refer to isn’t super interesting as it’s not controlled. You’d need to be able to prove that independent safety and crash testing organisations are pushing out faulty results, since Teslas are among the safest (if not the safest) cars by their standards. reply speedgoose 21 hours agorootparentprevI would still favour the car that has good crash test safety scores and AI powered safety features that work relatively well according to independent tests, over the random taxi. But otherwise I agree, the door opening mechanism should be improved. reply beAbU 23 hours agorootparentprevEspecially egregious considering it's likely kids will be back there. And the release is in a place thats probably impossible to get to from the front seat (in the model Y) reply Symbiote 22 hours agorootparentI have written this before [1]. I had to kick the rear door of the family car after an accident when I was about 11. The car blocking both doors on the other side was on fire, and I was later told our car was also on fire. I wouldn't have known to lift the carpet and pull some release tag, and with the door badly damaged from a collision I also wouldn't have been able to kick it while pulling the tab. It was night, so finding and using a glass-smashing tool also seems unlikely. [1] https://news.ycombinator.com/item?id=25941750 reply redwall_hp 19 hours agorootparentYou probably can't break the glass either. Newer vehicles, especially Teslas, often have laminated glass that glass breakers have been found to not break. reply thatguymike 19 hours agorootparentI hear a ball bearing will do the job nicely. reply persedes 23 hours agorootparentprevMunroe on YT complained about exactly that 4 years ago :/ reply everybodyknows 22 hours agorootparentprevWhy not do the first two steps, and stow the mat and access door on a shelf in your garage? reply more_corn 20 hours agorootparentprevYeah that’s not happening when you’re literally on fire. reply trog 22 hours agoparentprevSomeone on Mastodon pointed out that not all Model Ys even have the manual release. I didn't believe this could be true - how could regulators allow this? But it's actually listed on the Model Y page (https://www.tesla.com/ownersmanual/modely/en_us/GUID-AAD769C...): \"Note Not all Model Y vehicles are equipped with a manual release for the rear doors.\" Not sure what the distribution is or whether it's just an \"old version\" problem? reply MichaelZuo 21 hours agorootparentSome countries may not require it, though it does seem pretty suspicious to omit that, regardless of what regulatory quirks there are in the world. reply giantg2 23 hours agoparentprev\"Tesla didn't account at all for what happens ...\" Tesla might not have, but you can. Always have a glass breaker and seatbelt cutter in your vehicle. Doors get crumpled and can't open regardless of make/model. reply fallingsquirrel 22 hours agorootparent> Always have a glass breaker Isn't this advice becoming dated now that most new cars have side windows with laminated glass? https://www.caranddriver.com/news/a28422725/car-windows-glas... reply tetha 19 hours agorootparentThis is something I found worrying, tbh. With tempered glass, firefighters heading for a vehicle accident attach glass breakers on a string to their gloves. That way, they can pull a person out of a car in 20 seconds if the immediate danger is larger than the medical considerations, and the person isn't stuck. With laminated windows, you need a Halligan bar or some other poking tool (sometimes forcefully moving a spike towards a patient) to make a hole, a Sawzall which needs 10 seconds alone to go through common glass, time to get all of that... It's worrying how much faster vehicle safety is moving compared to emergency extraction capabilities. reply giantg2 19 hours agorootparentprevUsually rear windows do not. Even laminated side windows can be defeated more easily if cracked. The lamination is pretty thin compared to many other types of laminated glass. reply dyauspitr 22 hours agorootparentprevStill probably easier to kick out a laminated window with cracks in it. reply OutOfHere 22 hours agorootparentprevKick out the window with a very forceful boot kick with both legs. reply viraptor 21 hours agorootparentThat advice will work for significantly limited number of population. Like, it's true, but also \"hope you have enough mass/strength/flexibility\". My little-old-lady neighbour could not do it. reply jeffbee 22 hours agorootparentprev\"Police say area man had burglary tools and weapons in his vehicle at the time of the arrest...\" reply Schiendelman 14 hours agoparentprevI'm always surprised to see this comment without seeing a response that this is required by law in the United States. Remember child locks? They are on all cars. The manual release cannot override the child lock so it has to be hidden to meet federal law. reply globalise83 23 hours agoparentprevWhat is an \"unlikely event\" for any given passenger is nearly a 100% certainty for Tesla. The engineers and product managers who came up with that solution probably have trouble sleeping at night these days. reply DrillShopper 22 hours agorootparentSomeone told me something that stuck with me: \"for any system with millions of users a 1 in a million event happens multiple times a day\" reply theolivenbaum 16 hours agorootparentI think the original quote was \"One in a million is next Tuesday\": https://learn.microsoft.com/en-us/archive/blogs/larryosterma... reply solardev 22 hours agorootparentprevI bet they wanted something more obvious but were overridden by someone who wanted to keep the vehicle sleek and futuristic. If so, it's the worst kind of \"I told you so\" :/ reply renewedrebecca 21 hours agorootparentBut who at Tesla would do that? reply solardev 19 hours agorootparentIt's quite a mystery, isn't it? reply semiquaver 20 hours agoparentprev> Note: Not all Model Y vehicles are equipped with a manual release for the rear doors. Astounding. reply pininja 23 hours agoparentprevRegulations are written in blood.. it’s really disappointing to see a car make it to production without an obvious mechanical way to open the door. I’ve been in many teslas and hadn’t given this much thought, figuring there’d surely be a way to open the door if I need to get out. reply nemomarx 23 hours agoparentprevwhy are the doors electronically controlled to start with? is it cost savings? reply eptcyka 23 hours agorootparentIt is more cyber that way. Also, yes, electromechanical systems are easier to design. reply stouset 23 hours agorootparentThere’s still a second mechanical release so this is strictly more complicated than simply having a mechanical system to begin with. reply eptcyka 23 hours agorootparentRouting the mechanical linkage to a place in the door that would make sense for a door handle to be is the difficult and expensive part. reply davrosthedalek 22 hours agorootparentBowden cables are dirt cheap. reply eptcyka 22 hours agorootparentThe cables are cheap, designing a door latch system to be easy to install/cheap to manufacture is not. Why do you think all parking brakes on all ICE vehicles have turned electric now? reply newaccount74 22 hours agorootparentProbably because forgetting to pull the handbrake is a very common cause of accidents? reply cyberax 23 hours agorootparentprevThey use frameless windows, so the electronic release slightly lowers them to avoid them scraping the door frame. reply lttlrck 21 hours agorootparentDropping the windows on frameless doors goes back to at least the 90s and mechanical door handles. I wouldn't be surprised if it goes back even earlier and someone even tried it entirely mechanically without electric windows... Update: it looks like it was first done on 1946 Buick convertibles. reply OptionOfT 23 hours agorootparentprevIn 2008 I had a BMW Convertible with frameless doors. When you pulled the door handle the window dropped. Same from the inside. reply neuralRiot 22 hours agorootparentEvery car with frameless windows does this without the need for a death-trap electric door release, i work in McLarens and the windows will drop if the battery gets low so you can open the vertical doors with a dead battery. reply PittleyDunkin 23 hours agorootparentprevWhy do they want frameless windows? reply dagmx 23 hours agorootparentFrameless windows are aesthetically pleasing to many people. Tesla aren’t alone in that preference, they are just one of the few brands that use frameless by default even on the lowest end vehicles they sell, so there’s a higher number out there. reply onetokeoverthe 22 hours agorootparentat the funeral... \"at least they had pleasing windows.\" reply throwuxiytayq 23 hours agorootparentprevWhy do they want glued-on RAM and SSDs? reply yibg 21 hours agorootparentprevThere were plenty of older frameless doors where the door itself opens mechanically and the window lowers slightly. A lot of the older subarus for example. What's special about Tesla (or any of the other newer cars with full electrical door opening mechanisms) that makes this not an option? reply cyberax 21 hours agorootparent> What's special about Tesla (or any of the other newer cars with full electrical door opening mechanisms) that makes this not an option? Cost-cutting, mostly. reply Citizen_Lame 7 hours agorootparentprevIt's impossible cannot be done. They tried nothing and were out of ideas. reply DrillShopper 22 hours agorootparentprevTo make the marks they're selling the death sedans to feel like they have something special until the vape batteries under the car spontaneously combust and roast them like a gas station hotdog reply dagmx 23 hours agorootparentprevA lot of cars have electronically controlled doors. It’s due to the frameless windows. Opening the door requires the windows to roll down slightly to avoid damage to the outer trim. The doors still have a mechanical release so there’s no cost savings involved. For the front door they’re right next to the electronic release. For the rear doors they’re hidden under the passenger door pocket. Edit: to everyone replying I never said it was a necessity. I explained why they did it. I’m aware of alternate approaches. reply bahmboo 23 hours agorootparentNot necessarily. Many cars have manual doors and frameless windows. A 1996 Subaru comes to mind. Tesla could easily make the windows dip when a mechanical handle was activated. Electronic door latches are fine, it’s the backup mechanism that is the problem. Some cars have the mechanical alternate forward of the electrical release such that if you are grabbing frantically you would eventually pull it. This still looks minimal if that is more important than safety. reply xbar 22 hours agorootparentprevThis is a design choice, not a requirement. My frameless-windows 2007 car uses a mechanical door latch and the window rolls down slightly as I pull the latch. reply hughesjj 22 hours agorootparentAlso every convertible ever reply tirant 22 hours agorootparentprevMost current BMWs with frameless windows still have mechanical door openings (e.g. BMW i4). reply badgersnake 22 hours agorootparentIndeed, my 2001 E46 BMW had this. It’s not complicated or new. reply soramimo 11 hours agorootparentI still have over one these and can confirm the doors open with the battery disconnected. reply dvdbloc 22 hours agorootparentprevI always thought it was a luxury item like soft close doors on high end luxury cars. Supposed to feel premium compared to actually pulling a mechanical handle. reply rad_gruchalski 19 hours agorootparentprevHow are you otherwise going to close the door with a button on that ipad in the middle? reply noncoml 23 hours agoparentprevLexus’s latest cars have electrically controlled doors as well. The mechanical failover is a bit better mind you, you have to pull twice instead of pushing, but I am not sure how panic proof it is. I live techlnology but IMHO it is overdone in modern cars. Please bring back tactile and mechanical controls where possible. reply l1tany11 18 hours agorootparentI’d be curious if there’s a single brand that has no electronic door latches at this point. Every brand I can think of has them on at least one vehicle. They have been in mainstream brands (like Chevy) for like 20+ years now. reply DrillShopper 22 hours agoparentprevDamn if only we had the tech to open doors mechanically. Imagine that world. I hope Elon takes a few weeks away from destroying the US Government in January to think about this./s For real though, I hope the relatives of the deceased take Elon personally and Tesla as a company for all they're worth. reply valval 19 hours agorootparent> Some crazy shit with /s > Double down on the crazy shit this time for real reply trinix912 22 hours agoparentprev> Note that this involves removing the rear carpet in the Model S and the door pocket mat in the Model Y Seriously? How many people would be capable of pulling this stunt off in a burning vehicle filled with smoke? Especially considering the fact that in this case the vehicle was packed (5 people in it)--it's hard enough to get your own feet out of the way. If this passes the safety regulations, those regulations should be changed. Not just expecting car manufacturers to do it out of their good will because they won't. reply unsnap_biceps 22 hours agorootparentRegulations are written in blood. This is likely the first time a mass produced car went this far in not caring about the humans inside. I would say that they will be new regulations soon, but given the political climate in the US, I'm unsure if it will actually happen. We can only hope that Canada and other countries takes the lead and forces the improvements to passenger safety. reply crazygringo 23 hours agoprev> Tesla has faced criticism in the past for the design of its manual release levers, which are considered poorly designed and unintuitively placed. These emergency measures require intimate knowledge of the car, something that may not be feasible in a panic situation. First, how is this remotely legal? Are there not safety standards to ensure adults can easily exit a vehicle on fire? Second, regardless of regulations, what on earth were they thinking at Tesla? Cars catch on fire and need fast emergency exit. Do they not care that their passengers might die? I am absolutely horrified by this. Those poor passengers. reply proee 22 hours agoparentThis seems like a huge failure on the part of the NTSB. Tesla is getting a lot of attention for this incident, but are there other manufactures that would have had the exact same problem given this same incident? The entire point of organizations like the NTSB is to prevent unsafe cars from going into production. The NTSB has given this type of door opening a green light. WHY? reply drivebycomment 19 hours agorootparent> This seems like a huge failure on the part of the NTSB. This is a deep misunderstanding. NTSB is not an organization with a regulatory power - it is an \"investigative\" agency. It does not have any mandate or power to stop anyone from doing anything. It can investigate and issue recommendations and reports to other agencies that have the actual power - FAA, FHA, NHTSA, etc, etc. reply gamblor956 22 hours agorootparentprevUnfortunately the NTSB doesn't actually have that power... It's an investigative agency, intended to investigate accidents and make recommendations. Unfortunately, they're just that: recommendations, not mandates. It's up to the agencies that govern the respective industries to issue regulations enforcing those recommendations (i.e., the NHTSA or FAA). reply proee 22 hours agorootparentprevIn reading a bit on this topic: According to the NTSB, vehicle models with automatic locking doors should automatically unlock after an accident. This begs the question did the door automatically unlock? Perhaps the vehicle was so damaged that the door could not be opened due to structural damaged to the door itself. reply unsnap_biceps 22 hours agorootparentUnlock doesn't mean unlatched, right? The emergency release cable is to unlatch the door. reply Schiendelman 14 hours agoparentprevUS safety standards require that a child cannot manually open a rear door if child locks are engaged. An emergency manual release can't appear and disappear depending on whether the electronic button is enabled. Children die this way in all cars. reply uberdru 23 hours agoparentprevNot to mention the way these things burn. Basically an inferno. . . reply proee 22 hours agoparentprevThe tolerance on many doors is such that even with a slight amount of damage, they are \"physically\" unable to open. The latch mechanism can get \"jammed\". Per the NTSB, they recommend that all electronic locks disengage in the case of an accident. Does Tesla follow this recommendation? It's possible the vehicle was damaged in such a way that none of the door could open because of mechanical interferences. reply sahmeepee 19 hours agorootparentAs someone else has pointed out, a car with electronic opening won't open even an unlocked door without power, so the Tesla could be compliant without meeting the spirit of the recommendation. reply mmooss 22 hours agoparentprevActions speak. Also, think of the many hours, spent by many people, designing, testing, writing the manual, manufacturing, etc. Lots of people need to sleep at night. On the other hand, many in our society devalue human life in the name of progress, anti-liberal politics, etc. If society shrugs at Covid deaths, war deaths, oppression, climate change death and costs - why worry about this? reply bdjsiqoocwk 22 hours agoparentprevDon't worry, I'm confident that with Enron Musk at the Department of Government Efficiency, if this is illegal now it won't be for much longer. People like Musk are just natural born problem solvers. reply RoyTyrell 23 hours agoparentprevAnd now he's bought his way into US aristocracy so he can do whatevr he wants and no one can stop him. He doesn't like criticism from the NTHSB? Well he can deem the NTHSB \"inefficient\" and have it downsized and the leaders sacked. Does the FTC think he's lying about his self-driving claims? Well maybe the FTC is inefficient and he just makes a call to Trump and the DoJ won't be investigating anything either. The US is now completely an oligarchy and kleptocracy. reply BriggyDwiggs42 22 hours agorootparentTo be fair we’ve been ruled by corporations for a while. reply davidw 22 hours agorootparentThis is taking it to another level. reply dwattttt 21 hours agorootparentAfter all the other levels it's been taken to? Surely not! reply archagon 21 hours agorootparentprevThis is completely true, but it does mean his cars will be unsellable elsewhere in the developed world. reply kylehotchkiss 23 hours agoprevI’ll leave a thought that isn’t a Tesla criticism (because the others are good): everybody should carry a lifehammer in their car. If not for saving your own life, it might come in handy for saving somebody else’s. https://www.amazon.com/Lifehammer-Brand-Safety-Hammer-Nether... Don’t buy the cheap Chinese knockoffs. reply ch1234 22 hours agoparentI don't buy safety/medical products from Amazon. There was a time (maybe even today still) where those products go into a big bin with no verification of who the actual supplier was (1st vs 3rd party). I don't know how to verify if the issue has been resolved today, but life-critical items such as tourniquets, meds, etc. are expected to be 100% made by the supplier. Unfortunately, the money in the industry is so big that \"cheap Chinese knockoffs\" are being sold as high-quality replicas, even though they may not meet all the required specs. There were many cases a few years ago of people buying branded tourniquets, only to be sold fake ones. The item looked genuine, but the integrity of the plastic could not maintain the pressures needed and broke. An emergency is not the time to realize that mistake. reply snapetom 23 hours agoparentprevI'd add that for anything your life depends on, my general rule is don't buy from Amazon. Buy from the manufacturer. Way too many counterfeits on Amazon. reply OptionOfT 22 hours agoparentprevhttps://www.lifehammerproducts.com/app/uploads/2024/06/20240... Lifehammers don't work on laminated glass, like your front windshield (that would be bad, as it would mean a rock chip would shatter your window). But more and more manufactures are putting in laminated side windows in their cars both for comfort (noise) and rollover protection, so Lifehammers don't work there either. https://www.youtube.com/watch?v=ptaIBTyiKkc I believe in the USA lots of tests are actually done without seatbelts, and this makes the requirements harder to meet. reply redwall_hp 19 hours agorootparentTesla is one of those companies. The side glass on their deathtrap shitboxes is fairly resistant to glass hammers. reply Upvoter33 22 hours agoparentprevThis isn't a solution though; the driver of an uber may have a lifehammer somewhere, but the passengers don't know about it. It is simply criminal not to have an obvious way to open the door. reply pvaldes 19 hours agoparentprevMaybe cars should be designed with a small button and a system to do that when airbag is deployed. If you carry a fireweapon, don't lose time finding the lifehammer (But then we need to choose between bulletproof glasses for external threats or breakable glasses for internal danger. Both options are exclusive). reply pyrophane 22 hours agoparentprevNote that these tools don't work if you have laminated side windows, which many cars now do! reply kylehotchkiss 22 hours agorootparentOuhh didn’t realize that cars switched up windows so much. Is there a modern alternative tool that a common person could use? reply BuyMyBitcoins 22 hours agorootparentprevI don’t know much about laminated windows, but would a $5 hammer from a hardware store work? reply jabroni_salad 22 hours agorootparentlaminated windows have a layer of plastic in them. You need a cutting tool. https://youtu.be/DyZrQ3Q0ZR0?t=75 Also I know this video has a firefighter in it but I will tell you that FFs are more likely to use a sawzall than a hand tool. reply FireBeyond 18 hours agorootparent100% - hand tools are far too slow. Sawzall is really the quickest method these days, although I have seen some new tooling being experimented with. reply thomassmith65 18 hours agorootparentprevGoing by the last time Elon Musk publicly demonstrated Tesla's 'bulletproof' glass, an emergency steel ball bearing should work. reply remram 20 hours agoparentprevThis is way too big for everyday carry, just in case my Lyft happens to be a model S. They should forbid those as cabs or take them off the road entirely. reply browningstreet 22 hours agoprevI recently had a break-in to my Tesla. All captured on sentry mode. The thief got in with a subtle, barely visible stab of their wrist. The Tesla service person who replaced my window figured it was a spark plug. In the video they barely make contact with my window and the whole window shatters, completely. So maybe at least storing spark plugs in each door bin. (Btw none of the relevant police jurisdictions cared a whit about the break in. There were cameras where it occurred. I’m not sure what the societal discouragement is for car break-jns. Seems like the relevant authorities have basically granted permission to car hooliganism. They took the police report but explicitly acknowledged no one would look at it.) reply Ccecil 22 hours agoparentIt is the spark plug insulator. They are using the ceramic from it to break the glass. I remember hearing about this in the 90s with thieves carrying insulators on strings in their pockets. https://www.carparts.com/blog/can-a-spark-plug-break-a-windo... note from the article: \"Keeping Spark Plug Shards Might Be Illegal in Your State\" so keep that in mind reply trallnag 22 hours agoparentprevAre you living in a good neighborhood? reply kevin_thibedeau 23 hours agoprevThe model Y's inability to roll down its rear windows is another safety liability. I had to vomit out of an Uber and had much difficulty getting my head out the tiny opening. reply dagmx 23 hours agoparentPerhaps you mean “roll it down all the way”, but it most definitely can roll down most of the way. As someone with a large head myself, I can most definitely fit it out comfortably of mine. reply kevin_thibedeau 23 hours agorootparentI don't have a large head. There is zero chance of crawling out the window if you're trapped in these cars. reply dagmx 23 hours agorootparentThat’s a different point entirely. You talked about being unable to fit your head out comfortably. I addressed that. reply nineteen999 18 hours agorootparentAt least their head can escape even if the rest of them can't. reply Reason077 22 hours agorootparentprevIf the door won’t open electrically, then very likely the power windows won’t work either. So to be able to crawl out the window, you’d have to break the glass, which would make the full size of the opening available. reply namdnay 23 hours agoparentprevThat’s not really specific to Tesla. Lots of cars have rear windows that only hinge open slightly reply Reason077 22 hours agoparentprevThis is an issue with many modern cars, not just Tesla. The rear windows physically can’t roll all the way down due to the shape of the doors. One way to solve it might be to design a window mechanism where the glass rotates in the frame rather than just sliding on a single axis. But as always, there’s a cost and complexity trade off. reply Beijinger 23 hours agoparentprevReal life problems. Thanks for sharing :-) reply mgarfias 22 hours agoprevMy Chevrolet truck while having an actual door latch, doesn’t open the doors if they’re locked. You have to pull twice. Is that an electronic counter (likely) or mechanical? If the latter, no big deal, if the former it’s even worse than the Tesla - at least my MY has a separate mechanical over ride. reply rightbyte 8 hours agoparentPulling again is probably a pretty panic friendly procedure though. reply serf 22 hours agoparentprevolder generation BMWs do this same thing; it's achieved by a ratchet system on the door handle that interacts with the mechanically actuated lock. it isn't electronic in the case of BMW. I don't know what Chevrolet does. reply mgarfias 15 hours agorootparentI dont trust that it’s a pure mechanical system reply Syonyk 22 hours agoprev> This tragic incident has sparked a debate about the safety features of electric vehicles and the necessity for more intuitive emergency mechanisms. Tesla is an ever-more-irritating case study in what happens when you throw out all the accumulated wisdom of an industry, dismissing them as aging dinosaurs, because you know code. For most of the last century and change, cars have had some predictable behaviors. In the event of a total power loss (engine, electrical, etc), you can still steer the car, brake the car to a safe and controlled stop, and get out of the car. As far as I knew, these were basic certification requirements, once those things came around. You can't do a pure drive-by-wire system, because when (not if, when) things go badly wrong, you still need to be able to control the vehicle. This is why we have mechanical linkages between the steering wheel and the front wheels, hydraulic brakes that function without booster vacuum, mechanical door opening levers, etc. In a panic situation, say, \"car is on fire,\" people are not going to calmly consider how to remove bits of carpet and access the emergency release mechanism they don't know about. They are going to yank on the normal door opening lever, repeatedly. It should be a basic certification requirement that this works, at least for the front doors (I'm willing to grant that the rear doors can have the \"interior handle disabled\" child safety things, but also, once your kids are out of car seats, this shouldn't be left enabled). Tesla's arrogance about the lessons learned by the last century of the auto industry is killing people. I'm sure they've justified it internally as \"Well, once our self driving stuff is working, our cars will never crash or fail so this doesn't matter,\" but come on. It's been a decade and that stuff still isn't working, so maybe put some mechanical door handles on your cars. reply davidw 22 hours agoparentWait until that same throwing out the accumulated wisdom is applied to the US government... reply newobj 22 hours agoprevDon't trust software engineers to handle edge cases and failure modes reply remram 20 hours agoparentThat's what regulation and compliance is for. Engineers are actually very good with those. reply syndicatedjelly 21 hours agoparentprevOr teach them? Risk management is something any (and every) engineer should learn reply debo_ 23 hours agoprevI'm waiting for a new regulation that requires all EVs to have a sledgehammer in the passenger cabin. reply creesch 23 hours agoparentHow about a simple tiny safety hammer instead. The ones a lot of cars (at least here in the EU) are already outfitted with. As others have pointed out, any car should have such a hammer. reply trinix912 22 hours agorootparentI'd assume it doesn't do much with laminated (rear) windows. It would require way too much force to break them enough to crawl out. Also, I've only seen those on busses, never in cars (I'm in the EU as well). reply snapetom 23 hours agoparentprevFor a long time, I lived in an area with a lot of creeks and rivers. Since my first car with electric windows and locks, I keep something like this: https://www.amazon.com/AmazonBasics-Emergency-Cutter-Window-... in the glove box or center console. Call me paranoid, but I don't trust the electronic system to work if my car is sinking. reply teruakohatu 22 hours agorootparentDon’t Tesla gloves boxes require the touch screen to open? reply EricE 15 hours agoprevWas watching a video on the new Lexus RX 350s and they are moving to electronic door mechanisms too. Talk about solving a problem that doesn't exist - oh how I loathe modern vehicles. reply xyst 18 hours agoprevI am so glad I didn’t buy a TSLA during the 2020-2021 hype. These vehicles are god awful, and are now glorified status icons. Safety is clearly a third or fourth priority. reply fHr 22 hours agoprevYou want less regulations, so deal with the consequences. reply Upvoter33 22 hours agoparentThis is why it's so dumb to want \"more\" or \"less\" regulation; clearly, there is some regulation we want, and some we might not. We should always be arguing specifics, not generalities. reply tamimio 20 hours agoprevhttps://archive.is/2024.11.16-143549/https://myelectricspark... One of the reasons I will never buy an electric car, the batteries are dormant bombs. reply alex1138 22 hours agoprevYou know, I was really sad when the Shuttle retired in 2011 (which itself had numerous safety problems they probably had to fix). And this glowing idea SpaceX will aid us onwards into the future, blah blah. I hope to god SpaceX doesn't act in a careless way like Tesla has been accused of doing reply sorenjan 22 hours agoparentThey damaged at least one car when their launch pad was suddenly distributed over a large area, throwing concrete pieces at least 6.5 miles. https://www.latimes.com/business/story/2023-04-26/spacex-sta... reply redwall_hp 19 hours agorootparentThey've also been fined for polluting waters with their launchpad deluge system. https://www.nbcnews.com/science/environment/spacex-polluted-... They also have a history of doing things without waiting for FAA approval. https://www.faa.gov/newsroom/faa-proposes-633009-civil-penal... Enron Musk has also mouthed off about NLRB and OSHA stuff before too, which seems like a red flag for a company employing workers to handle hazardous materials and do dangerous things. reply sorenjan 22 hours agoprevThere are keychain sized glass breakers available, maybe a good christmas present for a Tesla owner? Although I don't know if they still carry keys. reply tokai 23 hours agoprevEveryone should have a glass breaker in their car. Even if the car has mechanical doors. reply tamimio 20 hours agoparentI have two in the compartment between the front seats, and I also have an axe secured under the seat. However, accidents are random events; you never know what will happen. If these tools are still in place, can you reach them, and are you able to use them, among other things? So I wouldn’t count on it in the slightest. reply OutOfHere 22 hours agoparentprevIt is said that the glass breaker no longer helps with laminated side windows. What then. Kicking the window out, if that's even possible, could be the only way. reply tamimio 20 hours agorootparentUnfortunately kicking doesn’t work, it needs to be strong enough with momentum which you can’t do from the inside with current position, not to mention any injuries from the impact. reply senectus1 15 hours agoparentprevarnt car seat headrests designed for this use? You remove it from the seat and the \"poles\" are tapered for this purpose... reply Havoc 23 hours agoprevwow. That's genuinely scary. Sitting on top of a lithium fire while locked in seems terrifying. I wonder whether legislators should require inclusion of one of those glass break hammers in each car? reply magnetowasright 17 hours agoparentIf they're going to legislate anything it should be that door handles (internal and external) just can't be like that in the first place. I say external and internal because a few articles went around HN a little while ago of parents ending up with their kids locked in teslas on hot days and unable to get out because the stupid thing had no mechanical external door handles. It really troubles me that in many countries we have to ponder legislating something as fundamental as car door handles. Like, yes, regulations are written in blood, but door handles? Do we really need to be told to make door handles mechanical and where door handles go? It's just absurd to me that these doors were designed as such in the first place. reply Schiendelman 14 hours agorootparentThe irony is that rear doors don't have emergency overrides easily accessible because of federal regulations. If we did, children would use them when the child lock is enabled. reply criddell 22 hours agoparentprevWould those hammers work on Tesla windows? IIRC, they now use laminated glass (like windshield glass) on the door windows as well. reply more_corn 20 hours agoprevNightmare fuel reply formerly_proven 23 hours agoprev> Not all Model Y vehicles are equipped with a manual release for the rear doors. Yikes. Makes me wonder if this is market-dependent. I mean, do you expect \"Emergency manual door release\" to be a line item in Tesla's configurator? Didn't think so. reply Schiendelman 14 hours agoparentThis is US law. You can't have a child usable manual emergency release on the doors where you might have child lock enabled. reply rightbyte 8 hours agorootparentYou could have the manual release just not do anything when child lock is enabled like on every other car with child locks. Then again, there should be a manual release on the outside too... reply ncr100 21 hours agoprevTragic. And disappointing that the Tesla PR department is not responding to the public's questions, according to this article. reply FireBeyond 18 hours agoparentI suppose we should be glad they're just being silent, not auto-responding with a poop emoji like they previously have. reply sys_64738 17 hours agoprevWill Elon try to kill OSHA and NTSB in quest? reply jonpurdy 22 hours agoprev [–] Just calling out the poor way this (and many) articles write about car accidents. I’m not a Tesla fan at all but blaming Tesla for the crash is incorrect. (It is correct to blame them for the way the door locks work though and therefore can be blamed for the excess injuries/deaths that result from the design decision.) From the article: > Four people were killed in a fire after a Tesla Model Y lost control and hit a pillar in Toronto last month. > Five people were trapped inside a Tesla Model Y after it crashed and burst into flames The Tesla didn’t lose control, the human driver lost control of the vehicle. From a previous article the day after: > Police said the driver of the Tesla lost control of the vehicle while travelling at a high rate of speed and collided with a guard rail. The vehicle then struck a concrete pillar, they said, before bursting into flames. If it wasn’t for the irresponsible driving on the part of the human driver, this incident wouldn’t have occurred in the first place. The driver paid for this with their and others’ lives. reply ThePowerOfFuet 21 hours agoparent [–] >It is correct to blame them for the way the door locks work though and therefore can be blamed for the excess injuries/deaths that result from the design decision. This is what is being discussed here: that four people burned to death because they were unable to exit the vehicle. reply Schiendelman 13 hours agorootparentIt's not correct to blame them for the way the door locks work. This is the case on all electronic door handles, now becoming common on new cars. The reason you can't have an emergency manual override easily accessible is that a child could use it when child lock is enabled. The US government created this problem. reply 9x39 18 hours agorootparentprevIt's not entirely fair to say it happened in a vacuum, either, since car doors are damaged and fail-shut enough that almost every fire department has hydraulic rescue tools to force open trapped cars. The spontaneous combustion of Tesla's battery pack was the proximal cause of death here, but that's an EV problem in general, and will probably only grow as they take over the car market. Maybe we need the car version of https://en.wikipedia.org/wiki/SUBSAFE to account for EV combustion risks that prevent FDs from responding in time for locked doors. reply FireBeyond 17 hours agorootparentprev [–] And they had survived the impact, and were capable of, but unable to, exit. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Tesla Model Y crash in Toronto on October 24 resulted in four fatalities and raised concerns about Tesla's electronic door mechanisms, as they failed to open, trapping passengers inside.- The incident has prompted an investigation into the car's battery and door mechanisms, with criticism directed at Tesla's manual release levers for being poorly designed.- This tragic event has ignited a broader debate regarding the safety features of electric vehicles, particularly focusing on emergency egress systems."
    ],
    "commentSummary": [
      "A fatal accident in Toronto involving a Tesla Model Y resulted in four deaths due to the car's electronic doors failing to open after a crash.",
      "Criticism has been directed at Tesla's design, which requires a hidden manual release for doors, deemed unintuitive during emergencies.",
      "The incident has intensified discussions on the safety features of electric vehicles, highlighting the necessity for more user-friendly emergency mechanisms."
    ],
    "points": 198,
    "commentCount": 174,
    "retryCount": 0,
    "time": 1731783799
  },
  {
    "id": 42162622,
    "title": "All-in-one embedding model for interleaved text, images, and screenshots",
    "originLink": "https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/",
    "originBody": "TL;DR — We are excited to announce voyage-multimodal-3, a new state-of-the-art for multimodal embeddings and a big step forward towards seamless RAG and semantic search for documents rich with both visuals and text. Unlike existing multimodal embedding models, voyage-multimodal-3 is capable of vectorizing interleaved texts + images and capturing key visual features from screenshots of PDFs, slides, tables, figures, and more, thereby eliminating the need for complex document parsing. voyage-multimodal-3 improves retrieval accuracy by an average of 19.63% over the next best-performing multimodal embedding model when evaluated across 3 multimodal retrieval tasks (20 total datasets). Two months ago, we released the voyage-3 and voyage-3-lite series of multilingual text embedding models, providing best-in-class performance across a variety of datasets. Today, we’re excited to introduce voyage-multimodal-3, our first multimodal embedding model and a big step toward RAG and semantic search for knowledge bases rich with both visuals and text. voyage-multimodal-3 supports text and content-rich images such as screenshots of texts, figures, tables, PDFs, slide decks, and more. The resultant vectors capture critical textual and visual features such as font size, text location, whitespace, etc. This eliminates the need for heuristic-based document parsing, which often struggles with accuracy when layouts are complex or interspersed with figures and photos. Unlike existing multimodal embedding models that handle either a single text or image input, voyage-multimodal-3 allows for interleaved texts and images for maximum flexibility. Our sample notebook demonstrates all of these features. voyage-multimodal-3 has an architecture that is similar to that of modern vision-language transformers. This makes it a significant departure from existing multimodal embedding models, including, but not limited to, OpenAI CLIP large (clip-vit-large-patch14-336) and Cohere multimodal v3 (embed-multimodal-v3.0). In a set of evaluations across 20 multimodal retrieval datasets and 34 text retrieval datasets, we found that voyage-multimodal-3: Outperforms OpenAI CLIP large and Cohere multimodal v3 by an average of 41.44% (a 2.1x improvement) and 43.37% (a 2.2x improvement) on table/figure retrieval, 26.54% and 25.84% on document screenshot retrieval, and 6.55% and 5.86% on text-to-photo retrieval, respectively. Outperforms OpenAI v3 large and Cohere multimodal/English1 v3 by 5.13% and 13.70% on text-only datasets, respectively. Support for Interleaved Text & Images All existing commonly used multimodal embedding models (such as Amazon Titan Multimodal G1, Google Vertex AI multimodal, and Cohere multimodal v3) are based on OpenAI’s CLIP, which processes different modalities of data through independent networks. In other words, images must be vectorized through the vision tower, while text must be vectorized through the text tower, preventing these models from being able to processing interleaved data. In contrast, voyage-multimodal-3 vectorizes both modalities of data directly within the same transformer encoder, ensuring that both text and visual features are treated as part of a unified representation rather than distinct components. This mimics the model architecture of the latest vision-language models, only for vectorization rather than generation. As a result, interleaved texts and images, document screenshots, PDFs with complex layouts, annotated images, etc can be vectorized in a way that preserves the contextual relationship between visual and textual information. Mixed Modality Search with Screenshots All CLIP-like models perform poorly on mixed-modality search due to a phenomenon known as the modality gap. As illustrated in the figure below, the closest vector to the snippet “I address you, members of the Seventy-Seventh Congress…” is not its screenshot, but other texts. This leads to search results that are skewed towards items of the same modality; in other words, text vectors will be closer to irrelevant texts than relevant images in the embedding space. To illustrate this issue quantitatively, we conducted an experiment involving mixed-modality data. We created two sets of PyTorch documentation with identical content: one set as plain text (strings) and and the other set as screenshots. By combining a subset of text-based documentation with screenshots of remaining subset, we created a series of mixed-modality datasets. Each dataset represented a different proportion of text and screenshots, ranging from 0% to 100% screenshots. We then evaluated the retrieval accuracy of various multimodal models on these datasets, reporting the normalized discounted cumulative gain (NDCG@10) for each model across different screenshot ratios. As shown above, CLIP-based models experience a decline in retrieval quality as the proportion of screenshots increases up to 90%, highlighting a retrieval bias influenced by modality. Moreover, these models perform poorly when all text is converted to images. In contrast, voyage-multimodal-3 is not only the most performant for all ratios, but also has little-to-no performance drop across the board, indicating that the vectors truly capture the semantic content contained in the screenshots. This robustness is due to the model’s unique approach of processing all input modalities through the same backbone. With voyage-multimodal-3, there is no longer a need for screen parsing models, layout analysis, or any other complex text extraction pipelines; you can easily vectorize a knowledge base containing both pure-text documents as well unstructured data (such as PDFs/slides/webpages/etc) — screenshots are all you need. Evaluation Details Datasets. We evaluate voyage-multimodal-3 across 20 multimodal datasets spanning three different tasks: table/figure retrieval, document screenshot retrieval, and text-to-photo retrieval. We also evaluate voyage-multimodal-3 on a standard text retrieval task spanning 34 datasets in 6 domains (law, finance, conversation, code, web, and tech). For all datasets, the query is text, while the document could be a figure, photo, text, document screenshot, or a combination of these. For each task, we use prior top-performing models as the baseline. Alongside task names, we provide each task’s corresponding description and datasets used in the table below: Task Description Datasets Table/figure retrieval Table/figure retrieval measures the strength of a model’s ability to match an image containing a table or figure (charts, graphs, etc) with descriptions, captions, or other textual queries which reference the figure. charxiv, mmtab-test, ChartQA, Chartve, FintabnetQA, PlotQA, Document screenshot retrieval In this category, models are used to match queries with scans or screenshots of documents containing both text and charts. Energy, Healthcare Industry, Artificial Intelligence, Government Report, InfoVQA, DocVQA, ArxivQA, TabFQuad, TAT-DQA, Shift Project Text-to-photo retrieval This is the typical text-to-image matching used by CLIP and other CLIP-like models, where queries are associated with the most semantically relevant photos. meme-cap, mm-imdb, winoground, docci Standard text retrieval Standard text retrieval retrieves relevant documents by matching query strings with document strings. LeCaRDv2, LegalQuAD legal_summarization, AILA_casedocs, AILA_statutes, rag-benchmark-finance-apple-10K-2022, financebench, TAT-QA, finance-alpaca-csv fiqa-personal-finance-dataset, finance-financialmodelingprep-stock-news-sentiments-rss-feed, ConvFinQA, finqa, hc3_finance, dialogsum, QAConv, HQA-data, LeetCodeCpp-new, LeetCodeJava-new, LeetCodePython-new, humaneval, mbpp, ds1000-referenceonly, ds1000, apps_5doc, Huffpostsports, Huffpostscience, Doordash, Healthforcalifornia, Cohere, 5GEdge, OneSignal, Langchain, PyTorch1024 Note that the standard text retrieval task encompasses all datasets used to evaluate voyage-3 and voyage-3-lite except long context and multilingual datasets. See our previous blog post for more information. Models. For the three multimodal tasks, we evaluate voyage-multimodal-3 alongside four alternative multimodal embedding models: OpenAI CLIP large (clip-vit-large-patch14-336), Amazon Titan Multimodal Embeddings G1 (amazon.titan-embed-image-v1), Cohere multimodal v3 (embed-multimodal-v3.0), and SigLIP So400M (siglip-so400m-patch14-384). We also evaluate ColQwen2 v0.1 (colqwen-v0.1), a late interaction model that outputs many embeddings per document. For the standard text retrieval task, we evaluate voyage-multimodal-3 alongside OpenAI v3 large (text-embeddings-3-large), Cohere multimodal/English1 v3, and voyage-3. Metrics. Given a query, we retrieve the top 10 results by cosine similarity and report the NDCG@10. Results Multimodal retrieval. As shown in the figure below, voyage-multimodal-3 outperforms OpenAI CLIP large, Amazon Titan Multimodal G1, Cohere multimodal v3, SigLIP So400M, and ColQwen2 v0.1 by: 41.44%, 45.00%, 43.37%, 20.66%, and 6.14% on table/figure retrieval, respectively 26.54%, 37.68%, 25.84%, 35.62%, and 0.98% on document screenshot retrieval, respectively 6.55%, 5.16%, 5.86%, 3.42%, and 10.34% on text-to-photo retrieval, respectively Standard text retrieval. As shown in the figure below, voyage-multimodal-3 outperforms OpenAI v3 large and Cohere multimodal/English1 v3 by 5.13% and 13.70%, respectively. The performance of voyage-multimodal-3 is 0.05% better than that of voyage-3, making the two comparable in terms of retrieval accuracy for pure text documents. All evaluation results are available in this spreadsheet. Try voyage-multimodal-3 now! voyage-multimodal-3 is available today! The first 200 million tokens are free. To get started, check out our sample notebook, or head over to our docs to learn more. If you’re also interested in fine-tuned embedding models, we’d love to hear from you—please email us at contact@voyageai.com. Follow us on X (Twitter) and LinkedIn, and join our Discord for more updates. 1 Cohere multimodal v3 uses Cohere English v3 (embed-english-v3.0) for the text tower, which makes the both models’ vectors identical on pure text. To minimize confusion, we use “Cohere multimodal v3” as the only label in the charts. Share this: Twitter Facebook Like this: Like Loading…",
    "commentLink": "https://news.ycombinator.com/item?id=42162622",
    "commentBody": "All-in-one embedding model for interleaved text, images, and screenshots (voyageai.com)190 points by fzliu 11 hours agohidepastfavorite21 comments djoldman 5 hours agoThis is a key observation that is simple and intuitive: >All CLIP-like models perform poorly on mixed-modality search due to a phenomenon known as the modality gap. As illustrated in the figure below, the closest vector to the snippet “I address you, members of the Seventy-Seventh Congress…” is not its screenshot, but other texts. This leads to search results that are skewed towards items of the same modality; in other words, text vectors will be closer to irrelevant texts than relevant images in the embedding space. reply FergusArgyll 7 hours agoprevI'm missing something. Shouldn't any llm that's 'natively multimodal' somehow include embeddings which are multi-modal? for ex here's googles blogpost on Gemini Until now, the standard approach to creating multimodal models involved training separate components for different modalities and then stitching them together to roughly mimic some of this functionality. These models can sometimes be good at performing certain tasks, like describing images, but struggle with more conceptual and complex reasoning. We designed Gemini to be natively multimodal, pre-trained from the start on different modalities. Then we fine-tuned it with additional multimodal data to further refine its effectiveness. This helps Gemini seamlessly understand and reason about all kinds of inputs from the ground up, far better than existing multimodal models — and its capabilities are state of the art in nearly every domain. reply fzliu 1 hour agoparentBecause LLMs such as Gemini -- and other causal language models more broadly -- are trained on next token prediction, the vectors that you get from pooling the output token embeddings aren't that useful for RAG or semantic search compared to what you get from actual embedding models. One distinction to make here is that token embeddings and the embeddings/vectors that are output from embedding models are related but separate concepts. There are numerous token embeddings (one per token) which become contextualized as they propagate through the transformer, while there is a single vector/embedding that is output by embedding models (one per input data, such as long text, photo, or document screenshot). reply aabhay 6 hours agoparentprevLLM embedding contain super positions of many concepts so while they might predict the next token they don’t actually out perform contrastively pretrained embedding models. reply jonathan-adly 5 hours agoprevIf you are interested in that space, would throw our project in the mix which uses ColPali under the hood transparently. https://github.com/tjmlabs/ColiVara The main benchmark for this is the Vidore leaderboard. Where we would love to see where VoyageAI performs compared to the more open-source implementations. reply greatgib 6 hours agoprevIndeed, sad that their models are both commercial proprietary and API only. reply doug_durham 1 hour agoparentSad that people have to pay their employees? reply carschno 9 hours agoprevThis does read very impressive. Any critical perspectives on the presented evaluation? What about noon-English text? I understand the model is, like for other commercial ones, available exclusively through their API, right? reply stephantul 9 hours agoparentYes, voyage models are API only. There was a part here about multilingualism but that was wrong! Sorry! FWIW: Voyage also has separate `law`, `code`, and `finance` models. See [1] Really cool results, anyway. [1]: https://docs.voyageai.com/docs/embeddings reply fzliu 8 hours agorootparentGlad you liked the results! We do have multilingual models (and rerankers) -- voyage-3, in particular, is multilingual: https://blog.voyageai.com/2024/09/18/voyage-3/ voyage-multimodal-3 is multilingual as well, supporting the same set of languages as voyage-3. reply stephantul 8 hours agorootparentSorry for spreading false information. I edited the post above. It is interesting that you’re not as up front about multilingualism compared to cohere. They seem to mention it a lot, which led to my confusion. reply fzliu 8 hours agorootparentNo worries at all. That's great feedback and an area of improvement for us when it comes to future posts -- we'll be more explicit about multilingualism in blogs and in our docs. reply djoldman 5 hours agoprevThis is a cool way to look at multimodal embeddings. They look at performance as the the percentage of inputs slides from one modality to another: https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/... reply Zopieux 5 hours agoprevAPI-only model. No thanks but congrats anyway. reply A4ET8a8uTh0 4 hours agoparentAgreed on both parts of the statement. Granted, there are obvious considerations for exclusive API focus beyond just trying get the money from people, but I personally would not consider it based on the fact that they don't offer other options. reply fzliu 2 hours agorootparentI understand the sentiment. We are starting to open source some tools, mostly around embedding model evaluation (i.e. https://github.com/voyage-ai/voyage-evaluation-public), with other stuff coming up. FWIW, there are other deployment options besides the API as well: AWS (https://docs.voyageai.com/docs/aws-marketplace-model-package), Azure (https://docs.voyageai.com/docs/azure-marketplace-managed-app...), Snowflake (https://docs.voyageai.com/docs/snowflake), and vector database integrations (https://docs.voyageai.com/docs/integrations-and-other-librar..., https://milvus.io/docs/integrate_with_voyageai.md, https://docs.pinecone.io/integrations/voyage, https://weaviate.io/developers/weaviate/model-providers/voya..., https://qdrant.tech/documentation/embeddings/voyage/, etc). reply unit149 8 hours agoprevIn the traditional Python API, the Voyage engine will tokenize blocks of text and output a string of characters. This model seems to be doing that by vectorizing images in space. Words like 'you' and 'apple' will be a unitary token. More complex terms like 'pikachu' may be divided into pik-a-chu. [1]: https://docs.voyageai.com/docs/tokenization reply mech4lunch 6 hours agoprev [–] The colab measures dot product values 0.428 and 0.498, describing them as \"...similarity value is quite high.\" Is that high? Can you design a system that confidently labels data with a 0.4 threshold? reply fzliu 1 hour agoparentWhile the raw similarity score does matter, what typically matters more is the score relative to other documents. In the case of the examples in the notebook, those values were the highest in relative terms. I can see why this may be unclear/confusing -- we will correct it. Thank you for the feedback! reply minimaxir 1 hour agoparentprevA 0.4 with cosine similarity is not the same as a 0.4 with sigmoid thresholding. 0.4 cosine similarity is pretty good for real-world data that isn't an near-identical duplicate. reply brokensegue 4 hours agoparentprev [–] The raw output value is generally irrelevant. What matters is its position in the distribution of outputs reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Voyage-multimodal-3 is a new model designed for multimodal embeddings, enhancing retrieval-augmented generation (RAG) and semantic search by processing both text and images together.",
      "It achieves a 19.63% improvement in retrieval accuracy over the next best model across 20 datasets, outperforming models like OpenAI CLIP and Cohere multimodal v3.",
      "The model is available now, with the first 200 million tokens offered for free, and it excels in mixed-modality searches, even with high screenshot ratios."
    ],
    "commentSummary": [
      "VoyageAI's all-in-one embedding model faces challenges with mixed-modality searches due to the \"modality gap,\" where text vectors align more closely with irrelevant texts than relevant images.",
      "Gemini, a natively multimodal model, is trained on various modalities from the beginning, but it is less effective for semantic search compared to dedicated embedding models.",
      "VoyageAI's models are currently available only via API, but the company is considering open-source tools and other deployment options to enhance accessibility and usability."
    ],
    "points": 190,
    "commentCount": 21,
    "retryCount": 0,
    "time": 1731829328
  },
  {
    "id": 42160501,
    "title": "Stop making me memorize the borrow checker",
    "originLink": "https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/",
    "originBody": "Stop Making Me Memorize The Borrow Checker I started learning Rust about 3 or 4 years ago. I am now knee-deep in several very complex Rust projects that keep slamming into the limitations of the Rust compiler. One of the most common and obnoxious problems is hitting a situation the borrow-checker can’t deal with and realizing that I need to completely re-architect how my program works, because lifetimes are “contagious” the same way async is. Naturally, Rust has both! Despite how obviously useful the borrow-checker is in writing correct code, in practice it is horrendous to work with. This is because the borrow checker cannot run until an entire function compiles. Sometimes it seems to refuse to run until my entire file compiles. Because an explicit lifetime must come from somewhere, they have a habit of “floating up” through the stack, from the point of usage to the point of origin, infecting everything in-between with another explicit generic lifetime parameter. If you end up not needing it, you need to go through and delete every instance of this lifetime, which can sometimes be 30 or more generic statements that end up needing to be modified. In the worst cases, your entire architecture simply cannot work with the borrow checker, and at minimum you’ll need to wrap things in an Rc, which again will requiring upwards of 30 or more statements depending on the complexity of your architecture. Other times you realize you need a split borrow, and have to then modify every single function under the split borrow check to take specific field references instead of the original type. These constant refactors have been a major detractor for the language for years, although some improvements, like impl, have reduced the need for refactoring in some narrow cases. This means, to be a highly productive Rust programmer, you basically have to memorize the borrow checker rules, so you get it right the first time. This is stupid, because the whole point of having a type system or a borrow checker is to tell you when you get it wrong, so you don’t have to memorize how the borrow rules work. I don’t need to memorize how all the types work, because these errors get caught almost immediately, and rarely require massive refactors because the whole architecture doesn’t need to exist before it can identify problems. This is painful because I am an experienced C++ programmer, and C++ has this exact problem except worse: undefined behavior. In the worst case, C++ simply doesn’t check anything, compiles your code wrong, and then does inexplicable and impossible things at runtime for no discernable reason (or it just deletes your entire function). If you run ubsan (undefined behavior sanitizer), it will at least explode at runtime with an error message. Unfortunately, it can only catch undefined behavior that actually happens, so if your test suite doesn’t cover all your code branches you might have undefined behavior lurking in the code somewhere. Even worse, the very existence of undefined behavior sometimes creates a new branch you couldn’t possibly think of testing without knowing about the undefined behavior in the first place! This means that in order to write C++, you effectively have to memorize the undefined behavior rules, which sucks. Sound familiar? This is both stupid and strictly worse than Rust, because there is no compile-time error at all, only a runtime error if you get it wrong (and you are running ubsan). However, because it’s a runtime error, correcting it usually requires less total refactoring… usually. At this point, C++ can’t fix it’s undefined behavior problem because C++ uses undefined behavior to drive optimization, so now it’s just stuck like this forever. Rust can’t really fix borrow checking either, because borrow checking is embedded so deeply into the compiler at this point. All Rust can do is make the borrow checker more powerful (probably by introducing partial borrows, which seems stuck in eternal bikeshedding hell) or introduce more powerful IDE tooling that can make refactors less painful and more automatic, like automatically removing a generic parameter from everywhere it was used. Problems like these are unfortunate, because it drives people towards using C for it’s “simplicity”, when in reality they are simply deferring logic errors until runtime. I think Rust manages to “get away” with it’s excessive verbosity because “safe C++” is even more horrendously verbose and arcane, and safe C++ is what Rust is really competing against right now. I just think Rust needs more competition. Any prospective Rust competitor, however, needs to be very cognizant of the tradeoffs they force programmers to make in exchange for correctness. It is not sufficient to invent a language that makes it possible to write provably correct kernel-level code, it has to be easy to use as well, and we really need to get away from indirectly forcing programmers to anticipate what the compiler will do simply to be productive. It’s not the 1970s anymore, writing a program shouldn’t feel like taking a stack of punchcards to the mainframe to see if it works or not. Rust is not the answer, it is simply a step towards the answer. Published on November 15, 2024 at 1:20am share:",
    "commentLink": "https://news.ycombinator.com/item?id=42160501",
    "commentBody": "Stop making me memorize the borrow checker (erikmcclure.com)167 points by signa11 19 hours agohidepastfavorite211 comments Aurornis 17 hours agoA theme I’m noticing more frequently as Rust gains popularity is people trying to use Rust even though it doesn’t fit their preferred way of coding. There is a learning curve for everyone when they pick up a new language: You have to learn how to structure your code in ways that work with the language, not in the ways you learned from previous languages. Some transitions are easier than others. There should come a point where the new language clicks and you don’t feel like you’re always running into unexpected issues (like the author of this article is). I might have empathized more with this article in my first months with Rust, but it didn’t resonate much with me now. If you’re still relying on writing code and waiting for the borrow checker to identify problems every time, you’re not yet at the point where everything clicks. The tougher conversation is that for some people, some languages may never fully agree with their preferred style of writing code. Rust is especially unforgiving for people who have a style that relies on writing something and seeing if it complies, rather than integrating a mental model of the language so you can work with it instead of against it. In this case, if someone reaches a point where they’re so frustrated that they have to remember the basic rules of the language, why even force yourself to use that language? There are numerous other languages that have lower mental overhead, garbage collection, relaxed type rules, and so on in ways that match different personalities better. Forcing yourself to use a language you hate isn’t a good way to be productive. reply dwattttt 17 hours agoparent> A theme I’m noticing more frequently as Rust gains popularity is people trying to use Rust even though it doesn’t fit their preferred way of coding. I could've expressed the sentiment in this blog post back when I started playing with Rust ~2016. Instead, I ended up learning why I couldn't pass a mutable reference to a hashmap to a function I'd looked up via that hashmap (iterator invalidation lesson incoming!). The kind of bug I was trying to add exists in many languages. We can only speak in general terms about the code the blog post is talking about, since we don't have it, but couching it in terms of \"doesn’t fit their preferred way of coding\" misses that the \"preferred way of coding\" for many people (me included) involved bugs I didn't even realise could exist. reply Const-me 17 hours agorootparent> The kind of bug I was trying to add exists in many languages Any example except C++? BTW, the closest thing possible in C# is modifying a collection from inside foreach loop which iterates over the collection. However, standard library collections throw “the collection was modified” exception when trying to continue enumerating after the change, i.e. easy to discover and fix. reply dwattttt 17 hours agorootparent> modifying a collection from inside foreach loop This is exactly what the mutable map pointer was for, for the function to be able to modify the collection; C++ would result in potentially iterating garbage, C# it sounds like would throw an exception (and so show the design wouldn't work when I tried to test it), Python definitely didn't do a graceful thing when I tried it just now. And if I had a collection struct in C, I'm sure I could've done some horrible things with it when trying. The best of those outcomes is C#, which would've shown me my design was bad when I ran it; that could be as early as the code was written if tests are written at every step. But it could be quite a bit later, after several other interacting parts get written, and you rely on what turns out to be an invalid assumption. For Rust, the compiler alerted me to the problem the moment I added the code. FTR I ended up accumulating changes to the map during the loop, and only applying them after the loop had finished. EDIT: Python did do something sensible: I didn't expect pop'ing an element from the list to echo the element popped in the REPL, and got a printed interleaved from front to back, which does makes sense. reply dgoldstein0 12 hours agorootparentPython defined the semantics of modifying lists while iterating over them, which is better than c/c++ just calling it undefined behavior, but I've basically never seen it not be a bug. Either I end up creating a copy of the list to iterate over, or figure out a way to defer the modifications, or write a new list. Imo the c# /Java behavior of detecting and throwing is probably the best option for non borrow checked languages. reply cyberax 14 hours agorootparentprev> Any example except C++? Java for sure. > However, standard library collections throw “the collection was modified” Java is similar, but the exception is done on a \"best effort\" basis, and is not guaranteed. reply nurettin 13 hours agorootparentprevPython will raise a runtime exception if you modify the dict you are iterating over. You can work around that by copying a snapshot of the whole thing or just the keys and iterating over that. C++ will laugh in invalidated iterators. Of course you can erase from the container you are iterating over, but you have to make sure to continue the iteration using the iterator returned from the erase function and avoid storing copies of .end() reply AlienRobot 17 hours agorootparentprevI'm pretty sure most languages just make the reasonable assumption that you want to map to the object so it uses the pointer for hashing and not actually hash its value. reply o11c 12 hours agorootparentprevAnd yet, such mutation is perfectly safe as long as you only change the value of existing keys. But you can't do that in Rust. reply dwattttt 11 hours agorootparentYou would use interior mutability, putting things in Cells in the map. reply SoftTalker 17 hours agoparentprev> you’re not yet at the point where everything clicks This just seems to be the standard excuse I read any time someone has a critique of Rust. reply chipdart 11 hours agorootparent> This just seems to be the standard excuse I read any time someone has a critique of Rust. The guys who parrot this blend of comments don't seem to be aware that cognitive load is a major problem, not a badge of honor. reply eddd-ddde 3 hours agorootparentLearning the language fundamentals is not \"cognitive load\" more so for rust than c. With c you also need to understand pointers, manual allocation, volatility, is that bad? reply blub 11 hours agoparentprevWhat did the Rust community expect to happen if they so strongly and often claimed that Rust is easy to learn and user-friendly? And how did we get from that to “for some people, some languages may never fully agree with their preferred style of writing code”? If a C++ programmer (ideal Rust learner) says four years in that the ergonomics of Rust are bad, then based on my own experience I will believe them. I don’t write something to see if it compiles either, I design every single line of code. But with Rust (and a lesser extent C++) a lot of that design is for memory safety and not necessary for the algorithms. reply tialaramex 7 hours agorootparent> C++ programmer (ideal Rust learner) Well there's your problem. Rust does look like a semi-colon language, that's intentional, but if that's all you understand you're probably going to struggle. The \"ideal Rust learner\" would have an ML, such as Ocaml or F#, maybe some Lisp or a Scheme something like that, as well as a semi-colon language like C or Java not just the weird forced perspective from C++ One experiment I probably won't get to try is to teach Rust as First Language for computer science students. Some top universities (including Oxbridge) teach an ML as first language, but neither teaches Rust because of course Rust is (relatively) new. The idea is, if you teach Rust as first language your students don't have to un-learn things from other languages. You can teach the move assignment semantic not as a weird special case but as it it really is in Rust - the obvious default assignment semantic. I pass a Goose to a function, obviously the Goose is gone, I gave it to the function. Nobody is surprised that when they pass a joint they don't have the joint any more, so why are we surprised when we pass a String to a function and the String is gone now? And once we've seen this, the motivation for borrows (reference types) is obvious, often we don't want to give you the string, we just want to tell you about a string that's still ours. And so on. reply chipdart 5 hours agorootparent> Well there's your problem. Rust does look like a semi-colon language, that's intentional, but if that's all you understand you're probably going to struggle. This is a silly point to make. What makes a C++ programmer a C++ programmer is not an uncanny ability to find a semicolon on the keyboard. It's stuff like using low-level constructs, having a working mental model of how to manage resources at a low level down and how to pass and track ownership of resources across boundaries. This is not a syntax issue. It's absurd. You have people claiming that Rust is the natural progression for C++ programmers because their skillsets, mental models, and application domain overlap, but here are you negating all that and try to portray it as a semicolon issue? reply tialaramex 1 hour agorootparentOh! Alas the apparent syntax similarity is misleading. If you prefer imagine I wrote \"C-like language\" anywhere that I wrote \"semi-colon language\". It's not really about the semi-colon, indeed the semi-colon isn't even doing the same thing and that's a clue†. You see, the typical semi-colon languages you'll have used such as C++ or Java have these \"everything is a machine integer\" type systems which were a small step up from the \"Who needs a type system\" of their predecessors but aren't anywhere close to what you'd expect in an ML or a functional language. So this means there's a substantial learning curve, or, if you try to just keep writing C++ even though you're in Rust, an impedance mismatch. It looks superficially like the thing you're used to, but that's not what it is. † In Rust the semi-colon is turning your expression into a statement, but in the semi-colon languages it's a separator, everything is a statement anyway. So while a rust program might say let x = if k > 3 { plenty(k) } else { too_few() }; in the semi-colon languages there's a whole separate ternary operator provided to do this trick - in fact they don't have any other ternary operators and so they often call this \"the\" ternary operator which is very funny if you come from a language which has the multiply-accumulate operator... reply Ygg2 8 hours agorootparentprev> What did the Rust community expect to happen if they so strongly and often claimed that Rust is easy to learn and user-friendly? No one really claimed it was easy to learn. Find me one Rustacean that claims Rust is as easy as Python/Ruby/Go. But it is higher level language with decent ergonomic and in such way it can be interpreted as user-friendly. > If a C++ programmer (ideal Rust learner) If Java programmer (me) can learn Rust in a year enough to contribute to Servo development, you (ideal Rust learner) should have no problem either. Plus Google saw about 6-month to get people up to speed with Rust. reply chipdart 5 hours agorootparent> No one really claimed it was easy to learn. It's a great example of unintended comedy the fact that the comment right below yours is literally \"Rust is easy to learn and user friendly.\" https://news.ycombinator.com/item?id=42162676 reply Ygg2 42 minutes agorootparentSure but that's a no one. Same as me. Find someone on Rust team saying that. Or someone teaching Rust constantly. I can see user friendly. It's got a solid ecosystem around it, and compiler is super helpful with errors. But easy to learn it ain't. reply rapsey 11 hours agorootparentprevRust is easy to learn and user friendly. But if you are stuck in your ways and insist on writing code exactly like you did in another language you will have a hard time. This is true for every language on earth. Rust will refuse to compile, whereas other languages give you much more freedom to not use them as they are meant to. > If a C++ programmer (ideal Rust learner) There is no ideal learner. reply chipdart 11 hours agorootparent> Rust is easy to learn and user friendly. But if you are stuck in your ways (...) It's high time that people in the Rust community such as you just stop with this act. The Rust community itself already answered that they find \"Rust too difficult to learn or learning will take too much time\" as a concern to not use Rust. The community also flagged Rust being too difficult as one of the main reasons they stopped using Rust. https://blog.rust-lang.org/2024/02/19/2023-Rust-Annual-Surve... reply rapsey 10 hours agorootparentAnyone who has managed to become proficient in C++ is smart enough to be proficient in Rust. The only too difficult part is adapting to the rust way of doing things and some refuse to. reply throwaway81523 9 hours agorootparentThere is a saying among Haskellers that \"Haskell has the steepest unlearning curve\". Sounds like Rust is similar. reply chipdart 7 hours agorootparentprev> Anyone who has managed to become proficient in C++ is smart enough to be proficient in Rust. I'm not sure you're paying attention. The people who are saying Rust is too hard are the Rust community itself. They said so in Rusty's annual survey. The ones who participate in it are Rust users who feel strongly about the topic to participate in their governance. It's Rust users who say Rust is too hard. There is no way around this fact. reply 7bit 8 hours agorootparentprevEverybody who has managed to become proficient building a school is smart enough to be proficient in building a library. So building libraries must be easy, that's totally why you can become an architect over night ... What a stupid argument you delivered reply brabel 7 hours agorootparentprevYou just seem to have missed the point the author was making. I will try to clarify it: when you find out that a decision you made early on didn't pan out and you're forced to change the lifetime of some data, this will incur major refactoring in Rust and that will cause you to lose a lot of time. It's nearly impossible to avoid mistakes like this, not because you don't know Rust enough, that's almost completely irrelevant... it's because you just can't predict the direction your design will go to after many iterations and changes in requirements, which are unavoidable in the real world. Replying to that with \"Rust is easy to learn\" just makes it sound like you didn't even understand what you're trying to reply to. reply 7bit 8 hours agorootparentprevRust is not easy to learn. Stop saying that. It is hard. It is harder than C#, harder than Python, harder than Java, harder than PHP, harder than JS, Harder than TS. Saying it is easy to learn is just delusional and does a disservice to the language. Rust has many advantages, but trying to get people learning the language by lying about why they should learn it is just dumb. reply Arch-TK 18 hours agoprevI have memorised the UB rules for C. Or rather, more accurately, I have memorised the subset of UB rules I need to memorise to be productive in the language and am very strict in sticking to only writing code which I know is well defined (and know my way around the C standard at a level where any obscure code I sometimes need to write can be verified to be well defined without too much hassle). I think Rust may be difficult But, if I forget something, or make a mistake, I'm screwed. Yes there's ubsan, there's tests, but ubsan and tests aren't guaranteed to work when ub is involved. This is why I call C a minefield. On that note, C++ has such an explosion of UB that I don't generally believe anyone who claims to know C++ because it seems to me to be almost infeasible to both learn all the rules, or at least the subset required to be productive, and then to write/modify code without getting lost. With rust, the amount of rules I need to learn to understand rust's borrow checker is about the same or even less. And if I forget the rules, the borrow checker is there to back me up. I still think that unless you need the performance, you should use a higher level language which hides this from you. It's genuinely easier to think about. That being said, writing correct rust which is going to a: work as I intended and b: not have UB is much less mentally taxing, even when I have to reach for unsafe. If you find it more taxing than writing C or C++ it's probably either because you haven't internalised the rules of the borrow checker, or because your C or C++ are riddled with various kinds of serious issues. reply tialaramex 17 hours agoparentThe ISO document for C has an appendix which lists all the known categories of Undefined Behaviour. It's not exactly a small list, but it's something you could memorize if you wanted to, like the list of all US interstates, where they start and where they end. There has been a proposal to attempt this for C++ but IMO the progress on making such an appendix is slower than the rate of the change for the language, making it a never ending task. It was also expanded by the fact that on top of Undefined Behaviour C++ also explicitly has IFNDR, programs which it declares to be Ill-formed (ie they are not C++) but No Diagnostic is required (ie your compiler doesn't know that it's not C++). This is much worse than UB. reply Arch-TK 7 hours agorootparentThat's the appendix containing documented UB. The standard also explicitly states that any behaviour not explicitly defined by the standard is undefined meaning that there are things which aren't in that list. And I can confirm, there are things which you can do in C which are UB but which are not on that list. reply blub 11 hours agorootparentprevThis only makes sense if one wants to write a Phd on C++ UB and needs the exhaustive list. For the rest of us, there’s cppreference, UBsan and quite a few books on writing correct C++ code. Of course, these will still not suffice to write 100% memory safe code, which is a pretty arbitrary goal that just happens to match what Rust offers and is pushed a lot by Rust advocates. It’s a nice goal, but not everybody works on software that’s attacked all day every day. reply kimixa 9 hours agorootparentAlso, memory safety isn't the only \"bug\" - I'd even argue that the majority of \"memory\" issues in unsafe languages like C are actually the result of a logic error or mismatch of interface expectations, and a memory error is often the \"first noticed failure\". In the trivial example strcpy() examples people love to use, unexpectedly truncating a string often means the program has \"failed\" in it's intended task just as much as a segfault or other memory corruption. I'm extremely positive on highlighting as many of these problems before it gets to the user's hands, even more so if it's as early as a compile step as in the borrow checker, but lets not delude ourselves that they are the only possible issue software has. Or that in many languages it's a tooling issue (or culture issue accepting that tooling...) rather than a fundamental language difference. On a side node, with the prevalence of things WASM I feel some people are just redefining what \"memory safety\" is. Defining a block of memory and using offsets within that is just reinventing pointers, the runtime ensuring that any offsets are within that block just mirroring the MMU and process isolation. We should really be looking at why that isn't well used rather than just reimplementing a new version on top for \"security\", as if those reasons aren't really \"technical\" (IE poor isolation between \"Trusted\" and \"Untrusted\" data processing in separate processes due to it being \"Easier\") we need to ensure we don't just do the same things again, and if they are technical we can fix them. reply PittleyDunkin 13 hours agoparentprev> I still think that unless you need the performance, you should use a higher level language which hides this from you. Exporting and consuming the full c abi with very little effort is also another huge thing in rust's favor. Languages have opted heavily for supporting calling into the c abi and being hosted by the c abi, so naturally support for rust on the same terms comes for free. There's even rust in linux now. reply scott_w 11 hours agoparentprevAfter reading the article, it’s clear the author approves of the fact Rust has these rules (and prefers it over C++). They’re highlighting the natural challenges that brings so future iterations or competitors can see what needs to be improved. reply akira2501 18 hours agoparentprev> This is why I call C a minefield. Computing is a series of \"minefields.\" At least you get a map of this particular one. I'm far more confronted by public facing APIs that involve user authentication than I am of any particular documented set of language facts. reply chipdart 11 hours agoparentprev> I have memorised the UB rules for C. Why? What's wrong with using one of the many static code analysis tool to tell you about them if/when they appear? reply rcxdude 8 hours agorootparentThose tools can't reliably identify undefined behaviour. reply chipdart 7 hours agorootparent> Those tools can't reliably identify undefined behaviour. I'm sorry, can you explain what leads you to believe your hypothetical scenario is an argument rejecting the use of static code analysis tools? I mean, I'm stating the fact that there are many many tools out there that can pick up these problems. This is a known fact. You're saying that hypothetically perhaps they might not catch each and every single hypothetical case. So what? reply rcxdude 5 hours agorootparentThey're a good idea, but not a substitute for knowing the rules. And they don't just miss theoretical cases, they miss problems in practice even when used rigourously. reply chipdart 4 hours agorootparent> They're a good idea, but not a substitute for knowing the rules. It's a good thing no one made that claim, then. The whole point is that were seeing people in this thread making all sort of wild claims on how it's virtually impossible to catch these errors in C++ even though back in reality there are a myriad of static analysis and memory checker tools that do just that. Your average developer also knows how to type in a space character but still it's a good idea to onboard linters and automatic code formatters. reply rcxdude 18 minutes agorootparentIt's not impossible to catch those errors in C and C++. In fact, every time you run a new tool against a large C or C++ codebase you will find new ones. What none of these tools do is catch all the issues, as demonstrated by the fact that people keep finding new ones. reply eddd-ddde 3 hours agorootparentprevYou made the claim > Why? What's wrong with using one of the many static code analysis tool to tell you about them if/when they appear? You clearly pose static analysers as an alternative to understanding UB. You still need to understand how things work. reply bargainbot3k 16 hours agoparentprevEmbedded. Your UB is my opportunity. reply cyberax 14 hours agorootparentReally? So far it seems like most of the UBs in C are caused either by: 1. Masochism 2. Underspecification, in a vain attempt to make a language that can theoretically be used on PDP computers. reply amluto 13 hours agorootparentYou’re missing #3, which accounts for an absolutely enormous amount of loss: 3. The fact that an inappropriate write through a pointer results in behavior that is so undefined that it can lead to remote code execution and hence do literally anything. No amount of additional specification can fix #3, and masochism cannot explain it. One could mitigate #3 to some extent with techniques like control flow integrity or running in a strongly sandboxed environment. reply cyberax 11 hours agorootparentThere's nothing really you can do with out-of-bounds write in C except say that it can do \"anything\". This UB is unavoidable. I'm talking more about the nonsense like \"c++ + ++c\". There's no reason but masochism to keep it undefined. Just pick one unambiguous option and codify it. An example of #2 is stuff like signed overflow. There are only so many ways to handle it: wraparound, saturate, error out. So C should just document them and provide a way to detect which behavior is active (like it does with endianness). reply jcranmer 4 hours agorootparentIt's someone disingenuous to purposefully ignore what is the most common kind of UB in C. It's also ultimately not a very useful dichotomy, especially because it misunderstands why behavior ends up being undefined. For example: > I'm talking more about the nonsense like \"c++ + ++c\". There's no reason but masochism to keep it undefined. Just pick one unambiguous option and codify it. It's because there's an underlying variance in what the compilers (and the hardware [1]) translated for expressions like that, and codifying any option would have broken several of them, which was anathema in the days of ANSI C standardization. (It's still pretty frowned upon, but \"get one person to change behavior so that everybody gets a consistent standard\" is something the committees are more willing to countenance nowadays). > An example of #2 is stuff like signed overflow. There are only so many ways to handle it: wraparound, saturate, error out. Funnily enough, none of the ways you mention turn out to be the way it's actually implemented in the compiler nowadays. As for why UB actually exists, there are several reasons. Sometimes, it's essential because the underlying behavior is impossible to rationally specify (e.g., errant pointer dereferences, traps). Sometimes, it's because you have optimization hints where you don't want to constrain violation of those hints (e.g., restrict, noreturn). Sometimes, it's erroneous behavior that's hard to consistently diagnose (e.g., signed overflow). Sometimes, it's for explicit implementation-defined behavior, but for various reasons, the standard authors didn't think it could be implemented as unspecified or implementation-defined behavior. [1] Remember, this is the days of CISC, and not the x86 only-very-barely-not-RISC kind of CISC, the heady days of CISC where things like \"*p++ = --q\" is a single instruction. reply Dylan16807 12 hours agorootparentprevThat's not missing, I think they left it out of the \"most\" criticism on purpose. A dangling pointer is one of the few really good cases for UB. (Though good arguments can be made to give the compiler less leeway in that situation.) reply thaumasiotes 12 hours agorootparentprev> The fact that an inappropriate write through a pointer results in behavior that is so undefined that it can lead to remote code execution This is a strange way to look at it. You'd get remote code execution only if the result of writing through the pointer was exactly what you'd expect: that the value you tried to write was copied into the memory indexed by the pointer. reply blub 11 hours agoparentprevI think you’re missing the author’s point, but OTOH he undermined it himself by stating that learning the rules helps: because Rust requires that the ownership and relationships are encoded in the type system, it requires significant design changes when those relationships change. Learning the rules only partly mitigates this, because sometimes one does exploratory programming and isn’t sure what the final types are or they just want to change something. Rust thrives on over-specification which calcifies the APIs. Anyway, just as the author’s allegedly holding Rust wrong, one could say that you’re holding C++ wrong - the right approach is to learn how to write correct code and then the exceptions. Also accept and be at peace with the fact that your code will have some bugs. I don’t know why the average Rust developer is so obsessed with getting things perfect and no less with memory safety when the overall software quality is the way it is. I mean if someone’s researching the topic or works on Rust, sure, be the Stallman of memory correctness. reply Arch-TK 5 hours agorootparentI think unless your code is guaranteed to never interact with any untrusted input it is nowadays an increasingly unacceptable compromise to just accept that your program might have serious flaws which can lead to remote code execution or worse. Moreover, it becomes increasingly unpleasant and unworkable to deal with code which progressively gets more and more unreliable. It's expected that if the complexity of a program grows, the state space that the program can occupy grows with it. But with UB you can run into by accident that state space seems to grow exponentially in comparison to a language like Rust. If you are required to write code at that low level, I would not use anything other than something like rust. If you are not required to write code at that level. There are many languages with much less uncertainty than C++ which are much more productive than either C++ or rust. reply troad 17 hours agoprevI think it's telling that whenever someone raises concerns about any element of Rust, no matter how constructively, they're always met with a wall of \"you must not truly get the borrow checker,\" or \"you're using Rust wrong,\" or \"stop trying to writein Rust!\", usually with zero evidence that that is in fact what is happening. There's never anything to improve on Rust, it's always user error / a skill issue. If there ever surfaces any audio of Linus Torvalds and Ken Thompson discussing the pros and cons of the borrow checker, I expect a sea of patronising anime avatars to show up, seeking to explain Rust's invention of the concept of ownership to them. Rust is really nifty, but there are still (many) things that could be improved in Rust, and we'd all benefit from more competition in this space, including Rust! This is not a zero sum game. Honestly, I also think many people just want a nice ML-like with a good packaging story, and just put up with the borrow checker to get friendly C-like syntax for the Option monad, sum types with exhaustive matching, etc. This is a use case that could very much benefit from a competitor with a more conventional memory model. reply chipdart 11 hours agoparent> I think it's telling that whenever someone raises concerns about any element of Rust, no matter how constructively (...) I'm far from a Rust expert, but to me if someone is whining about how it is hard to track lifecycle rules of an object because they are passing it through long chains of function calls across all sorts of boundaries, what this tells me is that you're creating your own problems that you could avoid if you simply passed the object by value instead of by reference. I mean, if tracking life cycles is a problem then why not prevent it from being a problem? Not all code lives in the hot path. I'm sure your performance benchmarks can spare a copy somewhere. reply brabel 7 hours agorootparent> I mean, if tracking life cycles is a problem then why not prevent it from being a problem? So you're suggesting that people should just wrap everything in Arc or make copies everywhere to avoid lifetimes? At that point why not just use Java/OCaml/Swift/your-favourite-GC-lang? reply chipdart 4 hours agorootparent> So you're suggesting that people should just wrap everything in Arc (...) You're the only one who managed to come up with this nonsense. No one else did, and clearly you did not pick that from what I wrote because I definitely did no wrote that. Please refrain from slippery slope fallacies. reply dathinab 10 hours agoparentprev> zero evidence you mean except the original poster often implying exactly that in their articles or the personal experience of the commenter that nearly always whenever they ran into borrow checker problems it was due to exactly that reason > There's never anything to improve on Rust, it's always user error / a skill issue. RFCs get accepted and implemented nearly every week, like in any language there is always a lot to improve the problem is that the complains of such articles are often less about aspects where you can improve things but more about \"the borrow checker is bad\" on a level of detail which if you consider the borrow checker a fundamental component basically is \"rust is fundamentally bad\" reply ramon156 9 hours agorootparentYes, and that's why the comments usually are in some sense \"you don't use the BC right\", because they don't want a BC. And that's fine, but you can't blame Rust for this reply NoboruWataya 17 hours agoparentprevNo one thinks there's nothing to improve in Rust, there are lots of features it is missing, some of which are in nightly or on the roadmap. But the borrow checker and the concepts that underpin it are pretty fundamental to Rust and what separates it from other languages. If you like Rust except for the borrow checker, then I would think you don't really like Rust. reply troad 16 hours agorootparent> If you like Rust except for the borrow checker, then I would think you don't really like Rust. The sentence in my original post that this addresses is supportive of the emergence of an alternative language to Rust for people with this use case, so I think we're just agreeing. (Although I wouldn't go so far as to tell others what they do or do not like based on my own ideas of what is essential and what isn't.) reply kstrauser 17 hours agoparentprevI am A-OK with someone not liking Rust. I do, but it’s still only my 3rd-most used language behind the Python and TypeScript I write at work. It’s just that time after time I’ve heard people criticize Rust because they were, in fact, trying to write their pet language in Rust. It’s similar to how many complaints I’ve heard about Python because “it’s weakly typed”. What? Feel free not to like either of them, but make it for the right reasons, not because of a misunderstanding of how they work. Now, the author of this post may be doing everything right and Rust just isn’t good at the things they want to use it for. The complaint about constantly bumping against the borrow checker leads me to wonder. reply troad 16 hours agorootparent> It’s similar to how many complaints I’ve heard about Python because “it’s weakly typed”. What? Feel free not to like either of them, but make it for the right reasons, not because of a misunderstanding of how they work. Are you sure you're not just being harsh to people whose grasp of CS vocab is weaker than yours? If someone tells me that Python is 'weakly typed', I translate it in my head to 'dynamically typed', and the rest of their complaint generally makes sense to me, in that the speaker presumably prefers static typing. Which is a valid opinion to hold, not necessarily the result of any misunderstanding. reply kstrauser 16 hours agorootparentReasonably sure. If it’s clear they actually mean dynamically typed, fine. That’s down to preference, and I won’t say they’re wrong any more than I’ll argue that chocolate is better than strawberry. However, I’ve heard lots of utterly wrong criticisms of Python (and Rust and…) that were based on factual misunderstandings and not just a vocabulary mistake. reply ordu 11 hours agoparentprev> whenever someone raises concerns about any element of Rust, no matter how constructively, I don't think that it is a very constructive article. The author's critique of Rust raises questions like \"how to do it better\" but there are not answers. > they're always met with a wall of \"you must not truly get the borrow checker,\" Yeah, it is frustrating in this case particularly. The author openly states that he doesn't want to learn all the quirks of the borrow checker, and people respond to it with \"you just don't get the borrow checker\". I can see how this answer could be helpful, but if it was expanded constructively, if there was an explanation how it can become easy to deal with problems the author faces if you understood the borrow checker. OTOH I cannot see how such an argument can be constructed without a real example with the real code and the history of failed changes to it. I personally feel, that the borrow checker is simple, if you got it. And the author's struggles just go away, if you got it. You can easily predict what will happen if you try this or that changes to the code, and you know how to do something so the borrow checker will be happy. But I cannot elaborate and to make it clear how it works. reply __float 17 hours agoparentprevI can't help but feel this is a somewhat veiled complaint about the Rust community instead of anything substantive with the language :/ reply troad 17 hours agorootparentVeiled? :P I'd characterise it as a gentle criticism of the way the Rust community tends to react to anything other than effusive praise. Rust is a nifty language, albeit with room for improvement, that falls into the (sadly overpopulated) category of 'neat thing, somewhat obnoxious fan club'. reply akkad33 8 hours agorootparentThere are improvements to the borrow checker that is in the roadmap for Rust 2024. So it's not like the \"community\" is claiming there are no issues reply kstrauser 18 hours agoprevRust was a pain in the ass until I stopped trying to write C code in it and started writing idiomatic Rust. I don’t know the author of this blog, but he mentions extensive C++ experience which makes me wonder if he’s trying to write C++ in Rust. Maybe not! Maybe it’s truly just Rust being stubborn and difficult. However, it’s such an easy trap to fall into that I’ve gotta think it’s at least possible. reply Aurornis 17 hours agoparent> Rust was a pain in the ass until I stopped trying to write C code in it and started writing idiomatic Rust. This is the #1 problem I see with people trying to learn a new language (not just Rust). I’ve watched enough people try to adopt different languages at companies over the years that I now lean pessimistic by default about people adopting new languages. Many times it’s not that they can’t learn the new language, it’s that they really like doing things the way they learned in another language and they don’t want to give up those patterns. Some people like working in a certain language and there’s nothing wrong with that. The problems come when they try to learn a new language without giving up the old ways. Like you, I’m getting similar vibes from the article. The author wants to write Rust, but the entire premise of the article is about not wanting to learn the rules of Rust. reply pansa2 9 hours agorootparent> The problems come when they try to learn a new language without giving up the old ways In Python, I frequently see the same problem from the other side. Instead of C/C++ programmers learning Rust and \"not wanting to learn the rules of Rust\", it's Java/C# programmers learning Python and not wanting to unlearn the rules of Java/C#. They write three times as much code as they need to - introducing full class hierarchies where a few duck-typed functions would do. reply zanderwohl 14 hours agorootparentprev> This is the #1 problem I see with people trying to learn a new language (not just Rust). Definitely! I've also noticed people will learn a group of similar languages, like Java, C#/.Net, then Kotlin as the most distant relation. Now, they think they know many languages, but they mainly have the same core idea. So when they try something new like Haskell or Swift or Rust, they think it's doing something different from the \"norm\" in a really irritating way. reply donatj 11 hours agorootparentprevTrying to convince developers from \"classical\" OO that not everything needs to be a class in JavaScript has been a major thorn in my side for years. Your little procedure with no state? That can just be an exported function. reply nicce 18 hours agoparentprevI learned Rust before learning C properly. Oh boy. I see bugs everywhere in C and why the borrow checker exists. It really forces you to understand what happens under the hood. The most issues in Rust are indeed related the expressions - you don't know how to describe some scenario for compiler well-enough, in order to prove that this is actually possible - and then your program won't compile. In C, you talk more to the computer with the language syntax, whereas in Rust you talk to the compiler. reply marcosdumay 17 hours agorootparent> In C, you talk more to the computer with the language syntax, whereas in Rust you talk to the compiler. The C compiler pretends to be the computer. But UB is still there, as a compiler-only thing that has no representation at all on the computer. reply kanbankaren 17 hours agorootparentprev> Oh boy. I see bugs everywhere in C and why the borrow checker exists. Any examples that you could provide? I have been dealing with C/C++ for close to 30 years. Number of times I have shot myself with undefined/unspecified behavior is less than 5. reply tsimionescu 12 hours agorootparentIn 30+ years of experience in C, you haven't used a free()d variable or written past the end of a buffer more than 5 times? If that's true, then you have more care and attention than 99.99% of all C experts. reply kanbankaren 3 hours agorootparentI should have been clear. Of course, I have done such mistakes, but they were caught early in the dev. process. I am talking about bugs that were caught in production due to misunderstanding of C compilers on 16/32 bit processors. I also avoid idioms like *p instead write p[i] whereever possible. reply jjnoakes 12 hours agorootparentprevThe number of times you shot yourself in the foot that you know about. Some of those bullets just haven't landed yet. C and C++ give you very interesting foot-guns: sometimes they go off even when you don't touch them (compiler upgrade, dependencies changing, building on a new architecture, ...) reply dafelst 14 hours agorootparentprevThe borrow checker isn't just about UB, it is mostly about memory safety. I'm sure you've seen plenty of use-after-frees/use-after-move/dangling pointer type things or null pointer derefs, or data races, etc etc. These are largely impossible to do in safe rust. reply oneshtein 12 hours agorootparentprevBorrow checker checks memory safety. Undefined/unspecified behavior still present in Rust[1]. [1]: https://doc.rust-lang.org/reference/behavior-considered-unde... reply bombela 11 hours agorootparentOnly from code annotated unsafe. In other words, if you do not use the keyword unsafe, you have no undefined behaviors. reply eddd-ddde 3 hours agorootparentprevClearly you must be superhuman then, something as simple as forgetting a null pointer check is bound to hit you every now and then. reply kanbankaren 3 hours agorootparentOf course, I do, but they are caught early in the dev. process. Not in production though. reply kstrauser 2 hours agorootparentI would contend that’s an unusually sophisticated dev process not used by most. reply dbtc 12 hours agorootparentprev> In C, you talk more to the computer with the language syntax, whereas in Rust you talk to the compiler. C is like a fast motorcycle, rust is a car with driver-assistance system. reply maguirre 18 hours agoparentprevAre there examples one can learn from about idiomatic rust? I would appreciate either books or projects to learn from. reply zeta0134 18 hours agorootparentGenerally I have the easiest time when I declare my state in the outermost scope possible, and then pass it into functions that need to operate on it. If I'm using an actual pointer, rather than a mutable reference that came in as an argument, something weird is happening! Usually that's the interface with some external library. Rust in particular is *really* obnoxiously bad at OOP patterns, and I think my lesson at this point is that this is because it is hard to do OOP safely, at least in a way that jives with its borrow checker. Something like functional core, imperative shell seems to be a much nicer flow for the thing in general. Anyway, I've just got the one major Rust project (an NES emulator) so I'd say I'm pretty early in my Rust journey. For me personally, the good points (delightful match, powerful enum) outweigh the bad (occasional borrow checker weirdness, frustrating lifetimes) but I think it depends a lot on what you're trying to do with it. reply ijustlovemath 17 hours agorootparentYou can achieve some level of OO design by using traits (the generic kind, not the dyn kind), but I think the functional style and inline testing gives you a ton of nice properties for free! Rust also pushes you to refactor in a way that really pulls out the core of your problem; the refactoring is just you understanding the problem at a deeper level (in my experience) reply galangalalgol 18 hours agorootparentprevRust, like ocaml, is best when used purely functionally until you run into something that isn't performant unless its imperative. But unlike ocaml or haskell there is a safe imperative middle ground before going all the way to unsafe. People who write modern C++ with value semantics etc. seem to have a lot less trouble than people coming from Java. reply IshKebab 2 hours agorootparentMost Rust code is not purely functional in my experience. It's quite similar in style to C++ except: 1. No class hierarchies and inheritance. 2. The borrow checker forces a tree structured ownership style. You don't get spaghetti ownership. This is generally great because that coding style leads to fewer bugs. But sometimes it is annoying and you have to use indices rather than pointers as references. reply nh2 18 hours agorootparentprevIt's difficult to really use Rust purely functionally given that it removed pure functions from its type system, and that has a limited stack size. reply lowbloodsugar 18 hours agorootparentprevI mean, I don’t write it that way, but if it works for you. I wouldn’t say you have to write it that way so I wouldn’t want to put anyone off. Thinking about your answer a bit more, one of the paradigms of Rust is “there shall be many immutable references or just one mutable reference” and so I can see that functional programming would naturally lead to that. But it’s a paradigm that works with the underlying principles rather than the true nature of the language, IMHO. I do it by thinking about different domains of object graphs, and how data moves between them, for example. reply kstrauser 18 hours agorootparentprevhttps://doc.rust-lang.org/book/ is great. I’d been writing Rust for months before I started reading it and still began learning new things from the start. Oh, that’s why it does this! Edit: Oh! And use “cargo clippy” regularly. It makes excellent recommendations for how to make your code more idiomatic, with links to docs explaining why it’s nicer that way. reply melvyn2 18 hours agoprevThe borrow checker exists to force you to learn, rather than to let you skip learning. To make an analogy, I think it would be weird if I complained that I had to \"memorize the rules\" of the type checker rather than learning how to use types as intended. reply Pannoniae 17 hours agoparentFair enough, but the problem in this analogy is that this learning isn't always useful or productive in any way. This is more like doing arithmetic in a sort of maths notation where every result must be in base 12 and everything else must be in base 16. Sure, you can memorise the rules and the conversions but you aren't doing much useful with your life at that point. Obviously, the borrow checker has uses in preventing a certain class of bugs, but it also destroys development velocity. Sometimes it's a good tradeoff (safety-critical systems, embedded, backends, etc.) and sometimes it's a square peg in a round hole (startups and gamedev where fast iteration is essential) reply kstrauser 17 hours agorootparentI think it destroys productivity if and only if you don’t roll with it and do things the Rusty way. If you write code with its idioms, it can be a huge productivity boost. Specifically, I can concentrate on fixing logic errors in my code instead of resource bookkeeping. When I refactor something, I know I didn’t accidentally forget to move alloc/free to the appropriate places for the new code: if my changes broke something, it’ll tell me. reply Aurornis 17 hours agorootparentprevRust shouldn’t “destroy development velocity” once you’ve grasped the core concepts. There is some overhead to being explicit about how things are shared and kept, but that overhead diminishes with time as you internalize the rules. reply tsimionescu 12 hours agorootparentNot if you're iterating and have to make fundamental changes. Just like certain advanced type systems, encoding too much at compile time means you have to change a lot of code in unnecessary mechanical ways when the design constraints change, or when you discover them. This is not a bad thing by the way, it's an extremely plausible design chocie, and is one that Rust made very clearly: rejecting not-entirely-correct programs is more important than running the parts that do work. Languages that want to optimize for prototyping will make the opposite choice, and that's fine too. reply chombier 11 hours agoparentprevBesides, if you still want to skip learning there are escape hatches like Rc but these hint pretty strongly (e.g. clones everywhere) that something might be wrong somewhere. reply Spivak 17 hours agoparentprevIf the borrow checker only errd on code with bugs you could call it learning. Or if it was only possible to express correct programs in the Rust language. But such a thing isn't possible in general so we accept the weaker condition, accepting a subset of all valid code that can be proven correct. The usability of the language goes with how big that subset is, and the OP is expressing frustration at the size of Rust's. Rust isn't alone in this, languages with type hints are currently going through the same thing where the type-checker can't express certain types of valid programs and have to be expanded. reply Animats 12 hours agoprevRust's reference topology is too restrictive. You can't have back references. This is what drives many C++ programmers nuts. It's common in C++ to have A point to B, and for B to have a pointer back to A. This happens implicitly with class inheritance, too. As a result, common C++ idioms don't translate to Rust at all. This is fixable. Because you can have back references. You just have to use Rc, Rc::Weak, .upgrade(), RefCell, .borrow, and .borrow_mut(). This works, but only if the upgrades and borrows never fail. A failed .borrow() is a panic. The implication is that if you use .borrow() or .borrow_mut(), there's some good reason to think it will never fail. For Rc::Weak, the key constraint is that all weak pointers must drop before all strong pointers have dropped. If you can prove that, .upgrade() doesn't need a run-time check. For RefCell, the key constraint is that no .borrow() or .borrow_mut() may be enclosed by the scope of a conflicting .borrow() or .borrow_mut(). This requires a transitive closure check on who borrows what. For many simple cases, this is statically checkable. It does require inter-function checking. Can those checks be moved to compile time? Probably. There's already a compile-time static Rc.[1] Compile-time RefCell checking looks possible.[2] It's non-trivial to do this, but worth thinking about. DARPA's TRACTOR project (Translating All C To Rust) is likely to generate vast amounts of Rc-heavy code, if it works. So that provides some motivation for doing something to check at compile time. [1] https://github.com/matthieu-m/static-rc [2] https://internals.rust-lang.org/t/zero-cost-interior-mutabil... [3] https://www.darpa.mil/program/translating-all-c-to-rust reply oconnor663 2 hours agoparentI don't love Rc as a cure for borrow checker woes. When Rust programs need cyclic, graph-y things like back references, I almost always suggest moving to indexes: https://jacko.io/object_soup.html. You can get fancy and reach for a SlotMap or a whole ECS, but a lot of simple cases can get away with just Vec. (And even complex cases can use HashMap if performance isn't critical.) reply Animats 4 minutes agorootparent> moving to indexes Then you can have dangling pointers that point to the wrong place. Race conditions become possible. You need an allocator for the indices. I've had problems with a renderer that works that way. On rare occasions, it crashes with an invalid index. Even with Rust safe code. reply sfink 12 hours agoprevI'm a relative beginner at Rust, but this matches my experience fairly well. Especially the part about the brittleness, where adding just one little thing can require propagating changes throughout a project. It might be adding lifetimes, or switching between values and references, or wrapping things in Rc or Arc or RefCell or Box or something. It seems hard to do Rust in a fully bottom-up fashion; you'll end up having to adjusting all the pieces repeatedly as you fit them together. Maybe there's a style I haven't learned yet where you start out with Arc everywhere, or Rc, or Arc>, or whatever, and get everything working first then strip out as many wrappers as possible? It just feels wrong to go around hiding everything that's going on from the borrow checker and moving the errors to runtime. But maybe that's what you need to do to prototype things in Rust without a lot of pain? I don't know enough to know. I have already noticed that building up the mindset of figuring out your ownership story, where your values are being moved to all the time, is addictive and contagious -- I'm sneaking more and more Rusty ways of doing things into my C++ code, and so far it feels beneficial. reply oconnor663 2 hours agoparent> It just feels wrong to go around hiding everything that's going on from the borrow checker and moving the errors to runtime. But maybe that's what you need to do to prototype things in Rust without a lot of pain? There's some truth to that, but I think the real problem is when some part of the state of your program looks like a graph with loops and cycles (not a tree). It's possible that it only looks that way during prototyping, but I think it's more likely that once it starts looking that way, it's gonna stay that way. In that case, \"hiding\" your lifetimes from the borrow checker is really about making your borrows shorter, which is how you can manage a graph without violating the no-mutable-aliasing rule. https://jacko.io/object_soup.html reply eddd-ddde 3 hours agoparentprev> Maybe there's a style I haven't learned yet where you start out with Arc everywhere, or Rc, or Arc>, or whatever, and get everything working first then strip out as many wrappers as possible? I wouldn't recommend that. It's easy to end up with a fundamentally flawed architecture impossible to refactor out of. In general as long as you stick to keeping data ownership as high up in the call stack as possible everything should slowly fall into place. Think functional core imperative shell. Your main has services, dependencies, data, and just makes calls that operate on data without trying to make deeper owned objects that are inherently hard to keep references to. reply kstrauser 2 hours agorootparentAgreed. IMO, anywhere you butt heads with the borrow checker is a place where you’d have to by hyper nitpicky about user after free or memory leaks in C or C++, just without the compiler shouting at you to fix it. reply IshKebab 2 hours agoparentprevI don't think this is really unique to Rust. Any language that requires you to write stuff down about interfaces might require you to change them in a lot of places if you get it wrong. E.g. if you get the type of a parameter that is passed everywhere wrong. I guess the hard bit here is it's more difficult to make a mental model of the borrow checker than it is most other features, and also the fact that borrow checking is a late phase of the compiler so you might put in a fair amount of work before getting feedback. reply sfink 1 hour agorootparent> I don't think this is really unique to Rust. Any language that requires you to write stuff down about interfaces might require you to change them in a lot of places if you get it wrong. E.g. if you get the type of a parameter that is passed everywhere wrong. My experience doesn't match this. I think the difference is that Rust has... \"specific types\", to pick an arbitrary term. The types store more information, which means that there are many more ways that you might need to update an interface. An interface with a function that takes a C++ pointer doesn't imply anything other than that the pointer is valid at the beginning of the calthe return value of l to that function. It doesn't even tell you whether it can be nullptr or not. It might be a pointer extracted from a `std::unique_ptr`, in which case the actual expectation is that the pointer be valid when the function returns. Or it might be passed the return value of `new`, in which case the expectation is that the pointer be either valid but now owned by something else, or invalid when the function returns. And you might change from one expectation to the other merely by removing a `delete` call 7 levels deep, without needing to adjust any of the intervening layers. Rust, on the other hand, encodes a specific subset of the possible lifetimes that the C++ version accepts, and every intervening layer has to agree on that lifetime or at least the structure of it. And it's not just lifetimes. In Rust, you'd typically make everything a specific type -- maybe an enum or Option or whatever. In C++, I often find myself intentionally degenerating even (C++) enums to ints when I need to store or output or manipulate them -- I want to test `valThis means, to be a highly productive Rust programmer, you basically have to memorize the borrow checker rules, so you get it right the first time. This is stupid, because the whole point of having a type system or a borrow checker is to tell you when you get it wrong, so you don’t have to memorize how the borrow rules work. This is completely back to front. Of course you have to internalise the rules of a borrow checker or type system to be highly productive. How can you hope to do a good job without that? reply chombier 11 hours agoparent> Of course you have to internalise the rules of a borrow checker This is generally a good thing: the more you internalise the logic of borrow checking, the earlier you start thinking about \"who owns what\" instead of deferring the choice to later, which often ends up in a tangled mess of \"incidental data structures\" as it is sometimes called in the c++ world [1]. Of course in c++ this means you have to internalise this discipline the hard way, i.e. without the borrow checker helping you. [1] https://isocpp.org/blog/2016/05/cppcon-2015-better-code-data... reply eviks 14 hours agoparentprevYou can do a good job by offloading that cognitive overhead to better tooling reply bombela 11 hours agorootparentWhat if Rust itself is the better tooling? reply audunw 7 hours agorootparentIs it just me or is everyone in this comment talking past each other, with half of them not really understanding what the article is complaining about? My take-away was that the article concludes that Rust is NOT a good tool for working with the borrow checker. I don’t think it said that there’s anything wrong with a borrow checker, and that you shouldn’t learn the basics of how it works or how to write idiomatic Rust. A good tool shouldn’t require you to have a perfect memory of all the rules for you to be highly productive with it. If you make mistakes it should quickly tell you so with a message that quickly lets you figure out what to change. I think this stands in contrast with Zig where these goals is the highest priority of the language. It’s also very strict with little to no undefined behaviour. But there’s also a lot of discipline in not introducing syntax or semantics that makes it hard for the compiler/checker to give a quick pass/fail with a clear message about went wrong. You can see from the issues in GitHub that improving error messages for failures in the type system is consistently prioritised. That puts a hard constraint on Zig where they’re held back from putting too much power into the type system. That’s not to say that Rust doesn’t prioritise being a good tool. But the semantics of borrow checking makes their job an order of magnitude more difficult here. It’s an inherent trade-off. They’ve made a huge jump in the complexity and power of the language, and it’s probably much harder to then make a tool that makes it comfortable to work with this kind of power. Some here may find it easy to deeply understand all the rules and to write code the first time that doesn’t trip up Rust too much. But in the real world code is written by many different kinds of people with different kinds and levels of intelligence. I’ve found this to be an important consideration when choosing languages, libraries, tools and methodologies for large teams. One way to be a 10x programmer is to write 10x as much code as an average programmer. Another way is to make 10 other average programmers twice as efficient, and that’s clearly more scalable. Rust may still be a good choice to make the team more productive in the long run. My point is that adopting it in a team should perhaps not be considered a trivial decision. reply bombela 2 hours agorootparentMy short comment was a bit tongue in cheek. > A good tool shouldn’t require you to have a perfect memory of all the rules for you to be highly productive with it. If you make mistakes it should quickly tell you so with a message that quickly lets you figure out what to change. That's exactly what the Rust borrow checker does for me. The borrow checker rules are quite simple conceptually. If I own a book, I can read it, write in the margins or even destroy it. `let book: Book = Book{...}`. I can lend this book to you exclusively `&mut Book`, you can read and write it, but not destroy it. And nobody else; including me; can even read it until you are done. I can lend this book to you and others for reading `&Book`. We can all read it concurrently. And I must wait for everybody to be done before I can regain full ownership. I can give you the book (passing by value). And it's now yours to do what you please. Including destroying it `drop(Book)`. Sometimes you do want to share to many; and maybe even gate exclusive write access; at runtime. This is where Rc, Arc, Cell, RefCell and Mutex come in. Rc and Arc destroy the book when a reference counter drops to zero. Another way to look at it, is that when the counter is 1, you have sole ownership of the book. And you can do with it what you please. As for the runtime check for mutability, Mutex should be obvious. Cell and RefCell are similar but within a single threaded context. And finally when you know better than the compiler, you use pointers (instead of references) and triple check your work within `unsafe` blocks. reply rokob 18 hours agoprevI agree with this. However memorizing the borrow checker rules has led me to architect code “more correctly” upfront and consider things like ownership that I was otherwise pretty lax about ahead of time before. I think this has made me more thoughtful even in other languages which I think has been a win for me. That said, the tedious refactors are a real pain. I think we all hoped that rustc would be smarter by now. It has gotten better but it isn’t there yet. reply kstrauser 18 hours agoparentSame for me. I think I write better code in other languages now. reply chipdart 11 hours agoprevFrom the article: > This is painful because I am an experienced C++ programmer, and C++ has this exact problem except worse: undefined behavior. In the worst case, C++ simply doesn’t check anything, compiles your code wrong, and then does inexplicable and impossible things at runtime for no discernable reason (or it just deletes your entire function). This is completely wrong, even in the \"not even wrong\" territory. It reads like an attempt to parrot a cliche without having any idea what it means. \"Undefined behavior\" just means the standard does not define what is the expected behavior, and purposely leaves implementations free to implement it how they see fit. This means crashing the app or sending an email to the pope. In practical terms this means developers should not write code that triggers undefined behavior, and treat the code that does as errors requiring a fix. Advanced users can lean on implementation-defined behavior from compilers to add some expectation to the behavior, but that's discouraged. It's so strange how someone calling themselves a seasoned C++ developer fails to understand such a basic aspect of the language. The important tidbit is that a) it's completely wrong to parrot \"undefined behavior\" on \"C++ doesn't check anything\", and b) if you code triggers undefined behavior without your knowledge then you just broke the code and wrote a bug out of your own ignorance. To make matters worse, there are a myriad of code checkers for C++ that catch undefined behavior and even some classes of safety errors. Take for instance cppcheck. Why is the blogger whining about undefined behavior and \"c++ not checking\" when adding cppcheck to any project is enough to detect most if not all cases? reply throw_a_grenade 11 hours agoparentThe quote is incomplete without its continuation: > This means that in order to write C++, you effectively have to memorize the undefined behavior rules, which sucks. Sound familiar? Which is the point TFA is making. I believe you expended the attention span a bit too early. reply chipdart 10 hours agorootparent> Which is the point TFA is making. Again, the point is wrong in more than one way. You don't simply add undefined behavior. It's wrong, and buggy code. Onboard a static code analysis tool like cppcheck to tell you when you messed up. It takes far less work to onboard any of these tools than it takes to write a sentence in a blog post. reply throw_a_grenade 10 hours agorootparentTFA argues developers add it left and right, unless someone memorised all the rules. Since reportedly it's not possible to memorise all the rules by a single human, then you either \"simply add undefined behaviour\", or limit yourself to a subset of C++ that programmers do actually understand. Which is a solution I see in many codebases: to limit a set of permissible constructs by a style manual. reply ufmace 18 hours agoprevI don't really agree with this. I'd phrase it more as, you have to learn to really understand what the borrow checker is trying to do and how it makes you architect your programs and consider that ahead of time. Once you understand that, you'll rarely have problems with the borrow checker. It does preclude significant chunks of styles and data structures often used in other languages though. reply Const-me 17 hours agoparent> it makes you architect your programs and consider that ahead of time This only works for projects which do not involve any R&D, but have a complete and well written functional specification written in advance. Also for projects which do a complete re-implementation of some pre-existing software. For greenfield projects which require substantial amount of R&D, it’s impossible to architect programs ahead of time. At the start of the development, people only have a wishlist. Architecture comes later, after several prototypes implemented and evaluated, and people have some general understanding what does and doesn’t work, and what specifically needs to be done. Rust implies that upfront architecture costs even for prototypes. reply ufmace 2 hours agorootparentI don't really agree with that interpretation. In my opinion and experience, it does not restrict architectural choices to the extent that it makes it difficult to develop greenfield projects. It's more that it rules out a relatively small subset of architectural choices which are arguably a bad idea anyways, as they do infact have flaws that may not be obvious at first but will lead to a lot of pain if the project grows above a certain size. reply Olumde 16 hours agorootparentprevAgreed. This is probably the reason why rewriting in Rust \"works\" -- because the architecture has been previously worked out. reply FridgeSeal 17 hours agoprevCan't say I agree, or that this matches my experience of writing Rust. I don't memorise how it works, I've just learnt what it rejects and why, and this in turn becomes clear as to why it's rejected that. Very rarely do I find myself going \"oh bother, now I suddenly need to `Rc` or `Arc` this, I suspect because I've just gotten into the habit of suspecting when I anticipate things will run afoul and structuring things from the get-go to avoid that. Admittedly, I'm not writing absurdly low-level code. I wonder if the authors grounding C++ is making life harder for them? Often when I've had to teach people Rust, getting them to stop writing {C/C#/Java}-but-in-Rust is the first stop on the trail to \"stop fighting and actually enjoy the language\". Every language has its idioms, just because you can, doesn't mean you should. reply s17n 16 hours agoparentIf you aren't writing low level code, why not use a GC language? reply FridgeSeal 10 hours agorootparentGreat type system, great performance, great packages, great tooling, nice high-level API’s that produce low overhead code, I’m most familiar in Rust now. I’ve had more than enough unpleasant experiences with write-runs-breaks-at-runtime style languages. I don’t like writing them, I hate having to support them in prod as they give me constant-persistent-stress. I hate what idiomatic C# is, and how much ceremony there is to read and write it. Java is worse. Go’s type system is too anaemic for my tastes. Haskell is nice, but gets a bit academic and lacks some day-to-day niceties. Kotlin is supposed to be nice, but again, we’re getting maybe 50% of Rust type system features, and you’re basically just piggybacking on Java/JVM which I hated dealing with previously. IDK what else that leaves in the mainstream. I used to play around with Nim, and that was quite nice though. reply neonsunset 10 hours agorootparentF# :) Expression-oriented, HM type inference with gradual typing, faster than other FP languages, can even reach for low-level bits, or write extra glue code in C# which is more pleasant at low-level imperative code. Not sure what exactly you refer to as idiomatic C#. If it has too much ceremony chances are it’s anything but! reply FridgeSeal 7 hours agorootparentYeah I’ve used F# before! It was pretty good, some solid features and nice experience. It just falls into a bit of weird place IMO? You have to rely on writing/using C# to fill any holes, and I really dislike that language/ecosystem, and why split between 2 lands when I can just get the same HM type system, similar-enough principles, better perf and no MS taint. Edit: I do love the ML style syntax though, Haskell, F#, Dhall are awesome, I wish it were more readily accepted. reply neonsunset 3 hours agorootparentThe hatred of .NET (and C#) is unfortunate, irrational and unwarranted. I ended up unfortunately resorting to just thinking less of engineers that have it, because they can’t update their priors (“it was slightly inconvenient 8 years ago so it must be bad today surely”) and distinguish between Microsoft’s other products and policies and .NET itself. reply kstrauser 2 hours agorootparentI believe that’s shortsighted. I’ve been adjacent to any number of Microsoft rugpulls over the years (Visual FoxPro.NET any day now, promise!). Their are enough non-MS languages that C#’s never tempted me. I don’t think it’s a bad language and don’t think poorly of you for using it, but I feel much better about the long-term prospects of Rust and wouldn’t likely build a new business on C# today. reply neonsunset 56 minutes agorootparentIt's not. It is shortsighted to blindingly hate thing X over Y instead of considering circumstances and understanding how big corporations work, or understanding the nature of the project you make use of (after all, the entirety of .NET is MIT) and just how much worse most alternatives are. There is a wealth of mainstream languages that are decently usable, which I wouldn't touch with a ten-foot pole as a main choice still because they carry a significant downgrade in one or another area, that .NET does not compromise on. reply skp1995 17 hours agoparentprevI do have to ask, I have worked in codebases which used lifetimes and didn't lean into Rc/Arc and vice-versa. I used to think Arc/Rc was a shortcut to avoiding the borrow checker shenanigans, but have evolved that thinking over time. You do mention it in your comment so wondering if you have anything to share about it reply mjevans 18 hours agoprevThis makes me further appreciate how golang's features tend to work entirely at compile time, which is also fast. One of the other things that makes me worry about Rust is how similar it's depends look to npm projects, where there's a kitchen sink of third party (not the language's included library of code, and not the project's code) libraries pulled in for seemingly small utilities. reply hypeatei 18 hours agoparentDependencies are optional, and having a huge standard library also has its tradeoffs. If the standard library has a less than ideal API, it's stuck with that until a major version bump and you either: 1. End up with a third party package filling in the gaps, or 2. Another standard library API that users slowly migrate to reply saghm 18 hours agorootparentIt's also a lot easier to release a new version of a package to fix a bug than do a bugfix release for the entire language toolchain, which is what would be needed in order to update the standard library. With Rust releasing a new minor version every six weeks, I think minimizing the chances of additional releases needed in between them is probably a good thing. reply tsimionescu 12 hours agorootparentprevUnfortunately, in a world with increasingly more sophisticated attackers looking at supply chain attacks, having a lot of dependencies, especially ones that update regularly, is a huge security risk. For a language like Rust, which aims to be both low level and used in secure environments, I would argue that the risks far outweigh the benefits. We'll see how this works, Rust is still young and not yet used in any hugely important projects (or at least not in hugely important parts of those projects - e.g. some Linux drivers, not the core kernel; some bits of Firefox'S rendering, not the JS engine). As it becomes more central, it's value as an attack target will increase, and people will start taking infiltrating malicious code in small but widely used dependencies. reply hypeatei 6 minutes agorootparentThe same could be said for all of the utilities used on Linux (that they're increasingly becoming huge targets) as seen by the recent XZ backdoor[0]. The open source model of limited funding and maintainer burnout are an inherent risk to any project. Rust is not special here. 0: https://en.wikipedia.org/wiki/XZ_Utils_backdoor reply maxbond 18 hours agoparentprevI think it's the natural state of affairs for a \"folk standard library\" to emerge. I don't think pydantic or serde should be part of their standard libraries. But I will use them in most projects. In ten years, the \"folk stdlib\" will probably be a different set of packages (perhaps a superset, perhaps not). Don't push the river; if it's natural, manage it rather than fighting it. Trying to anticipate all or even most use cases in the standard library is a fool's errand (unless we're talking about a DSL, of course). There are too many and they are too dynamic to be captured in the necessarily conservative release process of a language implementation. Languages should focus on being powerful and flexible enough to be adapted to a wide variety of use cases, and let the community of package maintainers handle the implementation. Think of this as a special case of the Unix philosophy; languages should do one thing very well, not a million things unevenly. I bet most people here don't believe a command economy could ever work in a market for goods and services. Why should it work in a marketplace of ideas? reply riwsky 14 hours agorootparentAnd new cars tailored for each consumer’s use case will emerge in ten years, too—that doesn’t make it any less awful to live in areas that lack good public transportation. reply maxbond 14 hours agorootparentI'm not sure I understand the metaphor? Let me know if I'm off base. If the suggestion is that putting things in the standard library makes them better, I disagree. My experience with Python for instance is that a \"batteries included\" strategy results in some phenomenal packages and some borderline abandoned packages that are actively dangerous to use. To riff on your metaphor, the federal government designs the arterial highways, but the state, country, and city/town officials design the minutia of the traffic system. If the federal government had to approve spending on replacing some street signs or plowing snow, we would have a terribly impoverished transportation system. reply kstrauser 18 hours agoparentprevRust’s checks are also evaluated and enforced at compile time. reply danpalmer 18 hours agoparentprevGo’s features work only at compile time, but are far more limited. I experience more crashes in Go than in any other compiled language because of how limited it is as a language. reply wduquette 3 hours agoprevThis tallies with my experience with Rust. Four years ago I wrote an implementation of the TCL language in Rust (see https://github.com/wduquette/molt). It uses no unsafe code, and includes enough of the language to be useful. But it isn’t terribly efficient, and it’s a bit of a memory hog, and so I started looking at ways to improve it. I usually like to evolve a code base towards a new architecture a little at a time, keeping it running and passing tests at every step of the way. What I found was that even seemingly small changes required an awful lot of work, as the OP says; if I could make them work at all. Eventually I decided that I’d learned what I’d needed to, and walked away from it. (To be fair, this was late spring or early summer of 2020, everything was peculiar, and I didn’t have the spare mental capacity for the project.) I should add: I understand the need to use a language the way it wants to be used, and that you need to assimilate and internalize that to be truly fluent. I concluded that I didn’t need Rust’s extreme performance for the kind of work I do, and that there are less intrusive ways of getting memory safety. reply jchw 18 hours agoprev> Rust is not the answer, it is simply a step towards the answer. True that. On one hand, it's amazing. On the other hand, the nagging feeling that we still have work to go in programming language design has not gone away. reply tialaramex 17 hours agoparentTwo examples of things I want, built-in on day one, in some future language: Structured concurrency. Don't provide \"legacy\" mechanisms and \"opt in\" for structure, just bite the bullet. Like the first language which told people no, we don't \"go-to\" other functions, that's not happening in my language, that was structured program flow I want structured concurrency, it's a thing but it's not yet popular enough to do that as the only provided concurrency, it should be. Smart arithmetic. Your computer has Floating Point math. FP math is fast, but, it's hard for humans to think about exactly where they lose precision and performance while using it. I should be able to write the real mathematics I want, specify the precision I need and possibly the performance trades I'm comfortable with, and the compiler not me the programmer, figures out how to use FP math to calculate my mathematics with acceptable precision or tells me that I made demands it couldn't meet or which are nonsensical. On the other hand, two things I really liked to see when I learned Rust: &[T]: The slice reference type, a fat pointer which specifies where zero or more contiguous Ts are, and, how many of them. This is the Right Thing™ and it's right there in the core language design, which means you don't need to go back and retro-fit it. String: The simplest possible way to build the growable text type, as a growable array of bytes but with the strict requirement that the array's content is always UTF-8 text. Is the \"Small String Optimization\" a cool trick? Yeah, but it need not live in this core vocabulary type. How about Copy-on-write ? Ditto. What about other text encodings? Transcode at the edges if you need that. reply ilaksh 14 hours agoparentprevI sincerely believe that it is nearly impossible to have an objective and constructive conversation about the merits of programming languages, because the language of choice becomes part of people's worldview. So it's like discussing politics or religion. People think that they have objective views, but they can't overcome their beliefs. That's just how beliefs work. They almost never change. Also, beliefs are tied to groups. Humans automatically adopt the beliefs of their group, at least to some degree. Or they learn to shut up about their disagreements. This is a thread for Rust critics and Rust advocates. Try to seriously sell F# or some other ML-like language in here and you are going to end up annoying both the C++ people and the Rust people. The world will be a better place when the AIs finally take over. If we survive. reply jchw 13 hours agorootparentIn my opinion, it seems like you may be taking random internet discussions a bit too seriously; I don't actually expect too much meaningful programming language discourse to occur in Hacker News comments. I think the reason why I keep coming here is in part because it's one of the rare public forums where occasionally some truly interesting discussions really do happen, but don't forget Sturgeon's Law. For better or worse, public and open forums are rarely productive places to have discussions, and a lot of the real innovations certainly seem to happen behind closed doors. (Personally I greatly prefer public forums for discussion, and even would prefer anonymity if it were feasible, but I take what I can get.) What does that say about participating here? Well, for me, sometimes when I write a comment that I feel is constructive, reasonable, and honest, it goes gray anyways, and it's easy to chalk it up to people just irrationally downvoting it because they don't like my opinion. It's also pretty easy to do this, I just need to be cynical about Apple or optimistic about the Go programming language, or something similar, and there's some percentage chance it will go negative depending on presumably who sees it first. It's not going to stop me from doing so, and ultimately it's pretty inconsequential, as I'm just some guy and my opinions are not really that important anyways. Somehow, even though I have all of this internalized, I can't help but go 30 nested replies deep into threads debating about something senseless and unimportant, but it almost feels like it wouldn't be the Internet without debates like that. XKCD 386. reply maxbond 17 hours agoparentprevThere is no answer. There are only improvements. reply bitbasher 16 hours agoprevI am currently learning Rust and found the post interesting. As I learn the language, I keep reading how Rust is great and you don't have to manage memory (unlike C or C++). However, managing ownership and lifetime _is_ managing memory. The borrow checker is there, all the time, reminding you of memory management. Now, in C and C++ the same problem exists but you don't have a borrow checker to remind you. I think this is the same conclusion the blog post came to, but I'm not entirely sure. reply dinobones 18 hours agoprevI've written a ton of software, both backend and embedded-like software in C++. What are people writing that requires such fancy/extensive usage of the borrow checker? I can't even remember the last time I had to use a shared_ptr... unique_ptr and other general RAII practices have been more than enough for our codebase. reply Const-me 3 hours agoparent> I've written a ton of software, both backend and embedded-like software in C++ Me too. > What are people writing that requires such fancy/extensive usage of the borrow checker? The simplest example I can imagine is this: https://en.wikipedia.org/wiki/Matrix_multiplication When your matrices are large and you want it to run fast, you want to parallelize. Good algorithms (which don’t bottleneck on memory bandwidth) need multiple CPU cores to concurrently store different elements of the same output matrix. Moreover, the elements computed by different cores are not continuous slices, they are rectangular blocks. Such algorithm is not representable in safe rust. reply loeg 17 hours agoparentprevI think OP is likely overusing references. The vast majority of code doesn't need to deal with explicit lifetimes. reply andybak 17 hours agorootparentOP sounds fairly smart and my first thought is \"if OP is struggling then Rust probably isn't for me\". Who is Rust for? reply loeg 13 hours agorootparentI don't think it's useful to think there is some single spectrum of intelligence that makes one more or less suited to using Rust. Rust is for anyone who finds it useful. reply kstrauser 17 hours agorootparentprevIn some ways, people who aren’t heavily invested in other languages to the point that they think in them. Neophytes know less, but they also have fewer things to unlearn. reply skp1995 18 hours agoprevRust can be hard to get right because of the borrow checker. I had a similar situation happen to me where I went about refactoring the code to make borrow checker happy ... until the last bit when things stopped compiling and I realized my approach was completely wrong (in the rust world, I had a self-reference in the structs) Having said this, the benefits of borrow checker out weight the shortcomings. I can feel myself writing better code in other languages (I tend to think about the layout and the mutability and lifetimes upfront more now) My rust code now is very functional, which seems to work best with lifetimes. I would love to know more about the authors pain, I do hope rustc gets better at lifetime compilation errors cause some of them can be very very gnarly. reply estebank 18 hours agoparent> I do hope rustc gets better at lifetime compilation errors cause some of them can be very very gnarly. When this happens, file tickets! We do our best to improve diagnostics over time, but the best improvements have been reactive, by fixing a case that we never encountered but our users did. reply skp1995 18 hours agorootparentwill keep that in mind going forward! The most recent ones which I have been hitting are around \"higher-ranked lifetime error\" I know my way around this now, which is to literally binary search over the timeline of my edits (commenting out code and then reintroducing it) to see what causes the compiler to trip over (there might be better ways to debug this, and I am all ears) Most of the times this error is several layers deep in my application so even tho I want to ticket it up, not being able to create a minimal repo for anyone to iterate against feels like a bit of wasted energy on all sides, do let me know if I should change this way of thinking and I can promise myself to start being more proactive. reply estebank 17 hours agorootparentIf it's public code, a link to a branch with the issue can still be useful. Looking at the compiler internals you can get a better sense on how to minimize the issue. That being said, not having a minimised repro lowers the chance of it getting addressed quickly. Even if you have already figured out how to deal with it, your future colleagues might not, and by improving the diagnostic you would also be getting that time manually commenting code back. reply oneshtein 11 hours agoparentprev> Rust can be hard to get right because of the borrow checker. In the same vein: «C/C++ can be hard to get right because of the valgrind.» ;-) reply Sytten 15 hours agoprevPeople seriously need to stop obsessing about RC/ARC. Just use it, it will be fine. The perf difference wont matter in 99.99% of the cases. Whole languages (Swift) are based on that. reply nu11ptr 17 hours agoprevLike many of these sorts of critique articles, I can see the author's pain point and empathize, but don't fully agree. Yes, it is true that if you aren't careful you can end up with a design that doesn't work and has to be redesigned. And yes, I do agree when this happens it can be very frustrating (and a time suck). However, in my experience, and it probably depends what type of code one writes, it doesn't happen enough to fully mar the experience of an otherwise very productive language. If I had to guess, I would say this happens to me maybe 1 day in 30. Not great, but not catastrophic either. If I'm working on a section of code the relies heavily on borrowing and lifetimes, I will typically work up a prototype without all the functionality just to ensure I have a workable design before going back to fill in the rest of the code. This is probably why I don't tend to hit it all that often. It would be ideal if this wasn't necessary, but Rust has all sorts of other awesome features that make this something worth enduring. reply dathinab 11 hours agoprevI habe been writing rust at work since 2016 or so and I can't say that the virtue checker ever had been much of a problem. Like it's not that it never caused issues but most times fixing them also produces much better code. In my experience the most common place to run into issues is if you write C/C++ style code in rust. Or if you write certain kinds of functional style code in rust, rust has many functional features but isn't strictly speaking a functional language and while some functional pattern work well many other fall apart especially if combined with async (which will get better once async closure are stabilize). in the end it often boils down to trying to use patterns and styles for other languages in a language which doesn't support them well, which always causes issues, but most times (in other languages) in more subtle ways then compiler errors, e.g. UB, perf, etc. Through there is one field (game programming) where as long as your project doesn't become quite big you can get away with a lot of suboptimal approaches of state handling but not in rust. So if it comes to hobby from scratch state game programming I wouldn't be surprised for people to get annoyed (but if it's game programming using existing frameworks and e.g. stuff like a entire component library like bavy it's a different topic altogether) reply melodyogonna 13 hours agoprevIt's interesting how Mojo solves some of Rust's lifetime UX issues. Because Mojo values uses ASAP destruction rather scope-based destructor, what Mojo's lifetime has to do is correctly track the last place a value was used, it doesn't track the validity of a scope. What this means in practice is that Mojo's lifetime checker extends the life of values. Just point it at an origin and it'll ensure the origin is still alive wherever you use the value attached to it. It completely defines away \"value does not live long enough\" compiler problems. reply sestep 18 hours agoprevIt is interesting that the borrow checker doesn't run until after typechecking succeeds. As far as I'm aware, rust-analyzer has its own builtin logic for doing typechecking, but it delegates to rustc for borrow checking. I wonder whether this is just a temporary situation due to lack of engineering resources to implement borrow checking in rust-analyzer; personally I doubt that, especially since gccrs is incorporating components of rustc wholesale and so I'd be a bit surprised if rust-analyzer moves in the opposite direction. In theory it seems possible to support borrow checking in the IDE for ill-typed programs, but having borrow checking as a separate analysis pass depending on successful typechecking is just such a nice abstraction boundary to have for maintaining the toolchain. reply dwattttt 18 hours agoparentborrow checking relies on types to be able to check; types are what carry borrows after all. reply sestep 18 hours agorootparentThis is true but misleading: analogously, typechecking depends on parsing, but IDEs typically make a best effort to typecheck syntactically ill-formed programs. reply estebank 18 hours agorootparentrustc does its best to recover, continue and provide diagnostics from later stages. But at the same time it is better to provide a single early error and mark the entire node as recovered to avoid further errors at the cost of requiring more cycles of back and forth, over the alternative of tons of useless knock down errors that drown the underlying cause of the problem. We are always on the lookout for improving in this area. Having examples of cases where we conceivably should have done better but didn't is useful. As mentioned already, the complexity here is that doing the right thing for the user requires architecting multiple separate stages of the compiler to talk to each other in way more complex ways than originally intended. reply James_K 18 hours agoprevAn often overlooked solution to this problem is to avoid using Rust, or to only use it for performance critical code. Writing a large application in Rust sounds hellish, it seems like it would be much nicer to only use it in sections of the hotpath where it is absolutely necessary. reply goku12 8 hours agoparentThat applies only if you're struggling with Rust. It's as good as any other general purpose programming language once you're out of the fight-the-borrow-checker stage. Structuring or refactoring large applications in Rust is nowhere as tedious as many project it. There are many zero-cost abstractions and other features that even makes it very pleasant. My first preference for making simple utilities is as a shell script. The immediately next one is actually Rust. reply James_K 7 hours agorootparentManually managing memory complicates the program, and makes it harder to change. Every interface written is contaminated with the implementation details of how it manages memory. This has a large cost in terms of development time. As much as you might want to imagine Rust has made every other programming language obsolete, that just isn't true. reply goku12 7 hours agorootparentYour assertion doesn't match my experience. Besides if that were true, nobody would be using C or C++ for writing general purpose (non-system) applications. C and C++ require the same system knowledge that Rust developers use to satisfy the borrow checker. Even worse, Rust borrow checker will remind you of those rules. C and C++ will just allow you to proceed and crash. C and C++ memory management is even more manually involved than Rust's. Yet people do write normal applications in C and C++. The only explanation I can think of for the dislike towards Rust's compile time checks is that some people don't entirely understand these rules when they use C and C++. It's possible to resolve simple memory safety issues in C/C++ without in-depth knowledge of hardware semantics. But a complicate bug will easily stump you at runtime (personal experience). reply James_K 6 hours agorootparentYou seem to have forgotten that garbage collected languages exist, and are much preferable to Rust in many circumstances. reply goku12 40 minutes agorootparentYou're diverting from the context of this thread. I'm asking why a developer who is comfortable with Rust borrow checker choose any other language? How is a GC language preferable in any way to Rust for such a person? In a broader sense, I keep seeing some people asking everyone else to avoid Rust based on an exaggerated account of the struggle with the borrow checker. There is actually a way to get comfortable with the BC. Perhaps beginners should be introduced to those ideas rather than such negative takes. reply pornel 16 hours agoprevTrue, you need to know what is and isn't possible in the borrow checking model to avoid learning it the hard way after writing the code. There are some gotchas that you need to learn (e.g. self-referential structs won't work, or & returned from a &mut method won't be shareable). But besides a few exceptions, it's mostly shared XOR mutable data in the shape of a tree. It's possible to build intuition around it. reply olvy0 14 hours agoprevThis is exactly what I thought about rust when trying to learn it a few years ago. I'm also an experienced C++ programmer. After trying for 3-4 months and constantly fighting the borrow checker, I lost all motivation and gave up. reply goku12 8 hours agoparentRust borrow checker rules are a bit weird and unintuitive. But if you are a systems programmer (C or C++) and think a bit about the borrow checker complaints, you'll find that they almost always correspond to memory safety bugs like use-after-free or invalidated references. All you need to think is about what might happen if the code was accepted (this is for C/C++ programmers, since GC-based language programmers don't face those often). The same mistakes can happen in C and C++ too - but without the BC to back you up. In essence, there is no escape from those exact same rules. There are a few genuine cases which the BC won't accept, though they may be valid. The first case is of data structures containing cycles (like dequeues, ring buffers, closed graphs, etc). The other is cross-FFI calls. This is due to the fact that the BC simply doesn't have the intelligence to reason about them (at compile-time). Even then, Rust gives you 2 types of escape hatches - runtime safety checks (using Rc, Cell, etc) with a slight performance impact, and manual safety checks (unsafe) when performance is paramount. All that's expected of you (the programmer) is to recognize such cases and use the appropriate solution. I'm not too surprised when non-C/C++ programmers struggle with BC rules. They may be unfamiliar with the low-level execution semantics. But I'm surprised when C/C++ programmers fail to make the connection. I was a C++ programmer too and this is the first thing I noticed. Memorizing the BC rules is the absolute worst way to learn it. You should be looking for memory safety problems and correlating them with BC error messages instead. I know this works because I trained non-systems (non-C/C++, primarily JS and Python) developers in Rust. They picked up the execution and memory semantics quickly and easily made sense of the borrow checker idiosyncrasies. reply wavemode 14 hours agoprevThis persons's problem is pretty clear - Rust is frankly miserable to write code in if you are trying to optimize everything as much as possible. Since this is the default mindspace of C/C++ programmers, the frustration is understandable. Rust becomes a lot simpler when you borrow less and clone more. Sprinkle in smart pointers when appropriate. And the resulting program is probably still going to have fantastic performance - many developers err by spending weeks of developer time trying to shave off a few microseconds of runtime. But, if you're a developer for whom those microseconds really do matter a lot, well then you just have to bite the bullet. reply jandrewrogers 14 hours agoparentI think I come down somewhere close to this. Idiomatic safe Rust is noticeably slower and less scalable",
    "originSummary": [
      "The author discusses challenges with Rust's borrow checker, which often necessitates major code refactoring when it cannot handle specific situations.",
      "Rust's complexity, particularly with lifetimes and async, requires developers to memorize rules to avoid frequent refactoring, making it more challenging than some simpler languages.",
      "While Rust improves safety over C++ by preventing undefined behavior, its complexity and the need for better IDE tooling drive some developers to seek more user-friendly alternatives."
    ],
    "commentSummary": [
      "Rust's borrow checker and strict memory safety rules can be challenging for developers accustomed to languages like C++, potentially impacting productivity in fast-paced environments.",
      "While some developers find Rust's features enhance coding practices by preventing bugs, others feel it makes code refactoring tedious.",
      "There is a debate on whether to use Rust selectively for performance-critical sections or to fully embrace its idioms to leverage its benefits."
    ],
    "points": 167,
    "commentCount": 211,
    "retryCount": 0,
    "time": 1731799746
  },
  {
    "id": 42158445,
    "title": "Logica – Declarative logic programming language for data",
    "originLink": "https://logica.dev/",
    "originBody": "Logic Programming Language for Data Analysis View project on GitHub. What is Logica? Logica is an open source declarative logic programming language for data manipulation. Logica extends syntax of logic programming for intuitive and efficient data manipulation. It compiles to SQL thus providing you access to the power of SQL engines with the convenience of logic programming syntax. Examples One may say that for programming languages like Python and Java functions are the basic building blocks. For Logica and other logic programming languages those building blocks are predicates. Logic program is defined as a set of rules that define output predicates from pre-defied predicates. Those pre-defined predecates represent input data. For example here is a rule to identify names of expensive books, from an existing table of book prices. # Logica rule to get expensive books. ExpensiveBook(book_name) :- # book_name is expensive if and only if Book(book_name, price), # book_name costs price price > 100; # and price is greater than 100. If you are familiar with SQL, you may see that the rule above is equivalent to the flowing SQL statement. Not that familiarity with SQL is required to learn Logica, not at all. # SQL statement to get expensive books. SELECT book_name FROM book WHERE price > 100; Predicate is a statement with variables. Any table can be treated as predicate, where column names are the variables, and each row is a set of values of the variables that satisfies the statement. While SQL is quite convenient for small queries like the one above it gets hard to read when complexity grows. Logica leverages power of mathematical syntax to scale nicely as complexity grows. Let's assume we have a table BabyNames that for each name, year, city and gender specifies number of babies of that name born. The following program finds a list of popular names, where a name is defined as popular if it was the most popular name on some year. # Count babies per year. NameCountByYear(name:, year:) += number :- BabyNames(name:, year:, number:); # For each year pick the most popular. TopNameByYear(year) ArgMax= name -> NameCountByYear(name:, year:); # Accumulate most popular name into a table, droppig the year. PopularName(name: TopNameByYear()); Sometimes data analysis requires solving algorithmic problems. Logica's syntax is suited for it naturally. Here is a program finding prime numbers that are less than 100. # Define numbers 1 to 30. Number(x + 1) :- x in Range(30); # Defining composite numbers. Composite(a * b) distinct :- Number(a), Number(b), a > 1, b > 1; # Defining primes as \"not composite\". Prime(n) distinct :- Number(n), n > 1, ~Composite(n); Finally here is an example of program that runs over GDELT Project dataset, finding people mentioned in the context of \"artificial general intelligence\". Observe that program is divided into a rule defining predicate NewsData and rule for AgiMentions. The first rule is essentially doing data cleaning, formatting the dataset in a shape that is convenient to use. Then second rule peforms the task at hand. In Logica problems are naturally split into smaller components that end up reusable. So in the future if we have more analysis to do with GDELT dataset we may take advantage of the NewsData predicate that we just wrote. # Structuring the data conveniently. NewsData(year:, month:, day:, persons:, quotations:) :- gdelt-bq.gdeltv2.gkg(persons: persons_str, quotations:, date: date_num), # Column `data` in GDELT dataset is given as an integer. year == ToInt64(Substr(ToString(date_num), 1, 4)), month == ToInt64(Substr(ToString(date_num), 5, 2)), day == ToInt64(Substr(ToString(date_num), 7, 2)), persons List= (person :- person in Split(persons_str, \";\")); # Performing the task at hand. @OrderBy(AgiMentions, \"mentions desc\"); @Limit(AgiMentions, 10); AgiMentions(person:, mentions? += 1) distinct :- person in persons, Like(quotations, \"%artificial general intelligence%\"), NewsData(persons:, quotations:); This program completes in interactive time when ran over the 4TB dataset via BigQuery. Why Logica? Logica is for engineers, data scientists and other specialists who need to perform complex data processing and analysis. Queries and pipelines written in Logica can run on BigQuery, SQLite and PostgreSQL engines. Information stored in these systems is thus available in Logica. Logica compiles to SQL and gives you access to the power of SQL engines, including the massively distrbuted Google BigQuery engine, with the convenience of logic programming syntax. This is useful because BigQuery is magnitudes more powerful than state of the art native logic programming engines. We encourage you to try Logica, especially if you already use logic programming and need more computational power, or you already have data in BigQuery, PostgreSQL or SQLite, or you want to learn logic programming and apply it to processing of Big Data. Among other engines, there is partial support for Trino and Databricks. Contributions to improve this support are very welcome! I have not heard of logic programming. What is it? Logic programming is a declarative programming paradigm where the program is written as a set of logical statements. Logic programming was developed in academia from the late 60s. Prolog and Datalog are the most prominent examples of logic programming languages. Logica is a successor to Yedalog, a language created at Google earlier. Logica as well as Yedalog belong to Datalog family. Datalog and relational databases start from the same idea: think of data as relations and think of data manipulation as a sequence of operations over these relations. But Datalog and SQL differ in how these operations are described. Datalog is inspired by the mathematical syntax of the first order propositional logic and SQL follows the syntax of natural language. SQL was based on the natural language to give access to databases to the people without formal training in computer programming or mathematics. This convenience may become costly when the logic that you want to express is non trivial. There are many examples of hard-to-read SQL queries that correspond to simple logic programs. Logica follows Yedalog in the attempt to merge these branches back together: extending the elegant syntax of Logic Programming to solve practical problems and leverage the tremendous advances of SQL infrastructure for the execution. How does Logica work? Logica compiles the logic program into a SQL expression, so it can be executed on BigQuery, the state of the art SQL engine. Among database theoreticians Datalog and SQL are known to be equivalent. And indeed the conversion from Datalog to SQL and back is often straightforward. However there are a few nuances, for example how to treat disjunction and negation. In Logica we tried to make choices that make understanding of the resulting SQL structure as easy as possible, thus empowering user to write programs that are executed efficiently. Why is it called Logica? Logica stands for Logic with aggregation. How to learn? 🏖 Playground 🎓 Tutorial Learn basics of Logica with the CoLab tutorial located at tutorial folder. See examples of using Logica in examples folder. You try Logica immediately in the browser in Playground. It is easy to install Logica on your machine as well. Installation Install Logica with `pip`. # Install: $ python3 -m pip install logica # Run: $ python3 -m logica # (optional) Create alias for convenience: alias logica=python3 -m logica Let's say this program is written in file hello.l. @ Engine ( \"sqlite\" ); Greeting ( \"Hello world!\" ); When exectued with $ logica hello.l run Greeting it should produce the following table: +--------------+col0+--------------+Hello world!+--------------+ Join the discussion! If you have any questions or ideas about Logica, you are welcome to post those in Discussions section of the repo! Unless otherwise noted, the Logica source files are distributed under the Apache 2.0 license found in the LICENSE file. Logica is not an officially supported Google product.",
    "commentLink": "https://news.ycombinator.com/item?id=42158445",
    "commentBody": "Logica – Declarative logic programming language for data (logica.dev)159 points by voat 23 hours agohidepastfavorite56 comments dang 23 hours agoRelated: Google is pushing the new language Logica to solve the major flaws in SQL - https://news.ycombinator.com/item?id=29715957 - Dec 2021 (1 comment) Logica, a novel open-source logic programming language - https://news.ycombinator.com/item?id=26805121 - April 2021 (98 comments) reply usgroup 10 hours agoparentI may be misremembering but I think that at the time, Logica was the work of one developer who happened to be at Google. I'm not sure that there was an institutional push to use this language, nor that it has significant adoption at Google itself. reply thenaturalist 10 hours agorootparentThis seems supported by the fact that the repo is not under a Google org and it has a single maintainer. reply diggan 6 hours agorootparent> that the repo is not under a Google org I don't think that matters? github.com/google has a bunch of projects with large warnings that \"This is not a Google project\", not sure why or how that is. From the outside it looks like if you work at Google, they take ownership of anything you write. reply azornathogron 3 hours agorootparent> From the outside it looks like if you work at Google, they take ownership of anything you write. That is precisely how it works. Disclaimer: I am not a lawyer, and I'm sure the validity and enforceability of the relevant contract clauses varies by jurisdiction. reply Agraillo 21 hours agoprevI think it is a good direction imho. Once being familiar with SQL I learned Prolog a little and similarities struck me. I wasn't the first one sure, and there are others who summarized it better than me [1] (2010-2012): Each can do the other, to a limited extent, but it becomes increasingly difficult with even small increases in complexity. For instance, you can do inferencing in SQL, but it is almost entirely manual in nature and not at all like the automatic forward-inferencing of Prolog. And yes, you can store data(facts) in Prolog, but it is not at all designed for the \"storage, retrieval, projection and reduction of Trillions of rows with thousands of simultaneous users\" that SQL is. I even wanted to implement something like Logica at the moment, primarily trying to build a bridge through a virtual table in SQLite that would allow storing rules as mostly Prolog statements and having adapters to SQL storage when inference needs facts. [1]: https://stackoverflow.com/a/2119003 reply cess11 7 hours agoparentPerhaps you already know this, but as a data store Prolog code is actually surprisingly convenient sometimes, similar to how you might create a throwaway SQLite3 or DuckDB for a one-off analysis or recurring batched jobs. It's trivial to convert stuff like web server access logs into Prolog facts by either hacking the logging module or running the log files through a bit of sed, and then you can formalise some patterns as rules and do rather nifty querying. A hundred megabytes of RAM can hold a lot of log data as Prolog facts. E.g. '2024-11-16 12:45:27 127.0.0.1 \"GET /something\" \"Whatever User-Agent\" \"user_id_123\"' could be trivially transformed into 'logrow(\"2024-11-16\", \"12:45:27\", \"127.0.0.1\", \"GET\", \"/something\", \"Whatever User-Agent\", \"user_id_123\").', especially if you're acquainted with DCG:s. Then you could, for example, write a rule that defines a relation between rows where a user-agent and IP does GET /log_out and shortly after has activity with another user ID, and query out people that could be suspected to use several accounts. reply usgroup 10 hours agoprevIts nice to see Logica has come on a bit. A year or two ago I tried to use this in production and it was very buggy. The basic selling point is a compositional query language, so that over-time one may have a library of re-usable components. If anyone really has built such a library I'd love to know more about how it worked out in practice. It isn't obvious to me how those decorators are supposed to compose and abstract on first look. Its also not immediately obvious to me how complicated your library of SQL has to be for this approach to make sense. Say I had a collection of 100 moderately complex and correlated SQL queries, and I was to refactor them into Logica, in what circumstances would it yield a substantial benefit versus (1) doing nothing, (2) creating views or stored procedures, (3) using DBT / M4 or some other preprocessor for generic abstraction. reply thenaturalist 10 hours agoparentNever heard of M4 before and, lo and behold, of course HN has a discussion of it: https://news.ycombinator.com/item?id=34159699 The author discusses Logica vs. plain SQL vs POSIX. I’d always start with dbt/ Sqlmesh. The library you’re talking about exists: dbt packages. Check out hub.getdbt.com and you’ll find dozens of public packages for standardizing sources, data formatting or all kinds of data ops. You can use almost any query engine/ DB out there. Then go for dbt power user in VS Code or use Paradime and you have first class IDE support. I have no affiliation with any of the products, but from a practitioner perspective the gap between these technologies (and their ecosystems) is so large that the ranking of value for programming is as clear as they come. reply thom 8 hours agorootparentM4 is absolutely ancient, one of those things you've probably only seen flashing by on your screen if you've found yourself running `make; make install`. I suppose it is a perfectly cromulent tool for SQL templating but you're right that you must be able to get more mileage out of something targeted like dbt/SQLMesh. reply pstoll 1 hour agorootparentHaving debugged my share of autoconf setups..I assumed it had to be a new M4 and not the ancient quirky GNU M4 thing because no one in their right mind would wish M4 (and related GNU autoconfig / autconf) on any other sentient beings. It’d be like saying - “hey, I’m starting a new project and trying to pick between ed, sed, or awk. Whatcha think”? Def not. reply pstoll 1 hour agorootparentprevAlso +1 for cromulent use of “cromulent”. reply Y_Y 23 hours agoprevIf, like me, your first reaction is that this looks suspiciously like Datalog then you may be interested to learn that they indeed consider Logical to be \"in the the Datalog family\". reply jp57 23 hours agoparentI think Datalog should be thought of as \"in the logic programming family\", so other data languages based on logic programming are likely to be similar. And, of course the relational model of data is based on first-order logic, so one could say that SQL is a declarative logic programming language for data. reply taeric 21 hours agoprevI find the appeals to composition tough to agree with. For one, most queries begin as ad hoc questions. And can usually be tossed after. If they are needed for speed, it is the index structure that is more vital than the query structure. That and knowing what materialized views have been made with implications on propagation delays. Curious to hear battle stories from other teams using this. reply FridgeSeal 18 hours agoparentDepends who your users are and what the context is. Having been in quite a few data teams, and supported businesses using dashboards, a very large chunk of the time, the requests do align with the composable feature: people want “the data from that dashboard but with x/y/z constraints too” or “ who did a|b in the last time, and then send that to me each week, and then break it down by something-else”. Scenarios that all benefit massively from being able to compose queries more easily, especially as things like “well defined customer segment” get evolved. Even ad-hoc queries would benefit because you’d be able to throw them together faster. There’s a number of tools that proclaim to solve this, but solving this at the language level strikes me as a far better solution. reply taeric 17 hours agorootparentI supported a team at a large company looking at engagement metrics for emails. Materialized views (edit: manually done) and daily aggregate jobs over indexed ranges was really the only viable solution. You could tell the new members because they would invariably think to go to base data and build up aggregates they wanted, and not look directly for the aggregates. That is so say, you have to define the jobs that do the aggregations, as well. Knowing that you can't just add historical records and have them immediately on current reports. I welcome the idea that a support team could use better tools. I suspect polyglot to win. Ad hoc is hard to do better than SQL. DDL is different, but largely difficult to beat SQL, still. And job description is a frontier of mistakes. reply avodonosov 20 hours agoprev> Composite(a * b) distinct :- ... Wait, does Logica factorize the number passed to this predicate when unifying the number with a * b? So when we call Composite (100) it automatically tries all a's and b's who give 100 when m7ltiplied I'd be curious to see the SQL it transpiles to. reply puzzledobserver 11 hours agoparentAs someone who is intimately familiar with Datalog, but have not read much about Logica: The way I read these rules is not from left-to-right but from right-to-left. In this case, it would say: Pick two numbers a > 1 and b > 1, their product a*b is a composite number. The solver starts with the facts that are immediately evident, and repeatedly apply these rules until no more conclusions are left to be drawn. \"But there are infinitely many composite numbers,\" you'll object. To which I will point out the limit of numbersMalloy is an experimental language for describing data relationships and transformations. [0]: https://github.com/malloydata/malloy reply pstoll 5 hours agoparentCame here to mention Malloy. Which is from the team that built Looker, which Google acquired. The Looker CTO founder then started (joined?) Malloy. And … he recently 6mo ago moved from Google to Meta. https://www.linkedin.com/posts/medriscoll_big-news-in-the-da... Also for those playing along at home - a few other related tools for “doing more with queries”. - AtScale - a semantic layer not dissimilar to LookML but with a good engine to optimize pre building the aggregates and routing queries among sql engines for perf. - SDF - a team that left Meta to make a commercial offering for a sql parser and related tools. Say to help make dbt better. (No affiliation other than having used / been involved with / know some of these people at work) reply usgroup 9 hours agoprevHas anyone used Datalog with Datomic in anger? If so, what are your thoughts about Logica, and how does the proposition differ in your experience? reply transfire 15 hours agoprevNice idea, but the syntax seems hacky. reply foobarqux 21 hours agoprevThere don't seem to be any examples of how to connect to an existing (say sqlite) database even though it says you should try logica if \"you already have data in BigQuery, PostgreSQL or SQLite,\". How do you connect to an existing sqlite database? reply kukkeliskuu 17 hours agoparentI was turned off by this at first, but then tried it out. These are mistakes in the documentation. The tools just work with PostgreSQL and SQLite without any extra work. reply foobarqux 6 hours agorootparentHow do you connect to an existing database so that you can query it? There are examples of how you can specify an \"engine\" which will create a new database and use it as a backend for executing queries but I want to query existing data in an sqlite database. reply cess11 21 hours agoprevIf this is how you want to compile to SQL, why not invent your own DCG with Prolog proper? It should be easy enough if you're somewhat fluent in both languages, and has the perk of not being some Python thing at a megacorp famous for killing its projects. reply cynicalsecurity 13 hours agoprevThis is going to be a hell in production. Someone is going to write queries in this new language and then wonder why the produced MySQL queries in production take 45 minutes to execute. reply riku_iki 23 hours agoprevOnly one active committer on github.. reply thenaturalist 22 hours agoprev [–] I don't want to come off as too overconfident, but would be very hard pressed to see the value of this. At face value, I shudder at the syntax. Example from their tutorial: EmployeeName(name:) :- Employee(name:); Engineer(name:) :- Employee(name:, role: \"Engineer\"); EngineersAndProductManagers(name:) :- Employee(name:, role:), role == \"Engineer\" || role == \"Product Manager\"; vs. the equivalent SQL: SELECT Employee.name AS name FROM t_0_Employee AS Employee WHERE (Employee.role = \"Engineer\" OR Employee.role = \"Product Manager\"); SQL is much more concise, extremely easy to follow. No weird OOP-style class instantiation for something as simple as just getting the name. As already noted in the 2021 discussion, what's actually the killer though is adoption and, three years later, ecosystem. SQL for analytics has come an extremely long way with the ecosystem that was ignited by dbt. There is so much better tooling today when it comes to testing, modelling, running in memory with tools like DuckDB or Ibis, Apache Iceberg. There is value to abstracting on top of SQL, but it does very much seem to me like this is not it. reply aseipp 22 hours agoparentLogica is in the Datalog/Prolog/Logic family of programming languages. It's very familiar to anyone who knows how to read it. None of this has anything to do with OOP at all and you will heavily mislead yourself if you try to map any of that thinking onto it. (Beyond that, and not specific to Logica or SQL in any way -- comparing two 3-line programs to draw conclusions is effectively meaningless. You have to actually write programs bigger than that to see the whole picture.) Datalog is not really a query language, actually. But it is relational, like SQL, so it lets you express relations between \"facts\" (the rows) inside tables. But it is more general, because it also lets you express relations between tables themselves (e.g. this \"table\" is built from the relationship between two smaller tables), and it does so without requiring extra special case semantics like VIEWs. Because of this, it's easy to write small fragments of Datalog programs, and then stick it together with other fragments, without a lot of planning ahead of time, meaning as a language it is very compositional. This is one of the primary reasons why many people are interested in it as a SQL alternative; aside from your typical weird SQL quirks that are avoided with better language design (which are annoying, but not really the big picture.) reply thenaturalist 22 hours agorootparent> but it is more general, because it also lets you express relations between tables themselves (e.g. this \"table\" is built from the relationship between two smaller tables), and it does so without requiring extra special case semantics like VIEWs. If I understand you correctly, you can easily get the same with ephemeral models in dbt or CTEs generally? > Because of this, it's easy to write small fragments of Datalog programs, and then stick it together with other fragments, without a lot of planning ahead of time, meaning as a language it is very compositional. This can be a benefit in some cases, I guess, but how can you guarantee correctness with flexibility involved? With SQL, I get either table or column level lineage with all modern tools, can audit each upstream output before going into a downstream input. In dbt I have macros which I can reuse everywhere. It's very compositional while at the same time perfectly documented and testable at runtime. Could you share a more specific example or scenario where you have seen Datalog/ Logica outperform a modern SQL setup? Generally curious. I am not at all familiar with the Logica/Datalog/Prolog world. reply burakemir 21 hours agorootparentHere is a proof that you can translate non-recursive datalog into relational algebra and vice versa: https://github.com/google/mangle/blob/main/docs/spec_explain... Since Logica is translated to SQL it should benefit from all the query optimistic goodness that went into the SQL engine that runs the resulting queries. I personally see the disadvantages of SQL in that it is not really modular, you cannot have libraries, tests and such. Disclosure: I wrote Mangle (the link goes to the Mangle repo), another datalog, different way of extending, no SQL translation but an engine library. reply aseipp 19 hours agorootparentMangle looks very interesting, thanks for the share. In particular I love your GRPC demo, because it shows a prototype of something I've been thinking about for a long time: what if we did GraphQL, but with Datalog! Maybe we could call it LogiQL :) In particular many people talk a lot about concerns like optimizations across GraphQL plans and how they are expected to behave on underlying tables, but this is something that I think has seen a lot of research in the Datalog realm. And to top it off, even ignoring that, Datalog just feels much more natural to write and read after a bit of practice, I think. (Obviously you need to be in the pure fragment of datalog without recursion, but even then it might be feasible to add those features with termination criteria even if it's just \"decrement an internal counter and if it hits zero throw a big error\") What do you think the plans for the Rust implementation will be? That's probably the most likely place I'd use it, as I don't really use Go that much. reply burakemir 15 hours agorootparentThe Mangle repo has the beginnings of a Rust implementation but it will take some time before it is usable. The go implementation is also still being improved, but I think real DB work with persistent data will happen only in Rust. Bindings to other host languages would also use the Rust implementation. There are no big challenges here it is just work and takes time. The combination of top-down and bottom up logic programming is interesting, especially when one can move work between pre computation and query time. I like that optimizing queries in datalog can be discussed like optimization of programming language but of course the biggest gains in DB come from join order and making use of indices. There is a tension here between declarative and having some control or hints for execution. I haven't yet figured out how one should go about it, and also how to help programmers combine top-down and bottom-up computation. Work in progress! :-) reply from-nibly 21 hours agorootparentprevProlog et al is a real brain buster. As in it will break your spirits and build you back up better. I remember in college I was able to build a binary tree with 3 lines of code. And once you write the insert, the delete, search, and others just magically appear. It also frames your thinking about defining what you want rather than how to get it. If you really want to see the power of these kinds of languages look up Einstein's puzzle solved with prolog. The solution just magically comes out by entering the constraints of the puzzle. reply surgical_fire 21 hours agorootparentI had to use Prolog in college, and while I never saw it in the wild - I at least never stumbled upon a scenario where prolog was the answer - I really enjoyed how I had to change how I looked at a problem in order to solve it in prolog. reply rytis 21 hours agorootparentprevI suppose something like this: https://stackoverflow.com/a/8270393 ? reply jyounker 20 hours agorootparentprevThe covid analysis seems like a pretty good example: https://colab.research.google.com/github/EvgSkv/logica/blob/... A good exercise might be converting it to the corresponding SQL and comparing the two for clarity. reply aseipp 21 hours agorootparentprev> If I understand you correctly, you can easily get the same with ephemeral models in dbt or CTEs generally? You can bolt on any number of 3rd party features or extensions to get some extra thing, that goes for any tool in the world. The point of something like Datalog is that it can express a similar class of relational programs that SQL can, but with a smaller set of core ideas. \"Do more with less.\" > I guess, but how can you guarantee correctness with flexibility involved? How do you guarantee the correctness of anything? How do you know any SQL query you write is correct? Well, as the author, you typically have a good idea. The point of being compositional is that it's easier to stick together arbitrary things defined in Datalog, and have the resulting thing work smoothly. Going back to the previous example, you can define any two \"tables\" and then just derive a third \"table\" from these, using language features that you already use -- to define relationships between rows. Datalog can define relations between rules (tables) and between facts (rows), all with a single syntactic/semantic concept. While SQL can only by default express relations between rows. Therefore, raw SQL is kind of \"the bottom half\" of Datalog, and to get the upper half you need features like CTEs, VIEWs, etc, and apply them appropriately. You need more concepts to cover both the bottom and top half; Datalog covers them with one concept. Datalog also makes it easy to express things like e.g. queries on graph structures, but again, you don't need extra features like CTEs for this to happen. There are of course lots of tricky bits (e.g. optimization) but the general idea works very well. > Could you share a more specific example or scenario where you have seen Datalog/ Logica outperform a modern SQL setup? Again, Datalog is not about SQL. It's a logic programming language. You need to actually spend time doing logic programming with something like Prolog or Datalog to appreciate the class of things it can do well. It just so happens Datalog is also good for expressing relational programs, which is what you do in SQL. Most of the times I'm doing logic programming I'm actually writing programs, not database queries. Trying to do things like analyze programs to learn facts about them (Souffle Datalog, \"can this function ever call this other function in any circumstance?\") or something like a declarative program as a decision procedure. For example, I have a prototype Prolog program sitting around that scans a big code repository, figures out all 3rd party dependencies and their licenses, then tries to work out whether they are compatible. It's a bit like Lisp, in the sense that it's a core formulation of a set of ideas that you aren't going to magically adopt without doing it yourself a bunch. I could show you a bunch of logic programs, but without experience all the core ideas are going to be lost and the comparison would be meaningless. For the record, I don't use Logica with SQL, but not because I wouldn't want to. It seems like a good approach. I would use Datalog over SQL happily for my own projects if I could. The reasons I don't use Logica for instance are more technical than anything -- it is a Python library, and I don't use Python. reply kthejoker2 19 hours agorootparentCTEs aren't really an \"extra\" feature they just are a composable reusable subquery. This just adds the benefit of storing CTEs as function calls aka table valued functions (TVFs) ... also not really an \"extra\" feature. The main advantage to any non SQL language is its ability to more efficiently express recursion (graph / hierarchical queries) and dynamic expressions like transposition and pivots. You can do those in SQL it's just clunky. reply cess11 21 hours agorootparentprevRight, so that's what they claim, that you'll get small reusable pieces. But: \"Logica compiles to SQL\". With the caveat that it only kind of does, since it seems constrained to three database engines, probably the one they optimise the output to perform well on, one where it usually doesn't matter and one that's kind of mid performance wise anyway. In light of that quote it's also weird that they mention that they are able to run the SQL they compiled to \"in interactive time\" on a rather large dataset, which they supposedly already could with SQL. Arguably I'm not very good with Datalog and have mostly used Prolog, but to me it doesn't look much like a Datalog. Predicates seems to be variadic with named parameters, making variables implicit at the call site so to understand a complex predicate you need to hop away and look at how the composite predicates are defined to understand what they return. Maybe I misunderstand how it works, but at first glance that doesn't look particularly attractive to me. Can you put arithmetic in the head of clauses in Datalog proper? As far as I can remember, that's not part of the language. To me it isn't obvious what this is supposed to do in this query language. reply aseipp 21 hours agorootparentFor the record, I don't use Logica myself so I'm not familiar with every design decision or feature -- I'm not a Python programmer. I'm speaking about Datalog in general. > making variables implicit at the call site What example are you looking at? The NewsData example for instance seems pretty understandable to me. It seems like for any given predicate you can either take the implicit name of the column or you can map it onto a different name e.g. `date: date_num` for the underlying column on gdelt-bq.gdeltv2.gkg. Really it just seems like a way to make the grammar less complicated; the `name: foo` syntax is their way of expressing 'AS' clauses and `name:` is just a shorthand for `name: name` > In light of that quote it's also weird that they mention that they are able to run the SQL they compiled to \"in interactive time\" on a rather large dataset, which they supposedly already could with SQL. The query in question is run on BigQuery (which IIRC was the original and only target database for Logica), and in that setup you might do a query over 4TB of data but get a response in milliseconds due to partitioning, column compression, parallel aggregation, etc. This is actually really common for many queries. So, in that kind of setup the translation layer needs to be fast so it doesn't spoil the benefit for the end user. I think the statement makes complete sense, tbh. (This also probably explains why they wrote it in Python, so you could use it in Jupyter notebooks hooked up to BigQuery.) reply cess11 13 hours agorootparentThey define a NewsData/5, but use a NewsData/2. Are you aware of any SQL transpilers that spend so much time transpiling that you get irritated? I'm not. reply aseipp 57 minutes agorootparentAh, I see what you mean. I'm not sure predicates like NewsData can actually be overloaded by arity, I'd have to check the docs. It mostly just seems like a shorter way to write the predicate with unbound variables. > Are you aware of any SQL transpilers that spend so much time transpiling that you get irritated? I'm not. Again, when you are running a tool on something that returns results in ~millisecond time, it is important the tool does not spoil that. Even 100-200ms is noticeable when you're typing things out. They could have worded it differently, it's probably just typical \"A programmer wrote these docs\" stuff, so it's just bad copy. A dedicated technical writer would probably do something different. reply joe_the_user 20 hours agorootparentprevIt's very familiar to anyone who knows how to read it. \"Anyone who know the system can easily learn it\" he said with a sniff. Yes, the similarity to Prolog lets you draw on a vast pool of Prolog programmers out there. I mean, I studied a variety of esoteric languages in college and they were interesting (I can't remember if we got to prolog tbh but I know 1st logic pretty well and that's related). When I was thrown into a job with SQL, it's English language syntax made things really easy. I feel confident that knowing SQL wouldn't oppositely make learning Prolog easy (I remember Scala later and not being able to deal with it's opaque verbosity easily). Basically, SQL syntax makes easy things easy. This gets underestimated a lot, indeed people seem to have contempt for it. I think that's a serious mistake. reply jyounker 20 hours agorootparent> Basically, SQL syntax makes easy things easy. This gets underestimated a lot, indeed people seem to have contempt for it. I think that's a serious mistake. The flip side of that is SQL makes hard things nearly impossible. SQL doesn't have facilities for abstraction, and it doesn't compose, and this has consequences that I deal with daily. The lack of abstract facilities makes it hard to construct complicated queries, it makes it hard to debug them, and it makes it hard refactor them. Instead of writing more complicated SQL queries, developers lean on the host languages to coordinate SQL calls, using the host language's abstraction facilities to cover for SQL's inadequacies. reply joe_the_user 20 hours agorootparentThe flip side of that is SQL makes hard things nearly impossible. What about SQL syntax makes the hard things possible? I get that the actual language SQL is broken in all sorts of ways. But I don't see any reason to replace it with some opaque from get-go. I mean, what stops you from defining, say adjectives and using those for rough modularity. Say EXPENSIVE(T) means T.price > 0; Select name FROM books WHERE EXPENSIVE(books); Seems understandable. reply geocar 12 hours agorootparentIsn't that just WITH? WITH expensive AS (SELECT * FROM books WHERE price > 100) SELECT name FROM expensive reply aseipp 20 hours agorootparentprevI mean, yes, that's sort of how linguistics works in general? You can't just look at a language with completely different orthography or semantic concepts and expect to be able to reliably map it onto your pre-existing language with no effort. That's sort of the whole reason translation is a generally difficult problem. I don't really get this kind of complaint in general I'm afraid. Many people can read and write, say, Hangul just fine -- and at the same time we don't expect random English speakers with no familiarity will be able to understand Korean conversations, or any syllabic writing systems in general. Programming language families/classes like logic programming are really no different. > it's English language syntax made things really easy That's just called \"being familiar with English\" more than any inherent property of SQL or English. reply jyounker 20 hours agoparentprev> No weird OOP-style class instantiation for something as simple as just getting the name. I understand the desire to no waste your time, but I think you're missing the big idea. Those statements define logical relations. There's nothing related to classes or OOP. Using those building blocks you can do everything that you can with SQL. No need for having clauses. No need for group by clauses. No need for subquery clauses. No need for special join syntax. Just what you see above. And you can keep going with it. SQL quickly runs into the limitations of the language. Using the syntax above (which is basically Prolog) you can construct arbitrarily large software systems which are still understandable. If you're really interested in improving as a developer, then I suggest that spend a day or two playing with a logic programming system of some sort. It's a completely different way of thinking about programming, and it will give you mental tools that you will never pick up any other way. reply thenaturalist 10 hours agorootparentReally appreciate your response and perspective! Goes on the holidays list. reply snthpy 13 hours agoparentprevHave a look at PRQL [1] for analytical queries. That's exactly what it's designed for. Disclaimer: I'm a contributor. That said. I like Logica and Datalog. For me the main use case is \"recursive\" queries as they are simpler to express that way. PRQL has made some progress there with the loop operator but it could still be better. If you have any ideas for improvement, please reach out! 1: https://prql-lang.org/ reply Tomte 22 hours agoparentprev [–] The syntax is Prolog-like, so people in the field are familiar with it. reply thenaturalist 22 hours agorootparent [–] Which field would that be? I.e. I understand now that it's seemingly about more than simple querying, so me coming very much from an analytics/ data crunching background am wondering what a use case would look like where this is arguably superior to SQL. reply tannhaeuser 20 hours agorootparent [–] > Which field would that be? Database theory papers and books have used Prolog/Datalog-like syntax throughout the years, such as those by Serge Abiteboul, just to give a single example of a researcher and prolific author over the decades. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Logica is an open-source logic programming language designed for intuitive data manipulation, extending logic programming syntax to compile into SQL for easy access to SQL engines.",
      "It uses predicates, akin to functions in Python or Java, to simplify complex queries and efficiently handle data processing, making it suitable for engineers and data scientists.",
      "Logica is compatible with BigQuery, SQLite, and PostgreSQL, and while it is easy to learn and install with available tutorials, it is not an officially supported Google product."
    ],
    "commentSummary": [
      "Logica is a declarative logic programming language developed by Google, designed to overcome SQL's limitations, particularly in complex data queries.",
      "It is open-source and part of the Datalog family, which allows for compositional query language and reusable components, but it has limited adoption and is maintained by a single developer.",
      "While Logica shows potential for simplifying complex queries and improving modularity, its syntax and practical benefits compared to SQL are still subjects of debate among users."
    ],
    "points": 159,
    "commentCount": 56,
    "retryCount": 0,
    "time": 1731784170
  },
  {
    "id": 42164541,
    "title": "Everything Is Just Functions: Mind-Blowing Insights from SICP and David Beazley",
    "originLink": "https://ezzeriesa.notion.site/1-week-with-David-Beazley-and-SICP-4c440389cf1e43f48fe67c969967f655#58ee6b0435b24e26bd624b33ffed94df",
    "originBody": "1 week with David Beazley and SICPNotion /* cspell:disable-file */ /* webkit printing magic: print all background colors */ html { -webkit-print-color-adjust: exact; } * { box-sizing: border-box; -webkit-print-color-adjust: exact; } html, body { margin: 0; padding: 0; } @media only screen { body { margin: 2em auto; max-width: 900px; color: rgb(55, 53, 47); } } body { line-height: 1.5; white-space: pre-wrap; } a, a.visited { color: inherit; text-decoration: underline; } .pdf-relative-link-path { font-size: 80%; color: #444; } h1, h2, h3 { letter-spacing: -0.01em; line-height: 1.2; font-weight: 600; margin-bottom: 0; } .page-title { font-size: 2.5rem; font-weight: 700; margin-top: 0; margin-bottom: 0.75em; } h1 { font-size: 1.875rem; margin-top: 1.875rem; } h2 { font-size: 1.5rem; margin-top: 1.5rem; } h3 { font-size: 1.25rem; margin-top: 1.25rem; } .source { border: 1px solid #ddd; border-radius: 3px; padding: 1.5em; word-break: break-all; } .callout { border-radius: 3px; padding: 1rem; } figure { margin: 1.25em 0; page-break-inside: avoid; } figcaption { opacity: 0.5; font-size: 85%; margin-top: 0.5em; } mark { background-color: transparent; } .indented { padding-left: 1.5em; } hr { background: transparent; display: block; width: 100%; height: 1px; visibility: visible; border: none; border-bottom: 1px solid rgba(55, 53, 47, 0.09); } img { max-width: 100%; } @media only print { img { max-height: 100vh; object-fit: contain; } } @page { margin: 1in; } .collection-content { font-size: 0.875rem; } .column-list { display: flex; justify-content: space-between; } .column { padding: 0 1em; } .column:first-child { padding-left: 0; } .column:last-child { padding-right: 0; } .table_of_contents-item { display: block; font-size: 0.875rem; line-height: 1.3; padding: 0.125rem; } .table_of_contents-indent-1 { margin-left: 1.5rem; } .table_of_contents-indent-2 { margin-left: 3rem; } .table_of_contents-indent-3 { margin-left: 4.5rem; } .table_of_contents-link { text-decoration: none; opacity: 0.7; border-bottom: 1px solid rgba(55, 53, 47, 0.18); } table, th, td { border: 1px solid rgba(55, 53, 47, 0.09); border-collapse: collapse; } table { border-left: none; border-right: none; } th, td { font-weight: normal; padding: 0.25em 0.5em; line-height: 1.5; min-height: 1.5em; text-align: left; } th { color: rgba(55, 53, 47, 0.6); } ol, ul { margin: 0; margin-block-start: 0.6em; margin-block-end: 0.6em; } li > ol:first-child, li > ul:first-child { margin-block-start: 0.6em; } ul > li { list-style: disc; } ul.to-do-list { padding-inline-start: 0; } ul.to-do-list > li { list-style: none; } .to-do-children-checked { text-decoration: line-through; opacity: 0.375; } ul.toggle > li { list-style: none; } ul { padding-inline-start: 1.7em; } ul > li { padding-left: 0.1em; } ol { padding-inline-start: 1.6em; } ol > li { padding-left: 0.2em; } .mono ol { padding-inline-start: 2em; } .mono ol > li { text-indent: -0.4em; } .toggle { padding-inline-start: 0em; list-style-type: none; } /* Indent toggle children */ .toggle > li > details { padding-left: 1.7em; } .toggle > li > details > summary { margin-left: -1.1em; } .selected-value { display: inline-block; padding: 0 0.5em; background: rgba(206, 205, 202, 0.5); border-radius: 3px; margin-right: 0.5em; margin-top: 0.3em; margin-bottom: 0.3em; white-space: nowrap; } .collection-title { display: inline-block; margin-right: 1em; } .page-description { margin-bottom: 2em; } .simple-table { margin-top: 1em; font-size: 0.875rem; empty-cells: show; } .simple-table td { height: 29px; min-width: 120px; } .simple-table th { height: 29px; min-width: 120px; } .simple-table-header-color { background: rgb(247, 246, 243); color: black; } .simple-table-header { font-weight: 500; } time { opacity: 0.5; } .icon { display: inline-block; max-width: 1.2em; max-height: 1.2em; text-decoration: none; vertical-align: text-bottom; margin-right: 0.5em; } img.icon { border-radius: 3px; } .user-icon { width: 1.5em; height: 1.5em; border-radius: 100%; margin-right: 0.5rem; } .user-icon-inner { font-size: 0.8em; } .text-icon { border: 1px solid #000; text-align: center; } .page-cover-image { display: block; object-fit: cover; width: 100%; max-height: 30vh; } .page-header-icon { font-size: 3rem; margin-bottom: 1rem; } .page-header-icon-with-cover { margin-top: -0.72em; margin-left: 0.07em; } .page-header-icon img { border-radius: 3px; } .link-to-page { margin: 1em 0; padding: 0; border: none; font-weight: 500; } p > .user { opacity: 0.5; } td > .user, td > time { white-space: nowrap; } input[type=\"checkbox\"] { transform: scale(1.5); margin-right: 0.6em; vertical-align: middle; } p { margin-top: 0.5em; margin-bottom: 0.5em; } .image { border: none; margin: 1.5em 0; padding: 0; border-radius: 0; text-align: center; } .code, code { background: rgba(135, 131, 120, 0.15); border-radius: 3px; padding: 0.2em 0.4em; border-radius: 3px; font-size: 85%; tab-size: 2; } code { color: #eb5757; } .code { padding: 1.5em 1em; } .code-wrap { white-space: pre-wrap; word-break: break-all; } .code > code { background: none; padding: 0; font-size: 100%; color: inherit; } blockquote { font-size: 1.25em; margin: 1em 0; padding-left: 1em; border-left: 3px solid rgb(55, 53, 47); } .bookmark { text-decoration: none; max-height: 8em; padding: 0; display: flex; width: 100%; align-items: stretch; } .bookmark-title { font-size: 0.85em; overflow: hidden; text-overflow: ellipsis; height: 1.75em; white-space: nowrap; } .bookmark-text { display: flex; flex-direction: column; } .bookmark-info { flex: 4 1 180px; padding: 12px 14px 14px; display: flex; flex-direction: column; justify-content: space-between; } .bookmark-image { width: 33%; flex: 1 1 180px; display: block; position: relative; object-fit: cover; border-radius: 1px; } .bookmark-description { color: rgba(55, 53, 47, 0.6); font-size: 0.75em; overflow: hidden; max-height: 4.5em; word-break: break-word; } .bookmark-href { font-size: 0.75em; margin-top: 0.25em; } .sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, \"Segoe UI Variable Display\", \"Segoe UI\", Helvetica, \"Apple Color Emoji\", Arial, sans-serif, \"Segoe UI Emoji\", \"Segoe UI Symbol\"; } .code { font-family: \"SFMono-Regular\", Menlo, Consolas, \"PT Mono\", \"Liberation Mono\", Courier, monospace; } .serif { font-family: Lyon-Text, Georgia, ui-serif, serif; } .mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; } .pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, \"Segoe UI Variable Display\", \"Segoe UI\", Helvetica, \"Apple Color Emoji\", Arial, sans-serif, \"Segoe UI Emoji\", \"Segoe UI Symbol\", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; } .pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, \"Segoe UI Variable Display\", \"Segoe UI\", Helvetica, \"Apple Color Emoji\", Arial, sans-serif, \"Segoe UI Emoji\", \"Segoe UI Symbol\", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; } .pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, \"Segoe UI Variable Display\", \"Segoe UI\", Helvetica, \"Apple Color Emoji\", Arial, sans-serif, \"Segoe UI Emoji\", \"Segoe UI Symbol\", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; } .pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, \"Segoe UI Variable Display\", \"Segoe UI\", Helvetica, \"Apple Color Emoji\", Arial, sans-serif, \"Segoe UI Emoji\", \"Segoe UI Symbol\", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; } .pdf .code { font-family: Source Code Pro, \"SFMono-Regular\", Menlo, Consolas, \"PT Mono\", \"Liberation Mono\", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; } .pdf:lang(zh-CN) .code { font-family: Source Code Pro, \"SFMono-Regular\", Menlo, Consolas, \"PT Mono\", \"Liberation Mono\", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; } .pdf:lang(zh-TW) .code { font-family: Source Code Pro, \"SFMono-Regular\", Menlo, Consolas, \"PT Mono\", \"Liberation Mono\", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; } .pdf:lang(ko-KR) .code { font-family: Source Code Pro, \"SFMono-Regular\", Menlo, Consolas, \"PT Mono\", \"Liberation Mono\", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; } .pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; } .pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; } .pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; } .pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; } .pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; } .pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; } .pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; } .pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; } .highlight-default { color: rgba(55, 53, 47, 1); } .highlight-gray { color: rgba(120, 119, 116, 1); fill: rgba(120, 119, 116, 1); } .highlight-brown { color: rgba(159, 107, 83, 1); fill: rgba(159, 107, 83, 1); } .highlight-orange { color: rgba(217, 115, 13, 1); fill: rgba(217, 115, 13, 1); } .highlight-yellow { color: rgba(203, 145, 47, 1); fill: rgba(203, 145, 47, 1); } .highlight-teal { color: rgba(68, 131, 97, 1); fill: rgba(68, 131, 97, 1); } .highlight-blue { color: rgba(51, 126, 169, 1); fill: rgba(51, 126, 169, 1); } .highlight-purple { color: rgba(144, 101, 176, 1); fill: rgba(144, 101, 176, 1); } .highlight-pink { color: rgba(193, 76, 138, 1); fill: rgba(193, 76, 138, 1); } .highlight-red { color: rgba(212, 76, 71, 1); fill: rgba(212, 76, 71, 1); } .highlight-default_background { color: rgba(55, 53, 47, 1); } .highlight-gray_background { background: rgba(241, 241, 239, 1); } .highlight-brown_background { background: rgba(244, 238, 238, 1); } .highlight-orange_background { background: rgba(251, 236, 221, 1); } .highlight-yellow_background { background: rgba(251, 243, 219, 1); } .highlight-teal_background { background: rgba(237, 243, 236, 1); } .highlight-blue_background { background: rgba(231, 243, 248, 1); } .highlight-purple_background { background: rgba(244, 240, 247, 0.8); } .highlight-pink_background { background: rgba(249, 238, 243, 0.8); } .highlight-red_background { background: rgba(253, 235, 236, 1); } .block-color-default { color: inherit; fill: inherit; } .block-color-gray { color: rgba(120, 119, 116, 1); fill: rgba(120, 119, 116, 1); } .block-color-brown { color: rgba(159, 107, 83, 1); fill: rgba(159, 107, 83, 1); } .block-color-orange { color: rgba(217, 115, 13, 1); fill: rgba(217, 115, 13, 1); } .block-color-yellow { color: rgba(203, 145, 47, 1); fill: rgba(203, 145, 47, 1); } .block-color-teal { color: rgba(68, 131, 97, 1); fill: rgba(68, 131, 97, 1); } .block-color-blue { color: rgba(51, 126, 169, 1); fill: rgba(51, 126, 169, 1); } .block-color-purple { color: rgba(144, 101, 176, 1); fill: rgba(144, 101, 176, 1); } .block-color-pink { color: rgba(193, 76, 138, 1); fill: rgba(193, 76, 138, 1); } .block-color-red { color: rgba(212, 76, 71, 1); fill: rgba(212, 76, 71, 1); } .block-color-default_background { color: inherit; fill: inherit; } .block-color-gray_background { background: rgba(241, 241, 239, 1); } .block-color-brown_background { background: rgba(244, 238, 238, 1); } .block-color-orange_background { background: rgba(251, 236, 221, 1); } .block-color-yellow_background { background: rgba(251, 243, 219, 1); } .block-color-teal_background { background: rgba(237, 243, 236, 1); } .block-color-blue_background { background: rgba(231, 243, 248, 1); } .block-color-purple_background { background: rgba(244, 240, 247, 0.8); } .block-color-pink_background { background: rgba(249, 238, 243, 0.8); } .block-color-red_background { background: rgba(253, 235, 236, 1); } .select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); } .select-value-color-pink { background-color: rgba(245, 224, 233, 1); } .select-value-color-purple { background-color: rgba(232, 222, 238, 1); } .select-value-color-green { background-color: rgba(219, 237, 219, 1); } .select-value-color-gray { background-color: rgba(227, 226, 224, 1); } .select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); } .select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); } .select-value-color-orange { background-color: rgba(250, 222, 201, 1); } .select-value-color-brown { background-color: rgba(238, 224, 218, 1); } .select-value-color-red { background-color: rgba(255, 226, 221, 1); } .select-value-color-yellow { background-color: rgba(253, 236, 200, 1); } .select-value-color-blue { background-color: rgba(211, 229, 239, 1); } .select-value-color-pageGlass { background-color: undefined; } .select-value-color-washGlass { background-color: undefined; } .checkbox { display: inline-flex; vertical-align: text-bottom; width: 16; height: 16; background-size: 16px; margin-left: 2px; margin-right: 5px; } .checkbox-on { background-image: url(\"data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E\"); } .checkbox-off { background-image: url(\"data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E\"); }1 week with David Beazley and SICPI had the chance to do David Beazley’s SICP course towards the end of 2022. I have only good things to say. There are a lot of free resources out there [1]. Having Dave as a guide, I was amazed at how much we covered in a week. I loved how he cherry-picked topics for the high-level overview, but takes the time to hone in on critical sections. In some cases, Dave even comes up with his own examples to more clearly illustrate concepts being discussed. What did I learn? It’s hard to describe. I’ll explain by analogy. When I learned about compilers, I discovered that languages have much more in common than I realized; I now see the big picture [2]. With SICP it’s a bit like that, but with the idea of computation more generally. Let’s review a few key concepts, and then go into what I found especially mind-blowing.Starting pointIn this section, we build a simple model of computation through the process of substitution. We start with a quick review of Scheme (the language used in SICP), next build a Scheme interpreter in Python, and then take a closer look at substitution.SchemeScheme is a dialect of Lisp. For the course we actually used Racket, which is similar but easier to set up [3]. For our purposes we only need a small part of the language; here Scheme and Racket coincide. The > in this subsection represents the Scheme REPL. Primitives are the simplest entities in the language. We only need integers. When evaluated we simply get it back.> 1 1 For built-in operations, we need +, -, * and /. Scheme uses prefix notation, where the operator appears first and then the operands. The example here illustrates adding 2 and 3.> (+ 2 3) 5 Next we have special forms. The first one we need is define, which lets us define variables. Here we define x to be 2.> (define x 2) > (+ x 3) 5",
    "commentLink": "https://news.ycombinator.com/item?id=42164541",
    "commentBody": "Everything Is Just Functions: Mind-Blowing Insights from SICP and David Beazley (ezzeriesa.notion.site)155 points by kurinikku 3 hours agohidepastfavorite68 comments marvinborner 2 hours agoThey give a nice introduction to encoding state as pure functions. In fact, there are many more purely functional encodings for all kinds of data like trees, integers, sum/product types, images, monads, ... The encodings can be a bit confusing, but really elegant and tiny at the same time. Take for example a functional implementation of the Maybe monad in javascript: Nothing = nothing => just => nothing Just = v => nothing => just => just(v) pure = Just bind = mx => f => mx(mx)(f) evalMaybe = maybe => maybe(\"Nothing\")(v => \"Just \" + v) console.log(evalMaybe(bind(Nothing)(n => pure(n + 1)))) // Nothing console.log(evalMaybe(bind(Just(42))(n => pure(n + 1)))) // Just 43 reply js2 28 minutes agoprevThere's a mistake in the code in \"the substitution model\" section: (\"+\", (\"fib\", (\"-\", \"n\", 2)), (\"fib\", (\"-\", \"n\", 1))), The two calls to `fib` are surely meant to be `fibonacci` since the latter is defined, but not the former. Indeed, the code is correct in the github repo: https://github.com/savarin/pyscheme/blob/0f47292c8e5112425b5... reply bombela 3 hours agoprevThe link takes around 10s to render. That's excessive for a text article. reply ristos 58 minutes agoparentThe arrow and page up/down keys don't work in any predictable pattern for me, it's really weird. Like I thought it only scrolled up and down with the arrow keys if I press it 4 times, but then page up/down keys don't work no matter how many times I press it, then I focus on the page and it works, but then the arrow keys take 6 times to press before moving, and then I tried the same pattern again, and the arrow keys now take 11 presses before they start moving. Usually a lot of modern apps predictably break the back/forward history buttons and tab focus, but I've never seen anything quite like this. I guess it must be still delivering value though even if the product isn't polished. reply defanor 3 hours agoparentprevAnd if you have JS disabled by default, it redirects to a page on a different domain name, so you cannot easily allow it in noscrpt just for that website, even if you want to. I gave up on that though; judging by the title, the article is going to be about modelling all the things as functions, as commonly and similarly done with other objects (e.g., sets, categories), which I wanted to confirm, and maybe to nitpick on this perspective and/or the title then (i.e., it is not quite correct to declare everything a function just because you can model or represent things that way). reply notjoemama 2 hours agorootparentYeah. But if you’re into My Little Pony, everything looks like a pastel neon horse. reply andai 1 hour agoparentprevhttps://archive.ph/kcZcY Archive seems to \"bake\" JS sites to plain HTML. reply anonzzzies 2 hours agoparentprevNotion. Why do people use that stuff? Especially for tech text articles. reply dustingetz 1 hour agorootparentwysiwyg document authoring experience, afaik there are still no alternative publishing platforms with both the flexibility and point click content authoring UX of Notion. Change my view, I’m in the market! reply debo_ 30 minutes agoparentprevMaybe it's made entirely of functions. reply bicx 2 hours agoparentprevWell, it’s a published Notion site, and Notion is a powerful doc creation platform. It’s not really intended to be a performant publishing tool. reply llamaimperative 1 hour agorootparentOr a performant anything else, AFAICT reply criddell 1 hour agorootparentprevIt’s a performant publishing tool (depending, of course, on your expectations) but it’s not a high performance publishing tool. reply yazzku 2 hours agoparentprev46 domains blocked by UBlock Origin, 3 by my own NoScript filter. Seems about right for a \"modern\" website. Edit: also, the pop-up menu on the right side that completely breaks your scrollbar. Putting that UI/UX degree to use. reply lelandfe 1 hour agorootparentPage weight is 7.2MB, 25.6 uncompressed. 110MB heap size. Such extravagant wastefulness. reply jancsika 1 hour agorootparentI wonder if that's large enough to contain an old linux running an old version of firefox and feed that the page content. reply uptownfunk 52 minutes agoparentprevWow it’s really bad. reply rufius 2 hours agoparentprevI mean it’s Notion. That’s par for the course. What if your text editing and presentation experience was slow and laggy? That’s Notion. reply ishtanbul 22 minutes agorootparentWhats the best corporate wiki platform? reply yazzku 2 hours agorootparentprevNotion. Delivering value right at your fingertips. reply deadbabe 1 hour agoparentprevThat’s why no one reads articles, just headlines. reply liontwist 2 hours agoprevThe cons/car/cdr implementation as lambda was magical the first time I saw it. But it just shows that the language runtime must implement key/value dictionaries and you are able to borrow that implementation to make other data structures. reply tasty_freeze 2 hours agoprevNeat article. But it was very difficult to navigate for me because 99% I use the keyboard up/down arrows to scroll the page as I'm reading. This page swallows those keystrokes, apparently. Page up/down work, but sometimes. I never use page up/down while reading because I'll be in the middle of a sentence of a paragraph at the bottom, hit page down, and now I need to scan my eyes back to the top of the page. First, it introduces a hiccup in the middle of a sentence, and secondly, because of the hiccup I often want to go back a line or two to reestablish context, but it is now offscreen. Grr. reply smusamashah 2 hours agoparentFor me it was \"Your browser is not compatible with Notion.\" on Android with Hack's (hacker news client) built in browser which is I guess just a stripped down Web view reply hyperbovine 2 hours agoprevReading this brings back fond memories of taking CS61a with prof Brian Harvey at UC Berkeley some 25 years ago. Same book, same level of mind=blown, and very similar instruction style. we spent a semester instead of a week and if memory serves tuition was about the same, but they threw in some English and history courses as well :-) reply ksd482 1 hour agoparentSame. For me it was 15 years ago, but was with Prof. Brian Harvey in Pimentel hall with the rotating stage. Nice memories. I fell in love with scheme eventually as it was such a simple syntax. Getting used to parentheses did take some time though. reply romanhn 1 hour agoparentprevSame memories, and even the same timeline :) I still recall being blown away by the concept of \"code is data\", the magic of which I haven't encountered in professional development, alas. reply bob1029 2 hours agoprevhttps://www.youtube.com/watch?v=PAZTIAfaNr8 reply vmilner 2 hours agoparentHe wrote my favourite maths book. https://www.cambridge.org/core/books/all-the-math-you-missed... https://m.youtube.com/watch?v=ur0UGCL6RWc reply rapnie 1 hour agoparentprevFellow is doing an aggressive function. I wouldn't dare put contrary functions against his output. reply qrush 2 hours agoparentprevthis guy has Chris Fleming energy. reply ysofunny 1 hour agoprevalternative take: everything is just sets both can be a foundation for mathematics, and hence, a foundation for everything what's interesting is how each choice affects what logic even means? reply WillAdams 3 hours agoprevThe book itself is currently being discussed at: https://news.ycombinator.com/item?id=42157558 Is there a reason why the link goes to the discussion at the bottom of that page rather than the beginning? Could this be folded into the other discussion? (I don't see that the link has been posted there yet) reply zetranrt 40 minutes agoprevDavid Beazley is using Scheme! That is a nice shift towards a civilized language. I hope he scraps the scheme-in-python section, but perhaps that is intended as an exit drug for Python addicts. reply pjmlp 2 hours agoprevActually it is more like Algorithms + Data Structures = Programs. reply fifilura 49 minutes agoprevSo an integer is represented by how deep in the stack you are? How do you represent an irregular float? reply marcosdumay 40 minutes agoparentProbably by using IEEE 754. What will make any function that uses floating point numbers mindblowing complex. But there's probably an easier way by creating some transformation from (Integer -> a) to (F64 -> a) so that only the transformation gets complex. Anyway, there are many reasons people don't write actual programs this way. reply behnamoh 2 hours agoprevShameless plug: https://aplaceofmind.notion.site/It-s-Lambdas-All-the-Way-Do... I got to the same conclusion a while ago, except that I found that it's lambdas all the way down. reply wslh 2 hours agoprev> Everything Is Just Functions... I'd iterate on that and say: everything is just languages and dialogues, with functions being one component of them. Over time, we’ve evolved from machine languages to higher-level ones, but most popular languages today still focus on the \"how\" rather than the \"what\". Programming paradigms, even those like functional and logic programming, requires the \"how\". My rant is this: the next major iteration(s) in programming languages should shift focus to the \"what\". By abstracting away the \"how\", we can reach a higher-order approach that emphasizes intent and outcomes over implementation details. I don't want to constrain this idea to Z3, LLMs, or low/no-code platforms, but rather to emphasize the spirit of the \"what\". It’s about enabling a mindset and tools that prioritize defining the goal, not the mechanics. I know this contradicts our work as software engineers where we thrive on the \"how\", but maybe that’s the point. By letting go of some of the control and complexity, we might unlock entirely new ways to build systems and solve problems. If I should be plain realistic, I'd say that in the middle, we need to evolve by mixing both worlds while keeping our eyes on a new horizon. reply SoftTalker 2 hours agoparent> programming languages should shift focus to the \"what\" SQL is an example of a language that is at least somewhat like that. SELECT foo WHERE bar = baz Doesn't really say \"how\" to do that, it only defines what you want. reply wslh 1 hour agorootparentIncorrect: you need to know the \"how\" to create more complex and optimal queries. Your example is like saying, in Python, you just need to write print(\"Hello World!\") to print something. reply moomin 5 minutes agorootparentThat’s every programming language abstraction. All of them break when you get a fair amount of complexity or performance requirements. reply fsndz 1 hour agoparentprevisn't that what declarative programming frameworks do already ? reply wslh 59 minutes agorootparentThey don't do it \"already\" but are one of the approaches taken. If you build state of the art web UI/UX you know that it is not just dragging and dropping objects on the screen while it is perfectly possible to build a tool like this. reply lupire 1 hour agorootparentprevYeah, but a new generation is coming of age, whose teachers only learned these ideas through books, not experience. They are rediscovering computer science one blog post or tweet at a time, because books and classes are obsolete. reply richrichie 2 hours agoprevHas anyone read the new SICP with Javascript as language of choice? reply easeout 1 hour agoparentI haven't, but you can compare editions with this SICP Comparison Edition: https://sicp.sourceacademy.org/ reply 0xpgm 2 hours agoparentprevIsn't scheme with close to zero syntax so easy to learn? Why did someone think it was a good idea to switch to JavaScript? I think the person who'll get value out of SICP will not have any problem picking up scheme syntax on the fly. reply liontwist 2 hours agorootparentI agree. Being self contained helps make it timeless. In contrast are books with a CD in the back with an outdated Java compiler you will never be able to setup. And then you have to migrate the snippets yourself. If you study any other related field like math or physics you become accustomed to learning a formal system for the context of a particular problem. CS students tend to have this weird careerist view where every page just directly help them get a job. reply SoftTalker 1 hour agorootparentMost undergrad CS students want a practical/engineering curriculum. They are not really there for theory, but for a long time that's how CS departments operated, unless maybe you were at an engineering school. Schools are so desperate to keep up enrollment numbers today that many have capitulated and are giving students what they want instead of what the faculty thinks they need. reply liontwist 49 minutes agorootparentThere is a big difference between being practically minded and the allergy to learning anything which doesn’t translate to resume keywords. SICP will teach you more about JavaScript, python, etc than most anything. reply tharne 1 hour agorootparentprev> Most undergrad CS students want a practical/engineering curriculum. If all someone wants is the practical benefits of programming and has no interest in the underlying theory, they shouldn't waste their their time and money on a CS degree. All the practical information is available for free or at very low cost. reply SoftTalker 1 hour agorootparentBut, a lot of employers demand a degree. reply tharne 20 minutes agorootparentMaybe so, but we shouldn't be doubling down on expensive and time consuming degrees in the name of ill-conceived credentialism. That hurts everyone except the universities profiting off of it. reply lupire 1 hour agorootparentprevThe same applies to CS, so you're missing something else -- skilled tutors and the campus experience. reply tharne 18 minutes agorootparentAt least in the U.S., many students are paying upwards of a $100k for a four-year degree. That better be one hell of a \"campus experience\" and some next-level \"skilled tutors\". Call me a hopeless optimist, but I think there's a better way out there. reply JTyQZSnP3cQGa8B 37 minutes agorootparentprev> They are not really there for theory Is that why they are so bad at adapting to foreign languages and frameworks? Maybe they should go back to the basics. reply lupire 1 hour agorootparentprevYou are comparing mathematicians to programmers. A more fair comparison is engineering or applied math major, not pure math at MIT. reply SoftTalker 1 hour agorootparentprevBecause knowing scheme isn't going to get you a job at most places. Employers overwhelmingly want JavaScript or Python these days. Trailing that would probably be Java, C++ and C#, and regular old C. When I did my undergrad CS degree, the fact that scheme was so heavily used was a common complaint they received from students. It just wasn't a marketable skill. reply Jtsummers 1 hour agorootparentFour year CS degrees usually require something around 20 (maybe even more) CS courses. Are you saying that all of those courses at your school were taught in Scheme? You never had a chance (in the classes, ignoring hobby or internships) to use other languages? That'd be a pretty unique school. But even if that were true and you did take 20+ classes in Scheme, you're still a college educated computer scientist. You can't pick up JavaScript or Python in time for a job interview for an entry level job? They're easy languages to learn. If you survived four years of exclusively being taught with Scheme, they'd be a breeze to pick up. reply SoftTalker 36 minutes agorootparentNo not all scheme. That's an example. The intro course and programming languages course was scheme. There were a number of other languages used. I guess I should have been more nuanced in that a number of students wanted to be taught the currently popular progrmmming languages so they could use them on a resume. They complained about using scheme (or whatever \"teaching\" language a professor might require) and did not yet appreciate that the concepts/theory they were learning applied to any programming language they might need to use. They wanted a trade school/practical education in something immediately marketable, not a theoretical education. The reason I remember this is that in my \"exit interview\" as a senior I mentioned that I appreciated the exposure to these languages and theory and my advisor remarked \"we don't hear that very often, the usual feedback is that we don't teach the languages employers want\" reply wrycoder 2 hours agoparentprevYes. But, I prefer the regularity of the Lisp syntax. reply revskill 1 hour agoprevI think it's a cool book for students. But for real world programming, the tedious ones is related to validation, parsing and other business logic. So i prefer a book to help teach CS by using real world codebase to solve real world everyday problem as a software engineer instead. You can have your cake and eat it. reply lupire 1 hour agoparentThat's like teaching physics via car repair. You'll learn a few ideas, but not much of the science. It's practical and productive and profitable, which is great, but not really the original goal. reply revskill 1 hour agorootparentIt's not a surprise that most of students failed and hate abstract algebra right ? I mean to learn the concept, you will need to know more about the concept itself in a real world context. reply cess11 1 hour agoparentprevSICP shows a real world code base. It's real world programs that builds up to implementing real world programming languages. Why would you validate if you can parse? If you have a decent chunk of experience in implementing business logic then you know that your quality of life will be destroyed by switches and other inscrutable wormhole techniques up until the point where you learn to use and build around rule engines. SICP shows you how you can tailor your own rule engine, so you won't have to get the gorilla and the jungle when you reach for one in an enterprisey library. reply blackeyeblitzar 1 hour agoprev [–] A computer fundamentally isn’t functions though. That’s not how a processor works. If functions are a useful abstraction, why haven’t functional languages taken off? reply doublepg23 20 minutes agoparent [–] It seems functional language experts are too busy rewriting SICP instead of actually useful programs. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "David Beazley's SICP (Structure and Interpretation of Computer Programs) course in late 2022 provided deep insights into computation, similar to understanding compilers.",
      "The course involved building a simple computation model using Scheme, a Lisp dialect, and creating a Scheme interpreter in Python, enhancing understanding of language commonalities.",
      "Racket, a Scheme variant, was used for its ease of setup, covering basics like integers, operations, and special forms such as 'define' for variable assignment."
    ],
    "commentSummary": [
      "The article explores encoding state as pure functions, drawing insights from SICP (Structure and Interpretation of Computer Programs) and David Beazley, with a focus on functional programming.",
      "It uses a JavaScript example of the Maybe monad to illustrate the elegance of functional encodings for various data types.",
      "The discussion critiques the Notion platform for performance and navigation issues, while also reflecting on the educational value of SICP and the practicality of functional programming in real-world applications."
    ],
    "points": 155,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1731856030
  },
  {
    "id": 42163597,
    "title": "Bpftune uses BPF to auto-tune Linux systems",
    "originLink": "https://github.com/oracle/bpftune",
    "originBody": "bpftune - BPF driven auto-tuning bpftune aims to provide lightweight, always-on auto-tuning of system behaviour. The key benefit it provides are by using BPF observability features, we can continuously monitor and adjust system behaviour because we can observe system behaviour at a fine grain (rather than using coarse system-wide stats), we can tune at a finer grain too (individual socket policies, individual device policies etc) The problem The Linux kernel contains a large number of tunables; these often take the form of sysctl(8) parameters, and are usually introduced for situations where there is no one \"right\" answer for a configuration choice. The number of tunables available is quite daunting. On a 6.2 kernel we see # sysctl --all 2>/dev/null|wc -l 1624 See here for an excellent writeup on network-related tunables.. At the same time, individual systems get a lot less care and adminstrator attention than they used to; phrases like \"cattle not pets\" exemplify this. Given the modern cloud architectures used for most deployments, most systems never have any human adminstrator interaction after initial provisioning; in fact given the scale requirements, this is often an explicit design goal - \"no ssh'ing in!\". These two observations are not unrelated; in an earlier era of fewer, larger systems, tuning by administrators was more feasible. These trends - system complexity combined with minimal admin interaction suggest a rethink in terms of tunable management. A lot of lore accumulates around these tunables, and to help clarify why we developed bpftune, we will use a straw-man version of the approach taken with tunables: \"find the set of magic numbers that will work for the system forever\" This is obviously a caricature of how administrators approach the problem, but it does highlight a critical implicit assumption - that systems are static. And that gets to the \"BPF\" in bpftune; BPF provides means to carry out low-overhead observability of systems. So not only can we observe the system and tune appropriately, we can also observe the effect of that tuning and re-tune if necessary. Key design principles Minimize overhead. Use observability features sparingly; do not trace very high frequency events. Be explicit about policy changes providing both a \"what\" - what change was made - and a \"why\" - how does it help? syslog logging makes policy actions explicit with explanations Get out of the way of the administrator. We can use BPF observability to see if the admin sets tunable values that we are auto-tuning; if they do, we need to get out of the way and disable auto-tuning of the related feature set. Don't replace tunables with more tunables! bpftune is designed to be zero configuration; there are no options, and we try to avoid magic numbers where possible. Use push-pull approaches. For example, with tcp buffer sizing, we often want to get out of the way of applications and bump up tcp sndbuf and rcvbuf, but at a certain point we run the risk of exhausting TCP memory. We can however monitor if we are approaching TCP memory pressure and if so we can tune down values that we've tuned up. In this way, we can let the system find a balance between providing resources and exhausting them. In some cases, we won't need to tune up values; they may be fine as they are. But in other cases these limits block optimal performance, and if they are raised safely - with awareness of global memory limits - we can get out the way of improved performance. Another concern is that increasing buffer size leads to latency - to handle that, we correlate buffer size changes and TCP smoothed round-trip time; if the correlation between these exceeds a threshold (0.7) we stop increasing buffer size. Concepts The key components are tuners: each tuner manages tunables and handles events sent from BPF programs to userspace via the shared ring buffer. Each tuner has an associated set of tunables that it manages. optional strategies: a tuner can specify multiple strategies; after running for a while a strategy times out and we assess if a better strategy is available. Each strategy specifies a name description timeout evaluation function set of BPF program names in tuner associated with strategy Strategies are optional and should be set in the tuner init() method via bpftune_strategies_add(). See test/strategy for a coded example. When a strategy times out, the various evaluation functions are called and the highest-value evaluation dictates the next stratgey. Strategies provide a way of providing multiple schemes for auto-tuning the same set of tunables, where the choice is guided by an evaluation of the effectiveness of the strategies. events specify a tuner id: which tuner the event is destined for a scenario: what happened an associated netns (if supported) information about the event (IP address etc) the tuner then responds to the event guided by the active strategy; increase or decrease a tunable value, etc. Describing the event in the log is key; this allows an admin to understand what changed and why. Architecture bpftune is a daemon which manages a set of .so plugin tuners; each of these is a shared object that is loaded on start-up. tuners can be enabled or disabled; a tuner is automatically disabled if the admin changes associated tunables manually. tuners share a global BPF ring buffer which allows posting of events from BPF programs to userspace. For example, if the sysctl tuner sees a systl being set, it posts an event. each tuner has an associated id (set when it is loaded), and events posted contain the tuner id. each tuner has a BPF component (built using a BPF skeleton) and a userspace component. The latter has init(), fini() and event_handler() entrypoints. When an event is received, the tuner id is used to identify the appropriate event handler and its event_handler() callback function is run. init, fini and event_handler functions are loaded from the tuner .so object. BPF components should include bpftune.bpf.h; it contains the common map definitions (ringbuf, etc) and shared variables such as learning rate and tuner ids that each tuner needs. Supported tuners TCP connection tuner: auto-tune choice of congestion control algorithm. See bpftune-tcp-conn (8). neighbour table tuner: auto-tune neighbour table sizes by growing tables when approaching full. See bpftune-neigh (8). route table tuner: auto-tune route table size by growing tables when approaching full. See bpftune-route (8). sysctl tuner: monitor sysctl setting and if it collides with an auto-tuned sysctl value, disable the associated tuner. See bpftune-sysctl (8). TCP buffer tuner: auto-tune max and initial buffer sizes. See bpftune-tcp-buffer (8). net buffer tuner: auto-tune tunables related to core networking. See bpftune-net-buffer (8). netns tuner: notices addition and removal of network namespaces, which helps power namespace awareness for bpftune as a whole. Namespace awareness is important as we want to be able to auto-tune containers also. See bpftune-netns (8). Code organization Both core bpftune.c and individual tuners use the libbpftune library. It handles logging, tuner init/fini, and BPF init/fini. Each tuner shared object defines an init(), fini() and event_handler() function. These respectively set up and clean up BPF and handle events that originate from the BPF code. Getting Started If building the repository manually, simply run $ make ; sudo make install at the top-level of the repository. bpftune also supports a $ make pkg target, which will make a bpftune RPM. See ./buildrpm/bpftune.spec We can also build with non-standard libdir for distros which do not use /usr/lib64 like CachyOS; in this case to install to /usr/lib instead $ make libdir=lib $ sudo make install libdir=lib To build the following packages are needed (names may vary by distro); libbpf, libbpf-devel >= 0.6 libcap-devel bpftool >= 4.18 libnl3-devel clang >= 11 llvm >= 11 python3-docutils From the kernel side, the kernel needs to support BPF ring buffer (around the 5.6 kernel, though 5.4 is supported on Oracle Linux as ring buffer support was backported), and kernel BTF is required (CONFIG_DEBUG_INFO_BTF=y). Verify /sys/kernel/btf/vmlinux is present. To enable bpftune as a service $ sudo service bpftune start ...and to enable it by default $ sudo systemctl enable bpftune bpftune logs to syslog so /var/log/messages will contain details of any tuning carried out. bpftune can also be run in the foreground as a program; to redirect output to stdout/stderr, run $ sudo bpftune -s On exit, bpftune will summarize any tuning done. Tests Tests are supplied for each tuner in the tests/ subdirectory. \"make test\" runs all the tests. Tests use network namespaces to simulate interactions with remote hosts. See ./TESTING.md for more details. Does my system support bpftune? Simply run \"bpftune -S\" to see: $ bpftune -S bpftune works fully bpftune supports per-netns policy (via netns cookie) Two aspects are important here does the system support fentry/fexit etc? If so full support is likely. does the system support network namespace cookies? If so per-network-namespace policy is supported. Demo Simply starting bpftune and observing changes made via /var/log/messages can be instructive. For example, on a standard VM with sysctl defaults, I ran $ service bpftune start ...and went about normal development activities such as cloning git trees from upstream, building kernels, etc. From the log we see some of the adjustments bpftune made to accommodate these activities $ sudo grep bpftune /var/log/messages ... Apr 19 16:14:59 bpftest bpftune[2778]: bpftune works fully Apr 19 16:14:59 bpftest bpftune[2778]: bpftune supports per-netns policy (via netns cookie) Apr 19 16:18:40 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default Apr 19 16:18:40 bpftest bpftune[2778]: due to loss events for 145.40.68.75, specify 'bbr' congestion control algorithm Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 6291456) -> (4096 131072 7864320) Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 7864320) -> (4096 131072 9830400) Apr 19 16:29:04 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default Apr 19 16:29:04 bpftest bpftune[2778]: due to loss events for 140.91.12.81, specify 'bbr' congestion control algorithm To deterministically trigger bpftune behaviour, one approach we can take is to download a large file with inappropriate settings. In one window, set tcp rmem max to a too-low value, and run bpftune as a program logging to stdout/stderr (-s): $ sudo sysctl -w net.ipv4.tcp_rmem=\"4096 131072 1310720\" net.ipv4.tcp_rmem = 4096 131072 1310720 $ sudo bpftune -s In another window, wget a large file: $ wget https://yum.oracle.com/ISOS/OracleLinux/OL8/u7/x86_64/OracleLinux-R8-U7-x86_64-dvd.iso In the first window, we see bpftune tuning up rmem: bpftune: bpftune works in legacy mode bpftune: bpftune does not support per-netns policy (via netns cookie) bpftune: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput bpftune: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 1310720) -> (4096 131072 1638400) This occurs multiple times, and on exit (Ctrl+C) we see the summary of changes made: bpftune: Summary: scenario 'need to increase TCP buffer size(s)' occurred 9 times for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput bpftune: sysctl 'net.ipv4.tcp_rmem' changed from (4096 131072 1310720 ) -> (4096 131072 9765625 ) For more info See the docs/ subdirectory for manual pages covering bpftune and associated tuners. bpftune was presented at the eBPF summit; video here. bpftune was also discussed on Liz Rice's excellent eCHO eBPF podcast, specifically in the context of using reinforcement learning in BPF Contributing This project welcomes contributions from the community. Before submitting a pull request, please review our contribution guide Security Please consult the security guide for our responsible security vulnerability disclosure process License Copyright (c) 2023 Oracle and/or its affiliates. This software is available to you under SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note Being under the terms of the GNU General Public License version 2. SPDX-URL: https://spdx.org/licenses/GPL-2.0.html See the license file for more details.",
    "commentLink": "https://news.ycombinator.com/item?id=42163597",
    "commentBody": "Bpftune uses BPF to auto-tune Linux systems (github.com/oracle)148 points by BSDobelix 7 hours agohidepastfavorite32 comments gausswho 4 hours agoWith this tool I am wary that I'll encounter system issues that are dramatically more difficult to diagnose and troubleshoot because I'll have drifted from a standard distro configuration. And in ways I'm unaware of. Is this a reasonable hesitation? reply Twirrim 2 hours agoparentDisclaimer: I work for Oracle, who publish this tool, though I have nothing to do with the org or engineers that created it I've been running this for a while on my laptop. So far yet to see any particular weirdness, but also I don't know that I can state with any confidence it has a positive impact either. I've not carried out any benchmarks in either direction. It logs all changes that it's going to make including what they were on before. Here's an example from my logs: bpftune[1852994]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput bpftune[1852994]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 7864320) -> (4096 131072 9830400) reply pbhjpbhj 4 hours agoparentprev>\"bpftune logs to syslog so /var/log/messages will contain details of any tuning carried out.\" (from OP GitHub readme) The rmem example seems to allay fears that it will make changes one can't reverse. reply admax88qqq 4 hours agorootparentIt’s not a questions of being able to reverse. It’s a question of being able to diagnose that one of these changes even was the problem and if so which one. reply nehal3m 2 hours agorootparentIf they can be reversed individually you can simply deduce by rolling back changes one by one, no? reply spenczar5 1 hour agorootparentSuppose you run a fleet of a thousand machines. They all autotune. They are, lets say, serving cached video, or something. You notice that your aggregate error rate been drifting upwards since using bpftune. It turns out, in reality, there is some complex interaction between the tuning and your routers, or your TOR switches, or whatever - there is feedback that causes oscillations in a tuned value, swinging between too high and too low. Can you see how this is not a matter of simple deduction and rollbacks? This scenario is plausible. Autotuning generally has issues with feedback, since the overall system lacks control theoretic structure. And the premise here is that you use this to tune a large number of machines where individual admin is infeasible. reply jstanley 2 hours agorootparentprevOnly if you already suspect that this tool caused the problem. reply trelliscoded 3 hours agoparentprevIf your staging doesn’t do capacity checks in excess of what production sees, yes. reply sgarland 3 hours agoparentprevYes, it is. IMO, except for learning (which should not be done in prod), you shouldn’t make changes that you don’t understand. The tools seems to mostly tweak various networking settings. You could set up a test instance with monitoring, throw load at it, and change the parameters the tool modifies (one at a time!) to see how it reacts. reply nine_k 3 hours agorootparentI'd run such a tool on prod in \"advice mode\". It should suggest the tweaks, explaining the reasoning behind them, and listing the actions necessary to implement them. Then humans would decide if they want to implement that as is, partly, modified, or not at all. reply sgarland 3 hours agorootparentFair point, though I didn’t see any such option with this tool. reply nine_k 3 hours agorootparentIt's developed in the open; we can create Github issue. Actually https://github.com/oracle/bpftune/issues/99 reply klysm 1 hour agoprevThis seems to step into control theory, which I think is somewhat underapplied in software engineering. reply 6SixTy 33 minutes agoprevAs an insane Gentoo user, sign me the F*** up reply gmuslera 5 hours agoprevTwo words: “feedback loop”. That was the first idea that jumped in when thinking in what could go wrong, not because the Linux kernel, or BPF or this program, just for how it is intended to work. There might be no risk of that happening, there may be controls around that, or if they happen they might only converge to an estable state, but still it is something to have in the map. reply marcosdumay 4 hours agoparent> or if they happen they might only converge to an stable state That one will always be dependent on the usage patterns. So the auto-tuner can't guarantee it. Also, I imagine the risk of the feedback turning positive is related to the system load (not CPU, but the usage of the resources you are optimizing). If so, it will make your computer less able to manage load. But this can still be useful for optimizing for latency. reply bloopernova 7 hours agoprevFascinating! I'd like to hear from people who are running this. Is it effective? Worth the setup time? reply mrbluecoat 4 hours agoprev> bpftune is designed to be zero configuration; there are no options On behalf of every junior administrator, overworked IT admin, and security-concerned \"cattle\" wrangler, thank you. Having to learn a thousand+ knobs & dials means most will never be touched. I for one welcome automated assistance in this area, even if the results are imperfect. reply sgarland 3 hours agoparentI think it’s still important to know what those dials and knobs do, otherwise (as the currently top-voted comment says) when things break, you’ll be lost. reply usr1106 6 hours agoprevInteresting. But if tuning parameters to their best values were easy, shouldn't the kernel just do that in the first place? reply RandomThoughts3 6 hours agoparentI would reverse the question: if it can be done by a BPF module, why should it be in the kernel? Distributions turning it on by default is another story. Maybe it deserves to be shiped on all the time but that's not the same thing as being part of the kernel. reply jiehong 5 hours agorootparentIndeed! The kernel might already be too monolithic. This kernel parameters optimisation reminds me of PGO compilation in programs. Yet, perhaps the kernel could come with multiple defaults config files, each being a good base for different workloads: server, embedded, laptop, mobile, database, router, etc. reply sgarland 3 hours agoparentprevI’d rather the kernel present a good-enough but extremely stable set of configs. If I’m using a distro like Arch or Gentoo, then sure, maybe run wild (though both of those would probably assume I’m tuning them anyway), but CentOS, Debian, et al.? Stable and boring. If you change something, you’d better know what it is, and why you’re doing it. reply onetoo 6 hours agoparentprevThis doesn't necessarily find the best parameters, and it doesn't necessarily do it easily. From my reading, it will converge on a local optimum, and it may take some time to do that. In theory, I don't see why the kernel couldn't have a parameter-auto-tune similar to this. In practice, I think the kernel has to work in so many different domains, it'd be impossible to land on a \"globally good enough\" set of tuning heuristics. I'm far from a kernel developer, so I'm ready to be corrected here. IMO if we ever see something like this deployed widely, it will be because a popular distribution decided to install it by default. reply nitinreddy88 6 hours agoparentprevIt depends on workload. This tool generates recommended config for that specific machine workload. App Nodes can have completely different recommendations vs Database Nodes. It will be completely different for Workstation. reply usr1106 6 hours agorootparentSure, but the kernel could just do the same. Of course the kernel is already too big. Is BPF the right level to make it more modular? Just thinking, I don't think I have the answer. reply nevon 5 hours agoprevI wonder how effective this would be in multi-tenant environments like shared k8s clusters. On the one hand, each application running will have a different purpose and will move around between nodes over time, but on the other hand there are likely broad similarities between most applications. reply BSDobelix 6 hours agoprevBTW one can use it out of the box with CachyOS. After installation -> CachyOS Hello -> Apps/Tweaks reply robinhoodexe 6 hours agoprevIs tuning the TCP buffer size for instance worth it? reply viraptor 6 hours agoparentIt depends. At home - probably not. On a fleet of 2000 machines where you want to keep network utilisation close to 100% with maximal throughput, and the non-optional settings translate to a not-trivial value in $ - yes. reply londons_explore 4 hours agorootparentTCP parameters are a classic example of where an autotuner might bite you in the ass... Imagine your tuner keeps making the congestion control more aggressive, filling network links up to 99.99% to get more data through... But then any other users of the network see super high latency and packet loss and fail because the tuner isn't aware of anything it isn't specifically measuring - and it's just been told to make this one application run as fast as possible. reply bastloing 5 hours agoprev [–] It's great how it grew out of simple packet filtering into tracing and monitoring. It's one of those great tools most should know. Been using it for years. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "bpftune is a tool that uses BPF (Berkeley Packet Filter) to automatically adjust system settings, addressing the challenge of managing numerous Linux kernel tunables in cloud environments.- It operates with minimal overhead, logs policy changes, and respects administrator settings by disabling auto-tuning when necessary, using a push-pull approach to optimize resource allocation.- The tool is zero-configuration, includes various tuners for system components, and is licensed under GPL-2.0, supporting both service and foreground operation with logging to syslog."
    ],
    "commentSummary": [
      "Bpftune is a tool that uses BPF (Berkeley Packet Filter) to automatically optimize Linux systems, aiming for zero configuration and appealing to users who prefer automation.",
      "Some users are concerned about potential system issues due to deviations from standard configurations, highlighting the importance of understanding changes to diagnose problems effectively.",
      "The tool offers an \"advice mode\" to review suggested tweaks before implementation, providing a balance between automation and user control."
    ],
    "points": 148,
    "commentCount": 32,
    "retryCount": 0,
    "time": 1731843515
  },
  {
    "id": 42161223,
    "title": "Xogot – Godot for iPad",
    "originLink": "https://xogot.com/",
    "originBody": "Xogot Contact Docs Sign Up Introducing Xogot Godot for iPad Sign up for Preview Bringing Godot to the iPad Watch Miguel de Icaza's GodotCon 2024 presentation about the development of Xogot to learn more © 2024 Xibbon, Inc Xogot Docs TestFlight Signup Xibbon, Inc. Blog Privacy Policy Terms of Service Contact This website uses cookies Settings Reject All Accept All",
    "commentLink": "https://news.ycombinator.com/item?id=42161223",
    "commentBody": "Xogot – Godot for iPad (xogot.com)127 points by codetrotter 17 hours agohidepastfavorite32 comments terhechte 8 hours agoI've been wanting to learn Godot for some time now. Being able to develop on the iPad is supercool (for side-project game devs). In addition, you can also now run Godot on the Meta Quest (https://www.meta.com/en-gb/experiences/godot-game-engine/771...). Also, as Xogot runs on iPad and VisionOS can run iPad apps, it might even run there (haven't checked). That's a lot of fun platforms for playing around with it. reply mcraiha 12 hours agoprevThis is a project of Miguel de Icaza https://en.wikipedia.org/wiki/Miguel_de_Icaza reply pjmlp 11 hours agoparentYep, he switched focus after how everything went with Xamarin post acquisition, seems pretty much done with anything .NET. reply migueldeicaza 5 hours agorootparentI still use .net :-) But this port could not have been done with Xamarin due to the lack of SwiftUI integration. reply jeswin 9 hours agorootparentprevHe worked on Mono for nearly two decades, and contributed significantly to the platform. He may have stopped working on it because the platform is quite mature (and Open Source) and his continued work would have limited impact. reply pjmlp 8 hours agorootparentHere a couple of examples, https://visualstudiomagazine.com/Articles/2022/06/16/csharp-... Or its beloved Xamarin, \" Rewrites never go as planned. Xamarin.Forms turning into Maui was supposed to be a quick change, fueled by hopium so strong it defied gravity. Instead, at best, it set it back 2-3 years.\" https://x.com/migueldeicaza/status/1610665502598127616 You will find other juicy remarks, after the deadline to not speak about the acquisition expired. reply fmbb 6 hours agorootparentNever attribute to respect or sincerity that which can be adequately explained by contractual terms. reply somat 9 hours agoprevI am a bit surprised Apple allows it. I am not really familiar with the apple ecosystem, but my understanding is that they frown on open execution environments, that is emulators, virtual machines, interpreters etc. and a system that lets anyone develop and load games sounds like just that. reply migueldeicaza 4 hours agoparentThe terms have changed gradually over the years and now we are boiling IDEs on the iPad. My plan is to ship something that is both a great iPadOS app and operates within the confines of the AppStore restrictions. I find restrictions as a powerful motivator to think about a problem differently. Lots of great art (and software) is great when it explores and brings to light what’s possible with the limitations of a medium. reply michael-online 3 hours agorootparentI love the spirit here, but the limitations on iOS are not the limitations of the medium. Mobile computing has lots of interesting and inspiring limitations, we don't need apple to draw artificial squircles we can't cross in an api. reply dartos 2 hours agorootparentUsers seem to like those squircles, judging by the popularity of Apple products. It’s not a fun walled garden to be a creative developer in. reply dagmx 4 hours agoparentprevThey allow execution environments and have for many years. See pythonista etc They haven’t allowed emulators till this year, but Xodot isn’t an emulator. But what you’re likely thinking of with regards to execution is that they don’t allow creating new executable code. Ie no JIT or compilers, but interpreters are fine. Hence you can do GDScript (which runs in an interpreter like Python does) but you won’t be able to use the other language backends which compile down. reply jezek2 7 hours agoparentprevProgramming languages (IDEs) were always allowed as long as the code couldn't be downloaded from the internet. Local or cloud load/save is OK. An user copying it manually using a clipboard from a web page is OK as that's user doing. But direct downloading was a no-no. This was explained as to prevent any application from becoming AppStore-like. There are some tricks, like using curlsh approach by the user for UNIX-like environments, or similar things for Python IDEs. But again it is something that the user have to do and learn about it from an outside source. reply stavros 6 hours agorootparentI wonder if Apple will allow code downloading in the EU, now that they have to allow alternate app stores anyway. reply dtgriscom 5 hours agorootparent... what's in it for Apple? It would just make their lives more complicated. reply cultofmetatron 8 hours agoparentprevthey have emulators in the app store now! reply rcarmo 9 hours agoprevThis is very impressive, and runs well even on an iPad mini 5. reply sharkjacobs 11 hours agoprevI’ve been following the development of this via Miguel’s blog and mastodon, and as someone who is really interested in iPad development and app design I really want to try it out but I just don’t have time for another hobby. I’m signing up and gonna try it out, but I feel like I’ll need to put more than an afternoon of dabbling to get anywhere interesting. reply Funes- 3 hours agoprevI wonder if Redot [1] is going to fork this project, as well. [1]: https://github.com/Redot-Engine. reply dartos 2 hours agoparentI don’t think this project is open source. reply wejick 11 hours agoprevImpressive, happy to see another touch from Miguel. reply blackeyeblitzar 15 hours agoprev [12 more] [flagged] CJefferson 15 hours agoparentIt was massively overblown. Godot is fine. Redot has none of the main godot developers. The ended up with 10x more controversy on their own discord, than on the official Godot one. I just had a quick look at their github, and almost everything is just merging PRs from standard Godot. Either they will stay close enough to the standard code they can keep merging (in which case, why exist?), or they will eventually start getting more different, in which case they are going to need a lot more developers to do anything useful. Look at this post about their latest \"beta release\", they are just linking to the godot PRs they merged: https://www.reddit.com/r/RedotGameEngineMain/comments/1gisaz... reply zanderwohl 14 hours agoparentprevWhen software projects fork for petty ideological reasons, they fail. None of the skilled developers moved over to Redot. Godot continues to get support and features. Redot still can't figure out how to refactor the code to remove references to Godot. reply rbits 14 hours agoparentprev [–] Godot is fine. This was their statement https://x.com/godotfoundation/status/1840721449364988300?t=S... Basically they made a post showing support for LGBT+, and they got a bunch of harrassment so they banned people. Also what were the political tirades and banned contributors? reply darylteo 14 hours agorootparentAgreed. For more detail, I trust Thor@PirateSoftware https://www.youtube.com/watch?v=PTxyu_p1qkc reply blackeyeblitzar 14 hours agorootparentprevnext [6 more] [flagged] zanderwohl 14 hours agorootparentIt seems like you follow it closely enough to have a strongly-biased opinion. reply monkeywork 13 hours agorootparentRather than do snipe comments can you dispute or show where this person is misrepresenting what happened for the rest of us reply sharkjacobs 11 hours agorootparent> And then there was more controversy in their discord, which they later falsely claimed was the “unofficial” discord even though it was listed on the community part of their website and run by their social media people There are two discords linked from the community section[1], one of them is listed under “Official communities” and the other under “User-supported communities”. The discord in question is the latter, the unofficial one. [1]: https://godotengine.org/community/ reply monkeywork 7 hours agorootparent>There are two discords linked from the community section[1], one of them is listed under “Official communities” and the other under “User-supported communities”. The discord in question is the latter, the unofficial one. I went and looked on the way back machine—that only became true in July of this year; prior to that, the user support community's Discord was marked as the official one. https://web.archive.org/web/20240629163842/https://godotengi... reply sharkjacobs 43 minutes agorootparentDo you think that blackeyeblitzar was mistaken about that being the official Discord because they were referring to an out of date version of the Community page dating back more than 4 months ago? reply ClassyJacket 14 hours agorootparentprev [3 more] [flagged] bean-weevil 14 hours agorootparent [–] You should try meeting some trans people in real life. I think it would change your perspective a lot. reply kstrauser 13 hours agorootparent [–] I wouldn’t inflict them on the trans people I know. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Xogot Godot, a new application, is now available for iPad, with a preview sign-up option for interested users.",
      "Miguel de Icaza will present at GodotCon 2024, providing insights into the application and its features."
    ],
    "commentSummary": [
      "Xogot is a version of the Godot game engine tailored for iPad, enabling game development directly on the device, created by Miguel de Icaza, known for Mono and Xamarin.",
      "The application can also operate on Meta Quest and potentially VisionOS, reflecting Apple's updated policies that now allow such development environments on iOS, albeit with certain restrictions.",
      "Xogot is not open source, sparking discussions about its impact and comparisons to similar projects like Redot."
    ],
    "points": 127,
    "commentCount": 32,
    "retryCount": 0,
    "time": 1731807122
  },
  {
    "id": 42160716,
    "title": "Effect of a giant meteorite impact on Paleoarchean environment and life",
    "originLink": "https://www.chemistryworld.com/news/meteorite-200-times-larger-than-one-that-killed-dinosaurs-reset-early-life/4020391.article",
    "originBody": "Skip to main content Skip to navigation Extras Newsletters Jobs Reading room Puzzles Publishing Education Membership CELEBRATING TWENTY YEARS Mast navigation Sign In Register Subscribe Search our site Search our site Search Menu Close menu Home News Research Industry Opinion Features Culture Careers Podcasts Webinars Collections Back to parent navigation item Collections Solutions for India's sustainability challenge The future of analytical chemistry Chemistry of the brain Water and the environment Chemical bonding Antimicrobial resistance Energy storage and batteries AI and automation Sustainability Research culture Nobel prize Food science and cookery Plastics and polymers Periodic table Coronavirus Members More navigation items Home News Research Industry Opinion Features Culture Careers Podcasts Webinars Collections Solutions for India's sustainability challenge The future of analytical chemistry Chemistry of the brain Water and the environment Chemical bonding Antimicrobial resistance Energy storage and batteries AI and automation Sustainability Research culture Nobel prize Food science and cookery Plastics and polymers Periodic table Coronavirus Members News Meteorite 200 times larger than one that killed dinosaurs reset early life By Anthony King23 October 2024 No comments A giant meteorite that slammed into Earth over 3 billion years ago devastated early microbial life in the oceans, but also freed up a nutrient bonanza. Source: © Getty Images Life showed extraordinary resilience in surviving the impact of a meteorite 3.26 billion years ago that was far larger than the one that killed the dinosaurs This meteorite was far larger than the infamous Cretaceous era ending one. ‘We’re looking at a bolide that was 500 to 200 times bigger than the one that killed off the dinosaurs,’ says Nadja Drabon, a geologist at Harvard University. The Archean eon 2.5–4 billion years ago suffered at least 16 major impacts by meteorites upwards of 10km across. Each would have vaporised enough rock to darken the ancient skies for years. Drabon’s group say the impact 3.26 billion years ago triggered a giant tsunami, as well as clouding the oceans and darkening the skies for years to decades. The impact also evaporated tens of metres of seawater. Yet there was a silver lining: the churning of the seas brought bioavailable iron up from the ocean depths to its depleted surface and allowed some microbes to flourish, while the meteorite also brought phosphorus vital for life. Drabon and her colleagues went in search of evidence of ancient major impacts in a remote area south of Kruger National Park in South Africa. There they sought out rocky outcrops containing a layer of spherules – molten droplets formed following a major meteorite impact that rained down over huge swathes of the planet. There are eight such spherule bands in this area, each preserving an ancient impact event. While the impact crater itself is long gone, analysis of rocks from 3.26 billion years ago tells a tale of planetary devastation. The layer of spherules from this huge impact was 15 to 20cm thick in places, compared with less than a centimetre for the famed dinosaur-killing meteorite, says Drabon. These ancient droplets contain spikes in iridium and chromium isotope anomalies, revealing their extraterrestrial origins. The glassy spherules were mixed into ripped-up seafloor materials, thought to be the result of gigantic tsunamis. m Source: © 2024 Nadja Drabon et al The meteorite churned up bioavailable iron that microorganisms recovering from the impact were able to make use of Above this layer are younger iron-rich rocks and minerals such as siderite and pyrite. ‘After the impact, we suddenly see a spike in iron in the sediment,’ says Drabon. This influx likely came from the deep ocean. The geologists also found a phosphorus spike after impact, calculating that the meteorite could have delivered 363 billion tonnes in a reduced and, therefore, bioavailable state. Tellingly, the group also saw a change in the carbon isotope signature above the impact layer that they interpret as a rise in microbes with metabolism geared towards efficient iron cycling. This indicates a rebound of microbial life, perhaps within a few years to decades, the investigators conclude. The group reason that, following the impact, the iron-metabolising microbes would have consumed the newly available Fe2+ in the shallow seas, transforming it to Fe3+, which would sink to the ocean floor as iron hydroxides. ‘Their argument is very compelling, with many different lines of evidence,’ says Alexandra Davatzes, a geologist at Temple University in Philadelphia, who was not part of the study. ‘We’re in a totally microbial world in the Archean and the potential for recovery would be much, much faster than today.’ This bounce back could have happened repeatedly. ‘Initially large bolide impacts might have killed off a lot of microbial activity on Earth’s surface and in shallow waters, but then have been good for microbial activity, especially in shallow water environments,’ says Ronny Schönberg, a geochemist at the University of Tübingen, Germany who was not part of the research. It might even shift how we view meteorite hits on early Earth. ‘Everyone associates big impacts with the extinction of the dinosaurs and thinks of them as disastrous,’ says Drabon. ‘But they also carried a lot of transient benefits for the early and evolving biosphere.’ References N Drabon et al, Proc. Natl. Acad. Sci. USA, 2024, DOI: 10.1073/pnas.2408721121 Anthony King Follow I am a freelance science journalist based in Dublin, Ireland. I cover a variety of topics in chemical and biological sciences, as well as science policy, health and innovation.View full profile More Anthony King The race to commercialise nuclear-powered batteries Adnoc to buy Covestro, continuing expansion into polymers Drug companies reluctantly accept state price negotiations Topics dinosaurs Environmental Meteorite Planetary science Space No comments Related articles Feature The race to build a base on the moon 22 May 2023 08:45 By Nina Notman Opinion Analysing the Winchcombe meteor fireball 28 February 2023 14:12 By Derek Robson News The most complete list ever of Martian organic compounds compiled 19 January 2023 11:00 By Rebecca Trager Research Mars’ water came from outer space 18 November 2022 09:54 By James Urquhart Feature A lightning burst of chemistry 12 July 2022 09:57 By James Mitchell Crow Research All of life’s nucleic acids could have extraterrestrial origins 27 April 2022 13:45 By Anthony King Load more articles No comments yet You're not signed in. To link your comment to your profile, sign in now. Only registered users can comment on this article. Sign in Register More News News Gadolinium, lutetium and zirconium all have new atomic weights 15 November 2024 10:17 By Rupali Dabas News New recommendations to assist UK move away from animals in chemical safety assessments 15 November 2024 10:17 By Julia Robinson Research AI robots work together to perform autonomous synthesis and analysis 14 November 2024 14:30 By Rupali Dabas Business Shell appeal overturns ruling enforcing faster emissions cuts 14 November 2024 13:11 By Angeli Mehta Research Tomato sweetness boosted by gene editing to knock out two genes 14 November 2024 09:30 By Rupali Dabas News Dirty secret of mysterious ‘tar balls’ washed up on Sydney’s shores uncovered 13 November 2024 14:30 By Julia Robinson Load more articles Subscribe Advertise Topics Issues Contributors RSS Help Contact Privacy Cookies Terms of use Accessibility Permissions Our mission News and events Campaigns Awards and funding Global challenges Support our work © Royal Society of Chemistry 2024Registered charity number: 207890 Site powered by Webvision Cloud",
    "commentLink": "https://news.ycombinator.com/item?id=42160716",
    "commentBody": "Effect of a giant meteorite impact on Paleoarchean environment and life (chemistryworld.com)126 points by kristianp 18 hours agohidepastfavorite48 comments dang 14 hours agoThe paper is at https://www.pnas.org/doi/10.1073/pnas.2408721121. We've adopted its title above. kevinkeller 17 hours agoprevI love this type of articles where we can reconstruct what happened so long ago just based on careful observations. Some other instances I've come across: * The K-Pg extinction event that wiped off dinosaurs had the impact it did because the asteroid happened to impact a shallow water region. This kicked up a lot of sulfur (in gypsum) that further affected global climate: https://en.wikipedia.org/wiki/Chicxulub_crater#Effects * Earth likely had rings ~466M years ago. We deduced this by looking at impact craters from that time period, and seeing that they all lie near the equator (accounting for continental drift): https://www.sciencedirect.com/science/article/pii/S0012821X2... * Earth's rotation period was probably frozen at 21h, ~600M years ago, likely due to interaction between lunar and solar tides. This resonance could have been broken by ice ages (!!!). Amazing to think that global climate affects earth's rotation: https://en.wikipedia.org/wiki/Earth%27s_rotation#Resonant_st... reply thangalin 16 hours agoparent> reconstruct what happened so long ago just based on careful observations. Me too! My book is filled with them. Like how minerals in lava, affected by Earth's magnetic field, lock into place while cooling, which provides us with yet another cross-check for radiometric dating. See page 23: https://impacts.to/downloads/lowres/impacts.pdf reply datameta 3 hours agoparentprevHere is the Chixculub impact effect in realtime simulated as happening in today's world: https://youtu.be/ya3w1bvaxaQ?si=S-jmFegMo63HKzID reply chiefalchemist 15 hours agoparentprevNot to nitpick but the dinosaurs were on already on the way out, the asteroid merely finished them off early. https://www.theatlantic.com/magazine/archive/2018/09/dinosau... reply Arech 10 hours agorootparentTo the best of my knowledge not everyone agrees to that hypothesis. One of the strongest arguments against it is that paleontological evidence is always incomplete. Holes in it that are treated in favor of the hypothesis are actually smaller or comparable to holes that appear just due to incompleteness. reply Timwi 7 hours agoparentprevThe dinosaurs were not “wiped off”, by which I mean they are not extinct. This is an extremely widespread misconception that popular science articles like this one keep perpetuating. We should do better and help people understand that (some) dinosaurs survived and evolved into modern birds. Birds are dinosaurs. Dinosaurs are alive today. reply asah 4 hours agorootparenthttps://www.google.com/search?q=bike+shedding reply Qem 6 hours agorootparentprevWhen referring to dinosaurs, most people are thinking about non-avian, teethed dinosaurs anyway. reply Timwi 7 hours agoprevThe article perpetuates the widespread misconception that dinosaurs are extinct. In reality, (some) dinosaurs survived and evolved into modern birds. Everything from penguins to ostriches, hummingbirds to albatrosses and woodpeckers to eagles is a dinosaur. Science communication should do better and clear up this misunderstanding. It would be so much cooler to say that the asteroid killed the pterosaurs. Not only is it factually correct, it also opens doors to more curiosity. Why do they say pterosaurs instead of dinosaurs? Turns out they are separate clades. The pterosaurs, plesiosaurs and mosasaurs are all extinct as best as we can tell. The dinosaurs are not. reply jvanderbot 4 hours agoparentThis is fascinating. Although I'm having trouble mapping your comment onto this: https://opengeology.org/historicalgeology/case-studies/dinos... What is the complete set and which are extinct? reply bregma 7 hours agoparentprevDinosaurs are delicious. They taste like chicken. reply pier25 4 hours agorootparentProof we live in a simulation. Everything tastes like chicken! reply 1970-01-01 16 hours agoprevVote for Giant Meteor 2028! https://votegiantmeteor.com/ reply hehehheh 16 hours agoprevWhen is the next one coming? Or what is the probability distributuon like? reply patrickthebold 16 hours agoparentIt's a poisson distribution. reply nverno 15 hours agorootparentI imagine it is more of an exponential decay mixed with poisson since strikes were far more common back in the day. Also, I'd guess an exponential decay in the expected size of impactors over time as they've been smashing themselves into pieces. reply Arech 10 hours agorootparentprevLikely it isn't, because the Solar system today and 3Bln years ago are two very different systems. reply dataflow 15 hours agorootparentprevHave the data actually been fit a Poisson distribution? Or is this is just a guess assuming constant rate and independence? reply glial 15 hours agorootparentNo natural phenomena ever exactly fits any probability distribution. reply Q_is_4_Quantum 14 hours agorootparentexcept the emission spectra from atoms :) reply dataflow 15 hours agorootparentprevRight but I'm saying do we have data showing it's even close? (Genuinely asking, I have no idea.) reply jeffbee 16 hours agoprevThe paper also mentions that, at the time, \"dinosaur killer\"-sized objects hit the Earth every 15 million years on average, which must have been sort of disruptive. reply kevinkeller 16 hours agoparentLikely due to this: https://en.wikipedia.org/wiki/Late_Heavy_Bombardment reply jeffbee 16 hours agorootparentWhat these authors claimed recently was that prior LHB estimates were low by a large factor. https://www.nature.com/articles/s41561-021-00835-9 reply kevinkeller 16 hours agorootparentThanks for the paper link! reply EGreg 18 hours agoprev [–] [flagged] dan353hehe 18 hours agoparent> Drabon and her colleagues went in search of evidence of ancient major impacts in a remote area south of Kruger National Park in South Africa. There they sought out rocky outcrops containing a layer of spherules – molten droplets formed following a major meteorite impact that rained down over huge swathes of the planet. There are eight such spherule bands in this area, each preserving an ancient impact event. > While the impact crater itself is long gone, analysis of rocks from 3.26 billion years ago tells a tale of planetary devastation. The layer of spherules from this huge impact was 15 to 20cm thick in places, compared with less than a centimetre for the famed dinosaur-killing meteorite, says Drabon. reply EGreg 16 hours agorootparent[flagged] mmooss 16 hours agorootparent> it's just a theory that tries to fit this data What do you feel is missing? You might find that if you read the paper, it goes through the evidence, prior evidence, and their hypothesis. reply andrewflnr 16 hours agorootparentprev> Yeah, but it's just a theory that tries to fit this data. Doesn't mean it is correct. Yes. What else do you expect from science, or really from any human attempt to find truth? Are you just upset they don't include the caveat \"subject to potential future evidence or better theories\" on literally every single piece of science journalism? Are you upset that people do their best to make sense of weird situations and then tell people about their work, even if it's not absolute truth? What do you want to happen here? reply drdaeman 15 hours agorootparentprevI hope that your reaction is because the headline is way more sensational (to the extent of probably being incorrect) than the actual paper's abstract (https://www.pnas.org/doi/10.1073/pnas.2408721121) Here's what the actual paper says: > [...] Thus, the S2 impact likely had regional, if not global, positive and negative effects on life. The tsunami, atmospheric heating, and darkness would likely have decimated phototrophic microbes in the shallow water column. However, the biosphere likely recovered rapidly, and, in the medium term, the increase in nutrients and iron likely facilitated microbial blooms, especially of iron-cycling microbes. Which sounds and - if I understand it correctly - means something kinda different than how \"reset early life\" is ordinarily understood, huh. reply EGreg 14 hours agorootparentnext [2 more] [flagged] dang 14 hours agorootparentPlease don't take the bait. It's fine to let us know when a headline is sensational/distorted so we can change it. It's not fine to take to the comments about it, because that is likely to produce a shallow and less interesting discussion, which is what happened here. Edit: I've changed the title to that of the paper. reply _moof 15 hours agorootparentprevHave you got a better theory that fits all available data and has predictive power? reply tracerbulletx 17 hours agoparentprevPublications are institutionally incapable of publishing an article (and readers incapable of appreciating) that says, A Paper Investigates How Early Archean Impacts Might Have Possibly Affected The Development of Nascent Life reply mmooss 16 hours agoparentprevThe purpose of scientific papers is to explain that, starting with observations. reply animex 17 hours agoparentprevnext [2 more] [flagged] tengbretson 16 hours agorootparentYep. Good ol' observing, questioning, hypothesizing, experimenting, analyzing and concluding. reply iambateman 16 hours agoparentprev [–] The downvotes are misplaced. This is a good question. The value of HN is when people-who-know help curious folks understand the validity of a story. Surely someone here is more capable of assessing this story and I agree that skepticism is in order at first. reply phalangion 16 hours agorootparentExcept the article explains in fairly easy to understand terms how the study came to this theory, and the original paper is linked from that article. The question here gives the impression that the asker read only the headline. reply _moof 15 hours agorootparentprevThe downvotes are because people are reading the question as rhetorical rather than being asked out of genuine curiosity. It's only a good question if the person asking it is doing so with an open mind. (That and the article answers the question.) reply bulatb 15 hours agorootparentprev [10 more] Skepticism should begin with the skeptic's own motives. A skeptic's second question (after \"Really?\" or \"Why?\") should be, \"Why am I asking?\" Do they want to test the claim to learn something, or to dismiss it, just to dismiss it? If they're asking questions which are literally answered as part of the claim, they need to start over, and start with themselves. reply aspenmayer 14 hours agorootparent> Sealioning (also sea-lioning and sea lioning) is a type of trolling or harassment that consists of pursuing people with relentless requests for evidence, often tangential or previously addressed, while maintaining a pretense of civility and sincerity (\"I'm just trying to have a debate\"), and feigning ignorance of the subject matter. It may take the form of \"incessant, bad-faith invitations to engage in debate\", and has been likened to a denial-of-service attack targeted at human beings. The term originated with a 2014 strip of the webcomic Wondermark by David Malki, which The Independent called \"the most apt description of Twitter you'll ever see\". https://en.wikipedia.org/wiki/Sealioning The comic strip in question is actually adorably absurd: http://wondermark.com/1k62/ reply dan353hehe 14 hours agorootparentThank you! I have been trying to remember the name for that comic for years, and no amount of searching has ever yielded anything. reply aspenmayer 14 hours agorootparentAww! I love that for you. Finding things people are searching for is a bit of a hobby of mine, so I’m happy I was able to have helped you. reply iambateman 15 hours agorootparentprev [–] The article claims that 363 billion tons of phosphorous were dropped on earth 3.26 billion years ago during a decade of darkness. I’m completely incapable of making sense of that claim because it’s so far outside of my expertise. But my fundamental problem is that I don’t trust the source’s incentives to deliver reliable information and I want someone independent to help me understand if this is a how strong or weak this science is. And my starting point for that is “it’s very hard to know anything specific about the deep past. And I’m tired of scientific retractions.” reply defrost 15 hours agorootparentThere's no one stop shop for instantly correct science, think less about retractions and more about incremental advances toward better understanding. > The article claims that 363 billion tons of phosphorous were dropped on earth 3.26 billion years ago The article correctly reports that a series of papers claim that a bolide (large mass) of an estimated diameter of 37 to 58 km across impacted some time ago. There's a slew of paths forward for anyone interested in knowing more and questioning these claims. The 96 references cover such things as estimating the impact crater, spray field, and impactor size. You might want estimate for yourself the mass of a spherical cow some 40km in diameter if the material were to be (say) nickel iron .. and then perhaps back of the envelope determine what fraction of that would 363 billion tonne be. It may or may not help to know that W.Australia move a billion tonne of iron ore per annum, that's a certain volume of mesa uprooted and moved to China, and 363 years of that would be a similar mass and volume. This goes to having a feel for the paper's methodology in estimating P mass. You may also wish to review papers and books on the K-Pg bolide, the one that \"killed the dinosaurs\" which is estimated to be some ~50 to 200 times smaller by mass than the one discussed here. There's also a body of work on theories of planet formation via big rocks smashing into each other, sticking together, and planets slowing growing as stray rocks get hoovered up. reply bulatb 13 hours agorootparentprevI meant that \"you\" like the general you, not iambateman you. Sorry if that wasn't clear. I couldn't figure out a better phrasing at the time. Hopefully it's better now. I'm nobody to lecture people. I don't matter. I just really dislike seeing epistemic nihilism framed as skepticism, and that's the vibe I was getting from the top of the thread. Science is the proven process for investigating nature while dealing with questions like \"What if you're wrong about everything?\" The comment at the top reads, out of context, like an absolutely wild example of someone asking, \"What if you're wrong?\" as if it's something new that's never been asked. reply rcyeh 14 hours agorootparentprevJust going through the numbers: 363 BB tons / (1 ton / cu m) / (1 BB cu m / cu km) is the mass of a 9-km-diameter ice ball, smaller for rockier materials. 363 BB tons / 10 years = 100 MM tons / day. By comparison, Mount St Helens (1980) and Eyjafjallajökull (2010) each produced 500 MM tons of ash. So the amount of material is about equivalent to having a similarly-sized volcano eruption every few days for ten years straight. The Earth's surface area is 500 MM sq km. If we were to distribute 363 BB tons uniformly, that would be an average of 1000 tons per sq km. If the layer had a density of 1 ton per cu m (same as water), the resulting layer would be 1/1000 of a meter thick. This seems to be thinner than the spherule layers described. reply datameta 47 minutes agorootparentWe're assuming an even average distribution, and comparing ash to spherules - which would have different patterns of sedimentation depending on how far from epicenter one is. Although, for a large enough impact, the distribution radii overlap around the planet so there may be quite a bit of averaging as the sun+atmosphere provides a mixing medium and the energy to do so. reply didibus 13 hours agorootparentprev [–] > And my starting point for that is “it’s very hard to know anything specific about the deep past. And I’m tired of scientific retractions.” There's no way to prove the past without doubt. It's always going to be conjecture. What people do is that, they observe current phenomenon, and see what kind of artifact it produces and leaves behind. They then work backward from that, if we see the same artifacts, they connect that back with a similar cause from the past. Generally, people consider this even more reliable than human written artifact, because, well, human write a lot of BS. But when there are also written texts or drawn glyphs, those are looked at for corroboration. All of that is added up to gain some level of certainty, but it'll never be for sure, because we'll always be working with incomplete information, and we'll use today's assumption to interpret the information from the past, but even the wildest things might be possible, like that the very nature of physics was different 1 billion years ago, and the same phenomenon would not result in the same kind of artifact as they do today for example. You have to decide for yourself if this inherent uncertainty makes you more skeptical of historical claims, or if you feel the methodology is still reliable enough for practical purposes. And I'd like to contrast this with science about the present, where once we assume something to be true, we can test it by predicting the future with it, and then seeing if that future materializes. If it does, it reinforces the validity of our truths, the more it can accurately predict the future, the truer it is, and where it fails to do so, we know it's not as accurate as it needs to be. Science is about using the best methodology to get us as close as possible to the truth as we can be. Historical sciences have less to work with, but this might still be the best methodology if you want to be as close to the truth. Experimental sciences are able to have even better methodology that allows us to be even closer to the truth. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A colossal meteorite impact over 3 billion years ago significantly affected early microbial life, initially causing devastation but later providing essential nutrients for some microbes to thrive.",
      "Evidence of this ancient impact was discovered in South Africa, where spherule layers indicate past meteorite events, highlighting the scale of the impact, which was larger than the one that caused the extinction of the dinosaurs.",
      "The impact introduced bioavailable iron and phosphorus to the ocean surface, facilitating microbial recovery and suggesting that large impacts, despite their initial harm, could benefit early ecosystems."
    ],
    "commentSummary": [
      "A recent paper discusses a giant meteorite impact during the Paleoarchean era, highlighting its significant environmental and biological effects, such as tsunamis and atmospheric changes.- Despite the disruptions, early life forms likely recovered swiftly, with increased nutrients and iron potentially fostering microbial growth.- The paper also addresses misconceptions about dinosaur extinction, noting that some dinosaurs survived and evolved into modern birds, while acknowledging the challenges in interpreting ancient events."
    ],
    "points": 126,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1731801768
  },
  {
    "id": 42164141,
    "title": "Claude AI built me a React app to compare maps side by side",
    "originLink": "https://github.com/veloplanner/map-matrix",
    "originBody": "Map Matrix Compare multiple maps side by side. Live demo This project was mostly generated by Claude AI. I wanted to develop a simple tool that I needed for veloplanner.com. I thought about using this opportunity to try out Claude AI for coding a project from scratch. It worked surprisingly well! I was able to explain my idea and get a working prototype in a few hours. Most of the time I was just copying code from Claude and pasting it into the editor. Later, I started using Cursor AI (with claude-3.5-sonnet model) which improved the experience a lot. You can add custom map source by clicking the \"Add Custom Source\" button in the navbar. Configuration is stored in the browser's local storage. Example of Cursor AI flow: Development npm install npm run dev",
    "commentLink": "https://news.ycombinator.com/item?id=42164141",
    "commentBody": "Claude AI built me a React app to compare maps side by side (github.com/veloplanner)123 points by caspg 5 hours agohidepastfavorite131 comments thefourthchime 1 hour agoFor years I've kept a list of apps / ideas / products I may do someday. I never made the time, with Cursor AI I have already built one, and am working on another. It's enabling me to use frameworks I barely know, like React Native, Swift, etc.. The first prompt (with o1) will get you 60% there, but then you have a different workflow. The prompts can get to a local minimum, where claude/gpt4/etc.. just can't do any better. At which point you need to climb back out and try a different approach. I recommend git branches to keep track of this. Keep a good working copy in main, and anytime you want to add a feature, make a branch. If you get it almost there, make another branch in case it goes sideways. The biggest issue with developing like this is that you are not a coder anymore; you are a puppet master of a very smart and sometimes totally confused brain. reply lxgr 1 hour agoparent> For years I've kept a list of apps / ideas / products I may do someday. I never made the time, with Cursor AI I have already built one, and am working on another. This is one fact that people seem to severely under-appreciate about LLMs. They're significantly worse at coding in many aspects than even a moderately skilled and motivated intern, but for my hobby projects, until now I haven't had any intern that would even as much as taking a stab at some of the repetitive or just not very interesting subtasks, let alone stick with them over and over again without getting tired of it. reply imiric 15 minutes agorootparentI'm curious: what do you do when the LLM starts hallucinating, or gets stuck in a loop of generating non-working code that it can't get out of? What do you do when you need to troubleshoot and fix an issue it introduced, but has no idea how to fix? In my experience of these tools, including the flagship models discussed here, this is a deal-breaking problem. If I have to waste time re-prompting to make progress, and reviewing and fixing the generated code, it would be much faster if I wrote the code from scratch myself. The tricky thing is that unless you read and understand the generated code, you really have no idea whether you're progressing or regressing. You can ask the model to generate tests for you as well, but how can you be sure they're written correctly, or covering the right scenarios? More power to you if you feel like you're being productive, but the difficult things in software development always come in later stages of the project[1]. The devil is always in the details, and modern AI tools are just incapable of getting us across that last 10%. I'm not trying to downplay their usefulness, or imply that they will never get better. I think current models do a reasonably good job of summarizing documentation and producing small snippets of example code I can reuse, but I wouldn't trust them for anything beyond that. [1]: https://en.wikipedia.org/wiki/Ninety%E2%80%93ninety_rule reply Sakos 1 hour agorootparentprevIt also reduces the knowledge needed. I don't particularly care about learning how to setup and configure a web extension from scratch. With LLM, I can get 90% of that working in minutes, then focus on the parts that I am interested in. As somebody with ADHD, it was primarily all that supplementary, tangential knowledge which felt like an insurmountable mountain to me and made it impossible to actually try all the ideas I'd had over the years. I'm so much more productive now that I don't have to always get into the weeds for every little thing, which could easily delay progress for hours or even days. I can pick and choose the parts I feel are important to me. reply imiric 2 minutes agorootparent> It also reduces the knowledge needed. I don't particularly care about learning how to setup and configure a web extension from scratch. With LLM, I can get 90% of that working in minutes, then focus on the parts that I am interested in. Eh, I would argue that the apparent lower knowledge requirement is an illusion. These tools don't produce working code more often than not (OpenAI's flagship models are not even correct 50% of the time[1]), so you still have to read, understand and debug their output. If you've ever participated in a code review, you'll know that doing that takes much more effort than actually writing the code yourself. Not only that, but relying on these tools handicaps you into not actually learning any of the technologies you're working with. If you ever need to troubleshoot or debug something, you'll be forced to use an AI tool for help again, and good luck if that's a critical production issue. If instead you take the time to read the documentation and understand how to use the technology, perhaps even with the _assistance_ of an AI tool, then it might take you more time and effort upfront, but this will pay itself off in the long run by making you more proficient and useful if and when you need to work on it again. I seriously don't understand the value proposition of the tools in the current AI hype cycle. They are fun and useful to an extent, but are severely limited and downright unhelpful at building and maintaining an actual product. [1]: https://openai.com/index/introducing-simpleqa/ reply elorant 38 minutes agoparentprevGood luck debugging it on production. reply vunderba 11 minutes agoprevI think we're going to see a similar backlash to AI apps as we did with AI art. Not necessarily because users can identify AI apps, but more because due to the lower barrier of entry - the space is going to get hyper-competitive and it'll be VERY difficult to distinguish your app from the hundreds of nearly identical other ones. Another thing that worries me (because software devs in particular seem to take a very loose moral approach to plagiarism and basic human decency) is that it'll be significantly easier for a less scrupulous dev to find an app that they like, and use an LLM to instantly spin up a copy of it. I'm trying not to be all gloom and doom about GenAI, because it can be really nifty to see it generate a bunch of boilerplate (YAML configs, dev opsy stuff, etc.) but sometimes it's hard.... reply CtrlAltmanDel 56 minutes agoprevWhat a feat! There's at least 3 pages of google search results for the nearly same thing. The \"prompt\" I used in google.com is: site:github.com map comparison I guess the difference, is that my way uses dramatically less time and resources, but requires directly acknowledging the original coders instead of relying on the plagiarism-ish capabilities of reguritating something through an LLM. reply mvdtnz 35 minutes agoparentBut creating things for which there are many existing, documented examples is what LLMs do best. Without this use case it's almost like they don't provide any value at all. reply spaceman_2020 3 hours agoprevI have about 6 months of coding experience. All I really knew was how to build a basic MERN app I’ve been using Sonnet 3.5 to code and I’ve managed to build multiple full fledged apps, including paid ones Maybe they’re not perfect, but they work and I’ve had no complaints yet. They might not scale to become the next Facebook, but not everything has to scale reply lucianbr 2 hours agoparentI learned to drive before in-car GPS was widely available, at least where I lived. Going to some new place meant getting a map, looking at it, making a plan, following the plan, keeping track on the map, that sort of thing. Then I traveled somewhere new, for the first time, with GPS and a navigation sofware. It was quite impressive, and rather easier. I got to my destination the first time, without any problems. And each time after that. But I did remark that I did not learn the route. The 10th time, the 50th time, I still needed the GPS to guide me. And without it, I would have to start the whole thing from scratch: get a map, make a plan, and so on. Having done the \"manual\" navigation with maps lots of times before, it never worries me what I would do without a GPS. But if you're \"born\" with the GPS, I wonder what you do when it fails. Are you not worried how you would manage your apps if for some reason the AIs were unavailable? reply vishnugupta 2 minutes agorootparentI learned to code during when internet access was limited to about 1hr/week, extremely slow, and unreliable. But now without inherent I just can’t get any work done. I guess it’s same for a good chunk of people. I never worried about what would happen if internet were to become unavailable. Given that it’s become one an essential service I just trust that powers that be will make sure to get it back up. reply duggan 1 hour agorootparentprevPretty sure people I remember similar conversations happening when people decided to produce content for YouTube full time, lean into Node.js as a dev stack, or build iOS apps. Make hay while the sun shines, friends. It might not last forever, but neither will you! reply sails 24 minutes agorootparentprevWondering around a new city today I had a similar thought. Prior to an iPhone I’d have the general lay of a city memorised within 10min of landing, using a paper tourist map, and probably never feel disoriented, let alone lost. This morning I walked 2 blocks further than needed (of a 1 block walk) because I wasn’t at all oriented while following Google maps. I won’t spell out the AI comparison, other than I think more “apps” will be created, and predictable “followed the GPS off a bridge” revelations. reply conscion 49 minutes agorootparentprev> The 10th time, the 50th time, I still needed the GPS to guide me. If anyone else is frustrated by this experience, I've found that changing the setting in Google Maps to have the map always point north has helped me with actually building a mental model of directions. I found instead of just following the line, it forced me to think about whether I'm going north, south, east, or west for each directions. reply kenjackson 1 hour agorootparentprevAfter 50x? I use GPS too, but I definitely learn the route after a few times with it. There are probably a class of people who don’t ever learn it, but I feel like this has to be a minority. reply SoftTalker 47 minutes agorootparentIt definitely takes me longer. Pre-GPS, I might need a map (or at least notes) to get somewhere, but then I could most likely find my way back on my own. Using GPS to get somewhere, I'd be lost trying to get back without it. I think that because with a map you are looking at street signs/names, etc. both in advance to plan the route, and much more actively and intently while driving to figure out \"do I turn here\" and you just remember that stuff. Where as a GPS says \"turn right at the next light\" and you really don't remember any context around that. reply dmd 2 hours agorootparentprevI was told a similar thing when a mentor discovered I didn’t know how to wire-wrap my own CPU from scratch. reply eastbound 2 hours agorootparentAI is much less reliable. Heck, it could go down like GPT went down in quality after the first 2 month: Services could in an instant become less good. reply tokioyoyo 42 minutes agorootparentWhen there's demand, it will be made reliable through supply. Internet and connectivity weren't really that reliable either 20 years ago. I'm simplifying it heavily, but discarding AI's usefulness and how it lowers the barrier of empty isn't a good idea for the future. reply dmd 2 hours agorootparentprevNobody’s forcing you to use someone else’s service though. reply skeeter2020 1 hour agorootparentthey are if that's the only way you know how to create something reply spaceman_2020 2 hours agorootparentprevYou have to temper your ambitions. Choose languages it understands really well (typescript or python). Choose easier deployment solutions (vercel over docker). Be specific about the versions you’re using (“I’m using nextjs 14 with app router”) reply poslathian 1 hour agoparentprevWe’ll see what the future holds but as an old timer, using LLMs to creat applications seems exactly the same as: Python/JS and their ecosystem replacing OS hosted C/C++ which replaced bare metal Assembly which replaced digital logic which replaced analog circuits which replaced mechanical design as the “standard goto tool” for how to create programs. Starting with punchcard looms and Ada Lovelace maybe. In every case we trade resource efficiency and lower level understanding for developer velocity and raise the upper bound on system complexity, capability, and somehow performance (despite the wasted efficiency). reply quantum_state 1 hour agorootparentWell said .. Hope the pile of complexity accumulated would not be a time bomb ... reply lxgr 1 hour agorootparentTo be fair, that ship has sailed years ago in many areas of programming, even without LLMs... reply hipadev23 2 hours agoparentprevGenuine question: Do you feel like you're learning the language/frameworks/techniques well? Or do you feel like you're just getting more adept at leveraging the LLM? Do you think you could you maintain and/or debug someone else's application? reply jstummbillig 49 minutes agorootparentThe more important question that programmers, who are not product makers, often miss is: Are you solving real problems? It's a slightly orthogonal way of thinking about this but if you are solving real problems, you get away with so much shit, it's unreal. Maybe Google is not gonna let you code monkey on their monorepo, but you do not have to care. There's enough not-google in the world, and enough real problems. reply spaceman_2020 2 hours agorootparentprevNot as much as I would have if I was writing everything from scratch. But then again, my goal isn’t to be a coder or get a job as a coder - I’m primarily a marketer and got into coding simply because I had a stack of ideas I wanted to experiment with Most of the things I’ve built are fun things See: GoUnfaked.com and PlaybookFM.com as examples PlaybookFM.com is interesting because everything from the code to the podcasts to the logo are AI generated reply kenjackson 1 hour agorootparentI’ve had the same experience, except helping complement build components or scripts. Everyone on HN tells me how LLMs are horrible, yet I’ve saved literally hundreds of hours with them so far. I guess we’re just lucky. reply spaceman_2020 25 minutes agorootparentLook at the replies on my comment This place is far gone. Some of the most close minded, uncurious people in tech I don’t think this place deserves to be called “Hacker” News anymore reply an_guy 2 hours agorootparentprevHow much time did you spend on getting it working especially for playbookfm? reply spaceman_2020 1 hour agorootparentLess than a week, tops. The hard part was the content - curating the resources for creating the podcasts reply lxgr 1 hour agorootparentprevThere are so many frameworks, especially on the web and in Javascript, that I have absolutely zero interest in learning. In fact, my main reason for not doing any web development is that I find the amount of layers of abstraction and needless complexity for something that should really be simple quite deterring. I'm sure e.g. React and GraphQL allow people to think about web apps in really elegant and scalable ways, but the learning curve is just way more than I can justify for a side project or a one-off thing at work that will never have more than two or three users opening it once every few months. reply yodsanklai 3 hours agoparentprevWhat do you do if your app has a bug that your LLM isn't able to fix? is your coding experience enough to fix it, or do you ship with bugs hoping customers won't mind? reply amonith 2 hours agorootparentIf customers do mind then at best it's an opportunity cost (less people will buy). Shipping with bugs > not shipping, simple as. reply namaria 5 minutes agorootparentYou better hope no bugs expose you to liabilities like runaway cloud costs or mishandling sensitive data reply jstanley 3 hours agorootparentprevWhat does anyone do if they have a bug they don't know how to fix? Find a way to work around it. reply instalabs 2 hours agorootparentprevYou start over from scratch /s(50%) reply ipaddr 3 hours agorootparentprevWhat I see is people using llm to make a new app without the bug reply willsmith72 2 hours agorootparentThere's always a bug, you just haven't found it yet reply epolanski 3 hours agorootparentprevWhat's the point of this question? Everybody ships nasty bugs in production that he himself might find impossible to debug, everybody. Thus he will do the very same thing me, you or anybody else on this planet do, find a second pair of eyes, virtually or not, paying or not. reply lucianbr 2 hours agorootparentPresumably what is possible for a person with 6 months of experience is rather limited. The idea as I understand it is that he achieved apps that he would not be able to write by himself, with the help of AI. That means that it is possible to have bugs that would be reasonable to fix for someone who built the app using their own knowledge, but for the junior they may be too hard. This is a novel situation. Just because everyone has problems sometimes does not mean problems are all the same, all the same difficulty. Like if I was building Starship, and I ran into some difficult problem, I would most likely give up, as I am way out of my league. I couldn't build a model rocket. I know nothing about rockets. My situation would not be the same as of any rocket engineer. All problems and all situations and all people are not the same, and they are not made the same by AI, despite claims to the contrary. These simplifications/generalisations \"we are all stochastic parrots\" \"we all make mistakes just like the llms make mistakes\" \"we all have bugs\" \"we all manage somehow\" are absurd. Companies do not do interviews and promote some people and not others out of a sense of whimsy. Experience and knowledge matters. We are not all interchangable. If LLMs affect this somehow, it's to be looked at. I can't believe LLMs or devs using LLMs cand suddenly do anything, without limitations. We are not all now equal to Linus and Carmack and such. reply spaceman_2020 2 hours agorootparentprevI haven’t encountered any serious bugs - mostly because I know what I’m capable of and what Sonnet is capable of. I don’t tackle things that are far too ambitious and focus on ideas I want to experiment with or ideas I can build the MVP for If I do encounter situations that Sonnet can’t fix - usually because it has outdated knowledge - I just read the latest documentation reply LunaSea 3 hours agorootparentprev> Everybody ships nasty bugs in production that he himself might find impossible to debug, everybody. No. reply monooso 2 hours agorootparentSome people haven't realised it yet. reply LunaSea 2 hours agorootparentWhich would be a lot better than knowingly releasing in production code with important defects. reply rlty_chck 1 hour agoparentprevEvery time I see claims like this, I instinctively click on the user's profile and try to verify if their story checks out. >I played around a lot with code when I was younger. I built my first site when I was 13 and had a good handle on Javascript back when jQuery was still a pipe dream. >Started with the Codecademy Ruby track which was pretty easy. Working through RailsTutorial right now. posted on April 15, 2015, https://news.ycombinator.com/item?id=9382537 >I've been freelancing since I was 17. I've dabbled in every kind of online trade imaginable, from domain names to crypto. I've built and sold multiple websites. I also built and sold a small agency. >I can do some marketing, some coding, some design, some sales, but I'm not particularly good at any of those in isolation. posted on Jan 20, 2023, https://news.ycombinator.com/item?id=34459482 So I don't really understand where this claim of only \"6 months of coding experience\" is coming from, when you clearly have been coding on and off for multiple decades. reply spaceman_2020 1 hour agorootparentyou do know that there are other kinds of freelancing apart from coding, right? reply azemetre 57 minutes agorootparentI think the comment is fair. The poster came across as inexperienced with programming when in reality they have a decade plus experience. I trust experience people can make better use of these tools because ideally they should have a foundation of first principles to work off of whereas inexperienced people jumping straight into LLMs may not be fully understanding what is happening or what they are given. reply spaceman_2020 35 minutes agorootparentI don’t have a decade of coding experience. I do have almost two decades of internet experience, especially marketing. I had an aborted attempt at learning to code back in 2013-14, but I never stuck around, mostly because I was freelancing as a content marketer (GrowthPub.com) My first real coding experience was when I joined a bootcamp (Code.in bootcamp) in 2022. Only reason I could stick around this time was because I had a chunk of change after selling my agency and had nothing else to do I’m a humanities grad for what its worth reply dartos 2 hours agoparentprevIn your opinion as a newer dev, what were the most complicated things that sonnet was able to do and was not able to do? reply jchanimal 3 hours agoparentprevI think the front end is the most interesting place right now, because it’s where people are making stuff for themselves with the help of LLMs. The browser is a great place to build voice chat, 3d, almost any other experience. I expect a renewed interest in granting fuller capabilities to the web, especially background processing and network access. reply njtransit 3 hours agoparentprevCan you share some examples? reply spaceman_2020 2 hours agorootparentThumbnailGenius.com (has a ton of new features I haven’t pushed yet as I wait for approval from a payment processor) MetHacker.io (has a lot of features I had to remove because of X API’s new pricing - see /projects on it) GoUnfaked.com PlaybookFM.com TokenAI.dev (working with blowfish to remove the warning flag) reply imiric 2 hours agorootparentGood job, I suppose, but the existence of all of these, and the fact you're able to pump them out so quickly, is genuinely depressing. reply spaceman_2020 1 hour agorootparentWhy is it depressing? I find it exhilarating I’m able to bring ideas to life that I could only think about before reply imiric 47 minutes agorootparentHonestly? These were ideas that you put a lot of thought into? All your sites are essentially wrappers around LLMs. You don't disclose which models or APIs you use in the backend, so did you train your own models, or are you proxying to an existing service? Your T&C and Privacy Policy is generic nonsense. What happens to the data your users upload? ThumbnailGenius.com has an example thumbnail of a person with 4 fingers. I honestly can't tell the difference in the comparison between Midjourney, Dall-E and your fine-tuned models. MetHacker.io is not loading. GoUnfaked.com claims to have royalty and copyright-free images, which is highly misleading and possibly illegal. PlaybookFM.com is another effortless wrapper around NotebookLM or a similar LLM. TokenAI.dev is non-functional and seems like a crypto+AI scam. I'm sorry to be so negative, but if you're going to leverage AI tools, at least put some thought and effort into creating something original that brings value to the world. I think you'll find this more rewarding than what you're doing now. Quality over quantity, and all that. reply spaceman_2020 28 minutes agorootparentThese are not the things I wanted to create, but its better to ship out something than waste months just building something and never shipping. I did that with MetaHacker which, under the hood, is very capable. But because I spent so much time building it, I never got around to marketing it or monetizing it, so much of it is abandoned and only 1/10th of it is live for end users. So for my future projects, I told myself I will only spend at most a month working on them. Learn to launch and get users before spending months just building There are much bigger, more creative ideas I want to tackle, but before that, I want to get the hang of actually building something from scratch I spent almost ten years as a b2b marketer. All the clients I worked with were established businesses that needed some scale and direction. I quickly learned that growing a 10M ARR business with established pipelines is a whole lot different than building something from scratch. This is my attempt to go from 0 to 1 as fast as possible and learn as much as I can before diving into bigger things reply azan_ 1 hour agorootparentprevCould you please explain why? I'm trying to think how is it depressing and can't come up with anything. reply eastbound 1 hour agorootparentBecause we don’t believe it’s equal quality to our job, so we see cheap competition arriving with swathes of bad products, but no way for customers to distinguish what makes quality. Plus we all create bugs anyway. reply imiric 1 hour agorootparentIt's not really that. The quality of these tools will probably increase, and I'm fine with more competition, and with less experienced developers being empowered to build their own products. What is depressing to me is that the products showcased here are essentially cookie-cutter derivatives built on and around the AI hype cycle. They're barely UI wrappers around LLMs marketed as something groundbreaking. So the thought of the web being flooded with these kinds of sites, in addition to the increase in spam and other AI generated content, is just depressing. reply 1024core 1 hour agorootparentprevThere was a time when mathematicians wrote LISP programs and other humans translated them into machine instructions. Then one day someone wrote a LISP program to do this, and had one of the translators translate it. A compiler was born. Think of Claude as a compiler which compiles NLP text instructions into functional code. reply imiric 1 hour agorootparentI don't mind tools that empower programmers or even less technical people to build products. I use these tools myself in minor ways, even though I find them to be more of a nuisance than actually helpful. What I find depressing is how quickly someone with minimal experience can flood the web with low quality services, in search for a quick buck. It's like all the SEO spam we've been seeing for decades, but exponentially worse. The web will become even more of a nightmare to navigate than it already is. reply tchock23 1 hour agorootparentprevAre you sharing your process anywhere (like on YouTube)? I’d be really curious to see behind the scenes of how you’re building these types of products. For example, are you just using Claude or Claude with Cursor (or something else)? reply spaceman_2020 1 hour agorootparentI think I should create a video showing it Usually its v0.dev for the basic UI and then just prompting cursor reply vunderba 25 minutes agorootparentprevWith the lower barrier to entry comes dozens of nearly \"apps\" that are nearly indistinguishable from each other. ThumbnailGenius There's already several sites that generate YT thumbnails with AI: https://vidiq.com/ai-thumbnails-generator/ https://www.testmythumbnails.com/create-thumbnails-with-ai PlaybookFM AI Podcasts have been a thing for a while - though I can't imagine who finds listening to TTS voices with LLM content particularly engaging over a genuine person who puts time and effort into crafting an engaging personality. GoUnfaked I don't really understand the point of this one - it generates photorealistic AI pictures? Isn't that exactly what Getty Images AI, Freepik, etc. are all doing already? Good luck - but this feels like a very \"spray and pray\" approach to development. It feels like it has the same probability to generate genuine income as people who try to start Patreon pages for their AI \"artwork\". reply spaceman_2020 21 minutes agorootparentI have at least 10 people signing up for thumbnailgenius every day when I haven’t even started marketing it So hey, maybe its not revolutionary, but some people find it useful enough Which is fine by me. Maybe you can tackle changing the world. I’ll just focus on being useful enough to some people reply lucianbr 2 hours agorootparentprevThank you for sharing these. So many people talk in superlative terms about the stuff they did with AI and give no details. It's very hard to gauge what they actually achieved. reply lostemptations5 2 hours agoparentprevI'm not saying you're wrong at all or in disbelief -- but I've spent lots of time with Claude 3.5 trying to prototype React apps and not even full fledged prototypes -- and I can't get it to make anything bug free somehow. Maybe I'm \"holding it wrong\" -- I mean using it incorrectly. True it renders quite interesting mockups and has React code behind it -- but then try and get this into even a demoable state for your boss or colleagues... Even a simple \"please create a docker file with everything I need in a directory to get this up and running\"...doesn't work. Docker file doesnt work (my fault maybe for not expressing I'm on Arm64), app is miss configured, files are in the wrong directories, key things are missing. Again just my experience. I find Claude interesting for generating ideas-- but I have a hard time seeing how a dev with six months experience could get multiple \"paid\" apps out with it. I have 20 years (bla, bla) experience and still find it requires outrageous hand holding for anything serious. Again I'm not doubting you at all -- I'm just saying me personally I find it hard to be THAT productive with it. reply spaceman_2020 27 minutes agorootparentYou have to temper your ambitions. Choose languages it understands well. Deploy on vercel. Specify exactly what you’re working with (“I’m using nextjs 14 with app router”) reply vachina 1 hour agorootparentprevAgreed. LLMs can give you ideas on how to get there, but you still need foundational knowledge of the language or framework to extend the code it generates. reply fragmede 2 hours agorootparentprevwould you be willing to share any of your chats? Like say the docker one? reply lostemptations5 1 hour agorootparentThat one was for work - but let me try again on an example project and I'll share it sure. reply belter 2 hours agoparentprevIf there are complaints who is going to fix it? :-) reply smallerfish 38 minutes agoprevClaude is fantastic. I think the model itself is good enough to be able to write good software when competently directed; it's let down only by the UI/UX around it. My only complaints are: a) that it's really easy to hit the usage limit, especially when refactoring across a half dozen files. One thing that'd theoretically be easyish to fix would be automatically updating files in the project context (perhaps with an \"accept\"/\"reject\" prompt) so that the model knows what the latest version of your code is without having to reupload it constantly. b) it oscillating between being lazy in really annoying ways (giving largeish code blocks with commented omissions partway through) and supplying the full file unnecessarily and using up your usage credits. My hope is that Jetbrains give up on their own (pretty limited) LLM and partner with Anthropic to produce a super-tight IDE native integration. reply grp000 7 minutes agoprevCan anyone measure in how Claude compares to copilot? Copilot feels like a fancy auto complete, but people seem to have good experiences with Claude, even in more complex settings. reply cluckindan 6 minutes agoparentYou can use Claude in Copilot. reply caspg 5 hours agoprevI wanted to develop a simple tool to compare maps. I thought about using this opportunity to try out Claude AI for coding a project from scratch. It worked surprisingly well! At least 95% of the code was generated by AI (I reached the limit so had to add final bits on my own). reply MrMcCall 3 hours agoparentThe problem is that you must understand that 95% in order to complete the last 5%. reply ericskiff 3 hours agorootparentInterestingly, I’m pretty sure they mean they hit the limit with tokens on Claude. There’s a daily 2.5 million token limit that you can use up fairly quickly with 100K context So they may very well have completed the whole program with Claude. It’s just the machine literally stopped and the human had to do the final grunt work. reply ericskiff 3 hours agorootparentWe’ve been hitting this in our work and in experimentation, and I can confirm that Claude sonnet 3.5 has gotten 100% of the way there, including working through errors and tricky problems as we tested the apps it built. reply negoutputeng 3 hours agorootparentprevexactly right. POCs and demos are easy to build by anyone these days. The last 10% is what separates student projects from real products. any engineer who has spent time in the trenches understands that fixing corner cases in code produced by inexperienced engineers consumes a lot of time. in fact, poor overall design and lack of diligence tanks entire projects. reply MrMcCall 3 hours agorootparentSometimes it's not even inexperienced coders -- it's our own dang selves ;-) reply ipaddr 3 hours agoparentprevI asked Claude AI to make me an app and it refused and called it dangerous. I asked what kind of apps they could build and they suggested social media or health. So I asked it to make one but it refused too dangerous. I asked it to make anything.. anything app and it refused. I told it it sucked and it said it didn't. Then I deleted my account. I can't think of a worse llm than Claude. reply 7thpower 14 minutes agorootparentThere have been rumors of the system prompt changing for some services if the user had strikes on their account from earlier conversations. I wonder if you were impacted by this because what you described has not been my experience nor have I seen it discussed previously. reply fragmede 2 hours agorootparentprevTbh this sounds like a skill issue. reply 2024user 4 hours agoprevClaude built me a simple react app AND rendered it in it's own UI - including using imports and stuff. I am looking forward to this type of real time app creation being added into our OSs, browsers, phones and glasses. reply swatcoder 3 hours agoparent> I am looking forward to this type of real time app creation being added into our OSs, browsers, phones and glasses. What do you see that being used for? Surely, polished apps written for others are going to be best built in professional tools that live independently of whatever the OS might offer. So I assume you're talking about quick little scratch apps for personal use? Like an AI-enriched version of Apple's Automator or Shortcuts, or of shell scripts, where you spend a while coahcing an AI to write the little one-off program you need instead of visually building a worrkflow or writing a simple script? Is that something you believe there's a high unmet need for? This is an earnest question. I'm sincerely curious what you're envisioning and how it might supercede the rich variety of existing tools that seem to only see niche use today. reply cj 3 hours agorootparentWhen I was in college (10+ years ago) there was a system that allowed you to select your classes. During the selection period, certain people had priority (people a year above you got to select first). Once a class was full, you could still get in if someone who was selected for the classes changed their mind, which (at an unpredictable time) would result in a seat becoming available in that class until another student noticed the availability and signed up. So I wrote a simple PHP script that loaded the page every 60 seconds checking, and the script would send me a text message if any of the classes I wanted suddenly had an opening. I would then run to a computer and try to sign up. These are the kind of bespoke, single-purpose things that I presume AI coding could help the average person with. “Send me a push notification when the text on this webpage says the class isn’t full, and check every 60 seconds” reply mgkimsal 3 hours agorootparentThis sort of thing needs to be built to be in-OS or in-device or whatever term we want to use to signify that the agent has to be me to do it. Scripting a browser that already has my saved credentials to do something for me, running in device, is where more things have to go, vs external third party services where we need to continually handle external auth protocols. reply bdcravens 3 hours agorootparentprevThere's no shortage of applications, both desktop and mobile, that never really stray outside of the default toolkits. Line of business apps, for instance, don't need the polish that apps targeting consumers need. They just need to effectively manipulate data. reply nkingsy 3 hours agorootparentprevHard to say as someone with the power. Ask a bird what flying is good for and their answer will be encumbered by reality. Kind of the opposite of “everything looks like a nail”. reply croes 3 hours agoparentprevThat will be a whole new level of malware attack angle. reply meiraleal 3 hours agorootparentEvery new tech is a new attack surface. reply mmsc 3 hours agorootparentprevCan you expand on what you mean by this, and why? reply danieldk 3 hours agorootparentThe best vulnerability is one that is hard to detect because it looks like a bug. It's not inconceivable to train an LLM to silently slip vulnerabilities in generated code. Someone who does not have a whole lot of programming experience is unlikely to detect it. tl;dr it takes running untrusted code to a new level. reply jstummbillig 38 minutes agorootparentMeh. Why would the model makers not be fantastic security vectors? The motivation to not be the company known to \"silently slip vulnerabilities in generated code\" seems fairly obvious. People have always been able to slip in errors. I am confused why we assume that a LLM will on average not be better but worse on this front, and I suspect a lot of residual human-bias and copium. reply caspg 3 hours agorootparentprevWebAssembly sandboxes might become handy. reply troupo 2 hours agorootparentThat guards against a small subset of vulnerabilities. Since the original desire was to build any kind of personal/commercial app on an OS, the amount of potential vulnerabilities is potentially infinite. reply sdesol 2 hours agorootparentThis ultimately why I believe Microsoft and Apple will be the big winners. I suspect a lot of companies will want Microsoft and Apple to sign off on things and Microsoft and Apple are going to make sure they get their cut. We may need a new layer above existing operating systems in the future, to safeguard things. reply williamcotton 1 hour agoprevI used Claude (and a bit of ChatGPT) to write a multi-pass recursive descent parser for a search query DSL: https://github.com/williamcotton/search-input-query Why multi-pass? So multiple semantic errors can be reported at once to the user! The most important factor here is that I've written lexers and parsers beforehand. I was very detailed in my instructions and put it together piece-by-piece. It took probably 100 or so different chats. Try it out with the GUI you see in the gif in the README: git clone git@github.com:williamcotton/search-input-query.git cd search-input-query/search-input-query-demo npm install npm run dev reply truckerbill 4 hours agoprevCool! Did you just prompt -> copy -> paste or did you come up with some specific workflow? reply caspg 4 hours agoparentI used Claude AI project to attach requirement for the project. Then I just went with single conversation. I specified that I want to do it in small steps and then was just doing copy -> paste until I reached the limit. I think it was because I was doing one big convo instead attaching code to the project. So pretty simple flow, totally not scalable for bigger projects. I need to read and check Cursor AI which can also use Claude models. reply johnisgood 3 hours agorootparentI wish I could try out Cursor, but I cannot due to this bug: https://github.com/getcursor/cursor/issues/598 reply ianhawes 3 hours agorootparentHave you tried a different IP address? reply johnisgood 3 hours agorootparentI have not, I am using my residential/home IP address though and I can access https://api2.cursor.sh/. reply Omnipresent 3 hours agorootparentprevare you able to share the link to your prompts / conversation? reply hijinks 3 hours agoparentprevyou can use the vscode cline to give a task and it uses a LLM to go out and create the app for you. In django i had it create a backend, set admin user, create requirements.txt and then do a whole frontend in vue as a test. It even can do screen testing and tested what happens if it puts a wrong login in. reply EcommerceFlow 3 hours agoprevBeen using LLMs since got3 beta in June 2021 and it’s interesting to see how my use cases have continuously been upgraded as models advanced. Started off with having it create funny random stories, to slowly creating more and more advanced programs. It’s shocking how good 3.5 Sonnet is at coding, considering the size of the model. reply GaggiX 1 hour agoparent>considering the size of the model. We don't know the size of Claude 3.5 Sonnet or any other Anthropic model. reply lxgr 1 hour agoprevClaude has worked amazingly well for me as somebody really not into UI/web development. There are so many small tasks that I could, but until now almost never would automate (whether it's not worth the time [1] or I just couldn't bring myself to do it as I don't really enjoy doing it). A one-off bitmask parser at work here, a proof of concept webapp at home there – it's literally opened up a new world of quality-of-life improvements, in a purely quantitative sense. It extends beyond UI and web development too: Very often I find myself thinking that there must be a smarter way to use CLI tools like jq, zsh etc., but considering how rarely I use them and that I do already know an ineffective way of getting what I need, up until now I couldn't justify spending the hours of going through documentation on the moderately high chance of finding a few useful nuggets letting me shave off a minute here and there every month. The same applies to SQL: After plateauing for several years (I get by just fine for my relatively narrow debugging and occasional data migration needs), LLMs have been much better at exposing me to new and useful patterns than dry and extensive documentation. (There are technical documents I really do enjoy reading, but SQL dialect specifications, often without any practical motivation as to when to use a given construct, are really not it.) LLMs have generally been great at that, but being able to immediately run what they suggest in-browser is where Claude currently has the edge for me. (ChatGPT Plus can apparently evaluate Python, but that's server-side only and accordingly doesn't really allow interactive use cases.) [1] https://xkcd.com/1205/ reply nine_k 3 hours agoprevThis is great progress. Next obvious steps: make it understand large existing programs, learn form the style of the existing code while avoiding to learn the bad style where it's present, and then contribute features or fixes to that codebase. reply Omnipresent 3 hours agoprevit'd be cool to see the prompts used and the edits required to get to the end product here. reply yieldcrv 3 hours agoprevI wish Claude let you share conversations more easily, I’d be curious to see how this one went and what follow on questions you had reply ffsm8 3 hours agoparenthuh? there should be a button on the top right to generate a share link in any conversation? is that really too hard? its even documented on their site https://support.anthropic.com/en/articles/9519189-project-vi... Click the \"Share\" button in the upper right corner of your chat. Click the \"Share & Copy Link\" button to create a shareable link and add the chat snapshot to your project’s activity feed. /edit: i just checked. i think they had a regression? or at least i cannot see the button anymore. go figure. must be pretty recently, as i shared a chat just ~2-3 weeks ago reply raldi 2 hours agorootparentNote the section you’re in at that doc link: “Claude for Work (Team & Enterprise Plans) -> Team & Enterprise Plan Features -> Project visibility and sharing” reply ffsm8 1 hour agorootparentHuh, did they remove it from the normal subscription then? I've never had a team & enterprise plan. reply bikamonki 4 hours agoprevCould this be used to RPA my browser? Is it safe? reply caspg 4 hours agoparentWhat is RPA? Robotic Process Automation? If yes then I have no experience with that. reply jckahn 4 hours agoprevThis sort of thing will be interesting to me once it can be done with fully local and open source tech on attainable hardware (and no, a $5,000 MacBook Pro is not attainable). Building a dependence on yet another untrustworthy AI startup that will inevitably enshittify isn’t compelling despite what the tech can do. We’re getting there with some of the smaller open source models, but we’re not quite there yet. I’m looking forward to where we’ll be in a year! reply Veuxdo 3 hours agoparent> and no, a $5,000 MacBook Pro is not attainable In many professions, $5000 for tools is almost nothing. reply cpursley 3 hours agorootparentYep. Typical landscape crew rolls with $50k in equipment (maybe more). People push back on tooling pricing in other industries (especially when the tooling is \"soft') but have no clue what that the cost of doing biz is huge for others. reply torginus 3 hours agorootparentprevYeah, but those tools don't get obsoleted in 3 years. reply zamadatix 3 hours agorootparentYou're pretty lucky if the specialised tools for your profession cost(and no, a $5,000 MacBook Pro is not attainable) I know we all love dunking on how expensive Apple computers are, but for $5000 you would be getting a Mac Mini maxed-out with an M4 Pro chip with 14‑core CPU, 20‑core GPU, 16-core Neural Engine, 64GB unified RAM memory, an 8TB SSD and 10 Gigabit Ethernet. M4 MacBook Pros start at $1599. reply zamadatix 2 hours agorootparentI get where GP is coming from and it's not really related to typical Apple price bashing. You can list the most fantastical specs for the craziest value and it all really comes down to that single note: \"64 GB memory for the GPU/NPU\" - where the mini caps out. The GPU/NPU might change the speed of the output by a linear factor but the memory is a hard wall of how good a model you can run and 64 GB total is surprisingly not that high in the AI world. The MacBook Pro units referenced at $5k are the ones that support 128 GB, hence why they are popularly mentioned. ~ the same $ for the Mac Studio when you minimally load it up to 128 GB. Even then you're not able to run the biggest local models, 128 GB still isn't enough, but you can at least run the mid sized ones unquantized. What I think GP was overlooking is newer mid range models like Qwen2.5-Coder 32B produce more than usable outputs for this kind of scenario on much lower end consumer (instead of prosumer) hardware so you don't need to go looking for the high memory stuff to do this kind of task locally, even if you may need the high memory stuff for serious AI workloads or AI training. reply bowsamic 3 hours agoprev [–] I’ve had insanely, shockingly good experiences prototyping a musical web app using tone.js using Claude with copilot reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Map Matrix is a tool that enables users to compare multiple maps simultaneously, initially developed for veloplanner.com using Claude AI.",
      "The development process was streamlined by using Claude AI to quickly generate a prototype and later enhanced with Cursor AI and the claude-3.5-sonnet model.",
      "Users can add custom map sources, with configurations saved locally, and developers can set up the tool using `npm install` and `npm run dev` commands."
    ],
    "commentSummary": [
      "Claude AI was instrumental in creating a React app for map comparison, with most of the code generated by the AI.- Users reported both advantages, such as accelerated development and reduced need for deep technical knowledge, and challenges, including AI limitations like hallucinations and non-functional code.- AI tools like Claude and Cursor AI are valued for rapid prototyping and small project development, despite concerns about increased competition and potential plagiarism."
    ],
    "points": 124,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1731850779
  },
  {
    "id": 42162878,
    "title": "Constraints in Go",
    "originLink": "https://bitfieldconsulting.com/posts/constraints",
    "originBody": "Oct 31 Oct 31 Constraints in Go John Arundel From Know Go Design is the beauty of turning constraints into advantages. —Aza Raskin This is the fourth in a four-part series of tutorials on generics in Go. Generics Type parameters Generic types Constraints In my book Know Go, and in the previous tutorials in this series, you’ll learn all about generic programming in Go and the new universe of programs it opens up to us. Ironically, one of the new features of Go that gives us the most freedom is constraints. Let’s talk about that, and explain the paradox. We saw in the previous tutorial that when we’re writing generic functions that take any type, the range of things we can do with values of that type is necessarily rather limited. For example, we can’t add them together. For that, we’d need to be able to prove to Go that they’re one of the types that support the + operator. Method set constraints It’s the same with interfaces, as we discussed in the first post in this series. The empty interface, any, is implemented by every type, and so knowing that something implements any tells you nothing distinctive about it. Limitations of the any constraint Similarly, in a generic function parameterised by some type T, constraining T to any doesn’t give Go any information about it. So it has no way to guarantee that a given operator, such as +, will work with values of T. A Go proverb says: The bigger the interface, the weaker the abstraction. —https://go-proverbs.github.io/ And the same is true of constraints. The broader the constraint, and thus the more types it allows, the less we can guarantee about what operations we can do on them. There are a few things we can do with any values, as you already know, because we’ve done them. For example, we can declare variables of that type, we can assign values to them, we can return them from functions, and so on. But we can’t really do a whole lot of computation with them, because we can’t use operators like + or -. So in order to be able to do something useful with values of T, such as adding them, we need more restrictive constraints. What kinds of constraints could there be on T? Let’s examine the possibilities. Basic interfaces One kind of constraint that we’re already familiar with in Go is an interface. In fact, all constraints are interfaces of a kind, but let’s use the term basic interface here to avoid any confusion. A basic interface, we’ll say, is one that contains only method elements. For example, the fmt.Stringer interface we saw in the first tutorial: type Stringer interface { String() string } We’ve seen that we can write an ordinary, non-generic function that takes a parameter of type Stringer. And we can also use this interface as a type constraint for a generic function. For example, we could write a generic function parameterised by some type T, but this time T can’t be just any type. Instead, we’ll say that whatever T turns out to be, it must implement the fmt.Stringer interface: func Stringify[T fmt.Stringer](s T) string { return s.String() } This is clear enough, and it works the same way as the generic functions we’ve already written. The only new thing is that we used the constraint Stringer instead of any. Now when we actually call this function in a program, we’re only allowed to pass it arguments that implement Stringer. What would happen, then, if we tried to call Stringify with an argument that doesn’t implement Stringer? We feel instinctively that this shouldn’t work, and it doesn’t: fmt.Println(Stringify(1)) // int does not implement Stringer (missing method String) That makes sense. It’s just the same as if we wrote an ordinary, non-generic function that took a parameter of type Stringer, as we did in the first tutorial. There’s no advantage to writing a generic function in this case, since we can use this interface type directly in an ordinary function. All the same, a basic interface—one defined by a set of methods—is a valid constraint for type parameters, and we can use it that way if we want to. Exercise: Stringy beans Flex your generics muscles a little now, by writing a generic function constrained by fmt.Stringer to solve the stringy exercise. type greeting struct{} func (greeting) String() string { return \"Howdy!\" } func TestStringifyTo_PrintsToSuppliedWriter(t *testing.T) { t.Parallel() buf := &bytes.Buffer{} stringy.StringifyTo[greeting](buf, greeting{}) want := \"Howdy!\" got := buf.String() if want != got { t.Errorf(\"want %q, got %q\", want, got) } } (Listing exercises/stringy) GOAL: Your job here is to write a generic function StringifyTo[T] that takes an io.Writer and a value of some arbitrary type constrained by fmt.Stringer, and prints the value to the writer. HINT: This is a bit like the PrintAnything function we saw before, isn’t it? Actually, it’s a “print anything stringable” function. We already know what the constraint is (fmt.Stringer), and the rest is straightforward. SOLUTION: Here’s a version that would work, for example: func StringifyTo[T fmt.Stringer](w io.Writer, p T) { fmt.Fprintln(w, p.String()) } (Listing solutions/stringy) Strictly speaking, of course, we don’t really need to call the String method: fmt already knows how to do that automagically. But if we just passed p directly, we wouldn’t need the Stringer constraint, and we could use any… but what would be the fun in that? Type set constraints We’ve seen that one way an interface can specify an allowed range of types is by including a method element, such as String() string. That would be a basic interface, but now let’s introduce another kind of interface. Instead of listing methods that the type must have, it directly specifies a set of types that are allowed. Type elements For example, suppose we wanted to write some generic function Double that multiplies a number by two, and we want a type constraint that allows only values of type int. We know that int has no methods, so we can’t use any basic interface as a constraint. How can we write it, then? Well, here’s how: type OnlyInt interface { int } Very straightforward! It looks just like a regular interface definition, except that instead of method elements, it contains a single type element, consisting of a named type. In this case, the named type is int. Using a type set constraint How would we use a constraint like this? Let’s write Double, then: func Double[T OnlyInt](v T) T { return v * 2 } In other words, for some T that satisfies the constraint OnlyInt, Double takes a T parameter and returns a T result. Note that we now have one answer to the sort of problem we encountered with AddAnything: how to enable the * operator (or any other arithmetic operator) in a parameterised function. Since T can only be int (thanks to the OnlyInt constraint), Go can guarantee that the * operator will work with T values. It’s not the complete answer, though, since there are other types that support * that wouldn’t be allowed by this constraint. And in any case, if we were only going to support int, we could have just written an ordinary function that took an int parameter. So we’ll need to be able to expand the range of types allowed by our constraint a little, but not beyond the types that support *. How can we do that? Unions What types can satisfy the constraint OnlyInt? Well, only int! To broaden this range, we can create a constraint specifying more than one named type: type Integer interface { intint8int16int32int64 } The types are separated by the pipe character, |. You can think of this as representing “or”. In other words, a type will satisfy this constraint if it is int or int8 or… you get the idea. This kind of interface element is called a union. The type elements in a union can include any Go types, including interface types. It can even include other constraints. In other words, we can compose new constraints from existing ones, like this: type Float interface { float32float64 } type Complex interface { complex64complex128 } type Number interface { IntegerFloatComplex } We’re saying that Integer, Float, and Complex are all unions of different built-in numeric types, but we’re also creating a new constraint Number, which is a union of those three interface types we just defined. If it’s an integer, a float, or a complex number, then it’s a number! The set of all allowed types The type set of a constraint is the set of all types that satisfy it. The type set of the empty interface (any) is the set of all types, as you’d expect. The type set of a union element (such as Float in the previous example) is the union of the type sets of all its terms. In the Float example, which is the union of float32float64, its type set contains float32, float64, and no other types. Intersections You probably know that with a basic interface, a type must have all of the methods listed in order to implement the interface. And if the interface contains other interfaces, a type must implement all of those interfaces, not just one of them. For example: type ReaderStringer interface { io.Reader fmt.Stringer } If we were to write this as an interface literal, we would separate the methods with a semicolon instead of a newline, but the meaning is the same: interface { io.Reader; fmt.Stringer } To implement this interface, a type has to implement both io.Reader and fmt.Stringer. Just one or the other isn’t good enough. Each line of an interface definition like this, then, is treated as a distinct type element. The type set of the interface as a whole is the intersection of the type sets of all its elements. That is, only those types that all the elements have in common. So putting interface elements on different lines has the effect of requiring a type to implement all those elements. We don’t need this kind of interface very often, but we can imagine cases where it might be necessary. Empty type sets You might be wondering about what happens if we define an interface whose type set is completely empty. That is, if there are no types that can satisfy the constraint. Well, that could happen with an intersection of two type sets that have no elements in common. For example: type Unpossible interface { int string } Clearly no type can be both int and string at the same time! Or, to put it another way, this interface’s type set is empty. If we try to instantiate a function constrained by Unpossible, we’ll find, naturally enough, that it can’t be done: cannot implement Unpossible (empty type set) We probably wouldn’t do this on purpose, since an unsatisfiable constraint doesn’t seem that useful. But with more sophisticated interfaces, we might accidentally reduce the allowed type set to zero, and it’s helpful to know what this error message means so that we can fix the problem. Composite type literals A composite type is one that’s built up from other types. We saw some composite types in the previous tutorial, such as []E, which is a slice of some element type E. But we’re not restricted to defined types with names. We can also construct new types on the fly, using a type literal: that is, literally writing out the type definition as part of the interface. A struct type literal For example, this interface specifies a struct type literal: type Pointish interface { struct{ X, Y int } } A type parameter with this constraint would allow any instance of such a struct. In other words, its type set contains exactly one type: struct{ X, Y int }. Access to struct fields While we can write a generic function constrained by some struct type such as Pointish, there are limitations on what that function can do with that type. One is that it can’t access the struct’s fields: func GetX[T Pointish](p T) int { return p.X } // p.X undefined (type T has no field or method X) In other words, we can’t refer to a field on p, even though the function’s constraint explicitly says that any p is guaranteed to be a struct with at least the field X. This is a limitation of the Go compiler that has not yet been overcome. Sorry about that. Some limitations of type sets An interface containing type elements can only be used as a constraint on a type parameter. It can’t be used as the type of a variable or parameter declaration, like a basic interface can. That too is something that might change in the future, but this is where we are today. Constraints versus basic interfaces What exactly stops us from doing that, though? We already know that we can write functions that take ordinary parameters of some basic interface type such as Stringer. So what happens if we try to do the same with an interface containing type elements, such as Number? Let’s see: func Double(p Number) Number { // interface contains type constraints This doesn’t compile, for the reasons we’ve discussed. Some potential confusion arises from the fact that a basic interface can be used as both a regular interface type and a constraint on type parameters. But interfaces that contain type elements can only be used as constraints. Constraints are not classes If you have some experience with languages that have classes (hierarchies of types), then there’s another thing that might trip you up with Go generics: constraints are not classes, and you can’t instantiate a generic function or type on a constraint interface. To illustrate, suppose we have some concrete types Cow and Chicken: type Cow struct{ moo string } type Chicken struct{ cluck string } And suppose we define some interface Animal whose type set consists of Cow and Chicken: type Animal interface { CowChicken } So far, so good, and suppose we now define a generic type Farm as a slice of T Animal: type Farm[T Animal] []T Since we know the type set of Animal contains exactly Cow and Chicken, then either of those types can be used to instantiate Farm: dairy := Farm[Cow]{} poultry := Farm[Chicken]{} What about Animal itself? Could we create a Farm[Animal]? No, because there’s no such type as Animal. It’s a type constraint, not a type, so this gives an error: mixed := Farm[Animal]{} // interface contains type constraints And, as we’ve seen, we also couldn’t use Animal as the type of some variable, or ordinary function parameter. Only basic interfaces can be used this way, not interfaces containing type elements. Approximations Let’s return to our earlier definition of an interface Integer, consisting of a union of named types. Specifically, the built-in signed integer types: type Integer interface { intint8int16int32int64 } We know that the type set of this interface contains all the types we’ve named. But what about defined types whose underlying type is one of the built-in types? Limitations of named types For example: type MyInt int Is MyInt also in the type set of Integer? Let’s find out. Suppose we write a generic function that uses this constraint: func Double[T Integer](v T) T { return v * 2 } Can we pass it a MyInt value? We’ll soon know: fmt.Println(Double(MyInt(1))) // MyInt does not implement Integer No. That makes sense, because Integer is a list of named types, and we can see that MyInt isn’t one of them. How can we write an interface that allows not only a set of specific named types, but also any other types derived from them? Type approximations We need a new kind of type element: a type approximation. We write it using the tilde (~) character: type ApproximatelyInt interface { ~int } The type set of ~int includes int itself, but also any type whose underlying type is int (for example, MyInt). If we rewrite Double to use this constraint, we can pass it a MyInt, which is good. Even better, it will accept any type, now or in the future, whose underlying type is int. Derived types Approximations are especially useful with struct type elements. Remember our Pointish interface? type Pointish interface { struct{ x, y int } } Let’s write a generic function with this constraint: func Plot[T Pointish](p T) { We can pass it values of type struct{ x, y int }, as you’d expect: p := struct{ x, y int }{1, 2} Plot(p) But now comes a problem: we can’t pass values of any named struct type, even if the struct definition itself matches the constraint perfectly: type Point struct { x, y int } p := Point{1, 2} Plot(p) // Point does not implement Pointish (possibly missing ~ for // struct{x int; y int} in constraint Pointish) What’s the problem here? Our constraint allows struct{ x, y int }, but Point is not that type. It’s a type derived from it. And, just as with MyInt, a derived type is distinct from its underlying type. You know now how to solve this problem: use a type approximation! And Go is telling us the same thing: “Hint, hint: I think you meant to write a ~ in your constraint.” If we add that approximation, the type set of our interface expands to encompass all types derived from the specified struct, including Point: type Pointish interface { ~struct{ x, y int } } Exercise: A first approximation Can you use what you’ve just learned to solve the intish challenge? Here you’re provided with a function IsPositive, which determines whether a given value is greater than zero: func IsPositive[T Intish](v T) bool { return v > 0 } (Listing exercises/intish) And there’s a set of accompanying tests that instantiate this function on some derived type MyInt: type MyInt int func TestIsPositive_IsTrueFor1(t *testing.T) { t.Parallel() input := MyInt(1) if !intish.IsPositive(input) { t.Errorf(\"IsPositive(1): want true, got false\") } } func TestIsPositive_IsFalseForNegative1(t *testing.T) { t.Parallel() input := MyInt(-1) if intish.IsPositive(input) { t.Errorf(\"IsPositive(-1): want false, got true\") } } func TestIsPositive_IsFalseForZero(t *testing.T) { t.Parallel() input := MyInt(0) if intish.IsPositive(input) { t.Errorf(\"IsPositive(0): want false, got true\") } } (Listing exercises/intish) GOAL: Your task here is to define the Intish interface. HINT: A method set won’t work here, because the int type has no methods! On the other hand, the type literal int won’t work either, because MyInt is not int, it’s a new type derived from it. What kind of constraint could you use instead? I think you know where this is going, don’t you? If not, have another look at the previous section on type approximations. SOLUTION: It’s not complicated, once you know that a type approximation is required: type Intish interface { ~int } (Listing solutions/intish) Interface literals Up to now, we’ve always used type parameters with a named constraint, such as Integer (or even just any). And we know that those constraints are defined as interfaces. So could we use an interface literal as a type constraint? Syntax of an interface literal An interface literal, as you probably know, consists of the keyword interface followed by curly braces containing (optionally) some interface elements. For example, the simplest interface literal is the empty interface, interface{}, which is common enough to have its own predeclared name, any. We should be able to write this empty interface literal wherever any is allowed as a type constraint, then: func Identity[T interface{}](v T) T { And so we can. But we’re not restricted to only empty interface literals. We could write an interface literal that contains a method element, for example: func Stringify[T interface{ String() string }](s T) string { return s.String() } This is a little hard to read at first, perhaps. But we’ve already seen this exact function before, only in that case it had a named constraint Stringer. We’ve simply replaced that name with the corresponding interface literal: interface{ String() string } That is, the set of types that have a String method. We don’t need to name this interface in order to use it as a constraint, and sometimes it’s clearer to write it as a literal. Omitting the interface keyword And we’re not limited to just method elements in interface literals used as constraints. We can use type elements too: [T interface{ ~int }] Conveniently, in this case we can omit the enclosing interface { ... }, and write simply ~int as the constraint: [T ~int] For example, we could write some function Increment constrained to types derived from int: func Increment[T ~int](v T) T { return v + 1 } However, we can only omit the interface keyword when the constraint contains exactly one type element. Multiple elements wouldn’t be allowed, so this doesn’t work: func Increment[T ~int; ~float64](v T) T { // syntax error: unexpected semicolon in parameter list; possibly // missing comma or ] And we can’t omit interface with method elements either: func Increment[T String() string](v T) T { // syntax error: unexpected ( in parameter list; possibly // missing comma or ] And we can only omit interface in a constraint literal. We can’t omit it when defining a named constraint. So this doesn’t work, for example: type Intish ~int // syntax error: unexpected ~ in type declaration Referring to type parameters We’ve seen that in certain cases, instead of having to define it separately, we can write a constraint directly as an interface literal. So you might be wondering: can we refer to T inside the interface literal itself? Yes, we can. To see why we might need to do that, suppose we wanted to write a generic function Contains[T], that takes a slice of T and tells you whether or not it contains a given value. And suppose that we’ll determine this, for any particular element of the slice, by calling some Equal method on the element. That means we must constrain the function to only types that have a suitable Equal method. So the constraint for T is going to be an interface containing the method Equal(T) bool, let’s say. Can we do this? Let’s try: func Contains[T interface{ Equal(T) bool }](s []T, v T) bool { Yes, this is fine. In fact, using an interface literal is the only way to write this constraint. We couldn’t have created some named interface type to do the same thing. Why not? Let’s see what happens if we try: type Equaler interface { Equal(???) bool // we can't say 'T' here } Because the type parameter T is part of the Equal method signature, and we don’t have T here. The only way to refer to T is in an interface literal inside a type constraint: [T interface{ Equal(T) bool }] At least, we can’t write a specific interface that mentions T in its method set. What we’d need here, in fact, is a generic interface, and you’ll learn how to define and use these in my book, Know Go. If these tutorials have given you an appetite for generic programming in Go, I think you’ll really enjoy the book—check it out! Exercise: Greater love Your turn now to see if you can solve the greater exercise. You’ve been given the following (incomplete) function: func IsGreater[T /* Your constraint here! */](x, y T) bool { return x.Greater(y) } (Listing exercises/greater) This takes two values of some arbitrary type, and compares them by calling the Greater method on the first value, passing it the second value. The tests exercise this function by calling it with two values of a defined type MyInt, which has the required Greater method. type MyInt int func (m MyInt) Greater(v MyInt) bool { return m > v } func TestIsGreater_IsTrueFor2And1(t *testing.T) { t.Parallel() if !greater.IsGreater(MyInt(2), MyInt(1)) { t.Fatalf(\"IsGreater(2, 1): want true, got false\") } } func TestIsGreater_IsFalseFor1And2(t *testing.T) { t.Parallel() if greater.IsGreater(MyInt(1), MyInt(2)) { t.Fatalf(\"IsGreater(1, 2): want false, got true\") } } (Listing exercises/greater) GOAL: To make these tests pass, you’ll need to write an appropriate type constraint for IsGreater. Can you see what to do? HINT: Remember, we got here by talking about constraints as interface literals, and in particular, interface literals that refer to the type parameter. If you try to define some named interface with the method set containing Greater, for example, that won’t work. We can’t do it for the same reason that we couldn’t define a named interface with the method set Equal: we don’t know what type of argument that method takes. Just like Equal, Greater takes arguments of some arbitrary type T, so we need an interface literal that can refer to T in its definition. Does that help? SOLUTION: Here’s one way to do it: func IsGreater[T interface{ Greater(T) bool }](x, y T) bool { return x.Greater(y) } (Listing solutions/greater) Like most things, it’s delightfully simple once you know. For a type parameter T, the required interface is: Greater(T) bool And that’s how we do that. Well, I hope you enjoyed this tutorial series, and if so, why not treat yourself to a copy of Know Go? There’s much more to explore, so I’d love you to come along with me for the ride. John Arundel Go, golang, generics, interfaces, constraints, approximations, type sets Twitter LinkedIn0 Reddit John Arundel John Arundel Cras mattis consectetur purus sit amet fermentum. Integer posuere erat a ante venenatis dapibus posuere velit aliquet. Aenean eu leo quam. Pellentesque ornare sem lacinia quam venenatis vestibulum.",
    "commentLink": "https://news.ycombinator.com/item?id=42162878",
    "commentBody": "Constraints in Go (bitfieldconsulting.com)122 points by gus_leonel 10 hours agohidepastfavorite51 comments pansa2 6 hours agoI'm surprised by the complexity of Go's generic constraints, given the language's focus on simplicity. Things like the difference between \"implementing\" and \"satisfying\" a constraint [0], and exceptions around what a constraint can contain [1]: > A union (with more than one term) cannot contain the predeclared identifier comparable or interfaces that specify methods, or embed comparable or interfaces that specify methods. Is this level of complexity unavoidable when implementing generics (in any language)? If not, could it have been avoided if Go's design had included generics from the start? [0] https://stackoverflow.com/questions/77445861/whats-the-diffe... [1] https://blog.merovius.de/posts/2024-01-05_constraining_compl... reply burakemir 5 hours agoparentGenerics are a powerful mechanism, and there is a spectrum. The act of retrofitting generics on go without generics certainly meant that some points in the design space were not available. On the other hand, when making a language change as adding generics, one wants to be careful that it pulls its own weight: it would be be sad if generics had been added and then many useful patterns could not be typed. The design choices revolve around expressivity (what patterns can be typed) and inference (what annotations are required). Combining generics with subtyping and inference is difficult as undecidability looms. In a language with subtyping it cannot be avoided (or the resulting language would be very bland). So I think the answer is no, this part of the complexity could not have been avoided. I think they did a great job at retrofitting and leaving the basic style of the language intact - even if I'd personally prefer a language design with a different style but more expressive typing. reply tapirl 2 hours agoparentprevThe difference between types.Implements and types.Satisfies is mainly caused by a history reason. It is just a tradeoff between keeping backward compatibility and theory perfection. It is pity that Go didn't support the \"comparable\" interface from the beginning. If it has been supported since Go 1.0, then this tradeoff can be avoided. There are more limitations in current Go custom generics, much of them could be removed when this proposal (https://github.com/golang/go/issues/70128) is done. I recommend people to read Go Generics 101 (https://go101.org/generics/101.html, author here) for a thoroughly understanding the status quo of Go custom generics. reply jerf 3 hours agoparentprevIn practice, none of this impacts your program. The standard advice I give to people messing around with this stuff is, never use the pipe operator. The standard library already implements all the sensible uses of it. In particular, people tend to read it as the \"sum type\" operator, which it is not. I kind of wish the syntax has used & instead of |, what it is doing is closer to an \"and\" then an \"or\". By the time you know enough to know you can ignore that advice, you will. But you'll also likely find it never comes up, because, again, the standard library has already implemented all the sensible variants of this, not because the standard library is magic but because there's really only a limited number of useful cases anyhow. I haven't gone too crazy with generics, but I have used them nontrivially, even done s could tricks [1], and the pipe operator is not that generally useful. When the generic constraint is an interface with methods is the case that can actually come up, but that makes sense, if generics make sense to you at all. It probably is a good demonstration of the sort of things that come up on generic implementations, though. Despite the rhetoric people often deployed prior to Go having them, no, they are never easy, never without corner cases, never without a lot of complications and tradeoffs under the hood. Even languages designed with them from the beginning have them, just better stuffed under the rug and with less obvious conflict with other features. They're obviously not impossible, and can be worthwhile when deployed, certainly, but it's always because of a lot of work done by the language designers and implementations, it's never just \"hey let's use generics, ok, that one sentence finishes the design I guess let's go implement them in a could of hours\". [1]: Just about the edge of the \"tricky\" I'd advise: https://github.com/thejerf/mtmap reply tapirl 2 hours agorootparent> In particular, people tend to read it as the \"sum type\" operator, which it is not. I kind of wish the syntax has used & instead of |, what it is doing is closer to an \"and\" then an \"or\". I don't understand here. In my understanding, the pipe operator is indeed closer to \"or\" and \"sum type\" operator. Interpreting it as \"and\" is weird to me. reply Groxx 2 hours agorootparentI think they're reading it as \"a bitwise-and of the functionality of the types passed\", which is accurate (since you're getting the lowest common denominator of all |'d types). I'm... not sure which way I lean tbh, now that I've seen that idea. Both have merit, it's more of a problem for educational material than anything. If you present it as \"these types\",makes sense. If you instead use \"these behaviors\", & makes sense.is slightly easier to type for me though, and & has more meanings already (address-of), so maybe I'd still favor |. reply tapirl 2 hours agorootparentOkay, it is some reasonable if the operator is viewed as a behavior operator. But it is not, it is a type set operator. reply jerf 31 minutes agorootparentAnd the real point I'm making here is that \"the type set operator\" is not \"a sum type\". A sum type with, say, three branches is either the first, or the second, or the third, and to do anything with any of them, you have to deconstruct it, at which point you have full access to the deconstructed branch you are in. Theoperator in a Go generic is more a declaration of \"I want to operate on all of these at once\", so, you can put multiple numeric types into it because you can do a + or a - on any of them, but while the syntax permits you to put three struct types into it, and it'll compile, it does not produce a \"sum type\". Instead you get \"I can operate on this value with the intersection of all the operations they can do\", which is more or less \"nothing\". (\"Methods\" aren't \"operations\"; methods you can already declare in interfaces.) Some people particularly fool themselves because you can still take that type, cast it into an \"any\", and then type switch on it, but it turns out you can always do that, theoperator isn't helping you in any particular way, and if you want to have a closed set of types, a closed interface is a much better way to do it, on many levels. It also doesn't currently do anything else people may want it to do, like, accept three structs that each have a field \"A\" of type \"int\" and allow the generic to operate on at least that field because they all share it. There's a proposal I've seen to enable that, as the current syntax would at least support that, but I don't know what its status is. reply tapirl 9 minutes agorootparentThere is actually a proposal to make type constraints act as sum types: https://github.com/golang/go/issues/57644 But I doubt sum types will be supported perfectly in Go. The current a poor-man's sum type mechanism (type-switch syntax) might be still useful in future Go custom generic age. reply rendaw 5 hours agoparentprevThere are tons of random limitations not present in other languages too, like no generic methods. reply bigdubs 3 hours agorootparentThat's not a random limitation, there are very specific reasons[1] you cannot easily add generic methods as struct receiver functions. [1] https://go.googlesource.com/proposal/+/refs/heads/master/des... reply abound 2 hours agorootparentFor someone not well-versed in language implementation details, it may very well feel random. I've been using Go as my primary language for a decade, and the lack of generics on methods was surprising to me the first time I ran into it, and the reasoning not obvious. reply indulona 9 hours agoprevi have been writing Go exclusively for 5+ years and to this day i use generics only in a dedicated library that works with arrays(slices in Go world) and provides basic functionality like pop, push, shift, reverse, filter and so on. Other than that, generics have not really solved an actual problem for me in the real world. Nice to have, but too mush fuss about nothing relevant. reply Groxx 2 hours agoparentThat's kinda the point. Generics are mostly a library concern, improving end-user experience and performance. End-user creation of generic types is relatively rare, and you can use them in very simple ways and that's almost always good enough because you don't need them to be maximally correct, only good enough. For libraries (that adopt generics): yes they can be complicated. But using them is mostly zero-effort and gets rid of a ton of reflection. reply whateveracct 1 hour agoparentprevthis is wild because i use parametric polymorphism by writing `forall` in basically every Haskell PR i do for work ever i think Go having a pretty bad implementation of parametric polymorphism (a programming concept from the 70s) is probably the root cause here reply kgeist 8 hours agoparentprevJust checked, in my current project, the only place where I use generics is in a custom cache implementation. From my experience in C#, generics are mostly useful for implementing custom containers. It's nice to have a clean interface which doesn't force users to cast types from any. reply BlackFly 7 hours agorootparentContainers are sort of the leading order use of generics: I put something in and want to statically get that type back (so no cast, still safe). Second use I usually find is when I have some structs with some behavior and some associated but parameterizable helper. In my case, differential equations together with guess initializers for those differential equations. You can certainly do it without generics, but then the initial guess can be the wrong shape if you copy paste and don't change the bits accordingly. The differential equation solver can then take equations that are parameterized by a solution type (varying in dimension, discretisation and variables) together with an initializer that produces an initial guess of that shape. Finally, when your language can do a bit of introspection on the type or the type may have static methods or you have type classes, you can use the generic to control the output. Basically, they are useful (like the article implies) when you want to statically enforce constraints. Some people prefer implicitly enforcing the constraint (if the code works the constraint is satisfied) or with tests (if the tests pass the constraint is satisfied). Other people prefer to have the constraints impossible to not satisfy. reply aljarry 6 hours agorootparentprev> From my experience in C#, generics are mostly useful for implementing custom containers. That's my experience as well in C# - most of other usages of generics are painful to maintain in the long run. I've had most problems with code that joins generics with inheritance. reply neonsunset 3 hours agorootparentprevC# generics are way more powerful than that when it comes to writing high-performance or just very, err, generic code. Generic constraints and static interface members are immensely useful - you can have a constraint that lets you write ‘T.Parse(text[2..8])’. They are far closer to Rust in some areas (definitely not in type inference sadly, but F# is a different story) than it seems. Of course if one declares that they are an expert in a dozen of languages, most of which have poorly expressive type systems, the final product will end up not taking advantage of having proper generics. reply peterldowns 2 hours agoparentprevMy most common use of generics is when testing — check out my library for typesafe test comparisons. I find it really useful because I like having readable helpers for asserting in tests, but I also want compiler errors if I refactor things. https://github.com/peterldowns/testy reply gregwebs 6 hours agoparentprevThere’s an existing ecosystem that already works with the constraints of not having generics. If you can write all your code with that, then you won’t need generic much. That ecosystem was created with the sweat of library authors, dealing with not having generics and also with users learning to deal with the limitations and avoid panics. Generics have been tremendously helpful for me and my team anytime we are not satisfied with the existing ecosystem and need to write our own library code. And as time goes on the libraries that everyone uses will be using generics more. reply jppittma 4 hours agoparentprevThe most frequent use case I and my coworkers run into where we use them is when we want type covariance on a slice. I.e., when you want to write a function that take some slice of any type T that implements interface I, such that []T is a valid input instead of just explicitly []I. reply tonyedgecombe 8 hours agoparentprevI sometimes wonder if they should have implemented generics. On the one hand you had a group of people using go as it was and presumably mostly happy with the lack of generics. On the other side you have people (like me) complaining about the lack of generics but who were unlikely to use the language once they were added. It's very subjective but my gut feeling is they probably didn't expand their community much by adding generics to the language. reply sbrother 4 hours agorootparentHaving recently had to work on a Go project for the first time, I think I agree with you here. I'd tried Go a little bit when it came out, had zero interest in what it offered, and then when I was asked to work on this project a couple months ago I thought it would be fun to try it out again since I had read the language had improved. No, it still feels like programming with a blindfold on and one hand tied behind my back. I truly don't get it. I've worked with a lot of languages and paradigms, am not a zealot by any means. Other than fast compiles and easy binary distribution, I don't see any value here, and I see even experienced Go programmers constantly wasting time writing unreadable boilerplate to work around the bad language design. I know I must be missing something because some people much smarter than me like this language, but... what is it? reply indulona 27 minutes agorootparent> I see even experienced Go programmers constantly wasting time writing unreadable boilerplate if it is unreadable, in Go, probably the most readable language used today, i would question the aforementioned experience. reply quinnirill 2 hours agorootparentprevMad LoCs, dude, gotta make alotta lines, that’s what productivity is! reply vbezhenar 7 hours agorootparentprevGeneric containers are needed in some cases. Using generic containers with interface{} is very slow and memory-intensive. Not a problem for small containers, but for big containers it's just not feasible, so you would need to either copy&paste huge chunks of code or generate code. Compared to those approaches, generic support is superior in every way, so it's needed. But creating STL on top of them is not the indended use-case. reply cherryteastain 7 hours agorootparentprevI think a lot of the people who wanted generics wanted them more to be like C++ templates, with compile time duck typing. Go maintainers were unwilling to go that route because of complexity. However, as a result, any time I think \"oh this looks like it could be made generic\" I fall into a rabbit hole regarding what Go generics do and dont allow you to do and usually end up copy pasting code instead. reply wyufro 4 hours agorootparentI think \"oh this looks like it could be made generic\" is the wrong time to convert to generics. You should convert when you reach the point \"I wish I had that code but with this other type\". Even then, sometimes interfaces are the right answer, rather than generics. reply throwaway63467 8 hours agoparentprevHonestly so many things profit from generics, e.g. ORM code was very awkward before especially when returning slices of objects as everything was []any. Now you can say var users []User = orm.Get[User](…) as opposed to e.g var users []any = orm.Get(&User{}, …), that alone is incredibly useful and reduces boilerplate by a ton. reply indulona 8 hours agorootparentunderstandable. thee are always valid uses cases. although ORM in Go is not something that is widely used. reply vbezhenar 8 hours agorootparentprevORM is anti-pattern and reducing boilerplate is bad. reply TheDong 7 hours agorootparent> reducing boilerplate is bad Programming is about building abstractions, abstractions are a way to reduce boilerplate. Why do we need `func x(/* args / ) { / body */ }`, when you can just inline the function at each callsite and only have a single main function? Functions are simply a way to reduce boilerplate by deduplicating and naming code. If 'reducing boilerplate is bad', then functions are bad, and practically any abstraction is bad. In my opinion, \"reducing boilerplate is bad in some scenarios where it leads to a worse abstraction than the boilerplate-ful code would lead to\". I think you have to evaluate those things on a case-by-case basis, and some ORMs make sense for some use-cases, where they provide a coherent abstraction that reduces boilerplate... and sometimes they reduce boilerplate, but lead to a poor abstraction which requires more code to fight around it. reply bobnamob 6 hours agorootparentprevNot liking ORM I can understand, db tableobject impedance mismatch is real, but \"reducing boilerplate is bad\" is an interesting take. Can you elaborate and give some examples of why reducing boilerplate is generally \"bad\"? reply vbezhenar 4 hours agorootparentWhat I mean is reducing boilerplate is not something one should strive to achieve. It is not bad in the sense that one should introduce more boilerplate for the sake of it. But reducing boilerplate for the sake of it is not good thing either. If you need to make code more complex just to reduce boilerplate, it's a bad thing. If you managed go make code simpler and reduced boilerplate at the same time, it's a good thing. And boilerplate might be a good thing when you need to type something twice and if you would make error once, the whole thing wouldn't work, so basically you'll reduce the possibility of typo. It might look counter intuitive. Just unrelated example: recently I wrote C code where I need to type the same signature in the header file and in the source file. I made mistake in the source file, but I didn't make the same mistake in the header file and the whole program didn't link. I figured out the mistake and corrected it. Without this boilerplate it's possible that I wouldn't notice the mistake and \"helpful\" autocomplete would keep the mistake forever. That's how HTTP Referer header made it into standards, I guess. reply rad_gruchalski 6 hours agorootparentprevNot the person you’re replying to. The orm sucks because as soon as you go out of the beaten path of your average select/insert/update/delete, you are inevitably going to end up writing raw sql strings. Two cases in point: postgres cte and jsonb queries, there are no facilities in gorm for those, you will be just shoving raw sql into gorm. You might as well stop pretending. There’s a difference between having something writing the sql and mapping results into structs. The latter one can be done with the stdlib sql package and doesn’t require an „orm”. There are two things an sql lib must do to be very useful: prepared statements and mapping results. That’s enough. reply metaltyphoon 5 hours agorootparentPerhaps you have to yet use a good ORM? I could probably count on my fingers the times I had to drop to raw SQL in EFCore. Even when you do that you can still have mapped results, which reduces boilerplate. reply rad_gruchalski 4 hours agorootparentI’m doing this job for 25 years and I haven’t seen a good orm. Sorry. Look, linq is nice. But linq is not enough of a productivity gain to switch the whole stack from go to .net. I used linq 15 years ago extensively and it feel like magic. But then again, how would you model jsonb select for a variable set of of properties and include nested or and and conditions using its notation? Maybe you could but how much longer is it going to take you rather than templating a string? reply bobnamob 6 hours agorootparentprevYou haven’t answered my question at all. The parent comment made two claims: ORM not great (I agree) and “boilerplate reduction bad” which still needs some elaboration reply rad_gruchalski 4 hours agorootparentI answered it, you just don’t see it. One ends up with the boilerplate anyway as soon as one attempts to step out of the usual crud path. There’s no gain, there’s no difference in templating an sql string vs fighting an orm api. reply makapuf 8 hours agorootparentprevI agree. The best language to handle data in a RDBMs is SQL, and in that case the best language to handle application logic is Go (or Kotlin, Python or whatever). So there must be some meeting point. Handling everything in Go is not optimal, and all in sql not always practical. So how to avoid redundant data description ? I often have structs in a model Go file that reflect queries I do, but that's not optimal since I tend to have to repeat what's in a query to the language and the query to struct gathering is often boilerplate. I also almost can reuse the info I need for a query for another query but leave some fields blank since they're not needed.. the approaches are not optimal. Maybe a codegen sql to result structs / gathering info ? reply bluesnews 8 hours agorootparentprevCould you expand on this? I don't like ORM because in my experience you inevitably want full SQL features at some point but not sure if you have the same issues in mind or not reply vbezhenar 8 hours agorootparentORM is for object-relation mapping. Go is not object-oriented language and OOP-patterns are not idiomatic Go, so using ORM for Go cannot be idiomatic. That's generic answer. As for more concrete points: 1. Mapping SQL response to maps/structs or mapping maps/structs to SQL parameters might be useful, but that's rather trivial functionality and probably doesn't qualify as ORM. Things get harder when we're talking about complex joins and structs with relationships, but still manageable. 2. Introducing intermediate language which is converted to SQL is bad. Inevitably it will have less features. It will stay in the way for query optimisations. It'll make things much less obvious, as you would need to understand not only SQL, but also the process of translating intermediate language to SQL. 3. Automatic caching is bad. Database has its own caching and if that's not enough, application can implement custom caching where it makes sense. In my opinion the only worthy database integration could be implemented with full language support. So far I only saw it with C# LINQ or with database-first languages (PL/SQL, etc). C# and Go are like on opposite spectrum of language design, so those who use Go probably should keep its approach by writing simple, verbose and obvious code. reply kgeist 7 hours agorootparentI find libraries like sqlx more than enough. Instead of a full-blown ORM, they simply help hydrate Go structs from returned SQL data, reducing boilerplate. I prefer the repository pattern, where a repository is responsible for retrieving data from storage (using sqlx) using simple, clean code. Often, projects which use full-blown ORMs, tend to equate SQL table = business object (aka ActiveRecord) which leads to lots of problems. Business logic should be completely decoupled from underlying storage, which is an implementation detail. But more often than not, ORM idiosyncracies end up leaking inside business logic all over the place. As for complex joins and what not, CQRS can be an answer. For read queries, you can write complex raw SQL queries and simply hydrate the results into lightweight structs, without having to construct business objects at all (i.e. no need for object-relational mapping in the first place). Stuff like aggregated results, etc. Such structs can be ad hoc, for very specific use cases, and they are easy to maintain and are very fast (no N+1 problems, etc). With projects like sqlx, it's a matter of defining an additional struct and making a Select call. reply indulona 7 hours agorootparentprev> Go is not object-oriented language That is most definitely not true. Go just uses composition instead of inheritance. Still OOP, just the data flow is reversed from bottom to the top. reply nordsieck 5 hours agorootparent>> Go is not object-oriented language > That is most definitely not true. I think at best, you could say that Go is a multi-paradigm language. It's possible to write Go in an object oriented style. It's also possible to write programs with no methods at all (although you'd probably have to call methods from the standard library). That's in contrast to a language like Java or Ruby where it's actually impossible to avoid creating objects. reply pjmlp 5 hours agorootparentUnless you happen to want to warm up the CPU, there is very little Go code that is possible to write that does anything useful without OOP concepts, like interfaces, methods and dynamic dispatch. Creating objects on the heap isn't the only defining feature how a language does OOP or not. reply randomdata 3 hours agorootparentprevGo has objects, but objects alone does not imply orientation. For that, you need message passing. reply eweise 2 hours agoparentprevhere you go. func Ptr[T any](v T) *T { return &v } reply kaba0 7 hours agoparentprevWell, generics are mostly meant for library code. Just because you don't need it, doesn't mean that code you use doesn't need it. reply guilhas 1 hour agoprev [–] I like in Go how the code looks like a execution graph, by avoiding smarts and just copying code, when you have an error in the log you can generally just follow it through the code as there is only one path to get there. In C# I would have mostly to debug to understand where did it came from Not just because of the language, but of the simplify culture. Let's see how generics will change that reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This article is the final installment in a series about generics in the Go programming language, specifically focusing on constraints, a new feature.- Constraints in Go generics limit the types that can be used in generic functions, allowing for more precise operations by using basic interfaces like `fmt.Stringer`.- The series highlights various constraint types, such as type set constraints, unions, intersections, and interface literals, and encourages further exploration through the book \"Know Go\" by John Arundel."
    ],
    "commentSummary": [
      "Go's generic constraints introduce complexity, contrasting with the language's focus on simplicity, due to differences between \"implementing\" and \"satisfying\" a constraint and limitations on constraint contents.",
      "The complexity is partly attributed to retrofitting generics into Go, which was not initially designed to support them, sparking debate on their necessity and impact on the community.",
      "Despite the complexity, generics are considered beneficial for library code, though some developers question their necessity for specific use cases."
    ],
    "points": 122,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1731833069
  }
]
