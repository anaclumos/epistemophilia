[
  {
    "id": 42467194,
    "title": "The era of open voice assistants",
    "originLink": "https://www.home-assistant.io/blog/2024/12/19/voice-preview-edition-the-era-of-open-voice/",
    "originBody": "The era of open voice assistants has arrived Paulus Schoutsen December 19, 2024 Announcements Assist Comments TL;DR: Check out the product page We all deserve a voice assistant that doesn’t harvest our data and arbitrarily limit features. In the same way Home Assistant made private and local home automation a viable option, we believe the same can, and must be done for voice assistants. Since we began developing our open-source voice assistant for Home Assistant, one key element has been missing - great hardware that’s simple to set up and use. Hardware that hears you, gives you clear feedback, and seamlessly fits into the home. Affordable and high-quality voice hardware will let more people join in on its development and allow anyone to preview the future of voice assistants today. Setting a standard for the next several years to base our development around. We’re launching Home Assistant Voice Preview Edition to help accelerate our goal of not only matching the capabilities of existing voice assistants but surpassing them. This is inevitable: They’ll focus their efforts on monetizing voice, while our community will be focused on improving open and private voice. We’ll support the languages big tech ignores and provide a real choice in how you run voice in your home. The era of open, private voice assistants begins now, and we’d love for you to be part of it. Table of contents Introducing Home Assistant Voice Preview Edition Why Preview Edition Built for Home Assistant Advanced audio processing Bringing choice to voice Fully open and customizable Community-driven Conclusion See what voice can do today Introducing Home Assistant Voice Preview Edition Our main goal with Voice Preview Edition was to make the best hardware to get started with Assist, Home Assistant’s built-in voice assistant. If you’re already using other third-party hardware to run Assist, this will be a big upgrade. We prioritized its ability to hear commands, giving it an industry-leading dedicated audio processor and dual microphones - I’m always blown away by how well it picks up my voice around the room. Next, we ensured it would blend into the home, giving it a sleek but unobtrusive design. That’s not to say it doesn’t have flair. When you get your hands on Voice Preview Edition the first thing you’ll notice is its premium-feeling injection-molded shell, which is semi-transparent, just like your favorite ‘90s tech. The LED ring is also really eye-catching, and you can customize it to your heart’s content from full gamer RGB to subtle glow. It’s hard to convey how nice the rotary dial is to use; its subtle clicks paired with LED animations are hard not to play with. Most importantly, the dial lets anyone in your home intuitively adjust the volume. The same can be said for the multipurpose button and mute switch (which physically cuts power to the microphone for ultimate privacy). We knew for it to work best, it needed to be out in the open, and let’s just say that Home Approval Factor was very front of mind when designing it. We also worked hard to keep the price affordable and comparable to other voice assistant hardware at just $59 (that’s the recommended MSRP, and pricing will vary by retailer). This isn’t a preorder, it’s available now! Why Preview Edition For some, our voice assistant is all they need; they just want to say a couple of commands, set timers, manage their shopping list, and control their most used devices. For others, we understand they want to ask their voice assistant to make whale sounds or to tell them how tall Taylor Swift is - this voice assistant doesn’t entirely do those things (yet). We think there is still more we can do before this is ready for every home, and until then, we’ll be selling this Preview of the future of voice assistants. We’ve built the best hardware on the market, and set a new standard for the coming years, allowing us to focus our development as we prepare our voice assistant for every home. Taking back our privacy isn’t for everyone - it’s a journey - and we want as many people as possible to join us early and make it better. Built for Home Assistant Many other voice assistants work with Home Assistant, but this one was built for Home Assistant. Unlike other voice hardware that can work with Assist, this doesn’t require flashing firmware or any assembly. You plug it into power, and it is seamlessly discovered by Home Assistant. A wizard instantly starts helping you set up your voice assistant, but critically, if you haven’t used voice before, it will quickly guide you through what you need to get the best experience. Get up and running with Voice Preview Edition in minutes with our new wizard This is not a DIY product. We’ve worked to make the experience as smooth as possible, with easy and fast updates and settings you can manage from the Home Assistant UI. Advanced audio processing If you have been following our work on voice, you know we’ve tried a lot of different voice assistant hardware. Most available Assist-capable hardware is bad at its most important job - hearing your voice and then providing audiovisual feedback. That was really what drove us to build Voice Preview Edition. Voice Preview Editions mics and audio processors effortlessly hear commands through loud music it is playing Our Assist software could only do so much with substandard audio, and its functionality is massively improved with clear audio. The dual microphones combined with the XMOS audio processing chip are what makes it so capable. Together, they allow Voice Preview Edition to have echo cancellation, stationary noise removal, and auto gain control, which all adds up to clearer audio. This combined with an ESP32-S3 with 8 MB of octal PSRAM - one of the fastest ESP and RAM combinations available - makes for an incredibly responsive device. This is the best Assist hardware you can buy today, and it will continue to give a great experience as Assist’s feature set expands in the years to come. Bringing choice to voice Assist can do something almost no other voice assistant can achieve - it can run without the internet 🤯. You can speak to your Voice Preview Edition, and those commands can be processed completely within the walls of your home. At the time of writing this, there are some pretty big caveats, specifically that you need to speak a supported language and have pretty powerful hardware to run it (we recommend a Home Assistant system running on an Intel N100 or better). Diagram of cloud vs local speech processing If you use low-powered Home Assistant hardware, there is an easy and affordable internet-based solution; Home Assistant Cloud. This privacy-focused service allows you to offload your speech-to-text and text-to-speech processing, all while being very responsive and keeping your energy bill low. Speech-to-text is the harder of the two to run locally, and our cloud processing is almost always more accurate for more languages (visit our language support checker here). Our goal is for Assist to run easily, affordably, and fully locally for all languages. As someone who has seen the rapid development of this technology over the past several years, I’m optimistic that this will happen, but until then, many languages have a good range of choices that provide strong privacy. Fully open and customizable We are sharing the design files if you want to 3D print a new case... these ones were inevitable We’re not just launching a new product, we’re open sourcing all of it. We built this for the Home Assistant community. Our community doesn’t want a single voice assistant, they want the one that works for them – they want choice. Creating a voice assistant is hard, and until now, parts of the solution were locked behind expensive licenses and proprietary software. With Voice Preview Edition being open source, we hope to bootstrap an ecosystem of voice assistants. We tried to make every aspect of Voice Preview Edition customizable, which is actually pretty easy when you’re working hand-in-hand with ESPHome and Home Assistant. It works great with the stock settings, but if you’re so inclined, you can customize the Assist software, ESP32 firmware, and XMOS firmware. Connecting Grove sensors allows you to use your Voice Preview Edition as a more traditional ESPHome device - here is it acting as a voice assistant and air monitor. We also made the hardware easy to modify, inside and out. For instance, the included speaker is for alerts and voice prompts, but if you want to use it as a media player, connect a speaker to the included 3.5mm headphone jack and control it with software like Music Assistant. The included DAC is very clean and capable of streaming lossless audio. It can also be used as a very capable ESP32 device. On the bottom of the device is a Grove port (concealed under a cover that can be permanently removed), which allows you to connect a large ecosystem of sensors and accessories. We’ve also made it quite painless to open, with easy-to-access screws and no clips. We even included exposed pads on the circuit board to make modifying it more straightforward. We’re providing all the 3D files so you can print your own components… even cartoon character-inspired ones. We’re not here to dictate what you can and can’t do with your device, and we tried our best to stay out of your way. Community-driven The beauty of Home Assistant and ESPHome is that you are never alone when fixing an issue or adding a feature. We made this device so the community could start working more closely together on voice; we even considered calling it the Community edition. Ultimately, it is the community driving forward voice - either by taking part in its development or supporting its development by buying official hardware or Home Assistant Cloud. So much has already been done for voice, and I can’t wait to see the advancements we make together. Conclusion Home Assistant values champions choice. Today, we’re providing one of the best choices for voice hardware. One that is truly private and totally open. I’m so proud of the team for building such a great working and feeling piece of hardware - this is a really big leap for voice hardware. I expect it to be the hardware benchmark for open-voice projects for years to come. I would also like to thank our language leaders who are expanding the reach of this project, our testers of this Preview Edition, and anyone who has joined in our voice work over the past years. The hardware really is only half the picture, and it’s the software that really brings this all together. Mike Hansen has just written the Voice Chapter 8 blog to accompany this launch, and this explains all the things we’ve built over the past two years to make Assist work in the home today. He also highlights everything that Voice Preview Edition was built to help accelerate development. See what voice can do today",
    "commentLink": "https://news.ycombinator.com/item?id=42467194",
    "commentBody": "The era of open voice assistants (home-assistant.io)573 points by _Microft 18 hours agohidepastfavorite210 comments steelframe 48 minutes agoIf it's possible for the hardware to facilitate a use case, the employees working on the product will try to push the limits as far as they possibly can in order to manufacture interesting and challenging problems that will get them higher performance ratings and promotions. They will rationalize away privacy violations by appealing to their \"good intentions\" and their amazing ability to protect information from nefarious actors. In their minds they are working for \"the good guys\" who will surely \"do the right thing.\" At various times in the past, the teams involved in such projects have at least prototyped extremely invasive features with those in-home devices. For example, one engineer I've visited with from a well-known in-home device manufacturer worked on classifiers that could distinguish between two people having sex and one person attacking another in audio captured passively by the microphones. As the corporate culture and leadership shifts over time I have marginal confidence that these prototypes will perpetually remain undeveloped or on-device only. Apple, for instance, has decided to send a significant amount of personal data to their \"Private Cloud\" and is taking the tactic of opening \"enough\" if its infrastructure for third-party audit to make an argument that the data they collect will only be used in a way that the user is aware and approves of. Maybe Apple can get something like that to a good enough state, at least for a time. However, they're inevitably normalizing the practice. I wonder how many competitors will be as equally disciplined in their implementations. So my takeaway is this: If there exists a pathway between a microphone and the Internet that you are not in 100% control over, it's not at all unreasonable to expect that anything and everything that microphone picks up at any time will be captured and stored by someone else. What happens with that audio will -- in general -- be kept out of your knowledge and control so long as there is insufficient regulatory oversight. reply Jarwain 14 hours agoprevI'm actually really excited for this! I noticed recently there weren't any good open source hardware projects for voice assistants with a focus on privacy. There's another project I've been thinking about where I think the privacy aspect is Important, and figuring out a good hardware stack has been a Process. The project I want to work on isn't exactly a voice assistant, but same ultimate hardware requirements Something I'm kinda curious about: it sounds like they're planning on a sorta batch manufacturing by resellers type of model. Which I guess is pretty standard for hardware sales. But why not do a sorta \"group buy\" approach? I guess there's nothing stopping it from happening in conjunction I've had an idea floating around for a site that enables group buys for open source hardware (or 3d printed items), that also acts like or integrates with github wrt forking/remixing reply pimeys 6 hours agoparentI'm also very excited. I've had some ESP32 microphones before, but they were not really able to understand the wake word, sometimes even when it was quiet and you were sitting next to the mic. This one looks like it can recognize your voice very well, even when music is playing. Because... when it works, it's amazing. You get that Star Trek wake word (KHUM-PUTER!), you can connect your favorite LLM to it (ChatGPT, Claude Sonnet, Ollama), you can control your home automation with it and it's as private as you want. I ordered two of these, if they are great, I will order two more. I've been waiting for this product for years, it's hopefully finally here. reply nine_k 2 hours agorootparentAs a side note, it always slightly puzzles me when I see \"voice interface\" and \"private\" used together. Maybe it takes living alone to issue voice commands and feel some privacy. (Yes, I do understand that \"privacy\" here is mostly about not sending it for processing to third parties.) reply iteria 52 minutes agorootparentI don't like these interaces because unless they are button activated or something, they must be always listening and sending sound from where you are to a 3rd party server. No thanks. Of course this could be happening with my phone, but at least it have to be a malicious action to record me 24/7 reply staunton 2 hours agorootparentprev> Yes, I do understand that \"privacy\" here is mostly about not sending it for processing to third parties. Then why does it puzzle you? reply entropicdrifter 1 hour agorootparentBecause you wouldn't ask it deeply private questions in front of your mom, for instance reply IgorPartola 13 hours agoparentprevA group buy for an existing product makes sense. Want to buy a 24TB Western Digital hard drive? It’s $350. But if you and your 1000 closest friends get together the price can be $275. But for a first time unknown product? You get a lot fewer interested parties. Lots of people want to wait for tech reviews and blog posts before committing to it. And group buys being the only way to get them means availability will be inconsistent for the foreseeable future. I don’t want one voice assistant. I want 5-20, one for every space in my house. But I am not prepared to commit to 20 devices of a first run and I am not prepared to buy one and hope I’ll get the opportunity to buy more later if it doesn’t flop. Stability of the supply chain is an important signal to consumers that the device won’t be abandoned. reply esperent 10 hours agorootparent> But for a first time unknown product? You get a lot fewer interested parties. Lots of people want to wait for tech reviews and blog posts before committing to it. I used to think so too. But then Kickstarter proved that actually, as long as you have a good advertising style, communicate well, and get lucky, you can get people to contribute literal millions for a product that hasn't even reached the blueprints stage yet. reply IgorPartola 5 hours agorootparentKickstarter isn't a group buy. reply yunohn 5 hours agorootparentKickstarter is often basically a group buy. Project owners make MVPs and market/pitch it, get funding from the public, and then commission a large batch run. reply bhaney 13 hours agorootparentprev> I am not prepared to buy one and hope I’ll get the opportunity to buy more later As long as this thing works and there's demand for it, I doubt we'll ever run out of people willing to connect an XU316 and some mics to an ESP32-S3 and sell it to you with HA's open source firmware flashed to it, whether or not HA themselves are still willing to. reply Jarwain 9 hours agorootparentI agree! I mean, just look at the market for Meshtastic devices! So many options! Or devices with WLED pre-installed! It'll take a Lot for Esp32 to go out of style reply ascorbic 12 hours agorootparentprevKickstarter shows that a lot of people feel different. reply IgorPartola 5 hours agorootparentKickstarter isn’t a group buy. Similar, but not the same. reply Brendinooo 13 hours agoparentprevI invested in Mycroft and it flopped. Here’s hoping some others can go where they couldn’t. reply tacticalturtle 37 minutes agorootparentI believe Mycroft was killed in part due to a patent troll: https://www.theregister.com/AMP/2023/02/13/linux_ai_assistan... Hopefully the troll is no longer around reply bronco21016 7 hours agorootparentprevI think Mycroft was unfortunately just ahead of its time. STT was just becoming good enough but NLU wasn’t quite there yet. Add in you’re up against Apple Google and Amazon who were able to add integrations like music and subsidize the crap out of their products. I just think this time around is different. Open Whisper gives them amazing STT and LLMs can far more easily be adapted for the NLU portion. The hardware is also dirt cheap which makes it better suited to a narrow use case. reply bdavbdav 10 hours agorootparentprevI guess the difference here is that HA has a huge community already. I believe the estimate was around 250k installations running actively. I suspect a huge chunk of the HA users venn diagram slice fits within the voice users slice. reply balloob 7 hours agorootparentOur estimates are more than a million active instances https://analytics.home-assistant.io/ reply emsixteen 5 hours agorootparentMore than a million? It says on the page: \"424,548 Active Home Assistant Installations\" Am I missing something? Is it that these are just those you know are sharing details, and you can scale that up by a known percentage? :) reply schnapsidee 3 hours agorootparent> Analytics in Home Assistant are opt-in and do not reflect the entire Home Assistant userbase. We estimate that a third of all Home Assistant users opt in. reply alias_neo 2 hours agorootparentprevI'm a big fan of home assistant, and use it to control a LOT of my home, have done for years, have tonnes of hardware dedicated to and for it, and I've also ordered some of these Voice devices. I'm also opted OUT of the analytics. reply geerlingguy 5 hours agorootparentprevIIRC one of the main devs behind this device came from Mycroft. reply robotfelix 5 minutes agorootparentYep, Mike Hansen was on the live stream launching the new device. He also notably created Rhasspy [1], which is open-source voice assistant software for Raspberry Pi (when connected to a microphone and speaker). [1] https://rhasspy.readthedocs.io/en/latest/ reply dole 3 hours agorootparentprevOP's username checks out. reply choffee 9 hours agoparentprevNot really sure what the benefit of group buy would be here. Nuba Casa, the company that supports the development of home assistant and developed this product, already has a few products they sell. They had this stocked all over the world for the announcement and it sold out. I assume they had already made a few thousand. They will get more stock now and it will sell just like the other things they make. Any profit from this will go back into development of Home Assistant. reply Jarwain 3 hours agorootparentHeh thus far I've been an excited spectator of HomeAssistant, and wasn't aware of Nuba Casa until doing research for a different comment on the thread. I do love and appreciate their model here I guess the benefits that came to mind are - alternative crowdsourced route for sourcing hardware, to avoid things like that raspberry pi shortage (although if it's due to broader supply chain issues then this doesn't necessarily help) - hardware forks! If someone wanted a version with a more powerful ESP32, or a GPS, or another mic, or an enclosure for a battery and charging and all that, took the time to fork the design to add these features, and found X other users interested in the fork to get it produced... (of course I might be betraying my ignorance on how easy it is to set up this sort of alternative manufacturing chain or what unit amounts are necessary to make this kind of forking economical) reply interludead 11 hours agoparentprevYour idea about group buys is really intriguing. I wonder if the community might organically set something like that up once there’s enough interest reply thumbsup-_- 14 hours agoprevWe need more projects like home assistant. I started using it recently and was amazed. They sell their own hardware but the whole setup is designed to works on any other hardware. There are detailed docs for installation on your own hardware. And, it works amazingly well. Same for their voice assistant. You can but their hardware and get started right away or you can place your own mics and speakers around home and it will still work. You can but your own beefy hardware and run your own LLM. The possibilities with home assistant are endless. Thanks to this community for breaking the barriers created by big tech reply PhilippGille 7 hours agoparent> We need more projects like home assistant Isn't openHAB an existing popular alternative? https://www.openhab.org/ reply tedivm 7 minutes agorootparentI think they meant \"projects with a culture and mindset like homeassistant\", not just a competitor to the existing project. reply btreecat 6 hours agorootparentprevHA long ago blew past OpenHAB in functionality and community. Unless you have a hard-on for JVM services, HA is the better XP these days. reply yurishimo 5 hours agorootparentWhen I was evaluating both projects about 5 years ago, I went with openHAB because they had native apps with native controls (and thus nicer design imo). At the time, HA was still deep in YML config files and needed validation before saving etc etc. Not great UX. Nowadays, HA has more of the features I would want and other external projects exist to create your own dashboards that take advantage of native controls. Today I’m using Homey because I’m still a sucker for design and UX after a long day of coding boring admin panels in the day job, but I think in another few years when the hardware starts to show its age that I will move to home assistant. Hell, there exists an integration to bring HA devices into Homey but that would require running two hubs and potentially duplicating functionality. We shall see. reply diggan 6 hours agorootparentprev> HA long ago blew past OpenHAB in [...] community. Home Assistant seems insurmountable to beat at that specific metric, seems to be the single biggest project in terms of contributions from a wide community. Makes sense, Home Assistant tries to do a lot of things, and succeeds at many of them. reply lokar 13 hours agoparentprevIt’s a great project overall, but I’ve been frustrated by how anti-engineer it has been trending. reply gerdesj 3 hours agorootparentInstall the Node-RED add on. I use that to do the tricky stuff. Install the whole thing on top of stock Debian \"supervised\" then you get a full OS to use. You get a fully integrated MQTT broker with full provisioning - you don't need a webby API - you have an IoT one instead! This is a madly fast moving project with a lot of different audiences. You still have loads of choice all tied up in the web interface. reply sofixa 11 hours agorootparentprevDo you mean the move away from YAML first configs? I was originally somewhat frustrated, but overall, it's much better (let's be honest, YAML sucks) and more user friendly (by that I mean having a form with pre-filled fields is easier than having to copy paste YAML). reply lokar 3 hours agorootparentYes, config is a major part of it. But also a lack of good APIs, very poor dev documentation, not great logging. A general “take it or leave it” attitude, not interesting in enabling engineers to build. reply cryptoegorophy 1 hour agorootparentprevOh thank got. Just started using HA few months ago and all these yaml is so confusing when I try to code it with ChatGPT , constant syntax or some other random errors. reply philjohn 10 hours agorootparentprevIt's worse though when you need to add a ton of custom sensors at once, e.g., for properly automating a Solar PV + Battery solution. reply ncallaway 10 hours agorootparentBut like, isn't YAML still available for configuring things? Have they gotten rid of any YAML configs, with things that are now UI only? My understanding was that they've just been building more UI for configuring things and so now default recommend people away from YAML (which seems like the right choice to me). reply ramses0 1 hour agorootparentFor \"integrated\" stuff, their stance is \"UI Must Work\". Tracing down the requirements, here: https://design.home-assistant.io/#concepts/home https://developers.home-assistant.io/docs/configuration_yaml_index https://github.com/home-assistant/architecture/blob/master/adr/0010-integration-configuration.md ...usually there's YAML kicking around the backend, but for normal usage, normal users, the goal is to be able to configure all (most) things via UI. I've had to drop to YAML to configure (eg) writing stats to indexdb/graphana vs. sqlite (or something), or maybe to drop in or update an API_KEY or non-standard host/port, but 99% of the time the config is baroque, but usable via the web-app. reply sofixa 9 hours agorootparentprev> But like, isn't YAML still available for configuring things? For most, yes. But for some included integrations it's UI-only (all of those I've had to migrate, it's been a single click + comment out lines, and the config has been a breeze (stuff like just an api key/IP address + 1-2 optional params). reply lolinder 6 hours agorootparentWhere and how are those configs stored? There has to be a backing representation somewhere, right? reply sofixa 5 hours agorootparentIn the Home assistant database (which is SQLite IIRC). reply iamjackg 3 hours agorootparentUI-generated configs are not stored in the database, they end up in a collection of JSON files in a .storage directory inside your config directory. reply lokar 3 hours agorootparentprevAnd there is no real API for you to interact with it. I would build my own config system if I could, but they don’t seem interested. reply lolinder 38 minutes agorootparentSQLite is highly automatable if you can deal with downtime to do your migrations. I'm sure there are things they could do to better support the power-user engineer use case, but at the end of the day it's a self-hosted web app written in Python that has strong support for plugins. There should be very few things that an engineer couldn't figure out how to do between writing a plugin, tweaking source code, and just modifying files in place. And in the meantime I'm glad that it exists and apparently has enough traction to pay for itself. reply thfuran 12 hours agorootparentprevHow so? reply mkagenius 14 hours agoparentprevI am working on automation of phones (open source) - https://github.com/BandarLabs/clickclickclick I haven't been able to quite get the Llama vision models working but I suppose with new releases in future, it should work as good as Gemini in finding bounding boxes of UI elements. reply interludead 11 hours agoparentprevCompletely agree! Home Assistant feels like a breath of fresh air in a space dominated by big tech's walled gardens. reply afh1 15 minutes agoprevMy experience with home assistance voice pipeline is nothing works and stt is terrible. I'll have to wait and see the reviews. reply joshstrange 13 hours agoprevIt's too bad it's sold out everywhere. I've tried the ESP32 projects (little cube guy) for voice assistants in HA but it's mic/speaker weren't good enough. When it did hear me (and I heard it) it did an amazing job. For the first time I talked to a voice assistant that understood \"Turn off office lights\" to mean \"Turn off all the lights in the office\" without me giving it any special grouping (like I have to do in Alexa and then it randomly breaks). It handled a ton of requests that are easy for any human but Alexa/Siri trip up on. I cannot wait to buy 5 or more of these to replace Alexa. HA is the brain of my house and up till now Alexa provided the best hardware to interact with HA (IMHO) but I'd love something first-party. reply bdavbdav 10 hours agoparentHow did you find it for music tasks? reply joshstrange 5 hours agorootparentI didn’t test that. I normally just manually play through my Sonos speaker groups on my phone. I don’t like the sound from the Echos so I’m not in the habit of asking them to do anything related to music. Right now I only use Alexa for smart house control and setting timers reply moffkalast 4 hours agoparentprevI'm definitely buying one for robotics, having a dedicated unit for both STT and TTS that actually works and integrates well would make a lot of social robots more usable and far easier to set up and maintain. Hopefully there's a ROS driver for it eventually too. reply IshKebab 55 minutes agoprevLooks great! The biggest issue I see is music. 90% of my use is \"play some music\" but none of the major streaming music providers offer APIs for obvious reasons. I'm not sure how you can get around that really. reply antonyt 26 minutes agoparentTo do this in Home Assistant, you'd probably want to run Music Assistant and integrate it in. Looks like they manage to support some streaming providers, not entirely sure how: https://music-assistant.io/music-providers/ Getting it to play the right thing from voice commands is a bit of a rabbit hole: https://music-assistant.io/integration/voice/ reply zbrozek 1 hour agoprevIs anyone aware of an effort to repurpose Echo hardware to do HA voice? reply jfim 15 hours agoprevThat's a pretty timely release considering Alexa and the Google assistant devices seem to have plateaued or are on the decline. reply IgorPartola 13 hours agoparentCurious what you mean by that. reply oaththrowaway 13 hours agorootparentFor me the Alexa devices I own have gotten worse. Can't do simple things (setting a timer used to be instant, now it takes 10-15 seconds of thinking assuming it heard properly), playing music is a joke (will try to play through Deezer even though I disaled that integration months ago, and then will default to Amazon Music instead of Spotify which is set as the default). And then even simple skills can't understand what I'm asking 60% of the time. The first maybe 2 years after launch it seemed like everything worked pretty good but since then it's been a frustrating decline. Currently they are relagated to timers and music, and it can't even manage those half the time anymore. reply IgorPartola 5 hours agorootparentThat’s interesting because I have a bunch of Echos of various types in my house and my timers and answers are instant. Is it possible your internet connection is wonky or you have a slow DNS server or congested Wi-Fi? I don’t have the absolute newest devices but the one in my bedroom is the very original Echo that I got during their preview stage, the one in my kitchen is the Echo Show 7” and I have a bunch of puck ones and spherical ones (don’t remember the generations) around the house. One did die at one point after years of use and got replaced but it was in my kids room so I suspect it was subject to some abuse. reply creeble 1 hour agorootparentI too get pretty consistent response and answers from Alexa these days. There has been some vague decline in the quality of answers (I think sometime back they removed the ability to ask for Wikipedia data), but have no trouble with timers and the few linked wemo switches I have. I’m also the author of an Alexa skill for a music player (basic “transport” control mostly) that i use every day, and it still works the same as it always did. Occasionally I’ll get some freakout answer or abject failure to reply, but it’s fairly rare. I did notice it was down for a whole weekend once; that’s surely related to staffing or priorities. reply lelag 10 hours agorootparentprevIt is, I think, a common feeling among Echo/Alexa users. Now that people are getting used to the amazing understanding capabilities of ChatGPT and the likes, it probably increases the frustration level because you get a hint of how good it could be. I believe it boils down to two main issues: - The narrow AI systems used for intent inference have not scaled with the product features. - Amazon is stuck and can't significantly improve it using general AI due to costs. The first point is that the speech-to-intent algorithms currently in production are quite basic, likely based on the state of the art from 2013. Initially, there were few features available, so the device was fairly effective at inferring what you wanted from a limited set of possibilities. Over time, Amazon introduced more and more features to choose from, but the devices didn't get any smarter. As a result, mismatches between actual intent and inferred intent became more common, giving the impression that the device is getting dumber. In truth, it’s probably getting somewhat smarter, but not enough to compensate for the increasing complexity over time. The second point is that, clearly, it would be relatively straightforward to create a much smarter Alexa: simply delegate the intent detection to an LLM. However, Amazon can’t do that. By 2019, there were already over 100 million Alexa devices in circulation, and it’s reasonable to assume that number has at least doubled by now. These devices are likely sold at a low margin, and the service is free. If you start requiring GPUs to process millions of daily requests, you would need an enormous, costly infrastructure, which is probably impossible to justify financially—and perhaps even infeasible given the sheer scale of the product. My prediction is that Amazon cannot save the product, and it will die a slow death. It will probably keep working for years but will likely be relegated by most users to a \"dumb\" device capable of little more than setting alarms, timers, and providing weather reports. If you want Jarvis-like intelligence to control your home automation system, the vision of a local assistant using local AI on an efficient GPU, as presented by HA, is the one with the most chance of succeeding. Beyond the privacy benefits of processing everything locally, the primary reason this approach may become common is that it scales linearly with the installation. If you had a cloud-based solution using Echo-like devices, the problem is that you’d need to scale your cloud infrastructure as you sell more devices. If the service is good, this could become a major challenge. In contrast, if you sell an expensive box with an integrated GPU that does everything locally, you deploy the infrastructure as you sell the product. This eliminates scaling issues and the risks of growing too fast. reply freedomben 9 hours agorootparentIt seems ridiculous to me that this comment is so down voted. It's a thoughtful and interesting comment, and contains a reasonable and even likely explanation for what we've seen, once one puts aside the bottom that Amazon is just evil, which isn't a useful way to think of you truly want to understand the world and motivations. I'm guessing people reflexively down vote because they hate Amazon and it could read like a defense. I hate Amazon too, but emotional voting is unbecoming of HN. If you want emotional voting reddit is available and enormous. reply imiric 8 hours agorootparentI didn't downvote it, but claiming that Echo/Alexa are behind because of financial reasons is misguided at best. Amazon is one of the richest companies on the planet, with vast datacenters that power large parts of the internet. If they wanted to improve their AI products they certainly have the resources to do so. reply thanksgiving 7 hours agorootparentHow do you justify to your manager to spend (and more importantly commit to spending for a long time) hundreds of millions of dollars in aws resources every year? Sure, you already have the hardware but that's a different org, right? You can't expect them to give you those resources for free. Also, voice needs to be instant. You can't say 'Well, the AWS instances are currently expensive. Try again when my spot prices are lower.\" I am sure you know this but maybe some don't know that basically only the hot word detection is on device. It needs to be connected to the Internet for basically everything else. It already costs Amazon.com some money to run this infrastructure. What we are asking will cost more and you can't really charge the users more. I personally would definitely not sign up for a paid subscription to use Amazon Alexa. reply gorbachev 1 hour agorootparentprevEven the richest company in the world doesn't run unprofitable projects forever. Just see Killed by Google. reply imiric 16 minutes agorootparentThat depends on the company. There is precedent of large companies keeping unprofitable projects alive because they can make up for it in other ways, or it's good for marketing, etc. I.e. the razor and blades business model. Perhaps Echo/Alexa entice users to become Prime members, and they're not meant to be market leaders. We can only speculate as outsiders. My point is that claiming that a product of one the richest companies on Earth is not as subjectively good as the competition because of financial reasons is far-fetched. reply baq 6 hours agorootparentprevAlexa is probably a cool billion under or something. They never figured out how to make money with it. reply IgorPartola 5 hours agorootparentprevThis is very well thought out but I think your premise is a bit wrong. I have about a dozen Echos of various generations in my house. The oldest one is the very original from the preview stage. They still do everything I want them to and my entire family still uses them daily with zero frustration. Local GPU doesn’t make sense for some of the same reasons you list. First, hardware requirements are changing rapidly. Why would I spend say $500 on a local GPU setup when in two years the LLM running on it will slow to a crawl due to limited resources? Probably would make more sense to rent a GPU on the cloud and upgrade as new generations come out. Amazon has the opposite situation: their hardware and infra is upgraded en masse so different economies. Also while your GPU is idling at 20-30W while you aren’t home they can have 100% utilization of their resources because their GPUs are not limited to one customer at a time. Plus they can always offload the processing by contracting OpenAI or similar. Google is in an even better position to do this. Running a local LLM today doesn’t make a lot of sense, but it probably will at some point in like 10 years. I base this on the fact that the requirements for a device like a voice assistant are limited so at some point the hardware and software will catch up. We saw this with smartphones: you can now go 5 years without upgrading and things still work fine. But that wasn’t the case 10 years ago. Second, Amazon definitely goofed. They thought people would use the Echos for shopping. They didn’t. Literally the only uses for them are alarms and timers, controlling lights and other smart home devices, and answering trivia questions. That’s it. What other requirements do you have that don’t fall in this category? And the Echos do this stuff incredibly well. They can do complex variations too, including turning off the lights after a timer goes off, scheduling lights, etc. Amazon is basically giving these devices away but the way to pivot this is to release a line of smart devices that connect to the Echos: smart bulbs and switches, smart locks, etc. They do have TVs which you can control with an Echo fairly well (and it is getting better). An ecosystem of smart devices that seamlessly interoperate will dwarf what HA has to offer (and I say this as someone who is firmly on HA’s side). And this is Amazon’s core competency: consumer devices and sales. If your requirement is that you want Jarvis, it’s not the voice device part of it that you want. You want what it is connected to: a self driving car you can summon, DoorDash you can order by saying “I want a pizza”, a phone line so it can call your insurance company and dispute a claim on your behalf. Now the last piece here is privacy and it’s a doozy. The only way to solve this for Amazon is to figure out some form of encrypted computation that allows for your voice prompts to be processed without them ever hearing clear voice versions. Mathematically possible, practically not so much. But clearly consumers don’t give a fuck whatsoever about it. They trust Amazon. That’s why there are hundreds of millions of these devices. So in effect while people on HN think they are the target market for these devices, they are clearly the opposite. We aren’t the thought leaders, we are the Luddites. And again I say this as someone who wishes there was a way to avoid the privacy issue, to have more control over my own tech, etc. I run an extensive HA setup but use Echos for the voice control because at least for now they are be best value. I am excited about TFA because it means there might be a better choice soon. But even here a $59 device is going to have a hard time competing with one that routinely go on sale for $19. reply stavros 7 hours agorootparentprevI think the economics here are wrong by orders of magnitude. It doesn't make sense to deploy to the home an expensive GPU that will sit idle 99% of the time, unless running an LLM gets much cheaper, computationally. It's much cheaper to run it on-premise and charge a subscription, otherwise nobody would pay for ChatGPT and would have an LLM rig at home instead. reply lelag 6 hours agorootparentYou are right, but that's not my point. The point is that it's difficult to scale in the cloud products that requires lots of AI workloads. Here, home assistant is telling you: you can use your own infra (most people won't) or you can use our cloud. It works because most likely the user base will be rather small and home assistant can get cloud resources as if it was infinite on that scale. If their product was amazing, and suddenly millions of people wanted to buy the cloud version, they would have a big problem: cloud infrastructure is never infinite at scale. They would be limited by how much compute their cloud provider is able/willing to sell them, rather than how much of that small boxes they could sell, possibly loosing the opportunity to corner the market with a great product. If you package everything, you don't have that problem (you only have the one to be able to make the product, which I agree is also not small). But in term of energy efficiency, it also does not have to be that bad: the apple silicon line has shown that you can have very efficient hardware with significant AI capabilities, if you design a SOC for that purpose, it can be energy efficient. Maybe I'm wrong that the approach will get common, but the fact that scaling AI services to millions of users is hard stand. reply stavros 5 hours agorootparentBut here you're assuming that your datacenter can't provide you with X GPUs, but you can manufacture 100X, which is dictated by 1% utilization. reply mrweasel 4 hours agorootparentprevAmazon also fired a large number of people from the Alexa team last year. I don't really think Alexa is a major priority for Amazon at this point. I don't blame them, sure there are millions of devices out there, but some people might own five device. So there aren't as many users as there are devices and they aren't making them any money once bought, not like the Kindle. Frankly I know shockingly few people who uses Siri/Alexa/Google Assistant/Bixby. It's not that voice assistants don't have a use, be it is a much much small use case than initially envisioned and there's no longer the money to found the development, the funds went into blockchain and LLMs. Partly the decline is because it's not as natural an interface as we expected, secondly: to be actually useful, the assistants need access to control things that we may not be comfortable with, or which may pose a liability to the manufacturers. reply interludead 11 hours agorootparentprevThat aligns with some of the frustration I’ve heard from others. It’s surprising (and disappointing) how these platforms, which seemed to have so much potential early on, have started to feel more like a liability reply stickfigure 2 hours agorootparentprevI was an early adopter of google home, have had several generations (including the latest). I quite like the devices, but the voice recognition seems to be getting worse not better. And the Pandora integration crashes frequently. In addition, it's a moron. I'm not sure it's actually gotten dumber, but in the age of chatgpt, asking google assistant for information is worse than asking my 2nd grader. Maybe it will be able to quote part of a relevant web page, but half the time it screws that up. I just want it to convert my voice to text, submit it to chatgpt or claude, and read the response back to me. All that said, the audio quality is good and it shows pictures of my kid when idle. If they suddenly disappeared I would replace them. reply bdavbdav 10 hours agorootparentprevGH is basically abandonware at this stage it seems. They just seem to break random things, and there haven’t been any major updates / features for ages (and Gemini is still a way off for most). reply cachvico 4 hours agorootparentGoogle Home's Nest integration is recent and top-notch though. Hopefully in a year they'll have rolled out the Gemini integration and things will be back on track. reply lolinder 5 hours agorootparentprevOn the Google side it's become basically useless for anything beyond interacting with local devices and setting timers and reminders (in other words, the things that FOSS should be able to do very easily). Its only edge over other options used to be answering questions quickly without having to pull out a screen, but now it refuses to answer anything (likely because Google Search has removed their old quick answers in favor of Gemini answers). reply sreejithr 1 hour agoprevGenuine question - How hackable is this? Can I have the voice commands redirected to my backend server where I can process it as I please? reply balloob 1 hour agoparentThis is Home Assistant. Everything is hackable. Inside Home Assistant the processing is delegated to integrations providing Speech-to-Text, command processing, Text-to-Speech. You can make custom integrations for all of them reply entropicdrifter 1 hour agoparentprevIt's fully open-source. I think the default use-case is to have the voice commands processed locally reply Havoc 9 hours agoprevHad to laugh a bit at the caveat about powerful hardware. Was bracing myself for GPU and then it says N100 lol reply moooo99 9 hours agoparentI mean, comparatively many people are hosting their home Assistant on an raspberry Pi so it is relatively powerful :D reply geerlingguy 5 hours agorootparentAnd the CM5 is nearly equivalent in terms of the small models you run. Latency is nearly the same, though you can get a little more fancy if you have an N100 system with more RAM, and \"unlocked\" thermals (many N100 systems cap the power draw because they don't have the thermal capacity to run the chip at max turbo). reply moffkalast 4 hours agorootparentIf we're being fair you can more like, walk models, not run them :) An 125H box may be three times the price of an N100 box, but the power draw is about the same (6W idle, 28W max, with turbo off anyway) and with the Arc iGPU the prompt processing is in the hundreds, so near instant replies to longer queries are doable. reply hamilyon2 7 hours agoprevI had great trouble simply connecting Bluetooth speaker to use it as voice input and for sound output. The overall state of sound subsystem for diy voice assistant feels third-class at best. reply frognumber 15 hours agoprevI don't fully understand the cloud upsell. I have a beefy GPU. I would like to run the \"more advanced\" models locally. By \"I don't fully understand,\" I mean just that. There's a lot of marketing copy, but there's a lot I'd like to understand better before plopping down $$$ for a unit. The answers might be reasonable. Ideally, I'd be able to experiment with a headset first, and if it works well, upgrade to the $59 unit. I'd love to just have a README, with a getting started tutorial, play, and then upgrade if it does what I want. Again: None of this is a complaint. I assume much of this is coming once we're past preview addition, or is perhaps there and my search skills are failing me. reply antonyt 14 hours agoparentYou can do exactly that - set up an Assist pipeline that glues together services running wherever you want, including a GPU node for faster-whisper. The HA interface even has a screen where you can test your pipeline with your computer’s microphone. It’s not exactly batteries-included, and doesn’t exercise the on-device wake word detection that satellite hardware would provide, but it’s doable. But I don’t know that the unit will be an “upgrade” over most headsets. These devices are designed to be cheap, low-power, and have to function in tougher scenarios than speaking directly into a boom mic. reply frognumber 15 minutes agorootparentIt's an upgrade mostly because putting on a headset to talk to an assistant means it's not worth using the assistant. reply ilaksh 13 hours agorootparentprevDoes it use Node-RED for the pipeline? reply haddonist 12 hours agorootparentNo, all of the voice parts are either inbuilt or direct addons. reply trb 15 hours agoparentprevFinding microphones that look nice, can pick up voice at high enough quality to extract commands and that cover an entire room is surprisingly hard. If this device delivers on audio quality it's totally worth it at $59. reply alias_neo 2 hours agorootparentI've found it quite hard to find decent hardware with both the input capability needed for wakeword and audio capture at a distance, whilst also having decent speaker quality for music playback. I started using the Box-3 with heywillow which did amazing input and processing using ML on my GPU, but the speaker is aweful. I build a speaker of my own using a raspberry pi Z2W, dac and some speakers in a 3d printed enclosure I designed, and added a shim to the server so that responses came from my speaker rather than the cheap/tiny speaker in the box-3. I'll likely do the same now with the Voice PE, but I'm hoping that the grove connector can be used to plonk it on top of a higher quality speaker unit and make it into a proper music player too. As soon as I have it in my hands, I intend to get straight to work looking at a way to modify my speaker design to become an addon \"module\" for the PE. reply bdavbdav 10 hours agorootparentprev100%. For a lot of users that have WAF and time available to contend with, this is a steal. Bear in mind that a $50 google home or Alexa mini(?) is always going to be whatever google deem it to be. This is an open device which can be whatever you want it to be. That’s a lot of value in my eyes. reply choffee 8 hours agoparentprevThis device is just the mic/speaker/wakeword part. It connects to home-assistant to do the decoding and automation. You can test it right now by downloading home-assistant and running it on a pi or a VM. You can run all the voice assist stuff locally if you want. There are services for the voice to text, text to voice and what they call intents which are simple things like \"turn off the lights in the office\". The cloud offering from Nuba Casa, not only funds the development of Home Assistant but also give remote access if you want it. As part of that you can choses to offload some of the voice/text services to their cloud so that if you are just running it on a Pi it will still be fast. reply Jarwain 14 hours agoparentprevI can't speak to home assistant specifically, but the last time I looked at voice models, supporting multiple languages and doing it Really Well just happens to require a model with a massive amount of RAM, especially to run at anything resembling real-time. It's be awesome if they open sourced that model though, or published what models they're using. But I think it unlikely to happen because home assistant is a sorta funnel to nabu casa That said, from what I can find, it sounds like Assist can be run without the hardware, either with or without the cloud upgrade. So you could definitely use your own hardware, headset, speakers, etc. to play with Assist reply frognumber 10 minutes agorootparentshrug whisper seems to do well on my GPU, and faster than realtime. reply nickthegreek 14 hours agoparentprevThe cloud sale is easy if you are an HA user already. If you don’t use Home Assistant right now, you probably rec it the target audience. I purchase the yearly cloud service as it’s an easy way to support HA development. It also gives you remote access to your system without having to do any setup. It provides an https connection which allows you to program esp32 devices through Chrome. And now they added the ability to do TTS and STT on someone else’s hardware. HA even allows you to setup a local llm for house control commands but route other queries directly to the cloud. reply frognumber 11 minutes agorootparentI don't mind paying for hardware. I do mind my privacy, and don't want that kind of information in the cloud, or even traces from encryption I haven't audited myself. reply fons 9 hours agoprevI wonder how this compares to the Respeaker 2 https://wiki.seeedstudio.com/ReSpeaker_Mic_Array_v2.0/ The respeaker has 4 mics and can easily cancel out the noise introduced by a custom external speaker reply robotfelix 8 hours agoparentIt's worth noting that product is listed in the \"Discontinued Products\" section of the linked wiki. Both of the ReSpeaker products in the non-discontinued section (ReSpeaker Lite, ReSpeaker 2-Mics Pi HAT) have only 2 mics, so it appears that things are converging in that direction. reply alias_neo 2 hours agorootparentThe S3-Box-3 also only has two mics, and I found I can talk to that from another room of the house and it detects what I said perfectly fine. reply stavros 9 hours agoparentprevI don't just want the hardware, I want the software too. I want something that will do STT on my speech, send the text to an API endpoint I control, and be able to either speak the text I give it, or live stream an audio response to the speakers. That's the part I can't do on my own, and then I'll take care of the LLMs myself. reply alias_neo 2 hours agorootparentAll of these components are available separately or as add-ons for Home Assistant. I currently do STT with heywillow[0] and an S3-Box-3 which uses an LLM running on a server I have to do incredibly fast, incredibly accurate STT. It uses Coqui XTTS for TTS, with very high quality LLM based voice; you can also clone a voice by supplying it with a few seconds of audio (I tested cloning my own with frightening results). Playback to a decent speaker can be done in a bunch of ways; I wrote a shim that captures the TTS request to Coqui and forwards it to a Pi based speaker I built, running MPD which then requests the audio from the STT server (Coqui) and plays it back on my higher quality speaker than the crappy ones built in to the voice-input devices. If you just want to use what's available HA, there's all of the Wyoming stuff, openWakeword (not necessary if you're using this new Voice PE because it does on-device wakeword), Piper for TTS, or MaryTTS (or others) and Whisper (faster-whisper) for STT, or hook in something else you want to use. You can additionally use the Ollama integration to hook it into an Ollama model running on higher end hardware for proper LLM based reasoning. [0]heywillow.io reply stavros 2 hours agorootparentI do the same, Willow has been unmaintained for close to a year, and calling it \"incredibly fast\" and \"incredibly accurate\" tells me that we have very different experiences. reply alias_neo 2 hours agorootparentIt's a shame it's been getting no updates, I noticed that, but their secret sauce is all open stuff anyway so just replace them with the upstream components; their box-3 firmware and the application server is really the bit they built (as well as the \"correction\" service). If it wasn't fast or accurate for you, what were you running it on? I'm using the large model on a Tesla GPU in a Ryzen 9 server, using the XTTS-2 (Coqui) branch. The thing about ML based STT/TTS and the reasoning/processing is that you get better performance the more hardware you throw at it; I'm using nearly £4k worth of hardware to do it; is it worth it? No, is it reasonable? Also no, but I already had the hardware and it's doing other things. I'll switch over to Assist and run Ollama instead now there's some better hardware with on-device wake-word from Nabu. reply bradly 4 hours agoprevAre there any MacOS software versions of this? I've been looking for opensource wake-work for a \"Hey Siri\"-like integration, but I'm very apprehensive of anything, malicious or not, monitoring the sound input for a specific word in an efficient way. reply ragmondo 5 hours agoprevMy plea / request : Make a home assistant a DROP IN replacement for a standard light switch. It has power, its adds functionality from the get-go (smart lighting), it’s placed in a convenient position for the room and no extra wires etc required. reply sirtaj 2 hours agoparentThe now 8-year-old blog post titled \"Perfect Home Automation\"[1] on the HA website agrees with you from the first heading, and is borne out by my personal experience too. Nobody in your house should need to retrain to do things they are already doing. 1. https://www.home-assistant.io/blog/2016/01/19/perfect-home-a... reply throwaway4220 4 hours agoparentprevWould a zigbee or z wave switch fit your needs? It’s “offline” but does need a hub reply Carrok 5 hours agoparentprevLook at Shelly light switches. reply timdiggerm 4 hours agorootparentYou've misunderstood what they're asking for. They're asking for Home Assistant hardware (microphone, speaker, wifi) that, instead of being a standalone box taking up space on the counter/table/etc, fits into the hole in the hall where they currently have a lightswitch. reply Carrok 4 hours agorootparentI guess I did misunderstand, because that request seems strange to me. I’m assuming they have more than one switch. Which one should have Home Assistant on it? Seems like an odd deployment strategy. A pi isn’t that big.. reply jazzyjackson 4 hours agorootparentNot OP but if I have to have a CPU and microphone for voice commands anyway it doesn’t sound crazy to throw a whole pi/relay node into every room of the house that I want to have control of. Pi zero 2 is fifteen bucks and can run Whisper speech2text iirc, throw ChatScript on there for local command decoding and call it a day. I think I’d pay 50 to 100 per room for the convenience, paying a premium to not have my voice surveilled by Alexa just to set timers. reply ragmondo 4 hours agorootparentWithout trying to digress, but why not make it modular too ? I.e. base model is a smart switch, one unit is the “base” unit and the rest talk to that. Possibly even add further switches, dials (thermostat or dimmer etc). Perfect placement in my opinion. reply jazzyjackson 4 hours agorootparentSuppose I have a bias for meshnet vs hub and spoke. Seems to me having full power cpu on every mic is going to be better experience latency and glitchwise than streaming audio feeds around. Of course they would still talk to each other to pass commands around. reply hn92726819 4 hours agorootparentprevNo I don't think that's it either. Home assistant runs on a server somewhere still. What the top level comment is asking for, completely unrelated to the article mind you, is to have a smart device in the form factor of a light switch that you can hook into your home assistant system. The problem they likely have (I have it too) is that you set HA up and it can control smart plugs, smart thermostats, etc, but it can't control 99% of the existing lights in your house because they are wired to dumb lightswitches. Instead of some mechanical finger flicking a switch or something, why not uninstall the existing light switch and replace it with a smart one. reply Carrok 4 hours agorootparentSo my original comment was not a misunderstanding. They are smart switch drop in replacements. reply hn92726819 2 hours agorootparentYeah, you're right. That is a weird request then, or I don't understand it either. I didn't realize something like [1] goes inside your switch. I was expecting a switch with a faceplate combined. 1: https://us.shelly.com/products/shelly-1-gen3 reply Carrok 1 hour agorootparentThey also make what you’re describing. reply moffkalast 4 hours agorootparentprevNot the home assistant controller, but a peripheral. A light switch you can toggle manually or through the assistant. I think the problem with this setup is that it needs to be wifi connected, and if you embed an esp32 inside a wall it will get exactly zero signal. Maybe with external antennas hidden in the switch outer case. reply jazzyjackson 4 hours agorootparent? I have my house packed to the brim with tplink Wi-Fi smart switches, they work fine. https://www.tp-link.com/us/home-networking/smart-switch/ reply moffkalast 3 hours agorootparentAh right I forget I'm talking to Americans on an American site, who all have walls made out of wood and gypsum. Try that with brick and steel reinforced concrete lol. reply jazzyjackson 2 hours agorootparent:) reply Carrok 4 hours agorootparentprevThe switches I linked are esp32. They live inside the wall. They get great signal. reply ragmondo 4 hours agorootparentprevYes - exactly this. If there are multiple needed, then some can be smarter/ more capable than others, but this removes the “just another box and cable(s)” issue. reply NegativeK 5 hours agorootparentprevAgreed. They sell UL rated models, have an option for cloud connectivity but zero requirement, your switch still works if the Shelly loses connectivity with whatever home automation server you have, and it's a small box that you wire in behind the switch. reply Carrok 5 hours agorootparentThey also make drop in replacement dimmer switches. Even easier than the small box style. https://us.shelly.com/products/shelly-plus-wall-dimmer reply dboreham 3 hours agoprevIt isn't even one year since the press stories about how dumb a product Alexa was and how it makes no money and all the devs are getting laid off. Something changed now? reply iamjackg 3 hours agoparentWell, the various Echo devices were allegedly built as loss leaders in the hope people would use them to make orders on Amazon. This is backed by the most active open source project on GitHub, which already has extensive support for voice pipelines both with and without LLMs, and is likely priced sensibly. A lot has changed in the open source ecosystem since commercial assistants were first launched. We have reliable open source wakeword detectors, and cheap/free LLMs can do the intent parsing, response generation, and even action calling. reply eightysixfour 3 hours agoparentprevIt was a bad product at making money for Amazon, but they are useful for smart homes. Home Assistant is pretty squarely in the smart home category. I bought two the second they were announced, I already use the software stack with the m5 atoms and they are terrible devices, but the software works well enough for me. reply marcosdumay 3 hours agoparentprevIf it's not clear, the Home Assistant business plan is different from the Amazon one for Alexa... and the Home Assistant open source project is even more different. reply sirtaj 3 hours agoparentprevI've been using the HA cloud voice assistant on my phone for the past few weeks, and it's such a great change from Alexa, because integrating new services and adding sentences is actually possible. Alexa, on the other hand, won't even allow a third party app to read its shopping list. It's no longer clear to me why Alexa even exists any more except as a kitchen timer. reply baq 1 hour agorootparentThey must be working on a LLM backend for it so it isn't dumb as a rock. Nothing makes sense otherwise, agreed. reply jmuguy 2 hours agoparentprevAmazon lost 25 billion dollars on Alexa (between 2017 and 2021, from WSJ https://archive.is/uMTOB). Selling the hardware at a loss and I imagine a bigger portion was the thousands of people they had working in that division. So yeah, Alexa is a dumb product... for Amazon. No one uses Alexa to buy anything from Amazon because the only way you can be sure of what you're ordering from Amazon is to be looking at the site. Otherwise you might get cat food from \"JOYFUNG BEST Brand 2024\" and not Purina. Voice Assistants for Home Automation, like what Home Assistant is offering, are awesome. And this in particular is exciting exactly because of Alexa's failure as a product. Amazon clearly does not care about Alexa now, its been getting worse as they try to shoehorn in more and more monetization strategies. reply causal 58 minutes agorootparent> “We worried we’ve hired 10,000 people and we’ve built a smart timer,” said a former senior employee. How the hell did Amazon hire that many people to develop such low-tech devices. reply weird-eye-issue 3 hours agoparentprevHuh? Being able to do things like turn off lights or change the TV volume with your voice is actually quite a nice convenience reply hoppp 14 hours agoprevIf it runs fully on premise that would be great. Im still not comfortable buying a device that records everything I say and uploads it to a cloud reply haddonist 12 hours agoparentFully on-prem can be done if you've got the LLM compute power in place. reply fx1994 10 hours agoprevWhat I don't like is that most voice assistances perform really bad on my native language so I don't use them at all. For english speakers yes, but for all other not so much. I guess it will get better. reply choffee 8 hours agoparentThat is one of the major things that Home Assistant are trying to fix. They have groups working on most languages and are adding them to their open as they improve. https://www.home-assistant.io/voice_control/contribute-voice reply shaklee3 13 hours agoprevAs someone not that familiar with haas, can someone explain why there's not a clear path to replace Alexa or Google home? I considered using haas recently to get a gpt like response after being frustrated with Google home, but it seems this is a complete mess. is there a way to get this yet? reply joshstrange 13 hours agoparent> explain why there's not a clear path to replace Alexa or Google home? There is. I've used HA with their default assist pipeline (Cloud HA STT, Cloud HA LLM, Cloud HA TTS) and I've also plugged in different providers at each step (both remote and local for each part: STT/LLM/TTS) and it's super cool. Their default LLM isn't great but it works, plugging in OpenAI made it work way better. My local models weren't great in speed but I don't have hardware dedicated for this purpose (currently), seeing an entire local pipeline was amazing for the promise of it in the future. It's too slow (on my hardware) but we are so close to local models (SST/TTS could be improved as well but they are much easier to do already locally). If this new HA hardware comes even close to performing as well as the Echo's in my house (low bar) I'll replace them all. reply jazzyjackson 4 hours agorootparentWhat does it use LLMs for? reply joshstrange 4 hours agorootparentTaking the text of what you said and figuring out what you want to do. It sends what you said plus a list of devices/states and a list of functions (to turn off/on, set temp, etc of devices). The LLM takes \"Turn off basement lights\" and turns that into \"{function: \"call_service\", args: ['lights.on', 'entity-id-123']}\" ( No wake words: it should listen to everything, process it, and understand when it's being addressed Even humans struggle with this one - that's what names are for! reply antonyt 13 hours agorootparentYeah, I’m having a hard time imagining how no-wake-word could work in practice. reply ethbr1 5 hours agorootparentLike that really annoying friend who jumps in every other sentence with \"Well actually...\" reply marcosdumay 3 hours agorootparentI have a coworker that set up an Alexa an year or so ago, I don't know what was the issue, but it would jump into Teams meetings after every noise in his house. reply fragmede 12 hours agorootparentprevafter setting up the system, if I say \"turn the ceiling lights to 20%\", who else would be changing the lights? But also, post-fix wake word would also be natural if it was recording all the time. \"turn on the lights, Google\", for instance reply TheCoelacanth 1 hour agorootparentSomeone in a TV show that you're watching? reply wild_egg 13 hours agoparentprevHow much are you willing to pay though? Full privacy means powerful enough hardware to do everything else on the list on-device and _quickly_. I don't know that most people have the budget for that reply Lanolderen 8 hours agoparentprevI'd imagine with 1-2 TVs constantly talking, general conversations and other random noises it'd get expensive quick. Definitely closer to a rack than a RaspPi or old laptop hardware wise. Also add to that more/better mics for coverage and the complexity of it guessing when you're asking it to remind you to buy toothpaste or your SO... It can probably be done by tracking who's home, who's in the room with the speaker, who the speaker is, etc but it's all cost.. reply nissarup 11 hours agoparentprevLooks like you are in the market for a butler. Especially your last point will, IMO, not be possible for a long time. reply micromacrofoot 3 hours agoparentprevwithout a wake word that's a lot of compute unless you live alone and don't watch tv or listen to music they even used a wake word in star trek fwiw reply nailer 2 hours agoprevYou should talk to Sonos about partnering with them. They currently have a very limited Sonos voice assist, plus Google Voice and Alexa, but the latter two are limited pre-LLM assistants. I’m assuming they eventually want to create their own LLM and something privacy focused would be good match for their customers. I don’t know how they feel about open source though reply jve 14 hours agoprevWhile we are getting shoveled AI keyword everywhere, I'm actually disappointed I don't see it here. The first thought I had when encountering LLM was that it can finally make these devices understand you and make them finally useful... and I don't need to know some presceipted keywords. reply antonyt 14 hours agoparentYou can actually integrate LLMs with Assist pipelines, it’s just orthogonal to this hardware announcement. Check out https://www.home-assistant.io/blog/2024/06/05/release-20246/... reply shepherdjerred 14 hours agoprevHome Assistant is such a fantastic project. I've been waiting for something like this for a long time; I just pre-ordered three. My only remaining wish is that I can replace Siri with this (without needing some workaround) reply singularity2001 10 hours agoprevsorry if this question takes away from the great strives the team went through but wouldn't it be much easier (hardware wise) to jailbreak one of the existing great hardware thingies like Apple HomePod or the Google one or Alexa? reply alias_neo 2 hours agoparentThe fact that it hasn't (widely?) been done yet suggests the answer is \"no\". The hardware in those devices is generally better, most of them have much better speakers, but they're locked down, the wake-word detection hardware isn't open or accessible so changing it to do what we need would be difficult, and you're just hoping there's a way in. Existing examples of opening them (as in freedom) replace the PCB entirely, which puts you back to square one of needing open hardware. This feels like the right approach to me; I've been building my own devices for this purpose with off-the-shelf parts, and designing enclosures, but this is much sleeker; I just hope an add-on or future version comes with much better audio out (speakers) because that's where it and things like it (e.g. the S3-Box-3) are really lacking. reply singularity2001 26 minutes agoparentprevor maybe find cheap Chinese smart speaker which is hackable? reply robotfelix 8 hours agoparentprevI've picked up an Echo Dot a few years ago when Amazon were practically giving them away, thinking that surely someone would have jailbroken it by now to allow it to be used with Home Assistant. It was only after researching later that I discovered that this wasn't currently possible and recommended approach was to buy some replacement internals that cost more than the device itself (and if I recall correctly, more than the new Home Assistant Voice Preview Edition). reply choffee 8 hours agoparentprevI don't think they are that easy to jail break but I may be wrong. I think they wanted to create an open device that people could build from rather than just a hacked up alexa. reply catmanjan 14 hours agoprevAll I want is a voice assistant that I can call \"computer\" like Star Trek, I don't want to have to say a brand name thankyou! reply antonyt 14 hours agoparentIf you run openWakeWord, “computer” is one of very many pretrained models the community has made: https://github.com/fwartner/home-assistant-wakewords-collect... reply dartos 14 hours agoparentprevYou could’ve always set Alexa to respond to “Computer” instead. reply catmanjan 14 hours agorootparentAh I admit I haven't looked into it for several years, good to see they added the feature - I might have to grab one reply bigstrat2003 11 hours agorootparentThe problem is that it will go off every single time you watch Star Trek. reply nickthegreek 14 hours agoprevAnd on back order everywhere. I just spent the last 2 weeks getting a esp32-s3-box setup to do this but its lack of audio out really irks me. reply joshstrange 13 hours agoparentAnd the mic is not all that great either. I have a couple of them but they just weren't reliably picking up my voice and I couldn't hear the reply either (when it did hear me). I figured it would be easy to add a speaker to them but that sent me down a rabbit hole that I gave up on and put them in a drawer. I'll buy this for sure though because when the ESP32 box thing worked it worked really well and I loved being able to swap out parts of the assist pipeline. reply alias_neo 2 hours agorootparentTo be fair, the issue with the Box-3 is HA's implementation; I used it with heywillow.io and it was incredible, I could speak to it from another room and it would pick up perfectly. The audio out is terrible so I wrote a shim-server that captures the request to the TTS server for heywillow and sent it to a speaker I build myself running MPD on a Pi with a nice DAC and have it play the responses instead of the box-3's tiny speaker. I don't expect the audio-out on this to be much better with its tiny speaker, but at least it has a 3.5mm jack. I'm going to look into what that Grove port can do too and perhaps build a new speaker \"module\" that the Voice PE can sit on top of to make it a proper music device. reply nickthegreek 4 hours agorootparentprevI ended up moddng the s3 yaml to turn off the internal speaker and to forward all voice responses to a google hub. reply yzydserd 12 hours agoparentprev> And on back order everywhere. I just clicked through to my large country and the first vendor and was able to buy 2 for delivery tomorrow. So it says. So maybe not on back order everywhere. reply sofixa 11 hours agoparentprevIf it's an ESP32-S3-BOX-3, there is audio out (assuming you mean being able to send arbitrary audio to it to play). Due to the framework used it's not available, but there's an alternative firmware available on GitHub that uses the newer framework and it exposes a media player entity you can send any audio to. reply nickthegreek 4 hours agorootparentI didn’t have the -3 version. Learned the hard way after loading up that alt framework last week and the screen went blank I did end up implementing that same solution on my hardware though. reply delijati 11 hours agoprevPerfect will dig more into it. Currently i like to have an spotify client without ui for my kids ;) reply ahaucnx 11 hours agoprevIt's not clear to me from the description if this is also completely open source hardware. Are the schematics, BoM, firmware published under a permissible license? If so, where are they accessible? And if not, I would be curious to know why it haven't been fully open sourced. reply choffee 8 hours agoparentI would think so in the end. They talked about the case design being open. The software and firmware are all open already and they said that they really wanted people to be able to take these components and make new devices. They have relesased the designs for the yellow so I assume it will all come. https://github.com/NabuCasa/yellow reply unshavedyak 3 hours agoprevWell shoot. Now i want to record everything in my house and transcribe it for logs. I already wanted to do that but didn't think there was a sane way.. assuming this lets me create a custom pipeline, that's wicked reply IG_Semmelweiss 14 hours agoprevCan someone describe the use case here? I don't quite understand what its purpose is. Is this a fully-private, open source alternative to Alexa, that by definition requires a CPU locally to run ? Is the device supposed to be the nerve center of IoT devices ? Can it access the Wifi to do web crawls on command (music, google, etc)? reply antonyt 13 hours agoparentThe nerve center would be your Home Assistant instance, which is not this device. You can run Home Assistant on whatever hardware you like, including options sold by Nabu Casa. This device provides the microphone, speaker, and WiFi to do wake-word detection, capture your input, send it off to your HA instance, and reply to you with HA’s processed response. Whether your HA instance phones out to the internet to produce the response is up to you and how you’ve configured it. reply IvyMike 14 hours agoparentprevIf you have home automation, surely you've run into this situation when Comcast flakes (or similar): \"OK, Google, turn lights on\" \"Check your connection and try again\" As far as I can tell, if you have Home Assistant + this new device, you've fixed that problem. reply leeoniya 10 hours agoprevanyone tried https://getleon.ai/ ? reply skyde 2 hours agoprevhow does this compare to ESP32-S3-BOX-3B ? reply solarkraft 10 hours agoprevRIP Mycroft. A tad too early. reply choffee 8 hours agoparentNabu Casa employ one of the Mycroft devs now and i think some of the tech came from that project so it's not all gone :) reply interludead 11 hours agoprevI think in some ways it could redefine how we think about voice control... taking it from the cloud and putting it back into users' hands, like literally reply cranberryturkey 8 hours agoprevhttps://linuxvoice.ai reply jauntywundrkind 14 hours agoprevNot super convinced the XMOS audio processing chip is really gonna buy a lot. Trying to do audio input processing feels like a dynamic task, requiring such adaption. XMOS is the most well known audio processor and a beast, but not sure it's really gonna help here! I really hope we see some open-source machine -learned systems emerge. I saw Insta360 announce their video conferencing solution today. Optics looks pretty medium, nothing wild, but Insta360 is so good at video that I expect it'll be great. But there's a huge 14 microphone array on it, and that's the hard job; figuring out how to get good audio from speakers in a variety of locations around a room. It really made me wish for more open source footing here, some promising start, be it the conference room or open living space. I've given all of 60s to look through this, and was kinda hopeful because heck yeah Home Assistant, but my initial read isn't super promising, isn't that this is starting the proper software base needed to listen well to the world. https://petapixel.com/2024/12/17/the-insta360-connect-is-a-2... reply choffee 7 hours agoparentThey showed a video at the end of their broadcast last night comparing what the raw microphone hears and what comes out of the XMOS chip and you can hear a much clearer voice all the time even when there is noise or you are far away from the device. It is also used to cancel out the music if you are using it's speaker output. I don't think it's doing any voice processing but it's cleaning up the audio a lot which makes the job of the wake word processor and the speach to text a lot easier. Up until now this was missing from a lot of the home made voice assistance and I think why Alexa can understand you from the next room but my home made one struggles with all but quiet conditions. reply summm 50 minutes agorootparentAlexa Echo Dot has 6 or 7 microphones. I'd expect that makes it much easier to filter out voices directionally than only the 2 microphone this hardware has. I hope they release a version with more microphones. reply bsdice 6 hours agoprevMajel Barrett voice please. reply albybisy 6 hours agoprev [–] i don't wanna talk to a computer reply cheema33 6 hours agoparent [–] > i don't wanna talk to a computer You are in luck. You can get a human butler. But not for $59. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Home Assistant has introduced the Voice Preview Edition, a private, local voice assistant that prioritizes user privacy by not collecting data or restricting features.- The device is open-source, customizable, and supports local processing, allowing users to modify both hardware and software without needing an internet connection.- Priced at $59, it aims to surpass existing voice assistants by focusing on privacy and community-driven open development, featuring advanced audio processing with dual microphones and a dedicated audio processor."
    ],
    "commentSummary": [
      "The discussion centers on the development of open-source voice assistants, with a focus on Home Assistant's new device, highlighting privacy concerns and limitations of commercial options like Alexa and Google Home.",
      "There is significant interest in integrating advanced models and local processing to improve functionality while ensuring user privacy.",
      "The conversation also addresses the challenges of hardware development and the potential for community-driven projects to create more open-source solutions in the voice assistant market."
    ],
    "points": 574,
    "commentCount": 210,
    "retryCount": 0,
    "time": 1734654597
  },
  {
    "id": 42468318,
    "title": "My favourite colour is Chuck Norris red",
    "originLink": "https://htmhell.dev/adventcalendar/2024/20/",
    "originBody": "My favourite colour is Chuck Norris red by Declan Chidlow published on Dec 20, 2024 Setting the colour of text on a webpage is usually a simple affair involving whipping it out the good ol' CSS color property. But this is HTMHell, dammit. None of that wishy-washy CSS nonsense here. No siree. We use HTML as the good lord intended and shalln't stray into the sins of cascading sheets lest we end up some non-HTML variant of hell where they define page structure with JavaScript vars. But HTML isn't great for defining styles -- or at least, it isn't anymore. If we wind back the clocks a few years to HTML versions of old, we find the colour attribute. If you've been around for a while, you've no doubt seen it. Something like this: HTMHell rules! HTMHell rules! If we render that in a browser, we get some text in the lovely HTMHell red. That's great. That's what we'd expect. Next we'll choose another colour. Something a bit different. Let's try 'chucknorris'. But... Chuck Norris isn't a colour. But... Chuck Norris isn't a colour. If you go through the effort of loading that up in a browser, you might notice it makes the text red. Why? Some funny character parsing HTML generally doesn't have an error state, at least not one akin to what would happen if writing something like invalid JavaScript. Browsers are very forgiving when parsing HTML (which explains how people have gotten away with the crimes documented throughout this website) and generally do their best to make up for user error. If you leave a dangling , the browser will do its best to close it up and render it out. This forgiveness is the reason behind the funkiness. Browsers simply try to forge ahead with the invalid value and hope it'll work. In the past web browsers all handled invalid values a bit differently, but now it's all outlined in the \"rules for parsing a legacy color value\" part of the HTML spec. A surmised version of the parsing outlined there is as follows: Initial Cleanup: If an octothorpe (#) is located at the start of the value, it's removed. The colour attribute only accepts hexes, so there isn't a point keeping it. Example: \"#FF0000\" becomes \"FF0000\". Replace Invalid Characters: Any non-hexadecimal characters (anything not 0-9 or A-F/a-f) are removed and replaced with '0'. Example: 'abcxyz123' becomes 'abc000123'. Standardise Length: While the string's length is 0 or not divisible by 3, append '0'. Examples: \"F\" becomes \"F00\" (padded to length 3). \"FFFF\" becomes \"FFFF00\" (padded to length 6). \"FFFFFF0\" becomes \"FFFFFF000\" (padded to length 9). Split into Red, Green, and Blue: The first third becomes the red value. The second third becomes the green value. The last third becomes the blue value. Example: \"FFFFFF000\" becomes [\"FFF\", \"FFF\", \"000\"]. Handle Length: If any component is longer than 8 characters, remove the characters from the left until it's 8 characters long. Example: \"123456789\" → \"23456789\" While the length is greater than 2, and all components start with '0', remove the leading '0' from each component. Example: [\"000F\", \"000F\", \"000F\"] becomes [\"00F\", \"00F\", \"00F\"] which then becomes [\"0F\", \"0F\", \"0F\"]. If length is still greater then 2 keep only the first 2 characters of each component. Example: [\"ABC\", \"DEF\", \"123\"] becomes [\"AB\", \"DE\", \"12\"]. Putting It Together: Get the final red, blue, and green components, then put them together in that order to create the colour. Example: [\"AB\", \"DE\", \"12\"] becomes ABDE12. I've written a small tool over on CodePen that will take any inputted value, break down the processing step by step, and output the colour as it would be handled. Go have a bit of fiddle! See the Pen Legacy HTML Colour Parsing Demo by Declan Chidlow (@OuterVale) on CodePen. Some fun examples So, we know this happens and why. The next task is obviously to have some fun with it. Finding words whose computed colours correlate with them is great fun. For example, 'Sonic' gives us a lovely blue like the hedgehog. I've put together a little table of some of these coincidental match ups: See the Pen Word Correlations With HTML Colour Parsing by Declan Chidlow (@OuterVale) on CodePen. Interesting parsing in the modern era So, that's all well and good, but it's old news. The color and bgcolor attributes that permitted our parsing adventures are relics of HTML 4. They're obsolete (though still in active use on a disturbingly high number of websites). That isn't to say quirks like that have disappeared completely though. CSS has its own set of fascinating peculiarities when it comes to handling invalid colour values. Most modern browsers will clamp values rather than reject them outright -– throw rgb(300, -50, 1000) at a browser and it won't fail; it'll helpfully transform it into rgb(255, 0, 255). The web's foundational principle of forgiveness -– the inherent flexibility that allows \"chucknorris\" to be parsed as red, even though the reason it does so is old, silly, and unsupported –- hasn't gone anywhere. Modern browsers still bend over backward to make our code work, even when we throw nonsense at them. It doesn't take long to see this forgiveness in action within the cursed examples held within the pages of HTMHell. Each horrifying snippet, each questionable hack, each \"it works but why\" moment exists because browsers simply refuse to give up on rendering our 'mistakes'. The web is built on this foundation of resilience, both in technology and ethos. It's what allows a website from 1996 to still render in a modern browser. It's what lets a page load even when half the CSS is invalid. It's what makes it magic. I've heard people quip that browsers should be less forgiving and enforce perfection. That allowing jank makes the web somehow 'bad'. I think a perfect web would be a boring web. I certainly wouldn't be here writing were it 'perfect'. It's about making the web work, no matter what we throw at it, and I wouldn't have it any other way. After all, in a perfect web, \"chucknorris\" would just be another error message -– and where's the fun in that? Resources Sam's Place - A little rant about Microsoft Internet Explorer's color parsing HTML Standard Why does HTML think \"chucknorris\" is a color? About Declan Chidlow Front-end developer, designer, dabbler, and avid user of the superpowered information superhighway. Website: vale.rocks Fediverse: @vale@fedi.vale.rocks Bluesky: @vale.rocks More articles Previous day (19) Getting Oriented with HTML Video",
    "commentLink": "https://news.ycombinator.com/item?id=42468318",
    "commentBody": "My favourite colour is Chuck Norris red (htmhell.dev)491 points by OuterVale 14 hours agohidepastfavorite95 comments liontwist 5 hours agoThis article appears to be recycling content from a 13 year old top stack overflow question: https://stackoverflow.com/questions/8318911/why-does-html-th... Truly any interesting thing ever created on the internet will be exploited for marketing until the end of time. Unfortunate that old redditors and other forum contributors were not able to capture the millions of dollars of value created from their work. EDIT: I did see it’s at least referenced at the end. reply BeFlatXIII 4 hours agoparent> Unfortunate that old redditors and other forum contributors were not able to capture the millions of dollars of value created from their work. It's all down to a lack of viable micropayment infrastructure. See also: ad tech. reply nemomarx 4 hours agorootparentI think a lot of forum posters wouldn't want to charge micro payments for it though? reply kibwen 3 hours agorootparentprevMicropayments exist in apps, and yet that hasn't done anything to stop apps from having both micropayments while also being infested with ads. It's time to dispense with the myth that micropayments were a missed opportunity for the web. Commercialization enshittified the web, and micropayments would have just accelerated that decline. reply codelikeawolf 4 hours agoprevThis was a good read, but the author is mistaken: chucknorris isn't rendered as red, red is rendered as chucknorris. reply inopinatus 13 hours agoprevMy favourite outcome is that 'chocolate' is reduced to '#c0c0a0' reply jffhn 11 hours agoparent'shiny' gives pitch black, and 'obscure' gives blue sky color. reply dark-star 9 hours agorootparentI think the point was that chocolate -> cocoa :) reply jffhn 7 hours agorootparentYes, that's nearly semantic f(x)=x, I added that we could also find an x such as f(x)=1/x and f(1/x)=x. reply interactivecode 9 hours agoprevI love how forgiving the web is. These days you can get strictness with typescript and the like, which is great for businesses and work. But the forgiving nature of html and css and even javascript has contributed to so much adoption. Plus grew one of the most important things in an platform the ecosystem itself. Seeing rust slow down with piles of crates and fall into the same issues, js and npm has, perhaps its not a language problem but a ecosystem size problem. Larger user base === larger problems If you really want pedantic strictness and perfection, native applications are the place to work. But it isnt always better. And the web is fast, like really fast in rendering highly markedup text layouts. Just because everyone uses a frontend framework for “maintainability” doesn’t mean the engine is slow. reply highwaylights 8 hours agoparentI do appreciate all of what you’ve said but the author of this piece is actually mistaken. The browser isn’t actually processing the string “chucknorris” and forgiving incorrectly provided hex codes, which is a common misconception. What actually happens within the rendering pipeline is that the full literal string (in this case, “chucknorris”) is parsed, and the browser attempts to render the tag in the colour of blood in hope of receiving the mercy that Chuck Norris doesn’t have. As said, it’s a common misconception and I’m glad I could clear it up before he reads this. reply afandian 7 hours agorootparentAnd, inevitably, the next generation [0] comes along and use the colour without having any idea of who Chuck Norris even was. [0] https://news.ycombinator.com/item?id=42461264 reply SamBam 5 hours agorootparentThis will keep His spirit alive, like an Old God who is fed by our unknowing adherence to traditions, hanging glass baubles on Christmas trees in a pale reflection of hanging the heads of our sacrificed enemies, yet still providing a drop of sustenance to the sleeping Gods. reply DonHopkins 4 hours agorootparentprevOr that the next generation doesn't even know that \"Chuck Norris is such a right-wing Trump supporting homophobic bigot that he endorsed disgraced anti-gay sexual abusing pedophile Roy Moore\" isn't a joke, but a hard cold true Chuck Norris Fact. Chuck Norris is even more forgiving than the web when it comes to anti-gay pedophiles, but not to LGBTQ people. Chuck Norris: Obama Is Pushing 'Pro-Gay' Agenda On Boy Scouts Of America: https://www.imdb.com/news/ni30934229/ Chuck Norris Writes Homophobic Article About Boy Scouts: https://www.youtube.com/watch?v=_rLtC8uWXW0 Hilarious memes storm the internet as Chuck Norris is called out for being a Trump supporter: https://www.sportskeeda.com/esports/twitter-reacts-hilarious... Chuck Norris endorses disgraced anti-LGBT extremist in Senate bid: https://www.thepinknews.com/2017/08/08/chuck-norris-endorses... Sacha Baron Cohen Interviews Roy Moore With 'Pedophile Detector': https://www.youtube.com/watch?v=zIpCzNWsyxU Sacha Baron Cohen defeats Roy Moore’s $95m lawsuit over ‘pedophile detector’: https://www.theguardian.com/culture/2022/jul/07/sacha-baron-... REGISTERED SEX OFFENDER ROY MOORE SENTENCED FOR SEXUAL ABUSE OF A MINOR: https://www.justice.gov/usao-wy/pr/registered-sex-offender-s... Roy Moore talks about Chuck Norris: https://www.youtube.com/watch?v=DOhOA-dfHT0 Alabama Chief Justice Roy Moore blames ‘radical homosexuals’ for getting him sacked: https://www.thepinknews.com/2016/10/11/alabama-chief-justice... reply ivanjermakov 7 hours agoparentprev> I love how forgiving the web is I have completely opposite opinion. This \"forgiveness\" comes at a cost: - unexpected behavior instead of an early crash - hard to treat the platform seriously for mission critical tasks - makes it common to have many ways to solve the same problem reply guax 6 hours agorootparentExactly, no bank or payment system would ever offer services on the internet. How can a store operate in this environment! Never gonna happen. Impossible for mission critical tasks. reply latexr 6 hours agorootparentThe person you’re replying to said “hard to consider”, they didn’t say it was “impossible for”. There is an infinity of difference. Presumably banks and payments systems aren’t using web technologies (one would hope) to do the actual payments and transfers. They use them as an interface to other systems in other languages. And most of them tend to push you hard to use their apps, bank websites are often subpar. reply specialist 5 hours agorootparentprevPigs can fly, given enough thrust. reply gizmo 7 hours agoparentprevThe web solved distribution and that's why the web won. Click on a link see a page. Click on a link open an app. The alternative was downloading a .exe from questionable origin over an unreliable dial-up connection. App stores have become hugely successful since and if Microsoft had invented the mobile app model in the 90s (sandboxing and 1 click install process, like flatpak on linux) that model would probably have won instead of the web app. The web was incredibly buggy and horrifically slow for 2 decades, but there was no alternative so it won by default. reply tuyiown 7 hours agoparentprev> And the web is fast, like really fast in rendering highly markedup text layouts. Just because everyone uses a frontend framework for “maintainability” doesn’t mean the engine is slow. Yes and no. Many many non trivial things becomes very slow if you stick naïve ways with larger amounts for visual elements. It bites hard, because even naïve ways of doing things require quite some time for complex UIs, and very often, the roadblock requires to redo most if not all of the work. reply lenkite 7 hours agoparentprevI don't love how forgiving the web is. We would all spend far less time debugging painful HTML/CSS/JS issues if the web was stricter. I think several billion man-hours would have been saved and human civilization probably more advanced. Also health-insurance costs would be reduced and web-developer lifespan likely increased thanks to less blood pressure. (Don't think the Rust analogy really holds. npm is worse than Cargo. Of-course things could be better - a blessed standard extensions library: `stdx` with a quarterly update cycle and the crate nightmare will be solved) reply myk9001 9 hours agoprev> Chuck Norris isn't a colour. But the browser is too afraid to point that out. (Sorry, I'll show myself out) reply djoldman 5 hours agoprev> I've heard people quip that browsers should be less forgiving and enforce perfection. That allowing jank makes the web somehow 'bad'. I think a perfect web would be a boring web. I certainly wouldn't be here writing were it 'perfect'. It's about making the web work, no matter what we throw at it, and I wouldn't have it any other way. It's probably less about \"perfection\" than precluding non-conformance to a standard from the beginning. The tale of imperfect beginnings to standards that haunt the world for decades repeats itself ad nauseam. In short, if one is clever enough to engineer a relatively future-proof standard, then one avoids (possibly substantial) wasted developer hours. Note: This is NOT easy and things are sometimes obvious and unforgiving in hindsight. reply gedy 5 hours agoparentXHTML tried this approach, but it failed for this and other reasons. reply lmm 5 hours agorootparentOr maybe it failed entirely for the \"other reasons\", and this particular part of its design was actually right. reply gedy 4 hours agorootparentWell at the time, I do know that the vast majority of complaints I heard from colleagues was that it breaks too easily and wouldn't render after that. reply 6510 4 hours agorootparentI cant remember but I had a list of unsolvable problems that just ruled it out. I think in one instance I wanted to populate a form after it failed validation but couldn't correctly escape the value attributes. I believe the biggest design flaw is that the data is the first document it loads. It doesn't work like that. The application should load first, then the ui logic, then the data and then you should get to load other data sets. Swap them, filter, join, merge etc You would get powerful applications with very little effort. reply 6510 0 minutes agorootparentThis was an enjoyable read https://www.reddit.com/r/AskHistorians/comments/10vfgiq/what... thih9 11 hours agoprevThis means we can treat \"o\" as \"0\" (zero) because it gets automatically substituted like this anyway. E.g.: coffee actually becomes: #c0ffee Same with baobab (#ba0bab), decode (#dec0de), etc. reply cubefox 8 hours agoparentInteresting. There are also differences between HTML and CSS: #fe11a710 becomes a sort of red in HTML, but a mostly transparent pink in CSS (for 8 digits hex numbers, the last two encode the alpha value). reply kiru_io 10 hours agoprevColor names are a strange thing, it is like given names to numbers. I made a game out of it [0]. [0] https://colorguesser.com/ reply ksymph 4 hours agoparent> How is the score calculated? Oh man, this was harder than I thought. Color is such a deceptively dangerous rabbit hole. A few months ago I entered a game jam intending to make a small pokemon-like where you collect colors rather than creatures. E.g. instead of fire>grass>water it would be red>green>blue, with randomly generated colors of any shade and about half a dozen 'types'. Trying to figure out the math of that nerd sniped me for a couple weeks, didn't even get started on the rest of the game before the jam ended. reply istjohn 4 hours agoparentprevI would love this with a limited, accurate color list. It would be a fun way to learn more obscure colors like chartreuse, ochre, and sienna. I'd particularly like to learn the colors that are likely to come up in literature (e.g., [0]). As it is, I got \"Jaycey's Favorite\" as one of the colors. 0. https://www.vocabulary.com/lists/141957 reply alex_duf 9 hours agoparentprevthat was fun! It would be nice to show my colour next to the result to compare a little more. reply Yujf 8 hours agoparentprevHah I played twice and did not meaningfully inprove my score. Even after seeing the color I could not match it up close enough, and the first time I got pretty close to most colors. reply mrob 10 hours agoprev>I've heard people quip that browsers should be less forgiving and enforce perfection. That allowing jank makes the web somehow 'bad'. Considering all the misery inflicted by computer crime that's enabled by the forgiving attitude, I 100% agree. And given the choice between \"you can still visit the Space Jam website[0]\" or \"never worry about drive-by ransomware again\", I'm pretty sure I'd be with the majority in choosing the latter. Security is a heavy price to pay for whimsy. Old-technology hobbyists could still run old web browsers in sandboxed VMs. [0] https://www.spacejam.com/1996/ reply gizmo 9 hours agoparentIt's a false choice in any case. Web browsers can support backward compatibility and at the same time offer a strict mode that benefits correctness and performance. Some real opportunities were missed to clean up JS semantics when Modules got introduced, for instance. reply winternewt 4 hours agorootparentAnd they did with XHTML, but unfortunately it didn't catch on. reply josefx 9 hours agoparentprev> Considering all the misery inflicted by computer crime that's enabled by the forgiving attitude, I 100% agree. Parsers should strictly adhere to a standard, if the standard says they should be \"forgiving\" and that \"forgiving\" is well defined then all parsers should act this way. Inconsistent behavior between implementations opens its own can of worms that may leave a system in an inconsistent or insecure state. reply Thorrez 6 hours agoparentprevI don't see how making browsers less forgiving would reduce drive-by ransomware. I don't think most browser vulnerabilities are related to the web being forgiving. reply mrob 6 hours agorootparentHave you seen how big the HTML spec is? https://html.spec.whatwg.org/ A huge part of this complexity exists because of the forgiving attitude. With a strict attitude the spec could be much simpler, and that means web browsers could be much smaller. The most secure code is no code. reply alexvitkov 6 hours agorootparentprevVulnerabilities are related to the web being complex, and just this one quirk involves a parsing algorithm with 6 transformations of a user-provided value. reply yread 7 hours agoparentprevI think the choice is more \"writing a browser is a weekend project\" vs \"writing a browser is years of toil and you'll need a local copy of the internet to test it comprehensively\" reply flobosg 13 hours agoprevUnintended rubrication, perhaps? – https://gwern.net/red reply f1shy 12 hours agoparentThank you. This happens to be invaluable to me! reply Darthy 8 hours agoprevThe parsing outline in the article omits that there are also 140 hard coded color names in html: https://htmlcolorcodes.com/color-names/ reply orko 10 hours agoprev\"smurf\" gives a nice #0000f0, ain't that funny? reply bartread 10 hours agoprev> If an octothorpe (#) is located at the start of the value, it's removed. An “octothorpe”! I never knew it was called that (and, apparently, neither does autocorrect). What a glorious name! reply richrichardsson 9 hours agoparentI wonder why it ended up being \"hash-tag\" on social media when it's quite common for North Americans to refer to the symbol as the \"pound symbol\"? reply dcminter 8 hours agorootparentNo idea, but it used to cause confusion that on a British keyboard Shift-3 produced the £ symbol, but a US keyboard produced the # symbol - while in the respective countries they were both referred to as \"pound\" Perhaps some British influence somewhere? Where were # tags first popularised in the public imagination? Twitter I assume? Or something else? --- Edit to add side-observation: \"Octothorpe\" I quite like, but I've never heard it spoken and mostly only read it in quite nerdy internetty contexts. Even amongst nerds I don't think we really use it that much. Meanwhile @ is occasionally referred to as \"commercial at\" and I've seen one or two uses of \"ampersat\" for it. Again, I don't think I've ever heard anyone use those in speech even though they might actualy be useful for disambiguating the symbol from the word (but I think people say \"at sign\" when they want to be specific). --- Another passing thought: I remember being exceedingly irritated to get a Mac with a UK keyboard in the early 2000s and discovering that the # symbol was not shifted to another key (as on a PC keyboard) but had to be accessed via the Alt-gr key combo (possibly with shift thrown into the mix as well?) ... as a recovering C++ developer at that time it was super annoying. Nowadays I have a Swedish keyboard and while # is fine, I have similar pain with {} and [] ... and now I think of it, what is the proper name for what I exclusively call \"curly braces\" ? reply thatfunkymunki 2 hours agorootparent> I have similar pain with {} and [] in grade school I believe we were told those were \"braces\" and \"brackets\" respectively reply xanderlewis 7 hours agorootparentprev> what is the proper name for what I exclusively call \"curly braces\" ? Sideways moustaches. reply Elfener 9 hours agorootparentprevSome people called it the hash symbol, and then they used it to mark tags (as in categories or keywords). So technically, the symbol is not the hashtag but the entire #tag construct is. reply Symbiote 8 hours agorootparentprevPerhaps influence from programmers, who would know the real \"pound sign\" is either ℔ or £, depending what type of pound you prefer, and the number sign is №. £ is a stylised L with a bar, incidentally. reply bartread 9 hours agorootparentprevYeah, it’s an interesting one. I’ve always known it as the hash symbol from back in the 80s when I got my first microcomputer. This was in the UK but I don’t think hash is UK-specific terminology: “shebang” (“hash bang” for #!) has been common parlance amongst the UNIX-crowd since I don’t know when. I know pound is incredibly common in the US, but in the UK it’s never referred to that way because here pound means £. “Octothorpe” is entirely new to me though, and I guess is quite context specific? reply a57721 8 hours agorootparent> “shebang” (“hash bang” for #!) I think the etymology of \"shebang\" isn't clear, some sources say it may come from \"sharp bang\" or \"shell bang\". http://catb.org/jargon/html/S/shebang.html reply dcminter 8 hours agorootparentprevYeah, I don't think I even heard \"pound\" for # until I went online and started getting exposed a lot more to US stuff (also harking from the 80s UK micro world). I feel like \"octothorpe\" might have been referenced in the jargon file or similar texts? reply dcminter 8 hours agorootparentI checked, and it gets a passing mention (along with a snipe about annoying Britons!) in Jargon File and Hackers Dictionary. reply esperent 13 hours agoprevThe included codepen is unreadable on mobile until you remove -webkit-text-stroke from them CSS. At the initial value of 0.5rem it gives a quite cool effect, as if the text has been badly redacted with a white highlighter. I initially thought that was intentional. reply jvdvegt 9 hours agoparentWorks fine on Android too, with Firefox. reply aetherspawn 11 hours agoparentprevWorks fine on iOS. It basically adds a white scribbly outline to the text which makes it easy to read the black text regardless of the background color. It actually looks fantastic for such a low effort effect. reply paradite 12 hours agoprevBack the in the days I used a lot of d3.js for making visualizations. Till today my favorite color for background, secondary text is still d3d3d3. reply dbbr 4 hours agoprevThe moment I've been waiting for: for a topic on HN to devolve into Barrens chat. This is going to be a great day. Zug zug. reply moopie 4 hours agoparentI’d prefer if the discussion was about how homophobic chuck Norris is. reply devmor 11 hours agoprevThis reminded me of one of my first web-dev projects as a teenager - the first one I showed my (recently passed) father, in which you were prompted to ask \"Chuck Norris\" a yes or no question with a text box, and then would present you a yes or no answer with a suitable photo of the man himself. I did some rudimentary string parsing on submit, and if the question started with a word like \"Where\", \"How\", \"Why\", \"Who\" and a few other words that signified the question couldn't be answered with Yes or No, it would show an angry photo of his face with the caption \"Your question has angered chuck!\" - I think I also gave it a 1% chance to randomly roll that result regardless. My dad absolutely loved that little project, and reminded me of how funny he found it even this year shortly before we lost him, almost 2 decades after I'd made it. Sorry this wasn't incredibly related to your submission, but I wanted to share a happy memory you just brought back to me with it. reply fooker 11 hours agoparentThis reminds me of the early web. So many fun websites like this. Now it's just silos controlled by megacorps, trying to outdo each other in competition for attention. reply bbarnett 9 hours agorootparentWell yes and no. I assure you, many many forums exist outside of Facebook, and mailing lists too. And endless, classic, non-https sites still exist too. They are just pages deep in Google's search results, especially with the entire first several pages of scrolling being their almost always wrong suggestions. And it doesn't help that verbatim is completely broken now, and that Google aliases search terms, and drops search terms, even when using quotes. A horrible design, and the result is all that goodness is harder to find. It's not siloed, it's Google only reply qoez 5 hours agoprevFeels like being back in 2012 all over again reading this reply peutetre 12 hours agoprev> After all, in a perfect web, \"chucknorris\" would just be another error message Chuck Norris has only ever received one error message. He stared the computer down until it apologized and fixed the problem. reply mukunda_johnson 12 hours agoprevI'm surprised this is well defined behavior. reply creatonez 11 hours agoparentIt certainly is now (HTML5 retroactively standardized a lot of quirks), but it wasn't always well-defined: https://scrappy-do.blogspot.com/2004/08/little-rant-about-mi... reply zahlman 12 hours agoparentprevI already saw the Stack Overflow reference cited in the article (https://stackoverflow.com/questions/8318911) many years ago, so I wasn't surprised. But I guess I can still be disappointed. Postel's Law has its limits. reply Ygg2 11 hours agorootparentPostel or Hyrum? reply zahlman 4 hours agorootparentPostel. This is about me thinking it was a bad idea to make it work in the first place. reply psychoslave 10 hours agoprevExcellent! \"green\" is green, but my favorite is \"peace\" actually. reply TonyTrapp 6 hours agoparent\"red\" is blue, and \"blue\" is red! reply jackallis 5 hours agoprevcould not help my self: Chuck Norris doesn’t see red; red sees Chuck Norris. Sorry another one, The color red was invented to match Chuck Norris's intensity. reply gdv__ 7 hours agoprevA while ago I made this app that lets you pick a color and find an English word that gives a similar color: https://g-dv.gitlab.io/color-namer reply sneak 9 hours agoprev> The web is built on this foundation of resilience, both in technology and ethos. It's what allows a website from 1996 to still render in a modern browser. It's what lets a page load even when half the CSS is invalid. It's what makes it magic. The concept of graceful degradation in web feature support is dead now. Presently most of the web fails to render at all if you don’t execute a giant javascript blob in full that is responsible for putting the words on the page. It’s quite sad. reply maxim-fin 8 hours agoprevAlso just a name \"Chuck\" isn't a colour. reply ilaksh 13 hours agoprevThis doesn't work with CSS, right? Only the color attribute of HTML. reply debo_ 13 hours agoparentFrom the article: > CSS has its own set of fascinating peculiarities when it comes to handling invalid colour values. Most modern browsers will clamp values rather than reject them outright -– throw rgb(300, -50, 1000) at a browser and it won't fail; it'll helpfully transform it into rgb(255, 0, 255). reply esperent 13 hours agoparentprevYeah it addresses that towards the end of the article. CSS has different rules for parsing badly formatted colors. Unsurprising given that CSS colors can be in several different formats (hex, RGB, RGBA, HCL etc.). reply AnonC 13 hours agoprevIt’s amusing that some of the other (English) word colors match what one would consider suitable or kinda close to those words. crap #c0a000 watermelon #a00e00 plant #00a000 sonic #0000c0 jade #0ade00 bloodily #b00d00 grass #00a000 midnight #0d00000 Has anyone created a more comprehensive list of such (unexpected) color words for English and other languages? reply OakNinja 12 hours agoparentThis is an old favorite of mine: http://bada55.io/ reply gaoryrt 12 hours agorootparentThat was amazing. reply wizzwizz4 5 hours agorootparentprev> Get out of here, lt IE9 user! http://bada55.io/img/old-ie-fist.png Rude. reply furyofantares 12 hours agoparentprevwell, there's those plus a few more in the article reply soheil 8 hours agoprevyou can use your name as a semi-unique color to you reply soheil 8 hours agoprevmine is crap beige reply bombela 10 hours agoprev [–] I can only think of one thing. The computational overhead of this parsing insanity. With the size of modern web pages and the scale. This must amount to a very significant cost. reply lblume 9 hours agoparentHighly unlikely. The parsers are written in efficient languages, and nobody is settingcolor attributes in a loop. Also, this is not how it is done today, and old websites are usually a lot faster than modern ones. I would even argue that the parsing CSS's color syntax is way more expensive than this comparatively simple step-by-step algorithm. reply bartread 9 hours agoparentprevNot really. The color attribute isn’t commonly used these days - it’s literally legacy support - and, even on pages where it is used, it’s going to be a tiny portion of the overall markup. Also worth bearing in mind that parsing markup is fast, and certainly not the reason web pages can feel slow. That’s much more to do with heavy assets, poorly constructed JavaScript, long-running web service calls, excessive DOM manipulation and re-rendering, bandwidth constraints, etc. Parsing the markup on its own isn’t going to be the root cause of a meaningful fraction of web performance issues. reply Cthulhu_ 7 hours agoparentprev [–] The problem there is that there's a lot of sanity checking happening in browsers; I hope there will be a new technology where things like html, css and JS are all precompiled / pre-verified so the page is executed as-is with minimal sanity checking. There was a post yesterday about Python's random() vs randint; the former just spits out a random number, the latter does a list of sanity checks on the arguments passed, whose cost adds up in many invocations. But that's a runtime sanity check, if that can be done beforehand with e.g. a stricter type system + a \"let it crash / fail\" attitude at runtime, all that sanity checking overhead would be gone. I mean this script / at-runtime checking is fine during development if it means shorter iterations and whatnot, but in production it shouldn't happen. reply Sesse__ 7 hours agorootparent [–] Hi, I work on CSS parser performance, and error handling isn't really a big pain point; if you removed all error handling overhead, you would not be likely to notice any real performance increase in your web page loading. Most of the time, you just hit the happy path anyway, and the error checks from that is an easily-predicted branch. A precompiled format (i.e., binary) _may_ help (I don't think anyone has really considered it), but “pre-verified” means it would come down to who you trust to do that verification, so it's a hard sell. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Setting text color on a webpage is now primarily done using CSS, although HTML previously used a color attribute, which is now obsolete.",
      "Modern browsers are forgiving with invalid color values, defaulting to red for unrecognized inputs due to legacy parsing rules, ensuring old websites remain functional.",
      "While some advocate for stricter standards, the web's flexibility in handling invalid values contributes to its resilience and adaptability."
    ],
    "commentSummary": [
      "The article discusses \"Chuck Norris red,\" linked to a 13-year-old Stack Overflow question, sparking debates on internet content commercialization and micropayments.",
      "Users express nostalgia for the early web's creativity, contrasting it with modern web standards' complexity and security issues.",
      "The conversation humorously addresses color parsing quirks in HTML and CSS, referencing Chuck Norris and color names."
    ],
    "points": 491,
    "commentCount": 95,
    "retryCount": 0,
    "time": 1734669349
  },
  {
    "id": 42469074,
    "title": "Tldraw Computer",
    "originLink": "https://computer.tldraw.com",
    "originBody": "tldraw computer - a computer by tldraw. Read the blog postWatch the video A COMPUTER PERHAPS An infinite canvas for natural language computing Create workflows of connected components that generate and transform data, using a multi-modal language model as a runtime to execute instructions. Create and connect components Run a component to generate data Create workflows that branch and loop EASIER DONE THAN SAID Get started with an example Click an example to start a new project with a pre-built workflow. You can edit the project to create a new copy in your account. Story Generator Sorting Machine Battle Simulator Invention Inventor Email Factory Animal Lab PERFECT MARKETING Made with tldraw Computer is a new experimental project by tldraw, makers of the tldraw SDK for infinite canvas applications and the popular tldraw.com free collaborative whiteboard. Learn more at tldraw.dev tldraw © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=42469074",
    "commentBody": "Tldraw Computer (tldraw.com)348 points by duck 11 hours agohidepastfavorite73 comments ffdixon1 4 hours agoI'd like to echo the impressiveness of tldraw. At the BigBlueButton project, an open source virtual classroom, we built tldraw into the core. It has saved us countless development hours as we stopped trying to build our own whiteboard and instead stood on tldraw's (very) wide shoulders. We've never looked back. reply all2 7 minutes agoprevSteve, I'd like to know if I can use the SDK to build workflow/process diagrams that specify inputs, outputs, and side effects (ie, this process creates a pile of logs or documentation) and then export a process specification for use in another application. My specific use case is process mapping and quality systems implementation in a hardware engineering setting. reply steveruizok 2 minutes agoparentThat sounds really useful. There's no export yet here apart from images and it isn't something I've thought about much so far. Are there standard formats for these types of workflows? reply boomskats 6 hours agoprevI ended up at Tldraw's London office a few weeks ago for a thing, and I remember afterwards being like 'ahh, now I understand how they end up just casually doing random cool shit and attracting the kind of talent they do'. They should be extremely proud of the culture they've managed to foster and I genuinely hope to see them succeed as a business. reply samwillis 6 hours agoparentVery much this! I was also at a thing at their office a few weeks ago (some thing? \"Local Thirst\"), and Steve gave a demo of this. It is incredible. I've joked before that the last generation of human machine interfaces ware invented at Xerox park, and the next generation is being invented at TLDraw of Finsbury Park. But it's not really a joke, I genuinely believe it. reply boomskats 3 minutes agorootparentHa yeah, that was the same thing! The night it rained sideways. So this is the demo people were talking about at the end of the night! I was quite annoyed I missed it, makes sense now. I think I was nerding out over current-gen HIDs while eyeing up their very tastefully equipped coffee station (ozone roasters ftw) reply britannio 1 hour agorootparentprevIt was a cool thing... I expected a hacky demo that'd fall apart mid-way but it held up. The Macintosh SE in the office was cool too. reply nightowl_games 3 hours agoparentprevTell us more about what you saw? reply ChrisArchitect 1 hour agoprevDidn't expect the blog post to go to a Google Gemini page: https://ai.google.dev/showcase/tldraw reply crimsoneer 9 hours agoprevEven \"vanilla\" tldraw is super cool as a clean, functional, open-source html5 whiteboard, and the team have absolutely been killing it in their comms and use of LLMs. I honestly think they might be some of the most innovative people around when it comes to really novel UI for LLMs. Also, Todepond is just very cool. reply dustingetz 8 hours agoparentdoes the cloud product’s “new project” button still trash your saved documents with one click behind a docstring something like “make sure you have saved your stuff before making a new project” where what they meant is “our cloud product does not save your projects to the cloud, it is in local storage actually and you can only have one project at a time so the new project button actually overwrites your old one, so when we say ‘save’ we actually mean export your stuff to a json file and save to local disk!! so you can re-import it back into the product later from local disk and overwrite it back!!!!” I did my VC seed pitch deck in tldraw along with a bunch of product mocks, ask me how i know this reply steveruizok 3 hours agorootparentSo sorry Dustin. We'll have a new version of tldraw with user accounts in a few weeks that should improve things, but until then please no one clear your browser storage reply dustingetz 2 hours agorootparenta clear docstring would be great reply gcanyon 5 hours agorootparentprevFile > New Shared Project -- and your problem is solved. Remember to bookmark your work, since there is no login/account/automatic storage. reply chris_pie 7 hours agoparentprevAnd (\"vanilla\") tldraw supports subpixel font rendering, unlike most of their competition (for example excalidraw or Miro). reply Kiro 9 hours agoparentprevI didn't know Todepond worked on tldraw. That's cool. > really novel UI for LLMs Are you referring to Tldraw Computer or something else? Don't get me wrong, it looks really nice but not that different from other graph representations of LLM workflows, including live updates in the nodes themselves. reply humbugtheman 7 hours agorootparenthello it's me Todepond reply crimsoneer 41 minutes agorootparentDo you somewhere have slides/recordings from the awesome AI tinkerers talk you did? Because that's what I had in mind when I made this comment and will be way easier than me trying to describe it reply delusional 7 hours agorootparentprevHi Lu reply humbugtheman 6 hours agorootparenthi reply humbugtheman 3 hours agorootparentGreat chat reply petargyurov 8 hours agoprevIf I can plug my own API key into this and/or run Llama locally, that'd be great. It reminds me of a tool I saw recently called Heuristica [0]. Would like to try it but I don't like being tied to a subscription and the free plan seems quite limited if I can't even plug my own key in. Don't see why this can't do what Heuristica does! :) [0] https://www.heuristi.ca/ reply predictand 7 hours agoparentHey there! Thanks for mentioning Heuristica. I would love to find out how to make the free plan for Heuristica to be more permissive (without destroying the incentive to subscribe for willing users). Feel free to send me your suggestions. At one point, I also worked on making it work with a personal API key. However, this added a lot of complexity. It felt like I was building and maintaining two separate branches of the same app, so I had to put the idea on hold. I might revisit it in the future. reply petargyurov 6 hours agorootparentHey! To be honest, I am not sure my feedback would be very valuable. I'm probably your worst type of user -- perma free plan -- simply because I'd only use your tool sporadically. I don't do literature reviews that often, but often enough to think about using a tool like this I suppose. I totally get it though, it's a difficult thing to balance. If I was doing lit review and deep research daily 6.99 is an amazing deal. reply predictand 5 hours agorootparentI am still happy to hear from a fellow user! Feel free to ping me if you ever have feature recommendations or suggestions. reply martypitt 9 hours agoprevI got to see this demo'd at a conference in Sydney recently, and it's really cool. It's not super serious, but it's not meant to be -- it's not pitching to be your enterprise AI strategy. However, even though it's presented in a playful way, I suspect it's quite powerful, and expect The Internets will build some cool stuff atop it. It's a fun and creative way to explore playing with LLM's, and it's brilliantly executed! Happy to see it here on HN. reply tholdem 5 hours agoprevI want to use Tldraw as a simpler alternative to Figma. I want to drag and drop Web Components (or React components) into the canvas to play around with different UI ideas. Maybe a built in library of Shadcn components I could mock up an UI with. reply stared 5 hours agoprevI was thinking of developing something similar, but it ended up being one of the thousands of ideas that never end with a line of code. I'm glad to see it here. Visual programming is a tempting idea I love. It rarely works, but this might be the case. I think there is a lot of room for AI UIs - between chats (the simplest and most prevalent) and arbitrary code (even if it is \"just API calls\", it is only people with at least some software inclination). One thing I am keeping track of is WordWare (https://www.wordware.ai/), which makes it easy to create a sequence of operations. It feels like an \"Excel formulas of AI\". Yet, I like the visual, graph-based approach of Tldraw. reply pipes 3 hours agoprevCan someone tell me what this does? Is it draw a diagram and it will automatically implement it in code? reply tantalor 3 hours agoparentusers create workflows from blocks of text, images, and instructions. When run, information flows from one component to the next, with the output of each generation serving as the input to the next, creating powerful processes that branch, loop, and iterate to produce outputs It's Yahoo! Pipes for AI. reply EagnaIonat 1 hour agoparentprevReminds me of Orange Data Mining but with a nicer UI. reply steveruizok 3 hours agoprevHey, Steve here from tldraw. We had a bunch of fun putting this together so I'm really happy to see folks enjoying it. I'm not sure where the project is going but I've been waking up for weeks with a fresh \"oh christ, we could do ___\", so that's exciting. Ask me anything! reply zamfi 3 hours agoparentHi Steve! Super cool implementation. Any chance you’ll make the source available? There are about 50 extensions I’d make to it if I could! (And I’m sure I’m not alone.) reply steveruizok 7 minutes agorootparentNot immediately! This might turn out to be just a great demo, might be something worth continuing with, really depends on how the next few weeks go. Either way there might be something we can do with the developer community around data endpoints in the short term. reply Imustaskforhelp 6 hours agoprevTHIS is it. I have been using tldraw with one of my friends or even generally when my whiteboard marker goes down and I wish to draw. Seriously tldraw makes sharing whiteboards so easier as compared to excalidraw and others. TLDRAW deserves more attention than excalidraw and I watched its demo video and holy moly , this is so crazy , the fact that this can create semi websites and etc. feels so cool , definitely going to try it reply sagaro 3 hours agoparentIn excalidraw I just have to click share session and anyone with that url can see my whiteboard and interact with it. I get tldraw has much more features etc. but how exactly is it making sharing whiteboard so easier compared to excalidraw? reply Imustaskforhelp 2 hours agorootparentI don't know maybe it was a skill issue from my side 2 -4 months ago , I felt as if I was forced to sign up back then I am sorry I guess then for this comment , excalidraw also works great but I still just like tldraw because of how familiar I have become of this interface. Shame that the licensing of tldraw is less permittive than excalidraw but I guess I am just a little bit okay with it considering its still open source and though I maybe wrong I had read the license , and it seems that it was focusing way more on that you had to have the name of tldraw / packaging of tldraw / copyright here is the license restrictions Not to disable, hide, remove, or alter the Watermark. Not to disable, change, or interfere with the license key validation process that governs the display of the Watermark. Not to remove any copyright or other notices from the Software. Not to make the Software available under a license that supersedes or negates the effect of this License. Not to distribute the Software or modifications of the Software as a standalone product, but only as part of another application. To include a verbatim copy of this License in any distribution of the Software. To comply with tldraw's trademark policy. reply forty 5 hours agoparentprevExcalidraw is free & open source software though, which IMO makes it deserve more attention reply rapnie 3 hours agorootparentOof, source available, that is an oversight on my end. Or was there a recent license change? Off the shortlist then, unfortunately. reply orlp 2 hours agorootparentWhat do you base this on? The main repository (https://github.com/excalidraw/excalidraw) states it's MIT and this has been unchanged for 5 years. EDIT: I guess you were talking about tldraw rather than excalidraw. reply rapnie 3 hours agorootparentprevYep, license change from Apache 2.0 in December 2023. reply rozenmd 5 hours agorootparentprevtldraw's source is available fwiw https://github.com/tldraw/tldraw reply 20after4 10 hours agoprevThis is actually a really nice interface for working with generative AI. This seems like it could be really powerful and actually useful. reply gcanyon 3 hours agoprevI'm not 100% sure why, but this is incredibly compelling to me as a fun developer-y thing. I want to use this. reply duxup 4 hours agoprevI'm new to this and maybe a bit dense. Is the magic here making a flow chart / workflow where sample data is generated to make it easier to visualize and you can update and see the results? reply isoprophlex 6 hours agoprevThis would be fantastic as a component for versioning, testing, editing and sharing both simpeler prompting and \"\"\"agentic ai\"\"\" systems! I see just an email signup thing, can't figure out if i can slap this onto the ai backends I'm building reply satvikpendem 8 hours agoprevThis is basically ComfyUI but for LLMs, is that right? I know tldraw as the open source Excalidraw competitor but this is an interesting product as well. reply steveruizok 3 hours agoparentExcalidraw is more open source than we are at tldraw! We're both source available on GitHub but Excalidraw is MIT while the newer versions of tldraw are a kind of watermark-ware. (We still have an older MIT version available but not in development) reply EgoIncarnate 3 hours agoparentprevTLDraw relicensed about a year ago. It is under a permissive license, but no longer strictly open source ('watermark-ware\"). https://tldraw.dev/ FAQ: Is the tldraw SDK open source? Our license is not exactly Open Source but you can view the source code on GitHub. We accept contributions from the community and work in public. reply hhh 8 hours agoparentprevExcalidraw is also mostly open source https://github.com/excalidraw/excalidraw reply benrutter 8 hours agorootparentI might be scanning and missing something, but from that it looks like the whole repo is MIT license? reply ALittleLight 1 hour agoprevI'd love a \"Code\" component where you could enter arbitrary code. After following the tutorials I asked myself \"What would I like to make?\" And I imagined a tweet-bot - grab headlines from Wiki news (or somewhere), combine with an instruction to generate text and another couple instructions to generate an image, post to twitter (or bluesky). This seems easy enough if I have a code component that could execute arbitrary code. I could just write a couple small component (take API key, text, post to twitter/search wikinews) and add them to the workflow. If the components I needed were generalizable I could share them on some kind of community repository - so the next person who needed a \"Post to twitter\" component wouldn't even need to rewrite it. reply vc4 9 hours agoprevSuch a nice visual spin to interact with LLMs, great work by the team reply calebm 2 hours agoprevHow's it different than draw.io? reply forgot_user1234 10 hours agoprevWhy though ? reply corentin88 10 hours agoparentThat might look like a toy, but that kind of remind me the Minority Report screen, where you see Tom Cruise moving things with a hand-mouse device. The UI built by Tldraw is different from a chat interface. That doesn’t mean it’s not a good fit to interact with an AI/LLM. I definitely see this in the hands of kids, just like they are great interfaces to code video games without writing a line of code. reply llamaimperative 7 hours agoparentprevIIRC they took VC money a year or so ago? Interesting product and obviously awesome execution, as expected from tldraw… but yeah… seems like a very strange departure from what Steve has been building the past few years. reply steveruizok 3 hours agorootparentyep, more news on that soon The core product / pitch is still the same—an SDK for whiteboards and other infinite canvas stuff—and that's what we monetize through licenses. Computer (and our other demos) are basically marketing, R&D, and fun. reply llamaimperative 2 hours agorootparentAh I see! Well if you're looking for fun stuff... could you make a tool that lets me easily breadboard [1] an app, and then you GenAI it into a low-fidelity clickable prototype? As always, excellent execution on this, Steve! [1]: https://basecamp.com/shapeup/1.3-chapter-04#breadboarding reply attentionmech 9 hours agoprevThis can be a good tool to teach kids programming/generative-ai reply delusional 5 hours agoprevSo this is what Arroost was leading into. reply agumonkey 8 hours agoprevAh, I didn't expect that this soon reply bentt 5 hours agoprevTLDraw is fascinating, but I feel like when I see them tweet cool stuff it isn’t actually in the app. This is likely me being dumb but since it happened a couple times now whenever I see their posts I assume the same. reply arb_ 3 hours agoparentI think they tweet prototypes and then don't ship most prototypes. Seems reasonable to me, otherwise you have instant bloat. reply steveruizok 3 hours agoparentprevYeah we did a lot of work this summer that was really far out, maybe too far out, and didn't come together as a product. We shipped a lot of it in teach.tldraw.com though. Computer is exciting to me in part because it feels both very weird and also intelligible as a piece of software. reply amne 7 hours agoprevtldr: needs email to play with it reply Imustaskforhelp 6 hours agoparentI think its decent considering it requires money , and even chatgpt in its early stages didn't allow for anonymous chats / unlimited chats and I remember going on all these chatgpt clones becuase of that. I also understand the hilarious spin that you added considering tldr (too long didn't read) lmao. but still its worth your email. Crazy how I realised that tldr meme after I had written the first paragraph reply steveruizok 3 hours agorootparentbelieve it or not I picked the tldraw name because I already owned the domain (I'd bought it for a different project called telestrator) and it was only weeks later when Francois Laberge complimented the clever name that I noticed the portmanteau reply emptysongglass 2 hours agorootparentI'd appreciate if you didn't consider Firefox Relay emails as disposable email. The Firefox folks specifically have tried to make Relay anti-abuse. It's an unkind thing to do to your prospective users. From Bleeping computer's coverage the last time someone tried to dump Relay in with a disposable email blocklist: > Back in November 2021, Firefox Relay's team lead had requested the maintainer of a separate burner email list, \"burner-email-providers\" to exempt the particular domain form the blocklist: > \"We are operating Relay with a number of features that I think mitigate the risks that these aliases pose,\" Mozilla's privacy and security engineer Luke Crouch explained in November. > Firstly, if a @mozmail.com alias is disabled by the user, any emails sent to the alias are not bounced back but instead discarded with a 404 error message returned by the service's HTTP webook, stated Crouch. Secondly, he explained, the anti-abuse protections built into Relay limit free users to a total of five aliases, and further rate-limit premium customers so they cannot abuse the service by creating large-scale throw-away aliases for, say, automated signups to web services. > With that reasoning, mozmail.com was swiftly removed from that blocklist. And it appears, the creators of \"disposable-email-domains\" have also honored the clause, for now. reply steveruizok 5 minutes agorootparentOh sorry, that's a toggle in Clerk (our auth provider), it doesn't provide granularity around which are disposable and which aren't. I'll take a look and see whether there's anything I can do short of turning off that feature. reply Imustaskforhelp 2 hours agorootparentprevI am sorry but I am confused. To whom exactly are you talking to? reply lolpanda 10 hours agoprev [–] this looks like the workflows in gumloop.com reply akira2501 7 hours agoparent [–] Give it a dark theme and I'd say the modern Westworld TV series. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "tldraw Computer is an experimental project providing an infinite canvas for natural language computing, enabling users to create and customize workflows of connected components.",
      "It utilizes a multi-modal language model to generate and transform data, offering pre-built workflows such as Story Generator and Sorting Machine.",
      "The project is accessible for further exploration and customization at tldraw.dev."
    ],
    "commentSummary": [
      "Tldraw Computer is recognized for its functionality, notably in the BigBlueButton project, where it efficiently integrated a whiteboard feature, saving development time.",
      "Users are interested in its potential for creating workflow diagrams, its innovative user interface for large language models (LLMs), and its cultural impact.",
      "There are discussions about its open-source nature, data handling in its cloud product, and comparisons to similar tools like Excalidraw, with a focus on licensing and applications in AI and UI design."
    ],
    "points": 348,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1734680556
  },
  {
    "id": 42466676,
    "title": "Kelly Can't Fail",
    "originLink": "https://win-vector.com/2024/12/19/kelly-cant-fail/",
    "originBody": "Kelly Can’t Fail By John Mount on December 19, 2024 • ( Leave a comment ) Introduction You may have heard of the Kelly bet allocation strategy. It is a system for correctly exploiting information or bias in a gambling situation. It is also known as a maximally aggressive or high variance strategy, in that betting more than the Kelly selection can be quite ruinous. I recently ran into a strange card game where the Kelly strategy is risk free with zero variance. Peter Winkler calls the game “Next Card Bet” in his remarkable book Mathematical Puzzles. The problem and solution appear to come from Thomas Cover. I find this betting game and its analysis amazing, and want to share them with you here. The Game The game is played as follows. A standard 52 card deck consisting of 26 red cards and 26 black cards is shuffled and the player start with a stake of $1. Each card is exposed one at a time, without being replaced in the deck. The player is allowed to bet any fraction of their current stake on whether the next card is black or red at a one to one payoff. The player clearly has advantageous strategies involving counting the number of black and red cards seen. Counting cards seen lets them know how many cards of each color remain in the unseen portion of the deck. For example they can safely double their stake by not betting on any card other than the last. This allows them to safely bet their entire stake on the now inferable color of the final unseen card. The Kelly strategy The Kelly strategy is to pick a bet that maximizes the expected logarithm of the stake. We can derive it as follows. Let r be the number red cards remaining in the deck and b black cards remaining. Without loss of generality assume r > b. We then want to maximize P[draw red] * log(1 + bet_fraction) + P[draw black] * log(1 - bet_fraction) as a function of bet_fraction. This expression is maximized where its derivative is zero. The probability of drawing red next is r/(r + b). So we need to solve (r/(r + b)) / (1 + bet_fraction) - (b/(r + b)) / (1 - bet_fraction) = 0. Some algebra tells us bet_fraction = (r - b) / (r + b). The entire Kelly betting strategy is then: If r = b, then no bet If r > b bet a |r - b| / (r + b) fraction of your stake on “red” If b > r bet a |r - b| / (r + b) fraction of your stake on “black.” Trying the strategy You really should see this strategy in action. It is a strong claim that it is in fact zero variance, so we really should insist on that being confirmed. We will work the example in Python. In[1]: # import tools import numpy as np In[2]: # set up our pseudo-random number generator to produce shuffled decks rng = np.random.default_rng(2024) In[3]: # define our deck shuffling tool def k_array_with_t_true(k: int, t: int): \"\"\"Create a length-k boolean array with t-True values\"\"\" is_true = np.array([False] * k, dtype=bool) is_true[rng.choice(k, size=t, replace=False)] = True return is_true In[4]: # implement our betting strategy def run_bets(is_red) -> float: \"\"\"Run the Kelly betting strategy\"\"\" stake = 1.0 n_red_remaining = int(np.sum(is_red)) n_black_remaining = len(is_red) - n_red_remaining for i in range(len(is_red)): # form bet bet_red = 0 bet_black = 0 fraction = np.abs(n_red_remaining - n_black_remaining) / (n_red_remaining + n_black_remaining) if n_red_remaining > n_black_remaining: bet_red = stake * fraction elif n_black_remaining > n_red_remaining: bet_black = stake * fraction # derive outcome stake = stake - (bet_red + bet_black) if is_red[i]: stake = stake + 2 * bet_red n_red_remaining = n_red_remaining - 1 else: stake = stake + 2 * bet_black n_black_remaining = n_black_remaining - 1 return stake In[5]: # play the game 10000 times payoffs = [ run_bets(k_array_with_t_true(52, 26)) for _ in range(10000) ] assert np.max(payoffs) - 1e-8 < np.min(payoffs) (np.min(payoffs), np.max(payoffs)) Out[5]: (9.081329549427776, 9.081329549427803) For each run we made a return of 9.08 times our starting stake. It is remarkable that there was no variation or variance in the outcomes. Notice this 9.08 times return is much larger than the 2 times return of the simple “wait to the end” strategy. This result is very unusual for a Kelly strategy. Kelly strategies guarantee to not “bust” (lose all of the money) and to maximize the expected growth rate of the logarithm of the stake. But they usually guarantee little else, can in fact lose money, and are usually high variance. How is it that in this case Kelly can’t fail? An explanation There is a remarkable proof that the strategy is zero variance. There are (52 choose 26) = 495,918,532,948,104 possible arrangements of red versus black cards. It is a standard result (not proven here) that each of these arrangements is in fact equally likely in a properly shuffled deck. We define a new “portfolio” strategy as follows. Each of the (52 choose 26) possible red/black arrangements is assigned as a sub-strategy in our portfolio. We allocate a 1/(52 choose 26) fraction of our initial stake to each sub-strategy. We allow each sub-strategy to keep its own money and do not re-allocate money between sub-strategies. Each sub-strategy assumes its assigned red/black arrangement is what is going to happen in the actual deck. The sub-strategy bets its entire stake on each card, betting the card exposed will match the corresponding one it its own defining arrangement. All but one of the portfolio sub-strategies will lose all of their money- as they eventually bet all their stake on a wrong guess. The single strategy that correctly guesses the entire deck ends experiences 52 doublings and no losses. Thus this strategy multiplies its starting stake by 2^(52). So our portfolio strategy itself always experiences a total aggregate return of $1/(52 choose 26) * 2^(52) ~ $9.08 on an initial $1 stake. This ending portfolio return is independent of the order of the cards. The claim to finish the argument is: the new portfolio strategy is in fact identical to the earlier Kelly strategy. Consider what happens to the portfolio when we draw a red card. In our portfolio strategy a r / (r + b) fraction of the non-bankrupt sub-strategies expect the next card to be “red”, and a b / (r + b) fraction of the non-bankrupt sub-strategies expect the next card to be “black”. The next draw bankrupts one of these families, and doubles the other (depending on the drawn color). Some though shows the portfolio strategy evolves its combined stake as follows: Aggregate stake goes to stake * 2 * b / (r + b) on drawing “red” Aggregate stake goes to stake * 2 * r / (r + b) on drawing “black.” It is a matter of algebra to confirm this portfolio payoff is exactly the payoff pattern for our earlier Kelly strategy of putting |r - b| / (r + b) on the most common color remaining. The Kelly strategy has exactly the same payoffs as the portfolio strategy, and we have our result that the two strategies are one and the same. The Kelly strategy is zero variance because it is identical to the portfolio strategy that is itself zero variance. Commentary An idea I like to take away is as follows. As we are betting on majority color, every time we lose a bet the deck becomes more unbalanced and more favorable to us. If we make the bet small enough then the gain in edge on a wrong bet offsets the loss of capital. In this case the Kelly strategy is pricing information or pricing uncertainty just right. This is similar to considerations of “exploration versus exploitation phases” in problems such as A/B testing. The proof given is from Winkler Mathematical Puzzles. I strongly recommend picking up the book to see his writeup on this and many other problems. The proof itself is very much the style of Cover. This is the Cover who later goes on to invent the universal portfolio investment strategy. Share this: Twitter LinkedIn Facebook Reddit Email Like this: Like Loading... Categories: Mathematics Quantitative Finance Tutorials Tagged as: betting iPython Kelly Criterion pydata python John Mount",
    "commentLink": "https://news.ycombinator.com/item?id=42466676",
    "commentBody": "Kelly Can't Fail (win-vector.com)328 points by jmount 19 hours agohidepastfavorite90 comments pcthrowaway 16 hours agoNote that you need to be able to infinitely divide your stake for this to work out for you all the time. For example, if the deck has 26 red cards on top, you'd end up dwindling your initial $1.00 stake to 0.000000134 before riding it back up to 9.08 reply boothby 15 hours agoparentIf you start out with a $1e12 stake, you're able to avoid catastrophic rounding errors even in the worst case. There's probably a life lesson here. reply cbsks 14 hours agorootparentMy simulation shows that with a 52 card deck, if you round the bet to the nearest $.01 you will need to start with $35,522.08 to win a total of $293,601.28. If you start with $35,522.07 or less, you will lose it all after 26 incorrect cards. reply boothby 12 hours agorootparentNearest rounding does seem like a mistake here. Rounding down is quite safe: rather than lose it all, you end up with at least 2^26 pennies. reply fragmede 15 hours agorootparentprevIs the lesson: choose to be born to wealthy parents? reply mannykannot 3 hours agorootparentIt would really help if your parents know someone who can and will take the other side in this game. reply croes 7 hours agorootparentprevIt’s easier to make money if you already habe money reply renewiltord 2 hours agorootparentprevA popular view is that having wealthy parents gives one a great advantage. Another popular view is that working extraordinarily hard for money is a waste of one’s life even if one gets the money. But the two are only consistent if one believes that one’s own life is the optimization target. If I live a life of misery so that my children live a life of prosperity that would strike me as a phenomenal result. So another reading is “choose to give your children wealthy parents”. reply darkerside 14 hours agorootparentprevOr is it to choose appropriate betting amounts based on your capacity for risk reply laidoffamazon 14 hours agorootparentI guess it then does follow that having rich parents does expand your capacity for risk! reply Etheryte 4 hours agorootparentprevOr is it to choose appropriate betting amounts based on your parents? reply User23 13 hours agorootparentprevThe lesson I'm taking away is \"learn math and how to use it.\" reply paulluuk 7 hours agorootparentApplying math to a more practical betting situation, like poker, is a lot harder. You'd have to be able to calculate your exact odds of winning given only a small amount of information, without a calculator and without it taking so long that the other players notice, and then also factor in the odds that the other players are bluffing and the advantages that you might have from (not) bluffing. reply barrenko 9 hours agorootparentprevLearn math and discover poignantly all the situations where it is effectively useless. reply Onavo 14 hours agorootparentprevIEEE-754 isn't precise enough for my capacity :( I too need rich parents. reply jmount 16 hours agoparentprevVery good point. I did some experiments and the system is very sensitive to any sort of quantization or rounding of bets. You get the expected value about the right place, but the variance goes up quickly. So in addition to your important case, things are a bit dicey in general. reply nyeah 5 hours agoparentprevIt's a good point. I think it affects the realism of the model. When the stake is very low, finding a penny on the street gives an astronomical improvement in the end results. At the high end, it's possible the counterparty might run out of money. reply tgma 14 hours agoparentprevYup, the dual would be saying Martingale can't fail with infinite money. reply aidenn0 15 minutes agorootparentIt's not because there is a finite amount of money at which this can't fail, which is never the case for martingale. Martingale is actually likely to bankrupt you against a casino that is much more well staked than you even if you have a small advantage. reply ab_goat 6 hours agoparentprevFinally a real world use case for bitcoin! reply kamaal 14 hours agoparentprev>>Note that you need to be able to infinitely divide your stake for this to work out for you all the time. This is what most people discover, you need to play like every toss of the coin(i.e tosses over a very long periods of time). In series, like the whole strategy for it to work as is. You can't miss a toss. If you do you basically are missing out on either series of profitable tosses, or that one toss where you make a good return. If you draw the price vs time chart, like a renko chart you pretty much see a how any chart for any instrument would look. Here is the catch. In the real world stock/crypto/forex trading scenario that means you basically have to take nearly trade. Other wise the strategy doesn't work as good. The deal about tossing coins to conduct this experiment is you don't change the coin during the experiment. You don't skip tosses, you don't change anything at all. While you are trading all this means- You can't change the stock that you are trading(Else you would be missing those phases where the instruments perform well, and will likely keep landing into situations with other instruments where its performing bad), you can't miss trades, and of course you have to keep at these for very long periods of time to work. Needless to say this is not for insanely consistent. Doing this day after day can also be draining on your mental and physical health, where there is money there is stress. You can't do this for long basically. reply teo_zero 12 hours agorootparentWhile I don't agree on nearly anything you stated, I enjoyed your prose: I suppose you left out words here and there as a metaphorical proof of your claim that you can't miss a single toss, didn't you? reply kamaal 5 hours agorootparent>>I suppose you left out words here and there as a metaphorical proof of your claim that you can't miss a single toss, didn't you? You must always practice in real world conditions. Notice in the experiments conducted in programs, you are taking series of tosses as they come, even if they are in thousands in numbers, one after the other, without missing a single one. Unless you can repeat this in a live scenario. This is not a very useful strategy. Kelly criterion is for people who are planning to take large number of trades over a long period of time, hence the idea is to ensure failures are not fatal(this is what ensures you can play for long). As it turns out if you play for really long, even with a small edge, small wins/profits tend to add to something big. If you remove all the math behind it, its just this. If you have a small edge to win in a game of bets, find how much you can bet such that you don't lose your capital. If you play this game for long, like really really long, you are likely to make big wins. reply teo_zero 4 hours agorootparentYou are conflating 2 concepts: a) that the reality converges to what the theory predicts only after a great number of samples; b) that if you skip some events the results will vary. Now, b) is false. You can change the code to extract 3 random numbers each time, discard the first 2 and only consider the third one, the results won't change. Instead a) is generally true. In this case, the Kelly strategy is the best strategy to play a great number of repeated games. You could play some games with another strategy and win more money, but you'll find that you can't beat Kelly in the long term, ideally when the repetitions approach infinity. reply kamaal 4 hours agorootparent>>Now, b) is false. You can change the code to extract 3 random numbers each time, discard the first 2 and only consider the third one, the results won't change. Might be in theory. In practice, this is rarely true. Take for example in trading. What happens(is about to happen), depends on what just happened. A stock could over bought/over sold, range bound, moving in a specific direction etc. This decides whats about to happen next. Reality is rarely ever random. Im sure if you study a coin toss for example, you can find similar patterns, for eg- if you have tired thumb, Im pretty sure it effects the height of the toss, effecting results. >>Instead a) is generally true. In this case, the Kelly strategy is the best strategy to play a great number of repeated games. Indeed. But do make it a point to repeat exact sequences of events you practiced. reply auc 9 hours agorootparentprevIf you assume coin tosses are independent, it shouldn’t matter if you miss coin tosses. reply kamaal 5 hours agorootparentCoin tosses are not independent. Unless the premise is coins toss themselves. A person tosses a coin, so tosses are are connected to each other. Ask yourself this question- Would your thumb hurt if you toss a coin 5000 times? If so, would that change the results? reply PaulHoule 1 hour agorootparentNaturally tossed coins tend to land on the same side they started with 0.51 of the time, see https://www.stat.berkeley.edu/~aldous/157/Papers/diaconis_co... reply aidenn0 8 minutes agorootparentLinked paper does not state that; it states that tossed coins tend to be caught on the same side they stared with slightly more than half the time. The results explicitly exclude any bouncing (which will happen if a coin lands on a hard surface). The paper does discuss coins allowed to land on a hard surface; it is clear that this will affect the randomness, but not clear if it increases or decreases randomness, and suggests further research is needed. reply PaulHoule 5 hours agoprevWhen I was a teen I discovered that I could always guess more than half the cards right using card counting to determine what color is more common in the deck. I programmed my https://en.wikipedia.org/wiki/TRS-80_Model_100 to simulate it and it never failed. Recently I thought about it again and wrote a Python script that tried it 30 million times and... it never failed. I've been thinking about what to do with it and came up with the options of (i) a prop bet and (ii) a magic trick, neither of which seemed that promising. As a prop bet I can offer $1000 to somebody's $10 which is not the route to great prop bet profits, also I worry that if I make a mistake or get cheated somehow I could be out a lot of money. (Now that I think of it maybe it is better if I re-organize it as a parlay bet) As a magic trick it is just too slow paced. I developed a patter to the effect that \"Parapsychologists were never able to reliably demonstrate precognition with their fancy Zener cards, but I just developed a protocol where you can prove it every time!\" but came to the conclusion that it was not entertaining enough. It takes a while to go through a deck which doesn't seem like a miracle, you will have to do it 7 times in a row to exclude the null hypothesis at p=0.01. Maybe somebody with more showmanship could do it but I gave up. reply jdhwosnhw 1 hour agoparentThat reminds me of my favorite algorithm, which can find the majority element in a list with any number of distinct entries while using O(N) time and O(1) space (provided a majority element exists). I sometimes pose deriving this algorithm as a puzzle for people, no one has ever solved it (nor could I). https://en.m.wikipedia.org/wiki/Boyer%E2%80%93Moore_majority... reply barapa 25 minutes agorootparentThat is really cool reply lordnacho 9 hours agoprevInteresting side note on Kelly: In probability theory, Proebsting's paradox is an argument that appears to show that the Kelly criterion can lead to ruin. Although it can be resolved mathematically, it raises some interesting issues about the practical application of Kelly, especially in investing. It was named and first discussed by Edward O. Thorp in 2008.[1] The paradox was named for Todd Proebsting, its creator. https://en.wikipedia.org/wiki/Proebsting%27s_paradox reply dominicrose 9 hours agoparentQuoting the same page: One easy way to dismiss the paradox is to note that Kelly assumes that probabilities do not change. That's good to know. Kelly is good if you know the probabilities AND they don't change. If you don't know or if they can change, I expect the right approach has to be more complex than the Kelly one. reply cubefox 2 hours agorootparentIn particular, then the right approach has to be more risk averse than Kelly would recommend. In reality, most probabilities can only be estimated, while the objective probabilities (e.g. the actual long run success rate) may well be different and lead to ruin. That's also what makes the title \"Kelly can't fail\" more wrong than right in my opinion. reply ilya_m 10 hours agoprevBeautiful, thanks for sharing it! I think the portfolio argument is an unnecessary detour though. There's a two-line proof by induction. 1. The payoff in the base case of (0,1) or (1,0) is 2. 2. If we are at (r,b), r >=b , have $X, and stake (r-b)/(r+b) on red, the payoff if we draw red and win is X * (1+(r-b)/(r+b)) * 2^(r+b-1) / (r+b-1 choose r-1) = X * 2^(r+b) * r / ((r+b) * (r+b-1 choose r-1)) = X * 2^(r+b) / (r+b choose r). Similarly, if we draw black and lose, the payoff is X * (1-(r-b)/(r+b)) * 2^(r+b-1) / (r+b-1 choose r) = X * 2^(r+b) * b / ((r+b) * (r+b-1 choose r)) = X * 2^(r+b) / (r+b choose r). QED reply fancy_pantser 16 hours agoprevA very similar card game played by deciding when to stop flipping cards from a deck where red is $1 and black is −$1 as described in Timothy Falcon’s quantitative-finance interview book (problem #14). Gwern describes it and also writes code to prove out an optimal stopping strategy: https://gwern.net/problem-14 reply snthpy 14 hours agoparentNice! Only quibble i have is that black should be +$1 and red -$1 to follow standard finance conventions, i.e. be in the \"black\" or \"red\". reply jmount 15 hours agoparentprevThat is a nice game and writeup. reply JohnMakin 16 hours agoprevKelly criterion is one of my favorite game theory concepts that is used heavily in bankroll management of professional gamblers, particularly poker players. It is a good way to help someone understand how you can manage your finances and stakes in a way that allows you to climb steadily forward without risking too much or any ruin, but is frequently misapplied in that space. The problem is kelly deals with binary results, and often situations in which this is applied where the results are not binary (a criteria for applying this) you can see skewed results that look almost right but not quite so, depending on how you view the math reply amluto 15 hours agoparent> particularly poker players The Kelly criterion seems excellent for many forms of gambling, but poker seems like it could be an exception: in poker, you’re playing against other players, so the utility of a given distribution of chips seems like it ought to be more complicated than just the number of chips you have. (I’m not a poker player.) reply fernandopj 1 hour agorootparentChris \"Jesus\" Ferguson \"proved\" an application of this theory back in ~2009 [1]. He was a the time promoting Full Tilt and commited to turn $1 dollar bankroll to $10000 by applying a basic strategy of never using more than a low % of his bankroll into one tournament or cash game session. So, if one's skill would turn your session probability to +EV, by limiting your losses and using the fact that in poker the strongest hands or better tourney positions would give you a huge ROI, it would be just a matter of time and discipline to get to a good bankroll. Just remember that for the better part of this challenge he was averaging US$ 0.14/hour, and it took more than 9 months. [1] https://www.thehendonmob.com/poker_tips/starting_from_zero_b... reply tempestn 12 hours agorootparentprevIt's used for bankroll management (basically deciding what stakes to play) rather than for sizing bets within a particular game. reply peter_retief 13 hours agoparentprevCould this work with roulette betting on color? Seems like you could spend a lot of time not winning or losing reply plorkyeran 12 hours agorootparentRoulette results are uncorrelated and you have the exact same chance of winning each time, so the Kelly criterion isn’t applicable. Betting on a color has a negative edge and you don’t have the option of taking the house’s side, so it just tells you the obvious thing that you should bet zero. reply dmurray 10 hours agorootparent> exact same chance of winning each time, so the Kelly criterion isn’t applicable. Actually, the main assumption that leads to the Kelly criterion is that you will have future opportunities to bet with the same edge, not constrained by the amount. For example, if you knew this was your last profitable betting opportunity, to maximise your expected value you should bet your entire stake. I'm slightly surprised it leads to such a nice result for this game - I don't see a claim that this is the optimal strategy for maximizing EV zero variance is great, but having more money is also great. Of course you are right about roulette and, if you are playing standard casino roulette against the house, the optimal strategy is not to play. But that's not because bets are uncorrelated, it's because they are all negative value. reply Tepix 9 hours agorootparentprevWhat makes 0 better than the other numbers? reply Vecr 8 hours agorootparentCan't bet negative in that kind of game. If a game is expected to lose you money, don't play. reply bloodyplonker22 15 hours agoparentprevYou are right that Kelly criterion deals with binary results. This won't work for poker. In poker, we use expected value because wins and losses are not binary because of the amount you win or lose. Once you figure out your approximate EV, you use a variance calculator in addition to that (example: https://www.primedope.com/poker-variance-calculator/) to see how likely and how much it is you will be winning over a certain number of hands in the long run. reply barbegal 18 hours agoprevIt would have been a better demo if reduced to more manageable numbers e.g. a deck of 2 black and 2 red cards. Turn 1 r = b so no bet Turn 2 bet 1/3 on whichever card wasn't revealed in turn 1. Turn 3 either you were wrong on turn 2 and you now have 2/3 of your stake but you know the colour of the next two cards so you can double your stake each time to end up with 4/3 after turn 3 or you were right and you have 4/3 of your stake but have one of each red or black left so you don't bet this turn. Turn 4 you know the colour of the final card so you double your money to 8/3 of your original stake. And then the exercise to the reader is to prove optimality (which is fairly straightforward but I don't believe there is a short proof) reply libraryofbabel 17 hours agoparentYes. Although four cards has only one nontrivial branch, on turn 3. So, start out with the four cards example, and then show tree diagrams for the 5 and 6 cards cases (still manageable numbers) to build intuition for induction to the general case. reply stevage 18 hours agoparentprevAgreed, I could follow the general argument but not enough to be convinced about why the result is exactly the same regardless of the order of cards. reply hawkjo 18 hours agoprevVery cool to see no variance in the outcome. But that also makes it feel like there should be a strategy with better expected return due to the unique problem structure. Do we know if the Kelly strategy is optimal here? reply travisjungroth 14 hours agoparentI have a feeling it’s the highest EV. I tried a strategy of flipping all the cards until there’s only one color left and then betting it all every time. Ran a million trials and got 9.08. I was thinking these are very different strategies, but they’re not exactly. The Kelly strategy does the same thing when there’s only one color left. The difference is this strategy does nothing before that point. Still, they feel like limit cases. Betting it all with only one color left is the only right move, so it’s what you do before that. Nothing and Kelly seem like the only good strategies. reply foota 12 hours agorootparentAh, but these aren't the same. The Kelly strategy has zero variance, whereas this strategy likely has very high variance. It would be interesting to do the math and show why they're equal. It seems like you should be able to make the same sort of portfolio probability argument. reply foota 12 hours agorootparentTo start, your minimum return is 2x, and depending on how many cards of a single color are left at the end, you get a return of 2^N. You could take the summation of those N card returns, times the probability of each, and that must come out to 9.08 on average. I guess the number of possible arrangements of cards with N of one color remaining is... The number of permutations of N times 2 times the number of permutations of 52 minus N times 26 choose N? Ah, yes this works, you can see it here: https://www.wolframalpha.com/input?i=%28summation+of+N%21+*+.... That is: (summation of N! * (52 - N)!* (26 choose N) * 2^N/52! from N=0 to 26 (for some reason the * 2 for different suits was over counting, so I removed it. Not sure why? Also it seems like it should be from 1 to 26, but that also doesn't give the right answer, so something is whack) reply travisjungroth 6 hours agorootparentprevOf course they're not the same. They have the same EV and the strategies do the same thing in a condition that always happens: there's only one color left. The variance is wildly different. reply rahimnathwani 18 hours agoparentprevDo we know if the Kelly strategy is optimal here? What do you mean by optimal? Do you mean you're willing to risk going bankrupt, if it means a higher expected value? reply scotty79 15 hours agorootparentSurely there's some space between risking to go bankrupt and risking of getting less than 9.08 return guaranteed by Kelly strategy. If you are willing to take some risk in exchange for possibility of higher payout just bet a bit more then Kelly recommends. That's your \"optimal\" strategy for the amount of risk you are willing to take. I imagine it's expected return is the same as Kelly and calculating it's variance is left as the exercise for the reader. reply rahimnathwani 10 hours agorootparentI imagine it's expected return is the same as Kelly Given two options with the same expected return, most people would prefer the lower variance. Accepting higher variance with no increase in expected return has a name: gambling. reply OscarCunningham 8 hours agoparentprevIn this game, all strategies have the same expected value, so long as they follow the rule 'if the remaining deck is all the same colour, then you should bet everything you have on that colour'. reply jmount 18 hours agoparentprevThe book claims it is optimal for a set of strategies they called \"sensible.\" I didn't think the argument flowed as well as the zero variance part of the proof, so I didn't work it in. I think the source also hinted at a game-theory proof as they called the sub-strategies in the portfolio \"pure strategies.\" reply barbegal 18 hours agoparentprevIt is optimal for expected returns yes. reply lupire 14 hours agoparentprevThe Kelly criterion is the strategy with better return due to the uniquely problem structure. reply raydiak 18 hours agoprevAs a guy named Kelly, I appreciate the vote of confidence! reply pvg 15 hours agoparentI think you're underselling it a bit, it's a decree of confidence rather than a mere vote. reply amluto 15 hours agoprev> The problem and solution appear to come from Thomas Cover. I don’t recall this specific example, but I learned about the Kelly criterion in a class that Thomas Cover taught. He was one of my favorite teachers, and any discussion with him was guaranteed to be interesting and worthwhile. RIP. reply im3w1l 3 hours agoprevThis article uses stake to mean bankroll, but usually it denotes bet size. reply Vecr 19 hours agoprevChecks out with multiple RNG seeds. It shouldn't be a problem because the RNG is advanced each run. Might save someone a check though. reply jmount 18 hours agoparentI love that. Gaming the seed is always a possibility in demos. reply malisper 17 hours agoprevI need to do some Math, but I wonder if there's a better strategy than Kelly betting. An assumption made for Kelly betting is the bets are independent of each other. That's not the case in the problem given. After making a bet, you gain information about the contents of the rest of the deck of cards. I could see it being possible to do better by pricing in that information into your bet. reply amluto 15 hours agoparentBut the information gained in this game is independent of your bet. The multi-armed bandit problem is a famous example of the opposite situation. reply necovek 9 hours agoparentprevThat seems to be exactly what this strategy is doing: at every step, you account for the probability of the red or black card coming up, and bet accordingly (both the sum and the colour). reply siavosh 18 hours agoprevCan anyone comment on the universal portfolio article linked in the conclusion? Asking for a friend. reply robbomacrae 17 hours agoparentIt's a theory on how to optimally rebalance your investment portfolio every day. Original paper by Thomas Cover: https://isl.stanford.edu/~cover/papers/paper93.pdf A good breakdown with links to code examples by Andy Jones: https://andrewcharlesjones.github.io/journal/universal-portf... reply dado3212 19 hours agoprevVery cool writeup, would’ve benefited from some LaTeX formatting. reply jmount 19 hours agoparentThank you, and sorry. The Wordpress/Markdown path seems to be getting worse over time. reply smcin 16 hours agorootparentHow is the Wordpress/Markdown path getting worse over time? reply jmount 14 hours agorootparentMathjax used to be available more places. Jupyter used to respect spacing around h2 labels. Things like that. reply bell-cot 2 hours agoprevInteresting as a mathematical puzzle - but note that it's difficult to find cooperative, solvent counter-parties for \"I can't lose\" betting games. reply lupire 15 hours agoprevCorollaries, by considering different deck shufflings, such as perfectly interleaved as perfectly separated: 9.08 ~ 52/52 × 52/51 × 50/50 ÷ 50/49 × ... 2/2 × 2/1 = 52/51 × 50/49 × ... × 2/1 = 2^52 × 26!² / 52! = (52/52 × 50/51 × ... × 2/27) × (52/26 × 50/25 × ... × 2/1) and these equalities can also be directly verified algebraically This also points to a non-\"many worlds\"/portfolio version of the prod of zero-variance. Every bet is e/d, where e is current edge and d is current deck size. So every outcome multiplies the stack by (d + e × (-1)^i)/d, where is ±1, depending on win or lose. Note that the product of all the values of d is constant, so we can ignore the denominator. Since we know (from the OP proof) that the product of these numbers is constant for all shuffles of the deck, we can split a shuffled deck anywhere such that both parts are balanced red=blue, and the total (multiplicative) return over each part of the deck is constant across all shuffling of that part of the deck. (There are at least two ways to prove this part!) This is gives a further hint toward another fascinating fact: over any span of the deck between points where the deck is balanced, the numerators of the bet results double-cover all the even numbers between the starting and ending deck size. To see why: * A loss after a loss has a numerator (deck minus edge) of 2 less than the previous bet, as the deck size decreased by 1 and the edge has inccreased by 1. * A win after a win also has a numerator (deck plus edge) of 2 less than the previous bet, as the deck size decreased by 1 and the edge has decreased by 1. * A win after a loss, causes a big swing in the numerator, exactly back to the largest not yet double-covered numerator that started the streak that just ended. Then the new win streak continues making the second cover of even numerators, until... a loss after a win jumps the numerator back to continuing the sequence of decreasing even numberators, which will get their second cover later when the later wins come. Since the deck is balanced, the number of wins always equals the number of losses, as long as we consider the 0 wager on a balanced subdeck to be a loss, since it increases the edge like non-degenerate losses do. (When the deck is balanced, edge is 0, so the return of no-bet is same as a win is same as a loss) You can visualize the numerator changes like so: a crane is driving from 52 to 0. Its arm is pointing either forward or backward, and there is a counterweight of the same length pointing in the opposite direction. At each step, the crane arm is either pointing toward 0 and stretches another step toward 0, or points backward to 52 and shrinks (toward 0 milestone and toward 0 arm length), or it swings to the other direction. Whenever the crane stretches toward 0, the counterweight stretches backward, its end not moving relative to the ground. Because the deck is balanced at start and empty deck is balanced, the crane starts and ends with a 0-stretch arm. The front side is either the frame arm stepping 2 steps forward at a time relative to the ground, or holding still while the backside crane arm shrinks closer, and the crane arm occasionally flips back and forth pointing forward or ackward. And vice versa for the counterweight. Over the course of the drive, the crane arm end reaches every even milestone once pointing forward and once again pointing backward. reply ed-209 16 hours agoprevwhy use a static seed on the random generator and could that be making this appear more interesting than it might otherwise? reply jfengel 16 hours agoparentThe idea is sound. The static seed is presumably so the results are repeatable, but it works for true randomness. (Assuming you were permitted to do it this way, which you wouldn't be.) reply andrewprock 13 hours agoprevIn practice, there are a number of factors which make using Kelly more difficult than in toy examples. What is your bankroll? Cash on hand? Total net worth? Liquid net work? Future earned income? Depending on the size of your bankroll, a number of factors come in to play. For example, if your bankroll is $100 and you lose it all it's typically not a big deal. If you have a $1 million bankroll, then you are likely more adverse to risking it. What is the expected value? Is it known? Is it stationary? Is the game honest? Depending on the statistical profile of your expected value, you are going to have to make significant adjustments to how you approach bet sizing. In domains where you can only estimate your EV, and which are rife with cheats (e.g. poker), you need to size your wagers under significant uncertainty. What bet sizes are available? In practice, you won't have a continuous range of bet sizes you can make. You will typically have discrete bet sizes within a fixed range, say $5-$500 in increments of $5 or $25. If your bankroll falls to low you will be shut out of the game. If your bankroll gets too high, you will no longer be able to maximize your returns. At the end of the day, professional gamblers are often wagering at half-kelly, or even at quarter-kelly, due in large part to all these complexities and others. reply zahlman 12 hours agoparent> In practice, you won't have a continuous range of bet sizes you can make. You may also be required to pay for the privilege of placing a bet (spread and commissions in trading; the rake at a casino table). reply lupire 14 hours agoprevIntuition for the bet size: When the deck has d cards left, it is sensible to make d bets of 1/d your stack, where each bet is that one specific card is next. If there are r reds and b=r+e blues, r of these bets simply cancel out r other bets, leaving e (times 1/d) remaining to be a nontrivial bet. reply moonlion_eth 15 hours agoprevI was like \"oooh fun a card game\" then was like \"oh shit I'm too dumb for this math\" reply IAmGraydon 14 hours agoparentYou aren't dumb. You just don't have enough exposure to the prerequisites. reply necovek 9 hours agorootparentIt could also be both: though it's not necessarily that they are \"dumb\", but that the language of mathematics is something they can't get their head around, even if they can understand the concepts when described in spoken language. Eg. it's probably pretty easy to convince them that with 15 cards in a deck, out of which 5 are red and 10 are black, chances are bigger (and in particular 10/15 or ~67%) that they'll pull out a black card, and that you should bet more on this happening. If you happen to miss, you should only bet even more on black since the chances grow further — to be able to maintain this strategy, you only need to never bet too much so you have enough \"funds\" to bet all the way through (eg. in the worst case where the least likely thing happens: in my example, that would be 5 red cards coming up first). Putting all this reasoning into formulae is what math is, and I do believe some struggle with abstracting these more than others (which is why the divide does exist and why many people believe those good at math are \"smart\", which is very much not so — seen plenty of \"stupid\" mathematicians, even professors). Does not make them \"dumb\", but might make them \"modern math dumb\". A signal that someone can be good at math today is that they are unfazed with more-than-3-dimensional spaces (you need to stop tying things to physical world). reply tooblies 16 hours agoprev [–] It's really disappointing that the code examples aren't given in PyGyat. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Kelly bet allocation strategy, typically known for high variance, is risk-free with zero variance in the \"Next Card Bet\" card game.- In this game, the strategy involves betting on the color of the next card from a shuffled 52-card deck, maximizing the expected logarithm of the stake based on the difference in remaining red and black cards.- The strategy consistently returns 9.08 times the initial stake with no variance, as it mirrors a portfolio approach where only one sub-strategy succeeds, akin to exploration versus exploitation in A/B testing."
    ],
    "commentSummary": [
      "The Kelly criterion is a strategy used in gambling and investing to optimize bet sizes based on probabilities, but its real-world application can be challenging.",
      "The discussion highlights the importance of infinite divisibility of stakes and the complexities in non-binary outcome scenarios, such as poker.",
      "Factors like bankroll size, expected value, and available bet sizes are crucial in applying the Kelly criterion, with mathematical proofs and simulations supporting its effectiveness, yet acknowledging its limitations and potential pitfalls."
    ],
    "points": 328,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1734649635
  },
  {
    "id": 42465535,
    "title": "Satellite powered estimation of global solar potential",
    "originLink": "https://research.google/blog/satellite-powered-estimation-of-global-solar-potential/",
    "originBody": "play silent looping video pause silent looping video Home Blog Satellite powered estimation of global solar potential December 12, 2024 Vishal Batchu, Senior Software Engineer, Google Research, and Betty Peng, Senior Software Engineer, Google High-quality satellite digital surface models and roof segmentation power Google Maps Platform Solar API expansion in the global south and reduce global revisit times. Quick links API Paper Sign up form Share Copy link × Energy demand is set to increase dramatically in coming years, and residential solar power is poised to play a crucial role in meeting this challenge sustainably. By 2035, solar photovoltaics are projected to generate a staggering 10.7k TWh globally — nearly 28% of the total anticipated demand! As cities grow and the impacts of climate change intensify, the transition to renewable energy sources like solar becomes increasingly urgent. By offering a cleaner alternative to fossil fuels, solar energy empowers individuals and businesses to control their own energy production and reduce their carbon footprint. Unfortunately, barriers to solar adoption persist, particularly in parts of the Global South where access to financing, technology, and infrastructure is limited. To unlock solar’s potential around the world, a concerted effort is needed from governments, organizations, and researchers to develop accessible and scalable solutions. Assessing the solar viability of a property involves numerous variables, often posing a challenge for homeowners and businesses. The Google Maps Platform (GMP) Solar API simplifies the process of assessing solar potential and designing solar systems by leveraging aerial imagery to provide key insights for rooftops. Today, we're excited to announce an experimental expansion in the coverage of this API in the Global South. By applying machine learning (ML) models to satellite imagery, we can generate digital surface models (DSMs) and roof segmentation maps to enable solar assessments in new areas around the world. The methodology is detailed in our paper “Satellite Sunroof: High-res Digital Surface Models and Roof Segmentation for Global Solar Mapping”, published at the Climate Change and AI workshop at NeurIPS 2024. You can explore this experimental data and contribute to a brighter future by signing up today! play silent looping video pause silent looping video Visualizations of experimental satellite-based data in the Solar API for a building in Brasilia, Brazil. Insights from the Solar API Installation of residential solar panels is often slow and complicated, especially in emerging markets with limited data. The process typically involves educating homeowners, taking manual measurements, and creating designs and proposals based on scarce information — all before a contract is even signed. To address these challenges, the Solar API was launched in 2023 under Google Maps Platform's Environment APIs. It provides comprehensive building solar data and detailed rooftop imagery by processing aerial imagery, weather, and financial data. Earlier this year, we expanded the Solar API’s reach by applying ML techniques within our processing pipeline, bringing solar insights to millions of additional buildings across the US, Europe, and Japan. This data aims to help: Empower businesses to provide people with personalized solar potential insights and optimized panel layouts. Identify installation locations for potential investments and business growth opportunities. Increase customer conversion rates with less effort and lower costs. Accelerate adoption with remote proposals and quotes. Optimize designs using 3D models for efficient panel layouts. Aid in the development of new incentive programs based on data-driven insights. Expanding globally with satellites To address the growing need for solar data in the Global South, we began to explore the application of ML techniques on satellite imagery. Though working with lower-resolution satellite imagery presents new challenges, such as the scarcity of accurate elevation maps, reduced image quality, and distortions from oblique viewing angles, we see this as a significant opportunity to accelerate the growth of solar markets in new regions. Satellite imagery not only offers a pathway to global coverage but also enables more frequent data updates, even in well-mapped areas like the US and Europe, where relying solely on expensive and potentially outdated aerial imagery can be a limitation. This data is currently available to experimental users through the Solar API Expanded Coverage Testing Program, with a number of solar installers already using the data outputs, as shown below. play silent looping video pause silent looping video Visualization of satellite inputs to the processing pipeline, and the outputs available via the Solar API, in Brasilia (Brazil). With this expansion, we unlock the use of satellite imagery for solar potential estimation, resulting in 125 million new buildings with Solar API data across 23 countries. This project extends the total potential coverage by 1.9 billion additional buildings around the world, based on currently available satellite imagery. More buildings will become available as satellites continue to capture new areas. play silent looping video pause silent looping video Illustrates the potential coverage increase made possible with satellite-based insights. Please refer to the coverage map for the latest Solar API coverage. This will continue to increase over time as we roll out to more regions. Using ML to predict high-quality DSMs and roof segments The solar data generation pipeline requires high-quality DSMs in order to compute planar roof segments for solar panel calculations. However, traditional stereo methods for satellite DSM generation are unreliable because high-resolution (<1 meter) satellite imagery is expensive to capture, often leading to limited views of a given region with significant temporal gaps. Existing roof segmentation techniques are also less accurate on satellite data due to the lower resolution. To address these challenges, we’ve developed new ML models that can generate high-quality nadir (overhead) DSMs and planar roof segment instances from single-view satellite imagery. Left: Inputs to the satellite ML model in the off-nadir view. Right: Outputs from the model in the nadir view. We employ a two-stage model to produce DSMs and roof segments. The first stage is the base model, which processes off-nadir satellite RGB imagery with the corresponding satellite view angles. We optionally include low-quality photogrammetry-derived relative heightmaps (DSM-DTM) where they are available. These initial input DSMs have limited coverage and are at an insufficient resolution for detailed rooftop calculations. Using a U-Net–style architecture with a Swin Transformer encoder, the base model generates improved height maps and roof segment instances in the off-nadir view. These are then reprojected to a nadir view using geometry-based reprojection. The second stage, the refinement model, further enhances the nadir RGB, DSM and segment instances by filling in gaps and artifacts produced in the reprojection step. The base and refinement models use L1 and Sobel gradient losses for DSM estimation, and affinity mask losses for roof segmentation. play silent looping video pause silent looping video An example of a reference satellite view (top) and aerial RGB+DSM (bottom) being reprojected to the reference view. Our models are quantitatively evaluated using a variety of metrics, including DSM mean absolute error (MAE), roof pitch error, and roof segment instance intersection over union (IOU). DSM and pitch results are compared to high-quality aerial DSM equivalents. Roof segment labels are obtained in two ways — either computed using graph-cut (GC) on DSM labels, or manually labeled using human annotations. We categorize these results into two groups based on input channels: \"RGB-only\" (global coverage) and \"RGB+DSM\" (limited coverage, only where stereo-based input DSMs are available), which help us understand model performance. These detailed performance metrics were compared across a broad set of countries where higher-quality aerial data is available. We also evaluated end-to-end results from the Solar API pipeline. Validation results for the combined base + refinement model. Columns left to right: Input channels used by the model, overall heightmap MAE (lower is better), buildings-only heightmap MAE (lower is better), roof pitch errors (lower is better) based on graph-cut (GC) segment labels, roof segment IOU (higher is better) based on graph-cut segment labels, roof segment IOU (higher is better) based on hand-annotated labels. The results show that while inclusion of low-quality DSMs improves shading predictions, as captured by the building DSM MAE, it doesn’t significantly improve roof segmentation or pitch accuracy, which are more critical for estimating solar potential. Our model's strong performance with RGB-only inputs makes it suitable for application in any region where satellite RGB imagery is available. Building DSM MAE distribution per country using RGB-only inputs, enabling evaluation across a broader set of countries. We observe that the error variation between countries is small, with the exceptions of Chile and the Philippines, which can be attributed to noisy ground-truth data. This suggests that our model can adapt to a variety of regions with varying building styles and sizes, and across complex roof structures. Visualizations Location: Ayodhya, India. Location: Kuala Lumpur, Malaysia. Location: Adelaide, Australia. Visualizations of model predictions: nadir RGB (left), nadir DSM (middle), and nadir roof segment instances (right), from various regions around the world. Our models generalize well across varying architectural styles and landscapes. In regions with flat rooftops, our DSMs accurately capture obstacles and roof surfaces with a high level of accuracy. In areas with tilted rooftops, the models effectively predict roof ridges, which are important for accurate panel placement. While the DSMs may not capture the intricate details of individual trees, tree height information is available and used for analyzing shading impacts over adjacent rooftops. The figure below compares the predictions of our satellite-based model against the high-quality aerial data that is currently available in the Solar API. play silent looping video pause silent looping video Comparison of high quality aerial data vs. satellite-derived model outputs. The figure shows RGB (left), DSM (middle) and roof segments (right) in Bloemfontein, South Africa. The figure below displays the annual solar flux estimated by the Solar API, superimposed on satellite RGB imagery. Visualization of Solar API annual solar flux predictions in Ipoh, Malaysia. Looking ahead While this expansion significantly increases the availability of solar data, inherent challenges and limitations persist. Factors like input pixel resolution, cloud cover, and occlusion artifacts can influence the output quality. We are actively working on improving the accuracy through ongoing research and user feedback. Future work will also focus on exploring new research directions, such as obstacle detection, roof material detection, and existing solar panel identification. Acknowledgements We would like to thank individuals in Google Research, Geo and DeepMind who carried out this work and made the launch possible, including (in alphabetical order): Alex Wilson, Alicia Noel, Ariel Mann, Artem Zholus, Betty Peng, Carl Elkin, Christina Ranalli, Christopher Schmidt, Christopher Van Arsdale, Courtney Maimon, Dana Kurnaiwan, Hedva Uriel, Jenna Hussein, Jordan Raisher, Juliet Rothenberg, Lisa Lovallo Ceppos, Marisa Leung, Mike Tavendale, Nobal Preet Singh, Paul Moniuszko, Peleg Amon, Rajroshan Sawhney, Revati Thatte, Ross Goroshin, Saleem Van Groenou, Sritoma Bhattacharjee, Tuvia Alon, Umangi Jain, Varun Gulshan and Vishal Batchu. Labels: Climate & Sustainability Machine Intelligence Quick links API Paper Sign up form Share Copy link × Other posts of interest December 19, 2024 Google Research 2024: Breakthroughs for impact at every scale Algorithms & Theory · Climate & Sustainability · General Science · Generative AI · Health & Bioscience · Machine Intelligence · Quantum · Year in Review December 10, 2024 Advancing AMIE towards specialist care and real-world validation Generative AI · Health & Bioscience · Machine Intelligence December 6, 2024 Looking back at speculative decoding Algorithms & Theory · Generative AI · Machine Intelligence",
    "commentLink": "https://news.ycombinator.com/item?id=42465535",
    "commentBody": "Satellite powered estimation of global solar potential (research.google)254 points by jonbaer 22 hours agohidepastfavorite187 comments tppiotrowski 19 hours agoAs someone who has researched DSM availability across the globe, Google's Solar API is a top contender. Other option is government LiDAR surveys but the coverage, file formats, projections, etc are all fragmented. I think it would be great for the mapping community to create a world wide DSM map tile dataset similar to the ground elevation tile dataset that contour lines and 3D terrain views are generated from. Maybe someone is already working on this? In the article they show areas where their approach can generate DSM although this is just the potential areas and not the areas where data is already available. :( reply pyaamb 18 hours agoprevThis is really incredible. If they could plug in local utility prices and come up with estimate for dollars saved per year, that would be an incredible conversation starter for homeowners who might not have considered taking on a home solar project otherwise. reply rrr_oh_man 15 hours agoparent> incredible conversation starter for homeowners who might not have considered taking on a home solar project otherwise Once you do the math in a Northern country (sans subsidies) it's not as compelling as you might think. reply rgmerk 15 hours agorootparentBecause (at least in the USA) the soft costs are excessive: https://pv-magazine-usa.com/2022/11/16/tackling-soft-costs-a... reply jvanderbot 2 hours agorootparentConsidering \"Customer aquisition\" as a cost is really funny (and that seems to be the \"soft cost\" discussed). In Minnesota the \"deal\" for solar if you cannot DIY / off-grid is just meh. They do not allow use of battery backups or cutover, they cut out when the power goes out, and they \"credit\" you to reduce your overall bill. You can make money if you produce more power in sunny warm times than you use year around (at least while you are the only one!), but the dream of energy independence at a local scale just isn't there yet. What I want is something that offsets my grid use (potentially to zero but not negative), so that I can use grid or solar to charge my EV and a whole-home battery bank with three days reserve. I don't care about becoming part of the overall grid solution, but in city limits, it appears I must, and that necessitates extra equipment and rules out my backup use case. And yet, I get constant calls and fliers about it - all \"soft costs\" - no matter how much I say no. reply bruce511 15 hours agorootparentprevBy \"Northen\" I assume you mean Europe, and (most of) USA? I live near the 33rd parallel South. Since installing solar my annual grid requirements are around 30% of before solar [1] ‐ even as my actual consumption has risen [2]. As far as \"Northern\" goes countries in my latitude north (or better) include India, Mexica, all of Africa, most of China, and so on. So for most people living in the north it is compelling [4]. [1] a very large fraction of my grid usage is really cold, wet conditions for 6 weeks in winter. A combination of low generation and high usage for heating. [2] cooling in summer is free, so we run the aircon a lot more. Plus things like slow-cooking etc are free as well. [4] my return on investment (grid cost of generated electricity over capital invested) is 16.7%. Projected lifespan is 10 years for battery and inverter, 25 years on panels, 50 years on wiring. reply HPsquared 5 hours agorootparentNorthern places (thinking UK here) don't use AC in summer, the economics are different. reply littlestymaar 4 hours agorootparentprev> By \"Northen\" I assume you mean Europe, and (most of) USA? People wrongly assume that you can put Europe and the US in the same basket (because temperature-wise climate is comparable), but half of Europe is further north than Montreal, and almost all of it is beyond Philadelphia, so no you can't really say “Europe and most of the US”. reply notatoad 15 hours agoparentprevlike this? https://sunroof.withgoogle.com/ reply geewee 13 hours agorootparentAw, I hoped for a second for global coverage. reply ak2372 9 hours agorootparent,$ reply xnx 20 hours agoprevThis is a very impressive refinement of their existing tool, but is this type of advanced calculation of roof-pitch (etc.) still relevant? Haven't we more or less concluded that a million piecemeal rooftop installations of solar are about the worst way to do it? More complicated and expensive to permit and install, less efficient operation, difficult to repair, difficult to insure, difficult to upgrade, inefficient to integrate into grid, etc. reply ijustlovemath 20 hours agoparentAs someone who recently lost power and water for weeks post Helene, do not discount the power of distributed grids. Distributed core infrastructure will make for much better climate resilience. Don't miss this in your efficiency calculations. reply XorNot 19 hours agorootparentGrid connected solar goes down when the grid is out though. You need specific inverters to retain power. You also just have issues like the low chance of having clear skies after a hurricane or a bushfire. For disaster situation power, a diesel generator is still the cheapest and most reliable option. reply ijustlovemath 19 hours agorootparentSure, but that's why my emphasis was on distributed grids. Interlinking local capacity / having one or two neighbors with fully fledged systems is way better than going weeks charging stuff in your car. When you're without power for weeks, you'll probably have enough sun for more than enough days to get yourself sorted. Hurricanes also tend to sweep up any other systems in the region, so once they disperse, it's pretty clear skies. Anecdotally, we didn't get any rain for months after Helene dissipated. Also, diesel and gas were pretty much inaccessible for the first 5 days of the disaster, so unless you have a stockpile that's been treated for longevity, you might not even be able to run your whole home generator for long. reply NavinF 18 hours agorootparent> Interlinking local capacity Is this a thing IRL? Every system I've looked at stops feeding the grid as soon as the grid goes down reply wongarsu 18 hours agorootparentThey have to. Feeding your own home needs some setup but is fine. But electricity companies require you to disconnect generating capacity from the grid when the grid is down to make it easier to effect repairs. But that's more a policy decision than a technical restriction. We could change it so power can flow on both sides of a fault instead of only the \"upstream\" grid side. reply xbmcuser 15 hours agorootparentWith battery systems getting so cheap maybe community batteries will become a thing where a neighborhood exports it's solar too and is it's own small grid. reply PaulDavisThe1st 15 hours agorootparentthat would mean either: a) government mandates that turn over existing grid infrastructure to such a project, because the existing grid infrastructure is almost all privately owned OR b) building new infrastructure to create an isolatable local grid Neither of these seem particularly likely to me. reply XorNot 14 hours agorootparentprevI mean it isn't though: it's defense in depth - policy is you must disconnect. Line workers will drive a ground stake in on both sides anyway, but if you don't disconnect then they'll just short your inverter to ground. reply ijustlovemath 13 hours agorootparentprevReferring more to microgrids here; think city block/neighborhood level independent grids reply NavinF 12 hours agorootparentAh I see. AFAIK selling electricity is highly regulated in most states so I can't imagine microgrids taking off in the US. It would be cool though reply malfist 16 hours agorootparentprevThere's a program involving F150 lighting trucks out in CA that pay you to grid tie them, that way a couple of them in your neighborhood can power the neighborhood for a day or so if wildfires take out the local grid reply PaulDavisThe1st 15 hours agorootparentAnything grid tied is generally required to have phenomenally reliable shutdown if the grid goes down OR proven (and very expensive) automated switching that disconnects it from the grid if the grid goes down. This is so those F150s are not backfeeding the wires while a repair crew is trying to fix it. Ergo, if the local grid is \"taken out\", those F150s cannot be \"on the local grid\". reply malfist 13 hours agorootparentI'm sure you know what you're talking about, but Duke energy is running the program, and they wouldn't be paying people to grid tie their EV for disruptions unless they could use it: https://news.duke-energy.com/releases/illuminating-possibili... The lightning extended range has a 135 kwh battery and can backfeed 90A@240V. That's a heck of a lot of power. reply NavinF 12 hours agorootparentArticle says \"customers will allow their EVs to feed energy back to the grid – helping to balance it during peak demand\". It doesn't say anything about what happens when the grid goes down during disasters reply bruce511 14 hours agorootparentprev>> Grid connected solar goes down when the grid is out though. You need specific inverters to retain power. Yes, and sort of. Inverters will prevent power flowing to the grid if the grid is off. However most inverters will continue to supply power into the house while the grid is off. There are various factors in play here, and you need to do proper homework, but certainly a fraction of the house can be powered, if not all of it. I'm not sure if this is \"special\" inverter or not. Every one I researched had the same functionality. reply bagels 12 hours agorootparentMost solar installations without batteries do not function without grid power present. Sure, some could, but most do not. reply p1mrx 3 hours agorootparentprev> a diesel generator is still the cheapest and most reliable option. The shelf life of diesel is about a year; the shelf life of propane is effectively unlimited. reply outside2344 3 hours agorootparentprevNot if you have a battery system attached reply rgmerk 14 hours agoparentprevAustralia manages to install rooftop solar at well under half the cost the USA does (most of that is soft costs) and integrate large amounts of it into the grid. As of lunchtime today, nearly 50% of all electrical generation on the national grid was rooftop solar (and another ~10% was utility-scale solar). Rooftop solar works just fine if utilities don’t actively try and obstruct its use. reply throwaway2037 11 hours agorootparent> As of lunchtime today, nearly 50% of all electrical generation on the national grid was rooftop solar Wow, this is incredible. Can you share your source? I would like to learn more! reply guerby 10 hours agorootparenthttps://aemo.com.au/energy-systems/electricity/national-elec... reply ltbarcly3 2 hours agorootparentprevThat's a great achievement, but could be stated in a more clear way. Not 'As of lunchtime' but 'At precisely lunch time'. An hour later it wasn't 50% anymore, and it won't be 50% except at noon for a long time yet. As of the moment I am posting this, solar is 0% and coal is 80%. If Australia cares about global warming they should build nuclear plants and stop generating 70% of their overall power from coal. It's still remarkable how much solar is growing and I hope it's 100% 24/7 soon! reply szvsw 20 hours agoparentprevOne advantage of distributed solar is that it can at least come online right away and when installed with a battery, can get a home pretty close to being fully self-sufficient (depending on the climate/heating system), whereas the generally much more efficient solar pv power facilities have to contend with backlogs in connecting to the grid, insufficient grid capacity, etc. But yes, distributed solar will not be the general solution to decarbonizing our energy systems as a whole. Does serve a meaningful role though and there is no reason to not do both. reply CorrectHorseBat 20 hours agorootparentInsufficient grid capacity can also be local, there are many cases of inverters turning off because of too high grid voltage in the Netherlands reply ZeroGravitas 8 hours agoparentprevYes it's relevant and no we didn't all agree it was a bad idea. It generates power at roughly the cost of nuclear. It's distributed and resilient. It works around sluggish government and/or corporate monopolies. It reduces transmission requirements. It enables and encourages electrification and time-shifting of load. Adding it at build time can be cheaper than tiling. It’s generally a good thing and we'll see even more if it as the tech progresses and gets cheaper. reply opo 11 hours agoparentprev>...Haven't we more or less concluded that a million piecemeal rooftop installations of solar are about the worst way to do it? The data shows that you are correct. Utility grid solar provides low cost power and consumer rooftop solar does not and will not. The rooftop solar price is usually hidden because no power source has been as subsidized as rooftop solar. Besides direct subsidies, wealthier home owners have often been paid the retail rate for the electricity they sell to the grid which causes higher electricity bills for those who can't afford to put panels on their roof - sort of a reverse Robinhood scheme. As the statista.com report says: >...Rooftop solar photovoltaic installations on residential buildings and nuclear power have the highest unsubsidized levelized costs of energy generation in the United States. If not for federal and state subsidies, rooftop solar PV would come with a price tag between 117 and 282 U.S. dollars per megawatt hour. https://www.statista.com/statistics/493797/estimated-leveliz... Looks like that report is a year old, but I doubt the installation costs have really gone down much since then. (Panel prices come down, but labor costs, etc. don't.) reply bryanlarsen 2 hours agoparentprevThe majority of the cost of electricity in most jurisdictions is distribution, not generation. Grid-solar still requires distribution, so it is always going to have significant cost even if the cost of generation is insignificant. If it can remove the need for a grid-tie, then rooftop solar can be significantly cheaper and more efficient. Can be, but isn't yet, because enough overcapacity and storage to eliminate the need for a grid tie is still too expensive. reply s1artibartfast 2 hours agorootparentThis is exactly the challenge. Here in California wholesale solar plant sell power for 0.03-0.04 kwh. Cost at the meter is 0.45/kwh. Rooftop is competitive with the meter price, but unless you can cut the cord entirely, connection fees and rates will just keep increasing proportionally reply throwaway346434 20 hours agoparentprevOr to put it another way: available with a rate of return that makes it sensible for average middle class home owners to say yes to, to the point dirty power sources are having to shut down in some markets (or fiercely lobby through the political system to be propped up). One such example: https://www.theguardian.com/environment/article/2024/sep/08/... Perfect is the enemy of good reply yongjik 19 hours agoparentprevSounds like a rare case of America's ubiquitous suburbs working out for the environment. Everyone has a \"roof\" that gets sunlight most of the day, so rooftop solar, while being less efficient, is still a viable candidate. (Although, if you factor out all the extra driving needed for the suburban life, it would likely still come out negative compared to a proper city.) reply szvsw 18 hours agorootparentYeah, don’t over look the fact that the thermal demand from space conditioning homes is way higher on a per capita basis in a suburban context compared to an urban context with multi-family housing/apartments etc. There’s just way more air volume to condition per person, generally more inefficient systems, etc. reply yongjik 18 hours agorootparentEven for the same amount of living space, apartments are way more efficient. A typical apartment unit is surrounded by other units up/down/left/right, so only two sides are exposed to outside air. A single house is exposed on five sides. reply nwiswell 18 hours agorootparent> A single house is exposed on five sides. Six. The most heat escapes through the roof, but thermal loss through the floor is generally about 10-15% of the total. reply szvsw 11 hours agorootparentprevYeah we refer to this as the heat loss form factor of the building, which is determined largely by the surface area to volume ratio (so you have a square-cube relationship at work) as well as the the number of floors in conjunction with the roof area. With more floors, the heat transfer through the roof (which can be substantial, as mentioned by a sibling comment) is less significant for the same roof area (after normalizing for the gross floor area). Same goes for the slab/foundations (which can also have substantial thermal transfer in many contexts). reply macintux 19 hours agoparentprevI’m amazed at the amount of opposition to centralized solar generation. I assume there’s a fair bit of fossil fuel industry astroturfing involved. reply bruce511 14 hours agorootparentThere's the perception that it's an \"either\" question. When in reality its both. Home solar is a big win, and if nothing else allows capital to be sourced from a million home owners. Centralized solar is a big win, generating grid power Erich is obviously important. It's not a question of either, it's a question of both. reply macintux 13 hours agorootparentI should have made it clear: I’m referring to people who are adamantly opposed to large solar installations, apparently because it’s a threat to agriculture? It’s very odd, but I see yard signs and bumper stickers everywhere in rural Indiana. reply throwaway2037 10 hours agorootparentDo you think some farms in rural Indiana will make more money by converting to a solar power park? I could imagine it, and I could imagine that some people would feel threatened by this change. reply macintux 5 hours agorootparentSure, but follow the money: unsurprisingly it’s the usual big money bad actors who are funding opposition. https://energyandpolicy.org/fossil-fuel-funding-opposition-r... reply dzhiurgis 18 hours agorootparentprevIt all hinges on how much your infrastructure costs. At the moment something like 1/3rd of your retail cost if delivery. At some point it's 15x cheaper to have 1kW home feed in + battery vs 15kW feed in. reply macintux 13 hours agorootparentResponded to a sibling comment: I’m referring to people who oppose industrial solar installations for some reason. reply yourMadness 17 hours agoparentprevThere are enough panels available to do both and there is no overlap in financing for both. So just do every installation that is economically viable, they don't compete for money or panels. reply yen223 20 hours agoparentprevWith rooftop solar there's a path towards mass deployment that other alternative electricity generation solutions currently lack. Rooftop solar for residential houses doesn't require permits or planning, and can be done by individuals within a reasonable budget, unlike solar farms or rooftop nuclear. reply PaulDavisThe1st 15 hours agorootparent> Rooftop solar for residential houses doesn't require permits or planning Either you're assuming residential battery storage systems replacing the grid, or your ignoring the connecting rooftop solar to the grid requires permits and planning (the grid may not be able to handle it). reply pjc50 10 hours agorootparentDepends on your jurisdiction. UK home solar under 4kW doesn't require permission. reply bruce511 14 hours agoparentprev>> Haven't we more or less concluded that a million piecemeal rooftop installations of solar are about the worst way to do it? It really depends on what you mean by 'worst'. In terms of land-usage it's the best. In terms of speed-of-deployment it's the best. In terms of distributing capital spend its the best. In terms of capital return, that will vary from one house to the next because it depends on location, energy consumed (and when), elec prices in your region, grid stability, and so on. reply rsanek 14 hours agorootparentwhat do you mean by \"distributing capital spend\"? as in the money to pay for the installations is not concentrated to large utilities? why is that desirable? reply adrianN 14 hours agorootparentSometimes it’s easier to find a thousand people with a thousand dollars than one guy with a million dollars. reply jillesvangurp 6 hours agoparentprevDepends on your cost of electricity. In most places, a solar setup pays for itself long before the warranty runs out max 5-10 years typically (depending on a lot of factors). Even in the US which has a lot of extra cost related to people making things needlessly complicated and costly, lots of people are installing solar and earning their money back. I can actually get balcony solar here in Germany for about 240 euros. Here's how that works: - I buy a kit on Amazon. I found several nice ones. This one is rated for 850w and includes cables, inverters and other bits and bobs needed. - I zip tie the panels to my balcony - And I plug in the equipment and connect it to a wall socket The idea is that this would offload some of the power used by e.g. my fridge. Not the same as a rooftop setup obviously and in my case quite pointless since I don't have a lot of sun on my balcony. But I might actually qualify for a rebate if I do this and get all or most my money back. The government is sponsoring this and landlords can't stop you from doing this. Nor do you need their permission, a permit, or special insurance. The point is that this stuff is cheap, easy, and pretty much plug and play. Roofs aren't a whole lot more complicated than this from a technical point of view. You need more panels and more expensive equipment and you probably need some professional electricians and installers to do the work. The rest is just nonsense that relates more to your local government and legislation than anything being inherently expensive or difficult. I'd suggest reminding your local politicians of their responsibilities during the next elections and maybe voting for the ones that aren't being jerks on this front. Otherwise, solar panels are pretty reliable and generally covered by long warranties. Repairing them is mostly not a thing, somebody would come and simply replace them. I doubt that a lot of solar panel companies and installers are suffering a lot under the enormous burden of this happening all the time for the simple reason that it this isn't a thing. reply xnx 3 hours agorootparentBalcony solar sounds brilliant and probably has clear ROI. Rooftop solar is an awkward middle between grid-scale solar and balcony solar. Rooftop solar might only make sense in developed countries through subsidies. reply WillAdams 19 hours agoparentprevYes, but one back-of-the-envelope calculation (it was a Python program someone wrote up as part of a comment on Slashdot as I recall) demonstrated that if all of New York's roofs were covered in solar panels there would be enough energy to run the city.... reply Scoundreller 15 hours agorootparentEnough energy or enough electricity? reply WillAdams 5 hours agorootparentGood point. It feels right that the calculation ignored losses --- but if I recall, it did include panel efficiency and that has gotten much better, so maybe it would work now? reply tejtm 20 hours agoparentprevI thought we may have concluded that shareholder efficient centralized single point of failure systems are the least robust providers of basic human needs in the face of natural levels of uncertainty. reply akira2501 20 hours agoparentprev> More complicated and expensive More durable for individuals in the face of large scale failures. You're paying for something real there. reply Glyptodon 19 hours agoparentprevAt a certain point shouldn't things get good enough you don't really need a traditional power grid? reply benlivengood 10 hours agorootparentGrids are pretty much the best solution available because any kind of good/service that can be transported at close to light-speed benefits tremendously from ubiquitous connectivity. Smarter grids are an even better solution; batteries backing local high-variance demand combined with rapidly negotiated requests for transmission power to meet expected future demand (and then stored in the batteries) reduces (electrical) inefficiency to a minimum. reply wongarsu 18 hours agorootparentprevResidential power demands are highest in the morning and in the evening. That's when people shower, cook, and are generally around using power. Solar peaks at noon. Maybe when battery prices come down even more. But the cost of grid-level storage are also falling, and wind pretty much only works at grid scale. Grids have to change but won't become obsolete anytime soon. reply PaulDavisThe1st 15 hours agorootparentThat usage pattern will be quite different in places with cold winters when most people there are using electric-powered heat pumps (which is \"the plan\"). reply xattt 19 hours agoparentprevWhy not both? reply dvh 20 hours agoparentprevI'll take 3kW on my rooftop over 5kW in billionaire's company. reply looofooo0 6 hours agoprevI am sceptical about putting PV on roofs, seems a lot of hassle and waymore expensive then using just flatground: https://en.wikipedia.org/wiki/Bhadla_Solar_Park Any additional money spent on it, could have helped to install more PV or batteries. reply victorbjorklund 4 hours agoparentIn general yes but due to both taxes/regulations and real issues with the grid it is \"easier\" to just consume what your produce vs producing and selling to the grid. And since space is limited on most peoples property if you live an urban setting then roof might be the only place to put it. If you got plenty of space though roof is a worse place than the ground from almost every point of view. reply Delmolokolo 6 hours agoparentprevEvery PV system on a roof means producing and consuming energy directly. In Germany we already have large distance energy transfer problems. And PV is so cheap now + battery, you get independence / real freedom out of the box. If you have valuable space on the ground and want to remove the utilization of it, sure but I prefer it on the roof were it doesn't do that. But yes next to autobahns or other smart locations yes put it on the ground. But when I invest in myself I will not sponsor pv somewhere else reply myroon5 11 hours agoprevRelated: Global Solar Power Potential Map - https://news.ycombinator.com/item?id=40303570 - May 2024 reply buckle8017 19 hours agoprevEstimate for a house in SF with a typical roof and typical electric bill. $20k upfront cost. $4k in savings over 20 years. That's an implied rate of return of 0.9% annually. No thanks. reply ggreer 18 hours agoparentHow are you calculating that? Solar installations are around $2.50-$3.50 per watt, so $20k would get you 6-8kW. Assuming actual output is 10% of capacity, that's 14-19kWh/day or 5,000-7,000kWh per year. Current residential electricity prices in SF are 38.9 cents per kWh[1], so that's $2,000-2,700 per year in savings, or $40-54k over 20 years. The actual amount saved depends on how much electricity you're consuming during peak times, but I doubt that number is off by a factor of 10. 1. https://www.bls.gov/regions/west/news-release/averageenergyp... reply buckle8017 17 hours agorootparentI didn't calculate anything I just put in an address and a monthly electricity bill. https://sunroof.withgoogle.com/ reply Retric 13 hours agorootparentAhh, ok the tool sucks it doesn’t seem to calculate based on your current cost per kWh or the local cost per kWh. It’s ignoring inflation on those calculations, acting like your electric bill will be the same in 20 years. It’s also ignoring residual value in the system after 20 years they typically last 25-30, and you don’t pay taxes on savings. There install estimates where also really high for my area, but I don’t know if that’s a general issue. reply patrickhogan1 12 hours agorootparentYour electric bill 20 years from now is just as likely to go down as it is to go up. In two decades, we could see advancements like mobile generators offering free power, ultra-affordable battery packs delivered to homes to meet energy needs, or even the widespread adoption of low-cost fusion energy. The key takeaway is that predicting the future cost of electricity is as challenging as it was to predict today’s solar energy costs—now far lower than anyone expected. reply Retric 12 hours agorootparentNone of what you just said is even vaguely realistic. Prices can’t drop below zero but they can easily more than double, so even if you assume equal odds in either direction it doesn’t cancel out. Worse, any physical device is going to have a cost to produce it which requires charging people to use it thus they can’t even drop to 0. Beyond that none of their prices or timelines are accurate, even ignoring the issues with inflation. reply r00fus 2 hours agorootparentprevNow you're sounding all pie in the sky. The cold hard reality is that hedge funds and billionaires control most power utilities and lobby governments to keep the cash flowing. We know for certain that pricing is going to get really bad in CA due to a 2022 law that permits PG&E and other utilities to charge large connection fees based on your income (will probably hit in 2026). I would gladly be the counterparty to any wager that 20 years from now electricity is going to be cheaper. reply throwaway2037 10 hours agorootparentprev> mobile generators offering free power Wow, where is this magical place? I want to move there. :) reply bagels 12 hours agorootparentprevWhen did PGE prices ever go down? reply notatoad 13 hours agorootparentprevsunroof was a 2015 project. if they haven't adjusted their cost estimates since they launched it, it could be wildly overestimating things. reply gloflo 5 hours agorootparentSame for panel efficiency https://en.m.wikipedia.org/wiki/Solar-cell_efficiency#/media... reply malfist 16 hours agoparentprevSolar installations have a 30% tax rebate currently. So your $20k would actually be $12k, makes the math a bit better. Plus, are you counting in inflation of electricity prices in those 20 years? I'm sure electricity isn't going to get cheaper reply prdonahue 19 hours agoparentprevWas that paired with a battery? Under NEM3 (and reduced net metering rate), it doesn't make sense to install PV in California without a battery. reply stainablesteel 19 hours agoparentprevi've heard of some business models that install these and have you pay what would be the difference to your electric bill to the company until they pay themselves off, not sure if the panels last long enough to make that work though reply ccozan 19 hours agorootparentYes. In Germany they are selling a lot of models, but none, I mean, really, none asked about the rentability. So I went to a neighbour who just installed his 25kW and was very proud and happy, and asked him, in how many years is the return of investment. Siderated, he could not answer and then a few days later, with a very stern face: 25 years or more because if more people install these, the price that the city is paying for the pumped energy goes down. So no. 20kw is not the answer. I showed my setup: 3.5kw + big battery. Pays the bill approx 60 70% of the daily usage. Investment payback : 5years. reply throwaway2037 10 hours agorootparent25kW? That is crazy huge! How many panels? What does this guys house (mansion!?) look like? Google tells me that average installation size is about 7-8kW. reply ccozan 4 hours agorootparentIs not that big. you have approx 400W ( mine are 440W) on a 2sqm. Hi sroof is like 15 x 8 m. and is not fully covered. You can easily reach 25kw. reply BonoboIO 13 hours agorootparentprevDamn, your neighbor got robbed by the installer … reply scotty79 15 hours agorootparentprevWhat if he added previous generation crypto miner (so it's cheap) and use the excess electricity instead of selling it to the grid? This could also save some money on heating in winter unless he has a heat pump priced in already. reply ccozan 4 hours agorootparentthis guy is a carpenter :). cryto mining would sound like chinese to him... reply PaulDavisThe1st 15 hours agorootparentprevprev gen crypto mining is phenomenally inefficient in terms of energy that ends up being converted to heat, but it is absolutely not what you would use to take electricity and create heat given any other choices. reply scotty79 1 hour agorootparentWhat are other choices? Heat pump is obviously the best but any other thing is just electric heater with 100% efficiently of heat generation. Pushing some bits around doesn't change that. I guess for some applications you might prefer higher temperatures but for residential heating crypto mining is as good as anything else, right? reply buckle8017 19 hours agorootparentprevYes I think in general those are a better deal for the homeowner. They're a terrible deal for those companies investors though. Presumably at some point they go bankrupt and sell your roof at auction??? weird setup reply dzhiurgis 18 hours agorootparentprevOne of these wouldn't sign me up as they couldn't offer any savings (92% of my use is off peak, around 16ct NZD (9 USD) / kWh). A lot of the time such companies pray on people on stupid plans (or those paying thru the nose for \"exclusively renewable\") power. reply nine_k 15 hours agorootparentThis exactly the case when a battery would make an immense difference. (9 USD / kWh sounds terrifying. Not only an electric kettle begins to cost you; probably playing computer games at high quality / resolution comes with a noticeable price tag in electricity that the GPU would eat.) reply bruce511 15 hours agorootparentI think he meant 9 USD cents per kw. (He included ct with NZD but forgot it with USD.) reply throwaway2037 10 hours agorootparentprevWoah, your electricity is so cheap! Is it mostly hydro? reply bokohut 2 hours agoprevI used an early version of the PV roof tool in 2020 for my own PV roof design. The front of my rectangle shaped home faces exactly North and therefore all sides are respective to exactly E/W/S. Given my professional experiences and knowledge awareness of photons I therefore opted to cover my entire roof in PV collecting technology and not just what faces direct sunlight, if one can see outside during daylight hours then the PV is functioning. Case in point, right now it is currently very cloudy and rainy here in the NE,USA and the roof is still generating 700 watts while my home's base load demand of 400 watts has the overage of 300 watts going to batteries. I have had this system for 3 years now and my choice to have such a system proved itself in our first outage when everyone else was panicking in the dark for hours. I sat relaxed and watched others in great stress and anxiety planning on how to preserve their refrig/freezers while visually panicking over their sump pumps not running in their basements. PV with a battery is a quality of life choice that directly impacts one's health and what price do you put on your health? I will also share with such sites that the energy and cost saving estimates are very much often wrong since the energy data is generalized for everyone and energy use per person significantly varies, some estimates are laughable to only me since I have my families own real world data for the last decade. I have also tracked our entire resource consumption at home for nearly a decade now, yes I am a data nerd to the extremes, and not only does such a solution save one GREAT stress and anxiety when it matters most but it also greatly reduces variable financial expenses and can also make one revenue. Proactive versus reactive : The data doesn't lie, people do. Stay Healthy! reply s1artibartfast 2 hours agoparent> sat relaxed and watched others in great stress and anxiety planning on how to preserve their refrig/freezers while visually panicking over their sump pumps not running in their basements. I hope you at least offered to help... reply bokohut 2 hours agorootparentYes, I did mention this in closing: \"can also make one revenue.\" reply s1artibartfast 1 hour agorootparentI was commenting on the sentiment of sitting back and relaxing watching your neighbors struggle. I don't think revenue relates to it reply neves 3 hours agoprevUnfortunately the beta is available just for enterprises. I'd love to run it for my house. reply barbegal 18 hours agoprevAn interesting use for satellite in future will be accurate estimation of solar power output in the very near future e.g. in the next hour period such that grid operators can adjust storage and demand to get a balanced grid. At the moment we can't do these predictions as we don't know where solar panels are in relation to any passing clouds. reply treyd 15 hours agoparentI'm sure you could get that data from public permitting filings. And failing that, train an AI model on scraped Google Maps imagery. I would be surprised if people aren't doing it already. reply mlsu 16 hours agoprevThis is fine and all, but each individual having a solar panel introduces a lot of issues. Your energy bill is about 1/4 or 1/3rd distribution. As you take less power from the grid because of the solar on your roof, that proportion grows larger and larger. At the same time, the power company makes less money off of you, because you are using less power. Therefore, they have less money to invest in distribution, which means they must increase distribution fees further to stay a going concern. This is to say nothing of the ballooning costs of distribution in general (nimbyism, permitting fees, can't build jack shit in this country for no good reason etc.). Therefore: in the hypothetical where everyone has solar rooftops, we all effectively pay the grid operator only for dirty/offpeak power. This makes the grid operators look bad to everyone (they're using dirty power, aren't we trying to fight climate change!? Why is my electricity bill astronomical, even though I only use a tiny bit of power!?) and puts them in an impossible situation -- they're stuck between capped profits, creating expensive clean power at off-peak hours, and limited cash in general, since their expensive power plants are dormant half the time. Yet they still must deliver power to their customers, 24/7. People have to have 24/7 electricity, even though the solar on their house does not cover them 24/7. It's illegal to sell a house that is not connected to the grid in most areas. Therefore, consumers must pay for the option of using electricity in off-peak hours. Everyone will be upset. The grid operator, who is constantly thrashed by politicians who insist on their using clean power, their customers who are enraged at them for the seemingly exorbitant electric bills (which are mostly distribution). The upside is that the grid is more resilient, but as others have mentioned, only if significant investments in local distribution are made (i.e. the ability to very dynamically/granularly pump power back up, from house to grid). Which is a big capital investment that the grid operators will not be able to afford. All this is downstream of the fact that it is hugely inefficient to put a ton of tiny solar panels all over the place, where they cannot be installed, cleaned, maintained, replaced cheaply. It's just way less expensive per watt to put a bunch of solar panels in one spot on cheap land in the desert and pipe it through the existing distribution network. Everyone will pay for that resilience, in their electric bill, one way or another. reply jodrellblank 12 hours agoparent> \"It's just way less expensive per watt to put a bunch of solar panels in one spot on cheap land in the desert and pipe it through the existing distribution network.\" If that were true people wouldn't be buying solar panels for their homes because grid electricity would be \"way less expensive\" and it wouldn't be worth it. Which means either it isn't true, or the grid companies are too busy profiteering and it's not \"putting the grid operators in an impossible position where everyone unfairly hates them\" it's \"grid operators putting themselves into an impossible position where everyone deservedly hates them\". reply mlsu 12 hours agorootparentNo. People put solar panels on their homes, but crucially, they still receive power from the grid when their solar panels are not producing electricity. People who don't have solar panels pay for electricity at 11:00AM. That's lucrative for the grid operator between 11:00-3:00 only -- when the duck curve is low. When demand peaks at 5-6pm, the grid operator pays boatloads of money to import power from elsewhere, burn expensive fossil fuels to service the demand. Crucially, the grid operator is limited on pricing: they cannot \"gouge\" consumers at 5pm -- they must keep prices below a cap. Utility pricing is extremely regulated, it's set essentially by the state. What you're doing when you set up solar panels on your home is actually freeloading. Your electric bill is less than it should be: you take power (at an artificially low rate) when it's super expensive, and don't take it when it's super cheap. This is very very bad business for the grid operator. They're also mandated by law (!) to keep your house hooked up to the grid and run distribution lines all over the place. Just in case you want to plug your car or run your AC at 5pm. Try getting a permit to build a new transmission line anywhere and see whether that's good business. If you have solar panels on your house, you are being subsidized by them -- not the other way round! Timing is everything here. The United states has on the order of minutes of energy storage across the electric grid. reply tsycho 16 hours agoparentprevValid points. Is there a known solution to this, even if it's too expensive today? Would it make sense for local electricity companies to go full solar with large battery backups? Or are batteries too expensive, or don't last long enough, for this to be feasible? What about a wind+solar combination? Both of them are unlikely to go offline at the same time. I see articles that the cost of wind and solar keep going down every year at a rapid rate, and the same for battery tech too. How far are we from where the costs are low enough for cities to have their own reliable grids composed of renewable energy? reply kla-s 9 hours agorootparentThe real solution is the dynamization of electricity prices. This needs some adjusting from your average consumer but not a lot if done right. In Germany there are startups like 1.5C, Enpal etc which will sell you a heat pump, solar, ev charger pack with some \"smarts\", switch you over to a dynamic pricing electricity contract and then claim to optimize the overall cost (i have no direct experience of my own). If you are willing to take a small amount of temperature swing your house is a big thermal battery (even more so if you have a heat pump to water with a big, well insulated reservoir), your ev is a battery with vehicle to grid. With this you can shift your main loads a good amount. Washing machines and dryer as well as cooking/baking might be slightly more problematic/harder to shift, though the car battery should be more than enough for average evening cooking and i have seen washing machines/dryers which can take an external signal as to run when the price is low/there is excess electricity... reply mlsu 13 hours agorootparentprevThe most sensible solution in the short term is to keep the distribution that we have in place and aggressively invest in large solar plants coupled with very large battery systems to ease the duck curve. Individual homeowners can do their part with solar + heat pumps to shift that duck curve. Power rates should see way more wild swings: 0c at the trough around 11am-2pm, $.50 at the 5pm peak. That aligns consumers to make sensible investments, either the energy they use or the energy they produce/store. Smart charging of cars, so that those car batteries can help shift the load? But that requires global coordination that is nonexistent today. Solar is no doubt the energy solution, there's really nothing better. It's low maintenance and lasts a long time, capital scalable, and can be deployed basically anywhere. Solar is far and away the cheapest thing for about 70% of our energy needs. For the last 30% that is very tough to squeeze out -- that baseline power for 24/7 stuff like aluminum smelters, datacenters -- you basically have: high voltage transmission (only available if you have land to your west), big battery banks (tenable, but only if batteries follow solar's dramatic reduction in cost), or nuclear (but requires a big culture change that I cannot really imagine). Or fossil fuels but those are not good obviously. Basically any of the other green stuff (hydro, wind, geothermal) can't be built at any price most places. reply PaulDavisThe1st 15 hours agorootparentprev> Would it make sense for local electricity companies to go full solar with large battery backups? Sure. But opposition to those battery energy storage systems (BESS) is intense and growing. reply scotty79 15 hours agorootparentprevThe solution to that is as much distributed storage as possible and cryptocurrency mining (or LLMs) for monetizing excess energy. reply mlsu 13 hours agorootparentSorry, capex for crypto -- let alone llm (datacenters must be on 100% of the time to pay nvidia) -- is way too high. It must see high utilization for amortization to be favorable. You only see crypto in areas that have really cheap, 24/7 power. Big crypto mining operations are only built near remote hydroelectric power stations, or worse, natural gas or coal rich areas. Places where fossil fuels are made but that don't have easy/cheap access to refineries, rail lines, or pipelines. reply scotty79 1 hour agorootparentYou are probably right about LLM because barely anybody tries to use distributed compute (like folding at home was using). But crypto is running 24/7 because energy price is still positive so people buy latest, most efficient hardware to be as efficient as possible. But latest hardware is expensive. You can buy prev gen mining hardware for peanuts comparatively. It can make you money if you run it when you have more energy than you can use or sell. reply theoreticalmal 15 hours agoparentprevWow, all this goes to show that distributed power storage systems will absolutely destroy contemporary power utility companies reply unit149 19 hours agoprevQuerying overhead nadir satellite imagery - captured at a vertical angle relative to its spatial position - and feeding it into Geo Deepmind's ML program gives us roof-segmentation data. Ostensibly, annual flux prediction imagery in the global south, after being ran in Google's Solar API gives us some enhanced DSM-RGB imagery. reply ben_w 21 hours agoprevNice to see, I hope it helps people get more cheap energy. All I have are nits to pick: > 10.7k TWh globally This brings back memories of the time I almost shortened \"thousand kilometres\" to \"kkm\". Also, and this is not a criticism of Google, the IEA link on that text looks suspiciously like the IEA is still forecasting linear deployment of PV between 2025 and 2035, despite at least a decade of people pointing at it being historically exponential and asking why they don't assume the exponent will continue — I'm expecting about double their number for PV by 2035, if trends continue. reply rcMgD2BwE72F 21 hours agoparent>despite at least a decade of people pointing at it being historically exponential and asking they don't assume the exponent will continue. So crazy and true. Sources: https://www.economist.com/interactive/essay/2024/06/20/solar... https://www.exponentialview.co/p/the-forecasters-gap 7 years ago (!): https://xwpxpfefwalgifkr.quora.com/A-modest-proposal-to-the-... reply PittleyDunkin 19 hours agoparentprev> This brings back memories of the time I almost shortened \"thousand kilometres\" to \"kkm\". For the uninitiated, what's confusing about this? It seems to communicate the intended meaning accurately. Is there some ambiguity here I missed? reply elliottkember 19 hours agorootparentI think it's that a thousand terawatts is equivalent to one petawat. So this is 10.7PWh. reply PittleyDunkin 19 hours agorootparentAh so the complaint is of moving the last order of magnitude onto the quantity rather than the unit. I can't imagine this affects readability that much (although I can understand why you'd want to enforce consistency in an academic context). Sometimes it's useful to distinguish these, though. And after many do have the inexplicable \"MM\" suffix (ie s thousand-thousand) to suffer through which seems much worse. reply Retric 20 hours agoparentprevBoth linear and using the current exponent are likely to be wildly off. If you assume it’s ~26% annual growth now, and drops by 2% per year so 24% next year then in 10 years you’ll see 4.25x last years installs and the cumulative initiation over the next decade is 2.8x a linear estimate. IMO that’s probably a reasonable ballpark, though capacity factors are an open question as they could fall dramatically or maintain fairly steady depending on how much grid storage shows up. reply jjcm 21 hours agoparentprev> 10.7k TWh globally Agree I hate this, but at the same time I don't know if I would have groked it correctly on first read if it had listed \"10.7Pwh globally\". We simply aren't exposed to numbers at that scale on a regular basis. Not sure what the correct solution is here. reply mjan22640 20 hours agorootparentJoules is the solution to both the problems (the second is that Wh for energy is as silly as speed hours for distance) reply sbierwagen 17 hours agorootparent>(the second is that Wh for energy is as silly as speed hours for distance) This would be a devastating own if a single Joule wasn't exactly equal to a Watt-second. reply XorNot 19 hours agorootparentprevWatt-hours is a perfectly pragmatic unit. Measure instantaneous power and multiply by a common human unit of time. It's easy to compare. reply ben_w 6 hours agorootparentPart of me is tempted to suggest kilograms as a unit of energy. 428.6 kg relativistic mass-energy equivalent: https://www.wolframalpha.com/input?i=10.7PWh%2F%28c%5E2%29 But then, I am a silly person. reply psychoslave 20 hours agorootparentprevI was reading https://en.wikipedia.org/wiki/International_System_of_Units and a few related the other day for fun and pleasing moment, and one thing I retained from that is that \"The kilogram is the only coherent SI unit whose name and symbol include a prefix.\" Also that the standard explicitly forbid redundant use of prefixes like kilo-kilo-. I guess that if you want to stick to TWh you can use - 10700 - 10,700 - 10.7×10³ - 1.07×10⁴ - 10.7e3 - 1.07e4 - 29E8₁₆ reply PaulDavisThe1st 15 hours agorootparentprevWe should be. Why? Because reasonable estimates of the amount of extra energy contained within the atmosphere due to anthropogenic effects are in the single digit petawatt range. It's a number everyone should be carrying in their heads. Put a different way: the total annual harvestable solar yield is within an order of magnitude of the energy we've caused to accumulate inside the atmospheric boundary. Think about that, for a second or two. reply Veserv 20 hours agorootparentprevSI prefix words are just kind of silly. We should just use the exponent as a number instead of having a different word for every 3 zeros. 10.7 E15 Wh or something similar. Scales to everything, you do not need to know any mapping, and directly supports mathematical manipulation. We should also do the same for large number words in general. No thousand, million, billion, etc. E3, E6, E9, etc. Now you can count and represent any meaningful number without needing to memorize a dictionary of words and they would precisely match the unit scale “words”. reply rabidrat 1 hour agorootparentI agree! I use ^3 etc for the notation: https://saul.pw/mag reply ant6n 20 hours agorootparentprevYou mean 1.07E16 reply vermilingua 19 hours agorootparentIt's pretty common in some contexts to only use Es for powers of 1000, so 100,000,000 is 100e6 rather than 1e8. reply SAI_Peregrinus 11 minutes agorootparentThat's commonly called engineering notation. reply geepytee 21 hours agorootparentprevThe correct solution is 10.7Pwh. We are often exposed to 'Peta' when dealing with data. https://en.wikipedia.org/wiki/Metric_prefix reply sneak 15 hours agorootparentprevWell, given that the intent is to communicate, using GWh is probably ideal. 10.7 million GWh is probably the easiest to understand and compare, given that GWh is probably the most commonly used unit for this purpose. reply jeffbee 20 hours agorootparentprevEIA Electricity Monthly gives data in certain tables in terms of either million kWh or \"thousand megawatthours\" which isn't even English. Let's just use J. reply akira2501 20 hours agoparentprev> This brings back memories of the time I almost shortened \"thousand kilometres\" to \"kkm\". SI is such a senseless system. Unit prefixes were not a good idea. Did you move the decimal point or just switch to \"Mm?\" reply ben_w 19 hours agorootparentIn that specific case, I chose megameters. reply sneak 15 hours agorootparentAt which point even metric-users who think in km are confused. Certain things are measured in certain units, prefix included. This would be like writing interstellar distances in km instead of light years or parsecs. reply navaed01 16 hours agoprevThis is a very neat exercise but I don’t think it’s going to create change. These models already exist and I’ve never met anyone who said their reason for not investing in solar is because they felt the accuracy of existing models is not good enough. I say this as someone who lives on a part of the world where a large % of the inhabitants could have solar but do not - and I find it sad, frustrating and puzzling. Biggest blockers for solar are (total conjecture) : 1- Inertia - flat out. 2- Long-term ROI is not totally clear - How long till I need to replace, roof damage, ability to hold up in storm. 3- Cost - You need to invest sig $ to see your electric bill decrease meaningfully. Gov subsidies are nowhere near where they should be. I am praying for a major breakthrough in cell efficiency to make it a no brainer. Does anyone have any insight on that? reply throwaway2037 10 hours agoparentThis chart on the progress of PV cell efficiencies always blows me away: https://en.wikipedia.org/wiki/Photovoltaics#/media/File:NREL... reply nick3443 15 hours agoparentprevSeems like qcells are on the road to a ~28% solution with silicon-perovskite tandem cells. When I researched for my own home install, it seems most of the cost is actually install labor, markup, electricians rates for hookup, etc. The plain BOM is close to $1-1.50 per watt for cells plus inverters and mounting hardware, but people still charge $3+ for systems. reply bagels 12 hours agoparentprevI have low confidence in the whole industry. High prices, holes in my roof, and many reports of systems being installed poorly with warranties not being honored. reply achillesheels 16 hours agoparentprevI think it has to do with the assurance of the warranty. The ROI is loooong; solar contractors can go out of business leaving the parts on the roof lacking in the promised energy savings. Who wants to litigate against a bankrupt company? reply tuatoru 15 hours agoparentprevDo you get the depreciated value added on to the house price if you sell? This was always a big problem for solar hot water systems. If the payback period is seven years but the average house turnover is five years, then there is little incentive. Gov subsidies are the government giving the tax money of poor people who cannot afford houses to rich people who have houses. Highly regressive. Your PV system should stand on its own merits without holding out your hand to other taxpayers to fund you. reply srameshc 20 hours agoprevThere was a startup that was doing something similar, can't find it but their entire business was built on providing similar service. reply MaxDPS 20 hours agoparentI applied at a company called WattTime a few years ago. I didn’t get the job but their work involved some of that. It sounded really interesting. https://watttime.org/about-us/climate-trace/ reply ximeng 20 hours agoparentprevhttps://www.transitionzero.org/products/solar-asset-mapper perhaps reply larodi 20 hours agoparentprevhundreds of people do this at the moment worldwide, no surprise someone is productivising it, or many people are. reply hndude 16 hours agoprevrelated: NSRDB (Nat'l Solar Radiation Database) Viewer from the National Renewable Energy Lab - https://nsrdb.nrel.gov/data-viewer reply sanj 18 hours agoprevI had the privilege of working with the heart and soul of this solar rooftop work. Carl is a mensch. He's also the brilliance behind https://blog.google/technology/ai/ai-airlines-contrails-clim... reply bensandcastle 15 hours agoprevmarginally relevant. space based dawn dusk LEO solar infra is the answer. vastly more power than we'll ever get on the surface of this rock and then onto Sol. reply janitorHenry 21 hours agoprevBuilders: optimize energy capture, put roof planes directed south (in northern hemisphere). reply szvsw 20 hours agoparentThere’s not always a lot of freedom to control roof angles like that - it might eg be directly determined by the orientation of the street - and even if there is, it might come into conflict with other thermal considerations. For instance, perhaps orienting the building such that the roof midline is E/W and the surface is due south results in more windows pointed due south, which in turn drives much more solar gain on the interior and greater cooling loads as a result - maybe the increased solar output outweighs those gains, maybe it doesn’t. You have to run some thermal sims to check. On the other hand, you will have more solar gains in the winter, which will decrease your heating demand. So it’s not universally applicable - but it is absolutely true that it will increase solar output! reply PaulDavisThe1st 14 hours agorootparent> more windows pointed due south, which in turn drives much more solar gain on the interior and greater cooling loads as a result C'mon ... people figured this out in 70s ... and centuries before that in various parts of the world. You put a shade above the window the excludes direct summer sun, but allows direct winter sun to enter the window. The angle and extent of the shade depends on where you are in the world. On my old adobe in New Mexico, a roof at about 30 degrees with about an 18\" overhang prevents all direct summer sun from entering our south facing windows, but provides 6-10F of additional ambient temperature during the winter from direct sunlight. reply szvsw 11 hours agorootparentOh I’m totally with you! There is a long and storied history of passive design strategies, and exterior shading is one of the oldest ones out there! But what I stated is plainly true, and many people simply don’t want exterior shades (or just don’t think about it). The point I was trying to make was just that there are thermal implications to the orientation, and you should think those through (using thermal simulations can help detect these issues) and come up with appropriate strategies (thermal simulations can help validate them). Maybe you don’t want shades, but you would be okay with emissivity coatings for your windows. Or maybe you just want to position windows on both sides of the home with continuous air volumes connecting them to promote natural ventilation. Maybe you can take advantage of thermal mass. The list goes on… reply PaulDavisThe1st 3 hours agorootparentI was not describing exterior shading. The terminology is hard. I was describing overhangs that create shade during the summer. reply szvsw 1 hour agorootparentOverhangs are considered exterior shading in the industry/practice/academia. Any obstruction that prevents solar gains by blocking radiation from entering the window falls within the general category of external shading, whether that’s a fancy high tech actuated shading system, a grille, a simple awning, a structural overhang, vertical fins, etc. reply PaulDavisThe1st 11 minutes agorootparentA structural overhand is viewed by homeowners as something utterly different from everything else you've mentioned there. reply edent 19 hours agoparentprevThat isn't quite true. Electricity use is more common in the evening, so west facing panels do really well because they offset demand. We have an East/West split on our panels and they're excellent for providing instantly useful electricity as opposed to stored electricity. reply elric 20 hours agoparentprevThat's terrible advice unless it's tied to local energy storage. When every roof and every solar panel is angled the same way, a sudden cloud (or a sudden lack of clouds) can cause huge fluctuations in power output. Diversity is protective. reply cjbgkagh 20 hours agorootparentUnless there is something I'm missing, the sun still shines from the same direction regardless of the cloud coverage so I'm not sure how having panels pointing in other directions could improve the matter. Perhaps there is a case for optimizing panel area for different times of day but since panels are so relatively cheap it seems the advice is just to get more panels than spend much time worrying about such things. reply jcgrillo 20 hours agorootparentprevAre you signing up to point your panels north and take a 30% efficiency hit? Or east/west for a 15% penalty? People point them south because it's the most efficient fixed orientation north of the equator. A more efficient solution is to use a tracker which keeps them pointing directly at the sun as it traverses the sky. reply elric 20 hours agorootparentNot every roof allows for perfect southward angling (obviously). And I'm obviously not saying that you should point panels north either. I'm disputing the parent commenter's claim that it would be beneficial to have all panels aimed directly due south. Because that way you get one strong peak at noon, which is the time of day when solar energy is most abundant but also least used. reply PaulDavisThe1st 14 hours agorootparentprevThe potential for mechanical failures in trackers makes them quite unpopular now (unlike in the 70s when they first started to appear, and seemed like an obvious win). You're better off just adding however many extra fixed panels you need to make up for the lack of tracking (and its normally not very many). reply lostlogin 18 hours agorootparentprevIt might be that south gives you the most electricity (I’m southern hemisphere so north for me), but if you’re after power for yourself, early am and late PM energy generation is very helpful. A battery helps negate this issue but not entirely. reply toast0 20 hours agorootparentprevPointing west is a reasonable option in California. Pointing west reduces production, but also shifts it later in the day, and addresses some of the duck curve. reply dzhiurgis 18 hours agorootparentprevThis problem has been know for well over a decade... reply jeffbee 21 hours agoprevThe image processing described is very cool, but I have questions about the application. Google started doing these solar potential estimates about 10 years ago, so let's imagine that they have been developing the capability since about 2010 or so. In that time the cost of PV has fallen by an order of magnitude. Hasn't that settled the question of where PV should be installed? I thought the answer is now \"yes\" everywhere. reply josh-sematic 20 hours agoparentEven assuming 100% solar rooftop coverage is the goal, given limited capacity of raw materials, labor, infrastructure would still necessitate prioritization of when to allocate those things to which places. reply jeffbee 20 hours agorootparentBut the audience isn't an omnipotent controller of PV panel allocation, it's emergent market participants. Presumably, the market emerges more plentifully in those sunnier places. It's hard to imagine the place where this data is useful to local construction firms who were previously not well-informed (potentially by just walking around with their eyes open). reply mbreese 20 hours agorootparentMaybe it's useful when trying to justify solar adoption. If you have control over some level of panel allocation, you could use something like this to explore where you'd want to put panels first -- answering the question of where are you going to make the best economic case for solar panels. Then, once the top places are addressed, you can move onto the second tier of locations, then the third, etc... This could be helpful if you're in gov't and have some control over a pilot neighborhood project. Or a developer that wants to include solar on some homes/businesses and wants to know where it makes the most sense. You're right that this probably isn't too much better than qualitative reasoning about how sunny certain places are, but this is quantitative, so you can have a little more confidence in your qualitative assessment. reply josh-sematic 20 hours agorootparentprevThere are several allocation opportunities I could think of. You’re a local government considering some subsidies for rooftop solar initiatives. How much bang for your buck will you get? You’re a regional grid operator and have some estimates for rooftop solar adoption. How do you translate that into plans for future grid capacity needs? You’re a rooftop solar installation company. What neighborhoods do you send your mailers to? reply akira2501 20 hours agorootparentPerhaps those three different groups should just coordinate together, rather than individually using this data, and arriving at three different and possibly interfering conclusions. Aside from that grid operators buy power from producers. They don't plan future capacity more than 72 hours in advance. If you're a producer with expensive power you won't sell much. If you're a producer with cheap power you will sell a lot. It's already a functioning market. Solar is a very small part of it. reply wongarsu 18 hours agoparentprevA lot of new homes are still constructed without solar. Either market participants are sleeping on easy money or the answer isn't a simple \"yes, everywhere\". The cost of panels has fallen a lot, but the cost of mounting hardware and installation is still pretty high in the US. reply jeffbee 17 hours agorootparentThat's exactly my point. This isn't telling you anything about the controlling variables: labor, G&A, taxes. reply 4b11b4 17 hours agoprevThis is where Google much more than - GCP vs AWS - Gemini vs ChatGPT etc reply bangaloredud 20 hours agoprevnext [2 more] [flagged] blacksmith_tb 18 hours agoparentAnd they're worse than belching smokestacks, somehow? Criticisms like calling wind power turbines \"bird shredders\" are either crocodile tears from the Drill Baby Drill conservatives (who curiously never cared much about birds until now - except for shooting them with shotguns, that is) or from Quixotic enviros who can't accept any tradeoffs, no matter how dire our circumstances get. reply HocusLocus 21 hours agoprev [–] \"We lose a little on each transaction, but make up for it in volume.\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Research has extended its Solar API to the Global South, utilizing satellite imagery and machine learning (ML) to evaluate solar potential for buildings, aiming to boost solar adoption in areas with limited tech access.- The Solar API offers detailed rooftop data, aiding businesses in optimizing solar panel layouts and enhancing adoption rates, now covering 125 million new buildings across 23 countries.- The project employs advanced ML models to create high-quality digital surface models and roof segments from satellite images, enhancing global solar assessments."
    ],
    "commentSummary": [
      "Google's Solar API provides a unified method for estimating global solar potential, contrasting with fragmented government LiDAR (Light Detection and Ranging) surveys.",
      "Integrating local utility prices into the Solar API could enhance its utility by estimating potential savings, thereby increasing the appeal of solar projects for homeowners.",
      "The adoption of rooftop solar is complex, influenced by location, costs, grid integration challenges, and regulatory, economic, and technical factors, despite its benefits of resilience and distributed energy."
    ],
    "points": 254,
    "commentCount": 187,
    "retryCount": 0,
    "time": 1734641086
  },
  {
    "id": 42468214,
    "title": "A Gentle Introduction to Graph Neural Networks",
    "originLink": "https://distill.pub/2021/gnn-intro/",
    "originBody": "Distill ABOUT PRIZE SUBMIT A Gentle Introduction to Graph Neural Networks Neural networks have been adapted to leverage the structure and properties of graphs. We explore the components needed for building a graph neural network - and motivate the design choices behind them. Hover over a node in the diagram below to see how it accumulates information from nodes around it through the layers of the network. AUTHORS AFFILIATIONS Benjamin Sanchez-Lengeling Google Research Emily Reif Google Research Adam Pearce Google Research Alexander B. Wiltschko Google Research PUBLISHED Sept. 2, 2021 DOI 10.23915/distill.00033 This article is one of two Distill publications about graph neural networks. Take a look at Understanding Convolutions on Graphs to understand how convolutions over images generalize naturally to convolutions over graphs. Graphs are all around us; real world objects are often defined in terms of their connections to other things. A set of objects, and the connections between them, are naturally expressed as a graph. Researchers have developed neural networks that operate on graph data (called graph neural networks, or GNNs) for over a decade. Recent developments have increased their capabilities and expressive power. We are starting to see practical applications in areas such as antibacterial discovery , physics simulations , fake news detection , traffic prediction and recommendation systems . This article explores and explains modern graph neural networks. We divide this work into four parts. First, we look at what kind of data is most naturally phrased as a graph, and some common examples. Second, we explore what makes graphs different from other types of data, and some of the specialized choices we have to make when using graphs. Third, we build a modern GNN, walking through each of the parts of the model, starting with historic modeling innovations in the field. We move gradually from a bare-bones implementation to a state-of-the-art GNN model. Fourth and finally, we provide a GNN playground where you can play around with a real-word task and dataset to build a stronger intuition of how each component of a GNN model contributes to the predictions it makes. To start, let’s establish what a graph is. A graph represents the relations (edges) between a collection of entities (nodes). Three types of attributes we might find in a graph, hover over to highlight each attribute. Other types of graphs and attributes are explored in the Other types of graphs section. To further describe each node, edge or the entire graph, we can store information in each of these pieces of the graph. Information in the form of scalars or embeddings can be stored at each graph node (left) or edge (right). We can additionally specialize graphs by associating directionality to edges (directed, undirected). The edges can be directed, where an edge $e$ has a source node, $v_{src}$, and a destination node $v_{dst}$. In this case, information flows from $v_{src}$ to $v_{dst}$. They can also be undirected, where there is no notion of source or destination nodes, and information flows both directions. Note that having a single undirected edge is equivalent to having one directed edge from $v_{src}$ to $v_{dst}$, and another directed edge from $v_{dst}$ to $v_{src}$. Graphs are very flexible data structures, and if this seems abstract now, we will make it concrete with examples in the next section. Graphs and where to find them You’re probably already familiar with some types of graph data, such as social networks. However, graphs are an extremely powerful and general representation of data, we will show two types of data that you might not think could be modeled as graphs: images and text. Although counterintuitive, one can learn more about the symmetries and structure of images and text by viewing them as graphs,, and build an intuition that will help understand other less grid-like graph data, which we will discuss later. Images as graphs We typically think of images as rectangular grids with image channels, representing them as arrays (e.g., 244x244x3 floats). Another way to think of images is as graphs with regular structure, where each pixel represents a node and is connected via an edge to adjacent pixels. Each non-border pixel has exactly 8 neighbors, and the information stored at each node is a 3-dimensional vector representing the RGB value of the pixel. A way of visualizing the connectivity of a graph is through its adjacency matrix. We order the nodes, in this case each of 25 pixels in a simple 5x5 image of a smiley face, and fill a matrix of $n_{nodes} \\times n_{nodes}$ with an entry if two nodes share an edge. Note that each of these three representations below are different views of the same piece of data. Click on an image pixel to toggle its value, and see how the graph representation changes. Text as graphs We can digitize text by associating indices to each character, word, or token, and representing text as a sequence of these indices. This creates a simple directed graph, where each character or index is a node and is connected via an edge to the node that follows it. Edit the text above to see how the graph representation changes. Of course, in practice, this is not usually how text and images are encoded: these graph representations are redundant since all images and all text will have very regular structures. For instance, images have a banded structure in their adjacency matrix because all nodes (pixels) are connected in a grid. The adjacency matrix for text is just a diagonal line, because each word only connects to the prior word, and to the next one. This representation (a sequence of character tokens) refers to the way text is often represented in RNNs; other models, such as Transformers, can be considered to view text as a fully connected graph where we learn the relationship between tokens. See more in Graph Attention Networks. Graph-valued data in the wild Graphs are a useful tool to describe data you might already be familiar with. Let’s move on to data which is more heterogeneously structured. In these examples, the number of neighbors to each node is variable (as opposed to the fixed neighborhood size of images and text). This data is hard to phrase in any other way besides a graph. Molecules as graphs. Molecules are the building blocks of matter, and are built of atoms and electrons in 3D space. All particles are interacting, but when a pair of atoms are stuck in a stable distance from each other, we say they share a covalent bond. Different pairs of atoms and bonds have different distances (e.g. single-bonds, double-bonds). It’s a very convenient and common abstraction to describe this 3D object as a graph, where nodes are atoms and edges are covalent bonds. Here are two common molecules, and their associated graphs. (Left) 3d representation of the Citronellal molecule (Center) Adjacency matrix of the bonds in the molecule (Right) Graph representation of the molecule. (Left) 3d representation of the Caffeine molecule (Center) Adjacency matrix of the bonds in the molecule (Right) Graph representation of the molecule. Social networks as graphs. Social networks are tools to study patterns in collective behaviour of people, institutions and organizations. We can build a graph representing groups of people by modelling individuals as nodes, and their relationships as edges. (Left) Image of a scene from the play “Othello”. (Center) Adjacency matrix of the interaction between characters in the play. (Right) Graph representation of these interactions. Unlike image and text data, social networks do not have identical adjacency matrices. (Left) Image of karate tournament. (Center) Adjacency matrix of the interaction between people in a karate club. (Right) Graph representation of these interactions. Citation networks as graphs. Scientists routinely cite other scientists’ work when publishing papers. We can visualize these networks of citations as a graph, where each paper is a node, and each directed edge is a citation between one paper and another. Additionally, we can add information about each paper into each node, such as a word embedding of the abstract. (see , , ). Other examples. In computer vision, we sometimes want to tag objects in visual scenes. We can then build graphs by treating these objects as nodes, and their relationships as edges. Machine learning models, programming code and math equations can also be phrased as graphs, where the variables are nodes, and edges are operations that have these variables as input and output. You might see the term “dataflow graph” used in some of these contexts. The structure of real-world graphs can vary greatly between different types of data — some graphs have many nodes with few connections between them, or vice versa. Graph datasets can vary widely (both within a given dataset, and between datasets) in terms of the number of nodes, edges, and the connectivity of nodes. Summary statistics on graphs found in the real world. Numbers are dependent on featurization decisions. More useful statistics and graphs can be found in KONECT What types of problems have graph structured data? We have described some examples of graphs in the wild, but what tasks do we want to perform on this data? There are three general types of prediction tasks on graphs: graph-level, node-level, and edge-level. In a graph-level task, we predict a single property for a whole graph. For a node-level task, we predict some property for each node in a graph. For an edge-level task, we want to predict the property or presence of edges in a graph. For the three levels of prediction problems described above (graph-level, node-level, and edge-level), we will show that all of the following problems can be solved with a single model class, the GNN. But first, let’s take a tour through the three classes of graph prediction problems in more detail, and provide concrete examples of each. There are other related tasks that are areas of active research. For instance, we might want to generate graphs, or explain predictions on a graph. More topics can be found in the Into the weeds section . Graph-level task In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease. This is analogous to image classification problems with MNIST and CIFAR, where we want to associate a label to an entire image. With text, a similar problem is sentiment analysis where we want to identify the mood or emotion of an entire sentence at once. Node-level task Node-level tasks are concerned with predicting the identity or role of each node within a graph. A classic example of a node-level prediction problem is Zach’s karate club. The dataset is a single social network graph made up of individuals that have sworn allegiance to one of two karate clubs after a political rift. As the story goes, a feud between Mr. Hi (Instructor) and John H (Administrator) creates a schism in the karate club. The nodes represent individual karate practitioners, and the edges represent interactions between these members outside of karate. The prediction problem is to classify whether a given member becomes loyal to either Mr. Hi or John H, after the feud. In this case, distance between a node to either the Instructor or Administrator is highly correlated to this label. On the left we have the initial conditions of the problem, on the right we have a possible solution, where each node has been classified based on the alliance. The dataset can be used in other graph problems like unsupervised learning. Following the image analogy, node-level prediction problems are analogous to image segmentation, where we are trying to label the role of each pixel in an image. With text, a similar task would be predicting the parts-of-speech of each word in a sentence (e.g. noun, verb, adverb, etc). Edge-level task The remaining prediction problem in graphs is edge prediction. One example of edge-level inference is in image scene understanding. Beyond identifying objects in an image, deep learning models can be used to predict the relationship between them. We can phrase this as an edge-level classification: given nodes that represent the objects in the image, we wish to predict which of these nodes share an edge or what the value of that edge is. If we wish to discover connections between entities, we could consider the graph fully connected and based on their predicted value prune edges to arrive at a sparse graph. In (b), above, the original image (a) has been segmented into five entities: each of the fighters, the referee, the audience and the mat. (C) shows the relationships between these entities. On the left we have an initial graph built from the previous visual scene. On the right is a possible edge-labeling of this graph when some connections were pruned based on the model’s output. The challenges of using graphs in machine learning So, how do we go about solving these different graph tasks with neural networks? The first step is to think about how we will represent graphs to be compatible with neural networks. Machine learning models typically take rectangular or grid-like arrays as input. So, it’s not immediately intuitive how to represent them in a format that is compatible with deep learning. Graphs have up to four types of information that we will potentially want to use to make predictions: nodes, edges, global-context and connectivity. The first three are relatively straightforward: for example, with nodes we can form a node feature matrix $N$ by assigning each node an index $i$ and storing the feature for $node_i$ in $N$. While these matrices have a variable number of examples, they can be processed without any special techniques. However, representing a graph’s connectivity is more complicated. Perhaps the most obvious choice would be to use an adjacency matrix, since this is easily tensorisable. However, this representation has a few drawbacks. From the example dataset table, we see the number of nodes in a graph can be on the order of millions, and the number of edges per node can be highly variable. Often, this leads to very sparse adjacency matrices, which are space-inefficient. Another problem is that there are many adjacency matrices that can encode the same connectivity, and there is no guarantee that these different matrices would produce the same result in a deep neural network (that is to say, they are not permutation invariant). Learning permutation invariant operations is an area of recent research. For example, the Othello graph from before can be described equivalently with these two adjacency matrices. It can also be described with every other possible permutation of the nodes. Two adjacency matrices representing the same graph. The example below shows every adjacency matrix that can describe this small graph of 4 nodes. This is already a significant number of adjacency matrices–for larger examples like Othello, the number is untenable. All of these adjacency matrices represent the same graph. Click on an edge to remove it on a “virtual edge” to add it and the matrices will update accordingly. One elegant and memory-efficient way of representing sparse matrices is as adjacency lists. These describe the connectivity of edge $e_k$ between nodes $n_i$ and $n_j$ as a tuple (i,j) in the k-th entry of an adjacency list. Since we expect the number of edges to be much lower than the number of entries for an adjacency matrix ($n_{nodes}^2$), we avoid computation and storage on the disconnected parts of the graph. Another way of stating this is with Big-O notation, it is preferable to have $O(n_{edges})$, rather than $O(n_{nodes}^2)$. To make this notion concrete, we can see how information in different graphs might be represented under this specification: Hover and click on the edges, nodes, and global graph marker to view and change attribute representations. On one side we have a small graph and on the other the information of the graph in a tensor representation. It should be noted that the figure uses scalar values per node/edge/global, but most practical tensor representations have vectors per graph attribute. Instead of a node tensor of size $[n_{nodes}]$ we will be dealing with node tensors of size $[n_{nodes}, node_{dim}]$. Same for the other graph attributes. Graph Neural Networks Now that the graph’s description is in a matrix format that is permutation invariant, we will describe using graph neural networks (GNNs) to solve graph prediction tasks. A GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries (permutation invariances). We’re going to build GNNs using the “message passing neural network” framework proposed by Gilmer et al. using the Graph Nets architecture schematics introduced by Battaglia et al. GNNs adopt a “graph-in, graph-out” architecture meaning that these model types accept a graph as input, with information loaded into its nodes, edges and global-context, and progressively transform these embeddings, without changing the connectivity of the input graph. The simplest GNN With the numerical representation of graphs that we’ve constructed above (with vectors instead of scalars), we are now ready to build a GNN. We will start with the simplest GNN architecture, one where we learn new embeddings for all graph attributes (nodes, edges, global), but where we do not yet use the connectivity of the graph. For simplicity, the previous diagrams used scalars to represent graph attributes; in practice feature vectors, or embeddings, are much more useful. This GNN uses a separate multilayer perceptron (MLP) (or your favorite differentiable model) on each component of a graph; we call this a GNN layer. For each node vector, we apply the MLP and get back a learned node-vector. We do the same for each edge, learning a per-edge embedding, and also for the global-context vector, learning a single embedding for the entire graph. You could also call it a GNN block. Because it contains multiple operations/layers (like a ResNet block). A single layer of a simple GNN. A graph is the input, and each component (V,E,U) gets updated by a MLP to produce a new graph. Each function subscript indicates a separate function for a different graph attribute at the n-th layer of a GNN model. As is common with neural networks modules or layers, we can stack these GNN layers together. Because a GNN does not update the connectivity of the input graph, we can describe the output graph of a GNN with the same adjacency list and the same number of feature vectors as the input graph. But, the output graph has updated embeddings, since the GNN has updated each of the node, edge and global-context representations. GNN Predictions by Pooling Information We have built a simple GNN, but how do we make predictions in any of the tasks we described above? We will consider the case of binary classification, but this framework can easily be extended to the multi-class or regression case. If the task is to make binary predictions on nodes, and the graph already contains node information, the approach is straightforward — for each node embedding, apply a linear classifier. We could imagine a social network, where we wish to anonymize user data (nodes) by not using them, and only using relational data (edges). One instance of such a scenario is the node task we specified in the Node-level task subsection. In the Karate club example, this would be just using the number of meetings between people to determine the alliance to Mr. Hi or John H. However, it is not always so simple. For instance, you might have information in the graph stored in edges, but no information in nodes, but still need to make predictions on nodes. We need a way to collect information from edges and give them to nodes for prediction. We can do this by pooling. Pooling proceeds in two steps: For each item to be pooled, gather each of their embeddings and concatenate them into a matrix. The gathered embeddings are then aggregated, usually via a sum operation. For a more in-depth discussion on aggregation operations go to the Comparing aggregation operations section. We represent the pooling operation by the letter $\\rho$, and denote that we are gathering information from edges to nodes as $p_{E_n \\to V_{n}}$. Hover over a node (black node) to visualize which edges are gathered and aggregated to produce an embedding for that target node. So If we only have edge-level features, and are trying to predict binary node information, we can use pooling to route (or pass) information to where it needs to go. The model looks like this. If we only have node-level features, and are trying to predict binary edge-level information, the model looks like this. One example of such a scenario is the edge task we specified in Edge level task sub section. Nodes can be recognized as image entities, and we are trying to predict if the entities share a relationship (binary edges). If we only have node-level features, and need to predict a binary global property, we need to gather all available node information together and aggregate them. This is similar to Global Average Pooling layers in CNNs. The same can be done for edges. This is a common scenario for predicting molecular properties. For example, we have atomic information, connectivity and we would like to know the toxicity of a molecule (toxic/not toxic), or if it has a particular odor (rose/not rose). In our examples, the classification model $c$ can easily be replaced with any differentiable model, or adapted to multi-class classification using a generalized linear model. An end-to-end prediction task with a GNN model. Now we’ve demonstrated that we can build a simple GNN model, and make binary predictions by routing information between different parts of the graph. This pooling technique will serve as a building block for constructing more sophisticated GNN models. If we have new graph attributes, we just have to define how to pass information from one attribute to another. Note that in this simplest GNN formulation, we’re not using the connectivity of the graph at all inside the GNN layer. Each node is processed independently, as is each edge, as well as the global context. We only use connectivity when pooling information for prediction. Passing messages between parts of the graph We could make more sophisticated predictions by using pooling within the GNN layer, in order to make our learned embeddings aware of graph connectivity. We can do this using message passing, where neighboring nodes or edges exchange information and influence each other’s updated embeddings. Message passing works in three steps: For each node in the graph, gather all the neighboring node embeddings (or messages), which is the $g$ function described above. Aggregate all messages via an aggregate function (like sum). All pooled messages are passed through an update function, usually a learned neural network. You could also 1) gather messages, 3) update them and 2) aggregate them and still have a permutation invariant operation. Just as pooling can be applied to either nodes or edges, message passing can occur between either nodes or edges. These steps are key for leveraging the connectivity of graphs. We will build more elaborate variants of message passing in GNN layers that yield GNN models of increasing expressiveness and power. Hover over a node, to highlight adjacent nodes and visualize the adjacent embedding that would be pooled, updated and stored. This sequence of operations, when applied once, is the simplest type of message-passing GNN layer. This is reminiscent of standard convolution: in essence, message passing and convolution are operations to aggregate and process the information of an element’s neighbors in order to update the element’s value. In graphs, the element is a node, and in images, the element is a pixel. However, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements. By stacking message passing GNN layers together, a node can eventually incorporate information from across the entire graph: after three layers, a node has information about the nodes three steps away from it. We can update our architecture diagram to include this new source of information for nodes: Schematic for a GCN architecture, which updates node representations of a graph by pooling neighboring nodes at a distance of one degree. Learning edge representations Our dataset does not always contain all types of information (node, edge, and global context). When we want to make a prediction on nodes, but our dataset only has edge information, we showed above how to use pooling to route information from edges to nodes, but only at the final prediction step of the model. We can share information between nodes and edges within the GNN layer using message passing. We can incorporate the information from neighboring edges in the same way we used neighboring node information earlier, by first pooling the edge information, transforming it with an update function, and storing it. However, the node and edge information stored in a graph are not necessarily the same size or shape, so it is not immediately clear how to combine them. One way is to learn a linear mapping from the space of edges to the space of nodes, and vice versa. Alternatively, one may concatenate them together before the update function. Architecture schematic for Message Passing layer. The first step “prepares” a message composed of information from an edge and it’s connected nodes and then “passes” the message to the node. Which graph attributes we update and in which order we update them is one design decision when constructing GNNs. We could choose whether to update node embeddings before edge embeddings, or the other way around. This is an open area of research with a variety of solutions– for example we could update in a ‘weave’ fashion where we have four updated representations that get combined into new node and edge representations: node to node (linear), edge to edge (linear), node to edge (edge layer), edge to node (node layer). Some of the different ways we might combine edge and node representation in a GNN layer. Adding global representations There is one flaw with the networks we have described so far: nodes that are far away from each other in the graph may never be able to efficiently transfer information to one another, even if we apply message passing several times. For one node, If we have k-layers, information will propagate at most k-steps away. This can be a problem for situations where the prediction task depends on nodes, or groups of nodes, that are far apart. One solution would be to have all nodes be able to pass information to each other. Unfortunately for large graphs, this quickly becomes computationally expensive (although this approach, called ‘virtual edges’, has been used for small graphs such as molecules). One solution to this problem is by using the global representation of a graph (U) which is sometimes called a master node or context vector. This global context vector is connected to all other nodes and edges in the network, and can act as a bridge between them to pass information, building up a representation for the graph as a whole. This creates a richer and more complex representation of the graph than could have otherwise been learned. Schematic of a Graph Nets architecture leveraging global representations. In this view all graph attributes have learned representations, so we can leverage them during pooling by conditioning the information of our attribute of interest with respect to the rest. For example, for one node we can consider information from neighboring nodes, connected edges and the global information. To condition the new node embedding on all these possible sources of information, we can simply concatenate them. Additionally we may also map them to the same space via a linear map and add them or apply a feature-wise modulation layer, which can be considered a type of featurize-wise attention mechanism. Schematic for conditioning the information of one node based on three other embeddings (adjacent nodes, adjacent edges, global). This step corresponds to the node operations in the Graph Nets Layer. GNN playground We’ve described a wide range of GNN components here, but how do they actually differ in practice? This GNN playground allows you to see how these different components and architectures contribute to a GNN’s ability to learn a real task. Our playground shows a graph-level prediction task with small molecular graphs. We use the the Leffingwell Odor Dataset, which is composed of molecules with associated odor percepts (labels). Predicting the relation of a molecular structure (graph) to its smell is a 100 year-old problem straddling chemistry, physics, neuroscience, and machine learning. To simplify the problem, we consider only a single binary label per molecule, classifying if a molecular graph smells “pungent” or not, as labeled by a professional perfumer. We say a molecule has a “pungent” scent if it has a strong, striking smell. For example, garlic and mustard, which might contain the molecule allyl alcohol have this quality. The molecule piperitone, often used for peppermint-flavored candy, is also described as having a pungent smell. We represent each molecule as a graph, where atoms are nodes containing a one-hot encoding for its atomic identity (Carbon, Nitrogen, Oxygen, Fluorine) and bonds are edges containing a one-hot encoding its bond type (single, double, triple or aromatic). Our general modeling template for this problem will be built up using sequential GNN layers, followed by a linear model with a sigmoid activation for classification. The design space for our GNN has many levers that can customize the model: The number of GNN layers, also called the depth. The dimensionality of each attribute when updated. The update function is a 1-layer MLP with a relu activation function and a layer norm for normalization of activations. The aggregation function used in pooling: max, mean or sum. The graph attributes that get updated, or styles of message passing: nodes, edges and global representation. We control these via boolean toggles (on or off). A baseline model would be a graph-independent GNN (all message-passing off) which aggregates all data at the end into a single global attribute. Toggling on all message-passing functions yields a GraphNets architecture. To better understand how a GNN is learning a task-optimized representation of a graph, we also look at the penultimate layer activations of the GNN. These ‘graph embeddings’ are the outputs of the GNN model right before prediction. Since we are using a generalized linear model for prediction, a linear mapping is enough to allow us to see how we are learning representations around the decision boundary. Since these are high dimensional vectors, we reduce them to 2D via principal component analysis (PCA). A perfect model would visibility separate labeled data, but since we are reducing dimensionality and also have imperfect models, this boundary might be harder to see. Play around with different model architectures to build your intuition. For example, see if you can edit the molecule on the left to make the model prediction increase. Do the same edits have the same effects for different model architectures? This playground is running live on the browser in tfjs. Edit the molecule to see how the prediction changes, or change the model params to load a different model. Select a different molecule in the scatter plot. Some empirical GNN design lessons When exploring the architecture choices above, you might have found some models have better performance than others. Are there some clear GNN design choices that will give us better performance? For example, do deeper GNN models perform better than shallower ones? or is there a clear choice between aggregation functions? The answers are going to depend on the data, , and even different ways of featurizing and constructing graphs can give different answers. With the following interactive figure, we explore the space of GNN architectures and the performance of this task across a few major design choices: Style of message passing, the dimensionality of embeddings, number of layers, and aggregation operation type. Each point in the scatter plot represents a model: the x axis is the number of trainable variables, and the y axis is the performance. Hover over a point to see the GNN architecture parameters. Scatterplot of each model’s performance vs its number of trainable variables. Hover over a point to see the GNN architecture parameters. The first thing to notice is that, surprisingly, a higher number of parameters does correlate with higher performance. GNNs are a very parameter-efficient model type: for even a small number of parameters (3k) we can already find models with high performance. Next, we can look at the distributions of performance aggregated based on the dimensionality of the learned representations for different graph attributes. Aggregate performance of models across varying node, edge, and global dimensions. We can notice that models with higher dimensionality tend to have better mean and lower bound performance but the same trend is not found for the maximum. Some of the top-performing models can be found for smaller dimensions. Since higher dimensionality is going to also involve a higher number of parameters, these observations go in hand with the previous figure. Next we can see the breakdown of performance based on the number of GNN layers. Chart of number of layers vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by the number of layers. Hover over a point to see the GNN architecture parameters. The box plot shows a similar trend, while the mean performance tends to increase with the number of layers, the best performing models do not have three or four layers, but two. Furthermore, the lower bound for performance decreases with four layers. This effect has been observed before, GNN with a higher number of layers will broadcast information at a higher distance and can risk having their node representations ‘diluted’ from many successive iterations . Does our dataset have a preferred aggregation operation? Our following figure breaks down performance in terms of aggregation type. Chart of aggregation type vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by aggregation type. Hover over a point to see the GNN architecture parameters. Overall it appears that sum has a very slight improvement on the mean performance, but max or mean can give equally good models. This is useful to contextualize when looking at the discriminatory/expressive capabilities of aggregation operations . The previous explorations have given mixed messages. We can find mean trends where more complexity gives better performance but we can find clear counterexamples where models with fewer parameters, number of layers, or dimensionality perform better. One trend that is much clearer is about the number of attributes that are passing information to each other. Here we break down performance based on the style of message passing. On both extremes, we consider models that do not communicate between graph entities (“none”) and models that have messaging passed between nodes, edges, and globals. Chart of message passing vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by message passing. Hover over a point to see the GNN architecture parameters Overall we see that the more graph attributes are communicating, the better the performance of the average model. Our task is centered on global representations, so explicitly learning this attribute also tends to improve performance. Our node representations also seem to be more useful than edge representations, which makes sense since more information is loaded in these attributes. There are many directions you could go from here to get better performance. We wish two highlight two general directions, one related to more sophisticated graph algorithms and another towards the graph itself. Up until now, our GNN is based on a neighborhood-based pooling operation. There are some graph concepts that are harder to express in this way, for example a linear graph path (a connected chain of nodes). Designing new mechanisms in which graph information can be extracted, executed and propagated in a GNN is one current research area , , , . One of the frontiers of GNN research is not making new models and architectures, but “how to construct graphs”, to be more precise, imbuing graphs with additional structure or relations that can be leveraged. As we loosely saw, the more graph attributes are communicating the more we tend to have better models. In this particular case, we could consider making molecular graphs more feature rich, by adding additional spatial relationships between nodes, adding edges that are not bonds, or explicit learnable relationships between subgraphs. See more in Other types of graphs. Into the Weeds Next, we have a few sections on a myriad of graph-related topics that are relevant for GNNs. Other types of graphs (multigraphs, hypergraphs, hypernodes, hierarchical graphs) While we only described graphs with vectorized information for each attribute, graph structures are more flexible and can accommodate other types of information. Fortunately, the message passing framework is flexible enough that often adapting GNNs to more complex graph structures is about defining how information is passed and updated by new graph attributes. For example, we can consider multi-edge graphs or multigraphs, where a pair of nodes can share multiple types of edges, this happens when we want to model the interactions between nodes differently based on their type. For example with a social network, we can specify edge types based on the type of relationships (acquaintance, friend, family). A GNN can be adapted by having different types of message passing steps for each edge type. We can also consider nested graphs, where for example a node represents a graph, also called a hypernode graph. Nested graphs are useful for representing hierarchical information. For example, we can consider a network of molecules, where a node represents a molecule and an edge is shared between two molecules if we have a way (reaction) of transforming one to the other . In this case, we can learn on a nested graph by having a GNN that learns representations at the molecule level and another at the reaction network level, and alternate between them during training. Another type of graph is a hypergraph, where an edge can be connected to multiple nodes instead of just two. For a given graph, we can build a hypergraph by identifying communities of nodes and assigning a hyper-edge that is connected to all nodes in a community. Schematic of more complex graphs. On the left we have an example of a multigraph with three edge types, including a directed edge. On the right we have a three-level hierarchical graph, the intermediate level nodes are hypernodes. How to train and design GNNs that have multiple types of graph attributes is a current area of research , . Sampling Graphs and Batching in GNNs A common practice for training neural networks is to update network parameters with gradients calculated on randomized constant size (batch size) subsets of the training data (mini-batches). This practice presents a challenge for graphs due to the variability in the number of nodes and edges adjacent to each other, meaning that we cannot have a constant batch size. The main idea for batching with graphs is to create subgraphs that preserve essential properties of the larger graph. This graph sampling operation is highly dependent on context and involves sub-selecting nodes and edges from a graph. These operations might make sense in some contexts (citation networks) and in others, these might be too strong of an operation (molecules, where a subgraph simply represents a new, smaller molecule). How to sample a graph is an open research question. If we care about preserving structure at a neighborhood level, one way would be to randomly sample a uniform number of nodes, our node-set. Then add neighboring nodes of distance k adjacent to the node-set, including their edges. Each neighborhood can be considered an individual graph and a GNN can be trained on batches of these subgraphs. The loss can be masked to only consider the node-set since all neighboring nodes would have incomplete neighborhoods. A more efficient strategy might be to first randomly sample a single node, expand its neighborhood to distance k, and then pick the other node within the expanded set. These operations can be terminated once a certain amount of nodes, edges, or subgraphs are constructed. If the context allows, we can build constant size neighborhoods by picking an initial node-set and then sub-sampling a constant number of nodes (e.g randomly, or via a random walk or Metropolis algorithm). Four different ways of sampling the same graph. Choice of sampling strategy depends highly on context since they will generate different distributions of graph statistics (# nodes, #edges, etc.). For highly connected graphs, edges can be also subsampled. Sampling a graph is particularly relevant when a graph is large enough that it cannot be fit in memory. Inspiring new architectures and training strategies such as Cluster-GCN and GraphSaint . We expect graph datasets to continue growing in size in the future. Inductive biases When building a model to solve a problem on a specific kind of data, we want to specialize our models to leverage the characteristics of that data. When this is done successfully, we often see better predictive performance, lower training time, fewer parameters and better generalization. When labeling on images, for example, we want to take advantage of the fact that a dog is still a dog whether it is in the top-left or bottom-right corner of an image. Thus, most image models use convolutions, which are translation invariant. For text, the order of the tokens is highly important, so recurrent neural networks process data sequentially. Further, the presence of one token (e.g. the word ‘not’) can affect the meaning of the rest of a sentence, and so we need components that can ‘attend’ to other parts of the text, which transformer models like BERT and GPT-3 can do. These are some examples of inductive biases, where we are identifying symmetries or regularities in the data and adding modelling components that take advantage of these properties. In the case of graphs, we care about how each graph component (edge, node, global) is related to each other so we seek models that have a relational inductive bias. A model should preserve explicit relationships between entities (adjacency matrix) and preserve graph symmetries (permutation invariance). We expect problems where the interaction between entities is important will benefit from a graph structure. Concretely, this means designing transformation on sets: the order of operation on nodes or edges should not matter and the operation should work on a variable number of inputs. Comparing aggregation operations Pooling information from neighboring nodes and edges is a critical step in any reasonably powerful GNN architecture. Because each node has a variable number of neighbors, and because we want a differentiable method of aggregating this information, we want to use a smooth aggregation operation that is invariant to node ordering and the number of nodes provided. Selecting and designing optimal aggregation operations is an open research topic. A desirable property of an aggregation operation is that similar inputs provide similar aggregated outputs, and vice-versa. Some very simple candidate permutation-invariant operations are sum, mean, and max. Summary statistics like variance also work. All of these take a variable number of inputs, and provide an output that is the same, no matter the input ordering. Let’s explore the difference between these operations. No pooling type can always distinguish between graph pairs such as max pooling on the left and sum / mean pooling on the right. There is no operation that is uniformly the best choice. The mean operation can be useful when nodes have a highly-variable number of neighbors or you need a normalized view of the features of a local neighborhood. The max operation can be useful when you want to highlight single salient features in local neighborhoods. Sum provides a balance between these two, by providing a snapshot of the local distribution of features, but because it is not normalized, can also highlight outliers. In practice, sum is commonly used. Designing aggregation operations is an open research problem that intersects with machine learning on sets. New approaches such as Principal Neighborhood aggregation take into account several aggregation operations by concatenating them and adding a scaling function that depends on the degree of connectivity of the entity to aggregate. Meanwhile, domain specific aggregation operations can also be designed. One example lies with the “Tetrahedral Chirality” aggregation operators . GCN as subgraph function approximators Another way to see GCN (and MPNN) of k-layers with a 1-degree neighbor lookup is as a neural network that operates on learned embeddings of subgraphs of size k. When focusing on one node, after k-layers, the updated node representation has a limited viewpoint of all neighbors up to k-distance, essentially a subgraph representation. Same is true for edge representations. So a GCN is collecting all possible subgraphs of size k and learning vector representations from the vantage point of one node or edge. The number of possible subgraphs can grow combinatorially, so enumerating these subgraphs from the beginning vs building them dynamically as in a GCN, might be prohibitive. Edges and the Graph Dual One thing to note is that edge predictions and node predictions, while seemingly different, often reduce to the same problem: an edge prediction task on a graph $G$ can be phrased as a node-level prediction on $G$’s dual. To obtain $G$’s dual, we can convert nodes to edges (and edges to nodes). A graph and its dual contain the same information, just expressed in a different way. Sometimes this property makes solving problems easier in one representation than another, like frequencies in Fourier space. In short, to solve an edge classification problem on $G$, we can think about doing graph convolutions on $G$’s dual (which is the same as learning edge representations on $G$), this idea was developed with Dual-Primal Graph Convolutional Networks. Graph convolutions as matrix multiplications, and matrix multiplications as walks on a graph We’ve talked a lot about graph convolutions and message passing, and of course, this raises the question of how do we implement these operations in practice? For this section, we explore some of the properties of matrix multiplication, message passing, and its connection to traversing a graph. The first point we want to illustrate is that the matrix multiplication of an adjacent matrix $A$ $n_{nodes} \\times n_{nodes}$ with a node feature matrix $X$ of size $n_{nodes} \\times node_{dim}$ implements an simple message passing with a summation aggregation. Let the matrix be $B=AX$, we can observe that any entry $B_{ij}$ can be expressed as $= A_{i,1}X_{1,j}+A_{i,2}X_{2, j}+…+A_{i,n}X_{n, j}=\\sum_{A_{i,k}>0} X_{k,j}$. Because $A_{i,k}$ are binary entries only when a edge exists between $node_i$ and $node_k$, the inner product is essentially “gathering” all node features values of dimension $j$” that share an edge with $node_i$. It should be noted that this message passing is not updating the representation of the node features, just pooling neighboring node features. But this can be easily adapted by passing $X$ through your favorite differentiable transformation (e.g. MLP) before or after the matrix multiply. From this view, we can appreciate the benefit of using adjacency lists. Due to the expected sparsity of $A$ we don’t have to sum all values where $A_{i,j}$ is zero. As long as we have an operation to gather values based on an index, we should be able to just retrieve positive entries. Additionally, this matrix multiply-free approach frees us from using summation as an aggregation operation. We can imagine that applying this operation multiple times allows us to propagate information at greater distances. In this sense, matrix multiplication is a form of traversing over a graph. This relationship is also apparent when we look at powers $A^K$ of the adjacency matrix. If we consider the matrix $A^2$, the term $A^2_{ij}$ counts all walks of length 2 from $node_{i}$ to $node_{j}$ and can be expressed as the inner product $ = A_{i,1}A_{1, j}+A_{i,2}A_{2, j}+…+A_{i,n}A{n,j}$. The intuition is that the first term $a_{i,1}a_{1, j}$ is only positive under two conditions, there is edge that connects $node_i$ to $node_1$ and another edge that connects $node_{1}$ to $node_{j}$. In other words, both edges form a path of length 2 that goes from $node_i$ to $node_j$ passing by $node_1$. Due to the summation, we are counting over all possible intermediate nodes. This intuition carries over when we consider $A^3=A \\matrix A^2$.. and so on to $A^k$. There are deeper connections on how we can view matrices as graphs to explore . Graph Attention Networks Another way of communicating information between graph attributes is via attention. For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes we could also consider using a weighted sum.The challenge then is to associate weights in a permutation invariant fashion. One approach is to consider a scalar scoring function that assigns weights based on pairs of nodes ( $f(node_i, node_j)$). In this case, the scoring function can be interpreted as a function that measures how relevant a neighboring node is in relation to the center node. Weights can be normalized, for example with a softmax function to focus most of the weight on a neighbor most relevant for a node in relation to a task. This concept is the basis of Graph Attention Networks (GAT) and Set Transformers. Permutation invariance is preserved, because scoring works on pairs of nodes. A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism. Additionally for interpretability, the scoring weights can be used as a measure of the importance of an edge in relation to a task. Schematic of attention over one node with respect to it’s adjacent nodes. For each edge an interaction score is computed, normalized and used to weight node embeddings. Additionally, transformers can be viewed as GNNs with an attention mechanism . Under this view, the transformer models several elements (i.g. character tokens) as nodes in a fully connected graph and the attention mechanism is assigning edge embeddings to each node-pair which are used to compute attention weights. The difference lies in the assumed pattern of connectivity between entities, a GNN is assuming a sparse pattern and the Transformer is modelling all connections. Graph explanations and attributions When deploying GNN in the wild we might care about model interpretability for building credibility, debugging or scientific discovery. The graph concepts that we care to explain vary from context to context. For example, with molecules we might care about the presence or absence of particular subgraphs, while in a citation network we might care about the degree of connectedness of an article. Due to the variety of graph concepts, there are many ways to build explanations. GNNExplainer casts this problem as extracting the most relevant subgraph that is important for a task. Attribution techniques assign ranked importance values to parts of a graph that are relevant for a task. Because realistic and challenging graph problems can be generated synthetically, GNNs can serve as a rigorous and repeatable testbed for evaluating attribution techniques . Schematic of some explanability techniques on graphs. Attributions assign ranked values to graph attributes. Rankings can be used as a basis to extract connected subgraphs that might be relevant to a task. Generative modelling Besides learning predictive models on graphs, we might also care about learning a generative model for graphs. With a generative model we can generate new graphs by sampling from a learned distribution or by completing a graph given a starting point. A relevant application is in the design of new drugs, where novel molecular graphs with specific properties are desired as candidates to treat a disease. A key challenge with graph generative models lies in modelling the topology of a graph, which can vary dramatically in size and has $N_{nodes}^2$ terms. One solution lies in modelling the adjacency matrix directly like an image with an autoencoder framework. The prediction of the presence or absence of an edge is treated as a binary classification task. The $N_{nodes}^2$ term can be avoided by only predicting known edges and a subset of the edges that are not present. The graphVAE learns to model positive patterns of connectivity and some patterns of non-connectivity in the adjacency matrix. Another approach is to build a graph sequentially, by starting with a graph and applying discrete actions such as addition or subtraction of nodes and edges iteratively. To avoid estimating a gradient for discrete actions we can use a policy gradient. This has been done via an auto-regressive model, such a RNN, or in a reinforcement learning scenario. Furthermore, sometimes graphs can be modeled as just sequences with grammar elements. Final thoughts Graphs are a powerful and rich structured data type that have strengths and challenges that are very different from those of images and text. In this article, we have outlined some of the milestones that researchers have come up with in building neural network based models that process graphs. We have walked through some of the important design choices that must be made when using these architectures, and hopefully the GNN playground can give an intuition on what the empirical results of these design choices are. The success of GNNs in recent years creates a great opportunity for a wide range of new problems, and we are excited to see what the field will bring. Acknowledgments We are deeply grateful to Andy Coenen, Brian Lee, Chaitanya K. Joshi, Ed Chi, Humza Iqbal, Fernanda Viegas, Jasper Snoek, Jennifer Wei, Martin Wattenberg, Patricia Robinson, Wesley Qian and Yiliu Wang for their helpful feedback and suggestions, and to Michael Terry for his code reviews. Many of our GNN architecture diagrams are based on the Graph Nets diagram . Author Contributions All authors contributed to writing. Adam Pearce and Emily Reif made the interactive diagrams and set up the figure aesthetics. Benjamin Sanchez-Lengeling and Emily Reif made some of the initial image sketches. Alexander B. Wiltschko provided editing and writing guidance. Discussion and Review Review #1 - Chaitanya K. Joshi Review #2 - Patricia Robinson Review #3 - Humza Iqbal References Understanding Convolutions on Graphs Daigavane, A., Ravindran, B. and Aggarwal, G., 2021. Distill. DOI: 10.23915/distill.00032 The Graph Neural Network Model Scarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M. and Monfardini, G., 2009. IEEE Transactions on Neural Networks, Vol 20(1), pp. 61--80. A Deep Learning Approach to Antibiotic Discovery Stokes, J.M., Yang, K., Swanson, K., Jin, W., Cubillos-Ruiz, A., Donghia, N.M., MacNair, C.R., French, S., Carfrae, L.A., Bloom-Ackermann, Z., Tran, V.M., Chiappino-Pepe, A., Badran, A.H., Andrews, I.W., Chory, E.J., Church, G.M., Brown, E.D., Jaakkola, T.S., Barzilay, R. and Collins, J.J., 2020. Cell, Vol 181(2), pp. 475--483. Learning to simulate complex physics with graph networks Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J. and Battaglia, P.W., 2020. Fake News Detection on Social Media using Geometric Deep Learning Monti, F., Frasca, F., Eynard, D., Mannion, D. and Bronstein, M.M., 2019. Traffic prediction with advanced Graph Neural Networks *, O.L. and Perez, L.. Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in {Real-Time} Eksombatchai, C., Jindal, P., Liu, J.Z., Liu, Y., Sharma, R., Sugnet, C., Ulrich, M. and Leskovec, J., 2017. Convolutional Networks on Graphs for Learning Molecular Fingerprints Duvenaud, D., Maclaurin, D., Aguilera-Iparraguirre, J., Gomez-Bombarelli, R., Hirzel, T., Aspuru-Guzik, A. and Adams, R.P., 2015. Distributed Representations of Words and Phrases and their Compositionality Mikolov, T., Sutskever, I., Chen, K., Corrado, G. and Dean, J., 2013. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Devlin, J., Chang, M., Lee, K. and Toutanova, K., 2018. Glove: Global Vectors for Word Representation Pennington, J., Socher, R. and Manning, C., 2014. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Learning to Represent Programs with Graphs Allamanis, M., Brockschmidt, M. and Khademi, M., 2017. Deep Learning for Symbolic Mathematics Lample, G. and Charton, F., 2019. KONECT Kunegis, J., 2013. Proceedings of the 22nd International Conference on World Wide Web - WWW '13 Companion. An Information Flow Model for Conflict and Fission in Small Groups Zachary, W.W., 1977. J. Anthropol. Res., Vol 33(4), pp. 452--473. The University of Chicago Press. Learning Latent Permutations with Gumbel-Sinkhorn Networks Mena, G., Belanger, D., Linderman, S. and Snoek, J., 2018. Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs Murphy, R.L., Srinivasan, B., Rao, V. and Ribeiro, B., 2018. Neural Message Passing for Quantum Chemistry Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O. and Dahl, G.E., 2017. Proceedings of the 34th International Conference on Machine Learning, Vol 70, pp. 1263--1272. PMLR. Relational inductive biases, deep learning, and graph networks Battaglia, P.W., Hamrick, J.B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., Gulcehre, C., Song, F., Ballard, A., Gilmer, J., Dahl, G., Vaswani, A., Allen, K., Nash, C., Langston, V., Dyer, C., Heess, N., Wierstra, D., Kohli, P., Botvinick, M., Vinyals, O., Li, Y. and Pascanu, R., 2018. Deep Sets Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. and Smola, A., 2017. Molecular graph convolutions: moving beyond fingerprints Kearnes, S., McCloskey, K., Berndl, M., Pande, V. and Riley, P., 2016. J. Comput. Aided Mol. Des., Vol 30(8), pp. 595--608. Feature-wise transformations Dumoulin, V., Perez, E., Schucher, N., Strub, F., Vries, H.d., Courville, A. and Bengio, Y., 2018. Distill, Vol 3(7), pp. e11. Leffingwell Odor Dataset Sanchez-Lengeling, B., Wei, J.N., Lee, B.K., Gerkin, R.C., Aspuru-Guzik, A. and Wiltschko, A.B., 2020. Machine Learning for Scent: Learning Generalizable Perceptual Representations of Small Molecules Sanchez-Lengeling, B., Wei, J.N., Lee, B.K., Gerkin, R.C., Aspuru-Guzik, A. and Wiltschko, A.B., 2019. Benchmarking Graph Neural Networks Dwivedi, V.P., Joshi, C.K., Laurent, T., Bengio, Y. and Bresson, X., 2020. Design Space for Graph Neural Networks You, J., Ying, R. and Leskovec, J., 2020. Principal Neighbourhood Aggregation for Graph Nets Corso, G., Cavalleri, L., Beaini, D., Lio, P. and Velickovic, P., 2020. Graph Traversal with Tensor Functionals: A Meta-Algorithm for Scalable Learning Markowitz, E., Balasubramanian, K., Mirtaheri, M., Abu-El-Haija, S., Perozzi, B., Ver Steeg, G. and Galstyan, A., 2021. Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels Du, S.S., Hou, K., Poczos, B., Salakhutdinov, R., Wang, R. and Xu, K., 2019. Representation Learning on Graphs with Jumping Knowledge Networks Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K. and Jegelka, S., 2018. Neural Execution of Graph Algorithms Velickovic, P., Ying, R., Padovano, M., Hadsell, R. and Blundell, C., 2019. Graph Theory Harary, F., 1969. A nested-graph model for the representation and manipulation of complex objects Poulovassilis, A. and Levene, M., 1994. ACM Transactions on Information Systems, Vol 12(1), pp. 35--68. Modeling polypharmacy side effects with graph convolutional networks Zitnik, M., Agrawal, M. and Leskovec, J., 2018. Bioinformatics, Vol 34(13), pp. i457--i466. Machine learning in chemical reaction space Stocker, S., Csanyi, G., Reuter, K. and Margraf, J.T., 2020. Nat. Commun., Vol 11(1), pp. 5505. Graphs and Hypergraphs Berge, C., 1976. Elsevier. HyperGCN: A New Method of Training Graph Convolutional Networks on Hypergraphs Yadati, N., Nimishakavi, M., Yadav, P., Nitin, V., Louis, A. and Talukdar, P., 2018. Hierarchical Message-Passing Graph Neural Networks Zhong, Z., Li, C. and Pang, J., 2020. Little Ball of Fur Rozemberczki, B., Kiss, O. and Sarkar, R., 2020. Proceedings of the 29th ACM International Conference on Information & Knowledge Management. Sampling from large graphs Leskovec, J. and Faloutsos, C., 2006. Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '06. Metropolis Algorithms for Representative Subgraph Sampling Hubler, C., Kriegel, H., Borgwardt, K. and Ghahramani, Z., 2008. 2008 Eighth IEEE International Conference on Data Mining. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks Chiang, W., Liu, X., Si, S., Li, Y., Bengio, S. and Hsieh, C., 2019. GraphSAINT: Graph Sampling Based Inductive Learning Method Zeng, H., Zhou, H., Srivastava, A., Kannan, R. and Prasanna, V., 2019. How Powerful are Graph Neural Networks? Xu, K., Hu, W., Leskovec, J. and Jegelka, S., 2018. Rep the Set: Neural Networks for Learning Set Representations Skianis, K., Nikolentzos, G., Limnios, S. and Vazirgiannis, M., 2019. Message Passing Networks for Molecules with Tetrahedral Chirality Pattanaik, L., Ganea, O., Coley, I., Jensen, K.F., Green, W.H. and Coley, C.W., 2020. N-Gram Graph: Simple Unsupervised Representation for Graphs, with Applications to Molecules Liu, S., Demirel, M.F. and Liang, Y., 2018. Dual-Primal Graph Convolutional Networks Monti, F., Shchur, O., Bojchevski, A., Litany, O., Gunnemann, S. and Bronstein, M.M., 2018. Viewing matrices & probability as graphs Bradley, T.. Graphs and Matrices Bapat, R.B., 2014. Springer. Modern Graph Theory Bollobas, B., 2013. Springer Science & Business Media. Attention Is All You Need Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L. and Polosukhin, I., 2017. Graph Attention Networks Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P. and Bengio, Y., 2017. Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks Lee, J., Lee, Y., Kim, J., Kosiorek, A.R., Choi, S. and Teh, Y.W., 2018. Transformers are Graph Neural Networks Joshi, C., 2020. NTU Graph Deep Learning Lab. Using Attribution to Decode Dataset Bias in Neural Network Models for Chemistry McCloskey, K., Taly, A., Monti, F., Brenner, M.P. and Colwell, L., 2018. GNNExplainer: Generating Explanations for Graph Neural Networks Ying, Z., Bourgeois, D., You, J., Zitnik, M. and Leskovec, J., 2019. Advances in Neural Information Processing Systems, Vol 32, pp. 9244--9255. Curran Associates, Inc. Explainability Methods for Graph Convolutional Neural Networks Pope, P.E., Kolouri, S., Rostami, M., Martin, C.E. and Hoffmann, H., 2019. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Evaluating Attribution for Graph Neural Networks [HTML] Sanchez-Lengeling, B., Wei, J., Lee, B., Reif, E., Qian, W., Wang, Y., McCloskey, K.J., Colwell, L. and Wiltschko, A.B., 2020. Advances in Neural Information Processing Systems 33. Variational Graph Auto-Encoders Kipf, T.N. and Welling, M., 2016. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models You, J., Ying, R., Ren, X., Hamilton, W.L. and Leskovec, J., 2018. Optimization of Molecules via Deep Reinforcement Learning Zhou, Z., Kearnes, S., Li, L., Zare, R.N. and Riley, P., 2019. Sci. Rep., Vol 9(1), pp. 1--10. Nature Publishing Group. Self-Referencing Embedded Strings (SELFIES): A 100% robust molecular string representation Krenn, M., Hase, F., Nigam, A., Friederich, P. and Aspuru-Guzik, A., 2019. GraphGen: A Scalable Approach to Domain-agnostic Labeled Graph Generation Goyal, N., Jain, H.V. and Ranu, S., 2020. Updates and Corrections If you see mistakes or want to suggest changes, please create an issue on GitHub. Reuse Diagrams and text are licensed under Creative Commons Attribution CC-BY 4.0 with the source available on GitHub, unless noted otherwise. The figures that have been reused from other sources don’t fall under this license and can be recognized by a note in their caption: “Figure from …”. Citation For attribution in academic contexts, please cite this work as Sanchez-Lengeling, et al., \"A Gentle Introduction to Graph Neural Networks\", Distill, 2021. BibTeX citation @article{sanchez-lengeling2021a, author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.}, title = {A Gentle Introduction to Graph Neural Networks}, journal = {Distill}, year = {2021}, note = {https://distill.pub/2021/gnn-intro}, doi = {10.23915/distill.00033} } Distill is dedicated to clear explanations of machine learning About Submit Prize Archive RSS GitHub Twitter ISSN 2476-0757",
    "commentLink": "https://news.ycombinator.com/item?id=42468214",
    "commentBody": "A Gentle Introduction to Graph Neural Networks (distill.pub)246 points by misonic 14 hours agohidepastfavorite27 comments openrisk 6 hours agoVery high quality work, its a pity that distill.pub did not find a sustainable way forward [1]. On GNN's, the lack of datasets [2] might be a reason they are not as talked about. This is something that has affected also the semantic web domain. [1] https://distill.pub/2021/distill-hiatus/ [2] https://huggingface.co/datasets?task_categories=task_categor... reply siver_john 3 hours agoparentHonestly, seeing this on the front page had my hopes up they had found out a way forward but alas. reply cherryteastain 8 hours agoprevThere are a lot of papers using GNNs for physics simulations (e.g. computational fluid dynamics) because the unstructured meshes used to discretize the problem domain for such applications map very neatly to a graph structure. In practice, every such mesh/graph is used once to solve a particular problem. Hence it makes little sense to train a GNN for a specific graph. However, that's exactly what most papers did because no one found a way to make a GNN that can adjust well to a different mesh/graph and different simulation parameters. I wonder if there's a breakthrough waiting just around the corner to make such a generalization possible. reply magicalhippo 7 hours agoparentNaive question: Words in sentences kinda forms graphs, referencing other words or are leafs being referenced, both inside sentences and between sentences. Given the success of the attention mechanism in modern LLMs, how well would they do if you trained a LLM to process an actual graph? I guess you'd need some alternate tokenizer for optimal performance. reply cherryteastain 7 hours agorootparentFor physics sims, I'd say it's useless. Imagine you discretize a cube into 1000 gridpoints in each direction, that's 1000^3 = 1 billion nodes/\"tokens\". Plus you typically time-march some sort of equation so you need the solutions previous 3-5 timesteps as well so that's 3-5 billion tokens. If you are gonna do that in the first place, you may as well just use the traditional solver. Traditional solvers usually set up and solve a matrix equation like Ax=b with an iterative method like multigrid which is O(n) as opposed to transformer's O(n^2). It'll give you a much more accurate answer much quicker than it'll take a transformer to do attention on a sequence of length 3 billion. The entire point of using GNNs/CNNs in this field is that people rely on their ability to make inference using local information. That means the value at each gridpoint/node can be inferred from neighbouring nodes only, which is O(n) like multigrid. Idea in most papers is that the GNN can do this faster than multigrid. Results so far are mixed, however [1]. [1] https://arxiv.org/abs/2407.07218 reply magicalhippo 6 hours agorootparentAh yes, for dense problems like that I wouldn't expect it to work well. The example graphs in the submission were mostly quite sparse, hence why I thought of LLMs. But perhaps that was just for illustrative purposes. reply disattention 5 hours agorootparentprevThis is actually a good insight. It turns out that transformers are indeed a form of graph network, precisely because of the attention mechanism. Graph attention networks are actually a very popular GNN architecture. Generally, the issue with using an LLM style architecture for generic graphs is modeling the sparsity, but is possible by using the graph adjacency matrix to mask the attention matrix. There are a number of papers and articles which address this connection, and plenty of research into mechanisms for sparsifying attention in transformers. There are also graph tokenizers for using more standard transformers on graphs for doing things like classification, generation, and community detection. reply algo_trader 4 hours agorootparentAny canonical papers on GNN for code graphs? reply whimsicalism 1 hour agorootparentprevyep you're now pretty much at state-of-the-art reply zmgsabst 6 hours agoparentprevA general graph solver has to be a general intelligence, since it would be able to successfully model category theory. reply samsartor 12 hours agoprevGNNs have been a bit of a disappointment to me. I've tried to apply them a couple times to my research but it has never worked out. For a long time GNNs were pitched as a generalization of CNNs. But CNNs are more powerful because the \"adjacency weights\" (so to speak) are more meaningful: they learn relative positional relationships. GNNs usually resort to pooling, like described here. And you can output an image with a CNN. Good luck getting a GNN to output a graph. Topology still has to be decided up front, sometimes even during training. And the nail in the coffin is performance. It is incredible how slow GNNs are compared to CNNs. These days I feel like attention has kinda eclipsed GNNs for a lot of those reasons. You can make GNNs that use attention instead of pooling, but there isn't much point. The graph is usually only traversed in order to create the mask matrix (ie attend between nth neighbors) and otherwise you are using a regular old transformer. Often you don't even need the graph adjacencies because some kind of distance metric is already available. I'm sure GNNs are extremely useful to someone somewhere but my experience has been a hammer looking for a nail. reply igorkraw 10 hours agoparentGNNs are useful at least in one case, when your data a set of atoms that define your datum through their interactions, specifically a set that is that is high cardinality (so you can't YOLO it with attention) with some notion of neighbourhood (i.e. geometry) within your set (defined by the interactions) which if maintained makes the data permutation equivariant, BUT you can't find a meaningful way to represent that geometry implicitly (for example because it changes between samples) => you YOLO it by just passing the neighourhood/interaction structure in as an input. In almost every other case, you can exploit additional structure to be more efficient (can you define an order? sequence model. is it euclidean/riemanian? CNN or manifold aware models. no need to have global state? pointcloud networks. you have an explicit hierarchy? Unet version of your underlying modality. etc) The reason why I find GNNs cool is that 1) they encode the very notion of _relations_ and 2) they have a very nice relationship to completely general discretized differential equations, which as a complex systems/dynamical systems guy is cool (but if you can specialize, there's again easier ways) reply energy123 10 hours agoparentprevGoogle's GraphCast is a GNN: https://deepmind.google/discover/blog/graphcast-ai-model-for... reply eperfa 3 hours agorootparentGoogle DeepMind's GenCast is based on diffusion: https://deepmind.google/discover/blog/gencast-predicts-weath... (Partially) Google Research's/DeepMind's NeuralGCM is based on hybrid models using ODEs and learnt physics: https://www.nature.com/articles/s41586-024-07744-y Microsoft Research's Aurora on vision transformers: https://www.microsoft.com/en-us/research/blog/introducing-au... Huawei's Pangu Weather is also a 3D transformer I believe https://www.nature.com/articles/s41586-024-07744-y I just wanted to highlight that there are multiple approaches in use for the same problem / in the same domain, and GNN does not seem to be the most widely used one. reply lmeyerov 12 hours agoparentprevAre you doing some regular like vision? For the reasons you're saying, I don't think it's an accident that GNNs are popular mostly in domains like recommendations that feel graph-y for their domain model so getting to a useful topology isn't as big a leap. A frustration for me has been more that many of these graph-y domains are about behavioral machine/people data like logs that contain a large amount of categorical dimensions. The graph part can help, but it is just as import to key on the categorical dimensions, and doing well there often end up outside of the model - random forest etc. It's easier to start with those, and then is a lot of work for the GNN part (though we & others have been trying to simplify) for \"a bit more lift\". Of course, if this is your core business and this means many millions of dollars, it can be justified... but still, it's hard for most production teams. In practice, we often just do something with pygraphistry users like xgboost + umap and move on. Even getting an RGCN to perform well takes work.. reply stephantul 12 hours agoparentprevSame! I’ve seen many proposals to use a GNN for some problem for which we used a “flat” model, e.g., taking into account HTML structure when predicting labels for pages. Even when it seemingly made a lot of sense to use them, it didn’t work. reply biomcgary 2 hours agoparentprevI've followed GNNs in biology and applied them in a couple domains, but have been disappointed by the results so far. I'm a bit surprised because I have successfully used other graph-based approaches in biology. reply eachro 14 minutes agoprevIs there consensus about whether gnn architectures are better than transformer based ones at this point? I am aware that transformers can be viewed as a gnn too. reply Legend2440 6 minutes agoparentGNNs let you build some of the structure of your problem into the network architecture. This can be useful if your problem has a well-understood structure, like physical simulations. However in many cases we do not know the structure of our problem (that's why we want to use ML in the first place) and in these cases GNNs do not beat transformers. reply ziofill 1 hour agoprevIt's very sad distill.pub doesn't accept new submissions... :/ reply helltone 11 hours agoprevIt seems GNNs operate on a fixed topology. What if I want to approximate some transformation of the topology of the graph? For example learning how to layout a graph, or converting program abstract syntax trees to data flow graphs. reply igorkraw 10 hours agoparentThe whole point of GNNs is that they generalize to arbitrary topologies by explicitly conditioning the idea of \"neighbours\" on the graph specifying the topology. Graph layout has been tried here https://github.com/limbo018/DREAMPlace to great fanfare although there is recent drama about it https://www.semanticscholar.org/paper/The-False-Dawn%3A-Reev... . Graph transformations are a thing as well https://arxiv.org/abs/2012.01470 but it's a tricky problem because you implicitly need to solve the graph matching problem reply Xmd5a 9 hours agorootparentGraph layout is extremely interesting for infographics, since a handmade graph will almost always beat what tools such as graphviz can come up with (and I'm not even mentioning algorithms that go beyond Sugiyama's for which there is only a paper). Any progress on this front ? reply FjordWarden 2 hours agoparentprevMaybe homology can help, it is a sort of calculus for discrete structures where you count how many N dimensional hole there are over time. Dunno about NN but that is what they can do with fMRI. reply memhole 4 hours agoprevWould love to see distill come back reply esafak 5 hours agoprev(2021) reply leah_sun 9 hours agoprev [–] good share reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Graph Neural Networks (GNNs) are specialized for graph-structured data, utilizing node and edge relationships, and are applicable in fields like antibacterial discovery and traffic prediction.",
      "The article offers a detailed introduction to GNNs, covering components, design choices, and applications, and includes sections on understanding graph data, building GNNs, and experimenting with them.",
      "Key topics include message passing, pooling, global representations, graph sampling, inductive biases, and graph attention networks, providing insights into effective GNN architecture design."
    ],
    "commentSummary": [
      "Graph Neural Networks (GNNs) face challenges such as a lack of datasets and struggle with generalization across different meshes and parameters, limiting their widespread discussion and application.- While transformers, which are a type of graph network, have gained popularity due to their efficient attention mechanism, GNNs are slower and less efficient compared to Convolutional Neural Networks (CNNs).- Despite their potential in specific cases like modeling interactions in high cardinality datasets, GNNs have been underwhelming in some applications, with transformers often outperforming them."
    ],
    "points": 246,
    "commentCount": 27,
    "retryCount": 0,
    "time": 1734667842
  },
  {
    "id": 42467375,
    "title": "Doctors Without Borders declares the war in Gaza as genocide",
    "originLink": "https://www.doctorswithoutborders.org/latest/gaza-death-trap-msf-report-exposes-israels-campaign-total-destruction",
    "originBody": "Related Palestine Access to medicines Malnutrition Vaccination View more Related Palestine Access to medicines Malnutrition Vaccination View more Repeated Israeli military attacks on Palestinian civilians over the last 14 months, the dismantling of the health care system and other essential infrastructure, the suffocating siege, and the systematic denial of humanitarian assistance are destroying the conditions of life in Gaza, according to a new Doctors Without Borders/Médecins Sans Frontières (MSF) report, \"Gaza: Life in a Death Trap.\" The international medical humanitarian organization is urgently calling on all parties, once again, for an immediate ceasefire to save lives and enable the flow of humanitarian aid. Israel must stop its targeted and indiscriminate attacks against civilians, and its allies must act without delay to protect the lives of Palestinians and uphold the rules of war. \"People in Gaza are struggling to survive apocalyptic conditions, but nowhere is safe, no one is spared, and there is no exit from this shattered enclave,\" said Christopher Lockyear, MSF secretary general, who visited Gaza earlier this year. The recent military offensive in the north is a stark illustration of the brutal war the Israeli forces are waging on Gaza, and we are seeing clear signs of ethnic cleansing as Palestinians are forcibly displaced, trapped, and bombed.” Gaza: Life in a Death Trap Bearing witness to 14 months of repeated attacks on civilians, the dismantling of essential civilian infrastructure including health care facilities, and a systematic denial of humanitarian assistance in Gaza. Read the report Bearing witness in Gaza \"What our medical teams have witnessed on the ground throughout this conflict is consistent with the descriptions provided by an increasing number of legal experts and organizations concluding that genocide is taking place in Gaza,” Lockyear said. “While we don't have legal authority to establish intentionality, the signs of ethnic cleansing and the ongoing devastation—including mass killings, severe physical and mental health injuries, forced displacement, and impossible conditions of life for Palestinians under siege and bombardment—are undeniable.\" In response to the horrific attacks carried out by Hamas and other armed groups in Israel on October 7, 2023—in which 1,200 people were killed and 251 people were taken hostage—Israeli forces are crushing the entire population of Gaza. Israel's all-out war on Gaza has reportedly killed more than 45,000 people, according to the Ministry of Health, including eight MSF colleagues. The number of excess deaths related to the war is likely much higher due to the impacts of a collapsed health care system, disease outbreaks, and severely limited access to food, water, and shelter. The United Nations estimated earlier this year that more than 10,000 bodies remained buried under the rubble. What our medical teams have witnessed on the ground throughout this conflict is consistent with the descriptions provided by an increasing number of legal experts and organizations concluding that genocide is taking place in Gaza. Christopher Lockyear, MSF secretary general Israeli forces have on numerous occasions prevented essential items such as food, water, and medical supplies from entering the Strip, as well as blocked, denied, and delayed humanitarian assistance, as documented in the report. Some 1.9 million people—90 percent of the entire population of the Strip—have been forcibly displaced, many forced to move multiple times. Destruction inside Nasser Hospital in Gaza on March 13.Palestine 2024 © MSF A decimated health care system Fewer than half of Gaza's 36 hospitals are even partially functional, and the health care system lies in ruins. During the one-year period covered by the report—from October 2023 to October 2024—MSF staff alone have endured 41 attacks and violent incidents, including airstrikes, shelling, and violent incursions in health facilities; direct fire on the organization’s shelters and convoys; and arbitrary detention of colleagues by Israeli forces. MSF medical personnel and patients have been forced to evacuate hospitals and health facilities on 17 separate occasions, often literally running for their lives. Warring parties have conducted hostilities near medical facilities, endangering patients, caretakers, and medical staff. Meanwhile, Palestinians' physical and mental health injuries are overwhelming, and the needs continue to grow. MSF-supported facilities have carried out at least 27,500 consultations for violence-related injuries and 7,500 surgical interventions. People are suffering from war wounds as well as chronic diseases, made worse when they cannot access essential health care services and medicines. Yasmin (right) lights a fire using plastic to prepare a meal for her children on November 7. Fuel is among other vital supplies that have been blocked or impeded from entering Gaza in sufficient quantities.Palestine 2024 © Ibrahim Nofal Unbearable conditions of displacement Israel’s forced displacement has pushed people into unbearable and unhygienic living conditions in which diseases can spread rapidly. As a result, MSF teams are treating high numbers of people for illnesses like skin diseases, respiratory infections, and diarrhea—all of which are expected to increase as winter temperatures drop. Children are missing out on crucial immunizations, leaving them vulnerable to diseases like measles and polio. MSF has observed an increase in the number of malnutrition cases; however, it is impossible to carry out a full malnutrition screening in Gaza due to widespread insecurity and the lack of proper deconfliction measures. A young girl suffering from severe malnutrition who was admitted to MSF's intensive therapeutic feeding center for urgent care. The health of children in Gaza has been severely impacted by the lack of food, medical care, and basic necessities available.Palestine 2024 © MSF Medical evacuations denied As medical care options dwindle in Gaza, Israel has made it even more difficult for people to be medically evacuated. Between the closure of the Rafah crossing in early May 2024 and September 2024, Israeli authorities have only authorized the evacuations of 229 patients—which amounts to 1.6 percent of those who needed it at that time. This is a drop in the ocean of needs. Victims are placed in body bags in northern Gaza on October 20.Palestine 2024 © MSF The siege of northern Gaza The situation in northern Gaza is especially dire following Israel's recent scorched earth military offensive that has depopulated large areas and reportedly killed almost 2,000 people. The northern part of the Strip, particularly Jabalia camp, has been besieged again by Israeli forces since October 6, 2024. Israeli authorities have dramatically reduced the quantity of essential aid authorized to enter the north. In October 2024, the amount of supplies reaching the whole Gaza Strip hit its lowest point since the war escalated in October 2023: a daily average of 37 humanitarian trucks entered in October 2024, well below the 500 humanitarian trucks entering Gaza each day before October 7, 2023. Palestinians have been killed in their homes and in hospital beds. They have been forcibly displaced time and time again to areas that are not safe or healthy. People cannot find even the most basic necessities like food, clean water, medicines, and soap. Christopher Lockyear, MSF secretary general “For more than a year, our medical staff in Gaza have witnessed a relentless campaign by the Israeli forces marked by massive destruction, devastation, and dehumanization,” said Lockyear. “Palestinians have been killed in their homes and in hospital beds. They have been forcibly displaced time and time again to areas that are not safe or healthy. People cannot find even the most basic necessities like food, clean water, medicines, and soap amid a punishing siege and blockade.\" A mass grave unearthed at Nasser Hospital in April 2024 (before the Nuseirat attacks).Palestine 2024 © Ben Milpas/MSF States must take urgent action MSF calls on states, particularly Israel’s closest allies, to end their unconditional support for Israel and fulfill their obligation to prevent genocide in Gaza. Nearly a year ago, on January 26, the International Court of Justice (ICJ) ordered Israel to take “immediate and effective measures to enable the provision of urgently needed basic services and humanitarian assistance to address the adverse conditions of life faced by Palestinians in the Gaza Strip.” Israel has taken no meaningful action to comply with the court order. Instead, Israeli authorities continue to actively block MSF and other humanitarian organizations from providing lifesaving assistance to people trapped under siege and bombardment. Lockyear breaks down MSF's report States must leverage their influence to alleviate the suffering of the population and enable a massive scale-up of humanitarian assistance across the Gaza Strip. As the occupying power, Israeli authorities are responsible for ensuring the rapid, unimpeded, and safe delivery of humanitarian aid at the level sufficient to address people’s needs. Instead, Israel's blockade and continued obstruction of aid have made it close to impossible for people in Gaza to access essential goods, including fuel, food, water, and medicines. At the same time, Israel has decided to effectively ban the United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA), which is the largest provider of aid, health care, and other vital services for Palestinians. How MSF is responding in Gaza What to know about the humanitarian catastrophe in Gaza and how MSF teams are providing medical and humanitarian aid. Learn more We need a ceasefire MSF repeats its call for an immediate and sustained ceasefire. The total destruction of Palestinian life in Gaza must stop. MSF is also calling for immediate and safe access to northern Gaza to allow the delivery of humanitarian aid and medical supplies to hospitals. While MSF continues to provide lifesaving care in central and southern Gaza, we call on Israel to end its siege on the territory and open vital land borders, including the Rafah crossing, to enable a massive scale-up of humanitarian and medical aid. Even if the Israeli military offensive on Gaza ended today, its long-term impacts would be unprecedented, given the scale of the destruction and the extraordinary challenges of providing health care across the Strip. The MSF report notes that even if the Israeli military offensive on Gaza ended today, its long-term impacts would be unprecedented, given the scale of the destruction and the extraordinary challenges of providing health care across the Strip. A staggering number of war-wounded people are at risk of infection, amputation, and permanent disability, and many will require years of rehabilitative care. The cumulative physical toll and mental trauma caused by the extreme violence, loss of family members and homes, repeated forced displacement, and inhumane living conditions will scar generations. Related stories Your questions about our work in Gaza, answered Here are some of the questions frequently asked about our work and mission as it pertains to the ongoing crisis. Read more December 19 12:00 AM Life in the death trap that is Gaza Israel’s war on Gaza is unraveling the fabric of society in the Strip. Read More November 04 10:11 AM Timeline: One year of bearing witness to all-out war in Gaza A grim milestone for Palestinians in Gaza suffering under siege and bombardment. Read More We speak out. Get updates. Developing story How we're responding to the war in Gaza See latest updates More news and stories See All View more related news & stories News Dec 20, 2024 Sudan: MSF condemns RSF attack on Bashair Teaching Hospital in Khartou... Read More News Dec 20, 2024 Sudan: Zamzam camp under shelling as violence escalates in North Darfu... Read More Story Dec 20, 2024 Hey AI, what bit me? How machine learning helps doctors identify snake... Read More View more related news & stories",
    "commentLink": "https://news.ycombinator.com/item?id=42467375",
    "commentBody": "Doctors Without Borders declares the war in Gaza as genocide (doctorswithoutborders.org)235 points by lr0 17 hours agohidepastfavorite141 comments A_D_E_P_T 17 hours agoRelated, interesting: > https://interactive.aljazeera.com/aje/2024/gaza-before-after... > https://www.ap.org/news-highlights/spotlights/2024/gaza-is-i... The strip is bombed out and half in ruins. With the import of construction material into Gaza highly restricted, I wonder how, or if, it'll be rebuilt. It is becoming a true open-air wasteland prison, barely capable of supporting life. So it's hard to dispute the conclusion drawn by Doctors Without Borders, even if the deaths lag behind the damage to infrastructure and shelter. reply bhouston 17 hours agoparent> the deaths lag behind the damage to infrastructure and shelter. It is pretty clear that the death counts from Gaza are widely inaccurate and incomplete. They are only counting dead if they are brought to the hospitals and then buried. But Israel is bringing down building after building with people in them that are never recovered. And then secondary deaths caused by lack of health facilities are not being counted as dead directly as a result of the conflict, but are definitely caused by it. reply hirvi74 16 hours agorootparentHow does this compare to other wars? reply maeil 9 hours agorootparent> Key findings > By almost every metric, the harm to civilians from the first month of the Israeli campaign in Gaza is incomparable with any 21st century air campaign. It is by far the most intense, destructive, and fatal conflict for civilians that Airwars has ever documented. Key findings include: > At least 5,139 civilians were killed in Gaza in 25 days in October 2023. This is nearly four times more civilians reported killed in a single month than in any conflict Airwars has documented since it was established in 2014. In October 2023 alone, Airwars documented at least 65 incidents in which a minimum of 20 civilians were killed in a particular incident. This is nearly triple the number of such high-fatality incidents that Airwars has documented within any comparable timeframe. > Over the course of 25 days, Airwars recorded a minimum of 1,900 children killed by Israeli military action in Gaza. This is nearly seven times higher than even the most deadly month for children previously recorded by Airwars. > Families were killed together in unprecedented numbers, and in their homes. More than nine out of ten women and children were killed in residential buildings. In more than 95 percent of all cases where a woman was killed, at least one child was also killed. > On average, when civilians were killed alongside family members, at least 15 family members were killed. This is higher than any other conflict documented by Airwars. Seems like a neutral source that documents all conflicts focusing on the casualties. reply coryfklein 5 hours agorootparentWe are pretty early in the 21st century. Would probably be rather different results if the 20th century was included. reply pas 3 hours agorootparentOne one hand, indeed, we're approximately at \"one quarterth\" of the century. On the other a high-tech well-funded professional combined-arms military with total air supremacy in complete control of the perimeter is ought to be capable of being more careful. And maybe it is, just wasn't feelin' it. reply coryfklein 2 hours agorootparentWell that. But also geurilla warfare against non-uniformed combatants that use public infrastructure for military purposes has inherently higher civilian casualties. It's not going to be all one thing or another. reply bhouston 16 hours agorootparentprevWikipedia says this about WWII: \"Deaths directly caused by the war (including military and civilian fatalities) are estimated at 50–56 million, with an additional estimated 19–28 million deaths from war-related disease and famine. Civilian deaths totaled 50–55 million.\" https://en.wikipedia.org/wiki/World_War_II_casualties#:~:tex.... We should expect similar numbers for Gaza in terms of additional indirect deaths. But the current numbers for Gaza still are an undercount of direct deaths. reply randunel 16 hours agorootparentWW2 was often at equilibrium. The bombing of Gaza is pretty one sided. A comparison might be better with other one sided conflicts. reply addicted 15 hours agorootparentA good comparable is Russia’s attack on Grozny. 5000-8000 dead in a city with a population of about 200,000. reply belorn 15 hours agorootparentprevA better (and more recent) conflict would be US war on terror, with a death count around 400 thousands to 6 millions. The numbers varies extremely. The US military claims that only a total of 20 civilians has died to drone strikes. At the other extreme, others has estimated that 10 civilians has died per killed military which would represent a civilian to combatant casualty ratio of 10:1. In iraq, the Iraq Body Count project estimate a civilian casualty rate of 77%, which is quite similar to the 68% and 83% estimated given by B'Tselem and Palestinian Centre for Human Rights. It should be mentioned that genocide is not defined by number of deaths or civilian casualty rate, but instead about the intention. US killing people with drones, even if the wast majority is civilians and committed for poor reasons, are not considered genocide. If that is fair or not is up to debate. reply TheSpiceIsLife 4 hours agorootparentprevThe population of Gaza is (was?) around the two million mark. reply throw310822 9 hours agorootparentprevThis is not a war. There aren't casualties on both sides. This is a one-sided massacre. reply weatherlite 8 hours agorootparentThere are no Israeli casualties ? wtf are you on about. There are enough Israeli casualties to completely shake a country to its core. Forget all the dead from the Hamas massacre of October 7th, Israel has 12k+ wounded soldiers. That's an enormous amount for such a small country. It still has around 100k internal refugees. Yes it's way way less than what Gaza has experienced but at the same time - correcting for population - it's so much worse than 9/11. There's no Western country in recent time that went through something event remotely similar to what Israel has gone and is going through. reply throw310822 8 hours agorootparentI would leave aside all proportions and corrections for population: because otherwise you need to multiply by a factor between 2 and 4 the deaths and injuries in Gaza to compare them with those of Israel. You'd probably not want to. Besides this, the number of Israeli casualties in the Gaza invasion amount to a few hundred soldiers while the Palestinians ones are two orders of magnitude higher, and most of them civilians. If you have more precise data plase share. reply weatherlite 7 hours agorootparent> I would leave aside all proportions and corrections for population: because otherwise you need to multiply by a factor between 2 and 4 the deaths and injuries in Gaza to compare them with those of Israel. You'd probably not want to. Why wouldn't I want to ? I'm not gonna deny for a moment what Gaza is going through isn't traumatic, of course it is. That's reality. And saying what Israel is going through is nothing is delusional as well. reply throw310822 7 hours agorootparentI think comparing what Israel is going through with the destruction of Gaza- which is comparable to that of Dresden or Warsaw, a wasteland of ruins, starving people, corpses and amputated civilians- is, well, obscene. reply weatherlite 2 hours agorootparentGaza is suffering much more - I never tried to say otherwise. I'm not sure what the point of this argument is anymore to be honest. It seems you can't or won't admit that Israelis are suffering quite a bit for some reason even if it pales in comparison to Gaza. reply throw310822 56 minutes agorootparentThe point is that this is not a war. It's a massacre in which an army is killing tens of thousands of civilians and razing an entire region to the ground, while itself is suffering minimal casualties. reply meiraleal 3 hours agorootparentprev> I'm not gonna deny for a moment what Gaza is going through isn't traumatic, of course it is. That's reality. And saying what Israel is going through is nothing is delusional as well. Only in one of those places people are celebrating. reply 486sx33 6 hours agorootparentprevReally? What about all the dead hostages ? reply throw310822 6 hours agorootparentHm, not sure if this is sarcasm. Most hostages have been killed by Israeli bombardments or even direct fire. But even if that were not the case, the hostages are a tiny number of people compared to the numbers of the massacre of the Palestinians. reply Paradigma11 6 hours agorootparentprevIt looks pretty similar in magnitude to the siege of Grozny by the Russians. reply randomcarbloke 9 hours agorootparentprevit actually ranks quite reasonably for civilian casualties even if we believe the Hamas figures (which we shouldn't), it's clear Israel are doing their best to minimize civvy losses. reply 4gotunameagain 11 hours agorootparentprevIt is for sure much more lopsided than other wars, as the Israeli deaths have been minimal. Which strengthens the argument for a genocide, not a war. reply hintymad 15 hours agorootparentprevnext [15 more] [flagged] nielsbot 15 hours agorootparent1) These numbers are from MSF (Doctors Without Borders) 2) Israel themselves rely on the Gazan ministry of health’s numbers, aka Hamas, which I believe are pegged at 40k, definitely an extreme undercount Finally, there’s no quibbling about it. Israel (on the US’s behalf) is a oppressor. Those imprisoned, starved and bombed in Gaza are the oppressed. But happy to hear why you think that may not be the case. reply ashoeafoot 11 hours agorootparentOpressed similar to germany by the treaty of versailes and then liberated by the.. oppression doesn't equal saint hood. the wirld is filled with opressed monsters. Part of the reason why they are opressed is a inability to form strong institutions . reply nielsbot 11 hours agorootparentThe gazans are oppressed because they can’t form strong institutions? 1) victim blaming 2) why can’t they form strong institutions? (I’m sure it’s nothing to do with putting them in a ghetto where nobody can enter or leave without Israel’s say-so, controlling their air and sea, and water supply and electricity, right?) Your “national socialists” analogy is tortured. a better analogy is the US and their genocide of the native americans. reply doorbumper 10 hours agorootparentnext [4 more] [flagged] atoav 9 hours agorootparentSo victims by your book are only allowed to speak up if (and only if) they never did anything wrong and showed inhuman restraint in not defending themselves? reply ashoeafoot 2 hours agorootparentyeah, similar to russia which can not play the \"saviour of the oprrssed card\" because it showed itself to be monstrous . There are no demonstrations for the dead of isis , the hanged queers in teheran, the genocide in sudan. Its a mimicry of western values with no depth. reply 8note 10 hours agorootparentprevpretty well, yeah reply tdeck 15 hours agorootparentprevIt's beyond me how someone can believe you can carpet bomb a city where 2 million people live and kill fewer than 40,000 people. In fact, I don't find myself able to believe that people genuinely think that. reply mahkeiro 11 hours agorootparentIsrael dropped about 7x the equivalent of the Hiroshima bomb on Gaza, a small strip of land. This statistic alone is sufficient. reply weatherlite 8 hours agorootparentI don't get what this statistic truly signify. between 90,000–166,000 people died in Hiroshima - almost all civilians naturally, while way fewer people died in Gaza - many civilians but also many Hamas people. I'm not denying a lot of bombing went on in Gaza but obviously it was way less lethal and way more surgical than what happened in Hirsohima, otherwise you can't really explain the death toll difference. reply BoingBoomTschak 7 hours agorootparentprevNB: most Japanese civilian losses were from firebombing of Tokyo. reply Purplehermann 13 hours agorootparentprevGiving notice is helpful reply notnaut 13 hours agorootparentThis is not a serious perspective. reply tdeck 10 hours agorootparentIndeed https://gaza-patterns-harm.airwars.org/ reply demarq 6 hours agorootparentprevCome on mate, it’s getting old reply calmbonsai 15 hours agoprevWell, I'm pretty certain by any reasonable (UN, AI, HRN, etc.) standard, it became genocide quite some time ago when Israel: 1. Used precision guided weapons in unguided-mode to take out entire buildings including schools and hospitals 2. Used precision guided weapons in guided-mode to take out cars and food supply trucks of the World Central Kitchen workers when the cars were clearly demarcated as UN 3. Blocked I18n (not just UN) food & water aid 4. Precisely demolished water, sewer, and electrical infrastructure 5. Denied PoWs fundamental rights under the UN charter reply addicted 14 hours agoparentnext [4 more] [flagged] text0404 14 hours agorootparent> 4. I’ve seen absolutely no evidence for this you can do a basic google search to answer your questions. i searched for \"israel palestine water access\" and these were the first page: \"Human Rights Watch accuses Israel of acts of genocide in Gaza over water access\" - https://www.bbc.com/news/articles/c75wqr0k3dyo (same coverage from Guardian: https://www.theguardian.com/world/2024/dec/19/israel-accused...) \"Israel using water as weapon of war as Gaza supply plummets by 94%, creating deadly health catastrophe: Oxfam\" - https://www.oxfam.org/en/press-releases/israel-using-water-w... https://www.al-monitor.com/originals/2024/12/israel-strikes-... https://www.csis.org/analysis/siege-gazas-water https://www.aljazeera.com/program/newsfeed/2024/9/1/israel-c... https://www.amnesty.org/en/latest/news/2023/10/israel-opt-is... https://www.pbs.org/newshour/world/in-gazas-widening-humanit... > 5. Hamas fighters are not fighting in uniform. They do qualify as Prisoners of War. this is not adequate cover for Israel's indiscriminate killing of civilians. the geneva conventions do not work this way. > Israel has blocked aid for short periods of time in certain areas. For the most part, the failure of aid reaching where it needs to go has been a result of Israel being unable to provide security. We’ve seen what happens when Israelis don’t provide security for aid workers. They get looted and killed. no, they've blocked access for long periods of time. this is why there is a famine: https://www.ohchr.org/en/press-releases/2024/07/un-experts-d... they are also killing aid workers who have cleared their routes with the IDF beforehand: https://en.wikipedia.org/wiki/World_Central_Kitchen_aid_conv... https://news.un.org/en/story/2024/09/1154206 > the pro Palestinian sides have absolutely destroyed the opportunity for moderation and negotiation by labeling Israel’s actions as genocide from day 1 yes, because the genocide has been occuring since 1947. i would highly recommend reading the history of this conflict as it started long before Oct 7 2023. reply calmbonsai 10 hours agorootparentprev> Hamas fighters are not fighting in uniform. They do qualify as Prisoners of War. I'm assuming you meant \"do not\". Please see the U.S. State Department's report on the \"exceptional measures\" involved: https://www.state.gov/reports/2023-country-reports-on-human-.... This is in direct violation of the UN Declaration of Human rights. > I’ve seen absolutely no evidence for this. Can you share evidence that Israel is precisely destroying water, sewer and electrical infrastructure? Google is your friend here. I didn't (couldn't initially) believe it myself until details of this (initial) BBC report came out in May. https://www.bbc.com/news/world-middle-east-68969239 What, indeed, could possibly be the anti-terrorism purpose of destroying solar panels? > Why in the world would Israel fire expensive precision guided missiles in unguided modes instead of using unguided missiles instead in the first place? Because, apparently, a preponderance of exigent circumstances dictated a rapid response--collateral damage be damned. Being more than passingly familiar with guidance systems technology and avionics in \"smart\" glide-bombs, and their exorbitant costs relative to \"dumb iron\", this is just stupid. Additionally, the IDF has the most highly trained urban assault force and undercover (Duvdevan) anti-terrorist commando (Egoz) units in the world and yet they somehow _must_ bomb an entire hospital to (potentially) take out a single cell?! > For the most part, the failure of aid reaching where it needs to go has been a result of Israel being unable to provide security. We’ve seen what happens when Israelis don’t provide security for aid workers. Notable that the \"inability to provide security\" seems highly selective wrt the source of the aid and not its contents. See details of the WCK attack: https://en.wikipedia.org/wiki/World_Central_Kitchen_aid_conv... and also this UN report https://news.un.org/en/story/2024/04/1148141 . I completely concur on \"genocide\" being an attempted \"Day 1 PR-flank\", but far too many precise and planned actions have since been taken. In a perverse way, the Israel government played into Hamas' hands at the expense of the Palestinian people, trade, the quality of life of the Israeli people and further instability in the region. As I mentioned in a prior thread, see the actions of the British in east Africa against the Kikuyu for a close historic analog. I had hopes that Gallant's official ouster would be a political pole-star/umbrella under which the Knesset could rally, but that (sadly) appears not to be the case. reply mo7061 9 hours agorootparentprevisrael is definitely commiting genocide in Gaza reply calmbonsai 15 hours agoprevSadly, there's a reason the \"Gaza tourniquet\" had to be invented. https://glia.org/pages/the-glia-tourniquet-project reply 486sx33 6 hours agoprevThe war could be over to tomorrow if hamas releases the hostages. The consequences for each dead hostage should be massive to let the world know that hostage taking is not acceptable. reply lossolo 6 hours agoparentnext [3 more] [flagged] commandlinefan 3 hours agorootparentBut isn't it the Palestinian's position that all of Israel is Palestinian territory? reply mu53 2 hours agorootparentprevThere are no conditions where the war would end tomorrow. reply stogot 16 hours agoprevI know this is a controversial issue. But honest question: what is a ceasefire going to do? Hamas refuses to surrender, so it’s only a few years until another Oct 7, and then it starts again. What other option does Israel have? They’ve been fighting these wars for years and they’ve now decided to continue this one vs waiting for a new one in three years reply UniverseHacker 15 hours agoparentThey could stop persecuting and murdering Palestinians, stop occupying Palestine, and agree to either a one state or two state solution that recognizes Palestinians as human beings with a right to live. reply UniverseHacker 2 hours agorootparentI'm very disappointed in people flagging everyone that disagrees with me. What is the point of even coming on here if you won't have a discussion with people you disagree with, but want to censor their ability to participate? Echo chambers are useless for everyone. reply bradlys 1 hour agorootparentThis website/SV has a very large Israeli presence. The fact that even one comment on this page that is pro-Palestinian is not downvoted into oblivion and flagged/banned is remarkable in itself and speaks to how many people within SV don't like Israel's genocide. It's the same issue for topics related to India/China. reply AnimalMuppet 15 hours agorootparentprevnext [14 more] [flagged] text0404 13 hours agorootparentnext [14 more] [flagged] weatherlite 8 hours agorootparent> as they said: \"They could stop persecuting and murdering Palestinians, stop occupying Palestine, and agree to either a one state or two state solution that recognizes Palestinians as human beings with a right to live.\" There's really barely any evidence Hamas would agree to a 2 state solution. The overwhelming evidence is it won't agree to it. Same for one state solution - Hamas would of course agree to cancel the state of Israel (thus creating something you could call a one state, slowly or quickly driving the Jews away) but definitely not to any kind of shared power democracy. To truly appease Hamas Israel needs to commit national suicide. That's quite a big ask for a people as persecuted as the Jews. reply SauciestGNU 4 hours agorootparentI don't want to pick on you because I think you raise reasonable points, but I see frequently the notion that if you have a one state solution, the Arab majority would treat the Israel minority in the way that the Israelis have been treating the Arab. I think this is spurious, we have no indication that this would actually be the case. I believe that this isn't a religious conflict and that an the to apartheid and occupation could actually bring peace. But it bothers me that people see the Arab Palestinian population as one incapable of accepting peace and driven by revenge or antisemitism. reply weatherlite 2 hours agorootparent> But it bothers me that people see the Arab Palestinian population as one incapable of accepting peace and driven by revenge or antisemitism What do you think drives the Palestinian movement and what are its main goals? If it was simply to get their own state surely they could have achieved it by now (as far back as in 1947). So there seems to be much more going on than simply attaining statehood - there is a very strong irredentist force among Palestinians that wants to go back to the way things were 80 or a 100 years ago. Which means returning to their original homes (I don't see how you could do that without throwing out the Jewish 'colonists'). To me that does seem to be motivated at least partly by revenge. As for antisemitism among Palestinians, it's there and widely documented (you could come up with good reasons why it's there, but denying it's there is wrong). reply bufferoverflow 11 hours agorootparentprevIsrael hasn't been an occupying force. They left Gaza in 2005. Palestinians decided to spend their time preparing for terrorist attacks against Israel. reply dragonwriter 8 hours agorootparent> Israel hasn't been an occupying force. Israel has indisputably been an occupying force in Palestine continuously since 1967, at the latest. > They left Gaza in 2005. They did not stop exerting control of Gaza at any point, continuing to regularly murder unarmed civilians within Gaza, without provocation, control its waters, and otherwise exercise dominion even after their tactical redeployment. Not that even if they had withdrawn from that part of Palestine it would change that they were occupying Palestine. reply throw310822 8 hours agorootparentprevIf they left Gaza in 2005, how come that that they always controlled water, electricity, movement of people, air space, sea space, and all resources access? The international community regarded Gaza as always under occupation. You can have your own (unqualified) opinions about this; that judgement is a fact. reply bufferoverflow 2 hours agorootparentYou mean they supplied water and electricity to Gaza, even though they didn't have to. reply maeil 8 hours agorootparentprevPalestine doesn't just consist of Gaza, doing so is playing a bad faith word trick. I can't imagine you're unfamiliar with the continuous annexations and illegal settlements in the West Bank, along with the continuous razing of Palestinian buildings there. If not, you're one of today's lucky 10,000. Here's a basic introduction [1]. [1] https://en.wikipedia.org/wiki/Israeli_settlement reply anal_reactor 12 hours agorootparentprevWhat the fuck you talking about, democratically elected Hamas has \"the complete destruction of Israel\" as their official policy, and polls show that only after being bombed to oblivion most Palestinians started to think that Oct 7 might've been a bad move. It's clear to me that Palestinians do not accept peace as a practical solution. https://www.reuters.com/world/middle-east/palestinian-poll-f... reply throw310822 8 hours agorootparentThe platform of the democratically elected Likud states the same: \"between the Jordan and the sea there will be only israeli sovereignty\". https://www.jewishvirtuallibrary.org/original-party-platform... Does this authorise Hamas to go there and raze the entire country to the ground? Please let me know. reply weatherlite 8 hours agorootparent> Does this authorise Hamas to go there and raze the entire country to the ground? Please let me know. Pretty much yes according to too many liberal professors in ivy league universities. I think human lives on both sides are quite cheap to them. reply throw310822 7 hours agorootparentI would like to know the names of these professors and their respective quotes. I suspect that they don't really exist but are just a convenient excuse to paint the perpetrators as victims. Besides this, even if Hamas and Likud are identical in the intentions, only one side is illegally occupying and annexing the other's territory, and almost all deaths and destruction are on the other side. The situation on the ground matters- people who are oppressed have a right to defend themselves, and this comes before any stated intention. reply anal_reactor 5 hours agorootparent> Besides this, even if Hamas and Likud are identical in the intentions In most juridical systems, it's the intent that matters. reply clydethefrog 10 hours agoparentprevI know this is a controversial thought experiment, but honest question: how should the German occupiers have reacted to the Warsaw Ghetto uprising? reply SauciestGNU 4 hours agorootparentMass suicide reply jfwuasdfs 15 hours agoparentprevA cease-fire may buy us time to figure out a long-term solution. reply kojdels 15 hours agorootparentnext [9 more] [flagged] selcuka 15 hours agorootparentIt's interesting that we don't count Israel as a religious lunatic state. reply shepherdjerred 15 hours agorootparentIsrael's stated goal is not to kill unlike Hamas reply defrost 14 hours agorootparentBest to watch what people do rather than what they say. Which one consistantly has the greater body count, which one has been steadily illegally encroaching on territory, etc. reply selcuka 13 hours agorootparentprevSure, not their \"stated goal\", but remember that Hamas is a reactive organisation. There would be no Hamas without Israel. I don't think there is a solution other than diplomacy as long as there are people who gain material benefit from war. Even nuking all Palestinians would not finish Hamas or its derivatives. reply text0404 13 hours agorootparentprevhttps://apnews.com/article/israel-palestinians-south-africa-... Israel would disagree with you. reply throw310822 8 hours agorootparentprevHamas' stated goal is not \"to kill\"- remember that everything you know about Hamas you know from Israel's perspective and according to Israel's interests. Hamas' stated goal is \"to free Palestine\"- it means gaining its political control, not murdering people. reply randomcarbloke 9 hours agorootparentprevit's a liberal democracy that welcomes even gazans as citizens rather than a genocidal theocratic ethnostate like all its neighbours. reply lr0 14 hours agorootparentprevAlmost all regimes in the Middle East (and even other Arab regimes) are having a very well relationship with Israel, even those who do not publicly do normalization of relations. Historically Israel (as well as the US.) supported these regimes to ensure its interest. Not many books written about that so far, but I recommend people to check William Blum's \"Killing Hope\", it studies a very similar case of supporting dictatorships by Israel's key sponsor (the United States). reply nitwit005 13 hours agoparentprevWhat are any of the options available going to do? They don't have any fundamental fixes for the situation available. Fundamental to Isreal's problems is that all security issues seem to only have temporary fixes available. reply throw310822 8 hours agorootparentFundamental to Israel's problem is that they want \"security\" while they keep oppressing Palestinians and grabbing more land. They do not want peace- quite the opposite, peace means establishing fixed borders, possibly evacuating illegal settlements, not having an excuse for further expansion, etc. They want a permanent state of attrition that allows them to keep doing what is convenient to them while being safe from all reprisals. This was said clearly by one of Sharon's advisors explaining the motives for Israel removing settlements from Gaza: \"The significance of the disengagement plan [from Gaza] is the freezing of the peace process, and when you freeze that process, you prevent the establishment of a Palestinian state, and you prevent a discussion on the refugees, the borders and Jerusalem.\" reply vr46 12 hours agorootparentprevAll they seem to offer the world has been revenge since the 1980s. reply jhanschoo 14 hours agoparentprevThe enlightened option from a felicific calculus method it seems to me would require putting the destiny of Israel democratically in the hands of the Levantine majority; scaling back its territory occupied and settled illegally. But of course, this is not an option. This risks the genocide of the Israelis by putting power in its neighbors, when they have the wealth and US support to ensure that it is their more numerous enemies that risks genocide instead reply invalidname 14 hours agorootparentYou do know Israel offered Palestinians a state and unilaterally left Gaza giving them an option to build a state... We tried that and it didn't work. reply 486sx33 6 hours agorootparentNot only that, Hamas stole the world’s money meant to feed and help and instead oppressed and killed. Palestine people would do well to join Egypt reply insane_dreamer 15 hours agoparentprev> What other option does Israel have? seriously? yeah, so lets just reduce Gaza to rubble, ruin the lives of 1.5M people and kill 45,000 men, women and children in order to root out remaining fighters who refuse to lay down their arms. In fact why don't we just go ahead and nuke the whole place -- that should get rid of Hamas once and for all. -- except that it won't actually get rid of Hamas--or whatever comes out of the ashes of Hamas. When a population has been oppressed as long as the Palestinians in Gaza have, it gives rise to people who don't care anymore, people who have seen their families and loved ones killed. Even if Israel kills every Hamas fighter today, how many 10 year old boys do you think there are today who are going to take up weapons to avenge their fathers and older brothers as soon as they are able? Just like today's fighters want to avenge their fathers from the last intifada? So yeah, Israel will be fighting this again in 5 year's time (unless of course they just kill most everyone or make Gaza unlivable, which seems to be the case now that this has gone on for over a year, thus ... genocide). The only way to stop it is for Israel to stop oppressing Gaza to begin with, but that it is unwilling to do. So the cycle will continue. reply thruway516 15 hours agorootparentThey appear to be trying to end the cycle once and for all. And they have bullied/co-opted the rest of the world into silence or indifference. reply TheSpiceIsLife 3 hours agorootparentSilence, indifference? I’m not hearing any silence or indifference. There are people as far away as the antipodes harassing Jews who, presumably, have nothing to do with what’s going on over there. A synagogue was recently burnt down in Melbourne https://www.abc.net.au/news/2024-12-09/melbourne-synagogue-f... reply insane_dreamer 2 hours agorootparent> I’m not hearing any silence or indifference. not really listening, then reply thruway516 1 hour agorootparentMore like filtering for only what they want to hear, and telling us the rest doesn't exist reply amanaplanacanal 15 hours agorootparentprevnext [2 more] [flagged] collingreen 13 hours agorootparentOof. I had more written here but I deleted it to just oof. What a terrible situation. reply fuzzfactor 13 hours agorootparentprev>The only way to stop it is for Israel to stop oppressing Gaza to begin with, That would be good. I don't have a dog in this fight, but it's a little too late since IIRC the oppression started decades ago as a security measure to regain a stalemate after excessive bombings from proudly hateful genocidal jihadists. And with hesitation from Israel, only after terrorists proved repeatedly to have too much freedom of movement outside of Gaza. Exactly as you say, the sons & grandsons of those evildoers have followed in the footsteps and drawn greater oppression, and what now looks like for the first time (or maybe finally?) an equally hateful genocidal response from Israel. But \"equal\" is now more lopsided than ever since Israel had to bolster its defenses so much for so long that it's now incredibly destructive when deployed as an offensive force. We shouldn't lose sight of what could have been, even though so much has been lost already. If they want to stop the killing as seriously as possible, every day since Oct 7 Hamas continues to have the opportunity to surrender the hostages and lay down their arms. Hamas clearly started this present war whether it was intended to get out of hand or not. What kind of conclusion is supposed to be possible other than complete vanquishment unless they surrender beforehand and agree to more effective security demands going forward? As a neutral observer you just have to accept that initiating a war like this directly establishes Hamas in at least a slight moral deficit compared to whom they viciously attacked. All other things being equal, it does point the finger of responsibility at Hamas for all subsequent destruction until the war is completely over. Even if things are not equal at all, Hamas could always end it any time they wanted. It would have saved a lot of lives, but not as many as if Hamas refrained from slaughtering civilians to begin with. The situation will eventually settle and judgment will coalesce whether it was in the best interest of Palestinians for Hamas to trigger a response-in-kind from the IDF the way they did. reply text0404 13 hours agorootparentfor a neutral observer, these are some pretty demeaning statements which don't seem to question the Israeli narrative whatsoever. the underlying assumption to your comments also seems to be that Palestinians have brought this upon themselves, which is an interesting argument - \"if they stopped resisting and just let the Israelis subjugate them, there would be peace.\" > IIRC the oppression started decades ago as a security measure to regain a stalemate after excessive bombings from proudly hateful genocidal jihadists you're recalling incorrectly. > Exactly as you say, the sons & grandsons of those evildoers have followed in the footsteps and drawn greater oppression we're talking about civilians, not combatants, not \"evildoers\" - normal human beings living their lives and being oppressed and murdered by an occupying force. separating humans into \"evil\" and \"good\" is how we get into nation-states targeting children with precision weapons. unfortunately it's not that clear-cut. reply fuzzfactor 11 hours agorootparent>for a neutral observer, these are some pretty demeaning statements I knew that in advance but not as bad as someone who is not sympathetic to both sides as much as possible, while being equally disappointed in their behavior. >you're recalling incorrectly. OK it wasn't a complete stalemate, once the suicide bombings were better prevented, jihadists continued to terrorize by shooting rockets at Israel. Try and point out any decade of the 70's, 80's, 90's and on when there have been no hate crimes committed by jihadists. And the response from Israel has amounted to gradually tightening the screws to protect their citizens, ending up with a more deplorable situation for Palestinians overall every time. Not without fatalities either. In a cruel tit-for-tat that has been easily followed over these last 6 decades for me. That's all Israel's fault, and the need for tightening their security is due to the fault of Hamas these days. Now there's war crimes on both sides. I don't mean peace-loving civilians at all, it's the bloodthirsty killers on both sides who are the evildoers. That's a clear enough line for me, I'm not willing to paint those who are \"less evil\" with the same broad brush as the real killers. And everybody can recognize that the number of killers in the IDF has skyrocketed over the last year, but can anybody be sure when this matches or exceeds the number of Palestinians who are fully dedicated to killing Israelis? One thing's for sure, the number of Palestinian casualties is the biggest tragedy and they should have stopped shooting way before it got this far. That's what this article is all about and I believe these doctors and their first-hand accounts. reply fakedang 13 hours agorootparentprevThe main difference between Gaza and other conflicts (such as Ukraine or Iraq) is that Hamas has and uses the willing (even if coerced) cooperation of the civilian population as part of its military strategy. Using humans as meat shields and using teenagers and young men in offensive combat roles is exactly what Hamas does. In comparison, in Iraq or Ukraine, the Iraqi and Ukrainian militaries made/make a clear distinction between military and civilian personnel (which their adversaries didn't respect). Even the Taliban makes sure to not use civilians as part of their military strategy (if we're going by the comparison with resistance fighter groups). The Gaza situation is more akin to Vietnam, where also the civilian population was actively integrated with the military and helped them in more ways direct than indirect. The key difference here being that Vietnam was invaded by France and then the US, while Hamas were the ones who stirred up the hornet's nest in Israel. reply cloverich 2 hours agorootparent> The main difference between Gaza and other conflicts (such as Ukraine or Iraq) is that Hamas has and uses the willing (even if coerced) cooperation of the civilian population as part of its military strategy. I find this IoW report of the situation a compelling expansion of that line of thinking[1], for anyone interested; excerpt: > Hamas’ long-term effort to embed itself in Palestinian society and politics makes defeating and replacing it very difficult, but not impossible. Hamas’ combination of social services and outreach with coercive measures have ensured that Hamas retains significant support in Gaza relative to the very limited number of other entities that could replace it, despite the extremely destructive war that Hamas initiated. Hamas’ coercive apparatus makes it extremely difficult for possible Hamas alternatives in the Gaza Strip to begin to build their own governance system because to do so while Hamas remains militarily active risks near-certain death. It is not impossible to destroy Hamas’ political and military system, but doing so will require Hamas’ military defeat and a long transition to a new Palestinian-led government in the Gaza Strip. [1]: https://www.understandingwar.org/backgrounder/hamas%E2%80%99... reply lostlogin 12 hours agorootparentprev> The key difference here being that Vietnam was invaded by France and then the US, while Hamas were the ones who stirred up the hornet's nest in Israel. Doesn’t this depend on when you define the conflict as starting? When do you think it started? reply fakedang 10 hours agorootparentTbf this isn't Hamas' first rodeo. They've been firing rockets into Israel since their conception. Then there was that ceasefire and the pullout by Israel from the Strip, but Hamas never really believed in a ceasefire. 15 years later, we ended up here. reply lostlogin 11 minutes agorootparentThats exactly it. And this didn’t start 15 years ago. There is not much point in arguing about what kicked it off either - that won’t fix it. nickserv 10 hours agorootparentprev> The key difference here being that Vietnam was invaded by France and then the US Not quite. Indochina was a French colony which rebelled and escalated into open conflict. The rebellion was successful, the French were expelled, and Vietnam was formed. However conflict in the area continued as a civil war between the two dominant factions in Vietnam (communist vs capitalist) for control of the new country. The US intervention was a failed attempt at suppressing the communist faction. Gaza is different in that it was conquered by Israel during their war with Egypt. The Israelies even started building settlements there. Israel then got out of Gaza and removed all their settlers as part of a peace accord (if memory serves). However Gaza never really accepted peace with Israel and kept on attacking them, culminating in the Oct 7th attack that got us in this mess. reply insane_dreamer 1 hour agorootparentprev> as a neutral observer your post certainly doesn't sound like it > the oppression started decades ago as a security measure to regain a stalemate after excessive bombings from proudly hateful genocidal jihadists you need to update your history; the oppression started in 1948 (late 1947, really) reply stogot 15 hours agorootparentprevYour answer is unrealistic, but I didn’t provide a long enough question. I’m not justifying genocide obviously. The initial response to Oct7 was justified but not complete destruction of Gaza. Im asking why “not continuing to fight” (a ceasefire) is even a viable option for Israel’s politicians per the article’s demands. I am a realist not an optimist. Give a viable alternative. The cycle continues reply insane_dreamer 1 hour agorootparent> initial response to Oct7 was justified but not complete destruction of Gaza agreed but it's pretty clear now that the complete destruction of Gaza was the plan all along reply catlikesshrimp 14 hours agoparentprevNo offence, yours is an effective altruist take on any problem:There is NO FINAL SOLUTION to any human problem: not hunger, not disease, not poverty, not racism. All effort counts and smart effort contributes more, but it is not a once and done deal. We must eat everyday, we must not shit plastic in our air, all children must get polio vaccine, and taxes have to be paid one way or the other. It's ugly, it's hard, it's long, it's life! reply thruway516 5 hours agorootparentI literally cannot believe the phrase FINAL SOLUTION is being used here without any irony reply hmcq6 13 hours agoparentprev> Hamas refuses to surrender Hamas has repeatedly said they would accept a 2 state solution if Israel would return to the 1967 borders. Literally the first line of this AP article starts with > The Palestinian militant group *Hamas has said for more than 15 years that it could accept a two-state compromise with Israel* — at least, a temporary one. But Hamas has also refused to say that it would recognize Israel or renounce it's armed fight against it. https://apnews.com/article/israel-hamas-gaza-war-f756cc05473... And before you say \"you said right there that Hamas refused to say it would renounce the fight against Israel\" it's like... yeah no shit, why would Hamas guarantee peace when Israel is extrajudicially kidnapping children and sodomizing them? https://www.jpost.com/arab-israeli-conflict/article-813953 reply 486sx33 6 hours agorootparentFirst release the hostages. reply fakedang 12 hours agorootparentprevThere's nothing about sodomizing children in your JPost article. There is however mention of sodomizing a Hamas member, which going by your assertion would mean that Hamas is recruiting and using children? The raw fact is that were the sides turned, you wouldn't be reading that news article in the first place. You wouldn't seriously think that Hamas would launch an investigation against their own members for sodomy now, would you? Hamas has no plans to recognize Israel whatsoever, unless you're so naive to take their word for it. Their call for 1967 borders is basically a sorry excuse for establishing a violent attack front on both sides of Israel so that they can fight more efficiently. reply hmcq6 11 hours agorootparent>There's nothing about sodomizing children in your JPost article. There is however mention of sodomizing a Hamas member, which going by your assertion would mean that Hamas is recruiting and using children? Perhaps I misremembered, because you're right that the article doesn't support my claim. Either way, sodomizing adults is not really justice, is it? Either way the population of Palestine was 43+% children before Oct 7th so Israel has surely killed multiple thousands of children. Death must surely be as bad as rape? https://www.pcbs.gov.ps/post.aspx?lang=en&ItemID=4732#:~:tex.... reply cabbagepatch01 10 hours agorootparentYou are not misremembering - the incident you recall is when NGO DFCIP - defense for children international Palestine had credible reports of the rape of a 13 year old boy. This was investigated, substantiated and a complaint made to the US state department. The staffer resigned as Zionist State responded by taking the computers and declaring the NGO terrorists - the legitimacy of the designation along with the interview with the staffer is here https://skeptics.stackexchange.com/questions/56437/was-defen... \"I was part of the human rights vetting process for arms going to Israel. A charity called Defense of Children International Palestine drew our attention at the state department to the sexual assault, a rape, of a 13 year old boy in an Israeli prison at Moskobiya in Jerusalem. We examined these allegations, we believed they were they were credible. We put them to the government of Israel. You know what happened the next day? The IDF went into the DCIP offices and removed all their computers and declared them a terrorist entity.\" The widespread sexual abuse of Palestinian Men, Women, and Children is very well documented, e.g. https://www.un.org/unispal/wp-content/uploads/2018/06/S3-Gav... The incident was covered by EI here https://electronicintifada.net/blogs/tamara-nassar/israel-cr... reply esalman 16 hours agoprevThe fact that you look at this banner- https://www.telegraph.co.uk/news/2024/12/04/giant-anti-israe... .. And instantly know what it's about, pretty much rests the case. reply drooby 15 hours agoparentGenocide requires proving intentionality. Specifically, the deliberate intent to destroy, in whole or in part, a protected group. This is a serious and complex standard, and it’s central to the legal definition. It's like the distinctions between murder and manslaughter in criminal law. Intent and premeditation are key factors that separate them. These kinds of distinctions matter because they preserve the legal and moral weight of crimes like genocide, which shouldn’t be diminished by rushing to label something without meeting the specific criteria. That’s why it’s important to avoid being too quick to judge. Determining intent, especially on this scale, takes time and a thorough review of all the facts, patterns of actions, policies, statements, and more. These are exactly the kinds of questions that need to be decided in court, where the evidence can be fully weighed and assessed. Thank god we don't just look at a banner and say case closed... jfc.. reply defrost 15 hours agorootparentThere's no shortage of material in print calling for the destruction of Gaza, the non personhood of Palestinians, etc. from Israel ministers and commentators from before the October attacks by Hamas. You can, for example, look to the Journal of Genocide Research at articles that draw parallels between Holocaust scholar Eugene's Finkel's declaration of Ukraine as a genocidal event and his point by point justification and similar parallels with Israel and Gaza. https://www.tandfonline.com/doi/full/10.1080/14623528.2024.2... reply orwin 11 hours agorootparentprevThey destroy or steal art and books each time they invade. The places with the most Palestinian pre-israel books and art are Israelian archives, where only Israeli historians have access if the government authorize them (i.e if they're not critical of the current politics). reply calmbonsai 15 hours agorootparentprevIronically, I think the closest historical context is the British military in east Africa (roughly what is now Kenya) to the Kikuyu in the late 1880s. reply 123yawaworht456 10 hours agorootparentprev>Specifically, the deliberate intent to destroy, in whole or in part, a protected group. Jews were not a protected group in the 30's/40's, so...? reply hirvi74 16 hours agoparentprevnext [8 more] [flagged] insane_dreamer 16 hours agorootparentHave MSF bombed anybody lately? reply hirvi74 15 hours agorootparentDid you see any bombings in the link I posted? reply insane_dreamer 15 hours agorootparentNo - that's my point. You're seriously comparing the allegations of sexual misconduct by MSF employees with the bombing of Gaza and killing of 45K people? reply hirvi74 15 hours agorootparentIn my comment, I made no mentions of bombs nor Gaza nor war. I was pointing out that the MSF are not the harbingers of world peace. My issues with the MSF are orthogonal to the Israeli-Palestinian War. Has the MSF ever done good? Absolutely, but they have also done some rather unethical things as well. reply UniverseHacker 15 hours agorootparentprevThe criticism in the Wikipedia you linked lists various cases where unethical things were happening, and the article explains how the other employees and the organization took apparently strong corrective action to deal with them. That hardly seems like something worth mentioning to claim they have no right to call out genocide. While I am in no way condoning the events that were listed, it is inappropriate to even bring that up in this context. reply hirvi74 14 hours agorootparent> That hardly seems like something worth mentioning to claim they have no right to call out genocide. I made no mention of genocide. The MSF is free to call out genocide as they please. reply UniverseHacker 4 hours agorootparentNo, that is what it means when a person or organization raises a concern and you reply like you did- that they have no right to raise the concern because you’re implying they are just as guilty. reply bhouston 17 hours agoprevAnd HRW says the same thing specifically with regards to Israel's targeted destruction of water resources: https://www.hrw.org/news/2024/12/19/israels-crime-exterminat... That adds to Amnesty International's declaration that Israel's action fit the definition of genocide a few weeks ago: https://www.amnesty.org/en/latest/news/2024/12/amnesty-inter... Anyhow, there are so many companies in the US that are complicit including in particular Google - it knew its software was likely to be used for human rights violations in Israel and they valued getting money over going the right thing: https://www.timesofisrael.com/google-said-worried-contract-w... EDIT: Instantly downvoted to -2 on a factual comment that links to high quality resources? Feels like bots to me. reply ghufran_syed 17 hours agoparentso was the dam-busters raid by england in ww2 against nazi germany also “genocide”? or were they both just “warfare” as the events of Rwanda showed, it doesn’t take very long for a nation state to successfully complete genocide. So are the israelis really incompetent at genocide, to the point where they drop leaflets that say when they’re going to bomb a building and call cell phones in the area to tell the civilian population to get out? or is this just the usual propaganda and hyperbole? reply FireBeyond 17 hours agorootparent> to the point where they drop leaflets that say when they’re going to bomb a building and call cell phones in the area to tell the civilian population to get out What about the times they tell the civilians to move to, say, Southern Gaza, because they're going to start bombing Northern Gaza more heavily, and then when they do, they increase bombing of Southern Gaza by 85%? https://news.sky.com/story/gaza-war-satellite-data-shows-isr... > it doesn’t take very long for a nation state to successfully complete genocide I didn't realize you had to \"complete\" a genocide within a certain time limit. Besides, what's the rush? The global reaction so far is that there'll be loud words and fists thumped on tables, but that they'll let Israel do largely whatever it wants. reply kbenson 16 hours agorootparentI can think of many understandable reasons that might happen, so those facts without additional context don't mean much to someone that hasn't already had their mind made up, which is the problem with reporting them and expecting everyone to just see what you see as obvious. reply eNV25 12 hours agorootparentWhat are the justifiable reasons to specifically kill journalists with machine guns? reply sershe 4 hours agoprevI dunno, Gaza (on per-sqkm basis) still looks nothing like Hamburg '43. Until it looks at least like that everywhere, I'd say Israel is being too soft given the historical precedent on dealing with these kinds of movements. reply EvgeniyZh 3 hours agoprevAnother day, another organization redefines genocide to fit their narrative, doesn't mention hostages held in Gaza and gets manually unflagged by admins. Business as usual. reply pas 3 hours agoparentthere are many definitions already. what's yours? https://en.wikipedia.org/wiki/Genocide_definitions#List_of_d... reply EvgeniyZh 2 hours agorootparent> almost all international bodies of law officially adjudicate the crime of genocide pursuant to the Convention on the Prevention and Punishment of the Crime of Genocide (CPPCG). > This and other definitions are generally regarded by the majority of genocide scholars to have an \"intent to destroy\" as a requirement for any act to be labelled genocide This post mentions intent once: > While we don't have legal authority to establish intentionality But anyway somehow > What our medical teams have witnessed ... is consistent with the descriptions ... that genocide is taking place in Gaza and then the title was changed from \"Gaza death trap: MSF report exposes Israel’s campaign of total destruction\" to \"Doctors Without Borders declares the war in Gaza as genocide\" reply shkkmo 1 hour agorootparent> This post mentions intent once Intent is something that will be proved if the any of the war criminals in this conflict (on either side) ever face justice. The relevant authorities have been pretty clear there is adequate evidence of intent to issue arrest warrants. MSF care less about the label, and more about convicinging the international community to force Isreal into a ceasefire so they can do their job and save lives. It is unsurprising that MSF doesn't discuss intent, since it is the practical actions that concern them here, not the motivation behind them. reply EvgeniyZh 1 hour agorootparent> MSF care less about the label Why would they use a very strong label that they don't even have proofs for? All the genocide talk is only about labels. Genocide is something universally acknowledged to be bad, so calling something genocide is a good trick: who would argue for genocide? > the international community to force Isreal into a ceasefire so they can do their job and save lives. Well maybe saving hostage lives, that would also be a very strong argument for Israel to withdraw is something they should consider reply grumpycamel 13 hours agoprevhttps://www.youtube.com/watch?v=L9n77DPJ7AE This guy has a very accessible take on the proper United Nations definition of genocide and how it applies to the Gaza and Ukraine war. Gemini summary: >>>> This video discusses the definition of genocide and its application to current events. The speaker argues that many people misuse the term to describe any atrocity, while genocide specifically refers to the intent to eliminate a group of people. The speaker uses the examples of the war in Gaza and the arrest warrant for Vladimir Putin to illustrate this point. They argue that while there are many civilian casualties in Gaza, it's unclear if there's an intent to eliminate the entire Palestinian people. In contrast, Putin's forced deportation of Ukrainian children to Russia aligns more clearly with the definition of genocide. The speaker emphasizes the importance of using the term accurately to avoid diluting its meaning and to properly address serious crimes.Off-Topic: Most stories about politics, or crime, or sports, or celebrities, unless they're evidence of some interesting new phenomenon. Videos of pratfalls or disasters, or cute animal pictures. If they'd cover it on TV news, it's probably off-topic. reply thruway516 15 hours agorootparentReally? Change the conflict to a different one and it doesn't seem all that unusual or off topic by hn standards >And they have bullied/co-opted the rest of the world into silence or indifference. reply shkkmo 1 hour agoparentprevPolitical content of all kinds often gets flagged on HN as lots of people don't like it and flagging is the easiest way to express that disapproval and impact front page placement. reply thruway516 1 hour agorootparentYes, flagging is a way for some people to express disapproval of what THEY don't like. A major organization makes a big statement about a major conflict. This is of general interest and would normally make front page headlines, even on HN. reply alex1138 13 hours agoprevnext [2 more] [flagged] lr0 13 hours agoparentSCIAF, Christian Aid, Age International , Trocaire, Plan International, Bond and Cafod, and many other 'charities'[1] (MSF is obviously not a charity, you at least could have opened the link but you clearly do not know what you are talking about) declared what's have been going in Gaza as genocide. Amnesty International made in January a UN call consisted of 250 global charities, organizations and institutions to stop the genocide in Gaza, either you are not actually giving money to charity or you are having a very hard time fining one. [1]: https://www.quaker.org.uk/documents/public-statement-uk-char... reply maeil 8 hours agoprev [–] Discussions on Israel just aren't very interesting because a single quote is enough to show there is no room for debate, it's laughable cut and dry. “Anyone who wants to thwart the establishment of a Palestinian state has to support bolstering Hamas and transferring money to Hamas … This is part of our strategy – to isolate the Palestinians in Gaza from the Palestinians in the West Bank.” - Benjamin Netanyahu https://www.theguardian.com/commentisfree/2023/oct/20/benjam... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A report by Doctors Without Borders (MSF) emphasizes the critical humanitarian crisis in Gaza, exacerbated by Israeli military actions, a failing healthcare system, and limited humanitarian aid.",
      "MSF calls for an immediate ceasefire and urges international intervention to protect Palestinian lives and ensure the delivery of essential aid.",
      "The report describes Gaza as a \"death trap,\" highlighting widespread destruction, forced displacement, and severe health crises, resulting in thousands of deaths and a humanitarian catastrophe."
    ],
    "commentSummary": [
      "Doctors Without Borders has described the conflict in Gaza as genocide, highlighting the extensive destruction and humanitarian crisis.- The situation is critical, with substantial civilian casualties and damage to infrastructure, sparking debate on whether it legally qualifies as genocide, which involves proving intent to destroy a group.- The conflict is being compared to other historical and ongoing conflicts, prompting discussions on implications and possible solutions."
    ],
    "points": 235,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1734656993
  },
  {
    "id": 42473321,
    "title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB",
    "originLink": "https://arcprize.org/blog/oai-o3-pub-breakthrough",
    "originBody": "Home ARC-AGI 2024 Results Technical Guide Play Blog ARC Prize remains undefeated. New ideas still needed. Home ARC-AGI 2024 Results Technical Guide Play Blog 2025 Sign up 2025 Sign up By François Chollet Published 20 Dec 2024 OpenAI o3 Breakthrough High Score on ARC-AGI-Pub OpenAI's new o3 system - trained on the ARC-AGI-1 Public Training set - has scored a breakthrough 75.7% on the Semi-Private Evaluation set at our stated public leaderboard $10k compute limit. A high-compute (172x) o3 configuration scored 87.5%. This is a surprising and important step-function increase in AI capabilities, showing novel task adaptation ability never seen before in the GPT-family models. For context, ARC-AGI-1 took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3. The mission of ARC Prize goes beyond our first benchmark: to be a North Star towards AGI. And we're excited to be working with the OpenAI team and others next year to continue to design next-gen, enduring AGI benchmarks. ARC-AGI-2 (same format - verified easy for humans, harder for AI) will launch alongside ARC Prize 2025. We're committed to running the Grand Prize competition until a high-efficiency, open-source solution scoring 85% is created. Read on for the full testing report. OpenAI o3 ARC-AGI Results We tested o3 against two ARC-AGI datasets: Semi-Private Eval: 100 private tasks used to assess overfitting Public Eval: 400 public tasks At OpenAI's direction, we tested at two levels of compute with variable sample sizes: 6 (high-efficiency) and 1024 (low-efficiency, 172x compute). Here are the results. Set Tasks Efficiency Score Retail Cost Samples Tokens Cost/Task Time/Task (mins) Semi-Private 100 High 75.7% $2,012 6 33M $20 1.3 Semi-Private 100 Low 87.5% - - - - - Public 400 High 82.8% $6,677 6 111M $17 Public 400 Low 91.5% - - - - -- Note: OpenAI has requested that we not publish the high-compute costs. The amount of compute was roughly 172x the low-compute configuration. Due to variable inference budget, efficiency (e.g., compute cost) is now a required metric when reporting performance. We've documented both the total costs and the cost per task as an initial proxy for efficiency. As an industry, we'll need to figure out what metric best tracks efficiency, but directionally, cost is a solid starting point. The high-efficiency score of 75.7% is within the budget rules of ARC-AGI-Pub (costs <$10k) and therefore qualifies as 1st place on the public leaderboard! The low-efficiency score of 87.5% is quite expensive, but still shows that performance on novel tasks does improve with increased compute (at least up to this level.) Despite the significant cost per task, these numbers aren't just the result of applying brute force compute to the benchmark. OpenAI's new o3 model represents a significant leap forward in AI's ability to adapt to novel tasks. This is not merely incremental improvement, but a genuine breakthrough, marking a qualitative shift in AI capabilities compared to the prior limitations of LLMs. o3 is a system capable of adapting to tasks it has never encountered before, arguably approaching human-level performance in the ARC-AGI domain. Of course, such generality comes at a steep cost, and wouldn't quite be economical yet: you could pay a human to solve ARC-AGI tasks for roughly $5 per task (we know, we did that), while consuming mere cents in energy. Meanwhile o3 requires $17-20 per task in the low-compute mode. But cost-performance will likely improve quite dramatically over the next few months and years, so you should plan for these capabilities to become competitive with human work within a fairly short timeline. o3's improvement over the GPT series proves that architecture is everything. You couldn't throw more compute at GPT-4 and get these results. Simply scaling up the things we were doing from 2019 to 2023 – take the same architecture, train a bigger version on more data – is not enough. Further progress is about new ideas. So is it AGI? ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI – as we've repeated dozens of times this year. It's a research tool designed to focus attention on the most challenging unsolved problems in AI, a role it has fulfilled well over the past five years. Passing ARC-AGI does not equate to achieving AGI, and, as a matter of fact, I don't think o3 is AGI yet. o3 still fails on some very easy tasks, indicating fundamental differences with human intelligence. Furthermore, early data points suggest that the upcoming ARC-AGI-2 benchmark will still pose a significant challenge to o3, potentially reducing its score to under 30% even at high compute (while a smart human would still be able to score over 95% with no training). This demonstrates the continued possibility of creating challenging, unsaturated benchmarks without having to rely on expert domain knowledge. You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible. What's different about o3 compared to older models? Why does o3 score so much higher than o1? And why did o1 score so much higher than GPT-4o in the first place? I think this series of results provides invaluable data points for the ongoing pursuit of AGI. My mental model for LLMs is that they work as a repository of vector programs. When prompted, they will fetch the program that your prompt maps to and \"execute\" it on the input at hand. LLMs are a way to store and operationalize millions of useful mini-programs via passive exposure to human-generated content. This \"memorize, fetch, apply\" paradigm can achieve arbitrary levels of skills at arbitrary tasks given appropriate training data, but it cannot adapt to novelty or pick up new skills on the fly (which is to say that there is no fluid intelligence at play here.) This has been exemplified by the low performance of LLMs on ARC-AGI, the only benchmark specifically designed to measure adaptability to novelty – GPT-3 scored 0, GPT-4 scored near 0, GPT-4o got to 5%. Scaling up these models to the limits of what's possible wasn't getting ARC-AGI numbers anywhere near what basic brute enumeration could achieve years ago (up to 50%). To adapt to novelty, you need two things. First, you need knowledge – a set of reusable functions or programs to draw upon. LLMs have more than enough of that. Second, you need the ability to recombine these functions into a brand new program when facing a new task – a program that models the task at hand. Program synthesis. LLMs have long lacked this feature. The o series of models fixes that. For now, we can only speculate about the exact specifics of how o3 works. But o3's core mechanism appears to be natural language program search and execution within token space – at test time, the model searches over the space of possible Chains of Thought (CoTs) describing the steps required to solve the task, in a fashion perhaps not too dissimilar to AlphaZero-style Monte-Carlo tree search. In the case of o3, the search is presumably guided by some kind of evaluator model. To note, Demis Hassabis hinted back in a June 2023 interview that DeepMind had been researching this very idea – this line of work has been a long time coming. So while single-generation LLMs struggle with novelty, o3 overcomes this by generating and executing its own programs, where the program itself (the CoT) becomes the artifact of knowledge recombination. Although this is not the only viable approach to test-time knowledge recombination (you could also do test-time training, or search in latent space), it represents the current state-of-the-art as per these new ARC-AGI numbers. Effectively, o3 represents a form of deep learning-guided program search. The model does test-time search over a space of \"programs\" (in this case, natural language programs – the space of CoTs that describe the steps to solve the task at hand), guided by a deep learning prior (the base LLM). The reason why solving a single ARC-AGI task can end up taking up tens of millions of tokens and cost thousands of dollars is because this search process has to explore an enormous number of paths through program space – including backtracking. There are however two significant differences between what's happening here and what I meant when I previously described \"deep learning-guided program search\" as the best path to get to AGI. Crucially, the programs generated by o3 are natural language instructions (to be \"executed\" by a LLM) rather than executable symbolic programs. This means two things. First, that they cannot make contact with reality via execution and direct evaluation on the task – instead, they must be evaluated for fitness via another model, and the evaluation, lacking such grounding, might go wrong when operating out of distribution. Second, the system cannot autonomously acquire the ability to generate and evaluate these programs (the way a system like AlphaZero can learn to play a board game on its own.) Instead, it is reliant on expert-labeled, human-generated CoT data. It's not yet clear what the exact limitations of the new system are and how far it might scale. We'll need further testing to find out. Regardless, the current performance represents a remarkable achievement, and a clear confirmation that intuition-guided test-time search over program space is a powerful paradigm to build AI systems that can adapt to arbitrary tasks. What comes next? First of all, open-source replication of o3, facilitated by the ARC Prize competition in 2025, will be crucial to move the research community forward. A thorough analysis of o3's strengths and limitations is necessary to understand its scaling behavior, the nature of its potential bottlenecks, and anticipate what abilities further developments might unlock. Moreover, ARC-AGI-1 is now saturating – besides o3's new score, the fact is that a large ensemble of low-compute Kaggle solutions can now score 81% on the private eval. We're going to be raising the bar with a new version – ARC-AGI-2 - which has been in the works since 2022. It promises a major reset of the state-of-the-art. We want it to push the boundaries of AGI research with hard, high-signal evals that highlight current AI limitations. Our early ARC-AGI-2 testing suggests it will be useful and extremely challenging, even for o3. And, of course, ARC Prize's objective is to produce a high-efficiency and open-source solution in order to win the Grand Prize. We currently intend to launch ARC-AGI-2 alongside ARC Prize 2025 (estimated launch: late Q1). Going forward, the ARC Prize Foundation will continue to create new benchmarks to focus the attention of researchers on the hardest unsolved problems on the way to AGI. We've started work on a third-generation benchmark which departs completely from the 2019 ARC-AGI format and incorporates some exciting new ideas. Get Involved: Open-Source Analysis Today, we're also releasing high-compute, o3-labeled tasks and would like your help to analyze them. In particular, we are very curious about the ~9% set of Public Eval tasks o3 was unable to solve, even with lots of compute, yet are straightforward for humans. We invite the community to help us assess the characteristics of both solved and unsolved tasks. To get your ideas flowing, here are 3 examples of tasks unsolved by high-compute o3. ARC-AGI Task ID: c6e1b8da ARC-AGI Task ID: 0d87d2a6 ARC-AGI Task ID: b457fec5 See our full set of o3 testing data. We've also created a new channel in our Discord named oai-analysis and we'd love to hear your analysis and insights there. Or tag us on X/Twitter @arcprize. Conclusions To sum up – o3 represents a significant leap forward. Its performance on ARC-AGI highlights a genuine breakthrough in adaptability and generalization, in a way that no other benchmark could have made as explicit. o3 fixes the fundamental limitation of the LLM paradigm – the inability to recombine knowledge at test time – and it does so via a form of LLM-guided natural language program search. This is not just incremental progress; it is new territory, and it demands serious scientific attention. Sign up to get updates Newsletter Discord Twitter YouTube GitHub © 2024 ARC Prize, Inc. Privacy Terms A non-profit for the public advancement of open artificial general intelligence. All rights reserved. ARC Prize : 2025 We expect to re-launch ARC Prize in Q1 2025. Sign up now to receive official competition updates and news. Sign Up No spam. You can unsubscribe at anytime. ARC Prize : Newsletter Subscribe to receive official competition updates and news. Subscribe No spam. You can unsubscribe at anytime. Toggle Animation",
    "commentLink": "https://news.ycombinator.com/item?id=42473321",
    "commentBody": "OpenAI O3 breakthrough high score on ARC-AGI-PUB (arcprize.org)222 points by maurycy 49 minutes agohidepastfavorite120 comments modeless 37 minutes agoCongratulations to Francois Chollet on making the most interesting and challenging LLM benchmark so far. A lot of people have criticized ARC as not being relevant or indicative of true reasoning, but I think it was exactly the right thing. The fact that scaled reasoning models are finally showing progress on ARC proves that what it measures really is relevant and important for reasoning. It's obvious to everyone that these models can't perform as well as humans on everyday tasks despite blowout scores on the hardest tests we give to humans. Yet nobody could quantify exactly the ways the models were deficient. ARC is the best effort in that direction so far. We don't need more \"hard\" benchmarks. What we need right now are \"easy\" benchmarks that these models nevertheless fail. I hope Francois has something good cooked up for ARC 2! reply dtquad 34 minutes agoparentAre there any single-step non-reasoner models that do well on this benchmark? I wonder how well the latest Claude 3.5 Sonnet does on this benchmark and if it's near o1. reply throwaway71271 29 minutes agorootparentnext [–]Name| Semi-private evalPublic eval|--------------------------------------|-------------------|-------------|Jeremy Berman53.6%58.5%| Akyürek et al.47.5%62.8%| Ryan Greenblatt43%42%| OpenAI o1-preview (pass@1)18%21%| Anthropic Claude 3.5 Sonnet (pass@1)14%21%| OpenAI GPT-4o (pass@1)5%9%| Google Gemini 1.5 (pass@1)4.5%8%https://arxiv.org/pdf/2412.04604 reply YetAnotherNick 29 minutes agorootparentprevHere are the results for base models[1]: o3 (coming soon) 75.7% 82.8% o1-preview 18% 21% Claude 3.5 Sonnet 14% 21% GPT-4o 5% 9% Gemini 1.5 4.5% 8% Score (semi-private eval) / Score (public eval) [1]: https://arcprize.org/2024-results reply refulgentis 20 minutes agoparentprevThis emphasizes persons and a self-conceived victory narrative over the ground truth. Models have regularly made progress on it, this is not new with the o-series. Doing astoundingly well on it, and having a mutually shared PR interest with OpenAI in this instance, doesn't mean a pile of visual puzzles is actually AGI or some well thought exploration of True Intelligence(tm). It's one type of visual puzzle. I don't mean to be negative, but to inject a memento mori. Real story is some guys get together and ride off Chollet's name with some visual puzzles from ye olde IQ test, and the deal was Chollet then gets to show up and say it proves program synthesis is required for True Intelligence. Getting this score is extremely impressive but I don't assign more signal to it than any other benchmark with some thought to it. reply modeless 11 minutes agorootparentSolving ARC doesn't mean we have AGI. Also o3 presumably isn't doing program synthesis, seemingly proving Francois wrong on that front. (Not sure I believe the speculation about o3's internals in the link.) What I'm saying is the fact that as models are getting better at reasoning they are also scoring better on ARC proves that it is measuring something relating to reasoning. And nobody else has come up with a comparable benchmark that is so easy for humans and so hard for LLMs. Even today, let alone five years ago when ARC was released. ARC was visionary. reply zebomon 35 minutes agoprevMy initial impression: it's very impressive and very exciting. My skeptical impression: it's complete hubris to conflate ARC or any benchmark with truly general intelligence. I know my skepticism here is identical to moving goalposts. More and more I am shifting my personal understanding of general intelligence as a phenomenon we will only ever be able to identify with the benefit of substantial retrospect. As it is with any sufficiently complex program, if you could discern the result beforehand, you wouldn't have had to execute the program in the first place. I'm not trying to be a downer on the 12th day of Christmas. Perhaps because my first instinct is childlike excitement, I'm trying to temper it with a little reason. reply sigmoid10 22 minutes agoparentThese comments are getting ridiculous. I remember when this test was first discussed here on HN and everyone agreed that it clearly proves current AI models are not \"intelligent\" (whatever that means). And people tried to talk me down when I theorised this test will get nuked soon - like all the ones before. It's time people woke up and realised that the old age of AI is over. This new kind is here to stay and it will take over the world. And you better guess it'll be sooner rather than later and start to prepare. reply lawlessone 5 minutes agorootparentFailing the test may prove the AI is not intelligent. Passing the test doesn't necessarily prove it is. reply samvher 20 minutes agorootparentprevWhat kind of preparation are you suggesting? reply johnny_canuck 4 minutes agorootparentStart learning a trade reply sigmoid10 14 minutes agorootparentprevThis is far too broad to summarise here. You can read up on Sutskever or Bostrom or hell even Steven Hawking's ideas (going in order from really deep to general topics). We need to discuss everything - from education over jobs and taxes all the way to the principles of politics, our economy and even the military. If we fail at this as a society, we will at the very least create a world where the people who own capital today massively benefit and become rich beyond imagination (despite having contributed nothing to it), while the majority of the population will be unemployable and forever left behind. And the worst case probably falls somewhere between the end of human civilisation and the end of our species. reply kelseyfrog 11 minutes agorootparentWhat we're going to do is punt the questions and then convince ourselves the outcome was inevitable and if anything it's actually our fault. reply foobarqux 9 minutes agorootparentprevYou should look up the terms necessary and sufficient. reply sigmoid10 2 minutes agorootparentThe real issue is people constantly making up new goalposts to keep their outdated world view somewhat aligned with what we are seeing. But these two things are drifting apart faster and faster. Even I got surprised by how quickly the ARC benchmark was blown out of the water, and I'm pretty bullish on AI. reply hansonkd 29 minutes agoparentprevIt doesn't need to be general intelligence or perfectly map to human intelligence. All it needs to be is useful. Reading constant comments about LLMs can't be general intelligence or lack reasoning etc, to me seems like people witnessing the airplane and complaining that it isn't \"real flying\" because it isn't a bird flapping its wings (a large portion of the population held that point of view back then). It doesn't need to be general intelligence for the rapid advancement of LLM capabilities to be the most societal shifting development in the past decades. reply surgical_fire 12 minutes agorootparent> to me seems like people witnessing the airplane and complaining that it isn't \"real flying\" because it isn't a bird flapping its wings To me it is more like there is someone jumping on a pogo ball while flapping their arms and saying that they are flying. Whenever they hop off the ground. Skeptics say that they are not really flying, while adherents say that \"with current pogo ball advancements, they will be flying any day now\" reply billyp-rva 3 minutes agorootparentprev> It doesn't need to be general intelligence or perfectly map to human intelligence. > All it needs to be is useful. Computers were already useful. The only definition we have for \"intelligence\" is human (or, generally, animal) intelligence. If LLMs aren't that, let's call it something else. reply handsclean 12 minutes agorootparentprevPeople aren’t responding to their own assumption that AGI is necessary, they’re responding to OpenAI and the chorus constantly and loudly singing hymns to AGI. reply zebomon 27 minutes agorootparentprevI agree. If the LLMs we have today never got any smarter, the world would still be transformed over the next ten years. reply AyyEye 17 minutes agorootparentprev> Reading constant comments about LLMs can't be general intelligence or lack reasoning etc, to me seems like people witnessing the airplane and complaining that it isn't \"real flying\" because it isn't a bird flapping its wings (a large portion of the population held that point of view back then). That is a natural reaction to the incessant techbro, AIbro, marketing, and corporate lies that \"AI\" (or worse AGI) is a real thing, and can be directly compared to real humans. There are people on this very thread saying it's better at reasoning than real humans (LOL) because it scored higher on some benchmark than humans... Yet this technology still can't reliably determine what number is circled, if two lines intersect, or count the letters in a word. (That said behaviour may have been somewhat finetuned out of newer models only reinforces the fact that it's inherently not capable of understanding anything.) reply amarcheschi 30 minutes agoparentprevI just googled arc agi questions, and it looks like it is similar to an iq test with raven matrix. Similar as in you have some examples of images before and after, then an image before and you have to guess the after. Could anyone confirm if this is the only kind of questions in the benchmark? If yes, how come there is such a direct connection to \"oh this performs better than humans\" when llm can be quite better than us in understanding and forecasting patterns? I'm just curious, not trying to stir up controversies reply zebomon 26 minutes agorootparentIt's a test on which (apparently until now) the vast majority of humans have far outperformed all machine systems. reply patrickhogan1 23 minutes agorootparentBut it’s not a test that directly shows general intelligence. I am excited no less! This is huge improvement. How does this do on SWE Bench? reply og_kalu 18 minutes agorootparent>How does this do on SWE Bench? 71.7% reply Eridrus 17 minutes agorootparentprevML is quite good at understanding and forecasting patterns when you train on the data you want to forecast. LLMs manage to do so much because we just decided to train on everything on the internet and hope that it included everything we ever wanted to know. This tries to create patterns that are intentionally not in the data and see if a system can generalize to them, which o3 super impressively does! reply ALittleLight 24 minutes agorootparentprevYes, it's pretty similar to Raven's. The reason it is an interesting benchmark is because humans, even very young humans, \"get\" the test in the sense of understanding what it's asking and being able to do pretty well on it - but LLMs have really struggled with the benchmark in the past. Chollett (one of the creators of the ARC benchmark) has been saying it proves LLMs can't reason. The test questions are supposed to be unique and not in the model's training set. The fact that LLMs struggled with the ARC challenge suggested (to Chollett and others) that models weren't \"Truly reasoning\" but rather just completing based on things they'd seen before - when the models were confronted with things they hadn't seen before, the novel visual patterns, they really struggled. reply wslh 15 minutes agoparentprev> My skeptical impression: it's complete hubris to conflate ARC or any benchmark with truly general intelligence. But isn’t it interesting to have several benchmarks? Even if it’s not about passing the Turing test, benchmarks serve a purpose—similar to how we measure microprocessors or other devices. Intelligence may be more elusive, but even if we had an oracle delivering the ultimate intelligence benchmark, we'd still argue about its limitations. Perhaps we'd claim it doesn't measure creativity well, and we'd find ourselves revisiting the same debates about different kinds of intelligences. reply zebomon 13 minutes agorootparentIt's certainly interesting. I'm just not convinced it's a test of general intelligence, and I don't think we'll know whether or not it is until it's been able to operate in the real world to the same degree that our general intelligence does. reply m3kw9 16 minutes agoparentprevFrom the statement where - this is a pretty tough test where AI scores low vs humans just last year, and AI can do it as good as humans may not be AGI which I agree, but it means something with all caps reply FrustratedMonky 17 minutes agoparentprev\" it's complete hubris to conflate ARC or any benchmark with truly general intelligence.\" Maybe it would help to include some human results in the AI ranking. I think we'd find that Humans score lower? reply kelseyfrog 13 minutes agoparentprev> truly general intelligence Indistinguishable from goalpost moving like you said, but also no true Scotsman. I'm curious what would happen in your eyes if we misattributed general intelligence to an AI model? What are the consequences of a false positive and how would they affect your life? It's really clear to me how intelligence fits into our reality as part of our social ontology. The attributes and their expression that each of us uses to ground our concept of the intelligent predicate differs wildly. My personal theory is that we tend to have an exemplar-based dataset of intelligence, and each of us attempts to construct a parsimonious model of intelligence, but like all (mental) models, they can be useful but wrong. These models operate in a space where the trade off is completeness or consistency, and most folks, uncomfortable saying \"I don't know\" lean toward being complete in their specification rather than consistent. The unfortunate side-effect is that we're able to easily generate test data that highlights our model inconsistency - AI being a case in point. reply obblekk 28 minutes agoprevHuman performance is 85% [1]. o3 high gets 87.5%. This means we have an algorithm to get to human level performance on this task. If you think this task is an eval of general reasoning ability, we have an algorithm for that now. There's a lot of work ahead to generalize o3 performance to all domains. I think this explains why many researchers feel AGI is within reach, now that we have an algorithm that works. Congrats to both Francois Chollet for developing this compelling eval, and to the researchers who saturated it! [1] https://x.com/SmokeAwayyy/status/1870171624403808366, https://arxiv.org/html/2409.01374v1 reply phillipcarter 26 minutes agoparentAs excited as I am by this, I still feel like this is still just a small approximation of a small chunk of human reasoning ability at large. o3 (and whatever comes next) feels to me like it will head down the path of being a reasoning coprocessor for various tasks. But, still, this is incredibly impressive. reply antirez 2 minutes agoparentprevNNs are not algorithms. reply cryptoegorophy 18 minutes agoparentprevWhat’s interesting is it might be very close to human intelligence than some “alien” intelligence, because after all it is a LLM and trained on human made text, which kind of represents human intelligence. reply hammock 12 minutes agorootparentIn that vein, perhaps the delta between o3 @ 87.5% and Human @ 85% represents a deficit in the ability of text to communicate human reasoning. In other words, it's possible humans can reason better than o3, but cannot articulate that reasoning as well through text - only in our heads, or through some alternative medium. reply 85392_school 6 minutes agorootparentI wonder how much of an effect amount of time to answer has on human performance. reply scotty79 21 minutes agoparentprevStill it's comparing average human level performance with best AI performance. Examples of things o3 failed at are insanely easy for humans. reply ALittleLight 22 minutes agoparentprevIt's not saturated. 85% is average human performance, not \"best human\" performance. There is still room for the model to go up to 100% on this eval. reply yawnxyz 33 minutes agoprevO3 High (tuned) model scored an 88% at what looks like $6,000/task haha I think soon we'll be pricing any kind of tasks by their compute costs. So basically, human = $50/task, AI = $6,000/task, use human. If AI beats human, use AI? Ofc that's considering both get 100% scores on the task reply og_kalu 0 minutes agoparentIt's not 6000/task (i.e per question). 6000 is about the retail cost for evaluating the entire benchmark on high compute (about 400 questions) reply cchance 29 minutes agoparentprevIsn't that generally what ... all jobs are? Automation Cost vs Longterm Human cost... its why amazon did the weird \"our stores are AI driven\" but in reality was cheaper to higher a bunch of guys in a sweat shop to look at the cameras and write things down lol. The thing is given what we've seen from distillation and tech, even if its 6,000/task... that will come down drastically over time through optimization and just... faster more efficient processing hardware and software. reply cryptoegorophy 15 minutes agorootparentI remember hearing Tesla trying to automate all of production but some things just couldn’t , like the wiring which humans still had to do. reply freehorse 6 minutes agoparentprevThis makes me think and speculate if the solution comprises of a \"solver\" trying semi-random or more targeted things and a \"checker\" checking these? Usually checking a solution is cognitively (and computationally) easier than coming up with it. Else I cannot think what sort of compute would burn 6000$ per task, unless you are going through a lot of loops and you have somehow solved the part of the problem that can figure out if a solution is correct or not, while coming up with the actual correct solution is not as solved yet to the same degree. Or maybe I am just naive and these prices are just like breakfast for companies like that. reply Benjaminsen 16 minutes agoparentprevCompute costs on AI with the same roughly the same capabilities have been halving every ~7 months. That makes something like this competitive in ~3 years reply jsheard 28 minutes agoparentprevThat's the elephant in the room with the reasoning/COT approach, it shifts what was previously a scaling of training costs into scaling of training and inference costs. The promise of doing expensive training once and then running the model cheaply forever falls apart once you're burning tens, hundreds or thousands of dollars worth of compute every time you run a query. reply Legend2440 20 minutes agorootparentYeah, but next year they'll come out with a faster GPU, and the year after that another still faster one, and so on. Compute costs are a temporary problem. reply redeux 27 minutes agoparentprevTime and availability would also be factors. reply dyauspitr 28 minutes agoparentprevCompute can get optimized and cheap quickly. reply Imnimo 26 minutes agoprevWhenever a benchmark that was thought to be extremely difficult is (nearly) solved, it's a mix of two causes. One is that progress on AI capabilities was faster than we expected, and the other is that there was an approach that made the task easier than we expected. I feel like the there's a lot of the former here, but the compute cost per task (thousands of dollars to solve one little color grid puzzle??) suggests to me that there's some amount of the latter. Chollet also mentions ARC-AGI-2 might be more resistant to this approach. Of course, o3 looks strong on other benchmarks as well, and sometimes \"spend a huge amount of compute for one problem\" is a great feature to have available if it gets you the answer you needed. So even if there's some amount of \"ARC-AGI wasn't quite as robust as we thought\", o3 is clearly a very powerful model. reply exe34 15 minutes agoparent> the other is that there was an approach that made the task easier than we expected. from reading Dennett's philosophy, I'm convinced that that's how human intelligence works - for each task that \"only a human could do that\", there's a trick that makes it easier than it seems. We are bags of tricks. reply vessenes 6 minutes agoprevThis feels like big news to me. First of all, ARC is definitely an intelligence test for autistic people. I say as someone with a tad of the neurodiversity. That said, I think it's a pretty interesting one, not least because as you go up in the levels, it requires (for a human) a fair amount of lateral thinking and analogy-type thinking, and of course, it requires that this go in and out of visual representation. That said, I think it's a bit funny that most of the people training these next-gen AIs are neurodiverse and we are training the AI in our own image. I continue to hope for some poet and painter-derived intelligence tests to be added to the next gen tests we all look at and score. For those reasons, I've always really liked ARC as a test -- not as some be-all end-all for AGI, but just because I think that the most intriguing areas next for LLMs are in these analogy arenas and ability to hold more cross-domain context together for reasoning and etc. Prompts that are interesting to play with right now on these terms range from asking multimodal models to say count to ten in a Boston accent, and then propose a regional french accent that's an equivalent and count to ten in that. (To my ear, 4o is unconvincing on this). Similar in my mind is writing and architecting code that crosses multiple languages and APIs, and asking for it to be written in different styles. (claude and o1-pro are .. okay at this, depending). Anyway. I agree that this looks like a large step change. I'm not sure if the o3 methods here involve the spinning up of clusters of python interpreters to breadth-search for solutions -- a method used to make headway on ARC in the past; if so, this is still big, but I think less exciting than if the stack is close to what we know today, and the compute time is just more introspection / internal beam search type algorithms. Either way, something had to assess answers and think they were right, and this is a HUGE step forward. reply jamiek88 2 minutes agoparent> most of the people training these next-gen AIs are neurodiverse Citation needed. This is a huge claim based only on stereotype. reply croemer 14 minutes agoprevThe programming task they gave o3-mini high (creating Python server that allows chatting with OpenAI API and run some code in terminal) didn't seem very hard? Strange choice of example for something that's claimed to be a big step forwards. YT timestamped link: https://www.youtube.com/watch?v=SKBG1sqdyIU&t=768s (thanks for the fixed link @photonboom) Updated: I gave the task to Claude 3.5 Sonnet and it worked first shot: https://claude.site/artifacts/36cecd49-0e0b-4a8c-befa-faa5aa... reply photonboom 3 minutes agoparentheres the right timestamp: https://www.youtube.com/watch?v=SKBG1sqdyIU&t=768s reply bearjaws 10 minutes agoparentprevIt's good that it works since if you ask GPT-4o to use the openai sdk it will often produce invalid and out of date code. reply m3kw9 6 minutes agoparentprevI would say they didn’t need to demo anything, because if you are gonna use the output code live on a demo it may make compile errors and then look stupid trying to fix it live reply attentionmech 34 minutes agoprevIsn't this at the level now where it can sort of self improve. My guess is that they will just use it to improve the model and the cost they are showing per evaluation will go down drastically. So, next step in reasoning is open world reasoning now? reply whoistraitor 22 minutes agoprevThe general message here seems to be that inference-time brute-forcing works as long as you have a good search and evaluation strategy. We’ve seemingly hit a ceiling on the base LLM forward-pass capability so any further wins are going to be in how we juggle multiple inferences to solve the problem space. It feels like a scripting problem now. Which is cool! A fun space for hacker-engineers. Also: > My mental model for LLMs is that they work as a repository of vector programs. When prompted, they will fetch the program that your prompt maps to and \"execute\" it on the input at hand. LLMs are a way to store and operationalize millions of useful mini-programs via passive exposure to human-generated content. I found this such an intriguing way of thinking about it. reply spaceman_2020 31 minutes agoprevJust as an aside, I've personally found o1 to be completely useless for coding. Sonnet 3.5 remains the king of the hill by quite some margin reply InkCanon 1 minute agoparentI just asked o1 a simple yes or no question about x86 atomics and it did one of those A or B replies. The first answer was yes, the second answer was no. reply og_kalu 28 minutes agoparentprevTo be fair, until the last checkpoint released 2 days ago, o1 didn't really beat sonnet (and if so, barely) in most non-competitive coding benchmarks reply vessenes 15 minutes agoparentprevTo fill this out, I find o1-pro (and -preview when it was live) to be pretty good at filling in blindspots/spotting holistic bugs. I use Claude for day to day, and when Claude is spinning, o1 often can point out why. It's too slow for AI coding, and I agree that at default its responses aren't always satisfying. That said, I think its code style is arguably better, more concise and has better patterns -- Claude needs a fair amount of prompting and oversight to not put out semi-shitty code in terms of structure and architecture. In my mind: going from Slowest to Fastest, and Best Holistically to Worst, the list is: 1. o1-pro 2. Claude 3.5 3. Gemini 2 Flash Flash is so fast, that it's tempting to use more, but it really needs to be kept to specific work on strong codebases without complex interactions. reply bearjaws 9 minutes agoparentprevo1 is pretty good at spotting OWASP defects, compared to most other models. https://myswamp.substack.com/p/benchmarking-llms-against-com... reply cchance 28 minutes agoparentprevThe new gemini's are pretty good too reply lysecret 17 minutes agorootparentActually prefer new geminis too. 2.0 experimental especially. reply smy20011 31 minutes agoprevIt seems O3 following trend of Chess engine that you can cut your search depth depends on state. It's good for games with clear signal of success (Win/Lose for Chess, tests for programming). One of the blocker for AGI is we don't have clear evaluation for most of our tasks and we cannot verify them fast enough. reply flakiness 29 minutes agoprevThe cost axis is interesting. O3 Low is $10+ per task and 03 High is over $1000 (it's logarithmic graph so it's like $50 and $5000 respectively?) reply Bjorkbat 9 minutes agoprevI was impressed until I read the caveat about the high-compute version using 172x more compute. Assuming for a moment that the cost per task has a linear relationship with compute, then it costs a little more than $1 million to get that score on the public eval. The results are cool, but man, this sounds like such a busted approach. reply futureshock 0 minutes agoparentSo what? I’m serious. Our current level of progress would have been sci-fi fantasy with the computers we had in 2000. The cost may be astronomical today, but we have proven a method to achieve human performance on tests of reasoning over novel problems. WOW. Who cares what it costs. In 25 years it will run on your phone. reply blixt 8 minutes agoprevThese results are fantastic. Claude 3.5 and o1 are already good enough to provide value, so I can't wait to see how o3 performs comparatively in real-world scenarios. But I gotta say, we must be saturating just about any zero-shot reasoning benchmark imaginable at this point. And we will still argue about whether this is AGI, in my opinion because these LLMs are forgetful and it's very difficult for an application developer to fix that. Models will need better ways to remember and learn from doing a task over and over. For example, let's look at code agents: the best we can do, even with o3, is to cram as much of the code base as we can fit into a context window. And if it doesn't fit we branch out to multiple models to prune the context window until it does fit. And here's the kicker – the second time you ask for it to do something this all starts over from zero again. With this amount of reasoning power, I'm hoping session-based learning becomes the next frontier for LLM capabilities. (There are already things like tool use, linear attention, RAG, etc that can help here but currently they come with downsides and I would consider them insufficient.) reply onemetwo 9 minutes agoprevIn (1) the author use a technique to improve the performance of an LLM, he trained sonnet 3.5 to obtain 53,6% in the arc-agi-pub benchmark moreover he said that more computer power would give better results. So the results of o3 could be produced in this way using the same method with more computer power, so if this is the case the result of o3 is not very interesting. (1) https://params.com/@jeremy-berman/arc-agi reply mensetmanusman 19 minutes agoprevI’m super curious as to whether this technology completely destroys the middle class, or if everyone becomes better off because productivity is going to skyrocket. reply wilg 37 minutes agoprevfun! the benchmarks are so interesting because real world use is so variable. sometimes 4o will nail a pretty difficult problem, other times o1 pro mode will fail 10 times on what i would think is a pretty easy programming problem and i waste more time trying to do it with ai reply cryptoegorophy 21 minutes agoprevBesides higher scores - is there any improvements for a general use? Like asking to help setup home assistant etc etc? reply neom 36 minutes agoprevWhy would they give a cost estimate per task on their low compute mode but not their high mode? \"low compute\" mode: Uses 6 samples per task, Uses 33M tokens for the semi-private eval set, Costs $17-20 per task, Achieves 75.7% accuracy on semi-private eval The \"high compute\" mode: Uses 1024 samples per task (172x more compute), Cost data was withheld at OpenAI's request, Achieves 87.5% accuracy on semi-private eval Can we just extrapolate $3kish per task on high compute? (wondering if they're withheld because this isn't the case?) reply tripletao 10 minutes agoprevTheir discussion contains an interesting aside: > Moreover, ARC-AGI-1 is now saturating – besides o3's new score, the fact is that a large ensemble of low-compute Kaggle solutions can now score 81% on the private eval. So while these tasks get greatest interest as a benchmark for LLMs and other large general models, it doesn't yet seem obvious those outperform human-designed domain-specific approaches. I wonder to what extent the large improvement comes from OpenAI training deliberately targeting this class of problem. That result would still be significant (since there's no way to overfit to the private tasks), but would be different from an \"accidental\" emergent improvement. reply TypicalHog 9 minutes agoprevThis is actually mindblowing! reply cchance 22 minutes agoprevIs it just me or does looking at the ARC-AGI example questions at the bottom... make your brain hurt? reply drdaeman 10 minutes agoparentLooks pretty obvious to me, although, of course, it took me a few moments to understand what's expected as a solution. c6e1b8da is moving rectangular figures by a given vector, 0d87d2a6 is drawing horizontal and/or vertical lines (connecting dots at the edges) and filling figures they touch, b457fec5 is filling gray figures with a given repeating color pattern. This is pretty straightforward stuff that doesn't require much spatial thinking or keeping multiple things/aspects in memory - visual puzzles from various \"IQ\" tests are way harder. This said, now I'm curious how SoTA LLMs would do on something like WAIS-IV. reply airstrike 22 minutes agoprevUhh...some of us are apparently living under a rock, as this is the first time I hear about o3 and I'm on HN far too much every day reply rvz 20 minutes agoprevGreat results. However, let's all just admit it. It has well replaced journalists, artists and on its way to replace nearly both junior and senior engineers. The ultimate intention of \"AGI\" is that it is going to replace tens of millions of jobs. That is it and you know it. It will only accelerate and we need to stop pretending and coping. Instead lets discuss solutions for those lost jobs. So what is the replacement for these lost jobs? (It is not UBI or \"better jobs\" without defining them.) reply neom 17 minutes agoparentDo you follow Jack Clark? I noticed he's been on the road a lot talking to governments and policy makers, and not just in the \"AI is coming\" way he used to talk. reply og_kalu 41 minutes agoprevThis is also wildly ahead in SWE-bench (71.7%, previous 48%) and Frontier Math (25% on high compute, previous 2%). So much for a plateau lol. reply throwup238 35 minutes agoparent> So much for a plateau lol. It’s been really interesting to watch all the internet pundits takes on the plateau… as if the two years since the release of GPT3.5 is somehow enough data for an armchair ponce to predict the performance characteristics of an entirely novel technology that no one understands. reply jgalt212 27 minutes agorootparentYou could make an equivalently dismissive comment about the hypesters. reply throwup238 12 minutes agorootparentYeah but anyone with half a brain knows to ignore them. Vapid cynicism is a lot more seductive to the average nerd. reply attentionmech 32 minutes agoparentprevI legit see that if there is not even a new breakthrough just one week, people start shouting plateau plateau.. Our rate of progress is extraordinary and any downplay of it seems like stupid reply OsrsNeedsf2P 18 minutes agoparentprevAt 6,670$/task? I hope there's a jump reply og_kalu 6 minutes agorootparentIt's not 6,670$/task. That was the high compute cost for 400 questions. reply optimalsolver 31 minutes agoparentprev>Frontier Math (25% on high compute, previous 2%) This is so insane that I can't help but be skeptical. I know FM answer key is private, but they have to send the questions to OpenAI in order to score the models. And a significant jump on this benchmark sure would increase a company's valuation... Happy to be wrong on this. reply braden-lk 38 minutes agoprevIf people constantly have to ask if your test is a measure of AGI, maybe it should be renamed to something else. reply OfficialTurkey 29 minutes agoparentFrom the post > Passing ARC-AGI does not equate achieving AGI, and, as a matter of fact, I don't think o3 is AGI yet. o3 still fails on some very easy tasks, indicating fundamental differences with human intelligence. reply cchance 26 minutes agorootparentIts funny when they say this, as if all humans can solve basic ass question/answer combos, people seem to forget theirs a percentage of the population that honestly believe the world is flat along with other hallucinations at the human level reply jppittma 15 minutes agorootparentI don't believe AGI at that level has any commercial value. reply maxdoop 39 minutes agoprevHow much longer can I get paid $150k to write code ? reply arrosenberg 0 minutes agoparentUnless the LLMs see multiple leaps in capability, probably indefinitely. The Malthusians in this thread think that LLMs are going to fix the human problems involved in these businesses - they won't. They make programmers more productive and make cost some jobs at the margins, but it will be the low-level programming work that was previously outsourced to Asia and South America for cost-arbitrage. reply prmph 29 minutes agoparentprevI’ll believe the models can take the jobs of programmers when they can generate a sophisticated iOS app based on some simple prompts, ready for building and publication in the app store. That is nowhere near the horizon no matter how much things are hyped up, and it may well never arrive. reply timenotwasted 24 minutes agorootparentThe absolutist type comments are such a wild take given how often they are so wrong. reply tsunamifury 22 minutes agorootparentTotally... simple increases in 20% efficiency will already significant destroy demand for coders. This forum however will be resistant to admit such economic phenomenon. Look at video bay editing after the advent of Final Cut. Significant drop in the specialized requirement as a professional field, even while content volume went up dramatically. reply exitb 7 minutes agorootparentComputing has been transforming countless jobs before it got to Final Cut. On one hand, programming is not the hardest job out there. On the other, it takes months to fully onboard a human developer - a person that already has years of relevant education and work experience. There are desk jobs that onboard new hires in days instead. Let’s see when they’re displaced by AI first. reply torginus 2 minutes agoparentprevWell, considering they floated the $2000 subscription idea, and they still haven't revealed everything, they could still introduce the $2k sub with o3+agents/tool use, which means, till about next week. reply sss111 21 minutes agoparentprev3 to 5 years, max. Traditional coding is going to be dead in the water. Optimistically, the junior SWE job will evolve but more realistically dedicated AI-based programming agents will end demand for Junior SWEs reply deadbabe 28 minutes agoparentprevThere’s a very good chance that if a company can replace its programmers with pure AI then it means whatever they’re doing is probably already being offered as a SaaS product so why not just skip the AI and buy that? Much cheaper and you don’t have to worry about dealing with bugs. reply colesantiago 33 minutes agoparentprevFrontier expert specialist programmers will always be in demand. Generalist junior and senior engineers will need to think of a different career path in less than 5 years as more layoffs will reduce the software engineering workforce. It looks like it may be the way things are if progress in the o1, o3, oN models and other LLMs continues on. reply deadbabe 25 minutes agorootparentThis assumes that software products in the future will remain at the same complexity as they are today, just with AI building them out. But they won’t. AI will enable building even more complex software which counter intuitively will result in need even more human jobs to deal with this added complexity. Think about how despite an increasing amount of free open source libraries over time enabling some powerful stuff easily, developer jobs have only increased, not decreased. reply tsunamifury 36 minutes agoparentprevOften what happens is the golf-course phenomenon. As golfing gets less popular, low and mid tier golf courses go out of business as they simply aren't needed. But at the same time demand for high end golf courses actually skyrockets because people who want to golf either can give it up or go higher end. This I think will happen with programmers. Rote programming will slowly die out, while demand for super high end will go dramatically up in price. reply CapcomGo 32 minutes agorootparentWhere does this golf-course phenomenon come from? It doesn't really match the real world or how golfing works. reply tsunamifury 25 minutes agorootparenthow so, witnessed it quite directly in California. Majority have closed and remaining have gone up in price and are up scale. This has been covered in various new programs like 60 minutes. You can look up death of golfing. Also unsure what you mean by...'how golfing works'. This is the economics of it, not the game reply razodactyl 42 minutes agoprevGreat. Now we have to think of a new way to move the goalposts. reply a_wild_dandan 18 minutes agoparentLet's just define AI as \"whatever computers still can't do.\" That'll show those dumb statistical parrots! reply Pesthuf 31 minutes agoparentprevWell right now, running this model is really expensive, but we should prepare a new cope for when equivalent models no longer are, ahead of time. reply cchance 25 minutes agorootparentYa getting costs down will be the big one, i imagine quantization, distillation and lots and lots of improvements on the compute side both hardware and software wise. reply dboreham 15 minutes agoparentprevImagine how the Neanderthals felt... reply tines 41 minutes agoparentprevI mean, what else do you call learning? reply behnamoh 37 minutes agoprev [–] So now not only are the models closed, but so are their evals?! This is a \"semi-private\" eval. WTH is that supposed to mean? I'm sure the model is great but I refuse to take their word for it. reply ZeroCool2u 22 minutes agoparentThe private evaluation set is private from the public/OpenAI so companies can't train on those problems and cheat their way to a high score by overfitting. reply jsheard 15 minutes agorootparentIf the models run on OpenAIs servers then surely they could still see the questions being put into it if they wanted to cheat? That could only be prevented by making the evaluation a one-time deal that can't be repeated, or by having OpenAI distribute their models for evaluators to run themselves, which I doubt they're inclined to do. reply cchance 21 minutes agoparentprev [–] the evals are the question/answers, ARC-AGI doesn't share the questions and answers for a portion so that models can't be trained on them, the public ones... the public knows the questions so theres a chance they could have been at least partially been trained on the question (if not the actual answer). Thats how i understand it reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI's new o3 system achieved a 75.7% score on the ARC-AGI Semi-Private Evaluation set, showcasing a significant advancement in AI capabilities compared to previous models like GPT-4o.",
      "The o3 model's ability to adapt to novel tasks marks a crucial step towards Artificial General Intelligence (AGI), despite the high costs associated with its development.",
      "The ARC Prize encourages open-source solutions that score 85% or higher, and the upcoming ARC-AGI-2 benchmark will further test AI models, pushing the limits of AGI research."
    ],
    "commentSummary": [
      "OpenAI's O3 model scored highly on the ARC-AGI-PUB benchmark, igniting discussions about its implications for AI reasoning capabilities.",
      "The model's success indicates progress in AI reasoning but also underscores the need for more accessible benchmarks due to high compute costs.",
      "There is ongoing debate about whether AI advancements will replace jobs or enhance productivity, with divided opinions on AI's future impact on the workforce."
    ],
    "points": 227,
    "commentCount": 123,
    "retryCount": 0,
    "time": 1734718273
  },
  {
    "id": 42465378,
    "title": "Hardware Security Exploit Research – Xbox 360",
    "originLink": "https://github.com/kooscode/srgh-matrix-trinity/blob/main/README.md",
    "originBody": "Hardware Security Exploit Research - XBOX 360 I'm fairly well versed with original XBOX and writing home-brew code for it 20 years ago, but I have since not spent much time on the XBOX 360 or XBOX One platforms beyond tons of gaming and I have always been interrested in how exactly the XBOX 360 security was defeated. So - here is a hopefully informative write up of my Journey to figuring out how these guys were running unsigned code in 2011 on a XBOX 360.. Buckle up.. its a long read :) Original XBOX (Released 2001) The Original XBOX was released in 2001 and the security of that system was defeated by hardware reverse engineering fairly soon after launch and folks were able to run Linux on the system. There mistakes made in the security for the original XBOX, the biggest of them were probably the basic oversights around implementation of weak and outdated security encryption algorithms used as hashing algorithms. The system saw 6 hardware revisions through its short 4 year life span and every single one those included fixes to address security flaws and each of those \"fixes\" were in turn defeated within weeks of release. Today the original XBOX still is one of my favourite systems and I have quite a few of them squirreled away.. XBOX 360 (Released 2005) This cat and mouse game ended with the XBOX 360 being released in November 2005 and security on this system was priority No.1. The system is pretty solid and secure and I wont go through all the details, but suffice to say that every step of the way during the loading and execution of any code, there are hardware layers to make sure only Microsoft \"signed code\" can run. but.. Like in life, not everything is always perfect.. XBOX 360 Security defeated - 2011 In late 2011, about six years after the launch of the XBOX 360, a couple of very smart hardware hackers (Gligli and Tiros) managed to defeat the XBOX 360 security by using a hardware \"glitching\" method and made the XBOX CPU essentially think the code it was executing is pure Microsoft provided \"signed\" code, when in fact it was tampered with.. i.e. You can run any code you want!! And thus the XBOX 360 RGH (Reset Glitch Hack) exploit was born! \"Hardware Glitching\" Turns out, hardware is pretty susceptible to electrial interference and in specific, digital logic chips like CPU's dont like very noisy or unstable power, data or reset lines.. So, you can alter the behaviour of a software system by manually injecting anomalies or errors onto the power, reset and data lines of underlying hardware. These anomalies makes the hardware execute the software instructions in unexpected ways and with a very cleverly crafted \"anomaly\" you can make hardware do things you want to software.. Like [SPOILER] skip verification checks!! How the XBOX 360 \"Glitch\" hack works Super High level explanation of XBOX 360 boot process. The XBOX 360 starts up and starts loading sequences of Boot Loader (BL) code During this process, it supplies 8-bit \"post codes\" on an 8-bit bus present on the motherboard You can read these pins for post codes and each code represents a different step of the boot process. At post code 0xD8, BL RC4 decryption is done (RC4 Encrypted BL stored on flash chip) At post code 0xDA, BL SHA1 verification is done (compares hardware embedded signature to loaded code signature) If signatures match, it is MS signed code and the system continues to start up If the loaded code signature does not match the hardware embedded signature, the system resets After a small number of resets and retry loops, the system halts The \"Glitch\" Glitching is done by injecting a very short 3-10 nanosecond pulse on CPU RESET line The Glitch is timed to happen EXACTLY when a \"memory compare\" function is executing This memcmp function is inside the SHA1 verification when comparing BL signatures The glitch will make memcmp return 0x00, meaning a perfect match, regardless of actual data compared If you can fake-out the CPU into thinking signatures match, you can run ANY code you want.. Step by step glitching an XBOX 360 Create a NAND image with custom code and flash to onboard NAND chip Wait for post code 0xD8 (BL decryption) Issue a command on the I2C bus to slow down the CPU significantly Wait for post code 0xDA (BL verification) Wait EXACTLY until memcmp executes to compare signatures Send a 3-10ns pulse on CPU RESET line to glitch a 0x00 return from memcmp The system will \"think\" the signatures match and will continue to run un-trusted code Issue a command on the I2C bus to speed up the CPU back to normal Tadaa - you are now running fully un-trusted code!! The custom NAND image also contains a custom SMC (Systems Management Controller) If this custom SMC does not detect a success within a specific timeout, it resets and tries again. The custom SMC will also override the halt and continiously loop and reset until the glitch works. You can read the full technical details and description from Gligli here: https://github.com/gligli/tools/blob/master/reset_glitch_hack/reset_glitch_hack.txt Reverse Engineering the XBOX 360 RGH Exploit Learning by standing on the shoulders of giants I have always been very intrigued at the inner workings of this incredible feat and wanted to duplicate this hardware glitch hack from scratch and really understand how it works. But, one of the barriers of entry was the timings of these attacks. You have to be EXTREMELY precise.. We are talking about TWO HUNDRED MILLIONTH of a second precise! Or more succinctly, you need te able to inject a single 3-10 nano second pulse at a VERY precise time after post code 0xDA shows up on the post bus. It has to align within 3-5 nanoseconds window of the memcmp function execution that verifies the signatures. Tools of the trade: XBOX 360 Step 1 - Get a XBOX 360 XBOX 360 acquired from Craigslist for $40!!! Tools of the trade: FPGA or CPLD Generating VERY precise timing and pulses, you need FPGA's or CPLD's Instead of re-inventing the wheel, as Gligli mentions, they used Xilinx CoolRunner II CPLD (xc2c64a) I found cheap xc2c64a boards on ebay that is actually specifically built for XBOX360 glitching This board has an onboard 48Mhz clock, but you can disable it and hook into the XBOX standbly Clock You can buy these from Amazon, Ebay or various online stores https://www.amazon.com/gp/product/B07KDCDN5H Tools of the trade: CPLD and NAND programmer You need to program the CPLD with glitch code And you need to flash a custom NAND image to the XBOX 360 Turns out, there is a really handy tool that can do BOTH! I used a J-R Programmer that you can buy off E-Bay or Amazon https://www.amazon.com/gp/product/B01MTUWLVJ Tools of the trade: Logic Analyzer You need to visualize data on the POST, RESET, DB2G3 and I2C lines I have a Saleae 8 channel 100Mhz, which turned out not to be fast enough I found a not too expensive 200Mhz Kingst LA2016 Logic Analyzer on Amazon There are better and more expensive, but this will do just fine. https://www.amazon.com/gp/product/B07D35FNYL Running existing RGH exploit I installed the \"Matrix\" board and was able to get the existing exploit running. This particular board uses an install called \"Project Muffin\" for XBOX 360 Slim systems \"Project Muffin\" does not connect to the I2C bus, but connects to the GPIO_0 pin on South Bridge marked \"DB2G3\" on the mainboard. The default custom NAND image just loads \"XELL Reloaded\", an open source boot loader After install, the Xell bootloader came up within 5-10 seconds.. the glitch works!! https://github.com/Free60Project/xell-reloaded Looking under the hood (Matrix board) After install and sucessfull \"Glitch\", I started to look under the hood how this hack actually works and I connected the Logic Analyzer to the RESET (A), POST (B), CLK (C) and DB2G3 (E) pads of the Matrix board and additionally hooked it up to the XBOX 360's I2C bus SDA and SCL pins to monitor I2C traffic. RESET (Matrix A >> XBOX RESET) The RESET pad is connected to XBOX CPU RESET pin, HIGH = Running, LOW = reset condition. When the system resets and starts boot the RESET pin goes HIGH and stays HIGH This is also the pin where the 5ns glitch pulse gets injected by pulling it LOW POST (Matrix B >> XBOX Post Bit 1) With every post message sent to the XBOX's 8-Bit post bus, the value gets incremented by 1 The POST pad is only connected on a single bit of XBOX 8-Bit Post bus - Bit[1] Connecting to Bit[1], means every SECOND post will toggle this pin HIGH/LOW This means you can count posts by counting every rising and falling edge of a single pin Should be easy to count posts to find post 0xD8 and 0xDA CLK (Matrix C >> XBOX Standby CLK) I disabled the Matrix onboard oscillator by removing a zero ohm resistor. The CLK connects to the 48Mhz standby CLK on the XBOX 360 The CLK signal is left unmodified, it clocks the CPLD and was ignored for my reversing purposes. Note - Newer revisions of XBOX 360 has no access to CLK and you must use Matrix oscillator DB2G3 (Matrix E >> South Bridge GPIO_0 / DB2G3) This pad connects to a the GPIO_0 pin of the South Bridge marked \"DB2G3\" on XBOX 360 mainboard I was not sure exactly what this did in regards to this \"Project Muffin\" method (yet) SDA & SCL ( XBOX I2C Bus SDA & SCL ) I wanted to also monitor the I2C traffic to see what devices are on the bus The I2C was not connected to anything on the Matrix board at this time. Reading the Tea leaves.. I captured a few runs of the glitch and this is what I saw during the glitch RESET (PINK) The RESET pin toggles LOW/HIGH and after a while a VERY short LOW/HIGH pulse and then cycle repeats I suspect the first toggle is simply a system reset the super short less than 10ns pulse is highly likely to be the glitch pulse the subsequent RESET toggles are probably retry attempts when the glitch failed POST (BLUE) There are 20 post bit 1 HIGH/LOW toggles that I counted during RESET LOW period I refer to these HIGH/LOW rising and falling edges as \"post counts\", 1 count each per edge Then there are 10 post counts before the DB2G3 pin goes HIGH Post count 10 is likely post bus message 0xD8 (BL Decrypt) and DB2G3 HIGH is likely CPU slow down After 1 more post pin toggle at post count 11 there is the ~5ns pulse on RESET line It is highly likely that post count 11 is post message 0xDA (SHA signature verify) The RESET pulse right after post count 11 is likely the memcmp glitch The DB2G3 line goes HIGH again right after the the glitch pulse, likely indicating CPU speed up DB2G3 (ORANGE) (Marked as DEBUG in trace) The DB2G3 pin on the South Bridge has a single long HIGH/LOW period during a RESET cycle It is highly likely that this is what controls CPU slow down and speed up I disconnected this pin and the time between post count 10 and 11 was WAAAAAY less.. This told me that DB2G3 HIGH at post count 10 is for sure CPU slow down and LOW is speed up at count 11 SDA & SCL (GREEN & YELLOW) The I2C bus has a bunch of traffic, but after a number of RESET cycle captures, I found a pattern! Right after the DB2G3 line goes HIGH, there is always a 0xCD,0x04,0x4E,0x08,0x80,0x03 message Right after the DB2G3 line goes LOW, there is always a 0xCD,0x04,0x4E,0x80,0x0C,0x02 message These two messages are identical except for th last 3 bytes, so they must be related! more captures by disconnecting the DB2G3 pin had none of these messages Confirmed DB2G3 HIGH/LOW is for slowdown/speedup and it triggers these I2C messages So, instead of using the DB2G3 pin, injecting these messages directly on the I2C should have same effect Glitching the XBOX 360 and running unsigned code!!! I ran a bunch of Logic Analyzer dumps, measured all the timings between events and was able to to piece together the EXACT timings and steps I needed to perform the XBOX 360 Reset Glitch Hack. STEP 1 - Wait for RESET to complete and start counting post Rising/Falling edges STEP 2 - At post count 10 - Issue a \"slow down\" I2C message 0xCD,0x04,0x4E,0x08,0x80,0x03 STEP 3 - At post count 11 - start a \"Glitch Timer\" STEP 4 - After EXACTLY 180,840 nano seconds, send a 10 nanosecond LOW/HIGH pulse on RESET (Glitch!) STEP 5 - Issue a \"speed up\" I2C message 0xCD,0x04,0x4E,0x80,0x0C,0x02 to restore CPU clock If RESET gets pulled LOW and there are post counts, this means the glitch failed and system reset If system reset, start over again from Step 1 I did not want to use the South Bridge GPIO_0 (DB2G3) pin, since I have heard rumours about repurposing the South Bridge output pin as a SMC input pin was not healthy for the South Bridge.. Jury is still out, but I wanted to use the tried and true Gligli method using just the I2C bus. So after reading a book and few tutorials on Verilog, I downloaded the free Xilinx ISE 14.7 IDE and went about implementing the all the code in this repo to perform steps 1 through 5 and all the rest of the logic to auto restart and retry and additionally use I2C based slowdown instead of South Bridge GPIO_0 (DB2G3) \"Muffin\" style slowdown. I have to say, getting everything to work and fit into a 64 cell CPLD, was REALLY tricky!! Everyone I spoke to told me that it can't be done.. Well.. I finally cracked it and it all fit and seemed to work as planned. I played with the Glitch Timer values and I finally got it to glitch and XELL loaded up!!! HOLY SHIT, IT WORKS!!!! but it was VERY inconsistent.. I could only get it to sucessfully glitch like once or twice after many many many reset cycles.. Finally I reached out to some folks on Discord familiar with XBOX 360 RGH (Mena and Octal450) and I learnt that the XBOX 360's standby clock at 48Mhz is waay too slow for consistent glitches. You can process the clock on Dual Edge Triggering (DET) with a Xilinx Coolrunner CPLD, meaning you can process on both rising and falling edges of a clock and in theory the processing happens at 96Mhz, but still even working with ~10 nanosecond periods it seemed too slow. I saw notes in existing exploit files that it was running at 192Mhz and getting 48Mhz to 192Mhz with this tiny CPLD seemed pretty darn impossible! There are no built-in IP logic on CPLD's to perform frequency multiplication using Phased Lock Loops (PLL) or Digital Clock Managers (DCM's) or other features you typically get for free in FPGA's.. After some serious Google fu and head scratching, I found an archive on Xilinx Forums on a way to DOUBLE the frequency of a digital circuit by phase delaying the signal a little and then XOR'ing an inverse of the delayed signal with the original and boom! you can double the Frequency! Super cool tecnique I found on now defunct Xiling Forums: https://web.archive.org/web/20201215191757/https://forums.xilinx.com/t5/General-Technical-Discussion/the-implement-of-frequency-multiplier/m-p/199162/highlight/true#M9312 I implemented this Flip-Flop with clock XOR trick on the 48Mhz clock that should produce a 96Mhz clock and then did Dual Edge Triggering ontop of that to theoretically get to 192Mhz! Now to test it out and check the output frequencies! I hooked up my Oscilloscope to the board and after some tests involving basic frequency measurements, I confirmed the CPLD was doing exactly what the Xilinx forum suggested.. It delayed the input 48Mhz clock phase by a few degrees, then XOR'ed the Input 48Mhz and delayed 48Mhz clock signals to produce a DOUBLE frequency clock signal at 96Mhz - Then you can do Dual Edge Triggering to process signals at 192Mhz!!!! Thats pretty crazy to process at 4x the input clock speed without any PLL's or DCM's!!! Now I could process and produce signals on the CPLD in 5.208333 nanosecond periods - that is a pretty darn accurate clock !! After these Changes and some more input from Octal450 on glitch timing fine tuning and a suggestion to delay the \"slow down\" message until 30-50ms after post count 10, I found the magic numbers.. and BOOM!! I was able to glitch the XBOX 360 pretty much within 1-5 seconds EVERY single time!! using code I created entirely from a Logic Analyzer output !!! This was a WILD ride! I learnt so much during the process about hardware glitching and how powerful of a tool such a teeny tiny little anomaly at the right time could be! I am still AMAZED at the people who researched this hack 10 years ago and found all the puzzle pieces to pull it off.. This is a very advanced hack and to get to to work so well and so consistently is pretty darn incredible. Thanks Octal450 and Mena on Discord for your help and guidance, it certainly was a cool journey. Feel free to ping me if anyone has any questions about the code or the process ENJOY! Koos",
    "commentLink": "https://news.ycombinator.com/item?id=42465378",
    "commentBody": "Hardware Security Exploit Research – Xbox 360 (github.com/kooscode)191 points by nazgulsenpai 22 hours agohidepastfavorite80 comments dinartem 21 hours agoGood times. I was the developer at Microsoft who designed the Xbox 360 hardware security, wrote all the boot loaders, and the hypervisor code. Note to self: you should have added random delays before and after making the POST code visible on the external pins. reply dhx 16 hours agoparentHave you seen Tony Chen's (development lead for Xbox One security) description of the Xbox 360 reset glitch hack at [1] and the effect this (and other console exploits of that time) had on Xbox One development? This is one of my go-to case study videos for the development effort required to architect a computer to resist attackers who have physical access. [1] https://youtu.be/U7VwtOrwceo?t=536 reply spencerflem 21 hours agoparentprevCongratulations, haven't had a reason to mess with it myself, but I've heard it described online as the most secure piece of consumer hardware before or since reply jsheard 20 hours agorootparentI think you might be mixing up the Xbox 360 with the Xbox One, the former was ultimately compromised in several ways, but the latter's security has held up extremely well for 11 years and counting. The Xbox One and its successor are easily the most secure consoles ever made. Obligatory: https://www.youtube.com/watch?v=U7VwtOrwceo reply ChocolateGod 18 hours agorootparent> The Xbox One and its successor are easily the most secure consoles ever made. Microsoft also allowed any console to switch to developer mode and run homebrew, massively reducing the need for people to try find exploits. reply spencerflem 19 hours agorootparentprevFound it! I misremembered, it was making a slightly different claim \"The Xbox 360 hypervisor is probably the most secure piece of code Microsoft has ever written.\" from the excellent article Tony Hawk's Pro Strcpy https://icode4.coffee/?p=954 reply landr0id 15 hours agorootparentThe Xbox 360 was overall a very, very secure device. While we don't know exactly how the folks who discovered the hypervisor syscall handler bug were able to get plaintext, it's theorized that it came from development kit and SDK leaks. With an SDK and dev kit someone could dump boot loaders and the HV. Otherwise on a retail console you can't do much. The hard drives are not encrypted but all content that can possibly contain code / save data is signed. Save data cannot contain code but introduces scripting engine / save parsing attack surface, but you can't modify it without first dumping keys from a retail console. To dump keys from a retail console you have to get code exec in the hypervisor. To attack the hypervisor you have be able to dump the hypervisor to audit it. To dump the hypervisor you have to be able to read its contents or dump it from flash. The flash is encrypted with a per-console key (and I don't think you can sniff the bus?) and RAM is encrypted. Realistically if it weren't for the original syscall handler bug and dev kits getting into researcher's hands, the Xbox 360 may have never been hacked. reply markus_zhang 14 hours agorootparentStupid question, is the reason that people cannot simply dump the ROM as they do with say routers is that the rom is encrypted? But if they have the SDK they can decrypt it? reply landr0id 11 hours agorootparentThe flash chip is encrypted with the console's CPU key, and the CPU key is unique per-console and encoded in efuses. So even if one person manages to dump keys they're mostly useless for hacking other consoles. The exception to this is the \"keyvault\" which is the console's own private key used for signing save games. You can take save games from console A and load them on console B, so console B is able to verify console A's signature based off the public key certificate embedded in the save. Microsoft had a revocation process for revoking keyvaults if they ever leaked but they just gave up once too many were in the wild. Dev kits are keyed differently and most of the console's keys for signing / encryption are in various SDK DLLs that if you reverse engineer you can find. reply markus_zhang 6 hours agorootparentThanks, MS did take a lot of efforts on the security. Searching for X360 keyvault gives a lot of webpages. I'll read a bit. reply SteveNuts 21 hours agorootparentprevI'm curious how it fares against a modern iPhone or similar, has that ever been compared? reply saagarjha 17 hours agorootparentiPhone has a fairly different threat model (and is more valuable to attack). reply liamwire 21 hours agorootparentprevI have a hard time believing the ‘since’ part of that description. Intuition suggests the latest iPhone would take that crown each year. reply walterbell 18 hours agorootparent> the latest iPhone would take that crown each year Apple continuously patches zero-day kernel exploits against the latest iOS and hardware, https://support.apple.com/en-us/100100 reply StrauXX 8 hours agorootparentSure, but there are many more people looking at iPhone security than at Xboxes. The incentives, both monetary and otherwise, are much greater with iPhones than they ever were with consoles. reply anyfoo 18 hours agorootparentprevThat is far from the only thing that would be relevant for such a metric. (For one thing, you also have to ask which kernel.) reply walterbell 17 hours agorootparentiPhone and iPad devices have been breached by zero-days for years, unlike Xbox One. reply anyfoo 28 minutes agorootparentStill simplistic. \"Breached\" can mean a number of things, and the incentives here are very different. reply spencerflem 19 hours agorootparentprevMisremembered, it was saying it was the most secure code Microsoft has written, not anyone From the excellent: https://icode4.coffee/?p=954 reply Dracophoenix 11 hours agoparentprevHow did you feel about teenagers and college students exploiting holes in your work? Were you impressed, disappointed, amused, etc.? Oh and I'd just like to say thank you for your contribution to my childhood/adolescence. reply notavalleyman 21 hours agoparentprevWhat are the reasons for why Microsoft wanted to lock down consoles to only run signed code? As a games console manufacturer, what are the business reasons for doing so? Thanks reply nemothekid 21 hours agorootparentLimiting piracy is the ongoing reason, but there is also the historical reason of the Video game crash of 1983 which led to Nintendo's Seal of Quality. Essentially as the platform owner, you want to ensure games sold for the platform \"just work\", and if you have a bunch of third parties running bad software, consumers would lose faith in the platform altogether. reply mrandish 17 hours agorootparent> ensure games sold for the platform \"just work\" To add a little more color to this, it wasn't solely to ensure games worked. The lesson of the video game crash was that third party publishers would make knock-off games similar to popular titles and flood the market with them at much lower cost - sometimes as low as $5 vs for a $40 for a top title. These games were generally low budget and rushed to market to capitalize on looking like a top-selling title - while being just different enough to (hopefully) avoid trademark infringement. These games usually \"worked\" (as in booting up and playing), the issue was more that that they were just bad versions of the title they were ripping off due to having little development time and minimal play testing along with poorer artwork and fewer levels (thus saving ROM memory). The flood of cheap, bad versions of more popular games is credited as the main factor that killed the Atari VCS. Another big factor was that later console manufacturers charged game publishers a license fee for the proprietary library code required for a console to run a game. This fee could allow manufacturers to sell game consoles at cost or even below cost and recoup the lost profit over time in the per game license fee. This wasn't always the case in the early days of hardware cartridge systems. Initially, some early console manufacturers didn't charge much more than a game publisher could buy blank cartridges for from a third party. Some other manufacturers chose to generate revenue simply by building more margin into the wholesale price they charged game publishers for blank cartridges. Of course, when console manufacturers started increasing their cartridge profit margin, game publishers were motivated to use third party cartridges - which led to console makers deploying \"genuine hardware\" checks or, later, disc checks and encryption. Nintendo popularized enforcing their business model both technically and legally (by requiring an IP license). Today, console manufacturer business models rely on 1) Collecting per game license fees, 2) Blocking piracy, 3) Limiting game supply. There is a lot of interesting history around how game console business models and the legal landscape evolved over time. (https://en.wikipedia.org/wiki/Atari_Games_Corp._v._Nintendo_....) reply maximilianburke 17 hours agorootparentprevI think it's also worth pointing out that the console makers (and developers) pour a lot more resources into ensuring that the products released for their platform are of a suitable quality than, say, phone app store gatekeepers. A big draw as well is that people can't (within the economic viability timeframe of the games/console) hack the games on a console, meaning you get a much more predictable online experience than you might on PC. reply droopyEyelids 1 hour agorootparentThere was a period of time when this was true but at least with nintendo, the eshop is full of shovelware now reply NotPractical 17 hours agorootparentprevMicrosoft actually reversed course on this. You can make a one-time purchase to access \"developer mode\" and then run whatever you want. It's been suggested that this is the reason there's been less interest in hacking the Xbox. Ironically it also means you have more computational freedom on the Xbox than on the iPhone/iPad. reply girvo 13 hours agorootparent> then run whatever you want Not quite. You (were? I don't know if this is changed) limited in how much of the hardware you could access: it wasn't 100% access. Enough for most homebrew, emulators and so on, but it wasn't carte blanche \"replacement for a dev-kit\" access. reply Narishma 12 hours agorootparentI don't think it much different from the official games, which also don't have full access to the console. reply klausa 12 hours agorootparentThe \"not-behind-the-paywall-and-NDA\" GDK version is severely more limited than the invite-only GDKX. IIRC the homebrew you can run is mostly UWP stuff? But if you want to launch a _game_, built for an Xbox, it requires to be in the program. reply hsbauauvhabzb 9 hours agorootparentprevYet Microsoft bought Bethesda reply akira2501 13 hours agorootparentprev> and if you have a bunch of third parties running bad software, consumers would lose faith in the platform altogether. Famously the reason no one ever used Microsoft Windows. reply mschuster91 6 hours agorootparent> Famously the reason no one ever used Microsoft Windows. Microsoft in its early days invested a shit ton of money and effort into backwards compatibility testing and fix development. Up until Windows 7 you could be reasonably sure that any piece of software from the Windows 95 32-bit days would still work without major issues - even 16-bit software would run under a 32-bit W7 host, only W7 x64 finally dropped support for that. reply treyd 21 hours agorootparentprevThey sell the consoles at a loss, so if you could port your own games to the consoles instead of buying the games that they could take a royalty from then they lose money. It doesn't have to be an effective circumvention to trigger the DMCA making it illegal. reply throwaway48476 15 hours agorootparentprevThey sell the console at a loss but make 30% on every game sold. The business model is variant of \"dumping\" but antitrust isn't enforced anymore. reply doctorpangloss 1 hour agorootparentIf it were possible to go the wrong way on the expanding brain meme, this would be it. Nobody is buying consoles for the hardware. 99% of the product is software. The accounting that you are using, a popular one, is so opppositely-informative that people who make consoles - and smartphones for that matter - clearly do not make decisions with it. It is 200% wrong to characterize it as dumping. Nothing is being dumped. Here’s a simple idea for you: show me the vibrant market for Xbox 360 2005 era computer hardware. There isn’t any right? What about Xbox One 2013 era? And yet we still play games that were developed earlier than 2013, like League of Legends. The product is software. Nobody loses anything by being unable to run Linux on 2013 hardware today, and nobody loses anything by being unable to run Linux on the Xbox One in 2013 because, if they wanted cheap computers then, they had plenty to choose from! reply brokenmachine 20 hours agorootparentprevThey are rent seekers. reply hsbauauvhabzb 8 hours agorootparentI’m not sure that’s a fair perspective, they built a proprietary product that’s intended to be a loss leader, the opposite of that is a desktop which costs substantially more. reply Lammy 21 hours agorootparentprevA games console provided a platform where they could more effectively argue that “their” works “““needed””” to be protected so they could farm us (people who want to run their own code on hardware they purchased) for digital-jail technologies which would never otherwise have reason to exist. Then those technologies can metastasize fully-formed over to general-purpose computing in a way that's harder to argue against. They learned with Clipper and Palladium that trying to develop jail tech on PC would be vehemently opposed. reply lyu07282 19 hours agorootparentThe opposition was pointless though, like everything has TPM/IME/etc. nowadays so we lost that war awhile ago. I don't see how consoles helped them win that war though. reply RGamma 12 hours agorootparentWhen everything is locked down for good I'll go back to physical books. Vaporware games and media are not worth preserving anyway. And the games and media I do have free from prison can entertain me for a very long time. Another possible (even worse) future could be cloudification of everything. Enjoy your thin client. Of course software is bigger than entertainment which might represent a problem. We're increasingly societally locked into this digital shit. reply liamwire 20 hours agoparentprevCan you speak to some of the harder or more interesting challenges you faced during that time? reply dinartem 20 hours agorootparentOne challenge was that while I started working on the Xbox 360 about three years before it would ship, we knew that the custom CPU would not be available until early 2005 (first chips arrived in early February). And there was only supposed to be one hardware spin before final release. So I had no real hardware to test any of the software I was writing, and no other chips (like the Apple G5 we used as alpha kits) had the custom security hardware or boot sequence like the custom chip would have. But I still needed to provide the first stage boot loader which is stored in ROM inside the CPU weeks before first manufacture. I ended up writing a simulator of the CPU (instruction level), to make progress on writing the boot code. Obviously my boot code and hypervisor would run perfectly on my simulator since I wrote both! But IBM had also had a hardware accelerated cycle-accurate simulator that I got to use. I was required to boot the entire Xbox 360 kernel in their simulator before I could release the boot ROM. What takes a few seconds on hardware to boot took over 3 hours in simulation. The POST codes would be displayed every so often to let me know that progress was still being made. The first CPU arrived on a Friday, by Saturday the electrical engineers flew to Austin to help get the chip on the motherboard and make sure FSB and other busses were all working. I arrived on Monday evening with a laptop containing the source code to the kernel, on Tuesday I compiled and flashed various versions, working through the typical bring-up issues. By Wednesday afternoon the kernel was running Quake, including sound output and controller input. Three years of preparation to make my contribution to hardware bring-up as short as possible, since I would bottleneck everyone else in the development team until the CPU booted the kernel. reply Zeetah 18 hours agorootparentYou have an awesome memory, Dinarte! Eric Mejdric from IBM called on Friday and said we have the chips, when are you guys getting here? I took a red eye that night and got to Austin on Saturday morning. We brought up the board, the IBM debugger, and then got stuck. I remember calling you on Sunday morning. You had just got a big screen TV for the Super bowl and had people over and in-between hosting them you dropped us new bits to make progress. I think Tracy came on Sunday or Monday and with you got the Kernel booted. Good times! This is Harjit by the way. Edit: added super bowl. reply saturn8601 18 hours agorootparentOMG Harjit! I saw you in the documentary! You and the entire team are total rockstars! I just cannot fathom ever being in a position to design something that provided so much joy and happy core memories to countless people around the world...you guys did it! Just the thought of how many people you touched with your work....just amazing! :) Had a question if you don't mind: Can you talk about the thought process behind the power supply design? Its very large even in the super slim models. Were you following a specific design driven by the hardware architecture or were there other reasons? I always wondered about that. reply maroonblazer 17 hours agorootparent>I saw you in the documentary! I presume you're referring to this one: https://www.xbox.com/en-US/power-on#watch reply saturn8601 16 hours agorootparentYes! It is worth watching every second. What an amazing production. reply dinartem 16 hours agorootparentprevActually Tracy never made it to Austin. He was going to fly in later in the week to continue bring-up, but since we were done by Wednesday, we just sent the chips to Redmond and he continued there. He was of course always available on the phone to answer my kernel questions I had. reply markus_zhang 17 hours agorootparentprevThis is really some blast from the past. Can you please shed more light on the simulator? Is it interpretation or JIT? But then I realize XBOX uses Pentium III, so maybe virtualization? Edit Sorry it was XBOX 360 so it's not Pentium. As someone who recently got interested in emulation and wrote two lc-3 emulators, would really love to learn from the masters. reply brokenmachine 19 hours agorootparentprevKick ass. This kind of post is why HN is the best. reply cbanek 17 hours agorootparentprevSmall world! I worked on Yellow Door / Golden Gate automation for releasing 360 titles and patches to prod, and the beta group / KDC service code. reply kridsdale1 20 hours agorootparentprevThis is the coolest HN post I’ve read in months. Cheers. reply saturn8601 18 hours agorootparentprevYou sir are an inspiration! I am but a mediocre Angular developer and reading this has me in complete awe! The kind of drive you must have had to get this done well I dont know how people manage to do it but it is so cool to see! :) reply n144q 18 hours agorootparentprev> we knew that the custom CPU would not be available until early 2005 Sounds a little bit like the situation with Xbox Series? The SDKs were released late because Microsoft was waiting for certain features in AMD APU reply fragmede 20 hours agorootparentprevdamn, that's bad ass. did that simulator run on a Windows system or was it something more esoteric? reply dinartem 19 hours agorootparentI called the simulator Sbox and it was just a simple console app. I didn't implement the GPU, so no graphics just the hypervisor and kernel and some simple non-graphics apps. I made it so that you could build the Xbox 360 kernel on your windows machine, then just run sbox.exe and it would automatically find the just built kernel image targeting the PPC64 and boot it. Then if you typed control-C it would drop into the kernel debugger as a sub process, and you could poke around at the machine state as if it were the real Xbox hardware, showing all the PPC instructions and registers. It was a lot of fun writing it, and quite useful. reply Zeetah 18 hours agorootparentYou should also talk about the lwarx/stecx bug. IIRC - in the first version of the chip there was a bug in one or both of these instructions. Your code booted on SBox but didn't on the hardware. You compared the two and then figured out it was these instructions. You filed a bug report and then dug into them and used SBox to figure out what must have been going wrong. The chip supplier came back with a workaround and within five minutes you simulated it on SBox and said it wouldn't work, why, and then said how it should be fixed. The supplier didn't believe you as yet. And you worked out a workaround so we could be unblocked. Two weeks later they agreed with your fix... reply maximilianburke 17 hours agorootparentI recall an issue when trying to use lwarx/stwcx on Xbox 360 directly that the compiler (or maybe even the kernel, on program load? it's been a while) raised an error and said to use the Interlocked intrinsics instead -- is that related? reply dinartem 16 hours agorootparentSo the PPC instruction set uses lwarx (load word and reserve indexed), and stwcx (store word conditional indexed), along with variations for word size, to implement atomic operations such as interlocked-increment and test-and-set. So on PPC interlocked-increment is implemented as: loop: lwarx r4,0,r3 # Load and reserve r4Generating VERY precise timing and pulses, you need FPGA's or CPLD's Back in the day, I managed to create a working RGH modchip based on Atmega8 (8 bit micro) running at 20 MHz with hand-crafted assembly code. I named it RWH (Reset Witch Hack) and it was able to boot Xbox 360 Jasper in 1-2 minutes. Old motherboards had a physical pad on the motherboard allowing for slowing down the CPU, so no i2c was required. I also have to connect the whole 8 bit POST bus to read the current value in one instruction. PCB was made at home, and since AVR is 5V system, I used NPNs for voltage conversion (all values were inverted in the software). Why? I didn't have money to buy the \"real\" CPLD modchip. Rush and happiness when it first booted - priceless. I still should have the source code for it somewhere on backup. photos: https://gist.githubusercontent.com/JaCzekanski/c02ed11c30fac... https://gist.githubusercontent.com/JaCzekanski/c02ed11c30fac... reply Lammy 22 hours agoprev> So - here is a hopefully informative write up of my Journey to figuring out how these guys were running unsigned code in 2011 on a XBOX 360 > XBOX 360 Security defeated - 2011 I realize this post is more about hardware security than software security, but if the benchmark is unsigned code execution then the author should at least mention the 2007 (King Kong shader exploit) and 2009 (SMC hack — same root flaw but executed automatically at boot) methods of achieving the same: - https://github.com/Free60Project/wiki/blob/master/docs/Hacks... - https://github.com/Free60Project/wiki/blob/master/docs/Hacks... reply PaulHoule 21 hours agoparentBack in the day I really liked my 360 whereas my ONE seems like a mistake. reply mrandish 19 hours agorootparentYeah, I still have an Xbox One hooked up (along with a SOTA gaming PC) but I now have more fun playing retro games via emulation than modern games. Lately I've been having a blast exploring the X360 library via Xenia (since I had a PS3 during that era and never got to see some of these titles). reply jackjackk0 17 hours agoprevIf you are not familiar with the fascinating story behind it, I recommend this podcast episode [1], it's one of my absolute favorites (along with its sequel)! I found out about it on this very forum a few years ago, hope to propagate the favor to somebody else out there. [1] https://darknetdiaries.com/episode/45/ reply kaoD 20 hours agoprev> Note - Newer revisions of XBOX 360 has no access to CLK and you must use Matrix oscillator If there's no CLK line on the mobo, does this mean newer X360s have everything that might be clocked (I assume at least CPU, GPU and V/RAM?) in a single chip, SoC-like? reply 15155 16 hours agoparentI'm not aware of any reason nor modern computer system that would have these things clocked by a common clock line of any kind. Today, GPUs connected via PCIe or the like use 8b/10b coding over differentially-signaled pairs. The signal itself has clock recovery. (V)RAM is generally clocked at a different frequency than the CPU as well, and all DDR utilizes strobes to determine when data is valid because access time is variable. In some SOCs/FPGA-based devices, a central clock generator will sometimes provide LVCMOS/HCSL/LVDS/etc. clock lines to each device, but these aren't often re-used. This allows for flexibility and later programmability. There's generally no assumed phase or frequency relationship between these derived clocks and the original source - especially after the signal has traveled 20cm across a board. In the case of a CPU/GPU, though, a 20 cent crystal oscillator at each device feeding into internal PLLs is typically the go-to. reply Aurornis 12 hours agoprevFun article. One note: > I have a Saleae 8 channel 100Mhz, which turned out not to be fast enough > I found a not too expensive 200Mhz Kingst LA2016 Logic Analyzer on Amazon The author is confusing MHz with MS/s (mega samples per second). Salaea has a logic analyzer that works on 100MHz signals (with 500 MS/s), but I suspect the author had the unit with 100 MS/s that only works up to 25MHz signals. The cheap Kingst unit has 200 MS/s but only works with signals up to 40MHz. reply 14 19 hours agoprev [–] Fun thinking back to the days of cat and mouse between MS and hackers so many cool things went down. My favorite being hackers making custom firmware for certain dvd burners so that you could burn right to the very edge of 7.5gb discs and make 8gb games that MS started using. Truncated games were being detected and then hackers came up with this idea it was so genius. Then came along the reset glitch hack and I moved away from discs to an external hard drive and never looked back. I did a few for me and a couple friends. The soldering involved was pretty precise in the fact that it was a very very small pad you needed to solder to and if you screwed up it was very easy to lift the pad and putting yourself into a big heap of trouble fixing it. I was also using a crappy $15 soldering iron with a bad tip because I was poor. But never did I have an issue. Depending on your install you could get the glitch to happen sometimes on the first reset or for some it took multiple resets. I was happy because all mine seemed to work first if not second reset which a lot of people struggled to get. I still have my rgh 360 my kids have it with a hdd full of games I backed up from my own games you know. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the 2011 defeat of XBOX 360 security using the Reset Glitch Hack (RGH), a method that allowed running unsigned code by tricking the CPU.",
      "Hackers Gligli and Tiros used a hardware glitching technique, involving precise electrical pulses, to bypass security checks, highlighting the vulnerabilities in the XBOX 360's security system.",
      "The author replicated the hack, gaining insights into hardware glitching and the complexities of the XBOX 360's security architecture."
    ],
    "commentSummary": [
      "A former Microsoft developer shares insights on Xbox 360 hardware security exploits, highlighting vulnerabilities and development challenges.",
      "The discussion compares Xbox 360 security to other devices like Xbox One and iPhones, emphasizing Microsoft's focus on preventing piracy and maintaining game quality.",
      "Anecdotes reveal the use of simulators during development and community efforts to exploit the console's security."
    ],
    "points": 191,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1734639993
  },
  {
    "id": 42469264,
    "title": "A comparison to Waymo’s auto liability insurance claims at 25M miles",
    "originLink": "https://waymo.com/research/do-autonomous-vehicles-outperform-latest-generation-human-driven-vehicles-25-million-miles/",
    "originBody": "Do Autonomous Vehicles Outperform Latest-Generation Human-Driven Vehicles? A Comparison to Waymo's Auto Liability Insurance Claims at 25 Million Miles Authors Di Lillo, L. Gode, T. Zhou, X. Scanlon, J. M. Chen, R. Victor, T. Abstract Understanding the safety impact of Automated Driving Systems (ADS) is crucial for their widespread adoption, yet robust real-world evaluation remains a critical area of development. By leveraging insurance industry third-party auto liability claims, we analyze the Waymo ADS performance across 25.3 million fully autonomous miles (with no human in the driver seat) and demonstrate a consistent and scalable framework for ongoing ADS safety assessment. This study not only updates previous findings with expanded geographical coverage and increased mileage but also establishes a methodology for comparing ADS performance to evolving subsets of human-driven vehicles (HDV). We introduce two key innovations: a novel “latest-generation HDV” benchmark representing drivers of newer, technologically advanced vehicles (2018-2021), and a robust insurance dataset for ADS safety assessment. Results demonstrate that the Waymo ADS significantly outperformed both the overall driving population (88% reduction in property damage claims, 92% in bodily injury claims), and outperformed the more stringent latest-generation HDV benchmark (86% reduction in property damage claims and 90% in bodily injury claims). This substantial safety improvement 1 over our previous 3.8-million-mile study not only validates ADS safety at scale but also provides a new approach for ongoing ADS evaluation. Our findings provide crucial insights into the evolving safety landscape of ADS technology and have far-reaching implications for transportation safety policies, insurance risk assessments, and public acceptance of ADS technology. This methodology establishes a foundation for future research into the safety impact potential of ADS and offers a framework for assessment as these systems continue to scale and develop. Share Share on Twitter Share on LinkedIn Share on Facebook Links Download PDF Copy CitationCopied! Topics 2024 Retrospective Safety Impact Peer-reviewed Research",
    "commentLink": "https://news.ycombinator.com/item?id=42469264",
    "commentBody": "A comparison to Waymo’s auto liability insurance claims at 25M miles (waymo.com)175 points by devangs 10 hours agohidepastfavorite402 comments mulmen 9 hours agoI rode in a Waymo recently and was amazed at how good it was. It was easily in the top 5 best drivers I have ridden with. Really really impressive. It wasn’t nearly as cautious or timid as I expected it to be. But it also wasn’t reckless. I would describe it as assertive, but I’m sure some people would call it aggressive. It knows the rules and what’s going on around and acts accordingly. This really should be the norm. For the first time in a decade I’m excited about an emerging technology. The future is bright. reply mstade 8 hours agoparentI was just in CA for a few weeks and drove in SF quite a bit. There are Waymo cars everywhere and from the perspective of a driver I was more than a little cautious driving behind or next to one of them. I would rate their driving as quite good, but their signaling of intent was terrible. More than once did I see them use turn signals, only to never actually turn. Turn the signals on, then off again, then on again, eventually turn perhaps but not always. Humans are terrible at this too, but we also use more subtle and inadvertent signals like the slight movement to the line telling me they're likely about to switch lanes, only to see the signal go on halfway into it. Those subtle signals are easier to pick up on than a robot driving more or less perfectly straight while signaling, turning of signals, turning them back on again, and so on. Also super creepy with empty driver seats, and no one responsible to make eye contact with. But the actual driving wasn't bad, as it turns out. Never had or saw a near miss, anything reckless or otherwise remarkable. I can see myself getting used to this tech and I would love for it to succeed, because man driving for anything but fun really sucks. reply gruez 3 hours agorootparent>More than once did I see them use turn signals, only to never actually turn. Turn the signals on, then off again, then on again, eventually turn perhaps but not always. >Humans are terrible at this too, but we also use more subtle and inadvertent signals like the slight movement to the line telling me they're likely about to switch lanes, only to see the signal go on halfway into it. Isn't waymo's behavior preferred? I'd rather see turn signals well in advance of any possible lane changes, rather than the moment before the cars actually start changing lanes. Sure, it'd be ideal if the turn signals were well in advance and there were no false positives, but road conditions are changing constantly, so by necessity you're going to be trading off between advance notice and false positives. reply returningfory2 3 hours agorootparentprevThe Waymo failure mode of false positives (signals but doesn't turn) seems much better than the human failure mode of false negatives (doesn't signal but turns)! reply tommiegannert 1 hour agorootparentHuman drivers also sometimes forget to turn their signals off, to the same effect as the described Waymo behavior: uncertainty of intent. reply engineer_22 4 hours agorootparentprevI think that as a pedestrian it would be hard for me to get used to. I like to look at the eyes of the driver to make sure they can see me. reply carteazy 4 hours agorootparentThere is a signal light mounted on the top of the vehicle. When it detects a pedestrian in a crosswalk or waiting to cross, it lights up with a little ‘human walking’ picture. It makes it very clear to everyone it sees you. reply underdeserver 3 hours agorootparentDoes it see you or is there someone else it's seeing? reply ASalazarMX 2 hours agorootparentWaymo, take note: instead of displaying a human walking, display googly eyes glancing at pedestrians. reply skygazer 1 hour agorootparentAh, now we know what to do with the Vision Pro's outward lenticular eye visualizations. reply ASalazarMX 48 minutes agorootparentDidn't know about this. Only Apple would think of taking live video of your eyes and projecting them on the exterior of the visor... and call it Eye Sight... Potential users will read \"external display\" and immediately think of many uses, and I'd bet the last of them would be \"stream my eyes\". It's perfectly bland and corporate, I suppose Apple is aiming for normalization, \"VR googles you could wear at a party without feeling dorky!\". The iFixIt teardown was very interesting, nevertheless. reply futureshock 4 hours agorootparentprevI get what you are saying. However where I live in Florida, drivers are so pedestrian blind and oblivious that they’ll run you down right in the middle of the crosswalk while playing on their phone. Friend of a friend was just killed as a pedestrian a week ago. Bring on the robodrivers! reply j_bum 4 hours agorootparentprevIn the future we’ll tell our kids, “try to make eye contact with the driver’s sensors before crossing the street” reply sho_hn 4 hours agorootparentprevDon't move to South Korea, where nearly everyone has tinted windshields and you literally can't. reply lmm 4 hours agorootparentOk I won't? What a horrible thing to normalise. reply H8crilA 4 hours agorootparentprevTo avoid this very problem North Korea has no cars at all. Clever. reply underdeserver 3 hours agorootparentprevWhy do they have tinted windshields? reply mirekrusin 4 hours agorootparentprevWe should require them to have big eyes like 3yo kids car toys. reply Mistletoe 4 hours agorootparentprevHaving just rewatched the original Total Recall, I can only think of one perfect answer for this. Need to add a Johnny Cab guy to the driver seat and have his head look the direction he is going to go. reply dessimus 4 hours agorootparentOr the automatic pilot from Airplane. reply yencabulator 1 hour agorootparentprev> use more subtle and inadvertent signals like the slight movement to the line telling me they're likely about to switch lanes For what it's worth, this was explicitly taught in Northern European driving classes, especially in the context of turns. It would literally translate as \"grouping\" or \"making a formation\". You \"group right\" to make a right turn (think aligning text left/center/right). You can look at a line of cars and immediately know which ones are preparing to turn, even from an angle where turn signals aren't noticeable. reply mulmen 8 hours agorootparentprevGood point about intent. As a passenger I appreciated how smooth it was but I can see how the lack of “body language” could be disorienting for human drivers. The Waymo driving style is almost passive-aggressive. It has superhuman situational awareness and knowledge. I wonder if it isn’t using blinkers effectively but it’s everyone else that’s technically wrong. It’s also not perfect so who knows. There’s probably still bugs to work out. reply necovek 8 hours agorootparentThat sounds great for Waymo: I'd love to experience a ride in one and I'll make sure to catch a ride next time I am in CA. I wonder what it does in common situations, like stop-and-go traffic with two streets joining at an angle, where one has to yield? In that case, if everyone simply followed the rules, the cars in the yielding street would never get through. While I am passive-aggressive myself as a driver, I religiously follow alternating one-by-one from either street \"rule\", even if I am in a street that has right of way, to ensure traffic moves for both of those and reduce chances of someone overly aggressively moving in from the yielding street. If it is still passive aggressive in that case, it will work ok while there are other passive human drivers in the road, but would quickly fall apart when everyone drives the same. reply mulmen 7 hours agorootparent> I wonder what it does in common situations, like stop-and-go traffic with two streets joining at an angle, where one has to yield? Plan a better route? I can’t picture the situation you describe. Yielding traffic just… yields. When there’s an opening they take it. On my ride the Waymo took a right turn on red. How is the situation you describe different? Do you still yield unnecessarily when there are cars behind you? reply necovek 7 hours agorootparentI was talking about a case where there are cars behind me. And it's \"unnecessarily\" only legally, but most drivers understand this as a driving etiquette in congested traffic. Picture two streets joining together, both with long lines of vehicles in them. One of them has right of way, the other one doesn't. When everyone drives \"passively aggressively\" (like Waymo is being described to), an opening never shows up, and \"yielding\" cars wait until the rush hour clears up, causing people in that street to go bonkers. This happens quite frequently in many old European cities I've been to in the rush hour or when anything unusual happens (because there are no alternative routes and streets are tight: like a crash or broken-down car ahead might cause this with lots of traffic). Not sure how much it applies to Waymo and SFO, but I can imagine it certainly happens in some areas. reply mulmen 7 hours agorootparentAh I see, like merging on to a freeway. In Washington the law is actually to zipper merge (take turns) so I would expect Waymo to do that. It’s a good question and I’m not sure what Waymo would do there. Based on my limited experience I expect it would navigate that situation correctly. The bias is to go (safely), not wait for perfect conditions. reply necovek 6 hours agorootparentThanks for the term as well (\"zipper merge\") — that's what I was referring to. Yeah, I really wonder how it'd fare in that case while differentiating between \"there are just 3 cars there, no need to yield\" and \"it's an infinite inflow of traffic, better yield to one car\"? reply mulmen 6 hours agorootparentMy Waymo ride was in LA. They aren’t operating on freeways there yet. Maybe this is one of the challenges. Apparently they do operate on freeways in San Francisco so maybe someone who has taken a ride there can share their experience. reply nextweek2 7 hours agorootparentprevIn England we call them \"Indicators\" as opposed to turn signals. My driving instructor said, they are call that because they are only indicating they might go that way. Never assume they will. It was some defensive driving advice. I can understand that it's annoying that inconsistent use of turn signals is an annoyance, it isn't as bad a people that don't use them at all, but my understand is that the American road system doesn't have roundabouts like we do, which kind of require good indicator use for smooth driving. reply mulmen 7 hours agorootparentWe have roundabouts. We don’t have them everywhere but then I bet you don’t either. My home town in Idaho has built at least five I am aware of in as many years, with more planned. My neighborhood in Seattle plants a tree in the middle of unmarked intersections which effectively creates a mini roundabout. reply krisoft 3 hours agorootparent> I bet you don’t either. Oh you haven’t been to the UK if you think that. :) They are absolutely everywhere. Traffic planers love them. reply Polizeiposaune 3 hours agorootparentprevI've driven in England and New Zealand, and they really had them everywhere. Yes, we have them in the US, but we don't have enough of them that you can expect that all drivers know what to do with them. It's entirely too common for approaching drivers to be unaware that they must yield to vehicles already in the circle. reply rglullis 8 hours agoparentprevThe whole thing with self-driving cars is that it feels like the story of NASA's space pen. All this money being poured into a technology that would not be needed if the richest country in the world had the common sense of simply getting rid of its car dependency and developed proper public transit infrastructure. reply Etheryte 8 hours agorootparentThe NASA space pen story as you call it is a nice quip. It's also a complete lie. The Soviets using pencils wasn't a clever scrappy solution, it was an absolute nightmare for the Soviets. Pencil cores are made of graphite, when you write with it, small bits of graphite break off. On land it just falls down, but in space it floats around and attaches to things. Graphite conducts electricity and it caused countless shorts in electronics, as well as fires, all while in space. If the Soviets had space pens, they would've switched to those in a heartbeat. reply JumpCrisscross 8 hours agorootparent> Soviets using pencils wasn't a clever scrappy solution, it was an absolute nightmare for the Soviets Note, too, that NASA didn't pay to develop the pen. Fisher did. > If the Soviets had space pens, they would've switched to those in a heartbeat Guess what cosmonauts use(d) on the ISS? (Qualified because I don't know post-2022.) reply gpderetta 7 hours agorootparent> Guess what cosmonauts use(d) on the ISS? (Qualified because I don't know post-2022.) I genuinely don't know. Do they use pencils still or switched to the space pen? reply Etheryte 7 hours agorootparentThe Soviets bought space pens from Fisher in 1969 [0] and have continued to use them ever since. [0] https://www.reuters.com/article/fact-check/nasa-did-not-spen... reply gizmondo 8 hours agorootparentprevI live in Switzerland which has a reputation for having good public transport. Still own a car because in many cases you can't beat convenience. Can't wait for Waymo to come here. reply rglullis 8 hours agorootparent> Still own a car because in many cases you can't beat convenience What about the places where people own cars not because it is the better choice, but the only choice? reply mulmen 7 hours agorootparentThen self driving vehicles will be a new choice. reply yencabulator 1 hour agorootparentSelf driving vehicles, with current technology, are unrealistic outside major cities. Major cities are the places where you least need a personal car. Google Maps still thinks the speed limit on a nearby highway is 35 mph. We spent several months without lane markers on the highway. Any vehicle driving around here based on the current self-driving architecture, requiring central mapping/planning and good infrastructure, would be ridiculously unsafe. Not to mention how lost they would be the moment they turned off the highway. reply fl0id 4 hours agorootparentprevor it won't like how uber etc at least here only operate in cities, and not where people actually really need cards. reply futureshock 4 hours agorootparentprevMany cities in Europe still have their Roman era street plans. The street layout of a city is incredible sticky. Once you have a city built around cars and all the private property and infrastructure that goes with it, you are basically stuck with it for 1000 years. And American city layouts are horrible for public transit and walking. We can look at international cities with longing and jealousy, but LA, Houston, Miami, and so on will never have useable public transit. You’d have to bulldoze the whole city and start again. So great for Paris and London and yes I would rather live there, but we are stuck finding solutions that work inside the mess we made. reply Aloha 4 hours agorootparentI agree with you in part - we do have 100 years of development patterns baked into concrete and steel, but they were not originally built just for cars. LA was built around interurbans, the idea that I should drive my car all the way from San Bernardino (or frankly even from Pasadena) to Los Angeles would be foreign to the original planners and builders in Southern California. Consider that every major freeway in LA is basically in whole or in part paralleling a former PE line, and suddenly my assertion doesnt seem so odd. https://www.pacificelectric.org/collections/pacific-electric... LA is not the only place where the sprawled layout was created by interurbans, Arguably to a greater or lesser extent - Detroit, Dallas, Cleveland, Cincinatti, and there are others whose early development was deeply influenced by the interurban exist. reply iknowstuff 3 hours agorootparentprevLA is densifying around transit. It’ll end up with islands of dense areas connected by trains. reply creer 1 hour agorootparentprevWait, what? Paris streets are a mess, even after Haussmann. That does not prevent outstanding transit. Even before the latest obsessive aggressive agenda-driven nonsense. The two things that Paris has are (1) inhabitant and workplace density and (2) the will to pursue public transit decade after decade. After that, there are lots of streets with a single lane of traffic - and buses go through them just fine. And there are lots of too narrow streets but they are isolated here and there - in between streets that are okay for buses. Equally there are lots of very wide avenues for several lanes of traffic and that's fine for pedestrians and transit even though it makes subway stations sometimes very wide. And there are lots of randomly angled streets. There are steep hills. There are rivers and canals and giant mining voids which make building subway tunnels interesting. There are lots of train track rights of way which sometimes block pedestrian traffic but are covered and crossed reasonably often (sometimes still not optimally so). There is snow, ice, floods, hot weather. You name it it's there. Both of these are essential. \"Decade after decade\" is essential. Both density and building that infrastructure are impossible to build at the stroke of a pen. So an advantage of Paris compared to San Francisco is that it had decent inhabitant and workplace density from the infancy of public transit when it was private animal pulled carriages. So what's missing in US cities: decade after decade of density followed by decade after decade of public intent. SF could do it - but for sure you wouldn't see the result tomorrow - but NIMBY so no, SF can't do it. Not before getting rid of NIMBY. LA is much more willing to build anything anywhere so it would have much more of a chance. But it's huge and people often live far from their place of work. Smaller areas with LA would have a better chance. Perhaps Glendale plus the entertainment industry north-south corridor? That might be manageable. Yet still more \"even then\", ride Paris transit at rush hours in summer and you won't feel that it's all that good: it's sweaty, packed, and there are lots of timetable incidents. You will regret having chosen rush hour. You car would have been nicely air conditionned and comfortable (but depending on your trajectory would have been stuck in traffic for a while.) reply JumpCrisscross 8 hours agorootparentprev> the story of NASA's space pen As an example of an urban legend/facile pop science take being treated as fact [1]? > if the richest country in the world had the common sense of simply getting rid of its car dependency and developed proper public transit infrastructure Is there a single developed economy that doesn't make significant use of trucks and cars? [1] https://en.wikipedia.org/wiki/Space_Pen#Uses_in_the_U.S._and... reply Aeolun 8 hours agorootparentDepends on your population density. Tokyo does pretty well with purely public transport. There’s still cars of course, but you don’t use them for travel into the city proper if you don’t hate yourself. reply JumpCrisscross 8 hours agorootparent> Tokyo does pretty well with purely public transport. There’s still cars of course, but you don’t use them for travel into the city proper if you don’t hate yourself Japan has .67 vehicles per person, almost 80% America's .85 [1] and above many European countries. They travel about a fifth as many miles per capita as America [2]. But again, four fifths and a fifth. Nowhere close to zero. There isn't a developed economy that wouldn't see a significant quality-of-life improvement from self-driving cars. [1] https://en.wikipedia.org/wiki/List_of_countries_and_territor... [2] https://www.fhwa.dot.gov/ohim/onh00/bar4.htm reply Aeolun 7 hours agorootparentHence why I’m talking about Tokyo. Not Japan. Living in the countryside basically requires a car by definition. People also often have a car, but don’t use it that much. Maybe you’ll get more interesting numbers if you compare miles traveled per person? Found only for 1997, but increases the discrepancy to 1:2.5 : https://www.fhwa.dot.gov/ohim/onh00/bar4.htm reply JumpCrisscross 7 hours agorootparent> I’m talking about Tokyo. Not Japan Tokyo would have a tough time existing in a world without cars, trucks or roads. Its economy depends on that access. There is no tradeoff between self-driving cars and a multi-trillion dollar infrastructure rebuild. reply Dylan16807 4 hours agorootparent> Tokyo would have a tough time existing in a world without cars, trucks or roads. Its economy depends on that access. I will agree with that statement but mostly because you added trucks in when the original complaint was about car dependency. reply graemep 8 hours agorootparentprev> Is there a single developed economy that doesn't make significant use of trucks and cars? You do not even need to restrict it to developed economies. Every city (even not very large ones) I have been to around the world, developed or not, has streets lots of cars: London, Manchester, Paris, Nairobi, Colombo, Madras, Bangalore, Sydney, Singapore..... and smaller towns and rural areas in those countries too. Those cover a pretty wide range of quality of public transport too. reply rglullis 8 hours agorootparentprevWay to miss the point. Yes, it is known that the \"NASA space pen\" was not really funded by NASA, but but its development still took millions of dollars in R&D. > Is there a single developed economy that doesn't make significant use of trucks and cars? For the 127th time: car dependency is not the same as car usage. reply JumpCrisscross 8 hours agorootparent> its development still took millions of dollars in R&D $1mm at the time, $10mm today. They sold for the equivalent of $30 each in today's money and saved manned spaceflight from having to deal with graphite shards in the air and electrical. > car dependency is not the same as car usage \"If the richest country in the world\" got \"rid of its car dependency,\" we'd still want safer cars. reply rglullis 8 hours agorootparent> we'd still want safer cars With the technology controlled by a handful of corporations? At an development cost that will force them to create any and every opportunity to seek rent on your mobility? reply JumpCrisscross 7 hours agorootparentYes, it would be better if the good thing were more perfect. reply rglullis 6 hours agorootparentNice rhetorical trick. It's not a matter of \"more perfect\". The bad outweighs the good, plain and simple, and only those who are extremely naive or stand to gain from it refuse to acknowledge it. reply Dylan16807 4 hours agorootparentThe bad things you describe as side effects already exist. So adding in good is... good. However you rate the current situation. reply kube-system 4 hours agorootparentprevIsn't that already the status quo? reply mulmen 8 hours agorootparentprevNobody says it has to be a car form factor. It can be a self driving van or shuttle or bus. Last mile is a nightmare with all public transit. With the low population density of the US we need a lot of small vehicles to feed transit hubs. reply creer 1 hour agorootparentThat would be a more reasonable trajectory for US cities: more frequent, faster main line transit plus a flood of local inexpensive automated electric vehicles. That would be compatible with the current low density. reply rglullis 7 hours agorootparentprevFor \"last mile\", we already have bikes, scooters, skates, plain walking... reply jazzyjackson 7 hours agorootparentReally fun stuff but most people have a limited amount of time in the day so if they can afford to take a car they're going to take a car. reply rglullis 7 hours agorootparent> limited amount of time in the day For trips shorter than 2 miles, I can bet you that it's faster for me to hop on my bike (or to find an electric scooter) and get to my destination than it is to drive. And let's not even talk about the time to find parking. reply mulmen 7 hours agorootparentThe grocery store is 1.3 miles from here but it’s a 300’ climb and it’s 42f and raining right now. Even with my e-bike that’s not pleasant. On a conventional bike that’s unrealistic for all but the most hardcore cyclists. There’s a bus that serves that route but the stop is uncovered and service is unreliable because it’s immediately after a rest stop where the human drivers take care of their biological needs. A robo-bus would be more predictable and enable more frequent service. reply rglullis 7 hours agorootparent> stop is uncovered and service is reliable And it doesn't even occur to you that the problem is the poor infrastructure? Do you honestly think that the optimal solution here is just to keep waiting for some trillion dollar corporation to be able to sell some new product that will bring you more \"convenience\" (at the cost of dependency and yet-more environmental costs related to cars and its required parking infrastructure) when you instead could be doing something like, I don't know, getting your city council to improve the fucking bus service? reply mulmen 6 hours agorootparent> And it doesn't even occur to you that the problem is the poor infrastructure? It has occurred to me. > Do you honestly think that the optimal solution here is just to keep waiting for some trillion dollar corporation to be able to sell some new product that will bring you more \"convenience\" Not sure where you got this idea. I’m not waiting for anything. I’m still excited for self driving vehicles to compliment the existing system. > at the cost of dependency and yet-more environmental costs related to cars and its required parking infrastructure Why would a self driving car need to park? The ability to always be in use is one of the advantages. As I said there’s no requirement that the self driving vehicle be a car form factor. A self-driving bus could improve access and reliability. > when you instead could be doing something like, I don't know, getting your city council to improve the fucking bus service? How? I choose to live in a city with good (for America) transit. I vote for every transit measure available to me. I ride the bus. I commute by bike when I can. I don’t own a car. What else should I do? reply rglullis 5 hours agorootparent> Why would a self driving car need to park? The ability to always be in use is one of the advantages. They are not going to be always in use. Unless you got a perfectly uniform distribution of demand over time, eventually most of these cars will have to be parked somewhere. And whey they do, let's hope they don't keep doing this: https://www.ctvnews.ca/video/c2977546-lot-full-of-self-drivi... reply mulmen 56 minutes agorootparentOk but they only need one parking space and even it can be time shared. They don’t need the same parking infrastructure we have now. Buses also need a place to park and get maintenance. Self-driving allows locating the parking in more distant locations. reply creer 57 minutes agorootparentprev> And whey they do, let's hope they don't keep doing How does bringing this up help anything? It's a bug, bugs happen, bugs get fixed. Quickly when they are software bugs. As opposed to NIMBY mind bugs. reply zahlman 3 hours agorootparentprev>The grocery store is 1.3 miles from here but it’s a 300’ climb and it’s 42f and raining right now. I would get a jacket and umbrella and walk this without giving it a second thought. reply mulmen 53 minutes agorootparentThat’s 1.5 hours round trip by foot and 15 minutes by car/e-bike. And I have to carry my groceries so I’m limited on how much I can buy. If there was a robobus I would absolutely take that option. reply rsynnott 4 hours agorootparentprev> Last mile is a nightmare with all public transit. In rural areas, sure. In urban and dense suburban areas, in most developed countries there's probably a bus stop within easy walking distance. reply creer 1 hour agorootparentprev> if the richest country in the world had the common sense of simply - There is nothing simple about it. - There is nothing inevitable to this appearance of \"not enough money\". For example very little of self-driving cars development has been on public funds. For example, there is plenty of money in California govt. And plenty of money in US federal govt. - One doesn't prevent the other. You can't seriously argue that better transit would remove all needs for automated driving. reply tim333 3 hours agorootparentprev>technology that would not be needed if... developed proper public transit infrastructure NYC and London have had 'proper' public transit for over a century. It's handy but not that great. I was on a 52 year old Bakerloo line tube train the other day and they are much like modern tube trains, if grubbier. It's not going to suddenly turn wonderful and solve everything. (typed on a London bus) Also while I'm not sure any technology is really needed, as in we could get by without it, there are about 1 million road deaths a year globally. A 90% reduction would save 900,000 lives which is a nice to have. And more meaningful than a space pen. reply lastdong 8 hours agorootparentprevIf it succeeds, self-driving technology is likely to be integrated into public transit systems, enhancing their reliability and overall efficiency. reply HPsquared 8 hours agorootparentWith self-driving tech, buses could be made a lot smaller and more frequent. They are large and infrequent because of fixed per-vehicle costs (mostly the driver). EDIT: Small size then enables personalized routing: a multi-passenger taxi taking a set of people to similar destinations. reply jazzyjackson 7 hours agorootparentThat makes a lot of sense, I never thought of the labor as the limiting factor on bus route (clearly I just never thought very hard about it) but boy would it be nice if there was a 9 passenger van every 5 minutes to replace a full size bus every 30. reply rglullis 7 hours agorootparentVans to complement buses are definitely a thing in São Paulo, and the cost of labor is not a limiting factor. reply AstralStorm 6 hours agorootparentReally the lack of stops and parking places is, and would be even worse for self driving vehicles deployed in numbers. Unless it's self driving motor bikes or such small personal transportation. reply Dalewyn 7 hours agorootparentprev>developed proper public transit infrastructure. No amount of public transport can accomodate the personal whims and demands of anyone let alone everyone. Even Japan, famous for its public transport infrastructure, still has a healthy population of drivers both in metro and rural areas. reply rglullis 7 hours agorootparentNice strawman. I am not saying to get rid of cars altogether. I am saying that it would be better (and cheaper) for everyone if we took all those resources being out into \"autonomous vehicles\" and developed public transit first. Reduce the amount of yearly trips that are done by car. Provide alternatives. The important thing about Japan or Europe is not \"they don't have cars\", but \"people make 3-4x less trips by car compared with the alternative modes of transportation\". If you want to have safer roads (in a way that doesn't give even more power to tech companies) the best way to do it is by simply reducing the amount of trips taken. reply JumpCrisscross 6 hours agorootparent> if we took all those resources being out into \"autonomous vehicles\" and developed public transit first Waymo has raised about $11bn [1]. That is at best 4 miles of New York subway [2]. It's a third of a train between Bakersfield and Merced [3]. These things aren't competing. To the extent we can compare them on capital efficiency, it's not a good look for American public transit. [1] https://www.nytimes.com/2024/10/28/business/waymo-investment... [2] https://www.bloomberg.com/news/newsletters/2023-02-24/cityla... [3] https://www.latimes.com/california/story/2024-03-21/high-spe... reply zahlman 3 hours agorootparent>That is at best 4 miles of New York subway [2]. It's a third of a train between Bakersfield and Merced [3]. Bakersfield to Merced is 171 miles of intercity high-speed rail. It's unclear to me why Californians need to make such trips with any significant frequency, and it's certainly not what I'd normally think of as \"public transit\". 22 years ago in Toronto, the Sheppard line (3.4 mi, underground) was built for less than $1b CAD (https://en.wikipedia.org/wiki/Line_4_Sheppard). From what I can tell, costs in NYC are mainly a NYC problem. reply kasey_junk 45 minutes agorootparentChicago is extending an existing above ground train line along an existing freeway (no right of way issues, not a subway, etc) 5.6 miles. It’s four stops and a new rail yard. 3.6B. https://www.transitchicago.com/ctas-36-billion-red-line-exte... It may be an American problem but it’s certainly not just NYC. But of course most of Waymos market is American as well. reply AstralStorm 6 hours agorootparentprevTry using a unit per person. It starts to look much less rosy for Waymo and also do not forget roads are still public infrastructure that has to be paid for and maintained. What, you think Waymo will be able to weasel out of road tax or drive without roads? reply JumpCrisscross 6 hours agorootparent> Try using a unit per person Not relevant when we’re comparing project costs. OP argued we should devote self-driving resources to public transit. I’m arguing that’s nonsense. > roads are still public infrastructure that has to be paid for and maintained Sure. But that isn’t a new funding commitment. Cancelling Waymo won’t reduce our road costs. reply zahlman 3 hours agorootparent>OP argued we should devote self-driving resources to public transit. Yes, because it would allow moving people more cost-effectively (among other things) - which is measured per person per unit distance traveled. (I'm not OP, but nothing in this discussion is even remotely new for transit advocates like myself.) reply rglullis 6 hours agorootparentprevYou are starting to seem dishonest when you resort to outliers and present them as the baseline. > To the extent we can compare them on capital efficiency We can not. This logic is stupid. This logic will take you to the idea that the best thing to do is to get everyone a helicopter because helipads are cheap to build and it costs zero dollars to \"build roads in the sky\". Yeah, you are right. These things are not competing. Yes, you are also right that proper infrastructure (re)development in North America will take a lot more money than what Big Tech has invested in self-driving cars. The upsetting part is to see even supposedly smart people buying into the idea that American Exceptionalism is a real thing, and that you can keep holding on to the hope to find a shortcut away of your problems. Self-driving cars or not, the US is still going to be an expensive, inefficient country that can boast about its amazing economy, yet most people living there are at third-world country levels of development. reply JumpCrisscross 1 minute agorootparent> Self-driving cars or not, the US is still going to be an expensive, inefficient country that can boast about its amazing economy, yet most people living there are at third-world country levels of development For fuck’s sake, the world’s largest rail system and navigable waterways say hello. I’ve advocated for public transit. But it’s turning into zealotry when an $11bn project showing actual gains is turned into a soapbox for decrying a pet project. yieldcrv 3 hours agorootparentprevAnd just like the NASA space pen story, the private sector is developing them on their own at their own risk, with maybe some indirect grants or subsidies, but not a direct contract specifically for the government to be a beneficiary. Way more money is being wasted on the grifts surrounding developing public transit infrastructure. LA County for example is 88 different municipalities and it will never get resolved. reply cmxch 3 hours agorootparentprev> if the richest country in the world had the common sense of simply getting rid of its car dependency and developed proper public transit infrastructure. Then have the dignitaries and environmental policymakers give their uparmored gas guzzling cars up first, leading by example. reply madeofpalk 3 hours agorootparentWhat are you talking about? Many politicians catch public transport around the world. I remember a few years back a mini nothingburger controversy about a politician 'caught' drinking a canned cocktail on the train in London https://www.theguardian.com/politics/2019/apr/20/diane-abbot... reply kiba 8 hours agoparentprevIt's impressive and all, but my reaction to self driving cars are completely different. It's a great technical feat, but it's not ever going to be efficient as public transportation. The form factor of the car works against it. reply graemep 8 hours agorootparentPublic transport cannot do everything cars can do, especially outside big cities. Better public transport can reduce the need for car ownership - I did not own a car for much of my life for that reason. However, it does not eliminate it. reply shafyy 8 hours agorootparentSure cars are helpful for transporting stuff. But most car rides is one dude sitting alone in a 1.5 ton machine moving his lazy ass around town. Public transport, if done correctly, can replace that, also outside of big cities. There are good examples across Europe for this. reply graemep 7 hours agorootparent> Sure cars are helpful for transporting stuff. But most car rides is one dude sitting alone in a 1.5 ton machine moving his lazy ass around town. I do not know about lazy. I find it a lot easier to use public transport myself. I would like to see numbers for \"most\" especially outside the US. Very few of my car trips are by myself without something to carry. > Public transport, if done correctly, can replace that, also outside of big cities. There are good examples across Europe for this. Where has public transport eliminated cars? Not anywhere I have been in Europe. You can significantly reduce car usage, but not eliminate it, so any safety improvements are still very important. Another problem outside big cities is that some buses and trains, especially at quieter times, also run pretty empty. There were about four or five people in the bus my daughter got into this morning (on a weekday morning!) and its close to the end of a journey between two reasonably large towns. The next bus gets very full though. reply shafyy 3 hours agorootparent> Where has public transport eliminated cars? Not anywhere I have been in Europe. You can significantly reduce car usage, but not eliminate it, so any safety improvements are still very important. Sure, not eliminated. There will always be cars. But reduced, as you said. I guess my main point was that one should not falsely believe that the existence of driverless buses and trains will somehow magically and significantly improve the public transportation situation in a given country. reply ghaff 3 hours agorootparentprevOne of the features of public transit--certainly the commuter rail relatively near my house (although I still need to drive to the station)--is that it's often very empty in off-hours but if you don't run (an insufficient number of) those near-empty trains, a lot of people are going to say screw it and drive. I won't take commuter rail into the city for an evening event in part because because I really need to time the return journey--and it takes quite a bit longer. reply mulmen 7 hours agorootparentprevOk but hear me out. Self driving public transit. Right now I have to walk 12 minutes to a bus stop because the one literally in front of my house was closed due to a lack of drivers. Then I wait 3-10 minutes for a bus that takes 20 minutes to get to the bus hub in my neighborhood. It takes 8 minutes to drive there. If my neighborhood bus route was replaced or supplemented with self driving shuttle busses feeding that hub then a 1 hour door-to-door trip could be 30 minutes. reply shafyy 3 hours agorootparentSure. I'm not saying that there no use cases. But I don't see the US turning into a public transportation utopia just because there are self-driving buses available. Because the reason public transportation sucks in countries where it sucks is not because drivers are expensive. reply graemep 7 hours agorootparentprevMore frequent smaller busses is a great idea. If self driving busses helps achieve that, it would be amazing. reply zahlman 3 hours agorootparentprevDoing the rare things that actually require a car, does not entail a need to own one. (And it's perfectly possible to have a fulfilling life without those rare things.) reply Qem 8 hours agorootparentprevI suspect the advent of self driving cars will just help get the streets even more clogged with cars. reply zenonu 4 hours agorootparentThere's a future, not in the short-term, where 99% of folks don't need to or want to own a car. You hail a ride, and a vehicle shows up, perhaps with 3 of people in the vehicle in their own bubble internally designed into the car. You get in, it drops offs others in the vehicle, and then finally drops you off. The vehicle exhausts its entire electric charge, recharges, and then gets back on the road. The number of vehicles on the road is down 50%. reply mulmen 8 hours agorootparentprevMake a self driving bus then. I take Ubers to bus stops today. Doesn’t seem like much of a leap. reply crazygringo 3 hours agorootparentThis is definitely going to be coming. You'll be able to pay more to take a single dedicated vehicle the whole way, or less that includes a self-driving bus or two for most of the middle segment of your journey. But the bus \"routes\" will be totally dynamic based on demand, and will only stop occasionally, and you won't have to wait long. It's going to be a complete revolution in public transit. reply agumonkey 7 hours agorootparentprevand with dedicated bus lines and predictable behavior that could be easier to do reply bsder 3 hours agorootparentprevSelf-driving cars help get us past the path dependence and move toward better public transit. I tried using the train for my commute. However, I had to maintain a car at each end and I could only use the 7AM train as the parking at my origin would be filled at any later time. Self-driving cars break my dependence on a car at destination and allow me to pick an origin train independent of parking. reply Dalewyn 8 hours agorootparentprevYou're conflating two tangential things, automatic driving is automatic driving whether it's a car or a bus. The biggest issue that automatic driving needs to overcome is that it's sharing the road with manually driven cars. We've already had the technology for a long time to have perfect automatic driving if the environment was fully automatic; computers are unparalleled at accurately sharing and processing data with each other. This isn't to say that the solution is to get rid of human drivers, because driving a car has been one of the most empowering paradigm shifts for the commons. Being able to travel yourself timely anywhere anytime for any reason is a level of power that pre-automobile commons simply did not have. Subjugating your power to travel to a computer is surrendering that incredible power. If (and likely when) we can figure out how to better share human data with computers and vice versa computer data with humans, everyone on the road will be better off. reply zahlman 2 hours agorootparent>driving a car has been one of the most empowering paradigm shifts for the commons. Being able to travel yourself timely anywhere anytime for any reason Everywhere that the roads go, sure. The more other commoners are trying to do this, and the more useful places that the roads will allow it, the slower it gets. But not only that, it's very unevenly paced - and therefore inefficient and less safe. The problems are compounded by North American road and intersection design. Many urban areas in Europe manage to get by with far fewer streetlights and stop signs (often by using roundabouts). But cars in North American cities routinely get to speeds that would be dangerous in a collision (which would be much less of a problem if this could be confined to routes where they're isolated from pedestrians - but this often doesn't happen), only to have to stop and wait for a minute or more at a time, an embarrassingly short distance thereafter. And then buses have to deal with the car traffic and the lights, make additional stops, and take extra safety precautions due to their size. Everyone thinks of taking the bus as slow. If there were no cars, the roads could be designed for buses, and streets for pedestrians. But we don't even properly distinguish streets from roads around here. reply tialaramex 7 hours agorootparentprevGoA 4 (no trained personnel onboard) is only practical for entirely grade separated (ie it's almost impossible for anything else to be there, no cars, no bicycles, no pedestrians) routes. Even GoA 3 is fraught without this constraint, and for GoA 2 you're still paying for a driver because although the machine does most of the work the human has to handle the inevitable deviations from the model. GoA 4 railways exist, if you're putting a metro in tunnels or elevating it obviously this is grade separated, and in principle you can do it for long distance rail if you're willing to eliminate at grade crossings (expensive). But they are nothing like a city bus route for example. reply fragmede 8 hours agorootparentprevOnce the technology exists and is proven, the only thing stopping public transportation from being automated with the same technology is their union. reply zahlman 2 hours agorootparentSubways and light rail already have such automation in many places. For example in Montreal: https://rem.info/en/light-rail reply shafyy 8 hours agorootparentprevI doubt that the reason public transport is not as prevalent e.g. in the US as in some European countries is the cost of the driver. The fixed costs of operating a train or a bus must be many many times more. reply heroprotagonist 8 hours agoparentprev> The future is bright. Ask the 2.3 million employed drivers in the United States how the future looks. Because pretty soon, they'll all need to be doing something else. And I don't see a technology that will open up 2.3 million jobs for them to move into, or training initiatives to support them while they shift professions. The future _could_ be bright, if we approach AI right, and build the social safety net to soften the massive amount of transition that will be necessary. But we're not. We're looking at cuts everywhere in the near future. And long term, it seems we have no strategy. Which makes it more likely that a lot of people will be harmed. reply ddalex 8 hours agorootparentI think if we ban cars now we may still have a chance to save the horse industry reply heroprotagonist 4 hours agorootparentNo, we won't need horse drivers either. But you might decide to build in enough additional taxes on the self-driving vehicles to cover at least the state's increased costs in terms of unemployment, medical, and services. This way all those people riding the fancy new cars are the ones subsidizing the new industry's hidden costs instead of every tax payer. reply tim333 2 hours agorootparentWhat is the normal annual turnover in those 2.3 million drivers? 20% perhaps? I doubt self driving cars are going to replace 20% a year - they'll take many years to roll out. So it'll just be less people entering the field rather than mass layoffs. reply eksapsy 7 hours agorootparentprevTechnology will open up new jobs. But I don't expect employed drivers to suddenly become data scientists. Its a fallacy we constantly use as an argument when we talk about technology taking people's jobs. Low specialty professions have been in my view a great way to have people employed, people who may be less fortunate, unspecialized or even students. Now that such professions start getting absorbed by tech, I don't know how those people are supposed to get by. I can see how somebody would argue 6hay this has occurred before, but for example replacing horses with cars just made postpone jump to learning how to drive. They didn't have to \"specialize for 4 years\" and become computer scientists. Now this is a bolder issue imo. But my perspective can be argued reply mulmen 7 hours agorootparent> Now that such professions start getting absorbed by tech, I don't know how those people are supposed to get by. Now? This has been going on since jobs were invented. reply mulmen 8 hours agorootparentprevEh, ask switchboard operators how they feel about the Internet. Cars wiped out farriers. Should we go back to riding horses? Gig work is a symptom. Not a triumph worthy of protection. reply Panzer04 8 hours agorootparentprev2.3m people we don't need to pay any more. Jobs'll open up, that money will go somewhere else. reply jazzyjackson 8 hours agorootparentSure but building yachts is skilled labor, there will have to be a massive retraining operation reply anal_reactor 8 hours agorootparentprevHard agree. Soviet Union built its economy around making sure that everyone had a job and, as a result... oh wait, nevermind. reply tim333 2 hours agorootparentThat was one of the few aspects of their economy which was probably good. reply fragmede 4 hours agoparentprevBut does this absolve Google for killing Reader? reply meiraleal 8 hours agoparentprev> The future is bright. We have been there. The internet and then Google, Facebook were the same. Big Tech can't be trusted. reply mulmen 8 hours agorootparentI think the Internet is pretty great. It’s not perfect but I’m not ready to throw out the frictionless communication baby with the cynical bathwater. reply JumpCrisscross 8 hours agorootparentprev> Big Tech can't be trusted Trust, trade and mutually-beneficial coëxistence need not go hand in hand. reply rglullis 4 hours agorootparent> mutually-beneficial coëxistence Their side is benefiting a lot more than ours, and the few benefits that we might end up seeing come with a good amount of harm inflicted by them. reply tim333 2 hours agorootparentI like my tech toys - the usual macbook, iphone, internet etc. provided by big tech. I'm not sure how they are supposed to have harmed me? reply rglullis 19 minutes agorootparentThis is the type of comment that makes you look either like a privileged elite that is part of Big Tech, or just a clueless moron whose day at the barrel is yet to come. Do you really need a list of ways how Big Tech has harmed society? If things like \"Surveillance Capitalism\" is not enough, maybe: - the collapse of quality journalism, because SEO and content farms made impossible to maintain a financially sustainable team of independent reporters? - The absolute destruction of people's ability to read a piece of text for longer than 15 seconds? - The mental health crisis in teens and even young adults caused by social media? - Planned obsolescence and the removal of our right to repair things on our own? - The normalization of the \"gig economy\" not just for young kids who are looking for some extra cash, but as the main source of income for grown up adults, with actual families to support? - (Google and Facebook mostly) adopting the absolutely anti-competitive practice of \"when we get a competitor, we will buy them out as early as possible or we will just keep offering our stuff for free until they just run out of money\"? - Apple outright refusing to let people install alternative app stores, because they know that without this artificial scarcity they would not be worth 1/10th of what they are today? Seriously, get out of SV bubble. reply rowanG077 8 hours agorootparentprevHow does trust factor into it. I would not say trust is even applicable to a corporation. reply arnaudsm 1 hour agoprevThese results are meaningless, Waymo only drives in controlled, good weather, urban streets, while the human control group does not. This is not science, this is PR. We need independent investigations. And remember that currently, self-driving cars in California are exempt from traffic tickets : https://www.theguardian.com/technology/2024/jan/04/self-driv... We learned that the hard way with Boeing, you cannot trust a company to self-regulate their safety standards. But with Musk in power, the legislation might encourage them to do so. reply creer 1 hour agoparent\"controlled areas\" is relative - for example it includes mayhem zone SOMA and the hills. Also they just got started, relatively speaking, and have been expanding. Give it a minute. Really, computers seem more naturally suited to driving in SF than humans - from the point of view of paying attention to enough things, not having to pay attention to map navigation and having more modes of sensory input than humans. reply jajko 9 minutes agorootparentI'll believe such companies with my life and life of my family when they can handle usual South east Asia capital city for example also during monsoon, say Bombay. Because this is in stake, nothing less. This aint some web app deployment where flaws are annoying but thats about it. I've just finished 2 day 1500km drive back home across Europe in various storms, heavy rain, a bit of snow, a lot of it in the dark, tons of properly dangerous idiots, some serious accidents along the way, few nearly misses. Our F11 BMW 5 series took it on effortlessly, complementing my and wife's skills but not interfering. I am not stellar but definitely above average driver. I've done this drive maybe 30x over past 15 years, without kids normally in one 16-18 hour push. Nr of clueless idiots is definitely rising and roads are definitely more full. No way in hell I'll trust something fully with most precious stuff in my life until its properly battle proven by billions of miles in harsh complex situations, which what you describe it isnt. Till then there is no self driving, just steps towards it. I don't need this for driving around some short distances that much. Good luck with beta testing to ya all. reply tim333 1 hour agoparentprevGoogle says >Waymo One, is available 24 hours a day, 7 days a week in the following cities: >Los Angeles Waymo One is available across nearly 80 square miles of LA County, including Santa Monica, Beverly Hills, and Downtown LA. >San Francisco Waymo One is available across 55 square miles of the Bay Area... 24/7 across those areas sounds different to what you mention. reply arnaudsm 1 hour agorootparentI agree about the 24/7 part, but the safe zone and weather biases are too big to ignore reply Brian_K_White 8 hours agoprevI just heard someone mention in a podcast how as a cyclist they need to make eye contact with drivers to be safe, and there is no one to make eye contact with. Waymo would say \"don't worry, it sees you\" and maybe the numbers even show they do some percentage more than the average human driver, but that still does not reproduce the self-help aspect of you looking at a driver until you see that that driver sees you. I think that is a pretty significant thing. It needs some sort of better answer than \"don't worry about it\" Maybe they will prove to be so reliable that you don't need to worry about them. You can just reliably assume and predict their behavior as animate objects about the same as you do for inanimate objects. IE, you can't make eye contact with jersey barrier, but you don't need to, you know what it will do (nothing). And you can't make eye contact with say, a motorized railroad crossing barrier, but you don't need to. It moves, but only in an absolutely predictable way. You can be a cyclist around the railroad crossing barrier no problem. Maybe Waymo and others will be that consistent that you can treat them like \"moving inanimate objects\" safely. I don't know if they are right now. They may be better than humans on avaerage, but that is a long way from predictable and safe. Maybe They can build in some way for the car to signal back to the surrounding people what all it has taken note of, or not. Some way for a cyclist or pedestrian to look at a Waymo and see that it sees you. That should be possible. Maybe it can go both ways, maybe we can develop some kind of standard where if you need to get a cars attention there is some gesture you can do that it will be especially watching for. So even if it doesn't see you, it will see you if you wave your hand a certain way or something. Only problem with that is you have to be able to do the thing, and some of the times you need a car to see you the most will be the same times when you are incapacitated, ie lying on the road after some accident or something. reply CalRobert 7 hours agoparentI ride my bike several times a day, and I have very mixed views about Waymo, etc. I care immensely about traffic safety (so much I moved to the Netherlands). If you took the world as it is now and left everything the same except that every car was a waymo and there were no human-driven cars left, I would be ecstatic. Humans are horrible drivers and some of them are downright murderous. If every car were a waymo I could even imagine letting my kids bike to school in the bay (where I used to live), which I wouldn't dream of now. But I think the second-order effects of self driving cars could be terrible. It removes any incentive not to have an incredibly long commute (exacerbating sprawl), and so far every time there has been a situation where the needs of walkers and cyclists were pitted against the needs of drivers, drivers won. I think the same will happen with self-driving cars, and people will be made to wear beacons just to walk across the street. NotJustBikes discusses this well here https://www.youtube.com/watch?v=040ejWnFkj0 But if we have proper regulation (pretty unlikely I would say) and use things like waymo to stop humans from driving (remember, drivers are the leading killers of children in the US!) that would be great. reply tim333 2 hours agorootparent>removes any incentive not to have an incredibly long commute The roads only have so much capacity which is not going to change much whether the cars are self driven or not. In London they have deliberately reduced road capacity to reduce traffic by blocking off lanes, side streets and the like. I could see a future where the normal way to get around is a self driving cab to the station at each end with a train for the main journey. I know you can do that now but the human cabs driven are kind of expensive. Maybe something a bit like Zermatt where there is a train station and then it's pedestrianized apart from electric golf cart like taxis. It all works quite well really apart from being expensive. But property being like £1m+ is kind of a symptom of people wanting to be there. reply BaculumMeumEst 4 hours agorootparentprevIt seems contradictory to care immensely about traffic safety but lament the idea of wearing a vest to cross the street. It seems like something that logically we should probably already be doing. Self driving cars are just making it more obvious. reply zahlman 2 hours agorootparent>It seems contradictory to care immensely about [school] safety but lament the idea of wearing a [bulletproof] vest to [enter] the [school]. (Or be subjected to a metal detector screening, etc.) No, it's perfectly consistent. The argument is that the underlying problem shouldn't exist to any significant extent in the first place, and doesn't need to (and doesn't in many other parts of the world). A lot of traffic safety issues in North America derive from road design, which has historically prioritized the needs and wants of car drivers above everyone else. It is not \"contradictory\" to reject a solution that entails doing even more to accommodate cars. reply throwaway4220 4 hours agorootparentprevConsider what you’re saying - you can’t walk on the street you live on without a vest reply CalRobert 4 hours agorootparentprevSimilarly, we should be sending kids to school in bulletproof vests. Safety first! It is the obligation of the vehicle operator not to kill people, not the obligation of the person walking not to be killed. reply Brian_K_White 4 hours agorootparentprevgood god no. entirely backwards. This is saying it's your responsibility to be ugly to be safe from rapists. reply usrusr 8 hours agoparentprevAs a cyclist I avoid eye contact like the plague: it's only a small minority of drivers, but that small minority is dangerous enough to outweigh all benefits eye contact might have with others. Some drivers will inevitably read eye contact as \"the cyclist has seen me and understood that my big and dangerous car will crush them without taking harm so they will yield no matter what traffic rules might say, so I will go\". Eye contact is like a green light to them. If I do want to yield despite having priority I can do that just as safely without eye contact and if I want to assert priority it's objectively less dangerous (because of that minority) if I do it without eye contact. Nothing to gain, so much to lose. The reality on the ground is what the car does, and I will focus on that. Taking guesses from looking at the driver is counterproductive. reply Brian_K_White 8 hours agorootparentI don't cross in front of a car without knowing that that cars driver sees me. And sometimes you have to cross in front of a car. Most of those times everyone is just stopped at a light anyway, but not always, and some of those lights still allow the driver to proceed anyway if turning right, which they might do at any time. I also ride a recumbent trike which is low to the ground. A diamond frame puts you up at eye level with most drivers and that makes everything easier. reply mtts 6 hours agorootparentprevNot just as a cyclist. As a pedestrian in one of those huge Asian metropolises with absolutely bonkers traffic, you should never ever make eye contact either. It’s the only way drivers will stop for you. reply thaumasiotes 4 hours agorootparentReally? I've seen a number of drivers in Shanghai stop for me while I'm just standing in the middle of the road, waiting for a clear spot in the traffic. Actually, I got a fairly strong feeling that Shanghai traffic has gotten noticeably less crazy over time, but I can't rule out that I was just observing the local traffic of different regions of Shanghai at different times. reply abyssin 8 hours agoparentprevA few weeks ago I had the nice surprise that my usual strategy of starting to walk on the pedestrian crossing to test if a car driver has the intention of stopping, resulted in an emergency stop from a Tesla coming for the right (it was a two-way street and I was testing the car coming from my left). The Tesla correctly stopped, in accordance with the law. Its driver wasn't happy. reply pfooti 4 hours agoparentprevThe waymos in SF seem to indicate that they see a pedestrian (when they are waiting to turn) by showing a pedestrian symbol on their spinning lidar hat. It's pretty obvious, but I don't know how consistently it is shown. reply creer 45 minutes agorootparentOh that's interesting thank you. Will look for it. I do believe that computers are much more likely to have attention span and sensor capacity to reliably spot pedestrians and other random wheeled traffic. The problem is \"reliably\", which needs to be near 100% for the pedestrian to decide to ignore that it's still in full motion. So it will be interesting to see if such notification helps or not. If we were all wearing AR glasses, a specific car could signal a specific person that it noticed and is tracking them - that THEY are safe from IT. But we are a few years from that. reply LoLFactor 8 hours agoparentprevThis. I'm always surprised how few people know as pedestrians to look at me, the driver and not my car. Some don't even look at the car. I developed a habit of looking for their gaze and if they don't look back, assume they're not fully aware and just am more cautious. This works because I, as a human, know this and can compensate when they just rush the crosswalk without being fully aware of their surroundings. How do you do that with a machine? reply david-gpu 7 hours agorootparentJust because a pedestrian is looking in your direction, it doesn't mean they can actually meet your gaze. I don't drive and always try to make eye contact with drivers, but tinted windows and windshield glare often make it impossible in reality. So I will stare at where I know the driver's face ought to be, but I can't actually tell whether they have seen me. Tinted windows darken the inside of the car and that makes windshield glare all I can actually see. reply creer 43 minutes agorootparentprevHey I'm always surprised at how many pedestrians walk around all in black (or dark) with no light, no reflecting stripe, no nothing and no care in the world. Even with the best of intention of drivers, it's a death wish. And it's everywhere. reply necovek 8 hours agorootparentprevIt's probably equally simple for a machine (if not simpler) to figure out if a human has looked at the oncoming vehicle with sufficiently advanced cameras and computer vision. However, we use a lot more hints (change of pace, facial expressions that indicate presence and focus, nodding etc), which, while not outside the realm of AI CV, would surely need lots of training, yet it comes pretty naturally to humans. reply david-gpu 7 hours agorootparentThe problem is not whether the machine can see the human, or even whether the machine knows that the human has seen the machine. The problem is that the human currently has no way to know whether the machine has seen the human. reply necovek 7 hours agorootparentThe GP was talking about the driver knowing if the \"human has seen the machine\". For the inverse problem, we could simply start adding screens (instead of windshields?) to self-driving cars that acknowledge the pedestrians in a particular way (when there's only a few people, in the Black Mirror realm, they'd actually greet them by name using facial recognition and universal DB of everyone :). reply Brian_K_White 6 hours agorootparentWhat? I was absolutely talking about human cyclists and pedestrians needing to know that the machine sees the human, and not by blind faith, but through some active explicit demonstrable indication. reply necovek 2 hours agorootparentI believe my reply was to user LoLFactor (threads open up subthreads which open up more subthreads...). If you are disagreeing with my use of \"GP\" (grandparent post), always go with the HN rule of \"assume the best possible interpretation\" :) reply Mawr 6 hours agorootparentprevOf course there is, the behavior of the machine should be the same as of a driver - the car shaped object starts to slow down in a way that will make it stop before hitting me at the pedestrian crossing. reply Brian_K_White 2 hours agorootparentThis one scenario is an entirely insufficient list of all possible situations that occur. Some of the worst incidents are when a stopped car stars moving just for the most obvious example. reply Mawr 6 hours agorootparentprevIt is not possible for me to see you in your car with any sort of reliability; even if I could the benefits are dubious and again, unreliable. Looking at your car is all I need anyway - I can tell if you've seen me by your behavior, you're either slowing down to yield to me or you're not. If you're not, the only possible outcome of knowing you're seeing me is being misled into stepping into your path of travel. reply Brian_K_White 5 hours agorootparentIt's not all or nothing. A hundred different things all add up and none of them do the entire job, nor are entirely unnecessary simply because they don't do the entire job. reply onlyrealcuzzo 4 hours agoparentprev> I just heard someone mention in a podcast how as a cyclist they need to make eye contact with drivers to be safe, and there is no one to make eye contact with. Cyclist here. Are you worried Waymos are going to blow through stop signs (or red lights) AND run you over? Or are there other situations where you're making eye contact with drivers? reply Atotalnoob 4 hours agoparentprevWayne has a signal light that lights up reply AstralStorm 6 hours agoparentprevOr maybe it could have a signal that says it's safe to cross. Humans tended to use hand gestures for that around here. Or flashing front or turn lights to disambiguate it. And the person crossing would often nod or just start moving. AI could be even more explicit about it. It can check if you're noticing the signal too, much like the driver does. People are conditioned to respond to crossing signals, why not give the self driving car one of those. reply mentos 6 hours agoparentprevI feel like I saw a self driving concept in the last few years where the headlights had eyes that could appear to be looking at you to signal that it was aware of your presence? reply Brian_K_White 5 hours agorootparentI'm pretty sure I would hate that. I want information and feedback, not misrepresentation or infantalization. I guess it depends how they did it exactly. If it looked like an animal or cartoon character etc, that's what I would hate. If it wasn't pretending to be an aware and caring being, that would be ok. reply mstade 8 hours agoparentprevThis makes a lot of sense, also for pedestrians and other drivers. Having seen these things live in action, it creeped me out to see an empty drivers seat. reply Qem 7 hours agorootparent> Having seen these things live in action, it creeped me out to see an empty drivers seat. I wonder if the safety gains could be just due to people being creeped out around them, and behaving more cautiously. Perhaps results would be different if they carried mannequins simulating a real driver in the wheel. reply zahlman 2 hours agorootparentCouldn't they just put a passenger in that seat? reply Aeolun 8 hours agorootparentprevNeed to give them led matrix front lights. The cars will be much less scary if they regularly blink. reply Aeolun 8 hours agoparentprev> Maybe they will prove to be so reliable that you don't need to worry about them. You can just reliably assume and predict their behavior as animate objects about the same as you do for inanimate objects. This seems to be what is happening. There was a comment here by some user not too long ago that said they deliberately drive in front of the Waymo’s because they trust them to slow down. reply bmicraft 6 hours agorootparentYou can also do that with human drivers and it will work for a while. The question is how often it doesn't work. A single person driving in front of a Waymo a couple of times can't determine that with any statistical significance. reply newsclues 4 hours agoparentprevAs a cyclist who has lifelong injuries from a bad driver hitting me, if driverless cars pose a threat to me, I will become very militant. reply mindvirus 8 hours agoprevI think insurance prices will drive adoption of self driving very quickly. Consider: if a non-self driving car is in an accident with a self driving car, it'll almost always be the non-self driving car at fault. And with the telemetry from the self-driving car, they can prove it too, so accidents that would have been no-fault or shared fault become fully the non-self driving cars fault. And so I think insurance for non-self driving cars gets expensive fast as there are more and more self driving cars on the road. reply coryfklein 3 hours agoparentInsurance for human drivers stays the same. If anything, it goes down, because the more Waymo-level autonomous vehicles on the road, the safer it is overall. Insurance isn't a zero sum game, where \"less insurance spent on autonomous vehicles\" means the insurance companies have to make up for it somewhere else. In a way, \"car driving getting safer overall\" isn't great for car insurers, because they make money financing auto risk, and if there is 50% less auto risk then they have less addressable market. reply fragmede 3 hours agorootparentInsurance is, however, a for profit corporation, out to maximize profits, so they'll charge both groups a premium, and then add a service fee on top of that. reply cloverich 2 hours agorootparentAnd when they post the obscene margins as a result of doing this, other insures can come in and undercut them. That's a key ingredient to making insurance work well. Its also why \"insurance\" doesn't work for healthcare. reply coryfklein 3 hours agorootparentprevNothing about that changes with the introduction of autonomous vehicles though, and it's a very open and highly competitive market. It is extremely easy to switch your auto insurance provider, and anyone who can pay some actuaries can start up a new business. (Though few do, because there isn't a huge margin to take away from the industry as it is.) reply myrmidon 8 hours agoparentprevWhy would insurance need to get more expensive for manual drivers as self-driving adoption increases? Ideally, insurance cost for self-driving cars would just be lower than insurance costs now (proportional to risk), and even insurance costs for manual drivers might go down because their risk decreases as well. reply mindvirus 7 hours agorootparentI think it's more about when the market is still majority manual. 20% self driving might see premiums for manual cars go up significantly because manual drivers would have more at fault accidents per mile than before (assuming the same rate of accidents, but most accidents with a self driving car are the manual driver's fault). There will also be things like not having DWIs and even cheap parking (since the car can drive away and park) that'll net out for self driving. And feedback loops there- the same size police force only pulling over manual cars from a smaller and smaller pool. reply myrmidon 7 hours agorootparent> assuming the same rate of accidents, but most accidents with a self driving car are the manual driver's fault This is a very shaky assumption in my view; more realistic would be (to me): 1) Overall accident rate reduction even for manual drivers 2) Reduced damage in accidents even for manual drivers 3) Slight increase in \"at-fault\" allocation toward manual drivers It seems very likely to me that those would result in net favorable effects even for manual drivers. I believe a lot of driving will move to full auto once viable, but not all of it because lots of people like to drive recreationally, and I simply don't see insurance rates for manual drivers spiking out of control-- just compare insurance pricing for less-safe vintage cars, which is also perfectly reasonable. reply Dalewyn 7 hours agorootparentprevInsurance premiums are higher for higher risk individuals/circumstances and lower for lower risk ones. If automatic driving lowers the floor of risk due to even lower risk than even the lowest risk human driver, insurance premiums will adjust to compensate and accomodate the now higher risk human driver compared to the now lower risk computer driver. And here's the kicker: Insurance premiums don't even have to increase for the human drivers. Once owners of automatic driving cars pay even cheaper premiums, that becomes the new baseline for \"cheap\" car insurance and the rest should be plainly obvious. \"Want lower rates? Get an automatic driving car.\" reply myrmidon 7 hours agorootparentI'm not disputing that insurance for full-auto cars is likely to be cheaper in the future, but I don't believe that manual driving insurance will ever get \"cripplingly\" expensive-- it might even go down compared to now thanks to reduced accident rates (contributed by full-auto cars). Also compare vintage-car insurance (which are in many cases drastically less safe): Pricing is perfectly viable there and has been for decades. reply BiteCode_dev 8 hours agorootparentprevBecause insurers are in the game to make money, and they will bait and switch. reply Etheryte 3 hours agoparentprevThis is not really how accident liability is sorted. Most countries have a clause in their traffic law that states that even if you're in the right, you must still do everything feasible to prevent an accident. If anything, I would imagine that self-driving cars would be held to a higher standard here, not humans. reply unshavedyak 3 hours agorootparentThe number of drivers that i see get into aggressive non-prevention habits just so they can \"be right and angry\" is kinda mind blowing. Ie someone goes into a roundabout when they perhaps shouldn't have, and so the other person who likely had rightofway guns the gas to make it even more obvious and risks and accident just to be \"right\". If you watch those dashcam communities you see similar behavior in what feels like half of the accidents. Someone else in the wrong but boy oh boy did the camera driver do nearly nothing to prevent the accident. reply InDubioProRubio 8 hours agoparentprevThis. The boomer generation can not be outvoted of rights, even when they will crawl the streets being traffic hazzards with dementia. So they will be pushed howling and screaming towards automated driving. reply ZacnyLos 8 hours agoparentprevOutside of mapped and heavily driven teritory? Good luck. reply michaelt 8 hours agorootparentBelieve it or not, a lot of driving takes place in heavily driven territory :) And I'm sure the autonomous vehicle will have a go-very-slowly mode for navigating people's driveways and similar places the mapping cars haven't been yet. reply jillesvangurp 7 hours agorootparentprevThe world is pretty well mapped at this point I don't think this will be a showstopper. And the nice thing about driver less cars is that they can drive wherever and whenever pretty cheaply. There's no driver to pay. Just the electricity bill for charging the vehicle and some servicing/vehicle depreciation and other fixed cost. That's a race to the bottom in terms of cost. There's no good economical reason to limit this to just small areas. You might charge passengers a bit extra if they are further out or even for the distance the car has to drive to pick them up. But there's no good reason for that to be very expensive as it would be with a paid driver. reply JumpCrisscross 8 hours agorootparentprev> Outside of mapped and heavily driven teritory? Why wouldn't rates go up for drivers driving outside mapped and well-driven territory? reply unyttigfjelltol 7 hours agoprevDid the paper really prove its claim? It set aside more than half of Waymo's claims history and compared only the most recent portion of its own history to the all drivers benchmark. All drivers do things that Waymo doesn't like operate outside specific city centers, drive in snow or other severe weather, real people drive more during the day in traffic but Waymo is biased toward nighttime (less traffic), and real people drive freeways and high speed roads. If you rigorously enforced those limits on regular drivers and additionally imposed an interlock device to prevent DUI and remote insurance company monitoring of driving habits-- that's the comparison population I want to see. Otherwise, this is a press release disguised as an academic paper. reply s1artibartfast 2 hours agoparentIt seems like you want them to explore a different question. Im confident that the best human drivers are better than Waymo. They are also better than all human drivers, by definition. If you are worried about other drivers hitting you, the \"all driver\" comparison seems relevant. If you want to know if Waymo is a safer driver than you are, that will depend on where you are on the spectrum. reply bitshiftfaced 4 hours agoparentprev> It set aside more than half of Waymo's claims history and compared only the most recent portion of its own history I don't see where the paper says this. Also, it compared against not only all drivers but also a subset of \"latest generation HDVs.\" reply zild3d 6 hours agoparentprevwhy should DUIs be excluded? There are regular human drivers out there at various levels of intoxication. I do want to know waymo vs all population. But yes it should be compared in the same areas during the same period. reply unyttigfjelltol 4 hours agorootparentMaybe DUI's should be included, but a paper drawing the conclusion that \"Waymo is safer because its computer drivers aren't drunk\" suggests very different policy actions. reply zamadatix 3 hours agorootparentUnless we really can finally stop drunk driving overnight after all these years of trying I don't agree the comparison should result in significantly different policy. I want to know how Waymo statistically compares to all of all the actual drivers when setting policy, not how Waymo compares to what we wish real drivers would have been like. The only mistake would be to compare solely to drunk drivers, which is what you comment makes it sound like. I would like to see the data sets filtered to match driving areas though. I.e. Waymo drives almost exclusively in urban environments so per mile data should be compared almost exclusively to urban driver data. reply unshavedyak 3 hours agorootparent> ..not how Waymo compares to what we wish real drivers would have been like. I want to see \"all the things\", but in specific reply to this point, i want to see this because i have no intention to commit a DUI myself. So the bar for me personally is how well it'll do compared to safe drivers. Lots of stats are useful, but i don't think we should undersell the various \"ai vs me\" comparisons that individuals could use. Since those are the ones that will help people decide if they themselves can/should/shouldn't take a Waymo or w/e. reply Dylan16807 3 hours agorootparentBut in terms of policy decisions, whether they should be allowed on the road, these are the correct numbers. Convincing people like you to ride is not the goal of this paper or its claims. reply unshavedyak 3 hours agorootparentSure, was just commenting that i find it valuable. Not a commentary on the validity of the paper. reply devangs 10 hours agoprevResults demonstrate that the Waymo ADS significantly outperformed both the overall driving population (88% reduction in property damage claims, 92% in bodily injury claims), and outperformed the more stringent latest-generation HDV benchmark (86% reduction in property damage claims and 90% in bodily injury claims). reply sebstefan 9 hours agoprevI can't trust that number if it comes from Waymo.com. I'd need to see it from an independant third party who has no interest having their finger on the scale reply zurfer 9 hours agoparentThe authors are from: a Swiss Reinsurance Company, Ltd, Switzerland b Zardini Lab (research affiliate), Massachusetts Institute of Technology, USA c Autonomous Systems Laboratory (research affiliate), Stanford University, USA d Waymo LLC, USA e Casualty Actuarial Society, USA reply ddalex 9 hours agorootparentSwiss Re is the actual thing when it comes to actuarial tables and statistics. reply richardw 8 hours agorootparentAnd would be very motivated to know the correct numbers in this case. reply passwordoops 8 hours agorootparentprevSo not independent. And published as a white paper on Waymo's website. And only addresses the collaboration between Waymo and the insurance company, no mention of who funded the academics. Pretty sure if you dig deep enough, Swiss Re is somehow a Waymo investor. I'd trust this more if Waymo had a direct pipeline to an anonymized public repository of their complete data set for independent analysis reply suddenlybananas 9 hours agorootparentprevSo you can't really trust it due to the obvious conflict of interest. reply hnaccount_rng 5 hours agorootparentI mean.. I get that for the Waymo guys. But the SwissRE ones? Seriously? Who _should_ do that evaluation? You will necessarily have Waymo co-authors. They have to provide the data. They are the only ones who have that.. reply vineyardmike 8 hours agoparentprevMost of this data they publish to the Government for legal reasons. Sure they could lie to the Government, but ask Cruise how well that went. Anecdotally, I see Waymos around town, and they are very clearly driving in a slower, safer, more cautious manner. a 92% reduction seems very plausible. reply digitcatphd 9 hours agoprevGood to see studies of incidents in comparison to human drivers. Historically what I have seen is 'self-driving car crashes into X, which seems to be concentrating exclusively on outliers to prove a point. reply CalRobert 9 hours agoparentFunny enough, when drivers hit people that’s _also_ reported as “car crashes in to x” reply MyFedora 6 hours agorootparentAh, the classics: \"Pedestrian involved in accident\" \"Cyclist collides with car\" \"Car brushes against cyclist\" \"Vehicle loses control\" Amazing how responsibility shifts when a two-ton machine is involved. reply milicat 7 hours agoprevStill worse than public transport, wastes more resources and endangers cyclists and pedestrians. I have yet to see anything that deserves to be called progress in self-driving. Yet another scam to sell more wasteful, inefficient vehicles. reply dkjaudyeqooe 3 hours agoparentWaymo is public transport. If they introduce automated vehicles that have fixed routes and larger carrying capacities then Waymo is indistinguishable from actual public transport. reply acuozzo 2 hours agoparentprev> Still worse than public transport I agree that the US needs better public transportation, but most of the US is not a city. If the nearest grocery store is 30 miles away and the nearest bus stop is several miles away from your home, then using public transportation turns this into a half-day affair. reply zahlman 2 hours agorootparentAt least 80% of the US population is considered urban (https://en.wikipedia.org/wiki/Urbanization_in_the_United_Sta...). reply Iulioh 7 hours agoparentprevPublic transport is not the answer to everything man and saying this again and again is cringe. -A man in his 20s who doesn't need a car and only uses public transport reply ericmay 4 hours agorootparentYou’re right that it’s not the answer to everything, but today car-only infrastructure is considered to be the answer to everything throughout America, so much so that we’ve reached the point where public transit is the only answer to how to move people more efficiently right now because it’s quite simply where all of our transit funding should be going. reply mavhc 7 hours agoparentprevIf I'm the only person going from/to somewhere having a large public transport vehicle take me is wasteful reply necovek 8 hours agoprevThis sounds quite a bit like massaging statistics until you get the numbers you like. A few things that pop to mind: did we exclude drivers who were not eligible to drive (under the influence, no valid driving permit, cars with issues [braking broken]...)? (This mostly matters for evaluating the average performance compared to average non-impaired human — a drunk person might mess up with self-driving vehicle sensors as well just for kicks once they are in suitable numbers and widely available) Did Waymo drive across all the same areas and time periods as the humans did with an equal \"proportion\"? Could we compare \"time behind wheel\" instead of miles travelled? (Eg. lots of small crashes happen when traffic is at a standstill) There are so many ways to slice and dice this and come up with favourable results for self-driving systems that I can't but be dubious of any claim. But notably, if we can liberate ourselves from driving through congested traffic, it would certainly reduce the incentive to speed and aim for more efficient driving as we'd be free to do other stuff while we get to our destination — and simply slowing down would buy both human and software drivers time to react and avoid most crashes (nothing really saves you from someone recklessly driving straight into your car). reply Reubend 7 hours agoparent> did we exclude drivers who were not eligible to drive One could argue here that it would be unfair to exclude the worst performing humans. Plenty of humans cause accidents for easily preventable reasons, but that's an honest part of our behavior. Or to rephrase, I think excluding the categories of people who drive terribly, but do still drive nonetheless, would be less representative of reality. > Did Waymo drive across all the same areas and time periods as the humans did with an equal \"proportion\"? No, they didn't. Their methodology didn't adjust for things like highway vs city street miles, although it did adjust for city and state. > Could we compare \"time behind wheel\" instead of miles travelled? We could, but that would incentivize slow driving rather than safe driving. You need to travel the same minimum distance from a hypothetical \"Point A\" to \"Point B\" no matter what, but the number of minutes could be inflated easily. Economic factors discourage inflating the number of miles. > There are so many ways to slice and dice this and come up with favourable results for self-driving systems that I can't but be dubious of any claim. I think it's fair to criticize the fact that they didn't adjust for geographic area with as much granularity as they should have (i.e. for highways vs city streets, or for excluded zones like airports). But other than that, their methodology seems solid to me. reply necovek 7 hours agorootparentI understand that viewpoint from an insurance perspective, but not necessarily from my own safety perspective: I wonder how well Waymo would fare in circumstances I see as a driver. Eg. humans can control whether they drive under the influence or not (eg. if you don't take your car to a bar, you ain't coming back driving it). But most notably, aggregated statistics like these focus on comparisons similar to comparing averages vs better statistical representations (like average vs median or p75 or... eg. it's possible for one driver to cause 20 collisions, and in a set of 10 drivers with no other collisions, we'd be at 2 collisions per driver instead of 0 really). It's also not only about highway/city street miles, it's also about time of day: if Waymo is proportionally less on the streets and areas where there is more risky driving (eg. around bars and around midnight to 3am when there are also drunk pedestrians around) compared to human drivers, that would obviously skew the numbers in SDV's favour. Again, potentially they did since they acknowledge a separate study focusing on those, but later on they only talk about aggregated insurance claims. They also acknowledge they are not accounting for accident severity, not even by using the dollar amount: while they had no fatalities, it's obviously important to weigh accidents by their severity. With all this said, this does demonstrate current insurance liability of an average human driver compared to a Waymo SDV in Phoenix and SFO, but only once we have more comparable data should we make a bigger claim. reply hnaccount_rng 6 hours agorootparentI get where you are coming from and you are correct. This is, up to a point, a PR piece of Waymo and we should take that into account. But they are pretty transparent about what they are doing. You just have to read the report. And for their metric, which rounds to \"all distance travelled in the interesting ZIP codes\", they are succeeding. What I'd take away from this is: If you give them a different metric, they can optimise for that too and they will end up being better than humans. That doesn't answer the questions: 1) Is it worth it? (I.e. what does it cost to achieve that) and 2) Is a Waymo better in any situation? I guess they don't have the answer to either yet. I'm pretty sure their cost-per-mile is still dropping like a rock (probably though not fast enough for their accountants) and they haven't reached all situations yet either. But I wouldn't bet on \"because it's too hard\", but rather \"because we didn't get there yet\" (and yes, they will have started with the easy part, as they should) reply foobarqux 1 hour agorootparentprev> No, they didn't. Their methodology didn't adjust for things like highway vs city street miles, although it did adjust for city and state. Doesn't Waymo only drive in the city? And damage/injury is much greater on highways? If so that pretty much makes the study worthless. reply myrmidon 7 hours agoparentprevRegarding drivers that are drunk or otherwise driving illegally-- why would you want to exclude them from such a study, if you can not exclude them from real traffic? If our current system of checks and incentives is not able to keep them off the road, then you need to take them and the accidents they cause into account when comparing driving safety with an autonomous system. Also note that the margins are too big, since only about a third of accidents involve intoxicated drivers, and the accident reduction rates from the paper are much higher than that. I don't want to come across as harsh or accusing, but the \"Methodology\" section contains a lot of detail (and a more nuanced discussion could be had without disregarding it entirely :P). reply necovek 7 hours agorootparentBecause they don't disappear even with half the non-illegal vehicles being autonomous — some crashes also happen due to avoidance manoeuvres. So the fairer comparison would be to say that if existing SDVs were instead being driven by human drivers, we would have seen ~60 property claims more and ~40 bodily injury claims more (forgot the exact numbers from the paper), which is what, like 0.1% improvement in claims overall (certainly still a great result for the small comparative number of miles travelled, but doesn't jump off the page really). But because the miles traveled are so far apart, nothing is really a \"fair\" comparison. reply hnaccount_rng 6 hours agorootparentBut.. they would disappear? Not all of course. But some drive under the influence because there is no other convenient way to get home after a night out. And Waymo solves that! And they are highly aware of their \"small number statistics\", they literally provide uncertainty ranges. For both SDVs and HDVs. And their values are consistent with increasing data. I.e. they ~only get smaller uncertainties but no significant drift. But they are statistically significantly better (which wasn't the case two years ago) reply jbarrow 7 hours agoparentprev> did we exclude drivers who were not eligible to drive I don't think we can discount people who aren't fit/eligible to drive _if they still drove_. They might not have a _legal_ right to be on the road, but they are still on the road. reply f1shy 7 hours agoparentprev>>did we exclude drivers who were not eligible to drive (under the influence, no valid driving permit, cars with issues [braking broken]...)? now THAT would be massaging statistics! Just take the best drivers, that had enough sleep, no drink, perfect car conditions... No. You have to compare with the whole world, \"as it is\" reply necovek 6 hours agorootparentWhat's the guarantee we'll have only fully up-to-date, safety-checked self-driving vehicles in the future with no messed up sensors or controls (there'll be impaired people doing the checks, right? :))? This is simple with a small, experimental fleet — so we are looking at the best case scenario for these vehicles, but the question is what does it fall down to in a realistic commercial application? That would also be comparing safety, because averages are always skewed by bad apples (i.e. 1 driver with 20 collisions gets an average to 2 for a group of 10 drivers with no other collisions). We at least need to start talking about medians, standard deviations groups and such. And we need autonomous vehicles to beat or match good drivers, otherwise, good drivers are worse off in the streets (and due to how averages are used, this might be more than 50% of drivers). Not sure why that's so controversial? reply hnaccount_rng 5 hours agorootparentI think you should open the PDF and look into that xD Really they discussed this. I'm still skeptical that they measure what we are interested in. But _your_ points they discuss reply necovek 1 hour agorootparentI went through the report, and they reference other studies that consider my points, but they end up only measuring incident numbers, don't specifically say how comparable were the driving conditions (iow whether they are representative). If anything, they could have removed incidents by human drivers which did not happen within their operating constraints, but I did not see that mentioned. reply hnaccount_rng 58 minutes agorootparentBut that data isn’t available to them. They are (iiuc) simply looking at the full set of insurance data and their own set. There simply is no driver-level data which would allow statistically relevant conclusions. Up to now their data for their own cars is still not able to strongly constrain the results. You wouldn’t be able to tell effects of sensor degradation. But let me ask this instead: What kind of analysis would you like to see? reply necovek 10 minutes agorootparentThe report specifically mentions a number of other studies and claims it improves on their methodology, and seems to want to have their methodology become the \"gold\" standard of measuring SDV vs HDV performance: \"This methodology establishes a foundation for future research into the safety impact potential of ADS and offers a framework for assessment as these systems continue to scale and develop.\" Or: \"By analyzing an unprecedented volume of autonomous miles, introducing a novel benchmark, and utilizing third-party liability insurance claims, we aim to set a new standard for ADS safety evaluation.\" Which leads me to worry that they are pushing for this to be considered comparative, and they want policy to be influenced by their claims. And they do: \"Our findings have the potential to significantly impact policy decisions, insurance practices, and public acceptance of ADS technology, contributing to the broader societal dialogue on the future of autonomous transportation.\" So I would like for them to compare to median non-impaired human driver with a car in good order (both in time-to-destination and safety), aggregate those over time of day, week and year (basically ensure identical driving conditions between comparison miles), adding claim dollar amount as weight for how severe the incident was. I believe that would be a great start. With them being Google and already tracking most Android phones as they go through traffic (they use this for traffic conditions), they do have a very rich data set they could compare to as well, but excluding that, they could exclude insurance claims which have happened in conditions they don't operate in (claims will always have time of event and location). reply f1shy 3 hours agorootparentprevThe study is about today. I would bot ever think to extrapolate that to “forever in the future” also is only one vendor. That is what the statistic shows and I think is fair comparison against human drivers currently on the street. reply fragmede 3 hours agorootparentprevIf you've used Google Chromecast or Google Chrome, a Tesla, or an Xbox, keeping software up to date isn't the chore it once was. Or you have to update to go online/have the car drive. The \"guarantee\" is that the other players who were too aggressive and did bad had to exit the industry. Uber killed a woman and exited the industry. Cruise dragged a woman 20 feet and lied about having footage of it, and exited the industry. So you ask what's the guarantee, and the guarantee is the same as when Google came out with Gmail, and everyone said that's stupid because how are you going to read your email when that website is down, so then they made",
    "originSummary": [
      "The study assesses the safety of Automated Driving Systems (ADS) by examining Waymo's performance over 25.3 million autonomous miles using insurance claims data.",
      "Findings indicate that Waymo's ADS significantly lowers property damage and bodily injury claims compared to both the general driving population and newer vehicles (2018-2021).",
      "The research provides an updated framework for evaluating ADS safety, with potential impacts on transportation safety policies and public acceptance."
    ],
    "commentSummary": [
      "Waymo's self-driving cars are reported to outperform human drivers in safety, but there is a lack of independent verification of these claims.",
      "Concerns exist about the potential impact of self-driving technology on jobs and the need for regulatory oversight.",
      "Critics suggest that improving public transportation infrastructure should be prioritized over relying solely on autonomous vehicles."
    ],
    "points": 175,
    "commentCount": 403,
    "retryCount": 0,
    "time": 1734683212
  },
  {
    "id": 42464966,
    "title": "How types make hard problems easy",
    "originLink": "https://mayhul.com/posts/type-driven-design/",
    "originBody": "How types make hard problems easy August 19, 2024 Over the last couple years, my programming brain has become increasingly warped around types, functional programming principles & Typescript. Most of it is influenced by the inordinate amount of time I’ve spent working on the Heartbeat codebase, a 300k+ line Typescript full-stack application that includes a React web app, a React Native mobile app and a Node.js server. My experience in this codebase has shown me that the more I lean into relying on the type system, the more I benefit. Writing code in a codebase that has fully bought into types feels like cheating. I can often implement 80% of a new feature without ever running the code. I’ll start working on a large refactor that requires breaking an assumption made throughout the code & quickly discover that the type system makes the change trivial. Simple features practically code themselves because typos are caught instantly and half my code is autocompleted. Nuanced questions from the support team about how a certain feature works can be answered with a quick Ctrl+F in the code even when little written documentation exists. Entire categories of bugs that I used to deal with have vanished. I’ve come to think of the style of coding that enables this as Type Driven Development. Below is a loose collection of thoughts & links to resources that have heavily influenced what type driven development means to me. 1) Let the types flow Investing in type safety is much more effective when types are able to flow across every surface of our application. In a simple full-stack application, the data flow typically looks like: database -> server -> client. Changing our database schema should cause us to see errors in our frontend code. By achieving this level of type interconnectedness, we can make changes to one side of our codebase and feel confident that the type system will inform us about the implications of that change, even if those implications are happening on a completely different side of the codebase. Enabling our types to flow through the system usually means: Using the same language everywhere. Naturally, if we want to share type information as much as possible, we need to be using the same language. While not perfect, React Native and Node.Js are powerful for allowing us to use Typescript on mobile & server-side. Making sure that type information is properly preserved across network boundaries. Using a well-typed ORM such as Prisma or Drizzle. Using a typed framework for API calls such as tRPC. Using a monorepo. We want changes in one part of the system to alert us about changes that need to made in other parts of the system, which doesn’t work when those other parts are in a different repo. Using any very rarely. Nothing breaks the flow of types more than any This can often times be the hard part. Letting the types flow entails doing a lot of work architecting the system in a way that allows for a completely closed loop. At Heartbeat, we’ve gone to extensive lengths to make this flow as robust as possible. And sometimes doing this work can feel pointless because I’m knee-deep in arcane Typescript errors instead of working on a new feature. But for any codebase that’s going to be sticking around for a while, setting up good base-level infrastructure is invaluable. 2) Start with the types Given that types act as a glue that tie the system together, the natural starting place for any new feature is the type definitions. The first thing I do when implementing a new feature is map out what are all the entities involved, what is their relationship, what properties do they have and how should they be represented as a type. This video is a great example of this concept: https://www.youtube.com/watch?v=2JB1_e5wZmU Some key takeaways from the video: a) type definitions are a great way to make sure that my understanding of the domain is aligned with reality. The process of writing these type definitions forces me to map out & wrangle the different components of the project in a comprehensive way. Usually this process results in me discovering gaps or ambiguities in the feature spec that I can then hash with the rest of the team. Often times, these gaps/ambiguities are things that would otherwise go undiscovered until I’m halfway through the project. At which point resolving them might involve throwing away most of the work I’ve already done. Type driven development brings these questions up to the beginning of the process, gets them answered, and serves as a blueprint for the rest of the project. b) type definitions are human-readable. They’re a great way for someone new (or me in the future) to get a high level understanding of how a feature is structured without having to dive into any actual code tracing. c) type definitions are both a documentation of the domain model AND real code that is directly used by our implementation. They are a living document that is guaranteed to be an accurate reflection of the codebase. d) an entity’s conceptual idea is more important than its representation. For example, an email address and a customer id are both represented by strings, but conceptually they are independent things and should not be considered the same type. This distinction should be reflected in our types. 3) Make illegal states unrepresentable Another key takeaway from the video that deserves it’s own section. Making our types reflect the true nature of the data as closely as possible makes it almost impossible to mess up. Some concrete examples of what this can look like in Typescript: We have Product entity. Every product must have at least one price associated with it: type NonEmptyArray = [T, ...T[]]; type Price = //something interface Product {//... prices: NonEmptyArray; //... } function createProduct(product: Product) { //... } //If I try to create a product with no prices, I get a type error createProduct({prices: [], }) Our users can optionally choose to give us their address: //Bad implemenation type User = {//...addressLine1?: string;addressLine2?: string;city?: string;state?: string;country?: string;//... }; function createUser(user: User) {//... } //It's possible for me to create a user & forget to include parts of their address createUser({//...addressLine1: \"123 Example St\",//... }); /*-------------------------------------------*/ //Good implemenation type User = {//...address: { line1: string; line2: string; city: string; state: string; country: string;}null;//... }; //The type system makes sure that we provide everything if we choose to createUser({//...address: { line1: \"123 Example St\", line2: \"Apt 1D\", city: \"Seattle\", state: \"Washington\", country: \"USA\",},//... }); Structuring our types in this way removes a complete category of bugs from ever occurring. Every single state that we make illegal via our type system was a bug waiting to happen in an alternate universe. Additionally, the process of making illegal states unrepresentable is valuable too. Making our types represent the “truth” as closely as possible forces us to ask a lot of questions about what the truth is. Are there cases where it makes sense for a product to have no prices? How many possible states are there? Are state X and Y actually different, or are they essentially the same thing? And those questions are vital to understanding the full expanse of the problem we’re trying to solve. 4) Parse, don’t validate Reading this article crystalized so many loose thoughts that I had into a clean slogan: https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/. The key insight of the article is that types can be interpreted as a vehicle to “store” validation. Having validation work encoded in our types means that: the rest of our code is allowed to make assumptions about data without having to constantly validate those assumptions the type system enforces that validation happens when needed changing these assumptions is much easier. We can change the types to reflect a new assumption & the type system will point us to the implications of this change (The only reason this section is so short is that the article explains things perfectly. Definitely go read it!) 5) Be honest In many ways, I’ve come to think of programming as finding the truth. The goal is to find the purest, rawest, deepest essence of what an entity represents and express that as a type. And if my goal is truth, then I need to value being honest in my code. This can manifest itself via “make illegal states unrepresentable” — I don’t want to lie and say that something is possible when it isn’t. Or, if I dive down and discover that two things I thought were the same are actually different, I shouldn’t lie and refer to them with the same type. I should do the extra work to split them into different types because that would be a more honest representation of the truth. To contrast that grandiose description, here’s a mundane example. We have a calendar app where users can create events & see a list of their events: type Event = { id: EventId; title: string; description: string; startTime: Date; endTime: Date; duration: number; } function EventList(props: { events: Event[] }) { return (My Events {props.events.map((ev) => ())}) } function EventListItem(props: { event: Event }) { return ({props.event.name} {props.event.description} Start: {props.event.startTime} End: {props.event.endTime}) } We decide to add a new feature. Users can now create recurring events! Users define a recurring event using a recurrence rule, which specifies when & how often the event repeats. We want our event list to show all instances of upcoming recurring events. To do this we create a getExpandedEvent function which takes in an event. If the event is recurring, the event gets expanded to include all of the instances. Otherwise we return the single event. Once we create this function, all we need to do is call it in our EventList component and then we can continue as usual. type Event = { id: EventId; title: string; description: string; startTime: Date; endTime: Date; duration: number; //New field added recurrenceRule: stringnull; } function getRecurringDates(startTime: Date, recurrenceRule: string): Date[] { //calculate all the recurring dates according to the recurrence rule } function getExpandedEvent(event: Event): Event[] { if (event.recurrenceRule !== null) { const recurringDates = getRecurringDates( event.startTime, event.recurrenceRule ) return recurringDates.map((date) => ({ ...event, startTime: date, })) } else { return [event] } } function EventList(props: { events: Event[] }) { const expandedEvents = getExpandedEvent(props.events).flat() return (My Events {expandedEvents.map((ev) => ())}) } This works great. Users can see all their recurring events with no issues. A month later, we decide to finally add a button for users to delete their events. So we do something like this: function EventListItem(props: { event: Event }) { //If you aren't familiar with tRPC, all you need to know is that deleteEvent.mutateAsync is a function that makes an API request to our server. On the server, we delete the event const deleteEvent = trpc.deleteEvent.useMutation() return ({props.event.name} {props.event.description} Start: {props.event.startTime} End: {props.event.endTime}deleteEvent.mutateAsync(props.event.id)}>Delete) } Seems pretty straightforward, so we go ahead and ship it. Soon, the customer bug reports come in: “I was trying to delete the May instance of my monthly event, but the whole thing disappeared!?!?!” As you may have noticed, the issue with this implementation is that clicking delete on an instance of a recurring event will delete the entire event. Probably not the behavior that we want. There’s a couple things that went wrong to get here: Whoever was speccing the delete event feature should have called out how it should work for non-recurring vs recurring events We probably would have realized this was weird if we had more tests or QA before releasing And while those might be true, I’d argue that one of the underlying reasons we got here was because we weren’t fully honest when we implemented the getExpandedEvent function. At the time, it was convenient to continue using the Event type. All we needed to do is call the function and everything else would remain the same. But if we were honest, we would have recognized that while very similar, events & event instances are different concepts. An Event is the core object that gets stored in the database. When someone creates a recurring event - say a meeting every Monday for a year - we don’t store 52 different events in the database. Instead, we store a single Event with a recurrence rule. Then, whenever someone needs to see their upcoming events, we use that rule to generate the appropriate EventInstances, each representing one occurrence of the meeting. Events are stored in the database, while event instances are ephemeral. Events can be created, while event instances cannot. Editing an Event (changing the meeting from Mondays at 2pm to Mondays at 3pm) is a completely different action from editing an EventInstance (rescheduling just one specific Monday’s meeting to Tuesday). A more honest representation might look like this: type EventInstance = Omit & {id: EventInstanceId;eventId: EventId; }; function getEventInstanceId(eventId: EventId, startTime: Date) {return `${eventId}-${startTime.toISOString()}` as EventInstanceId; } function getEventInstances(event: Event): EventInstance[] {if (event.recurrenceRule !== null) { const recurringDates = getRecurringDates(event.startTime, event.recurrenceRule); return recurringDates.map((date) => ({...event,startTime: date,id: getEventInstanceId(event.id, date),eventId: event.id, }));} else { return [{ ...event, id: getEventInstanceId(event.id, event.startTime), eventId: event.id,}, ];} } function EventListItem(props: { eventInstance: EventInstance }) {//Render event instance } The exact implementation of EventInstance would vary depending on what behavior we wanted. But the key point is differentiating event instances from events. If we had done this we never would have ran into the deletion issue because it would be clear that the deleteEvent endpoint is not applicable to event instances. In fact, going back to Start with the types, the EventInstance type in our codebase likely would have made us realize during the feature speccing phase that we needed to handle deleting events and deleting event instances separately. It’s easy to see why we wouldn’t want to make this change. It’s more work for no immediate payoff. Adding the new type requires changing EventListItem as well. In a larger project, the new type might require even more refactoring across the codebase. But by being lazy the first time, we introduced a subtle lie into our type system that corrupted it, causing it to deviate slightly from being a true representation of the underlying domain. This prevented the types from helping us when we needed them later. 6) Be specific A companion to being honest is being specific. We don’t want to lie by omission. So as much as possible, we want our types to be the narrowest possible expression of the truth. Branded types are a great example of this. We could use a string to represent the id of a user and it would be an honest representation. But by using a branded UserID type instead, we can be even more specific about what a user id truly represents. And the more specific we are, the more the type checker is able to help us out: type CommunityID = string & { readonly _: \"__CommunityID__\" }; type UserID = string & { readonly _: \"__UserID__\" }; type PostID = string & { readonly _: \"__PostID__\" }; interface Post {id: PostID;createdBy: UserID;communityID: CommunityID;//... } function getIsUserAdmin(userID: UserID) {//... } function getShouldShowPost(post: Post) {//If we accidentally call this function with the wrong id, we get a type errorconst isAdmin = getIsUserAdmin(post.communityID);const isAdmin = getIsUserAdmin(post.createdBy);//... } 7) Pure functions as a type bridge Once you start to see everything in your codebase through the lens of types, any action a user takes can be reduced down to a series of type jumps. Define the starting types. Define the ending type. Find a way to go from the starting types to the ending type. What’s the best way to convert one type to another with no distractions? A pure function. That’s quite literally what the mathematical definition of a function is. Let’s say that we’re implementing a payment page. Our domain looks like this: type Price = {id: PriceId;amount: number;interval: \"month\"\"year\"; }; type Product = {id: ProductId;name: string;prices: NonEmptyArray; }; type Subscription = {id: SubscriptionId;status: \"active\"\"canceled\";productId: ProductId;priceId: PriceId; }; type User = {id: UserId;subscriptions: Subscription[]; }; Our payment page has 3 different possibilities: The user has not purchased the product yet, in which they can choose a price point & make the purchase The user is currently subscribed, in which case we show a Cancel Subscription button. When the user clicks on this button: If they’ve been a subscriber for more than 12 months, offer them a 1% discount for each month they’ve been a subscriber (capped at 50%) Otherwise, offer them a flat $5 discount The user has canceled their subscription, in which case we prompt them to restart their subscription Representing this as a type, we get: type Discount =| {type: \"PERCENTAGE\";percentage: number; }| {type: \"FLAT_AMOUNT\";amount: number; }; type CheckoutPageState =| {type: \"INITIAL_PURCHASE\";product: Product; }| {type: \"CANCELED\";subscriptionId: SubscriptionId; }| {type: \"ALREADY_SUBSCRIBED\";product: Product;cancelationDiscount: Discount; }; A user visits the payment page for a particular product. We need to render the page. How do we do this? Well, given that we have these types established, the task at hand is clear. We need to convert a Product and a User into a CheckoutPageState. If the user has an active subscription, we need to convert a Subscription to a Discount. So…we write two pure functions to do the conversion & we’re done. //We pass in now as a parameter to make the function fully pure //This makes testing the function easy function getDiscount(subscription: Subscription, now: Date): Discount {const numMonths = differenceInMonths(now, subscription.createdAt);if (numMonths > 12) { return {type: \"PERCENTAGE\",percentage: Math.min(50, numMonths), };} else { return {type: \"FLAT_AMOUNT\",amount: 5, };} } function getCheckoutPageState(product: Product, user: User, now: Date): CheckoutPageState {const existingSubscription = user.subscriptions.find((x) => x.productId === product.id);if (existingSubscription !== undefined) { if (existingSubscription.status === \"canceled\") {return { type: \"CANCELED\", subscriptionId: existingSubscription.id,}; } else if (existingSubscription.status === \"active\") {const discount = getDiscount(existingSubscription, now);return { type: \"ALREADY_SUBSCRIBED\", product: product, cancelationDiscount: discount,}; } else {assertNever(existingSubscription.status); }} else { return {type: \"INITIAL_PURCHASE\",product: product, };} } //***** CheckoutPage.tsx *****\\\\ function CheckoutPage(props: CheckoutPageState) {if (props.type === \"INITIAL_PURCHASE\") { //render initial purchase} else if (props.type === \"ALREADY_SUBSCRIBED\") { //render already subscribed} else if (props.type === \"CANCELED\") { //render canceled} else { safeAssertNever(props.type); return null;} } Hopefully, you can imagine how this small example could expand to a production application with dozens of types & hundreds of business logic rules encoded in a network of pure functions. The magic of pure functions is that they turn something intimidating into something approachable. We could have the gnarliest, most complicated domain with tons of intersecting edge cases and unintuitive logic. But if we’ve broken it down into the constituent types, then at any given moment all I need to worry about is converting IntermediateType5 to IntermediateType6. I don’t need to think about anything else. That level of clarity & focus does wonders for easing my mental burden while working on large project. For a full-stack application, the pattern is simple: Define types for my core entities, the ones that get stored in the database (Product, Price, User, Subscription) Define my intermediate types (Discount, CheckoutPageState) Fetch the relevant core entities from the database Run my entities through a series of pure functions, jumping from type to type, until I have a UI to show Even React, the final piece of the puzzle in this example, is built on functional programming principles. Our CheckoutPage React component is one last pure function that converts the CheckoutPageState type to JSX that gets rendered on the screen. 8) Ask and you shall receive One of the most common changes required by a new feature is something that used to be simple gets just slightly more nuanced. Before the feature, we call a function and it does the thing. But now, that function needs a little bit more context. And based on that context, it does something a little bit different. For example, let’s say we have a generateInvoice function that takes in various values and uses them to generate an Invoice object. The details of the function itself are irrelevant. function generateInvoice(params: {customerId: string;currency: string;items: InvoiceItem[];//... }): Invoice {//Generate the invoice } But now the time has finally come for us to stop ignoring the IRS’ emails and start properly collecting tax from our users. To do so, our invoices will need to look different depending on what the tax rate is. With types, my approach for a change like this is straightforward. I go to the function that needs the additional context and I edit the input type to include the new context that I need. And then I see what type errors I get. If the function that’s calling generateInvoice doesn’t know what the taxRate should be, then I add taxRate to the input for that function and continue up the call stack. Eventually, I reach a function that is able to either pull the necessary context from a stateful source (a database, endpoint, etc) OR I’m able to calculate the necessary value and pass it in. So in this case, let’s say I add the taxRate field to params and see the following two errors: One that’s happening on the backend when we call generateInvoice from generateInvoiceForCustomer. To fix it, I call calculateTaxRateForCustomer inside generateInvoiceForCustomer and pass the result of that function into generateInvoice. One that’s happening on the frontend when we call generateInvoice from previewInvoice. In this case, we’re generating a preview invoice for a sample customer, so there’s no tax rate to be calculated. Instead, I just pass in a static value of 0.1 to use as the example tax rate. This approach saves a lot of time and headache. In a larger application, it’s possible that generateInvoice is being called from 7 different contexts. Rather than proactively trying to map out all of these different cases, I just tell the type system that I need a certain value and let it guide to me where I need to go next. 9) If it compiles, it works Haskell developers have a refrain that if the code compiles, it probably works. While Haskell is on the extreme side of the spectrum, I’ve found this to also be quite true for any system that relies heavily on types. Having types embedded in our codebase means the feedback loop for our code comes directly from the editor & type errors. I don’t need to run the code to see if I messed up, because my editor lets me know as I type. There’s an inverse relationship between the expressiveness of the types and the number of possible programs that type check successfully. So when our types are honest & specific, it can be hard to write code that type checks without doing what we want it do. The best example of this is how productive I’ve become on airplanes. Despite being a full-stack application that needs Internet to run locally, I can get on a flight with no wifi, pull out my laptop & implement a new Heartbeat feature with zero distractions — just me and my type checker. When I eventually land and run the code, I’m usually good to go after some UI work & maybe 2-3 quick bug fixes. 10) Types as an introspection tool One of the most underrated aspects of Typescript is how it can be used as a tool to understand your codebase. If I’m trying to understand how a certain feature works, I can play around with the types to help me learn about how parts of that feature interact with the rest of the codebase. For instance, let’s say I’m working on an update where I want to standardize how we can display prices in the product. Right now the only currency that we support is USD, and all of our prices are displayed like this: $100.00. But we’re getting some confusion from people in Canada about whether we’re referring to USD or CAD, so we want to update the UI to clarify that we mean USD. We show prices on a lot of different components in various contexts, so tracking down everything will be difficult. What can I do is temporarily delete the amount field from the Price type: type Price = {id: PriceId;interval: \"month\"\"year\"; }; Now, anywhere that I attempt to reference the amount field, I’ll get a type error instead. So if I have 10 different components that display a price in some way, Typescript will point me towards each of those components. I can go to each of them, make the changes I need to and undo the change I made to the type. Or, let’s say we have a Button component in our design system and we’re considering getting rid of the success variant because it feels unnecessary. To help us make the decision, we want to identify all the screens in our product where we use a success button. interface Props {//...variant?: \"primary\"\"secondary\"\"success\";//... } function Button(props: Props) {//button } I could do a Ctrl-F for success and try to find examples that way — but predictably it will lead to lots of unrelated results popping up. My approach in these situations is to just delete success as one of the options in Props. By doing this, I’ll immediately get type errors that point me to the exact location of every success button in the product. From there, I can click through the results and evaluate whether the success button is necessary or if it can be replaced with an alternative. The ability to quickly answer questions like “Where does every success button in our product live?” means that I can even use the codebase as a tool in design/product planning meetings. 11) Hard mode and easy mode Using types extensively splits coding into 2 phases. A short period of intense & difficult work followed by a longer period of straightforward work that’s hard to mess up. The hard part is setting up the scaffolding & defining the types. In Typescript, scaffolding can involve delving into arcane type-level programming or setting up complex frameworks to make sure that types are propagated robustly. As we’ve talked about above, defining types involves deep rumination to figure out what states are valid, how to be honest, where to draw the line between entities, etc. Figuring all of this out can be intimidating and cumbersome. But, the hard work pays off because coding with types on is astoundingly EASY. The editor is constantly guiding me down the right path. Typos, misused variables, forgotten validation checks are all caught instantly. Autocomplete means I don’t even need to type that much. In the age of AI code completion, type definitions provide a valuable source of documentation to help the AI provide more accurate suggestions. And the type checker makes it harder for invalid AI-suggested code to go unnoticed. This dichotomy gels really well with the way my brain works. I’m able to channel short bursts of creative energy into precisely mapping the domain or getting type scaffolding set up. And then I’m able to sustain long coding sessions to actually implement the feature because the scaffolding means I rarely have to think too hard. 12) Know when to opt out This one might be controversial for some — but I really like that Typescript allows us to cheat every now and then. Knowing when it’s ok to throw our hands up and use an any is important. If we’re thoughtful, we can maintain 99.9% of the benefits of the type system without wasting days trying to cover the last 0.1%. Typically using any or type assertions such as as string are a bad idea because they’re a form of lying to the type system. But in situations where we genuinely know better than the type system and the scope of the assertion is small, a small lie is acceptable. A common time where we might know better than the type system is when dealing with external dependencies or legacy code. For example, this is the helper function we use for getting feature flags from Posthog: export const POSTHOG_FLAGS = {\"longer-free-trial\": [\"control\", \"30-days\"],\"checkout-page-design\": [\"control\", \"variant-a\", \"variant-b\"], } as const; export type PosthogFlag = keyof typeof POSTHOG_FLAGS; export async function getPosthogFlagVariant(userID: UserID, flagName: T) {const variant = await posthog.getFeatureFlag(flagName, userID);return variant as (typeof POSTHOG_FLAGS)[T][number]undefined; } The default return type for posthog.getFeatureFlag is stringbooleanundefined. But we have more precise knowledge. If we’re getting a value for longer-free-trial then the return type must be either control or 30-days. So we can use the type assertion to assert our knowledge onto Typescript. And by doing so, anyone calling the getPosthogFlagVariant will have much more accurate & specific types. Because POSTHOG_FLAGS is edited in a very controlled context (only when we’re adding or changing a feature flag), we can feel confident that unrelated changes to the codebase are unlikely to cause this lie to backfire. Make illegal states unrepresentable is another rule that’s helpful to know when to break. There are times when the work it would take to make an illegal state fully unrepresentable is just not worth it. And if I know that changes to what a legal state is are possible in the future, I might not want to cut off all our options too forcefully. Building an intuition for when to leave the door open is difficult and mostly comes from experience. A great example of this is preemptive pluralization. At the end of the day, it’s important to remember that all of these rules are in place to help us be more productive. We’re here to use the tool, not let the tool use us. Have thoughts? Want to work with me at Heartbeat? Reach out at mayhul99@gmail.com! I'd love to hear from you. Want to get emails for new posts?Subscribe",
    "commentLink": "https://news.ycombinator.com/item?id=42464966",
    "commentBody": "How types make hard problems easy (mayhul.com)140 points by tlf 23 hours agohidepastfavorite152 comments digging 21 hours agoI loved this paragraph: > This dichotomy gels really well with the way my brain works. I’m able to channel short bursts of creative energy into precisely mapping the domain or getting type scaffolding set up. And then I’m able to sustain long coding sessions to actually implement the feature because the scaffolding means I rarely have to think too hard. It's why I keep begging my team, every time there's a new codebase (or even a new feature), to stop throwing `any` onto everything more complicated than a primitive. It is exhausting. It forces me to waste energy on the shitty, tedious parts. It forces me to debug working code just to find out how it works before I can start my work. They tend to take the quickest solution to everything -- which means everyone else has to do the same work over and over again until someone (me, invariably) sits down and makes a permanent record of it. In doing this they ensure that I can't trust any of their code, which is counterproductive for what should be obvious reasons. Every time I work on established, untyped (or poorly typed) code, it's like I'm writing new code with hidden, legacy dependencies. reply stouset 19 hours agoparentThe longer I’m in this industry, the more I find that there are two types of programmers: those who default to writing every program procedurally and those who default to doing so declaratively. The former like to brag about how quickly they can go from zero to a working solution. The latter brag about how their solutions have fewer bugs, need less maintenance, and are easier to refactor. I am squarely in the latter camp. I like strong and capable type systems that constrain the space so much that—like you say—the implementation is usually rote. I like DSLs that allow you to describe the solution and have the details implemented for you. I personally think it’s crazy how much of the industry tends toward the former. Yes there are some domains where going the time from zero to a working product is critical. And there are domains where the most important thing is being able to respond to wildly changing requirements. But so much more of our time and energy is spent maintaining code than writing it in the first place that upfront work like defining and relating types rapidly pays dividends. I have multiple products in production at $JOB that have survived nearly a decade without requiring active maintenance other than updating dependencies for vulnerabilities. They have had a new version deployed maybe 3-5 times in their service lives and will likely stay around for another five years to come. Being able to build something once and not having to constantly fix it is a superpower. reply dasil003 17 hours agorootparent> Yes there are some domains where going from the time from zero to a working product is critical. And there are domains where the most important thing is being able to respond to wildly changing requirements I agree with your observations, but I'd suggest it's not so much about domain (though I see where you're coming from and don't disagree), but about volatility and the business lifecycle in your particular codebase. Early on in a startup you definintely need to optimize for speed of finding product-market fit. But if you are successful then you are saddled with maintenance, and when that happens you want a more constrained code base that is easier to reason about. The code base has to survive across that transition, so what do you do? Personally, I think overly restrictive approaches will kill you before you have traction. The scrappy shoot-from-the-hip startup on Rails will beat the Haskell code craftsmen 99 out of 100 times. What happens next though? If you go from 10 to 100 to 1000 engineers with the same approach, legibility and development velocity will fall off a cliff really quickly. At some point (pretty quickly) stability and maintainability become critical factors that impact speed of delivery. This is where maturity comes in—it's not about some ideal engineering approach, it's about recognition that software exists to serve a real world goal, and how you optimize that depends not only on the state of your code base but also the state of your customers and the business conditions that you are operating in. A lot of us became software engineers because we appreciate the concreteness of technical concerns and wanted to avoid the messiness of human considations and social dynamics, but ultimately those are where the value is delivered, and we can't justify our paychecks without recognizing that. reply stouset 14 hours agorootparentSure it’s important for startups to find market traction. But startups aren’t the majority of software, and even startups frequently have to build supporting services that have pretty well-known requirements by the time they’re being built. We way overindex on the first month or even week of development and pay the cost of it for years and years thereafter. reply sfn42 8 hours agorootparentprevI'm not convinced that this argument holds at all. Writing good code doesn't take much more time than writing crap code, it might not take any more time at all when you account for debugging and such. It might be flat out faster. If you always maintain a high standard you get better and faster at doing it right and it stops making sense to think of doing it differently as a worthwhile tradeoff. reply mithametacs 5 hours agorootparentThat's the hard part of project management. Is it worth spending a bit more time up-front, hoping to prevent refactoring later, or is it better to build a buggy version then improve it? I like thinking with pen-and-paper diagrams; I don't enjoy the mechanics of code editing. So I lean toward upfront planning. I think you're right but it's hard to know for sure. Has anyone studied software methodologies for time taken to build $X? That seems like a beast of an experimental design, but I'd love to see. reply sfn42 2 hours agorootparentI personally don't actually see it as a project management issue so much as a developer issue. Maybe I'm lucky but in the projects I've worked, a project manager generally doesn't get involved in how I do my job. Maybe a tech lead or something lays down some ground rules like test requirements etc but at the end of the day it's a team effort, we review each other's code and help each other maintain a high quality. I think you'd be hard pressed to find a team that lacks this kind of cooperation and maintains consistently high quality, regardless of what some nontechnical project manager says or does. It's also an individual effort to build the knowledge and skill required to produce quality code, especially when nobody else takes responsibility of the architectural structure of a codebase, as is often the case in my experience. I think that in order to keep a codebase clean you have to have a person who takes ownership of the code as a whole, has plans for how it should evolve etc. API surfaces as well as lower level implementation details. You either have a head chef or you have too many cooks, there's not a lot of middle ground in my opinion. reply layer8 17 hours agorootparentprevWhat does strong typing have to do with procedural vs. declarative? IMO strong typing is beneficial regardless. reply whilenot-dev 13 hours agorootparentNot OP, but I'd answer... A strong type system is your knowledge about the world, or more precisely, your modeled knowledge about what this world is or contains - the focus is more on data structures and data types, and that's as declarative as it can get with programming languages(?). I'd also call it to be holistic. A procedural approach focussed more on how this world should be transformed - through the use of conditional branching and algorithms. The focus feels to be less on circumstances of this world, but more to be on temporary conditions of micro-states (if that makes any sense). I'd would call it to be reductionistic. reply mithametacs 16 hours agorootparentprevGrandparent was such a good post otherwise! I love strong types. I love for loops. I love stacks. GP! Try Rust. Imperative programming isn’t orthogonal to types. You can go hard in Rust. (I loved experimenting with it but I like GC) GP! Try data driven design. Imperative programming isn’t orthogonal to declarative. Real talk, show me any declarative game engine that’s worth looking at. The best ones are all imperative and data driven design is popular. Clearly imperative code has something going for it. and the advantages aren’t strictly speed of development, but imperative can be clearer. It just depends. reply stouset 11 hours agorootparentI adore Rust. My point isn’t that you can’t have both, but that the two types of programmers have different default approaches to problem solving. One prefers to model the boundaries of domain as best they can (define what it should look like before implementing how it works), one prefers to do things procedurally (implement how it works and let “what it looks like” emerge as a natural result). Neither is strongly wrong or right, better or worse. They have different strengths in different problem areas, though I do think we’ve swung far too hard toward the procedural approach in the last decade. reply mithametacs 5 hours agorootparentI agree with the distinction in approaches. In other words, it sounds like you're distinguishing agile and waterfall. I just find it odd to analogize: > agile : waterfall :: imperative : declarative reply stouset 2 hours agorootparentEither you misread something or I communicated poorly. reply rendaw 17 hours agorootparentprevI think GPs point is that they haven't gone from zero to a working solution, they've gone from zero to N% towards a working solution and then slowed down everyone else. Maybe for the most trivial programs they can actually reach a solution. You can't write a program without knowing that x is a string or a number, your only choice is whether you document that or not. reply mithametacs 15 hours agorootparentYes you can, you handle every case equally. You don’t even need the reflection mechanisms to be visible to the user with a good type system. A good type system participates in codegen. for a really simple example: languages which allow narrowing a numeric to a float, but also let you interpolate either into a string without knowing which you have. A statically typed Console.log in JS/TS would be an unnecessary annoyance. reply jfwuasdfs 17 hours agorootparentprevAgreed 100%. Other benefit is fearless refactoring since API changes appear as type errors. With no type-checking you need to gamble testing all codepaths. reply throwaway2037 14 hours agorootparentprev> those who default to writing every program procedurally and those who default to doing so declaratively. What is the difference between programming procedurally and programming declaratively? I saw these terms used this way. reply Mikhail_Edoshin 11 hours agorootparentIt is actually a rather hard question. There is a web page somewhere where the author asks it, lists possible answers and get amazed by some of the definitions, such as \"declarative is parallelizable\". Cannot find it now, unfortunately. I would say that imperative is the one that does computation in steps so that one can at each step decide what to do next. Declarative normally lacks this step-like quality. There are non-languages that consist solely of steps (e.g. macros in some tools that allow to record a sequence of steps), but while this is indeed imperative, this is not programming. reply stouset 10 hours agorootparentHere’s my personal attempt at a definition. One side cares more about how the solution is implemented. They put a lot of focus on the stuff inside functions: this happens, then that happens, then the next thing happens. The other side cares more about the outside of functions. The function declarations themselves. The types they invoke and how they relate to one another. The way data flows between parts of the program, and the constraints at each of those phases. Obviously a program must contain both. Some languages only let you do so much in the type system and everything else needs to be done procedurally. Some languages let you encode so much into the structure of the program that by the time you go to write the implementations they’re trivial. reply mithametacs 5 hours agorootparentprevSounds like a page worth another search if you don't mind. I'll give you Internet Points in return! -- my attempt: Imperative defines the order and semantics of each step. Declarative defines the prerequisites and intent of each step. The algorithms each can implement are equivalent. reply Mikhail_Edoshin 2 hours agorootparentFound it: https://existentialtype.wordpress.com/2013/07/18/what-if-any... Semantic is another word that is hard to define. reply mithametacs 48 minutes agorootparentI read that and the followup. It’s good writing but I slightly disagree. Imperative is actually a closer mathematical formalism for some things. I find imperative better for expressing state machines. I find declarative better for backtracking. You can write a state machine with just a loop, an assignable, and conditions. Writing state in prolog is irritating. reply DontchaKnowit 13 hours agorootparentprevI am also squarely declarative, but currently use a language for work that forces me to be procedural pretty much always and it kinda sucks. My code always feels bad to me and the cognitive load is always super high reply eyelidlessness 2 hours agorootparentIs it the language that forces procedural code? In my experience it’s usually the stdlib, but the language itself is capable of declarative constructs outside of existing APIs. If that’s the case, an approach like “functional core, imperative shell” is often a good one. You can treat the stdlib like it’s any other external API, and walk it off as such. reply Mikhail_Edoshin 12 hours agorootparentprevDeclarative programming is essentially programming through a parameter. The declaration is that parameter that will be passed to some instruction. In small doses declarative programming occurs with every function call. In declarative programming the parameter is essentially the whole program and the instruction is implicit; we know more or less how it works, but generally assume it just exists or even forget about it and take it as the way things work. Of course declarative programming is simpler and less error prone. But it is also essentially inflexible. The implicit instruction is finite and will inevitably run into a situation when the baked execution logic does not quite fit. It will be either inefficient or require a verbose and repetitive parameter, or just flat out incapable of doing what is desired. In this case declarative programming fails; it is impossible to fix unless we rewrite the underlying instruction. E.g. 'printf' is a small example of declarative programming. It does work rather well, especially when the compiler is smart about type checks, but once you want to vary the text conditionally it fails. (The thing that replaces 'printf' are template engines that basically reimplement same logic and control statements you already have in any language and the engine works as an interpreter of that logic. The logic is rather crude and limited and the finer details of formatting are left to callbacks that are mostly procedural.) For example, how do I format a list so that I get \"A\" for 1, \"A and A\" for 2, and \"A, A, and A\" for more? Or how I format a number so that the thousand separator appears only if the number is greater than 9999? Or what to do if I have an UTF-8 output, but some strings I need to handle are UTF-16? The existing declarative way did not foresee these cases and to add them to the current model would complicate it substantially. But if I have a simple writer that writes basically numbers and strings I can very quickly write procedures for these specific cases. Instructions are primary by their nature. A piece of data on its own cannot do anything. It always has an implicit instruction that will handle it. So instructions are the things we have to master. reply ninetyninenine 18 hours agorootparentprevIt’s not crazy, you have a million instructions and you’re just going to write all of that out in a single declaration or a list of procedures? First off the declaration is better as it’s less error prone but it comes at the cost of being harder to write and harder to interpret. Imagine if we communicated with one declarative run on sentence. No paragraphs at all… Procedures are default and easier to our nature as humans. reply dismalaf 17 hours agorootparentprev> I personally think it’s crazy how much of the industry tends toward the former. It's because most people who use technology literally don't care how it works. They have real, physical problems in the real world that need to be solved and they only care if the piece of technology they use gives them the right answer. That's it. Literally everything programmers care about means nothing to the average person. They just want the answer. They might care about performance if they have to click the same button enough times, and maybe care about bugs if it's something that is constantly in their face. But just working is enough... reply nine_k 16 hours agorootparent> they only care if the piece of technology they use gives them the right answer. A poorly typed program often would give a wrong answer, or, in a less dangerous case, crash. Same for physical parts: you want them to solve some business problem, but often you won't go for the absolute cheapest, because they may work poorly. reply dismalaf 12 hours agorootparentI'm thinking more along the lines of how scripting languages are often used in, say, scientific domains (Python, R, etc...). Or how JavaScript and Ruby are more popular than, say, Rust and Haskell for startups. \"Poorly typed\" means different things to different people, in the context of this article and thread it would probably mean weakly typed or dynamically typed? Which has nothing to do at all with the correctness of a formula or what output a program will produce. reply tyingq 17 hours agorootparentprevAnd often, how fast they have some mvp thing in their hands...the better. Maybe not actually better, but politically better or whatever. Quality, maintainability, etc, is less important in that moment. And, like many things in companies, short term desires dominate. reply ervine 20 hours agoparentprevWhy is `any` allowed at all? Enable strict mode, set up your linter, don't allow any implicit or explicit `any` anywhere. Without this, Typescript is next to useless. Not knowing if the types are good is worse than no types at all. reply tshaddox 18 hours agorootparentFYI, TypeScript strict mode does not prevent explicit `any` (only implicit `any`). You'd need to reach for something like https://typescript-eslint.io/rules/no-explicit-any/ reply ervine 7 hours agorootparentFor sure, linting is just as necessary as typescript for a sane codebase. reply phyrex 20 hours agorootparentprevProgressive typing of an untyped code base. Types that are too complex to represent in that type system. reply ervine 20 hours agorootparentYep, adopting strict after the fact is a different conversation, but one that has been talked about a bunch and there is even tooling to support progressive adoption. Types that are too complex... hmmmm - I'm sure this exists in domains other than the bullshit CRUD apps I write. So yeah, I guess I don't know what I don't know here. I've written some pretty crazy types though, not sure what TypeScript is unable to represent. reply mikepurvis 20 hours agorootparentProgressive code QA in general is IMO an underexplored space. Thankfully linters have now largely given way to opinionated formatters (xfmt, black, clang-format) but in the olden days I wished there was a way to check in a parallel exemptions file that could be periodically revised downward but would otherwise function as a line in the sand to at least prevent new violations from passing the check. I'd be interested in similar capabilities for higher-level tools like static analyzers and so on. The point is not to carry violations long term, but to be able to burn down the violations over time in parallel to new development work. reply nemetroid 4 hours agorootparentThis is how we introduced and work with clang-tidy. We enabled everything we eventually want to have, then individually disabled currently failing checks. Every once in a while, someone fixes an item and removes it from the exclusion list. The list is currently at about half the length we started out with. reply prmph 8 hours agorootparentprev> not sure what TypeScript is unable to represent. I want a type that represents a string of negative prime numbers alternating with palindromes, separated by commas. reply ervine 7 hours agorootparentOh yeah, you have to get into branded types for this I think, which means a parsing step. Fair point. reply sesm 19 hours agorootparentprevImportant note: TS doesn't let you enable strict mode on per-file basis. Flow allowed that. reply t-writescode 20 hours agorootparentprev* Common functions such as parsing functions in languages that don't support function overloading * \"equals\" and other global functions. reply shepherdjerred 19 hours agorootparentTypescript have solutions for both of those problems: conditional types and generics reply umvi 20 hours agorootparentprevSometimes you don't have the type for something, especially if it's 3rd party code. For example, if you are integrating recaptcha with your page: https://developers.google.com/recaptcha/docs/loading You could try to craft your own type to match google's schema or hunt down 3rd party types, but just doing `(window as any)[\"__grecaptcha_cfg\"]` gets the job done much faster and it's fairly isolated from the rest of the code so it doesn't matter too much. reply swatcoder 20 hours agorootparentYou don't have to provide complete types. If you know what you need to access, and what type to expect (you darn well should!), you only have to tell TypeScript about those specific properties and values. Generally, the conveniences of allowing any are swamped by the mess it accumulates in a typical team. reply digging 20 hours agorootparentAgreed; with 3rd party APIs I type down to the level of the properties I actually need. And when I use a property but don't care what the type is, I use `unknown`. That will throw an error if the type matters, in which case, you can probably figure out what's needed. Although I agree with the article that sometimes fudging the rules is acceptable, it's extremely rare that a 3rd party API is so difficult it's worthwhile. And enforcing `any` as an error means you have to be very intentional in disabling the linter rule for a particular line if that really is the best option. reply wesselbindt 19 hours agorootparentprevWhen you quarantine third party code with an adapter (which you should probably be doing anyway), you can make your adapter well-typed. This is not hard to do, and it pays dividends. reply tom_ 19 hours agorootparentprevTypeScript has \"unknown\" for this, forcing you to cast it, possibly to any, every time you use it. A much better type for your variables of unknown type! reply ervine 20 hours agorootparentprevYeah, those are few and far between, generally there will be a DefinitelyTyped for anything popular, and you start choosing libs that are written in TypeScript over ones that aren't. But for your own handwritten application code, there is no excuse to use `any`. reply neverartful 18 hours agoparentprevFor large code bases, the team has to pay the piper one way or the other. Pay up front with static typing or pay later with nearly infinite test cases to prove that it all works. To be sure, just because you're using a statically typed language does not mean that the code is bug free. It just means that it should all be correct with respect to types. reply Buttons840 15 hours agoparentprevThat phrase \"debug working code\" paints a nice picture of the unproductive part of dynamic types. reply darksaints 16 hours agoprevI've long been a fan of strongly typed languages, but have settled into using dynamic types a bit mostly for ecosystem reasons. Recently I've gotten into embedded programming and initially my thought was that I would have a much easier time getting into it by learning C and C++ simply because those are pretty well standardized on embedded devices. And it has been so fucking painful. The build systems absolutely suck...cryptic, finicky, and archaic. Small variations in developer environments cause so many errors. The package management is basically non-existent. Maybe you use Boost or a couple other libraries, but mostly you avoid them because the package management is terrible and build systems are even worse. You're basically writing everything from scratch. The thing I overlooked the most though was the type systems. C and C++ are statically typed, but weakly so. And therefore, the thought of using the type system for safety guard rails doesn't exist. You specify types so that programs will compile, and that's it. In comes Rust. I know the memory management is the thing that sells it, but in an embedded project, I'm simply not doing any dynamic memory allocation, so I didn't think I'd see much benefit. I mostly tried it because Cargo is an amazing build system. But the thing that has sold me on it is the type system. Within my first 5 minutes of porting a magnetic encoder driver, the type system caught an error in my ported code. I used the wrong pin for my SPI MOSI connection to my driver. It absolutely blows me away that the type system knew I was using the wrong pin. Turns out the code I could never get to work in C was broken because I was referencing the wrong pin, and I never knew why. Fifteen minutes later, it caught another error: by sharing the SPI bus, it could identify that there were more than two devices connected, because there were two CS pins declared, and because the device wasn't exclusive, I had to wrap the bus in a refcell for memory safety. Absolutely amazing. I never thought that embedded programming could be fun, and strong types were what changed my mind. reply sinuhe69 13 hours agoparentYeah, I see the same problem with C and C++ in embedding, too. My guess is that people in embedding were working originally in low-level language like assembly where types don’t exist (at least that's what I did with the PIC and older AVR microcontrollers). So when they introduced higher level languages such as C into it, they did it in an assembly-like fashion and not truly in the spirit of high level languages. For example macros are still extensively used for definition of a lot of things, including IO-pins, and they undergo no type checking. C is not a strong -typed language anyway and this mode of thinking and programming continues to spill-over when C++ was introduced. Type is used merely to limit memory allocation and ensure memory alignment, not truly used in its conceptual sense. Of course, the resource constraints and efficiency of the compiled code play a significant role here. So unless a new memory efficient strict-typed language/compiler comes along with a modern mindset, the power of type will not come into play. reply shepherdjerred 19 hours agoprevZod [0] is my favorite TypeScript library. It really helps ensure that all the little nooks and crannies of your application can be properly typed. An example is receiving API response with `fetch`. Normally you'd cast the response to the expected type, but it's not uncommon for you to misunderstand what the API can return or for the API to be changed/updated. Zod lets you verify your types at runtime so that if your API returns something unexpected then you can act on it. This is really useful anytime you're interacting with I/O or user input. For example, I've used Zod for: loading from JSON files, reading from local storage, parsing URL params, or validating form input. [0]: https://zod.dev/ reply threatofrain 15 hours agoparentI'd also say checkout Valibot. It has a nice composable pipe¹ API so a small handful of atoms is expressive over a lot of type needs. It's also more petite and performant. const natural = pipe(string(), transform(atoi), minValue(0)) const percent = pipe(natural, maxValue(100)) [1]: https://valibot.dev/guides/pipelines/ reply moshegramovsky 20 hours agoprevC++ guy here. I love being able to make a change and watch the compiler tell me what's broken. In the past year, I was able to justify large scale changes to a big codebase because I could say with confidence that the type system would reveal all. And it did. reply Measter 19 hours agoparentYeah same, though with Rust. I once did a refactor of my compiler project where I completely rewrote how the AST was represented, then spent the next three or four hours fixing compiler errors. Worked perfectly first time, because the type system allowed compiler to tell me everything that was broken. reply hansvm 15 hours agoprevI can't look at a conversation about types without thinking of hexing the technical interview [0]. It's not quite the sort of thing TFA is talking about, but how does everyone here feel about sneaking parsers and other code that normally exists at runtime or in the build system into the type system instead? [0] https://aphyr.com/posts/342-typing-the-technical-interview reply t-writescode 21 hours agoprevIt's always fun getting to see people experience the positives of type systems. So many of the most popular and \"easy\" / \"user-friendly\" languages drop types in favor of friendliness and speed. The most vocally popular web languages - Python, Ruby and Javascript - all seem to either ignore or not have types at all. People make huge projects in them and start learning new techniques and then the weight of the choices they made begin to grow. Enter: Types, a frequent savior. Not always the best choice for everyone, but a very good and useful thing. I welcome this person on their journey! reply stavros 21 hours agoparent> The most vocally popular web languages - Python, Ruby and Javascript - all seem to either ignore or not have types at all. All three of those languages have ways to use typing, so this statement is only true in the sense of types not being mandatory, which is also the case in any language that has the Any type. reply pavel_lishin 19 hours agorootparentBut Python, Ruby and Javascript effectively encourage you to skip using types out of the box. (Elixir, too - it supports @spec, but doesn't require it.) If you want to skip out on types in Typescript, you have to be explicit about it. reply axelthegerman 20 hours agoprevAnd: > How types make easy problems hard Sure that's sometimes an issue with the type system itself (looking at you Sorbet) but also preventing the programmer from taking advantage of the flexibility, expressiveness and elegance the language itself my add (yes, Ruby). But even Typescript, which is arguably one of the better type system/language pairings out there, often causes more headache than it's worth. reply umvi 20 hours agoparentI've seen some truly insane TS types. Ones that validate SQL queries and stuff. The problem with complex TS types is that there's no debug tooling. You can't set a breakpoint, you can't step through the type propagation. If there's an issue you have to just do trial and error, which can be very tedious. Here's a super complex type I ran into in the wild that has a bug that is extremely difficult to fix unless you burn hours on trial and error: https://github.com/openapi-ts/openapi-typescript/blob/main/p... (the bug in question, still unfixed): https://github.com/openapi-ts/openapi-typescript/issues/1769 It was so hard to fix this bug that I found it easier to just rewrite the entirety of the library but using code generation instead of ultra complex TS types to accomplish the same outcome. reply incrudible 18 hours agoparentprevIf you see programming primarily as a creative outlet, maybe Typescript is not for you. Otherwise, I can vouch for the techniques described in the article, they really keep the code manageable and understandable. They guide you towards working on specific things rather than premature generalizations, but if the specifics change (as your understanding changes), they will also help you change the code without fear. The escape hatch (any) is always there if you need it. reply motoboi 16 hours agoprevIt’s funny and sad to have people talking about types while I have Java and and IDE that basically writes code itself. JavaScript was a bad trip, guys. reply langsoul-com 17 hours agoprevOne thing author neglected to mention is just how time comsuimg making everything types is. Sure, primative types are fine, but anything more and it's a massive pain. Actually, types are best when someone else already did all that work. reply pkoird 16 hours agoparentLooks like a job for LLMs? reply smj-edison 17 hours agoprevI see proponents of type systems often mention that types make refactoring easier and safer, but wasn't the first refactoring browser made for and in Smalltalk? How did Smalltalk maintain the types when performing large changes? reply igouy 52 minutes agoparentiirc William Opdyke's thesis has much C++ :-) http://www.laputan.org/pub/papers/opdyke-thesis.pdf As-for \"performing large changes\" -- \"A very large Smalltalk application was developed at Cargill to support the operation of grain elevators and the associated commodity trading activities. The Smalltalk client application has 385 windows and over 5,000 classes. About 2,000 classes in this application interacted with an early (circa 1993) data access framework. The framework dynamically performed a mapping of object attributes to data table columns. Analysis showed that although dynamic look up consumed 40% of the client execution time, it was unnecessary. A new data layer interface was developed that required the business class to provide the object attribute to column mapping in an explicitly coded method. Testing showed that this interface was orders of magnitude faster. The issue was how to change the 2,100 business class users of the data layer. A large application under development cannot freeze code while a transformation of an interface is constructed and tested. We had to construct and test the transformations in a parallel branch of the code repository from the main development stream. When the transformation was fully tested, then it was applied to the main code stream in a single operation. Less than 35 bugs were found in the 17,100 changes. All of the bugs were quickly resolved in a three-week period. If the changes were done manually we estimate that it would have taken 8,500 hours, compared with 235 hours to develop the transformation rules. The task was completed in 3% of the expected time by using Rewrite Rules. This is an improvement by a factor of 36.\" from “Transformation of an application data layer” Will Loew-Blosser OOPSLA 2002 https://dl.acm.org/doi/10.1145/604251.604258 reply layer8 17 hours agoparentprevIt could fail. It also collected runtime information to improve correctness. See: https://www.researchgate.net/publication/220346807_A_Refacto... E.g.: “In a reflective environment such as Smalltalk, any change to the system can be detected by the system. Therefore, it is possible to write programs that depend on the objects being a particular size, or that call methods by getting a string from the user and calling perform: with it. Therefore, it is impossible to have totally correct, nontrivial refactorings. However, the refactorings in our system handle most Smalltalk programs, but if a system uses reflective techniques, the refactorings will be incorrect.” “To correctly rename a method, all calls to that method must be renamed. This is difficult in an environment that uses polymorphism to the extent that Smalltalk does. Smalltalk also allows dynamically created messages to be sent via the perform: message. If an application uses this approach, any automatic renaming process has the potential of failure. Under these conditions, guaranteeing the safety of a rename is impossible. “The Refactoring Browser uses method wrappers to collect runtime information. […] Whenever a call to the old method is detected, the method wrapper suspends execution of the program, goes up the call stack to the sender and changes the source code to refer to the new, renamed method. Therefore, as the program is exercised, it converges towards a correctly refactored program. […] The major drawback to this style of refactoring is that the analysis is only as good as your test suite. If there are pieces of code that are not executed, they will never be analyzed, and the refactoring will not be completed for that particular section of code.” reply smj-edison 17 hours agorootparentInteresting, thanks for the link and quotes! I've been trying to find more information Smalltalk in the 90s, with XP, GoF, and other interesting developments—I wasn't alive when all that was happening and it's been fun to rediscover. reply TZubiri 20 hours agoprevLooking forward to the response article on how types can make easy problems hard. reply shepherdjerred 19 hours agoparentI don’t think it takes much creativity to write such an article. Type systems can be frustrating to work with and throw arcane errors that take a lot of experience to decipher. The real question IMO is are the benefits worth the cost. reply TZubiri 6 hours agorootparentI think the article is too easy. I would like to see actual experiments. Group A writes a couple of tasks without typing. Group B writes it with typing. Compare development times, execution times, quality, security, etc... reply moshegramovsky 20 hours agoparentprevIn C++ you can make all kinds of easy problems much harder with C-style casts or static_cast. reply neverartful 18 hours agorootparentTrue, but C and C++ are not the only statically types languages available (thankfully!). reply digging 19 hours agoparentprevHonestly, yes, I'm curious to hear that perspective. The negative responses to \"TypeScript makes JS programming fun and easy\" are always pretty ill-formed, and I really want to know if there's a genuine argument against it in any complex application. (My suspicion is that no, there is not, but I'm trying to be generous and curious.) reply shepherdjerred 19 hours agorootparentThe biggest con is that you have to do all of the legwork of learning how static typing works, and types in TS can be fairly complex. When you have a team of engineers, this means your entire team needs to either learn or lean on an expert when tougher situations arise. reply digging 2 hours agorootparentYes, but, I'd argue it's trading one type of endless, tedious work for a different type of concrete, meaningful work. reply shepherdjerred 1 hour agorootparentI agree! It’s still not an easy sell though. reply turbojet1321 15 hours agorootparentprevThe thing is, you have to implicitly understand the \"types\" of javascript objects anyway, otherwise you can't use them. All the type system does is make that implicit knowledge explicit, and a long the way, stops you from doing things that are likely to cause issues. reply shepherdjerred 1 hour agorootparentYes, but properly typing your JS objects can still be quite hard reply akdor1154 19 hours agorootparentprevLess charitably, it means you need a competent team? reply shepherdjerred 19 hours agorootparentCompetent in types, yes. Just like you’d want a team competent in functional programming before starting a project in Haskell. It would be unfair to consider your team incompetent just because they are experts with another set of tools. It’s also unreasonable to expect these things to be quickly learned (TypeScript types are not friendly). But I think it’s reasonable to explain the benefits of this approach and to help your ramp up and learn the skill. But, anyway, I understand the frustration. I’m usually the one trying to get my team to understand the value of modeling problems in type systems. reply tubthumper8 19 hours agorootparentprevIf complex situations arise, they can slap `any` on it, at least it would be explicit, and marker to revisit in the future. Is there really that much legwork otherwise? Adding \": string\" to a function parameter assumes they know what a string is (which should already be the case), adding an object type assumes knowing what an object is, etc. reply shepherdjerred 19 hours agorootparentThere is a big difference between typing your application (e.g. changing (arg) => {} to (arg: string): void => {}) and modeling your application in the type system. Simply adding types is usually not too difficult and it is still quite beneficial. It does eliminate certain kinds of bugs. Modeling your application in a type system means making invalid states unrepresentable and being as precise as possible. This is a lot more work, but again is eliminates more kinds of bugs that can occur. An example of this being complex: earlier this week I wrote a generic React component that allows users to define which columns of a table are sortable. I wanted to prevent any invalid configurations from being passed in. This is what it looks like: https://tinyurl.com/bdh6xbp6 It's a bit complex but the compiler can guarantee that you're using the component correctly. This is more important and useful when it comes to business logic. reply crm9125 19 hours agorootparentprevI'm not trained as a programmer/software engineer, but this was ChatGPT's response: 1. Added Boilerplate and Ceremony: Simple tasks may require extra type declarations and structures, adding “ceremony” that feels unnecessary for quick one-off solutions. 2. Rigid Type Constraints: Combining different data types or working with unclear data shapes can force complex type solutions, even for simple logic, due to strict compilation rules. 3. Complex Type Definitions for Simple Data: Handling semi-structured data (like JSON) requires elaborate type definitions and parsing, where dynamically typed languages let you manipulate data directly. 4. Refactoring Overhead: Small changes in data types can cause widespread refactoring, turning minor edits into larger efforts compared to flexible, dynamically typed environments. 5. Complexity of Advanced Type Systems: Powerful type features can overwhelm trivial tasks, making a few lines of code in a dynamic language balloon into complex type arguments and compiler hints. reply JoeAltmaier 19 hours agorootparentAll of those come down to \"Let the compiler guess about my data, and it may produce correct results in some of the cases.\" A risk is, unexpected data (empty field instead of zero; a real number introduced in untested corner cases where only an integer will actually work etc) can cause issues after deployment. Those 'complex' requirements mean, if you want a reliably correct program well then you'll have to put in this much work. But go ahead, that 'trivial task' may become something less trivial when your task fails during Christmas sales season or whatever. reply shreddit 20 hours agoprevI also recently switched from javascript to typescript and noticed a clear improvement on my speed to write code. Before i had to constantly switch between files to check what i exactly passed to a function. But I knew C# before so a typed language is nothing new for me. But when i started with javascript exactly this “untyped” language felt like something good, it felt much less of a burden to think about the code beforehand. Now i look at dozens of projects which a have to be converted to typescript because I simply cannot deal with this typelessness anymore… reply yawaramin 13 hours agoprevFun fact: TypeScript can typecheck JSON files directly. I use this ability to define all my translation keys in my code as a type and enforce that my translated messages JSON files all have the correct keys. reply alephxyz 20 hours agoprev>Changing our database schema should cause us to see errors in our frontend code. I shuddered. reply shepherdjerred 19 hours agoparentWhy is that bad? reply Kuraj 19 hours agorootparentThis seems like a good thing if front-end fragmentation is not an issue, ie. if it's hosted on a server and kept in sync with the backend through deployment. As a mobile app? Maybe not. I'm honestly a bit puzzled which scenario the original article is envisioning when arguing this, because it mentions mobile, but then also argues for monorepos, which are kind of at odds with each other, unless you somehow force your mobile users to always be using the version that matches your back-end. reply shepherdjerred 18 hours agorootparentOh, I see. Yeah, you'd definitely need to be very careful in this case. To be fair though, this is a general problem when clients and servers might not agree on data formats. You can still safely do what the author is describing since type checking occurs at compile-time and not runtime. You would, of course, need to be sure your app handles whatever the API/db returns at runtime though. But, again, this is a general problem. reply tasn 15 hours agoprevGood utilization of the type system really makes a difference. I wrote a similar blog post a while back: https://www.svix.com/blog/strong-typing-hill-to-die-on/ reply kazinator 15 hours agoprevIf the code writes itself due to type declarations, it must be mindless drivel, not something containing \"hard problems\". For instance, if we just declare some data structures for computational geometry, like points, line segments and whatnot, code for, say, intersecting two meshes is not effing going to write itself! The author is living in some CRUD world of pulling things from one API or database, converting to a different data model, and stuffing them into another API, with maybe some HTML generation sprinkled on top. reply throwaway2037 14 hours agoprev> type NonEmptyArray = [T, ...T[]]; I never used TypeScript before, but this looks very useful. Is that possible in C+++ templates or Java generics or C# generics? reply tantalor 17 hours agoprevprices: NonEmptyArray Doesn't this mean you can't ever remove an element from the array, only add to it? Like, the compiler should throw a type error if you try to pop() from an array with one element. reply MichaelNolan 12 hours agoparentTypeScript is just for compile time. You can pop() every element out of the array at runtime with no error. This compiles with no issue - https://www.typescriptlang.org/play/?#code/C4TwDgpgBAcg9gOwK... reply tantalor 2 hours agorootparentIf that's true, then how is a type like this (non-empty array) useful at all, if it can't be relied on at runtime? TS should say, you can't pop() this array, unless TS can infer it has >1 elements. Otherwise it can enter a state at runtime which doesn't conform to the type. That seems bad! reply bruce343434 16 hours agoparentprevCould also be that pop() can now error out at runtime reply tantalor 2 hours agorootparentInterestingly, [].pop() does not throw an error. reply cjr 17 hours agoprevnice post :) I’m surprised there’s not been any mention of effect (http://effect.website/) yet, as it is kind of the next level up if you really want to model things like errors, dependencies and side effects in the type system, using functional concepts borrowed from more pure functional languages. It would be a bit of a risk adopting this into a shared code base depending on your team and the kinds of devs you’re looking to hire, but it could be useful to some folk that feel like they want even more type safety. reply tinthedev 21 hours agoprevNot to devalue the author, or their findings/learnings... but I could see this was a JavaScript/Typescript coder (very likely self-taught) learning about typing paradigms. A lot of people, especially people from the same background, would benefit from branching out and learning some other programming languages/paradigms. Some... statically typed and actually compiled languages. Maybe to take an entry course in CS. It's very popular to hate on formal education, especially in software, but all these lessons would have been learned in the first semester or two. reply tlf 20 hours agoparentThat's interesting to hear. I started out with a formal CS education learning Java & C in school. I've found that traditional CS education doesn't really take this approach. A lot of what I was exposed to was very OOP-heavy practices that emphasized data modeling via class hierarchy. To me, the expressiveness of the Typescript system (being able to do things like sum types or branded types) is what unlocked a lot of potential despite not being a compiled language. reply tpoacher 18 hours agorootparentYour experience of Java likely relates to Java 8, or possibly even prior versions. Modern Java is an entirely different beast, which feels very functional these days. (and yes, I say this as someone who teaches these things as part of an undergrad java course) reply TexanFeller 15 hours agorootparentAfter using languages like Scala, Java(I use 17) feels like a joke in terms of type system expressiveness and ability to use functional patterns. I currently have to switch between the two and the kindest thing I can say about Java is it’s getting better(very slowly). Even though the language is getting less painful, frameworks like Spring that do things at runtime instead of compile time, including rewriting bytecode on startup to inject code, make the ecosystem quite hostile to folks who want to work in a stricter, safer manner that’s easier to reason about(expressed in the language, not in some annotation based metalanguage with no principles and whose implementation changes randomly). We need to stop defending Java and move on to something actually modern and good. Scala has fallen from favor, so maybe Rust is the next thing I’ll try. reply Groxx 13 hours agorootparentA lot of the runtime fiddling is indeed a plague (the limited reflection is one of my favorite parts of Go, it means I can trust function call boundaries FAR more), but Java does do some nice things. E.g. I wish every language had as powerful of a compile time system as Java does - annotation processors and compile-time byte-code weaving enable magic \"best of all worlds\" stuff like Lombok, and it integrates with IDEs transparently. And hprof -> MAT is absolutely incredible compared to the memory-profiling capabilities of most languages. reply TexanFeller 3 hours agorootparentThe debugging and profiling features are definitely better than most, but other languages running on the JVM benefit from that too. I think most of what people use Lombok for though are features that should be part of the core language by now, or would be better as library methods instead of annotations. Like generating constructors, equals, and hashCode methods - case classes and data classes in Scala and Kotlin respectively handled that within the language spec many years ago. I need to try Java’s new Records, perhaps they handle that stuff now. Lombok and friends also include features that change language semantics like @SneakyThrows. Byte code injection sometimes also changes language semantics. Early in my career I spent a few hours perplexed by why my code was encountering null when the code path I was examining used only non-nullable primitives. Turned out injection and rewriting had turned my primitive long into a nullable Long. I don’t like not being able to understand my code from just reading the code. The magic means I have to be aware of spooky action at a distance mechanisms and review their documentation. I also need to open the debugger more regularly to inspect what’s actually happening at runtime instead of just mentally compiling my code. reply ninetyninenine 19 hours agoparentprevThe irony is that before types became popular with interpreted languages and modern languages like golang or rust, untyped languages became MORE popular because of formal education. The reason why is because most formal education curriculums teach C++ which ironically is more error prone and contains error conditions far harder to debug then untyped interpreted languages like python or JavaScript or ruby which were coming into popularity at the time. This is of course despite the fact that C++ has a type system with generics. Because of this, a lot of people tended to associate typing with something more error prone and harder to work with. It wasn’t until the advent of typescript, golang and rust when people started to get the difference. reply neverartful 18 hours agorootparentSemi-pedantic point -- Python is not untyped. In fact, it's strongly typed. It's not statically typed, but rather dynamically typed. reply ninetyninenine 9 hours agorootparentIs it? Then why can’t parameters be checked by default when called in a function? Anything passes through with zero runtime checks. Any type checks you need to implement it yourself. reply neverartful 5 hours agorootparentBecause Python isn't a statically typed language. Many will argue that this is a huge benefit of Python since you don't have to declare types. There are newer developments like mypy that allows you to add types as annotations, but the data types that you declare with the annotation is not enforced. reply motorest 20 hours agoparentprev> A lot of people, especially people from the same background, would benefit from branching out and learning some other programming languages/paradigms. I completely agree. I started reading the article expecting to read something interesting or smart about functional programming,but it turns out the blogger is just very vocal at telling the world their excitement over reinventing the wheel and being completely obliovius to what actually represents very basic things in any intro to software engineering course. reply shepherdjerred 19 hours agorootparentWhat? I have never heard of a school teaching the importance of static typing esp when it comes to engineering practices reply jfwuasdfs 17 hours agorootparentVery true. You need to go to a school that specializes in type theory [1]. [1]: https://cstheory.stackexchange.com/questions/50780/which-uni... reply motorest 11 hours agorootparentprev> What? I have never heard of a school teaching the importance of static typing esp when it comes to engineering practices The blogger is not a really talking about static typing. The blogger is waxing lyrical over designing a domain model and then writing an application around it. You know, what others call basic software architecture. Wait until the blogger learns of the existence of Domain-Driven design. reply tugu77 21 hours agoparentprev100% this. For a C++ or Rust programmer this reads so weird. Don't get me wrong, I'm not hating on JS here, and I have lots of beef with C++, but I fully agree with your take that TS barely scratches the surface of the statically typed world. reply shepherdjerred 19 hours agorootparentTypescript has one of the most advanced type systems of any of the common languages reply chamomeal 14 hours agorootparentprevNawww I’d say something like python or php is “scratching the surface”. Typescript’s type system is phenomenal and pretty deep. Honestly I think it’s the most interesting one to work with, too. Which is not always a good thing, but it is fun. The only type systems I’ve seen that are similarly expressive are rust and Haskell. Even go doesn’t come anywhere close. reply FractalHQ 20 hours agorootparentprevThis isn’t true, is it? I’ve only ever heard that TypeScript has one of the most advanced type systems of any mainstream language.. but I don’t have enough experience with other languages to know how true that is. reply throwuxiytayq 21 hours agorootparentprevBased on my small amount of work done in TS, it seemed like one of the more advanced type systems out there. To the detriment, even. The language was just huge, and that was years ago. reply eyelidlessness 21 hours agorootparentAnd it’s so advanced because it was/is designed to represent the types of real world dynamic JavaScript. More often than not, when people complain about the complexity of the types they encounter in the TS type system, they’re really complaining about the types of the underlying JS (which are the same whether they’re expressed statically or not). reply wk_end 20 hours agorootparentThere's a cultural problem in the TypeScript ecosystem, I find, where people are impressed (with both themselves and others) when complex interfaces can be expressed in the type system, and tend to embrace that instead of settling for simpler (and often admittedly more verbose) ones. Maybe that's because they're an ex-JS programmer who wants to use the exact same interface they'd use in JS with no compromise, or maybe it's just because they think it's cool. Either way I think it's really detrimental to TypeScript as a whole. reply gejose 16 hours agorootparent> Maybe that's because they're an ex-JS programmer who wants to use the exact same interface they'd use in JS with no compromise, or maybe it's just because they think it's cool That sounds a little reductive and gate-keepy. Maybe an advanced type system allowing for complex types to be expressed easily actually allows you to write simpler, more effective code. Curious if you have any specific examples though. reply chamomeal 14 hours agorootparentprevI think there’s a difference between ideal library code and ideal business logic code. The more you lean into crazy ass generics in your library, the simpler and more error-free the user can make their biz logic code. Really nicely typed libraries almost give you zero chances to fuck things up, it’s amazing. But then again most of your devs wont be able to understand all those generics, so you need to keep your biz logic types relatively simple. reply TheHegemon 20 hours agorootparentprevDo you have some examples for that? Most cases I've seen with more complex interfaces is due to the fact that it is what the interface truly expects. Usually making it simpler tends to mean it's actually wrong or incomplete. reply wk_end 19 hours agorootparentThis is hand-wavey, but that can't be true: less complex type systems manage to express all kinds of interfaces correctly all the time (sometimes at the cost of verbosity, but that that’s usually a good trade-off is the point). You're asking me to tell on my coworkers, and I'm too loyal to throw them under the bus :) Well, OK, here's one, but I'll keep it as blameless as possible. We had a thing where we wanted to register some event handlers. The primary use of these event handlers was to run a selector, and if the selected data changed, trigger an update, passing the selected data along. The initial implementation used existential types to store a list of callbacks, each returning different selected data. The \"driver\" then did the equality checking and update triggering. We later changed this, so that the callbacks - as far as the driver was concerned - all returned `void`, eliminating the need for an existential type. We just had to move the equality checking and update triggering to inside the callbacks. Some features are straightforward translations: anywhere you have overloading and/or optional arguments you can (and often should) simplify by refactoring into multiple functions. For a concrete, public example...well, I remember the Uppy library had a lot of stuff like this. A lot of work goes into making it's \"Plugin\" interface look the way it does (start at [1] and keep reading I guess) for instance, and while I haven't sat down and re-engineered it I don't think it needs to be this way, if you're willing to give up some of the slickness of the interface. [1] https://github.com/transloadit/uppy/blob/main/packages/%40up... reply behnamoh 19 hours agorootparentprevLike this: https://news.ycombinator.com/item?id=14905043 and this: https://news.ycombinator.com/item?id=37956856 reply shepherdjerred 19 hours agorootparentprevAdding static typing only shows you how bad your code already is reply TheTaytay 19 hours agoparentprevI didn't get the impression that this was a self-taught or newbie coder. I think their audience is not assumed to be a CS grad though. I found it a good and well-reasoned explanation of _why_ he enjoys types in a large codebase. He does take time to explain different type concepts, but I assumed that was because he doesn't assume his audience is familiar with all of them. Considering that the opinion \"types are good and helpful in a codebase\" is not universally held, even by very experienced/productive coders (see https://world.hey.com/dhh/turbo-8-is-dropping-typescript-701... or basically any ruby codebase), I think articles like this have a definite place. reply throwuxiytayq 21 hours agoparentprevIn my experience, university is one of the least efficient ways to learn CS. The actually useful classes are few and far between, dwarfed by useless outdated courses, courses that aren’t very relevant to the job, and classes that are sadly lead by incompetent burnouts who don’t know that they’re teaching, come terribly unprepared, and in general seem to hate their job. Most of the people there have theoretical experience in writing software. But maybe that’s just my shitty university. I dunno. Supposedly one of the better ones. reply karaterobot 20 hours agorootparentOn the other hand, as an Engish Lit major who taught himself programming from zero, and worked as a programmer for over a decade, all my experience writing software was practical, and I don't think that's the right way to go either. I wish I'd had any level of theoretical education that might have exposed me to fundamental concepts you (with yer fancy book-learnin') probably take for granted. If someone just learns on the job, or just learns as they go, they don't learn stuff until they need to. They learn it in a hurry, and on a deadline. That's not the best way to get a firm handle on tricky subjects, and maybe as a consequence, I always felt a couple steps behind my peers. reply digging 19 hours agorootparentAs someone in a similar position, may I take a tangent? I'm curious what you transitioned into out of programming. The stress of feeling \"always behind\" is taking its toll on me, and I wonder about another career change often. reply karaterobot 14 hours agorootparentI joined the software industry at a small consultancy that needed me to do a lot of different things, including both programming and design. So I got experience doing both of those. When I left the consultancy world in 2016, I had to decide whether to sell myself to employers as either a programmer or a designer—normal companies want you to pick a single lane—so I just focused on my design experience, and started doing that as a day job. I went from a fancy title to a much less fancy title for my first job as a designer, but more or less worked back up from there. I think for most programmers, their fork in the road would be to stay as an individual contributor or become a manager, but I don't want to be a manager, and was lucky to have a different path to fall back on. reply CaptainNegative 21 hours agorootparentprevI think the problem is in going for a Computer Science degree when you really meant to study Software Engineering. reply n4r9 21 hours agorootparentI imagine quite a bit of a Computer Science degree is relevant if you plan to be a computer scientist. reply goatlover 18 hours agorootparentprevA computer science degree is for the science of computing, not whatever is the latest in the workplace. You learn that on the job or a boot camp. Computer science is much more than the current popular framework and tools. It's the principles for how software works. reply throwuxiytayq 11 hours agorootparentYes, I wish I finished my degree having learned literally any of that. reply revskill 13 hours agoprevStructural typing is the key here. reply Barrin92 21 hours agoprev>Using the same language everywhere. Naturally, if we want to share type information as much as possible, we need to be using the same language This goes to the heart of what's not great about this, types impose global semantics on a piece of software, they introduce coupling. (It's why Alan Kay used to stress \"late binding of all things\") as a feature of managing complexity. In fact one result of this kind of programming were microservices. What do they do? Reintroduce runtime dynamism. It's not often framed that way but there's a reason you see more statically typed microservices than Lisp or Erlang ones. It's because they're an attempt to get away from the coupling imposed by type driven programming and towards more independence of each service. Which is already baked into message based, dynamic languages. And there's also a fundamental misunderstanding about data and types in the article. > Making our types represent the “truth” Types can't represent truth. Real world data doesn't have types. It changes incrementally however it wants, and all the time. You can use types to not let something you don't want into your program, but you can never represent arbitrary real world data by matching types onto them. reply tikhonj 18 hours agoparent> Types can't represent truth. Real world data doesn't have types. It changes incrementally however it wants, and all the time. You can use types to not let something you don't want into your program, but you can never represent arbitrary real world data by matching types onto them. That's true for static types... but it's just as true for the constructs in your dynamically typed code! Nothing about dynamic typing makes your logic or data representation any more adaptable, it just makes the rigid models inherent to your code implicit rather than explicit. reply pavel_lishin 19 hours agoparentprev> Types can't represent truth. Real world data doesn't have types. It changes incrementally however it wants, and all the time. That's like saying \"Maps can't represent truth\". They're a model that works well enough, just like types do, if you do it right. reply Garlef 20 hours agoparentprev> you can never represent arbitrary real world data by matching types onto them. I think that's why the article references the 'parse, don't validate' article: Real world data is messy and so you ingest it into your business logic at the system boundaries via parsing. reply esafak 21 hours agoparentprev> Types can't represent truth. Real world data doesn't have types. It changes incrementally however it wants, and all the time. What do you mean? If a variable is a date/time or an integer etc. in the real world it should stay that way and be represented as such in software. reply leeeeeepw 20 hours agorootparentAI chatbot example, you're chatting and then there could be some Mark down, latex, images maybe base64 encoded webp, audio files, we can type all this stuff do all the validations and such, understand it better and there's some gains to be had doing that, then likely someone like Facebook comes along with this Giant byte Transformer expert system with all of the data specific optimisations, that's kind of the bitter lesson but I guess the main point is that the problem itself of how to best communicate with AI is not necessarily solved so you can get bogged down typing the best possible ways to do it but it's a moving target. Same with a lot of systems like say a search system that tracks data using the best embedding, well we don't know what that best embedding is in terms of price performance and encoded knowledge perf it's just a moving target. Send me the system that tracks important metrics effecting the stock market, or a weather system etc... the sensors are all updating and then an entirely new thing comes along like Starlink that helps us track the weather in totally new ways reply msanlop 20 hours agorootparent> get bogged down typing the best possible ways to do it but it's a moving target As someone who is still learning this is a huge reason why I've come to love dynamic languages. Any project I do involves a lot of rewriting as the code evolves, I found that trying to predict ahead of time what the structures and types will be is mostly a waste of time. The best middle ground for me so far has been using python with type hints. It allows for quick iteration, I can experiment and only then update the types to match what I have, so that I can still get LSP help and all that. But I could see this being less relevant with more experience reply ervine 20 hours agorootparentprevNot if your types represent something you don't control, like an API response. reply DangitBobby 18 hours agorootparentHaving runtime type validation utilities such as Typebox help here. Even in the absence of type guarantees at I/O boundaries (where you have to just \"lie\" about the type you really have, which would be `unknown` if we were honest), I'd certainly rather my code at least specify what types it expects from the server than attempt to access arbitrary attributes in various places. reply ervine 7 hours agorootparentOh yeah definitely, I write the types that I expect from the API - the point the original comment is making is that the state of reality is not your types, it's what the actual API returns. But yeah if you use something like Zod you can at least say \"this is what I'm pretty sure the API should return\" but also define what should happen if things change / don't meet your types. reply turbojet1321 15 hours agoparentprevThe quote from the article is incorrect, though. We have a C# backend and a TS front end, with the shared types generated for TS using nswag. I'm sure there are many other variations on this, too. reply akira2501 19 hours agoprev> The default return type for posthog.getFeatureFlag is stringbooleanundefined. You could just as well say \"how bad APIs make simple problems complicated and how you might strain at a type system to pretend this bad design is worth keeping.\" I mean, \"string or boolean or undefined,\" is not at all a \"type.\" This is a poorly specified contract for an overloaded interface with terrible semantics built on the abuse of language grammar. It's why I think a language with the core semantics of JavaScript plus a goofy type system are never going to produce anything worth actually having. The two sides of the system are constantly at odds with each other. People are mostly using the type system to paper over bad design semantics. reply wryoak 21 hours agoprev [–] The first point lost me because it pushed responsibility for functioning software onto the user. If your entire application ecosystem has to be recompiled because you conceived of a new clever way to conceptualize the data that doesn’t actually affect the user experience, what happens is I have to update my damn bank app every time you think you’ve done a smart, even though you’ve changed nothing in regards to my checking my balance. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author discusses the benefits of Type Driven Development, particularly in a large TypeScript codebase, emphasizing how types can simplify coding and refactoring.",
      "Key principles include ensuring type safety, starting with type definitions, making illegal states unrepresentable, and using types for validation and introspection.",
      "The approach enhances productivity by allowing offline coding and reducing errors, with the type system acting as a guide and error-checking tool."
    ],
    "commentSummary": [
      "Types offer a structured framework that simplifies coding, reduces debugging, and eases maintenance by mapping domains and setting up scaffolding.",
      "There is an ongoing debate between procedural programming, which emphasizes quick solutions, and declarative programming, which focuses on fewer bugs and easier refactoring.",
      "While types enhance code reliability and maintainability, they can also add complexity and rigidity, making the balance between speed and stability essential, especially in startups versus established systems."
    ],
    "points": 140,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1734637080
  },
  {
    "id": 42471913,
    "title": "Artemis, a Calm Web Reader",
    "originLink": "https://artemis.jamesg.blog/",
    "originBody": "Earlier this year, I made a web reader that only showed a list of post titles, author domains, and links. The reader only updated once per day, so I wouldn&#x27;t feel compelled to keep checking for new posts.I have been using the tool, which I called Artemis, for several months. Every morning, I looked forward to my \"morning paper\" of blogs I love reading.There are no notifications, read vs. unread states, counts of posts, etc. Only the last seven days of posts are available. The colour scheme is changeable. Dark mode is supported. All popular feed formats are supported.There is no reading interface to read blog posts; rather, the links take you to the authors&#x27; websites. Many of my favourite bloggers put a lot of effort into the design of their blogs and like to change things up; I wanted an experience that embraced that.The reader is now available for anyone to use (with invite code \"hn\").",
    "commentLink": "https://news.ycombinator.com/item?id=42471913",
    "commentBody": "Artemis, a Calm Web Reader (jamesg.blog)134 points by zerojames 3 hours agohidepastfavorite38 comments Earlier this year, I made a web reader that only showed a list of post titles, author domains, and links. The reader only updated once per day, so I wouldn't feel compelled to keep checking for new posts. I have been using the tool, which I called Artemis, for several months. Every morning, I looked forward to my \"morning paper\" of blogs I love reading. There are no notifications, read vs. unread states, counts of posts, etc. Only the last seven days of posts are available. The colour scheme is changeable. Dark mode is supported. All popular feed formats are supported. There is no reading interface to read blog posts; rather, the links take you to the authors' websites. Many of my favourite bloggers put a lot of effort into the design of their blogs and like to change things up; I wanted an experience that embraced that. The reader is now available for anyone to use (with invite code \"hn\"). TripleChecker 1 hour agoI'll plan to give this a try. I like the forcing function to curb our naturally addictive behaviors. Small typo to fix ('chronolgically'): https://triplechecker.com/s/996462/artemis.jamesg.blog reply aurea 3 hours agoprevI have been thinking of creating a similar app; however I wanted to do a \"Sunday paper\". This look nice and I like the minimalist design, but I would prefer to have solution that I can self-host. reply exprez135 1 hour agoparentThe tool actually is open source, so you could self-host it if you wish. MIT license, in Python. The repository [1] is linked in the blog post the author wrote about the project [2]. [1]: https://github.com/capjamesg/web-reader [2]: https://jamesg.blog/2024/11/30/designing-a-calm-web-reader/ reply zerojames 20 minutes agorootparentThe open source version is a bit different from the hosted one: the open source code involves running the polling script, then building a static site (which is how I run the site for several months as a single-user project). I am planning to move the polling changes upstream soon and then figure out a plan for open sourcing the full project. reply imiric 1 hour agoprevThis looks great! Congrats on shipping. Have you considered open sourcing it? I would rather self-host something like this. reply exprez135 52 minutes agoparentIt is actually open source, though I'm not sure if it's linked directly on the site. (It is linked in his blog post.) The repository: https://github.com/capjamesg/web-reader reply imiric 28 minutes agorootparentAh, thanks, I missed it. reply kayge 52 minutes agoparentprevLooks like it's already open source: https://github.com/capjamesg/web-reader reply dewey 1 hour agoprevThis would be interesting as a project using the Miniflux API (https://github.com/miniflux/v2). That way it would already use my existing feeds and I don't have a separate \"reading tool\". reply kenrick95 2 hours agoprevI tried to import the OPML file exported by https://wordpress.com/read/subscriptions but it says \"Failed to parse OPML.\" Edit: just managed to find the support email. I'll send you the OPML file through it~ reply zerojames 2 hours agoparentApologies for the inconvenience. A fix has been deployed. reply conroydave 2 hours agorootparentthis is why HN is the best reply zerojames 2 hours agoparentprevThank you for the email. The OPML import is a bit of a newer feature so it hasn't had as much testing. I'll take a look to see what's going on and get back to you. reply xnx 3 hours agoprevI love the idea of a simple, digest-style, mode. Might make some version of this for Instagram. There's nothing so important on Instagram that it can't wait for the next day. reply venusenvy47 3 hours agoparentCan you recommend a tool that could check an Instagram feed once a day for the current photos? I found a command line tool, but it tries to download the whole account, rather than just the daily updates. https://instaloader.github.io/ reply xnx 2 hours agorootparentThat's exactly the tool I would use. There are options you can use to configure what posts are downloaded: https://instaloader.github.io/cli-options.html#which-posts-t... https://instaloader.github.io/basic-usage.html#filter-posts reply venusenvy47 2 hours agorootparentActually, I made a mistake. That tool I haven't got working yet because of the necessary authentication. I've been using this one without auth, but it downloads everything. https://github.com/mikf/gallery-dl reply alexpadula 39 minutes agoprevAwesome! reply borg16 2 hours agoprevthanks. I pay for miniflux through pikapods that I can now get rid of, thanks to your free and alternative offering. reply rakoo 2 hours agoprevFor reference, and not implying it's better or worse than your work OP, I've pleasantly used Fraidycat (https://fraidyc.at/) in the past. It's a webextension, so completely local, and also incorporates the idea of having a \"calmer\" experience: no infinite list of links to check, different update rates, ... I love your philosophy page, OP ! (https://jamesg.blog/2024/11/30/designing-a-calm-web-reader/) reply zerojames 1 hour agoparentThank you! I think how something is made, and the decisions that got it to where it is, is just as important as the thing itself. One of the delightful things about the web is we can all bring our own ideas and designs to problems. I haven't written about this yet, but one thing on my mind is the importance of good import/export features. With good import/export features, we can all move around and try different softwares to see which ones we like! reply mmahemoff 3 hours agoprevWhat's a good place to discover high-quality RSS feeds these days? reply freetonik 2 hours agoparentI'm curating a collection here https://minifeed.net/blogs/ reply dqv 2 hours agorootparentAw dang, looks like I can't subscribe to it in my feed reader. Still, this is a great collection. Thanks for sharing reply freetonik 2 hours agorootparentDo you mean to subscribe to the whole collection, one RSS feed for all the blogs in my list? I mean, I guess I can build that feature, but it's gonna be quite a firehose. reply onli 2 hours agorootparentNot sure what parent meant, but the right way should be an opml file with the feeds, which the feed reader then can import. But maybe you are offering that already? reply freetonik 1 hour agorootparentHere, I quickly put together an OPML generator: https://minifeed.net/blogs/opml.xml reply freetonik 2 hours agorootparentprevAh, sorry, that makes perfect sense. Not yet, but I plan to implement this soon. reply CharlesW 2 hours agoparentprevOne tip: Every Substack has a feed, which is a nice alternative to having everything dropped in your email in-box. You just append \"/feed\" to the end of a newsletter URL, e.g. https://simonw.substack.com/feed. reply marginalia_nu 51 minutes agorootparentI've been doing adjacent work for my search engine[1], and found substack to annoyingly be one of the sites that employ bot mitigation for its RSS endpoints. If you fetch at a very low rate it works fine, but for these types of bulk retrieval. Substack is also a bit of a pain to integrate with because they have zero useful contact information and direct all inquiries to a chatbot that is beyond useless, makes it so you have to guess how they want you to interact with their servers since there is nobody to answer questions. [1] Preview of my take of the idea: https://mastodon.social/@marginalia/113670235590972416 reply freetonik 1 hour agorootparentprevI wonder if Substack would at some point remove or at least cripple this feature. Right now it seems the full-content RSS is served. reply aharris6 1 hour agoparentprevI am working on a site, which is very pre-beta at this point, that works to help solve this problem using bluesky's \"starter pack\" model. Basically sharing curated lists of good follows. Give it a look at https://feed.computer if that seems interesting! reply nelsonfigueroa 2 hours agoparentprevI added one of the random RSS feeds from https://indieblog.page/rss. I’ve discovered cool blogs this way that I now subscribe to directly. reply freetonik 2 hours agorootparentThat's a very cool idea! reply quinto_quarto 2 hours agoparentprevi made a directory of indie creators from across the web here, which i'm not sure what to do with: https://fanzine.world/ I believe you can RSS most of them. certainly all the substacks. reply rixed 1 hour agoparentprevCreate a reader like Artemis and wait for people to upload their own bookmarks? reply charles_f 2 hours agoparentprevI'm just picking the rss for the links I like on hn reply nahimn 1 hour agoprev [–] HN hug of death - “Internal Server Error” reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Artemis is a web reader designed to display a list of post titles, author domains, and links, updating daily, and is now available to the public with the invite code \"hn.\"",
      "The reader focuses on simplicity, lacking features like notifications, read/unread states, and post counts, and only shows posts from the last seven days.",
      "Artemis supports all popular feed formats, offers a customizable color scheme including dark mode, and directs users to authors' websites to appreciate their blog designs."
    ],
    "commentSummary": [
      "Artemis is a web reader designed to display blog post titles, author domains, and links, updating daily to reduce the need for constant checking.- It supports all popular feed formats, offers a customizable color scheme, and links directly to authors' websites, enhancing user experience.- The tool is open source, can be self-hosted, and aims to provide a calm reading experience without notifications or unread counts, accessible with the invite code \"hn.\""
    ],
    "points": 134,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1734708530
  }
]
