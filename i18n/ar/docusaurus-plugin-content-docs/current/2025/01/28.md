---
slug: '/2025/01/28'
---

# 2025-01-28

## [نحن نعيد Pebble](https://repebble.com/)

### [ردود الفعل](https://news.ycombinator.com/item?id=42845091)

يتم إحياء Pebble بدعم من Google، مع التركيز على نقاط قوتها الأصلية مثل القابلية للتعديل، وعمر البطارية الطويل، والعمل كامتداد للهاتف. يهدف الإحياء إلى الحفاظ على طبيعة Pebble مفتوحة المصدر وتجنب الاشتراكات السحابية الإلزامية، مما يجذب المخترقين وعشاق التكنولوجيا. المجتمع متحمس لعودة Pebble، متأملًا في ميزاتها الفريدة وتأثيرها على تكنولوجيا الأجهزة القابلة للارتداء.

## [جوجل تفتح مصدر نظام التشغيل Pebble](https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html)

### [ردود الفعل](https://news.ycombinator.com/item?id=42845070)

قامت جوجل بفتح مصدر نظام التشغيل Pebble OS، مما أثار حماس المعجبين والمطورين لإمكانيات التطورات الجديدة في تكنولوجيا الساعات الذكية. الإصدار على GitHub لا يتضمن المكونات المملوكة مثل خطوط النظام ومكدس البلوتوث، لذا لا يمكن تجميعه في شكله الحالي. يُنظر إلى هذه الخطوة على أنها لفتة إيجابية من جوجل، تُعزى إلى الجهود الداخلية، وتُعتبر خطوة نحو إحياء نظام بيبل للساعات الذكية.

## [تشغيل DeepSeek R1 Dynamic 1.58-بت](https://unsloth.ai/blog/deepseekr1-dynamic)

### [ردود الفعل](https://news.ycombinator.com/item?id=42850222)

يحقق DeepSeek R1 Dynamic 1.58-bit تقليصًا في الحجم بنسبة 80% ويعمل بسرعة 140 رمزًا في الثانية باستخدام وحدتي H100، لكن سرعته البطيئة ومشاكل التكرار تثير تساؤلات حول جدواه العملية. يساعد التكميم الديناميكي في تحسين الأداء، ومع ذلك تستمر المخاوف بشأن إمكانية الوصول والتكلفة وادعاءات تكلفة تدريب النموذج، مما يؤدي إلى التدقيق. للنموذج تأثير ملحوظ على السوق، مع جهود جارية لتكرار نتائجه، رغم أن أدائه محل نقاش مقارنة بالنماذج الأكبر.

## [نتائج واعدة من DeepSeek R1 للرمز](https://simonwillison.net/2025/Jan/27/llamacpp-pr/)

طلب سحب (PR) من Xuan-Son Nguyen لـ llama.cpp يعزز سرعة WebAssembly (WASM) باستخدام تعليمات البيانات المتعددة ذات التعليمات الفردية (SIMD)، مع مساهمات كبيرة من DeekSeek-R1. يتضمن طلب السحب نموذجًا ديناميكيًا يُبنى من استجابات API، مما يلغي الحاجة إلى الإصدارات المرمزة بشكل ثابت، ويعرض الابتكار في تطوير الإضافات. يغطي مدونة سيمون ويليسون أيضًا مواضيع حديثة مثل مشاريع المصادر المفتوحة، وواجهة برمجة تطبيقات الاستشهادات من أنثروبيك، ومشاريع النماذج اللغوية الكبيرة (LLM)، مما يشير إلى تركيز على مناقشات التكنولوجيا المتقدمة.

### [ردود الفعل](https://news.ycombinator.com/item?id=42852866)

يظهر DeepSeek R1 إمكانيات الذكاء الاصطناعي في البرمجة من خلال كتابة 99% من طلب السحب (PR) لمشروع llama.cpp، مما يبرز الدور المتزايد للذكاء الاصطناعي في تطوير البرمجيات. أدوات مثل aider مسؤولة الآن عن توليد 70-82% من الشيفرة الجديدة في الإصدارات، مما يشير إلى زيادة كبيرة في الإنتاجية من خلال المساعدة بالذكاء الاصطناعي. على الرغم من هذه التطورات، لا يزال الذكاء الاصطناعي يتطلب إشرافًا بشريًا لحل المشكلات المعقدة والتكامل مع قواعد الشفرات الحالية، مما يشير إلى تحول في ديناميكيات الوظائف ومتطلبات المهارات في الصناعة.

## [النسخة المصورة من DeepSeek-R1](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)

DeepSeek-R1 هو نموذج ذكاء اصطناعي تم إصداره حديثًا يركز على تحسين قدرات التفكير من خلال عملية تدريب مكونة من ثلاث خطوات: نمذجة اللغة، التعديل الدقيق تحت الإشراف (SFT)، وضبط التفضيلات. يدمج النموذج سلاسل طويلة من بيانات التفكير، ونموذج تفكير مؤقت، وتعلم التعزيز على نطاق واسع (RL)، مما يجعله يتفوق في مهام التفكير من خلال توليد رموز التفكير. يستخدم بنية مزيج من الخبراء، مما يسمح له بالتعامل بكفاءة مع مهام التفكير المعقدة، مما يمثل تقدمًا كبيرًا في تصميم نماذج الذكاء الاصطناعي.

### [ردود الفعل](https://news.ycombinator.com/item?id=42845488)

DeepSeek-R1 يثير النقاش بسبب أدائه وكفاءته من حيث التكلفة مقارنة بالنماذج مثل GPT وGemini، حيث أشار بعض المستخدمين إلى مشكلات نموذج اللغة الكبيرة (LLM) النموذجية. يتميز النموذج بمتطلبات حسابية منخفضة وطبيعته مفتوحة المصدر، مما قد يغير مشهد الذكاء الاصطناعي ويجعل تطوير الذكاء الاصطناعي أكثر سهولة. تم تطويره من قبل صندوق تحوط صيني، مما يثير تساؤلات حول بيانات تدريبه والآثار الجيوسياسية، على الرغم من التقييمات المتباينة لقدراته في البرمجة.

## [التعلم الآلي في الإنتاج (دورة جامعة كارنيجي ميلون)](https://mlip-cmu.github.io/s2025/)

تقدم جامعة كارنيجي ميلون دورة بعنوان "التعلم الآلي في الإنتاج/هندسة الذكاء الاصطناعي" لربيع 2025، تركز على بناء ونشر وصيانة منتجات البرمجيات المدعومة بالتعلم الآلي. تؤكد الدورة على ممارسات الذكاء الاصطناعي المسؤولة وعمليات التعلم الآلي (MLOps)، وتغطي دورة الحياة الكاملة من النموذج الأولي إلى الإنتاج. تم تصميمها للطلاب الذين لديهم مهارات في علوم البيانات والبرمجة الأساسية، وتتميز بمحاضرات ومعامل ومشروع جماعي، مع توفر الموارد على GitHub.

### [ردود الفعل](https://news.ycombinator.com/item?id=42847834)

تقدم دورة جامعة كارنيجي ميلون حول تعلم الآلة في الإنتاج أدوات عملية مثل كافكا، دوكر، كوبرنيتس، وجينكينز، مع التركيز على عمليات تعلم الآلة (MLOps)، التفسيرية، العدالة، والمراقبة. يعمل كجسر بين تعلم الآلة وأنظمة الإنتاج، على الرغم من أن البعض يرونه كمستوى مبتدئ ويركز أكثر على تكامل الأدوات بدلاً من الإتقان. تُثار مخاوف بشأن الأهمية طويلة الأمد لبعض الأدوات والتركيز المحدود للدورة على جودة البيانات، ومع ذلك تُعتبر نقطة دخول جديدة لطلاب علوم الحاسوب.

## [Open-R1: إعادة إنتاج مفتوحة لـ DeepSeek-R1](https://huggingface.co/blog/open-r1)

Open-R1 هي مبادرة تهدف إلى تكرار نموذج DeepSeek-R1، وهو نموذج استدلال يمكن مقارنته بنموذج o1 الخاص بـ OpenAI، مع التركيز على الشفافية والتعاون المفتوح المصدر. يسعى المشروع إلى إعادة إنشاء مجموعات بيانات DeepSeek-R1 وخط أنابيب التدريب، والتي لم يتم الكشف عنها حاليًا، باستخدام التعلم المعزز (RL) دون إشراف بشري. يشجع Open-R1 مساهمات المجتمع لتوسيع تطبيقات النموذج إلى ما وراء الرياضيات، بما في ذلك مجالات مثل البرمجة والطب.

### [ردود الفعل](https://news.ycombinator.com/item?id=42849536)

Open-R1 هو مبادرة تهدف إلى إعادة إنشاء نموذج DeepSeek-R1 باستخدام مبادئ المصادر المفتوحة، على الرغم من أنه ليس نموذجًا فعليًا بعد. تؤكد المناقشة على التحديات والفوائد المحتملة لإعادة إنتاج نماذج الذكاء الاصطناعي بميزانية محدودة، بالإضافة إلى تأثير الذكاء الاصطناعي على التعليم والآثار الأوسع على المجتمع. تسلط المحادثة الضوء أيضًا على الحماس المحيط بالتقدم التكنولوجي ودور حركة المصدر المفتوح في جعل الذكاء الاصطناعي أكثر وصولاً لجمهور أوسع.

## [مستقبل Rebble](https://rebble.io/2025/01/27/the-future-of-rebble.html)

### [ردود الفعل](https://news.ycombinator.com/item?id=42845017)

تسلط المناقشة الضوء على الحنين إلى ساعات Pebble الذكية، التي كانت تُقدّر لشاشاتها المشابهة للحبر الإلكتروني وعمر بطاريتها الطويل، وتتساءل عن سبب عدم تبني تكنولوجيا مماثلة بشكل أوسع. هناك اهتمام بالإمكانيات المحتملة للأجهزة الجديدة من Rebble، وهو مشروع مدفوع من المجتمع، وطبيعة المصدر المفتوح للمشاريع المتعلقة بالساعات الذكية. يتم ذكر بدائل مثل Watchy وPineTime، حيث يلاحظ المستخدمون التحديات البرمجية التي تواجهها في مجال الساعات الذكية مفتوحة المصدر.

## [أسطورة الألفا: كيف أضلتنا الذئاب الأسيرة](https://anthonydavidadams.substack.com/p/the-alpha-myth-how-captive-wolves)

### [ردود الفعل](https://news.ycombinator.com/item?id=42844619)

تم دحض مفهوم "الذكر المسيطر" في الذئاب، الذي كان يستند في الأصل إلى دراسات على الذئاب الأسيرة؛ حيث تعمل مجموعات الذئاب البرية بشكل أشبه بوحدات عائلية بدلاً من الهياكل الهرمية. على الرغم من دحضها، تظل فكرة "الألفا" قائمة بسبب جاذبيتها في البيئات التنافسية، مثل وادي السيليكون، وتوافقها مع بعض الاحتياجات المجتمعية والنفسية. استمرار الإيمان بأسطورة "الألفا" يبرز كيف يمكن للسرديات أن تؤثر على تصورنا للديناميات الاجتماعية، حتى عندما تكون مبنية على افتراضات غير صحيحة.

## [أداة Go 1.24 هي واحدة من أفضل الإضافات إلى النظام البيئي منذ سنوات.](https://www.jvt.me/posts/2025/01/27/go-tools-124/)

يقدم الإصدار 1.24 من Go أمرًا جديدًا `go tool` وتوجيهًا `tool` في `go.mod`، مما يعزز إدارة أدوات المشروع في نظام Go البيئي. يُعالج هذا التحديث المشكلات المتعلقة بنمط `tools.go`، مثل تأثيرات الأداء وانتفاخ شجرة التبعية، من خلال السماح بإدارة أكثر كفاءة للأدوات وتقليل التبعيات غير الضرورية. بينما يحسن أمر `go tool` الأداء عن طريق تخزين استدعاءات `go run` في الذاكرة المؤقتة، هناك مخاوف بشأن اعتبار تبعيات الأدوات غير مباشرة، مما قد يؤدي إلى تعارض في التبعيات.

### [ردود الفعل](https://news.ycombinator.com/item?id=42845323)

أدى تقديم "أداة go" في Go 1.24 إلى نقاشات حول تأثيرها على إدارة التبعيات، مع مخاوف بشأن دمج أدوات وتبعيات المشاريع مما يسبب صراعات. يقترح النقاد بدائل مثل ملفات الوحدات المنفصلة أو استخدام أدوات مثل Nix لتحسين التحكم في الإصدارات. يجادل مؤيدو نهج Go بأنه يوفر البساطة والفعالية، مما يعكس التحديات الأوسع في إدارة التبعيات عبر لغات البرمجة.

## [لقد وثقت في نموذج لغوي كبير، والآن أنا في اليوم الرابع من مشروع بعد الظهر.](https://nemo.foo/blog/day-4-of-an-afternoon-project)

بدأ المؤلف مشروعًا يسمى Deskthang، يهدف إلى إنشاء جهاز مكتبي باستخدام Raspberry Pi Pico، وشاشة LCD، وLEDs RGB، مع اختبار قدرات الذكاء الاصطناعي. أدوات الذكاء الاصطناعي مثل ChatGPT وClaude ساعدت في البداية ولكنها أدت في النهاية إلى تنفيذ مليء بالأخطاء، مما تسبب في مشاكل مثل تعارضات المخزن المؤقت وفساد البيانات. تشمل الدروس الرئيسية المستفادة التعرف على الذكاء الاصطناعي كأداة بدلاً من كونه مساعدًا، وفهم قيمة الاحتكاك والأخطاء في عملية التعلم، وأهمية الصبر على الثقة الزائدة.

### [ردود الفعل](https://news.ycombinator.com/item?id=42845933)

يمكن أن تكون نماذج اللغة الكبيرة (LLMs) مفيدة للمهام البسيطة ولكن قد تمدد جداول المشاريع الزمنية إذا تم الاعتماد عليها في حل المشكلات المعقدة دون إشراف مناسب. هم فعالون في تلخيص المعلومات ولكن قد يواجهون صعوبة مع المواضيع المتخصصة أو المعرفة الجديدة، مما يتطلب من المستخدمين أن يكون لديهم أساسيات قوية وخبرة. يجب على المستخدمين الحفاظ على السيطرة من خلال تقديم مطالبات واضحة ومراجعة المخرجات بشكل نقدي لاستغلال الإمكانات الكاملة لنماذج اللغة الكبيرة بفعالية.

## [إنفيديا تفقد ما يقرب من 600 مليار دولار من قيمتها السوقية](https://www.cnbc.com/2025/01/27/nvidia-sheds-almost-600-billion-in-market-cap-biggest-drop-ever.html)

عانت القيمة السوقية لشركة Nvidia من خسارة تاريخية تقارب 600 مليار دولار، حيث انخفضت الأسهم بنسبة 17% بسبب مخاوف المنافسة من مختبر الذكاء الاصطناعي الصيني DeepSeek. أثرت عمليات البيع على قطاع التكنولوجيا الأوسع في الولايات المتحدة، مما تسبب في تراجع شركات مثل ديل وأوراكل، وساهم في انخفاض بنسبة 3.1% في مؤشر ناسداك. نموذج الذكاء الاصطناعي الجديد لشركة DeepSeek، الذي تم تطويره باستخدام رقائق H800 من Nvidia، قد زاد من مخاوف المنافسة، مما أثر على أسهم Nvidia على الرغم من مكاسبها السابقة، وقلل من صافي ثروة الرئيس التنفيذي جنسن هوانغ بمقدار 21 مليار دولار.

### [ردود الفعل](https://news.ycombinator.com/item?id=42845681)

شهدت القيمة السوقية لشركة إنفيديا انخفاضًا كبيرًا يقارب 600 مليار دولار، مما أدى إلى نقاشات حول تقييم الشركة وما إذا كانت مبالغًا في قيمتها. على الرغم من رد فعل السوق، تظل وحدات معالجة الرسوميات من Nvidia حاسمة للمهام المتعلقة بالذكاء الاصطناعي، مما يبرز أهميتها في صناعة التكنولوجيا. يمكن أن يكون تركيز وسائل الإعلام على الخسائر المالية الكبيرة دون النظر في التضخم مضللًا، لكن تراجع شركة إنفيديا يُعتبر ملحوظًا حتى بين الشركات الكبرى.

## [Janus Pro 1B يعمل بنسبة 100% محليًا في المتصفح على WebGPU](https://old.reddit.com/r/LocalLLaMA/comments/1ibnso0/janus_pro_1b_running_100_locally_inbrowser_on/)

### [ردود الفعل](https://news.ycombinator.com/item?id=42852400)

يُعتبر نموذج Janus Pro 1B نموذجًا يعمل محليًا في المتصفح باستخدام WebGPU، مما يُظهر القدرة على تنفيذ نماذج الذكاء الاصطناعي في بيئة المتصفح. وعلى الرغم من عدد معاييره المنخفض الذي يحد من قدراته، إلا أن النموذج يمكنه العمل على وحدات معالجة الرسومات ذات الأداء المنخفض، مما يبرز سهولة الوصول إليه. وبينما تكون نتائج توليد الصور غير متسقة، فإن القدرة على تشغيل مثل هذه النماذج محليًا في المتصفح تُعد تقدمًا تكنولوجيًا كبيرًا، على الرغم من أنه لا يدعم حاليًا الأجهزة المحمولة.

## [باحثو بيركلي يكررون تقنية DeepSeek R1 الأساسية مقابل 30 دولارًا فقط: تعديل بسيط](https://xyzlabs.substack.com/p/berkeley-researchers-replicate-deepseek)

### [ردود الفعل](https://news.ycombinator.com/item?id=42855283)

نجح باحثو بيركلي في تكرار التكنولوجيا الأساسية لـ DeepSeek R1 بتكلفة لا تتجاوز 30 دولارًا، مع التركيز على مهام محددة مثل لعب لعبة العد التنازلي. يتضمن الابتكار استخدام التعلم المعزز، وهو نوع من التعلم الآلي حيث يتعلم الوكيل من خلال التفاعل مع بيئته، لتعزيز نماذج الاستدلال، على الرغم من أن تطبيقه يقتصر على المجالات ذات الحلول القابلة للتحقق. تؤكد المناقشة على الإمكانيات لتحسين الذكاء الاصطناعي لنفسه وآثاره على تطوير الذكاء الاصطناعي في المستقبل، على الرغم من الانتقادات الموجهة لعنوان المقال المضلل وافتقاره إلى روابط المصادر المناسبة.

<head>
  <meta property="og:title" content="نحن نعيد Pebble" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://og.cho.sh/api/og/?title=%D9%86%D8%AD%D9%86%20%D9%86%D8%B9%D9%8A%D8%AF%20Pebble&subheading=%D8%A7%D9%84%D8%AB%D9%84%D8%A7%D8%AB%D8%A7%D8%A1%D8%8C%20%D9%A2%D9%A8%20%D9%8A%D9%86%D8%A7%D9%8A%D8%B1%20%D9%A2%D9%A0%D9%A2%D9%A5%3A%20%D9%85%D9%84%D8%AE%D8%B5%20%D8%A3%D8%AE%D8%A8%D8%A7%D8%B1%20%D8%A7%D9%84%D9%82%D8%B1%D8%A7%D8%B5%D9%86%D8%A9" />
</head>
